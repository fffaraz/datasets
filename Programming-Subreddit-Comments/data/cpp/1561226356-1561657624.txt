\&gt; It was designed long before coroutines and will require serious rework to integrate *elegantly* with them Corentin has been bloviating about his dislike of Networking TS for some time, and his objections are entirely subjective (e.g. "elegantly"). Therefore, I am responding with my own subjective interpretation. One cannot "prove" or "disprove" elegance, which is why I find Corentin's comments particularly useless and divisive. On the other hand, there is much to say about Networking TS which is entirely objective: It is mature, used in many places, has been built upon and written about, and for the most part it represents established practice. When Corentin repeatedly ignores these things and blurts his feelings instead, I think it is fair for me to say that he should stay in his lane. No one else will do it because there is an epidemic of over-politeness that has seized the hearts and minds of cplusplus-land (excluding Ville of course) so the task falls to me. One can almost hear the collective approval and nodding of heads in agreement with me.
Please, stop adding "simple"(which means half-baked, unable to be used seriously) graphics library to the standard library.
That's how it's presented indeed, however the benchmarks used are mostly regular C or C++ programs and it performs better than other malloc implementations on these generic workloads according to the authors.
It is also discussed in the research paper, and on the suite of benchmarks presented mimalloc generally outperforms it; furthermore, in the few cases snmalloc is faster, it's only marginally so.
I think his opinion will find more support outside the committee. Mature and stable should not equate to standardized inclusion IMO. That’s just not the language we have. I’ve worked on large scale projects that rely on ASIO and the compile times are absolutely killer because of the over templatization and I fear the same for the proposed standardized implementation (I switched to libuv with good success). But yea from reading this doc I can tell I would also be at great odds with the committee. :/ The core issue if anything is a lack of alignment as I no longer feel I’m a core audience for the language. Incidentally, ASIO actually has far less success in the industry than you allude to (all the big tech firms have custom solutions after all) so if anything, you’re the one making subjective claims.
&gt; I feel like I want "zero cost" abstractions. If I didn't care about zero cost, I wouldn't us C++ and a lot of the existing friction is due to features that exist today that have too high of an abstraction penalty, resulting in fragmented usage and confusing communication on best practices. I love "zero cost" or "zero overhead" abstractions, however regular "zero overhead" is in tension with ergonomics or safety. In this case, I personally think it makes sense to provide both: - The "zero overhead" abstraction, for performance. - The lightweight abstraction, for convenience. Furthermore, it's important to realize that even when performance matters, an extra 1% slow-down is perfectly acceptable. Therefore, sufficiently lightweight abstractions can be used in all but the most performance critical spots.
It seems all of them are commercial, such as [SuperTest](https://solidsands.com/supertest).
Sanitization, probably.
Isn't there many other aspects of C++ that are more important than on which side you write the const keyword?
Thanks, updated.
\&gt; the compile times are absolutely killer because of the over templatization I think it is unfair to blame the library when the long compile times are caused by misuse. My projects have absolutely no problems with compile times. Understanding how to design and maintain the physical structure of a program to keep compile times reasonable in the face of heavily templated libraries is part of the required skillset of a good C++ engineer.
Yeah. east const vs west const is just a fun little debate that anyone can partake in, no matter the level of experience. Nothing wrong with having a bit of fun.
Whoa. &gt; Allocators are interesting as there exists no algorithm that is generally optimal -- for a given allocator one can usually construct a workload where it does not do so well. (proceeds to do well under all workloads) This seems to explicitly hit all the major pain points I'm aware of w.r.t. allocation. If I had to hunt for missing bits I would say: * It doesn't explicitly mention `realloc`, which is important during incremental construction of dynamic arrays. (`obstack` is better, but you can't expect people to use it) * Is this prone to hitting the 64k `mmap` limit, or is there enough coalescing to avoid it? * Old allocators used to deliberately avoid eagerly returning memory to the system. Is `MADV_FREE` enough to completely negate that? * How does the cache-line-sharing logic deal with partial frees from another thread? How hard is it to construct a case that will be nasty? Several of the URLs have invisible Unicode characters in them that break the links.
You are misinformed. This is the only important issue. Jokes aside. East Const is correct const, or consistent const West Const (aka Const West) is conventional const. We can't keep using the excuse that old resources use an old convention and old style methodologies... of course they do. I'm not going to pick up a book teaching C++98 and it talk about smart pointers, or CTAD. Just because it was how things were done, doesn't mean its a valid argument for why thy shouldn't change.
I'm not claiming it's the only thing or most important thing.
Can you please listen to yourself? You immediately jumped to the conclusion of misuse before thinking about the use case (lines of code, number of people working on the project, etc). The premise of your argument is once again, that the person you're talking to isn't a "good C++ engineer" as in your first post. I'm starting to see a pattern. Trying to reduce compile times by sidestepping templates sidesteps the issue of cases where a template *was not the right choice* in the original interface which is overly generalized depending on user needs. All the socket variants, endpoints, etc are templatized and frankly, I shouldn't have to worry about this.
`&lt;algorithm&gt;` being parallelized and OpenMP being standardized in the language are *not* the same thing.
&gt; All the socket variants, endpoints, etc are templatized and frankly, I shouldn't have to worry about this. I agree that there should be a non-templated layer which addresses your use-case but that layer should not be Networking TS. There is a noteworthy lack of supporting documentation and explanatory exposition surrounding asio and net TS, and it is a common error for users to assume that the types exposed by the networking library are suitable as vocabulary types throughout an entire project. Often they are not. Once Net TS is standardised, then we will see investment in those vital layers that sit above it which address the valid issues you brought up. However, to say that what we standardise should be that higher level layer instead, is a design mistake (the same one that Corentin is implying).
Central const is the winner. `inconstt`
I acknowledge the sentiment, but still disagree. Well, let's see how people take Python 3 (which breaks compatibility and has a migration plan)? Not so well, and 12 years later some people have not migrated. If it ain't broken, don't fix it. What a painful process! And blaming the environment doesn't fix their problem. What are they going to do then? Roll their own buggy implementation?
Thanks for pointing it out. Didn't notice the lower case. But except that I believe my other points still stand.
At first I hated it. But then I found a property that I really loved: you first see a type or a placeholder, then you see what kind const reference, rvalue reference etc. And how it is passed around stay together `const&amp;` `&amp;&amp;` etc. I don't need to look at many places to see if it's a const reference or by other means.
Those companies may have a legitimate reason for those policy, such as size requirements (consider embedded environment), security requirements (mission critical and has limited outside Internet access), etc. Blaming them doesn't fix those problems.
I used to care and was at war. Now I no longer care and am at peace.
This will break function signatures as parameter's constness doesn't take part on overload resolution, while your suggestion embeds it in the type.
He's a good presenter. &amp;#x200B; That's all.
Could you hazard an estimate at how many translation units in that codebase pulled in asio?
Let's talk about tabs vs. spaces
Nonsense, the compiler merely determines that it is central const and removes the 'const' from the type beforehand.
Yours isn't centered, though. ´iɾconstɿt´
Use a very well designed c++ project as a template, e.g. [nlohmann/json](https://github.com/nlohmann/json) is very good. E.g have a good readme, cmake build, Travis builds, release numbers, coverage analysis, etc.
Why would you say something so controversial yet so brave?
There exists a superior alternative that also settles the asterisk issue. https://pbs.twimg.com/media/D5_7BU8UEAEM61_.png
Typically name voting is "here are a bunch of names, vote yes to any/all that you are OK with", and then we narrow it down, then do a "OK pick one".
In an ordinary range-based for loop, the thing you're iterating over isn't (can't be) a constant expression. So like, this doesn't work: template &lt;int&gt; struct X { }; for (int i : view::iota(10, 20)) { X&lt;i&gt; x; // nope } But with an expansion statement, we're effectively instantiating the body of the for loop for each iteration, so these things actually _are_ constant expressions: for ... (constexpr int i : view::iota(10, 20)) { X&lt;i&gt; x; // ok }
The extreme templatization is turning it into alphabet soup. There was some discussion of this on a thread of mine here, where I presented a way to do something in my CIDLib system and someone else presented a semi-alternative, not quite the same since it's still a template. Here is mine, which loads any type of collection with some strings. Just a token example of course: tCIDLib::TVoid LoadCollection(TCollection&lt;TString&gt;&amp; colToload, const tCIDLib::TCard4 c4Count) { TString strTmp(L"Value #"); const tCIDLib::TCard4 c4BaseLen = strTmp.c4Length(); for (tCIDLib::TCard4 c4Index = 0; c4Index &lt; c4Count; c4Index++) { strTmp.CapAt(c4BaseLen); strTmp.AppendFormatted(c4Index + 1); colToload.objAdd(strTmp); } } Here is his, STL based one: template&lt;class T&gt; auto push_back = poly_method&lt;void(T const&amp;), void(T&amp;&amp;)&gt; ( [](auto&amp; self, auto&amp;&amp; arg){ self.push_back( decltype(arg)(arg) ); } ); void populate(any_view&lt;&amp;push_back&lt;std::string&gt;&gt; target, int count) { for (int i=0; i&lt;count; ++i) target-&gt;*push_back( fmt::format( "Value #{1}", i ); } I mean, in comparison, mine is practically natural language. And I bet if I showed the latter to ten average C++ programs, they would have to take quite a good look at that to even understand what's going on.
3. modify `switch`. ie `switch inspect` or `switch [asdf]` or whatever.
Before auto you explicitly indicated the types of things, which I argue is still the correct thing to do if you aren't writing trivial software. Of course because STL is templated to death and so many things become incredibly wordy, it pushes people towards use of auto. But I argue that failure to be as explicit as possible is just asking for problems in large code bases maintained over time.
`realloc` is pretty much just `malloc`-`memcpy`-`free`, see https://github.com/microsoft/mimalloc/blob/69efa50a0d4b86a86ab579836efb60db95242867/src/alloc.c#L326
Standardizing sockets/timers/io\_context now, before executors are part of the standard library, would require breaking compatibility in the future. Judging by the amount of grief that a recent breakage in ASIO (related to executors) caused (in an interface that was deprecated for over 2 years), it's better not to introduce breakage in the standard library.
About 14 cubic feet
I would also put Apple Clang to the right side of MSVC. MSVC is by far the more important compiler, and it had its place there before.
He's asking for graphics to be added to the compiler so he can use them. That already indicates that it is not a hardware constraint, but purely a political one. And I'm not 'blaming' anyone, I'm only saying that the C++ community does not have to bend over backwards in order to accomodate absolutely every last piece of managerial madness on the face of the planet. Is Python building in all of PIP just so companies that don't allow internet can use them anyway? Is Rust shipping every crate on the planet with the compiler just to accomodate those people? No, they aren't - because it just does not make any sense. Why should it be any different for C++?
The reality is some companies even forbids pip usage in Python due to some of the reasons I stated earlier, which is also why Python's huge standard library contributed big to its success. Back to the point: Languages are supposed to accommodate different environments. If you don't adapt, they'll find another language that does, that's just the reality. Even if you don't care, it's still a loss to the language community.
There are ways of searching open source code nowadays. You could find out how often the std algorithms are used. (And I'll bet that it probably isn't used much, FBOW.)
Python 2.7 will not be maintained past 2020. (https://pythonclock.org/)
It will still be supported with an enterprise plan of sort by some distribution, mainly from Redhat.
 #define inconstt int const
&gt; However, the current process tends to reduce proposals to their most conservative cores. Because currently (almost) the only way of evolving C++ is addition, I'd expect people to be overly conservative. There needs to be a deprection/removal story.
*const*
/r/EnlightedCentrism
&gt; BTW, love the new Microsoft... keep up the good work. I don't know who's idea this was but the 'new' Microsoft is definitely working. I feel like for the younger generation Microsoft will have quite different appearance that for the people that started growing up with Windows 95.
Not all beginner c++ is single TU code though, e.g. One of my friends got into c++ through ue4
Much better. But can we leverage the Canadian Aboriginal block to make things clearer?
You can also do it with macros. `#define CONST(type) const type`, or even template aliases, `template &lt;typename T&gt; using const_t = const T;`. That way, everybody (nobody) is happy.
I do wish we had a natural way, right now, to express integer ranges. I'm fond of Ruby's syntax for it: `for (auto c4Index : 0 .. c4Count)` I've seen your example before, I believe. It was one of the things I'm referencing.
It's harder to find situations where it's *not* used. I know in most codebases I've worked on it is very rare.
nlohmann/json doesn't cover some common cases required for cpp projects in general since it is a header only library. in general cmake project needs to have proper handling of finding dependency packages, supporting shared and static linking builds, installing the binaries, installing the header files, installing cmake packages. there have been some posts specifically on this topic her in this subreddit.
So ultimately when we get constexpr pattern matching, it’s going to be three keywords in a row? Anyways, I trust the committee won’t transform it into an awful naming scheme. There’s a lot of smart people making difficult decisions.
I'd argue "please stop trying to I ckude graphics in the standard at all"
Thanks. What is the status of P1061?
&gt; That way, everybody (nobody) is happy. That's why I write pointer types as `int * p` instead of `int *p` or `int* p`.
I guess a lot of people are not happy with direction C++ has taken, i just wanted to point out that traditionally you can just ignore a vast portion of C++. It's been like that since the beginning, people just use what they consider a good subset of C++ ignoring the junk that is being added for whatever reasons. Those reasons are probably all good, but as they say, the road to hell is paved with good intentions. It might help to just chill and ban half of C++ in your coding guide. With that being said, i think Punk Revolution TS would a great addition to C++ regardless of its content.
this isn't go
`regular_ptr&lt;int&gt;`
But we can do so much worse than Go.
signed vs unsigned indices
What is the reason for this behavior?
* `string_view` constructor that takes two `const char*`s * `string_view` constructor that takes two `string_view::iterator`s * `path` constructor that takes two `path::iterator`s
Really? auto it = std::find(v.begin(), v.end(), 5); Please don't tell me you actually care about `it`'s type. Also how is this a maintenance problem?
P0533R**4** is displayed correctly, P0533R**5** is not, as far as I can see. I checked the HTML source, and it's written as "constexpr for and ".
&gt; Not so well, and 12 years later some people have not migrated. I don't see how that's an argument. There are still windows 3.1 systems in production, it does not mean that the world cannot advance in the meantime.
As someone relatively new here, how do the meetings work? Will the minutes be published, or is it a simple yes/no/postponed for the proposals?
The same software can run on Windows 3.1 and Windows 10 if you use the supported Win32 API. That's exactly how C++ did it right.
It would be interesting if this example started showing up in talks about making small types that differentiate these two uses of size_t and make it impossible to accidentally run into this.
Exactly, it's called tail call optimization.
Ah, I never really thought about it outside of recursive functions
I agree; I will pass the request along.
So transform_reduce does a transform using the last arg and a reduce using the second-to-last arg. So the name is transform_reduce and the order of operations is transform then reduce and the order of the args is.... reduce, transform
There has always been pressure and demand for heavy syntax for new features, followed by anger, blame, ridicule of said heavy syntax after some time of use. It is a problem that faces nearly every new proposal, and it is a tough one to navigate successfully.
I'm sorry, but to me this is natural. For some reason I tend to think of argument orders as outside-in. If anything, it's a bit strange to me that the collection argument comes first, but that's just STL algorithms have always been.
Do I? I could never look at that and know, because I don't know what it is, because you didn't indicate that explicitly.
Do you have examples of APIs with this order? Would you expect `divide(a, b)` to do `b/a` ?
Maybe because the result of transform is input to reduce, ie `reduce(transform(...`
It's actually pretty difficult due to transitive includes and all that and I no longer work on the project. Hundreds? Thousands? I have definitely worked with larger projects that didn't struggle to compile as much and things improved noticeably when the net layer was replaced.
Gonna try this also be good the graph it
"can't find a suitable member function"? Why not just make one? Doesn't this work: void concept_check() { static_assert(Shape&lt;Rectangle&gt;); }
Aliasing
Good point, I don't know why my mind was stuck on special members.
One thing I never get with these drop in allocators. If they truly are better than malloc in most cases, then why wouldn’t they change malloc to use these algorithms?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c3y0n1/any_good_starting_resources/ertz396/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
What I find odd is that there already are de facto sub dialects of C++, but driven by C++'s failings EG Embedded C++ is a totally different beast to gamedev, which is wildly different to application development. And for a lot of it, its not simply which language features are best, but because xyz features are poorly designed and simply don't work in a particular context (eg exceptions, throwing new, aspects of the STL, aos vs soa, features that are simply dangerous) A well designed dialect would have the opportunity to unite many of the existing de facto standards by making parts of the language usable again for various industries
I bet you love atan2. http://www.cplusplus.com/reference/cmath/atan2/
The new Microsoft came after open source won. If you want to support "new Microsoft" first you should support open source.
My point is that you know that `it` is an iterator. You don't need to explicitly spell out the type
There might be applications where a new allocator performs significantly worse, which is a regression you want to avoid.
Did anyone built the test and run them. heap stats: peak total freed unit count elapsed: 0.000 s process: user: 0.000 s, system: 0.016 s, faults: 644, reclaims: 0, rss: 2.2 mb
Many useful proposals. Thanks to the authors. Especially these three proposals are so important: * P1654R0 - as the document says impact of ABI compatibility now seriously hurts evolution of the standard. Lot of good proposals were shut down it's frightening. Time to do something about it. * P1485R1 - this. There is exactly 0 people in the world who like the co_ keywords. This proposal fixes that. * P1747R0 - there is no real benefit for using u8string over string. Size will still return number of bytes, [] still returns nth byte etc. No unicode algorithms. Why can't we just continue using string then? Programs which only store unicode strings are fine with that. Programs which need to do processing just assume utf8 everywhere. No need to differentiate between utf8 char and ascii char on language level. Fingers crossed these 3 will make it.
Please stop adding "simple" IO and half backed network APIs to the standard library.
No, it's not. Not all platforms support it. Implementations have freedom here, which is a feature, not a bug. If you are on a platform that supports 128bit lockfree atomics, then your C++ standard library is free to implement std::atomic with them. TL;DR - We already have 128bit atomics
With char\*, you get the overload `string&amp; append (const char* s, size_t n);` `Appends a copy of the first n characters in the array of characters pointed by s.` With std::string, you get the overload `string&amp; append (const string&amp; str, size_t subpos, size_t sublen = npos);` `Appends a copy of a substring of str. The substring is the portion of str that begins at the character position subpos and spans sublen characters (or until the end of str, if either str is too short or if sublen is` [`string::npos`](http://www.cplusplus.com/string::npos)`).`
This guy's pretty good. He basically won every speaker award at C++Now.
Back when I attended university, before the rise of C thanks to widespread use of FOSS, teaching C was already out of the curriculum. First year languages were C++ and Pascal. The department thought that with OWL, MFC, Turbo Vision, PowerPlant, CSet++, VCL, Motif++, Tools.h++, POET adoption across the industry, C was going to be just to do some UNIX stuff. Which were indeed the only classes that used plain C.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c3pkb7/what_to_do_after_learning_cpp_basics_and_simple/erudezf/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
As former C++ dev, I think it is easier to adopt a language that offers similar features, or at least features that covers one's use cases, than rebooting C++, which will be a new language anyway.
I think there will be a talk about the inner working of the committee at CppCon * Proposals go through a series of design reviews in Library Evolution, Evolution or both depending whether they are a language change, library change or both * We take strawpolls to determine whether we like a proposal, are happy with is as is and are not interested - we give recommandation to the authors * Once a proposal is approved by the evolution groups it goes through Library or Core which are the wording groups, they iterate the wording with the author until they are happy with the words * Then all the committee vote to approve or not a paper to be merged in the Working Draft of the next standard - restrictions applies as to who can vote there as it is an official, binding, ISO voting. It is rare people vote no at this stage because it does happen
Care to spell it out for those of us watching at home?
&gt;And blaming the environment doesn't fix their problem. What are they going to do then? Roll their own buggy implementation? Either that, or use off the shelf libraries, same as everybody else. If they need such a library to meet high security standards they can vet them (and perhaps release their results to the community, so everybody benefits).
&gt; P1747R0 This paper targets the teaching group. `u8string` is a null terminated sequence of bytes which is assumed to be utf8-encoded. whereas there is no such assumption for string/char* which are in an implementation defined encoding. A distinction is needed (unfortunately) between u8 string literal and char literals because char literals are not ascii but in some encoding that is implementation defined - and interpreted at runtime by the local-derived encoding which is a design that works so effectively anything that is not ASCII will break
Is almost 15 years in production considered half-baked state?
&gt; The things that people struggle with are You forgot error handling and debugging in the list. While the latter is outside of the language standard, both are, unfortunately, largely overlooked in teaching.
Maybe it works well, I don't know, but from the outside it looks a little suspicious when looking at the votes ([§4.5](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0288r4.html#name-options)). *mofun* and *mofunc* are very similar names and if you combine their votes you would far exceed the votes for *any\_invocable.* I guess many if not all of the votes were probably from the same persons so I'm more concerned about the other names. What if the people that voted for *movable\_function*, *mofun/mofunc*, *mvfunction*, *mfunction,* would all have preferred *movable\_function* over *any\_invocable*?
Quite a few people use C++ because they are dealing with non-trivial data sets, and they don't want their software to just abort on giant allocations. They also don't want to rewrite their software to put "try\_" on every potentially allocating function. If you want constexpr push\_back, by all means add a new constexpr function for that purpose. Just name it something else, and don't destroy our compatibility for your convenience.
&gt;Lot of good proposals were shut down it's frightening. Time to do something about it. The question is *what?* Breaking ABI is also scary.
The first programming language we used in School was C++. We worked a lot with stack allocated arrays and null terminated strings. I think it was alright because the goal was not to learn C++. It was just to learn the basics of programming and how to solve problems before we started with Java. This was about 15 years ago.
It's pretty much described by the user above. If you replace the char array with the string, the output will be 456 instead of 123 as they call different constructors.
Well any_function was on the list. They should have voted for it _as well as voting for mofun, etc_. Honestly, mofun/mofunc was only on the list because Saturday afternoon at the end of a long week of Committee leaves everyone burnt out but giddy. mofun/mofunc were _hilarious_. any_invocable sucks unless we start having more any_&lt;insert-concept-here&gt; so users see the pattern. If we do have more, it is great.
I actually do that. For the everybody/nobody reason, but more because the `*` is pretty important - make it stand out.
&gt; &gt; P1747R0 &gt; This paper targets the teaching group. This paper was drafted to ask that [P1389][1] remove the table for encouraging teachers to push `char8_t`-based types in C++20 because we're lacking full `char8_t` support. P1389 is currently locked, and changes can only be made if SG20 votes changes in. This proposal doesn't aim to kill `char8_t`-based types, and has no bearing on the language, nor the library. [1]: https://wg21.link/p1389
CTAD for alias templates is being proposed by [P1021](https://wg21.link/p1021). "lambda capture for structured bindings" is already approved and changes have been applied to the draft standard AFAIK.
My comment referred to avoid standarizing timers, `io_context` and other features that depend on those. In other words: why types like `std::socket` or `std::net_addr` would need executors?
Yes, and for that, you can have them use an IDE or a simple Makefile, as I mentioned, i.e. they were independent options depending on the needs.
&gt; traditionally you can just ignore a vast portion of C++ I feel like a vocal portion of the community wants to change that. Just see literally every mention of ”idiomatic C++”.
What realistic options are there if you require ability to seamlessly call C code (and use callbacks from that) and complete lack of GC / VM?
Well, on one hand there is "idiomatic C++" and on the other hand there are good practices, readability and maintainability. If former can not match the latter then you either has to stick to "idiomatic C++" with bad practices or ban "idiomatic C++" to reach your other goals ¯\\\_(ツ)\_/¯
Now if only the advocates would also understand that. What works in real world is far more important than any ideological purity or being ”idiomatic”.
Wait for modules. Textual includes make this simply insane to deal with.
I'm pretty sure ranges is going into c++20. One of the examples from the ranges-v3 user manual is using namespace ranges; std::vector&lt;int&gt; vi = view::for_each(view::ints(1,10), [](int i){ return yield_from(view::repeat_n(i,i)); }); // vi == {1,2,2,3,3,3,4,4,4,4,5,5,5,5,5,...} So view::ints(1,10) is pretty much the same as 1..10. Boost also has `counting_range` and `irange`. Both of which do the what you seem to want today.
Off the top of my head: Zig (C-like) and Rust (C++-like) fit the bill. There are probably other languages out there too, for early adopters: Myrrdin? Odin? V?
The question needing to be answered, the problem needing solving is : How can we make ABI break not scary?
That example is... vastly more verbose and arcane than what I proposed.
Ok, I moved the column. I also added documentation into the version templates using noinclude markup elements.
Yes, given what other programming languages offer and considering that Network TS might not make it in a full state. Also the same argument applies, not every deployment target supports all iostream features, or has even network capabilities, so why burden the language standard with them. C++ could have had something like OWL, PowerPlant since the get go, instead it lost the plot to managed languages for app development and now is being left to write low level system libraries or GPGPU code. Exactly because of the C attitude of OS APIs are only what matters.
FreePascal, Ada, D (you can disable GC if you so wish), Rust, Zig, Swift. For 99% of app development cases where using a tracing GC isn't an issue, D (now with GC enabled), .NET Native, Java AOT compiled (there is a new FFI in the works).
How is "views::ints(1,10)" *vastly* more verbose? It's also far *less* arcane, as it doesn't need parsing magic and a new token that is almost the same as an existing token (really two": . and ... are already tokens in c++) to work.
I know char is implementation defined. But my development style and libraries which I use are driven by practical needs not by what is clearly defined or not in the standard. I mean we all have been using DLLs and threads since ever there is nothing new about it. So what happens when we get u8string. As I said it's interface is still serving bytes so it's confusing in the same way as using std::string. Actually even more because std::string at least doesn't have u8 in it's name. No new unicode algorithms in the standard which would require to use it. Not compatible with existing unicode libraries which use std::string or frameworks like Qt/wxWidgets. Uglier to type. So far we have exactly zero reasons to use u8string. Then there is a theoretical chance for a program to deal with more kinds of strings including utf8 and ascii or local encoded strings. And for some reason you want to process your strings but you don't want to use any existing libraries out there which don't use char8\_t. In that case you might need to overload on char type to distinguish between your char and char8\_t. But why wouldn't you convert your strings to the same format at the point of input/output (most probably utf8 std::string or std::wstring if you wanna be windows only) and save yourself from all that pain? This kinds of overloading on character type is not a compelling use case to me. So what I predict is u8string will become just another string class without much adoption. It can go along u16string/u32string or historical wstring. And you can't change it. Unicode libraries exist, popular frameworks all use their own strings. People who just want to store unicode strings can use std::strings as usual. Committee should better invest time in designing unicode algorithms and ranges based on existing std::strings and chars. That would be truly useful at least for some people out there who are still waiting for the standard to include it.
I would like to see a discussion about why is not ABI tagging sufficient or where it fails. Techniques already exist.
I see. Teaching to use u8string with byte access and without any unicode algorithms is truly a crazy idea. That would be the last nail to it's coffin. But I would go even further and revise the whole char8\_t/u8string thing as described above.
Is appears that we have a fundamental disagreement and will just have to agree to disagree.
The immediate (C++20) benefit of char8_t literals is that char8_t will contain utf8 data instead of implementation specific data We agree this is far from sufficient and a lot of things will need to happen over the next few years to make C++ able to deal with Unicode sanely &gt; std::wstring if you wanna be windows only :(
Fortunately you don't need to use view::for\_each. Standard ``` for (int i : std::ranges::ints(1, 10)); ``` should do the trick. Yes namespaces are still verbose but you can always define an alias globally for your project. ``` namespace stx = std::ranges; ``` So I think the progress is there
Seems to me another perspective on this would see that as insecure, since the libraries they develop in-house wouldn't be exposed to the same vicious environment that widely adapted libraries have. If the in-house code ever got leaked, that seems like a massive security breach by simply not using tried and tested libraries. That being said, I think it would be unfair to plainly label it as a totally insecure practice, as off the top of my head I can't name a lot of open-source libraries that I would consider developed ground-up (and maintained as such) to be secure enough for highly sensitive information.
GCC 5 broke ABI - https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_dual_abi.html &amp;nbsp; Unaware users of ancient distros (read: RHEL) still occasionally run into obscure linker errors.
I am not advocating for wstring I use utf8 string on windows too. But all Microsoft tutorials make use of it including the new WinRT API [tutorials](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/strings) and so people will follow.
Yeah, I gathered you don't. But Microsoft's insistence on promoting wide strings makes me sad and makes teaching those things harder. I once had to seal with a commit that was "support Unicode" which did nothing but to replace hundreds of std::string by std::wstring (this is strictly a personal opinion)
That example is a poster-child for whats wrong with c++...
Sure it's not perfect for all projects, but it was a great help for my own header only library
You are going to have to help me out and explain more concretely what this solves and how you would use it. I understand that things like this can be difficult to explain, but I don't get what it is or what the point is with just the abstract in the post.
I really did not intend for that comment to start a discussion about code style. Hard pass.
Not really secretly. Step into new in the debugger and you'll see it uses malloc. For example in vs2017: _CRT_SECURITYCRITICAL_ATTRIBUTE void* __CRTDECL operator new(size_t const size) { for (;;) { if (void* const block = malloc(size)) { return block; } if (_callnewh(size) == 0) { if (size == SIZE_MAX) { __scrt_throw_std_bad_array_new_length(); } else { __scrt_throw_std_bad_alloc(); } } // The new handler was successful; try to allocate again... } }
Apple clang is also tied to your target OSX version. The most recent Apple clang will give you variant ... if you target the most recent OSX version. (For some reason, variant isn't a header-only feature)
You are still teasing instead of saying.
So, your macro does west const. Which means it is wrong. CONST(int *) * isn't a pointer to a constant pointer to int. I've used template aliases like that to deal with the insane way C++ expects you to have "operator return function pointer". Go ahead and write that one.
You should give it emphasis. int *** p make it bold.
east const best const west const worst const.
Reflection
The docs are pretty confusing, but as far as I was able to determine, "actions" are what is commonly called [actors](https://en.m.wikipedia.org/wiki/Actor_model).
I don't understand, what's so bad about standardizing low-level components first and then progressively going higher in abstractions? As far as I know, all languages that offer their own idiomatic networking facilties, offert both low level(TCP sockets) and high level interfaces (HTTP requests). I don't think it makes sense to call the proposal half-baked. After all, we don't call Quantum Electro-Dynamics a half-baked theory because it's low-level and isn't practical in some mundane applications. &amp;#x200B; As for the point that many targets don't have networking, therefore we shouldn't standardize it - by the same logic, many (mainstream!) targets don't have either threads or a general heap, should we also remove those from the standard?
 template &lt;typename T&gt; using const_t = const T const; #define CONST(type) const_t&lt;type&gt;
I don't like it either, but less face it: Windows, Java, Python, and Qt use UTF-16. Usually, because they added Unicode support early, when UCS-2 seemed to be enough back in the time. Fixing it now is hard, just like we can't fix many things in C++ standard. So for now, it seems like wide strings are the only answer for Unicode on Windows. Even [UTF-8 Everywhere](http://utf8everywhere.org/#windows) suggest using wide strings when interfacing with Windows API (but immediately convert them to UTF-8 and store them this way internally).
"when interfacing" being the key part !
As /u/c0r3ntin and /u/cjdb answered already, my paper is about the question what to teach, not anything about the standard itself. For the reasons to have `char8_t` in the language, see the motivation section in [p0482](http://wg21.link/p0482) (mainly overloading / template specialization over it)
\`atan2(a, b)\` does arctan(a/b), so what's the problem?
\`std::socket\` without executors would be a glorified RAII wrapper over \`int\`, which doesn't bring that much value. In fact, most of the value that the Networking TS provides, comes from the concepts it standardizes, because they enable interoperation between unrelated libraries. &amp;#x200B; As for non-async I/O being sufficient - that may be true for client-side applications, but on the server side, it's very easy to use an excessive amount of resources (mostly memory) when you do async I/O. I'm doubtful synchronous interfaces indeed cover most situations where C++ would be used.
The (non-live) example in 9.6.1 is incomplete, the live example is ok.
What's "TR"? I can't see the abbreviation defined anywhere in the document. I know "TS", but "TR" I can't remember. Would be good if the document defined all the abbreviation that it uses, as is standard writing practice.
If anything, C++ is becoming *less* verbose as time goes on. Once upon a time to iterate over a `std::list&lt;std::string&gt;` I'd have had to say something like for (std::list&lt;std::string::const_iterator i = my_list.begin(); i != my_list.end(); ++i) { // ... } whereas now I can say for (auto it = my_list.begin(); it != my_list.end(); ++it) { // ... } or just for (auto&amp; s : my_list) { // ... } Once upon a time I'd have had to spend time making sure that every class with an owning pointer member had correct (or deleted) copy constructors and copy-assignment operators; now I can just add a `unique_ptr` member and everything works correctly. Once upon a time I'd have had to write a separate function or function object to use a custom comparator with `std::sort`. Now I can just pass a lambda directly. Once upon a time I'd have had to write half a dozen different "overloads" of the same class to handle variable numbers of template parameters. Now I can just use a parameter back. Once upon a time I had to write recursive functions and a special base case. Now I can often just use a fold expression. Once upon a time I'd have had to do offensive amounts of template metaprogramming to compute anything at compile time. Now I can use a constexpr function. Today I have to do horrible things with `std::enable_if` to correctly constrain my template parameters . Soon I will be able to use concepts. Today I need to say `r.begin()` and `r.end()` everywhere when using STL functions. Soon (or today, in fact, using third-party implementations) I can just pass a range directly instead. ...and those are just off the top of my head. There's no denying there's a lot of cruft in C++, and many bad defaults, but in general it's heading in the right direction.
come on, boost.ranges has existed for ... 20 years and does exactly that. This is 99.999% of what people want.
Sure, but it's y then x, which isn't what you'd normally expect. Say you're trying to convert to polar coordinates. Vector2f v; float theta = atan2(v(1), v(0)); Always looks awkward (but makes sense mathematically, I guess).
...except, sadly, `accumulate` won't have such an overload in `20, because it's in `&lt;numeric&gt;` and not `&lt;algorithm&gt;` :(
&gt; I wish we could claim @ or some other unused syntax for unique pointers. then you'd get a vocal 30% complaining that the language is even more unreadable.
&gt; &gt; &gt; In short, mixing and matching of compilers and standard libraries is possible, allowing older compilers to compile newer code with new, but strictly library, features. outside of clang supporting both libstdc++ and libc++, I don't know of any other combination that works. gcc does not support libc++, msvc only supports its own standard library... The reality of the thing is, most standard libraries use a lot of compiler intrinsincs so unless all the compilers implement the same intrinsincs it's not going to work.
Well that is the logic that is being used when arguing against graphics library inclusion. So...
Technical report IIRC
Yeah, and that also helps access stand out! `***p = 17`.
BSL would have been better.
Clang can also use MSVC library. ALso, gcc can use libc++, you'll just have to figure a few things out, like the correct set of `-l` flags, system root, `-isystem` flags and so on, but it's definitely possible.
I'm sure people are working on books for 20 and modern c++ ! I'm especially looking forward to Sean Parent's
Ca we actually list them _all_? Or, being "anything not defined", do we always miss some? (This doesn't mean we shouldn't list what we know)
Thanks. Don't take this the wrong way, but it does sound like build times could have been improved with better physical design (using the term in the sense used by the Lakos book). Several large codebases I've worked on have gone to some lengths to avoid expensive (e.g. boost) headers getting transitively included, using explicit instantiation and extern templates to keep common instantiations in a single TU, for example. I appreciate that's not ideal or obvious as a library user, and it's an extra engineering problem to take on - but not an insurmountable one.
The document mentions "List all the explicit undefined behavior in the core language" as a goal. It does not seem to be concerned with the "anything not defined" case and so it is much more feasible.
Okay, I see what you mean! Thanks. I don't think it looks particularly awkward or more awkward than `atan2(v(0), v(1))`.
&gt; `std::socket` without executors would be a glorified RAII wrapper over `int`, which doesn't bring that much value. That is a bit like saying `std::thread` is a glorified RAII wrapper over `int` which doesn't bring that much value. It would be the standard way of representing a socket, which can then be used in several networking libraries right away. More importantly, it would bring a portable way to create a socket. Same applies for network addresses, endpoints, etc. Can you provide an example of `std::socket` without executors that would not work when executors and async I/O come into the standard? In other words, why are they interleaved? Why do we need everything at the same time? &gt; because they enable interoperation between unrelated libraries. Yes, more concepts would bring more interoperation, but clearly having the traditional sockets interface years ago would have been much more important. &gt; As for non-async I/O being sufficient - that may be true for client-side applications, but on the server side, it's very easy to use an excessive amount of resources (mostly memory) when you do async I/O. I'm doubtful synchronous interfaces indeed cover most situations where C++ would be used. Asynchronous I/O is not a hard requirement to achieve very high performance servers. Even if that were true, that does not mean you cannot standardize the traditional interface. I am unsure about what you mean by synchronous I/O having more resource usage. Can you expand?
Thanks for pointing out that someone else provided an explanation. I see that /u/htnshtns123 explained the situation around the time I asked my question. I bet that he posted when I had the page open (which I did for a while on my phone) and then I later submitted my question. :-)
Thanks for correction! I did not expect such an omission. Is there any technical reason?
Doesn't the C standard have such an Annex? I would argue that calling out behaviors that are undefined because they are never defined would be very helpful, as merely looking for "undefined" or "UB" does not locate such occurrences, but I also wonder whether such an enumeration is possible and finite.
This!
Thanks for this!
Pardon my ignorance, but what would that even mean? How can a thread be constexpr?
I'm just curious. Do people think this is the right direction to add pattern matching to C++? It's indeed very powerful, with full of special syntax and customization points for more than simple matchings. Is that what you want?
This is very much needed. I attended a talk on UB at CppCon 17, and a major problem is that there is no canonical list.
Most of the benchmarks they show are about small short-lived allocations. It appears there are real-life workloads where it performs badly: https://github.com/microsoft/mimalloc/issues/11 Author replies it is optimized of short-lived small allocations, not long-lived large ones.
If it can be done well syntactically and reasonable performance then absolutely. There are plenty of times where I have to deal with writing code that deals with parsing or dealing with many possibilities where pattern matching is so much more natural. At those times I really wish I could use something like Haskell or Elixir. Now that I see rust has it too, I might look mixing it with c++ though.
My problem with Rust’s pattern matching is that it’s hard for me to discern runtime costs. I know that it’s 99% of the time not important at all, but I’m used to looking at code and having a good mental model of costs.
I'd like a better random api and a fast small rngs included
This is very much needed. I attended a talk on UB at CppCon 17, and a major problem is that there is no canonical list.
Don't quote me on that but i believe this proposal is designed to be, at worse, linear with the number of patterns - which should at least make it as efficient as possible. Of course dynamic casting is never free. Gotta pay for what you use.
Have you looked up of your compiler actually implemented the stuff? They dont implement 100% of what the standard says
/r/cpp_questions
Sadly, Clang (or more specifically its usual standard library implementation, libc++) doesn't implement have the parallel STL functions yet, [according to cppreference](https://en.cppreference.com/w/cpp/compiler_support). For the second part, you need to use Unicode character literals: int main() { char8_t i = u8'a'; char16_t you = u'你'; char32_t laugh = U'😂'; return 0; }
That's a great idea.
Why?
Graphics library issue is solved with "vcpkg install &lt;whatever_you_like&gt;". It's far better to advertise vcpkg, instead of adding useless "newbies only" features
I encourage people to develop some closed source software. I have a code generator that blends closed and open source.
Well, for the case of `import` we aren’t done yet. We often underestimate the value of simplicity :-( Full disclosure: I am not a bug fan of contextual keywords.
&gt;Can you provide an example of &gt; &gt;std::socket &gt; &gt; without executors that would not work when executors and async I/O come into the standard? In other words, why are they interleaved? Why do we need everything at the same time? In order to support async operations, a socket object needs to store: \- the executor \- the per-descriptor state (implementation detail) &amp;#x200B; The executor has to be user-provided, so you either make the socket type dependent on the executor type or you do type erasure. Either way, adding this is a breaking change, it breaks both constructors and ABI, both a big no-no in the standard. &amp;#x200B; &gt;I am unsure about what you mean by synchronous I/O having more resource usage. Can you expand? Full duplex socket I/O potentially requires spawning 2 or more threads per connection. Every thread needs a stack and a little bit of bookkeeping. Most OSes allocate memory (including stack space) lazily, so the memory requirement per connection is somewhat mitigated, but it's still on the order of 16K of hard-allocated memory for the stack plus the in-kernel bookkeeping. Compared that to less than 512 bytes for the typical async operation state (usually closer to about 256 bytes), when using callbacks or stackless coroutines.
[libc++ actually does have a PSTL implementation](https://github.com/llvm-mirror/pstl). This component isn't compiled by default because it needs Intel's TBB to work. On the other hand libstdc++'s implementation also needs TBB to work, it's just that they decided to enable it by default.
This would be a lot of work; who's going to do it? (I have no idea how the distribution of work and compensation works for the committee)
The argument against graphics library inclusion is much more pervasive than that The real problem is that the graphics library is A: An absolutely ginormous project and a colossal time sink, B: Not well designed, and C: requires the standardisation of loads and *loads* of features that are half baked and would do better being standardised as their own independent features first The reality is that C++ is a step behind the ability to standardise graphics. We need unicode/matrices/vectors/loads of other stuff first before we can start on graphics
&gt; In order to support async operations, a socket object needs to store Why would a socket necessarily store anything regarding async operations? The socket might not even be used for async I/O. That is what is a big no-no. It is a non-zero abstraction, plus you are mixing a socket abstraction with unrelated things that may not even be used. Same as mixing algorithms with containers. The state for the async operations should be stored in another per-socket object, or in the `std::io_context`, or wherever. But not in the `std::socket`. &gt; Full duplex socket I/O potentially requires spawning 2 or more threads per connection. Not really -- there is non-blocking I/O, `select()` and friends, etc. No need to spawn thread(s) per network socket. Even if you go for a trivial 1:1 model, it is fine for a *lot* of server software, and performs great. Regarding memory and other resources: many kinds of servers need way more memory to serve actual requests compared to the stack you have to reserve and the kernel structures. The point being: you don't really need async I/O in the standard right now. Further, standard types like `std::socket` could have been used already by libraries like ASIO, already back in C++14 or C++17. Now it is likely that will not get any networking at all for another 5 years, taking into account stdlib support, companies moving forward, etc.
Depends on whose perspective you're taking. It's not hard to argue for this kind of procedure
I appreciate the dedication to rules reminders, but please try to avoid being unnecessarily harsh. In this case, although it’s borderline, I had approved the post due to several interesting replies. Sincerely, One Of Your Moderators, Mr. Has A Problem With The Eyes
I think it works on gcc 9 with the Intel TBB library also installed.
Just a point of terminology: **STL** is short for [the *Standard Template Library*](https://en.wikipedia.org/wiki/Standard_Template_Library), a generic programming library by Alexander Stepanov, originally developed for Ada, that was adopted mostly wholesale into the C++98 standard library. The **C++ standard library** contains much more. When we talk about features added after C++98 it's at best unclear to refer to any of these features as part of the “STL”, even when they're strongly tied to original STL components. However, since so many now use “STL” to refer to the whole C++ standard library, with the history, including the Ada period, just forgotten, maybe it's time to adopt that meaning and perhaps re-acronymize it, like *ST*andard *Library*. Maybe.
EWGI liked it. Needs a new draft to talk about some other things, like implementation concerns and use in pattern matching. Also, view from a lot of people was no reason not to support: auto [x, ...y, z] = some_tuple; Since we're not in overload resolution contexts, and don't need to deal with weird shit.
`true switch` and `new switch` sounds pretty good to me.
No compensation, but people can propose their changes. The Core Guidelines for example use a Git repo where you can put PRs with changes.
The "why" is of course a joke, but that's my personal style as well.
There is no attribution required for inclusion in a machine executable form with BSL.
Thank you, thank you, thank you! This has been high on my wish list for a long time, and I'm glad someone else has felt this was needed, too.
What's your interface? I made my own scanf-like function, called Deformat, and it doesn't use variadics, it returns an array of strings, one string for each parameter. I know, it's kind of a hassle compared to old scanf, but I just prefer it this way.
From my own code, I know that these work on Apple LLVM 10.0.1 (clang-1001,0,46.4) which is what comes with the current Xcode release 10.2.1: * std::string_view * std::clamp * Structured Bindings * constexpr if * auto * constexpr * Strongly-typed enum * nullptr * Raw string literals * Lambda expressions * Range-for loop * noexcept * Rvalue references
&gt; it returns an array of strings, one string for each parameter Half the job of scanf, and scnlib for that matter, is parsing meaningful values, like integers or floats, out of input data. This just sounds like a function for splitting strings. &gt; What's your interface? Documentation is here: https://scnlib.eliaskosunen.com/0.1/
It seems to be pretty universally agreed now that streams are really terrible - we're getting some of the replacement with {fmt} now, is there work on ditching the entire thing generally with better replacements?
I'm pretty sure BurntSushi (ripgrep author) also contributed the stdlib regex crate, so that claim is probably false.
Awesome library! This is so needed. One feature request: Can you do a version that takes types as part of the template parameters and returns a tuple. With C++17 this could lead to a very nice interface. ``` auto [str,i] = scn::scan&lt;std::string,int&gt;(stream,"{} {}"); ``` Just my 2cents. Once again, thanks for the library.
By including `&lt;scn/tuple_return.h&gt;`, you'll get pretty much that: https://scnlib.eliaskosunen.com/0.1/#tuple auto [result, str, i] = scn::scan&lt;std::string, int&gt;(stream, "{} {}"); // result is for error handling, see docs The rationale for not making this the default is also in the docs: https://scnlib.eliaskosunen.com/0.1/#rationale
Nice. Makes sense. Sorry I missed that in the docs.
There is ongoing work in providing better I/O in the standard. You already named {fmt} (https://wg21.link/p0645), /u/ned14 is working on https://wg21.link/p1031, Networking TS might get merged during the next millennium, and /u/aearphen just published https://wg21.link/p1729, referencing this library.
We have TR 1 in pre C++ 11 period. https://en.wikipedia.org/wiki/C%2B%2B_Technical_Report_1
I don't think anyone involved wasn't aware of extern templates and all that. Sometimes, projects just beyond and with lots of people working on something (including people that come and go), things become problems many months/years later that aren't always predictable. Compile times are always a concern and I am generally wary of template-heavy code in cases where I don't think the template should be necessary (the code is overly parameterized), not so much for me, but for how it will evolve/propagate over time (hundreds of lines or millions of lines of code into the future). Dealing with every individual class/struct/header with extraneous layers for explicit instantiation is really not pragmatic.
Growing up with win95? Or maybe people who were excited about windows for workgroups?
Yes
Thanks for the references! &gt;Networking TS might get merged during the next millennium In the grim darkness of the future, there is only w- attempts to get the networking TS merged?
Not arguing about it [I'll try to be friendlier .-) ], but my motivation was 1) question not related to C++; 2) specific to MSVC;
&gt; Has anybody had success using the alleged std::par feature in the C++ STL? Yes, I have [in a genetic evolution application, particularly well suited for `std::execution::par_unseq`]. They work a treat on VS2019/SDK 10.0.18362.0 [and I haven't found an algorithm that was not yet implemented yet (but did not try them all)].
Ok, but what is the Xcode version each of these first started working?
Same applies to the ongoing effort to standardize networking libraries, and I don't see anyone complaing about them being added. Anyway the ship has sailed, C++ has lost its place for app development on mainstream desktop and mobile OSes, the last standing OS where the SDK still has full support for writing UIs in C++ is Windows, and even there most developers end up using .NET or React Native instead. So a graphics library, or networking library, don't make sense in a language used to write OS drivers and GPGPU algorithms.
This is a very cool new feature, but the weird syntax and customization points make me wonder if C++ will survive adding this many cool new features.
&gt; Same applies to the ongoing effort to standardize networking libraries, and I don't see anyone complaing about them being added. &gt; &gt; Heh hey, I was complaining about the interface for boost/websockets just recently! :)
It grinds my gears when WG21 members argue in all seriousness that `std::variant` is a good and usable sum type for writing expressive, readable code. You know who you are.
With the big difference that npm and pip are installed as part of the respective toolchains, written on the respective language without 3rd party language dependencies, and everyone agrees in one library distribution format. On C++'s case, we have still package managers competing among themselves, all of them dependending in an external build tool of some sort.
sorry, i study IT at university but never had a an actual job related to C++. I do 99% of my personal projects in C++ though. Why do you see "It seems to be pretty universally agreed now that streams are really terrible", when i only found a couple topics online related to that view? Is that something agreed in real world jobs that i can't be aware about? What are the reasons?
I'm afraid the rationally doesn't convince me: The return type should (“of course”) be an option type. And they see the issue of non it constructible values doesn't arise.
https://github.com/cplusplus/LEWG/blob/master/library-design-guidelines.md: &gt; General design guidelines for successful library components. &gt; [...] &gt; - Class signatures want to be near minimal (the obvious counter-example is std::basic_string).
In real code the check could be inside another function that you call but if the compiler decides to inline the function call it should also be able to remove that check if is allowed to assume the precondition always holds.
I guess you could use Boost.Graph for the graph construction? Seems a tad unmaintained of late, but still has a pretty comprehensive and well-documented \[1\] API... &amp;#x200B; \[1\] [https://www.amazon.co.uk/Boost-Graph-Library-Reference-Manual/dp/0201729148](https://www.amazon.co.uk/Boost-Graph-Library-Reference-Manual/dp/0201729148)
Why would you convert the (whole) MD5 to a string just to check for the first few chars being zeros? I don't believe this is a "good" solution...
People keep saying "write a paper". Hopefully it won't be ignored... Oh, who am I kidding, it will be ignored to hell.
TL;DR: Throwing \`std::bad\_alloc\` is not the same as "there is no heap space available" - in particular when dealing with custom allocators. I very much agree with that! I agree that we need a way to reduce/eliminate overhead (runtime/compiletime/code-complexity) that is only there in order to cope with allocation failures which either never happen in the first place or aren't handled correctly anyway in most contexts. However, the standard can not just ignore valid usage patterns, just because it is more convenient. All that being said. I'm not completely up to date on Herbs paper, so I'm not sure if this is already addressed (at least partially) in newer revisions of it.
Finally someone has put all these concerns together "officially". Thank you.
Finally someone has put all these concerns together "officially". Thank you.
The motivation behind the original paper from Herb Sutter, is that most allocations, especially those which we consider mundane are non-recoverable, poorly protected against and that poor protection has a big impact on both api design and runtime performance. It doesn't mean that there exist in some applications some allocations that we _know_ might routinely fail because they are huge etc and we care to handle those. The original proposal would have made this use case more explicit which better expresses the intent and actually encourage these large allocations to be carefully handled while making small allocations more efficient. I think the original proposal was on the right track, even if it might not have provided the full extent of solutions required to realize its vision. it's sad to see it take a step backward. I agree it would probably be better to separate static exceptions and allocation failure handling in separate papers
FWIW, HPX ([https://github.com/STEllAR-GROUP/hpx](https://github.com/STEllAR-GROUP/hpx)) provides an implementation of (almost) all parallel algorithms specified by C++17 (see [https://github.com/STEllAR-GROUP/hpx/issues/1141](https://github.com/STEllAR-GROUP/hpx/issues/1141) for a list of missing ones). HPX works with all major compilers (MSVC, Clang, gcc) and on all major platforms (Windows, Linux, Mac, etc.).
It's embarrassing that this paper has to exist, but thanks for writing it, nonetheless.
How would returning an option type mesh with structured bindings?
FWIW, here were my initial musings on something similar: https://github.com/fisherro/scanner
Herb considers this in a long section of his latest talk starting at [38:25](https://youtu.be/os7cqJ5qlzo?t=2305), with the key slide fully revealed at [40:33](https://youtu.be/os7cqJ5qlzo?t=2433). To spell it out, he differentiates between failures to allocate large buffers or failures from custom allocators, which may be recoverable, and failures to allocate "small" buffers with the default allocator, which is generally unrecoverable.
Some people complain about perf, others about size or compile-time. Imho, w.r.t those points, they are not optimal, but also not "terrible", which actually describes many parts of the standard library. The real bummer is that the API requires you to mix data and formatting parameters in a really cumbersome manner. If you want to output data in a remotely structured manner or - god forbid - in multiple languages, printf is imho still easier to use. Not to mention more modern alternatives like fmt.
But is it safe to allocate memory when handling an allocation error? What if the entire OS has exhausted the available memory? Including using file system to swap pages?
Awesome! Any ideas how well it handles memory fragmentation in practice (which is one reason to use jemalloc)?
I understand and somewhat agree with your point, but it points to a good culture. I would be somewhat surprised if BurntSushi would have spent so long helping to create a highly performant regex implementation if it wasn't going to be highly reusable, *JUST* for ripgrep. Similarly, ripgrep relies on a lot of phenomenal code that isn't just regex. My point was more of a technical/after-the-fact one, where there is now one of the fastest and easiest to use regex crates ever is really easy to add. Implementing ripgrep "from scratch" today would be much easier than implementing it in C++, I believe in large part because of the crate ecosystem and regex.
What's embarrassing about it? Proposals aren't perfect, they get things wrong. Not everyone is a subject matter expert in every subject. Having papers point out problems in other papers is a really valuable part of the process.
I agree that bad_alloc is not the same as no heap space available. However in the vast majority of the places where my program can throw bad_alloc, I am not prepared to handle it. Places where I am prepared to handle bad_alloc - for example while opening a user supplied file - I can either use a separate allocator or try_xxx functions. This highlights my intent that yes, I have thought about my allocations failing and am prepared to handle it. Suggestion: Static exceptions are new and have no backward compatibility requirements. So if I build my program with static exceptions enabled and normal exceptions disabled, the default allocator should terminate on allocation failure.
Seen Herb's talk at this year ACCU, and he explicitly talked just about this point. So he is aware of it!
Well, allocating memory is *never* entirely safe as it can always fail. Though no doubt if you're just handling an allocation error it's not far fetched to assume you won't succeed with another allocation.
I have some references at [https://github.com/BartVandewoestyne/Cpp/blob/master/C%2B%2B17/examples/parallel\_stl.cpp](https://github.com/BartVandewoestyne/Cpp/blob/master/C%2B%2B17/examples/parallel_stl.cpp) The most helpful and recent ones that answer the OP's question seem to be: * [How to Boost Performance with Intel Parallel STL and C++17 Parallel Algorithms](https://www.bfilipek.com/2018/11/pstl.html) * [C++17 STL Parallel Algorithms - with GCC 9.1 and Intel TBB on Linux and macOS](https://solarianprogrammer.com/2019/05/09/cpp-17-stl-parallel-algorithms-gcc-intel-tbb-linux-macos/) Have fun! :-)
And you think braces will affect that? Show an example.
Can we stop with this spam please?
So a facade here is like a Rust dynamic trait or a Swift protocol? I cannot really comment on the specific implementation chosen here, but transparently decoupling static and dynamic dispatch is definitively a step in the right direction.
The author explicitly linked P0709R2, not P0709R3, where the difference between small buffers and large / custom allocators is made differently. For me, it seems more likely to be a collision of request for change / change made than a confusion.
Oh right, of course - that's where filesystem lingered as well for a few years (perhaps even a decade or more).
Not every target supports threads or atomics either. Not every target supports heap allocation. Lowest common denominator is not a good metric.
I think you're right.
You could return a `std::tuple&lt;std::optional&lt;T1&gt;, …&gt;`. That said, I find returning optional values a lot more important than the ability to use structured bindings directly. So I would probably prefer it if `scan` returned a `std::optional&lt;std::tuple&lt;T1, …&gt;&gt;`, to be used as follows: if (auto result = scn::scan&lt;int, int&gt;(stream, "{}/{}"); result) { auto [d, m] = *result; // … use it }
That is exactly my point regarding the argumentation against the graphics library. What goes against it, apparently is a no go when we start applying the same arguments against each one's beloved feature.
We should do floating point indices. That way "find" can return 2.5 if the value halfway between 2 and 3
They couldn't be more different and I think you are choosing to ignore that. To start, the graphics stuff was never going to work with triple AAA games, it has proposals to include all of cairo into the C++ standard library. The graphics proposal hasn't really been tested or used at all as a library. It's design was pretty obviously not done by professional computer graphics people in any sub domain. It is filled to the brim with red flags and deal breakers. The idea that the standard would include a huge addition that has never been used as a separate library is nonsense. I'm all for window creation as a proposal and library but the current graphics proposal is in another world.
If the entire OS has exhausted all the available memory and the entire swap space, there's way bigger problems than keep your program running.
&gt; Anyway the ship has sailed, C++ has lost its place for app development on mainstream desktop Then why are all the programs I use written in C++?
I'd take return values over out-params any day, but there is a conflict in cases like these between returning monadic error types (or optionals, or whatever) and having a neat syntax for structured bindings. Returning `optional&lt;tuple&lt;T...&gt;&gt;` would absolutely be preferrable but how would you be constructing that tuple piece-by-piece without default-constructing it first? It's not immediately obvious to me. Meanwhile, returning `tuple&lt;optional&lt;T&gt;...&gt;` doesn't make much sense for an API where you're nearly always interested in whether *all* those `T`s could be parsed, rather than each `T` individually.
No, it's not at all safe. At that point the C++ abstract machine is "exhausted", just like in the case of stack overflow. GCC for example works around this by preallocating a small chunk of memory as the source of `std::bad_alloc`s.
The paper is not mine though, I just found that it was interesting and didn't gather much coverage. I also can't comment on Rust dynamic traits or Swift protocols since I'm familiar with neither. I found the proposal interesting because it solves an issue that I encountered several times when trying to store collections of objects that are unrelated from an inheritance point of view, but share a similar interface. This proposal would have allowed me to create such collections without much boilerplate compared to my current implementation :)
You have no basis to make that claim.
That's not "someone" that's an active member of committee. What he did was hardly something magic.
Man, I feel for you. 9 downvotes, and no-one even tried to explain why they downvoted you...
to do multiple languages you really just can't use iostreams at all unless you wrap them in a macro or something
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Namespaced keywords have been proposed and rejected more than once, if I remember correctly, though I don't recall the paper numbers off the top of my head; sorry.
Running out of memory is not like stack overflow. With stack overflow the program truly cannot continue. With running out of memory (but not stack), the program should still be able to do things that don't involve allocating memory. You can clean up after \`bad\_alloc\` by not doing anything that allocates memory. That's the ideal though, and how it works in simple systems. In Linux overcommit is enabled by default which means that once you run out of memory, memory that you have \*already allocated\* may not be available.
One of the authors is a long standing and widely respected member of Boost, maintainer of one of the core libraries, and is on the WG21 internal mailing lists. I would be quite surprised if this paper is not taken seriously.
&gt; Running out of memory is not like stack overflow. With stack overflow the program truly cannot continue. With running out of memory (but not stack), the program should still be able to do things that don't involve allocating memory. You can clean up after `bad_alloc` by not doing anything that allocates memory. What happens if even `new char` fails? There will definitely no heap space left to allocate `std::bad_alloc`, so yes, this really is an abstract machine exhaustion.
`bad_alloc` isn't dynamically allocated, but placed in pre-allocated memory for exceptions (with GCC at least). Also note that `bad_alloc` only has a `bad_alloc()` constructor which is noexcept.
&gt;I do 99% of my personal projects in C++ though. Use any other language and see how they handle formatted output and notice how much cleaner, safer, and expressive it is compared to how it's done in C++.
I know what GCC is doing, but that's called "a special case", because of what I tried to explain.
Anyway, the point here is that with a proper compiler implementation and OS support (e.g. RTOS or disabling overcommit), you *can* handle `bad_alloc` caused by memory exhaustion. Your argument about "what if new char fails" does not matter when you can assure that no memory allocations happen in that throw and handling code. C++ and C happen to be one of the few programming languages that have this capability.
There are cases where out-of-memory can be handled correctly, and is useful: &amp;#x200B; Analysis of large datasets. Here it is not uncommon that data-allocation happens at the beginning, a single very-large block, which might fail. If it does, the exception-mechanisms allows to handle that error and re-try with, e.g. different subsampling parameters.
I think you’re right that an optional tuple couldn’t be constructed piece-wise in-place. However, there’s no obligation to return this exact type, only to use its interface. It an implementation using these standard library types isn’t possible, using a dedicated type that supports the desired semantics is the next-best option. I’ve never tried implementing this but some playing around in Godbolt leads me to believe that it should be possible to implement such a type without any further overhead using a `std::aligned_storage` buffer into which the tuple members are written. This buffer would always be constructed, even in the case of failure, but then it could be used to construct the read values in-place in that buffer without requiring default construction. I don’t think you could avoid the copy during the structured binding initialisation, though.
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Haven't enough (somewhat) specialized type-erasing polymorphic wrappers been standardized already? We currently have at least:&amp;nbsp;&amp;nbsp; - '`std::any&lt;&gt;`' for copiable types. - '`std::function&lt;&gt;`' for '`Callable`' types. I recall seeing '`any_iterator&lt;&gt;`' for iterators, too, and there may have even been a proposal for '`any_range&lt;&gt;`' for ranges of objects of specific types. Wouldn't something more like a concept-constrainable version of the once oft-proposed `std::polymorphic_value&lt;&gt;`&amp;thinsp;—&amp;thinsp;at least that's how I _think_ it was spelled, as far as I can remember&amp;thinsp;—&amp;thinsp;suit the use case of holding any object that embodies a given concept better and more generically? I suspect that standardizing a new polymorphic wrapper type for each possible concept conformance might get old fast (if it hasn't already.)
On which platform, with what C++ GUI toolkit?
Actually, that is the point of the paper: not all allocators are calling new/malloc and even the ones that do can be of very different sizes. So just because one kind of allocation failed does not necessarily mean all other allocations will fail too (even it might be the right default assumption).
Just like the networking library for anyone that has written distributed systems in anger. It isn't a match for what Akka, Orleans and similar stacks offer. Yeah, one can open sockets and do curl like web requests. It would never be part of C++ if the same quality gate would be applied.
... and the other author is _also_ on the WG21 internal mailing lists and has been an active contributor for years.
An observation in the section "Alternatives proposed are inacceptable" It is argued that allocation failure would have to be propagated up via error codes, defeating the purpose of the static exception proposal. Rather than doing that, I would simply detect the error and throw my own flavor of \`bad\_alloc\` and let it propagate up. It seems like the \`try\_\` variations could do this themselves if static exceptions are available.
Sorry for high jacking this thread, but does someone know, if there happen to be a simple, production quality, SI unit library out there that doesn't blow up compile-times and debug symbols/error messages? At most it should allow different numeric types.
Funnily enough, both Windows and Linux let you recover from stack overflow if you set up for it beforehand.
I know; what I mean is that out-of-memory is a pretty likely culprit when you're dealing with an allocation failure in general. So my base assumption is that I can't count on new allocations succeeding. That's not always that case, of course, but when you hear hooves you think horses.
I know my lib is still in the early stages, but is there something in particular that's missing from it that you would like to see? I have a working SI implementation here: [https://github.com/bstamour/units/blob/master/examples/si.cpp](https://github.com/bstamour/units/blob/master/examples/si.cpp) (maybe that should be included in the readme?)
might be just me but i find organizing output with subsequent shift operators and the dynamic content right in middle where it will appear cleaner than printf style string with separated arguments to be replaced in the string… In java i used the string + operator with a single println, still closer to iostream than printf
&gt;Discussions, articles, and news about the C++ programming language or programming in C++. For C++ questions, answers, help, and advice see r/cpp_questions
The sdk includes a toolchain file at `$EMSCRIPTEN/cmake/Modules/Platform/Emscripten.cmake`, it sets up the compiler paths and provides a few helper functions like `em_link_js_library`. It's nothing super fancy, but it's extremely useful for cross-platform projects.
Sure, but you can't just allocate what you need and handle bad_alloc in these cases, since (a) overcommit is a thing and (b) you probably don't want to trigger the OOM killer. I suppose it could make sense if you establish a cgroup/job limit on your memory usage before you start. (although even then overcommit is a thing)
Fun fact I really struggled with dimensional analysis until I understood the formulation in terms of linear algebra.
The problems with the shift operator are, in no particular order, and with no pretense of being exhaustive: 1. Wrong precedence for the intended use case. The shift operator was intended as a bitwise operation, and that's how expressions involving it are parsed. That's why ternary operators often have to be parenthesized, e.g. the following probably won't do what you expect: bool greeting = true; cout &lt;&lt; greeting ? "hi" : "bye"; 2. Arguments can't be reordered, which is a problem if you care about internationalization. 3. Unlike format strings, the io manipulators actually change the streams' internal state, so if you choose e.g. a floating point format to output, you better put a ring on it because it's sticking around. Your options here are either live with this, and keep track of what formats you want every time (unwieldy), or use something like the [boost stream state saver library](https://www.boost.org/doc/libs/1_40_0/libs/io/doc/ios_state.html). You can roll a minimal version of this in a couple lines, but the fact that this is needed at all is kind of ridiculous. 4. Somewhat subjective, but anything nontrivial ends up really verbose when compared with the format string counterpart. The fact that the shift operator takes two characters instead of 1 (as in `+`) doesn't help -- when you have a lot of things to output, those extra characters add up.
Thanks, I didn't notice. But consider that unexplained downvotes are purely social arguments. I gather it's a mix of reasons, but generally it means that one has mentioned facts that some dishonest people are uncomfortable with. Thus, being massively anonymously downvoted is a kind of honor. Cheers!
We're open to feedback to improve the feature, and certainly do not want to kill C++ 😅. Could you elaborate on which syntax and customization points feel weird to you? For example, in the latest revision of the proposal [P1371R1](https://wg21.link/p1371r1), we removed the `^` expression introducer.
It definitely works on windows. As far as I know, overcommit can be disabled on linux, although I've never tested that.
Is there a specific reason to make `si` a struct instead of namespace?
Not at this time. I have some ideas in mind for how to do system-to-system conversions, and that would require the system itself to be some kind of type. But since that's not implemented yet... feel free to namespace instead!
Another thing: non-integer powers should be allowed. For example, amp;itude spectrum density is often measured in V/sqrt(Hz), which is currently not representable in the library as I can see.
Is there formatting to this... it doesn’t come across on mobile...
Oh sorry, after the weight the next amount of packages is is on a new line
I appreciate the feedback. I'll have to look into the non-integer power situation. As long as we stick to rationals it should be a-ok.
Ahhh well you could approach it like this if you are supposed to use &lt;iostream&gt;: cout &lt;&lt; x &lt;&lt; “ packages [...]” &lt;&lt; endl; cout &lt;&lt; y &lt;&lt; “ packages between [...] &lt;&lt; endl; And so on... where x and y are the variables that store the package quantities.
I’m also supposed to take inputs and have inputs be invalid if it’s not between 2 and 40 lbs
The networking library solves a basic problem. The graphics proposal is huge, questionably solves many problems, is completely untested and isn't even being used as a library. I don't know what distributed systems has to do with anything. These two things are completely incomparable in their focus and execution.
ou handle inputs like: while(input not valid) { cout &lt;&lt; “Message for user”; cin &gt;&gt; x; cout &lt;&lt; endl; If (x &lt; 2 || x &gt; 40) { Input is valid } Else { Input not valid cout &lt;&lt; “Value must be between 2 and 40” &lt;&lt; endl; } Pseudo code, but it outlines the idea..
Oh I’m not allowed to use loops I forgot to state that, we haven’t gotten that far
I actually don't think `inspect` is all that bad, and we thought that the design in [P1371R0](https://wg21.link/p1371r0) was too different from `switch` to be a variation of `switch`. Having said that, the design changes in [P1371R1](https://wg21.link/p1371r1) (removal of `^` and the use of `case`) have gotten us more comfortable with considering options to extend `switch`. We didn't have time to decide on a concrete suggestion for R1, but it'll be something we tackle for R2. Stay tuned!
Not missing- too much. I haven't checked out your lib yet, but usually I favor simplicity over genericity and so far, every library that allowed me to define my own unit system became either a compile-time, debugging/readability or comparability burden. Thing is: I have simple needs: si units (often even just kms) with integral powers and no need for scaling factors. For that I'd prefer not to put a heavy weight solution into the interfaces of my library - certainly not if the definition of standard SI units is left to each library using it.
So they just want you to terminate the program in the users input is invalid...?
So they just want you to terminate the program in the users input is invalid...?
Yes. Or output an error statement
You could just do it twice. First time they screw up say what the value should be. Second time assert the program.. or return 0; at that second check
&gt; On Windows, using pure C++ means either all those programs use custom made Win32 C++ wrappers, wxWidgets, or are written in a mix of MFC and ATL, as everything else uses something besides C++ on their stack, or use C FFI to Win32. The fact that things like this get repeated is insane to me. Qt, fltk, juce, wxwidgets and gtk all work. Basic GUIs with typical components aren't even the difficult part of most programs. So yes, most programs I use are written in C++ and all cross platform programs I write are as well. It just isn't a problem.
Fair enough. Good luck with your search!
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;I'd generalize that statement to be usable in the context of _any_ package manager, including any one that adopts and works well with the conventions of the upcoming Ecosystem TR, but yes.
Drawing is also a basic problem in modern computers.
I wonder if they are going to relax the C++ restrictions that SYCL has. I would love to have function pointers in SYCL.
I agree. It's a shame the current graphics proposal is such a ridiculous way to confront that problem.
1. std::vector::resize\_with\_default\_initalization 2. a explicit small-object-optimization versions of vector &amp; string 3. 128 bit integer type
Godbolt doesn’t support linking with external libraries. You can circumvent this by using the header-only version of {fmt} by adding `-DFMT_HEADER_ONLY=1` on the command line.
Now I am confused, it wasn't **all** the programs you use are written in C++? &gt; Then why are all the programs I use written in C++? So for starters, which OS do you use that is written in C++? Gtk+ is a C library, so by definition is not written in C++. Fltk, Juce, wxWidget, faire enough. Any commercial success with any of them, beyond ROLI's hardware? Qt is only pure C++ if one is targeting classical deployment targets with C++ Widgets. All the new APIs are mostly QML based, to the point that there is ongoing talks to expose some of them in pure C++ for Qt 6 roadmap. So I am lost on which OS 100% written in C++ and what applications you are using where **all** qualifies as truth quantifier, ∀𝑥 (𝑥 written in C++).
In my ignorance, why not just an `optional&lt;T&gt;` or `variant&lt;T, error_t&gt;`? Less code, simple, already made. Just wrap the classes for a better API.
That's what I did =\]
In OpenCL, last time I checked, actual functions did not exist (only if they can be inlined, but that is mot the same thing). Thats a hard restriction from how a GPU works. I think that would also mean no function pointers in SYCL. Not an expert tough, someone with more expertise might elaborate later on.
Oh I see, I guess I was looking in the wrong places. Thanks for the pointer!
Here's the official announcement: [https://newsroom.intel.com/news/intels-one-api-project-delivers-unified-programming-model-across-diverse-architectures/#gs.kbvfpm](https://newsroom.intel.com/news/intels-one-api-project-delivers-unified-programming-model-across-diverse-architectures/#gs.kbvfpm)
Must be exhausting moving those goal posts. You said desktop app development.
Nope, I did not. &gt; Anyway the ship has sailed, C++ has lost its place for app development on mainstream desktop and mobile OSes, the last standing OS where the SDK still has full support for writing UIs in C++ is Windows, and even there most developers end up using .NET or React Native instead. My statement did not mention anything about third party libraries, only what Apple, Google and Microsoft support on their SDKs (**mainstream desktop and mobile OSes**). So which OS are you using, written 100% in C++, with an OS SDK that allows for writing UIs 100% in C++, in a way that `Then why are all the programs I use written in C++?`is true?
@29m20s: Okay, I'll bite. How do you implement `std::is_permutation` as a reduce/fold? To be fair, I don't even know how to implement it with a reasonable space/time complexity in the first place, and [cppreference is no help](https://en.cppreference.com/w/cpp/algorithm/is_permutation#Possible_implementation).
Yes but the error code stuff etc. Plus virtual functions etc. A simple template class wrapper + a user defined strong error type would suffice from my point of view.
how do you reorder arguments in printf style output? When you have a long output all together you'd end up with a messy list of arguments for printf style imo. But anyway, all these we're talking about are just personal preferences on how you want to see your code on the text editor, and there's hardly one that is better than the other (tab vs space &amp;co). That aside, is there some performance gain using one way over the other? And finally, isn't having to declare the type of each variable in output in printf style less safe than using &lt;&lt; operator, which can be overloaded by multiple child classes of a virtual class for example?
I think that for strong error type you might as well just use an enum. The idea of this is to provide type erased error handling much like what exceptions do, so errors can be forwarded gracefully from nested functions.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c4tw51/hey_guys/eryj34b/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I think you're too attached to the C++ approach because it's the only approach you know. As you said, 99% of what you do is C++. That's fine if you like it, no one is suggesting to take it away from you, just understand that most people who use multiple languages tend to see a very big benefit from using the way pretty much every other language handles formatted output and so we welcome having that approach brought to C++. Maybe it's just a coincidence, maybe we're all just foolish, or maybe there really is something more expressive and natural about that style. As for performance, the usual approach of using streams is notoriously slow and the implementation is rather bloated. You can review the {fmt} library to see benchmarks which show it vastly outperforming iostreams: https://github.com/fmtlib/fmt#speed-tests
that test doesn't specify if std::ios\_base::sync\_with\_stdio was set to true or fals, which heavily affects iostream's performance. I'll have a look at that nontheless. Stilll, can you provide me an example of reordering arguments with printf style output?
It can and should be disabled on linux servers. Even its documrntation mentions that it's really only useful when dealing with things like sparse matrices. There is nothing to be gained, only heartache, by letting the kernel lie to you.
&gt; how do you reorder arguments in printf style output? In different languages, you may want to change the order of things (e.g. adjectives and nouns). Even if you have the correct word ("red" and "hammer" translated to each language), you still need to output them in the correct order. With streams, you need to write different code for each order. With format strings, you simply need to change the format string, and you're done: `"{0} {1}"` vs `"{1} {0}"`. Both can be printed with `print(fmt_string, adjective, noun)` &gt; When you have a long output all together you'd end up with a messy list of arguments for printf style imo. Not sure if it's worse than a messy list of shifts &gt; But anyway, all these we're talking about are just personal preferences on how you want to see your code on the text editor, and there's hardly one that is better than the other (tab vs space &amp;co). If you worked hard enough, you probably could take any program in any language, and translate it to any other language you want. But some languages are more suited for some tasks, making the code you write easier to read, understand and maintain. &gt; That aside, is there some performance gain using one way over the other? The standard requires the stream library will be implemented in a very non-trivial class hierarchy with virtual inheritance and separation between the stream logic ("formatting") and the streambuf logic ("writing"). This is not a bad design, but this causes the iostream library to be very large and not very efficient compared to the simple `printf`. &gt; And finally, isn't having to declare the type of each variable in output in printf style more error-prone than using &lt;&lt; operator, which can be overloaded by multiple child classes of a virtual class for example? As far as I know, this is actually the main argument against fmtlib and in favor of streams, and I accept it, although fmtlib currently provide some support to check the format string at compile time, and it is possible that compiles will implement their own heuristics (I know GCC does for `printf`). But, personally, I mostly find myself not printing something unprintable, but rather wanting to control how I print something. The separation between the type of the object and how you want to format it is actually something I much prefer - Bases for numbers, `char*` as pointers, padding and alignment, custom structs, changing positions... This is the feature I want, and I trust that compilers will be able to warn me if I forgot to write a format for one of my arguments.
Been saying this since all this started.
No it's not, but that's an issue with C++exceptions and their design, not with the philosopy of handling OOM
\&gt; Thats a hard restriction from how a GPU works. The is not a consistent restriction across all GPU vendors. I also believe that OpenMP offload has support for function pointers.
&gt;Stilll, can you provide me an example of reordering arguments with printf style output? format("{0}, {1}", "hello", "goodbye"); // Outputs "hello, goodbye" format("{1}, {0}", "hello", "goodbye"); // Outputs "goodbye, hello" format("{1}, {0}, {1}", "hello", "goodbye"); // Outputs "goodbye, hello, goodbye" For internationalization this feature is very useful since you can pick the order of things based on the language you wish to display.
I did something similar (minus custom allocator support), but using tag types types so it can be library only. [https://github.com/google/cpp-from-the-sky-down/blob/master/metaprogrammed\_polymorphism/example.cpp](https://github.com/google/cpp-from-the-sky-down/blob/master/metaprogrammed_polymorphism/example.cpp) ```cpp // Our 2 operations class draw; // Draw an object class x2; // Double an object // We will take any type that supports calling "draw" with an ostream. // void draw(std::ostream&amp;) const -&gt; void(draw, std::ostream&amp;) const // polymorphic::view is a non-owning polymorphic "facade" void call_draw(polymorphic::view&lt;void(draw,std::ostream&amp;) const&gt; d) { std::cout &lt;&lt; "in call_draw\n"; d.call&lt;draw&gt;(std::cout); } // Define default operations for these two operations template &lt;typename T&gt; void poly_extend(draw*, const T&amp; t, std::ostream&amp; os) { os &lt;&lt; t &lt;&lt; "\n"; } template &lt;typename T&gt; void poly_extend(x2*, T&amp; t) { t = t + t; } int main() { // polymorphic::object is owning std::vector&lt;polymorphic::object&lt;void(x2), void(draw, std::ostream&amp;) const&gt;&gt; objects; for (int i = 0; i &lt; 30; ++i) { switch (i % 3) { case 0: objects.emplace_back(i); break; case 1: objects.emplace_back(double(i) + double(i) / 10.0); break; case 2: objects.emplace_back(std::to_string(i) + " string"); break; } } // There is no notion of inheritance. We can convert a view or object to another view or object // as long as the supported operations are a subset of ours. // In this case the object supports draw and x2. Since call_draw requires something supporting // draw, we can convert our object to a view and pass it to call_draw. for (const auto&amp; o : objects) call_draw(o); for (auto&amp; o : objects) o.call&lt;x2&gt;(); for (auto&amp; o : objects) call_draw(o); } ```
Well. Actually, on modern systems, you won't get std::bad_alloc from heap exhaustion at all. Other reasons, like a custom / local allocator are much more likely.
It wasn't even a hard restriction of how a mobile GPU worked when we initially created SYCL. It was, however, a restriction of what could reasonably be negotiated into OpenCL at the time, because it was a hard restriction of how *some* GPUs worked, especially for efficient compilation.
Ughhh OpenCL, ISPC, TILE ... how many abortive data parallel langs has Intel had its hands in?
It messes with forking, you won't be able to fork a process that is larger than half of all physical memory for example.
I just pulled the repo, `sync_with_stdio` is set to false (line 81 in tinyformat_test.cpp). Here are the results I got on my system: running speed tests... printf timings: real 1.29 user 0.87 sys 0.42 iostreams timings: real 1.53 user 1.51 sys 0.03 format timings: real 1.06 user 0.81 sys 0.25 fmt::prepare timings: real 1.24 user 0.79 sys 0.45 tinyformat timings: real 1.87 user 1.84 sys 0.03 boost timings: boost is not available real 0.01 user 0.00 sys 0.00 folly timings: folly is not available real 0.01 user 0.00 sys 0.01 stb_sprintf timings: real 1.05 user 0.65 sys 0.39
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c4udot/godbolt_has_execution_support_now_but_what_about/eryv4yc/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
filesystem wasn't part of TR1 - it was planned to be part of TR2 but that didn't end up happening.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c4uffd/single_header_lightweight_easy_to_understand/eryvb1c/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Good. I was hoping it wasn't going to be SPIR-V based.
I'd like to see timing comparisons against MSVC 2019 16.1's from_chars() for floating-point parsing.
Cilk Plus
STL maintainer here. Using "STL" to refer to the C++ Standard Library is a valid use of [metonymy](https://en.wikipedia.org/wiki/Metonymy), and doesn't lead to confusion in practice.
You're right. I posted in here because when I Google searched this topic, a previous post involving execution on Godbolt that I think was an announcement was posted here. I should've red the forum rules.
&gt; But anyway, all these we're talking about are just personal preferences on how you want to see your code on the text editor, and there's hardly one that is better than the other (tab vs space &amp;co). To an extent, yes. But in some aspects there are clear winners. E.g. reordering (printf* wins), sane (stateless) formatting (printf wins), thread safety (printf wins), memory safety (iostreams win), type safety (iostreams win), customizability (iostreams win). I hate that we have to "pick our poison" over something as simple as text formatting, but here we are. That's why I can't wait for `{fmt}` to make its way into the standard proper. * Technically this is nonstandard, but there's ways to get it in all 3 major compilers. &gt;That aside, is there some performance gain using one way over the other? Typically `printf` performs better. Disabling `sync_with_stdio` helps but then you have to start yelling at people who use `printf`. &gt;isn't having to declare the type of each variable in output in printf style more error-prone than using &lt;&lt; operator, which can be overloaded by multiple child classes of a virtual class for example? Yes. I like the customizability of iostreams; I just wish I didn't have to pay such a high price for it. But format strings don't have to look like `printf` format strings. Look at Python's `.format`, for example, whose syntax is also supported by `{fmt}`.
What's wrong with SPIR-V?
&gt; doesn't lead to confusion in practice That you don't know. Old-timers like you and I have a firm foundation including the history of things, new learners don't. Still as I wrote, it's maybe time to adopt “STL” as a term for the standard library also in books, Wikipedia, the FAQ etc.: to use the shortest term for the most common meaning. After all, AFAIK there's no longer any free ~pure STL implementations around. A little micro-dictionary could be added to the ISO CPP FAQ. It could describe the meanings of e.g. “STL”, “SFINAE”, "CTAD”, etc. Of old Marshall had an item called “What is the "STL"?”. But then, he also an item called “What is the NIHCL?”, a C++ implementation of the Smalltalk library that I think few if anybody now remembers. Since Herb is one of the FAQ maintainers, and you work at the same company, you could maybe air the micro-dictionary idea?
Sorry, I don't keep old versions of Xcode and my code may not have switched to these features on their first arrival. One of the problems has been that sometimes incomplete or even empty versions of features are added in one version then finished in another.
I’m dumb. Can someone explains what this means to an average programmer?
So I might have some (slim) luck that they allow this as a vendor extension
I didn't realize in your reality that using a GUI library meant that programs are no longer written in C++.
&gt; Thats a hard restriction from how a GPU works. It's a hard restriction from how GPUs used to work. Modern GPUs do not have such restriction anymore.
Which is relevant extremely rarely. posix_spawn() doesn't need overcommit to launch new processes (glibc and musl use vfork to implement it), and normal forking is typically done close to startup.
&gt; Well. Actually, on modern systems, you won't get std::bad_alloc from heap exhaustion at all Well. Actually, this statement isn't correct. Modern systems like Windows 10 do not implement memory over-commit, because it's a bad feature. Let's please try to be better than using "modern X" as a stand-in for "X that I use."
Depends how average. It's useful if your use GPU to accelerate a CPU program. Basically, we are still trying to come up with a good language to program heterogenous architectures. SYCL is supposed to be the next best thing. But meh, it's not even standard and we already come up with the next one... Basically, just the industry struggling with agreeing on a standard.
By heterogeneous architectures, do you mean “can take advantage of serial hardware and parallel hardware without us telling it which to use”?
Maybe I'm being dense, but don't concepts fulfill this functionality? They're able to constrain algorithms on necessary behavior/structure, and could be used for the \`immutable map\` example.
Yes, but unfortunately, none of those languages makes it that easy. OpenCL was supposed to be able to run on any hardware, but it's cumbersome (not all applications can be written easily in OpenCL) and only provide good performance on GPU anyway. SYCL try to abstract as much away from OpenCL, and encapsulate the rest into nice C++ classes. But it is still cumbersome to program with. Typically, the biggest issue is portability of the performance. There is, as of today, no language that is abstract enough that it is portable, yet precise enough that it compiles into an optimized program on all those hardwares.
I guess we already have #if for that.
#if happens before the C++ compiler is even invoked. There’s no type information it can use.
Yikes. Sounds like on of the hardest problems to solve, since it's supposed to optimize without the coder having to be aware of the difference in architecture. Good luck to them; lord knows I wouldn't want to work on that. At least at my current level of knowledge (0).
The worst is that we have made incredible progress in compilers, but none of them are in mainstream compilers because people prefer a fast compiler than a smart compiler. It's so frustrating...
I think the reason is for the same reason that two-phase template instantiation exists. Like the first phase of template instantiation, both branches of an `if constexpr` statement must have all independent names resolved during the first phase regardless of how the condition evaluates. As for your second example, my guess is that even though `printf` looks like an independent name on first glance, I think it is actually a dependent name due to ADL (since you are passing a dependent name as an argument to the function). In fact, in the second example, if you just replace `printf(t)` with `printf(“hi”)`, it fails to compile since `printf` becomes an independent name.
Your first example works fine. You’re missing an include.
It means whenever you see `atan2(x, y)` in code, you wonder whether they meant `y,x` and made a mistake, or whether they really knew what they were doing. We have this in our codebase.
I don't agree with the reasoning, but [a comment from another thread](https://www.reddit.com/r/cpp/comments/agb8t1/if_constexpr_isnt_broken/ee6er3c/) pitched this reason: &gt; As the [if constexpr paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0128r1.html) noted, scopeless token-soup "static if" is "fundamentally incompatible with the template model used by at least two major implementations". Features with that kind of cost had better be the best thing since sliced bread, which this one is not. Imo, C++ type-compatible compile-time conditions *should* have aimed to fully replace their macro counterparts. Threads like this show how inherently unintuitive the current implementation is, on top of weakening important constructs like constexpr types and static traits.
So then it is for an implementability reason? As in, there would need to be a three-phase lookup or something if it would allow the above code to be valid?
What compilers are you alluding to? The smart ones
Where would your first snippet actually be useful? If you ever expect the false branch to be taken, it needs to actually work, and this won't. If you never expect it to be taken, it shouldn't be there at all. I appreciate the immediate feedback that something is wrong even before I start having tests that actually take that branch.
ISPC is great, though. I agree on the rest, far too many.
I work on a hardware platform where we also have a software emulation platform. My goal was to use if constexpr to switch between the 2, as only 1 exists depending on the compiler target. I also expected it to be useful for switching between windows and linux, where the calls are slightly different, such as sockets. If constexpr is cleaner then the preprocessor, so that was kind of what I wanted to see, and what my intuition told me I could do.
There are really easy ways to improve compiled code: one of the surprising one is that today compilers avoid statically evaluating expensive code even if they could statically evaluate it. Just because it can take arbitrarily long to evaluate. There are also hard ways: automatic parallelization using polyhedral techniques, abstract interpretation and design space exploration. You can detect parallel loops, try a lot of different way of vectorizing and parallelizing them, and pick the best one, all automatically. The problem with all those compilers is that they are proof of concept and hard to use (you typically have to compile it yourself, and only care about a subset of the language). But a lot of start-up are built around better compiler technologies (and die with them). Pochoir stencil compiler is interesting to look at. Polly/LLVM is promising too. Nowadays a lot of research is going into optimizing machine learning algorithm as they are quite simple yet trendy. See Tensor Comprehensions. If you want to get an idea of what happen in those compilers you can look at the Halide language. The basic idea is if your compiler can separate what you want to compute, from the order in which it is computed, and from where it is computed, then it can rewrite your code without changing it's meaning and it's just a matter of trying lots of versions and picking the best one.
In my reality writting in C++ means writing in C++, plain and simple English, no word games here. If the library wasn't written in C++, by definition it isn't writing in C++.
It’s the opposite. You’d need a naive one-phase lookup (like the old MSVC compiler) that does no semantic analysis before the template is instantiated (or the constexpr condition is evaluated). However, that is not conformant to the standard. The question is, why would you want the compiler to avoid evaluating the `printf` function in the else statement? The name `printf` is not dependent on any types not known during the first phase of parsing, so the compiler knows for a fact that it will always be invalid, regardless of what happens with the constexpr condition.
Looks like `@` was also removed, but now we have `let`? I think it's very confusing to have both `auto` and `let` in the same language.
For me, printf was just an easy example. The real use case I was thinking of was multi platform code with small differences between the platforms. Where the functions are slightly different, or certain platforms need a few extra calls.
I find it interesting that a MSVC dev concerns themselves with Linux first.
&gt;Our recomendation is to proceed with the first goal and abandon the second. I think the paper authors have mixed up the second part as a feature rather than a necessity for an efficient implementation.
OTOH if you want to significantly change the language, you probably should start by consulting people who are experts in the subject. Also pretty much everything in this paper has been informally said ever since Herb first published his paper. So maybe the embarrassing part is the committee model. 🤷‍♂️
Extending the designator matching to structured bindings is a great idea, I was hoping that would come up. Also: &gt; [ Note: Unlike designated initializers, the order of the designators need not be the same as the declaration order of the members of the class. — end note ] So if the designator matching get extended to structured structured binding, we'll have a situation where 2 out of 3 places that designator syntax is used, order does not matter. Just putting that out there...
I know that people throw around deep learning like it's a tired meme but I seriously wonder if we could use deep learning for this? Like, set it up so that the compiler can actually learn how best to optimize code for arbitrary architectures?
I know that people throw around deep learning like it's a tired meme but I seriously wonder if we could use deep learning for this? Like, set it up so that the compiler can actually learn how best to optimize code for arbitrary architectures?
The facade is a subset of a concept. Concepts allow you to describe properties which cannot be efficiently represented with runtime information, such as typedefs. But I think reusing concepts with these limitations put in place would be better than introducing this. If a concept is too complex give a compile error. Rust does the same thing for its static and dynamic dispatch with traits.
So let’s say you want to do something like: ``` if constexpr (&lt;some condition that indicates this is Windows&gt;) { sscanf_s(...); } else { sscanf(...): } ``` Because the calls available to you are slightly different on Windows than on POSIX based platforms. Well, this, to me at least, seems like a bit of a misuse of `if constexpr`. The condition you are evaluating is giving you some hint about the availability of certain symbols, but that hint is really a tenuous contract you have made yourself, and isn’t really a type-safe assumption in and of itself. In this use case, it isn’t doing anything more for you than you would get from using `#ifdef` in the preprocessor. On the other hand, `if constexpr` is a feature that is strictly type-safe, and unlike the C preprocessor, it does a lot of work for you before you even try to evaluate it. This is a good thing, because you get to catch errors early, and when there are things obviously wrong in any branch, it can tell you right away. The general reason to use `if constexpr` is not usually to just to evaluate some statically defined constant as your code does, but to do some logic on a placeholder value or type, like a template argument. I realize your code is just a toy example and probably not how you ultimately plan on using the feature, but the point I’m trying to make is that `if constexpr` is only actually more useful than `#if` in situations where you are doing compile-time logic on dependent types and values; that is, template arguments whose identity has not yet been decided until later during instantiation. There could be an argument for doing platform differentiation using the actual C++ type system. You could define types for each platform that have static functions for each of the calls you need, and then use `if constexpr` in situations where the function signature might differ. Then, the magic of `if constexpr` can truly shine, because the compiler can help you right away with semantic analysis in both branches. Hope this helps.
I don’t think `if constexpr` was ever intended to replace macros, and especially not to consume information vended using the preprocessor. I think it is intended to be a more convenient and more readable SFINAE-like functionality.
Who are the end users and who are the intermediate developers in your example. And speaking as someone who might be considered as an intermediate developer "working groups, community contribution, or "other means"" doesn't leave me feeling very confident that my woes will be alleviated.
&gt; I don’t think `if constexpr` was ever intended to replace macros I didn't state that it was, just that I believe it should be (or should have been). `if constexpr` provides type safety and allows the use of `constexpr` types- it enables more flexible conditions and more strongly defined compile-time options. So then my question would be: why not?
Here’s my take, FWIW: I think it is possible to use C++ types and constexpr values to create strongly defined compile-time options, in which case you could use `if constexpr` and get all the flexibility it offers. However, if we say that `if constexpr` must respect semantics of the C Preprocessor, which is ultimately just textual inclusion/exclusion, it necessarily weakens the strength and type-safety of its functionality. What I mean is, if the compiler is forced to assume that some other text (such as the declaration of `printf`) could be included or excluded based on the `if constexpr` condition, it can basically make no evaluations at all in either branch until it can evaluate the condition, and even once it can evaluate the condition it can only evaluate the branch satisfying the condition. So what I’ve basically just described is actually the preprocessor, and `if constexpr` would just be a slightly different syntax for `#if` (with maybe just a tiny bit more lexing and tokenizing).
&gt; Who are the end users and who are the intermediate developers Intermediate developers = compiler/language tool devs. End users = general language users and targets of a feature. There will be overlap, of course, but *my point isn't the semantics of who* is using a feature but the applicability and intuitiveness of the resultant features. &gt; "working groups, community contribution, or "other means"" doesn't leave me feeling very confident that my woes will be alleviated That's absolutely a fair concern. I'd still be interested in hearing about explorations in this area, though: past or future. More so, I'm one person; any specific examples given come from a limited perspective and should be treated as such. The method should absolutely be discussed and delved into more deeply, so you shouldn't weigh any amount of confidence on my short list xD Limiting a language specification based on specific implementations seems far too constrictive; unless it includes anything near a total re-specification, of course. If there were another way to go about addressing the implementation-side of things, that should be worth exploring beyond an initial perception. Especially in the face of confusion about the end features
Not easy to adopt when devs have to fill in the missing High =&gt; Intermediate stack.
Tensor products of 1d vector spaces? And some units are represented by affine instead of vector spaces.
There are some major flaws in the paper, even if the main point is reasonable.
If you ever end up providing a specialization for which the if constexpr does hold, you'll be surprised that ot suddenly does not compile... In fact, code coverage reviews must demand that these constexpr branches are covered.
&gt; I think the following features in the standard may gradually be deprecated in the future: 1.Virtual functions haha
Herb did more than six months of consulting experts before the first R0 was published. Draft versions went out to many of the major multinationals, kernel and embedded experts gave their opinions, we saw essay length feedback from teams responsible for some very well known major software products. That's all before anyone on WG21 officially saw it, which I believe was SG12 followed by LEWG. I don't believe EWG has seen it yet, it's on the backburner until C++ 20 ships, which is why I didn't update P1095 my proposed implementation for P0709 for Cologne. Point is, it wouldn't have been proposed if it weren't feasible. The strict OOM changes got unanimous approval at SG12 and LEWG as well. So I think you're way underestimating the consensus investment done for this proposal. Just because *some* experts feel concern at such a seismic change, does not mean a majority do. So far, in all the votes held so far, there has been widespread approval for the proposal in principle.
See also https://www.reddit.com/r/cpp/comments/8i9b1g/if_constexpr_cplusplus_202001_doesnt_discard_the/
I shouldn't have written "at all", but it is still very unlikely. Modern desktop machines (and even modern smartphones) have lots and lots of RAM augmented by page files and on many actually memory constraint systems, exceptions are disabled anyway. Virtualized server systems may be more problematic, but In most cases, your system will start suffering severe effects of memory exhaustion long before malloc will actually fail to give you another 1K of memory. IIRC, This is in fact one of Herb's main arguments: Global memory exhaustion is rarely signald via std::bad_alloc in practice, so why provision for it by default? So I think it is fair to say that, the most likely reason to get a std::bad_alloc is not "There is no memory left on the system" but either "Some local allocator ran out of memory and doesn't have a backup" or "My App tried to allocate an unusually huge chunk of memory"
If a compiler din't known what symbols is, the compiler even couldn't know the bound of the scope. Considering the following example, the `else` scope actually doesn't contains the `c=3;` ``` cpp constexpr int val = 5; #define printf(...) }{ int f() { int c = 1; if constexpr(val &gt;= 5) { c = 2; } else { printf("Failure"); c = 3; } return c; } ```
There is some overlap but the author actually describes why concepts aren't exactly the tool for the job (also mentioning an older proposal about `virtual` concepts).
If the keyword `facade` is introduced it would probably make sense to make it possible for a concept to check that it requires the functions described in a facade + more things I guess. But I agree that we could just constrain the kinds of concepts usable in a proxy. Anyway it would required to be able to pass concepts as template parameters which - as far as I know - isn't possible in C++20.
There was recently an example that showed a muteable constexpr on this sub, has it been fixed?
&gt; Can someone explains what this means to an average programmer? Intel is trying to lock you in, as they usually do.
Isn't the second goal essentially §4.5 in Herb's proposal? In that case it's an "extension" and not part of the core proposal. If I understand correctly having to annotate expressions and statements with `try` is just to make exceptional control flow visible in the code and not something that helps the compiler in any way.
I did consider the issue with passing the concept. I don't see why that couldn't be added to the standard. Templates emulating concepts can be passed as template templates and I don't see why concepts should be less powerful. But I have no idea about implementation details so I'm sure there could be some issues.
There's no need to use the two-part form of `if` if you the value you are testing is the variable you're initialising, so this would be enough: if (auto result = scn::scan&lt;int, int&gt;(stream, "{}/{}")) { // ...
And one more thing: as I understand, currently the library SFINAEs out operations with incompatible units. I wonder if it would be better to provide a hard error with a readable error message with a `static_assert`?
There have been [two](https://brevzin.github.io/c++/2019/01/09/concept-templates/) [articles](https://brevzin.github.io/c++/2019/03/24/concept-templates-2/) about such a feature by Barry Revzin, but I don't know whether it was ever brought up during committee discussions. Even if it gets discussed, it's most likely not something we will see before C++23.
&gt;if I build my program with static exceptions enabled and normal exceptions disabled, the default allocator should terminate on allocation failure. Static exceptions are supposed to coexist with dynamic exceptions. Disabling dynamic exceptions would still be a non-standard feature so it's not something the standard would say anything about.
This is a bad example; macro substitution happens before the compiler is invoked. In your case 'printf' is not a symbol but a preprocessor token.
I really like ISPC, it is simple and does a single thing well.
you know, I've never really thought about the implementation for std::is_permutation. A simple way to implement it would maybe be to sort it, find a common start point and compare from there (if we relax the requirements slightly so operator&lt; must be supported) A possible implementation of it exists on devdocs: https://devdocs.io/cpp/algorithm/is_permutation That should fit the complexity requirement: &gt; At most O(N2) applications of the predicate, or exactly N if the sequences are already equal, where N=std::distance(first1, last1) Sounds like a fun challenge to convert that to a reduce/fold!
First of all, thanks for your interest ! :) Indeed, I could have directly extract only the first n characters from the `MD5`. I did it that way, because, I was expecting the part 2 of the problem to have something to do with the rest of the `MD5` hash, and when I didn't changed it when I saw the part 2. At least, it allowed me to experiment a bit with the `MD5` algorithm which I dodn't know before this Advent Of Code problem :D
The goal is to use the normal architectural calling and return mechanism like a register to give exceptions in the 'throwing values' domain fixed space and time costs necessary for use in places with hard real time requirements like games or the kernel or embedded. That means it has to be part of the signature, since it's a caller/callee contract. It's morally the same thing as declaring a function that returns expected&lt;T&gt;, but doing that in the core language.
You are thinking about the `throws` keyword that are used on functions that can throw this new type of exceptions: int foo() throws; The quote that you posted is talking about the use of `try` when calling the function: int x = try foo();
No my point is: No need to convert it to a string at all. You can just work on the bytes already. If you decouple those 2 (generate MD5, convert bytes to string) you can just check the first few bytes for zero. If part2 requires a string, you got the function ready.
Hey **electricCoder**, Maybe you can work around it since we are not in an OpenCL C environment anymore. SYCL is built in C++11 (and onward depending on the implementation), introducing things like lambdas that have insignificantly little to zero overhead. But even going back to C++98/03 you can use Functors or even Template Functors if you wish. Then, you can template your operation to provide a generic way to use/consume the Functor or Lambdas. **#1** Use with **Functors / Template Functors**: *Sticking to (maximum) C++11* The context of the following code is a "generic" program that generates sequences of any type. It is very simplified for the purpose of showcasing the main idea here, an alternative to function pointers via the use of Functors. So here is the function we call to generate a sequence: *The input array stores index values.* ``` template &lt;typename T, class Operation&gt; void generate_seq(const std::vector&lt;T&gt;&amp; input, std::vector&lt;T&gt;&amp; output, size_t num_elements, Operation op) { &lt;&lt; setup buffers &gt;&gt; queue.submit([&amp;](handler&amp; cgh) { &lt;&lt; setup accessors &gt;&gt; cgh.parallel_for&lt;kernels::gen_kernel&gt;( my_range, [=](item&lt;1&gt; item) mutable { auto id = item.get_linear_id(); output_acc[id] = op(input_acc[id]); }); }); } ``` Here we have templated the operation instead of using a function pointer. Now we can create the Functors that we pass as operations. A functor that generates an incremental sequence. ``` template &lt;typename T&gt; struct Increment { T operator()(int idx) { auto res = T{}; for (auto i = 0; i &lt; idx; i++) { res++; } return res; } }; ``` Another that generates the Fibonacci sequence. ``` template &lt;typename T&gt; struct Fibonacci { T operator()(int idx) { auto res = T{}, a = T{1}, b = T{1}; if (idx &lt;= 0) { return 0; } if (idx &gt; 0 &amp;&amp; idx &lt; 3) { return 1; } for (size_t i = 2; i &lt; idx; i++) { res = a + b; a = b; b = res; } return res; } }; ``` And finally, here is how you pass them to the generic function `generate_seq`: ``` // generate incremental sequence generate_seq(input, output, num_elements, Increment&lt;int&gt;{}); // or to genereate fibonacci ... generate_seq(input, output, num_elements, Fibonacci&lt;int&gt;{}); ``` This is a standard **go-to alternative** to **function pointers**. **#2** Use with **lambdas / generic lambdas**: Here is a recent blog post about generic lambdas and how to use them within SYCL device code with practical examples, which match the sample code I posted here for Functors. Bear in mind that the blog post is more **ComputeCpp** oriented, since Codeplay's SYCL implementation supports most of **C++14** features, or at least it definitely supports generic lambdas. Nonetheless, you can still modify the code to work with **C++11** lambdas as well if you wish and it is another **good alternative** to **function pointers**. Regards, Georgi
I thought I had playback speed set to 1.5. I didn't.
Concepts just do type checking, but this is about dynamic dispatch. C++ traditionally mixes static and dynamic dispatch in one bag, i.e. we have statically and dynamically dispatched member functions; and on top of that, dynamic dispatch is tightly coupled with inheritance, which creates a lot of issues on its own. In the ideal world, the would be no virtual functions and dynamic dispatch would be done by specifying type-external vtable descriptors that types can adhere to. Great examples of this done right is Rust traits. Swift protocols are also similar, but the rules are more complex.
I would love that. Unfortunately, I don't see this ever happening.
&gt; in principle. seems to do a lot of heavy lifting in there. In principle I am for value exceptions. In practice, I am against a proposal that conflates them with removing bad_alloc.
Made my day!
So what's your suggestion for improvement?
Woah blockchain is really everywhere
So anything that calls a function that uses cdecl is now not written in C++? I'm now just curious where the lines are drawn in your brand of mental illness.
The argument that I read in their rebuttal paper is that, paraphrasing, "Cairo is used in production apps, so the graphics API we propose can be used seriously." ... to wit, should people not simply just use Cairo if that suits their needs? I have yet to read a well-articulated set of guidelines that indicate what the "bar" is for inclusion into the C++ library. I'm seeing the "C++ was created before GUIs and the Web" thrown around a lot, and honestly, that doesn't cut it. C++ was around before probably billions of things, but you don't see us trying to add blockchain to the standard (or so help me god...).
Well, if we cherry pick the worst offender in recent history, surely I'm allowed to cite libraries and languages that have broken compatibility for me in ways that didn't scuttle the ship. I mean, the worst of it I've seen is when Apple just straight up deprecated Carbon and moved everyone to Cocoa. But the world moved on in spite of that.
C++ is perfectly fine for this space.
&gt;cgh.parallel\_for&lt;kernels::gen\_kernel&gt; &amp;#x200B; I had previously thought that kernel names had to be unique. Is that not the case? &amp;#x200B; The desire for function pointers stem from working with code that has numerous configuration points. For example lets take a kernel which has two varying inputs. The first an implicit shape ( box, sphere, plane, frustrum, and cylinder ) and some solver ( RK3, RK4, Euler, Gauss ). &amp;#x200B; With this we have 20 unique kernels that we need to generate with the template approach compared to the single for the function pointer approach. Yes, the function pointer approach potential has worse performance ( Presuming the kernel isn't actually memory bound, or the optimzied versions don't already spill ). In addition the template approach requires either the entire call stack be templated ( which has real compile time costs ), or requires some de-virtualization / switching at the kernel location. Which forces the kernel location to know all the possible types for implicit shapes and solvers.
Doesn't matter! In neither case I want my program to just be terminated out of nowhere...
The same reason why you cannot do this: template&lt;typename&gt; auto function() { return undefined_function(); } You wounldn't expect this to compile and indeed that's the case (unless old msvc versions). However, this code should compile: template&lt;typename T&gt; void ElsePrint(T t) { potato(t); // no definition of potato } The `potato` call might be a friend or a free function to call using `t`. So ADL calls are not part of that rule, since this code should also compile: template&lt;typename T&gt; void ElsePrint(T t) { t += 1; // no definition of += ?? }
Ah yes! This is an excellent idea, I haven't thought about it! I will do that! &amp;#x200B; Thank you :)
Do it like MS (did up until recently) and break your ABI all the time so everybody is aware that there is no C++ ABI?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/rust] [Cardiff Rust meetup!](https://www.reddit.com/r/rust/comments/c58dyw/cardiff_rust_meetup/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
The problem is that doing so requires the world to be ready for it. If libraries can't be build from source easily abi sounds like a good idea. If people think that not distributing all their dependencies is normal, abi sounds like a good idea
It looks like BlastBay is a language close to C++, with functions to easily make an audio application. I don't know why they didn't develop a C++ library instead. If you want 3D audio, you can use OpenAL Soft. It can use HRTF to output binaural audio.
What's the comparison with [nholthaus](https://github.com/nholthaus/units)' library? I've been using that currently. For ease of comparison, check out [this section](https://github.com/nholthaus/units#defining-new-units). Your README is nice and explains custom units nicely, step-by-step
&gt;The problem is that doing so requires the world to be ready for it. Definitely. &gt;If libraries can't be build from source easily abi sounds like a good idea. If people think that not distributing all their dependencies is normal, abi sounds like a good idea Yet it's Linux/Unix - where most code is actually readily available to be recompiled - that purports a stable C++ ABI... As someone with an extensive Windows-background I always considered this illusion of a stable C++ ABI strange/bizarre and felt justified when this std::string-mayhem in libstdc++ took place.
You are correct! SYCL kernel names must be unique, therefore the same type cannot be used twice to name 2 kernels. The above code was a demo where I have forward declared the kernel name - `class gen_kernel` in the `namespace kernels`. However, you could refactor my example and move the code that is inside `cgh.parallel_for&lt;kernels::gen_kernel&gt;` to a functor, that will be called like so: ``` cgh.parallel_for(range&lt;1&gt;(num_elements), kernels::gen_kernel&lt;T, Operation&gt;( input_acc, output_acc, op)); ``` Here is how the **SYCL kernel functor** would look like: ``` namespace kernels { template &lt;typename T, class Operation&gt; class gen_kernel { static constexpr auto rmode = access::mode::read; static constexpr auto wmode = access::mode::write; static constexpr auto gtarget = access::target::global_buffer; public: gen_kernel(accessor&lt;T, 1, rmode, gtarget&gt; input_acc, accessor&lt;T, 1, wmode, gtarget&gt; output_acc, Operation op) : m_input_acc(input_acc), m_output_acc(output_acc), m_op(op) {} void operator()(item&lt;1&gt; item) /* mutable */ { auto id = item.get_linear_id(); m_output_acc[id] = m_op(m_input_acc[id]); } private: accessor&lt;T, 1, rmode, gtarget&gt; m_input_acc; accessor&lt;T, 1, wmode, gtarget&gt; m_output_acc; Operation m_op; }; } // kernels ``` Following this, we don't actually need more than 1 kernel object, where the device-specific code for each of your solvers will be placed in separate template functors. The reasoning behind all I've said is based on the where SYCL originates from. SYCL needs to translate the kernels to OpenCL code, which is you an OpenCL runtime is required. Therefore, some limitations posed to what can be allowed in device code are unavoidable. But this is why C++ has such a complete feature set or array of options. I can only suggest adapting for the moment being. List of C++ constructions that cannot be converted into a valid OpenCL code are invalid in SYCL: * Exceptions (try / catch expressions) * Accessing non-const global variables inside device code * **Function pointers** * RTTI (dynamic\_cast, typeid) * Dynamic memory handling: new, delete * Note: [placement new](https://en.cppreference.com/w/cpp/language/new) is allowed I get where you are coming from, but moving your solvers to Template Functors rather than function pointers can also help for more clarity in your program. It is a limitation that will be a part of SYCL 1.2.1, so software applications that aim to adopt SYCL for parallel acceleration will have to re-design some of those old C++ / C specifics in their code base.
That is correct. And you may be right about using static asserts in a few places instead of SFINAE'ing out everything. Personally I like to see the full template stack traces, but I can understand wanting more human-understandable errors. I'll look into this. Thanks.
I've not seen that library before, so I can't comment on it. I'll check it out when I have time, and maybe add a comparison section to the readme. Thanks.
Would you recommend an allocator such as this for a dynamic language interpreter?
Affine spaces are why I'm not doing things like degrees Celsius. It doesn't mesh well with my \`scaled\_unit\` type. When your zero isn't really a zero, things go wonky really fast.
You are the one not checking reality, as every argument about 100% C++ code can be easily proven wrong. So your point is that cdecl implies being written in C++?!? Lets start for what it actually means on Windows, https://docs.microsoft.com/en-us/cpp/cpp/cdecl?view=vs-2019 &gt; __cdecl is the default calling convention for C and C++ programs. Because the stack is cleaned up by the caller, it can do vararg functions. The __cdecl calling convention creates larger executables than __stdcall, because it requires each function call to include stack cleanup code. The following list shows the implementation of this calling convention. Which implies that it could have been written in C, not C++. Better yet, maybe it was written in Delphi actually: unit output; interface procedure HelloFromCpp; cdecl; implementation procedure HelloFromCpp; cdecl; begin WriteLn('I am written in C++') end; end. Ok, that is a Windows thingie, lets go to an UNIX platform instead #[no_mangle] pub extern "cdecl" fn HelloFromCpp() { println!("I am written in C++") } I can carry on doing with other language examples, so what was again your point regarding cdecl implying being written in C++?
&gt; The strict OOM changes got unanimous approval at SG12 and LEWG as well. So I think you're way underestimating the consensus investment done for this proposal. Just because some experts feel concern at such a seismic change, does not mean a majority do. So far, in all the votes held so far, there has been widespread approval for the proposal in principle. So why was the section on OOM watered down in the latest version of the paper?
Kind of relevant, at University we had a blind lecturer that taught us audio programming. We used C++ to produce sound only games for his module and it was really interesting. However, that was a number of years ago now so the tech isn't useful anymore but it is certainly still do-able.
Gothic Revivalist C++ is just doubling up on your { brackets: if (x &lt; 10) {{ b = 100; }} Not that hard to understand, Ben. But the larger point is that the structure revealed by curly-brackets is important and needs to stand out more, particularly after C++29 introduced python style bracketing-via-indentation. I am definitely against AAI (almost always indent).
At first you said C++ wasn't being used for desktop development, now you keep saying &gt; 100% C++ code For some reason. Not even sure what you are trying to say or prove. It sounds like you have some crazy hangups on what you wish was true and you think if you keep commenting on the internet it might magically happen. &gt; So your point is that cdecl implies being written in C++?!? That's not at all what I said.
The thing that immediately comes to mind with this `failures to allocate "small" buffers (usually single objects)` is this: What constitutes a small buffer? Is `new int` small? Is `new int[1]`? Related note: do these two calls now work differently in terms of allocation errors? What about `new X` with `struct X { int vals[10000]; };` ? Now `X` may be a singular object yet it's definitely **not** a small object and failure to allocate a `X` can in no way signal heap exhaustion…
The problem with that is that a prime number of brackets might introduce a scope in static_if - tbh I don't think narwal initialization is a net positive as in most cases hallowing conversations are not an issue, just use std::bless
It seems that the C++ users are hoping for a packaging system and a portable ABI but modules are delivering a better precompiled headers and build time improvements. I know I must be wrong so... what is the best tangible benefits that will come from modules?
It is very much possible to do it with C++, given that C++ is a systems language. In other words, you can develop any kind of system with C++,, even ones requiring very high performance. Given this, you could write your own C++ code to compute 3D audio properly. However, you will probably want to use a library for that. Take a look at Wwise, fmod, XAudio2, OpenAL and other libraries.
Better trackability of where things are defined, better componentization, better build times if only because you don't do the same work hundreds of time, macro isolation - meaning compiled modules expose a consistent truth. All of which help writing more dependable code which despite having nothing to do with package management is an important pre requisite.
I would call it a *refinement* of the earlier "one size fits all" proposal. Now failure to allocate abstract-machiney objects is terminate by default, whereas arrays throw bad alloc. I think that's a reasonable evolutionary step, even if I don't agree with it myself. (Last time I met with Herb and a few other committee folk at the ACCU conference I raised the point that Windows now looks for allocated pages not recently used, compresses them, and unmaps them from your process. Upon first access, the page is decompressed and mapped back in. That means that even if you write into everything returned from `malloc()`, you are no longer guaranteed that that memory still exists when you next access it i.e. any access of **any** RAM can hard OOM at any time. That, in turn, effectively means that `malloc()` will always succeed for any number under 127Tb, and there is zero point in doing `bad_alloc` any more for any C++ code running on Windows. The other major OSs are not as extreme as Windows, but all have been heading in the same direction what with zero page zapping, same page combining etc, so for me, just ditch 'bad_alloc' completely from any container using the standard allocator, it's quite literally wasted opcodes, pointless overhead)
Nobody has proposed to remove `bad_alloc`, just from STL containers with the standard allocator, where it only ever threw for ludicrous allocations in any case, as any reasonable number always succeeds irrespective of system resources on the major OS kernels.
Right, but I think concepts can be used to make those proxies is what I mean. No new technical tools seem necessary for this; it's only a design pattern.
This was also mentioned in Nicolai’s talk at around 28:00 https://youtu.be/9-_TLTdLGtc
What are you trying to accomplish?
I like to use Alure (an OpenAL C++ wrapper), free and can make the usage of OpenAL a breeze.
You can use also std::variant&lt;std::string, bool&gt; c = "abcd"s;
&gt; posix_spawn() doesn't need overcommit to launch new processes (*glibc and musl use vfork to implement it*) They use vfork *some of the time*. Pass certain options regarding streams and such to posix_spawn and it will fall back to normal fork.
I just want to play around a little bit.
FWIW, the actual proposal makes "small buffer" analogous to a single object. So `new int` is small (as is `new class_with_sizeof_equal_to_5gb_for_some_reason`), but `new int[1]` is big.
In R3 of Herb's paper he distinguishes, not "small" and "big", but "fixed length" (`new int`) and "variable length" (`new int[N]`), then goes to say something like "fixed -&gt; errors; variable -&gt; bad_alloc". Then goes into details about `new int[1]` being variable and how allocators are implemented - they only have `allocate(size_t)` so they will definitely call `new int[1]`. Then Herb proposes a new allocator API - `allocate_one()` which would do a `new int` instead. &amp;nbsp; Yeah, I'm not a fan of this idea.
As far as I can see, conversion to `bool` is explicitly ignored. Do you know of any use case?
I read the major changes of R3 (section 4.3) and I'm not a fan! This "single object allocation failure is a hard error"-approach is just plain wrong IMHO and the reasoning behind it is 100% arbitrary to me...
I lost it at the bit about arithmetic division :D
The C++ side has virtual constructs, so if we want to execute SYCL code based on those polymorphic types we have to build some mapping from concrete types to the run time types and launch the appropriate kernel. Which means some kernel generation code will have to explicitly know all the derived types.
It sounds like you're saying you want order-independent designator initialization? There's a reason described in http://wg21.link/p0329r0 under "Evaluation and Initialization Orders". Do you have an idea as to how to handle the order mismatch?
Not sure the easiest way to do this with OpenCV. I would recommend using something like OBS [https://obsproject.com/](https://obsproject.com/)[https://obsproject.com/](https://obsproject.com/) to record a screen capture to file, and then you could load that video into your OpenCV program to work with.
Thanks for the clarity. Some of these features feel vague early on and then Tada! They stick the landing and we have some awesome-sauce like lambdas or constexpr, etc.. It would be nice to see the whole vision articulated up front. It seems everyone is moving the ball incrementally forward and hoping for the final vision to pan out but not explicitly stating the best case end goal.
Not an answer but a note: I'd honestly say that the "3D" sound is actually a 2D sound when you don't have a visual reference to apply it to. Normally it's called 3D sound because it adds front-left-right-back audio to up-down-left-right video from the screen. The audio alone is 2D, since it gives you only 2 axis (as you said, no height reference)
I need it in real time. With Python it is possible with "imgrab" but I can't finde something similar for C++
The `@` construct is still there, just spelt differently because `@` is not in the character set for C++ and adding it was not going to fly in EWG. I can understand the concern for `auto` and `let`. The notion of `let` ("bindings") was introduced in C++17 for structured bindings, but it is implicit and is restricted to the structured bindings context. We could certainly hide them in patterns as well. Since a pattern is implicitly in `let` mode, without the `let` keyword we can simply insist that you write `[x, case y, case z]`. With `let`, one could write `case [let x, y, z]` instead. But there's something to be said about having one way to write things, so I could certainly see `let` going away. We'll see how it evolves. Thanks for your feedback!
I don't think that the C++20 concepts, as they are designed currently, are well-suited for this. With dynamic dispatch proxies, you want description of function signatures. C++20 concepts however are sets of parametrised expressions that need to be valid for complaint type or types. I don't see an obvious way how concepts can be made to fulfil this function. You either need to redesign them to be more like Rust traits or you need to have two different kinds of concepts, at which point you might just as well call one of these facades or protocols.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
I see; if that is the case, withdrawn.
This is a very interesting topic. You can very well use C++ to make audio games - I would recommend checking out creative programming tools like openframeworks/cinder. I would also recommend trying web development because JS has a lot of easy to use game/audio libraries(tone js, etc) which can easily be used on websites or even native mobile apps. Would mobile phones be a good medium for you to play these games?
I don't think C++ can do syntax checking without certain level of semantic analysis. E.g. T * a; // #1 sizeof a; // #2 To determine whether #2 is valid, the compiler has to examine #1, which can only be done when a declaration of `T` is present. Within templates, cases like this often require the `typename` disambiguator.
That depends on how you define it. If you define it by playback then it depends on your setup, use only headphones? Then it's 1d, it can pan left or right. Use a Dolby Atmos setup and you can throw sound anywhere for actual 3d sound. If you define it by recording, then it depends on the microphone, if you have a fancy 3dio mic that pics up the sound differently depending on all 3 directions around it then you could say it's still 3d audio even if you play it back on headphones. Since audio recorded below or above the mic sounds different to each other.
My biggest issue with the current proposal is that `push_back` on a `vector`, or if I understand correctly, even a `list`, will be able to throw `bad_alloc`. This seems a giant step backwards. Also, `new int[3]` can throw `bad_alloc', yet struct X { int arr[1000][1000]; }; new X; // Will call terminate
I use Spout (http://spout.zeal.co/) for passing GPU texture buffer pointers between applications. You might be able to find a program that is supported by Spout that can do screen capture in real time. Then you would need to pass the pointer into your C++ application, for which there is a Spout SDK with C++ API and documentation for how to do that. I would also maybe look at something like this: https://github.com/smasherprog/screen_capture_lite Trying to screen capture like that is going to be quite slow unless you can find a handle on the texture buffer directly, especially if you're running a game at HD or larger resolution.
All production audio/game development is done in c++. C++ is a great option
Still can't believe [std::get_money](https://en.cppreference.com/w/cpp/io/manip/get_money) wasn't mentioned in this talk
All very valid observations which I'd agree with personally.
I think it's not necessary the language, but more or less the compiler, somebody probably will eventually make a compiler that competes with Rusts safety. I think it would have to be called a different language though cause if they changed it too much, it would be hard to compile with older compilers, and people would have to try learning the new C++. Making an entirely different language such as Rust was probably the smarter idea
Cross-platform remains something you do with the preprocessor. if constexpr is something you consider using instead of sfinae or tag dispatch. Hiding code that is invalid on the current target isn't the use case.
This is brilliant! I am considering this a serious suggestion and will be taking steps to implement it.
is this the pumpkin guy
* No anal borrow checker. * Variadic generics. * Function overloading.
responsibility
Rust tries to learn from C++ mistakes and avoid them altogether. The wheel connotation is really bad here.
Exactly. If `if constexpr` behaved exactly like `#ifdef`, what would be the point of it?
&gt; use only headphones? Then it's 1d, it can pan left or right. Not really. We only have 2 ears and that's enough for 3D positioning.
As a fan of both languages, the only real advantage of Rust over C++ is their standardized build system. The safety Rust offers can be had in C++ using compiler flags, tools and sanitizers (Clang even has an experimental lifetimes flag). Complexity-wise, they’re quite similar. I would like Rust to have a better ecosystem, better tooling and better libraries. In C++ you might end up using far less libraries in your project, but they’re usually well-tested battle-proven libraries like boost or Qt. So while you might have 20000 crates in crates.io, only a far tiny fraction can be considered production ready. Rust has the advantage of having learned from past mistakes. You can look at a Rust project and know fairly easily how it’s structured. A disadvantage of Rust, in my opinion, is that moves are what’s considered a shallow copy in C++, the rust compiler ensures that you don’t access the moved from an object after a move, however since no destructor is run (a drop in Rust semantics) this would mean a higher memory footprint. C++ also has a more advanced template system and compile-time expressions. It’s also far easier to use C libraries in C++. C++ also makes it easier to hide abstractions without leaking complexity, a library user can simply extend (inherit) a class and not worry about lifetime annotations. In Rust if you wanted to extend a trait, it’s more boilerplate-y to do so. Also Rust currently links everything statically, making binaries larger. C++ debug builds are generally faster than Rust, as well as builds optimised for size. Whereas builds optimised for speed perform as well as C ans C++.
Who thought this is a good name?
Who is saying Rust is faster than C++? That isn't the case. Rust has a couple disadvantages. It lacks important features and capabilities of C++, though many of those will be added eventually. Rust's memory model is incompatible with the design of increasingly common high-performance software architectures based on direct DMA-ed I/O and opaque memory structures (this is best practice for things like database kernels or anything I/O intensive) since memory ownership is not observable at compile-time. Rust is a good choice for applications where you might've written it in Java in the past but you want something more deterministic and closer to the metal. If you are looking for maximum performance and throughput, you'll want to stick with C++.
Like others have said, you should look into an existing tool rather than trying to implement spatial audio yourself. I recommend trying out [Steam Audio](https://valvesoftware.github.io/steam-audio/), which is focused on creating physically accurate sound simulations for VR. It might be the best option out there, and you don't need to use Steam or create a VR game to use it. I have no idea what the license is like, but the SDK is free to download. They offer some plugins for game engines like Unity and Unreal Engine 4, but there is also a C SDK. That's probably what you want to use, as you'll easily be able to use it in a C++ project.
Awesome! I'm moving back to Wales from Berlin, so not having to give up Rust meet-ups will be fantastic :D (the bus down from Aber might be a bit rough but worth it haha)
Everyone?
being able to use whatever allocator you want whenever you want.
Doesn't seem worth using unless your code base is plagued with implicit conversions.
&gt;... I mean, the worst of it I've seen is when Apple just straight up deprecated Carbon and moved everyone to Cocoa. Which is also one of the reasons why there are significantly less softwares available on Mac compared to Windows because if they built something for macOS it won't work after just a few years while for windows the same software written 10 years ago may still work, without a recompile. Apple just doesn't care, but it doesn't mean it's a good thing to do. Similar sentiments were expressed by Sony regarding ABI on a recent C++ conference stating that such breakage is simply unacceptable because it upsets the customers, which allows one to play old PS games on the latest PS4.
Nothing specific, but this change has broken previously working code. And it broke in really unexpected way - if the code with ConvertibleToBool stopped compiling it would be fine, but it still compilers, and now variant holds int alternative instead of bool as programmer would expect.
I don't really get the point of this answer. I've shown a code that is broken now due to P0608, and proposed two solutions. How does this help to fix the issue or root cause?
Hello, This is a great question. I have developed audio-based games in the past using C++. The main advantages of C++ are of course that being a systems language, you can program pretty much anything in it, but more importantly it allows for very high performance code, which is going to be necessary when dealing with low level audio algorithms most notably DSP. I'd recommend starting out using a game engine like Unity or Unreal which both offer the ability to play 3D sounds out of the box on top of a lot more game systems ready for use. If you would like to dig deeper, you could use an audio engine like FMOD which is designed for games and offers 3D audio out of the box. Note that if you want to do the programming yourself, there are a lot of tools out there for blind programmers. The most popular IDE for writing games is Visual Studio and there are a number of accessibility options and plugins for you. Best of luck, please reach out if you need any help.
To add to the exceptions argument, the other option is std::error_code which offers a standard interface. In Rust, a Result can hold an error which might be an int, a custom error code, a string or whatever. So nothing standard, which might also be confusing for newbies as it was for me.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/c5d0ez/looking_for_some_help_regarding_the_cost_of_the/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Your ears are still 1d, the shape of them is just really good at compressing a 3d sound space into 1d. This is the same as with the fancy mics I was talking about. That's essentially what they are doing as well, since it's a stereo recording it has to be 1d, since there literally isn't any more data other than pan left/right.
As someone who doesn't use rust, I pretty much held the opinion "it's interesting, and I should probably learn it, but I'm not sure I'd enjoy using it more that C++". But seriously, no function overloading? That's a deal breaker.
&gt; whatever allocator I nevre used a "non-standard" one. what am i doing wrong?
&gt; Rust's memory model is incompatible with the design of increasingly common high-performance software architectures based on direct DMA-ed I/O and opaque memory structures (this is best practice for things like database kernels or anything I/O intensive) Could you provide a link with further information please?
Hey, you're more than welcome to join us. We're happy to see new faces and experiences.
Nothing. Some cases benefit greatly from a custom allocator, many do not. Having the STL containers able to take a memory pool allocator (yes I know this wasn't the original intention) has given me 50%+ speed up in some cases. (e.g. lots of operations on a std::set). Rust does have crates that allow for arenas and custom allocators built on top of the system allocator, however. I don't know how well they work with boxed types.
You were the one stating that **all programs I use are written in C++** as response to my statement. The onus of proof is on you. I just keep deconstructing everything that you throw at me as false, proving which layers aren't written in C++, thus invalidating the assertion. Provide the list of OS and application written in pure C++ for desktop and mobile OSes that are those magical **all applications I use are written in C++**, which make my comment incorrect regarding the C++ support in OS SDKs from Apple, Google and Microsoft, and we are done. "You are arguing, you are loosing" -- Dan Saks, CppCon
I find this pretty interesting, besides first person shooters what other kinds of audio games can be done?
&gt; since there literally isn't any more data other than pan left/right. There is also a delay and all sorts of other stuff that allows to determine the position of the sound pretty accurately (cons the artifacts/illusions and other perceptional quirks). At least in the context of OP's post (and usual interpretation between mono/stereo/etc.) this is enough.
I don't have a Windows machine, so I can't really test that. Right now, library uses `std::strtod` internally for parsing floats (it is customizable, though), so if your `std::from_chars` implementation beats that, it's likely to prevail.
The hate exceptions get is ridiculous... or is there really some new magical solution to propagating errors from deep in a call chain? Something that doesn't involve a lot of error-state checking.
These are pretty much the reasons I decided to use C++ for my current hobby project. Once Rust has dependent types and compile-time evaluation, I am willing to take another look. And yes, in my limited experience with Rust, the borrow checker was more of a bother than help, especially since Rust lifetime analysis is lexical...
https://github.com/gabime/spdlog
I'm assuming by "delay and all sorts of other stuff" you're talking about stuff like reverb and echo. These are part of the information compressed into 1d when it either enters your ear or a mic. There's no way to distinguish between a thing in a large room making reverb vs a thing right in front of you that just happens to sound like it from the audio alone. Your brain can do it if it has other context clues like visual information or previous knowledge of where the sound came from, it's a really amazing machine. And I agree, it is enough, but this comment chain started as a response to a guy being pedantic about "3d vs 2d sound". When anything stored as a stereo track can not be more than 1d by definition
&gt;especially since Rust lifetime analysis is lexical... This is actually not the case starting with the 2018 edition of rust. There is still room for improvement but the borrow checker isn't quite as frustrating. [https://doc.rust-lang.org/stable/edition-guide/rust-2018/ownership-and-lifetimes/non-lexical-lifetimes.html](https://doc.rust-lang.org/stable/edition-guide/rust-2018/ownership-and-lifetimes/non-lexical-lifetimes.html)
Existing libraries, existing community, employ-ability, tools (although rust has better dependency management and build tools), shared knowledge, did I mentioned existing libraries? Languages are little without an ecosystems and ecosystems are slow to grow
Another significant gap is the lack of constant generics. In other words, in C++ a template can be specialized with a constant. In rust, this is not currently possible. There are cases where the standard library manually defines implementations for traits for arrays up to size 32 as a workaround for this gap in the language.
Thanks. This looks very interesting
Hello, may I ask how well do you think that HRTF works for you in the spatial locating sense? HRTF models are good but they do not account for differences between the ears of each human, which have subtleties that provide many localization cues. Do you use a particular headphone you found worked best for you, or it is generally satisfactory with many headphones?
Implementation inheritance. In rust, one cannot extend a struct. Supertraits are support but this is the equivalent of extending a Java interface.
This is in the works and afaik will be ready withing a few stable releases. There are talks of integrating what's already done into std.
It used to be called friend name injection. Have been using it for decades.
It's also possible to change global allocator (and write a custom one), but the per-container allocator support is still WIP, IRC.
&gt; exceptions (...at least you have options) That's not _really_ true, unless you're in the mood to replace the entire standard library. Certainly some companies do, but not everyone has those kinds of resources.
yeah, although to be honest I didn't need to think about affine units to understand dimensional analysis in terms of vector spaces. I'm referring to the Buckingham pi theorem
Nothing magical. My understanding is that since exceptions are often implemented with zero cost unless thrown, exceptions can be faster in cases where they aren't thrown. In rust, the question mark operator can be used as syntactic sugar to check a result and then bubble is up as long as the calling function returns a Result. However, it is just syntactic sugar so while it is ergonomic, the compiled code still has to check the result. [https://doc.rust-lang.org/stable/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html](https://doc.rust-lang.org/stable/edition-guide/rust-2018/error-handling-and-panics/the-question-mark-operator-for-easier-error-handling.html) I have grown to like the Rust approach since it forces me to consciously bubble the error up or to handle it. The compiler will not allow ignoring Result values without explicit syntax. My view may be heavily influence by coming from working with Java code that throws exceptions in a background thread they isn't caught or handled by anything.
Herbceptions is an interesting idea (http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0709r0.pdf) Looks like it still has a bit of momentum, and I personally quite like it.
&gt; I mean, in comparison, mine is practically natural language. You have a 16 character typedef for void.
Right, I should have mentioned that.
While rust's build tooling is nicer in a lot of ways, it is less flexible, and doesn't have great support for stuff like binary packaging and shared libraries (this may be an upside for some). It's real advantage is it's been there from the beginning and (hopefully) everyone will use cargo instead of 4 different build systems. Then again build systems tend to take a while to start proliferating. Oh also rusts orphan rules can be annoying (although they do provide some useful properties)
One neat aspect of rust is that it's design actually allows for more kinds of garbage collection than c++. For example there's some infrastructure in rust's stdlib to support moving/compacting GC (it's unclear if anyone will ever actually implement such a gc for rust, unfortunately)
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;I see several mentions of '`operator &lt;=&gt;()`' rendered as '`&amp;lt;=&amp;gt;`,' or literal HTML escape sequences, too.
&gt; A disadvantage of Rust, in my opinion, is that moves are what’s considered a shallow copy in C++, the rust compiler ensures that you don’t access the moved-from object after a move, however since no destructor is run (a drop in Rust semantics) this would mean a higher memory footprint That's incorrect. Moves in Rust are not different from moves in C++, other that they are not required to leave the moved-from object in the valid state (hence "destructive"), which is ensured statically by the compiler. This is an advantage. This allows for "shallow copy" (or even just a noop in most cases), where C++ had to resort to swap idiom or something even more complicated. &gt; C++ also has a more advanced template system and compile-time expressions This is also debatable. Regarding TMP: it surely is more powerful in some regards, but not really more expressive (though Concepts do make things better). As for the compile-time expressions - those are also present in both languages with relatively the same capabilities (though some features are only available in Nightly Rust). &gt;It’s also far easier to use C libraries in C++. C++ also makes it easier to hide abstractions without leaking complexity, a library user can simply extend (inherit) a class and not worry about lifetime annotations, same for dynamic dispatch Heh, I'd argue the opposite. It's really hard (almost impossible) to write a good C++ abstraction without leaking complexity (see strings for example). It all depends on a use case, of course, but there are a lot of potential leaks. I mostly agree (or don't disagree) with the other points.
[spdlog](https://github.com/gabime/spdlog) is probably the most popular library AFAIK. You could also checkout [glog aka google log](https://github.com/google/glog) which has some convenience features like printing stack traces and the ability to control logging on a per module level from the command line.
spdlog and google-log (soon to be part of abseil) are both popular options. Someone should write a good structured logging lib for C++.
Hey there, I can't offer any advice. But could you recommend a game to see what it's like? I'm quite curious about it!
Most of the applications of function overloading can still be done in Rust with `foo.overloaded_function()` instead of `overloaded_function(foo)`. You define a trait and implement the trait instead of write a new overload. For the simpler cases, there's already a trait for you, so you just write a "template" (I think they call them generic functions, but it's the same thing in the end)
May I suggest stackoverflow? @/u/war3_exe
Thanks, i'll give spdlog a look. not sure if lack of an inbuilt method to import prefs is a deal breaker though.
More than 3 developers on job market if you need to hire
This is standard kernel bypass code, I don't have a link to it per se. As an elementary observation, DMA operations contain live references to your address space that are invisible to the compiler. Mutability isn't the property of a reference, it is the property of a region of memory. In software like databases, most of your working address space has this property. Managing this is relatively simple, it just requires a different model. There are ways to work around these implications in Rust without an unreasonable amount of unsafe code but it defeats the purpose i.e. performance.
"Herbceptions" would be nice ([http://open-std.org/JTC1/SC22/WG21/docs/papers/2019/p0709r3.pdf](http://open-std.org/JTC1/SC22/WG21/docs/papers/2019/p0709r3.pdf)) for about everything I do with current day exceptions. Too bad they come bundled with this "bad\_alloc shall terminate you"-semantics...
Why isn't that its formal name? I love it.
Amplitude is a distance, left-right proportion is an angle. Your argument boils down to "x axis and y axis are 1d therefore x;y is also 1d".
I was much in the same boat, so recently I looked at some introductory material. I noticed that Rust moves by default, which made me a little skeeved out, but "maybe I can get used to it", I said. But no function overloading? Deal breaker indeed. I don't understand why none of these newfangled language people ever said "let's just do C++ but with all the insane/legacy crap removed". I'd be so happy with that.
&gt; But seriously, no function overloading? I was similarly disappointed about the "lack of function overloading". I remember even complaining about it (about 5 years ago) on a now defunct Mozilla mailing list with these words I quoted. Turns out, I was just used to programming in C++ and couldn't imagine a language worth looking at that doesn't offer that "feature". I don't miss it in Rust. In that respect, Rust is different enough of a language compared to C++ that it does not matter. There are generics. There are traits. One can sort of "overload" implementations of trait methods. I arrived at the conclusion that if you can't express it in Rust (via a generic function and/or a trait method) your functions probably *deserve* to have different names anyways. "Lack of overloading" is not something on a Rust programmer's feature wishlist. &gt; not sure I'd enjoy using it more that C++ YMMV. I can only speak for myself: Yes. It's overall more enjoyable.
Totally agree with the perceived boiler plate for extending functionality from other sources. A small detail is that inheritance sometimes can have too many effects—and unexpected ones—while dispatch to a member does not. The latter is quite comparably easy and hard to write in both languages, except templates and SFINAE driven approach make it finicky compared to traits (hopefully improved by introduction of Concepts). I'm sceptical towards usage of inheritance to extend functionality, the more I used it the smaller the fraction of cases where it felt like the most appropriate solution. &gt; A disadvantage of Rust, in my opinion, is that moves are what’s considered a shallow copy in C++, the rust compiler ensures that you don’t access the moved-from object after a move, however since no destructor is run (a drop in Rust semantics) this would mean a higher memory footprint. This sounds like a misunderstanding of the semantics. A `move` in Rust will not invoke any user code and is a simple byte-wise copy of the object's representation in *any* case. The bytes previously used for the instance are basically unused afterwards and consequently the compiler is allowed to, and will, overlap the memory used for new objects with storage that has already been moved from if it can. So in some cases the memory usage in methods can be *decreased* by dropping objects early, exactly because the object livetime is not bound to lexical scopes (Sidenote: The similar current tie of lifetimes to lexical structure is pointed out as a Rust flaw above).
I can't count how may times I heard "language X tries to learn from C++ mistakes" as design rule, just to find out on inspection that said language succeeded at introducing new mistakes by ignoring things C++ did right in the first place...
Wait, with that approach you just lost/diminished the main advantage of pImpl: being able to change the internal representation of your class without having to recompile all user code.
A short version that compiles: ``` template&lt;typename T&gt; int div(int a, int b, T t = "failure") { if constexpr(val &gt;= 5) { return a / b; } else { printf(t); } } ```
You still can do that as long as the size of the data members doesn't exceed the size of the buffer. I'm not saying it solves all problems, I genuinely wanted to know if the poster new about it (not everyone does).
On some platforms, you have standardized and backward compatible ABI with C++. This let the system provide pervasive shared object libraries, with (positive) impacts both on memory footprint and fixing bugs in particular security holes. Today the Rust dev story beside static linking is not great, in comparison. That's not necessarily a problem for all projects. IMO that's a problem for a language that wants to be a "system" programming language, because you are very constrained to build large scale systems with that language with a traditional build and distribution model like in classic GNU/Linux distro... For now I consider that Rust is in its own special position because of that, that I would call something like "low level mostly-applicative programming language". (Ironically that's mostly not a problem for extremely low level things, like a kernel -- it's more annoying for user-space libraries that could be classified as platform libraries) Also Rust is less well specified that C++ is, for now. Related, Rust has only one implementation. The borrow checker is excellent but it does not come without constraints. For example, the programming model is way more closed that what let C / C++ do; e.g. we did thread even when they officially did not exist, we did and still do shared memory / file mmap on objects while this officially still is not a thing, etc. That kind of approach is far more difficult in Rust (it is also not without questions in C++, because of UB story in C++ is completely insane, but that is another issue -- let's just say that sane compilers allow it somehow, and an hypothetical general purpose C++ compiler that would stop allowing it would be completely useless garbage) "Whatever makes Rust so good" is essentially the borrow checker (that extremely strongly aims to be sound). It is virtually impossible to retrofit it in C++ at this point. Maybe if the C++ committee does only that during 30 years it would become possible (providing also a coevolution of existing code bases), but I doubt that is their goal...
&gt;You still can do that as long as the size of the data members doesn't exceed the size of the buffer. Yeah, I was exaggerating. You can even grow bigger than the initial buffer by bringing back that heap allocated storage. But now you overcomplicated your design even more...
It's tradeoffs all the way down.
Rust operator "?" is quite good. The problem with exceptions propagating implicitly by default is that RAII won't even save you from some higher level logical carnage, except if ALL the logic of your program is in RAII constructs, at which point I certainly don't want to have anything to do with it (and to be honest I actually don't think this is even possible to write a program like that). For example releasing a mutex during the propagation of unplanned exceptions is particularly insane. The risk you will break an invariant because of work half-done is too high. So in some cases in C++, you need to statically check that some code paths won't raise exceptions, but you don't have built-in tools to do that.
&gt; My understanding is that since exceptions are often implemented with zero cost unless thrown, exceptions can be faster in cases where they aren't thrown. In [theory, yes](http://www.open-std.org/jtc1/sc22/wg21/docs/TR18015.pdf). But it does come with quite a bit of bloat especially since runtime type data is necessary to figure out which catch clause is the correct one. It's kind of a runtime overload resolution that needs to happen. And this bloat can impact performance when the hot code parts don't fit into the instruction cache anymore. AFAIU, the "Herbceptions" would solve this issue. &gt; In rust, the question mark operator can be used as syntactic sugar to check a result and then bubble is up as long as the calling function returns a Result. However, it is just syntactic sugar so while it is ergonomic, the compiled code still has to check the result. Yup. Well, it might be optimized out with some inlining. But I honestly don't know how big of an issue this is. I guess what's important is to avoid branch mispredictions. And I guess, it's fair to nudge the CPU to predict the happy path. BTW: The try operator (`?`) works for `Result`s as well as `Option`s. They just can't (yet) be mixed at. So, if you have an `Option` within a function returning an `Option`, the try operator works, too.
Shared libraries are a baaad idea. Also, ubiquity of build tools is be necessary to make the ecosystem viable. Or at least, ubiquity of build file format and universal understand of what "libfoo 4.2 is precisely". npm was reimplemented (yarn) but it's only a reimplementation, it still speak the same language in the same universe
&gt; The safety Rust offers can be had in C++ using compiler flags, tools and sanitizers (Clang even has an experimental lifetimes flag). There is a huge difference in that: Rust safety is (mostly) static and sound (barring bugs), the tools and sanitizers are mostly dynamic, and the lifetime checkers for C++ can not be sound (Rust has more constraint in order for it to be even possible). &gt; A disadvantage of Rust, in my opinion, is that moves are what’s considered a shallow copy in C++, the rust compiler ensures that you don’t access the moved-from object after a move, however since no destructor is run (a drop in Rust semantics) this would mean a higher memory footprint. I don't understand what you say at all. After a move the indirectly owned resources are owned by the new object, and the storage for the old one is just unusable garbage. There is nothing to destruct, and in C++ destructors after a move typically do nothing (except more runtime code to actually figure out that the state command doing nothing...). There is also no rule in C++ that states that the storage for an object is necessarily free ASAP after its destructor is called (when that's even possible), nor would that provide any advantage for memory footprint anyway.
&gt; So nothing standard, I would expect most error types to conform to the [`Error` trait](https://doc.rust-lang.org/std/error/trait.Error.html) which is kind of the "conceptified version of C++'s `std::exception` class interface". An error usually offers a textual description like `std::exception::what`.
would be nice but the type doesn't definite this at all. your code might, but that's not generally applicable
Shared libraries are a bad idea for some people. They have their place.
Nothing. The only time I used a custom allocator was to have stronger alignment guarantees for SIMD. I got to keep using std::vector with a custom allocator for my data and could feed it to FFTW which would do its SIMD-enabled magic.
Author here. This is indeed not good. My model for qualifying a conversion is that "whether there is a chance for unintended information loss," so in theory, ConvertibleToBool -&gt; bool and ConvertibleToBool -&gt; int could be considered ambiguous because you lose information in neither case, assuming -&gt; bool is intended. But when switching from R1 to R3, the paper disabled a user-defined conversion which causes the issue. I'm thinking about this fix: If U is convertible to bool, disable conversion to all T that is a builtin type which can be converted from bool. (Your suggested fixes drastically change the motivation of the converting constructor, so I think it's hard to apply.)
Would it be possible to extend Rust by somehow declaring external references to the compiler?
Well that may change as thru love through standardization.
If you just want to focus at the bad side of trying new solutions, that's your call.
&gt; C++ has lost its place for app development on mainstream desktop That's actually what you claimed, backed up by what seems to be misguided frustration. &gt; Provide the list of OS and application written in pure C++ Sure buddy I'll get right on that. I'll use my time trying to explain something basic to a mentally ill guy on the internet that doesn't understand that libraries are written by other people. Take a look at ninite.com
Because the author of the paper doesn't like that name.
It's not ridiculous, it's well deserved when they get employed as the hammer for all error handling instead of exceptional errors (exceptions). Errors and exceptions are different concepts, the issue is that some languages make it easy to confuse the too. Errors will not necessarily happen exceptionally, they may happen often, or even more than successful results, and when exceptions are wrongly adopted as solution for error treatment, you fall at the trap of also using them in these situations. Even some object construction may be subject to **fail** often because of bad construction parameters (from input) that's verified at construction.
Fine :(
&gt; The safety Rust offers can be had in C++ using compiler flags, tools and sanitizers (Clang even has an experimental lifetimes flag). I don't think that's a fair characterization. The lifetime checker for C++ is not meant to catch all errors. It's only meant to catch most common of the local errors. So, need to rely on runtime checks (sanitizers, checked iterators, etc) for the purpose of testing and debugging segfaults. That's different from compile-time guarantees. &gt; A disadvantage of Rust, in my opinion, is that moves are what’s considered a shallow copy in C++, the rust compiler ensures that you don’t access the moved-from object after a move, however since no destructor is run (a drop in Rust semantics) this would mean a higher memory footprint. I don't see how the destructive kind of move in Rust implies a higher memory footprint. Can you give an example? I have to disagree with you about Rust's move semantics being a disadvantage. It's a trade-off. It's less flexible in that as an author of a user-defined type you don't get to control its behaviour on a move. But what Rust gives you are *greatly* simplified move semantics. In Rust, *everything* moves *efficiently*, *always*. That's just awesome! The fact that a move might throw an exception in C++ makes things very complicated. Just look at the history of `std::variant`'s design and the discussions around it. Thanks to potentially throwing moves in C++ we have [this thing](https://en.cppreference.com/w/cpp/utility/variant/valueless_by_exception). &gt; C++ also makes it easier to hide abstractions without leaking complexity, a library user can simply extend (inherit) a class and not worry about lifetime annotations, That reminds me: I like the fact that in Rust function signatures are self-explanatory w.r.t. any borrowing relations. In C and C++ I might not even find this information in the comments that are supposed to document a function's interface.
You can't blame a language feature for bad programming. Besides it all depends on what your needs are as in something may fail often, but the code that really cares is nowhere near... does everyone in the call chain really need to accommodate the error? Also constructor failing without an exception sounds like a headache waiting to happen.
just waiting for static_throw to enter the language :)
It's for portability. The platform drivers get to control types. So we can't use the actual C++ types. In actual fact they won't set TVoid to anything else but void, but it would horrendously inconsistent to do some and not others. And, it's still more readable.
&gt; Who is saying Rust is faster than C++? That isn't the case. Yeah. I expect them to be the same. There are a lot of factors affecting performance that are not really intrinsic to the language but about language implementations. But there is one Rust feature I can think of that (at least in theory) might give Rust a slight edge. And maybe that has been construed to this outrageous claim from above: It's about the "strict aliasing" guarantees of Rust's references which could lead a little more room for optimization. Though, I don't know of any comparisons between C++ and Rust in this respect.
I sure blame the language when it's clearly designed to cause this confusion and only lately is attempting to undo the damage.
&gt; No anal borrow checker. Given that the borrow checker is explicitly a *feature* of Rust, and very intentionally designed, itʼs a bit … “nonsensical” (to say the least) to list it as a disadvantage. It is definitely an advantage, since it prevents certain classes of unsafe code, some of which are the cause of the most serious bugs and security holes in C++. Yes, the Rust borrow checker is certainly overzealous and also forbids provably correct code but that's simply an unavoidable mathematical property of static type checkers. Given that it rigorously prevents dangerous and common bugs, and that it can be circumvented in unsafe mode if really necessary, the balance easily tips in its favour, and listing it as a disadvantage is objectively wrong.
&gt;The safety Rust offers can be had in C++ using compiler flags, tools and sanitizers (Clang even has an experimental lifetimes flag). Come on, that’s complete nonsense. We rigorously use static analysis, strict warnings and address sanitisers in our C++ code at work and yet it still occasionally has hard to debug memory errors that are provably impossible in Rust safe mode. C++ safety has gotten a lot better but it’s at a fundamentally different level than Rust’s. It’s not even the same ballpark.
Unfortunately, a lot of software still isn't built, and doesn't build, in LTO mode.
&gt;soon to be part of abseil Oh nice, that's good to hear! Was there a post announcing this anywhere?
The general consensus is that Rust succeeded in this goal more than any other language so far.
My implementation of from_chars is ~40% faster than strtod/strtof. (I assume you use strtof for floats, instead of strtod followed by narrowing to float, which is incorrect.)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c5gb4t/how_do_i_get_started_in_cv_tesla_nvidia_and_more/es1qxq4/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
check out opencv https://opencv.org/ ? start a project on your own and build from there also for future reference i think posts like this are more for our /r/cpp_questions (but idk for sure because im not a mod here)
How do you determine the lifetime of that reference? It lives beyond the operation that creates it. This also has the fun side effect of making some destructors non-deterministic. Freeing the last in-the-code reference doesn't imply that the hardware isn't still holding an active reference. You need a mechanism to delegate destruction for whenever the hardware is no longer referencing it since the hardware doesn't understand object lifetimes or your code. Fortunately, you can wrap much of this in nice C++ libraries that make it mostly automagic with a good user space execution scheduler. You end up with shared\_ptr/unique\_ptr analogues that do all the fix-ups and context switching under the hood. The biggest idiomatic change is that you must not recycle object memory (think placement new) when managed this way.
They tried that with D. The garbage collector was the big deal breaker but they've been working on providing the option to remove it with a sane standard library still.
afaik this is a perfectly acceptable situation to use unsafe rust.
&gt; Shared libraries are a baaad idea. Says the person following his arguments with nodejs and npm. Imagine how horrible it would be if you had to rebuild nodejs everytime you want to use some native code. You want to use any library, you'd have to rebuild and link statically everything. Also, shared libraries are good when you want to add/remove features at runtime. Without shared libraries, you'd have to compile all of your plugins inside the binary regardless of you using them or not. Then somehow activate disable the features at runtime when required. But the moment you want to add a new feature later, you'd have to recompile the whole binary yet again.
As a start, you could download the OpenCV library and play around with some of its image recognition functions by feeding it images or a camera stream. Try making a fun project that uses those functions, for example an AR application or something. Then you could go on to read about how the different CV algorithms work and maybe try implementing them. Also, Tesla is probably very focused on the machine learning part of CV at this point (that's my guess at least). I wouldn't try to study something simply to get a job at a particular company though, especially as the needs of companies can change over time. It might be better for you to decide which areas and technologies you are interested in and try to get good at those. But if you're interested in this kind of stuff, maybe study the machine learning field a bit, in particular neural networks. The basic technology is pretty old, but the innovations are done in how that technology is applied as far as I know. Machine learning is pretty big right now as every company seems to want something to do with AI.
https://github.com/zuhd-org/easyloggingpp is what I use, but spdlog looks good
I understand perfectly why `swap(&amp;mut a[i], &amp;mut a[j])` is not allowed, and am aware of `a.swap(i, j)` but it's simply ridiculous that you can't mutably borrow multiple element of the same slice, it comes up quite often and is extremely annoying.
Itʼs inconvenient alright but it isnʼt “ridiculous” at all, since there's a very good technical reason for this restriction, and it's trivial to work around by using an unsafe block (wrapped into a function that preserves the necessary variants to be itself safe). I think itʼs great that people try to avoid unsafe code in Rust as much at possible but when we pretend that unsafe mode doesnʼt exist at all, this is clearly going too far. Unsafe mode is a useful and necessary tool in the Rust toolbox.
bool func(In in, Out&amp; out) or pair&lt;bool, Out&gt; func(In in)... there are easy solutions to not using exceptions, but there are no real workarounds for propagating errors. Let's not assume everyone is stupid just to help our argument.
It's really not though. It's not like you abandon function overloading in return for nothing, it's that Rust considers Traits and powerful type inference to be a better trade-off than ad-hoc function overloading. Function overloading in C++ is simply too broad, has too many edge cases, and results in massive wall of text errors when used incorrectly. In Rust you get some ability to do a limited form of function overloading via Traits, which basically lets you do function overloading on the first argument, and you get powerful type inference that makes code a lot more to the point, especially when working with generics.
&gt; ~40% faster Sounds great! So few implementations have `from_chars` for floats, that I haven't had a chance to integrate it yet, but it sounds like I could now do that with VS. It's a shame that Appveyor still doesn't have VS 2019, so it's kind of hard to test it. &gt; I assume you use `strtof` for floats Yes, and `strtold` for `long double`.
Because function overloading is one of the those insane/legacy crap that Rust removed. Function overloading is an ad-hoc, bug ridden, and insanely complicated aspect of C++. All the tricks and hoops people have to go through, like rules about ADL, the "using namespace std;" trick to avoid qualifying function names, and compiler workarounds because to this day compiler vendors still don't agree about how to perform name lookup is all because of how overly broad and complex C++ function overloading is. Rust has an unbelievably simple solution to what is commonly referred to as ad-hoc polymorphism. It supports a limited for of ad-hoc polymorphism that a type must explicitly opt into to. There is no ambiguity or confusion or complex processes you have to run in order to deduce exactly which function is called.
You can mutably borrow elements of the same slice, although it's usually quite awkward. Use `split_at_mut` // Assuming i &lt; j let (l, r) = a.split_at_mut(i + 1); swap(&amp;mut l[i], &amp;mut r[j - i - 1]);
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/c5h6va/how_to_access_control_variable_from_main_dialog/es1v71v/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Isn't that a bit too dogmatic though? Just because *some* memory might be volatile and might be accessed by DMA (disk controller, GPU, co-processor, accelerator card, network card, RDMA) or whatever doesn't mean it doesn't make sense for the compiler to check the other (dare I say 99% - but of course depends heavily on your use case) statically.
For completeness I really think you should post that question also on r/rust. The guys there are really nice and humble about th language shortcomings.
&gt; Having the STL containers able to take a memory pool allocator (yes I know this wasn't the original intention) has given me 50%+ speed up in some cases. (e.g. lots of operations on a std::set). Is there any good article on how to do this? I've never used a custom allocator either, and it seems like maybe I could benefit from one (std containers show up a lot in my profiling output).
&gt; Because function overloading is one of the those insane/legacy crap that Rust removed. Nah, it's perfectly sane. It's complicated in C++ because of all the rest of the rules for type inference/promotions, name lookup, the works. "Apply this function to an argument of this type"? Simplicity itself.
Is OpenAL reliable for commercial software?
I'm not sure those really give Rust an edge though. Idiomatic high-performance/high-scale software architecture is effectively single-threaded these days, which renders most of those advantages moot when chasing performance. Shared immutability produces much slower code than non-shared mutability in practice due to the large amount of implied data motion in the former. If data concurrency doesn't matter then modern C++ is pretty safe, and you can focus on constexpr/template-driven code optimization and cramming data structures into the smallest number of cache lines, where C++ excels. &amp;#x200B; Of course, these software architectures create a new problem -- how do you uniformly distribute load across your cores -- but that has straightforward solutions with few safety implications.
I certainly hope so, yet we had 1 year and 3 revisions of Herbceptions (with some form of this semantics present in every version) and from what I (as someone not part of the standardization process) gather agreement from (parts of) the committee... I'll be in Cologne next month as a "spectator" and hope to have some meaningful discussions on this topic...
Cologne will be full of discussion of last minute C++20 stuff, so anything targeting post-20 might not get discussed.
Exceptions aren't only for exceptional cases. They are for error handling.
Officially? Most probably not. It's my first time "participating" in a meeting, so maybe I'm a bit optimistic imagining a scenario like on a conference (e.g. CppCon) where there are informal/ad-hoc discussions "between sessions"/"at lunch"/etc.
This doesn't make any sense. Extending Rust's model with `unsafe` isn't a workaround and it doesn't cost you any performance. It's an intentional language feature that lets libraries provide compile-time-checked APIs around things that would otherwise go unchecked. If anything, Rust has better tools for writing high performance code in this sense- better control over aliasing and its associated compiler optimizations, more confidence in "pushing the limits" of an API instead of "playing it safe" by making conservative copies or locks.
The statement is literally "if you are looking for maximum performance...", and you reply with "performace is not the deciding factor...". Wat? Everyone's use cases are different, some people really are looking for maximum performance. That's a good chunk of the C++ community frankly because if you can afford to sacrifice much performance you often don't use C++ to start.
For the absolute beginner Rust has a bit more of a learning curve than C++. Ultimately, the C++ dev will want to know the same things, but Rust can be a bit anal about it, and for good reason.
definitely lots of talking at lunch and after hours. Somewhat like a conference, but more intense at times. Particularly when we are close to shipping. So even most of the "free time" discussion will be about urgent matters.
Support to install and use multi-platform dependent package (android, iphoneos and etc). see [https://github.com/xmake-io/xmake-repo/blob/master/packages/z/zlib/xmake.lua#L12-L29](https://github.com/xmake-io/xmake-repo/blob/master/packages/z/zlib/xmake.lua#L12-L29) &amp;#x200B; BTW, how to modify the title of the reddit post?
Rust has a pretty high initial hurdle to get over before you feel productive. C++ doesnt have the hurdle but it does let you write shitty code until you wise up.
For something like a database kernel, most of your internal data structures need to directly interact with e.g. the storage hardware. The alternative is lots of memory copies and less robustness. You don't have the luxury of mmap() transparently managing your virtual memory for you. And most of the remaining data structures are effectively globals. On the other hand, there is no reason that peripheral logic like a query parser could not be implemented in ordinary safe code. However, it would be deeply entangled with objects from the unsafe domain since that is where all the operational data lives. I don't know Rust well enough to have a good idea of the implications of that entanglement for the "safe" code. For that matter, how well does Rust play with JIT compilation? I have no idea. Most queries are dynamically turned into machine code... (I primarily design database engines but most ultra-efficient high-throughput server software is built the same way these days. I've been trying to figure out how Rust fits the way these systems are typically designed.)
Fine, but equating exception handling to error handing is a fatal mistake, as already exposed.
&gt; Whatever makes Rust so good, the C++ language could also implement. Why reinventing the wheel if you could optimize the existing one. This isn't really true, actually - some of the most interesting Rust features are new restrictions added to the language that can't be added to C++ without breaking a bunch of existing code. To pick one example, constant data in Rust is very different from const in C++. If I have a reference to const data in C++, it guarantees that I can't modify that data, while a reference to non-mutable data in Rust guarantees that *nobody* can modify that data. That gives you a lot of useful safety guarantees that can't be retrofitted onto C++. Beyond that, they're both low-level languages, but they have very different goals. Rust has a goal of guaranteeing certain safety properties at all costs, while C++ has a goal of getting out of the programmer's way at all costs, and letting you implement whatever you can come up with.
I never stated that unsafe cost performance. The point I was making is that for some types of software the only way to preserve performance seems to be for a large percentage of the code to be unsafe, which would appear to defeat a major selling point of Rust. I am trying to figure out how I would apply Rust to a systems software domain I understand extremely well. At least in high-performance data infrastructure software, there is almost no copying or locking in any case. Why would anyone add it to "push the limits" given that it has no functional purpose?
I think it’s just from looking at branches on their git repo
I love using exceptions, I only need to wrap the final API calls and return an error instead of allowing any exceptions to leak. The issue is that some go overboard with them since they're really useful for sending information back up the call chain... but they're a slow process with all of the unwinding.
To be honest when I first started programming, I'd say function overloading was a cool thing but now, I'd say that function overloading is a the poor man's version of default attributes/named attributes and automatic casting. It's not a big deal but make Rust code more verbose compared to other languages. For example, if you want to build a `vec(float, float, float)` in rust, if you want to create it from a f32, f64, i32, u32... those could be all different `new_i32, new_f32...` which become difficult to remember. But in reality we could potentially write something like this: `Vec::new(a.into(), b.into(), c.into())` and hope that Rust can properly cast to the internal type. Because in reality you don't need multiple new methods with different parameter types. You only need to know how to cast them properly.
"`std::bad_alloc` from `new int` with the default allocator will terminate you". If I had your experience, what would I see wrong with it?
Yes, exceptions should be avoided where it is too costly vs other alternatives. That is only vaguely aligned (if at all) with "when exceptional". (And too costly can be said about almost anything in C++ - avoid X when too costly (runtime/space/compiletime/maintenance/...) vs other alternatives.)
I'd say the rust way of doing it is by having a struct that encapsulate an other struct. If you want to call the parent implementation you use that parent field can call its method. That's technically the same thing as inheritance in C++ as a parent class cannot access member of the inheriting class. While the trait do sound a lot like Java Interface, I'd say that Rust sound like they're doing it the right way. But in Java, interface are more like a poor man's multiple inheritance. But in Rust, Trait allow you to append new behaviour to existing dataset. In other language, the moment your struct/class is created, you cannot really bind new behaviour later. In Rust, you can give similar behaviour to anything that may be completely unrelated. So it allows interesting things like you're making a library that does something and you define a Trait that "do_something()". Then you want to add support for types coming from a different library. You simply have to implement the Trait you created and you're good. In Java, to support a different type, you'd have to either overload a constructor/method to support the new type or subclass it with your class or interface. But You'd also have to create an object from the newly created class while in Rust, the original constructor will just work because the data doesn't change.
But if you need to be hired it's not an advantage.
I'd say one of the good thing about Rust is that there is an official stable and unstable version. And from my understanding. Rust 1.0 was a milestone that aimed to make a usable language. Now, update made to Rust are aiming to make Rust more usable so the language seems to be constantly evolving as much that operators such as `~` seems to have been removed from the language as other "special" case things that were created to make it just work. The downside is that things compiled in Rust 1.0 may not compile in Rust 1.20 so backward compatibility might be a bit poor vs making the language better over time.
c++ syntaxed sort of like golang without the lame forced formatting, absolutely stupid special thread syntax, and even lamer strictness about unused variables.
C++'s template system is way more powerful than Rusts generics. (At least the last time I checked)
I think I just got used to Rust's `match` keyword :P
\&gt; better build times if only because you don't do the same work hundreds of time This was how modules were sold to the community. Build times are a huge drawback to developing C++. However, in the code bases I've contributed to, the time spent parsing headers is insignificant relative to the time spent instantiating templates. Modules don't save us. \&gt; macro isolation - meaning compiled modules expose a consistent truth In retrospect, I feel like this religious war was a much larger motivation for the modules TS, but I've never really felt like this much of a problem. I can count the number of times I've been bitten by a spurious macro definitions on one hand in more than a decade of C++ development, larger because as a community we've been trained to use &amp;#x200B; \+ macros sparingly and to not allow macros to escape our header files \+ the \`SCREAM\_CASE\` convention to distinguish preprocessor functions and definitions is nearly ubiquitous. Exceptions in production do exist of course, but to whit, those are coming from headers we share with C programs. \`windows.h\` is an example with it's min/max macros. I recall bumping into similar issues with libstdc++ \`&lt;cXXXX&gt;\` headers at one point. &amp;#x200B; That said, this 'macros are evil' mentality ignores numerous legitimate use cases where macros are our only recourse to work around limitations of expressiveness, introspection, and reflection in C++ (e.g. \`BOOST\_FUSION\_ADAPT\_STRUCT\`) &amp;#x200B; Then there are the questions the modules proposal has introduced for the build system folks and the absolutely bonkers interactions between modules and symbols with internal linkage that make the whole idea seem half-baked. &amp;#x200B; Modules were a hell of a lot of effort and trouble for what appears to be very little value in practice,
I'm aware of the concerns listed in the paper, but I don't agree that one would expect designated initializers to work like list initialization w.r.t. evaluation order. I do agree that it would be a bad idea to prevent copy elision with temporaries, so I think the only logical solution is to define that they be rearranged in the same way that member initializers are. The primary reason why specific initialization order is desirable is stateful initialization expressions, right? This is the most clear non-bogus example I can think of that would cause problems is something like this: struct SomeStruct { int x; int y; }; SomeStruct load(Archive&amp; ar) { return SomeStruct { .y = ar.read&lt;int&gt;(), .x = ar.read&lt;int&gt;(), }; } void dump(SomeStruct&amp; s, Archive ar) { ar.write(s.y); ar.write(s.x); } In this case, consolidating into one serialization function like Boost.Serialization or cereal does it will prevent the issue. The other example I see cited for why the warning about member initializers in constructors should be turnwd into a warning is for small buffer optimization. I don't think that's necessary since the most programmers are not writing SBO types every day, but at least in this case the compiler nagging is just limited to constructor definitions. What other substantially different situations does requiring ordered members catch? Because it seems like they'd be relatively few, whereas now if you have a type that uses designated initializers, if you ever want to reorder members to optimize struct layout, suddenly you have to update every single location where that struct is constructed with designated initializer syntax. The balance is completely off. I haven't had major bugs caught by the member initializer order warning, but I can see how it's valuable in situations (like writing constructors for SBO types), and its impact is localized. Meanwhile, you have people posting using designated initializers as pseudo-named arguments or more generally for configuration objects. My experience with named function arguments in C# has convinced me that requiring the syntax use declaration order is a source of real frustration. I argue that the standard currently has these two diagnostics backwards. The only positive thing I can say about this restriction is that at least it is possible to loosen it in the future.
OpenAL licensing is fraught.
error_code unfortunately has operator bool. Hence migrating to it can be difficult unless for example you stick to using it as an out parameter instead of a returned value.
Rust has some syntactic sugar for dealing with this, the ? operator. It's like a try/catch that returns from the function if error or continues execution with the valid value if not. It's still a pita that you have to explicitly write the result&lt;t,e&gt; in the function signature though, granted.
Definitely the second. It seems to me like obvious smell to give bool special treatment. There are other built in implicit conversions with higher priority than user defined ones so solving the problem for bool will not eliminate all weird scenarios.
A lot of times I’ll write a very simple macro that does the conversions.
G3log, one that is crash proof, meaning that it can log the exact line that crashes, most other loggers can't do this.
Backwards compatibility in Rust has been pretty strong, even to the point where you could compile certain code that will segfault, but the Rust compiler will only warn instead of error (with a message strongly suggesting the code be fixed and pointing out that it's only a warning for backwards compatibility reasons). Backwards incompatible changes are generally handled via an "edition" variable in Cargo.toml, but are not compiler version dependent.
Relevant video, where they put blue tack on a kid's ears and it disrupts his ability to accurately position sounds in 3D space: [https://youtu.be/Oai7HUqncAA?t=296](https://youtu.be/Oai7HUqncAA?t=296) That being said, I'm not sure how game audio systems can replicate these effects when replayed through headphones that don't move relative to your head.
C++ would certainly work, but if you're getting rid of graphics, maybe an audio targeted language like chuck makes sense? For C++, I've been plenty happy with SDL.
That sounds like an overreaction. Rusts type system is more than capable of handling 90% of the convenience of function overloading. For whatever it’s faults, Rust is characterized by very carefully considered design decisions. AFAIK, the reason why it doesn’t have function overloading has to do with it not playing nice with generics, and adding it in would come with significant compiler additions (I’ll have to see if I can find a design thread or something later). Also worth pointing out that rust does have operator overloading just so there’s no confusion. As to your latter point, I think that’s what zig tries to do with C. So there’s some interest in “2.0-ing” languages. But is the best we can do is just pry the barnacles off of old languages?
&gt; For whatever it’s faults, Rust is characterized by very carefully considered design decisions. I'm not saying it's a bad language. It's just not for me.
I stand by my claim, which you are yet to prove as wrong. So lets deconstruct my claim, as you are lacking English understanding skills. &gt; Anyway the ship has sailed, C++ has lost its place for app development on mainstream desktop and mobile OSes, the last standing OS where the SDK still has full support for writing UIs in C++ is Windows, and even there most developers end up using .NET or React Native instead. The key part of the sentence is **Mainstream desktop and mobile OSes**. So what does this mean? Well, it refers to what is widespread across the general consumers as computing devices, which would mean macOS, iOS, watchOS, iPadOS, ChromeOS, Android, Windows. GNU/Linux desktop usage is only 1% according to Steam hardware survey, so hardly mainstream. Then what is the second relevant part of the sentence? Right, **where the SDK still has full support for writing UIs in C++**. Now given the list of mainstream OSes and their SDKs, lets put both together. From Apple side we have `macOS, iOS, watchOS, iPadOS`, which use Cocoa, UIKit and now SwiftUI for doing UIs with their SDKs. The only places where C++ is used in regards to programming UIs is for writing Metal shaders in C++14 variant. None of Apple's platforms are written in pure C++, so they fail `Then why are all the programs I use written in C++?`. From Google side we have `ChromeOS, Android`, where ChromeOS uses JavaScript/HTML 5/CSS, and Android uses Java and now Jetpack Composer (written in Kotlin). At the UI level both only use C++ to the extent of the graphics composition engine, not exposing its APIs to app developers. None of Google's platforms are written in pure C++, so they fail `Then why are all the programs I use written in C++?`. From Microsoft side, we have Windows. The only desktop OS vendor with support for doing GUIs in C++, via MFC, ATL and UWP. Which might almost make true `Then why are all the programs I use written in C++?`, sadly also Windows is not written in pure C++, so also fail. Then I wonder which OS do you use where `Then why are all the programs I use written in C++?` is true, after all if the OS isn't written in pure C++, that assertion is already false, no need to go into userspace libraries. And I doubt you are using Symbian, GenodeOS, BeOS, Haiku, ARM mbed, Arduino Sketchs. The few OSes that are fully written in C++. &gt; Sure buddy I'll get right on that. I'll use my time trying to explain something basic to a mentally ill guy on the internet that doesn't understand that libraries are written by other people. Take a look at ninite.com I wasn't the one making the assertion `Then why are all the programs I use written in C++?`, without being able to stand by it.
This maybe possible in Rust, but recently I've been reading more about NUMA, and wondering how Rust is going to deal with such configuration. Not that it's completely painless with C++'s STL, but with custom allocators (or pmr) one can probably do something better. (I know very little of Rust yet, so I could be wrong about this)
I think the first point, about (custom) allocator, should be stressed more. Even if you don't care about cache locality, once NUMA architectures spread more and more, it'll become clear that one has to get in control of which threads (CPUs) should work with which memory.
Rust allows custom allocators on a per crate basis. They switched from jemalloc to whatever is the system default with the ability to change. Not sure what you mean by compiler enforced const , but rust does have const and constexpr . But the exceptions and standards is definitely a thing that is different
exceptions=Yup, hate ISO old people process=Yup, hate most const weirdness=Yup, hate
&gt; shared libraries I have watched the world burn because of this "convenient" feature way too many times.
That’s totally fine. I’m dying to know what your use case is though that an absence of function overloading would be an automatic dealbreaker. Especially cuz you can often get almost exactly the same thing using builder syntax.
Check std::pmr, memory\_resource, and std::pmr::vector/map/std/etc. There are talks from John Lakos, Pablo Halpern, and other folks from Bloomberg about them. Then there is talk from David Sankel (also from Bloomberg), which goes a bit against them. &amp;#x200B; In my case (MSVC+Windows), I've simply used them to replace whatever CRT uses to allocate (new -&gt; \_malloc\_base -&gt; HeapAllocate -&gt; RtlAllocateHeap) which simply does not scale well, when under heavy thread usage (20+ threads banging new/delete). &amp;#x200B; It's not easy to migrate code, and it introduces a new vocabulary type (that's like the 2nd time I'm using "vocabulary type" in writing) where std::vector is different from std::pmr::vector. In my case I've changed const std::vector&lt;T&gt;&amp; references to gsl::span&lt;const T&gt; - but maps and sets are different story. Strings (std::string) are probably best served as string\_view instead of const std::string&amp; - but then need to take care of the not guaranteed "\\0" - e.g. things are not easy, and you may not be able to translate all code - I'm roughly 30-40% - but translated mostly hot threaded paths, and god speedup of x2 - e.g. instead of only 50% utilization, I'm now up to 100%. &amp;#x200B; Not sure why the Windows LFH (Low Fragmentation Heap) does not scale (e.g HeapAlloc/Free), as it was written with this in mind, then again it has lots of security features (against intrusion). &amp;#x200B; What I did was simply to install a default memory\_resource and use jemalloc. Oh, you also pay 8 bytes (64-bit) for every structure allocated. It carries pointer to the memory\_resource used.
Shared libraries are like democracy. If you are Google, or Facebook, and your BUILD infrastructure is so good that caches everything correctly, then static linking maybe your thing. &amp;#x200B; If you are game developer, and your tools needs to be rebuild daily, and you happen to use Qt, then static linking is not only a bad idea, it's terrible idea. It just does not work in practice, for this or another reason.
&gt;The statement is literally "if you are looking for maximum performance...", and you reply with "performace is not the deciding factor...". Wat? I'm sorry. Poor wording on my side. There are apparently two ways of interpreting what I said. I didn't mean to imply performance isn't important (maximum or otherwise). I should have been more clear: C++ doesn't IMHO offer "more maximum performance" than Rust which makes the performance goal irrellevant in the choice of the language.
The BORROWCHECKER is the singlest most important difference. It changes quite a lot the game here. The rest, e.g. the build system, not so. Language should not be married to a build system to begin with. As it stands, you end up linking multiple of different languages together. You need something else here.
&gt;can't be added to C++ without breaking a bunch of existing code. Breaking existing C++ code wouldn't be more of a problem than abandoning that code for a new language though? The C++ lifetime profile checker will/does impose restrictions somewhat akin to Rust and it does "break" a lot of existing code. &gt;that can't be retrofitted onto C++. Well, you can implement essentially a `RefCell&lt;&gt;` in C++, [right](https://github.com/duneroadrunner/SaferCPlusPlus#exclusive-writer-objects)? So if you consider native pointers and references as part of the "unsafe" subset of C++, akin to Rust, you could attain the same sort of access restrictions for any object for which you need them. But you don't always need them, right? Even in Rust, you could wrap every individual element in a `Cell&lt;&gt;` if you really wanted to. &gt;while C++ has a goal of getting out of the programmer's way at all costs, and letting you implement whatever you can come up with. Yeah, it's imperative that that option be available to the programmer, but I think C++ has been fairly good in doing it in a way that does not necessarily preclude other goals. There seems to be some skepticism as to whether C++ has (or can have) a practical safe subset analogous to Rust's. It's not clear to me that it doesn't. Such a subset has yet to be explicitly identified, as far as I know, and obviously tooling to enforce adherence to it is currently inadequate. But in the future, who knows? The way I see it, the main functional difference between Rust and C++ language design at this point is the lack of move constructors in Rust. In my opinion this leaves Safe Rust a little bit "incomplete" (wrt "self-referencing" objects, for example) and results in Rust programmers occasionally straying from Rust's safe subset in a way they might not need to with C++. (I mean, in a hypothetical future where a safe subset of C++ is identified and enforced.) But yeah, in the mean time Rust's prioritization of safety (and C++'s lack thereof) makes a big difference.
&gt; Rust allows custom allocators on a per crate basis. They switched from jemalloc to whatever is the system default with the ability to change. Yes, but it is inconvenient if you only need a different allocator for one data structure. &gt; Not sure what you mean by compiler enforced const , but rust does have const and constexpr . This works and is perfectly valid Rust. There's nothing in the language that forbids it: fn main() { let x = 0; let mut x = x; x = 2; } In C++ this is not allowed by the standard (but it can compile): int main() { const int x = 0; const_cast&lt;int&amp;&gt;(x) = 2; }
I'm not familiar with allocation on NUMA architectures. Are there special syscalls or some other mechanisms that allow one to request virtual memory be placed at channels?
Your Rust example is showing shadowing. What does that have to do with const?
C++ is pretty low-level. Usually you package up audio and ship it to some buffer, which the OS sends off to hardware. You can make it from scratch, minus the part that sets up and ships it to the OS. If you learn how to do it in C++, learning it in other languages becomes a lot easier
In general, you can't be sure that some section of code will not raise an exception. Particularly if you call into any code you didn't write yourself, or that someone else may edit in the future. So it doesn't seem to me it is quite so simple as not using them.
&gt; The lifetime checker for C++ is not meant to catch all errors. It's only meant to catch most common of the local errors. So, we need to rely on runtime checks (sanitizers, checked iterators, etc) for the purpose of testing and debugging segfaults rusts borrow checker also doesnt catch all errors and in some cases it forces you to do runtime checks (all the cell stuff) even in release builds. absolute no-go
The fact that shadowing is happening is besides the point. `x`, which is an immutable binding to an object, is moved into a mutable binding. That mutable binding then modifies the original object.
I agree it is may be a drastic change, but motivation of converting constructor is still the same. Only change is error-out on ambiguous calls, non ambiguous calls works as before, e.g.: std::variant&lt;std::string, int&gt; c = "abcd"; // ok std::variant&lt;std::string, bool&gt; d = "abcd"; // error: we could either SFINAE-out the constructor, or report error about ambiguous construction std::variant&lt;int, long&gt; e = 1; // ok std::variant&lt;float, long&gt; e = 1; // error &amp;#x200B; As /u/quicknir stated special casing bool, fixes only a few cases, leaving all the other implicit conversions cases problematic and possible buggy. #include &lt;variant&gt; template &lt;typename T&gt; struct ConvertibleTo { constexpr operator T() const { return T{}; } }; static_assert(std::variant&lt;int, unsigned short&gt;(ConvertibleTo&lt;short&gt;{}).index() == 0); // is this really what user expected? static_assert(std::variant&lt;signed char, unsigned char&gt;(ConvertibleTo&lt;char&gt;{}).index() == 0); // result depends on platform - non portable
No borrow checker is the biggest one for me: The borrow checker just forces you to add unnecessary amounts of complexity to your code, using lots of abstraction-bloat just to hide what youre actually doing, until youve added enough complexity to confuse the borrow checker A simple example (that ive actually seen many advocates of Rust use to praise their borrow checker): You want to hold iterators into a data structure, but you cant because they may get invalidated. Rusts "solution": hold indices. they may still get invalidated (when you eg. delete the element/remove another element/insert somewhere etc). The only thing you "solved" is making the borrow checker no longer understand that you're still sharing/borrowing
I've used Rust for a couple years now, and have been slowly but very surely coming back to C++. \-C++ has a vastly more expressive template system, complete with variadics, specialization, overloads, constexpr, etc. that make actually using your code feel as easy as writing in a dynamic language. I honestly wish this was a larger bullet point because it just makes so much difference to the way you think about and write code. The compiler is able to do so much by itself at no runtime cost, and it's truly incredible (and fast as well, the more you offload to compile-time. Slow compilation is worth it for this). \-more generally, rust's constant explicitness, while dubiously more 'safe', is many thorns in one's side. I'm maybe getting subjective here, but writing in C++ feels more natural, more elegant, when I don't have to write things that the compiler should by all means know already. Imagine if `float a = 3;` was a compiler error in C++. \-oft criticized, however, I find exceptions to be much more ergonomic and developer-friendly than integrating errors into the type system via Result and Option. Providing means for something to fail and being able to handle it at whatever rung of the call chain I want (wherever it logically makes sense to do so), without breaking existing code via changing return types, is a lot cleaner and more efficient. I always hated rust's std::io and std::path libraries for having numerous error cases with no meaningful way to handle them but panic. It should be a sign that people requested to be able to use ? in main that panicking is a-okay for most people. \-Also oft criticized, data inheritance is actually incredibly useful when doing more high-performance data-driven programming. Rust is often touted as promoting data-driven development, but when all the available abstractions have to do with behaviour (Traits, Generics) and only thus, it's hard to believe that claim. I would much prefer a Rust where I could compose, inherit, and embed data to my liking. That is to say, I prefer C++. C++ does that just fine via classes. Unrelated, but Go also does this well with anonymous embedded struct members. \-C++ allows you to have references to mutable data. Rust makes programs more sound by outlawing this entirely, preventing many classes of errors, but also excluding many classes of valid programs. C++ allows you to increase performance by using references (possibly mutable) wherever necessary, instead of having to `.clone()` potentially large data. Furthermore, if I want to ensure a safe and immutable API C++ provides const anyway. Yet further, in Rust it is a reference, and not a dereference, that triggers the borrow checker. That means that simply storing a reference in some struct, even if it's never touched, means that that reference is now immutable. This is a non-issue in C++ as you can choose to deal with usership, not ownership.
Especially because most of people that use Rust come from C++ which they still use, appreciate and respect.
The termination thing, especially for STL containers, is a show-stopper for me as well. I deal with large data sets, and I do occasionally see bad\_allocs in the log when an operator was too enthousiastic about loading data. The software doesn't care; it drops that work packet and moves on to the next thing. Anyway, I'm not convinced that the new exception mechanism is actually an improvement. Exceptions used to work this way in early C++ compilers, and C++ was considered a slow language during that time. Only after it moved to table-based exceptions did it gain a reputation for speed. If you think about it that makes sense: the proposed mechanism adds a conditional jump after every function call, massively increasing the number of conditional jumps in a program. The branch prediction is not going to like that, and it will decrease cache effectiveness as well. I'd like to see some real timing results from real code produced by a real compiler before I make up my mind about them. And I'm also wondering whether we have really reached maximum performance on existing exceptions. As far as I can tell this is an area that has not seen much research, mostly because nobody cared much (people who used exceptions weren't bothered by their performance, and people who didn't weren't either), and because exceptions were determined by the ABI and as such set in stone anyway. Given that the new proposal breaks ABI anyway, I'd like to see if there are things we can do to the existing mechanism to improve its performance - preferably before adding yet another mechanism.
Exceptions were fine until std::variant came along, now we can just return an error value or a value value. If you want your error handling that way exceptions get insanely annoying to deal with.
The second case in your first set of example is already under motivated. (About the second set of example, the motivating examples for having both signed T and unsigned T in the same variant I saw in real code doesn't care which to be initialized.) I totally understand that special-casing bool is poorly realized. Working on that.
https://meta.stackoverflow.com/questions/251134/where-can-i-ask-about-finding-a-tool-library-or-favorite-off-site-resource
y.atan2(x) is uglier than atan2(y,x)
&gt; to see what it's like
https://github.com/PlatformLab/NanoLog is slightly more awkward to use, but blows all other loggers, including spdlog, out of the water in overhead.
&gt; rusts borrow checker also doesnt catch all \[memory safety\] errors That's exactly what it's intended to do. If you found a loophole you should file a bug report. &gt; in some cases it forces you to do runtime checks (all the cell stuff) even in release builds. absolute no-go So, you would basically prefer *all* code to be "unsafe" (in Rust terms, a C++ program is one huge unsafe block in which everything is allowed) instead of confining the critical parts to a few lines of unsafe code that deserve scrutiny while the remaining safe code is statically checked. Got it. Makes total sense. /s
If it's hot code, a branch point after every function is free of cost. If it's cold code, it's probably under 4%.
&gt; I never stated that unsafe cost performance. The point I was making is that for some types of software the only way to preserve performance seems to be for a large percentage of the code to be unsafe, which would appear to defeat a major selling point of Rust. Alright, that's a clearer way of putting it, but this is a (fairly common) misconception- a large percentage of the code is *not* unsafe. Instead, a small percentage of unsafe code implements those new constructs not understood by the core language, and provides a safe interface to the rest of the codebase. For some good examples of this pattern in action you might check out [this blog](https://os.phil-opp.com/), which demonstrates it in the context of some early pieces of an operating system implementation, or else [japaric's work](https://blog.japaric.io/) on embedded Rust. Even the standard library works this way- the core language knows nothing about vectors, reference counting, threads, etc- instead it provides the *tools* for library code to implement them safely. &gt; At least in high-performance data infrastructure software, there is almost no copying or locking in any case. Why would anyone add it to "push the limits" given that it has no functional purpose? I believe you misread my comment here- they wouldn't. Most C++ codebases I work in tend to be conservative around things like references and synchronization, in an attempt to avoid bugs and stay robust against future changes. Making a copy of some data when its lifetime is complex, adding locks when data might be shared across threads (or just not parallelizing at all!). They only really avoid this overhead in hot paths, because it takes continuous effort to ensure correctness. What I'm saying is that Rust lets you write the fast zero-copy minimal-synchronization code *all the time* because the compiler can verify things for you. [This post](https://manishearth.github.io/blog/2015/05/03/where-rust-really-shines/) goes into more detail with an example from rustc.
Without a borrow checker and lifetimes syntax I don’t believe you can have Rust’s guarantees in C++. In Rust a function signature like `fn foo&lt;'a, 'b&gt;(bar1: &amp;'a, bar2: &amp;'b) -&gt; Foo&lt;'a&gt;` tells you that the returned value keeps a reference to the first argument only (and thus `bar1` *must* outlive the returned `Foo` but the lifetime of `bar2` is irrelevant and it might be deallocated immediately after `foo` returns) and that the function won’t modify either `bar1` nor `bar2` (so they are also safe to be shared elsewhere). You could argue that the compiler could figure out that `Foo` depends only on `bar1` from the implementation of `foo` and `Foo`. But then compilation success or failure of **your code** using them depends on their implementation details and not public API. In Rust adding a dependency on `bar2` to the `Foo` type would obviously be a breaking change requiring modification of signatures. I don’t think this is achievable in any backwards-compatible subset of C++.
Or Sutter Faults
The cost of rebuilding a binary is pretty low. Or should be. But we can cache things The cost of deploying something is higher but you should have a plan for than The cost of having an ABI and never be able to upgrade your tool chains or dependencies ? Pretty high. Neither Qt, Microsoft or the C++ standard are able to do that to a degree that satisfy them (there are large lists of things they really want to fix the day they can break ABI) - sometimes it has big performance implications. Plugins are pretty great but it's very hard not to run into ODR or other issues - unless _everything_ is shared and _built at the same time_ (such that all dlls get shipped along the binary) I agree that it's pretty hard not to rely on them and that they are _useful_ however, that doesn't make them sensible or reliable I know this is a very divisive issue and we seem to have gone back and forth over the decades:) http://harmful.cat-v.org/software/dynamic-linking/
This is wrong. The Rust borrow checker is *sound*, meaning if your program compiles you know for sure that (barring incorrect `unsafe` code) it contains no violations of memory safety. The C++ lifetime checker is unsound, meaning that even if it flags no errors your program may still be wrong. This is why you need sanitizers/etc., which can miss things because they're dynamic. What you're pointing out is the opposite- the Rust borrow checker is *conservative*, and will produce errors in some cases even though they contain no violations of memory safety. This is exactly the same as any other static checker, including C++'s type system. You *can* work around this with runtime checks (e.g. `dynamic_cast`, `RefCell`), but you have lots of other options as well- `Cell&lt;T&gt;` which has no runtime overhead (much like C++ `mutable T`), `unsafe` with human verification (much like using `static_cast` when you know it's fine), etc.
&gt; The downside is that things compiled in Rust 1.0 may not compile in Rust 1.20 so backward compatibility might be a bit poor vs making the language better over time. You've got it backwards. Rust 1.20 still compiles Rust 1.0 code just fine; the incompatible changes like removing `~` were done before 1.0 in order to provide that guarantee.
Please show an actual example then because as far as I'm aware immutable actually means no one can change the value of it. So it really shouldn't be possible to get a mutable reference of something that's immutable.
To expand, support on nightly is already good enough for people to start implementing Eigen-like linear-algebra libraries in Rust using const generics.
&gt; The point I was making is that for some types of software the only way to preserve performance seems to be for a large percentage of the code to be unsafe This isn't true. You can do DMA-I/O in Rust using a safe abstraction like VolatileCell&lt;T&gt; over raw pointers and volatile loads/stores. This abstraction does not add any runtime cost. Rust does not force you to use these abstractions, and you can write unsafe code all over the place, but then you would be missing one of the most powerful features of Rust - the ability to write safe abstractions over unsafe code that are impossible to misuse.
The current deal breaker for Rust for me is the very restricted meta-programming it provides. It lacks the equivalent to constexpr, value template parameters, an equivalent to SFINAE and all the traits you can make from it, variadic templates... Every-time I mention that, some crustaceans will point out that these are worked on and indeed it is for SOME topics: \- const fn: [https://doc.rust-lang.org/unstable-book/language-features/const-fn.html](https://doc.rust-lang.org/unstable-book/language-features/const-fn.html) \- const generics: [https://github.com/rust-lang/rust/issues/44580](https://github.com/rust-lang/rust/issues/44580) It might come at some point as much as lifetimes might come to C++ at some point. And even then, will that cover all the use-cases without the full meta-programming package: how would you the presence of the member of a type without SFINAE or some sort of compile-time reflection (traits being explicit you cannot rely on that)? How would you do type-list computations without some variadic templates? In my opinion, parity with C++ meta-programming will be reached the day you can make such thing as compile-time reg-exp in pure Rust: [https://github.com/hanickadot/compile-time-regular-expressions](https://github.com/hanickadot/compile-time-regular-expressions) or something as simple as creating a custom tuple type purely with Rust generics. The day we can do such things, I will seriously consider Rust as a language I should master. Right now, only D can claim having a real edge on meta-programming. If it wasn't for the garbage collector, I would prioritize it over Rust.
Boost.Log does have a possibility to configure it from a configuration file, take a look at the SO question https://stackoverflow.com/q/25845154/6576546 I was looking at using it, but as far as I saw it didn't support all of the cases that we needed, atleast in the version of boost that we are currently using
Lifetime extension / validation around function calls is a huge wish for C++.
I believe you can get DMA working in safe Rust by doing something like [this](https://rust-embedded.github.io/embedonomicon/dma.html).
&gt;In my opinion, parity with C++ meta-programming will be reached the day you can make such thing as compile-time reg-exp in pure Rust: &gt; &gt;https://github.com/hanickadot/compile-time-regular-expressions I think this should be already possible using [procedural macros](https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html).
&gt; Breaking existing C++ code wouldn't be more of a problem than abandoning that code for a new language though? Two different groups of people. One can afford to migrate because they can't get changes they want and another one can't because any change costs millions of dollars.
I've seen this criticism a couple of times. But it doesn't hold much water, IMHO. Yeah, sure, the borrow checker will not consider an index to be a "borrow". But that's fine because it really isn't (in the strictest sense). An index *alone* is *not enough* to qualify as an "access path" to whatever it "refers" to. You need the container as well in order to access the item. So, there is actually no sharing (w.r.t. access paths) going on. That's the big difference. And that's why there is no need for the borrow checker to understand this. Nothing could go wrong w.r.t. memory safety. You might access the wrong item in the container because of a bug, but it's not a memory safety issue.
&gt;Without a borrow checker and lifetimes syntax Well, why couldn't C++ adopt one or both of those? As long as the lifetimes annotation is optional, a lot of existing code would continue to work fine, no? &gt;But then compilation success or failure of your code using them depends on their implementation details and not public API. In the "pre-Concepts" era, C++ programmers are very accustomed to under-specified public interfaces. I mean, you typically can't tell whether a supplied template argument is going to cause a compile error or not just by looking at the template parameter declaration. So I don't think C++ programmers would not be overly distraught by having to learn about their lifetime violations from compiler error messages. And just as Concepts were added to address under-specified template parameter declarations, lifetime annotations could eventually be introduced to address interfaces with inadequate lifetime information. Right? &gt;I don’t think this is achievable in any backwards-compatible subset of C++. I'm not sure what you mean. There would be existing code that does not satisfy the new safety restrictions, but that code would just be considered part of the "unsafe subset".
If done right, it would be a forward jump that is always considered "not taken" by the static branch predictor. Thus I'd say the cost even in cold code is practically nonexistent and shadowed by the costs of loading that cold code into your L1 cache and "compiling" it into microcodes in the first place.
Rust is slowly catching up, but most of the functionality is still only available to nightly users and hidden behind feature flags.
&gt; [Rust] lacks [...] an equivalent to SFINAE Why would you want that? Aren't we already trying to get rid of SFINAE abuse with concepts in C++?
Empirical benchmarking showed the impact to be probably under 4% for the worst case scenario. That's still not zero, as with table based EH. For that reason, I continue to argue there is a place for both table based and branch based EH in C++. Also, there are some design patterns where type based polymorphism is a much better fit than value based polymorphism. And there's the backwards compatibility issue, of course.
&gt; Every-time I mention that, some crustaceans will point out that these are worked on and indeed it is for SOME topics: &gt; - const fn: https://doc.rust-lang.org/unstable-book/language-features/const-fn.html &gt; - const generics: https://github.com/rust-lang/rust/issues/44580 &gt; It might come at some point as much as lifetimes might come to C++ at some point. `const fn`s are already in stable Rust [since 1.31](https://blog.rust-lang.org/2018/12/06/Rust-1.31-and-rust-2018.html#const-fn) (albeit they’re still very limited in what is allowed in their bodies). const generics RFC has been accepted for a long time (so their design is known) and they have preliminary, but still buggy, implemenetation in unstable Rust. But yes, it’ll take a lot more time before they are stabilized and actually usable. In the meantime there is the [`typenum`](https://docs.rs/typenum/1.10.0/typenum/) library.
&gt; Oh, you also pay 8 bytes (64-bit) for every structure allocated. It carries pointer to the memory_resource used. You also pay a virtual call penalty, because the memory resources are polymorphic. Which, to be honest, might be worrying about exchanging a quarter for a hundred dollar bill, but hey... Have you measured? If you haven't, why are you using custom allocators?
Ah, I get it now. When do you want to express that kind of "won't ever change"? I think that the "I'm just giving this a name, I won't modify it (but I will probably move it when I'm done)" expressed by Rust's `let` is pretty common for me. (It also sidesteps the somewhat awkward way C++ has to fudge and make const objects non-const during their destructors).
There is certainly room for both. My empirical evidence: we have a very large C codebase that uses macros and return values for error handling (basically wrapping every function call into a ```Check(F(a,b,c))```, and the Check macro is ```{err=F(a,b,c); if (err!=OK) return err;}```). I once compiled it with the Check macro doing nothing but calling the function, and there was no measurable overhead in the execution times.
You could define it this way: impl Vec3 { fn new(x: impl Into&lt;f64&gt;, y: impl Into&lt;f64&gt;, z: impl Into&lt;f64&gt;) -&gt; Self { Vec3 { x: x.into(), y: y.into(), z: z.into() } } } Another example off the top of my head that you can find in the standard library is this: let mut file = File::open("foo.txt")?; Here, `open` accepts not only `&amp;str` but really anything that could be turned in to a `&amp;Path` with the help of the `AsRef&lt;Path&gt;`. This included `String`, `&amp;String`, `&amp;str`, `OsString`, `&amp;OsString`, `&amp;OsStr`, `PathBuf`, `&amp;PathBuf`, `&amp;Path` and `Cow&lt;Path&gt;`. The traits I've seen used for such a purpose are `AsRef`, `Into` and `IntoIterator`.
Let's take the case of a vector. You can only really modify non-Copy types if you own them or have a mutable reference. If you pass an immutable reference to a function, there's no way to modify the value, except to return a new one. As stated in your example you are just shadowing variables and copying values around. The value of the original`x` is never really changed. I for one like the shadowing part of Rust. Unlike some other languages which makes it hard to do proper shadowing and force you to come up with stupid variable names.
Yes, but I believe I was responding to the overuse of always throwing exceptions in error handling or possibly even control flow.
Yes, you shouldn't use exceptions as part of control flow as a norm.
In theory everything is possible. Practice shows otherwise.
I agree. Though, you could also write `f64::atan2(y, x)` if you know that you deal with two `f64` floats or `Float::atan2(y, x)` if you're OK with relying on the [`num_trait`'s `Float` trait](https://rust-num.github.io/num/num_traits/float/trait.Float.html).
We’ve had great success with the ‘expected&lt;T,E&gt;’ . One nice thing we’ve done with that is that each caller appends local context before passing the error on up. It kills me now to see some exception where I know *what* went wrong but not what the code was trying to do that led to it.
i agree, but just memory safety is a too small part of overall safety for me to have to put up with the borrow checker. it won't help you with checking for correctness (it obviously cant), and the complexity i have to add to pass the check makes it not wprth it fpr me. th Thats why I prefer c++, it lets me express what i actually want to say in code ( semantically holding an iterazor or an index are very different) and imo the iterazor makes it more understandable that im referenceing a specific item and i will find the bug faster
I am not speaking of SFINAE but an *equivalent* in term of what it brings: checking properties on a type (traits in C++). Concepts are such equivalent. Traits in D are such equivalent. But traits in Rust are explicits and therefore do not fulfill that purpose.
Can't wait! Some of my favorite speakers will be there this time. Super exciting
&gt; being able to use whatever allocator you want whenever you want Yes, ok, you have a point. But to be fair, custom allocators in C++ are a nightmare, and Rust’s custom allocator support is improving. You are now able to choose your own global allocator, for example. On the other hand, C++’s custom allocator support is also improving, and approximately at the same rate, it seems to me.
He means let x = vec![1, 2]; let mut y = x; y.push(3); There is one object here that is first bound to x, then bound to y. When it is bound to x it can't be changed. Later, when it is bound to y it can. This is different than const in C++, where a const object can't be modified through its whole lifetime (except construction and destruction).
An advantage in one context can be a disadvantage in another. Rust’s big advantage is it’s borrow checker. Rust’s big disadvantage is... also it’s norrow checker. This is a pretty common refrain from “rustaceans,” in fact. I think the larger point is that it’s not a zero sum game. We can have Rust and C and C++ all at the same time. Rust’s success does not require C++’s failure. I suspect this is nuance that you probably agree with, but I think it’s nuance that is worth saying. &gt; listing it as a disadvantage is objectively wrong. This is just stupid. Sorry for being rude. (But not very.)
The vector example is trivial: fn main() { let v = vec![1, 2, 3]; let mut mv = v; mv[0] = 4; println!("{}", mv[0]) } The underlying object for binding `mv` was originally an immutable binding called `v`. You can also trivially show this by moving an immutable variable into a function that takes a mutable value. That function is free to do whatever it wants, then. fn print_it(mut v: Vec&lt;i32&gt;) { v[0] = 4; println!("{}", v[0]) } fn main() { let v = vec![1, 2, 3]; print_it(v); } In both cases, there are no diagnostics or warnings issued for the latest stable release.
But that only really takes care of one single function call returning an error. It does nothing in the case where you have to keep checking validity and passing the faulty result up. Suppose you're making a fileformat reader that creates an object as a result, cleanest way is to throw an exception on say an IO-error at a very low level, then you can report it as a "return optional" and just disregard the unfinished object. I am not talking just about an API, I'm talking about implementation.
See my example provided in [another comment](https://www.reddit.com/r/cpp/comments/c5bnme/what_are_the_advantages_of_c_over_rust/es2yuya/)
As much as i dislike some things about the ISO process (eg it being pretty slow and often leading to very suboptimal decisions), C++ being standardised at least gives me confidence that my project will still work 10 years later. Rust has one compiler with a mandatory and very strict "sanitizer" built into it which comes too close to 'the implementation is the spec' kind of thinking imo. In C++ there is a standard, multiple compilers, many useful tools to choose from etc as a result of it being not one centralized blob
In a certain light, I actually prefer Rust's way. C++ has it as UB, from my understanding, because some C implementations for more niche platforms may put that data in read-only memory. So it literally would be impossible to physically write to the that memory. Rust, instead goes "f*** it. At the end of the day these are just bits you can frob. If you really want to fiddle with them, go ahead". There's no quirky-ish case causing UB.
&gt; custom allocators in C++ are a nightmare agreed
&gt;Rust’s big disadvantage is... also it’s norrow checker. This is a pretty common refrain from “rustaceans,” in fact. Sure but that’s tongue in cheek or frustration speaking, not a genuinely held belief, at least not by the majority. Blaming the borrow checker for highlighting the complexity of memory ownership is phenomenally confusing cause and effect. It’s akin to blaming climatologists for warning about global warming.
&gt; let mut file = File::open("foo.txt")?; &gt; Here, `open` accepts not only `&amp;str` but really anything that could be turned in to a `&amp;Path` with the help of the `AsRef&lt;Path&gt;`. This includes `String`, `&amp;String`, `&amp;str`, `OsString`, `&amp;OsString`, `&amp;OsStr`, `PathBuf`, `&amp;PathBuf`, `&amp;Path` and `Cow&lt;Path&gt;`. This is far and away my favorite API for file IO. Yeah, you do sometimes need more sophisticated machinery, but 92.13% of the time you just want the data in the variable. And because it is so often a pain in the ass, I have developed this persistent automatic dread any time I need to do file IO, even in languages like Python or Rust where it’s dead easy, to the extent that I subconsciously go out of my way to avoid it. Ever find yourself pasting a wall of data into a Jupyter notebook instead of just reading it from the stupid file like an adult? That’s a symptom of accute File IO Anxiety Disorder.
Yes, generally moving means giving ownership, that's the point.
In C++, passing ownership cannot take away constness from a const-declared variable without invoking UB. Remember, the point is describing differences between C++ and Rust.
 __cpp_lib_endian [P1612R0, Relocate Endian’s Specification](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1612r0.pdf)
Or "stutter".
This was this biggest blunder of Rust, in my opinion. You have this great idea about ownership and lifetimes that’s very different from the status quo, but it was implemented without ergonomic inference. Which is insane. Now you have the entire internet saying how frustrating this feature is—which is the very feature that is Rust’s superpower—and for the ridiculous reason that nobody thought to do some basic lifetime inference from the beginning. I’m talking basic inference here, easy stuff, not much harder than liveness analysis. A PL theorist should have known better. *Anyone* should have known better. Now they are fixings it—in fact, they’re making the lifetime inference *really* sophisticated. When it finally lands in stable, that whole story about the oppression of the borrow checker will disappear. But now you have an internet full of “fighting the borrow checker” blog articles. All of that programmer frustration was for nothing.
Who is that?
&gt;If I had your experience, what would I see wrong with it? Let's see. Maybe the fact, that failure of an operation (at least in the context of a desktop application) does not necessarily imply failure of application! You're missing too much context to reliably determine that failing to allocate an `int` is unrecoverable. You may have just beforehand allocated heaps of memory without a problem. With current day semantics that big buffer would just be deallocated again and the error would be reported to the caller. Example: Say you use some image processor. Said software allows you to work on multiple images in parallel - all of them are handled by the same process. You try to create a new 16K image and encounter `bad_alloc`. Is it ok for the software to kill all your existing work no matter what just because creation of a new document failed? Our users would **never** accept something like that!
&gt; Well, why couldn't C++ adopt one or both of those? And monkeys could fly out of my bum, but they probably won’t. They like it in there. There is a big difference between on by default and off by default. Also, despite having amazingly good static analyzers for C++ (it’s like magic to me), there is not nor ever will be something like Rust’s borrow checker. It is fundamentally tied to the type system in a way that cannot be replicated in C++. I can’t prove this mathematically, but I’m pretty sure it’s true, and even if it’s not, it’s contrary to the design philosophy of C++ and so won’t happen for social reasons. Which I think is ok. I’m actually really excited about the proliferation of programming languages that are adopting features from paradigm’s that used to be out of the mainstream. Pretty much everyone has caught on to how fricken useful functional programming concepts can be. I love that we’re seeing some of the best features from functional programming being added to even older established languages. C++ has lambas!
C++20 (maybe C++23) is going to have audio library implemented. It is still unfinished but certainly I would give a try after standardizing. I recommend standard libraries to everybody.
Oh sorry I misunderstood.
My point isn't about if these features are in or not or when. But that even if they were in, that's not enough power to reach what you can do in C++. You need the full package. And that's probably in a long time if ever. Unlike D which had those and more from the get-go.
Have you read or seen Herb's explanation? If the default allocator fails to allocate a small object, you won't be able to run exception handlers, because they need to allocate. Failure of that operation thus implies UB, which implies failure of your application and leaves it free to terminate. 16K is unlikely to meet that standard; it will throw as now. And if you really think you can handle a failure to allocate a word, just use a custom allocator.
That is true. You can mutate owned value even if originally it was created as an immutable one. And as you indicated in another comment, you cannot enforce immutability of an owned field in a struct (you can keep it private and only provide API that does never mutate it). But why would you need this `const`ness, what’s the actual use-case? After moving the value, the user of `print_it` has no longer any access to that value, they have no way of witnessing the mutation – it is in no way observable by them. One would argue they see it because the first element is printed differently, but really what you observe is just what gets printed, not that the original vector changed. As far as they can tell, the function could be implemented as fn print_it(v: Vec&lt;i32&gt;) { println!("4"); } instead (and I actually wouldn’t be surprised if both compiled to the same code…). That’s the whole point of Rust ownership – if you own the value (and nobody is borrowing it at the time), you are free to do whatever to it, because it’s yours and nobody else can see it. If you need something to actually be and stay immutable, you pass references. And if you need something to exist through the entire program in an immutable form, you make it `&amp;'static` – nobody ever can mutate a static reference (although creating `&amp;'static` references to more complex objects is harder and that’s why libraries like [`lazy_static`](https://docs.rs/lazy_static/1.3.0/lazy_static/) exist).
You wrote ‘[i]t might come at some point as much as lifetimes might come to C++ at some point’ and that’s what I was referring to. The features you mentioned are already implemented or are already accepted and coming, while lifetimes for C++ are much farther away (if they ever come). Also, I’d argue that Rust [procedural macros](https://blog.rust-lang.org/2018/12/21/Procedural-Macros-in-Rust-2018.html) are actually much more flexible metaprogramming tool that is available already (it really allows you to embed almost any arbitrary domain-specific-language in Rust code – the only requirement being that macro input must produce a valid Rust token stream). But they are much more difficult to write (you need to parse the input token stream, and then produce a new one that’s valid Rust from it), and thus certainly not a replacement for, eg., const generics (this is currently worked-around by [`typenum`](https://docs.rs/typenum/1.10.0/typenum/), but it’s a hacky work-around for the time being and I agree Rust does lack in this regard for now).
But why are all the programs I use written in C++?
That only works if you use HRTFs customized for your own ears, flat headphones (read: not a gaming headset) AND have a visual reference and / or headtracking. If any of those go wrong, the sound very easily falls inside your head.
Isn't a token-based approach a bit brittle to use on the long term? As far as I understand this looks like an "extensible embedded preprocessor". Somehow very similar to what custom preprocessors (QMOC, OpenMP...) do on annotated (pragma, macro...) C++, with the added benefit that it runs straight into the compiler and can have user-defined rules. Manipulating types feels a lot safer.
Right, my bad! I was not comparing explicitly these two specific features with lifetimes. But rather Rust meta-programming support versus C++ lifetime support. As mentioned in a sibling comment, procedural macros feel very similar to what you could do with a custom preprocessor and few annotations in C++. It is nicely packaged, I give it that. But it does not feel on par with proper meta-programming on types.
Ah I see. I don't really se that as an issue though. As moving from v to create mut mv seems fine to me as you will get errors trying to use v afterwards. And if you don't want v to be moved from then you can use clone().
Wow that's pretty expensive at 1k$
"The `&lt;pmr&gt;` header" is called `&lt;memory_resource&gt;`. And it doesn't contain any type-erased wrappers at all. All it provides is classically _polymorphic_ types. `&lt;experimental/memory_resource&gt;` did provide [`resource_adaptor`](https://en.cppreference.com/w/cpp/experimental/resource_adaptor), which is sort of one-half of a type-erased type, but that didn't get adopted into C++17, and it's definitely not as easy to use as, say, `std::function`. As a rule of thumb, type-erased wrappers are not followed by angle-brackets: it's `std::any`, not `std::any&lt;T&gt;`. The lack of type parameters is exactly what distinguishes "type-erased wrapping" from plain old (type-parameterized) "wrapping." `std::function` is a special case because it takes the _interface signature_ (not the wrapped type) as a template type parameter.
Herbs talks are always enjoyable IMO and having the creator of the language speak is always interesting. I also enjoy listening to Sean Parent; lots of his old talks are some of my favorites.
Shared libraries are not for convenience. On CentOS 7: $ cat main.cc #include &lt;iostream&gt; int main() { std::cout &lt;&lt; "Hello World" &lt;&lt; std::endl; return 0; } $ g++ -o shared main.cc $ g++ -static -o static main.cc $ ls -lh total 1.6M -rw-r--r-- 1 owner group 94 Jun 26 08:48 main.cc -rwxr-xr-x 1 owner group 8.9K Jun 26 08:59 shared -rwxr-xr-x 1 owner group 1.6M Jun 26 08:59 static
I agree. You _could_ write `atan2(y, x)` to forward on to `y.atan2(x)`, but that's altogether much more boilerplate than the equivalent C++. This is one case where Rust's lack of function overloading hurts.
You are not understanding the nature of the problem. If volatile loads and stores solved the problem it would be trivial in C++ too. In fact, volatile loads and stores are not used at all because they are not required for correctness and don't solve any problems. The object you are referencing may be obliterated at any point in the future by another reference that isn't even in your address space. How does volatile solve this? You can't copy the data because that would be extremely expensive so you need a zero-copy obliteration safety protocol that guarantees the reference will always be correct over its lifetime *even if the referenced object is obliterated*. Also, how does volatile solve the problem of intrinsically non-deterministic destruction? That is a resource leak waiting to happen.
Okay :) Thanks :)
There are plenty of ways to do DMA in isolation. A friend of mine wrote some of the DMA code in Tokio (he has done the same in C++). That's the easy part. The hard part is when almost your entire address space lives entirely within actively and concurrently DMA-ed memory. None of your objects are ever really "safe". In practice, you solve this with a user space execution scheduler that only schedules execution against objects in temporal windows where safety of that operation is guaranteed but this is only observable at runtime. This also means that all references are necessarily effectively mutable.
Herb's talk always seem to actually present new ideas and techniques, like every year he manages to provide new insight about C++. Bjarne is the opposite, every year his talk is basically a recycled telling of "the history of C++". It's basically like he feels he has to show up and say something because it's the main CppCon, but if you've heard any of his previous CppCon talks you've heard them all.
You should consider adopting Outcome into your codebase! No more forgotten error checking.
I would say you probably want an even higher-level library/framework for this? And if it doesn't exist yet, someone should investigate developing a C++ framework for audio game development. People could then build upon this framework to build audio games. I bet there are many common things such a framework could offer and abstract, there must be many common tasks and requirements in audio game development. That framework itself would use any of the low-level audio libraries that you mentioned.
Wait a minute, I think I know what's the problem here: You think I'm arguing in a "current exception model world" - I'm not! I want static exceptions! What I don't want is this "failed to allocate singular value of arbitrary(!) size so just terminate"-semantics! Everything you said about allocation problems for dynamic exception handlers is true - though as Herb's paper lays out there have been (partial/hacky) solutions/workarounds to this problems \[hacking the stack, preallocating in a dedicated storage\]. The thing is: &gt;This let us achieve the zero-overhead and determinism objectives: &gt; &gt; • Zero-overhead: No extra static overhead in the binary (e.g., no mandatory tables). No dynamic allocation. No need for RTTI. &gt; &gt; • Determinism: Identical space and time cost as if returning an error code by hand. Iff there is no dynamic exception allocation, that "allocation of bad\_alloc" can't fail =&gt; we can report heap allocation problems via `std::error` just like any other exceptional situation...
That’s why dynamic libraries are not evil by themselves, but dynamic libraries with unstable, not standardized, ABI, is a much worse idea. There’s a reason why many APIs with multiple implementations (pthreads, graphics APIs like OpenGL, Vulkan, etc.) are typically defined as C APIs. C ABI for any major platform typically is stable and stays so forever. And those typically work well. But using a dynamically linked library written in, and exposing native API of, a language (like Rust or C++) whose compiler can change ABI from version to version or between implementations is a huge PITA. So I myself am not against shared libraries, but if one intends to build one, IMO it should provide only an external C API (and then perhaps a statically-linked shallow native wrapper for nicer user experience). This also makes the library much more friendly to users of other languages with some kind of FFI, as this typically depends on C ABI.
The “don’t use `-Weverything`” guy. The “always use `for (auto &amp;&amp;var : container) { }` guy.
&gt; The object you are referencing may be obliterated at any point in the future by another reference that isn't even in your address space. When doing DMA-I/O, either your process owns the memory and devices write directly to it (which means that the memory can't be "obliterated" behind your back whatever you might intend that to mean - I suppose you mean at worst that the memory is deallocated), or your device owns the memory, in which case you need to make sure that the memory is still there while you are accessing it. Either way, can be easily done in both C++ and Rust. --- The problem volatile solves in Rust is that of allowing you to read from DMA-I/O a value while concurrent unsynchronized writes modify parts of it, but that problem is more complicated than that of memory ownership, which is what you seem to be struggling with.
Boost.Log is a head f\*\*k
IIUC, I think that would be possible to do in Rust, but it would likely be much more involved than in C++. The scheduler would probably need to own all of the DMA-ed memory and hand out the references itself when it schedules a new task. I wouldn’t be surprised if `unsafe` code is required as well. Do you know of an open-source project (hopefully one that’s not too complicated) that follows this particular model? It sounds like something that would be interesting to experiment with.
The point is there are semantics to say “this object will never ever change”. A slightly different point than being concerned about lifetimes.
&gt; custom allocators in C++ are a nightmare I'd say C++11 allocators are a nightmare, but I really like the C++17 polymorphic ones.
&gt; ... functional programming ... C++ has lambdas! C++20 will have ranges, which, as far as I have seen, makes it even more functional-like.
That's what it's always been; and for a conference, it's a pretty good price.
What is the total duration of videos in this nano degree? I have once purchased Udacity nano degree program and there was only 23 hours of video inside that program. By paying 999 USD in some offline training center I could have mastered full stack Python/Java/Asp.Net development but I wasted my money on Udacity. To be honest some 10 USD courses on Udemy with lakhs of students are better than Udacity nanodegree.
You need to strip the static exe to compare. Also -static is usually not what you want even if you intend to statically link. (In particular you probably want a position independent executable). The advantages of shared libs are mostly to do with less stringent requirements on transitive dependencies and ease of updates.
If they had implementation inheritance, honestly, I think I'd jump off C++ to Rust. It has enough other advantages, and doesn't have C++'s massive evolutionary baggage and massive over-templatization. It is a bit alpha-soupy in its syntax. I think that the 'write once, support forever' rule argues for a somewhat more verbose but readable syntax in an optimal language. I still may end up going the Rust direction, because I just think C++ has become far too bloated and arcane. Of course this will likely get down-voted into oblivion, which makes me even more want to move to get away from C++.
Hey now, sometimes Bjarne adds a new slide or two.
&gt;Bjarne Stroustrup &gt;C++ is turning forty. I read this as Bjarne is turning 40...
I've never used a custom allocator. If I need a lot of temporary objects fast, I just use an object pool, and avoid any allocation or deletion at all.
At some point, does being pushed for the answer to everything all the time work against a technology because people are just sick of hearing about it?
In 2019 1.6m is a rounding error. Yes it offends me somewhat, but the pain of mismatched libraries offends me more. Sometimes a mismatched library just blows up, but it occasionally will almost entirely work, then do bad things without blowing up.
I have a love hate relationship with the many C++ interpreters out there. Competition is good. But C++17 took forever to be halfway useful on most of them, and my C++17 code was fantastically non portable for a long time.
 **Company:** Adobe **Type:** Full time **Description:** Are you energized by the intersection of technology and design? Do you spend your time optimizing and enriching creative work using cutting edge technologies, such as multi-platform development frameworks, native code, and modern C++? Are the features you write visible in leading design products like Photoshop, XD, Premiere and After Effects, helping millions of users get their work done with simplicity and joy? If not, and you wish you were, look no further. Our team builds the platform for user experience and features that will propel Adobe to the next level of engagement and user retention of our flagship Creative Cloud products, on desktop, web and mobile platforms. **Location:** San Francisco or San Jose **Remote:** No. **Visa Sponsorship:** Will sponsor VISA. **Technologies:** Multiple C++ positions open. Prefer individuals with desktop or client side C++ experience. **Contact:** Please apply and we'll contact you with more details: &amp;#x200B; Sr. C++ Developer: Strong C++ with some JavaScript skills. [https://www.linkedin.com/jobs/cap/view/1343104602/?pathWildcard=1343104602&amp;trk=job\_capjs](https://www.linkedin.com/jobs/cap/view/1343104602/?pathWildcard=1343104602&amp;trk=job_capjs) &amp;#x200B; **Computer Scientist - Mobile Engagement SDK**: Strong C++ with Android/ JS background. [https://adobe.wd5.myworkdayjobs.com/en-US/external\_experienced/job/San-Francisco/Computer-Scientist---Mobile-Engagement-SDK\_69219-1](https://adobe.wd5.myworkdayjobs.com/en-US/external_experienced/job/San-Francisco/Computer-Scientist---Mobile-Engagement-SDK_69219-1)
But isn't the argument that X isn't getting modified, because it no longer exists? Y is all that exists. It makes sense in a way if everything is a reference. The vector is neither const nor non-const. It just exists. You can view that vector via something that applies constness to it or not. So it's X that's const, not the vector. I can at least see that as a valid argument. Though it would be useful to have some means to say, I want the freaking vector to be immutable, period.
Exceptions are ummm... exceptionally useful for general purpose code. I have a LOT of general purpose code in my code base. That type of code typically doesn't care in the slightest what went wrong. It just wants to clean up and pass the problem up stream to some code that is program/domain specific and knows how to react to it correctly. Exceptions, in conjunction with stack based cleaner-uppers (I call them Janitors), vastly streamline such code. The only reason you even ever need to catch in that kind of code is if you just want to add some value to the error that is propagating past you or if you are in some cases working with system calls perhaps. I really hate to think about how much boilerplate having to explicitly deal with errors, no matter how much they streamline the verbiage, would get added to my code to move to that sort of model.
Or in the case of adding new syntax put behind the edition change that defaults to 2015 but all newly generated projects put in 2018.
"Exceptions are for exceptional conditions" is tautological nonsense. Exception = the method could not fulfill its contract. If the contract is to return an error code in case of error, fine, return an error code. Dlib (http://www.dlib.net/intro.html) is a fine example of this line of thought. "What happens exceptionally..." is another nonsense. How is a library author to know how the library is going to be used? E.g., a CSV parser might be built with the expectation to be pointed to a valid CSV file and throw if it can't parse it. I on the other hand could use it to extract data from a folder with a million of files where 0.01% of them are valid CSV files. Which gives?
I really wish I could go, but I'm not sure if I'd even qualify for student pricing and even with that airfare, lodging, and food add up to enough I probably couldn't go anyways unless I can convince my work to help pay for it. I'll be sure to try and watch through many of the talks once they're online though.
What sort of features do you want from a logger that you can't write yourself?
I you find any, I'd like to know. On Linux, I have found some specific functions to control quite a bit of things about NUMA, but no way to control the allocation itself. The allocation is done based on which core it happens on, and you can only control the fallback option (fail or use another node). I wish I could specify exactly which NUMA node to allocate from instead :/
Rust actually has compiler-enforced constness to a greater degree than C++: void foo(int const&amp; i) { int a = i; bar(); assert(a == i); // Maybe, maybe not. `bar()` may have modified the memory location. } In Rust, if you have a `&amp;i32`, you are guaranteed that it will not be modified for as long as you can use the reference. It's irking, but `const&amp;` (as `const*`) is too often a lint more than anything else in C++ :/
There's two things discussed here, the carpenter (programmer), and the toolbox (programming language) given to him, which may influence how the carpenter works depending what tools are inside. If the toolbox has a hammer (exceptions) that has been venerated for decades and don't provide a drill (algebraic data types) you end up using hammer and nail to drill. If the drill comes too late, when it comes, you'll still be driven to use the hammer to drill, and will have to deal with works produced that way for decades, until the technical and cultural problem is fixed, if ever. So answering your ending question, &gt; Which gives? Was the author wrong to use exceptions to signal an error (unparseable file)? It's never wrong to nail with a hammer. Despite your 0.01% figure, the exception's cost after failing to parse an entire file is irrelevant. When I provided examples regarding error frequency, I did so where the cost of failing with exceptions is relevant, as well as it's conceptually expected to happen often too, I may have not been clear enough there. Failing to parse a file equates to the task of opening a file is terms of problem domain, it's obviously expected they may be handled in similar fashion, it's a complete different expectation when failing to parse a number in a small string, they surely may not be handled the same way, one can easily see one shouldn't be expected to exist in hot path, while the other can.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/c5tqwz/help_me_choose_a_new_string_representation_for/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
There's two things discussed here, the carpenter (programmer), and the toolbox (programming language) given to them, which may influence how the carpenter works depending what tools are inside. If the toolbox has a hammer (exceptions) that has been venerated for decades and don't provide a drill (algebraic data types) you end up using hammer and nail to drill. If the drill comes too late, when it comes, you'll still be driven to use the hammer to drill, and will have to deal with works produced that way for decades, until the technical and cultural problem is fixed, if ever. So answering your ending question, &gt; Which gives? Was the author wrong to use exceptions to signal an error (unparseable file)? It's never wrong to nail with a hammer. Despite your 0.01% figure, the exception's cost after failing to parse an entire file is irrelevant. When I provided examples regarding error frequency, I did so where the cost of failing with exceptions is relevant, as well as it's conceptually expected to happen often too, I may have not been clear enough there. Failing to parse a file equates to the task of opening a file is terms of problem domain, it's obviously expected they may be handled in similar fashion, it's a complete different expectation when failing to construct a number out of a short string, they surely may not be handled the same way, one can easily see one shouldn't be expected to exist in hot path, while the other can.
I would note that Rust does not even *aim* at implementing anything like templates. That is, Rust aims at implementing *generics* not *templates*, the difference being that templates are checked at instantiation time whereas generics are checked at definition time. You can see generics at being template + mandatory concepts in a sense. With that out of the way, Rust's generics story is lacking: - Non-Type Generic Parameters (the ability to parameterize a template by a value): a minimal implementation is in the work, which allows passing integers as parameters, but not constraining them. - Variadics: not planned; native tuples help a lot, but traits are implemented by using a macro to define the tuple for all arities from 0 to 12 which is a PITA. - Specialization: there have been various attempts at coming up with a sound proposal, I'm unclear if any ever concluded and it's for now on the back burner.
&gt; how would you the presence of the member of a type without SFINAE or some sort of compile-time reflection (traits being explicit you cannot rely on that)? I think there's a values mismatch here. Rust's take on generics (not templates) is specifically to AVOID duck-typing, so I don't see any proposal for SFINAE making headway any time soon. &gt; How would you do type-list computations without some variadic templates? The same way you did them in C++03? See frunk's [HList](https://docs.rs/frunk/0.3.0/frunk/hlist/trait.HList.html) (Heterogeneous List), and weep. The lack of variadics is less cleanly felt since the language has native tuples; it's felt that const generics (values in template parameters) and specialization are more important, and work is ongoing on the former. &gt; Why prioritizing meta-programming so much? I've done meta-programming. Both preprocessor programming (thanks, Boost.Preprocessor) and template meta-programming. I remember implementing with a colleage a full-blown reflection system in C++, where the only requirement was declaring data-members with a macro (methods were not supported), and then implementing automatic serialization and an ORM-like system on top. It worked, crazily. Pretty efficient and all. It was such a horrible kludge, though. The slightest comma mistake in the declaration and the macro would barf at you. The slightest error in the instantiation of serialization methods, and you'd drown under *pages* of errors. By comparison, Rust's [`serde`](https://serde.rs/) library is as efficient and extensible (for serialization), and so much more *user-friendly* in case of errors. --- TL;DR: I won't pretend Rust's generics are more capable (especially as incomplete as they are today), not even that they will ever *be* in the end, however templates are not that great at meta-programming *either*.
You can use huge parts of the standard library with disabled exceptions and even more if you are fine with program termination on allocation failure
Then again, all the companies I've been with used C++ as their main language, and yet used very few 3rd-party libraries (and mostly C one), with the big exception being Boost. The difficulty in integrating 3rd-party libraries in C++ is making it more difficult than it should be to leverage the ecosystem, leading to poorly re-implemented local solutions because "it's easier" way too often :/
I know of no way to directly control memory affinity. I use the same obvious workaround as everyone else: set cpu affinity before allocating memory, which causes Linux to almost always allocate from memory local to the core.
&gt; This was this biggest blunder of Rust, in my opinion. While that may be true, it's easy in retrospect, but it was not as obvious at the start. Lexical borrowing seemed *natural*, after all, following the lifecycle of the references themselves. &gt; When it finally lands in stable, It landed last year. It did not solve all error messages though (some are genuine, after all) making it difficult to sort out which complaints are because of real issues vs which complains were solved with the better inference :/
Huh? You can have a mutable reference in a struct.
Yep - it's probably one of the main challenges faced by C++
&gt; Not that it's completely painless with C++'s STL, but with custom allocators (or pmr) one can probably do something better. I haven't found a way to specify on which NUMA node to allocate on Linux, so I'm not sure. I've used libnuma, but it seems allocations always go to the local node, and only the fallback behavior in case it fails on the local node can be controlled :/ (And if anybody knows, please do tell!)
getSalesTax has a /* in it, which is the beginning of a comment.
I have yet to encounter a situation where the virtual function call overhead doesn't pale in comparison to calling new. Not saying there aren't any, but they seem to be rare enough that I don't worry about them and everytime I'm pressed for performance, there are usually bigger fish to fry (often you can avoid allocation on the hot path completely). So I think your quarter for 100 bucks analogy nails it.
Very good point!
Have you had a look at c++17 pmr? They are straight forward to use and writing your own memory resource is also pretty simple. It's still not trivial of course (what parts of c++ are) but I'd say c++17 is a game changer
I've been using VS 2019 on Appveyor for a while, [19.21.xxx](https://19.21.xxx) \- should have it [https://github.com/willwray/type\_name\_pp/blob/master/.appveyor.yml](https://github.com/willwray/type_name_pp/blob/master/.appveyor.yml) (disclaimer: I blagged my config &amp; hacked it without reading the manuals or any understanding of what I was doing CI-wise). I can't wait for more floating-point \`from\_chars\`, to the point that I may look for sponsorship to do the GCC job (never really played video games so not afraid of the 'boss')
What is your compiler outputting as errors? You can't just post your code and ask whats wrong without any context.
Yeah, there are workarounds in Rust, it just becomes complicated and/or inefficient. I looked at doing a Rust port of a database kernel a few years back with a Rust expert and it was daunting. In any design, you don't want the developer to have to reason about the safety of using a reference at every point in time, non-deterministic destruction, etc in any language, so you push that reasoning to a scheduler that enforces the invariants by only allowing code to run when the invariants can't be violated (also great for eliminating locks). This concentrates the safety complexity in the scheduler design, which is amenable to formal verification in practice. &amp;#x200B; Open source is oddly lacking in high-performance database kernels. The only one I can think of, though having never looked at the internals, is ScyllaDB which I know manages all of its I/O in user space. It isn't a particularly new style of architecture, I've been designing them this way for over a decade and other people were doing it at least a decade before I was.
Sorry but the correct subreddit for help is r/cpp_questions
*Disclaimer: I've been programming professionally in C++ for 11 years now, and generally have a good working knowledge of it. On the other hand, while I discovered Rust circa 2011, I've only ever dabbled in it, with my "biggest" project topping at a few 1000s lines of code. This of course voids any claim of objectivity: I've had much more time to run into the skeletons in the closet of C++.* First of all, I think it's important to note that *both* languages evolve over time. If you've been following C++ news, you already know that C++20 is gearing up to be as major as C++11 was: Concepts and Modules are nothing short of a mini-revolution. As such, I think it's important to qualify any advantage (or disadvantage) based on how long said advantage (or disadvantage) can be forecast to last. Some will endure, because they are based on core values of the community, while others will smooth over time as the language evolves. *Note: It's getting late here, so I'll stop with templates, not because I have carefully considered that it was everything that C++ had to offer, but simply because I cannot think of anything else right now. I'm also happy to entertain suggestions in comments to help flesh this list out.* ###Short-Term: Horizon Q2 2019 - **Templates**. C++ templates have 3 significant features that Rust generics lack: - Non-Type Template Parameters (`template &lt;std::size_t N&gt; class X;`): Work is ongoing in Rust, current nightly compiler is sufficient to handle arrays generically, but there's still some design and implementation work needed in the area. - Specialization: Rust wishes for sound specialization, and to the best of my knowledge all proposals to date ultimately fell short. - Variadics: Rust has built-in tuples and uses macros to implement traits "generically" (for arities from 0 to 12). Clearly on the back-burner for now, trying to change too much about generics at once being liable to backfire. ###Medium-Term: Horizon 2020 - **Templates**: - Variadics: As mentioned, given the priority to const-generics and specialization right now, powerful variadic features are unlikely to be there for the next year. ###Long-Term: Horizon 2023 - ? ###Unclear **Compile-Time Function Execution**. `constexpr` is strictly more powerful than `const fn` right now. Yet, at the same time: - MIRI (the interpreter used by rustc) is strictly more powerful than `constexpr`, and it's mostly policies restricting which capabilities it's allowed to interpret; so no technical barrier, only design ones, especially around conditionals. - Rust has vastly more powerful code generation capabilities, between built-in `build.rs` support and procedural macros. As a result, in some cases `constexpr` makes things easier, while in others the problem is more easily solved by using code generation. To illustrate the power of procedural macros, the first incarnation of the Rust `regex` library had a `regex!` macro which would pre-compile the string into the necessary state-machine at compile-time. Some will also tout that the ability of `build.rs` (a full-blown program) or procedural macros to connect to a database, etc... are advantages, and although I am personally dubious of anything which uses non checked-in material as a source to build a program, it's certainly not something that `constexpr` can achieve. **Ecosystem**. C++ has a much wider ecosystem: libraries, conferences, documentation, and "pool". Yet, at the same time: - There is lot of outdated (or outright bad) C++ material there, making it difficult to access quality up-to-date documentation^1 . - 3rd-party libraries are a pain to integrate (it's a snap in Rust). Every single C++ library comes with a "How to install" guide, regularly asking you to install some dependencies by hand first, etc... and we've all experienced the shortcomings of said instructions once in a while. - Both C and C++ developers should be able to pick up Rust relatively quickly. The hard part is manual memory management, after all. This means that you don't need to specifically recruit "Rust" developers (10 years experience wanted!) to work on a Rust application; a C or C++ developer who dabbled in Rust should quickly be up-to-speed, and one which doesn't shouldn't take more than a month or two to be proficient. ^1 *By the way, you can find some quality documentation by checking out the links [in the C++ tag over on StackOverflow](https://stackoverflow.com/tags/c%2b%2b/info).*
That last section is very interesting. How did it go with the C++11 release? I guess many people consider C++20 as big as C++11. Did C++11 have any open ends about lambda's or whatever before it was released?
&gt;C++ doesn't IMHO offer "more maximum performance" than Rust `asm` is an unstable nightly feature so it's not a similarly production ready endgame equaliser. Optimisation to SIMD isn't at the same level either.
I do think the issue is gaining more mind share, though, and while I loathe CMake the wide adoption it has seen has made things a tad easier than when one had to juggle Make, Autoconf, etc... (And to be fair, it's a hard problem; when you see all the horror stories from NPM...)
Well it was called C++0x......
It's ironic that Javascript has a better syntax for await/async then the currently proposed coroutine paper (similar to P1485). The `async` annotation in the linked paper feels like a must.
There! I didn't know about this `impl Into&lt;f64&gt;` type wizardry! That's pretty cool. That's exactly what I was thinking. It reduce a lot of the pain of writing `into()` everywhere.
Well, calling `new` means a global allocator lock, since the global allocator needs to be thread safe, otherwise, how will you reason about anything? The "quarter for $100" is actually said by John Lakos in one of his talks about the polymorphic allocators. &amp;nbsp; Technically, a custom C++11 style allocator has slightly better performance, since it avoids the virtual function call. To extend the analogy, yes, you can get $100 without paying the quarter, but that $100 bill is far away from you and now you need to walk hours to get that bill. Is it worth it? Maybe it is... but most likely the answer will be no.
I do understand that but regarding the compiling, if you take linux as an example, it's never really a big issue as if the binaries are built by the linux distribution maintainers. It's going to be built with the same compiler anyway. If you build your own binaries. Chances are that you'll build everything with the same toolchain. In my case, the plugin part is what's the most annoying. Coming from a very modular platform being unable to have plugins kind of make me want to ditch the idea of native plugins and resort to using scripting languages for functionality extensions. So the platform could have a core library that is native and a scripting api that can be used for anything else. The core can be completely statically linked and it's not a huge problem while the scripting api can be loaded at will too.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/c5w1jg/beginner_friendly_open_source_projects/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; The release of C++2a should be delayed past 2020 As much as I would like shiny new things now, I have to agree.
Removed. Post in the quarterly jobs thread, which will rotate at the beginning of July.
I've measured it. And it does not come in the profiler. What comes (used to come) is HeapAlloc getting serialized at some point, waiting on another HeapAlloc/HeapFree. Once that part of the code was moved to "std::pmr" and default pmr memory_resource changed to jemalloc (could've been really tcmalloc, or tbb's scallable_allocator) - then we no longer see them. Very observable, where a level in our map editor used to take ~5 min to load and now down to 2.5 - the CPU utilization before was about 50%, now closing to 100% (full utilization does not mean good use of it, but in this case we see it). I'm not really worried about virtual function call in front of memory allocator/deallocator - since what happens there would be much more expensive compared to the virtual call... Okay, not always - once we start using more of a "bump allocator" style - then we might some perf decreases, but still compared to what's before - it'll be negligible. We do about ~300,000,000 allocations with jemalloc (in our biggest map), and that's only 30-40% of what we capture - there are unknown much more used by HeapAlloc, etc.
const in signatures is basically just documentation for the caller.
I thought it was about C++40
I suspect most people get their work to pay. Otherwise Bryce's suggestions. Although once upon a time I paid my own way to C++Now (BoostCon at the time). It was definitely worth it career-wise.
Two orders of magnitude a rounding error? Maybe in astronomy.
Well C++0x as it was called back then was seriously delayed and at least one new feature (Concepts) considered essential was purged from the standard again... I'm deeply concerned about the state hinted at by that last section - especially about that part of features being completely unimplemented (anybody else getting serious export-98-vibes?)
Found an [issue about it on Github](https://github.com/abseil/abseil-cpp/issues/297) \- looks like there's no hard schedule, but at least 6 months off.
&gt; "The `&lt;pmr&gt;` header" is called `&lt;memory_resource&gt;`. … &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Thanks, corrected. I was consulting cppreference to make sure I got everything when I originally wrote my reply, so I'm not sure how I missed that… &gt; …And it doesn't contain any type-erased wrappers at all. All it provides is _classically polymorphic_ types. The lack of type parameters is exactly what distinguishes "type-erased wrapping" from plain old (type-parameterized) "wrapping." &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Also fixed. &gt; …`std::function` is a special case because it takes the interface signature (not the wrapped type) as a template type parameter. &gt; &gt; ⋮ &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Ah, thanks: that clears _that_ up… &gt; ⋮ &gt; As a rule of thumb, type-erased wrappers are not followed by angle-brackets: it's `std::any`, not `std::any&lt;T&gt;`. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Sure, gotchya; style canonicalized. (That's not how you'd reference an unspecialized template in code, though, hence the style I was using before.)
I've thought that having consistent behavior with member init-list was also the right thing to do here. But I don't know what can be done at this point... &gt; The only positive thing I can say about this restriction is that at least it is possible to loosen it in the future. This is true? If people are relying on the left-to-right evaluation order, that wouldn't be relaxable in the future, would it?
Also if your checking the systems endianess your probably doing something wrong, and hopefully not reordering bytes.
What's ironic about it?
Maybe I'm missing something, but changing this wouldn't break existing code since it's currently an error to *not* write the designators in order, right? The code that currently relies on left-to-right evaluation in designated initializers is spelled the same as code that would rely on member order evaluation if this behavior were changed to match member init-lists. Unless you were talking about requiring the member init-list be in the right order, then yeah. The codebase I work on doesn't even have the warning for that enabled.
There will be no delay -- the only alternative is to pull everything not deemed sufficiently ready.
It's not fully true that modules are "completely unimplemented" -- the current modules are a mix of two designs implemented and deployed to production in two major companies. So the \*\*mix\*\* of the two hasn't been deployed, the thing they were mixed from has, for a while. I think it's a bit disingenuous to imply we have zero implementation experience with modules.
This does look like an amazing update. It’s much easier to read.
Everyone loves to shit on JavaScript for having goofed up syntax, but it honestly makes a lot of sense to me most of the time.
Thanks, I'll look into it. Quick question: why was overloading operator new not an option?
The only thing with unanimous consensus on the committee is the schedule. We will not delay the standardm
What if the door to the committee meeting place is locked and nobody can find the key?
Is it because it sets a bad precedent for delaying features and the ISO equivalent of filibusters?
The deadline for volunteering was yesterday, according to the website. If there's interest in my free [code generator](https://github.com/Ebenezer-group/onwards), I'd be happy to give a demo at Tool time.
Udacity
There is a god. I really hope this makes it to the final version. This is making me excited for C++ all over again. Take as long as it needs to for the next release.
You can declare the symbols to make it compile, since they won't be used the linker won't complain it doesn't actually exist.
Overload per class is probably the thing to do, but needs more intrusive changes (to the codebase). Also I really like the memory_resource concept, so I'm trying this to be my front "allocator" interface
tnx, Do you have any course suggestion on it? a link or something?
Besides what others have said, lambdas got refined in C++14, C++17 and C++20, so yes, there were open questions about their design when C++11 came out even though the release date was moved back ~4 years. In C++14 `std::boyer_moore_searcher` almost got merged. At the last meeting before C++14 they realized they couldn't figure out the wording that was precise enough. Searcher didn't make it in C++14, but was finalized on the very first C++17 meeting. &amp;nbsp; Bottom line is, there will always be "just one more feature" kind of wishes and you have to ship at some point.
Also as an example of NUMA awareness and use of std::pmr you can check https://github.com/hyrise/hyrise
I guess you have goofed up syntax too.
Ah, taking the Space Shuttle Challenger approach, I see.
You could have a look at the regular C++ course on Udacity. If you are looking for certificate recognized by headhunters from top companies, you can take a glance at the [Udacity nano course.](https://www.udacity.com/course/c-plus-plus-nanodegree--nd213#)
Great news, thank you for all the hard work! However, I'm not quite sure about the "... the Microsoft debugger is proprietary and cannot be used outside of Microsoft tools". If I recall correctly, it is possible to build and debug Windows (MSVC) applications in Qt Creator, isn't it?
Because of C++0x. And human nature.
Is that forcing you to be very on time on the enrolment program or it’s kind of flexible like coursera ?
In an embedded system or something 1.6mb is something. On most machines in the world. 1.6mb is a rounding error. My hard drive capacity might have gone up an down 1.6mb typing this response.
It is relevant if your code for example restores bytes from a file, if the file was stored in a little endian system and loaded in a big endian system, or the other way around. You need to check and potentially reorder bytes.
To be fair, *syntax* is not really what JavaScript gets wrong (ignoring optional semicolons). Most of the wacky shit in JavaScript stems from its "type" system.
The important bit is this though: rust will not allow you to move a value (in this case rebind a const as a mut) as long as there are references to it. That means that if an immutable reference exists to an immutable object, the computer will ensure that that object will not change as long as the reference is live.
Devil's advocate here: But what if you fall to allocate the object pool? Wouldn't you try to suffice with a smaller pool? I'm a rust fanboy, but that's admittedly something that worries me sometimes
I didn't take the Udacity C++ nano course. My friend took the Udacity Self-driving nano course, which is more rigorous than the C++ nano. She told me that it was not self-pacing like Coursera but manageable.
Custom allocators and object pools are not replacement for one another. They are complementary.
&gt; It's still not trivial of course (what parts of c++ are) On the other hand, what parts of allocators, even outside C++, are trivial?
The keywords should have been async, await, yield from the get go like in most other languages. Sorry for the 0.00001% (hypothetic, I hope it's even less) codebase broken by this change but C++ must move forward. Maybe C++ committee should reserve most of common keywords encountered in other languages today for future usage so that such papers like this are not blocked.
&gt; the current modules are a mix of two designs implemented and deployed to production in two major companies. could we get someone from google or fb actually tell us about the module system they use ?
Nooe, Qt Creator uses GDB.
This is my use case. ;-) &amp;#x200B; If writing time is important, the file format must support both. This way you can always perform a possibly necessary conversion during time-uncritical loading.
&gt; Sorry for the 0.00001% (hypothetic, I hope it's even less) codebase broken by this change but C++ must move forward. I think you're being overly optimistic. [yield](https://codesearch.isocpp.org/cgi-bin/cgi_ppsearch?q=yield&amp;search=Search) [await](https://codesearch.isocpp.org/cgi-bin/cgi_ppsearch?q=await&amp;search=Search)
&gt; Sorry for the 0.00001% (hypothetic, I hope it's even less) codebase broken by this change but C++ must move forward. life sucks ``` /usr/include % rg ' yield\(' !10457 c++/v1/thread 74:void yield() noexcept; 474:void yield() _NOEXCEPT {__libcpp_thread_yield();} c++/9.1.0/thread 353: yield() noexcept tbb/tbb_thread.h 319: inline void yield() { internal::thread_yield_v3(); } boost/fiber/context.hpp 296: void yield() noexcept; boost/fiber/operations.hpp 33:void yield() noexcept { 59: yield(); boost/fiber/scheduler.hpp 129: void yield( context *) noexcept; asio/impl/spawn.hpp 378: const basic_yield_context&lt;Handler&gt; yield( glibmm-2.4/glibmm/thread.h 341: static void yield(); glibmm-2.4/glibmm/threads.h 196: static void yield(); OpenImageIO/thread.h 174: yield(); 669: yield(); irrlicht/IrrlichtDevice.h 77: virtual void yield() = 0; llvm/IR/LLVMContext.h 300: void yield(); boost/asio/impl/spawn.hpp 379: const basic_yield_context&lt;Handler&gt; yield( boost/coroutine/detail/symmetric_coroutine_impl.hpp 87: R * yield() 227: R * yield() 374: inline void yield() boost/thread/win32/thread_data.hpp 187: void BOOST_THREAD_DECL yield() BOOST_NOEXCEPT; boost/thread/pthread/thread_data.hpp 248: void BOOST_THREAD_DECL yield() BOOST_NOEXCEPT; boost/thread/detail/thread.hpp 550: static inline void yield() BOOST_NOEXCEPT boost/polygon/detail/polygon_45_formation.hpp 2214: inline ActiveTail45* yield() { return p_; } boost/polygon/detail/polygon_formation.hpp 618: inline ActiveTail&lt;Unit&gt;* yield() { return p_; } 666: inline ActiveTail&lt;Unit&gt;* yield() { return p_; } boost/polygon/detail/polygon_arbitrary_formation.hpp 2206: inline active_tail_arbitrary* yield() { return p_; } boost/smart_ptr/detail/yield_k.hpp 16:// void yield( unsigned k ); 20:// for( unsigned k = 0; !try_lock(); ++k ) yield( k ); 81:inline void yield( unsigned k ) 131:inline void yield( unsigned k ) 173:inline void yield( unsigned ) corvusoft/restbed/session.hpp 83: void yield( const Bytes&amp; data, const std::function&lt; void ( const std::shared_ptr&lt; Session &gt; ) &gt;&amp; callback = nullptr ); 85: void yield( const std::string&amp; data, const std::function&lt; void ( const std::shared_ptr&lt; Session &gt; ) &gt;&amp; callback = nullptr ); 87: void yield( const Response&amp; response, const std::function&lt; void ( const std::shared_ptr&lt; Session &gt; ) &gt;&amp; callback = nullptr ); 89: void yield( const int status, const std::string&amp; body, const std::function&lt; void ( const std::shared_ptr&lt; Session &gt; ) &gt;&amp; callback = nullptr ); 91: void yield( const int status, const Bytes&amp; body = { }, const std::function&lt; void ( const std::shared_ptr&lt; Session &gt; ) &gt;&amp; callback = nullptr ); 93: void yield( const int status, const std::multimap&lt; std::string, std::string &gt;&amp; headers, const std::function&lt; void ( const std::shared_ptr&lt; Session &gt; ) &gt;&amp; callback = nullptr ); 95: void yield( const int status, const Bytes&amp; body, const std::multimap&lt; std::string, std::string &gt;&amp; headers, const std::function&lt; void ( const std::shared_ptr&lt; Session &gt; ) &gt;&amp; callback = nullptr ); 97: void yield( const int status, const std::string&amp; body, const std::multimap&lt; std::string, std::string &gt;&amp; headers, const std::function&lt; void ( const std::shared_ptr&lt; Session &gt; ) &gt;&amp; callback = nullptr ); log4cplus/thread/threads.h 47:LOG4CPLUS_EXPORT void yield(); opencv4/opencv2/gapi/gkernel.hpp 55: // yield() is used in graph construction time as a generic method to obtain 64: static inline cv::GMat yield(cv::GCall &amp;call, int i) { return call.yield(i); } 68: static inline cv::GScalar yield(cv::GCall &amp;call, int i) { return call.yieldScalar(i); } 72: static inline cv::GArray&lt;U&gt; yield(cv::GCall &amp;call, int i) { return call.yieldArray&lt;U&gt;(i); } 179: static std::tuple&lt;R...&gt; yield(cv::GCall &amp;call, detail::Seq&lt;IIs...&gt;) 192: return yield(call, typename detail::MkSeq&lt;sizeof...(R)&gt;::type()); boost/interprocess/sync/spin/wait.hpp 99: void yield() CLucene/ext/boost/smart_ptr/detail/yield_k.hpp 15:// void yield( unsigned k ); 19:// for( unsigned k = 0; !try_lock(); ++k ) yield( k ); 61:inline void yield( unsigned k ) 97:inline void yield( unsigned k ) 139:inline void yield( unsigned ) ```
Qt Creator can use GDB, LLDB, CDB...
Ofc, my point was, that it doesn't use MSVC debugger.
Thanks a lot!
Yeah i was replying to the part about C++ analyzers needing to do runtime checks. The Rust borrow checker also can't catch all errors at compile time therefore forcing you to do runtime checks, whereas c++ gives you this option, but you dont have to pay for runtime checks in your released builds
At Google, we use Clang header modules (and have done so for several years), at least for the most-commonly-used headers in our main C++ codebase. That module system is essentially the same as the "header units" in the module system in the current C++20 draft, except that we don't use the `import "header.h"` syntax and instead rely on include translation and `#include "header.h"` syntax -- we're not on C++20 yet, so we don't get the new syntax. I gave a talk on this at CppCon in 2016, which covers what Google was doing at that time: https://youtu.be/h1E-XyxqJRE (usage stats at 18:40). I don't know exactly what the numbers are now.
what do you mean ? it can use both the MSVC debugger ("Debugging Tools for Windows", the one that comes with visual studio when you install it) and CDB which comes with the windows SDK
Manipulating types also won't let you implement Catch2, while procedural macros would make the implementation much saner. Different features for different things..
I think keywords and function name don't overlap. void override() { int final = 0; } This is compiling. Would it be different with `yield`?
well, yield is supposed to be used in the function bodies...
Which OS do you use written in C++?
Do you remember how well handled were the tooling author's misgiving about module models? Because I do.
Use Rust's governance model. In other words, stop making it near-mandatory to be able to attend expensive in-person meetings in often expensive locations, and instead make it accessible to people who are not sponsored by a big company or cannot/do not want to burn a lot of their own personal money.
Which might be sensible for the lesser ready features - this paper should not delay coroutines though, if we can agree we want it
Man this is so apt. There does seem to be a fairly extreme rush on getting c++2a out of the door, I worry that we're going to end up with a lot of half baked features just so that we can have 'new shiny'
That’s a bit of a misrepresentation. Not all ostensibly-rushed projects end up metaphorically like the Challenger. But we of course remember the bad outcomes (confirmation bias).
I have to admit, c++ is the only language, where I ever dealt with custom/hand written allocators. So I can't really say, but you are probably right.
Being much easier to write GUI and games code, with plenty of mature options available. First class support on Apple, Google and Microsoft respective OS SDKs.
Modules are implemented per the general understanding the committee has of implemented - but we don't really now for sure how proper modules (that are not header units) behave at scale and don't really have a good tool story and have generally no idea how they will be adopted. Modules do require build systems support and build systems really are not ready. There is not enough good deployment story yet and getting implementers to implement something that behave similarly across platform is challenging I'm still very much unconvinced about module partitions (which is a push toward big modules - big libraries being a source of slow compile times since you end up building way more things than you actually will link), and the general design of 1 interface + n implementations files which is very much a direct copy of the sources + headers model that isn't necessarily representative of the actual language where a decreasing number of entities can be defined in an implementation (constexpr, concepts, templates, function that you want to inline, functions whose type you want to deduce etc) this lead to some interesting questions about inline and static: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1604r1.html http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1498r1.html I'm note sure modules preamble add anything of value either - one could simply import a module interface unit, would make the design slightly simpler, code a bit cleaner I also failed to convince any one modules would have been a good opportunity to support hoisting outside of class context https://godbolt.org/z/5PYxld - i didn't fought very hard, i realize that way too late Overall, modules will be workable in the long term - don't expect to be able to use them day one. They certainly could have been better in my opinion but I don't know if at this stage pulling them out would be helpful
The problem is they were incremental updates. Most of current stuff is different. If you for example settle on co_await keyword I don't think u will ever get await keyword later.
I can't argue with that, however my point of view on this specific thing is, hey, it's a cosmetic syntax difference, so get over it and let's spend time and cpu cycles on more important issues.
This is not an issue if yield and await are only considered keywords in functions annotated with async and async itself only considered keyword in the annotation.
override, final, import, module are context sensitive keywords - only keywords in specific places
&gt; I also failed to convince any one modules would have been a good opportunity to support hoisting outside of class context https://godbolt.org/z/5PYxld - i didn't fought very hard, i realize that way too late Oh, that would have been so cool. It is the single reason I still sometimes use classes entirely made of static functions, because I like to order my code top down and not bottom up. Of course you can always forward declare functions, but that is just adding noise and making changes harder for no very good reason.
That creates a different problem - compiler writers hate contextual keywords. Pick your poison.
That doesn't even always work - some types are very tedious, very hard to spell or implementation defined which is why there is automatic return type deduction - which you can't forward declare
You see the core problem here is not the naming, but not being able to understand if a function is coroutine or not without trimming it? Yes, await is preferable to co\_await, but if it is going to break backwards compatibility, then not the biggest deal.
If you mark function body with async you don't have a problem with await &amp; yield anymore. That's the purpose of the proposal. And async itself is contextual so there is no issue
Yes, it is just a workaround and not a very good one I admit. Forward declaring a return type of a lambda or something based on it (lambda type is a template parameter of the return type) is impossible.
The problem here is not about one more feature. It is about making sure the existing features don't have fundamental design flaws that can not be fixed later. That being said: I really don't care about co_await vs await and I don't know about the various features in general to say if there are any really problematic points left.
Sure, but there is no control whatsoever what kind of exceptions might be thrown. And that is not very type safe, which C++ is all about.
so what happens with `std::async` then? Because I can't imagine it coexisting with the `async` keyword
 &gt; If you mark function body with async you don't have a problem with await &amp; yield anymore I don't understand how it makes task&lt;..&gt; f() async { int yield; yield yield; } any better ; also there's the problem of people defining await and yield with macros.
No, I think I misspoke here. I was thinking about "breaking" people's expectation of left-to-right order but that is exactly the thing this proposal would be changing. If you're willing / have the time, please write a proposal to change this behavior!
I seem to recall that while it's a problem worth solvable, there wasn't consensus on the approach and most people are scared to change how lifetimes in C++.
I do not believe that is entirely accurate. The last talk I saw with Bjarne was an introduction to Concepts. A good talk, by the way.
Rude
&gt;compiler writers hate contextual keywords Do they?
`async` here is a "contextual keyword" - `std::async` is never valid there, and the proposed `async` is never valid in a code scope where `std::async` could be.
PeakAndrew, the lack of high-performance database kernels in open-source that you mention caught my eye. Are you able to give examples of commercial codes that fit the high-performance characteristic that you mention or that you are particularly familiar with? Do you happen to have any references to design techniques that are commonly used in the high-performance kernels you mention - in particular the hardware interaction that you mention in other comments?
&gt; I don't know about the various features in general to say if there are any really problematic points left. I believe I've been following what's happening fairly closely and here's what questions can bee discussed regarding the features that Arthur mentioned: - Concepts use CamelCase and committee doesn't like upper case letters, so Bjarne and a few others submitted a paper for Cologne to change them to snake_case. - Coroutines have ugly keywords, but so what? There were other discussions regarding their implementation, but it was decided "let's have coroutines now instead of spending time and money for an alternative design and maybe get them in ~10 years". - Modules design is currently a Frankenstein's creation based on two already existing implementations, so while some concern regarding "hey, we need to learn/teach how this thing is used" is well placed, saying it's completely unimplemented is not quite right. - `operator&lt;=&gt;` has a lot of details that C++ should get right, otherwise there will be a lot of moaning. Stuff like "should `operator&lt;=&gt;` also provide `operator==`, considering containers" is important, but whatever is the final design you'll be able to do everything as efficiently as you could, though you might need more boilerplate than what would be optimal. Granted, this is something I haven't followed closely, so maybe I missed something, but I do have enough trust in the committee to not worry about something as simple as an operator. - I'm not sure what is Arthur referring to when he says `constexpr new`. Is it something like having an allocation and a deallocation in the same scope or are we talking about arbitrary `new` statements in `constexpr` context? Either way *some* experience does exist - clang is able to optimize away simple pairs of `new` and `delete` and there was even an implementation of `new` that "promotes" the storage to `.data` segment, so it is accessible, but readonly at runtime. This first implementation had flaws that I don't know anything about and we probably won't get something like this in C++20. The simpler version of paired allocation and deallocation might be in C++20 and yeah, compilers will need to "wise up" to understand that kind of concept. So we'll see about this one. - Ranges heavily depend on Concepts, so pulling Concepts off the table means pulling Ranges off the table too. &amp;nbsp; To summarize, of 5 features (not counting Ranges), 2 are debated over correct spelling, 2 require a bit of faith in the committee and/or compiler/tool writers and only 1 needs to be thought through enough to not make that feature accidentally really hard to implement. &amp;nbsp; Disclaimer: I have *not* read every paper that went through C++20 committee meetings, so it definitely is possible that I missed something regarding any of these.
That's a perfect example of where it's not relevant. Obligatory [byte order fallacy](https://commandcenter.blogspot.com/2012/04/byte-order-fallacy.html) reference.
The reason contextual keywords are not liked (I don't know if "hate" is too strong a word) is because you need to keep track of context to know what a specific token means. By itself it doesn't sound so bad, but C++ already is hard to parse due to all the ambiguities. Contextual keywords always add new ambiguities and require context tracing (it's in the name). Obviously, looking just at `return foo;` you can't say if it's the today's `return` or P1485's equivalent of `co_return` without checking if you're in a regular or `async` function. &amp;nbsp; That said, you have a point. On the other hand, I am not a compiler developer, so maybe this change wouldn't cause that many headaches.
What is the current size of your messages?
If you use TCP you shouldn't be worried of message sizes as the stack handles it for you. For UDP you'll need to think of splitting messages into multiple fragments anyway, as unless you have small fixed length messages, regardless of compression used you there's a chance you'll exceed packet size sooner or later. For compression, I'd pick zlib by default, or some other compression algorithm/library lots of which are available now, depending on your requirements to compression/decompression performance and desired ratio. The only advantage of RLE is that it's easy to implement, but you're better to not implement the compression by hand and just take an existing proven solution instead. You may also play with serialization implementation you use. For instance, Google protobufs offer variable length encoding for integers (e.g. small values need less bytes to store) and offer other advantages like forward and backward compatibility and arch portability. Carefully crafted binary protocol may be more effective, but may be harder to extend and prone to portability issues. In some cases a well compressed text protocol would be no less effective than either of them. All depends on your data.
Thanks for the clarifications, this sounds way less disturbing than Arthur's condensed list.
A function being a coroutine is an implementation detail. It doesn't matter to the caller. All that matters is the return type, and how you interact with it. It is possible to return an Awaitable from a function that is not a coroutine, by design.
[This](https://medium.com/dailyjs/parseint-mystery-7c4368ef7b21) was a fun read: about why ['1', '7', '11'].map(parseInt) returns... `[1, NaN, 3]`?
The largest message is about 2051 or so bytes, and I'm concerned it will be too slow in realtime, over the internet. Right now I only tested on LAN.
That's true for the caller, of course. But I guess /u/eyes-are-fading-blue was thinking of people who were trying to understand the *implementation* of a function.
I forgot to mention contracts, so read my above post again.
Ok, that sounds somewhat large if you aim to utilize UDP over the internet. IIRC, 508 bytes is considered a safe payload size (576 - 60 [IP header] - 8 [UDP header]). Depending on the contents of the messages, a 4:1 compression may be achievable, but I think some other tricks would be needed in order to shrink the messages down a bit.
Qt Creator uses CDB on Windows. We experimented with it and hit a number of issues, the main one is that CDB is too slow on large binaries with lots of PDBs. Visual Studio uses its own debugging engine (unrelated to CDB), and if we wanted to provide a debugging experience comparable to VS, our only option was to make LLDB work better with binaries produced by the MSVC toolchain.
Is this actually the first time someone proposed a way how we can have coroutines without co\_\* keywords while not breaking backwards compability? &amp;#x200B; If yes - please spare us from the silly co\_\* dance.
You missed my point- Rust gives you the same options *plus* more powerful compile-time-only checks. After that it's just a question of defaults.
Unfortunately, some people will never listen and instead believe reinterpret_cast and memcpy are how you deal with streams of data, yet then seem to think they fix their code for endianness issues by swapping bytes.
Thanks for your help, I will check this.
Thanks for the more detailed discussion. As I said: I don't worry too much about spelling either, but it is actually one of the things that can't be "refined" later, so there is only one shot to "get it right" (Again, I'm not really worried about it - just saying). What does worry me a bit is that almost all major c++20 features are undergoing design changes almost till the very end, which doesn't give the final design a lot of time to be reviewed and tested. Put it differently: If people find new flaws after the N-1 meeting that get fixed in N (where N is the last meeting that allows design changes), it is hard to have confidence that a) all problems where really found and b) that the latest set of changes didn't introduce new problems. &gt; Modules design is currently a Frankenstein's creation based on two already existing implementations [...] saying it's completely unimplemented is not quite right. I think the question is not, if modules as currently specified can be implemented. The question is if they can deliver / are sufficiently useful. Whenever there is a question about performance, we tell people to measure and not to rely on their intuition. Same when designing an API: You need users that actually use your library to be able to say, if an API is really intuitive. I do trust the committee, but I'd feel more comfortable if there where actual implementations of the final design available that people had some time to experiment with. Anyway. Personally, I don't have any influence on what gets standardized and what doesn't and I'm also not an expert anyway, so I decided not to worry too much ;)
Note that the two code snippets are invalid. The first lacks a ```}``` and probably a ```break;``` in ```case 1:```, the second lacks ```{}``` of the switch statement, even though the lines are there.
I noticed, and was confused, by the missing `break`. I thought it was part of what was being attempted.
I wonder why we cannot go for some syntax similar to what Swift uses. In Swift, keywords are reserved (like C++), but you can use them as an identifier by using \`. func `func`(): Int { return 10 } `func`(100) The biggest advantage of this is that the compiler knows that everything with a \` is an identifier and there's no ambiguity while parsing. Whenever a new keywords gets added, it's easy to add back ticks to all occurrences of it (we could have tools for it). https://docs.swift.org/swift-book/ReferenceManual/LexicalStructure.html#ID412 You can even have members and functions with name `class`. That would be nice for reflection libraries (no more ugly `clazz` or things like that).
Yes, spelling can't be changed later, but again, so what? Anyway, no point dragging this part of discussion, since we do agree on this point. All the other points of committee discussion might be possible to get refined later on. With Contracts, just make that thing in question UB and when we figure out something better, just amend the standard, since it was UB no one could have been relying on it. For `operator&lt;=&gt;` a safe bet would be to never provide `operator==` in case there's no way to figure out in which cases is "`operator==` from `operator&lt;=&gt;`" sufficient. I'm sure others will be figured out too. &gt; Modules You make a fair point, though you might want to check [this](https://old.reddit.com/r/cpp/comments/axnwiz/cmake_gcc_module_proofofconcept/) out.
Rust also allows multiple references to mutable data, through `Cell` and its variants. And on the other hand, C++ const provides basically nothing- a const pointer's target can still be modified by someone else.
&gt; Most of the wacky shit in JavaScript stems from its "type" system. or lack thereof
Actually, I didn't say that completely correctly. In fact, each time you need an object and all the pool objects are taken, you DO allocate one more. It's just that you never drop any objects and reallocate them. So it's not all pre-allocated and it does use the heap, so it doesn't need to be allocated to a worst case size up front. It just avoids ever creating more objects that are needed at an one time. Assuming you are accessing objects fast enough to warrant even doing such things, it will be a big win. There will be occasional allocations if the need exceeds the current high water mark, but it'll quickly get sufficient capacity and won't need any more. I have two flavors. One is for 'fixed size' elements, and one for variable sized elements. In the latter you indicate a capacity and it will find the available element with the capacity closest but not smaller than that capacity. So it tries to minimize memory usage at the cost of having to binary search the free pool for the best match, and again to put a returned element back in the list at the sorted position. The fixed size one doesn't make that distinction so it can just grab the last one on the list and put any returned ones back on the end of the list. It's good for something like, say, CD ripping, where every element is the same block size.
You said desktop apps
This just making `co_return` to simply be `return` worth it. Even if we don't change other keywords. Also, marking the definition makes it much clearer, both for the programmer and the compiler.
Previous discussion from a couple of days ago: https://www.reddit.com/r/cpp/comments/c59h3o/the_power_of_hidden_friends_in_c_article_by/
The concept of this is really cool and will help us 'old school' style programmers learn more on when and how to learn constexpr better. I don't agree with all the new stuff being introduced in c++, but constexpr I definitely do like a lot!
Did not see that coming
It seems trivial to me to support contextual keywords by augmenting the grammar like this: async : "async"; await : "await"; ... identifier : async | await | ... | \w[\w\d]* That way the keywords are always keywords to the lexer, but the parser can handle it.
Another compression library worth looking at is Google's snappy: https://en.m.wikipedia.org/wiki/Snappy_(compression). This is what Valve's Source engine uses to compress networked data.
What kind of systems do you work with that use big endian, out of curiosity?
The point is that by requiring the user to explicitly specify \`async\`, the user is always acknowledged in the change, thus no existing code will be silently broke.
That's a single executable that only links with the standard library. Real programs link with many more libraries. Also, the space is not only consumed on disk, but at all levels of the memory hierarchy. I'll use my workstation as an example: * Persistent storage: /usr/bin contains over 2500 linked executables, which at an additional 1.6MB each would be 4GB additional storage necessary just for my OS installation. * Main memory: I currently have 349 unique executables running. At 1.6MB per executable, that would use an additional 556MB of RAM. * L3 Cache: Let's say my 6-core hyperthreaded processor is currently executing threads from 4 unique executables. With static linking, the working set has increased by 4.8MB, which is over 1/3 of my total L3 just to hold duplicate copies of standard library code.
You hit the nail on the head. I didn't really want to open this can of worms on an old thread about something else, but C++ has always struck me as strange in this regard. On the one hand, huge effort is put into features for abstraction and reuse of code, customization points, and a host of other complex advanced language facilities targeted at library writers. There is a lot of emphasis on supporting the writing of libraries with nice flexible and extensible interfaces. On the other hand, the inherent ABI instability of all the libraries these features enable makes them unusable in many environments!
&gt; constexpr everything! please don't
It's correct in the godbolt link interestingly enough.
&gt; spelling can't be changed later For the coroutine syntax issue, it seems like the new syntax *could* be adopted later, because it specifically doesn't conflict with existing syntax. So just because the committee adopts the `co_` language now, doesn't mean we couldn't get `async`-tagged functions later. But I doubt they'd add two syntaxes for the same feature unless there was a compelling reason to do so.
&gt; thus no existing code will be silently broke. No existing code will be broken, but it's worth thinking about the fact that you'll have functions that you "can't" call from within a coroutine.
Looks good, but what's the purpose of the virtual inheritance in the handlers? If i need to inherit from some class in order to use a library I usually look elsewhere since it puts unnecessary constraints on my code.
Is this a bad idea because of the risk that an implementation change down the line could inadvertently change the interface?
Yes, but it’s straightforward only relative to what it used to be. But yeah, C++17 is definitely a game changer.
well, AFAIK windbg has separate debugger engine nowadays, maybe you could use it as well &amp;#x200B; It is used in WinDbg Preview
I *love* constexpr... but ... Making everything constexpr could slow down builds because functions definitions must be available in every TU where they’re used. Also IME non-trivial constexpr code is almost an order of magnitude more difficult to write in a way that works with multiple compilers. I’m hopeful this will continue to improve.
Hello and thank you for comment! Other solutions of this problem do not look safer or more convenient. What do you want see instead this? static function with user pointer like pure C API?
It’s like saying “inline” all the functions
I don't know what you're referring to.
Everyone has a different opinion of which features are more or less ready.
Yep. The question is how strong the consensus is, how fixable it is in the future, what's the cost of not fixing it. contracts is the one thing that is still extremely divisive. Coroutines have interesting future direction that require a few changes.
lz4 is [https://github.com/lz4/lz4](https://github.com/lz4/lz4) another great option, it also has the ability to give it a pre-defined dictionary which is great for further reducing overhead of compression of small amounts of data (such as network sends).
&gt; It landed last year. You are referring to non-lexical lifetimes, which is a huge step in the right direction. By "it" I meant [Polonius](http://smallcultfollowing.com/babysteps/blog/2019/01/17/polonius-and-region-errors/), the "*really* sophisticated" lifetime inference that I left unnamed. Sorry, I should have been more clear. Following on your last sentence, I do wonder about the extent to which maximally sophisticated lifetime inference will *increase* confusion about lifetimes. It's a little like the noble experiment that the C++ standards committee is currently doing with copy elision. [Will copy elision make programmers less vigilant about copies](https://www.youtube.com/watch?v=lkgszkPnV8g&amp;feature=youtu.be&amp;t=2882), particularly since [the copy elision rules can be subtle and complicated](https://en.cppreference.com/w/cpp/language/copy_elision)? So with lifetimes, when a lifetime cannot be inferred, will we just be really confused? "It works here, why doesn't it work there?" &gt;&gt; This was this biggest blunder of Rust, in my opinion. &gt; While that may be true, it's easy in retrospect, but it was not as obvious at the start. Lexical borrowing seemed natural, after all, following the lifecycle of the references themselves. It certainly isn't obvious to *everybody*. Without intending any condescension whatsoever, it *is* obvious to language designers and, especially, to programming language theorists (researchers in the academic field of programming languages), which is a very small demographic. But I am speaking with the benefit of hindsight. While I think this was their biggest blunder, I *am* talking about an accomplishment only a handful of people in the history of programming languages have achieved, after all. I have the utmost respect for Graydon Hoare and Niko Matsakis and the rest, all of whom have more talent in their little finger than I have in my whole body. I can only dream of having the opportunity to make such a blunder!
&gt; So with lifetimes, when a lifetime cannot be inferred, will we just be really confused? "It works here, why doesn't it work there?" Well, it's already regularly the case so... :p
The blog software ate some characters. I’ll fix it shortly.
Contacts are divisive but also deeply wanted. I'm torn about whether throwing it out or patching it up would be best for the feature and community.
We are heading towards the entire C++ standard libraries being in one header and your application being in another (which is in the form of the one of the 5 million standard template program algorithms.) #include &lt;programs&gt; int main() { Program&lt;programs::WebSrv, std::BlockChain, std::AI&gt;(); }
Or you hurt performance from blowing out your icache