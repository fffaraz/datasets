If a site might be interesting for crackers, you might want to block the said perpetrators. isocpp was probably very attractive.
Kinda sounds like what scylladb does
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/agm8rk/syntax_error_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
[https://imgur.com/a/yiH7Qvl](https://imgur.com/a/yiH7Qvl)
Technically `std::optional` does as well, just via `std::reference_wrapper`.
Well. Eventually that will exist in one way or another. Generators need language supoort though to be really nice to write.
Yes, but that's kind of like saying `std::optional` can support zero, one, or many elements, because you can stick a `std::vector` in it.
I don't believe that Boost libraries should continue to aspire to standardization. The standardization process is a victim of it's own success. It has evolved into "Design by (part time) Committee". It has resulted in adding components that are way too complex to be "cast in stone". We now have scheduled for 2023 a networking library - while we have a good one (ASIO) which has been available for at least 10 years. Others proposals such as linear algebra and GUI graphics will be obsolete before they are actually available. Sometimes things have to get bigger. But not always. As a process, adding libraries to the standard has passed the point of diminishing returns. We've passed "peak C++"
Macros are evil.
```cpp template&lt;typename T&gt; using Ptr = T*; ```
Seems like Eric Niebler likes complicated examples to show what ranges can do. More on topic, I don't consider myself an expert, but for me ranges can't come soon enough.
The drawback of such approach is the increased number of keywords which is already quite large. I think the general direction of the standards committee is to reuse existing keywords where it makes sense, even if it leads to such obvious awkwardness as `requires requires`.
Did you look at precompiled headers for memory and functional?
FYI, the link to the Scylla GitHub page is broken (has a semicolon at the end).
I don't know why C++ w/ Modules couldn't have what Rust has with the "Editions" system. For those unaware, when you write an executable or library in Rust you tell it what "edition" of the language you are using. Claiming a particular edition enables / deprecates / removes features from the language. However, you are still able to pull in and use libraries from other editions of the language. 
Yes, long time ago, but the buildsystem complications and other issues were not worth it. It usually needs a different PCH for every set of compiler flags, which for me meant having one PCH per library or test exe. And, with having 10+ libraries and 200+ test cases the overhead of generating them was bigger than potential benefits. In the blog post I tried the Modules TS, but that did not convince me either ... yet :)
Hmm I will see about that. But like 50% of what you have with the same functionality is probably possible. 
but boost is able to optimize the T&amp; case by storing it as a T* in that case, which is legally impossible in C++ due to the aforementioned UB restriction on specialization. 
One day we'll get both forward-declaring headers and minimalist-include headers from the standard that only hand us what we need...
And more likely to be used.
I don't question the feasibility of code migration, but we are talking about why Boost want to keep some of the old libraries instead of dropping them.
I hope so, but I'm not sure if it ever happens as the focus is solely on modules :( For some types a minimalistic forward declaration also might not be possible without ABI breaks (due to the way the default template params are done, for example).
 template&lt;typename... Args&gt; T* alloc(Args&amp;&amp;... args) { T* p = stack.pop(); if (p != nullptr) return p; p = (T*)memory_provider.alloc_chunk(sizeof(T)); new (p) T(std::forward&lt;Args...&gt;(args)...); FlagLock f(lock); p-&gt;list_next = list; list = p; return p; } void dealloc(T* p) { // The object's destructor is not run. If the object is "reallocated", it // is returned without the constructor being run, so the object is reused // without re-initialisation. stack.push(p); } Why TypeAlloc::alloc doesn't always run constructor and dealloc never runs destructor? Looks really hazard without any benefit. There are quite limited cases where I see that user wouldn't want/need allocated objects initialized and destructed as expected, but usually then the type is POD and has no-op default constructor and destructor.
I don't understand why people stuck on pre-C++11 would want to use a new version of boost anyways. It's not like Debian Lenny comes with boost 1.69.
I work at NVIDIA, and we use docker internally for a bunch of stuff. I haven't had any issues using it with GPUs.
In a truly async program (i.e. that does not use periodic polling but the event loop thread sleeps while there is nothing to do), an OS-specific facility is used to sleep until something which requires a reaction happens. Examples of such facilities are: Linux (from worse to better): select(), poll(), epoll. Can be combined with things like timerfd, eventfd and signalfd. Windows: WaitForMultipleObjects, WSAPoll, WSAEventSelect, IOCP, and many more. Others: kqueue (Some BSDs and Mac OS X). This is how it's done irrespective of what kind of abstractions are built on top.
I absolutely agree, but have heard varying opinions about that. Some people in the community seem to believe that there is a significant body of c++03 projects that want to use the latest boost libraries, which then would stop using boost. I sometimes believe the only 03 projects that use the latest version of boost libraries directly are other boost libraries... Actually I created a straw poll about this some time ago, but didn't get too much feedback. Apparently the are at least some 03 projects using a recent version. 
I tend to cross read a lot of things. In this case I guess I just read "dependencies" and "docker" and then read the actual text :).
&gt; Vendoring dependencies isn't really the C++ way Oops. Says me + tons of large C++ projects.
Did you tried the EASTL implementation? It has equivalent for pretty much everything in the std but with big concern regarding compilation time and minimal runtime overhead. 
Wasn't this already posted a few days ago? Anyway: it's crazy there is no cmake switch to just get a timing per translation unit.
I am working on a concept TS based library for a while. require require seemed odd to me at first, but I get used to it pretty soon. Now, it isn't confusing at all. I found inconvenient that I can't define type alias in a require expression, but extra namespacing solve that. I see people saying you shouldn't use concept for trivial syntax checking sort of thing. I agree fundamentally, but also I think require expression is the best tool for that kind of check. So, I still use concept for trivial checking but put them in a private namespace.
I will add, avoid macros whenever possible. &amp;#x200B;
test comment, please ignore
std::unique_ptr??
I hope they change the direction to allow writing easier to understand code.
Everybody needs a box of soap.
Fair enough. I can see your issues here. It seems like a mistake to have one header for both unique and shared pointer, when unique pointer is both substantially more ubiquitous and simpler than shared. Also, I don't actually agree with this: &gt;Main use of this stan¬≠dard type is to al¬≠low stor¬≠ing ref¬≠er¬≠ences (or non-nul¬≠lable point¬≠ers) in var¬≠i¬≠ous con¬≠tain¬≠ers The main use case of reference wrapper is actually to allow for passing references into functional objects, where if a raw reference were passed it would result in a value type being deduced potentially. E.g. in std::thread constructor. That's why its in functional. I think std::bind was actually a big part of the original use case for reference wrapper. If you want to put something in a container, I would just put raw pointers, or something like observer\_ptr (or a non-nullable version of observer\_ptr). The thing is that while a reference in principle is nicer, reference wrappers I find are ugly because you can't call member functions directly. With a pointer or pointer-like class you have \`-&gt;\`. Regardless thanks for actually writing a nicely balanced post, lately the blogosphere has been lots of people just going crazy on either trashing everything in the STL/C++ or supporting it unconditionally without giving reasons in either case.
RHEL has DevToolset with pretty recent compilers though.
yes, you already got D. And turns out no one use it.
Yep, but that doesn't help on the ARMs, so we didn't move to it yet.
D has different semantics (e.g. garbage collection) and as far as I know you can'T mix and match c++ and D code, wheras you could mix and match c++1.0 and c++2.0 code as long as they reside in different modules.
Probably because they put so much effort into those libraries that it seems a waste to get rid of them (sunk-cost fallacy).
No. And I have already answered that. Put it another way: because people are still using them and dropping those libraries will break their code.
I checked it out back in the C++03 days but it wasn't really getting updated for C++11 so I kinda lost interest. No idea how it is now.
Is there a paper or site describing the ‚Äúnovel message passing scheme‚Äù mentioned in the readme?
&gt; Its proponents have claimed that it has basically the same principles ("leave no room for a lower-level language") but in practice, it's a lot farther from that than C++, and it seems to be a lower priority than safety. Interesting, in my experience with both languages I'd argue that standard Rust is leaner than standard C++. For example, there is no RTTI in Rust. That is, just because you use run-time polymorphism doesn't include a whole hoist of type information in your binary that you may never need; unlike C++ `virtual` keyword. Do you have cases in mind where Rust has run-time overhead that C++ doesn't?
Just eondering: - Is there no newer compiler for your system or why don't you upgrade? - are you using most recent versions of boost?
CMake does build configuration, no actual building. If they supported that then that'd mean they'd have to figure out how to do it across all build systems. Not happy times.
&gt; That's why i will never support a breaking change in C++. That's exactly the key point, though: it's not breaking. Instead, the goal is supporting both versions of the language in a single codebase so that you can migrate incrementally and mix and match libraries of either version.
&gt; There‚Äôs another case where we have a member when the type is non-empty, otherwise we just alias the type: &gt; &gt;static if (stateSize!Hook &gt; 0) Hook hook; else alias hook = Hook; &gt; &gt;Which actually we can do even easier in C++ with our new attribute: &gt; &gt;\[\[no\_unique\_address\]\] Hook hook; I don't think this works. In the first branch of the \`static if\`, \`hook\` is defined as an object and in the second branch it is defined as a type (alias). This doesn't make much difference in the D code since it has the same syntax for accessing class members (like \`using\` declarations) and object members - the \`.\` operator. In C++ you use \`::\` for classes/structs and \`.\` for objects. Generally, there seems to be a much sharper distinction between types and variables in C++ than there is in D. For example, you can't have a template parameter that is a type in some instantiations and a variable in others.
Actually they just removed those old toolchains from their test matrix (there are still some c++03 toolchains remaining though)
I already addressed that [here](https://www.reddit.com/r/cpp/comments/agh45h/if_boost_libraries_aspire_to_standardization_why/ee6ino7/).
I added the `-&gt;` on my implementation, in fact, to make them less annoying to use :) The intent of using them in containers was to imply that I want valid references, hard to do that with plain pointers. Conversely, I don't see the point of the new `observer_ptr` or `non_null` etc. patterns when the reference wrapper type is already there. I agree with the bind part you're saying, but frankly to me it still feels like a hack and I wonder if it could be done better. That's also why I didn't add any equivalents to `std::ref()` to my implementation. Oh, and thanks for the appeeciation. I think it *is* pretty biased, tho :)
They do way more complex stuff, across operating systems, compilers and build systems. Adding a `time` invocation (and whatever the windows analogue is) to each compiler invocation sounds trivial in comparison
Consider how many programs out there depend on ASIO, which is pretty much a one-man show. I'd very much have at least basic networking functionality in the standard. That aside, there are indeed relatively few things in boost I'd consider a good fit for the standard - partially, because they are completely outdated and partially, because they are too domain specific. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/agowf2/resources_to_learn_fast_c_optimization_practices/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I use whatever the radio vendor provides. They provide a version of boost as well.
&gt;how does LEAF know that this enum represents error codes and not, say, types of cold cuts sold at Bay Cities Italian Deli? Subtle... &amp;#x200B;
Thanks. I finally understand the odd behavior of c++ committee.
sounds really cool!
Oh, this is interesting. It is specific to `mpark::variant`, I hadn't thought of letting it work with `std::variant`. I think I would have to introduce a separate `std_visit` though since `get_if` isn't findable via ADL.
Yeah, they're optional. They're only optional for `sizeof` if you're using it on expressions. For types you need tg parens.
It does if you understand the intent behind the D code. Yes sure the two languages do something different, but they're solving the same problem; namely that if the hook has no state then it shouldn't take up any space in the enclosing class. In D that's achieved using either an alias or an actual data member depending on the size. In C++ it's done with a data member with an attribute that tells the compiler "hey, this data member doesn't need an address so you can omit it if it is empty.". Different way of achieving the same thing.
I am a total Rust beginner and haven't looked at it in almost a year, so my personal experience might not be the best anecdotes. I tried to port some C++ code to Rust and when I couldn't make ownership work for some cases (involving callbacks that need to refer to their owner and its members IIRC), I was told to use `Rc` and `Weak` for things where I could use C++ references or raw pointers (and know it was safe in my context, but there was no way to prove that to the Rust compiler). I also generally found it hard to program in a way that gave me tight control over how data is arranged in memory. My professional C++ work was in an environment where we generally couldn't allocate directly from the system heap and instead used our own memory management system, allocators, placement-`new`, etc, and at least at the time Rust seemed to be lacking in equivalents (it seemed like there was a way to replace the whole system allocator, but not on an object-by-object basis). I would be happy to learn that I'm wrong, though. I really did like Rust from the brief time I played with it, and in most cases the safety benefits far outweighed the frustrations I had with it.
[Ninja](https://ninja-build.org/) (which can be used as a backend for CMake) already writes start and finish times for all the steps to its log file. There is [also a tool](https://github.com/nico/ninjatracing) to convert it to Chrome's format.
Even then if you are building one part of something not nessesarly but if you are manageing the project sure.
If that's all you want it'd be trivial to just set up a toolchain that does that without having to modify CMake itself though...
Sure I can do it myself :) my point is that CMake is in the perfect position to do this cross platform and cross compiler, and given how many projects seems to suffer from long compilation times I'm surprised we don't have standard tools to inspect them yet 
Just to add to discussion: [scons](https://scons.org/) also logs build times per translation unit. Unfortunately if you're dealing with a complex unit w lots of header files, compile time per translation unit will not necessarily give you a whole lot of information on *what * is causing slow compile times (except for lots of headers of course!)
Wow, trying that tomorrow :) Thanks!
But this is already present in C++: you can select C++03, C++11, etc.
I guess it'd really be up to the language implementing it, but the way I see it, (and without forcing every datatype to implement an empty constructor), you have two options: Initialize 20 `f`'s and create new methods of indexing the particular `f`
I know Nim, but it's a bit of a different beast - with GC for example. A close project to mine is [kitlang](https://www.kitlang.org), which compiles to and interacts with C, but it doesn't have some of the abstractions of C++, like move semantics.
Functors/function object classes are often the optimal solution, but lambdas are terser and easier to read when you just want to write a function/closure inline. Raw pointers or all pointers? `unique_ptr` is perfectly fine and necessary. `shared_ptr` is useful, but should be used sparingly. Raw pointers are necessary for interop, and are generally ok if they're non-owning and backed by an owning `unique_ptr`.
What is the result of sizeof(...) on the key types that get passed around and returned a lot? I think I'm asking, what is \`sizeof(leaf::result&lt;void&gt;)\` and \`sizeof(leaf::result&lt;Some\_Class\_of\_size\_1K&gt;)\`. Is the return of such a thing cheap, or will it generate a lot of code and / or compile time?
Thanks. This looks pretty good I may take a shot at quickly testing this on my 600k+ loc code base
Try getting the size of a file above 4GB in Windows, Linux and MacOS. 
Nobody wants to waste time looking for the right way to get the size of a file above 4GB in Windows, Linux and MacOS. After that you still need to code it, make sure it compiles in all the platforms, and actually test if it works on all the platforms. 
Not quite. The author assumes `Hook` has a default constructor (a "fallback"). In the case of a stateless hook, it makes perfect sense for `Hook` not to have any constructor at all. The true fallback here is the type itself (`Hook`) and you can't conditionally define a symbol in C++ to be a variable or a type. The solution he proposes later, in the context of a ranges module, doesn't help either. I don't see a way out of this other than to SFINAE the hell out of `Checked`. The point of that D code snippet is to not spend space needlessly, yes. But it also shows how two very different situations are handled smoothly and uniformly through the use of symbol aliasing. I think this point was missed.
Yeah though there is a follow-up now. https://aras-p.info/blog/2019/01/16/time-trace-timeline-flame-chart-profiler-for-Clang/
&gt; olatile does not have anything to do with threads. If you use it in this sense you are sure to introduce undefined behavior. `volatile` guarantees a memory barrier on MSVC (by default now; always in previous versions), which I think is largely what fuels this misconception.
The problem is that overloading keywords to mean different things in context is the absolute bane of being able to write understandable/correct code IMO
The reason the move can throw is because the const data member will copy instead of move. Throwing aside, that simply isn't viable.
I saw LEAF a few weeks ago and was super impressed. It is a very neat library. However, I found the previous introduction simpler for me to understand. The problem LEAF solves is that it provides an efficient way to add arbitrary information to an error which is expressed as either as part of the return type, or as an exception. This way you can have rich error reporting without polluting your return types(for example being able to see what filename was associated with a file open error, etc). In addition, it allows this arbitrary information to easily pass up the call hierarchy. The previous explanation had this fact front and center. In this refactored explanation, that gets lost as it looks just simulating try, throw, catch using lambdas, which in my opinion is not the most interesting part.
If you use it mostly for PIMPL, you may prefer to deviate from `unique_ptr` interface and use something like [`value_ptr`](https://github.com/martinmoene/value-ptr-lite) which additionally supports deep copy. (see also references to other implementations there)
I feel like I'm taking crazy pills here and no one is grokking what I'm saying. &gt;as it is a huge performance pitfall as well. **This is a language problem**. It's really easy with the human eye or basic static analysis to show that a given assignment can or can't be a move. The goal should be "let the compiler make that code go fast", and not "make the programmer write convoluted code that's logically inconsistent in order to enable some optimizations."
You have been downvoted, but you have made a reasonable and well-written comment which, I feel, deserves an answer, even if nobody else is going to read this now. &gt;I think a lot of this has to do with OOP being a newer, relatively speaking, paradigm than procedural programming. I think it is even easier: There is just not so much to say about procedural programming. And people like to feel smart and boast (or blog) about their knowledge. At least these are usually the people that you learn programming from. &gt;This leads a lot of programmers getting the false impression that OOP is inherently better than procedural when they start learning computer science and programming. &gt; &gt;I think educational institutions and how programming is taught is much to blame for this false assumption. You are probably right that education is - at least partly - to blame. However, not for the false assumption that it is better, but for misconceptions about OOP. The latter are to blame for OOP being used as the wrong tool for the job. OOP is actually better than procedural programming at specific things, but surely not for all purposes. Thus my advice is to use it - but only where it makes sense. Talking about misconceptions from education: When I learned OOP in 2002 at an in-company training of a major IT company, it was introduced in a banking application example. There was inheritance of a base "Account" class and subclasses "CheckingAccount" and "SavingsAccount". So far so good. But then the concept of private and public was explained as a "security" measure, so nobody can change the balance in the wrong way. Took me a while to realize the misconception that the "security" is not against hackers, and is not needed because it is about money. The true benefit is: Making variables and methods private with a separate public interface makes (almost) sure other code is not using the private part. This allows you to change the private code without fear of breaking functionality outside of the class or even library. In a large code base that is written long ago or by several people, this makes changes **a lot** easier. As an example, I have a written a class that encapsulates a 3D rigid motion measurement with a covariance matrix. One day we found that these exhaust the memory in the long run. Since the variables were private and they were only accessed through public functions, I could easily change the storage of the 6x6 doubles array of the symmetric covariance matrix so that only the upper-right half of it is actually stored. Also I changed the motion representation from a 4x4 transformation matrix (16 doubles) to a translation (3 floats) and a angle-axis representation (3 doubles). The public interface stays the same, the conversion is done transparently. Nothing else of the 40 kloc code base had to be touched. &gt;One point that this blog post really hits the nail on the head is about programmers spending so much time on defining objects and thinking about how to implement OOP principles before they even start solving the problem at hand. I feel like all this accomplishes is adding extra boilerplate, which usually manifests itself as bloat. Inheritance is often shown in toy examples that look (and generally are) grossly overengineered. And this encourages beginners (in cpp this is a few years) to create overengineered programs. I started out the same way. In my practice the OOP design often comes more or less naturally from thinking about how to structure the data and which functionality goes with it. In my code, there is seldom much boilerplate from OOP, because I don't use it if it isn't beneficial. You don't need to always start out with constructor, destructor, getter and setter methods. If it is just a collection of data used in a few places, use a plain struct without bells and whistles. If it is a central datatype of your application, better make it robust to changes with public/private interface. If you need to allocate heap space or manage files, add constructor/destructor (RAII is a great benefit of OOP btw). But if it doesn't make things simpler and cleaner, don't. Also, if some functionality only needs the public interface of a class, I don't make it a class method but a separate function. And if there is not even a state to be maintained, I use functional programming instead of a class. &gt; I don't think OOP is necessarily bad, I just think it is extremely over used and shoehorned in as a solution to problems that don't really benefit from OOP. Yes, but I have the feeling that you underestimate its usefulness, because when you started learning you saw all the toy examples that were just demonstrating some concept without need, instead of complex applications that benefit from exactly those concepts. In a recent case, I had a quite fundamental class that represents sensor readings of a 3d sensor with some related data (calibration), plus some operations on it. Then a customer requirement came in to support multiple synchronized 3d sensors. Great application for inheritance: Write the class for the latter case analogously to the single-sensor case. Put the common functionality in a base class and use that instead of the original single-sensor class. This process kept the refactoring quite sane. I don't know how this would have been best done without OOP because virtual functions made it possible that in 99% of the uses, the base class interface was used regardless of the actual subclass of the object. &gt;Areas like simulations / scientific modeling, video games, and GUI libraries are perfect use cases of OOP, but outside of those areas, I don't see much benefit. There are certainly use cases where OOP doesn't make sense. If I need to quickly process some text, plot some data, or write any other small tool I don't use OOP. I actually don't even use C++ for this, mostly just a (non-OOP) bash or python script. But for complex, stateful applications the encapsulation provided by objects really helps keep the code sane. And somehow that is the kind of code I have worked on in much of my professional life.
Great stuff, looking forward to trying it out later this week!
It's worth noting that _significant_ modularization has taken place in the last two years.
Awesome documentation! 1: I really like the `try_block`/`handler` abstraction for short programs / as a translation layer. 2: The `preload` approach is really interesting, I haven‚Äôt seen that before. 3: It seems like all the error handling methods in this space require some sort of macro for modify control flow to be convenient to use (i.e. `LEAF_AUTO`, `BOOST_OUTCOME_TRY`, etc.) which makes sense but is a shame. Would be nice if there was a language construct for this syntax (ex: Rust `!`, Haskell `&lt;-`, etc.)
So you're talking about what theoretically could/should be then..? Because no one else in this subthread is.
The last example, Detacher class, what if a thread has been detached somewhere else, and in Detacher's dtor, there will be problems.
.... `cmake -DCMAKE_CXX_COMPILER="time g++"` ?
what is that referencing?
Not the author but I think it's the same size as an optional. It places the detailed the detailed information in per type thread local variables. You only generate code at all at points where you create and handle the error, otherwise it is cheap to return. The best way to think about it for me is a slightly more manual, much more efficient in the error path, binary typed (a function either can error or not) version of exceptions.
From article prior to its editing. Under the "error codes" section in enum error discussion. Article contains line above which also had a link to the business establishment named.
I don't mind switching to `mpark::variant` in implementation/detail code just for the improved visitation, but it's important to me to retain the stdlib vocabulary types in my public interfaces. I think it would be wonderful to be able to use this visitation mechanism with `std::variant` if it's technically practical. :-]
Please include the Technologies section as required by the template.
The ugly macros are just for convenience, you don't have to use them. Also, if you use exception handling, there is no need to use the macros (LEAF works with or without exceptions).
Or the standard would include some basic things in the language itself without needs for includes. Outside of the obvious types (seriously, including for `std::byte`), tuples, variants and optionals should be actual language features.
The approach is the same, the syntax is better. What used to be: ``` leaf::expect&lt;e_this, e_that&gt; exp; if( result&lt;T&gt; r = f() ) //Success, use r else leaf::handle_error(exp,r, [ ]( e_this const &amp; x, e_that const &amp; y ) { }, [ ]( e_this const &amp; x ) { }); ``` (that is, the user hand to manually list with expect&lt;&gt; the types he needs) Now becomes ``` leaf::handle_some( [ ] -&gt; result&lt;void&gt; { LEAF_AUTO(r, f()); //Success! Use r... return { }; }, [ ]( e_this const &amp; x, e_that const &amp; y ) { }, [ ]( e_this const &amp; x ) { }); ``` That is, the expect&lt;&gt; is hidden and deduced automatically.
Bay Cities is an 80-ish year old deli in Santa Monica, CA. I wouldn‚Äôt expect many to get the reference since there‚Äôs only one of them (as far as I know.) It get super busy in the summer, and their subs are pretty good, though.
The error objects are stored in the stack in the scope of the call to `handle_all`/`handle_some`, they aren't thread-local (there are thread-local pointers, per type).
Implementation details: `result&lt;T&gt;` is similar to `variant&lt;T,leaf::error_id&gt;`. The `error_id` type is essentially an `unsigned int`. The actual error objects are not passed in the `result&lt;T&gt;`, instead they're moved directly to the scope of the `handle_some`/`handle_all` call that handles the error, where they are uniquely associated with the `error_id` passed in `result&lt;&gt;` objects.
Thank you! Of course the macros are optional. I do hate macros, but `LEAF_AUTO` does save a lot of typing and avoids errors. Let's say you have a function `leaf::result&lt;int&gt; compute_answer()`. Without the macros, if you want to consume successful results but forward failures to the caller, you'd do: ``` leaf::result&lt;void&gt; use_answer() { result&lt;int&gt; answer = compute_answer(); if( !answer ) return answer.error(); //Use answer.value() (or *answer) return { } //report success to the caller } ``` With `LEAF_AUTO`, this becomes: ``` leaf::result&lt;void&gt; use_answer() { LEAF_AUTO(answer, compute_answer()); //Use answer return { } //report success to the caller } ```
This is not my area of expertise, but regarding long compile times reducing developer productivity, the low-tech technique that I've used (/resorted to) is simply to "`#ifdef` out" (in my local copy) the parts of the project that aren't necessary to what I'm currently working on. (Sometimes you have to replace the excluded parts with minimally functional stubs.) I haven't seen anyone else mention it, but does anyone else do this? When I've introduced it to the (generally small) teams I've worked with they've generally adopted the technique without objection.
You seem to have fundamentally misunderstood the part you quoted, and your commentary drastically changed the meaning from "people were being harassed on Slack about their bodies" to "OP loves talking about their genitals in Slack". I suspect /u/AirAKose's response to you was heated because it was difficult to tell from your comment if that part of the post had just completely gone over your head, or if you were practicing malicious ignorance. I'm surprised your first comment was upvoted as much as it was, tbh. Also. I don't expect everyone to know who Eric Garner is since that story is America-centric, but since you appear to realize it's a sensitive topic (or you could have learned as much with a few seconds of googling and skimming the wiki) then you shouldn't be surprised if people downvote you for being flippant about the matter.
You don‚Äôt have to focus on one language. Instead focus on computer science concepts that apply to software engineering in general. At this point of your career, any experience is beneficial to your career.
Yup
Right sorry, my bad.
Oh I know, the macros are actually so useful that places I‚Äôve worked with sum types use them (the equivalent for our error library), it‚Äôs precisely because it‚Äôs such a useful / common idiom across languages it‚Äôd be nice if C++ had it as well, although I don‚Äôt know how to constrain it to the appropriate use cases. Every implementation I‚Äôve seen has relied on statement expressions, for which a macro seems the right place to put them.
That fixes only the basic things and does not aid us elsewhere. Better includes and forward declarations would greatly help compiled libraries.
That‚Äôs such a cool way to do this! I‚Äôll have to look at the implementation and come back here with some questions.
Why would the stateless hook not have a default constructor? There are some cases that, while technically possible, just aren't worth supporting. The requirement is that `Hook` is default constructible - full stop. The optimization is that we use zero size where possible. Like... sure, the D code just happens to support some other weird and pointless scenarios - but that's about the least interesting thing in this whole code that D does better. Heck, I'd almost argue that it's worse. 
That approach works well for small project. It helps little for medium sized projects. It's basically useless for large projects. Build times are mostly a problem for large projects.
My first job was Pascal, Html, and Javascript. next was C++, Then C and C#, then C++ and assembly, then C again. In my experience once you get past a certain point specific languages stop being a big issue. 
It was easy with the hyperlink (prior to edit). Sounds like a good place to eat.
There's a lot more I would love to change in C++, but I try to keep my dreams somewhat realistic. Removing the template nightmares for the STL writers and the large burden on compilers that slow down from these by a first class language feature would be a big change. I'd even also add `unique_ptr` to that list of library features that should be language features.
I didn't mean to be harsh, but some people get really touchy when they hear `thread_local`. The point is, they're just pointers, not _that_ scary. :)
The `if` inside `LEAF_AUTO` is a bit scary but I don't think it's possible to avoid it.
Yeah, `requires requires` is *far* clearer.
You claim 'low latency' but provide zero benchmarks or reasoning behind that.
I've at least seen the parse errors show up when they are in different files (or at least headers the open file includes).
It isn't trivial to benchmark LEAF, especially if you want to compare to other libraries. Consider: - Other libraries can't transport error objects of arbitrary types without memory allocations, so in that case you're benchmarking LEAF vs. a memory allocator. - If no handler needs a particular error object in a specific use case, LEAF won't even bother transporting it, it'll be discarded on the spot. - If the error object needs to be sent up through N stack frames to the error-handling scope, LEAF will do exactly 1 move (which might even get elided, I'm not sure), whereas other libraries will be moving it N times. The point is, it's apples and oranges. And if you're not comparing to other libraries, what operations exactly do you want measured? I mean, toy examples won't tell us much. That said, LEAF does not use any memory allocations, except when error objects need to be sent to a different thread. I'm reasoning that its cost is comparable to an access to a thread_local pointer, per error object reported. If performance is an issue (it has never been for me with LEAF), it can probably be optimized.
You can wven use part of the STL. Take a look at the latest release. You can also call C++ code easily with extern C++
Looks like TypeAlloc is more of an object pool than an allocator. It's a common pattern, but strange to call it an allocator.
Not really. Rust 2018 contains some breaking changes from Rust 2015 (only one or two of them, but nonetheless). As an example: https://rust-lang-nursery.github.io/edition-guide/rust-2018/trait-system/no-anon-params.html
std:: is the language. There's nothing stopping anything in std:: from being implemented in the compiler directly if compiler vendors chose to do so. 
Ok. Again, not my area of expertise, but I'm having a little trouble with this answer. Is it the case that people don't consider compile times an issue for medium sized projects? Even in the (few) really big projects I've worked on, they were broken down into smaller components. In some cases it took some work to isolate the components as we had to "emulate" the interaction with the other components, but I assume this is the only practical strategy for really large projects. I mean, when you're working on one component of a big project you would probably want to avoid even linking to the rest of the project, right? Btw, I'm not saying that excluding "not currently relevant to you" parts of the project is a "no effort" technique, just "low-tech" (portable, no dependencies) one, that doesn't seem to be discussed much. I mean, the general strategy of "component isolation" is used at the macro level in (at least) some big projects. It's not clear to me why it wouldn't be helpful at a more micro level as well.
But the standard says you have to `#include` stuff anyway, and unless everyone does that, you still suffer through the processing of the headers.
Minimal *unoptimised* runtime overhead. Optimised builds are close, but the Dinkumware std library was generally better performing in optimised builds when I did tests a couple of years ago. Eastl was never faster, and often slower. The boost equivilents performed mostly on par with Dinkumware, and sometimes better. 
Did anyone think about this specific problem in the modules stuff or anywhere else? I'd like some sort of annotation on an include that means: Keep all macros to this file or namespace; no spilling everywhere. Outside of compilation speed issues the main problem with macros really is the global namespace pollution. Makes using tons of old-but-proven stuff a huge problem.
My experience is that you have to try hard and break up large projects into smaller ones that can be independently developed and tested. If you can't do that, you end up with big projects that aren't very accessible to #ifdef'ing either.
Sorry if it was posted before - Reddit didn‚Äôt warm me, which I thought it did if a similar link was posted recently.
Wrong. Unicode is not the same as UCS. Hiragana and Katakana require 24 bits in UTF-8. Code points beyond the BMP require 32 bits in UTF8. 
I'm stil disputing your basic premises: If it has an effect at all, using const members makes your code more convoluted - not less.
Const would be the default for local variables as well. Immutability everywhere by default.
&gt; ignorance of most basic Unicode knowledge among the Standard Committee members. &gt; Unicode or UCS &gt; Japanese characters can be represented by two UTF-8 units. &gt; characters don't fit it BMP so it usually requires 3 UTF-8 units So sad. 
Such a snowflake. 
You can post this job in the [quarterly jobs thread](https://www.reddit.com/r/cpp/comments/abh8bm/c_jobs_q1_2019/) if you follow the template, but not as a standalone post.
Please submit links as links, not text posts.
I know backwards compatibility is important, which is why I want this feature so badly. However, it is already a reality, that you have to rewrite parts of your code from time to time. New c++ versions make breaking changes (mostly in the library), Dependencies break APIs with new major versions, supported protocols change and you want to make use of new hardware features. If you are not able to (slowly) upgrade your codebase as part of the regular development process you are playing a very dangerous game.
Shows what I know... Sorry. Still, D is a different language. Not the same language with a different syntax/different defaults.
It's not portable and does not do aggregation of the data :(
This is a really great talk from author of the "hardware effect" set of example what was discussed here on reddit recently. * the repository: [https://github.com/Kobzol/hardware-effects](https://github.com/Kobzol/hardware-effects) * previous discussion: [https://www.reddit.com/r/cpp/comments/9y98l5/set\_of\_c\_programs\_that\_demonstrate\_hardware/](https://www.reddit.com/r/cpp/comments/9y98l5/set_of_c_programs_that_demonstrate_hardware/)
As she stated in her blog post, they have - she is not allowed to participate at CppCon 2019.
Very interesting, thank you! I will definitely try it out. While i am (compared to you) very inexperienced in c++ and have never written a library comparable to leaf, i have a suggestion/question: Do you think it would make sense to overload operator*() for leaf::result&lt;T&gt; types similarly to std::optional, so you could do (in your example) ¬¥¬¥¬¥ auto filename = *parse_command_line(argc,argv); ¬¥¬¥¬¥ instead of the macro LEAF_AUTO? There are probably reasons why this is a horrible idea but to me it seems right now that this would get rid of the macro and enable a syntax that is more familiar to most c++ developers. Also it would leave it up to the user whether he wants to be verbose and declare the type for the result.
Awesome work and. But to be honest, for me, it isn't readable at all. Sorry. Over 30 lines of error handling for 10 lines of production code? Many lamdas with up to 3 parameters? That's too much for what you get. 
Ok. Thanks for the explanation. I didn't mean to imply that OP loves to do such things. Just that *someone* who does it is violating the contract of professionalism. 
True, one can write a much simpler "read a file and print it to `std::cout`" program. :)
`result&lt;T&gt;` does overload `op*`. If we knew that there was no error, we could do `auto filename = *parse_command_line(argc,argv)`. Since in this case we do not, we use `LEAF_AUTO`.
Nice! This reminds of llvm::Expected and llvm::Error.
Sorely needed to understand the possible impact of modules on compile times! Great job!
That's not an apology. But you also dodged the question. What will happen if someone else gets on stage with an offensive message? Will their talk be allowed to continue? The post referenced some kind of audience voting. Does popularity matter more than the offensive message?
I don't see why you'd think any of these points mean benchmarking is difficult or doesn't make sense. The fact that it is different from other libraries is the whole point of benchmarking things.
The keynote starts \[here\]([https://youtu.be/ScKNrkN2SF4?t=287](https://youtu.be/ScKNrkN2SF4?t=287))
Stay away from M$ shits if you want to write C++ code.
Will coroutine be in next next std? Seems gcc still no plan on it, and there is uncertain optimization issue in other implementations.
Thanks. Calling people "shits" is a great way to be taken seriously. :)
Why? Some of the biggest contributors to the standard have come from microsoft, not to mention some of the most acrive members of this subreddit.
Clang has a coroutines implementation, too ‚Äì should we stay away from 'LLVM shits' if we want to write C++ code?
I don't see how that might be possible. Our thread objects are constructed in the \`emplace\_back\` function of the \`vector\` member and owned by it, and it's private. You could say that it's possible to do reinterpret cast manipulations and get to the thread objects somehow and join them earlier, but I don't think this kind of scenarios are worth discussing :)
I am the author of the framework, thank you for your attention!
In C++ you can choose the standard on per-TU basis. And C++ standards also have incompatible changes. Admittedly, there are differences. Include model in C++ causes incompatibility problems. Also if the standard breaks ABI on library level, you may get problems (but mainstream implementations like libstdc++ or MSVC normally give stronger compatibility guarantees).
Good question! I have changed to use kqueue instead of poll on Mac/BSD.
Thanks for the framework. üòä
Thank you for your introduction here :)
But written as an imperative.
I'm like 99% sure the memcmp and std::equal in their tests are optimized away because the result is never used. If you look in the assembly between the calls to [steady_clock::now (line 1387-1400)](https://github.com/germandiagogomez/the-cpp-abstraction-penalty/blob/master/plots/assembly/assembly-clang++/use_memcmp.cpp.s#L1387) , there is only code for the mersenne twister and the followup call to steady_clock::now.
This is excellent, flame charts are such an excellent way to debug performance.
A lot of the more niche embedded platforms have only one version of compiler provided by the platform vendor. It‚Äôs not so rare to be stuck with an ancient version of gcc that was originally ported 10+ years ago and has since been patched with the bare minimum required to support newer versions of the platform. Last I checked, Analog Devices CrossCore Embedded Studio still had only partial support for C++11 language features and the stl was mostly stuck in C++98 era. And that‚Äôs one of the better vendor specific toolsets.
I'm not disputing the fact that there are outdated toolchains still in use. I'm questioning a) if projects using them need the **latest version** of boost / can use boost at all (AFAIK Hardly any boost library is e.g. regularly tested against a freestanding implementation of the c++ library) b) If it really is the responsibility of the boost community to spend time, effort and resources to compensate for a vendor's bad c++ support or a companies unwillingness to upgrade their tools if possible. 
Hopefully this will make it's way into Clang. But it would also be really cool if something like this would be available in MSVC.
I \*really\* don't want to make personal insults. That's resume of 11+ years in C++, their point of view of the language is completely broken, you can see longstanding Visual C++ as most stupid language extension ever, COM, Win32 - hell of stupid code and implementation. So in resume i just wrote one phrase to make clear as is.
I wouldn't hold my breath on getting significant parts of boost to work on such platforms. They tend to be small and limited enough that the value provided by boost wouldn't be that great anyway.
The #include doesn't need to do anything either. The language doesn't even know about files. #include &lt;vector&gt; could very well simply allow one to instantiate a vector from that point forward. 
I'm not a big fan of Microsoft either. But the Microsoft guys in the committee make a really good job. Just stay away from platform dependent libraries and if you use VisualStudio use cmake as build system, so people on other platforms have no problems with compiling and running it. 
Also Herb Sutter is one the most exciting people of C++ world but M$ frameworks are in opposite. 
Exactly my point. 
I hope you don't abandon it like the \`crow\` author did. Right now the promising frameworks/libraries seems to be \`pistache\`, \`feather\`, \`oat++\` and yours.
I'll be writing about forward declarations next time, turns out it's already possible for *some* types on *some* implementations and the gains are significant. Maybe this could push vendors to implement more types in a way that's forward-declarable :) Besides that, for `std::string` for example, I could imagine the whole header consisting of just method declarations, with templates for `char`, `wchar` and all the fancy new types being explicitly instantiated inside `libstdc++.so` and *not* leaking into the header. The same could be done for the new `std::string_view`. I'm doing this for many types in Magnum and so far it served me well. Yes, this would make things like `std::basic_string&lt;std::byte&gt;` impossible, but ... do we *really* need that? If desperately needed, the STL could provide some `&lt;string.impl&gt;` that contains the definitions.
I'm currently making the same switch for indie development. I agree with your assessment of Microsoft's built in tools. They're slow and still pretty alpha stage feeling. I'll take a look into cquery do my projects. Good read, I'll have to bookmark.
I'll be adding more things to the https://github.com/mosra/magnum-singles repository once I have my single-header-generating environment a bit more stable -- for example [array](https://doc.magnum.graphics/corrade/classCorrade_1_1Containers_1_1Array.html) as a lightweight alternative to `std::vector`, [array view](https://doc.magnum.graphics/corrade/classCorrade_1_1Containers_1_1ArrayView.html) as a `std::span` alternative, [scoped exit](https://doc.magnum.graphics/corrade/classCorrade_1_1Containers_1_1ScopedExit.html) (as an alternative to `std::unique_ptr` with a custom deleter) and similar other utils.
Thank you for taking the time to write out that very well thought out response. I really appreciate it. 
You can always find answers in two ways, hard and easy - i just give you easiest one.
My rule of thumb for Magnum is: if the class internals are allocating something or are heavy in some other way (compiling a shader, let's say), I'm turning the class into a move-only type. So basically whenever I need to PIMPL something (usually because there's a `std::vector` or `std::map` inside), the class is already too heavy to be copied and so a move-only pointer wrapper is completely fine.
I will continue to improve it. I hope you try to use it, any \`issue\` or \`PR\` will be welcome.
The MSVC STL is based on Dinkumware, right? Do you have any idea if this performance advantage still holds in the latest releases with the C++XY features being added to it?
+1 for getting something like this in MSVC
Calling it array is kind of unfortunate because of std::array. Your scoped exit, may want to name scope guard as that's been the standard name for this concept for a couple of decades in C++. Also, it's a bit odd and unnecessary to have a handle argument, and not seemingly allow captures in the lambda. Just take a capturing lambda and that's all that's necessary.
&gt;Nineteen uses are testing library types that in my opinion ‚Äúdon‚Äôt really need‚Äù CTAD. They use CTAD basically as a party trick ‚Äî observe [the test](https://github.com/nyorain/nytl/blob/39397a41d1ddd/docs/tests/vec.cpp#L73-L74) which verifies that &gt; &gt;Vec{1.f, 2, 3, 4.} &gt; &gt;deduces as &gt; &gt;Vec&lt;4, double&gt; Don't really see the complaint here. It's a test. Of course it's going to be a "trick". It's a library of utilities. Why is he expecting CTAD to be used just because? CTAD is obviously meant to aid his use of the library outside of the library. For what it's worth, I have a library with similar aims and I use C++17 and CTAD liberally. My tests in that library are also "party tricks" to ensure that similar usage outside of the library does not regress. So the test in nytl obviously serves as both a regression test as well as a usage example/reference. In this world of FUD against CTAD, I'd personally have lots of these "party trick" tests to show people there's nothing to be scared about in general usage, especially if they serve also as regression tests.
I wish VSCode would intergrate better with C++ on Windows. It's upsettingly annoying to setup the same C++ IDE like features that work on Linux if you are bound to use Windows and Visual Studio (not VSCode, the "normal" Visual Studio) MSVC compiler.
&gt; There are still a couple of features I miss (for example, being able to just start a Google Test case without editing the launch.json file) There is quite good test runner extension for Google Test [here](https://marketplace.visualstudio.com/items?itemName=OpenNingia.vscode-google-test-adapter). Although i used it in very basic manner.
Scope guard: noted, sounds much better, thanks. Naming is hard :) Array: same could be said about `std::vector` and having [Vector](https://doc.magnum.graphics/magnum/classMagnum_1_1Math_1_1Vector.html) as the actual math type. If I could rewrite history, I would use `std::array` instead of `std::vector` (as that's the standard naming in *every other language*) and then have `std::static_array` or something for the compile-time-sized version. Here I'm similarly bound by backwards compatibility, can't rename it without making lots of users angry ;) I'm disallowing captures in the lambda for one simple reason: I would need to allocate (since it's no longer a plain function pointer but rather a struct of unbounded size) -- and I don't want to. Another option would be to turn the class into a template, but then it would be much more verbose for the user to type, basically going back at the awful [`std::unique_ptr&lt;void, void(*)(void*)&gt;{h, [](void* h){ cthulhu(h); }};`](https://twitter.com/czmosra/status/997077182982901760). Most of the uses I had were simply `ScopedExit e{h, dlclose};` which is quite succint.
(author of this here) I'd love to have this for MSVC too! But that's kinda hard to do without being somewhere inside Microsoft :)
Just about the entire bag of tricks described in the article would become unnecessary if we adopted the changed I proposed here: https://www.reddit.com/r/cpp/comments/afn548/suggestions_for_modules/ ...which is sort of the reason why I was proposing that in the first place. 
Regarding keywords, I would introduce only one: **internal** like in C# which is "public only within the current assembly" (current module in our case).
Nice work. Hopefully it gets incorporated into clang since xray doesn‚Äôt work on windows. Clang already has better tooling in general than cl, and it produces MSVC compatible binaries on windows to boot. 
Yes, but even in the best case it won't be available for years. I'm surfing reddit and having a coffee break while waiting for our &gt;2 million line code base to partially recompile itself after a header change. If we didn't already employ most of these techniques, I could go have lunch instead. 
A few more tips and tricks on top of my head: switching to a better linker than the default one when you can (like gold or lld) is also an easy way to improve link times. The other easy thing to do is parallel compilation when you've got a suitable computer (by the way CMake finally added a `-j` option to `--build` which makes building things in parallel easier).
Whether CTAD is there or not can be subtle though: I've got a C++14 library where I didn't write explicit deduction guides, but reorganized some of my constructors to make sure that they would serve as working implicit deduction guides when C++17 is enabled (and I actually encountered a Clang bug in the process).
The current rules for coroutine variable capture seems far too prone to mistakes. The fact that a coroutine functions should (almost) never have reference params is already a massive deviation from best practice of normal C++. And now we find out that you should (almost) never create a coroutine lambda function because variables captured in the lambda aren't captured in the coroutine. As much as I want coroutines in the language, this is going to make code reviews involving them a royal nightmare. IMHO, similar to lambdas, coroutines should require variable capture lists. 
gcc already working on it.
Yes, Dinkumware is in MSVC, and some other vendors license it as well. I don't know if this is all still true, and I realise I have no evidence, but it's inspired me to build a public benchmark. One of the other interesting things was that eastl and Dinkumware compile at about the same speed. Again, eastl was no faster, which is its biggest claim to fame. Boost was slightly slower than both in compile times, but I remember being surprised that it wasn't much slower. 
Perhaps it could be made to work with clang power tools to at least get some visibility about what is taking a long time for clang to compile your solution,
How long does it take? 
All this illustrates why a CoC is a bad idea. It turns a stupid stunt which is easy to dismiss into a subject of debate - which is a waste of time.
Well it‚Äôs a good thing several of them are regular posters on here like @spongo2 hint hint
I used VSCode almost exclusively when working on Windows. For me, the features that edge it over VS is the ease of script integration with build steps (we built a tool to interact with the compiler so executing it from VSCode is a breeze) and the fact that it's not impossible to write your own plugin. My current pain points are: * The debugging experience leaves A LOT to be desired, but hardware breakpoints would be a good start for me. * Single window, multiple tabs. I really wish there were a better way to detach tabs from a code instance but still have them be under the same process. * It's Electron, it comes with Electron baggage.
&gt;It's Electron, it comes with Electron baggage. I see a lot of "humour" about Electron. Can you elaborate on why it is a pain points?
Haven't measured in a while. Something like 30 minutes on my powerful laptop isn't too far off... 
VSCode is one of the few electron apps that don't fall in the "it's electron so it sucks" category, the main pain point most people see are: Massive RAM usage for no good reason as it's literally chrome and a webpage. Slow interop with your computer since it's chrome and does stuff. Doing everything in javascript instead of pulling out needed functions into things such as C++. Poor optimization in general with terrible interface. No way to change what you want to change despite it literally being chrome with a wrapper.
Typedef? Is this the nineties?
How about automatic forward declarations? Seriously, though - what value does sprinkling the obvious types before they are used in signatures add?
Well 15 years of using MS "shit" here. If i can resume one thing with MS: when they release something, they will maintain it for a very long time. So IMO using there stuff is good strategy
I feel your pain, and I didn't mean to imply we don't need short-term solutions. I was just thinking ahead a bit ;-) 
There's some chance it'll make it into C++20, but it's not certain.
&gt; I am a total Rust beginner and haven't looked at it in almost a year, so my personal experience might not be the best anecdotes. I tried to port some C++ code to Rust and when I couldn't make ownership work for some cases (involving callbacks that need to refer to their owner and its members IIRC), I was told to use Rc and Weak for things where I could use C++ references or raw pointers (and know it was safe in my context, but there was no way to prove that to the Rust compiler). If it cannot be proven to the compiler, it is possible to `unsafe` to handle pointers directly. In general, it is recommended to encapsulate this use of `unsafe` behind an abstraction specifically dedicated to it, thereby reducing the code having to worry about maintaining the invariants. Writing correct `unsafe` code requires discipline... though no more than writing C++. &gt; I also generally found it hard to program in a way that gave me tight control over how data is arranged in memory. My professional C++ work was in an environment where we generally couldn't allocate directly from the system heap and instead used our own memory management system, allocators, placement-new, etc, and at least at the time Rust seemed to be lacking in equivalents (it seemed like there was a way to replace the whole system allocator, but not on an object-by-object basis). There is no per-type allocator override (placement-new) in Rust, as in general memory allocation is disjoint from types; or otherwise said allocators are typeless. You can move objects over raw memory using `ptr::write`. Direct in-place construction is desired, but not yet available; since all objects are movable in Rust it is less pressing.
The Chrome tracing viewer is awesome af, and the output format is not hard to generate. My organization implemented support for generating them from our VR metaverse client and it's been incredibly useful for debugging and optimization. 
Not sure what the purpose of this survey is, but I think guards in all forms (lock_guard, scope_guard, finally, on_success...) and tuple-like datastructures are indeed prime candidates for their usage.
The [dragon book](https://en.wikipedia.org/wiki/Compilers:_Principles,_Techniques,_and_Tools) was the text we used in college for compiler construction class.
Beat in mind it might be a tough sell to a PM at Microsoft to make an MSVC too that can only be used with Chrome.
\&gt; Any class, struct, or enum class (c++11 and higher) that is only ever referred to by reference or pointer and never dereferenced may be forward declared. &amp;#x200B; Just to be 100% certain; you cannot forward declare (incomplete type) **nested** classes, structs, and enums right? I know I can forward declare a type in a namespace; but I don't think I can with nested types.
I'd recommend the book [Lisp in Small Pieces](https://en.m.wikipedia.org/wiki/Lisp_in_Small_Pieces) which walks through the creation of multiple Lisp interpreters and compilers. It assumes you're writing your tools using a Lisp though.
COM is the stupid thing, I see; better not mention that around GNOME or Mozilla folks :)
COM is a language extension?! Since when? Also, better not say that around Mozilla folks :)
I see. But I don't get &gt; terrible interface This has nothing to do with Electron but the UI/UX dev. &amp;#x200B;
Debugging is less of an issue for me with VSCode, quite the opposite actually. I like the Multi-Debugger support and the high configuration possibilities. It runs a lot smoother and faster than in the Visual Studio IDE I use. I only miss OpenCV's ImageWatch plugin which I haven't yet been able to port. I also made my own extensions to integrate Incredibuild. Not perfect, but it does its job still better than how Visual Studio does things...
have you been living in the woods for the last 10 years?
So exactly i think that for people that use M$ technologies not even 10 they are even old and deprecated.
Well, if we could rewrite history, we would do many things, but we can't. Also, FYI Rust for example calls its dynamic array Vec. Anyhow, if you're bound you're bound I guess, it's just unfortunate to name things in a way that is going to make a lot of real code very confusing (Array and std::array in the same function for example). Assuming you are stuck pre 17, you can do \`auto e = makeGuard(\[&amp;\] { cthulhu(h); });\` which seems perfectly reasonable to me.
I believe the core coroutines alternate proposal uses lamda capture lists for just this reason
Part 2 is now published as well: https://blogs.msdn.microsoft.com/oldnewthing/20190117-00/?p=100725 
Can you please PM me the link? Thanks!
For me find all usages doesn't work with c/c++ intellisense on Linux, which is a big limitation. 
&gt; Including &lt;future&gt; in a header puts the include in every single file that directly or indirectly includes that header. What does this mean? Are they using `future` as an example of a STL header, or does it mean that there is some black magic inside the header itself that could change things?
Damn, I wish I'd known about these secret compiler switches earlier.
Minus that whole part where [Edge is being rewritten to just be glorified Chromium skin](https://blogs.windows.com/windowsexperience/2018/12/06/microsoft-edge-making-the-web-better-through-more-open-source-collaboration/), but yeah. :) That said, there's no reason this feature for MSVC would even need to use Chrome event tracing. Microsoft has similar tools, e.g. for ETW. It'd just be a matter of making sure cl.exe actually exposes all the necessary events. I don't think anyone is going to complain _too_ loudly if Clang and cl.exe use different profiling tools, so long as they both _have_ them at a similar quality level.
Saw his talk live. So awesome!
A friendly reminder to never ever forward declare templated types and functions of libraries that you don't own :)
&gt; What will happen if someone else gets on stage with an offensive message? Will their talk be allowed to continue? Of course not. Please contact conduct@cppcon.org if you have questions about these types of procedures. My understanding is that policy changes have been made. In future year, we will have improved CoC training to mitigate this sort of incident. &gt; Does popularity matter more than the offensive message? Of course not and I think you know that. You are referring to the lightning talk challenge, where the length of the talk depends on how much the audience likes it. That's completely tangential to the incident in question.
I'm sorry you feel that way. CoCs are industry best practice and we believe it's an excellent idea.
It doesn‚Äôt have to be exactly the same as what has been done here by Aras but the general idea of getting compile time info about our code that Id like to see. They could do it with ETW instead and I‚Äôd be just as happy. I think that was said in the first article but maybe I‚Äôm remembering a comment. 
Because there are no benefits to use vscode as IDE on Windows (at least for C++).
Not stuck, [quite happy](https://twitter.com/czmosra/status/1085993965529255936) there :) Yes, I was investigating the `auto e = make();` way too, but it was still longer and harder to type with all the extra `=([&amp;];)`. The current implementation is sufficient for all the use cases I have in the engine so far, when the need arises, I can always reconsider ;)
\&gt; All this illustrates why a CoC is a bad idea. \&gt; It turns a stupid stunt which is easy to dismiss into a subject of debate - which is a waste of time. &amp;#x200B; Reddit is a bad idea: it turns stupid blog posts into a subject of debate‚Äîwhich is a waste of time‚Äîyet here we are using it. Or we could see things in another way: reddit is useful and entertaining for some (even if it's a waste of time), whereas a CoC helps maybe feel safe and welcome while keeping behaviors and people the conference deem unwanted away. You don't feel unsafe and unwelcome? Good for you! You feel you or your behaviors are unwanted? Good for everyone else!
Author here. That extension is deprecated now in favor of the catch extension that now handles gtest as well 
You can use Windows subsystem for Linux as your compiler for c++. This allows you to run Linux on Windows and gives you the ability to use gcc or g++ from Linux while using VSCode on Windows. It will just replace your default terminal in VSCode.
I think they meant API not UI.
Multiple cursors!
I could have sworn coroutines and executors were dead for 20, we‚Äôll have to wait for 23.
Two (free) books about writing interpreters: http://craftinginterpreters.com/contents.html https://beautifulracket.com/ 
Don't really use this, but first search shows that there is an extension for this: [Multi Edit Mode](https://marketplace.visualstudio.com/items?itemName=MadsKristensen.MultiEditMode)
You can use a version of fast PIMPL that doesn't have the same maintenance problems as the traditional approach by taking advantage of std::aligned_storage and move-only semantics. This is similar to what I use: https://github.com/sqjk/pimpl_ptr Not sure what sort of compile time costs it introduces, though.
Yeah. You can only forward declare them if their containing type's declaration is visible. It is a sadness.
This is basically a variation on have a struct for configuration that you pass to a free function instead of having a bunch of parameters, except that you made the free function a member. Add member functions returning `*this` to set the values, and you get this: #include &lt;iostream&gt; class int2str { public: int2str&amp; base(int i) { base_ = i; return *this; } int2str&amp; len(int i) { len_ = i; return *this; } int2str&amp; fill(char c) { fill_ = c; return *this; } std::string convert(int i) const; private: int base_ = 10; int len_ = 0; char fill_ = '0'; }; int main() { std::cout &lt;&lt; int2str().base(16).len(8).convert(2019); } It's a pretty common idiom, but good of you for coming up with something similar on your own.
I have this installed. It's nice, but isn't at the level of Sublime/VSCode/Atom/multiple-cursors.el.
Yes, it's similar but a lot more noise I think, and could be mush less efficient, and doesn't let you to just pass by order (as in plain case, w/o names). I guess the two cases could be combined as necessary.
&gt; a lot more noise I think I'd agree that it's _more work_ to set this up, but it's much less noisy on the call site (compare this with your "named init" line). &gt; less efficient What do you mean? There's probably no difference in the codegen between the two. &gt; doesn't let you to just pass by order That's a feature, not a bug. The whole point is to avoid something like `convert(16, 8, 3, 2019)`.
Obviously a function call is less efficient than assignment (generally speaking) unless you are sure of what the complier optimization does, this is why I said 'could be'... | That's a feature, not a bug. Sure, I didn't say it is a bug.
This can be even better with c++20 designated initializers. struct int2str { int base = 10; int len = 0; char fill = '0'; std::string operator()(int n); }; int2str{.len = 8}(2019)
Yep, I know... cannot wait! &amp;#x200B; &amp;#x200B;
It's in the works: https://developercommunity.visualstudio.com/content/problem/181010/demangle-d2cgsummary-output.html?childToView=426776#comment-426776
I guess so that stuff like `void MyFunction(SomeTpye t);` will give you an error instead of silently forward declaring `SomeTpye`?
Assignment is a function call that you write differently
I was confused initially as to how you were seemingly naming a class template without specifying the parameter, pre 17. Then I realized, that your ScopedExit isn't a template at all, only the constructor is. Pretty weird design. It's less versatile, generates worse assembly, and the implementation is filled with dangerous casts and void\*... to save a few characters? Dubious priorities IMHO.
Realistically, you probably don't have to, at least in cases where your arguments are simple things like integers, pointers, etc, as most compilers already have some support for designated initializers.
I am against this proposal being accepted as a standard, but I also think it has to be accepted to get anything LA started. The latter because it is pathetic cpp does not have LA as a first class citizen. About the LA-library, I don't think this is even close to what it needs to be. Anyone requiring LA today use Eigen or another library. But since everyone affected have had a need for this since before the Fortran punch-card times, we all have our own ancient stuff that works for our problems. Adding something on this level seems insufficient. What does BLAS/LAPACK folks (e.g., Intel) and Eigen folks say about this? Could they use it or would it be just another thing to support? These are the folks that best know whether the proposal is too limited in scope... Lastly, I hope someone takes him up and fixes the std::complex-bit! The current standard is ugly. Fixing complex, and updating most math-functions to have std::complex support would be so nice! Just think about having sqrt(-1) simply work and produce complex&lt;int&gt;(0,1) by default! Life would be so much better! Then the promotion and casting bit has to happen at a later stage...
Great, clang 9.0/10.0 support designated initializers. I am not sure to what extent though. Thanks, I didn't know that.
Okey, then im sorry, that is what i understood from the post
could you elaborate?
The place where you do static cast instead of dynamic cast is in the body of the lambda that decays to a function pointer. Directly comparing with traditional polymorphism, that pointer in the lambda has the same role as this in the body of a member function of a derived class. Clearly, there is no cast happening there. As for this technique of letting a lambda decay into a function pointer vs inheritance, I think the question is a bit broad to answer. Both techniques have their place. I would say that if you want a collection of polymorphic functions attached to a piece of state (i.e. an interface), I would still certainly prefer inheritance. Mocking it up with lambdas-&gt;function pointers is not only more boilerplate, but also would in the straightforward implementation be inlining the whole vtable which is not likely to be a good move. Lambdas and std::function I use extensively, but this particular kind of approach with having a lambda that really wants to be stateful but has its state fed in externally so that it can function pointer decay, is not something I use that much. When I do its usually part of an implementation detail for something else. As an example, I suspect that std::function itself uses something like this as part of its implementation.
Interesting, because the exact code where i used this design is in a stack based alternative to `std::function` that i'm implementing.
I don't understand why is anyone advertising terribly optimised software.
My design choice is motivated by the need to do more work at class construction than at `operator()`; That and possibly eradicating levels of indirection. Clang seems to be able to completely inline the deleter calls which is cool and all, but GCC and MSVC both compile into many more instructions than their `std::function` counterpart. Probably something to do with intrinsics. This is what lead me to my original question.
Just write any C program and make is \[sufficiently complicated\]([https://en.wikipedia.org/wiki/Greenspun%27s\_tenth\_rule](https://en.wikipedia.org/wiki/Greenspun%27s_tenth_rule)).
It comes with the territory. Since it's basically a web page, everyone tries to reimagine it, break OS UI conventions or mess up in other ways. Imagine using a mediocre website as a power hungry desktop app. Not all Electron apps are like this, but the notable majority, as usual, are.
This is rolling your own vtable. In this case the vtable is one function and stored inline. I am personally looking forward to metaclasses or type functions so I can write this from a classic interface automatically. 
I‚Äôm not a domain expert. However I don‚Äôt understand why this is not good enough? I can see an argument being made that we need more - especially algorithms. However we need the base vocabulary types first, no?
&gt; a function call is less efficient than assignment It is trivial for an optimizer to inline these functions. In any case, if profiling shows that this is a bottleneck, you got other problems. Don't let "efficiency" get in the way of writing clear, concise and correct code. &gt; | That's a feature, not a bug. &gt; &gt; Sure, I didn't say it is a bug. It's an expression. In this case, it means "it's a good thing".
Visual C++ says hello.
Fairly certain they mean it generically
Even as far back as C++98, boost components support functionality the standard does not. For example, boost::container::vector is std::vector, but the boost version can both be forward declared, and can officially handle forward declared types, which the standard versions can not. I actually tend to just reach for the boost components for everything because they offer superior functionality. The compile time is a little worse if one is mindless about it, but with a little effort, such as using the forward decl functionality above, it's possible to offset that, and even sometimes beat std::. 
I mean, yes, `std::string` is a type provided by the standard library, but I'm guessing from your code that you're writing an integer -&gt; string conversion function, so probably they just meant you can't use something like `sprintf` that does the conversion for you; I doubt they meant you can't use any built-in types/functions at all
Very clever. And in C++17 you can use decomposition declarations. https://www.reddit.com/r/cpp/comments/ac4pow/cista_c17_serialization_reflection_library_single/
This is an interesting technique. Basically a hand-written vtable. But I still prefers to let compiler create a vtable for me.
To paraphrase Andre him self: this article is an amazing example of missing the point.
That "paper" is full of inconsistencies, made up facts and straight lies.
use gobject 
It breaks if any defaulted template parameters are added. 
Hey, there‚Äôs nothing wrong with me! üòø
and if you write a library, provide a header for forward declarations
Tell that to WTL, or ConcRT, or the PPL...
Why would I want to use this? That seems to be missing from the github page.
The reason you don't understand, is because no body IS advertising "terribly optimised software".
Yeah, here I only used Chrome format because it's trivial to write, and there's a readily available viewer. If whatever instrumentation the compiler would have be in some different format, that's great too! ETW would be a natural choice on Windows I guess.
I have a strong suspicion that you didn't click the link and had a certain other paper in mind. But if you did mean to talk about the paper I linked, then I'll take the words of Clang's maintainer over what's incompatible with their template model over the unsupported assertions of some random guy on the internet.
&gt; In C++ you can choose standard on per-TU basis. Yes, but you'd be nuts to link them together. (Or maybe I'm missing your point...)
eww 
eww glib 
&gt; CMake finally added a -j option to --build Huh? Is it in trunk or in one of released versions already? 
I think the code is clear, concise (your example is probably less so) and correct in both cases but your milage may vary. I think those setters and .convert() look so 20th century especially when designated initializers are around the corner. Write clear, concise, correct and *efficient* code, modern c++ features make it easier and more fun. &amp;#x200B;
In one of the released versions, 3.12 of I'm not mistaken.
C&lt;&lt; 
you can do --build -- -j4 in any version; flags after -- are passed to make
yeah, except that sometimes there is msbuild instead of make :)
Just checked and yes it is there! Apparently it just doesn't understand \`-j4\` as Make or Ninja do, only \`-j 4\` -- that's why I thought it is absent
I don't understand why you're bringing up designated initializers. Your post was about doing stuff like this: auto f = int2str{}; f.base_ = 16; f.len_ = 8; auto s = f(2019); If you think this looks more "modern" than my "20th century" example, then let's just agree to disagree. 
/s
Perhaps this is the right time to modernize the old BLAS interface and standardize on something which is less error-prone. Only the interface needs to change, the underlying algorithms are already very fast. 
When i read the title i expect to see instead of virtual function, std::function that can be overridden by children.
&gt; `stl` Can you explain what you actually mean? standard library, or part of core language, or something else? 
Hungarian notation makes code harder to read IMHO. Redundant comments just get in the way (// constructors and destructor) and make maintenance harder like those stating the class name, etc.
Why would you expect that when the title in no way refers to std::function?
I agree that this might be necessary to accept as it stands to get started in the standard because of vocabulary reasons. If the standards exist to create linguistic interfaces, then it should be accepted. However, if the standard should solidify existing practice, then this needs to add support for a significant subset of BLAS/LAPACK from the get-go (inverse, eigenvalues/vectors, solve,etc). This is the common standard in LA. (Even though I prefer using Eigen for syntax reasons, I think the Eigen devs would probably also agree to that statement since BLAS is so ubiquitous; in fact I would say they have done so already as they can use BLAS as one of their backends.)
Agreed, what's nice is that it's offered by PearsonVUE, which also facilitates Oracle and SAS exams.
As you noticed yourself, the lambda is unnecessary here. Your solution makes different space tradeoffs compared to inheritance based polymorphisms: You need one pointer per function per object. Usual inheritance based implementations require only one pointer per method and one pointer per object. (The object holds a pointer to the viable, which is stored somewhere else and shared between all objects of the same dynamic type. The online storage is a nice extension though. However, be aware that you strictly Speaking need to use `std::launder` when casting the byte array to the object.
Note that the Cppcon organizers are not clairvoyant nor omnipresent. They cannot know ahead of time of a violation, nor can they be there when they happen - they are usually notified during or after. Even if they are present, in some cases they may be paying attention to the contents of messages or otherwise busy with conversations to realize. Within reason, they respond and act quickly.
thanks
doesnt matter im planning on learning lisp kinda with this project.
i wanted to buy it for some time but im kind of broke.
Why do you have a typedef for void? (I suppose I can see some use of having your own `bool`..). Also I feel like having to qualify fundamental types (eg. `tCIDLib::TBoolean`) adds a lot of line noise.
Greetings, I've been working as a part-time Unity developer for almost a year, but after working on my final degree project in C++ i've been wanting to shift to a similar line of work. I've been raised and am currently living in Spain, but I'm willing to relocate anywhere. I‚Äôll leave here my [LinkedIn profile](https://www.linkedin.com/in/src-santana/) and my [GitLab page](https://gitlab.com/SergioSantana) with some of my projects.
that this is a quote doesnt suprise me at all.
STL = Standard Template Library, although people tend to use it to refer to the entire C++ standard library.
The main difference between visual studio and vscode is that in vscode you can get some "low priority" features faster than "high priority" ones mainly because of its open source nature. Even with incremental patches VS update is slow and usually a lot of changes are deemed "low priority" and get added only when time is right (like re-sizable settings windows that required few decades to be added). Still VS is an IDE and has a lot of powerful tools be it for debugging, profiling or writing code. Also vscode gets exponentially slower as the number of files in the opened folder grows and there are performance issues with big files/"projects".
thanks for the tip about \`std::launder\`, don't want UB. I am making a \`std::function\`-like class which doesn't heap allocate or do "vtable lookup". It has an adjustable "stack space". It does not use the exact same api, but allows initializing from function pointer, pointer-to-object and pointer-to-member pair, pointer to object with defined \`operator()\`, alternatively you can copy or move said objects to be held internally instead of pointed to. \`std::shared\_ptr\` is supported. About performance idk yet, but so far with opt-flags the compiler is making less instructions than with dynamic-polymorphism. This is probably due to the fact that it's not looking up type info at runtime.
I am in a quiet environment where I don't generally watch videos out of consideration for others. I don't suppose you have a text summary of what you're doing, or a link to some repositories that use your technique? (To be honest, I don't love videos, because I have to watch them in real-time, and because in text I often stop and go back and forth over one section until I completely understand it - something that would be maddening to do in a video.)
Using lamdas without virtual -&gt; [http://www.cpp.sh/2fla](http://www.cpp.sh/2fla)
I believe `STL != Standard Template Library`. It is just used widely and wrongly. Sometimes it will cause confusion. more reference https://stackoverflow.com/a/5205571/6949852
&gt; This is probably due to the fact that it's not looking up type info at runtime. Unless you are using dynamic_cast, RTTI is not necessary for "normal" polymorphism. But it does do an additional indirection (as the vtable is not stored inline) and there may be some other inefficiencies around it. Btw.: This talk from Sean Parent might be relavant for you: https://www.youtube.com/watch?v=2KGkcGtGVM4. He doesn't use `std::launder` which probably means that current compilers are conservative enough, that in practice you don't need it (it wasn't available pre c++17 anyway) or maybe it is not necessary at all times. 
As I said, compiler and stdlib implementations provide some guarantees about ABI compatibility, so linking TU compiled with different C++ standarts is fine if you are careful. Otherwise using any systemwise-installed non-header-only C++ library would be practically impossible.
Isn't c already have something like that? Why cpp doesn't take it?
STL _does_ stand for "Standard Template Library", which is _not_ the C++ "Standard Library", it's a much older library that large parts of the C++ Standard Library were based on (much like "Boost" now, which gets parts put forward for standardisation on a regular basis). People often use "STL" to refer to the "C++ Standard Library" though, or refer to the "C++ Standard Library" as "Standard Template Library" as if templates is the only thing it contains (which, while templates are the majority of it, is still far from the truth).
Totally agree. It's near to perfect IDE and works on all platforms.
Serious question: what is wrong with GLib (aside from the fact that it lacks a proper C++ port)?
Horrible codebase. Makes one appreciate modern C++ and the standard library,
Agree. I hate watching a video just to get a glimpse of the code. No thanks!
Hi!, I'm 24 years old an Argentinian/Italian software developer, with 5+ years as a freelance developer and 6 months in a company working for a gaming studio. I'm looking for an opportunity to develop as a professional facing more challenging proposals. In my daily work I use mainly C++11 for development and Python for scripting. I'm currently living in Argentia but wouldn't mind to reallocate. Don't hesitate to contact me for more information if you're interested. Thanks for reading.
&gt; Even though C++ is described as a multi-paradigm programming language, the truth is that most programmers will use C++ exclusively as an Object Oriented language [citation needed] (that is, I am a C++ dev who also uses free functions, lambdas, and structures - whatever is best for the situation at hand; my colleagues are the same). &gt; The way I visualize an OOP solution is like a constellation of stars [...]. &gt; What worries me, though, [...]. As I see it, [...]. How can we measure all these opinions? Why are they authoritative on what happens in programming? &gt; The fact that we‚Äôre ‚Äújust‚Äù solving the immediate problem at hand should be good news but, in my experience, when using OOP design principles, programmers write a solution while shackling themselves to a commitment that the problem won‚Äôt change significantly and, therefore, the solution is permanent. ... unless programmers decide later to re-write / re-engineer the whole thing. I think this permanence is in the OP's head only. &gt; I mean, from now on the solution is to be talked about in terms of the objects that form the constellation instead of e.g. data and algorithms; the problem has been abstracted away. Yes, abstraction abstract details away. &gt; What is very clear to me, though, is that code will always degrade into chaos and disorder unless consciously fought against. &gt; I‚Äôve seen this take many forms in OOP solutions: [descriptions of hacked-together solutions] Since OP is criticizing OOP here, but entropy is also present in non-OOP solutions, what forms does entropy take in _those_ projects? &gt; There‚Äôs a point in the lifetime of an OOP design where it has degraded to an untenable situation. ... as opposed to functional designs, where there is a point in the lifetime of the project, where it has degraded to an untenable situation. ... ... oh, wait! Experienced programmers say that when your application has grown in size ten times over the original version, it should be rewritten anyway. This is not only particular to OOP. &gt; There‚Äôs also the fact that OOP features are inherently poor performance-wise. I implemented a simple OOP hierarchy [...] Contrived anecdotal evidence cannot be used to demonstrate a generic argument: the "simple OOP hierarchy" the OP implemented is not a demonstration of the general inefficiency of OOP. If anything, it demonstrates it was inefficient in the case the OP chose (to demonstrate inefficiency). This is a straw-man argument. &gt; Given that the job of a programmer is to solve problems using computers, it‚Äôs mind-boggling that so much of our industry cares so little about [...] [citation needed] &gt; I‚Äôve had a lot of conversations about OOP and its inherent problems with different people and, although I think I‚Äôve managed to convey why I think the way I do, I am not sure I‚Äôve swayed anyone towards the non-OOP way. Maybe this post will help. Invalid arguments sometimes change people's opinions. This is not a good thing. &gt; ‚ÄúGood OOP wouldn‚Äôt do this.‚Äù, ‚ÄúThis is badly designed OOP.‚Äù, ‚ÄúThis code doesn‚Äôt follow OOP principles.‚Äù and similar variants. I‚Äôve heard this one when showing examples of OOP gone bad (I‚Äôve already talked about why OOP code invariably goes wrong). This is a clear case of the No true Scotsman fallacy. The "No true Scotsman" fallacy is not a "clear case" whenever somebody discusses a good (vs. bad) solution. "OOP gone bad" is (maybe) good design, that has _gone bad_. That doesn't make it a fallacy, it makes it bad design. &gt; I‚Äôm fully aware that identifying arguments as fallacies is not suficient to disprove their validity. It is sufficient actually, when the fallacy is clear. In this case it just felt ambiguous.
STL is a big library, so let's take the simplest question how in this "STL free" environment vectors are implemented? Specifically a dynamically growing array container that is easy to use with any class. Also STL is usually seen as containers&lt;-&gt;iterators&lt;-&gt;algorithms relation, how this is achieved in your environment?
Love his library. It let me easly define (in-place!) and upload geometry data to OpenGL. 
It's thoroughly unsafe. You need to use the glibmm abstractions to get safety via RAII. There is no templating, so all generic use requires the use of dangerous typecasts. I once ported a decent sized glib/gobject-based codebase to C++. I uncovered a number of hidden bugs whilst doing so. The amount of typecasting via `gpointer` (`void *`) removes a huge amount of context and hence typechecking the compiler can perform. I would not recommend its use. The C++ standard library is of far better quality. It will also perform better.
https://www.reddit.com/r/cpp_questions/
IMO this article isn't really comparing C++ against C, more it's comparing the use of generic library functions against hand-rolled use-tuned implementations - which are naturally going to be better, because they are specifically chosen for the use case! The very last step, going from hand-rolled C++ code to hand-rolled C code, actually made no difference at all, and the article even concludes "it doesn‚Äôt look like C is faster to compile than C++ assuming a compile time conscious subset of C++ is used - so at this point a switch to C isn‚Äôt warranted for meshoptimizer." The only thing that was really called out was that C++ has a bad compile time problem when it comes to its monstrous library headers... which is unfortunately true.
Thanks for the comment. Fixed https://github.com/Microsoft/snmalloc/pull/6
&gt; IMO this article isn't really comparing C++ against C, more it's comparing the use of generic library functions against hand-rolled use-tuned implementations - which are naturally going to be better, because they are specifically chosen for the use case! The fact that it's C++ is almost irrelevant for that part of the conclusion. Yet, limiting yourself to "basic" features of C++ ( not much std:: ), will earn you plenty of snarky comments, "C with classes", etc.
I've just added an important piece: How to pass arrays from JavaScript to C++: [https://medium.com/@tdeniffel/c-to-webassembly-pass-and-arrays-to-c-86e0cb0464f5](https://medium.com/@tdeniffel/c-to-webassembly-pass-and-arrays-to-c-86e0cb0464f5)
Would you consider using STL but template meta programming category only? E.g type_traits and numeric_limits
Hey STL, um I just want to say something you didn‚Äôt know for long You‚Äôre automatically generated
For good reasons. The author of the post is trying to squeeze maximum performance and compilation time improvement for a small component. That's not what you want to do 99% of the time.
Who would have thought that spending hours on replacing general-purpose components with minimal handwritten ones tailored specifically to one particular use case makes your code faster and quicker to compile? Revolutionary blog post!
TL;DR Yes
A wonderful attorney told me, what matters more than the particular wording of the contract is the relationship between the parties. It doesn't matter how "airtight" you think your contract is, if you can't trust the other side to operate in good faith. A prescription for behavior in a physical or virtual community ("CoC") is much like a contract. What matters more, is the integrity and good faith of the parties involved. So, while the wording of a policy is not useless, it is not the sole factor which determines its efficacy.
&gt; Let‚Äôs try to replace the only STL component we‚Äôre still using, std::vector, with a really simple dynamic array - we don‚Äôt need resize or push\_back in our code, all arrays are initialized with the right size. While I understand the issue with msvc STL debug (which mostly can be optimized by disabling all debug STL related defines), I don't understand the optimization. A vector is already a dynamic array underneath, push\_back usually don't cost much as it uses placement new to add new item (and with more complex type emplace\_back is better to use as it doesn't copy the data) and std::fill should be optimized for PODs. &gt; Some time last year during a regular lunch time C++ discussion at work somebody said ‚Äúthere‚Äôs a good language subset of C++, C with classes‚Äù, to which I replied ‚Äúthere‚Äôs an even better subset, C with structs‚Äù Better for what? Your [demo](https://github.com/zeux/meshoptimizer/blob/master/demo/main.cpp) is a perfect example of why this API is bad, you mix STL with raw pointers and c-style function calls, is ugly and doesn't follow any guideline. Maintaining such code (not this demo but an actual project written in this way) will be a joy for anyone who is either a C++ or a C developer.
\&gt; Not using unordered\_set in the first place what are the ready-made alternatives? 
`absl::flat_hash_set`/`absl::node_hash_set` will do the trick!
White IDE! Triggered!!
We have done sth. similar here: https://github.com/loopperfect/smallfunction
We had significant performance gains when using this approach also: https://github.com/loopperfect/smallfunction
I remember speeding up the execution of an OpenCV algorithm on iOS by replacing std::vector with a plain C array. Even though I add extra code to calculate the size at runtime and allocate the array, it was about 2x faster
If you are willing to forego allocation failures you can try this allocator : template &lt;class T&gt; struct pod_allocator { static_assert(std::is_pod_v&lt;T&gt;, "can only be used with POD types"); static_assert(alignof(T) &lt;= alignof(std::max_align_t), "type must not have specific alignment requirements"); using value_type = T; auto allocate(std::size_t num) { return (T*) malloc(sizeof(T) * num); } void deallocate(T* p, std::size_t) { free(p); } }; as well as this alternative vector implementation which does not initializes memory : https://github.com/aguinet/pector This will give you the exact same behaviour that you would have in na√Øve (but fast) C.
std::function already does keep things on the stack if they're small enough. If you implement your own you can obviously control the stack size, and also error out if the passed object is too big for the stack space instead of fall back to heap. Obviously making it bigger also has downsides though. If you're interested in this sort of thing, may want to check out: [https://github.com/WG21-SG14/SG14/blob/master/SG14/inplace\_function.h](https://github.com/WG21-SG14/SG14/blob/master/SG14/inplace_function.h). The thing about this approach is that while you do remove one indirection, it's at the cost of either inlining all your polymorphic functions, or introducing branches into a single polymorphic implementation function. And once you're talking about something stateful, you almost always have to have a polymorphic move, destruction, and maybe constructor. That's already 3-4 functions. IIRC std::function for this reason does the second option, it has a single polymorphic implementation function that then takes some kind of enum to determine what it's doing, or something like that. My overall point is that the way that the vtable is setup, performance wise, is actually very robust. Moving from a vtable towards a polymorphism alternative, in most benchmarks you can only gain a little at best, but you can lose a tremendous amount.
Maybe I'm an extreme outlier but that described a sizable portion of my career for the last 15 years. Squeezing every drop of performance and avoiding unpredictable latency.
What do you work on? 
PearsonVUE manages the process of taking the certification but who makes the exam? The standards committee? Bjarne himself? Does he correct the exams every night by the fireplace?
Embedded systems and signal processing (both together and separately).
The real C++ replacement for a plain heap array is `std::unique_ptr&lt;type[]&gt;`, not `std::vector&lt;type[]&gt;`. Of course the extra functionality `std::vector` provides is going to cost something.
Are you surprised by the fact that many components in the Standard Library might not be appropriate for your particular use case?
Job adverts should be posted to https://www.reddit.com/r/cpp/comments/abh8bm/c_jobs_q1_2019/ only.
That‚Äôs just a C array wrapped in a unique_ptr though 
The whole of NetApp storage software in Kernel space is free of any STL. Since exceptions were disabled and no calls to blocking memory allocation, they decided to avoid STL. We had wrappers around C implementations of different containers like list, stack queues. I implemented a tree based on C implementation of RBTree available in FreeBSD kernel. It was fun trying to implement all those wrappers with custom memory allocators and placement new, it was a PITA though!
Hopefully modules will fix that problem.
## Trading Technologies Seeks C++, Python, JavaScript for Chicago, Pune &amp; London üì∑ Company: Trading Technologies Type: Full time Description: We're seeking a C++ Software Engineer to join our Chicago team. Candidates should have extensive experience #programming and #coding in #C++. Several other roles are available in Chicago, Pune and London. Open positions include: Senior Software Engineer, Software Engineer, C++ Software Engineer, Automation Test Engineer, Python Developer, Data Scientist, Full Stack JavaScript Developer Location: Chicago, Pune, London Remote: Possible? Visa Sponsorship: Unsure Technologies: C++, Python, JavaScript Contact: PM me here on Reddit [https://www.tradingtechnologies.com/about-us/work-at-tt/jobs/](https://www.tradingtechnologies.com/about-us/work-at-tt/jobs/)
Out of curiosity and as someone not familiar with anything other than make, why does a build tool need to support modern C++?
Not at all. A lot of vocal users in C++ community do keep insisting that everyone should use ‚Äùidiomatic‚Äù C++ including STL and that the exceptional cases are extremely rare (while ignoring that in industry the realistic options are often only ‚ÄùC with classes‚Äù and ‚ÄùC without classes‚Äù).
So? (and to be pedantic: it uses C++'s `new[]` and `delete[]`)
This is what you fail to understand: "idiomatic C++" is not the same as "Standard Library". No matter what hardware you're targeting, features such as RAII, move semantics, lambda expressions, templates, fold expressions, namespaces, references, `constexpr`, attributes, `auto`, `explicit`, and more... will come in handy to have a safer and more maintainable code base. If `std::unordered_map` or `std::vector` are not appropriate for your particular target, it is silly to drop many other useful features the language offers just to revert to "C with classes".
Good debugger! use it too
I for one like the article. Not because it contained anything particular suprising but because it provided real measurements for realistic problems evaluating (largely) realistic parts of the design space. The standard library contains mostly general purpose functionality and that just doesn't come for free. On the other hand, it is readily available, doesn't require maintenance from me and often beats more targeted but naive custom implementations.
std::array and std::vector are just wrappers for c arrays too.
As fasts as you can, no more, no less.
Oh! Glad it was helpful to you, thank you for sharing your work
&gt; Not because it contained anything particular suprising but because it provided real measurements for realistic problems evaluating (largely) realistic parts of the design space. Had the article been framed with that in mind, titled appropriately, and had appropriate conclusions, I would not have had a problem with it. The measurements are valuable. The issue here is that this was written just to create more fuel for the "C++ is slow" and "abstractions are bad" fire that has been raging on Twitter.
‚ÄúYes‚Äù
Personally, I think using STL as an abbreviation for the c++ standard library is totally fine. In typical conversations, no one cares about the original STL and "c++ standard library" is usually the only meaning that makes sense in the context anyway.
There is big difference between your approach and the one author used, in your case the C interface/logic is wrapped in C++ utilities so in production code there will no impact on productivity (as much as it goes for C++). To use optimized OP library in a C++ codebase a wrapper will be needed anyway, because mixing heavy C++ with C is a pretty bad idea. This is what other people here mentioned as well, one can't just take a general purpose library like STL then made an optimized library for specific task and then conclude that general purpose library is not as fast as an optimized one. 
&gt;Of course not. Hmmm - how is that supposed to work. a) Someone is giving a talk which includes a statement which some number of people feels crosses some line. b) Someone else stands up and shouts: "STOP I claim a code of conduct violation!" c) Then some committee is present and debates the statement among themselves while everyone waits around for the decision as to whether or not the talk should be permitted to continue? Or what. The whole idea is just ridiculous. Here's a better idea. a) Someone is giving a talk which includes a statement which some number of people feels crosses some line. b) Those people shout "Boooooooo" c) the speaker decides to ignore it, apologize, rephrase or whatever and move on. d) The program committee can consider the incident when it next approves presentation. In 10 years of going to conferences, this is the first time I've ever seen something rise to this level. Of course from time to time someone has made a tasteless comment that they probably regretted. (I'm sure I've made a few, though I don't actually remember regretting any.) This is a manufactured problem. The offender has pretty much acknowledged this. Chuck the whole CoC Bullshit. It's just a way to try to hijack a technical conference to bully random people into feigning support of views that they might not believe in. 
If you read more carefully auto f = int2str{}; f.base_ = 16; f.len_ = 8; was just one of the options. I am bringing designated initializers b/c my example is totally ready for it. The line you mentioned is almost that and could be replaced (as @louiswins noticed) in c++20 with int2str{.base=16, .len=8}(2019) without any modifications int2str. I think it is a good thing.
All platform and language headers are confined to the virtual kernel layer, plus a small number of low level facilities that wrap less used functionality. So that wouldn't be doable. I've implemented various things myself, like the stuff required for move semantics, and some others that can be done without magic. But some things (unfortunately IMO) are now privileged operations that we can't do ourselves. &amp;#x200B;
Nicely written article. Just to add my 2p in the mix, the correct way of specifying Emscripten as your compiler is to use the toolchain file that ships with Emscripten with \`cmake -T &lt;EmscriptenRoot&gt;/cmake/Modules/Platform/Emscripten.cmake\`. Besides being far more pragmatic CMake which keeps your CMakeLists.txt file clean of Emscripten specific code, it is cross-platform compatible across Windows, Linux and macOS.
I'm not prepared to dig into the details. But there are collections (my term for containers) and cursors (my term for iterators.) I don't do the begin/end thing. Cursors are primarily there for two reasons. One is to pass out a way to iterate a collection without exposing the collection. The other is to have a mechanism to iterate/modify collections by multiple bits of code and have them be aware if the other has modified the collection in a way that requires them to reset and start over. Oh, there's a third reason. My collections and cursors are polymorphic. So I can get a collection via the base collection class and ask it to create a cursor for me. I can use that to iterate the collection polymorphically, which is very useful. Actually, that's how the ForEach guy is implemented. It's done in the base class, which just asks the derived class for a cursor, and it uses that to iterate and call the lambda callback. Derived classes might provide their own versions of it, which provide information specific to them, like the current index for an indexed one, or the current key for a keyed one and so forth. For me, if the collection is indexed, and I'm using it literally, not polymorphically, and ForEach isn't useful, then I just iterate it with an index. I'm not one of those folks who considers a for loop to be a failure.
It's too much to post here, and I need to explain it. So the video is the most practical thing. But, I mean I go straight down through each file slowly. So it's not hard to check each section out repeatedly.
Just a link to the actual source couldn't be so hard...?
Just consistency mostly. Keep in mind that this system is highly portable, so each platform implementation of the virtual kernel layer has to define types for various things that are correct on that platform. And it would just be inconsistent to have some be in the namespace and some not. See the virtual kernel video for how all that works. &amp;#x200B;
That's for commenting, but of course, as you say, a matter of opinion. Some folks don't like Hungarian. But, you plop me down in any spot in any of the many thousands of files in this system, and I can tell you what everything is without even having to go find their declarations. That's a useful thing. Sometimes I can only tell what 'family' it is, but still, very useful. Families of related classes use a family prefix. like col for all the collections. &amp;#x200B;
Wonderful. Thank you. I will add this 
Yeh, I should have been more specific. I don't use any of the standard libraries, templatized bits or otherwise. Sorry. Of course initially I was going to try to be overly cute and say "Living STL-Free", as a reference to living STD-free. But I figured that wouldn't go over well, at least by those who got the joke. &amp;#x200B;
Not an IDE of course, just a text editor in that case. I kind of like the white look, though I use the dark ones in Visual Studio when I work on other stuff besides my own.
Love my NetApp, that support license is expensive though!
&gt; This is what you fail to understand: "idiomatic C++" is not the same as "Standard Library". But that's exactly what /u/SkoomaDentist and myself are talking about. Many will argue that hardly using std::whatever is not true C++, especially since people throw "modern" here and there as if it had any value in itself. Use a raw pointer and you're a heathen and so on.
Some of them, yes. Others less so. And in embedded systems, system design constraints (cost and absolute cpu &amp; memory limits) _trump all other considerations_ - whether online C++ advocates like that or not. If templates increase code size so it exceeds flash, those templates will simply not be used (I just had to hack stuff so using a templated container wouldn't increase the code size by 20%). Whether they make the code more idiomatic or not. Additionally a lot of the time raw pointers simply fit to the problem best. You're handed sequential raw data from outside that you need to process and you're not allowed to allocate any extra memory. There's little point in wrapping that inside a container just to satisfy random demands for "idiomatic C++". And on top of that lambdas, fold expressions etc introduce a whole another level of complexity on top that everyone in the team then has to deal with. In this field domain expertise and generic programming skills _vastly_ outweigh C++ specific expertise. Ultimately what I'm against are the very common demands (just see this very thread) that everyone _must_ use "idiomatic C++" because, well, just because. Even when doing so would simply bring in unneeded complications for no gain. Whatever happened to the concept of not paying for things you don't need?
C++ compilers aren't slow at all, they are on average blazingly fast... But, the code is often deceptively large. A traditional iostreams based hello world program is about 30,000 LOC on my machine after the preprocessor has run. So when gcc takes 1 second to compile a REAL program source file, it's probably chewing through over 100K LOC in that second. (There are exceptions of course, templates and linking are notorious in their "not very fast" reputation)
Bottom line, we need modules and we need our library headers to be more streamlined.
Ah well, I don't read Twitter so... ;) (But I think I read something about that here on Reddit)
No problem, and thank you for sharing!
msvc debug iterators performance is abysmal. Is there a chance for them to be fixed? And maybe being replaced by proper instrumentation like a memory sanitizer?
You shouldn't listen to people who advocate for something without giving you a reason why. I can provide good use cases for every feature I've mentioned (and bad use cases, as well). --- &gt; Use a raw pointer and you're a heathen This is not an argument, and comparable to when people say *"C++ is overengineered garbage"*. Idiots are on both sides. What I would tell you is that if you're using a raw *owning* pointer, you could very probably do better in C++, as we have RAII. If you're using a raw pointer as a *view* over an array, you could very probably do better in C++, because you can create a lightweight abstraction for that, safer and without performance costs.
PCHs already take care of that.
&gt; If templates increase code size so it exceeds flash, those templates will simply not be used That's perfectly fine. But it's different from saying *"never use templates, templates bloat your code"*, which is the kind of "snarky" comments I am against. --- &gt; You're handed sequential raw data from outside that you need to process and you're not allowed to allocate any extra memory. There's little point in wrapping that inside a container just to satisfy random demands for "idiomatic C++". Sounds like a use case for something like `gsl::span`. There is point in wrapping a raw pointer, as it clearly states the intent of your code (a raw pointer could be used in tons of different way) and increases its safety through a more limited API. If you use a raw pointer when you could have used a lightweight abstraction over it that doesn't affect codegen, then I will rightfully suggest you to make use of what the language offers. Even a simple "strong typedef" around a raw pointer is often good enough to increase readability and decrease chance of bugs. --- &gt; lambdas, fold expressions etc introduce a whole another level of complexity on top that everyone in the team then has to deal with Educate yourself on the features, play around with them. After that, if you think they're valuable enough, educate your team. That's what I did at my company. --- &gt; everyone must use "idiomatic C++" There is no definition of "idiomatic C++". What people often endorse is to use C++ language features to make your code safer and more readable without additional run-time overhead. 
the ska::flat_map family is pretty good
Is this really "Integrating C++ Libraries in your Xcode Project" or rather "Integrating ‚Äã‚Äã‚ÄãC++ Libraries with Swift"? That aside, I think it's a bit horrific that the dependencies are just all copied (?), which makes updating them a huge hassle, as well as keeping track of their versions. And also all these manual scripts... this should really be handled by a build system and package manager, shouldn't it?
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
The first problem has a solution called headphones, if you wear them for an hour it shouldn't be a problem hopefully. I completely agree on the second point. You can remedy it somewhat by watching at 1.25x speed but that'll of course be too fast then for the hard parts. Anyway even if you like text (I do too), videos have their advantages too, e.g. you can watch them laid-back in your chair without having to actively scroll through a document.
That looks like it's making an awful lot of claims it can't keep - Most notably, that's doesn't look like C++ to me. It's C++/CLI.
`constexpr` functions are allowed to be computed at compile time, not required. Your program is also probably too short for benchmarks to give any meaningful results. You can force compile time evaluation using a `constexpr` variable: constexpr auto i = fibonacci(44); return i;
Or possibly OP hasn't enabled optimizations, see [this](https://gcc.godbolt.org/z/kMpBNw) compiler explorer example.
Also, compilers are allowed to evaluate _non_-constexpr functions at compile time as well - so it may already be calculating this at compile time. You'd have to examine the disassembly to be sure.
Interestingly this only works up to 91 after which the compiler gives up trying to compute it. 
 It works! &amp;#x200B; Tell me more, why the same program with constexpr gives the result for fibonacci(50) immediately , but without constexpr execute for a very, very long time? Where does the compiler know how to calculate it quickly? &amp;#x200B; It even calculates fibonacci(91)!
There are a number of sentences which are either incomplete or or are not being rendered properly in the document.
The cost is commensurate with the work they are doing. Full debug iterators (the default) does more than just range checks, if you want that turn it down to \_ITERATOR\_DEBUG\_LEVEL=1. It's also not so different to \_GLIBCXX\_DEBUG=1, people just complain because it's at maximum by default in debug builds. [https://docs.microsoft.com/en-us/cpp/standard-library/iterator-debug-level?view=vs-2017](https://docs.microsoft.com/en-us/cpp/standard-library/iterator-debug-level?view=vs-2017)
To optimize the Fibonacci function, either just calculate the values in advance and use a table lookup, or calculate the value directly (using a power involving the golden ratio).
GCC is probably caching values as it goes along when running at compile time (it can because constexpr guarantees the function is completely deterministic) so it only has to run 91 iterations. At runtime, or on Clang at compile time, no caching is performed and it runs in O(2^X) time - which for 91 depth would be 2,475,880,078,570,760,549,798,248,448 - that's a very big number and explains why it can't calculate it. It's worth noting you can fix it to go much faster (and probably calculate further at compile time) by switching to an alternative algorithm for calculating Fibonacci numbers which isn't based on dual-recursion.
The compiler decides what to calculate during compile time and what not. And it will do that for everything that's possible to calculate at compile time which is great because you don't have to do anything for that. So why is there constexpr? It's basically a control mechanism, it's there to make sure that you do not use anything that can not be evaluated at compile time. It just limits what you can do.
It actually started out as an SBO capable class, but there are some cases where people want to guarantee that a piece of code will behave predictably every time it is run. So the goal is not pure speed, but consistency in the time taken to perform an operation. When you heap allocate on an OS you probably have no way of knowing how long that allocation will take, and it might be different every time. Add SBO to the situation and the actual operation does different things depending on the size of the type. My class throws compile-time error if the size is incompatible. [Check it out](https://github.com/tacticalmelonfarmer/handlebars/blob/master/include/handlebars/function.hpp) if you want.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [Living in an STL-Free environment](https://www.reddit.com/r/programming/comments/ahdkjx/living_in_an_stlfree_environment/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
If you think about, \`std::launder\` is essentialy a standardized compiler instrinsic function.
After 91 the result doesn't fit into a "long long". You have to go to extended integer types, or use a floating point number and accept the inaccuracy.
The unfortunate part about constexpr functions is that their arguments cannot be constexpr, meaning you must store all data in the type, I recommend using `std::integral_constant&lt;type, #&gt;`.
Mate, I know. I am only interested in the technical aspect of the compilation. :-)
&gt;Interestingly this only works up to 91 after which the compiler gives up trying to compute it. 92 if you use unsigned long long :D
&gt;GCC is probably caching values as it goes along when running at compile time (it can because constexpr guarantees the function is completely deterministic) so it only has to run 91 iterations. At runtime, or on Clang at compile time, no caching is performed Can not perform buffering during execution? It is not expensive (91 \* sizeof(long long))? Is there any switch for buffering recursion results?
At runtime, C++ doesn't do anything for you - if you want to buffer the results, you have to do it yourself. At compile time, I just don't think Clang has implemented that.
I know its a c library, but this may be of interest [DPDK ring buffer](https://doc.dpdk.org/guides/prog_guide/ring_lib.html) (/[mempool](https://doc.dpdk.org/guides/prog_guide/mempool_lib.html))
To nearly **guarantee** constexpr function evaluation store all data in the type, a great option is `std::integral_constant`. Otherwise the compiler will most likely choose to not evaluate at compile-time. Even using constexpr variables and passing to constexpr function might not evaluate at compile-time, due to the constexpr variable being an actual object. This is counter-intuitive and in my opinion needs some remedy at the language level.
Well I know, I meant that it could optimize it during compilation (why not?). Of course, this is not a problem formally.
As u/TheThiefMaster mentioned: &gt; constexpr guarantees the function is completely deterministic If the compiler has access to the body of the function theoretically it could apply a similar optimization to a runtime function if it can accurately detect side effects, but that's a harder problem than it sounds like and determining _whether_ such an optimization is appropriate for you application is even harder. For example, if, under normal operation, this function will only ever be called once and with a parameter of like 9 or something, caching would be a pessimization - make it slower.
You can also do something like: template&lt;auto Value&gt; static constexpr auto compile_time_constant = Value; And then you can do `compile_time_constant&lt;value&gt;`, and it will be guaranteed to evaluate at compile time.
Take a look at the output on compiler Explorer. &amp;#x200B; With constexpr: [https://gcc.godbolt.org/z/8VHpCB](https://gcc.godbolt.org/z/8VHpCB) &amp;#x200B; Without constexpr: [https://gcc.godbolt.org/z/tHXG-r](https://gcc.godbolt.org/z/tHXG-r) &amp;#x200B;
absolutely, add a user defined literal and you've got super nice syntax: template &lt;char...&gt; constexpr auto operator "" _lit() { ‚Ä¶ }
So what's the Hungarian notation for an auto? lol. 
How do you include and link against std::experimental parallelism libraries? 
Probably not for use, but for learning implementation techniques certainly useful. 
It's part two of Integrating Swift with Objective-C and C++. You can see [part one here](https://learningswift.brightdigit.com/objective-c-and-swift-being-friendly/). I agree context would help. **And yes, I agree. This sucks.** As someone who's used Cocoapods, SPM, NuGet, NPM, Gems, etc... this is a mess. I think once Swift accepts C++, you should probably be able integrate C++ libraries using the Swift Package Manager. The other thing I thought about doing is to automate this is using [brew bundle]. Unfortunately, homebrew doesn't support installations by version number: &gt; Homebrew does not support installing specific versions of a library, only the most recent one, so there is no good mechanism for storing installed versions in a .lock file. https://github.com/Homebrew/homebrew-bundle 
In those fairly rare cases where the type is not fixed and it's known not to be an object, it's just 't' for type. That's used, for instance, in the indexable collections, where the index can be a number or an enumeration. So the type of the index, in the collection interface, is 't'. The actual users of the collection know what the type of the index is of course. The TObject class from which almost all classes derive, has an obj prefix. Any time it's something known to be an object but not of a specific type, then obj is used. So, for instance, that's used in the interface of the collections that hold objects (and some other things like counted, managed, etc... pointers and such.) &amp;#x200B;
Interesting. Something like this was created at Microsoft for internal use around 2008-2009. It was used to develop system apps for the now defunct Windows Phone platform. The problem was that the performance of .NET framework on ARM left a lot to be desired. But there was already sizable investment in C# code for that platform. So a some team developed a C# to C++ transpiler. It generated C++ code from C# code. The resulting C++ code could be compiled by a much better optimizing MSVC compiler and linked with a native replacement for .NET libraries. The end result was a native executable without JIT or GC with a much better, predictable performance. The development still continued in C#, whereas C++ was used just as an intermediate language. Of course, the transpiler was limited to a subset of the C# language and .NET libraries. But it was still quite an effective solution at that time.
Great to see C++ possibly becoming the de-facto WASM language.
Don't use getch, sdl has keyboard input events. 
&gt; \&gt; `_getch()` &gt; &gt; \&gt; $CURRENT_YEAR wut
&gt; If anyone can tell me how to format code for this sub I'd appreciate it! Indent four spaces: &gt; Lines starting with four spaces are treated like code
Not sure if this is something you are looking for. I saw it being used by the Tracy profiler under a quite heavy workload with hundred thousands of events per second from multiple threads. https://github.com/cameron314/concurrentqueue
How do I use that?
You're already using SFML events, `if (event.type == sf::Event::Closed) ...`, now get rid of the current keyboard handling and add handling for Keyboard Events in your main loop. if (event.type == sf::Event::KeyPressed) { if (event.key.code == sf::Keyboard::Escape) { std::cout &lt;&lt; "the escape key was pressed" &lt;&lt; std::endl; } } and so on, see the [Event Handling Tutorial](https://www.sfml-dev.org/tutorials/2.5/window-events.php). There are also links to read the keyboard state directly, but start with events. 
I tried that and it just deletes the spaces and treats it like regular text.
Thank you!
Yes, but you have to realize as well that being SBO capable, or SBO-or-error, is completely orthogonal to whether you use inheritance or lambda to implement your std::function. Inheritance is actually quite a bit easier to reasonably implement than lambda decaying to function pointer approach, when you consider having to deal with move, copy, destruction, and the fact that an inlined vtable is horrible. Personally unless I had a lot of time to devote to both getting the details right and to really carefully measuring performance, I would for sure start off by using inheritance because the implementation is very, very easy (well I would just use something off the shelf I trusted, but you know what i mean).
[https://github.com/aguinet/pector](https://github.com/aguinet/pector) seems nice (and also well documented) until you realize it hasn't been touched since February 2015, and there are open issues still from 2015. This does not necessarily increase my trust in this project.
C++ is blazing fast. In the worst case you will get Performance of the C. In the best case you will slightly outperform C code. Of course a bit of work and knowledge is required.
The same author also has a SPSC queue: https://github.com/cameron314/readerwriterqueue
[libcds](https://github.com/khizmax/libcds) (Concurrent Data Structures) is a collection of a variety of lock-free algorithms and data structures, including queues.
Also Dmitry Vyukov has a collection of lock-free queues: http://www.1024cores.net/home/lock-free-algorithms/queues/queue-catalog
Absolutely the implementation leaves a lot to be desired, but I've found the algorithm to very flexible and efficient when converted into c++
I think the title of the post is the worst part. The methods and results seem to be fine, but as you and others have said, the hand-tuning is what makes the difference. 'Is C++ (vs. C) fast?' is not the real question here.
The 3 visible examples seem like just regular old C++11 to me.
Completely agreed. Without the clickbait title, this post would have been informative and valuable.
i updated the post with a non-lambda approach. The [old](https://github.com/tacticalmelonfarmer/handlebars/blob/390e0911ea06a7afdab9572d68c8dc74ec19997b/include/handlebars/function.hpp) version of my function class used the standard inheritance and virtual functions approach. It was worse in terms of amount of generated code.
Do you have access to physical page remapping? Ring buffers are easier and faster when you can remap the buffer after itself.
For most projects yes. Does this make a significant difference, when you only store fixed sized items?
I updated the code to your suggestion and there is still the same pause. How do I get rid of it?
This part is important: ‚Äî csPorter for C++ reproduces original C# type system in the converted C++ code, that is; csPorter for C++ uses its own analogs of original .NET types rather than closest STL substitutes. This allows using the types in the same way as used in the original code by calling specific methods absent in the STL substitutes. ‚Äî So I believe it is native C++ but has special defines/classes to look like the .NET types on purpose. Which in this case look like the C++/CLI types. It‚Äôs confusing to read, because I agree it just looks like managed C++ with missing ^.
Note that for a use case that mostly relies on iteration (not insertion or lookup), abseil isn't a very good choice. after *a lot* of benchmarking, I ended up using `absl::flat_hash_map`s, but staying with `std::set`s. It's also worth pointing out that I'm iterating over `std::unordered_map&lt; std::string, std::shared_ptr&lt; std::unordered_map&lt; std::string, std::shared_ptr&lt; std::set&lt; const LargeStruct * &gt; &gt; &gt; &gt; &gt;` that I replaced with `absl::flat_hash_map&lt; std::string, std::shard_ptr&lt; abs::flat_hash_map&lt; std::string, std::shared_ptr&lt; std::set&lt; const Largestruct * &gt; &gt; &gt; &gt; &gt;`.
They really don't. They're compiler dependent, with compiler dependent semantics and caveats. In many situations they don't help at all or make the situation actively worse.
That's a strange usecase. Why do you need so much indirection? I'm especially curious why you're using shared_ptr in this case. Can you explain? I work on Abseil fulltime for my job, so if there's something I can do to potentially help, feel free to let me know.
We ask employers to follow a consistent template so the postings are easily scannable. We don't want to be too harsh about it, but could you remove the large-font header? Also, your Location should appear on a separate line. (And you should bold each section with two stars, as described in the template.) Thanks!
Yep, it's a valid use of metonymy, and as an STL maintainer, I have the sovereign right to bless this usage.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/aheprb/get_rid_of_pause_when_pressing_arrow_keys/eeeb03l/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
There's nothing CLI related in the examples. Rather looks like they're just more-or-less modeling the .NET class libraries as C++ classes. Not sure what they're doing about GC and all that though...
Is the buffer size divisible by the item size? Is the page size divisible by the item size? If they are truly fixed-size, then no. The advantage is when you can have objects that overlap the end and beginning of the buffer - looping it in virtual memory makes that free. That's how I implemented a gpu command buffer for the XB1, actually. Though it was a *bit* more complex than that.
Something I find interesting about all this stuff is that folks worry about stylistic stuff so much, or obsess about the fact that I'm not using the standard (not so much here but badly in some other threads.) I've had people argue me down that I'm clearly incapable of writing a vector class, that only people who write the standard libraries can do that. But, looking at the standard libraries to try to maybe get more up on them, I find things like (as best I can tell) there no such thing as built in binary object streaming support supported universally. That's so fundamental to everything I do, and built in from the core my system, that I cannot imagine how people can do realistic work without that. Even just if you look at the ORB video, and how every object that supports the MStreamable interface can be passed back and forth as parameters to remote calls. I can't imagine living without that, but it fundamentally depends on binary streaming of objects being supported at a fundamental level. Same for the object database, or for storing all sorts of bits of info here or there without the time consuming and error prone need to convert to/from text formats. Or translatable text. That's fundamental to almost any GUI application. I have that built in at a fundamental level and couldn't live without it, but as best I can tell it's not supported by the standard libraries? In my systems it's used both for exceptions and for translatable text, automatically loading the text for an error code when it's thrown or message when it's logged, with token replacement, all in one shot. Or you just create a string with the msg id and any tokens and it loads the string and does the replacement. And I'm completely spoiled by my really powerful enumeration support. They are just so useful on a day to day basis in so many ways. &amp;#x200B; It's work-a-day practical stuff like that, to me, that seems the most important. I get that it's cool that there are a hundreds of algorithms that can generically work on containers, for instance. But that almost seems a little bit academic to me compared to less flashy, but very practical, capabilities like the above. I'm sure that there are third party bits and bobs that can be used to provide some of these things, but that means that they cannot be built in at a fundamental level and universally supported.
&gt; That's a strange usecase. It is and that data type is a monstrosity, but let me elaborate. &amp;nbsp; I initially replaced the `std::set` with `absl::flat_hash_set` (along with hash map replacement) and was surprised that simply using what STL provides is much faster. So I started [a discussion about my benchmark](https://github.com/abseil/abseil-cpp/issues/223) on the abseil repository. To be clear, I'm talking about the IdentifierDatabase benchmark. What is this used for? The code "scans" files a user has open in their text editor and populates the map with available code completions based on the already seen identifiers. The identifiers are categorized by filetype and filepath. That way, when presenting completion candidates, the candidates from different languages won't be interspersed. This explains the nested maps, but not pointers within the maps. With that in mind, let's rewrite the type declaration as something more readable: using FileType = std::string; using FilePath = std::string; using SetOfCandidates = std::shared_ptr&lt; std::set&lt; const Candidate * &gt; &gt;; using FilePathToCandidatesMap = std::unordered_map&lt; FilePath, SetOfCandidates &gt;; using FileTypeMap = std::unordered_map&lt; FileType, FilePathToCandidatesMap &gt;; Why so many pointers? I'm not sure, this piece of code has been there for more than 5 years (before I joined the project). However, this type is used only in `IdentifierDatabase` class as the type of a private member and access to the data that this map contains needs to be thread safe, so it is guarded by a mutex. The threads are spawned by the python layer, but the infamous GIL is released as soon as python invokes any C++ function. Like mentioned in the abseil repository discussion, the tight loop is [here](https://github.com/Valloric/ycmd/blob/master/cpp/ycm/IdentifierDatabase.cpp#L68-L112) and despite the monstrosity that this type is, filtering and sorting of candidates takes ~50ms for 65k total candidates in the database.
Well, at least most of the use cases I encountered so far were either fixed size, or close enough that using the maximum item size for general slot size didn't seem too wasteful. Would still be interesting top see how such a budget for variable objects should be implemented. 
Apologies! I will post in the correct sub next time.
Same. I've never gotten it to be worth anything with navigating c++, so unfortunately I haven't been able to make use if it. 
That's partly true. It has been said that they are indeed horribly slow, even for the work they are doing. This is even worse in multi threaded environments. The reason it is still slow is that they can't break the ABI, so yes, there is a chance for them to be fixed, it has been said by some of the devs themselves, but no, not soon, need to wait for the next ABI break 
Gotcha! Thanks for the detailed explanation. As much as I'd like to help, I think this ends up being outside my area of expertise. Derek and Sam replied quite a bit on Github, so if they weren't able to solve the issue, I don't think I'll be able to, sadly. :( I didn't see any mention of a profiler in the comments, though. Have you been profiling production use? I curious if your benchmarks match reality.
Yes, I already got a few great tips from them, though before I migrate to abseil I need Python 3.4 to reach end of life, because of [ths](https://github.com/abseil/abseil-cpp/issues/235) and it would be nice not not mess with abseil internals just to set `-fPIC` as mentioned in [this report](https://github.com/abseil/abseil-cpp/issues/https://github.com/abseil/abseil-cpp/issues/225) (even though it affects only debug builds for whatever reason). &amp;nbsp; The benchmark is running a very extreme case where all candidates in the database have a common start of string (`a_A_a_`). Querying those with `aA` matches every candidate, but also renders all the cleverness of the comparison function useless because both `a` and `A` are considered "word boundaries". Again, this is the extreme case. An actual user will have a set of candidates in the database that differ more, so the filtering and sorting will have a much easier job with the real world use case.
Disclaimer: I'm working on what he might consider external tooling. I disagree with lumping external tooling in with macros. I'm not using macros either, but am interested in on-line code generation. Some may label on-line code generation as external tooling, but it doesn't imo have the same baggage that macros have. One of the benefits of [my approach](https://github.com/Ebenezer-group) is portability. It minimizes the amount of code that has to be downloaded/built/maintained. Probably you can download and build everything in 20 seconds.
Back in the dark ages, you'd download the source code for each dependency, compile it with compiler settings compatible with your project, and set up the include paths on the command line.... Things are better now, but there still is no official C++ package manager. You have a couple choices. You can use an OS level package manager to install packages: \- dnf (CentOS/Fedora) \- apt (Debian/Ubuntu) \- brew (macOS) \- pkg\_add (OpenBSD) The list goes on, usually the package names will have -dev or similar in the name indicating they come with the C/C++ headers. E.g. libboost-all-dev Then there's some C++ specific package managers which are useful for enterprise-level development tasks: \- [conan.io](https://conan.io) \- vcpkg \- nuget These are useful when you need to test against multiple versions of dependencies, etc. 
I use the moodycamel queues a lot. I write trading systems, so heavy workloads and low-latency is a must.
Variable is easy with virtual allocation. Without it, you have to check in every allocation if you are straddling the edge. You can then either split it (which makes reads slower), or pre-pad it to realign it to the start of the buffer. Either way, more branching.
Vcpkg is quite nice
This isn't the first time I recall you claiming that `auto` reduces compile-time safety, but I've yet to see you explain *how* in a meaningful way.
+1 for Moodycamel SPSC. Using it for producing frames on one thread for consumption on another.
Yeah it would be interesting to see it properly after all these mighty claims. 
You are awful misinformed. Other languages got modules in no time because they Pimp all their stuff. 
Auto takes the type of what you assign to it. If you accidentally assign it the wrong thing, it will just happy take that type. If the thing that you assigned to it just happens to implement the methods/operators you apply to it subsequently in that method, the compiler isn't going to complain. That's perfectly correct from the compiler's point of view. If you say specifically it's a TGoober object, you can't assign something unrelated to it. Here is a really simple example, but I think it's not unlike the way a lot of folks might use auto when it's not a good idea. class TFoo { public : TFoo&amp; operator++() { i++; return *this; } int i = 0; }; class TBar { public: TBar&amp; operator++() { i++; return *this; } int i = 0; }; // These would really be somewhere else in reality TFoo&amp; someFoo() { static TFoo fVal; return fVal; } TBar&amp; someBar() { static TBar bVal; return bVal; } // And we need to update some stuff so this is called static void SomeMethod() { // Get the foo object and increment it auto&amp; target = someBar(); ++target; } The comment clearly says we are getting a foo object and incrementing it. But, since target is auto, it just let us set it to a bar object without complaint. The bar object implements everything we are calling (not hard in a lot of cases), so the compiler is perfectly happy with this. All you need to make that compile time safe is: TFoo&amp; target = someBar(); And that problem gets caught. &amp;#x200B; Templates aren't an issue in this way. Templates INCREASE compile time safety, which is one of the major reasons they were invented. Before they came along, we had to use void pointers and such to create generic collections of objects. So the point of them is to be able to create strongly typed generic code. &amp;#x200B; Auto is the opposite of that, or can be. It can reduce compile time safety because it makes it easier to make mistakes that the compiler can't catch.
And of course it can be a lot more simple than that. It could just be that later someone accidentally changes the right hand side making changes. He never realizes it because it compiles perfectly fine, and the error may not be remotely obvious until it's in the field. Using the explicit type makes that a lot less likely to silently happen. &amp;#x200B;
That's a convoluted example, and you haven't actually proven anything. You've just moved the requirement from having the function name right to having the type name right. You can still provide the *wrong* type name and get incorrect behavior - it isn't any safer. In fact, it's worse - it gives you the *illusion* of safety. Now you're confident it is correct because you didn't use that dastardly `auto`, but you *did* type the wrong type name. Oops! I will also reiterate what I said before - if your code is architected in such a way that `auto` can *legitimately* cause type/behavioral confusion, your design has *serious* flaws. The interface of a class, in the end, should represent its functionality. If you have two classes with equivalent interfaces, they *should* be interchangeable. If they're not, why the heck do they have equivalent interfaces, especially in a context where you could trivially access them both? Equating `auto` to `void *` is just nonsense. They don't function similarly in any fashion, and `auto` retains type. Show me a *real* instance of well-designed, or even average-designed, code where `auto` induces behavioral ambiguity. Not a constructed instance. A legitimate situation where the user could get the wrong type that is 100% compatible with the rest of the code, and isn't due to an obvious programmer error. Preferably one where the user *also* could not trivially use the wrong type and have a similar problem. I'll be waiting. I've been using C++ for a *very* long time, and I've been using `auto` since it has been available. I have *never* run into a situation remotely similar to what you've described. From my perspective, it is either fear-mongering, or masking a poor design of a code base by blaming the language. I don't really like either.
So every class that supports streaming should be interchangeable? It doesn't matter if you stream out the system configuration data to the user's account settings? Anyway, I'm not wasting any more of my life on this discussion. You obviously can do whatever you want. I'm not getting paid to change your mind on this or any other subject. 
&gt; Chuck the whole CoC Bullshit. No. If you don't like it, maybe CppCon or C++Now aren't the right communities for you. 
Personal attacks against the OP are not advised.
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ahhn5e/using_a_thirdparty_cpp_library/eeezbit/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I used both in production, never failed me yet
It still is interesting, the title is just misleading.
Well if the point is just to make vector default-initialize elements rather than value-initialize them, then that can _also_ be trivially accomplished with a custom allocator. But, if one really wants it baked into the data structure, Boost.Container's `vector` implementation supports this explicitly.
You may wish to consider using CSS to format your code rather than taking a picture of it on your desktop; this formats poorly and makes the text look blurry due to non-integer image resizing. 
Overall, an interesting article with clickbait title to draw people in.
He notes at the end that the only real issue with C++ is large library headers, which C lacks. Avoid those, use optimized code, and C++ vs C becomes a game of preference.
The conclusion points out that C++'s ***real*** problem is its behemoth library headers. Avoid those, roll your own lightweight replacements, and all is well.
"Yes" ~ if you avoid the standard library.
In the worst case, you use the STL and you definitely don't get C-like performance. Best case, C++ can definite match C in performance ~ avoid the STL, use your own optimized code.
Depending on which version he was using that can make a big difference. For example, just sucking the reallocating part of emplace_back into a separate function (which allowed the backend to inline the 99% non-reallocating case) made a bunch of benchmarks run 3x faster. vector's code is complex in a lot of cases too due to needing to support EH scenarios that inhibit the optimizer. I've been trying to fix most of those by changing the EH related stuff to use destructors instead but it isn't an all done thing.
Tidy lib. What is the error handling concept applied?
I don't actually think this is iterator debugging's fault. At least, it has not been in similar examples I've been submitted in the past. &amp;#x200B; The times when it was iterator debugging's fault were when we had things that were slower big-Oh in there. &amp;#x200B; There are certainly cases where it can be iterator debugging's fault, but those cases are usually when people are making a lot of iterators into one container that make the list management expensive. Notably, it isn't related to operator\[\].
Heavily threaded code is indeed one of the places where it can be iterator debugging's fault. The iterator debugging data structures are protected by a single global lock shared by all debugging machinery, which breaks down when you have like 40 CPUs of stuff constructing and destroying iterators. It really should be per-container locks at the very least but that's a difficult thing to do when we still had to support Windows XP that does not have a small/efficient mutex primitive. If iterator debugging remains a thing post-ABI-break world SRWLOCK makes that way easier to do per container.
This is EXACTLY what I needed to parse user defined literals at compile time. I was thinking on writing parser generators on top of CTRE, but I'm glad you already did the job
Avoid STL \*containers\* in this case where you've got POD you don't want to initialize, maybe. Algorithms should be safe and it is not easy to beat those.
Minor point. Instead of `struct string {} ;` , I would, in the context of your lib, rather do: `struct string final {};` &amp;#x200B;
There is a C++ version of Cassandra out there called ScyllaDB. Another Pub/Sub tech in ZeroMQ which is C/C++. I'm not convinced by the Fault Tolerance argument. Our data jobs that use a lot of the tech mentioned in the article always seem to be going down. It should be the case that these technologies are written in C++ but, for infrastructure costs reasons, you want more performance with less hardware. So why isn't it? I guess a large part is that C++ was at 03 at the time they were developed. Doing anything involving networking in C++ comes with a great deal of faff. C++'s io is crap.
failing to compile...
Should not this be named CPU Cache Oriented Design instead?
Possibly, what's your reasoning?
Awesome, but note this is work-in-progress and the api is still subject to change as I figure what types of functionality people might find convenient or pointless. There are built-in parsers that I am working on such as backtracking/lookbehind and other non-consuming parsers. Another thing I should mention is MSVC is currently not 100% supportive of my sorcery, I have reported a weird compiler bug and it is **Under Investigation**... so there is hope, in the meantime gcc and clang are good to go.
Or by using linda (this code from the thesis 'High Performance Linda Using a Class Library'): bool grab_forks(int left, int right) { bool result = false; in("grab semaphore"); if (rdp("fork", left) &amp;&amp; rdp("fork", right)) { in("fork", left); in("fork", right); result = true; } out("grab semaphore"); return result; } void drop_forks(int left, int right) { out("fork", left); out("fork", right): } int philosopher(int no) { const int left = no; const int right = (no+1) % NUM; while (true) { think(); if (grab_forks(left, right)) f eat(); drop_forks(left, right); } } return no; } void main() { for (int i = 0; i &lt; NUM; i++) { out("fork", i); eval("philosopher", philosopher(i)); } out("grab semaphore"); } https://en.wikipedia.org/wiki/Linda_(coordination_language)
Depends on how performant those algorithms are. Most of the STL's algorithms are general purpose, and cannot be tuned for the thousands of different usecase requirements, in which case you will have to eventually write an algorithm to suit your own usecase. So ~ start with STL as a base, and then construct your own algorithms when the time comes, and tune and test. Nothing ever beats a custom-purpose algorithm for your needs.
Dmitry's bounded MPMC queue is insane
For what the STL algorithms do on the tin, I doubt it. Only one that might be borderline is sort. e.g. the `remove_if` loop doesn't leave much room for anything to differ.
Can you give an example where those would be useful? Standard c++ hardly allows any form of useful type punning (even though compilers often do)
I like that one too, and since the maintainer seems to have gone awol, I've [forked](https://github.com/degski/pector) it and fixed some issues.
Well. To static assert to avoid undefined behavior would be a good thing already for what I saw in the codebase I am working. Of course people can still bypass it in many situations... not sure. Maybe going through some routine with staric asserts is the way to go.
&gt; ... post-ABI-break ... Is there any ETA on this, I'll have to re-compile quite a lot of stuff, but looking forward to this happening anyway (and get std::deque behaving sanely). From what I gather(ed) from /u/STL even VS2019 is not gonna break things (at least not from the get-go). 
or write everything in header
I'm asking the other way round: What useful types of type-punning exist in c++ (other than "You can treat everything as an array of bytes") that spurred you to use that technique in the first place? In what useful circumstances would `can_alias` return true?
One that springs to mind is deleting [an element] in the case you don't care about order [often the case], just std::swap with the last element and pop_back(). If you do this a lot, [plf::colony](https://github.com/mattreecebentley/plf_colony) is a good fit, though.
No specific ETA. The more customers complain about it the sooner it is likely to be. Balancing customers angry about ABI breaking bugs against customers happy about not breaking ABI isn‚Äôt an exact science sadly. Given this particular issue has an easy workaround too it likely doesn‚Äôt contribute much.
Or in [a specific, i.e. int's only] case, use [a better algo](https://github.com/skarupke/ska_sort).
&gt; Given this particular issue has an easy workaround too it likely doesn‚Äôt contribute much. You're referring to the debug-iterators, I presume? 
Odd. My heavily-templated C++ for AVR is faster *and* smaller than comparable C. Sounds like you're doing something wrong.
Just design LL1 grammar and use CTLL (part of CTRE) and you can build any type you want :)
Then we would need to rename OOP to Anti CPU Cache Oriented Design.
&gt; Best case, C++ can definite match C in performance ~ avoid the STL, use your own optimized code. No. Best case, high-level C++ outperforms high-level C. The classical example being `std::sort`, which can be optimised further than `std::qsort` due to the lack of function pointer indirection. Of course link-time optimisation evens the playing field again but there are similar situations (which I‚Äôve encountered in real-world code) where link-time optimisations cannot be performed. Consequently, templated C++ code was inlined more aggressively than equivalent C code, and performed substantially faster.
Here is a nice single consumer - single producer fifo that I've used and has worked fine in rt-critical systems. Templated and header only with no dependecies. Ideal if you need something compact and minimal. [https://github.com/KjellKod/lock-free-wait-free-circularfifo](https://github.com/KjellKod/lock-free-wait-free-circularfifo) &amp;#x200B; There is also a nice breakdown of the inner workings in this blog post by the author [https://kjellkod.wordpress.com/2012/11/28/c-debt-paid-in-full-wait-free-lock-free-queue](https://kjellkod.wordpress.com/2012/11/28/c-debt-paid-in-full-wait-free-lock-free-queue)
C isn't some magical limit on performance that every other language can hope to cap out at, you know. C has language level limitations that can inhibit optimizations that can be done in C++, largely due to the more sophisticated type system and generics. 
Wat? You will get it. Containers in STL is good enough for almost any task. And those containers are error free opposite to your own optimized C code which is just a big mess of bugs. If you need high performance you may use the time you saved because of using STL. AND OPTIMIZE bottlenecks, Deal done. 
&gt; The measurements are valuable. I wish I knew about those measurements, though. The 5% difference of replacing `std::vector` looks strange to me. I wonder if it's just noise, really... and if it's not I'd like to have an explanation of why the optimizer failed when `operator[]` is so barebone...
Making empty types ineligible for EBO needs an excellent reason to justify it IMO...
Do you have outsource opportunities in Nigeria? You may take a look at those.
This is my honest feedback, some might disagree and hopefully they prove me wrong. Most of the cpp jobs will be about maintenance of legacy software most of the time or that the software has been running for so long that there isn't much of new features to develop. Though, with AI here and AI there, this might be different but Python is also a popular language for this field too. Also, in electronics and embedded, C and C++ is also very popular but you won't find these jobs everywhere in the world. There a huuuuge trend on the famous "full stack developer" and web technologies. Obviously, this is where you'll find most of the jobs, so databases, JavaScript, react and angular, etc. And sadly, employers only seems to check which language you know and you worked with and less if you are an excellent programmer and can easily learn your way even if you barely touched the language. Learning a particular field like finance, AI or Games while learning C++ should help you also. Disclaimer, I live in Montreal, Canada
Phew.. I had no idea about `hypot`, thanks for this!!!
They talked about how their goal wasn't to build the fastest solution, but it would still be interesting to see how the various methods perform. Here's another article that [focuses on performance][1]. [1]: https://howardhinnant.github.io/dining_philosophers.html
The one I know only outsource web and Mobile App 
If you want to get really good at x, stop reading books and use it in practical projects. Maybe a product that you can eventually sell to customers or that does some good to others. This way, you can keep up your motivation, which should be your goal #1. No motivation, no gain. The nice side effect is, you learn to solve problems of the real world, and not theoretical ones covered in books, which makes your more worth than other candidates in the industry (especially when your product/project went through the roof and/or grew in popularity)
&gt;Most of the cpp jobs will be about maintenance of legacy software most of the time or that the software has been running for so long that there isn't much of new features to develop. Not my experience in the least.
&gt; I am aware of std::bit_cast but not sure how good it is at avoiding the aliasing rule violations and it is C++20. The implementation gets to take advantage of implementation defined functionality. That said, the typical implementation of `bit_cast` uses `memcpy`, which doesn't fall afoul of the aliasing rules because nothing ever aliases with this method.
Yup c++ developer since 1996... never done maintenance.
Or if you don't have any new idea that you can sell to your customers, an excellent excercise is to create a copy of an existing software that you like. This way you will have a clear end goal and motivation since you picked something you like and use. Who knows, you might alter it based on your needs and have something that suits you better than the original!
Excellent alternative üëç
Agree. I work in a huge legacy code base, but most of the work is NOT maintenance, it's adding new features. That being said, I do look for places to refactor, to make the improvement work easier. Knowing the common refactoring patterns, which is what I think u/Ceros007 means when he says "Most of the cpp jobs will about maintenance", can really help when it comes time to design something new. If you're coding in a commercial setting, there may not be opportunities for total rewrites. That's probably true for full stack developer jobs, too. Having an awareness of potential refactoring patterns is an advantage for every software developer. &amp;#x200B;
Check out cURL.
&gt; If you're coding in a commercial setting I work in the "it works, so there is no budget for this software". I might have been a little bit extreme in my maintenance statement. We do add new features but I'd say that most of the times, they are really really small features. Nothing to really put your logical brain to work. But fixing an issue in almost 20year old c++ code, that requires a lot of grey matter just to understand this mess.
&gt; Most of the cpp jobs will be about maintenance of legacy software most of the time or that the software has been running for so long that there isn't much of new features to develop. Not universally true, performance sensitive, embedded systems are still in C/C++. Now-a-days, we are building more. 
What if there is no CPU cache? DoD is a little more adaptable, although I doubt you'd get 100% agreement on what DoD actually means from the people who resurrected it.
I'm working on a project that's written from scratch in C++14 which is now transitioning onto C++17. Your experience is not universal.
In the first few minutes he said almost everyone is using chrome nowadays. I've used chrome in the past, but not recently.
&gt;&gt; michael_scott_queue ramalhete_queue harris_michael_list_based_set harris_michael_hash_map chase_work_stealing_deque vyukov_hash_map Just why?
His claim is still probably true.
I've written a large number of boost features, and I really don't care if any of them are standardized. Most of them I would probably argue against standardizing. The reason I write them are: &amp;#x200B; 1) The feature is a generic tool which doesn't have any competitive value to me, better it be put in a location where I can find it later. Also it gets maintained through time. 2) I get free code review. 3) I might half-ass the feature if I keep it in my own codebase, and then have to debug it later. Best to do things right and then my mental energies can be focused on the bugs in my current features, rather than worry about the bugs in my stack. (Ever been there? I'm sure you have.) &amp;#x200B; As to relying on other Boost libraries: I've actually found that libraries age more gracefully the less dependencies they have. But it's a tradeoff: Most of what I do in Boost is not complicated, it's just features which need to be written \*somewhere\*, unit tested, and maintained. For other libraries, what they are trying to do \*is\* super complex. In this case the tradeoff tends more towards use of dependencies. &amp;#x200B;
Maybe there should be a linear algebra library, maybe not. But I doubt it would be obsolete before available; many of the standard tools of numerical linear algebra have been well understood since the 1970s. But a standard way to do multidimensional indexing would be \*hugely\* useful to me. (Say, \`M\[i,j\]\` as is proposed). Then I could write template code which could accept matrices.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Thanks for posting, this has been interesting to dive in to. I'm still getting used to reading through the indirection in modern C++. However, I am so many abstractions deep and I cannot see where the actual image data is stored. I'm trying to unpack how the pixel class provides efficient access to the actual image data and am a little lost. Can you give a kick in the right direction?
I just looked at market share stats. It said Chrome and Edge fell slightly from 2017 to 2018 and Internet Explorer rose a little. I'm sometimes using Falkon (aka QupZilla) and like it. I think he's exaggerating. If he had said "most people" it would be different.
It isn't the only one that can already target WASM.
Ranges were supposedly created to make it possible to use code in more ‚Äúcompositional‚Äù ways without the allocation overheads of the STL. I‚Äôve not formed my own opinion on ranges yet. The book Functional Programming in C++ seems to like them. But then if you‚Äôre approaching C++ as functional to begin with I suspect that ranges don‚Äôt seem so awful
Sorry, shouldn't have been so snarky. What I meant to say, before my evil co-pilot responded for me, is that we just disagree on this point. My position is, just in general, that auto-magical stuff is bad. Anything that lets the compiler make a decision for me, as opposed to do what I tell it, is risky in a large and complex code base that has be maintained and greatly improved over the years. I avoid all conversion operators as well, for the same reasons. Every time I've done such a thing I've regretted it later when something happened that wasn't at all obvious, and something got magically converted to something else. I'd rather type a few characters to call a getter which requires an explicit request on my part to do such a thing. Auto falls into that category, IMO. Anyway, that's all I have to say about that, to quote Forrest. &amp;#x200B;
Well, no mighty claims were made. And it's all there in the video. It's not like the video is allowing for any misdirection or anything. &amp;#x200B;
Thanks for the historical info. So was that in some way related to the MDIL(Bartok) or .NET Native efforts?
In template&lt;class T&gt; inline constexpr bool is_incrable_v = requires(T t) { ++t; }; Isn't the `inline` redundant? 
!remove
OP, A human moderator (u/STL) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ahof0v/look_what_ive_done_with_ncurses_maybe_somebody/eegqbwb/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I'm impressed by the simplicity of the cmake file. No need for findpackage?
Hi, I'm a dev. working on the VC++ code optimizer, just wanting to let you know that a colleague has been working for a while on a tool that collects very detailed build events and statistics and it will be released fairly soon. It's based on ETW events and WPA (Windows Performance Analyzer) is used as the viewer. One can see on a timeline each cl/link invocation, how long it takes and what were the flags used, which are the header files taking most of the time, functions slowest to compile and a lot of other info. Used it myself recently to look over our own builds for MSVC to spot inefficiencies and tune it for high-core CPUs, it's a great tool and also really easy to use (start it, do your normal builds - no changes needed, stop it and open the trace in WPA). &amp;#x200B; Thanks, Gratian
The VS 2019 release series (RTW and all Updates) will preserve bincompat with 2015/2017. We don't have an ETA for the "WCFB02" incompatible toolset (as in, we don't know, versus we can't tell you). It won't be soon. The code exists, but lots more work needs to be done, starting with getting it out of TFVC and into git.
The tool you want is almost done, see my reply above.
The tool you want is almost done, see my reply above.
`bit_cast` will actually need a compiler builtin because it is constexpr. (At runtime this emits a special kind of memcpy, but one that doesn't require the object to be default-initialized first.)
I am saddened that after all those efforts all the OP got was ~10% compile-time reduction, and it still takes about 2 hours to compile that project :(
Now **THAT** is a great readme showing a fantastic full use case of the library. Many projects should have something similar. It's basically a proper hello world for the library. It also looks well documented, tons of examples, and just, well, amazing. The dependency situation is also great for embedded. I am interested in using this on an MCU, can you comment on the memory usage when using this library? For example, I assume it uses dynamic memory allocation? If so, can I provide my own allocator (on the stack)? Lastly, I love that this is MIT, thank you!
guess unity build could save you more time. I'm now considering write everything in headers.
There is also the ‚Äúdisruptor‚Äù ring-buffer data structure popularised by LMAX. It has the ability to support multi-stage pipelines using a single ring-buffer and also supports acquiring batches of items from the buffer with a single synchronisation operation. I had a play around with building https://github.com/lewissbaker/disruptorplus a while ago when I was learning about it. 
Sounds very interesting. Thanks.
&gt; Release Mode (-O3 or /Ox) Please don't use /Ox with MSVC. The compiler backend devs regard it as an ancient abomination. Instead, use /O2 (which adds optimizations that are always desirable). Note that in VS 2019, there is an additional optimization option relevant for modern C++: /O2 /Ob3 requests extra inlining which can help reduce abstraction penalties. (So far I've seen it make a minor difference in Ryu, it might help C++ code more; haven't tried it widely yet). Xiang Fan from the compiler frontend team just taught me an interesting throughput trick for MSVC. When `if constexpr` is available, it is awesome, but if tag dispatch must be used, the location of the tag can affect throughput. `(true_type, normal args)` has better throughput than `(normal args, true_type)` because the compiler avoids instantiating templates sometimes. The efficient form is used in the middle of this post (`branch()`); naturally, in MSVC's STL we had been unknowingly using the inefficient form for over a decade. &gt; [if constexpr is] only available for C++17 Surprisingly not true! :-) MSVC, Clang, and GCC all support `if constexpr` in earlier standards (C++14 for sure, I believe Clang/GCC support it down to C++11), emitting a warning that can be locally suppressed. With MSVC it is an "error-as-warning" (look closely at the number). This is how we can use `if constexpr` in the STL. &gt; Albeit for some reason it still doesn‚Äôt ship a regular make.exe-named executable, but rather some weird mingw32-make.exe thingy instead. My distro ships both. (CMake wants the weird name.) &gt; std::aligned_storage_t&lt;sizeof(T)&gt; delay_init_value; `aligned_storage` is TR1-era tech; using `alignas` is much better. (I wish I could implement the former with the latter, but there are obnoxious platform bugs to deal with at the moment, which don't apply to you.) &gt; new (&amp;delay_init_value) T( In generic code, the proper way to invoke True Placement New is `::new (void_pointer) Type(args)` (or with braces). The double colon is necessary to avoid being hijacked by class-specific new, and the `void *` type is necessary to avoid being hijacked by global new with other pointer type arguments. (Encountered in STL production.) &gt; I think I can squeeze another 10 minutes off the compile times of the project mentioned above at least I recommend getting compiler devs to help. Here's what I'd do - prepare a repro of your library usage that is both fairly realistic and annoyingly pathological to compile. You want realistic so they optimize something useful, and pathological so they can see the really long compile time and find the bottlenecks. Distill it down to a *preprocessed* repro with full command line, and file compiler bugs against the major compiler vendors. Definitely let the slower compilers know that the faster compilers on identical platforms have better throughput. You might get some improvements. With MSVC, you can use `/d1templateStats` to gain limited insight into what's getting instantiated so much in your library (it is not super actionable but it's more than nothing). And some editorial issues: &gt; Lambda‚Äôs are ultra convenient Incorrect apostrophe. &gt; I can assume an l-value The usual convention is to write lvalue and rvalue without hyphens. &gt; then destructing that said 260-element tuple &gt; but don‚Äôt destruct "destroying" is a more readable word. (Even the Standard thinks so; look at allocator helper functions.)
Right, I meant the debug lock. Nothing for engineering folks to pencil in; this is a business decision. We wanted to do the ABI breaking release literally years ago now, that's why I spent months rewriting our concurrency support to be not garbage that I can't ship :(
How does it compare with CImg, which is what I currently use? 
There are several linear algebra libraries available with many years of usage and user experience. Do none of these not meet your needs? Why does one of these of some other one need to be in the standard? What will be gained by including it in the standard. I believe that future holds LA and similar libraries which can take good advantage of array/graphics processors to make operations much faster. That is what I'm referring to when I say that I expect that any standard library for LA will be obsolete by the time it's delivered.
What do "alias" and "alias call" mean in the Chiel Chart?
Looks great, thank you! :) Do you have any benchmarks to compare your data structures with other libraries? &amp;#x200B; &gt;correct (in the C++ memory model) I have seen other libraries that depend on properties of the CPU architecture (such as cache line size) for lock-free data structures. So your implementation does not make those assumptions? &amp;#x200B;
just another day at the office...
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ahqxbx/beginners_guide_to_reading_in_command_line/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I assume to give credit to the authors
I recommend stackoverflow and cppreference.
Hmm, where do I start? I don't know CImg well, nor do I ever want to, but here's a non-exhaustive attempt: * Selene is MIT licensed, while CImg is under some strong copyleft niche license. * CImg strictly assumes planar data storage (according to [its documentation](http://cimg.eu/reference/group__cimg__storage.html)), while Selene by default assumes interleaved storage, which I think is a good default. It allows you to use represent existing interleaved image data in memory via views, and more. Multiple planes can of course be represented via multiple single-channel images/views. Software engineering-wise, CImg is the complete antithesis to Selene, to be diplomatic: * Selene does not couple every single function together with the data representation by literally dumping all of them into one massive class as member functions, as CImg does. Instead, classes are used only to represent either data holding entities or views, and algorithms are ideally modeled as free functions operating on these. * Selene does not try to put everything and the fricking kitchen sink into a single header file; instead its code is well structured. Header files follow a strict 'include only what you use' pattern. * The Selene code is hopefully very readable for everyone who's a little bit acquainted with more modern C++. YMMV, but I get genuinely scared every single time I look at the CImg header file. All sensible software engineering practices seem to be out the window with this one. * ...
Thanks a lot for the praise, I highly appreciate it! Am trying hard to make Selene very accessible by providing a good build &amp; first use experience and good documentation. (I'm quite happy with what is on GitHub, but I'm still unhappy with the state of the Doxygen documentation. Although that might be more related to Doxygen and the kind of output it produces.) Image data allocation does make use of dynamic memory allocation, and at the moment there is unfortunately no allocator support. I am planning to add this in one of the next releases, though, since it's clearly beneficial.
I really want to give you 100 upvotes for this post! :-) Very well put. Too many people see code like CImg's and think that it is C++ and how C++ is and is supposed to be, and then pass on the opinion that C++ is an ugly and hard language. Oh well. Thank you for your awesome library :)
Agreed. Not only is intention important - but it's also important that we be willing to give reasonable folks the benefit of the doubt when they say the "wrong" thing - (by reasonable, those who lack a pattern of behavior that suggests hatred and bigotry). In the interest of civilized discourse and social progress - I vote that we learn as a community how to better use our anger - against what we perceive as bigoted/hateful/triggered speech - to at least first attempt to educate the perpetrator in a manner that inspires the kind of change that matters (before shaming them (e.g. on social media) - and seeking to destroy their reputation). If we care about talking healthily about difficult topics in a constantly evolving community - we have to allow reasonable folks to make mistakes - but reasonable folks also have to be willing to learn from them. (If I have inadvertently offended anyone with the above statements - please see above ;) 
You can get the cache line size in C++17 via hardware_(de/con)structure_interference_size https://en.cppreference.com/w/cpp/thread/hardware_destructive_interference_size 
I actually like this. This immediately tells me what you are trying to do. I view it the same as naming an algorithm boyer_more_search or djikstra_shortest_path. 
Thanks! :) I really don't know what to say about CImg, besides that I would not be able to trust this monster of a code dump a single bit. Another point to add: I don't think CImg has any unit tests whatsoever. I am very happy I have added halfway comprehensive tests to Selene (though they could still improve!), as I've found and subsequently fixed many subtle bugs through them.
Thanks! 
This talk just convinced me that isn't possible any longer to just keep following C++ standardization effort on the side, as means to use it as get to go sister language for Java and .NET projects. C++ code has become very fragile just by means of the actual value of `--std=`. As one of those application developers mentioned on the talk, it is not possible to keep Java or C# on my head and still remember all nuances of each standard revision, including the differences of those features across all major C++ implementations.
This talk just convinced me that isn't possible any longer to just keep following C++ standardization effort on the side, as means to use it as get to go sister language for Java and .NET projects. C++ code has become very fragile just by means of the actual value of --std=. Compiling the same code with different standard versions can lead to very subtle bugs. As one of those application developers mentioned on the talk, it is not possible to keep Java or C# on my head and still remember all nuances of each standard revision, including the differences of those features across all major C++ implementations. For me it just felt like the complexity budget for language features has been completely used.
vector doesn't have a "don't initialize the values" mode, and that extra fill isn't free (even if just zeroes).
I guess you can go on vacation when you hit compile ;)?
It's hopefully not that difficult to see through the (relatively thin) abstractions once you look at the right code sections. I've marked line numbers in every link below. Let's take the example of the `Image` class, which always owns its memory. Its only member is an `ImageView` ([see here](https://github.com/kmhofmann/selene/blob/v0.3/selene/img/typed/Image.hpp#L155)). The view contains the raw pointer to the underlying image data, and information about the image size and row stride, but it doesn't own any data. See [here](https://github.com/kmhofmann/selene/blob/v0.3/selene/img/typed/ImageView.hpp#L123) for the view members, which reduce to a [pointer](https://github.com/kmhofmann/selene/blob/v0.3/selene/img/common/DataPtr.hpp#L72) and the [size](https://github.com/kmhofmann/selene/blob/v0.3/selene/img/typed/TypedLayout.hpp#L48) information. Memory allocation is taken care of in the [allocate\_memory](https://github.com/kmhofmann/selene/blob/v0.3/selene/img/typed/Image.hpp#L857) member function of the `Image` class, and thus the raw data pointer contained in the `Image` class's `view_` member is actually owned by the `Image` class. Pixel data access is using [some trickery](https://github.com/kmhofmann/selene/blob/v0.3/selene/img/typed/ImageView.hpp#L445) by simply casting to the corresponding pixel type -- it just needs to return a reference. This is only acceptable if the underlying pixel type is trivial and of standard layout, which the `Pixel` class is [guaranteed](https://github.com/kmhofmann/selene/blob/v0.3/selene/img/pixel/Pixel.hpp#L221) to be. One *could* conceive an Image class that simply contains a `std::vector&lt;Pixel&lt;T, n&gt;&gt;`, or something like that. In the current design, though, externally allocated memory can be subsumed by the image class, which would otherwise not be possible. Also, all of the actual data access can be delegated to the view class, so it doesn't have to implemented twice.
By default only on x86. Everywhere else is opt in. 
Thanks for the tag location tip. I wonder how many other things I‚Äôm doing that unwittingly hurt compiler performance 
The Chiel chart makes an appearance here: https://youtu.be/EtU4RDCCsiU, which is an excellent talk about metaprogramming and metaprogramming performance. (Would link a timestamp, but I'm on mobile.) An "alias call" is the evaluation of an alias template `template &lt;...&gt; using something = ...;` where it acts like a "function call" in the metaprogramming sense.
Thank you for the detailed reply. I had completely missed the raw pointer, which was essentially the one thing I was looking for. As an HPC guy, for me it is raw pointers all they way. It is indeed not to hard once you have the right place to start. I probably got a little lost starting in the wrong place, but as I said, I'm getting used to reading modern c++... Very nice, I'll dig in a little further.
&gt; Please don't use /Ox with MSVC. The compiler backend devs regard it as an ancient abomination. Instead, use /O2 (which adds optimizations that are always desirable). I've spent more time than I probably should have compiling our code with different optimization flags and one thing that has always been consistent is: any combination of /O3 and /Ox that I try has produced larger binaries and slower runtimes. So, we just don't use those.
does cppreference include things like external libraries and build tools?
Keep it mind this was with 2700 files using sol2 heavily, and another 800 after that. It's a pretty huge project using a lot of different templated libraries. A LOT of the compiler speed is spent eating header files. Some more forward declaration magic might help...
&gt; Please don't use /Ox with MSVC. I saw your messages before about that in other threads (or was it Twitter...?). I'll pass the message along, but it's not my code. &gt; Xiang Fan from the compiler frontend team just taught me an interesting throughput trick... Because I use variadics so much I couldn't put the tags at the end. So they were always at the beginning. I later learned this same fact, so I considered myself super lucky! Maybe that's why the overall gains from just the initial `if constexpr` stuff wasn't that big: I mostly replaced a good chunk of low-hanging tag dispatching stuff. I've got a lot more gnarly SFINAE and overloading shenanigans I can do that have dependent types, which will be a good fit for `if constexpr`. &gt; In generic code, the proper way to invoke True Placement New is... I didn't know about the `::new` trick. Curiously, there's a lot of overloads of new for certain tags and such: should I be using any of those specifically, like the align tags and what not? &gt; And some editorial issues: Thank you for the editorial fixes! I pushed them, hopefully they'll reflect. I read this thing over like 5 times, took a break, and then read it again and there's always still typos that escape me. I don't know how people shell out perfect blog posts on their own... maybe just something I learn with practice? &amp;#x200B; &amp;#x200B;
The library can provide the std::string\_literal type, but if anyone other than the compiler can create it it's sort of not a very good way of indicating something is a string literal...! The paper I wrote for that needs to be rewritten anyhow.
Speaking of pathological cases, any idea why a tuple containing a large fixed sized array gives a C1060 heap exhaustion error in MSVC? [Example here.](https://godbolt.org/z/ZwhSuT)
Probably time to post an update to that old post. ;)
You might like learncpp.com
Can you use UDLs for that?
Yes, but the point of this is to make -- somehow -- more default than UDLs. UDLs also are hard to get into non-function scopes (because they outright require using statements), so they're less than ideal for this kind of code.
What C++17 features are you using? 
&gt;What if there is no CPU cache? There likely is some kind of a cache.
I don't understand... You're writing a app that makes calls to some kind of market place that allows you to buy things via an API or something? Wouldn't your limitation actually be the speed of that network and API?
It sounds like a Qt GUI is the least problematic piece of this.
First, be aware of Qt's licensing. It isn't necessarily free for your commercial project. Next, it hurts me to say this but evaluate why you're using C++ versus something like C#, which is also very fast and hasneasier networking libraries. Without more about your background, hard to say anything else.
Look up something called a sneaker bot or shoe bot. Cyber, written in C#, sells for thousands and checksout in seconds. I‚Äôve tried making my own python bot in the past but the language is simply not fast enough. I was going to learn c++ but I might be able to get away with C# as I hear it‚Äôs a little easier. Apologies for the poorly written post. 
No, I‚Äôm actually glad to hear you say look to something like C#. Spent the day fiddling with c++ and qt and I can tell the learning curve is huge. Thanks for all of the pleasant responses, everyone :) 
If you have knowledge in another language, it's not super difficult to pick up. Only think to keep in mind is that, definitions go in header files .h, and implementation goes in .cpp files. If you're like me however, I came into c++ as a first programming language. I found handmade hero's intro to C helpful. The creater is in the middle of developing a full game from scratch, all live, on this same channel. This playlist tends towards the more technical side. https://www.youtube.com/playlist?list=PLEMXAbCVnmY6RverunClc_DMLNDd3ASRp Also another YouTuber who's known for Java tutorials, was actually really helpful for be learning cpp. Bucky "thenewboston" has a ton of playlists going over a variety of topics. Here's where I would recommend starting. This playlist tends towards an absolute beginner. https://www.youtube.com/playlist?list=PLAE85DE8440AA6B83 Also recommend looking into reference manual sites once you get going. And Google / stack overflow for any answers. https://en.cppreference.com/ http://www.cplusplus.com/reference/
I'm primarily a C# developer, professionally. I can confirm something like that is very doable fairly quickly. But as far as execution speed, you're always going to be in the nanoseconds, as long as you write it properly. I think you'll be waiting for the store postbacks more than anything. I honestly can't see why python would be too slow here. But, I have no personal experience in this specific thing you're trying to do. I'm just making assumptions based on personal experiences. Either way, C# would probably serve you well if you want to go that path. C++ speed is absolutely exceptional at things executed on the bare metal. Big reason why OS software and gaming engines often use C++. But once you leave the machine and you're working with an I/O on the internet, I'm not entirely sure there's a speed benefit there.
Can't it [the improved/ABI-breaking stuff] be made an opt-in [or in a different namespace]? I mean, we're having a std::deque that's looks like it came with VC6, and now you're saying, that we'll have C++20 before we can have a fix for this, and even then we might see C++23 first!
I have not benchmarked anything so i don't know.
&gt; ... this is a business decision ... Sack it, whoever made that decision! :-]
Financial HFTs still prefer C++. But I do agree that it is easier to find jobs in web technologies than C++, 'coz C++ has been narrowed down as a choice for financial, embedded, gaming and obviously systems programming sectors , and wherever one cares too much about efficiency.
Thanks a ton for the responses! Deciding I‚Äôm gonna go with C# here. My work environment is a little funky to say the least at the moment, but hopefully soon I‚Äôll have some quality time to dive into C#. Any good books you‚Äôd recommend? Hopefully I‚Äôll check back in soon to give you guys an update if you want, but I don‚Äôt know. Thanks again :)
from what I've done so far compile time is rather slow but i'm working on optimizations.
Honestly, I didn't learn from a book so I don't have any good suggestions. I am just not a book learner. Wish I was. I learned from a lot of years of just doing applications end-to-end and a lot of Googling, to be honest. After a while, you just learn it automatically like you would a human foreign language after living in another country. I'd hit up /r/csharp and see what they suggest on the side bar or search the question. I know the topic of books comes up more often than not.
There's a legend about a place filled with wisdom that answers frequently answered questions and guides you to the places that will answer posts about C++ questions, answers, help, and advice. Legend says this elusive place is called a sidebar. 
Unless I'm overlooking something, your algorithm looks good. The problem with trying to use std::tolower on a strong, is that it takes a char as a parameter, and not a char[] or an std::string. You'll want to iterate over there whole string, one character at a time, and convert std::tolower(). I suspect A good place to do this, is within your lambda, in the sort algorithm. Though I'm not able to think of possible side effects right now, this may not be the best/correct option. Here's a stack overflow question that should be able to guide you in the right direction. https://stackoverflow.com/questions/313970/how-to-convert-stdstring-to-lower-case
I don't have an exhaustive list, but I know I'm using and/or relying on \[\[maybe\_unused\]\] and \[\[nodiscard\]\], std::variant, std::filesystem (for the tests), a sprinkle of CTAD, and a whole bunch of \*if constexpr\*. Maybe more.
It might appear as an opt-in toolset. It might have inline namespaces, but won't have a different top-level namespace.
There's a possible interaction with the type traits that tuple needs to invoke, but I don't really know - a compiler dev would need to debug. Please file a bug through Developer Community.
The operator new overloads for over-aligned types should be invoked automatically, no user action required (IIRC).
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ahuwd5/sorting_a_vector_of_stringsstruct_tolower/eeifzh2/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ahtvyk/as_a_new_learner_to_c_what_are_some_of_the_best/eeifzqc/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ahq61v/practical_c_learning_resources/eeig020/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ahtr26/moving_over_to_c_from_python_for_a_new_project/eeig0e8/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I've been looking for a image library to replace age old freeimage in my project, this is looking promising so far.
Isn't this mainly a shortcoming of the compilers? If multi-line arguments to macros were common practice I'm sure they would have implemented better error messages for it.
The author mentions lambdas inside of templated classes or functions with a lot of template parameters. The compiler seems to create one instantiation of the lambda function for each combination of template parameters, which seems wasteful. A more intelligent (future) compiler could check whether the lambda depends on the template parameters and only emit unique instantiations. This should reduce this combinatoric explosion and it could also reduce compile times since the compiler would have to optimize a lot less functions. 
May I ask, can you also wrap image data in planar format (as opposed to interleaved)? It seems like with this `Pixel&lt;&gt;` design, it wouldn't be possible to represent planar data, or would it? (I mean you can of course copy the data and store it in interleaved format).
Single header SPSC and MPMC used in my production HFT system: https://github.com/rigtorp/SPSCQueue https://github.com/rigtorp/MPMCQueue
The best way to currently represent planar data is through multiple single-channel images and/or views. But, indeed, I'm thinking about ways to make planar data better supported. I very rarely come across real use cases, though, so it's not my first priority. Regarding the logging bits, I would like to avoid them too. But how else do you transmit string-level messages from, say, the underlying image I/O libraries back to the user? Which is what they all emit. The MessageLog class is not intended to be used as a logging facility by the user of the library, but mainly to receive messages from image reading and writing. And I have purposefully kept it as simple as possible. The only alternative that I could think of would be a much more complicated error state system, custom for each image format, that includes parsing error strings from each respective I/O library (hello, regex?) and transforming these into an error state. A bit scary, cause no one guarantees you that these string don't change between versions or else.
I am a entertaining a new position as a C++ developer. My Stackoverflow profile: [https://stackoverflow.com/users/story/301883](https://stackoverflow.com/users/story/301883) &amp;#x200B; I'm looking for: * remote - for personal reasons, I have to remain where I am...unless it's a really great offer with even better medical. * I would like to work on Open Source. * I would like to work on something that advances or protects the positive aspects of the human condition. Science, medical, privacy, security, the arts * I want to work with current technologies, including current C++. * I prefer Linux (or similar systems) and would like to work with it and for it. * I want interesting problems to solve. I want to be challenged. Shouldn't be too hard. * I love automation and would like to have it backing my development process. * My SO profile mentions my target technological topics and environment. * I want a continuous set of challenges and opportunities to succeed and advance. I have 15 years of professional experience and a number of years before that doing my own thing. I'm still in the 1% for the C++ language on SO, though participation has been minimal for years. I'm experimental, think outside of the box, and have the ability and desire to learn both from others and through self instruction. I have a history of being useful and productive very quickly even in large, undocumented code-bases in domains I'm completely unfamiliar with. I'm a US citizen living in the US. More info: * LinkedIn: [https://www.linkedin.com/in/noah-roberts-63b95535/](https://www.linkedin.com/in/noah-roberts-63b95535/) * Blog: [https://crazycpp.wordpress.com/](https://crazycpp.wordpress.com/) * github: [https://github.com/crazy-eddie](https://github.com/crazy-eddie) * gitlab: [https://gitlab.com/](https://gitlab.com/) Message me here or through SO. &amp;#x200B; Thanks :)
This sounds excellent, looking forward to it! Thanks &lt;3
You mean why I named the classes this way? There exists a large number of proposals for cocurrent/lock-free data structures of the same type (queues, hash-maps, etc.). The library already contains two queues and two hash-maps. I wanted them to be easily distinguishable and to clearly communicate which version is implemented (as @jbandela has already pointed out). But yes, giving credit to the authors is also part of it. If you want to use them I would recommend to define your own alias anyway (especially if you use configurations with a larger number of policies).
Cobol code is still alive, developers willing to fix bugs or add new features not so much.
Right now C# seems to be going through the same hurdles that C++ had to endure to get a foothold on console SDKs. That might be the one, or not, but it will be undoubtedly a language that gets first party support on future game console SDKs.
Thanks! No, I do not have benchmarks to compare them with other libraries. I do have some benchmark results comparing the different reclamation schemes ([https://github.com/mpoeter/emr-benchmarks](https://github.com/mpoeter/emr-benchmarks)). I have plans to add benchmarks to evaluate the different data structures and the performance effects of the various parameters. But I have not plans to implement benchmarks for comparison with other libraries (at least not yet, there are too many other items on my todo list). Different cache line sizes can have an impact on the performance, but they cannot spoil lock-freedom. My implementations rely solely on atomic pointers, so they are lock-free on any architecture that provides atomic operations for pointer sized words (e.g., x86/x64, SPARC, ARM). What I mean with "correct in the C++ memory model" is that the implementation uses relaxed operations where possible (to improve performance, especially on architectures with weak memory models like ARM), while taking great care to ensure that all required happens-before relations are established in order to maintain correctness.
You never dis-appoint, sounds good.
/O3 isn't a flag and is not recognized - using /O3 is equivalent to no optimizations.
this is ridiculous...
Does it handle 16bit per channel png/pnm image files correctly? Unfortunately a lot of image libraries are pretty much useless due to not handling these correctly...
Since it's just using libpng in the background, it *should*.
Still he's not far off, if at all. I havnt used chrome either so far, but on my ubuntu laptop firefox now doesnt survive sleep mode for several months. Chrome does. Chances are I will switch sooner or later.
Planner data is crucial if you want to write or read video data. I am very interested in using your library, but writing video files is the my only use case for working with images. I suggest you try making a ‚Äúdraw in RGB write with ffmpeg‚Äù example to see the pain points.
Huh? &gt; cl /O3 a.cpp Microsoft (R) C/C++ Optimizing Compiler Version 19.20.27027.1 for x86 Copyright (C) Microsoft Corporation. All rights reserved. cl : Command line warning D9002 : ignoring unknown option '/O3' Also, be careful: `/meow` also won't give you optimizations.
If course, the reason why `&amp;a[i] &lt; &amp;b[j]` is not strictly defined is to allow for segmented memory implementations. It's possible for different objects in different segments to have identical ("near") addresses. Unless the standard were to only allow "far" pointers (which isn't always possible, sometimes the segment descriptor is implicit or variable), it's unavoidable. However, since the standard requires a reversible pointer to integer conversion, comparing pointers as integers should yield a reasonably well defined, if meaningless, result in (nearly; the standard allows "trap representation") all implementations.
Oh, I am not blaming compilers. Honestly, C++ compilers are blazing fast. When you realize they can pre-process a source file into a multi-MBs monstrosity, full of templated code, and then get an object file out of it within a second... kudos! As a user, though, no matter the feats of engineering of the compiler, having to wait 2 hours to compile is just plain painful :( Modules should, hopefully, alleviate much of this pain!
Excellent point; I was misled by that `new T[]`, and forgot that for integrals it would leave them uninitialized. Still not clear if that would account for 5% of the total running time, with all the loops, but definitely an overhead... though it then means that the `Buffer` created by the OP is rather unwieldy to use, with potential UB for accessing uninitialized memory.
What the... why in the hell why did they decide to make that prevent the EBO?
Been a while since I used libpng but I feel like one had to do an endianess conversion (i.e. swap bytes) when reading as a simple char stream...
How can it be an empty base if it cannot be a base? ;-]
Oh, my bad. I was thinking of empty member optimization, which I've found, after some brief research, actually does not exist. My misunderstanding, clearly. Thanks for the clarification!
\&gt; We‚Äôre not worried about a hardware platform where &lt; does the wrong thing for pointers at runtime! We‚Äôre specifically worried about the GCC compiler, where &lt; does the wrong thing for pointers at compile-time. So delegating to the compiler‚Äôs &lt; at compile-time and the hardware‚Äôs cast-to-uintptr\_t &lt; at runtime seems exactly backwards, to me. I didn't read the details about the gcc bug, but it makes sense to me. If the "&lt;" can be evaluated at compile time, then the operands must be within the same array, so there is no problem using "&lt;", and we do that to enable further optimization (constant-propagation, inlining). Otherwise, we compare integers which is correct assuming some specific behavior of the compiler with respect to casting pointers to uintptr\_t. &amp;#x200B; &amp;#x200B; &amp;#x200B;
Please let me know what you find. If a manual endianness conversion is required, I'd highly welcome any 16-bit test imagery, if possible.
I'm saying that if you fork the language to the point of partial compatibility, you are not alienating anyone and not leaving *any* percentage of the community behind in the sense that their skills and their core algos are still relevant, it's just their Boost.PP magic that has to go out the window, which is obvious in any case because that stuff is hell on earth, even if we have tools like CLion that can momentarily expand macros into code.
No that's not quite it. I mean, you don't want to throw away all the advances made by compiler writers, for example. I don't think you can compile D under CUDA. So it's not a fair comment. You may as well have invoked Rust equally, but both of these languages have different syntax and an entirely different set of libraries.
They're adding it in C++20 :-D https://en.cppreference.com/w/cpp/language/attributes/no_unique_address
This will be so useful, can't wait!
TIL! Nice :)
Sorry, I'm beginner to CMake and don't know about "findpackage". Everything works on my Arch Linux. 
[removed]
There is another tool that can do that: https://github.com/amidukr/pak-c-mak
In truth, `&amp;a[i] &lt; &amp;a[j]` isn't any different: as soon as the array crosses a segment boundary you will have the exact same problem. The real reason is that the standard believes that supporting comparisons in arrays is simply important enough that the compiler must always make the extra effort to perform far pointer comparisons, while leaving it implementation defined in all other cases. Anyway, the standard could simply specify that operator&lt; works deterministically for pointers. I really don't get this fetish it has with turning comparators into single CPU instructions; you could easily compute the corresponding far pointer (it's one shift and one add) and compare that instead. 
In segmented memory models, arrays larger than a segment can be illegal.
In which way? I have no problem with it.
A question to the gurus here: Is there any conforming way to ask, if a pointer points to an element in an array that doesn't require me to loop over each element and compare for equality. The reason I'm asking is because - if I understand the article correctly- there is no reason why std::less wouldn't be allowed to order the pointers to different arrays interleaved. If this is not possible, then the standard is plain and simple - broken. No matter what possible optimization benefits it yields.
Can you rephrase the question perhaps with an example?
This library looks amazing, may I ask you how it compares to Boost's Generic Image Library (GIL) ? Also have you done some benchmarking to see how it competes with Opencv for convolution or other tasks for example ?
Let's say you have two arrays `a1` and `a2`. Would it be a legal for `std::less` to order pointer to the elements like this: `a1[0] &lt; a2[0] &lt;a1[1]&lt;a2[1]&lt;a1[2]&lt;a2[2]`? If this is legal, how can I tell if arbitrary pointer that is handed to me points into an array `a`?
Is there a reason vector with a custom allocator couldn't accomplish this?
Ok I am now convinced that concrete C++ is collapsing under its own weight :/ And one of the major root cause of that is of course, as usual, the crazy idea that UB can be "exploited" for optims. 
Can you make a comparison with other popular package managers, like Conan and Vcpkg?
I'll give this an upvote, because if you persevere through the first part, after that you do learn some interesting things about libstdc++'s implementation of `std::less`. For the first few minutes I thought it was going to be the usual rant from someone who found out that the semantics of the C++ language is not quite what he expected (because we start off with the author's surprise as he learns that undefined behaviour has apparently illogical effects), but if you wade through that to the second part of the article it is worth reading to see some of the complexity in implementing a constexpr `std::less`.
There is no order between pointers to different objects, if the objects are not in the same array. See [[expr.rel/4]](http://eel.is/c++draft/expr.rel#4) for the full detail. A very similar rule is also present in the C language, ¬ß6.5.8.5. &gt; If this is legal, how can I tell if arbitrary pointer that is handed to me points into an array a? That seems like a strange problem to want to solve. But I have a lot of legacy code, and I can see how it might happen. Your implementation should allow you to cast the pointers to a value of an integer type using a `reinterpret_cast&lt;&gt;`. The exact rules for that conversion should be specified by the implementation. If you intend to dereference this pointer, you will also want to be concerned about alignment requirements and potential aliasing rule violations.
Somewhat informative I suppose. When it comes to HFT I'd be more interested in being informed about how they organise the hardware so that the software part can be so fast? For example, - is there a load balancer in there somewhere? - is incoming data sharded by ticker? - how does infrastructure costs affect how the whole system is configured? - does the 'startegy' part compute equations, or is there some other component somwhere else that does that and then this component informs the buying machines to (for example, "BUY AMD IF ASK &lt; $20")
We are talking about std::less, which has a guaranteed strict ordering for all pointers. That's what the blog post is about. And the need is very common: You get two ranges of values and you want to check if they overlap or not (std::memmove).
Correction: bit_cast would most likely use memmove (or it's constexpr cousin for whatever compiler it does as STL mentioned), memcpy breaks if it's aliased, whereas memmove doesn't care. &gt;https://en.cppreference.com/w/cpp/string/byte/memcpy &amp;nbsp; &gt;If the objects overlap, the behavior is undefined. Whereas memmove does not have this problem: &gt;https://en.cppreference.com/w/cpp/string/byte/memmove &amp;nbsp; &gt;The objects may overlap: copying takes place as if the characters were copied to a temporary character array and then the characters were copied from the array to dest. However both can break if the object in question is not trivially copyable.
In this case, it is C++ collapsing under the weight of C. The C++ pointer comparison rules date from C.
Well the main compassion should be with Hunter.
There is the interesting fact that went either unnoticed or unreported: `std::less&lt;T*&gt;::operator()` cannot be both constexpr and provide a total order. Something has to give, or else you get an inconsistent behavior between runtime and compile-time results.
In HFT the machines will be co-located at the exchange, and the exchange matching engine will publish multicast ticker data. You can have different machines listen to different symbols by changing which multicast groups they subscribe to. But generally if it's ultra hft you want everything that's related to a particular trade in the same machine, because minimizing hops is very important for latency.
Yes sure, and comparision analysis to Hunter. In short words main advantage distributed nature - no central repository. Thank you for the comment.
What you interpret as a strawman is usually simply a bad experience related to real code bases a few of us are unfortunate to work with. Yes given competent programmers a "sea of objects" should not happen, nor should the GoF book be considered what defines "architecture". Yet it happens regularly, and I, and others, have been witnessing it, and are affected by that kind of insanity and incompetence on a daily basis. It puts you into a particular state of mind where you wished OOP were taught more appropriately, and certainly not as a major structuring element, because yes it often breaks down when interpreted like this and when the other tools are forgotten. As for "all code goes wrong"; I strongly disagree. Linux for example, has not gone wrong. OTOH I can't think of a *single* example of a software developed with an object-first and everything-is-object mindset that has *not* gone wrong. Usually what really matters is an afterthought in such contexts, and not even the "patterns" employed make sense for long.
&gt; memcpy breaks if it's aliased The arguments to `memcpy` in `bit_cast` will never alias. The 'dst' argument is a function local variable that can never be in the same storage as the object passed in to `bit_cast`.
UB being exploited is almost the only way we can have optimization. For example, `constexpr` value won't be inlined and loaded and evaluated every time because one could always `const_cast` it. Assuming the programmer don't break rules is almost the only way to achieve reasonable performance. Although I must agree that some of these rule hardly make sense today.
See [here](https://github.com/kmhofmann/selene/blob/master/docs/rationale.md) for a comparison to other libraries, including GIL. For convolution, the OpenCV implementation still has a distinct advantage (1.6-2.5x on my machine; using my microbenchmark in benchmark/image\_convolution.cpp). Note, however, that I have not made any attempts yet at using explicit SIMD vectorization, which is likely used inside OpenCV's implementation. This is planned, but currently not my first priority.
Conan is distributed too though.
Indeed, selene\_export.hpp is generated by CMake, and will be located in the selene/ subdirectory in the build folder after building, or in the include/ directory after installing. It's the proper CMake way to generate export macros, expanding to things like '\_\_declspec(dllexport)' on Windows platforms, and to nothing on Unix-like platforms. Regardless of this, I'd strongly recommend to build Selene using CMake instead of just dropping source files into a project. When using CMake downstream (which I also highly recommend), all necessary preprocessor definitions automatically get propagated via imported targets. If not, some might have to added manually at the moment. I did not do any testing not using CMake downstream.
Mandating strict ordering for pointers is like mandating all ellipses are circles. &lt;Insert OO joke here.&gt; Beyond disjoint segments with overlapping index ranges there is aliasing which allows different bit patterns in a pair of pointers to refer to the same ‚Äúmemory.‚Äù I‚Äôm fine with optimizing for the 99% case where this doesn‚Äôt happen but I‚Äôm now slightly curious if there are corner cases where one can‚Äôt write optimization safe code when explicitly coding for such aliasing. As for the need, how often are people who don‚Äôt understand things like implementation defined behavior writing their own std:: functions? The reason things like memmove are standardized is so they can be part of the implementation, taking into account and possibly living outside the normal language behaviors so the client doesn‚Äôt have to be so tied to specific HW/OS/Tools/Flags.
&gt; Mandating strict ordering for pointers is like mandating all ellipses are circles. Have you read the article? That is exactly what is mandated for std::less. That is neither the question, nor the problem. That side I've no Idea, what aliasing has to do with my question. 
What is trap representation?
I read the article. You didn‚Äôt comprehend my post. I pointed out that design violates decades of OO Programming 101 classes. This is distinctly different from saying they never made that design decision. As for aliasing, it offers another perspective on why strict ordering between unrelated objects might be a problem. You are free to ignore it.
UB
This proposal suggest some related traits. [https://wg21.link/P0466](https://wg21.link/P0466) "Layout-compatibility and Pointer-interconvertibility Traits"
thanks i guess
It's a term used by the standard to refer to a "conversion" where the integer's bit pattern is considered invalid and causes a "trap" when used that results in some alternative code being run. Since on modern systems, all bit patterns are valid integers, it's not used (although it is sometimes used with floating point values) for pointer &lt;-&gt; int conversations on any common platform. As an explanatory example, some old mainframe architectures have a software-visible parity bit in their integer bit patterns. A C compiler for such a platform could, in theory, "convert" a pointer to an integer by returning a value that contains an index to a pointer table with invalid parity and use the "parity error" hardware exception handler to deal with any attempts to interact with the "integer". In such a system, it's easy to see how performing undefined comparisons may not result in a sensible result (especially since said old mainframes often used "exotic" memory addressing schemes; how do you compare 0xF00 as a byte addressed index into the writable data segment with 0xBA7 as a word addressed index into the read-only data segment?).
There is only code, no demonstration. volatile has nothing to do with threads. The outcome of the program is undefined.
I was under the impression that you could not portably depend on converted integer sort for this because the standard didn't guarantee that the pointer conversion was deterministic, i.e. `p == q` doesn't necessarily imply `(uintptr_t)p == (uintptr_t)q`. The only guarantee in the standard is `p == (T *)(uintptr_t)p`. This would be possible with either don't-care bits in the pointer representation or overlapping segments. 
You'll never hear anything especially useful in these talks. Firms like Optiver don't even implement their ultra-latency-sensitive logic in software--it's all on FPGA. &gt; is there a load balancer in there somewhere? As u/tending said, all HFT trading systems are co-located in the exchange data center, so a firm typically rents a cabinet for their machines and gets a 10G/40G fiber handoff which allows them to directly connect to an access switch that connects to the exchange's order entry network. &gt; is incoming data sharded by ticker? It varies by exchange format but most will "shard" market data across n UDP multicast channels either by product group/asset or ticker symbol letter range. E.g. CME segregates market data by product group (S&amp;P futures on one channel, Treasury futures on another, crude oil on another, etc) across ~40 multicast channels. A few feeds like NASDAQ TotalView ITCH are all on one line. &gt; does the 'startegy' part compute equations on the fly, or is there some other component somewhere else that does that and then this component informs the strategy component on the buying machines to, for example, "BUY AMD IF ASK &lt; $20" Depends on the strategy. Simple triggers can be implemented directly on hardware, others require the output of very complicated pricing models living on potentially large clusters of machines.
I've been looking at re-doing my collection classes, based on the stuff I've been picking up lately. Something I noticed is that there's a lot of 'undefined behavior' warnings related to iterators in the STL. Something that I do, and it's not hard, is to allow my cursors (my version of iterators) to know if the underlying collection has been modified. If so they can throw instead of just causing something horrible. All it takes is a 'serial number' in the collections. Every change of the collection itself (the ordering, addition, removal, etc... of elements) causes that serial number to be bumped. Every cursors gets the serial number that was set when it was created. So any subsequent access via the cursor can check if the underlying collection was modified. When a cursor itself is used to modify the collection, after the modification, it can be gotten back in sync again (if it's a modifiable one) and the new serial number stored. So it can remain valid. If it can't be modified, it still can know it is no longer valid. Of course it might still be technically valid (points to something before the modifications in a sequenced type collection), but that would get pretty hairy to do. At least just knowing if it is invalid is a big step forward. And you can of course ask if it is invalid, not just depending on it failing with an exception if it is. &amp;#x200B; Anyhoo, something to think about. It's a quite nice thing to have. To me any sort of 'undefined behavior' is really bad. Obviously you can't prevent all of it, but in a case like this, you can prevent a lot of it with a pretty simple mechanism. I actually use serial numbers like this a lot, to very good effect. &amp;#x200B;
&gt; I very rarely come across real use cases, though, so it's not my first priority. I'm curious what use cases you are considering? From my experience this is correct wrt common storage formats, but for performance processing it would seem that planar storage will be way more efficient.
This isn't something unique to lambda expressions. I've seen dramatic compile time and object size improvements from extracting code that doesn't depend on the template parameters into a non-templated function (or even a templated function with fewer template parameters).
How does it compare to [libcds](https://github.com/khizmax/libcds)?
Do you sleep
The standard doesn't need to be quite that strict about implementation defined behaviours, because generally the implementation defined behaviours are whatever can be nicely handled by the hardware. As long as you aren't doing something dumb like using custom funky memories or aliasing, you'll be fine. 
I AM THE UNBLINKING EYE
So the Gcc problem is solved! I was thinking of a way to ensure that but I suppose it would be too much change, and some form of cooperation between compile phase and link phase. At compile time, it is not possible to know where a global variable will be placed in memory. Nevertheless compiler track constexpr pointer so that they always know to which variable they refer. All variable with external linkage have a name which is unique in all TU. For variable with internal linkage, the name is unique inside the TU, on the other hand these variables may only be compared with variables declared in the same TU. So using the name, size, alignment and the fact a variable has internal linkage or not a compiler could define in each TU an order that would be verified in other TU and that could be suitable for the linker.
 template &lt;typename T&gt; var&amp; operator=(T src) { m_inner = std::make_unique&lt;inner&lt;T&gt;&gt;(std::forward&lt;T&gt;(src)); return *this; } That is not how you use std::forward. Read this : https://stackoverflow.com/questions/13725747/concise-explanation-of-reference-collapsing-rules-requested-1-a-a-2
&gt;UB being exploited is almost the only way we can have optimization. Hardly; most optimisations don't rely on UB. And the type of 'optimisation' that requires the programmer to fix his program, to stop the compiler from removing something that really needs doing, isn't an optimisation at all. 
If you touch an outdated cursor, do you throw an exception I assume?
agree with your first paragraph, disagree with second. child classes should not be able to bend encapsulation. if they need to, then the relationship/architecture is not correct.
Compilation time before and after ranges? ;-)
Thanks a lot for the insight! To be honest the logging I didn't look through closely. I've used an older version of Selene and I've just browsed through the repo today to see the changes you've made and saw the `MessageLog` files and was just thinking "whaaat, what does a simple image library need that for...". But that was indeed too short-sighted. Good to hear it's only an internal, and to receive error messages. It might indeed be the best strategy for that. I don't know, maybe in the future, if/once it gets standardized and widespread, `expected&lt;T&gt;` might be useful for such cases and embed the error as string like you do now? I don't know. Definitely I'd agree I wouldn't do any of the parsing that you suggest... :-)
One of the nice things about Ranges is that there are overloads of the algorithms that just take Ranges, instead of iterator pairs. So you can just write ranges::for_each(v, print_elem); ranges::for_each(v | reverse, print_elem); ranges::for_each(v | reverse | filter(is_even), print_elem); etc.
Is there anything in C++ that is not a horror story?
To be fair, that forward could be safer if someone manually passes a reference type to `operator=` like `foo.operator= &lt;int&amp;&gt;( x )`.
Yeh. If you tried to use it, and the serial number was out of date, it would assume the worst and throw. It MIGHT be OK, but no way to know for sure, so best to be safe. Some really fancy scheme might be able to know for absolutely sure when they are invalidated, but it would be messy. &amp;#x200B;
One thing to note is that the code isn‚Äôt strictly equivalent, given that if you wanted to lazily generate the values in the ‚Äúbefore‚Äù code, you‚Äôd need much more code, which is another large benefit of ranges.
&gt; `/meow` won't give you optimizations either. /u/STL, explain.
Every class that supports streaming should be interchangeable *as a stream*. I'd imagine that a system configuration class would not have the same interface otherwise as a user account settings class. With or without `auto`, there shouldn't be a reasonable place where you could pass the wrong one and have it still compile. I'd mainly say that you should probably not call `getSystemConfigurationData()` in that case. If you were typing that out, typing out `SystemConfig_t` seems just as plausible. Added redundancy isn't safer in this case - it just makes issues more ambiguous (is the type or the function wrong?), and makes refactoring so much more difficult. You can certainly subtype from the common stream, but `auto` doesn't inhibit that. It makes it *easier* to refactor in such a way as you don't have to alter to code at every usage point, as the type is still both derived *and * strict. It actively *prevents* refactoring bugs due to incorrect casts or slicing. You can also wrap such types in an effective tagging template, and use `enable_if` or such (or explicitly expect the tag in the parameters). `auto` can also have some performance benefits in some cases, as it will keep the return type rather that the potentially more abstract type you would use, which can enable more devirtualization or compiler introspection. My main point is that you shouldn't have any actual problems. You seem to be fabricating unreasonable failure cases to justify disliking automatic type inference. If you actually do encounter such problems, there is a *severe* architectural problem.
O_-
Why not remove /Ox, or map it to /O2? Its nomenclature in VS is very confusing (Maximum Optimization vs Optimize for Speed), and there are no warnings when using it. Also, why /Ob3 instead of /O3, to keep consistency with other compilers? Plenty of people here on Reddit (I've personally corrected two) compile with /O3 because they think it is equivalent to GCC -O3, but instead they effectively disabled optimizations. Maybe /Ofast as well, to auto-self fast-math? I wasn't even aware of /Ob3 - many compiler and linker flags are not exposed through the IDE, nor via /?, nor on MSDN. As an aside question, is Clang/C2 still being maintained? The LLVM toolchain for VS by LLVM sorta is terrible and doesn't work at all with LTO.
Hi everyone, I am C++/Boost/Cmake/docker developer with 10+ years and 20 plus delivered projects. I am US citizen living in SoCal, but will relocate within California or to Western Europe. I am interested in challenging / collaborative FTE or consulting roles. my current stack : * C++03 ( 7 years ) * C++14 ( 3 years starting from C++11 ) * Boost ( 5 years ) * Cmake ( 2 years ) * Java8 ( 2 years ) * Spring ( 1 year ) * Golang ( 1 year ) * Python ( 6 months ) * TCP/IP and UDP ( 3 years ) * Docker ( 3 years ) * Scrum , Kanban ( 3 years ) * Git ( 3 years ) * Linux ( since 2000 ) * Shell scripting * Messaging frameworks ( since 2000 ) * Functional programming (since 2015 ) Special interest : * Blockchains * Distributed computing * Distributed database * Network protocols * Network virtualization * Network security * Cryptography * performance optimization * System programming my main open source projects: https://github.com/venediktov https://github.com/vanilla-rtb You can contact me via telegram t.me/vanilla_rtb or send e-mail to vv ~-at-~ forkbid ~-dot-~ com Cheers, Vladimir.
I presume he meant that it is ridiculous that `/O3` doesn't map to `/O2` or `/O2 /Ob3`... and I agree.
Very good point, however unless you are doing something absurdly evil, you shouldn't have two pointers with a different integer representation pointing to the same thing. Maybe if you have some kind of flag for read only or the like, but then you should know they are supposed to be different and you can mask them.
Are there some papers who propose dropping near pointers so we are free of this insanity? I doubt anyone is still running C++17 on a segmented architecture.
Gotcha, thanks
I'm not sure I understand. If you specify `/O3`, you get a warning. If you specify any unknown option, you get a warning. The only way you can silently disable (most) optimizations is to forget to add a `/O` option altogether and default to `/Ot`, which is a subset of `/O2`. But then you might also forget `/GL`, or any of the other dozens of flags a typical project requires.
Plenty of type punning between array types when you have images for example. Like if you have RGBA, you might want to read uint32 for the whole color, but still access a single channel as well (as uint8). If you have 10 bit or packing, it gets even more complex. Especially with things like YUYV.
![I see what you did there](https://media1.popsugar-assets.com/files/thumbor/eOF2Umn-mqNGnohxrtjeurwWDmI/fit-in/2048xorig/filters:format_auto-!!-:strip_icc-!!-/2018/08/20/677/n/1922283/1118a12c5b7adb1e342de9.55515725_/i/Michael-Scott-Misquotations-Office-Video.jpg)
Time Zone and Taxes , I'd say more weight on the taxes. Perhaps it's possible to live outside of US and have 5 hours overlap between the teams , however 30% tax for paying to non-resident is a big problem for US companies . Even if you agreed to pay 30% , those firms need to train accounting staff to file with IRS. It used to be easy to get Corp-to-Corp contracts with US firms for us locals , but lately it's almost impossible ; every one wants to do W2 ( employee status) as 1099 ( Corp-to-Corp) is an extra hassle, plus government wants to collect taxes from employees . 
Sense of humor is rare these days.
You try making a cat perform common subexpression elimination and tell me how it goes!
Just to point out that these examples use Range-v3, but not everything here will be in `std::ranges` in C++20. In particular, we won't be getting any "actions" in '20; these will hopefully be added in '23.
&gt; Why not remove /Ox, or map it to /O2? People hate it when we break their build systems, making us reluctant to remove/change options. Probably too reluctant, but people who are disrupted by changes are way more vocal than people who benefit from them. &gt; Its nomenclature in VS is very confusing (Maximum Optimization vs Optimize for Speed), and there are no warnings when using it. The compiler really should warn, yeah. &gt; Also, why /Ob3 instead of /O3 It is a strengthening of the existing options /Ob1 and /Ob2 which are purely about inlining. The backend team says that it's possible that /O2 will eventually imply /Ob3. I imagine it's possible that an /O3 could be added to mean /O2 /Ob3, instead. &gt; I wasn't even aware of /Ob3 - many compiler and linker flags are not exposed through the IDE, nor via /?, nor on MSDN. It is new in VS 2019 and I *just* read about it in preview release notes. I bring reddit early news of future tech :-) &gt; As an aside question, is Clang/C2 still being maintained? No, it is super duper dead, and MSVC's STL stopped supporting it (with a hard `#error`) ages ago. &gt; The LLVM toolchain for VS by LLVM sorta is terrible and doesn't work at all with LTO. You'll have to complain to cfe-dev about that. We're doing as much as possible to ensure that Clang/LLVM works great with our STL. &gt; Also, can we please have inline assembly back for x64? You can submit suggestions through Developer Community now. (I don't think this is likely but you can try.) I'm not a compiler dev, so I can't grant this wish. &gt; Or at least expose all instructions via intrinsics? This is an entirely reasonable request; what instructions are missing? According to my highly limited understanding (I have used only a handful of intrinsics), inline asm is super problematic because the optimizer can't reason about it at all, but intrinsics don't pose that problem, and the compiler team is regularly adding intrinsics for new instruction sets.
The compiler defaults to `/Od`, i.e. no optimizations.
Darn it. [The overall `/O` documentation](https://docs.microsoft.com/en-us/cpp/build/reference/o-options-optimize-code?view=vs-2017) says "`/Ot` (a default setting)", which I took for "the default setting", and doesn't mention defaults for `/Od` at all. However, [the documentation for `/Od`](https://docs.microsoft.com/en-us/cpp/build/reference/od-disable-debug?view=vs-2017) does say "This option is the default." My bad, I guess.
Before: slow After: still compiling...
But it's not a baseless worry. There's a reason that languages that do that kind of thing all the time are sub-optimal for large scale development. Anything that allows you to do something wrong and not have the compiler catch it is bad. And auto, in a lot of uses, allows you to do something wrong and not notice it. Every bug or mistake should be obvious, but we all know that many of them are not. It's a competitive software world, and there are always fewer resources than are needed to do all the things required. Anything that lets those resources spend less time on problems is a competitive advantage. I really just don't consider explicitness to be either verbosity or noise, any more than I consider good commenting to be. I mean, in really well written code, no comments should be necessary, right? And it's not letting the compiler handle more, it's forcing the compiler to work on less information, and hence be less able to verify your intent. 
&gt; The LLVM toolchain for VS by LLVM sorta is terrible and doesn't work at all with LTO. LTO works great but you need to link with LLVM's linker instead of MSVC's.
This seems to not to require extra scripting for cmake projects and is decentralized, which is similar to cget. What would be the key differences? Couldn't pak-c-mak re-use cget's [requirements.txt](https://cget.readthedocs.io/en/latest/src/requirements.html) instead of creating a new file to list dependencies?
Yet all these complaints are what make C/C++ second-to-none in speed. If you let the compiler not to assume things like this, arithmetic overflow and strict aliasing you lose a lot of optimization opportunities.
I've never understood why iterator pairs were required. It seems easy enough to have overloads for a container that just sorts the whole damn thing. 
Constraining such overloads pre-concepts was deemed too impractical.
I remember there were awesome articles by this guy on Habr. Hope they will pop on reddit now that the site became multilingual and supports translations :)
I have _everything_ set that way, including specifying that I want it to use lld-link. I get object format errors - my guess is that somewhere it is still using a MS executable.
I'm not using msbuild or clang-cl, so the problem must lie in one of those; using clang++ directly I haven't encountered any issues with LTO since before LLVM 6.
A quick summary of how this particular raytracer works: - At each pixel in the image, you send out a ray in the -z direction. - If it hits a surface, calculate the angle difference between your light source direction and the surface's normal vector. - Small angle difference means return a dark color value (since the surface is facing away from the light). - Large angle difference (180 degrees) means return a light color value. The reason we don't go from light source-&gt;sphere-&gt;camera is because it's too computationally expensive.
&gt; There's a reason that languages that do that kind of thing all the time are sub-optimal for large scale development. Anything that allows you to do something wrong and not have the compiler catch it is bad. Except that *not* using `auto` is allowing you to do something wrong and not have the compiler catch it. As I've said before, you've merely shifted the responsibility from typing a function name correctly to typing a type name correctly. &gt; Every bug or mistake should be obvious, but we all know that many of them are not. In this context, for this specific 'issue', every bug or mistake should be incredibly obvious. As I've said, I've *never* run into it, and if I were to, the problem should be just as obvious as an incorrect type. What, precisely, is the difference between debugging: auto some_stream = getRedStream(); and RedStream some_stream = getRedStream(); when what you really wanted is a `BlueStream`? If you were to have typed `getRedStream`, it is likely that you *also* were to have typed `RedStream` in the type. It would be odd to do the opposite. There's no reasonable way to type out: BlueStream some_stream = getRedStream(); unless you're doing something bizarre, and I maintain that if you wanted something that was a `BlueStream` in the situation of `auto`, there shouldn't be any ambiguity, and it shouldn't be trivially usable in the same context. Worse, in the context where you have `BlueStream ... = getRedStream();` or `RedStream ... = getBlueStream();`, you can clearly see the type mismatch (in the unlikely situation you were to manage to have the type and function be so different), but it is unclear which is correct. If you are having behavioral issues with `auto`, you know that it must be the function that's wrong, because it's just accepting what it returns. And, again, `BlueStream` and `RedStream` shouldn't be compatible enough for this to be an issue *anyways* (and if they are, they shouldn't be trivially accessible from the same context). &gt; I really just don't consider explicitness to be either verbosity or noise, any more than I consider good commenting to be. ... And it's not letting the compiler handle more, it's forcing the compiler to work on less information, and hence be less able to verify your intent. The entire point is that you should be architecting your code so that it *isn't* dependent on explicit types in such a fashion everywhere. That's a technical flaw, and inhibits refactoring.
She rolled over and is kneading.
I'm talking about the LLVM toolchain extension for msbuild that exposes 'LLVM' as a toolchain to msbuild.
I understand; what I'm saying is that the _actual underlying_ toolchain (LLVM 6+) supports LTO just fine when invoking the clang++ compiler driver. To my knowledge, the msbuild support you're referring to merely invokes the clang-cl driver rather than clang++, so the problem you're having is either in the msbuild side or in clang-cl.
To the best of my knowledge, it was a completely independent project not related to Bartok or .NET Native.
Are action can be just considered as algorithms?
&gt; In particular, we won't be getting any "actions" in '20 Seriously? Why? 
Imho it is perfectly reasonable to want to put a bunch of pointers into a set (std::set or just an array with unique elements), which requires some sort total ordering. But again. My question wasn't about total ordering. I want to know if I can detect if a given pointer points into a given array or not - I thought it was obvious that I want to know this for pointers/arrays of the same type. 
For a second I thought it was going to be able to actually raytrace meshes rather than primitives and I was about to be extremely impressed. Still impressive though, interesting to read through after having written a much more fully fledged one myself recently (well, WIP actually).
For US-only companies yes, but if they have a venue elsewhere it shouldn't be a problem (inter-EU for example). Somebody might also be fine with a US timezone even if they're CEST (night owls)
Don't care if it isn't measured with the c++20 ranges (not sure if all of the examples compile with them though).
Performancewise I can't tell since I have not performed any comparing benchmarks. Conceptually there are a few differences: * libcds implements hazard pointers (HP) an URCU as memory reclamation schemes. Most containers are implemented twice - once for HP and once for RCU. Xenium implements 8 different reclamation schemes and uses an abstract interface to make the container implementations agnostic of the used reclamation scheme. * AFAIK in libcds when using HP you have to define the max number of threads up front; Xenium does not have any such limitation. * According to the libcds documentation iterators for the MichaelKVList (harris\_michael\_hash\_map in Xenium) is "for debugging purpose only" since "a crash is possible when you try to iterate the next element that has been deleted by concurrent thread". The harris\_michael\_hash\_map::iterator in Xenium does not have this limitation; a conflicting delete can cause some performance overhead, but you can safely iterator the whole container. Obviously, at the moment libcds contains many more data structures than Xenium. On the other hand, Xenium contains some data structures that are not available in libcds: * ramalhete\_queue is probably one of the fastest queues available (see [http://concurrencyfreaks.blogspot.com/2016/11/faaarrayqueue-mpmc-lock-free-queue-part.html](http://concurrencyfreaks.blogspot.com/2016/11/faaarrayqueue-mpmc-lock-free-queue-part.html)) * vyukov\_hash\_map; this implementation is not finished yet and I do not have any performance numbers. But several years ago I ran some benchmarks and this was by far the fastest concurrent hash map I could find. * chase\_work\_stealing\_deque; AFAIK libcds provides nothing comparable.
I'll be surprised if even the c++20 ranges aren't pretty horrible compilation time wise.
Isn't that just basic Lambert diffuse lighting? 
I find that a bit hard to believe. But in any case: Couldn't they just have given them new names? (sort_range)
They ran out of time?
Maybe (most of the stl has horrible compilation times), but emulating concepts in c++11 is slow as hell and that won't be necessary anymore.
For details see https://corecpp.org/. There's already a list of pre-conference workshops published: https://corecpp.org/schedule/.
So it's going from camera -&gt; sphere? Is that not raycasting rather than raytracing?
Hello I'm (together with my team) considering buying tickets. Is there any more info about the speakers and agenda? I read that you want to have it on the same level as CppCon, which is nice. ( sadly we will not be able to join workshops :( )
Talk submissions just ended and the reviews are in progress. The full program will be publish in Mar. However, we will have multiple experienced international speakers that speak regularly at CppCon and other big C++ conferences. The workshop trainers themselves are some of them. 
That's actually funny. Read any proposal paper, and consider why the Ranges TS was so held up by the Concepts TS for years. ;-]
Sounds very interesting, thanks!
I'm aware, that's why I specified the LLVM Toolchain for MSVC, not LLVM itself.
&gt;Here's another example, of a GetTimeZoneInformation() crash with Boost.Context involved: &gt; &gt;https://svn.boost.org/trac10/ticket/10657 The problem is that MS does not document all parts of TIB.
Facebook's folly fibers are based on Boost.Context as Boost.Fiber does.
swapcontext was removed from the POSIX standard (because of a design mistake -&gt; API doesn't conform C99)
Judging from the examples, I have mixed feelings about ranges. Some code samples make the code without ranges a lot easier to read.
I'm pretty sure the 'Count the number of words (as delimited by space) in a text.' example can be done with vector and stringstreams
I think it is always done like that. Imagine you would trace rays coming from a light source. Most of them would end up going nowhere near the camera, so it would be hugely wasteful. The laws of physics are mostly reversible, besides thermodynamics, so it works quite well doing it like that. Interestingly, people used to think that vision is done by sending out rays from the eyes, see here: https://en.wikipedia.org/wiki/Emission_theory_(vision)
Before you go for specific stuff like cuda, be sure to be good with the basics. I highly recommend [Effective C++](http://www.aristeia.com/books.html) by Scott Meyers. It teached me alot of useful technics.
Set all sockets to nonblocking and spin without sleeping. You can achieve nanosecond resolution this way.
Did you try Asio? Boost version: [https://www.boost.org/libs/asio](https://www.boost.org/libs/asio) Standalone: [https://think-async.com/Asio/](https://think-async.com/Asio/) I think it should be precise to 1ms. Of course, if you need higher precision, you may chose to implement a while (true) { ... } spinning loop as well.
Oh, I know that but thanks for the info. When I initially read the comment earlier, I thought it was just doing something akin to the raycasting used in DOOM rather than something like the the ray tracing in Battlefield 5. Having re-read it, it sounds like raytracing with only taking the primary rays into consideration. I had never heard of emission theory. I wonder if the Superman comics had some influence from that.
The two terms are used interchangeably by many people, but there is a difference. In both cases though, you send rays out from the camera - there is no point in calculating light rays that doesn't ultimately end up seen by the camera. The key difference of ray*tracing* is that when a ray collides with an object in the scene, new rays are fired out at different angles. These rays themselves then collide with other objects or light sources in the scene, enabling realistic reflections and lighting. Ray*casting* doesn't do lighting or reflections.
I knew that but appreciate the info and I'm sure there are others here who didn't, thank you.
http://learncplusplus.com Is a nice resource (I think; I've not used it for 5+ years).
so easy write your own
!removehelp
OP, A human moderator (u/cleroth) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ai966n/what_are_some_resources_to_get_good_at_c/eem4wb5/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Falkon uses QtWebengine, which is effectively a packaged Chromium, which is basically Chrome. So you are using something, that renders pages like Chrome. For web developers you are using Chrome.
As I said, I already did, but it would be interesting how others do it and how it performs in reality. Also, if there is already a good/well maintained implementation out there, why should I roll my own?
Something which annoys me about this post is the lack of mention that getting the file size from filesystem is inferior to tellg() etc because it's **racy** because the file, or any directory in its path, may have been renamed by a third party since you opened it. The current directory may have also been changed by library or malicious code to get you to open something different to expected, or to leverage a TOCTOU attack. The only correct non-racy algorithm, incidentally, for reading all of a file is to read all of the file! Sure you can do `tellg()` to get an idea of the file size before you begin. But you *absolutely must assume* that the file may have changed size by the time you read it. At which point, you may need to expand some structures and keep going, or you may need to throw everything away and do it again. Also, the kernel can and does lie to you regarding maximum file extent, both via asking filesystem or via `tellg()`, but it tells more lies for the former than the latter. The latter is guaranteed by POSIX to never be inconsistent with writes previously performed to the same open file handle, so if you write off the end to extent X on handle A, you are guaranteed that a query of metadata using handle A will reflect the maximum extent written. Handle B does not have to. `lstat()' certainly does not have to, and often does not for *seconds* at a time. What we should be teaching is "Use `file_size()/tellg()` as a **hint**, never ever assume it is not lies. If you want to read a whole file, the only correct way is to keep reading the file until EOF".
I haven't tried anything yet! :-) I'm still in the fact-gathering phase. I looked into ASIO but it seemed overkill for what I wanted, and it was unclear what sort of guarantees it offers on real time.
Ah, interesting! I essentially use up a whole core in exchange for better timing. So if I needed to sleep for, say, 1ms, I'd examine `std::chrono::high_resolution_clock::now` and spin until the current time was 1ms or later? 
Sorry, I'm apparently missing something here &gt; and consider why the Ranges TS was held up by the Concepts TS for nearly a decade. ;-] Because they decided to depend on concepts? It is not like that there haven't been libraries that put range based wrappers around the raw std algorithms for over a decade. So it has been doable for quite some time. 
yeah that is essentially a thin wrapper around clock_gettime() on the glibc. I usually prefer to call tge primitives directly when I dont expect the code to be cross platform But for such small intervals Id convert ms to clock ticks and count ticks with __rdtsc() from x86intrin.h 
&gt; Couldn't they just have given them new names? (sort_range) That naming scheme is going to run into trouble when you want to wrap `equal_range` or `swap_ranges`...
Essentially, yes. Range-v3's actions are basically algorithm calls wrapped in the "pipeable" syntax used for views.
The build tool needs to be able to support the various language standards in use. CMake, for example, allows one to specify that C++17 or C++14 are required. It also knows how to enable this for every contemporary compiler. However, it goes a bit deeper than this. There may be additional libraries and options needed for specific features. CMake allows compile features to be exported as a target configuration property. This means if my library uses a specific C++14 feature (for example), it will be exported, and any downstream consumer of that configuration will be informed of the requirement, and will therefore enable the appropriate compiler and linker options. A larger question is support for language and system features like threading, for example. CMake has `Thread::Thread` from `FindThreads`, which is cross-platform and exportable since it's an imported target. Autoconf has nothing. There's a non-portable `ACX_PTHREAD` in the unofficial autoconf macro archive. But that's it. It's 2019, and Autoconf doesn't have any way to use threads at all! And that's just the start. We're nearly two decades into the 21st century. But the Autotools haven't progressed past solving the portability problems of the 1990s. If you need to care about all the contemporary portability problems, which includes modern C++ usage as well as a whole host of other more recent portability problems, tools like CMake are solving them while the Autotools gave up on this a good long while back. There are a few reasons for that, not least of which is the overburgeoning complexity of the whole edifice, as well as the lack of concern for portability and cross-platform building outside the narrow realm of C+Unix+Make. Need to build against the Python libraries? There's a CMake module for that? And for many dozens of other libraries and tools. It's not that you can't use modern C++ with the Autotools, but rather that you'll have to do a lot of make-work to make it do anything like what you can do out of the box with CMake. When the whole purpose of a tool is portability, you shouldn't have to hardcode system-specific details in your build logic, or manually write more flexible cross-platform equivelents, simply to make it function. That stuff should be provided or else it's not meeting its primary purpose.
I think Andrei Alexandrescu (the last question) has a missunderstanding, of how chaining with pmr allocators work: The main allocator must always own the memory handed to him for deletion. A deallocation call to the chained allocator only happens for complete memory regions that the primary allocator requested from the fallback allocator. So e.g. `a1` gets a request to allocate 10 bytes. It doesn't have that much memory avalable, so it asks the fallback allocator `a2` for e.g. an new chunk of 1KB. Initializes any necessary metadata for that memory and then hands out the 10 bytes sub-slice. Later, when that 10 bytes slice comes back it may or may not detect, that the 1KB chunk it got from `a2` is now completely unused, so it might now decide to hand back **THAT 1KB chunk of memory** to a2. a2 will never see the pointer to the 10 byte allocation.
&gt; Seriously? Why? The ranges proposals are huge -- the last revision of [P0896](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0896r4.pdf) weighs in at 226 pages, with another 27 pages for the basic concept definitions in [P0898](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0898r3.pdf). Getting all this specified is a huge task, and is almost entirely the work of just two people, Eric Niebler and Casey Carter. It's also required a very large amount of review time in LEWG and LWG. All this means that things have to be prioritised in order to not hold up the C++ release train.
It would be more interesting to see a comparison to other (native?) options as well, such as `stat` and `GetFileSizeEx`
Cool, very impressive!
The way many people in industrial computing do it is by using the communications device as a timer. Ethernet packet timing on full-duplex links is completely deterministic, so keep the device supplied with dummy packets and when you‚Äôre ready to send something useful, send it. Same with serial ports: use framing (e.g. HDLC) and send idle state bytes between packets. Or use a self-synchronizing protocol without byte stuffing (look at ATM for ideas). The reliability of such timing in the user space will be much better then that of ‚ÄúFire a timer and write something to a port‚Äù. For precomputed packets the timing is fully reliable if the queues are big enough. For packet computed basing on sensor readings, you may have late sensor input ‚Äì then just keep sending the dummy packet until you have something else to send. 
My experience to date is that the current implementation of the Concepts TS in GCC is not significantly faster than using SFINAE. On my system, it takes roughly the same amount of time to compile the test suite for [CMCSTL2](https://github.com/CaseyCarter/cmcstl2) (the reference implementation using Concepts) as it does for [my SFINAE-based Ranges implementation](https://github.com/tcbrindle/NanoRange), which uses the same tests. However, this is not a strictly like-for-like comparison: CMCSTL2 implements some things that I don't yet have in NanoRange, and I have ported the tests to Catch2 which may slow things down somewhat. However, it's relatively early days yet for Concepts -- I'd imagine that as they become more heavily used, we'll likely see more optimisation work put into compilers. The fact that concepts are baked into the language may offer more possibilities for optimisation than (ab)using template instantiation rules via `std::enable_if`.
Also, a few days ago I looked at libcds as I had an opportunity to try it. Then I read that I have to do: cds::Initialize(); to initialize the internal garbage collector. That's obviously useful in some context, but that's a show-stopper for me.
Yup, this is just basic Liskov substitution principle.
Thank you very much taking the time to write such an in-depth answer. I had no idea that CMake takes care of such a range of portability problems for you.
If you're on Linux you probably want to look into the realtime extensions (which are actually in the mainline kernel but you have to enable them in the build) Writing to a HW based serial port the hardware will take care of the timing of sending the actual data, you just need to fill a buffer.
okay, that's a reason I can accept. I was already worrying that the committee just decided to hold back important parts of a finished spec without good reasons. I mean it's not like that never happened before, just look at `std::optional` or the parts of the networking-TS that could be shipped without executors.
But `equal_range_range` would fit right next to `requires requires`!
Here is a small twist on this [Article](http://www.vitorian.com/archives/370) [Github](https://github.com/Vitorian/RedditHelp/blob/master/test_spsc_ring.cpp) 
The article seems incomplete because it doesn't explain the etymology and history of \`iota\` function.
boost::range works fine
&gt;It can still be preempted by IRQS This is why you isolate cores and assign business critical processes to cores manually,
Great stuff, very readable indeed! 
I know this is not what you asked for but it might be relevant as I have a similar problem: On windows you can use userspace scheduling which allows you to control the scheduling yourself Someone else mentioned rdtsc which doesn't work in a threading context AFAIK, if your thread gets bumped to another core itll give incorrect results On windows to get consistent timing I use a combination of sleep(1), yielding threads only to other threads on the same cpu (yield and sleep(0) do different things), and then spinning in a loop when you get near your target time to get your subms granularity In my use case (sleeping a thread for 12ms, allowing it to execute for only 4ms) CPU usage is important so this strikes a decent balance between timing accuracy and CPU usage, and I only need to ensure 'mostly' consistent
I've made different projects using the spinning technique. If the periodic load is much smaller than the msec slice you can yield inside the sleep to use that core to do sometimes something useful... 
You could probably write a unit test to time a similar transaction to the one you're planning. At the very least you should be able to get a general idea of how long a transaction will take to run on average. I have some video processing stuff I do that for, and they seem to indicate that under fairly low load they run in around 20ms per video frame. That means I can process frames in real-time-ish, which is what I was shooting for.
Do ranges require any new compiler features, or is it purely an STL thing?
If real-time scheduling is actually the goal (e.g 1000Hz rate with less than 1ms variance) then there exists variants of the linux kernel which do exactly this. Low-latency kernel and real-time kernel (see documentation [here](https://help.ubuntu.com/community/UbuntuStudio/RealTimeKernel)). You can try out the low-latency kernel by installing it though the synaptic package mananger.
&gt; the file, or any directory in its path, may have been renamed by a third party since you opened it Why can't you [lock the file](https://gavv.github.io/articles/file-locks/), in which case the Linux kernel won't let the file get modified untill you release the file?
File locks are *advisory* on POSIX (Linux has a buggy mandatory lock implementation, it's unreliable and nobody should use it). Plus you are assuming that the other actor is not malicious, and not deliberately trying to confuse your code by deliberately manipulating paths and sizes deliberately without holding locks.
for sub-millisecond scheduling you gotta suck the power bill and take control of your event loop, there is no way around it.
Filesystem's `file_size()` just calls `stat()` or `GetFileSizeEx()`, so no difference. More interesting is if you query an open file handle for its size, which tends to be far quicker than querying size from filesystem path.
That's true of nearly all IO operations though. Don't trust an IO operation to succeed just because a previous one suggests it might succeed _if nothing happened in between_. I'd use something like `file_size()` not for reading the file in, but rather for things like displaying file info in a browser or similar.
Parent has the goodies for Linux. If that's not enough accuracy ... last time I played in this space, Xenomai was current hotness. Not sure if it has been superseded, not sure if it has maintained support. Unsure what the equivalent would be for BSD and Darwin.
I think a better title for "The Best Parts of C++" talk would be "The Right Side of C++" (I'm taking that from "The Right Side of History" by Ben Shapiro.) I don't know much Hebrew, but know that it's read from right to left: [http://slashslash.info/eastconst/](http://slashslash.info/eastconst/) , [http://slashslash.info/petition/](http://slashslash.info/petition/) &amp;#x200B; &amp;#x200B; . 
For it to be useful you'd need type erasure. For example, if I have a function that receive a view to a container of `int`, I don't care what is the source container, buy only the value type of that container. Then the issue of what operations are available arises: if you type erase, you need a finite set of operations, and this will limit the functionality of the container view, or limit the sets of container that can fit into a container view.
Can you avoid it being preempted by using "isolcpus" to set which CPUs the scheduler will run on and set the process to run on one of the isolated CPUs?
Eh I would change that to sub-microsecond (but you need to measure to be sure). Note that if you're sleeping to a target time, you can use the OS's sleep functionality to get close then spin or the remainder of the time. Power + heat is a significant cost so only pay it if the timing improvement is worth it.
I don't see why it MUST be type-erasured. *BTW, if you have personal need in type-erasured range view, there is \`ranges::view::any\_view&lt;int&gt;\`.* I personally need view to set/map/etc. explicitly typed.
Hmm it looks like I was a bit outdated. There is a discussion in the kernel docs https://www.kernel.org/doc/Documentation/timers/NO_HZ.txt The language used there is somewhat confusing though, be warned. But yes, on modern kernels you have supported ways to mitigate and avoid the mandatory LOC interrupts. Of course this assumes you've done your homework wrt IRQ shielding 
&gt; consider why the Ranges TS was held up by the Concepts TS for nearly a decade The [initial commit](https://github.com/ericniebler/range-v3/commit/7a663cf249262b7ae8fca6ffd90) to Range-v3 was made on November 11th 2013, or a little over 5 years ago now. Given that the Ranges TS and subsequent `std::ranges` work is a standardised version of Range-v3, I'm really not sure how this was supposedly "held up for nearly a decade". 
It's a common misconception that Doom used raycasting, but it's not the case. iD's previous title Wolfenstein 3D did use raycasting, with the limitation of only a single ray per column for performance reasons.
Alternative name: embloaten for what this will do to your compile times
How do you represent near and far pointers in portable C++ ? I keep hearing the argument that these architectures need to be supported by the standard, but I only know about non-compliant compilers offering support for these as an extension.
Xenomai is still here. The problem is that it is simple to. Trigger a domain (real time &lt;-&gt;linux) change easily via a device driver not ported ora some unforeseen allocation
Languages rarely treat timing as a first-class feature. (Ada is the only language that comes to mind.) You need to address this problem at the system-level, by using an OS capable of supporting deterministic latency, and telling the OS about the real-time requirements of your application (scheduling policy). As others have pointed out, Linux with the PREEMPT\_RT patch is one good way to go (It's good enough for [SpaceX rockets](https://lwn.net/Articles/540368/)). The easiest way to get this kernel source code is to clone it directly from the rt-project git repo: [http://git.kernel.org/pub/scm/linux/kernel/git/rt/linux-stable-rt.git](http://git.kernel.org/pub/scm/linux/kernel/git/rt/linux-stable-rt.git). I believe the current stable version is for kernel v4.14, but v4.19 should be ready soon. The patch is not enough to ensure real-time capabilities. You need to configure the Linux kernel, at compile-time, to include `CONFIG_PREEMPT_RT_FULL=y`. You probably also want to set `CONFIG_HZ_1000=y`. If you're not up to compiling the Linux kernel yourself, you may want to look at real-time focused Linux distributions, or rt packages for your current distribution. Note: The `low-latency` kernels distributed by Ubuntu's apt are NOT real-time kernels. Other tips: * If your application (assuming that it is running with a `SCHED_FIFO`/`SCHED_RR` policy) uses timing mechanisms other than `clock_nanosleep()` (e.g., `timerfd`), make sure that you boost the priority of the timer interrupt handling threads (named `ktimersoftd`), so that your application does not starve them out. You can do this with the `chrt` command. * Folks on this thread have suggested polling on a non-blocking socket. This is not bad advice, but *there is a risk*. Beware that if your application is running with a `SCHED_FIFO`/`SCHED_RR` policy, that Linux, by default, will force a real-time thread consuming 100% of a CPU to sleep 50ms every 1s. You can disable this behavior by doing `echo -1 &gt; /proc/sys/kernel/sched_rt_runtime_us`. Forgetting to do this is a common mistake. * RedHat has a fairly complete system [tuning guide](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_for_real_time/7/html/tuning_guide/index). (Some elements may be out of date.) * Here's some [advice on how to write a real-time friendly application](https://rt.wiki.kernel.org/index.php/HOWTO:_Build_an_RT-application#Application). Much of the advice is about eliminating page-faults once your real-time work has started. There is also information on how to schedule your application with a real-time priority.
That is so disappointing :( 
Thanks buddy!
That sounds great. Years ago I did some ugly hacks (wrapping devenv.exe in a process that parsed the output to emit ETW events) in order to do build-time investigations and I desperately wished for ETW events to mark when each file started compiling. Going deeper to show the time spent in individual header files will be great (even if I don't use VC++ as much as I used to). My blog post on doing this profiling is here: [https://randomascii.wordpress.com/2014/03/22/make-vc-compiles-fast-through-parallel-compilation/](https://randomascii.wordpress.com/2014/03/22/make-vc-compiles-fast-through-parallel-compilation/)
sub 10 micros is the time to get a thread/process to wake up you still get milliseconds resolution when you sleep #include &lt;stdlib.h&gt; #include &lt;stdint.h&gt; #include &lt;x86intrin.h&gt; #include &lt;unistd.h&gt; #include &lt;limits&gt; #include &lt;regex&gt; #include &lt;string&gt; #include &lt;fstream&gt; #include &lt;iostream&gt; double read_cpu_frequency() { std::regex re( "^cpu MHz\\s*:\\s*([\\d\\.]+)\\s*$" ); std::ifstream ifs( "/proc/cpuinfo" ); std::smatch sm; double freq; while ( ifs.good() ) { std::string line; std::getline( ifs, line ); if ( std::regex_match( line, sm, re ) ) { freq = std::atof( sm[1].str().c_str() ); break; } } return freq/1000; } int main(int argc, char* argv[]) { uint32_t usecs = ::atoi(argv[1] ); uint32_t maxcount = ::atoi(argv[2]); double freq = read_cpu_frequency(); std::cout &lt;&lt; "Frequency: " &lt;&lt; freq*1000 &lt;&lt; " MHz\n"; uint64_t min_elap = std::numeric_limits&lt;uint64_t&gt;::max(); for ( uint32_t j=0; j&lt;maxcount; ++j ) { uint64_t t0 = __rdtsc(); usleep(usecs); uint64_t elap = __rdtsc() - t0; min_elap = std::min(min_elap,elap); } std::cout &lt;&lt; "usleep: " &lt;&lt; min_elap*freq &lt;&lt; " ns\n"; min_elap = std::numeric_limits&lt;uint64_t&gt;::max(); for ( uint32_t j=0; j&lt;maxcount; ++j ) { struct timespec tm,remtm; tm.tv_sec = 0; tm.tv_nsec = usecs*1000; uint64_t t0 = __rdtsc(); nanosleep(&amp;tm,&amp;remtm); uint64_t elap = __rdtsc() - t0; min_elap = std::min(min_elap,elap); } std::cout &lt;&lt; "nanosleep: " &lt;&lt; min_elap*freq &lt;&lt; " ns\n"; return 0; } $**./test 10 1000 ** Frequency: 4125 MHz usleep: 4.49675e+06 ns nanosleep: 3.96549e+06 ns 
I don't quite see the need for that. `std::span` and `std::string_view` have the advantage that they effectively type erase the original container , so I e.g. don't have to use a template if my function is supposed to work on "any continuous range of ints". Your views on the other hand still carry the concrete type, which looses half the advantages of the std types. Now, generally speaking it can certainly be useful to only hand out a subset of a container's interface to some part of your code (I believe for std::set your view is identical to a const std::set&amp;), but I don't think the need is common enough/the implentation difficult enough to put it into std and imho not even into boost. Best way for you to find out is to put your library on github, announce it on some community platforms (as you did here) and see how many people start to clone/star/use your library. 
If you're going to spin on the CPU in a real time process, you'd better have more than one core, or your system will be unusable.
src( &amp;const\_cast&lt;src\_t&amp;&gt;(src) ) It does not need, leave it const and make src const too.
&gt; you'd better have more than one core, or your system will be unusable. that was a problem back in 1999 I guess but even in VMs with 1 core you can still do stuff 
[https://www.reddit.com/r/MachineLearning/comments/a1bfpg/p\_ensmallen\_flexible\_c\_library\_for\_efficient/](https://www.reddit.com/r/MachineLearning/comments/a1bfpg/p_ensmallen_flexible_c_library_for_efficient/)
&gt;...when architecting software. So "architecting" is not really a verb. An architect designs. Being a software architect sounds better than a programmer (although there is truth in the distinction). Perhaps this came about because dedicated programmers / architects didn't want to be confused with "web designers". None the less, you cannot "architect" because it's not a verb. =)
&gt; Now, generally speaking it can certainly be useful to only hand out a subset of a container's interface to some part of your code That's the only reason for this "container view" to exists. I don't see much facilities in C++ world to (work with)/(split into) exterior/interior mutability. Actually, the only one I found is \`range::view\`. Just returning const reference to container is not the same thing - all iterators becomes const too. &amp;#x200B; From the other side, if there would standalone find/equal\_range/etc functions that could work with range, there would be no need in such "container view" at all.
Happy cake day ü•≥ü•≥
the samples confuse new user of range
This is off topic. OS questions don‚Äôt belong in CPP
No, the problem is that switching thread contexts requires adjusting private OS structures. Even if all fields were documented, some of them would still be subject to change in a future version of the OS. Otherwise it would be impossible to add features or fix limitations in context switching, such as when Windows 2000 raised the limit of 64 TLS entries. 
Mandatory locking is very rare in Linux distributions and is not suited for general purpous API. Advisory locking is not really locking, and does not solve any of the mentioned problems
I've always had problems getting VS Code set up with C++. When developing C++, I usually end up going back to Visual Studio. It looks pretty good in dark mode and it still is pretty feature heavy. CLion is also pretty modern but I only used it back when it was in early beta.
You can also put \`emcmake\` in front of your cmake command ;)
I took the following steps to get consistent timing: * Disabled frequency scaling and turbo mode (otherwise my TSC isn't stable and the measurements are all bad) * Disabled deep CPU sleep states * Run at a realtime priority (note: I am using the standard Debian stretch kernel which is not even a lowlatency kernel) I get the following results: &lt;username&gt;:/tmp$ clang++ -O3 -o time_test -std=c++14 time_test.cc &lt;username&gt;:/tmp$ sudo chrt -f 99 ./time_test Frequency: 4200 MHz Requesting 100000 us: usleep:100002 us nanosleep:100002 us Requesting 50000 us: usleep:50002 us nanosleep:50001 us Requesting 10000 us: usleep:10001 us nanosleep:10001 us Requesting 5000 us: usleep:5001 us nanosleep:5001 us Requesting 1000 us: usleep:1001 us nanosleep:1001 us Requesting 500 us: usleep:501 us nanosleep:501 us Requesting 100 us: usleep:100 us nanosleep:101 us Requesting 10 us: usleep:10 us nanosleep:10 us Requesting 5 us: usleep:5 us nanosleep:6 us Requesting 1 us: usleep:1 us nanosleep:1 us &lt;username&gt;:/tmp$ cat time_test.cc #include &lt;stdlib.h&gt; #include &lt;stdint.h&gt; #include &lt;x86intrin.h&gt; #include &lt;unistd.h&gt; #include &lt;limits&gt; #include &lt;regex&gt; #include &lt;string&gt; #include &lt;fstream&gt; #include &lt;iostream&gt; double read_cpu_frequency() { std::regex re( "^cpu MHz\\s*:\\s*([\\d\\.]+)\\s*$" ); std::ifstream ifs( "/proc/cpuinfo" ); std::smatch sm; double freq; while ( ifs.good() ) { std::string line; std::getline( ifs, line ); if ( std::regex_match( line, sm, re ) ) { freq = std::atof( sm[1].str().c_str() ); break; } } return freq/1000; } int main(int argc, char* argv[]) { // Disable deep CPU sleep states. std::ofstream cpu_dma_latency; cpu_dma_latency.open("/dev/cpu_dma_latency", std::ios::binary); cpu_dma_latency &lt;&lt; '\x00' &lt;&lt; '\x00' &lt;&lt; '\x00' &lt;&lt; '\x00'; cpu_dma_latency.flush(); double freq = read_cpu_frequency(); std::cout &lt;&lt; "Frequency: " &lt;&lt; freq*1000 &lt;&lt; " MHz\n"; uint32_t maxticks = 500000000*freq; for ( uint32_t usecs : {100000,50000,10000,5000,1000,500,100,10,5,1} ) { std::cout &lt;&lt; "Requesting " &lt;&lt; usecs &lt;&lt; " us: "; uint64_t min_elap = std::numeric_limits&lt;uint64_t&gt;::max(); uint64_t count = 0; while ( count &lt; maxticks ) { uint64_t t0 = __rdtsc(); usleep(usecs); uint64_t elap = __rdtsc() - t0; min_elap = std::min(min_elap,elap); count += elap; } std::cout &lt;&lt; "usleep:" &lt;&lt; uint32_t((min_elap/freq)/1000) &lt;&lt; " us"; count = 0; min_elap = std::numeric_limits&lt;uint64_t&gt;::max(); while( count&lt; maxticks ) { struct timespec tm,remtm; tm.tv_sec = (usecs*1000)/1000000000L; tm.tv_nsec = (usecs*1000)%1000000000L; uint64_t t0 = __rdtsc(); nanosleep(&amp;tm,&amp;remtm); uint64_t elap = __rdtsc() - t0; min_elap = std::min(min_elap,elap); count += elap; } std::cout &lt;&lt; " nanosleep:" &lt;&lt; uint32_t((min_elap/freq)/1000) &lt;&lt; " us\n"; } cpu_dma_latency.close(); return 0; }
Did you really reply to a 2 month old comment to make a meaningless argument that isn't even correct? https://www.dictionary.com/browse/architecting 
I guess I'm showing my age :)
mlpack started to depend on it. was quite surprise to see it for the first time.
VS Code is almost perfect, but the C++ syntax highlighting isn't great. Close behind is Visual Studio, which highlights the syntax nicely.
QtCreator is fabulous. and works. KDevelop is not fabulous (unless you make it on it), but it also works.
I was actually caught by the filesystem lying to me about size. I was just doing an include, so asking for the filesize, resizing a string and reading into it, then concatenating the rest of the string. Wasn't working for some files - the remainder wasn't appearing. I racked my brain and cursed for hours. Turns out Windows just gave me an upper bound approximation of the size, and reading the file left a bunch of trailing nulls. Utter madness. Don't trust the filesize.
CLion. You can get it for free as a student.
well I bet I'm older than you
Here's some footage of one of my colleagues working with our new development system. We're hoping to release it somewhere in the third quarter: https://youtu.be/P5k-4-OEuTk?t=65 
GNOME Builder is quite usable for C++ and looks awesome with the right GTK theme. It also has these very *whoosh* animations for sliding panels and editor windows and also some of the most frequently used Vim keybindings.
Cool. I‚Äôm particularly interested in the SDP solvers. Are there benchmarks?
There is no glamour in C++, or not the kind you're looking for anyway. Maybe Javascript would be more up your alley. Or you can always write your own - it used to be a rite of passage of sorts in those uncool days long, long ago.
&gt; a header-only c++ library for mathematical optimization Just because you *can* doesn‚Äôt necessarily mean that you *should*.
If I may make a suggestion (I am taking the liberty and making one anyway) - you might want to consider a stylus instead, something maybe like a... wand or similar? Also, the neural interface requires a hat. A cone-shape is optimal for electrical-cognitive interfacing. The star-shape is OPTIMAL for air-flow, for cooling. Our prototypes from 1990's looked like this: https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/ImageMagick_logo.svg/200px-ImageMagick_logo.svg.png .. but we were ahead of our time so went bankrupt. Better luck to you guys! 
none that's easier to setup than Visual Studio Code
&gt; with a fabulous look I dunno, Visual Studio is more glamorous than it is fabulous.
usually i hate shameless advertisement but in this case i make an exception. Looks pretty impressive, the only thing that i'd criticize is the blue on blue color scheme - looks cool but the lack of contrast makes everything really hard to read. 
&gt; IOW, view - hide container modifiers How does that usefully differ from a const reference to the container?
Hmm. I make a point of getting older every single day.
I'm going with #1 these days.
const container have const iterators, const iterators return const references to underlying elements. Thus, with const reference to the container you can work only with const elements. With view, like this - you cannot change container (insert/erase/clear), but can change underlying elements (iterators mutable). This is useful, when changes to container is not allowed (or need to be trackable) by design : class Data{ std::map d; public: Data(int size){ // fill d. } container_view::map&lt;std::map&gt; get(){ return {d}; } } P.S. Probably std::set is bad example, in general, because you're not allowed to change elements at all. view to std::map would be better example.
Turbo C/C++'s real/protected mode x86 memory models can serve as examples for most of the awkwardnesses discussed here. No language extensions are necessary as the default pointer types themselves are enough. For example, the medium memory model uses near pointers (16-bit offset only) for data and far pointers (32-bit segment:offset) for code. In this model, function pointers cannot be converted to `void *` because data pointers are narrower than code pointers -- which is fine since the standard conditionally allows this conversion. The large memory model, where both code and data pointers are far pointers, exposes more of the weird possibilities for pointer behavior: * `size_t` and `ptrdiff_t` (16-bit) are smaller than an object pointer (32-bit), because no object can be larger than a segment. * `==` and `!=` compare the full pointer, but `&lt;`, `&lt;=`, `&gt;`, and `&gt;=` compare only the offset. The segment is assumed to be the same because objects are contained within one segment that is always used for all interior pointers to the object. Thus, equality comparisons work against different objects, but relational comparisons only within the same object. * `std::less` therefore fails if implemented with direct pointer comparison, but works if implemented as the comparison of both pointers casted to `uintptr_t`. In both cases, code written against these memory models doesn't look any different than code you would write with a modern flat memory model. Some or all pointers are segment:offset far pointers, but still take the form `T *` as near/far is implicit from the pointer type and the memory. model. It is up to the implementation whether two objects or functions are allocated in different segments or not, and when they are in separate segments, the code can break if the standard rules are not followed. 
I vote for Visual Studio 2015+ echanced with Visual Assist. Both pretty and fast. My second vote would be QtCreator with some custom theming.
embiggen... It's the more cromulent word.
Does it include automatic differentiation? I love http://ceres-solver.org/
I'm sure there's a reason you've decided std::decay doesn't work? &amp;#x200B; I guess it collapses references to their underlying type (IE: std::decay&lt;T&amp;&gt;::type == T), which may not be what you want.
yeah, std::decay does something fundamentally different than what I'm looking for. As I said - I want to remove the const/volatile qualifiers from the underlying type and leave everything else untouched. References to const T should become references to T in this case.
there's also `std::remove\_reference` and `std::remove\_const`
remove\_const removes the topmost const, so it's not what I'm looking for here. remove\_reference isn't suitable because I would need to manually re-apply the reference (e.g. \`const\_cast&lt;std::remove\_cvref\_t&lt;T&gt;&amp;&gt;(in)\` ) which isn't suitable in a templated environment where I don't know whether I have an lvalue reference, rvalue reference, pointer, pointer to pointer (to pointer to pointer...) and so on. If you look at the supplied code on godbolt, I've demonstrated the behaviour I'm looking for with an extreme edge case. There's no standard library solution (that I've found) that does this.
I‚Äôm going to leave it up because it got useful replies, but yeah, this is off-topic and future questions along these lines should be submitted elsewhere.
I find that if I sleep until a short time prior to the desired event, and *then* spin, I can get very good precision without making bitcoin mining look cheap. For example: #include "date/date.h" #include &lt;iostream&gt; #include &lt;thread&gt; int main() { using namespace std; using namespace std::chrono; using namespace date; system_clock::time_point t = sys_days{January/21/2019} + 22h + 48min; this_thread::sleep_until(t-10ms); auto n = system_clock::now(); for (; n &lt; t; n = system_clock::now()) ; std::cout &lt;&lt; n &lt;&lt; '\n'; } This just output for me: 2019-01-21 22:48:00.000000 I slept until 10ms of the target time, and then dropped into a spin loop, and got microsecond-precision.
In our embedded sector, we use special hardware to generate 1ms interrupts reliably. A software only solution on general purpose boards is not possible.
&gt; Turns out Windows just gave me an upper bound approximation of the size, and reading the file left a bunch of trailing nulls. Actually Windows has a logic to what is does here. When you write past the end of the maximum extent, the handle you wrote to reflects the new maximum extent, but no other open handle in the system does until the NTFS journal entry for the new metadata completely reaches non-volatile storage. Then, and only then, do all open handles return the new maximum extent i.e. the one which would appear after sudden power loss. Once you realise this, it's actually quite neat. ZFS does something similar, incidentally, so it's not just a NTFS thing. The workaround is to keep reading from the file until a buffer is not fully filled. On a busy filesystem where a journal update may take seconds to reach storage, I've seen the reported length of the file differ from the data readable from the file by hundreds of Kb. Obviously as the extra data hasn't reached storage yet either, you are guaranteed it is in the kernel filesystem cache. If you really don't want this lazy maximum extent update to occur, open the file in append-only mode. Writes now always append atomically, and the reported size of the file is kept much more consistent with reality. Note that multiple concurrent atomic appenders are a global mutex, and so do not perform well.
&gt;\_\_rdtsc There are good reasons for not using \` \_\_rdtsc\` though, see [https://groups.google.com/a/isocpp.org/forum/#!topic/sg14/iKE8VRBksxs](https://groups.google.com/a/isocpp.org/forum/#!topic/sg14/iKE8VRBksxs)
Wait, what does _bottom_ level qualifiers mean in this case? Types don't have a generic _bottom_ in this sense. If you have an `T&lt;const A, const B, const C&gt;` what do you expect to get from your thing?
and the alternative is....
I don't understand your interpretation here - it'll be T&lt;const A, const B, const C&gt; still - it doesn't make any change to the specialisation of T. Think of it within the same style as remove\_reference/remove\_const/remove\_volatile/etc. It removes the qualifiers of the underlying type while leaving the reference/pointer notation in place T const&amp; -&gt; T&amp; T volatile \*\* -&gt; T \*\* vector&lt;int&gt; const&amp; -&gt; vector&lt;int&gt;&amp; and so on.
`[]` mutates.
I'd break things down. Part of that is a container. The other part is a searchable. `count`, `contains`, `find` are one subset of functionality. `lower_bound`, `upper_bound` another. `equal_range` could go either way. A sorted vector, unordered set, map, etc -- all qualify for some of those. Now C++ lacks the ability to say "parameter that satisfies all of these view contracts" then make use easy. But we can write it I think. 
\`clock\_gettime\` ? Just like you would call \`QueryPerformanceCounter\` on Windows. Those are wrapping \` \_\_rdtsc \` because there used (and still are) glitches (sometimes patched by the kernel) and actually returning something consistent. But of course if you know precisely what CPU you are using (eg, ones with no glitches related to the TSC) and pinning your thread to a given core / don't need consistency between cores, then yeah, use rdtsc. 
TLV = Tel Aviv? Really cool seeing another C++ conference and it looks great!
What's that meme picture with the anime character who is pointing at C++ Headers, and saying "Is this package management?"
Out of curiosity... why are header-only libraries so popular? Is there some issue with including a source file? Even if it's multiple source files, it can have a simple script that merges them into one source file or module (like a few libraries out there).
std::map's - yes. view can throw error if key not exists. 
tsc is consistent clock_gettime uses the tsc look at the underline glibc implementation 
&gt; Now C++ lacks the ability to say "parameter that satisfies all of these view contracts" then make use easy. I don't understand. What parameter? Container property? I suppose search - features of tree-like containers bolted to containers for some reasons.
&gt; I guess everyone (including me) has written one at some point in their career
As I said:You can view everything as a range of bytes (char, unsigned char, std::byte (and most likely uint8 is just a typedef for unsigned char)) you don't need a trait to detect that. Almost everything else is UB in c++, so the type trait would return false. Where would it be useful?
From reading their documentation, I do not think it does, all examples implement the derivatives manually, and there's no mention of auto-diff in the docs.
Is there any ELI5 on how e.g. `std::string_view` achieves this "type-erasure"? If I pass e.g. an `std::string` to a function that takes an `std::string_view`, does a `std::string_view` get implicitly/automatically constructed (with the small overhead of having to construct a `std::string_view`, which probably has two member variables like a pointer and a size or something like that)?
I have been looking for something like this for quite a while and it looks great in general, but it's really a no-go that they didn't choose Eigen (the more-or-less gold standard) as linear algebra library. I don't want to buy into the armadillo types when I am already using Eigen. Would be great if it was either using Eigen or if it was more agnostic to any particular matrix library. The dependency on BLAS/LAPACK is also a bit annoying - where again Eigen would be the better choice because it includes its own BLAS/LAPACK routines. (And it can still use a BLAS backend or MKL if someone really wants to). Also ensmallen doesn't seem to have support for auto-diff, which is really too bad! I am not going back to manually computing derivatives when I can have Ceres's auto-diff. Also auto-diff is great to check manually computed derivatives, for when you do really need them. I wish this project the best of luck, libraries like these are needed particularly when they use modern C++, 11/14 upwards. If it wasn't depending on Armadillo, would support Eigen better, and were to include Auto-diff, I'd be all over it! :-)
Correct. A string_view holds a pointer and a length with the assumption that the pointer points to a contiguous range of chars. That range can be a string literal, any c-style array (aka a zero terminated array of chars), the internal buffer of std::string or the data of any other string type that stores its data continuously. How it is constructed depends on the source type. std::string has an implicit conversion operator to std::string_view and so would your custom string type. For string litterals as well as c-strings (const char*) string_view has a conversion constructor.
https://i.imgur.com/joBr1du.png
Or it could return a `mapped_type*` instead of forcing exceptions into the mix.
If you have 10 bit unpacked values, each value would be 2 bytes long, so you'd be doing type punning between uint64 and uint16. Also you can do type punning between equivalent types (that contain the same underlying types) but are named differently. Like how you might convert some OpenCV vector types to tuples to get the structured bindings working.
(most of) the devs are also involved with armo, and my impression is that this lib is a kind of extension to that project. 
https://stackoverflow.com/q/12671383/2446102 I recommend reading whole thread, not only accepted answer. 
I mean: int func( span&lt;pair&lt;int, int&gt;&gt; and searchable&lt;int, pair&lt;int, int&gt;&gt; x ) saying "func takes one argument that obeys the joining of the contracts of span and searchable, and x is the name of the value". Concepts is close but writing type erasure isn't trivial this way. You can do it, but no language support for it. 
`int const*const*volatile&amp;`?
&gt;int const\*const\*volatile&amp; int \*\* &amp; as the code above already produces. The behaviour that I'm looking for is what I've achieved above (as far as my tests go). I'm just looking for someone to point out the obvious solution that doesn't require nasty recursive boiletplate nonesense to do something (seemingly) as simple as stripping type qualifiers.
If you are on Windows, then Visual Studio is hard to beat. It has got the smoothest code completion of any IDE and the smoothest debugger ( I have tried Qt Creator, CLion, Eclipse, Visual Studio Code, and Vim with YouCompleteMe). I would recommend Visual Studio 2017 as it also has the LLVM plugin available so you can make sure you code compiles both with the MSVC compiler and with Clang. 
A bit of recursion should do it: template &lt;typename T&gt; struct strip_all_cv { using type = T; }; template &lt;typename T&gt; struct strip_all_cv&lt;const T&gt;: strip_all_cv&lt;T&gt; {}; template &lt;typename T&gt; struct strip_all_cv&lt;volatile T&gt;: strip_all_cv&lt;T&gt; {}; template &lt;typename T&gt; struct strip_all_cv&lt;const volatile T&gt;: strip_all_cv&lt;T&gt; {}; template &lt;typename T&gt; struct strip_all_cv&lt;T*&gt; { using type = typename strip_all_cv&lt;T&gt;::type*; }; template &lt;typename T&gt; struct strip_all_cv&lt;T&amp;&gt; { using type = typename strip_all_cv&lt;T&gt;::type&amp;; }; template &lt;typename T&gt; struct strip_all_cv&lt;T&amp;&amp;&gt; { using type = typename strip_all_cv&lt;T&gt;::type&amp;&amp;; }; template &lt;typename T&gt; using strip_all_cv_t = typename strip_all_cv&lt;T&gt;::type; I think this does what you wanted.
vim
I agree with /u/NotAYakk that the usefulness of this trait is extremely dubious, but nonetheless here's a shorter implementation: https://godbolt.org/z/3EXgHC
`template &lt;typename T&gt; using strip_all_cv_t` earlier, then get rid of `tyoename` noise by using it. 
I don't have the code on me, but last time I did similar, I basically recursed through the pointers/refs, pushing them into a counter (or vararg to handle those modifiers), until I was at the base type. I then stripped away the modifiers, and reapplied the stored indirections to the type.
I still not get it. You mean, that for example, for free-standing \`lower\_bound\` have "specialization" for std::map::iterator pair/range, like: auto lower_range(range::iterator_range&lt;range::iterator_t&lt;std::map&gt;&gt;){ // implementation } Iterators - point to the nodes of the map tree. In order to traverse tree, they must be able to climb to the parent node, and up to the root (and this is if tree structure allow to do this). I'm not aware about map implementation that can do this. IOW, all searches made from the very root of the tree (there is no \[or there is?\] map implementations that can search in narrow range).
I was recently in the same situation and wrote a timing engine based on techniques dug out of the Asio source, thinking Asio was bigger than what I needed. Internally, at least on Linux, Asio sets timers using the timerfd family of functions and monitors them with one of select/poll/epoll - basically what you described in your initial post. The timerfd functions have no guarantee of accuracy, other than they won't fire earlier than you specify. In practice though, I found the timers would typically cause select to wake up within 10-20 microseconds of the value set with timerfd\_settime, assuming the system didn't have too much else going on. This is with default scheduling parameters. By comparison, things like usleep, nanosleep, select with a timeout parameter, etc. were only accurate to about 1/1000th of the timer value, so wouldn't work on a millisecond scale when some of the timers had the potential to wait for minutes/hours. Anyway, the takeaway for you might be that the best way to set timers on Linux is with a Linux-specific API. BSD/Darwin/etc. are likely to be similar (I have no experience there), so just using Asio would probably save you a lot of trouble if you need a portable solution.
I think what you want is a [Container Adaptor](https://en.cppreference.com/w/cpp/container#Container_adaptors), that forbids the modifying operations on the container.
&gt; so you'd be doing type punning between uint64 and uint16 As was said, this is never legal, so the trait would return false.
Try KDevelop.
Now that is some very interesting output! Is there anything that can produce something as detailed with either clang or gcc?
Triggered: a unit test which depends on the OS details, isn't. It's a test alright, or a "spike", or... just not "unit", please...
I'd argue it should be, and it does work just fine in practice on a sane architecture. I have some Avisynth filter that's 99% type punning to convert the packed 10 bit into a sane planar 2 bytes per pixel frame.
&gt; I'd argue it should be, and it does work just fine in practice on a sane architecture. Sure, but don't move the goalposts; the bottom line is that this trait would not be terribly useful, as that simply isn't legal now.
Well it's more or less legal if you jump through some hoops. The only real issue is endianness, but that's not undefined behaviour, it has to be one or the other in a given implementation.
Meh, I use it for Qt things but "its" C++ parser has always had issues for me, in addition to being slow in general. Plus, if there are syntax errors (simply when I'm not finished typing for instance) I can't ctrl-click a symbol (or even an overloaded operator, but that's not even supported at all from what I saw), or things like that. It's quite infuriating. Its Git "integration" is also quite terrible. No issue at all with a CLion however, which is my main IDE. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aijwp3/is_sean_parents_better_code_a_real_book/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aijzdo/looking_forward_to_sean_parents_book_better_code/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yup. Same week as the Eurovision Song Contest if that‚Äôs your thing üòÅ
For whatever it's worth, you can also get template instantiation stats using `/d1templateStats`, and memory usage with `/d1reportMemory`.
What would be the alternative to header-only when everything is templated?
according to the link you yourself posted, both cases are undefined behavior, so the trait would return false. 
If the TIB fields would be documented by MS the code could adopted accordingly - has nothing to do with adding features. The code switching the context simply needs to swap some values of the TIB (for instance SEH, stack bottom etc.) - see Boost.Context. But MS decided not to document the complete TIB. BTW, WinFibers do internally sapping the TIB fileds - but of course WinFibers are implemented by MS they have all the required knowledge about the TIB etc. &amp;#x200B; It's MS fault.
No, it is actual and true UB. As will all kinds of UB, compilers are allowed to make it work as you would expect - by accident or as guaranteed behavior. What you are apparently asking for isn't a type trait whose output depends on what the standard allows, but what a particular compiler allows. IIRC gcc and clang follow the standard pretty closely, but msvc doesn't do type based alias analysis, so I wouldn't be surprised if what you are asking were officially allowed.
I'm actually really surprised that `#include &lt;vector&gt;` results in 74 total headers. No wonder we have such issues with compiletimes o.O
You might want to take a look at ROL https://trilinos.org/packages/rol/ The Rapid Optimization Library is an open source C++11 package for numerical optimization that operates on the user's application data structures directly to avoid copying data. The algorithms are predominantly matrix-free and the user can specify their own linear algebra as needed. There are some adapters for TPLs like Eigen included.
Well I don't mess with strict aliasing in those cases. If you know the underlying memory model, you can have fun with reinterpreting memory however you want if your compiler was not made by Satan. You can read something as a sequence of bytes, then manipulate them to make larger types than you know the implementation of for a given platform. To be fair, if I really need performance I'd probably code the unpacking in assembly right away.
If your problem fits in Matlab or SciPy, sure. 
&gt;Well I don't mess with strict aliasing in those cases. Interpreting a 64 bit integer as 4 16 bit ones and vice versa is doing exactly that. Interpreting a char array as any other type is also doing just that, but IIRC, the committee wants to allow this starting in c++20. Again, I'm not disputing that any of those things are doable in practice with most compilers, just that it is UB according to the standard.
Breaking up one's code into smaller headers with the goal of improving compile times naturally results in more headers being included for large pieces of functionality. ;-]
Hint: for finding cool MSVC flags, you can use `strings` or a similar utility to dump the `cl.exe` binary. (Unfortunately this also finds the uncool flags :( )
`constant_tsc` doesn't mean there are no inconsistencies between cores though, nor that there is no drift at all (afaik), it just means it's not dependant on the CPU frequencies variations. This also does not mean that going into C-state is safe (though I guess it does not matter here) as this is covered by the `nonstop_tsc` (invariant tsc) flag. You also have the `tsc_reliable` Then there's also the case of multi sockets etc etc etc. I'm not saying you shouldn't use the TSC directly, I'm saying that most of the time unless you know precisely what you are doing / the hardware you are using, using clock_gettime even though slower is a better idea.
If you want the complete list of flags that can be used: http://lectem.github.io/msvc/reverse-engineering/build/2019/01/21/MSVC-hidden-flags.html
I did a test on how good the generated code was and I think that it is worse than using a lamda to access the fields. Optimization enabled. Are pointers to members the equivalwnt of function pointers performance-wise?
Ah, this is sort of grim news. Don't get me wrong - this is a very high quality answer, the sort of thing that reinforces the value of the internet for solving questions. But I was hoping for a solution that didn't require people to tweak their kernels. On the other hand, I don't need much better than millisecond accuracy - I would call this "near real time". The application is controlling lights and hardware for art installations - you really won't notice ~1ms and you probably won't notice 10ms (though in my experience, intermittent errors in the 10ms range do read as "less smooth"). And single errors are not critical - if you gave me a solution that had a 100ms delay several times a day, I wouldn't care. But something like this: &gt; Beware that if your application is running with a SCHED_FIFO/SCHED_RR policy, that Linux, by default, will force a real-time thread consuming 100% of a CPU to sleep 50ms every 1s. That's probably unacceptable. You can easily perceive delay or jitter of 50ms, if it's every second. Still, the intended users are going to be technological artists. I think even asking them to install a new kernel is going to be too hard, and getting them to compile their own kernel is out of the question. Telling them to tweak configurations is fine, I think. --- Again, I want to reinforce the high quality of your answer - just because I can't handle the truth :-D doesn't mean it isn't fantastic.
The answer is obvious: ed
I did a pass to make vector include less stuff in VS 2019 that helped a lot. The issue with removing these dependences is that when we do, user code breaks. The amount of user code that expected &lt;vector&gt; to include &lt;string&gt; makes me sad :(.
Looking at our physical design.... I wish that had been the intent :)
Hey, Howard, good to run into you! I actually did something like that decades ago on a 16-bit machine (6809 or 68000 series?) with an extremely inaccurate sleep and it worked very well - and then I forgot about it till now. Very good idea, and also not so much code to write..
 std::ranges::sort( persons, std::ranges::less, []( auto &amp;&amp; n ) { return n.age ; } ) ; This is where a terse lambda syntax would shine, like in C#: std::ranges::sort( persons, std::ranges::less, (n) =&gt; n.age ) ; &amp;#x200B;
The absolute best that you could do with such documentation would be to adjust your code to fix breakage due to an OS changes on the _next_ version of the application. The fibers API in Windows does not have this problem because it is part of the OS and can be updated with the OS accordingly. It is not Microsoft's fault when they choose not to document all structures in the OS. All operating systems have a distinction between publicly visible structures and internal data structures not meant for public access, even if mapped read/write into user space. Hacking undocumented fields of the TIB in an attempt to circumvent this is unsound development practice that can and has resulted in programs breaking after OS upgrades through no fault of the OS. 
There is nothing preventing the compiler to optimize away the indirect access through a pointer and this is a part of intended usage of projection. So I expect the C++ compilers can do better job when implementation of C++20 got matured enough. That said, entire design of range depends too heavily on compiler optimization because projection function is always there. If you don't pass a projection function, std::identity, which just returns a identity reference of its argument, took the place of projection function as a default template parameter argument and default argument. ``` template &lt; typename R, typename Comp = std::ranges::less, typename Proj = std::identity &gt; auto sort( R &amp;&amp; r, Comp comp = {}, Proj proj = {} ) ; ```
It is. terse lambda expression is proposed and I really wish it is accepted in some way or other.
The sad thing is that even min_element doesn't cache projection result, so you still have to use fold with `struct {float distance; ...}` to find nearest object.
Actually the most annoying thing when working with it is that you can see straight through it. We have an ant farm in our office, so sometimes you are looking at your code and all you see is bugs...
I wish we could write for ( auto age : persons | &amp;Person::age) std::cout &lt;&lt; age &lt;&lt; '\n' ; 