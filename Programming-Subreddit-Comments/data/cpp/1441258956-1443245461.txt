Thanks for writing that out, it's always nice to see people's take on API design.
Re your MinGW distro: do you have plans for a gcc 5.2.0 / Boost 1.59.0 update any time soon?
Well after reading the responses of Barbara here to the valid remarks people are making about DoxyPress' retarded choices I'm pretty sure this project will be as successful as a bunny trying to fly by flapping its ears. 
C++ predates Java and most of the critics people throw at Java were standard practice in C++ frameworks when Java was brought into the world. So for someone like myself that knows C++ since the only available book was C++ ARM, this type of critic is kind of funny. 
My comment was simply an echo to /u/Abyxus's one (which you saw): use tags to create categories like - "dot": { &lt;insert dot options here&gt; } - "latex": { &lt;insert latex options here&gt; } Subcategories might be interesting to make, but I don't know Doxyfile enough to judge that.
Absolutely. We have been doing it for years.
C++ always had the possibility to have modern frameworks as in other high level languages, but the C spirit is too strong[0]. Also the community is highly divided regarding type inference. [0] A reason why MFC looks as it does. Legend says that as it was being developed it failed acceptance testing by being considered too high level, thus it was trimmed to be a very light abstraction over Win32.
That issue has been fixed though https://code.google.com/p/gperftools/issues/detail?id=489
Better yet, -MMD. It makes a dependency file each time the object file is compiled. That way, it stays up to date when you modify code. CPPFLAGS += -MMD -include $(shell find -name "*.d")
Is there an API you really like? I would to get ideas on better API designs. 
I like when people bash msvc just for the fact that it doesn't implement some features, like above mentioned expression SFINAE is a big impediment on writing modern C++ code. I don't quite understand how I used many modern C++ features\STL classes from msvc10+, but didn't notice lack of the most important ones. Also what do you mean by "lets you use compilers which already fully support C++11 &amp; 14", because boost is specifically made to support [a wide range of compilers](http://www.boost.org/users/history/version_1_59_0.html) (you don't even need a C++11/14 compiler to use most of boost libraries)? And to last question how many boost libraries actually require a fully conforming C++14 compiler, how many libraries in general have such requirement? The difference between using boost and msvc version of filesystem is that: you're testing a TS version of the library (which later will be in standard) and the library is integrated in environment like any other STL library (no need to build boost and set link/include paths).
Ah, good to know!
It doesn't sound so bad actually. What about the OpenGL and Gui module, I'm sure you're aware QtOpenGL is deprecated in 5.x and was revamped and vastly improved (as QtGui) in 5.3, 5,4 and 5.5. What about the whole QtQuick 2.x bandwaggon, are you not jumping on that? What about developing cross-platform (PC, Android, iOS) apps and CS? Is it as good and easy as with QtQuick 2.x? What about Visual Studio on Windows? What about VS2015? I can't find anything on your homepage. If it doesn't work on VS2015, that's a big no-no.
The community is not highly divided regarding type inference. In any case this would make no difference to the API design - one could just use auto if one wanted to. It's not prescribed or prevented.
Memory obtained from the OS that may have been used by another process is already zeroed. Memory re-used within your own process is not - I can't see a compelling security reason (?), and it could be a significant performance cost. In C++ you rarely allocate raw memory, it's mostly via new() so you're about to write real init values to it anyway, so it's just wasted cycles. Setting memory from malloc to zero by default is likely to cover up bugs, like forgetting to initialize pointers to null or counters to zero. Indeed many allocators have debug modes which initialize the memory to some pattern to highlight such errors.
&gt; I'm not trying to be a jerk, but I have no idea from your post what you are trying to do. `read this into c++ as a title, first name, last name, and text (all strings)` Sadly there are some assignments written like this out there.
hope we can work together someday, buddy
Then ask the professor for clarification. It'll be good practice for sussing out requirements in the real world. 
QT is more or less a horrible solution looking forward. As you point out it will never catch up with modern C++. 
It's a different kind of dependency. It seems you have to link a library to use Boost.Test, while most stuff in boost are headers only. I never tried to link it, but I know some libs are a pain in the ass to link with (Boost.Log for example). I'm using boost (filesystem, signals), but I still prefer using gtest for parameterized tests. But Boost.Test has template test, so it really depends what you want to achieve with those. Also, if you use gmock, you'll also have a dependency on gtest.
Thanks, I think I'll try VS, as I have used it in the past for other languages
So did you figure it out?
These are all questions about CopperSpice, which is wonderful. Our announcement was actually about DoxyPress and DoxyPressApp which use: CsCore, CsXml, CsGui, and CsNetwork. We have already back ported many of the Qt 5 classes and will continue to do as users request other classes. We have resolved QAtomic issues Qt can not fix until them move to Qt 6 in a few years. We are currently working on fixing all of the container classes. The Qt Project just released information about some major issues with QList, again they can not resolve this until Qt 6. Yes, we know VS is of value but it simply does not support constexpr fully. The Qt project is willing to wait 5-10 years to use C++11, we are not. We hope to talk more with MS in Seattle in two weeks at CPPCon about the missing C++11 features in VS2015. As soon as MS has full support for C++11 we will test it and update asap. Yes, we are aiming to support Android, but using the NDK which is the better approach for a C++ app.
Maybe a little more trial and error and a little less 420 would help if you can't finish you homework without begging strangers on the internet to do it for you.
It is similar to the other SDKs in that there are synchronous and asynchronous versions of all requests. 
I don't really see the indignation here. The people that use this software get paid a salary, right? In the context of that expense, a few hundred dollars a year for increased productivity really isn't significant. If management can't see that, then you have much bigger issues. Running a business is expensive. One of the bosses at my company mentioned that a new office chair costs between $200 and $1,000. Keeping the lights on is expensive. Computers are expensive. There are lots of costs to running a business. Out of curiosity, what IDE is your company using currently?
We do exclusively Linux development. So any of the Microsoft products are out. 
Eclipse is pretty good to be fair. Bloated, but very useful.
I'm happy to pay for software. It's less about indignation, and more that the clion was a tech I was ready and happy to invest in. I _wanted_ to pay them and take a risk (less about the money than the time energy to invest in a tooling) because I felt it was good. However, this changes the calculus - I'm already taking a risk investing my time, the subscription on top of that tips the balance towards too much about the tech being out of my control. I'm also less comfortable recommending it to others knowing there's an extra justification/management hurdle they'll have to jump through to get perpetual sponsorship for this. Additionally the pricing scheme seems high - usually subscriptions are attractive if they're a fraction of the price so that it's equivalent to buying the software once every several years, here it's more like 1 to &lt;2 years. I'm not so much indignant as I am bummed out that I can't give them more of my business because I really did want to.
[Codelite](http://Codelite.org) is pretty nice.
Eh, in a more perfect world maybe. Too many things can bump that 2k out of a budget. Lower than expected revenue, changing executives, etc. I would absolutely positively never ever "subscribe" to this type of model for an IDE. It's completely ridiculous. I can't even, in good faith, recommend CLion for any further investigation at this point--which is a pity because a lot of our team was excited to see it develop. Also: &gt; If management can't see that, then you have much bigger issues. This will be the case at most places. &gt; you have much bigger issues. Uh..... well that's convenient for you to say I guess. "I'm definitely right unless I'm probably wrong, in which case instead go kill yourself I'm still right." &lt;3
People don't like to pay. I think $7 a month is peanuts, personally...
&gt; Too many things can bump that 2k out of a budget. Lower than expected revenue, changing executives, etc. Come on. The most that you can be paying per person is $20 a month - if you get ALL the JetBrains stuff! If that makes your employee one hour more efficient a month, you're ahead of the game. I haven't even tried CLion yet, but $8 a month for it isn't going to deter me...
Is there a better way to implement this? 
If you really are ok with that, and your executive team is too, then you should definitely go for it! I sincerely hope it works well for you guys. It's a nonstarter for us, so ~eh~. I use Vim and Sublime Text for 99% of my daily development anyhow (I've somehow moved from C/++ to Perl in the last 8 months?), so I'm more than happy to stick with those. Er, slightly less than more than happy, but you get the idea. &gt; Come on. Hey now, it's the pitch to executives, the ridiculous money grab tactics, and the lack of control of your own tooling that have me irked. Not the price point in and of itself. This is that point in time where the "invisible hand of the market" hints very strongly at, "none of your bullshit please." Edit: oh right, what if they increase their pricing model or things of that nature? Suckling on the teat of a software subscription isn't exactly a safe place to be, which isn't quite what you want to say about your IDE. IMO.
Apparently people love to get paid while using tools from others that are supposed to give them for free. Only in software do we have this freetard culture, in other domains people pay for their tools.
We've made the tool available. http://plrg.eecs.uci.edu/automo/
It works. But its not great. Much better than most of tools but great is still not quite there yet. Im using it too..
Vim and emacs remain viable IDEs. There are a _lot_ of plugins for damn near any language you want to use, it's lightweight and it isn't going to a subscription model anytime soon.
No, they are no IDEs. You can install bells and whistles to get them close though, I admit that.
Try netbeans.
No matter how many plugins you install, refactoring and navigation support is shit. Fact is, most of these plugins don't even parse the source code into an AST. They're glorified CTRL+F replacements. 
I was going to try their products, as I was getting increasingly interested due to the buzz around them. Now reset to zero interest.
Qt Creator user here, it's my tool of *choice*. Better than VS (well, with VAX it's comparable, but it forces you to use a crappy compiler and it's impossible to uninstall it), better than sluggish-as-hell Eclipse and let's not even mention Code::Blocks and the likes. I feel that, until CLion, Qt Creator's only real competitor was vim, but not many will use it either. Now, we're left with only vim again.
A proper IDE understands the code you write (== has a code model). Everything else is just a bunch of tools integrated into one UI.
Qt Creator has also a clang C++ parser plugin, also in development mode. One can switch to this clang code model (given that the plugin is enabled) from Tools -&gt; Options -&gt; C++ -&gt; Code Model.
The only problematic thing I found with Qt Creator was its auto complete support, which was instantly better at parsing code when I turned on the Clang backend for "intellisense" instead of using Qt Creators built in engine.
&gt; The most that you can be paying per person is $20 a month Note that companies will be paying $40 a month for all the JetBrains stuff and after the promotional offer expires: $50 a month. If that provides an efficiency increase? Money well spent. But the question is: does it really? What's missing compared to free tools, say Eclipse or Netbeans.
I don't mind paying for software but I refuse to use software where if I stop paying a subscription fee it stops working.
&gt; And yet they work marvellously. &gt; For some value of "marvellously" :P Anyway clang_complete is kinda the exception and works reasonably well. Still, it takes way more than autocomplete to make an IDE. 
I know, that is why I said you can get close to an IDE with vim and emacs. Close because the nothing but the text editor actually makes use of that data, unlike a real IDE.
I also see autotools as a step backwards. But, it would certainly help to provide integration with CMake, at least provide proper CMake modules in the binary distribution. If it would be easy to just use `find_module(DoxyPress)` in an CMake environment, it would be a tremendous step forwards, since CMake nowdays is the de-facto standard in the C++ world. Alternatively a `FindDoxyPress.cmake` module for the official CMake distribution, similar to `FindDoxygen.cmake`? 
refactoring and browsing (at the very least, I want to ctrl+click to see the definition, alt+click to see the latest declaration, option+click to see autocorrect "did you mean" options, and hover to see comments) Also watching variables during debugging. Common data structures like strings and vectors should be displayed correctly when I hover over the variable after pausing execution. 
In reality this makes it even better for you than before. You can try it without buying a license and in case it's not good enough or developed enough for you, you can cancel your subscription again and save money.
I used netbeans (and am trying eclipse), and it just ate all my RAM and then hung. CodeBlocks wasn't much better. I'm struggling to find an linux IDE. I use visual studio on windows, and there is nothing even remotely comparable. To be honest, I don't mind using a fairly good text editor, such as sublime text and a terminal. The major problem is debugging. Command line debuggers are simply terrible. Being able to see the code you're debugging, plus hotkeys to step in/out/next, plus mouse over variables to get information, it is just so much more powerful. At this rate using a VM with visual studio and something like VisualGDB or the microsoft remote gdb thing are becoming viable options.
"Clicking" (with the keyboard) to go to definitions is built into vim and emacs, they (mostly) use tags files for this. Usually generated with exuberant-ctags. When/how you generate them is up to you. I use a plugin for vim called gutentags to keep it all up to date automatically so I never think about it. Syntastic and similar linting/compiling/checking frameworks have come a long way, but afaik we can't yet do "click X to apply default fix A for this common compiler error". Though I've got automated ways of jumping between compiler errors, and since editing in vim is so fast I've usually automated all fixes myself already, so I can execute them with a few button presses. Not as good as a single click, but applicable to any situation you can put your mind to, not just the common-denominator things commercial providers have to focus on. Debugging is indeed shit outside of IDE-land, which is why I usually fire up Qt Creator to do any complex debugging.
Yes I know these are CopperSpice questions - I just took up on the opportunity to ask here since I was interested, you were answering, and I couldn't find much/any of that information on your homepage :-) Well, thanks for replying, but you didn't really answer most of the questions. I mostly use the standard containers and not Qt containers, but anyway, nice that you fix them. I agree the NDK is the better approach, but it doesn't solve the GUI problem (and the cross-platform), which QtQuick 2.x does. So, if I had to summarize from your reply: * No QtGui revamp in CS, your state is pre-Qt-5.3 with all the mess and deprecated stuff in QtOpenGL * No QtQuick 2.x * No possibility to make a cross-platform app (including a GUI) * No VS2015 support at all You would probably say I could add a "not *yet*" to all of these, but that's a lot of stuff. And Qt is evolving in good directions too. That strengthens my worries that while it's certainly good that you modernize Qt and distance yourself from it a bit, you will never be able to keep up with the *good* things that Qt change (for example all the flaws in pre-Qt-5.5 QtGui/QtOpenGL). It seems to me like the goal of your project is a bit weird (or I just haven't grasped it yet - your homepage doesn't offer much info), I'm not sure what problem CS is supposed to solve. It's neither one thing nor another. (On a sidenote: IMHO VS2015 supports enough of C++11/14 to define it as the target w.r.t. C++ features used - and as soon as there's an upgrade (either Update X or VS2016 whatever), CS would move with it. That way, you can use 95% of C++11/14 features but don't exclude all Windows users. But that's just my opinion.) *Edit: This is all quite negative, so I want to mention as well that I think it's an interesting, good project, and I'm glad you're doing it - if anything, the C++ community will only benefit!*
Well, I surely don't like these "cloud-subscriptions" or monthly licenses. But they offer free licenses for students and open source projects! This is **very** nice. Thank you. Anybody else shouldn't complain in my opinion, because they are using the CLion tools to make money with their software, so they can as well pay for the tools!
I'm sure Jetbrains would be willing to discuss your needs if you're a paying customer. Did you try to contact them? No? Then don't complain. *Edit: Anyone care to explain the downvotes? Do you like people that complain, without even trying to talk to somebody first?*
When the subscription expires then the product locks itself so you cannot use it anymore until you pay again for a subscription extension.
&gt; I use a plugin for vim called gutentags to keep it all up to date automatically so I never think about it. &gt; Huh can I type this and click on `f` inside `g` to go to the definition? extern "C"{ int f(x){return x;} int g(x){return f(x);} } I was under the impression that those tools require you to run a static analysis every time you define new things and save the file. 
We were already paying. The issue isn't that we don't want to pay, it's that we don't want to rent. I think complaining about the rent to not-own model is perfectly valid and reasonable.
All of these secenarios are quite far fetched IMHO - in addition, they still don't seem like good reasons not to use JetBrains tools in the interim time before these calamitous events happen: They are asking you to pay month to month I'm assuming, loneraver says he won't use a tool he would otherwise use because its subscription. If JetBrains suddenly goes under, without providing a way around the activation servers ... won't he just be back to where he is now? Whats the foul? Under what circumstance would you have paying work, or even hobby work without internet access unkowingly .... and more importantly that the "no internet for a month" concern would be so high that you would refuse CLion because of it? - If I was going to do C++ programming in the middle of the sahara I'd just buy a longer subscription beforehand or tough it out for a few weeks with something else....but that wouldnt stop me from using CLion to begin with
Are you so young that you don't remember non-subscription software? You can continue to use perfectly good software for years after release. Sometimes with legacy projects you _have_ to use the older version.
What kind of refactoring and navigation? You need to jump from a function to its declaration? or jump to its multiple occurences? or jump to std sources for eg vector class? YCM does that. You want to change a function throughout the source files? you want to rename a function, delete a function and its all occurences throught the source? vim can do that. and then you have tons of other plugins to do these task too.
I don't know about clicking but pressing **,jd** does this for me (when using YCM)
Code model still pales compared to Eclipse. If you have complex code with templates, Eclipse just does a much better job indexing. It also has (I believe) some excellent code navigation tools that QtCreator doesn't, like step-by-step macro expansions, include graph and call graph. Also, if you're a vim guy, Eclipse's vim emulation (Vrapper) puts Qt Creator's vim emulation (fakevim) to shame.
Ah, so forking Qt wasn't enough ? What next, opencv ? boost ? 
Step through debugging depends on the language; but the integrated GDB stuff works very well for C/C++. 
Huh neat. 
Sure, which is why I'm looking for NeoVim to support some of the plugins I use, because then I can use [lldb.nvim](https://github.com/critiqjo/lldb.nvim). Video of it [here](https://youtu.be/aXSNhTH1Co4).
I like to pay for software, as long as I'm buying it. If I'm renting software, that's a different can of worms. I got CS6 and didn't upgrade to CC for Adobe, and I'll probably stop upgrading CLion and RubyMine for the same reason.
Neat! I invested heavily into neocomplcache/neocomplete before I knew about YCM, so I've never tried it. Might give it a go next time I'm working on systems stuff!
The foul is that the software, as far as we know right now, doesn't function at all if it doesn't get the opportunity to do its 30 day phone home. With the current perpetual licensing scheme, he could use the software as much as he wants whenever he wants without worrying about whether or not it will actually work when he needs it. He also has the opportunity right now to forego an update if he feels it provides no benefit or utility to him. Under the new rental scheme, you can (probably) still choose not to update... but you still have to pay. That may not be important to you, but it could be very important to him. Who knows! I don't. But it's certainly nice to have the option and, as far as I know, we've lost that option going forward.
Thanks for reply. Guess for me it doesn't change it that much and I'm still yet to buy my first product from jB.
By the way I wonder why using things like FakeVim for QtCreator isn't enough? I mean there are also things I've heard about vim being fast to open large files, but I believe it shouldn't mostly be a concern for people who work with source code.
&gt; Deugger is still lacking compared to VS What are you missing in the debugger? edit: in qtcreator, that is.
1. There are other C++ compilers besides MSVC 2. There are even posts by developers working at Microsoft (on the Boost mailing list) indicating some teams within Microsoft use Boost (even if the same components are provided as part of the C++ standard library that ships with MSVC)
YCM for cpp and omnisharp for c#. YCM displays "(quick fix)" at the bottom for a correction via clang.
1 &amp; 2: I don't know about them since they're pretty new additions and vim plugins are made by devs in their free time so expect a little time hehe. 3. for functions ycm has quick jump to next occurrence using clang, will that qualify? for variables there is another plugin - clighter that highlights occurences if you hover. but you have to install two different plugins now. &gt; Yep and I also want to extract local variables to fields and generate constructors based on fields. I do not understand this. Do you have some sort of video/gif or image to make me understand :/ I guess this isn't possible for now or I would have known about it. I use cgdb for debugging and it has all features you would want. Also there is nemiver too. And for experienced programmers, nothing beats gdb I guess.
hmm I guess the plugins aren't *that* bad but hey, C++11 was 4 years ago :P Hopefully someone starts implementing all that. Oh and gdb is painful. 
 &gt;I used netbeans (and am trying eclipse), and it just ate all my RAM and then hung. CodeBlocks wasn't much better. I'm struggling to find an linux IDE. I use visual studio on windows, and there is nothing even remotely comparable. Eclipse is one of those products I'd really would want to use but it defeats me every time I try a new version. Many of the bugs have been outstanding for years now. I really do wish they would get their act together and focus on big fixes to make Eclipse stable. One option to consider is XCode on a Mac. XCode is another IDE that leaves a bit to be desired stability wise but it is flexible. &gt;To be honest, I don't mind using a fairly good text editor, such as sublime text and a terminal. The major problem is debugging. Command line debuggers are simply terrible. Being able to see the code you're debugging, plus hotkeys to step in/out/next, plus mouse over variables to get information, it is just so much more powerful. I see lots of comments about how powerful the command line is and while true it isn't the most productive way to develop these days. The Linux community apparently gave up on many IDEs in favor of Eclipse back when it was being ramped up as a product. The problem is the platform never really matured to the point that it has become something one can recommend to other developers. I really don't know of a decent IDE for Linux anymore. This is probably why so many people develop on a Mac even if the eventual target is Linux. &gt;At this rate using a VM with visual studio and something like VisualGDB or the microsoft remote gdb thing are becoming viable options. Yes very similar to what is happening with Mac OS. Actually developing on Linux is a bit like working with Stone Age tools at this point. Sad really. 
$49/year for existing customers. This isn't a tremendous amount for paid developers. I'd complain more about companies that have huge processes in place for petty software expenses like this. They prefer their devs waste days rather than throwing a $50 tools at a problem. That said, I hate subscriptions. But its for the exact reason jetbrains probably loves them. Its reoccurring revenue/expense.
Considering I'm working in a similar dysfunctional company I can safely say that JetBrains will eliminate itself from consideration by many that have to struggle with similar management non sense. Sometimes there is no rational explanation other than a manager getting a bone up his ass about spending money in a certain department. Mind you this isn't about a company in financial risk, it is all about a management team that has decided to devalue entire teams of workers. On the flip side almost every company at one time or another has had to engage austerity measures where things like subscriptions just aren't possible. So JetBrains looses again. There are so many things wrong with the subscription model for software that I can't rationally recommend it to anybody. 
It wasn't like that. I am into computing since the mid-80's. Before the rise of FOSS, we paid for our tools, every single application that was installed. Of course, there was shareware and pirated software as well, but generally we paid it. Now it seems everyone wants their tools for free, but at the same time feel entitled to get money for their work.
Sure, there are lots of plugins that do some part. But in general a plugin does everything and no other plugin can easily access the codemodel from another plugin. In an IDE that functionality is there and a plugin can just access that data and do something valuable with that.
 &gt;Come on. The most that you can be paying per person is $20 a month - if you get ALL the JetBrains stuff! If that makes your employee one hour more efficient a month, you're ahead of the game. To business managers that doesn't matter, especially if the choice between an austerity budget and lay offs have to be made. If you have a large team it is very easy for software costs to get out of control and often represent a greater expense than a programmer. Scrapping all software updates and hardware updates for a year can save significant cash for a company allowing it time to work out of any financial issues it might have. Often a tight budget can mean retaining key people which does more for productivity than any subscription service. Let's face it if you have been in the work force long enough you will have to have worked for a company that has tightened its belts significantly. Sometimes this is for a few months sometimes for a year or longer. Software subscriptions just suck in these situations, especially if the software goes dead for a few months. &gt;I haven't even tried CLion yet, but $8 a month for it isn't going to deter me... Maybe not you as an individual but it makes suggesting such software in a large organization impossible. You just never no when a decision will be made that you have no control over. 
Its got great codesearch and error detection. Do you have a particular problem with clion?
I use vim with You Complete me, Syntastic and a couple other plugins. 
Thanks. I am still learning C++ (3 months in) and so far have stuck to Visual Studio as it "just works" on Windows but I also compile all my code with MinGW to get some experience with GCC. When/If I switch to Linux I will certainly look into Vim as the plugin eco-system looks really nice.
Right. Even though right now the organization is currently in a good place. I can't risk putting the development workflow at risk. As a lead, I have to suggest to management that we move away from JetBrains to protect the team from future constraints. All of a sudden using JetBrains just became a liability for my development team. 
Well you are doing the right thing here even if it hurts. The question is what will you move to?
&gt; Are you so young I will replace my "Are you so stupid?" phrase with this one. 
Yes, it's pretty nice, but the real value comes from the whole Linux ecosystem: thousands of libraries that you can install with just one command. The awesome shell tools that allow you to do so much with just a few commands once you master them. And of course the possibility to deploy your stuff on as many machines as you wish without even thinking about software licenses.
Isn't boost.variant a good enough universal value object?
I was just starting with CLion because unlike most IDEs, it lets me group my .h and .cpp files how *I* want to (similar to XCode), instead of auto-splitting .h and .cpp files into entirely separate trees in the project view (VisualC++, QtCreator, Code::Blocks, etc...). This move of JetBrains really pisses me off. I'd just paid for a regular license and everything.
Yay, \_\_attribute\_\_((target)) support (like \_\_target\_\_ in gcc)! Can finally compile overall with one set of instructions (eg. -mssse3) and still be able to use higher level intrinsics (eg. sse4.2) for specific functions (using manual dispatch based on detected CPU capabilities) without having to separate all that code out into individual source files (which isn't always easy or possible, esp. when using templates). I'm not sure why explicitly using intrinsics is disallowed for instructions not supported by what -m specifies.
You. I like you. You've seen a thing or two, haven't you? :)
Nice, thanks! 
`boost::variant` is already implemented as a tagged union, basically the same as a Rust enum. It can be initialized from any of the possible contained data types. For type-safe `match`ing, use `boost::apply_visitor`. See [here](http://www.boost.org/doc/libs/1_59_0/doc/html/variant.html#variant.motivation.solution) for an example of that. The main drawback is that you need to use a separate functor for the match body (so the "`match`" arms can't implicitly access the outer scope). `boost::variant` won't always be as efficient as Rust enums (`boost::variant` is sometimes forced to heap-allocate, and the underlying representation might be bigger because C++ allows null pointers), but as far as I'm aware, it's more or less as good as it can be with current versions of C++.
I'm not sure what your implementation is providing that `variant` doesn't give you. I expect the C++ version to look like struct quit_message {}; struct change_color_message { int a,b,c; }; struct move_message { int x,y; }; struct write_message { std::string str; }; using message = std::variant&lt; quit_message, change_color_message, move_message, write_message&gt;; In the case that every alternative of the variant has be an individual type, this is not actually more verbose than Rust (cf. [Entry](https://doc.rust-lang.org/std/collections/hash_map/enum.Entry.html) for example). What's really going to make you grind your teeth is the lack of Rust's `derive` to write tedious things like `operator==` for all these classes. The big drawback is, of course, elimination. Rust has pattern matching. The visitation schemes in N4542 suck, they basically just kicked it off down the line (Boost's are equally bad). I've said before I'd like a simple scheme like `visit(variant, l0, l1, ..., ln)` which will call, if `variant` holds its `k`th alternative, `lk` on `get&lt;k&gt;(variant)`, which would let you write lambdas to handle each alternative. I really hope N4542 in some form (as long the empty state is invalid) gets accepted.
&gt; `boost::variant` is sometimes forced to heap-allocate It seems scary when expressed like that... `boost::variant` never heaps-allocate behind the programmer's back. Only if you need to use [recursive variants](http://www.boost.org/doc/libs/1_55_0/doc/html/variant/tutorial.html#variant.tutorial.recursive) (ie, variants referring to themselves) then you have to use a specific construct which may heap allocate; however referencing to self has the same issue whether you use a variant or not, so it's not exactly surprising. 
Tagged unions are good, but without pattern matching (which is what the visitors attempt to get you), they are unwieldy...
no this isn't it. it's for exception safety. see here: http://www.boost.org/doc/libs/1_59_0/doc/html/variant/design.html#variant.design.never-empty.heap-backup-solution
Oh, thanks for the heads-up. Once again I so much appreciate the stricter semantics of Rust: by guaranteeing a no-throw move, such problems are a non-issue.
right sure, although this is for copy-assignment. i don't know rust but i assume that can fail? the [next section](http://www.boost.org/doc/libs/1_59_0/doc/html/variant/design.html#variant.design.never-empty.optimizations) outlines some ways of avoiding this extra storage: &gt; &gt; Accordingly, variant is designed to enable the following optimizations once the following criteria on its bounded types are met: &gt; &gt; * For each bounded type `T` that is nothrow copy-constructible (as indicated by `boost::has_nothrow_copy`), the library guarantees variant will use only single storage and in-place construction for `T`. &gt; &gt; * If any bounded type is nothrow default-constructible (as indicated by `boost::has_nothrow_constructor`), the library guarantees variant will use only single storage and in-place construction for every bounded type in the variant. Note, however, that in the event of assignment failure, an unspecified nothrow default-constructible bounded type will be default-constructed in the left-hand side operand so as to preserve the never-empty guarantee.
I use it as git pre-receive hook and integrated in vim with synstatic plug in. It's very handy. Well done to developers. ðŸ’ª
This looks interesting, and I had high hopes for it. But, why is everything a double? It looks like it's possible to define your own types that operate floats, but can anyone confirm that?
For the match part there is[ Match7 by Strousup et al.](https://github.com/solodon4/Mach7), [pdf](http://www.stroustrup.com/OpenPatternMatching.pdf) It works like that : // Lambda calculator struct Term { virtual ~Term() {} }; struct Var : Term { std::string name; }; struct Abs : Term { Var&amp; var; Term&amp; body;}; struct App : Term { Term&amp; func; Term&amp; arg; }; Term* eval(Term* t) { var&lt;const Var&amp;&gt; v; var&lt;const Term&amp;&gt; b,a; Match(*t) { Case(C&lt;Var&gt;()) return &amp;match0; Case(C&lt;Abs&gt;()) return &amp;match0; Case(C&lt;App&gt;(C&lt;Abs&gt;(v,b),a)) return eval(subs(b,v,a)); Otherwise() cerr &lt;&lt; "error"; return nullptr ; } EndMatch }
Do you like people that tell you what to do? Everyone got the right to discuss, like or dislike something, without someone (you) telling them what to do. Plus it's a fixed price model, there is little reason for Jetbrains to make exceptions. Sure they might do it, who knows, but is it worth the negotiation? Who can guarantee that it would last?
short summary: comple-time/expression template based skyline
Does CLion do this? (I also want to see the value of *type-id*s.)
This is a cppcheck bug, if its installer doesn't contain the VS 2015 redist, or app-local DLLs.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [Where Rust shines compared to C++](https://np.reddit.com/r/programming/comments/3jrye3/where_rust_shines_compared_to_c/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
I loved cppcheck but it is a sourceforge thing and thus it might as well be covered in ebola infested poop it is so untouchable. 
Actually that is exactly what's being done with VC++ 2015 onwards. It's being installed through windows update on Vista and above.
They now are, and maybe in a year or two it'll be reasonable to skip shipping the redist (assuming you've dropped XP support).
That's actually incorrect. The Universal CRT is part of Windows, but the rest of the VCRedist (including msvcp, where I live) is still part of VS and must be redistributed as usual.
Gutted. Glad I bought what I needed while I could get perpetual licenses. The worst thing is the subscription isn't any cheaper than the old pricing, it's like they are just trying to force you to pay support you generally don't use.
I am hoping that the developers take the hint and pull it themselves. I don't think the world needs me to fork it and then be perpetually behind the curve on updates. 
It might be worth mentioning that Rust's *enum* is an implementation of [algebraic data types](https://en.wikipedia.org/wiki/Algebraic_data_type) (ADT) that originated in functional programming languages, which in turn took the concept from mathematics. Rust just called it "enum" to avoid scaring off C programmers. :-) No implementation of ADTs should come without (deep) pattern matching, i.e. a *case* statement that binds variables in the pattern. That can't be done in a library. Most of the convenience of ADTs comes from having this.
So it's just a way to put all code into one file and have it automatically split up instead of being organized yourself?
&gt; C++ isn't difficult, yet writing it is often a hassle thanks to the 1980's way the language is processed C compatibility is to blame. Modules were already a thing in the 70's. Check Mesa, Modula-2, Algol and PL/I variants.
yo why every1 h8in on dis comment
I should add that you can also declare your own types to be `Copy` as long as all their contents are `Copy`, e.g. #[derive(Copy, Clone)] struct Foo { .. } 
Thanks for posting the link /u/mttd (I'm the author)! This is the second in a series on the permissively licensed open source lightweight multithreading task scheduler for C++ (with C and C++11 variants), the [first linked to on /r/cpp here](https://www.reddit.com/r/cpp/comments/3i0j67/implementing_a_lightweight_task_scheduler/). Any feedback appreciated.
I wonder how and if it deals with templates...
&gt; C compatibility is to blame. On the other hand, the header system is quite good at allowing the build system to compile each translation unit in an independent order, thus easing parallelization. I don't know how modules work on those languages, but for example, modules in a compiled language as Fortran impose that each unit has to be compiled after the ones containing the modules that it uses. Therefore you are not able to parallelize the build in many cases. 
Those languages also allow for textual inclusions. Also compilation times are hardly an issue in module based languages.
Definitely. It's not a particularly forward-looking choice, and it does make compiling it for Windows unnecessarily difficult. I use doxygen on all the major platforms, and would certainly appreciate being able to easily build it on all of them.
Is there a public version control system? I don't see any links to git or any other VCS on the announcement or elsewhere on the website, unless I overlooked them.
Any clips to go with this?
0. On the download page, there are numerous fake download buttons, which will download some adware or nobody knows what. Sourceforge does nothing to change that. 1. They are inserting some bloatware/adware into installers of the software hosted there. First they did it on opt-in basis, paying some money to the project administrators, but later seem to start doing this on their own. 2. Recently they even started hijacking some projects, like GIMP and nmap. [Read more](http://arstechnica.com/information-technology/2015/05/sourceforge-grabs-gimp-for-windows-account-wraps-installer-in-bundle-pushing-adware/). 3. They are simply unreliable: couple of months ago Sourceforge was offline for about a week. 
&gt; to compile each translation unit in an independent order Except that all dependencies are already included in correct order. And compiled again, instedad of taking from cache. You are comparing apples and apple trees here. 
So then, if b.cpp depends on a module defined in a.cpp, are you saying that a.cpp and b.cpp can be compiled simultaneously because a.cpp can be included into b.cpp as the preprocessor would do with a.h? As for the compilation times, certainly they are an issue with C++ when a project is composed of many several submodules.
&gt; On the other hand, the header system is quite good at allowing the build system to compile each translation unit in an independent order, thus easing parallelization. Well the reason this works is simply because the work processing the header is done every single time it's used. With a module system a module's 'header' is processed once and then everything that depends on that module simply uses the result. This processing of a module's 'header' before processing a translation unit that depends on it is a dependency that exists in both module systems and in C++'s header system, so there's no additional dependencies there that hinder parallelization. What most module systems do add is that processing the module's 'header' also necessarily entails processing the whole module. So that is an extra dependency that could slightly hinder parallelization. However it's not necessary to design a module system that way. If you look at clang's module implementation, which is focused on backwards compatibility and so still supports headers, the ability to process a module's header separately from actually building the module still exists. That means that clang modules allows it to avoid the repeated work of processing a header over and over, but also doesn't add those new dependencies that traditional module systems do. On the other hand that means that clang's module system doesn't eliminate headers yet. Hopefully we'll eventually be able to choose to either write 'modern' modularized C++ without headers, or to use modularized headers. (or to just use the regular header model.)
boost is usually my first place to look, but just because a library is in boost doesn't necessarily means has a good balance of complexity/usability or even performance. boost::format is incredibly slow and not as nice to use as cppformat. boost::signal (and signal2) are ok for simplicistic use, but for not-much-worse interface libsigc++ has actually decent performance. boost::locale has no true utf8 support. Just to name a few. As I wrote, many times the boost libraries tend to be overengineered. I pick my boost dependencies *very* carefully.
Doesn't really cross the threshold of solving a big enough problem to justify the downsides of using a bespoke C++-like language. I'm guessing the author writes code in a text editor with at most ctags-like code completion, as that's about the upper limit of IDE tooling that'll work with something like this. If you don't care about that then it may be a reasonable choice for a person project you don't ever expect anyone else to contribute to, but not much else.
Yes, I get a feeling that some boost libraries live up to the ideal of something common that should be in the standard library. But with many boost libraries I get the feeling that the developer is showing off; or worse doesn't understand how complex they have made things. My favourite small ones: * www.agner.org/random makes a random library that I like. It is small and nice to have certainty that from one platform to another I will get the same "random" numbers given the same seed. Very important for procedural generation. * I like crypto++. http://www.cryptopp.com/ I don't know if you can use it to secure your bank but for my purposes it is one of the cleanest crypto libraries around. I don't use this to communicate with other crypto but more for just passing things around so they aren't in plaintext. * json11 from dropbox https://github.com/dropbox/json11 is presently my favourite json library although I do pretty much find a new greatest json c++ library every project. * The classic c sqlite3.h/sqlite3.c pair show up in many of my projects. It is not C++ but straight C. I then use a personal C++ class that wraps them in a very simplistic way. What I love most about the above three is that they are clean and small. Not a pile of linking nightmares. This is critical as I often program one codebase that goes to at least three pretty different platforms and sometimes to four. Poco is another wildly useful set of C++ libraries. http://pocoproject.org/ It is a bit bigger and more complex than the others to integrate into a project but it is multiplatform and covers just about all the basics including networking, ssl, database, zip, json, plus a bunch of other little things that you really don't want to build for yourself such as dates, threading, base64, unicode, etc. ---------------------------------------------------------------- What I am on the lookout for is a graphics library. TK is too old, wx feels like TK. QT is to onerous with their licensing. Cairo isn't enough. I want something that is very very multi platform, but doesn't overreach what I want which is a library to make screens, dialogs, animations, etc. Also I am looking for fantastically lightweight. Ideally a handful of headers, a handful of cpp files, and that is all. Linking on 4 different platforms is very unpleasant. 
First, good question. I haven't actually encountered a lot of libraries that take advantage of C++11 unfortunatly, but two very good ones: - moodycamel::concurrentqueue https://github.com/cameron314/concurrentqueue - cereal https://uscilab.github.io/cereal/index.html
Libraries in the standard try to be one-size-fits-all. Even if there were standard libraries for the data structures and algorithms you miss, what makes you think you'll like them, especially when you feel that one of the most popular matrix libraries is too big for you? Python deprecates and breaks its library APIs in just about every version. The C++ standards committee absolutely loathes deprecation. Where possible (i.e. in the absence of a dependence on new language features), they try to standardize existing, proven, popular libraries instead of proscribing new ones. Given the culture and history of C++ standardization, there's a reason the standard library is small compared to other languages.
Filesystem is already on its way in, and can be found in namespace experimental. Same with optional.
If you think program_options is great, you did not try docopt, seriously. https://github.com/docopt/docopt.cpp
The advantages are: * For what it's worth, you can keep encapsulation and provide object-based interfaces around member functions such as particle::render, particle::move etc. * By decoupling access from the class itself, you can easily play with different data layouts: SOA, partial SOA or even get back to "traditional" objects (see tuple_storage in the [first article](http://bannalia.blogspot.com/2015/08/c-encapsulation-for-data-oriented-design.html ) of the series).
With regards to graphics libraries, do you have an opinion on CopperSpice, seeing as you have used Qt before? Also, what do you find onerous about Qts licensing? You can get it in LGPL, can't you?
For parsing I'd like to suggest the [PEGTL](https://github.com/ColinH/PEGTL) (parsing expression grammar template library), a small, modern, header-only C++11 library. If you have any questions feel free to contact me, I'm one of its authors.
https://github.com/open-source-parsers/jsoncpp jsoncpp is quite good.
It's kinda sad, that few people have enough experience and funding to push new features through the whole standardization process and they are mostly interested in cool stuff like metaprogramming or parallelism/concurrency and not "boring" everyday things like `string::split`.
Not sure why you think cppformat is a "gem" - could you further elaborate and qualify why it is you think that to be the case? &amp;nbsp; One other thing, you're a first time poster, posing a generic/vague question with no real intent, a question with links to projects under the guise of "examples" for your premise - smells a bit fishy to me...... Victor is it you? 
PSA: plugin kept crashing in MSVC2013 so I built it from source. 
What is not free about GPL and LGPL?
I think at the moment that's highly implementation dependent. I guess it would be time to check if all VS2015, gcc&gt;=4.8.4 and clang&gt;=3.5 support it, but taking a guess, I highly doubt it.
Now that you're talking about libraries, I've had a hard time finding a object oriented markdown library for C++. Do you know of any?
IMHO this is not really correct. May be in real time (games) 3D float are used but in offline 3D doubles are used too. Yes they are slower (very slow on GPU) but have much better precision. So for example Maxon Cinema 4D has switched from floats to doubles long time ago. With greatly reduces all the problem with floating point math.
https://www.archlinux.org/packages/community/x86_64/cppcheck/
Problem with that is that it requires boost =[
I like how it enforces a consistent (and sane, it seems) documentation style, but I'm not sure how I feel about parsing the documentation to generate the model at runtime.
I don't understand your complaint about Wx. I don't see the comparison to Tk. Wx needs a sprucing up to modernize it and fix some bugs, but fundamentally it seems fine. Somebody should just fork Wx, rip out all the bits that don't belong in a GUI library or have been obviated by other libraries (networking, filesystem), put things in proper namespaces, spruce up the interfaces with C++14.
LGPL is OK, but for iOS or Android you pretty much have to buy it. MIT, Apache, BSD are the sort of licences that I much prefer. Looked at CopperSpice and it looks interesting. Eliminating moc is a very good thing; always stuck me as sloppy. But no iOS or Android.
First, cppformat takes a much more pragmatic approach to argument parsing using argument packs as opposed to operator overloading. It feels as an improved evolution on the printf family of functions, it's faster than boost::format, and it's more concise as well. It uses a python-esque format syntax, which is a bit of a deviation compared to standard printf-like formats, but it *does* play much better with localization as well, which is something that I only appreciated later on when I started with python. It's also completely self-contained, well documented, actively developed and after years of use I couldn't find anything significant that I'd like to change. It solves a little but common issue in general programming, with an implementation which I believe being a notch more modern than boost::format as well. I'd use it all the time, in almost every project, if it was part of the code C++ library. Of the other printf-alike libraries I've came across, *this* is what I use daily. That, for me, is the reason why is a "gem". As for the generality of the question, it's somewhat intended: I'm already aware of several other libraries for the basic needs that I use regularly, where I had time and invested effort in choosing a particular implementation. But for the occasions where I need something else I usually don't have time to dedicate to "library scavenging". This is why I left the question rather open-ended. Finding small, well documented, well implemented libraries has become very hard for me. There's a whole load of projects for any topic, but most are just immature, not documented, or not even developed anymore. Many are unjustly hyped. There's no easy well to tell if the API actually has any advantage versus another model unless you use it for a while a discover the flaws in the choices that were made. Is it too specific for a particular domain maybe? Hard to tell at a glance. It's even harder that many of these needs are so common as small that people just lump together the next "general c++ library" (such as poco or folly - as suggested here). I have mixed feelings with these libraries, because generally there's no clear separation in the stuff they introduce, often not linkable in a separate way, and maybe even introducing too many private types (yet another exception hierarchy, for example). I would accept one, but it *must* be something of the level "yeah, if I had to choose ONE standard library, that would be it". It's very hard for me to make such a choice, and this is why the larger the library, the greater the chance I'll just implement that crappy ~50 lines of code I just need for this occasion, *yet again*. There's only one occasion in my experience where this actually succeeded, and it's the Jane Street's ocaml core library, for which I actually *did* ditch the standard ocaml base entirely. boost, in that sense, offers the "easy" choice. It's the de-facto second standard. But it has backfired on me *many* times in the past. The over-generality of the templates, heavy meta-template programming to overcome c++ old limitations are things that I generally loathe today. API usage *must* be part of the consideration when designing the API itself. I much prefer to have two libraries for the purpose: a general, simpler, well-designed library that solves the general case, and a much more targeted library for the specific circumstance. I's very easy to look for specific libraries: you know *exactly* what you need, the performance you're after, the requirements. I have no trouble going for a specific LLR parser generator, or an hash table given a set of constraints. It's much harder to pick a small library for everyday use, like a good all-around implementation that you can pick as a default. For example, looking at the above messages, I much prefer ``cxxopts`` in terms of design choices compared to docopt, boost:: mostly because docopt tries to do too much. It's already too specific. I have no trouble choosing between cxxopts and boost::program_options if I account for dependencies, but if dependencies are the same, is cxxopts API generally better or more pleasant to use? Hard to tell unless you have plenty of experience with both. I would really value more specific advice for the suggested libraries. Sometimes it's easier: with cppformat there's just no contest, by contrast. With many others, a lot of experience is required, and there's has to be a starting point. Sorry for the overlong reply, but I hope this justifies the question even more.
Why you have to buy Qt when on iOS or Android?
Normally it's either complete tokenizer or strings are not processed at all. Anything in-between goes to python/perl or done in C++ anyways and segfaults from time to time. Because even if there is a std::split, then the programmer will obviously use the overload that returns iterators. So, the good std::split needs at least ranges... Something along these lines.
I've been using https://github.com/whoshuu/cpr extensively for client-side networking. It's a work in progress, but I think the API is small, intuitive, and useful. *Disclaimer: I'm the author of this library.*
Sweet
Thanks for the heads up! Incidentally, I think there's a missing text fragment on the website. In particular, notice the blank line after "the following lines:" around this fragment: &gt; When you run AutoMO with a test case, you can find in the output with the following lines: &gt; Then you use the AutoMO option â€œ-o file-./input.txtâ€ to run the next test case. 
VS 2015 has it (and has had the tr2 version since 2008). libstdc++ will ship it in 5.3, and libc++ is aiming for 3.8.
Google LGPL and iOS to see the mayhem involved. 
some time ago I saved this link: https://github.com/fffaraz/awesome-cpp HTH
This was a problem for a long time, but with the latest relaxment of the Xcode policies (you don't need to pay 99$ anymore to upload apps to your phone), I think that you can now legally do so since the problem was that an user could buy an app with LGPL libs and would not be able to change the LGPL part freely on his own device (which would void the LGPL license).
&gt; I'd like a smaller library for basic linear algebra which is not the size of eigen, but would avoid to implement simple dense matrices and multiplication just to get quaternions in every damn project I've been working on. [Blaze](https://bitbucket.org/blaze-lib/blaze). They created this as an implementation of Smart Expression Templates, which usually provide much better performance than pure ETs and it's connected to BLAS, it has internal parallelism. Interface is quite nice and easy to use, in my opinion: better than Eigen. General linear algebra operations, you are not overwhelmed with a lot of stuff for tensors etc.
Initialization is a mess. For list-initialization, another problem is that it _also_ performs aggregate initialization if the target is an aggregate. This means that in a template with parameter `T`, you'd better not do `T clone {x};` to copy the value `x` (if you think that's unlikely compared to `T clone = x;`, the same thing happens in a temporary `T{x}`, a mem-initializer `y{x}`, a new expression `new (pos) T {x}`, etc.) because you don't know if `T` is an aggregate. Aggregate initialization is also a pain in `std::unique_ptr&lt;Agg&gt;(new Agg {...})`, which cannot be rewritten as `std::make_unique&lt;Agg&gt;(...)`. It seems like you're better off only using `{}` initializers when you either want to call an `initializer_list` constructor or want to disallow narrowing.
That's too bad. It'll be ages until these compiler versions are in mainstream-linux distributions out-of-the-box. Most likely they won't make for example Ubuntu 16.04, which means the first LTS that they'll make it into is 18.04, which is only 2.5 years from now! Great!
The GPL is unambiguously incompatible with the app store, but a lot of people consider the LGPL to be compatible, and in practice some juicy lawsuit targets (such as Sparrow, which was bought by Google) have shipped LGPL libraries and provided object files for relinking.
http://en.cppreference.com/w/cpp/experimental/fs http://en.cppreference.com/w/cpp/experimental/optional
Aggregates will use the brace-or-equals-initializer when there aren't enough initialization clauses in 14, if that's what you mean by controlling the defaults. But I agree aggregates look a lot like a trap and I avoid them. You're drawn in by the allure of not writing tedious constructors only to find their lack has made your type a second-class citizen.
Sorry, I stand corrected, I thought it was 17 not 14 for some reason. 
I've taken to using inline defaults for any primitive types, to avoid all this: struct S { int y{}; }; // ... S s; cout &lt;&lt; s.y; // reliably 0 
You are misinformed: The license of the IDE has no influence on the license of the code you develop with it. You are free to develop *anything* with Qt Creator, but you need to follow the GPL/LGPL (or buy a license), if you change the Qt Creator IDE itself. If you use Qt in your project, then you must pick a license that is compatible with the license of the Qt version you are using. If that is LGPL you do not have to release the sources of your application, but you need to release any changes you did to the Qt version used to your users. You must also make sure your users can replace the Qt version your binaries are using with one of their chosing, which makes static linking a inconvenient option. A commercial license is an additional option, which helps to finance Qt development, too. Quite frankly: If you do a commercial application, then you should be able to afford Qt, or your company is in deep trouble:-) Standard disclaimer: I am not a lawyer, get legal counseling by a professional in your country before deciding on licenses. 
Eigen is "Smart Expression Templates" too. And I consider the fact that Eigen does not have external dependencies as an advantage. And performance is very similar in my experience. (If using the same instruction set, the latest version of Eigen does support AVX). The most annoying thing about Eigen is compilation time. 
Doubles are actually fairly widely used in 3d animation software, not just in Cinema 4D. For example if you take a look at Maya's [MTransformationMatrix](http://download.autodesk.com/us/maya/2011help/api/class_m_transformation_matrix.html) class you will see that it is all doubles. 3d animation in film is often doubles. That is the reason this library is written in double precision. As mentioned in the slide deck, a single precision version would be an welcome addition, and hopefully someone will be willing to take a stab at it...
I was aware of this link and the several forks, but it's just a random collection of c++ and *c* libraries that the author found, without any logical connection. I wouldn't even classify them awesome, or modern really. This is exactly the kind of random list I *don't* need. Reading through the list out loud of those I already know, just to prevent other people to consider this list as "valuable advice": Ignoring the initial, pointless, "standards" links at the top, and most of the "frameworks" which are just large collection of mediocre implementations of various utilities. Loki uses the old approach of template meta-programming to achieve what can be done much easily nowdays with regular templates and conceptslite. There's *no point* in Loki today. ROOT is just plain awful, by their own authors admission. It's a framework for *existing* code. STLport is in there? ASIO / libevent / libev / libuv are tangentially incompatible with each other. Of those, only ASIO / libevent are c++ related. When picking between the two, you might constrain your choice in the signal/slot library choice! This is very important when choosing an implementation and it cannot be made lightly! Audio just contains a random list of codec implementations, as for compression, torrent, etc... CLI contains "ncurses"! In the "encryption" section, I might only highlight Botan as a good C++ encryption library which might classify as a good base, but I cannot compare to the mentioned crypto++ that I never used. Libre/OpenSSL are both C and too level. Unless you're implementing a encryption-related tools, as a client you can probably use Botan. GUI contains GTK+, which is implemented on top of gobject! GTKmm wraps an useless object runtime on top of the C++. QT, which is far from being "small" (and encompassing too much for my taste), is a *much* better choice for GUI development. I mean, I could go on, I used/tested maybe 40% of the libraries listed there, and could only recommend a handful just for consideration.
jsoncpp has a decent API, I've used it before, but it's not particularly efficient. I'd rather see comments on "jbson" or "json11" which both are more inclined towards recent standards and similarly trying to build a friendly API. There are several other "fast json" libraries out there, but they frequently cut corners such as invalidating the input stream or putting *very* hard constraints in the input data (I'm looking as "gason"). I wouldn't consider them as "general purpose".
I reply to this, mostly about the Python argument. I have to say that by coming from a C background, I never (and still don't) appreciate the indentation-based python syntax too much. My taste is actually skewed towards the ML family of languages to tell the entire story. But I've been using Python despite its awful performance as my first go-to for a long time now. I've been incredibly productive in Python overall, much to my surprise. And it's not due to Python itself. Python has nothing really special, afterall. Python *is* boring. The object model is clean and small enough, but, if you exclude dynamism (not a small point, mind you), it has *nothing* that I feel is lacking in C++. In fact, I do consider static type checking and templates as a strong argument towards C++ in several classes of programs. I'm *waiting* to get type annotations in the Python runtime. What Python has going for it is a well balanced standard library. It's not as small as the standard C/C++, and not too big either. You won't find a super-high-performance hash library, but the internal dict implementation is actually pretty good, and so on for the rest of the system. It's true that breaking the standard library is bad, and I'm bitten by this by constantly having problems with python 2/3, but I *do* value what has been done in python 2.6/2.7 and now python 3 in making it more uniform and switch to better packages as they became available.
A very good question! This is an analysis of relative performance in terms of cache misses. The total time spent in each case is &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;*T* = *W* + *M* where *W* is actual work and *M* the idle time on cache misses. Let's say we have *n* elements and cache lines download *C* bytes at a time. In AOS, each particle takes 20 bytes (in 32-bit architectures), so we have 20*n* bytes and 20*n*/*C* cache misses. For SOA, each data member (1 byte for color, 4 bytes for x, 4 bytes for y) is handled separately by the cache (i.e., they go to parallel cache lines): this is key, because it means that misses are dominated by the cache line that gets emptied first, i.e. the one devoted to either x or y (they empty exactly at the same time, in fact). So cache misses here are 4*n*/*C*, and &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;*M*(AOS)/*M*(SOA) = 20/4 = 5, which is indeed greater than 3 (the observed speedup). We can further derive (assuming that *W* is the same for AOS and SOA): &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;*T*(AOS)/*T*(SOA) = 3 = (*W* + *M*(AOS))/(*W* + *M*(SOA)) = &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;= (*W*/*M*(AOS) + *M*(AOS)/*M*(AOS))/(*W*/*M*(AOS) + *M*(SOA)/*M*(AOS)) = &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;= (*W*/*M*(AOS) +1)/(*W*/*M*(AOS) + 0.2) ==&gt; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;==&gt; *W*/*M*(AOS) = 0.2, i.e. for AOS the actual working time is 20% of the time spent waiting for the cache, or 16% of the total execution time. By contrast, &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;*W*/*M*(SOA) = 0.2 * 5 = 1, so in SOA we spend the same time working as waiting, that is, working time is 50% of the total execution time.
If someone feels brave enough: parse string at compile-time and generate the state machine for options statically through metaprogramming. :D
Thank you, this is very interesting. &gt; (i.e., they go to parallel cache lines) This is pretty much where my misunderstanding came from. So with your model, it seems like it doesn't matter (as far as *M* is concerned) whether you use the data as long as it's not the limiting factor (in size). Do you obtain similar results if you actually use dx and dy in render()?
I just learned about list initialization and aggregates and I think it's a pretty nice way of creating a flap door for bugs to freely pop up in your program (how hard can you promise the order and amount of members in a class will be always the same, and will never stop being an aggregate?) I understand this syntax for good old arrays, but is there really a good reason to use them anywhere else?
&gt; Do you obtain similar results if you actually use dx and dy in render()? I did a small test with GCC in Coliru; the original example yields render: n;oop;raw 10000;0.0221037;0.00744528 100000;0.0268358;0.0103488 1000000;0.0840979;0.0248579 Then I changed particle::render (*not* OOP plain_particle::render) to void render()const { do_render(get(x())+get(dx()),get(y())+get(dy()),get(color())); } and results are: render: n;oop;raw 10000;0.0202393;0.00753701 100000;0.0263269;0.010373 1000000;0.0667517;0.0251399 which are roughly the same. So, yes, adding dx and dy to the computation does not change things, as the model predicts.
I think I've answered: boost::locale operates only with a constant-length encoding using a string of wide characters. By native UTF8 support I just mean it: algorithms/iterators that work on top of the UTF8 encoding, allowing to avoid transcoding entirely. This is *not* as a petty argument as it may sound: UTF8 is everywhere. You want to be able to handle the input *directly*, and store it just as *efficiently* without intermediate conversions. Also note that converting UTF8 into something fixed like UTF32 is dumb. In UTF, the definition of a character changes depending on what you need to do (either visually or logically). If you're storing an UTF string in a vector providing fixed slots, these slots have *no meaning* half of the time.
No, the OP is not me =). But I am pleased to see such a great user response.
"boost::locale's implementation of X is slow" and "boost::locale doesn't support X" are entirely different claims. As it so happens, boost::locale's break iterators are dogshit slow, but it's not because of the conversion to UTF-16, which is an irrelevant implementation detail. My experience from actually profiling code using them was that the conversion was typically 5-10% of the total runtime. There's a lot of good reasons not to use boost::locale and I've mostly been moving away from it, but they're all implementation quality issues, and not missing or incorrect functionality, and definitely not because it's in any way problematic to use UTF-8 with it.
Increase the precision of the output. The text result of the value is often rounded compared to the _actual_ value.
There is a big difference between how numbers are are represented in memory (this what you are asked) and how they are printed. By default, the iostream library is rounding float and double numbers to 6 significant digits before printing. This is what you see.To see more, you have to set higher output presicion using [std::setprecision(n)](http://en.cppreference.com/w/cpp/io/manip/setprecision) manipulator. And even then, be aware that the internal representation in binary and thus not exactly representable in decimal, so you will see not exactly the same number as stored in memory. PS. Next time please submit such questions to /r/cpp_questions/
If your compiler supports C++11 then you can see an exact representation by using hex floats: http://coliru.stacked-crooked.com/a/c0065996333392d4 0x1.07e6b8p+2 0x1.8fcd6e9ba37b3p+1 And you can convert the hex to binary pretty easily: 0x1.07e6b8p+2 = 100.0001111110011010111000 0x1.8fcd6e9ba37b3p+1 = 11.00011111100110101111101001101110100011011110110011
Thanks for the good work on the video. I am the author of the program. A couple of comments. * I think that the int type for CString is probably a problem with include paths as you suspected. * Right clicking on a class in the class diagram allows choosing many other types of class relationships. * The mostly empty sequence diagrams are also probably related to include paths missing. CLang does not parse the source well if there are too many compile errors. I plan to look at the video in more detail in the future when I have more time. 
Thanks for the feedback :) Where to set the include path then? The settings dialog is little bit unclear here. CString? Its not MFC. Most of those are std::string.
It's all about space efficiency. You store/retrieve strings as dumb buffers most of the time. Even for the worst-case scenario of asian text, what happens nowdays is that you would end-up transcoding from UTF8 to UTF32 just to do the inverse when *displaying* that buffer from the text catalog! An iterator based approach that exposes codepoints on the fly, like utfcpp makes perfect sense. It's *fast*, and would allow to implement additional unicode functionality on top of it with negligible impact. I'm pretty sure, just due to data locality, that it should be *faster* than manipulating UTF32, not slower!
Yes, I've mostly switched to using ICU directly. ICU's break iterator is super expensive to construct, but you can just create one and use it on a whole bunch of strings, while boost::locale's wrapper forces you to create a new one for each string. Most of the other places I've switched to using ICU directly were simply due to that locale's wrapper dragged in parts of ICU that I was not otherwise using, rather than any actual functional problems.
I guess I misheard CString. Under the Analysis/Settings menu on the Build Arguments tab, there is a list of common build arguments. The typical compiler -I switches can be added there. The External Project Packages button is the easiest to use if you are using some standard package to supply the include files. For example, if you are using MinGW-Builds, it is easiest to add them by adding the mingw-w64 selection. Too bad the dialog is unclear. I am not sure what I can do to make it simpler. If you have any ideas, feel free to let me know.
What
You mean, could somebody write this code for you? Why don't you write it yourself? Or you could just find one of the many existing and available ascii art converters, such as [jp2a](https://csl.name/jp2a/).
Is thirty considered old where you live? Two of my friends in college were 26 when they started programming and we had someone who was 35. I don't see age as a problem here. It's always about experience. I would recommend that you build a portfolio on github or bitbucket with a few personal projets, that's a great way to get an edge when you are applying for jobs in the future. You might be admitted to an undergraduate degree at that age based on experience and certificates instead of college courses.
no I was hoping someone already had it
Thanks for your response - I actually have a bachelors in comp sci. I technically have the degree to get a position, but since it's been so long I'll definitely need to work on some personal projects to show my renewed interest in the field. 30 isn't necessarily old, but for someone to jump around in different specialties to then go into an entry level programming position may look indecisive to some employers, I guess.
I agree age is not a problem at all. A lot of students or PhD students are around your age when they finish. Also, you don't look indecisive to me. You were slightly changing between related IT fields, no problem there. Your support experience sounds great, sql, web and unix/win work means you are comfortable with operating a computer and shell and know quite well what you're doing. Working as a supporter means you are a good problem solver - very important as a programmer. Helpdesk means you also have experience interacting with people. Sounds all good to me. Go for it!
For the crime of naming your member variable and your function parameter to the same name (and not even using this to disambiguate), I sentence you to death. Jokes aside, I didn't find it very easy to read your post. Your first motivating example is talking about graphs where you want to disconnect from all the guys pointing to you. Your code doesn't seem to actually solve that use case, at least not in the most natural way. It seems to only do 1-1 connections. It may seem obvious to you or like a little thing, but that was very jarring and the first ten minutes of reading your article it didn't make any sense. I also assumed by the name that it was an owning pointer, and really had trouble understanding what was going on at first, especially since there was so much code (mostly boiler plate). Personally, I'd probably write the post explaining with only key code segments and explain those, and put the full code slice in a file or github somewhere. Just some constructive criticism. The idea itself is pretty neat and I'll file it in my mental toolkit, thanks.
When I had a need to implement this, I did not attempt to make it generic. Instead, I had one specifically be the owner and the other contain the data (but supported detaching), and the constructor for the owning class was in charge of constructing the data class. There's still a bit of cruft, I'm no longer working on that project and nobody left has the skill: https://github.com/themanaworld/tmwa/blob/master/src/net/timer.t.hpp#L129
Normal in Java maybe. Most C++ guides have a specific naming convention that doe not allow a member variable and a function parameter to have the same name. Shadowing is confusing, underscores are no big deal. Granted this is bikeshedding, but this is a point of probably 95% consensus in my experience.
Did you test your statement &gt; The reason why this is so simple is that now I can just have a pointer into something thatâ€™s stored inside of a std::vector. I'm not 100% familiar w/ the implementation of std::vector, but I'd find it a bit silly if during reallocation it calls the copy constructor of each item in the array instead of just doing a memcpy() (which would leave your pointer into the std::vector broken) Beyond that, I can't say I've really run into a situation where this would be useful, but it's really hard to say since I've been avoiding problems this attempts to solve for years. For instance, I wouldn't store a pointer to an object allocated by a vector, I'd just store a vector of pointers.. or store an index value into the vector instead. Cool though, as a guard against the memcpy and any other stuff like that, you could probably store the value of 'this' during consturction and check to make sure that this always points to the same location as when the TwoWay pointer was constructed, and if not, fix up both locations there. Also, this isn't threadsafe and I'm not sure how you'd make it threadsafe.
std::vector has no choice but to call the copy constructor, unless it is basically pod or something like that, which implies (amoung a few other things) no explicit copy constructor has been defined. No hacks like storing this needed
Those solve a different problem
&gt; What's wrong w/ just doing a realloc() `std::vector` does not directly use the C memory allocation functions to acquire/release/manage memory, it uses a C++ allocator. C++ allocators do not support `realloc` or anything similar to it. They allocate and they free, that is all. There are other good reasons why `std::vector` doesn't do this (e.g. it would be UB to do this on a non-empty `std::vector` of non-PODs), but this is the most immediate.
&gt; I'm trying to figure out why this might be illegal or unsafe but can't come up with anything that would be solved by reconstructing all the elements. Think harder then.
I bit the bullet and bought IntelliJ Ultimate, and have not regretted it. I can code in any programming language I want. I think the only language I don't code in with IntelliJ is code, and just because the Sublime plugin is superior to IntelliJ's plugin. 
Looks like Qt's `QPointer` 
It seems like both gcc and clang recent versions (from coliru) warn about this with `-Wshadow`. I've found some interesting reasoning about both cases [here](http://stackoverflow.com/a/268591/1269661). Personally I've never thought about writing constructors with shadowing parameter names, but Resharper generates constructors like that and it surprised me at first but now I see that it actually makes sense.
True, but I don't fully agree. It's good that C++11 finally knows about threads, atomic operations, etc. and offers library implementations that allow everybody to leverage those facilities in platform-independent cross-platform code. However, in my opinion you should still know which platform you're coding for, and what the underlying hardware/memory model is. If you don't know what acquire/release semantics are, or what a strong/weak memory model is, you can of course still go ahead and use C++11 atomic operations with their default arguments (sequential consistency!) everywhere. Do note that this incurs a full memory barrier for each atomic operation though, so your lock-free code might end up being slower than equivalent code using critical sections (or other user-space primitives). 
Would it be too much to ask for a simple explanation? Reading through all the templated code is painful.
Are you an EU citizen ? If so, Switzerland has a big med-tech companies ecosystem and you are allowed to apply for jobs. The salaries are usually very good, except in startups. Be careful though that the cost of life is also very high especially in Geneva and Zurich. We use C++ in many places. The common place to search for a job in Switzerland is www.jobup.ch. 
Phillips healthcare too uses c++ in most areas. They have nuclear medicine division and also their ultrasound division has some cancer related stuff like mammography etc.
I don't understand the purpose of this. Intrusive or non-intrusive, there's no need to include boost serialization headers in your class header to support serialization. You only need to write the serialize function, which is a template function with no non-template parameter dependent types (other than your class itself), so no need to include anything anywhere except where the serialization is initiated from. A fourth way to use boost serialization? class MyClass { private: template&lt;class Archive&gt; friend void serialize(Archive &amp; ar, MyClass&amp; m, const unsigned int version); int v; }; template&lt;class Archive&gt; void serialize(Archive &amp; ar, MyClass&amp; m, const unsigned int version) { ar &amp; m.v; }
So, thanks for your feedback, with those macros this is now generated by boost preprocessor: #define SERIALIZE(Type) template&lt;class Archive&gt;friend void serialize(Archive&amp; ar, Type &amp;t, const unsigned int ); #define ELEMENT(TE) TE #define ELEMENT_MACRO(r, data, i, elem) ar &amp; t. ELEMENT(elem); #define FRIEND_ELEMENT(...) BOOST_PP_SEQ_FOR_EACH_I(ELEMENT_MACRO, _, BOOST_PP_VARIADIC_TO_SEQ(__VA_ARGS__)) #define SERIALIZE_IMPL(Type,...) template&lt;class Archive&gt;void serialize(Archive&amp; ar, Type &amp;t, const unsigned int ){ FRIEND_ELEMENT(__VA_ARGS__)} #define SERIALIZE_DERIVED_IMPL(Type,Base,...) template&lt;class Archive&gt;void serialize(Archive&amp; ar, Type &amp;t, const unsigned int ){ar &amp; boost::serialization::base_object&lt;Base&gt;(t); FRIEND_ELEMENT(__VA_ARGS__);} But for derived types, you still have to include something from serialization. But this code gets rid of fusion &amp; the tuple middle man. Edit: tricky formatting on reddit...
Oh gosh these Rust fanatics &gt;.&lt;, we all know C++ is the devil and Rust will save us from Hell, any C++ developer with enough years of development knows the goods and bads of C/C++, no need to recall us every week that C++ is not the safest language on earth.
yes, but its intrusive. Thats what I like in my original solution, that it keeps all serialization code in one file.
Out of curiosity, why does that matter to you? Why not just have it in the header with the class?
&gt; If the compiler is clever enough though, it can take advantage of the fact this is actually `constexpr` and only evaluate it once. No it can not: [constexpr counter](http://b.atch.se/posts/constexpr-counter/).
My understanding of shadowing is that it occurs at the point of declaration, not the point of use. Shadowing occurs whether or not the shadowed name is referenced. 
 aMap[0] = aMap.size(); There is nothing indicating to the compiler that one side of this needs to be evaluated before the other. What would the rule be? "Prioritize the side with non-const operations"? ++n = n + 1; ++n = n++; Things can get crazy pretty fast.
Sorry for that. But there are just a couple of qmake projects. Compiler tested with is recent clang++ with libc++. Someday I'll make an instruction. Currently it is hard to me due to my poor knowledge of English.
Please explain, what do you mean?
It's about the sequence points. There are none in-between, so it's UB.
With C++14 constexpr, I don't believe that this is a significant issue for users. You just write a loop and you're done. It is, however, an issue for implementers - the LWG is currently dealing with the fact that char_traits would like its member functions to be constexpr, but they want to call things like strcmp(), which exists because it can be written in ultrafast assembler.
Like Newtonian mechanics and the Bohr model, sequence points are still a reasonable way to understand the basic behavior. C++11's "sequenced before" matters for multithreading, weird singlethreaded scenarios, and velocities close to the speed of light. (In this case, there are "sequence points" due to the function calls, so you're right that it's unspecified, not undefined.)
In most cases, it probably isn't, but take a look how flexible D's CTFE is -- they can compile [html page templates](http://vibed.org/) or [regexes](http://dlang.org/phobos/std_regex.html#.ctRegex). I wish C++ had that (and `if(__ctfe)`).
Don't take this the wrong way, but I also don't like having to declare vars and methods as const for example. Still, I do. They are language features that have their uses. Friend is the same. 
In general there isn't a speed difference between C and C++, so that isn't a different question.
Though I understand why people write these articles, I am baffled by why they get posted in the C++ reddit. No one is using Rust. It is probably great, but we won't know for sure until people start to use it. Even if it is 100 faster than C++, it is still useless to me until a significant number of people start to use it. It is not hard to make a better language. Most programming languages in common use suck (from an academic perspective) because they have had to make compromises to be useful. There are tons of good research languages. The hard part is not making a good language, it is doing all the things needed to get a user base for that language.
Actually, if you have two unsequenced operations where the side effects of one operation determine the result of the other (or both have side effects that affect the same object) then you end up with undefined behavior. Strictly speaking, the compiler doesn't have to be reasonable.
The parameter names aren't in scope outside the parentheses though, which is why this "trick" works. 
You might be right, I can see the text, but I fail to comprehend it. Here's N4527: &gt; When calling a function (whether or not the function is inline), every value computation and side effect associated with any argument expression, or with the postfix expression designating the called function, is sequenced before execution of every expression or statement in the body of the called function. [ Note: Value computations and side effects associated with different argument expressions are unsequenced. â€”end note ] Every evaluation in the calling function (including other function calls) that is not otherwise specifically sequenced before or after the execution of the body of the called function is indeterminately sequenced with respect to the execution of the called function. ^9 &gt; 9) In other words, function executions do not interleave with each other. From what I can understand, `aMap.operator[](0)` and `aMap.size()` are _indeterminately sequenced_ and that means that both operate on an object that doesn't have any unsequenced side-effects. I might be totally wrong though.
Is __builtin_log (supported by GCC/clang) usable in constexpr context? That seems like a simpler way to achieve it with faster compile-time performance while retaining compiler optimizations at runtime as well as having good accuracy.
&gt; yet pulling in another boost header in most of my core classes isn't benefiting my compile time or IDE Like I mentioned earlier, it's not necessary to include any boost headers to support serialization. The docs recommend it in a few places, but it's optional. For example, the base class thing you mentioned is effectively a checked dereference and cast from this* to base&amp;, so it's not actually necessary. &gt; I try to keep the serialization code central, I don't want it to be scattered around the application everywhere. It makes working on this code and refactoring it much easier. Most of my classes use the macros below now. I understand the concept of wanting to centralize things; sometimes it's a really good way to un-clutter the code. But, what is the difference between writing out the macro in the class or writing out the serialize function? They seem to be about the same amount of code. Considering that they seems to be the same size, and assuming it's not necessary to drag in any headers, a huge benefit to leaving it as a plain serialize function is that it's possible to debug it; you can't step through the macro.
Did not know declaring a "= default" move constructor didn't produce any errors when members are non-movable. That's disappointing.
I like n = n+++++n 
It's just a habit. Handy IDE. What is your advice?
Well, I prefer the macro approach, which will generate the correct code and is less noisy. I am able now to define the SERIALIZE_IMPL macro in the cpp file of the serializer, so that changes to this will only recompile the cpp file of the actual serialization code. Not every other header including my base types. And I don't see a need to debug this code, as its always doing the same thing. Also it would be trivial to replace the macro in this case.
Look at it as a challenge.
Each function call has a sequence point on exit and entry (using C++03 terminology), so regardless of which function is chosen to execute first, there are still at least two sequence points in between the writes in question.
After seeing dozens or even hundreds of projects without or with really bad documentation I beg to differ, it's not a challenge it's a bore. It's also a reason to not spend more than 10 seconds on such a project. Which is a shame, some of them are probably really quite nice. I just don't agree with expecting dozens or even hundreds of people to sift through the code in order to find out what exactly the thing does, and more importantly whether it satisfies their needs, rather than having one person spending some time on at least some introductory documentation.
This is some\_lvalue = map.size(), and that is unspecified in the standard or I'll eat my sock :-).
im so sorry about the formatting it seems to have copy and pasted quite badly 
Yeah, I should really start with writing my application some of these days. Any tipps?
No, they don't. Because they don't define which side will be evaluated first.
But they do define that one of the sides will be evaluated fully before the other. The standard calls such ordering "indeterminately sequenced". Look up, I even pasted relevant standardese above.
Don't care about that. There are no sequence points that guarantee the order of the sides. So, we have problems that are highlighted in the blogpost. Why add more confusion with unrelated obvious stuff like "the functions don't crash because they are evaluated fully"? If you remove functions on both sides, there will be the same situation.
This depends on your operating system and compiler. One great thing about moving from windows 7 to windows 8 was seeing one of my applications use a few gigabytes less of memory with the exact same binary. If you are accessing something inside a vector, the OS should only be storing one copy of it and everything else is just a reference to it until it needs to be modified. In theory it's a neat idea, but not one that should have much of effect in real world applications. I agree with the others on the use of std::shared_ptr as well. If you're worried about objects of significant size being deleted then use a vector or list of shared pointers. If you're using this with ints or floats, then your object size is on the order of the size of the pointer itself. If you want to know whether the object was already deleted, use a weak_ptr instead and use the expired() function before accessing the data.
It's used a couple of ways in C++. Regular inheritance is a way to eliminate code re-use through the use of base classes that hold common behavior. Virtual inheritance is more along the lines (usually) of abstracting away implementation details while maintaining a common API. Once you start adding things like templates and patterns like [CRTP](https://en.wikipedia.org/wiki/Curiously_recurring_template_pattern), it starts being abused more as a means of implementing certain trickery. But yes, at it's heart it's a way of defining a "core" set of functionality that can later be extended. You might be interested in the [expression problem](https://en.wikipedia.org/wiki/Expression_problem) which is what C++ is trying to implement. Using classes makes it easy to add new types, but hard to add new functions on those types. If you're interested in formal aspects, you can look at [subtyping](https://en.wikipedia.org/wiki/Subtyping). As that's what C++ is trying to implement, though it doesn't really give you any theoretical guarantees w.r.t. things like substitutability. 
The key is that some languages will eventually have a problem come along that the language is especially good at solving, or some other change that makes the language particularly attractive. At that point the language might get some serious traction. So the original VB was a huge hit because people wanted to make windows programs and in the early days windows programming was brutally hard. This was also combined with the huge number of "missing" applications that needed to be built where VB was good enough. As database driven websites became a new boom, PHP was nearly the perfect tool at the time for all the people who were more looking to push their HTML harder than to really become programmers. Then there are forced situations like where Apple required that people learn Objective-C in order to program for the iOS family. They are doing it again with Swift. If instead it was Blackberry who had chosen Objective-C or created swift for their platform but released it for desktop as well, it is doubtful that many people would have bothered learning either. But to have a language that is better in certain general categories become popular without serious support is very very rare. 
Quick tip: paste the code and then highlight it and hit the &lt;&gt; button in the toolbar. I assume that's there for people who don't use RES.
&gt;To me this sentence expresses that Inheritance in programming is a shorter way of creating a clone of a class with a few changes. Is that all it is? Well, sort of. In principle that's what it does, but in practice it also means that the compiler can assume that both classes will behave interchangeably in certain ways, allowing you to write code that works no matter which type of object you happen to give it. In other words, we get to reuse not only much of the classes' own internal code, but also much of the other code that deals with the classes.
The idea is probably OK but signal/slot implementation is just for the demo I hope. signal/slot as a paradigm is quite dangerous as it may create infinite loops on the graph. Very hard to deal with especially when graph gets changed in runtime and uses async/posted events. There is an alternative to it - bubbling/sinking events used in HTML DOM. Events generated on some object bubble up on child-container chain. Thus they do not require any additional structures and links other than existing container/children (windows - sub-windows, etc). 
Two more comments, * the link to the complexity article is my mistake and will be fixed in the next version. It is listed as .shtml, and should be .html. * The statistics that show in the browser are output in XML in the output directory and displayed in the browser using XSLT. Once again, thanks for making the video. 
board[0] to board[size] are of type int*. That is, they are pointers to ints. Each one, in that loop, is set to point to the first element of some new array (a different one for each iteration) of ints. So for example, if size = 3, we could have board pointing to memory location 42. At that location, if you read 3 int*s in a row (that is, three blocks of memory of the size of a pointer-to-int), you would find 3 values, say for example 123, 456, and 789. These are memory locations. At each location in memory, you will find an array of 3 elements. So at location 123 in memory you might find (if you read 3 ints in a row) the numbers 1337, 31337, and 313373. At location 456 you might find three others, and three others at location 789 as well.
The following... int **board = new int*[size]; ...creates an array of `int` pointers, each element pointing to nothing: board -&gt; [0] -&gt; ? [1] -&gt; ? [2] -&gt; ? . . . [size-1] -&gt; ? Then... for (int i = 0; i &lt; size; ++i) { board[i] = new int[size]; } ...creates an array of `int` values for each `board` element: board -&gt; [0] -&gt; [0][1][2]...[size-1] [1] -&gt; [0][1][2]...[size-1] [2] -&gt; [0][1][2]...[size-1] . . . [size-1] -&gt; [0][1][2]...[size-1] 
It looks like someone is learning C++ as taught by a C coder. This is one version of what STL means by using a vector of vectors (keeping close to the original code for understandability): std::vector&lt;std::vector&lt;int&gt;&gt; board(size); for (int i = 0; i &lt; size; ++i) { board[i] = std::vector(size); } There are quite a few other ways of writing it, with various plusses and minuses.
You should know that in many (if not most) cases a 1D vector is preferable to a vector of vectors, such that each row is stored sequentially in the vector. The vector index is then equal to: rowIndex * size + colIndex ...since you defined size to be equal to both length and width of the "board".
Or he could use a ``std::array``.
Yes I am, thanks for the link I'll take a look at that
I can't as I'm on my phone, but I would suggest checking with valgrind and if you're using mingwgcc turning on all the optional checks, see [this file](https://github.com/Dekken/maiken/blob/master/mkn.xml) at the bottom. I recommend using the .hpp naming convention for c++ headers, so you can tell them apart from c headers easily Maybe try cppcheck
For understanding this code, you should find answers for the following questions. After that you get deep understanding, what is going on in this code and you'll become better developer. 1. What is a memory? 2. What is virtual memory? 3. What is virtual address space? 4. What is virtual address? 5. What is a pointer? 6. What is a call stack? 7. What is a dynamic memory allocation? 8. What is a heap? (not a data structure in this case) 9. What is a variable? 10. How computer stores variables in memory? 11. How computer stores arrays in memory? 12. What is the difference between int and pointer to int? 13. What is the difference between array and pointer? 14. What is pointer to pointer to int? 15. What is pointer to pointer to pointer to int? 16. How to store multidimensional arrays in memory? (find at least 2 ways) (optional) 17. What is Standard Template Library? 18. What is std::vector and std::array? 19. Why you should avoid using raw arrays in C++?
Thank you for your detailed help! - I have moved ans inside the function. - I changed vector&lt;node*&gt; to &lt;node&gt; - Will fix the input validation part soon However, don't I need getGridDeep() to copy each value in order for it to be a deep copy? I need each node object to hold its own unique grid. or is there a better way? Also, i am trying to make it const Node&amp;, however, any "n" objects that appear in that function give the error "passing const Node as 'this' argument of 'bool Node::isSolved()' discards qualifiers" However, just Node&amp; works
&gt;However, don't I need getGridDeep() to copy each value in order for it to be a deep copy? I need each node object to hold its own unique grid. or is there a better way? The node constructor already copies the grid, so you don't need to do it twice. &gt;Also, i am trying to make it const Node&amp;, however, any "n" objects that appear in that function give the error "passing const Node as 'this' argument of 'bool Node::isSolved()' discards qualifiers" However, just Node&amp; works Ah, this is because the functions aren't marked `const`. Any member function of a class which doesn't modify the class's member variables should have `const` on the end of the function (after the parameter list). This allows it to be called on const instances of the class or const references: class Node { public: Node(int*); void printNode() const; bool isSolved() const; inline void setGridVal(int r, int c, int new_val){ grid[r][c] = new_val; }; std::vector&lt;Node&gt; getCandidates() const; protected: private: int grid[9][9]; bool solved; cell getMostConstrainedCell() const; int getNumPossibilitiesForCell(int r, int c) const; std::set&lt;int&gt; getPossibilitiesForCell(int r, int c) const; }; Generally you want to pass anything that's not a primitive type (int, float, char, pointer, etc) as a `const&amp;` whenever possible to avoid unnecessary copies. You can always make an explicit copy inside the function if you need to.
This isn't a code critique, but if you're not using version control (which it seems like you're not) it would be a good idea to invest some time in it. You can then host your code either publicly or privately on sites like [GitHub](https://github.com/), [BitBucket](https://bitbucket.org/) or [GitLab](https://about.gitlab.com/) (the last two offer free private repositories). Sharing code publicly via one of these services gives you a auditable history of the changes you've made over time and is a much better platform for code reviews.
Note that in your vector-of-vectors type: std::vector&lt;std::vector&lt;int&gt;&gt; The &gt;&gt; will get interpreted as the right-shift operator. Adding a space will get you what you want: std::vector&lt; std::vector&lt;int&gt; &gt;
You're right. I haven't looked carefully enough... Sadly the OP deleted his sample code and perhaps some of his explanations â˜¹
to let people know such thing exists and still is being updated?
Actually this was fixed in C++11, and all modern compilers interpret it as a double-template-close instead.
Unfortunately, it's necessary to bind away the optional argument (Wt::WMouseEvent) of a clicked() event handler.
I suppose this is why I'm slowly getting more and more dissatisfied with c++. Some undefined behavior I understand. But this seems unnecessary. I understand that the order of evaluation is not fully defined in order to allow different systems to implement it in a way that is efficient for them. But it doesn't seem worth the cost. Frankly I bet the implementers spend enough time working out what they need to implement exactly that if they were able to spend that time implementing a might tightly defined spec they could be as efficient!
Ah, nice! We'll update the syntax.
There are [C++ release notes](http://www.webtoolkit.eu/wt/doc/reference/html/Releasenotes.html) and [Java releases notes](http://www.webtoolkit.eu/jwt/latest/doc/javadoc/index.html) that list just that, mentioned within the blog post.
&gt; Tool::Tool(Tool &amp;&amp;) noexcept = default; Holy shit. I would never have even considered trying this syntax...
So, Scott Meyers won't be presenting anything at CPPCon. That's disappointing, he is an incredible speaker.
The well-known bug :) You can use PVS-Studio for detect this issue: http://www.viva64.com/en/d/0349/
That makes it very clear, much appreciated, thank you. 
Thank you for the reply, definitely helps. 
So essentially a faux 2d array then right? 
Pointers are like the first lesson in my class lol
I'm going to answer all these later tonight, definitely going to give me a better foundation for my class so thank you 
I think C++ should introduce a new keyword BEHAVIOR_IS_DEFINED, with this keyword everything has a defined behavior for the compiler and developer, it may cause some performance loss, but get a predictable world. Isn't it good?
As for why the `initializer_list` deduction is happening, I always thought that the possibility to iterate over a small fixed-size "inline" array was a motivating example: for (int prime : {2,3,5,7,11,13,17,19}) { â€¦ } At least it's an example I've seen before which relies on this deduction rule.
a website that cannot be read without javascript .. fuck it, cant be that important .. 
As of VS 2015, yes.
Here's a project I had fun with a while back: [Universal Machine (ICFP programming contest 2006)](http://fileformats.archiveteam.org/wiki/Universal_Machine_(ICFP_programming_contest_2006\)). Basically you write a super simple virtual machine to run programs according to the provided spec. It's great because once you have the working virtual machine the contest has provided a program to run on it that is basically a little text based operating system with puzzles and things. You can make more creative use of basic text input/output. For example, someone wrote an [ASCII art fluid dynamics](http://www.youtube.com/watch?v=QMYfkOtYYlg) simulator. Writing a fluid dynamics simulation might be a bit advanced, but you can simulate all kinds of things and display animated visual output with ASCII art. [Conway's game of life](http://en.wikipedia.org/wiki/Conway's_Game_of_Life), for example, is one common project that's pretty approachable for a beginner. You can use text based output to draw normal images, using an external program to display them. The [PPM image format](http://en.wikipedia.org/wiki/Netpbm_format#PPM_example) is simple to output and, for example, is the output image format of the [business card ray tracer](http://fabiensanglard.net/rayTracing_back_of_business_card/index.php). A program to generate a ppm image of the [Mandelbrot set](http://en.wikipedia.org/wiki/Mandelbrot_set) is a good place to start. Another use of text based IO is the [Common Gateway Interface](http://en.wikipedia.org/wiki/Common_Gateway_Interface). Web servers use this to interface with another program running on the server to create dynamic web pages. The web server starts up a program to handle a user request and the program writes its output to the standard output (e.g. std::cout) in the HTTP format, and the web server sends that to back to the browser. To do this you'll install a free web server and then configure it to run your program via CGI. You can even use the built-in input/output facilities to generate audio. A few simple math functions can be used to calculate raw PCM audio samples of simple sound waves. You can save them to a file to play using an external program, or you could pipe that output directly to /dev/audio if you're working on platform that provides that, or you can use a program like Audacity which can read and play raw, headerless audio files. If you're not satisfied with the built-in input and output facilities then there are also lots of C++ libraries that provide additional options. One I've heard about as a good option is [Cinder](http://libcinder.org).
I wouldn't really call almost 60 pages "brief". Also, I think that the ideas behind Rust are interesting, but the syntax just looks so hard to read at times. I wish that they had been willing to make it a bit more "C/C++" like.
I disagree, I think the guy is on point. This belongs more in /r/programming than it does in the subreddit devoted *specifically* to C++. Rust and C++ don't have a close relationship, other than Rust trying really hard to be a C++ replacement.
from the OP link http://www.aristeia.com/videos.html
I 100% agree with ltce, I wrote something similar just a couple of days ago. FWIW I think occasional articles comparing the two, or discussing Rust from a C++ dev's perspective are fine. It's just a matter of degree. You wouldn't see such a harsh reaction if this hadn't been going on non-stop for months. If an article had been posted about python bindings to C++, I'm sure the reaction wouldn't be like this. It's because people are not trying to ram python into this reddit all the time. It's bad in comments too. You're discussing the best way to do something or some performance vs safety trade-off, and someone invariable comes in and explains how much better Rust does it. Again, fine in moderation, not fine in excess.
Being explicit about exception specification is nice. It's pretty pedantic, but ultimately it's a good thing. I draw the line though at declaring a function you plan to default in the header, and defining in the .cpp file. I don't see any benefit at all. If it's going to be defaulted, write it that way in the header file. If you later need to write it by hand then you... change the header file! Seriously, in C++ it's already a fact of life that you have to change header files to change implementation details in many cases. This just isn't a big deal. It's easier to read the source when trivial functions are simply defined inline; you can mentally check off that function because you know that it has an empty body, or it's just a trivial getter returning a const ref, etc. You know there's no magic in that function. Edit: Just to clarify, this is orthogonal to the issue of exception specification. You can write: Tool(Tool &amp;&amp;) noexcept = default; inline in the .h file, works just fine.
&gt; given the close relationship Rust and C++ have I think I threw up in my mouth a little...
TiddlyWiki!
All though Qt is not "modern c++" for me it was a "gateway drug" into the world of c++. Create some small tool for your personal use and then evolve form there. Take a look at the Qt documentation and start creating small GUI applications such as a music player or web browser.
Try to make a subreddit less hostile and get completely annihilated by downvotes... I am not saying we should turn into /r/rust, but this kind of hostility is bad for the C++ community. Imagine you were in a C++ club and a guy came in and said something about rust. Would you start throwing stones at him? Or would you instead kindly point him to the rust club down the street? /u/gnzlbg didn't come here to proselytize, he (or she) didn't post a link to a news article about the relationship between Finland and ISIS and its economic impact, he just posted a link to some website talking about rust. There is no need to be mean.
That does rely on the deduction rule, but it would have been just as easy to create a special rule for braced initializers that applied only to range-based for loops. Such a rule is what makes it possible to iterate over arrays. 
I'm seeing a guy wearing shades and a cap EDIT: Oooh, it's Brett Hall
We are presenting DoxyPress at CPPCon in two weeks. We we return we will add a Git repo. Thanks for being patient. 
Hopefully the Rust evangelism is going to level off at some point? THe marketing effort thus far has been truly staggering...
Enable floating point exceptions. Of course it doesn't work for GPU code, but it's extremely convenient when working on CPU code.
I didn't even know of floating point exceptions, thanks. Oh and the gpu code is the worst. All the fragments randomly going black -_-
Definition of move constructor can still be placed in .h file with inline keyword: inline Tool::Tool(Tool &amp;&amp;) noexcept = default; BTW, I think it's very bad that defaulting member function inside class definition doesn't perform this check. You will need to add comments about this difference to every place you use such declaration. Otherwise another programmer who is unaware of such difference will eventually 'simplify' your code by moving =default into class definition.
I think this is a perfectly good way for the reasons you said, but only if this "initialization" isn't supposed to set the values to a legal initial value, which is the whole point of an initialization after all. Setting memory to ~0 helps you with finding cases where you access uninitialized memory, but a) there are tools for that and b) you have to assign a legal value to the memory at some point in your program before using the value, which in some sense makes the memset a superfluous operation (only useful for debugging). Usually you would use memset to some meaningful initial value. E.g. if you want to sum up values in a histogram you want the buckets to start with value 0 as the initial sum. 
Either seems like a bit of a crutch compared to using proper sanitizers, like valgrind, clangs/gccs canary values, mudflaps or somesuch. I never really felt the need to apply this technique to anything, personally. That being said, I suppose you could alternative between setting them to 0 and 1 each run, or somesuch? That way, if either triggers an easily detectable/traceable error, you will eventually observe that behaviour, and if the program reacts in some way weirdly every other time you run it, you have a starting point to figure out what's wrong (e.g. by starting to bisect which PODs are getting set to 0 and which are getting set to 1 on this iteration)
This might just be me and if so you should ignore this but I get kind of skeptical nudge when downloads send me via SourceForge these days. (ex. the Ad-loaded installers, and the GIMP code seizure with the excuse "it was an abandoned project")
You seem to be assuming that data be uninitialized will be a major difference between programs that work and it shouldn't be. Just use a vector&lt;type&gt; and initialize it to a sensible default (probably 0). This shouldn't really be a major hurdle in whatever you are doing.
For anyone interested, there's also [Boost.DI](https://github.com/krzysztof-jusiak/di) (not yet a Boost library). Curiously, it actually does support constructor injection. Unfortunately, I haven't had the time to figure out how. The only real idea I have is that it would keep a list of bound types and try all permutations of them (using SFINAE) to get a set of what compiles, then choose the best one. Here are some relevant examples of its capabilities: (I assume the aggregate comes from trying `T{...}` in addition to `T(...)`. Or braces are always used, but you have to consider list constructors.) Simple Constructor Injection -- struct c { c(int a, double d) : a(a), d(d) { } int a = 0; double d = 0.0; }; auto injector = di::make_injector( di::bind&lt;int&gt;.to(42) , di::bind&lt;double&gt;.to(87.0) ); auto object = injector.create&lt;c&gt;(); assert(42 == object.a); assert(87.0 == object.d); Aggregate Injection -- struct c { int a = 0; double d = 0.0; }; auto injector = di::make_injector( di::bind&lt;int&gt;.to(42) , di::bind&lt;double&gt;.to(87.0) ); auto object = injector.create&lt;c&gt;(); assert(42 == object.a); assert(87.0 == object.d);
Well, the compiler could just emit the code and throw it out, which would trigger the error as you want. But it would hurt compile times. It would be nice if it was a flag. Templates are a bit different. With templates everything is decided at point of use. Even if you have a template class, for a given template parameter some methods may be valid, some not, and that's fine.
`std_lib_facilities.h` is a header that's used like a set of training wheels to gradually introduce the language. The early exercises use it, the later ones don't. It's not something that you implement, you are meant to [download it from the book's website](http://www.stroustrup.com/Programming/). 
I think I'm starting to understand why. People who use C#, Java, python, etc, have no interest in Rust. Their languages are fast enough for their application, they don't need manual memory management. Rust is lots of complexity to no gain. C people wouldn't be expected to have much interest in Rust either. They want to be close to the metal, and avoid complexity. A language where you need a special block just to use a raw pointer probably isn't very appealing. Rust will need to grow at the expense of a language community that is willing to deal with complexity, and has extreme performance needs. C++, and maybe Objective C, are the only major candidates. Hence the non-stop evangelism into C++.
The memset values are supposed to bring foo into a stage where accessing it's value will most likely cause wrong but consistent behavior. I think in case of the for loop I would prefer count to be 0xFFFFFFFF (in case it is unsigned) and override all accessible memory until the program crashes
Find a program you use regularly and start fixing bugs.
I admit I have never really been able to understand what DI is good for. The coffee example in Boost.DI would IMO be much better written void brew(iheater&amp; heater, ipump&amp; pump) { heater.on(); pump.pump(); clog &lt;&lt; "coffee!" &lt;&lt; endl; heater.off(); } Can someone give a non-artificial example?
Finally got around to checking this out. That's truly impressive! Thanks a lot for the link.
Hm, seems better and less confusing to achieve the same with unit testing indeed. Thanks for feedback, seems I don't need to change my workflow except actually writing unit tests. Started to get into the habit of writing as many sensible ones I can and they exposed so many subtle bugs its was not even funny :)
Why wouldn't you simply pass a parameter depending on which you want to use?
&gt; Obviously if you are using nullptr and what not, this is irrelevant. How so? nullptr is still converted to 0 when converted to pointer types.
* Right, it's just the declaration/assignment distinction. * There is one. I imagine not using it here is either didactic or stylistic (same for not using `mem::swap`). * Blocks are expressions; their value is the value of the last expression in them, just like most everything-is-an-expression languages, like eg. Lisp. This is one of things I like about Rust. In C++, if I need to use a block for eg. a mem-initializer, I have to write and immediately call a lambda expression.
The best advice in my opinion? Learn to know the language and its paradigms inside out before contributing [meaningful amounts of] code to open source projects. Many of these projects need some amount of quality improvement, so hold off with contributing until you are sure you can deliver that.
fair do's, but, let's consider your example for a sec, you still have to create header and pump, don't you? auto heater = make_unique&lt;Heater&gt;(electricity, ...);// etc. auto pump = make_unique&lt;Pump&gt;(electricity, ...);// etc. notice, that exactly here DI becomes handy, to avoid this boilerplate code, imagine changing dependencies order or adding another dependency to the constructor of heater/pump, DI will take care of it, so you don't have to brew(*heater, *pump);
Sorry, could we be concrete? I still don't get it. I'm imagining the difference between - data_access_layer(postgres); + data_access_layer(nosql); and auto injector = di::make_injector( - di::bind&lt;db_type&gt;.to(postgres) + di::bind&lt;db_type&gt;.to(nosql) );
Even in C using memset to zero a POD is an anachronism. Use value-initialization[1] instead. I also agree with posters who say that special values are a crutch. [1] http://ideone.com/57PG2A
Maybe a different example would help... with an application component (class) that has the following dependencies: * http_client * storage_layer * stats * logging * auth each of those deps would be an interface - a pure virtual class, for example. You'd then accept those parameters in the constructor as usual - so far, pretty standard: my_component(http_client &amp;, storage_layer &amp;, stats &amp;, logging &amp;, auth &amp;) { ... } One thing DI gives you is the ability to bind the concrete implementations to those interfaces - libfruit, for example: fruit::createComponent() .bind&lt;stats, statsd&gt;() .bind&lt;logging, boost_log&gt;() .bind&lt;storage_layer, postgresql&gt;(); Once you've done this, any component which lists one of those dependencies in the constructor will be passed the relevant instance: the injector will take care of instantiating that as part of dependency resolution. It passes the resulting storage_layer instance to any component which needs it - this means you don't need calls like this: my_component(http_client_impl, storage_layer_impl, stats_impl, logging_impl, auth_impl); because the DI framework will instantiate my_component for you. So, each component declares its dependencies, and as long as a concrete implementation exists for each of those dependencies, you can add/remove deps from those components without needing to change constructor invocation. You could now modify the constructor definition to this: my_component(auth &amp;, stats &amp;, http_client &amp;, storage_layer &amp;, logging &amp;) { ... } or my_component(http_client &amp;, storage_layer &amp;) { ... } without changing other code. DI tends to encourage code separation between interfaces and implementations - it's not the only way to do it, of course, but it does make it quite easy to do that by default. This obviously has advantages when it comes to compile times and testing - easy to swap in a mock implementation at injection time. I find it helps with modular design - from the start you're composing interfaces rather than implementations, in a way you could think of the injector as a central registry for features that various components can use without worrying about how the feature is provided or what order things need to be initialised in. There's much more to it than this - partial resolution for components, for example (resolve some of the dependencies now, but defer others until later), or multi-binding (more than one instance of the given interface, e.g. plugin support or logging to file and console) but the tutorials for one of the DI frameworks should hopefully cover it in more detail.
Do you have an itch? Then scratch it. Is there some open source program you use with a bug that annoys you, or a feature you wish it had? Make it so. Don't be surprised when you patch isn't immediately accepted though. Reviewing patches does take a certain amount of work, and the people running the project may have a different idea about what's a bug, or what features they want, or how to name a variable. So you may have to do some back and forth to get your chances acceptable and make anybody happy. If what you're doing is a significant amount of work, make sure you communicate with the project first to make sure your work isn't being duplicated by someone else and your changes are likely to be accepted. Some projects have a list of "easy" bugs. So look into those. But make sure whatever you're doing keeps you motivated.
There will most likely be a standard version of something close to `unpack` in C++17, called [apply](http://en.cppreference.com/w/cpp/experimental/apply): auto check_equal = [](auto x, auto y) { return x == y; }; assert(std::experimental::apply(check_equal, std::make_tuple(1, 1))); Not that this detracts from the blog post any.
Not OP, but link?
https://github.com/OSSIA/i-score (Grep for TODO / OPTIMIZEME 's in the code, there are some that are simple file rename and other a bit more involved.)
Awesome! Thanks. I'm a CS student looking for something to learn from outside of school. 
It's janky. You initialize with 0 because it's faster. And in general many structs are properly initialized this way because 0 is a valid number and a good starting number. Values should be properly initialized. With real values. Your structs should never be used without being properly initialized. You shouldn't have to look at the various values to determine whether something is initialized. It should be implied by it being in use. The benefit to memset 0 is that at least it is a reasonable initialization. But honestly memset 0 isn't great unless 0 is properly initialized. Relying on these values in your code to detect bad behavior is janky. If you need them there is a problem and your code doesn't work and/or you don't understand it. If you need magic values while debugging use proper magic values like 0xDEADBEEF that are only used in debug and debugging. 
I would only do this 2 stage thing in debug. Otherwise I would just leave it as uninitialized memory until you properly initialize it.
Others have already given the 0xDEADBEEF/etc. answer, which some compilers do automatically for heal-allocated objects (but generally not for stack-allocated objects like foo in your example.) However, the best software engineering answer is the one C++ has provided for 25+ years precisely to eliminate the 2-step initialization problem: don't declare variables until you're ready to initialize them, and use constructors. If foo is a struct then give it a constructor that sets its values. If foo is an array then make it an std::vector and initialize it with an initializer list. Or better yet make foo a class that takes arguments and fully initializes itself. If foo itself is "plain old data" then memset makes no sense - initialize it with "foo = 7". There are always exceptional cases where you can't do this, like creating a complex cyclic graph data structure where nodes can point to each other, and you can't fully initialize data up front, but in practice incomplete initialization should be the exception rather than the rule. 
A few years ago, sourceforge is what everyone used. There's still quite a few using it. (They've gotten kind of a black eye lately though due to taking over projects that left and adding ads to their installers, or something along those lines) [gitlab](https://about.gitlab.com/) is the similar to github, but it's opensource. Not as many projects are using it, but since you can install it on premises, a lot of companies use it internally. There's also http://savannah.gnu.org/ and https://launchpad.net/ I think you're approaching it from the wrong direction though. You should pick a project you already use, and then go where ever they are hosted.
When you're on Windows (and most other systems a far I know) all the memory you get from the OS will be 0. This is because otherwise you could read private data from some other program that used it before. In debug mode, special patterns are used by your compiler to indicate specific types of memory. In release mode, they're just passed along though (and are still zero once you get them). This does not mean that all the memory you get when using "new" or "malloc" will be 0 however. The heap management is implemented in user space and part of your runtime. If you call new, then delete, then new again you might get the same chunk of memory (or you may not), as it's never returned back to the system in between those calls. One reason for this: On Windows you can only get memory in 64k chunks, all the finer allocations (and possibly any sized allocations) are handled by your own heap.
`std::memset(&amp;foo, 0, sizeof(foo));` is a poor idea in the first place. For a structure, `foo = {};` is less error-prone, more readable, easier, possibly faster, and most importantly, *correct* if `foo` contains members where all-bits-zero isn't valid initialization. For an array, use `std::fill( std::begin(foo), std::end(foo), Foo{} );`, which has all the same benefits I just listed. You could put it in a function template that deduces the array size and type, to keep your code tidy. &gt;Like prematurely going into a branch where we read from our POD instances before we have initialized our types with real data. Avoid this by using initializers at the point of creation. E.g. `Foo foo{};` . 
Very interesting article. How does the `FIT_STATIC_LAMBDA_FUNCTION` macro work? Could occurrences of it be replaced by functions taking `auto` arguments in C++17?
What no one has mentioned is that doing your memset (with any value) will break any kind of sanitizer or tool (e.g. valgrind) you run to find uninitialized memory access. That is because as far as they are concerned you have initialized this memory. I would recommend to not do this. Additionally, there are performance implications to doing this. In one library where I had done this to be extra safe (because I was in C) I had been using calloc. Switching to malloc gave an enormous speed boost; not only is the CPU not wasting writing data to memory you'll never touch, you're not putting pressure on the CPU cache. Also, in response to people claiming that the compiler will 0-memory for you or that you're guaranteed zeroed pages on Windows, that's not correct. Any pages that you get from an OS are zeroed to protect against leakage between processes. However, in a longer-running processes typical malloc implementations will not go out to the OS for every allocation &amp; instead keep some pool for every thread. So while initially you may see pages with all 0s, over time your application data will leak into them. This will be true of every modern OS I can think of that cares about performance &amp; security even a little. TLDR: memset &amp; not using constructors properly for POD are a giant maintenance nightmare. We have a huge codebase that regularly suffers bugs due to having these POD c structs that don't have initializers.
Richard!? Richard!!? Is that you?!?!!??!
&gt; I'm not really familiar with them. Looks like they're by the Jira people. Do they have public projects? I didn't see a way to explore them from that link. BitBucket's a lot better for private repositories/mirrors, if you ask me.
To everyone's benefit, he did a [blog post](http://pfultz2.com/blog/2014/09/02/static-lambda/) on that macro :) One comment I'll make on functions vs. functors (including lambdas) is that functors tend to be more useful. Consider the following example, with parameter qualifications simplified: auto less(auto x, auto y) {return x &lt; y;} auto less2 = [](auto x, auto y) {return x &lt; y;}; Now you want to use this as a comparator: algorithm(begin(...), end(...), less); //compiler: "Which less did you want?" algorithm(begin(...), end(...), less2); //compiler: "Ah, I'll figure out which operator() to use." Note that it's somewhat likely that we'll be getting `constexpr` lambdas soon. Those would be a good thing to compare to this macro.
Are you asking about the difference between DI and a DI container? Injecting a dependency is all about the caller passing the dependency to your code via the constructor or a parameter (or sometimes a setter, but I don't like to talk about that), rather than your code accessing a global or getting it from some instance. It is highly related to "tell, don't ask", "the Hollywood principle", etc, and is a type of inversion of control. Your example is injecting `iheater` and `ipump` instances into `brew` (and taking a dependency on a global, `clog`). A dependency injection container builds on the above and just automates the construction of objects with the correct parameters. If your project would benefit from a centralized (and hopefully easy to edit) configuration of your core objects, or your objects have a lot of cross-references with each other, it might be worth considering whether a DI container would help. When done well, you just need to specify in a declarative way the configuration you want for your system, and then request whatever object you need, and the container makes sure that it has all the correct dependencies with the lifetimes you specified. You never need a DI container, but DI is nearly always beneficial. Frankly, the name is far too fancy for what it really is, and people look for something unusual and new on first hearing about it (I certainly did), when the reality is they are already actually familiar with it. But I do think the name is good since, for long term maintenance, you do want to be thinking about the dependencies your code is taking and how to make your code changeable over time without slowing down future development.
Yeah bitbucket and gitlab are great. I like the unlimited free private repos from gitlab. There's an import from github feature which I just used yesterday. Also hosting on your own server is handy
At the moment, I use GitHub as my main platform, and have my main repositories set to automatically upload to GitHub and GitLab at the same time. That way, I have mirrors. I use BitBucket for private projects. Didn't realize GitLab had unlimited private repos on the main sight. That's good to know. I originally wanted to run GitLab on my Raspberry Pi, but I couldn't get it running properly. Probably would be slow anyway. I've considered just doing a direct SSH upload for my repos, though.
&gt; Very interesting article. How does the FIT_STATIC_LAMBDA_FUNCTION macro work? It initializes a function object. These two previous blog posts explain it in more detail: [Static Lambdas: Initializing lambdas at compile time](http://pfultz2.com/blog/2014/09/02/static-lambda/) [C++: Uniquely addressed](http://pfultz2.com/blog/2015/05/31/unique-address/) &gt; Could occurrences of it be replaced by functions taking auto arguments in C++17? Not exactly. First, you can easily pass a function object to another function, like this: FIT_STATIC_LAMBDA_FUNCTION(plus) = [](auto x, auto y) { return x+y; }; std::accumulate(v.begin(), v.end(), 0, plus); If it were defined using C++17 `auto` arguments, then you would need to use `FIT_LIFT` to pass it to another function: auto plus(auto x, auto y) { return x+y; }; std::accumulate(v.begin(), v.end(), 0, FIT_LIFT(plus)); Which makes using lambdas more expressive, especially when combine with function adaptors. 
As part of the posts about Concepts Lite I was working on, I found many bugs on the GCC implementation, but I wasn't sure about submitting them to bugzilla before tracking them properly. For this purpose, I developed a way to host Concepts Lite examples on github and test them against a continuous integration system with a GCC built pointing to the Concepts Lite TS support commit. I will be happy if people playing with concepts lite help me with their own snippets. Both to help with bug tracking, and to build a sandbox where people could look for CL examples.
I agree with what the others say about the windows heap setting allocated memory to 0. When a pod type is on the stack however, you are correct. You will see whatever crap was left there by previous function calls.
&gt; Also, in response to people claiming that the compiler will 0-memory for you or that you're guaranteed zeroed pages on Windows, that's not correct. Any pages that you get from an OS are zeroed to protect against leakage between processes. However, in a longer-running processes typical malloc implementations will not go out to the OS for every allocation &amp; instead keep some pool for every thread. So while initially you may see pages with all 0s, over time your application data will leak into them. This will be true of every modern OS I can think of that cares about performance &amp; security even a little. Hm. Testing that out with some simple code: int main() { constexpr auto sz = 256 * 256 * 256; auto p = new int[sz]; for(size_t i = 0; i &lt; 1000000; i++) { *p = 0xBA; delete[] p; // Also tried dynamic sizing â€” same result // sz = 256*256*16 + (rand()*4 + rand()*2 + rand()); p = new int[sz]; if(*p != 0) { cerr &lt;&lt; "*p = " &lt;&lt; *p; abort(); } } return 0; } It seems for low sizes (sz ~= 256\*256), the memory is just garbage. However, getting a memory block like 256\*256\*256 seems to always get initialized to 0 (abort is never called).
 Just clicked around your repo to see how you write your Qt/C++ and this line[1] seems suspect to me. .toLatin1() returns a temporary,then you take a pointer to something inside this temporary object and the temporary object gets deleted at the end of the line causing "basename" to point to an object that no longer exists. [1] https://github.com/OSSIA/i-score/blob/ee7e841533e053cb86cdbbc41a0c24dbf2601275/base/lib/core/application/Application.cpp#L27
Qt's currently stuck with VS2012 due to Windows EC 2013 not coming with a newer compiler, do you know if there might be any plans to update the compiler there?
I don't know anything about that, sorry.
I would prefer just to use the `defer_lock` way because: * You still get RAII unlocking. * If I have too many mutexes being locked at the same time, there probably should be fewer of them. * If they really do need to be separate mutexes, chances are I can unlock them separately.
Let us repeat the mantra of the GPU programmer: "There is no debugger, but printf"
I make use of the `struct { enum }` alternative, only also couple with Wikibook's "[typesafe enum](https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms/Type_Safe_Enum)". Even when working in C++11 (since otherwise there's some semantic changes that are hard to plan for and respect, such as the use of `underlying_type`). I even incorporated it into my own libraries.
It's a multiple-mutex lock guard. You get RAII unlocking.
This code is reminding me a lot about a course I had 2 years ago (basic programming.) The teacher did not teach STL at all, any use of STL and strings was immediate fail on any assignment. And now that we have C++14.. such a waste. And he also insisted to use 1-N. OP may be in his class.
I'll just say that the standard way to get contiguous memory is to use a vector of the right size. Of course there are other options along with placement new. But there is never any reason to use new in modern c++.
Really? 1 to N? So you had the subtract one off every access?
I don't really follow your comment. A vector is a way to get one dynamic array, with one type, with contiguous memory. It does not by itself solve how to get multiple dynamic arrays of different types, all in one block of storage.
Nice post. I've got a similar problem in some of my own code (an offline renderer) which I've been meaning to address. Looking forward to the next part!
Consider using [std::aligned_storage](http://en.cppreference.com/w/cpp/types/aligned_storage) rather than `new char` .
Thanks, hopefully the code in the next part is appealing. It will need to be more complex which is unfortunate but hopefully it's a worthwhile tradeoff. 
Can you elaborate? If what you're suggesting is to create a single large object on the heap to hold the data rather than a char array, than this will not work as it would require the sizes of the arrays to be known at compile time.
I'm not sure what counts as a clear intro from your perspective (I'm not being snarky). I did say exactly where the code was from, and that it was being used to motivate the discussion. I tried to be careful when writing the post not to be negative and to stay away from directly criticizing, and just focus on providing some technical discussion of C++. What would have made it clearer? If I had moved a couple of the sentences from the paragraph after the code block, to before? That is, to say something like: the code that follows was presented as a solution for joint allocation, but it has some issues...
&gt; That is, to say something like: the code that follows was presented as a solution for joint allocation, but it has some issues... Yeah that would be good. This is just my preference of course, you're free to write what you want.
Your code *does* allocate a single large object on the heap. I'm suggesting replacing `new char[N]` with `std::aligned_storage`. But it's probably not necessary since `new char` does guarantee max alignment anyway.
I think you forgot your morning coffee.
Except that the way this link does it is not at all applicable with the way mutexes are supposed to be used. Using separate deferred `lock_guard`s and then using `std::lock` lets you unlock them as soon as possible, which is the single most important thing you can do with a mutext.
There's a non-owning array wrapper proposed for C++17, called array_view. Beautifully it also allows arbitrary multidimensional views of the underlying memory, which may put an end to people manually calculating y*sizex+x and occasionally screwing it up (especially in higher dimensions).
No, that would make sense. 0 was never used and the array was defined as N+1
Some architectures have special instructions to set a register to zero, but that doesn't help at all when setting a block of memory to zero. It isn't any faster.
That's unfortunate. I chaired [a session](https://wiki.qt.io/Qt_contributors_summit_2015_Program#Qt_and_Modern_C.2B.2B_-_the_future_is_now.2C_how_can_we_make_use_of_the_new_stuff.3F) at the Qt Contributors' Summit this year about how we could start to adopt newer C++ features, and we're really being held back only by Windows EC. The features we can't use are central to modern C++ - alias templates, initializer lists, variadic templates, member initializers... It's very frustrating. I was excited when I found [this](http://blogs.msdn.com/b/visualstudio/archive/2014/03/31/windows-embedded-compact-2013-now-available-for-visual-studio-2013.aspx) blog post, but upon further study I realized that it is about using the older compiler with the newer IDE, which was not self-evident to me from the post.
Well, the first suggestion is: add the document.
Because, unsigned for such things has been widely acknowledged as a mistake, and not one that I feel obligated to repeat. The problem with int is that it's 32 bits even on 64 bit systems, so not always big enough. Anyhow, if it bothers you or someone else, I'm sure you can change it before using it. I hope this isn't your main take away, which integer is being used. 
Well yeah, if you pre-allocate and just assign a pointer, that's going to be faster than a run-time allocation.
Larger pages get returned to the kernel. The kernel likely doesn't have any kind of optimization to give back pages to processes that freed them. Instead it just moves freeds pages to the "to zero" list. Of course there's absolutely no guarantee of this behaviour. * EDIT: Also, this experiment relies on a particular malloc implementation. There are many in the wild.
Right. In my code I use custom stack, fixed-sized free, and buddy allocators. I was commenting more on the guy's surprise that a pool of pre-allocated blocks would outperform run-time allocations.
It says [here](http://www.microsoft.com/windowsembedded/en-us/windows-embedded-compact-2013.aspx) it supports VS2013 now.
See my other comment, that's only about the IDE itself, not the compiler or the standard library.
AFAIK it doesn't support switching between row major / col major order so... it's actually only going to be useful if you want to store/access the data in the order it supports. I wish this kind of functionality would go through a Boost peer-review before getting submitted into the standard. It's basically standardizing something that we have almost zero practical experience using (even tho it comes from C++AMP). 
Hi, I've tried Gradle for C++ in several projects and for now it doesn't fit to my project requirements, so at the end I came back to Autotools or Meson. But we have to say that: * Gradle native is **incubating project** (https://docs.gradle.org/current/userguide/nativeBinaries.html) so of course CMake is more mature. * Gradle is slower, but clearer. What do you want for your development team? * You can use generators, you can call to whatever generation tool from Gradle. In fact one of the things I don't like from Gradle is that you can do too many things. * Why do you say this tutorial (http://carlosvin.github.io/en/posts/gradle-cpp.html) is obsolete? It works with gradle 2.7 (lastest). Have you even try it? It is at github and you can write a remark or create a defect or improve it yourself. If you just say *it is obsolete* nobody will improve it. BTW: I made this tutorial, but I have no relationship with Gradle team. As abstract: Gradle for my C++ projects, not for now , but I think it is really promising build software. P.S: Take a look to Biicode (https://www.biicode.com/), it is based on CMake with a powerful dependency management system. 
&gt; I've been looking to get to use a memory pool library recently. Your memory library seems rather big for such a purpose, whereas this one is tiny. Why is there the need for so much more code in yours? Half of the header file linked contains boilerplate necessary to use the class inside STL containers and the like. The class itself also more generic: there are multiple implementations of free lists available for the user to choose one. This leads to the linked class which just takes a given free lists and combines it with my helper class `detail::block_list`, which takes care of the memory block allocation when the list is exhausted. One actual implementation is `detail::free_memory_list` here: https://github.com/foonathan/memory/blob/master/include/foonathan/memory/detail/free_list.hpp#L17-L175 https://github.com/foonathan/memory/blob/master/src/detail/free_list.cpp#L21-L261 This has a similar size than the other pool implementation. In addition, my memory pool supports array allocations and debugging helpers. This adds more complexity to the implementation. The linked (as in: URL linked, not doubly linked) free list implementation has only rudimentary support via a cache, but still. tl:dr: The actual free list implementation is only a little bit more complex due to the array support. The rest is boilerplate for generic use. Edit: If you meant the whole library, not just the implementation: My library provides way more. It defines a whole new allocator concept, a `RawAllocator` with related traits, a wrapper for `Allocator` and `Deleter`, there are other allocator classes defined and many useful adapters, like an `allocator_reference` or a `tracked_allocator`.
Thank you for your reply! To be completely honest with you (feel free to downvote...), this was 21 days ago, I haven't touched Grade since, and I have no idea anymore why I found your tutorial to be outdated. But I watched that talk, read a lot about Grade on their homepage, googled a bit, tried it on a couple files, and came to that conclusion. (Part might have been because it doesn't include generators, while Gradle seems to possibly support them now, but I'm not sure.) Anyway, thanks again for your reply, and I hope Gradle will get there in the future :-)
&gt;compiler optimizations â€œoffâ€œ Maybe that's the reason? It's not entirely clear how he compiled the code, but I see no reason of testing this without `-O2`. What's interesting here is release-timing, not a debug build.
Why do you separate allocation and construction for the pool, but not for the stack? Your stack "allocation" is basically free, all it has to to is increase the stack pointer. All that time you measured is construction, not allocation. Also if I'm reading this code correctly, stack and heap tests always zero out the array beforehand (see: call the constructor), while your pool test uses whatever is sitting in the pool. Initially they will be zeroed out, since you just duplicate your heap creation there. But after continued use, you will start reusing old objects. For your pool implementation to be *correct* it should call the constructor as well, using placement new as /u/Fiennes suggested. There is no need to construct the objects at all in your pool allocation.
I could be confusing with another memory, but I think Sutter said "we were young", which was amusing. 
There are better pool implementations as well. A simple free list would give `O(1)` allocation/deallocation and `O(1)` storage overhead.
 Sure, that's more or less malloc in a nutshell. Ideally if you are making a custom pool like this, you'd do all the heap allocation in one call to reduce overhead and fragmentation, but OP naively does one `new` call for each object.
I think we agree. There are issues with methodology and the implementations. Sixteen bytes of overhead per chunk and an `O(n)` allocation/deallocation would essentially be unusable in a production setting.
Except that you have individual control over the guards.
just update the readme.md to contain some usage examples - the unit tests dont actually demonstrate anything
Both very cool and certainly in the correct direction. Imgui is amazing built and installed the test app and it was well under a meg. I don't think that I have ever installed an app to the iPhone so very small. But the look and feel aren't flexible, and the text input isn't very usable. Thus this is close but no cigar. nanovg didn't work very well.
I'm looking at OP's code right now, `reset()` is a no-op. So it's a bug either way. Making users duplicate construction/destruction in another function is terrible design anyways.
Hey, thanks ! We are still working on perf issue since asio timers are not as precise as needed but we hope to get through it ASAP. If you want to contribute, feel free :)
If you are using the Microsoft compilers, the debug builds will return malloc'd memory with various useful values. For example 0xCC, in which case, if you try and execute data, it will automatically drop into the debugger (0xCC is INT03). Also 0xDD on free. There are various other values depending on where the memory is allocated from (windows heap, etc). Of course, it doesn't do any of this in a release build. There has been a lot of thought put into these various code, so (badly) re-inventing the wheel is not recommended. http://www.docsultant.com/site2/articles/debug_codes.html
The timings were for 1000 1MiB objects, so that's roughly 100us per construction which is about what you would expect. The problem (one of) is that the comparisons aren't comparable (pre-construction vs. construction).
Sometimes you can use an empty struct for such purposes. struct void_type {};
I only know of two issues with unsigned: - the lack of overflow detection; a signed type gives you a slightly better shot at detecting overflow in the index (if you bother with bounds checking). - computation: if I remove 5 and add 3, this might underflow more than if I add 3 and remove 5; only an issue when underflow/overflow checking occurs. Are there any other?
I recently found served and have been meaning to try it out so I cannot speak to how good it is but perhaps it's what you are looking for https://github.com/datasift/served it's from datasift, and they have some pretty high performance requirements, so I trust they did at least something right, and it uses boost asio which I think is evented the way you want. 
Have you thought about making a generic version? Today, the fact that `Mesh` requires a copy constructor is slightly annoying. I believe however that the issue could be solved relatively easily by moving on to a fully contained class (and possibly hand over some handles externally). The other advantage of a fully contained class is the possibility to handle constructors/destructors. The basic interface I am thinking of is: template &lt;typename... T&gt; class ContiguousStorage { typedef std::tuple&lt;ArrayView&lt;T&gt;...&gt; Members; public: template &lt;size_t N&gt; auto get() const -&gt; decltype(std::template get&lt;N&gt;(this-&gt;members)) { return std::template get&lt;N&gt;(this-&gt;members); } private: std::unique_ptr&lt;char[]&gt; memory; Members members; }; // class ContiguousStorage Because the storage class now knows exactly which memory zone contains which type it can be extended to handle construction, copy construction, copy assignment and destruction. Then in the Mesh class, usage is much simplified: class Mesh { typedef ContiguousStorage&lt;Vector3, int, Vector2&gt; Storage; public: private: ArrayView&lt;Vector3&gt; positions() { return storage.get&lt;0&gt;(); } ArrayView&lt;int&gt; indices() { return storage.get&lt;1&gt;(); } ArrayView&lt;Vector2&gt; uvs() { return storage.get&lt;2&gt;(); } Storage storage; }; and more importantly, if another class also needs some contiguous storage you do not need to worry again about construction, copy construction, copy assignment and destruction; it's all handled once and for all.
This is, of course, the standard solution - but it has costs and potential issues. First off, even if you always spell it `void_type`, it's not a standard spelling in the sense I mean. e.g. once it's in a namespace or a class, it's a different `void_type` to all the other `void_type`s in other libraries. So long as it's an internal implementation detail, not something that clients of your library see, that's fine. But if there's ever a reason for clients to use that `void_type` - when two different libraries have their own `void_type`, and a third library uses both the lack of a standard spelling starts to get awkward. That's part of the reason we have standard libraries - common interface conventions. The reason we can pass `string` instances between different libraries is because they're all using the same `string` class, etc etc. Also, referring back to my issue 1, as soon as you instance this type it's not a zero cost abstraction. The run-time cost is the space taken up by the instances, which is non-zero. At present, neither C nor C++ allows any zero-sized types AFAIK. The reason is in order to ensure that pointers "behave themselves" - e.g. if `val1` and `val2` are distinct objects we know that `&amp;val1 != &amp;val2`. A standard spelling would require (at least) that class in the standard library. Spelling a value of that type as `void_value ()` would work. But to get a zero-sized `void_type` would require a language change - and would certainly throw a spanner into the works of pre-existing assumptions, meaning there would be a cost/benefit trade-off and something IMO worth some thought. Actually, I've been wondering of `void_type []` would really need to banned as well as `void_type *` for a zero-sized `void_type`. A zero-sized array of zero-sized elements isn't in itself problematic. If there's no `void_type*` for the array to decay to, that's awkward in terms of existing idioms - you'd have to pass the arrays as arrays rather than pointers. In any case using `sizeof` to determine the size of an array would result in division by zero. But if all you needed was to have the array and to be able to subscript it (keeping track of the size some other way), it could work in theory. 
I won't hash out the technical issues here, but if you do a search on the cpp reddit you'll find several posts where I do hash them out. And there's plenty of material by people smarter than me explaining the issues. 
Today I'd use either proxygen, grpc or lwan (don't know if this one is production ready). Also: self promotion: I've developed a simple one that runs in actual production too: http://github.com/daedric/httpp (I left the company since then but I was told that it can relatively easily achieve 100K qps with their rtb workflow).
I wasn't aware of the empty base optimization - I knew the size rules for inheritance, but didn't know the name and hadn't made a connection to this zero-size component issue. I just looked up [this explanation](http://stackoverflow.com/a/2826753/180247), which is clear enough. You also reference [boost::compressed_pair](http://www.boost.org/doc/libs/1_58_0/libs/utility/doc/html/compressed_pair.html). That's interesting. Like so many things in C++ template metaprogramming, it's a bit obscure and arguably an abuse of the rules. The natural way to get a type with two member fields is to literally define a `struct` or `class` with the relevant two members. Using (potentially multiple) inheritance to get the effect of a struct, but with potentially-zero-sized components, is awkward. In addition... 1. Not all types can be inherited from - this isn't just about the empty case but also the non-empty case. I can see workarounds, of course, but that's a bit more awkwardness. 2. If two/more bases are actually the same type, it's even more awkward to selectively access each of them - you can work around not having unique member names by first casting the derived class pointer type to the appropriate base type, but not if the base types are the same anyway. Again, I can see workarounds, but workarounds aren't ideal. I haven't looked up how this affects `std::tuple`, and I didn't know it could have keep zero-sized components zero-sized, though now it seems fairly obvious that it could - and access to components is positional (rather than by-type or by-name) anyway, so (2) above isn't an issue. Of course criticisms of the underlying mechanism aren't relevant when they're wrapped inside `std::tuple` anyway, so this clearly a good solution. 
std::nullptr_t as a "null type"? No one is going to use this type as a real template argument from what I can see, so should be safe. Or use a void_type as already suggested.
Actually, in the standard library the empty class situation is very common. Allocators (in every container), predicates (in ordered containers), hash functions (in unordered containers), deleters (in smart pointers) all are commonly empty. Good implementation would employ EBO to avoid wasting space. As of tuple, yes, its interface allows to employ EBO. It depends on the implementation if it actually does. GCC's `libstdc++` and clang's libc++ do it, but I am not sure about Microsoft. The easiest way to employ EBO in your own classes is to pack a potentially-empty member into a `compressed_pair` together with a non-empty member, so you don't have to deal with inheritance yourself. For example, `libc++` uses `compressed_pair` trick internally https://github.com/llvm-mirror/libcxx/search?utf8=%E2%9C%93&amp;q=__compressed_pair&amp;type=Code Upd: And libstdc++ uses just an `std::tuple` internally in their `std::unique_ptr` https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/include/bits/unique_ptr.h#L133
No, I haven't. Thanks for link. I work with Qt and I've wanted to implement something that not very bulk as Qt's signal/slot mechanism and I though what this one maybe will be useful for community. I've compared only with signals of boost library.
Does it force me to use FastCGI?
Interesting again. It's not a zero-size solution `sizeof(std::nullptr_t)` seems to be equal to `sizeof(void*)` as I'd expect because, despite not being a pointer type, it's obviously closely related to pointer types. Although `struct void_type {};` isn't a zero-size solution either, g++ 4.8.4 (compiling for 64-bit) has `sizeof(void_type) == 4` for that `void_type`, but `sideof(std::nullptr_t) == 8`, and I'm not even sure why that `void_type` can't be a single byte. A type that's implicitly casts to any pointer types by design could mask errors where that's not the intent, but that's probably not a real problem. 
The article only discusses lookup speed. std::map does have better insertion/deletion complexity (logN) than sorted arrays (linear time to insert/delete).
All these thread unsafe implementations are next to useless. The crazy thing is that they justify the lack of safety as a *performance* reason.
&gt; The thing about map is that if all you need is fast insert/delete/access, it gets beat by an unordered_map I don't get where is the surprise in that. `unordered_map` lookup and insertion are both O(1), vs O(logn) for `map` and a sorted `vector` (for lookup). `map` is only worth if you need the elements to be sorted. Maybe `map` should have been unordered by default, and something like `ordered_map` should have been used for ordered maps, but it is too late for that.
Remember that unordered is expected O(1), worst case O(N). This leads to hash denial-of-service attacks, which the ordered containers are utterly immune to. So be careful about using hash containers in things like server applications. (Yes, you can try to create resistant hashes, but it's hard and attackers can try to exploit them anyways.)
include is #include, and you don't include "namespace" end1 is endl you do not ask the user "what is the sum", you calculate it no need to set values for your variables, will be overwritten by user input #include &lt;iostream&gt; using namespace std; int main() { float num1; float num2; float num3; // enter num1 cout &lt;&lt; "please enter num1" &lt;&lt; endl; cin &gt;&gt; num1; //enter num2 cout &lt;&lt; "please enter num2" &lt;&lt; endl; cin &gt;&gt; num2; //enter num 3 cout &lt;&lt; "please enter num3" &lt;&lt; endl; cin &gt;&gt; num3; // find sum of num1+num3 float sum = num1 + num3; cout &lt;&lt; "n1 + n3 is " &lt;&lt; sum &lt;&lt; endl; //find diffrence of num2-num3 float difference = num2-num3; cout &lt;&lt; "the diffrence n2 - n3 is " &lt;&lt; difference &lt;&lt;endl; return 0; } 
I don't remember hearing about another series of hash DOS attacks on servers since the big one that led to lot of scripting languages change their default string hash, so I'd say it isn't that bad. How much of a PITA it is to change hash implementation in C++ codebase is a different problem and mostly in the C++ hash designs.
 class signal&lt;R(Args...)&gt; Never seen that syntax before ... does it have a name I can google to read more about?
Compared to a BST, a sorted vector has faster lookups for 2 reasons, 1) it has optimal balance, a red black tree's height is up to 2x worse than the implicit tree represented by a sorted vector. 2) a sorted vector is more cache efficient _in the last N lookups_. It's only when a sorted vector binary search is narrowed to about a cache line that it has any cache benefits. The truth is that sorted vectors and BSTs are _both_ cache inefficient. If you benchmark a B-Tree implementation vs a sorted vector with a small key you will find that it has both faster lookups and faster inserts compared to a sorted vector. If the key is large then a sorted vector will only be faster due to the superior balance, but large keys are rare.
it's just [partial template specialization](http://en.cppreference.com/w/cpp/language/partial_specialization) in this case
This isn't thread-safe at all.
Maybe, it'll be useful - [polymorphic function object wrapper (proposal)](http://open-std.org/jtc1/sc22/wg21/docs/papers/2002/n1402.html) .
Its fine, as long as you don't mind undefined behaviour ;-) (From the draft standard, (17.6.4.2.1)) "The behavior of a C++ program is undefined if it adds declarations or definitions to namespace std or to a namespace within namespace std unless otherwise specified."
If you can, get second edition PPP. Otherwise I would probably still recommend PPP, but not so strongly.
To flesh out user 18f191519dbd805a2d87's point. The message "The symbol 'operator delete' is not located in a source code file' indicates that the specific delete under being navigated to is not defined in source code, in other words is provided by the compiler. However, it is possible to overload operators new and delete, with member functions with the following signatures: void *operator new(size_t size); void *operator new[](size_t size); void operator delete(void*); void operator delete[](void*); In these cases, choosing "Go To Definition" will go the user-defined operator. I hadn't noticed this before, and am really pleased to hear it has been added to VS2015.
Ok, I left in std namespace only is_placeholder, thanks.
Yeah, I can get an ebook version of it but the physical copy is very expensive. Is it worth buying? I have picked up a few Nth edition books in the past and been frustrated that there is hardly any new content, at least not enough to justify the price when I own the older edition. 
I always recommend the Primer, as I prefer their didactic style, but that is just my personal preference. Both are good books. If you cannot get the updated PPP, prefer the Primer, because you will have a much easier time if you learn C++11 from the start. 
Sounds like either a bad hash generator or a bad comparison implementation. The comparison operation should have at least as many conditionals as the hash map has hashed elements. The hash shouldn't be more complex than some multiplications and additions, which are fast and easy to execute in parallel.
That's a slanted question if I've ever seen one. Why would you ask this question if you're so inclined to think Golang is better? What leads you to this question?
When you have a GC you have an indeterministic overhead. It is your call. You should bench and graph performances on long run with variation in the qps.
It was the msvc 2012 standard hash for uint64_t if I recall correctly.
nah. I was very sceptical of everyone who said that the only way you could learn c++ was from books. I was sure that you'd get a decent idea from online tute's. But the fact is, that you NEED to do a few hundred pages of reading to get it. None of the online easy-fix sites do that. At best, they seem to teach a mashup of mostly C with some nods to C++ thrown in just to make it look legit. don't waste your time. Get a book. 
From what I remember, there was talk of a new special type in there. 
Thank you! This was actually a very easy-to-understand explanation! The examples were super useful.
Your argument assumes that you are talking about doing a single lookup on a completely cold cache data structure. Usually you don't necessarily fully evict the structure between accesses. If you make that assumption, a sorted vector is always more cache efficient because more of it fits into cache. A BST of doubles is triple the size of an array of doubles. Furthermore, each time you read a double from an array, you get the next 7 into cache "for free", since a cache line is 64 bytes. With a BST, you read a node which is 24 bytes, and then the next 40 bytes of random junk into cache. To top it off, there are similar issues with pages that were mentioned in the original. I think that by similar reasoning, you tend to see fewer page faults with sorted vectors. Err, what do you mean by a small key? The tests performed in the article used a double as the key. That's a pretty small key. Do you have any benchmarks to back your faster lookup claim? (nobody is denying that a tree has faster inserts for large amounts of data).
This was a double post. Appologies.
shorter code=better code
1. http://en.cppreference.com/w/cpp/numeric/random 2. remove pointers. Use std containers and iterators. 6. Yes, see my comment below. Think, not write. You want to be a programmer, not a secretary. 7. You used vector in wrong way. Initialization, etc. Check other comments. DO NOT use raw pointers! 8. There is a type named Cat and an object cat: Cat cat; cat.move().meow().run(); We call this "method" chaining. For using this you have to return a ref for the object in every non-static void member functions.
1. Which is more expressive (especially for newbie): find(arr.begin(), arr.end(), 18) or find(arr, 18)? 2. shorter, does not pollute with defines 3. There is a good reddit thread about this struct topic in this subreddit. 4. Sorry, there was a missing 'void': nont-static void member functions. 
&gt; For #1, what else should I use? The STL has stuff for random numbers: http://en.cppreference.com/w/cpp/numeric/random &gt; For #2, how do I use those with pointers? Say you have an array like this: int numbers[SIZE]; To use it with find you can do this: std::find(&amp;numbers[0], &amp;numbers[0]+SIZE, n) But using a standard container (like vector) with iterators is the recommended way to go here. &gt; \#6 They are identical for all intends and purposes. However members of structs are by default public, while members of classes are by default private. However, it is common courtesy to write public or private regardless, to avoid any possible confusion. &gt; \# 7 It probably became faster because the memory wasnt cleaned up, which saves time (but also leaves memory lieing around)... &gt; \# 8 He wants you to declare your functions with the return type `Board&amp;` and instead of returning the result of a computation always write `return *this`. But this is not needed here and I think in fact bad advice.
I think you may be confusing the terms [BST](https://en.wikipedia.org/wiki/Binary_search_tree) and [B-Tree](https://en.wikipedia.org/wiki/B-tree). I should have been more clear in my post.
swapIfGood(rnd_col, wrst_col).updateAllCollisions();
&gt; In main.cpp: You write `Board b=Board(input)`. I would replace this with `Board b(input)`. It does the same thing but not everybody knows why. (It might be especially confusing since you dont define operator= for your Board class) I have a couple concerns. The former way of writing it does not actually do the same thing as the latter way. The former constructs a temporary Board object and then uses the copy-constructor for `b`. The latter way, while actually constructing `b` in place, is [potentially ambiguous](https://en.wikipedia.org/wiki/Most_vexing_parse) and error prone because `Board(input);` will compile, but probably not do what you want, especially not when it looks more like this: `std::lock_guard(some_mutex);`. So my recommendation would actually be to change nothing. Your compiler can probably elide the copy-constructor. Its also worth pointing out that neither way invokes `operator=`. EDIT: As i just found out `auto guard = std::lock_guard&lt;std::mutex&gt;(m);` should not compile, so my point about the default way being error prone is wrong. 
&gt; Which is more expressive (especially for newbie): find(arr.begin(), arr.end(), 18) or find(arr, 18)? The second version is not range based though. Plus it requires getting boost which can also be challenging for a newbie. &gt; shorter, does not pollute with defines I see your point. But /u/acwaters says its slower and less portable. So Im still not convinced either way. &gt; There is a good reddit thread about this struct topic in this subreddit. Ill have to look for it. &gt; nont-static void member functions. I can see how that could make sense.
Oh cool, I had not extrapolated from the wording that it is what you had in mind; I'll stay tuned :D
Cool stuff, thanks for providing this, I'll definitely look at your code in more detail when I have a moment.
Don't use chaining unless the method obviously indicates that it's going to return its owner. Chaining just makes for long lines of unclear code.
I've done both; they're both perfectly workable. The "http baked into the language" is a bit of a red herring. While the base http in Go is definitely a nice-to-have, it's not too hard to implement and it's also baked into some perfectly good C++ frameworks. There's a higher learning curve for C++, not because it's inherently harder, rather because "build a minimal web app" is pretty much the "todo list" first demo Go walks you through. Having done that once I can spin up a C++ based web service with little more effort than using Go. There are several things I'd base my choice on. Ability to integrate into other code is one thing - if I'm building an API or admin interface for an otherwise C++ system that's a nod to C++ (though polyglot coding is an option too - I have four different languages in my current app). Availability of domain-specific functionality is another thing. As a non Go/C++ example of that, for some requirements Perl+Mojolicious+CPAN is an obvious solution, because of the breadth of generally good quality code available on CPAN. Hard performance and memory requirements is another. If I'm developing in an environment where I need predictable latency, C++ is a better match. If it's an environment where CPU and RAM are limited and I can't just spin up a few more web worker VMs, e.g. embedded or consumer gear, then again C++ has an advantage (though low performance requirements in most of those mean that bytecode based solutions are also competitive). Platform support is yet another. There are platforms (CPU, OS, OS version) where Go doesn't run conveniently while C++ does. (I'm currently replacing a C++/Qt web app with a Go based one, so I've been thinking about this).
Check out the TechEmpower web framework benchmarks for some additional options (you can filter by C &amp; C++, but some frameworks only appear on certain tabs): https://www.techempower.com/benchmarks/#section=data-r10&amp;hw=peak&amp;test=json Proxygen isn't on that list but does look very good. However, I tried to build it on Fedora and ran out of patience (default is Ubuntu). The LWAN authors blog posts are really interesting: http://tia.mat.br/posts/tags/lwan.html
&gt; The second version is not range based though. With the Ranges proposal terminology, it is, as `arr` satisfies the Range concept. (I agree with the point about getting Boost, of course)
[It's portable](https://en.wikipedia.org/wiki/Pragma_once#Portability) for all(?) compiler versions from last 10 years. Also faster in MSVC, comparable for Clang and admittedly much slower in GCC - according to [this test](http://tinodidriksen.com/2011/08/31/cpp-include-speed/) (which is 4 years old, so maybe something has changed in the meantime. Also the files are empty, so there is no indication what % of compilation time would these additional 2 seconds be in real case.) &gt; Sometimes the simpler way is better, even if it requires two more lines of code. Wait, are you suggesting that `#ifndef MY_HEADER_H` is simpler than slapping `#pragma once` at the top of the file? 
Note: the OP was talking about implementation overhead (ie, time "lost" re-inventing the wheel).
Like always, Nth edition of a book is meant to be mostly updates on the same skeleton. However, PPP gets updated to C++11, which, together with it being IMO the best book for starting with C++ and programming makes it definitely worth it.
Java fixed that by updating its HashMap implementation. It now converts individual buckets into sorted trees when they reach a certain size. Of course that only works for comparable keys.
Visual Studio Code is available for Linux and OSX
&gt; Java for example is not really a contiguous array of data, it's a contiguous array of pointers. Unless you use an intrusive linked list it seems hard to beat an array in Java. With every Node of a linked data structure being another Java (TM) Object with its own overhead and just a reference to the actual value/next node. 
Boy, I'm glad that Wikipedia article cleared up the issue of portability for every C and C++ compiler. All 13 of them. You and I are spoiled. We get to live in a world where `char` is an 8-bit byte and the operating system reclaims your unfreed memory on termination and `#pragma once` is supported by every major compiler. Unfortunately, the reality is that some platforms don't come with your choice of toolchain, and many vendor-specific compilers don't even have full standard compliance, much less unofficial-standard-feature compliance. Does every major x86 compiler support `#pragma once`? Yes. Does that fact make it "portable"? No. Regarding speed, I saw a benchmark a while ago that showed `#ifndef` guards outperforming `#pragma once` on both GCC and MSVC, but "a while" in this case is years and years in this context means the result is almost certainly no longer applicable. So I really shouldn't have said "slower", since I have seen conflicting newer benchmarks and have no honest idea anymore. I would point out, though, that no matter which is faster on a given compiler, the time spent opening headers (and thus the time saved by not opening them) must be insignificant compared to the time spent actually compiling. So this is all probably a moot point anyway. As for which is simpler, well, one is a construction of the CPP, which is standardized, which works as a natural consequence of the preprocessing rules and is thus supported by every compiler I've ever seen (I suppose theoretically there might be one where `#if` and `#define` aren't supported, but that would amaze me). The other is a nonstandard compiler directive that has to be specifically implemented by compiler vendors independently of the language or the preprocessor. You and I may have different ideas of what is "simple", but I think we can agree that one of the above is conceptually more fundamental, even if it requires just a bit more typing. Now, there are two big advantages to the pragma: First and most significantly, it prevents dangerous macro name collisions; however, if you're namespacing your macros the way you should be, the odds of those are vanishingly small -- and you can always add a few underscores. Two, it prevents trivial copy-paste mistakes and typos which might allow headers to be accidentally doubly included and cause difficult-to-diagnose bugs. Personally, I don't believe either of these advantages outweighs the lack of portability. Furthermore, while it is certainly a decision that can be argued for either way, I think it is Bad Advice to tell a newbie to use a feature that, while widely supported, is not strictly standard. It is tantamount in my mind to condoning reliance upon undefined or implementation-defined behavior, such as pointer aliasing, signed overflow, vendor-specific extentions, or assumed type widths.
it's a bit old so I guess it's normal if some stuff are missing. - you should use [std::make_shared](http://en.cppreference.com/w/cpp/memory/shared_ptr/make_shared) and [std::make_unique](http://en.cppreference.com/w/cpp/memory/unique_ptr/make_unique) when you want to create a new pointer. The control block will be created with the object, [also avoiding internal redirection.](http://stackoverflow.com/a/27082939/564079) - you can't copy a std::unique_ptr, but you can move it. Use this one if you don't want to share the ownership of the object. Perfect for the Pimpl pattern. - std::weak_ptr is constructed with a shared_ptr as parameter, you call the lock() function to get a shared_ptr from the weak_ptr. If the object is already destroyed, you get a nullptr. It's useful for example if a child object has a reference to the parent, to avoid a circular reference like the post said.
If you're using a modern compiler, you should almost never need to use new or delete because of the availability of smart pointers.
&gt; You and I are spoiled. We get to live in a world where char is an 8-bit byte and the operating system reclaims your unfreed memory on termination and #pragma once is supported by every major compiler. Unfortunately, the reality is that some platforms don't come with your choice of toolchain, and many vendor-specific compilers don't even have full standard compliance, much less unofficial-standard-feature compliance. Sure, but that doesn't mean you can't use them in areas where it *is* commonly supported, like Windows/Linux/Max application developement (which also the area most newbies are going to spend most time with). I'm very aware of limitations of various vendor-specific compilers and platforms, but when for example AVR-GCC doesn't implement C++ stdlib including new/delete, I treat it as a quirk I have to get used to, not a general rule that makes me give up some nice features on platforms that do provide them. edit: ~~I also wouldn't compare pragmas like `once` to other implementation-specific behaviors, as this is a kind of feature that either will work or won't (and give an "unsupported pragma" warning/error during compilation), while others you won't notice until you run the program. Not even gonna talk about undefined behavior :P~~ ...unless some very specific/old compilers would completely ignore it. OK, I admit I didn't think about that.
you can use a container of boost::any.
That requires a type conversion to get to the type you want. I realised I can't overload purely on return value :-(
You are correct. It goes both ways actually: If you need to write any one of copy-constructor, assignment-operator or destructor you need to write all 3. For the purpose of this post however, I thought it best to give a simplified version to every fresh beginner. It is in any case not bad to write a (possibly empty) destructor if you write a constructor.
Qt Creator works on Mac, Linux and Windows and is great for C++ development.
1: No, I decided against having a default empty state. It is not needed as a user could just add an empty case (like Some&lt;T&gt; / None in Optional&lt;T&gt;) if they need one. As for an intentional invalid state, I do not currently use one, though I do throw as a fallback if the tag is invalid at any point. 2: This is something I had not thought of, and so I expect currently the variant will be rendered invalid because the existing object gets destructed. I very much intend to fix now I am aware of it though. As I type this I can think of 2 initial options - one is to revert to the object that was there before, and two is to set the tag to an invalid number and use the fallback mentioned above. Do you have any suggestions as for recommended ways to handle this? 3 &amp; 4: These are functions that I considered implementing but at the time decided match was sufficient. I definitely see that it is more convenient though, and will implement it very shortly. Thanks for the feedback! I have very little experience doing this sort of thing and learning about things like question 2 are exactly why I posted it here.
Just a note - std::make_unique is only present in C++14 and higher. If you don't have access to that boost::make_unique works just as well.
Qt Creator is a fully-fledged IDE for any sort of C++ programming, not just cross-platform GUIs. That being said, its debugging facilities kinda suck.
I'd recommend CLion if JetBrains hadn't gone over to the dark side (subscription-only model).
http://codeblocks.org/ is a pretty reasonable IDE, although I find it somewhat unstable at times. The website seems to be down at the moment, but you should be able to get it at https://sourceforge.net/projects/codeblocks/.
I will give it a try :) thanks
Qt Creator is a Qt-based IDE that was, at first, designed for Qt development, but then extended to the point it's now a general-purpose IDE, supporting any CMake-based projects. And being based and Qt, it works on OSX, Linux, *BSD and Windows.
Launched 1.0 this year. 
If you can afford it: Slickedit www.slickedit.com /source: Longtime user of it
It's a great answer for sure, but doesn't it make some sweeping statements presenting pointers &amp; dynamic allocation as the same concept? Granted they are most of the time used together, but I think I prefer [this answer](http://stackoverflow.com/a/22146244)
Currently I do not, however it is definitely something I could look at implementing. It does just seem to be a hidden smart pointer though, is there a reason you could not just use std::shared_ptr or similar?
I started with Eclipse and thinking it was crap. I tried everything else (on Linux) and decided that everything else was worse crap. QtCreator is ok but Eclipse just has flat out better indexing and more features, I've tested them many times on the same pieces of code. CLion is pretty nice interface wise, and I hear their indexer improved a lot with the latest version. But it's a pain to use if your project is not CMake. Eclipse is much more build agnostic.
While this solution is batteries not includes, you may want to consider [libuv](https://github.com/libuv/libuv) and joyent's [http-parser](https://github.com/joyent/http-parser). Both are used by Node.js and provide a great cross-platform solution for async/evented IO. The http parser was originally based on nginx's HTTP parser and is very fast
I also recommend Codeblocks, works on Linux too.
If you can afford it: C++Builder from Embarcadero. Does c++ for iOS , Windows and OS X 
otherwise paste these four lines into your project: template&lt;typename T, typename Args&gt; std::unique_ptr&lt;T&gt; make_unique(Args&amp;&amp;... args) { return std::unique_ptr&lt;T&gt;{new T(std::forward&lt;Args&gt;(args)...)}; } and done.
make_shared and make_unique.
Vim, there's a reason it's been around so long.
Is this for a class? If so what class?
I'll just note that as long as the deleter has zero data members any good implementation should have the std::unique_ptr object be exactly the size of a raw pointer.
Was this a college class? And thank's I'll probably look through StackOverFlow too.
If you want to get good at making clean programs, the only advice I can give you is practice. Books can only do so much.
Accelerated C++. The best intro book imho. 
A separate specialization is required for arrays, however.
What sucks about it? It uses gdb/lldb/cdb as backends, just like all the others (except Visual Studio AFAIK), and thus has the same problems as all the other IDEs out there -- with a nice UI, but that is subjective of course.
Eclipse is good if your project is not too large (say linux kernel size). It does code indexing/completition/macro expansions etc. Just OS X - Xcode is great. Just windows - visual studio is great. You might want to try Microsoft Visual code - not sure if it supports intellisense for C++ though.
http://www.youtube.com/watch?v=kMzH3tfP6f8&amp;list=PL24126B3A47B69CB5&amp;sns=em C++ Programming abstractions. Stanford Uni
nice introduction but i think there are a few mistakes in there: 1. Obviously don't use `new` or `delete` but use `make_shared` and `make_unique` instead. 2. Raw pointers are perfectly fine. Use smart pointers to model **ownership** and to control **lifetime**. If you want to pass an object to a function that needs to alter that object, pass a pointer to show that the function is **not taking ownership**. 3. Circular dependencies with shared_ptrs are a sign of a horribly messy ownership model. Getting 2. right almost always solves this. 4. Who the hell allocates a smart pointer on the heap?!?!?! People often argue that C++ is a difficult language because of the manual memory management. But in reality when you realize that you should better call it "resource management" and languages like java really only solve the memory part, you start to realize that C++ is way more elegant. In every language, you need to have a clear concept of ownership to decide when to release a lock or close a file or release some other resource and C++ makes this very convenient with RAII.
Visual Code is pretty new... I think I will try it
const char * const cnst = "const";
There is a remedy for this though: Make your hash_set/map use a [fast cryptographic *keyed* hash function](https://131002.net/siphash/) with a randomly chosen key an attacker can't predict.
I wouldn't prefer a reference because of the readability. If you pass a pointer to a function it is obvious that the function alters the object. Otherwise you'd need access to at least the signature, better the whole implementation. For my own projects my rule is: `const&amp;` if i don't want a copy, pointer if i want to alter the passed in object.
So, based on tests made with suggested libraries made by fellow redditors, lwan seems to be the best choice for now. It's really fast, the API is really simple and you can integrate your application code with it's serving mechanisms quite easily. I'm a bit uneasy because it clearly seems like a weekend project, but i hope it all ends well. :)
Is this controversial? I've always more or less thought of it this way and it makes much sense IMO.
 #define CNST 'const'
Great point with #2. So for example if you had a print function, you'd pass the head of the list as a raw pointer? E.g. void PrintList(Node* head) { } over void PrintList(unique_ptr&lt;Node&gt; head) {} Would like to learn more about this... 
 auto auto_(auto(auto::*auto_)(auto)) -&gt; auto;
I believe it's valid once the Concepts TS goes through. Unfortunately, the only part GCC hasn't implemented yet is auto as a parameter, and presumably the generalized auto (auto::, forget the feature's actual name) in parameters. That means I can't check without looking through the TS again, which I don't have time for right now. 
I don't know why the article is written in such a patronizing tone. This is common knowledge.
Agreed. It's getting dated though, since the way to go is probably to have const imply threadsafe, meaning const functions cannot change physical state either.
Too bad the attitude of the article sucks. It teaches as if the reader is stupid and it gives no reasoning behind it. Just going "YES that is how it is meant to be you retard because it just is!" doesn't teach nearly as well as respectfully explaining the reasoning behind something.
The answer is a resounding yes (with exceptions) His resounding yes and my resounding yes look very different.
They can, but it's supposed to be responsibility of the class to make that changes thread safe (using a mutex or whatever else).
I agree with the argument, as long as "logical constness" is guaranteed to be threadsafe. See Sutter for reference: http://herbsutter.com/2013/01/01/video-you-dont-know-const-and-mutable/ And that is where hazzle begins...
The important thing not discussed in the article is thread safety. By default, const methods are supposed to be thread safe (since they have "read" semantics, it should be safe to call such methods from different threads concurrently). If such a method actually changes the physical state (using `mutable`), it is responsibility of the method to make these changes in a thread-safe manner, using proper synchronization techniques. 
Police police police police police police police police. 
1. Don't create board with new. Just use a local variable. . Board b(input); b.solve(); b.printBoard(); 2. Check your input for correctness. For example, if an error has happened (the user types some non-number string), print an error message and exit. . if (!(std::cin &gt;&gt; input)) { std::cerr &lt;&lt; "Incorrect input" &lt;&lt; std::endl; return 1; }
Because while you read one variable from the struct, another thread could write to the another one. The struct wouldn't be synchronized. Even just reading from a 64-bit variable in a 32-bit environment isn't thread-safe.
I agree, but this issue isn't directly related to structs, it can happen in any function.
From the warnings I got when using them, I think it's currently a GCC extension rather than effort toward this TS. 
Using `const_cast` to write to a `const` object is UB.
There are many more ways of making something thread safe than not mutating its state. 
A struct has no relevance to thread safety.
If your class is clearly documented as single thread only, then of course you don't need to bother. My rule should read: make them thread-safe OR clearly document that the are not, to avoid confusion.
`mutable` is "normal means". It's rare to see an `std::mutex` not declared as mutable...
&gt; By default, const methods are supposed to be thread safe (**since they have "read" semantics**, it should be safe to call such methods from different threads concurrently). Functions which only read are thread safe with regards to each other, however this does not make them thread safe with respect to write functions. Therefore, a const (aka read-only) function is not inherently thread safe.
I don't have it backwards since I was replying to the second part: &gt; have const imply threadsafe, meaning const functions cannot change physical state either. Something can be thread safe while its state is changing. That is the whole point behind combinations of mutable, mutex and atomic within a class.
What about C++ Primer 5th edition?
+1 for C++. I saw a few old-style casts in the hints and it's clear the author is a C programmer, not a C++ programmer. Ah well, old habits die hard haha.
It was a joke, in case it wasn't clear enough. As in, it'll compile, and it'll probably work, but it's stupid.
Yes, but it doesn't state how to do so. I only just realized the 'solution' was the question right after it, which I didn't see.
Diferent usages. Pointers are good for optional references, for example to pass to function arguments. Boost optional is meant for optional values, like for function return types. For example, the square root may be returned as empty optional in case the argument was negative. 
That has nothing to do with a struct and in fact I'm not sure what the number of variables has to do with anything. Also reading a variable isn't necessarily a race condition, it depends on what is done with result.
&gt;Given that strncmp is at the very least safer than strcmp, it is very reasonable to use strncmp. This makes their solutions relatively reasonable. That's incorrect - `strcmp` only reads from the strings. As long as they are null terminated, it is always safe. If your strings are not null terminated, you have bigger problems that a `strncmp` won't mask for long. In this example, one string is a literal, which is guaranteed to be null terminated. However, `strcmp` and `strncmp` are *logically* different. String length plays a role in lexicographical compares. Meaning `strcmp("ThisIsLong", "This") &gt; 0` and `strncmp("ThisIsLong", "This", 4) == 0`, since it only looks at the first four characters. In the example code, they are checking the initial characters of `vstart`, so they *have* to use `strncmp`.
&gt; As long as they are null terminated, it is always safe. precisely, if the strings are certainly null terminated. &gt; If your strings are not null terminated, you have bigger problems that a strncmp won't mask for long That's not necessarily within your control depending on the circumstances. So best to handle it properly if required. In this context, we don't know if it's avoidable or not. &gt; In this example, one string is a literal, which is guaranteed to be null terminated. That's a good point lol. &gt; However, strcmp and strncmp are logically different. String length plays a role in lexicographical compares. Meaning strcmp("ThisIsLong", "This") &gt; 0 and strncmp("ThisIsLong", "This", 4) == 0, since it only looks at the first four characters. In the example code, they are checking the initial characters of vstart, so they have to use strncmp. another good point - it seems I was correct in concluding strncmp was the correct choice, just not correct in why.
A `starts_with` function would be way more readable than what's in the example. The `strcmp` family of functions are too generic for it to be immediately obvious how they're being used.
Reading and writing from an atomic variable is atomic. What you are taking about is some non fundamental situation where two atomic variables are used in some way where they depend on each other's data in some fragile way I guess? I think I would need to see some code to know what you are saying. Either way a struct still doesn't have anything to do with it. 
If there's only one writer and one reader, there's no problems with having a word-sized integer being atomic without the need of wrapping it in std::atomic. And I can't really come up with an example right now. I don't work with multithreading that much that I need caching through a const method. As for the struct... it was just an example of how a const method could access multiple variables in a thread-unsafe way. A pair would work the same way. Or simply just reading two variables inside the method.
First timer as well. See you there :)
But two atomic variables instead of one isn't thread unsafe. If there needs to be some synchronization between them it might take some extra code, but it can be done.
Maybe I need to make it clearer, but Macaroni isn't a real C++ compiler and doesn't try to be. It really just copies and moves code around, and makes it easier to keep track of what units are being generated. [Templates work](https://github.com/TimSimpson/TypeErasureZL/blob/master/src/anything.mcpp), though some valid template syntax isn't yet supported. It's annoying and I'm fixing it, but it isn't a huge deal because it's very easy to [use normal C++ header files in a Macaroni project](https://github.com/TimSimpson/Lp3-Engine/blob/master/Engine/Gfx/src/Lp3/Engine/Gfx/Renderer.mcpp) or bypass the Macaroni parser within Macaroni source [using the ~block feature](http://border-town.com/macaroni/docs/reference/code/blocks/index.html). The important thing is Macaroni isn't really a C++ compiler- it just parses sort of a fuzzy view of the language (similar to Swig, maybe) and then pastes the blocks of code into the "generated" source files. 
You don't have to have everything in one file. Macaroni projects also allow for normal header and implementation files to be mixed in freely, so if you really wanted to design a custom set of header files for your project and put them in a separate interface directory. However, lets say you're writing a very simple non-template class. Maybe this class is only used in one place, and you could define everything in the header file and just include it, but the better practice is to still write the implementation file and put the method definitions there. So in Macaroni that bit of grunt work is done for you. Macaroni does some other things that are harder to explain but still useful. For example, lets say you decide you want to build your project as a shared library in Windows. Assuming you made the simple class Typically you'd need to add that declspec stuff to the header file of the simple class I mentioned above, as well as most other symbols. Now I get if you're designing a DLL you want to ship to customers and support for 50 years then it might be better design to add those symbols yourself and really think through every single thing you export as it should be part of an iron-clad contract with your users, but if you're only building a shared library for tactical reasons (such as making the build run faster) then its nicer to have Macaroni add that stuff for you. Macaroni creates a library config header- following the way Boost does it for it's libraries and also generates an ugly- but unique - symbol for each library. The big deal here IMO is that Macaroni takes the effort to "create a library" from normal C++ code down to zero, especially if you care about Windows support. Additionally Macaroni has Lua embedded, meaning you can do other things with it, such as write generators for [CMake](https://github.com/TimSimpson/Macaroni/blob/master/Main/Generators/CMake.lua) or [Boost.Build](https://github.com/TimSimpson/Macaroni/blob/master/Main/Generators/BoostBuild2.lua). So personally I find having to do all the things I listed above annoying and find that using Macaroni makes it much easier to create tiny libraries I can reuse than anything I've yet used in the C++ world. Of course at this point I'm probably biased since I wrote the tool. :) 
And sadly, me and other embedded folks, dynamic allocation done via most of the standard library is unacceptable. I still use classes and enums and a decent bit of other goodies, but the standard library? Heck no. That sadly forces me to rewrite an implementation of a queue and whatnot over and over. 
You know why all those types are templates? So that people like you can write an allocator that avoids dynamic allocation. You *are* being thought off, you just have to realize that. So, you really shouldn't have to implement all those things yourself.
This can only be read in a heavy Russian accent.
Yes, of course only with regard to other reading functions. This is what I meant.
Sounds like a really novel idea.
I tried that one, *once* in a code which read *really roughly*: const int x = 0; // do some computations const_cast&lt;int&amp;&gt;(x) = [result of computations]; The compiler happily optimized out the subsequent modification of `x`.
Sounds about right. I don't see why it wouldn't optimize it. Sort of an interesting trick, but I'm still not sure I'd sell my soul to use it.
I am subscribed to receive this by email and I enjoy daily the problems you propose and their solutions. Thank you!
Or more likely strstart() :P but yes, that is a good point. I really should have realized why strncmp is necessary in this case, but I'm going to say the reason I didn't is because I haven't done much char * manipulation in a while.
Just discovered this: http://duda.io/about/
wow calm down there, boy ... Who told you, that pointers mean "optional"? What problem then solves `boost::optional` or soon `std::optional`? You've just brought up contrived examples of poor code to prove me wrong which is really poor reasoning. For example: void g(type* p) { // whatever... f(p); // It's "obvious" that function alters the object - NOT! } come on, really?? At least use const correctness in your examples ... This really proofs nothing. What reason do you have to use a pointer here instead of an optional or a const ref? or: void f(const type* p); TYPE var; f(&amp;var); // It's "obvious" that function alters the object - NOT! Again, what reason do you have to use a pointer here instead of an optional or just an overload function? Well ok i think i know what you're trying to tell me with your examples. Sometimes you have to work with shitty code bases or at least code that uses different conventions but that was not what i was talking about. I use these rules for the code i write myself and it does give a benefit in readability because i can immediately see by looking at the calling code wheather the function is altering its argument or not. And I'm pretty confident that this is a benefit everyone shares that works together with me on a bigger codebase and not just a &gt; haphazard convention or even complete *nonsense*. On the other hand, I'm with you on the fact that using pointer arguments as additional return values is not very beautiful but the only alternative I know is returning a std::tuple and thats really better. A better way maybe would be to return a temporary struct because you'd get named values in addition to there ttypes but that again would have a bit of coding overhead and is not very widely used as far as i know.
The entire function is pretty bad. The nice thing about pointers is that they automatically jump bytes by the size of their type; why lose that benefit by doing some random cast? it's not even clear what iSteps represents? The whole function should be changed, really.
Do note that there is no need to write your own mathematical functions (from math.h), as they are already `constexpr`.
The standard sez: &gt;[C++11: 5.1.2/3]: The type of the lambda-expression (which is also the type of the closure object) is a unique, unnamed non-union class type â€” called the closure type â€” whose properties are described below. This class type is not an aggregate (8.5.1). The closure type is declared in the smallest block scope, class scope, or namespace scope that contains the corresponding lambda-expression. So yes, the actual type is guaranteed to be unique by the standard.
A lot of the time important things like alignment are forgotten when doing this sort of pointer arithmetic though, especially when adding/removing data from blocks. From what I can tell from this function, it would have been better handled by creating a struct of the desired size &amp; data and moving through those. I understand that sometimes it's necessary, but it doesn't look like this is a case.
~~Not currently~~ ~~There are propsal in this direction though, the most recent, is, afaik, http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2014/n4135.pdf~~ The document later [defines a bunch of utilities](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#S-support) to meet the guidelines requirements I have mixed-feeling about this. 
That's news to me - where is that specified in the Standard?
Correct - decay is a very precise concept. It strips references and cv-qualifiers, converts arrays to pointers, and functions to function pointers. Anything else isn't decay.
Thank you all for the responses. One more question: are the sizes of all non-capturing lambdas guaranteed to be the same?
Fun read. The document is a bit of a mess currently. It's very early stage, so it's probably normal. But it mixes very obvious stuffs that don't even qualify as guidelines ( delete / delete[] ), non-c++ related advice (they did open their "code clean" copy), as well as novels/debatable ideas (and really good ones). Plus some of the idea lays on top of non existing tools, or highlight some weakness of C++. It felt like they are going backward about it. "Advice: write thread safe, statically checked, contract-based, with clear intent code. Solution: C++1z/2x ?" "A comparison operator shall always be symmetrical.... so I guess you will have to write it twice anyway". Another obvious example is uninitialized variable. But it may lead the path to better compilers, standardized formatting tools and language utilities to make the ideas more realistic and easy to implement. I like to have a "Month" type. which amount to a bounded integer between 1 &amp; 12. There are libs to do that, but nothing standard yet. It's an interesting approach, I hope it pays off. 
Just a nitpick: Is it really a "concept"? Like promotion or conversion of types which are part of the core language? I looked at the standard and `std::decay` (and `std::decay_t`) is only the name of a transformation trait (20.10.7.5 Pointer modifications [meta.trans.ptr]), so I wouldn't call it a concept - just a specific helper the standard library offers.
That scrolling animation is not a good idea.
[removed]
The other answers don't really explain why the types need to be unique. Remember that when you call a lambda, you are actually calling the operator() of a function object. Now if the types of the function objects were not different, how does the compiler know which operator () to call ?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/cplusplus] [C++ Hints](https://np.reddit.com/r/Cplusplus/comments/3mayhh/c_hints/) - [/r/programming] [C++ Hints](https://np.reddit.com/r/programming/comments/3lgkt9/c_hints/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
On point 1, the dynamically allocated objects I noticed were all arrays, so I'd say prefer `std::vector` to manually dynamically allocating arrays. If you can choose a smallish safe maximum number of elements, the other alternative is to use a simple array local variable (no dynamic allocation, so the array lives on the stack) but of course the size must be known at compile-time (there's the C extension which some compilers provide for run-time-determined array sizes in local variables, but the C++ standard explicitly rejects it) and stack space is a much more limited resource than heap space. If you're *really* worried about performance and dynamic allocation overheads (which shouldn't be a problem for this, but still...) another option is to have a single `std::vector` which is shared by all boards, so the board class would reference a range within a shared std::vector. This works well for a FIFO (not CPU) stack of subarrays, using `resize` to allocate/free new subarrays. Note - by default, `std::vector` grows quite efficiently (amortized constant time for repeated constant size increases) and doesn't free space as it shrinks, so this approach does a fair job of providing the advantages of a custom allocator without having to figure out how standard library allocators work (at the IMO trivial expense of a bit of explicit handling of subranges). As for ownership, as long as something owns that `vector` throughout the whole run, the solver can just reference it without owning it. The `vector` could even be a global variable for something like this. 
Though IMO (1) using `new` purely to initialize a smart pointer isn't particularly bad - it's not prone to bugs, though it's a missed opportunity to slightly improve readability, and (2) there are still times when low-level programmers might want an explicit `new` or `delete`, though with `unique_ptr` being a zero-cost abstraction these are unusual and mostly involve interfacing with old or C code. 
show him the documentation on what delete does with a 'nullptr` (nothing is done) Maybe also ask him, how the system should know the value the pointer had before changing. 
You can completely avoid linear complexity searching during visitation simply by means of type erasure and subscript access to array of function pointers.
Ask him how the compiler is supposed to delete something if it doesn't know what to delete. If that doesn't work then try hitting them with a clue-by-four.
Sorry what example is it that you'd fire Herb Sutter for writing?
Heh, on one hand you have P.5: Prefer compile-time checking to run-time checking and on the other F.6: If your function may not throw, declare it noexcept
So why would you not use `boost::optional` for optional function arguments? I can see quite a few advantages: - for built-in types where you can't set a reasonable default value (or it just doesn't make sense), for example you want to indicate that a float parameter is optional - you want to make an object of some class an optional argument, but do not want to use pointers (I still think that's ugly, using a pointer in the function signature just to convey the information that it's optional!).
Are you sure he doesn't mean after deleting it? Also, avoid manual delete whenever possible (most of the time) by using smart pointers.
Not sure what the point is that you're making.
Thanks, always learn from my mistakes lol. Will definitely post there.
The C++ Standard does not mention STL, but I am taking STL to mean the algorithms and data structures portion of the standard C++ library. At this stage in your learning of C++, disregard what they say about the STL. The STL is good, and if you want to really progress as a C++ programmer you will need to really know the STL. Once you have mastered the STL, you will realize that there are some issues. 1. Built around iterators, instead of around ranges. This is Andrei Alexandrescu's critique. However, I think this is actively being worked on by Eric Niebler with his range proposal. 2. Some of the containers especially are not as efficient as they could be. Where you do not care about order, you should probably be using std::unordered_map instead of std::map. In addition, Chandler Caruth critique's that even std::unordered_map requires collision chaining which may not be the best way to hash. 3. There is the issue of memory allocation when using the STL containers with default allocators. Often high performance systems such as games use custom allocation strategies. These can sometimes be worked around using a custom allocator. The bottom line is that there are scenarios where the default standard containers may be sub-optimal, but the solution is to extend and/or design containers that implement the concepts of the STL in a more efficient way. Also, this is unlikely to affect you as you are starting out with C++. Once you master the STL, you will be able to use that mastery even with outside libraries as good C++ libraries usually try to follow the example of the STL where appropriate.
Books by Scott Meyers and "C++ coding standards" by Herb Sutter. Also Vandevoorde's "C++ Templates: The Complete Guide". Also watch some talks about C++11/14/17/... to know what workarounds from these books are not needed any more.
Minor point, it ain't the compiler. It's the running programming (that the compiler created). But this is basically the crux of the problem.
That noexcept isn't checked at compile time.
I sadly won't be attending CppCon this year. But some general good conference advice would be: * Wearing something casual like jeans and a t-shirt is fine * Don't forget to bring and use deodorant * Don't be afraid to ask questions at the end of a talk, even if it's someone you idolize. They're all normal people. * Attend all the social events you can and do some mingling * As others have said I wouldn't be too concerned with bringing your laptop and having your IDE at the ready. Take good notes but don't worry about writing code
Override the new/delete operators for the class, then show how they don't get called if you null the pointer first. e.g. http://pastebin.com/xTBTkxvE
Ask him how to get the following code to stop crashing: int _tmain(int argc, _TCHAR* argv[]) { for(int i = 0; i &lt; 10000; i++){ char* arr = new char[1000000]; arr = NULL; delete[] arr; } return 0; }
Tell your professor he should resign immediately, and if he gets mad tell him hes a dumbass and needs to go read a basic C++ book, or like...use google. EDIT: And this is why 90% of people who graduate colleges can't code for shit, or call themselves programmers when they don't really know jack shit.
&gt; Also, avoid manual delete whenever possible (most of the time) by using smart pointers. This way, you get to chase down leaky references, which are much more fun to debug than simple memory leaks!
&gt; A comparison operator shall always be symmetrical.... so I guess you will have to write it twice anyway Doesn't `std::rel_ops` help ?
&gt; The literal string is null terminated, but you are sure with the OTHER STRING ? In special if is user input. Does it matter? I mean, it does because of the substring thing /u/RedAlert2 discusses, but does it matter in the context of *safety*? `strncmp` will compare the first character of each, then the second, then the third, etc until either: 1. It finds a pair that differs 2. It reaches a null character in at least one of the strings 3. The specified number of pairs have been checked `strcmp`, on the other hand, will do the same comparison except it doesn't have the third termination condition. * If the two strings differ before the literal's termination, both `strncmp` and `strmp` will definitely return before the end of the literal regardless of whether the other string is null-terminated. * If the two strings are the same including the null termination, there is obviously no problem. * If the two strings are the same up to but not including the null termination *all three* conditions of `strncmp` and *both* conditions of `strcmp` will be true and thus it will terminate. Since one of our arguments is a literal, we know this null termination will happen regardless of the other string. Output-wise, `strncmp` and `strcmp` might differ here, but I don't see a safety issue when one of the inputs is a literal.
&gt; You probably misunderstood him. I have a feeling the professor just said "before" instead of "after" by mistake and OP's first reaction was to ramble about how stupid he is.
He might mean setting a member variable to null before deleting it by keeping a temporary local copy of the pointer value. &gt;Type* tmp = myMemberPointer; &gt;myMemberPointer = NULL; &gt;delete tmp; I'm not sure what it would get you but it would be safe.
&gt; Why do some C++ programmers dislike the STL algos and containers? I'm not sure that this kind of programmers would like the python containers more, they won't even acknowledge its existence
I gotta say. I like this a lot better than Unreal Engine's approach which leaves you guessing on what is or isn't allowed in their annotations.
unique_ptr is a smart pointer
man, sometimes there are guys on reddit that post on cpp_questions, or programming, and the poor guys code on turbo C++ in DOS. in 2015.
Yes, I think I remember a proposal for that. However, I don't remember it being approved. That's not to say it wasn't, though. For example, I didn't remember most of the things in Library Fundamentals 2 being put there, but found out today when I noticed GCC 6 has support for them.
Basically I'd use optional when I don't have an alternative. Also I want to emphasize the difference between an optional reference and optional value. Pointers are optional references and boost optionals are values. 
**Atomic Mutex** would make for a great 80's glam metal band name
No need, you can just keep downloading more as the program keeps running.
Yea but then you need to wrap null checks around your deletes. It's one of those mistakes you never really make after a while, like accidently doing an assignment in a comparison check. 
One common thing I see is an implementation simply not having these parts of the standard library. This comes into play if you're developing for an embedded device.
I was thinkint OP meant something like this int a = 344; int *x = null; X = &amp;a; Delete x; That's a double delete? TIL.. 
But you are right i was taught set null after. Sorry. I couldn't think of a properly example to what OP meant
I think the OP is talking about: int *x = new int; x = NULL; delete x; 
Oh, Fuck. Yeah. No sense in doing that.
What frustrates me in these situations is the fact that some of these universities have ridiculously high tuition fees,the professors are idolized by all the students (understandably so), and then they get taught this style of C++. Oh well, what can be done? 
fucktard?
But the same behaviour presents itself if you do `strncmp("LONG_LITERAL_STRING", s, LENGTH_OF_LONG_LITERAL_STRING)` so `strncmp` doesn't buy you any safety in that case.
You shouldn't need tools to write good code. You can "write thread safe, statically checked, contract-based, with clear intent code" in C++ today. The committee is working on standardizing proposals that will help you do so (without external dependencies) in the future.
Probably meant use null to initialize the pointer.
But I need more bandwidth first. Can I download those too?
 NL.10: Avoid CamelCase Ha ha! Suck it, camel lovers! NL.17: Use K&amp;R-derived layout if (0&lt;x) { // ... } Wait. What the shits? Spaces where it doesn't matter and no space where it does? [Fffffuuuuuuuu](http://knowyourmeme.com/memes/rage-guy-fffffuuuuuuuu)...!
rel_ops were already a failure in 1998
&gt; (as long as they're non-capturing.) Say, what?! You can convert any lambda to an `std::function`, whether or not it captures - [proof](http://melpon.org/wandbox/permlink/yIkW0gvzKK0AoeVN).
https://github.com/tomilov/variant_simple/blob/5a8c18c7761202b32b459e44acccb28e8fc2ad32/include/variant.hpp#L418
That has nothing to do with what I wrote. I said that they have a conversion operator to funcptr only if they are non-capturing. Capturing lambdas cannot be converted to function pointers, which makes sense since calling a capturing lambda would require an extra context parameter not present in a funcptr. That doesn't mean they can't be used with `std::function`, which does not require the object being wrapped to be convertible to a function pointer. `std::function` works with any callable. 
It was a hard job, but it seems someone has already done it for me. http://cpphints.com
For a capturing lambda, a conversion to pointer-to-function is not available, `std::function` has to store a copy of the lambda type itself. The conversion to an actual function pointer is indeed only available for non-capturing lambdas, as defined by &gt; ### 5.1.2 Lambda expressions [expr.prim.lambda] &gt; &gt; 6 The closure type for a *lambda-expression* with no *lambda-capture* has a public non-virtual non-explicit const conversion function to pointer to function having the same parameter and return types as the closure typeâ€™s function call operator. The value returned by this conversion function shall be the address of a function that, when invoked, has the same effect as invoking the closure typeâ€™s function call operator. Fun fact: It can be triggered in interesting ways [`with +`](http://stackoverflow.com/a/18889029/2073257)
/u/0x0080FF is a friend of mine, he's pretty serious about this stuff, and I'm super happy about the response he's been getting. I've been wanting to dig into this myself, but I've been busy putting out other fires in my own codebase before turning my attention to tackling this myself. (I've been using a Macro-based reflection system developed by the guy who wrote our scripting language, so I can afford to wait for /u/0x0080FF to figure it out for me :P )
Ever since I laid eyes on Unreal Engine's property system I've been wanting to do this very exact thing with clang's annotation attributes. Even down to using a template engine for generating the code (although I had no idea there was a Mustache implementation for C++). Very cool to see it all fleshed out. You might have just motivated me to finally do it. :) 
Of course you can. But there are pain points. Some proposed solution ( not_null, owned, contracts, etc) are not currently in the standard nor are they all currently proposed as future standardization works. By working on the guidelines they identified required modifications that we will hopefully get to benefit from someday.
&gt; real code should not have functions called "dosomething" or "f" That was **do_something**, which does something completely different than **dosomething**...
&gt;SomeLargeType var; // ugly CaMeLcAsEvArIaBlE That's so unfair. It should be: SomeLargeType var; // ugly CamelCaseVariable
 int f() noexcept(noexcept(g())) does the trick. ( f will be noexept when g is noexcept) Having some way to get a compile-time error would be nice indeed. I assume there are corner cases making this harder that it looks.
YouTube is your friend. Look for the CppCon channel and you can look over last year's videos while you are waiting for this year's to be posted.
Yeah, I'm guessing they aren't streaming it, but I posted just in case someone knew something since the website wasn't explicit.
piedmontchris, Thanks for your interest and I'm glad you have enjoyed the videos of last year's conference. Nothing will be streamed. Given the costs and benefits of streaming, we have no plans to stream any content at any point. The numbers are truly frightening. We will be recording and posting on YouTube (and probably Channel 9) almost all of the content. What will not be recorded? *) Any session where the speaker declines to be recorded. (Last year we didn't have a single instance of this.) *) The Open Content sessions (other than lightning talks and Grill the Committee panel) *) The planning/work sessions for 2016. Jon Kalb CppCon Conference Chair I'm happy to answer questions on Reddit, but I'll confess to not reading everything that gets posted on this subreddit (I know I should) particularly in the week before the conference. So know that I will read every message sent to info (at) cppcon.org and that I (or someone on staff) will respond. 
Immense cost of streaming? Then how do random gamers from the Internet stream their games all the time? As far as I know, you don't have to pay for live streaming on YouTube or Twitch.
This seems a little hard to believe when there are 10 year olds streaming on twitch. The camera and wireless mic are already in place, I wouldn't think it would be that crazy.
Thanks for the definitive answer and good luck this week!
Not the same thing, std::array is on the stack and must have size known at compile time. A unique_ptr to an array (unique_ptr&lt;char[]&gt; for example) is on the heap and may have sized determined at runtime. Can't really say one or the other is preferred, it's more of apples and oranges.
Remembering to delete memory you've allocated is also very tricky. Also, it is impossible to write unique_ptr from scratch if you aren't using C++11 because it requires move semantics. You'll have to live with e.g. scoped_ptr which isn't as good.
I believe it it she cost of the team managing, filming, live-editing the videos that is expensive and unavoidable when you make an event in such a place. It's not like they are gathering at the big house of one of them and starting talks with webcams...
Thanks for sharing. I'm curious how cmake workflow has been with most users in VS. Does building within VS run the prebuild first? Our team is mostly VS and our linux build uses make files that grep the vcproj files to find sources/etc. We are thinking of switching to cmake to better support development on the linux side, but don't want to loose things on VS side,e.g. adding a new file via the VS ide. 
What will be the rough time delay between the event and me able to watch it on youtube? An hour? Day? Week? 
I also thought I could eliminate the linear search somehow, but I wanted to make it work first. would be nice to have some benchmarks to see when linear search and when type indexing is faster. 
I don't particularly understand why, but high-quality live streams can cost upwards of twice as much as recording them (even with in-hour teams doing it, so it's not just contractors overcharging).
I wasn't entirely clear how the build step works. Are you always running the reflection tool, or do you only run it when a modification has been made to the reflected header?
You can do `int f() noexcept { static_assert(noexcept(g()); return g(); }`, but have fun duplicating all of your code (or wrapping every expression in macros).
Yes, it's only a problem if there are several of those new's being called in the same block. This happens a lot for constructors themselves. eg. in one of my classes I have this: SGame::SGame(sf::RenderWindow &amp; wnd) : Scene(wnd), _ui(wnd, *this), _cursor(std::make_unique&lt;Cursor&gt;()), _game_map(std::make_unique&lt;GameMap&gt;()), _self(std::make_unique&lt;SelfPlayer&gt;()) If those `make_unique`s were replaced with news and any of them threw, they can result in a memory leak. This is a pretty common pattern, specially when doing component based systems. I agree though that the benefits and risks aren't huge, and I've pondered myself whether to go back to using `new`, not because of readibility, but because if you have an error in the constructor's arguments, you end up with a page long compiler error (at least in MSVC). Also the fact that you don't have any tooltips info regarding which argument you're on (it just shows `make_unique`s template argument instead). **Edit:** Actually now that I think about it, I find the `make_*` versions more readable, due to being able to write: `auto ptr = std::make_shared&lt;T&gt;(args);`. I prefer using auto as much as possible so I can read the variables without knowing their type first.
I'd say the problem there is you shouldn't have `new` (or pretty much anything substantial) in that particular place - if you want to initialize members with substantial values, they should be passed in ready-built as parameters, or else built in the body of the constructor. Though of course that shows a useful advantage of `make_unique` - your class never has to allow for a null state in that member, even within the body of the constructor. 
https://akrzemi1.wordpress.com/2011/06/10/using-noexcept/ is a really interesting read. The committee is considering statically checking noexcept specifiers in a future version of the standard, which is great news indeed. calling std::terminate has little value when it can be detected and fixed at compile time. 
I don't get it. I just showed you a common case where it's not exception safe.
Herb Sutter gave a talk on this: https://channel9.msdn.com/posts/C-and-Beyond-2012-Herb-Sutter-You-dont-know-blank-and-blank You can still achieve thread safety if you synchronize it (either with a mutex or atomics), but you obviously have to pay attention, so you do not end up with rubbish performance.
One of the best C++ things that I have seen in the last months. Great job!
The gamers all sit still so they're in frame. They don't walk around, and in general you can pretty much rely directly on having most of the video be the screencast, and a little bottom corner inset for the player's quartershot. A conference speaker is a whole different animal. There will be walking around on stage. There will be hand gestures. There will be insanely complex slides (not that there should be, but there can be). There will be laser pointers used. There might be physical demos with additional video inputs coming in to the mix. All of these things would require a live mixing board and producer/director for streaming/broadcast in the same way that such things are required for sporting events (though there's many fewer cameras and a lot less quick action). These things all cost money. Further, tech conferences always have bandwidth issues, so streaming is technically challenging. Further, you would then have to consider the impact on the value of the conference to those who have actually paid (or might pay in the future). This is not a trivial element.
It's not a common case to create your components on your constructor? How the hell else are you going to do it?
Again, it's not about advocacy, it's about disproving your false claim about exception non-safety. And BTW, you're wrong again. Let's look at your example, modified to use `new`, again... SGame::SGame(sf::RenderWindow &amp; wnd) : Scene(wnd), _ui(wnd, *this), _cursor(new Cursor ()), _game_map(new GameMap ()), _self(new SelfPlayer ()) Every use of `new` in this is providing a single argument to a single constructor. The example you're referring to is providing several raw pointers to the same function call. Of course for that, all the `new` calls must be done before calling the function, and nothing is responsible for cleanup of those allocations if an exception is thrown by one of the constructors. In fact it's an example of something I already told you - providing a constructor argument using `new` is only safe if there's nothing (that can throw) in-between. In this example, there's another `new` in-between and that can throw. This issue exists, and it can exist where you use multi-parameter constructors to initialize members, but it doesn't even occur in your own example. It's nice that we can avoid it, but again, I was calling out your false claim with counter-examples - not advocating an alternative style. If you feel like continuing this, feel free, but you'll be doing it on your own. 
Because I admitted possibly being wrong even when I wasn't sure (and turned out not to be when you pushed me into double-checking), whereas you kept on and on refusing to acknowledge a mistake. Sure, fine, whatever. 
I've worked on very large crossplatform projects with CMake. IMO, it's the only maintainable solution for crossplatform C++ development. Yes the syntax is wonky. Yes it can be a pain. But it works. I'd personally be very nervous about make files that grep the VS source files, just because of potential breakage. Plus you've traded one thing (being able to add files to a vcproj from the IDE) with another (making it absolutely impossible to do any primary development on Linux, since you cannot maintain the build system there at all). This means you are forcing all non-windows developers to be second-class citizens, if you will. If you move to cmake for all of it, you at least put everyone on equal footing. Plus, your developers can use Qt Creator with CMake support on all platforms (with even cl.exe support on Windows), or CLion with CMake support on all platforms. The Windows developers on the team I work with have not complained about the inability to add files from the IDE, as far as I know. It's worked out for us, anyhow. And tends to make porting to new environments easier.
So generally I would say it depends on the approach of how you set up you cmake. I will also say that I've never used the cmake plugin for VS so maybe that solves some problems. But when you add a file in VS, it won't be added to your CMake, and in fact it will default to the projects build directory. So if your CMake is based on Globing files, and you're mindful that you might put a source file in your build directory, you can use that dialog. And yeah, CMake will run a prebuild when you build. It just checks of things have changed since the last run, if you use globbing it might now work. I usually just have a prompt open to do the regenerate manually when I start adding anything serious.
First time for me, too. And I'm already here (just in case anyone wants to socialize).
What is the license for this code?
The latter won't compile against C++98. A bare instantiation calls the default constructor, which is what the second one is.
The two statements perform the exact same operations. I know that in C++ the constructor is automatically called, so I don't need to call it myself with {}. There is no benefit to readiblity or code clarity, in fact I'd start to argue the opposite. So really there is no reason to have {}.
Both of those define (instantiate) a vector. They are called "[default initialization](http://en.cppreference.com/w/cpp/language/default_initialization)" and "[value initialization](http://en.cppreference.com/w/cpp/language/value_initialization)", respectively. The difference doesn't matter for a vector (because it has a "user-provided" default constructor), but it does for a non-class type: int result; // uninitialized int result{}; // zero-initialized Read the above links for the gory details.
I see what you mean. On my first read, I actually misinterpreted what you were saying (thought it was referring to deleting a null pointer - woops). Mentioned that since there's been many cases where I've heard people believe that deleting null pointers were undefined behavior. I'll keep the comment for history, but apologies for the unnecessary correction!
Better to do it this way really. const int x = [&amp;]{ do some computations... return result of computations; }();
&gt; Heck, I even use a mutex to read out an int shared between threads because I don't want to think about memory ordering and visibility issues. Why not use atomics for primitive types?
&gt;Is the constructor invoked with every declaration of any C++ object That's the point of the constructor. It's guaranteed to be called so the class can maintain its invariants. &gt; (even T)? What's "T"?
Unless I'm misunderstanding you, i don't think it's totally reasonable to expect the compiler to know that those will have the same effect. I think it would be a little odd to have a special case where the compiler checks to see if the copied value in a copy constructor is equal to the value that the default constructor would produce and if so, ignores it.
Both cases perform default initialization and therefore call the exact same constructor. I would be surprised if the generated code was different. Your case is totally different. The two initializers call two different constructors. 
That is an abomination. I cringe and vomit every time I see it.
Because it's almost always a part of a larger operation where I'd need a mutex anyway afterwards if a condition is satisfied. I don't have the kind of contention that double-checked locking would be worthwhile. (It's video processing, so I have very low rates of concurrency.)
Interesting to know, although I wasn't the one needing its use (yet). :) Tagging /u/zvrba for him/her to know.
The second is value-initialization rather than default-initialization, but as they behave identically here, your point still stands. 
This is pretty much what Bjarne's "Tour" was made for.
That's right. I thought you were speaking generally.
We're conditioned to hate it. There is certainly room for a C++ style where the type is usually on the right, rather than the left. This means the first thing you see is usually the variable's name, and the declaration keyword `auto`. It's really not much different than Rust's `let`. Lots of C++ people seem to be loving Rust, so why the hate in C++ for similar practices?
Where `T` has a constructor, yes.
I can't think of a way to do it without it being `T*` or `T&amp;`.
Such an initialization requests, "construct a thing, move it, then destroy the original". I find that intolerable (especially given that it's more verbose than traditional initialization), even if it's a copy elision candidate.
That's true, I didn't think about that. Being more verbose doesn't mean less clarity though. I find that when reading code I usually want to know which variables are where and when they are being used, not their type, especially because usually when you know the variable's name, you usually know what type it is, or you simply don't need to know. In the case of a vector, the name usually implies it's a container, and whether it's a vector or something else usually doesn't matter as much as the logic behind it being used.
One area that will be different in C++ is resource management. In particular you should learn about using RAII to manage resources. Another difference is exceptions. Java uses compile time checked exceptions but C++ doesn't. To see how exceptions should be dealt with in C++ see http://exceptionsafecode.com Both these two topics are areas where you can do things naÃ¯vely, but which experience has shown there are better, simpler, easier, and more reliable ways. In resource management you can call functions that have to be explicitly paired for creation and destruction of resources. E.g. `open()`/`close()`, `new`/`delete`, or `malloc()`/`free()`. But using RAII to encode such pair relationships is not only more reliable, but also helps raise the code to a higher level of abstraction, making it more readable. With exceptions, you could sprinkle `try`/`catch` all over your code (or use error codes), but this makes the code difficult to read. Using the better practices outlined in the linked site again makes the code more readable as well as being easier to write and less likely to be messed up.
For objects that have a constructor, yes. Builtin types don't.
I'd expect the compiler to optimize this, it is a simple case.
&gt;"construct a thing, move it, then destroy the original". Same thing applies to functions that return by value, are you also opposed to that? 
Going from java to C++ shouldn't be very difficult the problem is the learning material you will find is often terrible. Most things in C++ is very similar to java syntax wise but the underlying implementation is completely different, so I've seen a lot of java programmers do stuff that seems like it would work just the same but is actually awful (including things like declaring everything on the heap and never deleting, that was in a *textbook* I found, ugh) Most things should come naturally to you but look up RAII, difference between stack/heap, pass by value/pass by reference, move semantics. Those are pretty much the biggest strengths of the language, learn it well and you'll do great. In short beware of the fact everything looks the same but works differently.
It is the first time I used placement new so I don't know if this is the proper way to do it. I need to call the destructor of the type somehow. Do you know a better way, or is this completely wrong? 
I would too, but not an ancient one like 4.1.2 with COW strings.
Are you sure 'C' is represented as 110000? [Ascii table](http://www.asciitable.com/) says otherwise.
Most important part of that list: all books by Scott Meyers and 'C++ Coding Standards' by Herb Sutter and Andrei Alexandrescu. Resource management is widely misunderstood. Even when you meet C++ programmers at your job, they can be teaching wrong things. There are a lot of misleading books. People who know the topic are: Stroustrup, Meyers, Sutter, Alexandrescu. Their talks are on YouTube and vimeo.
Is this one of your homework questions? First convert that binary value of C back into decimal. Now pretend that that's the ascii decimal value of C. Simply add the correct offset (or manually count one-by-one) until you get to Z. You could also do all of the counting in binary for fun, and then convert the value for Z to decimal at the end.
I was really surprised by the part of Herb's talk where this idea was first introduced (at least to me). Were there previous discussions ? in the committee, at Microsoft, etc ? Clearly there is no consensus ( hopefully ). I tend to agree with you that the syntax is both incorrect and cumbersome. What is Bjarne stance on this ? On the the hand Herb is a really good orator, and this idea does have some kind of logic. Let's hope it doesn't get to much traction or that something is done about it. ~~C++ needs an universaler way of initializing types.~~ 
How can mirrors be real if our eyes aren't real?
I think this case would be simple, it's really no different to `static int x;` versus `static int x = 0`.
Recommended by a few gurus is a lot different than "best practice."
So, I have done some work on this, and I have implemented (in a new branch) an invalid state that is entered if (and only if) a copy/move throws, or if the variant is moved from. Checking for this is optional, and done by an extra callback to ```match()``` that takes an error object. I like this solution, as when using simple types that do not throw, nothing has to be changed, and when using types that could invalidate the variant, the error only has to be checked where necessary. Any attempt to access the object inside an invalid variant will cause the variant itself to throw, to prevent undefined behaviour, and the error objects explain why the variant was invalidated, for debugging. Can I ask for your opinion on this, or for anything I might have missed implementing it?
Verbosity is always a cost. As the amount of the stuff on the screen increases, it becomes harder to understand what's happening, and harder to notice problems. Sometimes, verbosity is a cost worth paying (e.g. it is worth having larger quantities of straightforward code, than a small quantity of super-dense super-tricky code), but it is a cost. All things being equal, more verbose stuff is worse.
Yeah, you can request copy-initialization of the return value from a braced-init-list or an ordinary expression (in C++98, even). But you can't get direct-initialization that way. My point is, function returns are different from local variable initialization.
just to be sure we are on the same page, like this: https://github.com/gregorburger/variant/blob/master/variant.hpp#L63
good idea! "this" line is because visual studio thinks _b is unreferenced (don't ask me why). shared_ptr because i was lazy 
It's pretty easy to construct an example where it's not a simple case. What if, for example, the default constructor stores something that's nondeterministic, like it's creation time.
I added an MIT license! Feel free to do whatever your heart desires with the code.
Sincere question: I assume you're talking about automatics here, correct? Because I believe for static data, the C++ (and C) standards guarantee that the "result" (int object) will be zero initialized (let's say the above 2 lines are located outside of any function). (I'm from the embedded world, where things like "the world before main()", linker map files, linker command files, etc. are part of everyday work. The reason I mentioned the embedded background is because at least one person will read this and say, "But my toolset for my MSP430/PIC/AVR... platform doesn't do that default zero initialization!" And that would be a non-comformant (or non-compliant?) toolset...)
I have not heard anyone advocate the "Almost always use auto" mantra other than Herb Sutter. Scott Meyers disagreed with Herb on the issue and I remember a talk where Herb advocated for it and Andrei Alexandrescu visibly gagged. One issue with much of Herb Sutter's advice, compared to say Scott Meyers, is Herb advocates for things in a very kind of militant fashion. His advice is almost always of the form "Always do X... Never do Y..." whereas Meyers is more of a "Prefer to do X... consider the downsides of Y." I prefer Meyers approach because it encourages me to think about the issue at hand and weigh the advice against other considerations, rather than just memorize a bunch of "best practices" and dogmatically apply them. But honestly why does everyone just look to what some big shots think rather than evaluating the pros and cons on what is kind of a pretty basic issue? I guess I just find it odd that people are so used to being told how to program by the so-called thought leaders that the idea of coming to an independent and reasoned decision on something as basic as initializing a variable results in paralysis among C++ programmers.
I'm only talking about `std::string with `""` as initializer.
You mean the compiler should check to see if a statement is EXACTLY `std::string s = ""` and if so, replace it with `std::string s`?
There's no assignment at all in `static int x = 0;` , it is initialization. `int` does not have an assignment operator either, since it is a builtin type. So your claims make no sense. [Here](http://goo.gl/LH51Dz) is an example with gcc. You can see that `z` gets special treatment but `x` and `y` both don't, despite the initializer. (Moving the variables into `main` makes no difference either, try that out if you want)
Delete all the members ;)
You're right, my example assumed automatic variables. For statics, it's actually a two-phase initialization: the variables is first [zero-initialized](http://en.cppreference.com/w/cpp/language/zero_initialization) (in practice, before the program even runs) *then* intialized appropriately at run-time. In the case of static int i; the second initialization is a default initialization and does nothing, leaving the zero-initialized value.
That requires g being correctly marked noexcept. If I modify g to throw, but forget to remove the noexcept specifier, I get hit with terminate.
*Shameless plug* [C++: Minimalistic CSV Streams](http://www.codeproject.com/Articles/741183/Cplusplus-Minimalistic-CSV-Streams) [Github repo](https://github.com/shaovoon/minicsv) I have used this CSV class to write Wavefront(*.obj) file parser.
*Another shameless plug* CSV isn't a precisely defined format; on multiple occasions I slapped together a simple CSV parser for whatever file format was thrown my way with our [PEGTL](https://github.com/ColinH/PEGTL) parser library (PEG based, C++11, header-only, production quality, small and light - and with documentation).
&gt;and I can't say there's anything I miss other than Intellisense. The clang code model plugin somewhat solves this, it's super correct, but because (I think this is the case, it might be different) it does code completion on the fly, it's also super slow. My own game (engine) is about 3200 LOC and code completion using clang code model is basically dead, unless you want to wait 5+ seconds to get correct code completion. I think this could be solved by building a database of the AST like VS does for intellisense. &gt;Qt Creator's debugging tools (auto, memory, breakpoints, etc.) don't appear as nice as VS's, but it's pretty feature-complete IMO. Again, clang comes to the rescue here! If you use clang in combination with libc++ (currently mac, bsd, linux exclusive) your debugging experience becomes much nicer, data such as strings become immediately visible in the debugger and a bunch of other stuff I can't remember from the top of my head. Beware that you cannot mix libc++ with libstdc++, so you need to recompile all your c++ libraries to use libc++ (yes, even Qt/boost). It might be a hassle to set it up on linux (I don't know about BSD, but libc++ is default on mac, so it's easy there), but it has been 100% worth it for me. If you want I can post some helper scripts I made to compile boost and ICU with libc++. If I hate one thing, it's that people constantly have to reinvent the wheel :)
&gt; VS 2015 supports app-local deployment. That made me go "wait a minute", because last I heard, app-local deployment wasn't possible with the universal CRT. But apparently, there's been a [update](http://blogs.msdn.com/b/vcblog/archive/2015/03/03/introducing-the-universal-crt.aspx) very recently, and now it's possible after all. Awesome!
CMake can easily create .zip / .tgz files after build if you want to make quick releases. I distribute a Qt app that way (but with an installer on windows), here are my scripts if you want : https://github.com/OSSIA/i-score/tree/master/CMake Thanks to Travis CI and Appveyor we just push a new tag and releases are generated automagically for Win &amp; OS X (Maintaining Linux packages was too cumbersome and it's on the AUR). 
In this code fragment: // you can also use type meta::Type::Get( "SoundEffect" ) based on a string name Field volumeField = typeof( SoundEffect ).GetField( "volume" ); // meta data for the volume field MetaManager &amp;volumeMeta = soundEffectType.GetMeta( ); Are you not missing an `auto soundEffectType = typeof( SoundEffect );` ?
Keep in mind that even if you use MinGW instead of MSVC, you still have to distribute the libstdc++ and libgcc dlls with your application, or link them statically.
I'd really like to see app-local deployment of DirectX and XInput. It would make my life much easier.
I absolutely loves Qt and Qt creator is my go-to IDE, especially with the clang code model. It's actually feature full, and very light at the same time. It has a good integration with msvc, and the debugger is decent, but VS is better in this area. What other feature are you looking for ? As per the no-installer requirement, can I ask why ? as STL mention, you open yourself to the issue of vulnerabilities, etc. Users on windows are used to installers. They suck but users accept that. You probably want to think about a way to keep your application up-to-date. * Consider using an installer framework on windows. MSI being the more standard. Understand that for most people an installer is simpler than a zip. If not only for the fact that the application should be registered in the start menu. * As your application will be open source, you can consider having it integrated in various linux distributions * On mac, you probably want an app, bundled in a dmg. you can also considered publishing it on the app store. depending of you other base, you can also use something like a simple configure script or something like homebrew. It also depends or wheather you are willing to cash out for a developer certificate. I would advise against statically-link Qt, as the binary won't work or be otherwise unstable in many distributions that are not your own. You can improve that by using a LSB-compliant build chain on an old distribution, using a stripped down version of Qt, but there will be dragon. Also, security. And as a user, I will hate it. I'd rather have to deal with a configure script and use my own version of Qt. But that's just me. There are some other crazy ways. look at Ubuntu snappy's for example. The Qt documentation has some hint about deploying an app. But, it's not easy. But fortunately, whatever you do, redistributing the msvc runtime dll won't be the culprit. Microsoft recently reverted its decision not to support in-app deployment. Thanks Microsoft. 
You don't need to link it statically. Just bundle the library with it. I agree with other points.
 #include "minicsv.h" #include &lt;iostream&gt; #include &lt;cassert&gt; int main(int argc, char **argv) { csv::ofstream os("oops.txt"); os.set_delimiter(','); os &lt;&lt; "this will break, badly" &lt;&lt; ":)" &lt;&lt; NEWLINE; os.flush(); csv::ifstream is("oops.txt"); is.set_delimiter(','); std::string a, b; is.read_line(); is &gt;&gt; a &gt;&gt; b; assert(a == "this will break, badly"); assert(b == ":)"); return 0; } -- ~/Dev/C++&gt; g++ test.cc ~/Dev/C++&gt; ./a.out a.out: test.cc:21: int main(int, char**): Assertion `a == "this will break, badly"' failed. zsh: abort (core dumped) ./a.out Dealing with values that may contain the same characters as used for delimiters is what makes CSV so fun :)
You might want to look into WxWidgets. I don't think it has the problems you mentioned. You just ship the dlls with your app and it works.
What about switching to wxWidgets, which only uses standard C++ and can be compiled to one exe (by changing both your project and the library to statically link the Visual C++ libraries, and then statically link the library). Note that wxWidgets only supports desktop targets(Windows, Linux, OSX) now, and it focuses on GUI so it has less feature than Qt.
I use my own. Works very well and is easy to use. It's a single header file. https://github.com/labyrinthofdreams/sfcsv edit: See the test file for what it can do.
This is not the responsibility of the library to escape/unescape text. The user can escape the text before feeding into the CSV library and unescape after reading. Just because you need escaping, you want other users who does not need it, to pay for it? Escaping is different for different system(example: DBMS), the library has no knowledge of how to do it, and it should not be automatic. The common delimiter for CSV in use is tab.
I don't understand what is your problem with optional parameters. That exists in all sorts of places: "this parameter is optional; if you pass 0, f does X (or does not do it, or whatever)". That has nothing to do with your "return" example, which merely shows the **completely idiotic** code pattern in lesser programming languages (like C), where people code are trying to defend themselves from broken clients for non-optional parameters. But because C language is **stupid**, people have to emulate pass-by-reference using pointers, and **that** is the real reason why this crap exists in the first place. But we are discussing C++ here.
&gt; The user can escape the text before feeding into the CSV library and unescape after reading. Do they know they should, though? You don't seem to document this on github ;-). Also, escaping the text is exactly where much of the fun starts with CSV (bad name, see below+++). Does the library handle newlines in the text? Some do, you know, and for that, you absolutely need escaping. (My point: you say "not the responsibility of the library", I say "library doesn't do much, it's therefore less useful "). &gt;The common delimiter for CSV in use is tab. **C**omma Separated Values (**C**SV) ;-). +++ In the olden days, people rather called this [**D**elimiter Separated Values](https://en.wikipedia.org/wiki/Delimiter-separated_values). Comma is quite US-specific, e.g. Europe commonly uses a semicolon as a list separator, and Unix uses a [colon](http://www.catb.org/~esr/writings/taoup/html/ch05s02.html). Tab is, in fact, seldom used nowadays.
When writing safe code escaping is very rarely optional. The library should be safe by default. If anything it should be an optional off switch. *Especially* DBMS show you how terribly wrong "the user will do it if they need to" will go.
There are no licensing issues with redistributing the MS redistributables (except the debug versions) that's what they're for, to be redistributed. It's not true that you necessarily need to use the redist installer to deploy them. You can also create a [private assembly](https://msdn.microsoft.com/en-us/library/dd293565.aspx) for the CRT libraries within your application. This only requires you to understand a couple of things about the library manifest that Visual Studio generates for your executable. It's quite simple. If you're using VS2015 the process is different because of the universal CRT although it looks like application-local deployment is still supported [as per bullet (6) in this blog post](http://blogs.msdn.com/b/vcblog/archive/2015/03/03/introducing-the-universal-crt.aspx). Alternatively you can just statically link everything. The effort required here can range anywhere from "super easy" to "incredibly difficult" depending on if your dependencies already support building as static libraries and statically linking the CRT. Have you ever deployed a C++ project before (just curious)? A lot of these things are fairly basic and are just the things you learn the first time you try to deploy a C++ project.
The great thing about the book is that it's really two books in one, a tutorial and a reference. He's a really good writer, even the reference sections read like a good explanation rather than a technical manual.
`configure -static -static-runtime` and you're set as far as Qt goes - you need to build it yourself, of course. Whatever you build with that Qt will be statically linked against Qt and the C++ runtime. You get a nice executable with no dependencies at all. Visual Studio is a bundle of an IDE and a compiler. You can use the compiler from Qt Creator just fine. I've been doing that for pretty much as long as Creator was in existence... &gt; if I use the Visual Studio compiler, I'd need to either create an installer Huh? Who told you this?
You don't have to install the CRT. It in fact ships with the system, and you can use it, you have all you need with the system SDK (IIRC). The name of that module is msvcrt.dll. What you want, however, is that the CRT of your/any version of MSVC (and CRTs are always different between versions) is on the system.
There is an RFC for CSV file format. https://tools.ietf.org/html/rfc4180
Also posted on [std-proposals](https://groups.google.com/a/isocpp.org/forum/#!topic/std-proposals/JVzWe586akI).
This is all you need to build Qt statically: Open a VS Native Tools Command Prompt and type out the following: wget http://download.qt.io/official_releases/qt/5.5/5.5.0/single/qt-everywhere-opensource-src-5.5.0.zip unzip qt-everywhere-opensource-src-5.5.0.zip mv qt-everywhere-opensource-src-5.5.0 qt-5.5.0 cd qt-5.5.0 echo y &gt;&gt; accept configure -opensource -static -make libs -make tools -opengl desktop -no-icu -qt-zlib -mp &lt; accept set CL=/MP nmake rm accept cd .. rm qt-everywhere-opensource-src-5.5.0.zip 
You're totally correct! Nice catch. I'll update the snippet. 
https://github.com/ben-strasser/fast-cpp-csv-parser Header-only, very fast, multithreaded using C++14 threads. Also, compile-time configured using policy templates.
Not on windows, if the app shipped its own libssl.dll in its folder
in the section &gt; How could await-first be more efficient than yield-first? The author uses the words suspend and register, what does it mean to register or suspend a coroutine? &gt; Notice the difference? Not really, you lost me right there. What is the exact difference in terms of what is happening with the stack, program counter,... between both approaches? Why can't functions be `async(true)` by default? It seems that the RFC splits the world, neglecting the main advantage of the resumable expressions proposal. Why can't constexpr functions be `async(true)` ? This seems to be a major drawback.
No, declarations never cause constructors to be called, but definitions do. The examples you've included here are both declarations *and* definitions, so they result in the instantiation of objects, and as a result the type's constructor is called to construct the object.
Not at all, consider the following code: #include &lt;iostream&gt; #include &lt;vector&gt; class MyClass { public: /* Uncomment to change the behavior of main() MyClass(std::initializer_list&lt;int&gt; l) : v(l) { std::cout &lt;&lt; "Initializer list constructor\n"; } */ MyClass(int a = 0, int b = 0, int c = 0) : a(a), b(b), c(c) { std::cout &lt;&lt; "Default constructor\n"; } private: int a, b, c; std::vector&lt;int&gt; v; }; int main() { // Behavior may change when implementing the initializer list constructor MyClass o{ 1, 2, 3 }; std::cout &lt;&lt; "Press any key to continue...\n"; char c; std::cin.get(c); }
I used to know C++, well pretty much most of it up to and including template meta-programming, and it was fun and zany, like that movie "Spaceballs.". But then C++11 came out, and it was dark and disturbing, like that movie "Police Academy." Any language where the ["Core Guidelines"](https://raw.githubusercontent.com/isocpp/CppCoreGuidelines/master/CppCoreGuidelines.md) document is 12000 lines long (and apparently incomplete), has jumped the shark. Rather like how biological ageing could be seen as the accumulation of genetic mistakes that can't be evolved out, every (successful) PL is doomed to become an accumulation of design mistakes that can't be corrected. Raw pointers, nope they're bad m'kay, use a pointer wrapper class, macros bad - use plain enums, plain enums - bad use class enums, arrays bad - use an array template class, ...
There's a library (Guidelines Support Library) with implementations for those things at https://github.com/Microsoft/GSL . The reason these aren't part of the standard is because Bjarne wanted something "now" (or at least quickly), and standardizing them would take a long time, and it's better to standardize something that has some implementation already. 
You can find microsoft implementation of these classes here: [https://github.com/Microsoft/GSL](https://github.com/Microsoft/GSL).
&gt;what I had in my head was to have a browser of my own which will send a special code to my server which only then will grant access to the site (thru PHP), disable any source inspecting, and add encription between my server and the browser. my god. Are you going to build an AI and cure cancer too? It sounds like you don't have much time but you need to learn more about how web applications work as well as things like SSL to have secured connections. If you don't want to give away your secret sauce then the computation should take place server side and only display should be client side. If you have to ask "how do I do that?" Then you need to find someone who can sit with you and show you how things work. Good luck!
Took about a month for videos to make it up last year.
Any words on standardizing project layout, build system or package management?
found a copy of the original code. Some differences that do end up affecting performance: the initialization of `a` and `b` are indeed reversed vs. the original. The `swap_anyway` probability is half the original's. The original caches the number of collisions instead of calculating it every time (although this seems to make less of a difference than one might imagine.) Also when building in debug mode my version has a number of assertions that do extra work.
Take Asio + Boost.Coroutine for example timer.async_wait(yield) Internally, it will transform the yield_context object to some callback, and then pass it down to the async operation, this is what I call "register". After the registration, it'll "suspend" the coroutine, when the async operation is done, the callback will be invoked, and the coroutine will then be resumed. The point is that `await` can make sure that the coroutine is in a ready-to-suspend state before `aswait_suspend`(i.e. the registration phase) is called, so the async operation can invoke the coroutine immediately. The yield-first approach cannot provide such a guarantee. The reason I don't make it `async` by default is the same situation as `constexpr`. If the existent codes want to take the advantage, the codes must be marked as `async` manually. In reguard to why `constexpr` cannot be `async`, well, `async` is for runtime, `constexpr` is for compile-time, I don't see how could them coexist. 
You can learn them as you go, and the tools should be able to tell you the rationale for why something is discouraged, and you can learn that way. The rules are not going to be static, so there will never be a point at which "you know all the rules now" - there's no such thing. 
what you have just said is one of the most insanely idiotic things I have ever heard. At no point in your rambling, incoherent response were you even close to anything that could be considered a rational thought. Everyone in this room is now dumber for having listened to it. I award you no points, and may God have mercy on your soul. 
You're getting down voted, but that's a bit unfair because what you say is mostly true. But what's the alternative? We can't rewrite everything every few years with the latest greatest language. To me, the best course is to try to encourage best practices and high level libraries. Interestingly, and anecdotally, I'm seeing modern C++ directly impact the productivity of the team on my current project. The code programmed using all the new bits has far fewer stability and maintainability problems than the other new code that's been programmed in an older style. 
It is fairly liberal, but the issue comes when statically linking. When you're dynamically linking an LGPL-licensed software, it's all fine and good. However, when you statically link the library into your own software that's proprietary, it's forced into the LGPL license (which you obviously don't want). The only solution to that in Qt's case is to purchase the commercial license. So if you're dynamically linking proprietary software, that's fine - just not static. I think this person in Stack Overflow did a pretty concise/reasonable explanation of it: http://stackoverflow.com/questions/10130143/gpl-lgpl-and-static-linking
Can I find out somewhere what the reasons were that it got voted down?
Very interesting. I didn't know such a distinction could even be made in a license.
Anybody know if and when the video of the talk will be available?
Sure. Could you give me an example where `async constexpr` would be useful? I can't figure it out. When written in `constexpr`, you're restricted in a subset of the language that can be run in both compile-time and runtime. And `async` is for runtime only, that is, you can't use any async function in constexpr function, so I don't think that `async constexpr` makes sense.
&gt; However looking at the usual quality of enterprise C++ code bases, ... But this is not a C++ specific problem. Bad code can be found everywhere in every language. I have seen enterprise code bases in C, Java and C#, which I don't want to touch with an arbitrarily long pole. There is no technical solution, bad programmers produce bad code, no matter the language or tools. 
I agree, but given the unsafety inherent to C and C++, the problem gets extrapolated. Not only you need to deal with logical security errors, memory corruption issues add another level of complexity.
There's not much point until we get modules. If and when that gets in I'm pretty sure package management won't be far behind.
OK, I found the problem. I was thinking that `async constexpr` means `async` &amp; `constexpr`, while it should be `async` | `constexpr` as you suggested, which makes great sense. I'll update the draft. Thank you!
It's not a technical question. It's more about unifying Windows and Linux. Conflicting business interests exist.
&gt; But in C++ especially since C++11, there is a significantly lower chance to do harmful memory management, if you use the language and library correctly. Check the presentations from CppCon 2014. There you will see three major camps: - Fully embraced C++11/14, and doing cool stuff with it - Like to use at least C++11, but compiler vendor (embedded space) or company's IT/rules don't allow it - Forced to use C++, so C with classes it is and nothing else matters The last camp is what you tend to see more in enterprise code bases. Java like any other language has a runtime. C++ also has a runtime. People should stop mixing Java with the JVM, there are plenty of commercial AOT Java compilers and even Oracle is planning to add support for AOT compilation in the JDK, around Java 10+. However it is true that runtime vulnerabilities are also bad.
Works on all major OS's?
That is not really the domain of the standard, AFAIK.
Platform independent and portable will be Khronos SYCL and (most likely) C++AMP. This would be great if it could work with AMD GPUs and CPUs as well (e.g. through OpenCL).
New languages achieve nothing of the sort: those you mention, who are so stubborn, just won't switch. You'll only reach people willing to learn new things, advance. The same people that can also adapt to language improvements.
Minor nit: Foo foo(); The above is not initialization at all, it declares a nullary functions `foo` that returns a `Foo` instance. This is also known as the "most vexing parse".
&gt; However the same doesn't seem to be true for other cases, like vector&lt;int&gt;(100). Why? [Look at its declaration](http://en.cppreference.com/w/cpp/container/vector/vector), the `value` parameter has a default value of `T()`, i.e. [value-initialization](http://en.cppreference.com/w/cpp/language/value_initialization), and in the case of primitives, value-initialization performs [zero-initialization](http://en.cppreference.com/w/cpp/language/zero_initialization). &gt; Foo foo(); // x = 0 That's not value-initialization, that's a declaration for a function named `foo` that takes no arguments and returns a `Foo`. &gt; Value initialization also seems to work for primitive types. Why does no one use it? Having to repeat the type twice seems like the opposite of DRY. Herb Sutter argues for something along the same lines, but without the repetition of the type, in [GotW #94](http://herbsutter.com/2013/08/12/gotw-94-solution-aaa-style-almost-always-auto/). &gt; Foo foo = Foo(1); // Does this call the copy constructor? Why do I see this &gt; // so often? &gt; Foo foo(1); // What is the difference? I should know this, but I can't &gt; // even search for it! The first is copy-initialization and the second is direct-initialization. [cppreference.com as always has the complete details](http://en.cppreference.com/w/cpp/language/initialization), but here's a summary: Copy initialization: - is performed as if a temporary is created and then copied, so a T copy ctor is required - the copy ctor requirement exists even if the types differ â€” in that case both a converting ctor and copy ctor are required - compiler is allowed to elide the copy, so the copy ctor might not be actually called - is considered an implicit conversion, requires a non-explicit ctor - can only perform one step of conversion Direct initialization: - explicit ctor allowed - overload resolution selects the best matching ctor, including performing implicit conversion - therefore multiple steps of conversion possible: implicit to convert to the arg of a converting ctor, and then inherent to the converting ctor 
In the old days of computer programming, when all variables were built-in types (like integer and float), initialization and assignment were pretty much the same thing, so using an equal sign for initialization was okay. But in modern languages that support really complicated types (like binary trees), initialization and assignment are often radically different operations, so C++ offers distinct syntax for them.
&gt; class Foo { int x; }; &gt; Foo foo; // x maybe 0 &gt; Default initialization. Simple types could contain random values?! Default constructor is called for all members. A vector would be empty. x could be 0, or 384738374, possibly even depending on whether the build is in debug mode or not. Correct. &gt; Foo foo(); // x = 0 &gt;Value initialization. No, this is a function declaration. &gt; Foo::Foo() : x(1) {} &gt; Foo foo(); // x = 1 Same. &gt; class Foo { int x = 0; }; &gt; Foo::Foo() : x(1) {} &gt; Foo foo(); // x = 1 &gt; Foo foo; // x = 0 First one is a function declaration. Second one will call the default constructor and initialize `foo.x` to 1. Yes, the constructor wins over the NSDMI. &gt; struct Foo { int x; }; &gt; Foo foo{0}; &gt; Aggregate initialization. Used for things like arrays in the past. A type is an aggregate type if it is an array or a class with no user-provided constructors, no private or protected non-static members, no base class and no virtual functions. Phew, lets remember that... Correct. &gt; struct Foo { int x = 0; }; &gt; Foo foo{1}; // x = 1 &gt; In-class initialization combined with Aggregate initialization. C++14 only. Aggregate initialization wins? Correct. &gt; struct Foo { int x = 0; int y = x; }; &gt; Foo foo{1}; x = 1, y = 1 &gt; So this seems possible now... Yes. &gt; Foo foo(1); &gt; Foo foo{1}; // Could be initializer_list&lt;int&gt;? What if Foo(int) exists? If `Foo(initializer_list&lt;int&gt;)` exists, it wins. &gt; Foo foo{{1}}; // This seems unambigous, but apparently initializer_list wins &gt; // if both exist?! Yes. &gt; Foo foo = {1}; // Could be aggregate or initializer_list?! If Foo has a `initializer_list` constructor, it is by definition not an aggregate. But yes, this syntax can be used for both, as well as a class with only a `Foo(int)` constructor. &gt; Value initialization also seems to work for primitive types. &gt; &gt; int x = int(); // x = 0 Correct. &gt; Foo foo = Foo(1); // Does this call the copy constructor? Why do I see this &gt; // so often? It conceptually calls a copy or move constructor, but the call may be elided. The constructor is still required to exist and be callable. &gt; Foo foo(1); // What is the difference? I should know this, but I can't // even search for it! This version always constructs `foo` directly and does not require a copy or move constructor. &gt; vector&lt;int&gt;(100) // Default constructs 100 ints. `vector` by default (when used with `std::allocator`) performs value-initialization for new elements. This behavior is controlled by the `construct` member of the allocator it uses. &gt; vector&lt;int&gt;{100} // Constructs one int with value 100. Correct. 
&gt; Look at its declaration, the value parameter has a default value of T(), i.e. value-initialization, and in the case of primitives, value-initialization performs zero-initialization. That's only for C++03. &gt; The first is copy-initialization and the second is direct-initialization. cppreference.com as always has the complete details, but here's a summary: `Foo f = 1;` is copy-initialization. `Foo foo = Foo(1);` is a mix - it direct-initializes a temporary `Foo` from `1` and copy-initializes `foo` from the temporary.
That's called Most Vexing Parse, right? Totally forgot about that!
Looking at the slides, I get the feeling the C++ really needs to add a linear type system like Rust. A lot of dangling pointer, use before initialization, destroy after move, etc problems will be solved with one. Also, the slides mention some tooling support from Microsoft in October. Any idea what is in the works?
Code formatters are confused too.
That seems to be about auto-typing variables right? ... As an intro level CS student I don't understand why people would want that feature at all, it's hard enough to keep track of programs when I can clearly read the types..
Why is this in a C++ sub? 
auto is very useful when the type name is either redundant or long. For instance, if you make a vector of a type and then have a for-each or an iterator-based for loop, the loop variable's type is obvious, but typing it is long and adds coupling, so auto is useful.
[removed]
Herb Sutter expanded more on this in his talk today, and demoed with Neil MacIntosh the current version of the tool. It looks like someone just [submitted their paper](https://www.reddit.com/r/cpp/comments/3lz9y9/lifetime_safety_preventing_leaks_and_dangling/) here to /r/cpp.
Check out languages like ocaml or Haskell where specifying the type of any variable is optional and it figures out what it is based on usage. It's really nice not having to clutter up code with type specifiers everywhere.
auto is very helpful with templated c++ code. It allows you to change the return types of functions and the code calling the function doesn't care, so long as the type still behaves the same as the original type. This can be very useful in testing or refactoring when the specific type may change quickly during development, but the behavior of the type doesn't really change. 
Do they have a documentation up for their GSL? I can't seem to find one.
You seem to assume this is a finished guideline. It isn't. If you believe better examples are needed, then find some yourself and push them. If you believe a suggestion is actually detrimental in real world code, say so and back yourself up with proof. The C++ Core Guidelines are a __collaborative__ effort led by Bjarne Stroustrup, much like the C++ language itself. (that was from the first paragraph of the readme)
It's a tool intended to be used with C++ (it's described as a C preprocessor, but the examples are C++).
It probably isn't. But they write the standard so they can make it the domain. That kind of thing is part of Rust and Go's standards, or at least the language has been given some level of support allowing it to be done outside of the standard. In reality, I don't think it should be part of the actual standard, but I don't see any reason for it not to be some kind of 'extra', these standards meetings are where you get the core devs on all the compilers together in one room and other major users of C++. They can come up with something and have GCC, Clang and VS all support it then it basically would become the standard. Even if it's nothing more than officially blessing some layout as the one true layout.
I feel your pain mate. I guess its all necessary for backwards compatibility with C and previous versions of C++, but as a newcomer to the language, what a clusterfuck.
An interesting aside on pp. 26 for anyone who doesn't read the whole thing &gt; It is debatable whether the STL made the right decision in not distinguishing structure from contentsâ€”that is, failing to treat the container's own structure distinctly from the contained elements. But STL isn't alone here, and many C++ libraries have followed such a convention... The STL might be a better library if it treated `vector&lt;int&gt;` and `vector&lt;const int&gt;` distinctly; that is, the constness of the elements is distinct from the constness of the container. Then `vector` would mark `operator[]` as a const function; and a `vector&lt;int&gt;::iterator` would be allowed to convert to a `vector&lt;const int&gt;::iterator`, avoiding the need for the `const_iterator` oddity. Something to think about for STLv2. (edit: btw, in case anyone else is wondering, the "profiles" mentioned in the link are described [here](https://github.com/isocpp/CppCoreGuidelines/blob/master/talks/Sutter%20-%20CppCon%202015%20day%202%20plenary%20.pdf).)
The big upside of CSV files is that they're trivially viewable and editable in every text editor in existence, and you lose that with the ASCII record stuff.
I think they made the right decision; nobody cares that a vector (or similar scalable container) is actually just interfacing a pointer to a seperate buffer containing the *actual* data. For all intents and purposes, the identity of a vector is determined by the elements it contains. 
Can be compiled with non-CUDA compilers -&gt; runs on non-CUDA architectures.
I violently agree with you !! I know this is not a finished guideline. Better examples are needed. I did find some myself and "pushed them" by editing my post to add a link to them. I generally agree with the effort by the authors and the direction of the guidelines they are suggesting. My issue is with the examples used to support those guidelines. This may seem like a minor quible, but my instant and visceral reaction to the draft was to burst out laughing and junk it after getting to the first example. Are these guidelines some academic's personal opinion about what should be, or are they a distillation of hard won experience by industry veterans? The author list implies the latter, but the examples imply the former. These guys are literally standing up and saying "Google is programming C++ wrong". Strong evidence is needed. That's my feedback. From some random person on the internet.
I was at cppcon, I asked bjarne about the name conflict. He said they considered many names and all names had some conflict. They decided that if there are problems with this name conflict, They would deal with it later. 
It's useful for cases where you don't care the type. Iterator based for loops, for example.
Okay
Babble on, friend! And thanks for the explanation!
Wow. I heard before on Twitter that Sutter mentioned the Rust programming language during his talk. But I didn't expect him to spend the 2nd half of his presentation on the topic of lifetimes and how C++ could be made to approximate what Rust is already doing w.r.t. dangling pointer avoidance including lifetime annotations and lifetime elision rules. I'm impressed.
That's *a* vexing parse, the *most* vexing parse is: Foo foo(Bar()); Which declares a function `foo` that returns `Foo`, and takes an (unnamed) function that returns `Bar`. You need to write this instead: Foo foo((Bar()));
These are my CppCon 2015 slides. I'm happy to answer questions.
And then there's: int x = 2; Foo foo(Bar(x)); This declares `foo` as a function returning `Foo` and taking a single parameter named `x` of type `Bar`. Of course modern compilers warn about these.
They had their chance with `{}`, and it's really unfortunate that it turned out so much less uniform than everyone hoped for.
You might get more of a response doing this when the video comes out. I, for one, love watching your talks instead of only looking at the slides. Every one of them I've seen has been really entertaining and educational partly due to your personality and livelihood, and that's without getting started on your Channel 9 videos. Actually, I do have one question I can think of right now. If it's something I'll find out when watching the video in a month, then don't worry about it. Could you elaborate on the difficulty in implementing `std::invoke`? I recall you saying on here that it was "the hardest thing you've implemented", or something to that effect. The slides also mention the difficulty, and do so in a way that makes me think you didn't spend much time on that point. In my opinion, the nittier and grittier, the better.
I am starting to get lost: `owner&lt;array_view&lt;T&gt;&gt;` vs `unique_ptr&lt;T[]&gt;` vs `vector&lt;T&gt;`. I can see `unique_ptr` loosing its size on the way, but what is the difference between a `vector&lt;T&gt;` and an `owner&lt;array_view&lt;T&gt;&gt;`. 1. Because if I want to be the owner of a piece of memory in the first place, maybe I will use a `vector&lt;T&gt;` directly?`. 2. Maybe `owner&lt;array_view&lt;T&gt;&gt;` can get memory that was already reserved in some way in another library, I want to avoid copying the data into `vector&lt;T&gt;` but it still needs to be released by the caller? I think the [[lifetime]] annotations are difficult to follow. The attemp seems very nice to me: get memory safety without run-time cost, caring about backwards-compatibility. But there is a lot of baggage to it, especially the iterators part. 
Looks very promising. Thanks for sharing. I look forward to the video of the talk. 
What I mean is that in many (not all) cases bind MAY do a sub-allocation. When (for whatever reason, timer, work, etc) the marshaled data is brought back (maybe/likely on a different CPU/core) the immediate data package in 'my' routines will contain ALL relevant data in close proximity (assuming the underlying routines didn't 'punt' to the 'system' heap, and even THEN, all of the scalar marshaled data will adjacent). This is based on bind (implementation dependent) requesting more memory when the number of bytes needed to store the bound data exceeds a fixed memory block size. One fundamental tenet of this design is that ALL memory for marshaled arguments and associated containers (vtables, lambda objects, etc) is known at the 'call point' and the aforementioned objects ARE laid out in memory together. This gives the OS/CPU the MOST likely chance of having the NEXT needed chunks of data 'hot' (on cache line) or speculatively loaded. The call to async under most circumstances would be have a memory 'picture' like this: [TP/Q/ETC_OVERHEAD][delegate_v_table][delegate data][...user stuff...] With std::bind, under MANY cases the BEST you can do is this: [TP/Q/ETC_OVERHEAD][bind -&gt; data] | | &lt;who knows where&gt; | [delegate_like_store][...user stuff...] std::bind has a FIXED size and you NEED to know the entire memory picture required to store the appropriate data. (Think about a lambda that captures the state of local variables, even as references, you STILL need to save the marshaled data SOMEWHERE.) If you look VERY closely at the one header, there IS a request for memory. HOWEVER, the request is intended to be honored by the implementation in a way that is 'most best.' In the case of work on a Threadpool, that would LIKELY (the intention is anyway) be adjacent to the data (overhead) required (if any) by the TP implementation. You really can't do much about marshaling 'complex objects.' But you CAN keep the 'restart' data close (the first few chunks the CPU HAS to 'fly through' to get to the meat of the work). Who knows how long it would take. These routines don't know, nor does bind. I also like the syntax better, but that is 'opinion'. Is that clearer? (I'd give $$$ to be as eloquent as Mr. Sutter. :-( )
Nice work! I would enjoy that series very much!
I am old enough to have seen this (legacy data). **That's not funny, don't snort your coffee there!** ;-)
Do you have any numbers regarding performance? how does it compare to Spirit ?
No, I mean classes. For a simple example, in python you can do: class Foo: def __init__(self, num, ch): pass map(Foo, [1, 2, 3], ['a', 'b', 'c']) # [Foo(1, 'a'), Foo(2, 'b'), Foo(3, 'c')] Using a class where any callable is acceptable is very common in Python - in fact, in many cases, the APIs are *documented* as taking a class even though any callable will work.
Shao Voon Wong this is possibly one of the worst examples of modern C++. 
I don't know Python, but I think I understand what you want. I'm guessing it's a tiny helper, maker&lt;T&gt;. This would be a variable template (so you don't need empty parens), which is a function object. Its function call operator takes an arbitrary number of arbitrary args and perfectly forwards them to construct a T, which it then returns. You could then binary transform() with maker&lt;T&gt; to construct T(elem1, elem2).
I admit it is not modern C++. It has 2 features which normal CSV library do not have. * It can support user-defined types as long as you define the custom stream operators. PODs (like int and float) is supported out of the box(not need to do your own data conversion to and fro from strings). * It support changing the delimiter halfway parsing. Because of this, I have written 3 file parsers based on this library. Normally to write a Wavefront(*.obj) file parser, you need half to one day. With my CSV library, I wrote the obj file parser in half hour. I have added the escape/unescape functionality.
Lovely article. Very nice examples that show the nuances between different implementations and interfaces.
&gt; I've been thinking about filming a "Hyper-Advanced C++" series delving into this implementation and others. Yes, pretty please! :-)
Thanks!
I'm glad people like you exists who have the skills to conjure black magic STL features for everyone else to use. Looking forward to the presentation video once it's out.
Yep that was one reason why C++ lacked nice libraries alongside the code C with a C++ compiler mentality. C++98 already had the ability to code nice developer friendly libraries/frameworks. 
but that's not a wrapper object, but a plain PMF which should be inlineable.
What is your opinion about using **auto** keyword as much as possible? Why is: *auto v = load_shapes();* better than *vector&lt;Shape * &gt; v = load_shapes();* ? With the second construct, I can immediately see that I am getting vector of pointers to shapes. With the C++14, I shouldn't care what I get?
Competition is a good thing :)
[here](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4128.html#algorithms-should-take-invokable-projections) you can see the example with passing a PMD; and in the linked proposal, in 24.3.2 you can see `mem_fn` used in `__as_function`, which is later used: [ Note: Projections and predicates are typically used as follows: auto&amp;&amp; proj_ = __as_function(proj); // see 24.3.2 auto&amp;&amp; pred_ = __as_function(pred); if(pred_(proj_(*first))) // ...
I first thought it would be straightforward with expression SFINAE, a la [cppreference's "possible implementation"](http://en.cppreference.com/w/cpp/utility/functional/invoke#Possible_implementation). Then I realized that that implementation doesn't correctly handle a bunch of corner cases. Ugh. Great work.
I am a bit ambivalent about it. Sometimes you want that extra detail right there but other times its nicer to abstract away the redundancy. For code that I am familiar with I prefer the auto version but when reading someone else's code I am likely to prefer explicit types. As other posters are implying good tooling can give you the best of both worlds.
&gt;Your point was that string versions should behave the same as integral types, No, that wasn't my point. My point was that `string x{""};` should generate the same code as `string x`. The integer example was a parallel case demonstrating that it is easy to implement. The C++ standard says that `string x{""};` and `string x;` have identical behaviour; if a compiler treats them differently then the compiler must be generating sub-optimal code in one case.
For the third time, I was talking about the `string x = "";` version. Yet somehow you manage to mix things around and say we're comparing `string x;` with `string x{};`
No, that's not what I said. Read my last comment again. 
Simply amazing. 
I wrote a quick sample of STL's idea: http://ideone.com/Gye8zg
I... what. Boggles the mind. Not that I'm criticizing, far from it. I'm struggling to find a language that will allow something even approaching the level of sliding up and down the computational ladder like this...
Glad you liked it! Yeah, I had to select the highlights to fit it in an hour. I probably had a few more slides than ideal, but I couldn't find anything to cut. And that was after omitting most mentions of the transparent operator functors, and all mentions of hash (which technically lives in &lt;functional&gt;, but really belongs to the unordered containers).
And if you want to omit the parens, add this: `template &lt;typename T&gt; constexpr maker&lt;T&gt; Maker{};` Then you can pass `Maker&lt;foo&gt;`.
You're right, this may not be completely kosher with respect to the ODR. (The Standard primarily uses constexpr objects as pure tags, but maker&lt;T&gt; would be used as a function object.) I wish that the rules could be changed to permit more of this, somehow.
Yes, that *works*, but it's noise. I can write both of: *dst = Foo(a, b); // class *dst = foo(a, b); // function but I have to write: *dst = invoke(maker&lt;Foo&gt;, a, b); *dst = invoke(foo, a, b);
[The guidelines url.](https://github.com/isocpp/CppCoreGuidelines)
I'll be there taking photos. Be sure to say hi to a former Bronco. Look for the girl with blue hair and a camera!
When I hear all this breathless reporting of this datastore or that I usually check it out. The second I see that some halfwit wrote it in Java I move on. Not only will it be slower than it needs to be but in all likelihood the developers will have lost the plot somewhere else. Thus the datastore is probably being hyped by some company and at best is filling a need that another product will come along and do so much better. 
I'm loving The Wonderlands, but I'm extremely confused why this is on /r/cpp hahah
I am going to come out and say something really nasty. Science proceeds one ... C++ has gone off the rails. It is time for this "guru" and his boomer academics to stop telling us how to use C++. This is not how the code being used in billion dollar products is done. If you look at the code that drives games, operating systems, and highly successful Open Source projects like MariaDB none of this crap is in there. The code that non-academic programmers is doing is clean, fairly free of templates and even exceptions and can be maintained by someone with fairly basic knowledge of C++. The code that he is writing is far too abstract and I don't know what problems he is solving. Each one of his core arguments is pretty much instantly shut down by the fact that few C++ programmers could then follow the code written as he suggests. One of the original beauties of C++ was that you basically constructed your own "programming language" as you went along. So you ended up with code that looked a bit like(minus error handling): UserList *users=UserList::GetUsers(); User user=users-&gt;addUser("Billy Bob"); user-&gt;setRank(CAPTAIN); user-&gt;sendUserToVietnam(); And at a glance we could see that a new soldier Captain BillyBob was sent to Vietnam. Not any more. That is terrible code there. Whoever wrote it should be shot in in their template free face. There will be hue and cry about every single line. Yes an auto is good, some kind of smart pointer might help, and so on. These are fine improvements. But what Moon child keeps talking about is enforcement. I suspect that this is a slow but steady push to make the leap of where you write code his way or the compiler is minimally going to start complaining, or worse start erroring out and saying "ERROR: to make this code compile you must set the --OBSOLETE flag." The key to C++ is that I can write code how I want. This is its strength and its virtue. But to have a generation of academics going out and shitting on everyone's code is going to drive the people who build large very valuable systems away from the language. A perfect example of this would be Python. 2.7 was a thing of beauty. It needed a few fixes such as unicode string handling and still needs multithreading of some real sort. But it was the culmination of the whole Pseudocode as programming language. Then in 2008 Python 3.0 came along. It didn't really come of its own until about 2009 2010. But then I sensed a sea change among the top "gurus" suddenly they started to wander far away from Pseudocode and redefined the term "Pythonic" suddenly pythonic meant "To pack as much shit into a single line of code as possible" Suddenly people were writing things where they would say, "Look I have built a backpropigating neural network in 8 lines of completely unintelligible code." and calling anything less "un-pythonic" Well if you look at the graph of python's market share it is shrinking. If you look at C++'s graph of market share it is shrinking. If you look at C's share of the market it is high and steady because nobody is assholing it. If you look at Javascript's share it is taking off because KISS is very much the rule of the day with javascript and people are choosing to shove it into every nook and cranny of the programming world. Why aren't they shoving Python into these nooks and crannies? What C++ needs to remember is that every day there is a new batch of young programmers who are asking, "What language should I learn?" to a certain extent they will be influenced by their elderly academic professors, but to another extent they will be influenced by the existing community. I am hoping that Stroustrup realizes one day that he should drop strutting around on stage saying, "Look at my academic haircut, look at my casual clothing, I am the only guru that you should be listening to and you all are dumb." and go farm mushrooms or something in his dotage. If he quits the world of computer science then maybe, just maybe C++ won't continue its long slow slide into oblivion. For now it might be respectable, but a day will come when more and more critical libraries and SDKs are not C++ compatible and like all the programmers who adopted Objective-C because of its sudden relevance to their day to day goals they won't leave C++ because they hate it but because there are other better choices. So while I am personally getting sick of what C++ is becoming I still haven't crossed the line into some other greener pasture. But I am looking very very hard. Quite simply the original idea of improving C by making C with classes was brilliant. Many of the improvements since then have also been awesome. Standard implementations of things like maps, vectors, iterators, the wonderful new for loop iterator. Those are all brilliant. But the philosophy surrounding all this is terrible. When I hear how Linux has so strongly rejected C++ I wonder if the rejection is the language or the baggage that would come along with a sudden influx of academics telling everyone in the Linux world that they are dumb and doing everything wrong. Maybe Linus realizes that this baggage would kill Linux dead in its tracks. 
Please don't take this the wrong way, but it seems you've gone out of your way to find the worst and most inefficient usage of Spirit and then run a benchmark against your library. A simple google on the topic would have given you something more reasonable: https://github.com/miloyip/nativejson-benchmark That said, this discussion is about CSV files and not JSON. Would you happen to have CSV processing benchmarks? 
PEGTL also forces you to write parsers which are so confusing that if someone else looks at them they have no clue WTF your code is supposed to be doing.
Tell your customers to not export in CSV ;) 
You are making very good points, but I must ask though: Did you watch the keynote?
Yes and read his Enforcement guide. I can see the disappointment when he labels something "Unenforceable" 
My assumption is that one of two things would happen. One is that some code down further. Or two it is a singleton that lives for the life of the application because the application is called something like "User Master Ultimate" and that is all it does. oooooh singletons, another thing his highness wants eliminated. 
Point is, without enforcement of rules the only way for me to know it, is to track all usages of pointer myself.
Actually I find it highly disrespectful of you to post a link with my name and the 40x claim after I explicitly asked you to not quote me on the benchmark since it was the result of about 20 minutes of playing around and I made it quite clear that I don't trust these numbers yet myself. I didn't have much time, and for the heck of it I took the first random JSON library with a Spirit parser and did a few simple benchmarks. (Actually it was the third, the first two didn't work correctly).
You make some good points, but nobody's changing the language so you can't do what you've always done. I'm a supporter of the guidelines because I have to work with a big team, and I want everybody on the team to understand the modern, safe, canonical way to do things in c++.
In this scenario there isn't one. Its an annotation for legacy api's where you can't use `unique_ptr`.
You do realize we are developing the PEGTL in our spare time and are giving it away for free? If you want a benchmark, how about being more constructive and do it yourself? Or if you think the PEGTL is not for you, that's fine, just move on. We still think that some people might find it as useful as we do, though.
Enforcement... you act like this is such a scary word but many devs employ enforcement already. Compilers have different warning levels, with the ability to treat warnings as errors. This is enforcement, and it can be turned off. Static analysis tools that run alongside builds, these provide even more enforcement. Code lint tools, these are even stronger levels of enforcement that can ensure coding standards are followed. All levels of enforcement and all are optional. You come across as a person with a serious problem with Bjarne rather than the language. Constantly calling him names severely detracts from your credibility. Who are you to judge? The only example of your code is a pretty crappy one at best. You have incredibly weak arguments here, mostly based on the assumption that apparently Bjarne is some kind of dictator and all the compilers are suddenly going to force you to write C++ code his way and no other way. What a load of crap. Go back to C if that's what you love so much, or keep writing the kind of C++ example code you posted where its not possible to determine ownership by reading it. Nothing is stopping you. What's being presented is the equivalent of a future compiler warning level that anyone can turn off (or on, who says it will be on by default on every compiler) if they feel like. Don't like how things are done? Join the committee, because that's how things are decided. It's not Bjarne deciding on how everything must be, he couldn't if he wanted to because that's not how an ISO committee works. It's a group effort.
On slide 30: I'd like to see some details on the performance problems. At least a [quick test][1] doesn't confirm it (clang trunk with -Os), so I'd like to see some code that does show the problem. In any case, if a solution is more clearly expressed in terms of the concept of binding, then choosing lambdas for performance prior to profiling and determining that the substitution is helpful (if there are even cases where that's true) is premature optimization. I think it's a stretch to say `std::bind` syntax isn't 'normal C++'. Obviously it's using normal function calls, etc. It's using the same core language features as everything else. The author is clearly talking about 'style', for example how some C++ code is OO heavy and uses deep object hierarchies, or how some code is just C with classes and uses raw pointers everywhere and RAII nowhere, or how some C++ code is basically lisp. What 'normal C++' is differs vastly between programmers. This is one of those areas where you can't just say "C++ is one thing" and "This is how everyone uses C++." For some programmers, their 'normal C++' means functional programming and using higher order functions like `std::bind`. About that surprising behavior of immediate vs. delayed calls: What the author is talking about is how `bind(foo(), bar())` calls `foo()` and `bar()` immediately, rather than only calling them when the bound object is invoked. I just want that to be clear, because I think most people that know C++ won't actually be surprised by that. The only way they'd be surprised is if they've been convinced that `bind()` is somehow not using normal C++ syntax. In all normal C++ syntax, function arguments are evaluated before the function is called, and `bind()` is no different in this respect. As for the surprising behavior of passing arguments as lvalues, it's true that there are probably various reasonable choices here and that the actual choice used by `std::bind()` does need to be learned. Any of the other choices would produce equally, if not more, 'surprising' results in some circumstances. The same is true of lambdas, and the way I've explained `bind()`s behavior before is that bound arguments are effectively the same as lambda captures. (Though of course one might be surprised by the behavior of lambda capture lists too...) There's a [proposal][2] to expand `std::bind` with some new functionality that discusses [some trade offs][3] between `std::bind()` and lambdas and is worth reading. --- Slide 34 shows a perfect example where `bind` more clearly and directly expresses an idea than using lambdas. The lambda is explicitly avoiding all the default lambda behaviors: auto d20 = [urng = mt19937(1729), dist = Dist(1,20)] () mutable { return dist(urng); } It's making extensive use of the capture list in order to get immediate execution instead of delayed execution, it's using `mutable` because it needs to modify it's internal state, and it's important that that internal state be passed as an lvalue to the distribution. What's going on here is that we have a function object `uniform_int_distribution&lt;&gt;(1,20)` and we're modifying it by binding its parameter to a particular object. This idea is expressed so much more clearly and directly with `std::bind`. auto d20 = std::bind(Dist(1,20), mt19937(1729)); Note that the value here is not terseness (or not entirely anyway). The value is in the fact that the concept is expressed more clearly: we're operating on an existing function to produce a new function whose behavior differs according to a common and widely used pattern known across many languages as 'binding'. Using `bind` as shown above is a far better representation of this concept than the earlier lambda, which requires one to think harder in order to figure out the pattern. This is similar to how a use of `std::accumulate`, for example, is a much clearer and more direct expression of an idea than using a `for` loop to do the same thing. A `for` loop is a general tool and one has to figure out which of many possible things any given `for` loop is doing, whereas `accumulate` does one specific thing. Even when the `for` loop is more compact, `accumulate` is still generally the better choice, because it's the clearer expression of the idea. [1]: http://pastebin.com/nZzdbxak [2]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4171.html [3]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4171.html#appendix.bind_vs_lambda [4]: http://www.n-a-n-o.com/lisp/cmucl-tutorials/LISP-tutorial-11.html
They are just summarizing what we've seen in various code bases. And work on the tools that will check that. He also explained why not make another language instead. Overall, sudden activity in the C++ area is caused by the barrier for the performance growth. So, the business wants them go on stage and talk about something.
We don't have to prove anything. We are offering a choice. We wouldn't even compare the PEGTL against others, if is wasn't for people constantly asking about a comparison. In this case, it was you asking. Colin decided to spend some time on doing a very first and rough benchmark, using JSON instead of CSV since that seems to be quicker to do. And he was as surprised by the 40x difference as you are - and he explicitly pointed out that this is not really something to trust. You then when ahead, ignoring what he wrote as a disclaimer, and pilloried him (while you are hiding your real name). And now you continue by implying that he was looking for the worst example he could find, which is just insulting and tells more about *you* than about Colin. Regarding Boost.Spirit's authors: We are well aware of Boost and the people involved and I can assure you we have the highest respect for them and their work. Not to mention that I'm a Boost developer and maintainer myself, although not very active in the last years. Nevertheless we know that Spirit is much more powerful than the PEGTL, it is just that sometimes you don't need all that power and you can't afford the dependency on Boost within your projects. Especially since a lot of Boost's work ended up in C++11. The PEGTL is using a different approach in some areas, which might be good, bad, better or worse compared to Spirit or others. This is choice, this is how progress is made and maybe we can learn something from Spirit while keeping our focus and our goals. Maybe even Spirit might learn something from the PEGTL, who knows. As a final note let me ask you what you have done. Any projects that might actually help someone? Anything constructive from you to look at?
I am more fearful of the people who turn these ideas into a religion. I have met people who would pretty much throw a physical exception if you didn't really like exceptions. I have met way more people who thought that exceptions were an exceptionally bad idea. It becomes religion not an opinion. The concept C/C++ sends some people into a full on rage. They say that if you can't pick one that you are a big fat amateur loser. I have been on large teams where the coding standards were few and most involved formatting more than how things were built. The teams where they started to enforce the how is where there was one guy who was enforcing his standards because he was so obsessed with other people doing things his way that he corralled the standards into his little kingdom. Any arguments about how everyone should have input were met with "too late". The result was a massive turnover of staff except for a small number in his little treehouse. Over the years one of my favourite religious wars was over the concept of XHTML. I thought that this was about the stupidest idea in my programming lifetime. Every now and then I dance a little jig on the grave of XHTML. XHTML was all about rules and the enforcement of those rules. To no real world purpose at all; yet the advocates of that insanity were insisting that all browsers by year X would only consume XHTML compliant code. I wouldn't be surprised if in some dark corner of some government or massive organization there is some head of development insisting that all code be code checked for XHTML compliance. I just see a generation of programmers looking at C++ and going, "Screw that hidebound language." Just like a new generation of network admins looked at Novell and said, "Screw that hidebound system." and went with the happy go lucky Linux or the learn in 5 minutes NT. It doesn't take much. Unity has gone with C# and a sort of Javascript. If all the best tools and libraries start to drop C++ because of new programmer uninterest then C++ is dead. 
In good clean code this should be easy and thus overdoing it then makes for less clean code. In those cases where the pointers are dancing about then more complicated means are needed and then more complicated C++ can be brought to bear. It is getting to the point where some are saying: int i=0; is bad. That is insane.
I think 3) is wrong. It looks like `owner&lt;array_view&lt;...&gt;&gt;` has the same effect as `owner&lt;T*&gt;`: &gt; As a future extension to help C-style code, we could also consider providing some malloc compatibility along the following lines: &gt; &gt; ... &gt; &gt; m_owner&lt;array_view&lt;X,M&gt;&gt; p = malloc(N) is legal iff sizeof(X)*M&lt;=N and ...
Have a look at the [ABNF-converter](https://github.com/ColinH/PEGTL/blob/master/examples/abnf2pegtl.cc) I wrote as an example. It takes a slightly extended ABNF input and generates a PEGTL-grammar from it, ready to be used. [Example input](https://github.com/ColinH/PEGTL/blob/master/examples/abnf.abnf) which is hopefully readable enough: ; grammar for ABNFs taken from RFC 5234 + RFC 7405, ; slightly adapted and extended to PEGs rulelist = 1*( rule / (*c-wsp c-nl) ) rule = rulename defined-as elements c-nl ; continues if next line starts ; with white space rulename = ALPHA *(ALPHA / DIGIT / "-") defined-as = *c-wsp ("=/" / "=") *c-wsp ; basic rules definition and ; incremental alternatives ; different order due to PEG elements = alternation *c-wsp c-wsp = WSP / (c-nl WSP) c-nl = comment / CRLF ; comment or newline comment = ";" *(WSP / VCHAR) CRLF alternation = concatenation *(*c-wsp "/" *c-wsp concatenation) concatenation = predicate *(1*c-wsp predicate) predicate = ["&amp;" / "!"] repetition ; extension for PEGs repetition = [repeat] element repeat = (*DIGIT "*" *DIGIT) / 1*DIGIT ; different order due to PEG element = rulename / group / option / char-val / num-val / prose-val group = "(" *c-wsp alternation *c-wsp ")" option = "[" *c-wsp alternation *c-wsp "]" char-val = DQUOTE *(%x20-21 / %x23-7E) DQUOTE ; quoted string of SP and VCHAR ; without DQUOTE num-val = "%" (bin-val / dec-val / hex-val) bin-val = "b" 1*BIT [ 1*("." 1*BIT) / ("-" 1*BIT) ] ; series of concatenated bit values ; or single ONEOF range dec-val = "d" 1*DIGIT [ 1*("." 1*DIGIT) / ("-" 1*DIGIT) ] hex-val = "x" 1*HEXDIG [ 1*("." 1*HEXDIG) / ("-" 1*HEXDIG) ] prose-val = "&lt;" *(%x20-3D / %x3F-7E) "&gt;" ; bracketed string of SP and VCHAR ; without angles ; prose description, to be used as ; last resort 
This exactly the response that I get when discussing Python. PEP. But I am not on about any given language construct. For instance templates are great. If I ever had a specific complaint about templates it was the whole &gt;&gt; confusion; which has been solved. My complaint about templates is not their existence or their syntax; it is the culture behind their use. A critical mistake made in software development is premature optimization. Yet people insist on templating the living crap out of pretty any class they write. Why? In many cases the class will be used in exactly one way. Templating willy nilly is premature optimization plus it makes the class more confusing to read/use in most cases. Then there is this push for shorter functions. Why? I have read studies about the optimal length of a function and it is actually quite long. Then I realize that most people who are advocating shorter functions are mathematicians and have a whole different idea of what a function is and that short functions suddenly become "provable". But beyond some unit testing this is not the goal of the software developer. Basically, C++ philosophically is becoming a computer science language instead of a computer engineering language and certainly far away from a hacker's language. I think we have enough Lisps and Haskells to keep the mathematicians happy. 
Something I never really understood is when Java folk say "well actually Java is basically as fast as C++ code once it has been through JIT/AOT compilation" but that never seems to be true in any real world applications, only in very specific benchmarks. 
Funny that you take ScyllaDB's word for it. The reason this code is faster isn't because of C++, it's because of the shared-nothing approach and low-latency networking capabilities. 
In as much as any native code can be run using JNI which has its own overhead. It is painful to write or debug JNI though.
C++ leads to really, *really* bad design decisions. You can read Linus' rant on it. Zero-copy I/O is actually really common with Java now.
Even if you disagree with this guy, please don't downvote him. Discussion is good. Opinions are good. It's *GOOD* to have to argue your points. It makes you understand things better.
His rant applies to Java too, you know that right? He was ranting about OOP design.
&gt; I'd like to see some details on the performance problems. As you'll see in the video, I mentioned that VC's optimizer is incapable of seeing through the data member and performing inlining. When I asked, they told me that it was a pretty deep limitation and unlikely to be improved soon. If LLVM can optimize this, great! But mem_fn() still doesn't have portable performance across the major compilers. &gt; premature optimization. I disagree. Avoiding unnecessary pessimization is also important, and functors given to algorithm inner loops are likely to matter. Using a lambda involves no additional *conceptual* complexity, only some verbosity. &gt; I think it's a stretch to say std::bind syntax isn't 'normal C++'. Especially when nested bind() is involved, it is completely wacky. For example, I reviewed someone's code where they accidentally messed up what would have been `A &lt; x &amp;&amp; x &lt; B` in ordinary code. In bind()-ese, the syntax was different enough for the bug to be less obvious. &gt; What 'normal C++' is differs vastly between programmers. I'm not talking about that. What I'm specifically referring to is how expressions behave. The way you have to write bind() is a contortion of how you would write an ordinary expression. &gt; I think most people that know C++ won't actually be surprised by that. Well, Scott Meyers was. As I mentioned in the video. This stuff catches experts off guard. &gt; bind(Dist(1,20), mt19937(1729)) Yes, this is more terse. It's probably (unintentionally) the best case scenario for bind(). I still argue that bind() should be avoided. Programmers already need to learn how lambdas work, since they're used everywhere. Programmers should not also need to learn the bind() protocol, with all of its twists and turns, because it just doesn't buy enough to be worth the complexity cost. (In fact, some of the lambda verbosity is a feature; the mutable nature is unusual for a function object, and deserves prominent attention.) I'm stopping short of saying that bind() is the worst evil and should never ever be used. I even warmed up to it a little after reimplementing it and fully understanding how it works. If you have a comprehensive understanding of bind() *and so does everyone else who will ever have to maintain your code*, then go ahead and use it. But I can't recommend to general audiences, even of skilled programmers, that they should use bind().
Yeah page 28 is a total copy attempt of rust lifetimes, even the syntax. I still don't see how they'll fix STL iterators though. STL collections need to be burned and redone. [edit: I see he has another paper going into STL iterators. ambitious. And he has a blurb about "something to think about for STL V2"]
RDMA is point-to-point though... Intel DPDK is basically an ordinary NIC remapped into user space. Do you know if anyone has made Java bindings for DPDK?
Precious to anyone who thinks a programming language can't make use of new hardware just because it runs inside a VM................
That's the point. C++ gives people the flexibility to do *very very* stupid things that are still legal. You should read his rant on it. C++ is a terrible language. 
I do use it. I have to edit code written in C++. Some of them are good, i.e., LAMMPS. Others, not so much. The good ones didn't have anything that could be done in C, anyways. 
Wait, aren't variable templates ODR-safe?
Here is the first one: [Bjarne Stroustrup â€œWriting Good C++14â€](https://github.com/isocpp/CppCoreGuidelines/blob/master/talks/Stroustrup%20-%20CppCon%202015%20keynote.pdf)
Hmm, they do have that "selectany" behavior. That makes them different from ordinary constexpr objects, I think. Honestly, this area of the Standard hurts my head. I can understand the Standardese, but I have to look through it every time, instead of intuitively remembering it.
You are way too invested in this, and it is shameful that you are trying to bring someone down when they are just working on their own project and not making any false claims.
Ok, il feels weird though because the problems you are ranting about are precisely the problems these guidelines tend to try to address. Like in your example, even though using raw pointers as array containers will probably always be frowned upon, the guidelines allow you to use them safely as reference to an actual object, so I guess the last three lines of your examples, which are error-prone, will be safe without the need to add an additional layer of code (not in that part of the code, and not real code anyway, just). So yeah, you seem to be saying that what Stroustrup is trying to do is stupid, whereas you rather mean, if I understand correctly your points, that he will likely fail. You should find another argument than a fancy haircut to convince people that he will fail.
The slides are pretty terse, have to wait for the video to grasp the message.
&gt; just how much of a performance difference are you talking about? As far as I'm concerned, inhibiting inlining is doomy doom doom. &gt; it's not really unintentional that I'm pointing out a best case scenario for bind(). What I meant was, it was unintentional that my d20 lambda was more verbose than a binder. I didn't consider using bind() for it, since I never engage the bind() logic in my brain unless I have to. (Having a full implementation of bind() in there is scary.) &gt; I think you're giving far too much weight to those 'twists and turns'. Well, I've seen enough of them in my day job to conclude differently. Having Herb call me into his office to explain why bind() couldn't bind a unique_ptr was an enlightening experience. (As I mentioned in the talk, I knew the answer, but only because I had been personally burned before, with the "grand theft bind" regression.)
The haircut comment is part of my complaint that academic programming and commercial programming basically take place on two separate planets. People on his planet have hair like that. He is a dyed in the wool academic. Check out his web page. 
Yeah I don't agree with that. Smart people can understand both world, even when they belong to one in particular, and this one person appears to be pretty smart, to my standards at least, and gives a lot of attention to the commercial programming world. The fact that he is technically part of the latter, being an employee in a big commercial company, gives me reason to believe that he is not the clueless alien you depict.
Have you also bothered to check that most of those games were full of anti-patterns? Minecraft is a good example of a sh*t pile of Java code quality.
The examples given in this talk are really great! Unfortunately, they also show how much complex C++ is. Nowadays C++ becomes almost undebuggable, so I think this language is dead. Except for a small group of people who like to spend a huge amount of time in writing one class. During two minutes, imagine a low level programming writing bad modern C++ and then imagine that you have to debug that code! Welcome to the real world! 
I'd advise you to stay away from legacy C++ applications, especially on Windows. They are not so fun to work on, and the code style is miles away from the modern C++ we love. I'm maintaining a C++/COM/VB6 legacy data driven modelling application as my day job. I choose any modern technology with decent tooling above the Microsoft configuration window mess and old school C++ style. Yes, even javascript.
If you provide something for free, nobody would spend money to reverse engineer your code. Especially not if it is minified javascript. Unless if your product doesn't do what it needs to do. But then it probably would even be cheaper to just rebuild it from scratch. Please remember that you'll need to maintain the beast you are producing.
Bjarne's talk is up at youtube.com/cppcon...I would keep checking there to see if they upload the rest of the talks.
I'd tell you but I don't want the competition For reals though, you're going to have to show you can do it before being let do it So build something, or get involved in an existing project, even if it's only documentation until you figure it out. I wanted to get into C++ so I built a cross platform build tool, now I don't need make or visual studio
The problem is that "most of the time" is a non sense in software maintenance. "Most of the time" must be considered as "never" and so everything should be checked. 
I'd upvote you more than once for that if I could.
&gt; You need to use SIMD or AVX instructions to have better performance. you know that C++compilers are able to use SIMD and even AVX without you doing anything, right ? http://goo.gl/9di6Wa Look at line 50 &amp; 53 of ASM
wow, awesome!!
&gt; You need to use SIMD or AVX instructions to have better performance. So roughly, C code may be faster, not C++ First, you can use SIMD just fine from C++. Second, there are all sorts of things that you can do in C++ that you can't in Java, mostly regarding the memory layout of objects. Some of the more basic changes that one can make (or just happen) are less space used on object metadata and references, stack allocation (which escape analysis does not fully replace), and less indirect references (one can pack objects in an array, class, etc without having to hope the GC puts them close in memory. You can also get more advanced and put stricter controls on memory management by using custom allocators, thread-local allocators, controlling when/how threads can access each other's data (which a GC makes pointless). And that's not even comprehensive, there's plenty more that C++ (or C, Rust, kinda D, etc) offer that simply isn't available in Java.
This made me think, has anyone created library that assembles a string and writes it to a byte buffer ( and possibly wraps it with C linkage )? I realize it would just be a matter of taking pieces of a standalone programs like nasm or fasm that already exist and putting them into a different form. Surely someone has done this?
After a little thought I have to say that more and more I'm thinking that any modern language should ideally have a very explicit compile time metaprogramming aspect that isn't incidental like C++ templates. I think modern macros in things like rust are too separate from the language itself, and separate from issues of types and templating. C++ templates are powerful, but far from intuitive for anything non-trivial. It seems to me that ideally you would write in templates more often than not, with a separate syntax for dealing with checking and modifying any and all compile time data. I see things like this, parsers, and even the idea of small kernels that could use SIMD more effectively like ISPC, and it makes me think that we really haven't hit on the sweet spot of power and simplicity yet. 
You pretty much need to know which library defines that function. If it's a popular library you should be able to Google it. Also make sure you have downloaded the relevant libraries and are compiling with the relevant flags
I think transcript+slides are what you're looking for. 
Do you have something to say *about* the code that's not necessarily represented on the slides? Code examples are good to support a technical nuts and bolts talk (which I imagine is the kind you give?), but you'd be wasting (precious!) slide room by annotating them with what you're saying about the code. Abstract talks can get a lot further on general diagrams where code would just be a distracting detail.
They are one part of a whole presentation. The sum is greater than the parts, yaknow? Ideally slides are used to visually describe something or be a supporting object to a talk. If there is too much detail they can become a distraction as the audience focuses on them instead of the presenter who can react to the audience. Kind of like demonstrations in physics class. If you only saw the setup you wouldn't get much out of it until the professor starts talking about it and fiddling with it.
@penguindev: I hear that "they copied XYZ" about most features of most languages. You should see how many emails I got complaining that C++11 stole "auto" variable type deduction from language XYZ, when language XYZ was invented in the 1990s or 2000s and Bjarne first implemented that syntax in 1983 (and there were still older examples in other languages). Also see "Java invented GC." :) Seriously, before I did this design I deliberately didn't look at Rust (other than hearing the word "borrowing") or Cyclone or CCured or other efforts, because I wanted to maintain my fresh perspective of the problem as long as possible before being too exposed to paths that others had followed and then starting to think in those grooves. After I got a design I was satisfied with, I then looked at Rust and a few other efforts as a sanity check to see if I'd missed any opportunities, and saw some similarities and a lot of differences with the other work. Similarities include that Rust came up with similar return lifetime deduction rules -- that's not surprising, because it's generally true that functions return results based on their inputs, so it's natural that we independently observed that's true also when the type is a pointer. Differences include that Rust seems to need a lot of annotation; for example, I'm not sure why there should be any need to provide additional syntax to invent a name of a region (as both Rust and Cyclone do, for example), when every local variable and parameter already has a well-known scope/lifetime and already has a name, so we can just use its name to denote that scope/lifetime. Also, there are some other usability questions such as that it doesn't seem to allow reusing local pointers as easily (but I could be misunderstanding, I haven't actually looked at Rust in detail). Another is that I'm not sure whether Rust generalizes to treat user-defined Pointers (such as iterators, ranges, etc.) uniformly with raw pointers. And of course Rust's goals were different, including data race freedom (also of interest to me but not part of the initial target; a 'concurrency' profile will likely come next). Rust and Cyclone and others are good work. This is a very hard problem and having lots of people keep working on it is a good thing and appreciated, and I hope to be educated about how I can improve this design by learning from what others have done. Please send mail or open GitHub issues! Thanks.
My code slides are almost always devoid of comments, and I explain them out loud. Generally I can barely fit a fully worked example.
 &gt; you have to do is avoid using objects, and do everything with primitives and primitive arrays. This is what you have to do with ANY language. There is no mystery behind performance. &gt; In the real world, being able to eliminate the object allocation overhead (monitor, vtable, plus the pointers to the object) and indirection (since all objects are pointers, you need an additional memory fetch (100 ns if you hit main memory, which is very easy with the way Java uses memory) to access every single object) matters a lot. I disagree. Nowadays the PIMPL design for instance costs nothing. In any case it does not matter A LOT as you say 
You are quite right about two things (if I may paraphrase your post slightly): 1) The majority of real-world code (and coders) are worlds apart from the big names in C++ (I mean committee, bloggers, etc). 2) There does seem to be relationship between a persons enthusiasm for learning about the language itself and becoming fixated on 'the one true way'. I love C++. I watch talks about it. I read blogs about it. I code in my spare time. I read some communications we receive from the planet on which those into functional languages live. But I'm now middle aged. I've seen many many codebases over the last 15 years of my career. For every blog posting showing the latest template wizardry which doesn't yet build under Visual Studio, someone is submitting a const declared function which modifies and uses a global variable in calculating its output. For every job which should just be a simple free-standing function, someone is 'cleaning' it up to be a heap-allocated virtual-interfaced factory-constructed object taking the storing the function parameters like a function object with capture, except for not having the operator() to let me call it like one. Suffice to say that the real world environment, as is my experience, is a mix of people who prefer a 'C with classes' style of coding and those who have cottoned on to some architecture style and enforce it with all the minutae. Possibly some have heard the jokes about the C++ code which used #defines to make it look like another language? I have worked on such a codebase in the past. One (informal) test I did based on the GSL was to take the example of array_view - what it was replacing - and ask someone how they might do it. The reply was that they didn't really see what the issue was to begin with (which in part explains the answer) but just make it a struct. A struct with 2 members: the pointer and a count. Now look at the 2288 lines of code for array_view in GSL. Just about every programmer who reads reddit cpp is going to be going 'but but but!'. BUT what I want to point out is that in my experience, the majority of people who are full-time employed as career programmers working primarily in C++ would: - not see/recognize the issues raised by the more 'academic' people - would certainly not solve them in the same way - would not use nor understand the set of language features needed for a full solution - actually get upset seeing code like that, EVEN if they dont have to ever debug it For full disclosure: a significant portion of my career has been in the games industry. While I used to think it had its own kind of 'programmer culture', I'm not so sure now that I have left it.
They already have. They disapprove of your behavior.
&gt;If you want performance with any language, the same set of rules applied: for instance, try to define all the objects before the computations. Still going to be on the heap in java (unless it's a primitive/primitive array), wherever the memory management feels like putting it. Try allocating two contiguous objects in Java. In C++, they can be on the stack, in contiguous memory, etc. If it needs to be dynamic, you can use object pools arenas, stack-based allocators, etc. Even with plain malloc, the memory it gives you will likely be live in the cache unlike Java where you are getting cold data while some unreachable objects sits in hot memory. &gt;Even with your own allocators you will have to try to minimize the allocation/deallocation and try to replace these operators by using again the same objets. That's true for C++ and Java. Yes, of course, reusing objects can be helpful. But this doesn't really mean that Java can perform close to C++. In fact, throwing an object back into the allocator can increase performance because that memory is probably in the cache, and this means that something which needs that memory asap can use it. The reverse can be true as well. holding memory away from an allocator for too long means that the block you hold will get evicted from the cache, whereas the memory returned by the allocator may be fresh. This effect can actually be quite big. &gt; The examples where C++ is really faster (I speak about a factor 2 for instance) is when you code like in C with a lot of hacks that are machine dependant This is just plain false. C++ generally compiles to very efficient code, comparable to or often better than these C-style 'hacks' which you refer to. &gt; if you really need to control the cache, then C++ does not bring anything, the solution is more close to a C code. This is so completely wrong that it's almost funny. C++ actually gives more opportunities for taking advantage of the cache since generics go a long ways in reducing the need for type erasure and indirect calls/references. What are these 'C-style hacks' that you keep talking about?
Disclaimer: I haven't watched the video yet and I'm mainly observing the modern c++ transition from the sidelines. I've been immersing myself in Academic CS lately (graduated computer engineering.... I know the nuts and bolts already). It seems like the direction the language is moving is one where you can still construct your "own programming language" (a DSL), but you do it on a more conceptual level that reduces to pretty much the same thing at compile, maybe with more guarantees and range checking. The biggest eye opener to me was writing some generic loop at work and I realized that I didn't care that I was looping over a Vector, I just wanted to do an operation on some Collection of objects. At some point someone specifies a vector, sure, but I don't care as long as I can loop over it. The really fun part about C++ to me is that there are so many ways I can use it and at the end of the day, I can link straight to a library using a different style (biggest example, the STL) and it Just Works without writing a wrapper. I hear what you mean when you say "Look I have built a backpropigating neural network in 8 lines of completely unintelligible code.", but those posts don't seem to be from the movers and shakers of the languages, rather the abusers. (Underhanded/Obfuscated C Contest anyone?) Absolutely keep voicing your opinion though, because I think you and the academics have the same goals wrt getting work done, but they may not realize that their ideas aren't translating well to the laymen. Are you a regular on any IRC channels? I'd like to rant with you some time probably :)
&gt; They are annoyed that people without 2 masters and a PhD in CS can actually learn to code well in C++ and do impressive things. No, Haskell is the elite academics only club. &lt;/sarcasm&gt;
I think it is very strange to see authors of a language propose some guidelines for using their own language. Normally, the language should be defined in such a way that no guideline is needed. Defining guidelines is normally the job of users and not of the authors 
If it cost 5% in a simpler language then we should not hesitate and select this other language. Nowadays Pimpl costs almost 0% in Java as any monomorphism hierarchy. So? 
I don't think Rust requires more annotations as he says, there are similar lifetime annotations as in his examples (although in Rust you name the lifetime and specify it for every variable instead of saying that lifetime of this variable is the same as of the other) but defaults usually works. Anyway many concepts described in this video about type, bounds and lifetime safety are similar to Rust but Rust is so very different in many ways.
I mean, honestly if he had kept it clear and concise I wouldn't down vote him. Even if he had just stopped after a couple paragraphs. But this is a rant. 
&gt; The modern garbage collectors in Java are not stupid at all and it is not easy to outperform them. Allocations are often contiguous. Hoping that the GC gives me a contiguous allocation is not the same as actually having one - not to mention the object metadata takes up a decent amount of space between objects. It's not very hard to beat the java GC in C/C++ - you have so much more control/knowledge over allocation patterns, and can often make allocation very, very cheap. In addition, much of what requires many different allocations simply becomes the stack, or a single allocation on the heap. Take the benchmarks game - Also, it doesn't matter how good your GC is, dead objects will waste cache space that would otherwise be used for new objects which isn't really a C++ problem and has a serious affect, in the realm of 1/2 performance or more. The JVM will have it really bad, since the GCs don't usually start happening in the young generation until ~30mb, which is much larger than most L1 caches, and larger than most L2/L3 caches as well. &gt;they can group together the codes that are frequently used together. We program by grouping things semantically. However there is no program that call the functions along with the order we define them. Function calls are incredibly cheap on any CPU from after 2000, and moving things around in the binary won't have much of an effect in pretty much every case due to very good instruction prefetching. &gt;I made some benchmarks and I am very surprise by the current performance of the recent JIT compiler. For instance, The C version of a minmax algorithm (with alpha/beta cuts) outperforms a Java version by only 20%. Source? If it's an algorithm similar to the benchmarksgame one that you posted, then it doesn't mean much for real world performance differences between C/Java &gt; The future could really be a language like Java + some code in C It won't at all, because for high performance (and low latency) applications having absolute control over the memory space is paramount and Java shits all over that. &gt;If you want to have a look at some famous benchmarks look at the nbody code of the famous benchmarks: http://benchmarksgame.alioth.debian.org/u32/performance.php?test=nbody The benchmarks here are worthless, it's a microbenchmark that is barely affected by the issues being discussed here. If you look at the java source: 1. There is a single array of references that is initialized at the beginning and no more allocations happen. This means that the GC is probably not invoked during the program duration, and the objects will be fairly compact. In addition, all objects are live - there are no dead objects taking up cache space waiting for the GC to reclaim them. Also, the GC won't collect them at program exit. 2. Almost all of the operations are on primitives many of which are constant - there is a little bit of object lookup in the array, and then a bunch of floating point math. This is also uncharacteristic of most real programs, and is pretty much the sort of microbenchmark that people point at and say 'hey look the JVM isn't that bad' because none of what actually makes the JVM significantly slower comes into play. 3. There's a fairly small amount of code that is constantly interacting in the same fashion with no surprises, all of the classes are final, and there is no polymorphism going on. The benchmark that you posted (and pretty much all of the ones in here) are absolute best-case scenarios for any Java program that isn't completely nontrivial. This doesn't even get into how much better native multithreaded code can perform than multithreaded java with good control over memory accesses.
&gt; I have read studies about the optimal length of a function and it is actually quite long. Link?
The things you are saying "his highness"wants are things most good devs agree on. Practically every dev I know with at least a few years experience think singletons are over used and shitty. Most of the dev world has learned from C that it's actually really hard to get malloc free pairs right. Like, what is your hang up here? I think your posts are more a reflection of some personal issues than anything technical. Honestly, if you don't like unique ptr, just go back to C. We have plenty of 1995 shitty C++ code to deal with, don't need people producing more in 2015. 
Well I think it is worth raising the bar - at a company level - for hires. But how to do that is a really difficult task. I've had enough of people writing code which is just _asking_ for heap corruption, race conditions, other violations. These are incredibly frustrating to track down (as I am sure you and many readers here know). And they don't tend to bite early in the project, or at least the warning signs are ignored. So when I am already doing bits of overtime trying to finish something which was not allocated enough time at the proposal phase, these things really ruin my day. I DO want people to try writing safer code. But most people I have worked with are highly resistant to change. I'm not walking up to them mandating some policy like "we should ban commits which use 'new'". I'm talking about just saying: we have these issues and we have some recurring themes. Lets have a discussion and see what solutions people think would help. Unfortunately there seem to be the aforementioned (in my previous post) two camps: - the detailed standard camp (with all the minutae including code formatting) - the bunch which dont see it as an area worth discussing. just do what you do and debug if you have to. I think for the former bunch (the 'loves academia' side) the only cure is for them to appreciate neat, simple and functional API's from a variety of languages. When you're willing to see a C API and go "thats really neat. It works well and debugs easily" while also appreciating one written in C#, I think it goes a long way to understanding the need to use language features (whatever they may be!) appropriately and not mandating their inclusion (or exclusion). For the latter bunch I don't know if there is a cure. If someone will not look at the _problem_ and discuss how not to have it on future projects, theres nothing that can be done. They will, through their pig-headedness, ensure that every future project they work on has the same issues as the last. So for all the interest I have in C++, it does feel like the core group of people are grouped somewhere in an ivory tower. Anyway this has spawned an interesting discussion anyway. It's been a good reddit read for me.
Pimpl is more like 100% extra cost, not 0% cost.
making sure that people who don't read to the end see this bit: "Fortunately Debug Heap is disabled by default in Visual Studio 2015". debugger team heard this feedback and adjusted 2015 but I'm glad that the potential issue is getting publicized now for people still on earlier versions. thanks, Steve VC Dev Mgr 
&gt;&gt;" I still don't see how they'll fix STL iterators " &gt;&gt;"STL collections need to be burned and redone." Glad its not just my imagination, often wanting to avoid using them.
You can. When it asks you to sign up there's a button on the top right if i remember correctly. Signed up with my trash mail afterwards though so i can't check.
Hm that website has an interesting idea - unlocking job offers when you complete puzzles with associated skills required. Just the jobs don't look too tempting. Winning the competition wins you a T-shirt or "getting an offer from one of our sponsors" without a mention of who that actually is. I think I'll pass.
You're absolutely right! My bad!
100% extra cost of what? Of something which takes 0,000001% of the total computation time? BTW if PIMPL cost 100% in a language whose goal is 0% additional cost for abstraction then it means that the language is really bad. 
It matters a huge amount. Cache misses are one of the main issues in modern performance. The best way to avoid cache misses is to have very linear access patterns of data so the pre-fetcher saves you from misses. The best way to have linear access patterns is to make sure that your data is laid out correctly in memory. In C++ you can create a struct, create a vector of that struct, and now you have a very precise contiguous memory layout. It's also incredibly simple to do; it doesn't require tons of work or complexity or expertise as people who would discredit C++ would have you believe. In Java, there's no way to do this with anything other than the primitive types. Of course, if you create an array of objects there's a good chance they'll get laid out contiguously, but there's no guarantees, and as the program keeps running it's likely to get more and more fragmented. Java's a good language, but the fact that it's primitives get "special status" is a real issue, both in terms of controlling memory layout, and in terms of generics. And of course, Java's generics are not zero cost. And if you want to get intense, C++ templates can do crazy thing to reuse code while not paying runtime indirection costs. I want to emphasize again: Java is a good language. It has tons of libraries, package management, build tools, great IDE support, great tooling. On all those fronts it overall has C++ beat. To top all that off, it's pretty damn fast. It doesn't need to be as fast as C++ to be useful, which is good, because it's not.
Reference to a recent reddit thread at 28:45.
&gt; &gt; &gt; Furthermore going out of ones' way to find the worst counter example to compare against ones' offering then claiming a 40x performance increase seems rather disingenuous. So why exactly have you turned this into an entirely new thread if you recognize that the claim stands on weak grounds as it is? Because it sounds like you were deliberately posting low-quality content.
Didn't your argument just contradict itself? You say that Rust is "inarguably" cleaner and less error-prone, yet somehow teaching it on C++, of all languages, makes it more accessible? Unless you're big on blaming users for their lack of intelligence, it would seem Rust has more than just a pedagogy problem---it has a complexity problem (a different kind of complexity than C++, mind you).
Do you see how you contradict yourself? First you are disappointed about enforcement of any rules, and then you talk about certification. It looks likes you would like to enforce rules, but only YOUR rules. 
&gt; &gt;Function calls are incredibly cheap on any CPU from after 2000, and moving things around in the binary won't have much of an effect in pretty much every case due to very good instruction prefetching. &gt;So what the advantage of all the new C++ stuff? What's the advantage of template programming and so on? Functions can be inlined into a new context, where many optimizations that wouldn't happen in the first place can &gt;A C program efficient when is doing a kind of matrix multiplication, but when you are calling member functions of objects that are calling other member functions and so on there is not a big difference with Java. Actually, this is exactly where C++ is incredibly strong - the relationship between those objects in memory can often be statically determined, which lends itself to all sorts of crazy optimizations. When objects are dynamically allocated, then it depends on the allocation strategy and the cache, which will dominate execution time. It's also not as if the two options are BLAS or big dynamic object hierarchies - there's plenty of high performance software that is much more intricate than matrix multiplication. &gt; If you want to have an efficient program you absolutely need to avoid allocation during the hot part. So no dead object. In C++ and in Java. In Java if the GC is triggered you're dead. However if you think that you can allocate/deallocate during this part in C++, I can tell you that you are also dead. Using malloc/free during a hot loop may not be the best, but it depends. In a lot of real-world programs, Java would force you to allocate an object. This may be quick, but you will smear the cache very quickly with that. with malloc/free, you will be recycling that memory over and over again. In addition, pretty much every malloc implementation temporarily stores freed memory in a stack, so repeated requests for a similarly sized chunk of memory just push/pop off the stack. I've also benchmarked object pools for this purpose that roll in at about ~2 ns per alloc/dealloc and are very cache friendly, so you can get the best of the JVM allocation without the downsides of the GC. &gt;BTW, Look at PGO. If reordering the code, eliminate dead code and so on is not efficient then explain to me why it gain something like 10-15% of the elapsed time? Why Intel is pushing PGO so much? PGO is only part of if - you can't just say JIT does more PGO stuff and pretend as if that's justification for saying Java is comparable to C++. The PGO isn't happening in a volume, it's happening in concert with a highly optimizing compiler that can much better use the information about object layout, object type, and memory layout than javac (JVM has all the information, but it wouldn't make sense to use it since at runtime in an environment like the JVM). Also, Intel is pushing PGO to sell it's compiler. I've never seen more than a ~5% increase in performance from PGO. This is the myth of a sufficiently optimizing compiler all over again, except it's now a sufficiently optimizing JIT compiler. The JIT can't magic away cache effects, GC problems, lack of memory control, poor stack allocation, all of the indirect references, space used on object metadata, etc. Java is simply a very different environment and runtime than C++ and it will never really be able to compete except in a few niche regards. &gt; I also do not speak about multithreaded code. Multithreaded performance it incredibly important to many high performance applications, and how the JVM performs in that setting is relevant. Have you ever tried to seriously optimize a C/C++ (or Java, for that matter) program? You sound as if you are just repeating basic internet wisdom without knowing how/when it actually applies or what it really means.
Not sure what you mean by only such a model is efficient. If your cortical path lends itself to any reasonable linear access pattern, this will typically be the fastest. Obviously laying stuff out contiguously in memory is possible in C. The problem is that it's much less safe, and easier to leak memory. That's generally the pattern. Everything is preallocated? So the maximum size of every single data structure in the program is known in advance? Must be nice. Even assuming this were often true, it's still harder to reason about the memory layout. What if an object contains another object? That's indirection to somewhere else in memory. In C++ this is very simple and much of it is mandated by the standard (see standard layout). 
&gt; ...; for example, I'm not sure why there should be any need to provide additional syntax to invent a name of a region (as both Rust and Cyclone do, for example), when every local variable and parameter already has a well-known scope/lifetime and already has a name, so we can just use its name to denote that scope/lifetime. In Rust, the lifetimes (scopes) of arguments/variables and temporaries don't need to be used explicitly because they can always be inferred: in fact, there's currently no way to refer to the lifetime of a variable, although it would be nice to have, for documentation purposes. In fact, explicit lifetimes (or lifetime *parameters*, rather) in Rust are always about parametrism at the type/function level: they thread through type definitions and function signatures, so that borrowing via function calls is determined by the callee's signature, not its body. Presuming you wanted to have the following examples interchangeable: fn field&lt;'a&gt;(foo: &amp;'a Foo) -&gt; &amp;'a Bar { &amp;foo.bar } // Elision allows it to be also written as: fn field(foo: &amp;Foo) -&gt; &amp;Bar { &amp;foo.bar } // Your suggestion, perhaps? fn field(foo: &amp;Foo) -&gt; &amp;'foo Bar { &amp;foo.bar } There would be, however, several problems there: * `'a` in the first example is the lifetime that the reference tracks, not `foo`'s scope * this would not scale beyond simple reference types, consider `Vec&lt;&amp;'a Foo&gt;` or `slice::Iter&lt;'a&gt;` * it's trivial to get multiple lifetime parameters in one argument, e.g. `(&amp;'a T, &amp;'b U)` &gt; Also, there are some other usability questions such as that it doesn't seem to allow reusing local pointers as easily. Are you referring to a local variable that contains a reference which can come from a few various sources, and whether they may conflict? Rust uses subtyping for lifetimes, so depending on what you have in mind, it will likely be addressed by the automatic combination of multiple lifetimes into their "lower upper bound"/"greatest lower bound" (depending on variance). I'd be happy to dissect a tricky (yet practical) example, though (which could involve invariance over lifetime parameters). &gt; Another is that I'm not sure whether Rust generalizes to treat user-defined Pointers (such as iterators, ranges, etc.) uniformly with raw pointers. Actual "raw pointers" (`*const T` and `*mut T`) are only used in "unsafe Rust" (though they can be manipulated as plain addresses outside of that), are you referring to Rust's safe references? In any case, Rust does iterators slightly differently, not involving a notion of "pointer" in [the generic interface](http://doc.rust-lang.org/std/iter/trait.Iterator.html#tymethod.next). However, the slice/vector iterators do use pointer ranges under the hood (for the same performance reasons C++ prefers pointer ranges to indexing). And maybe this is what you're getting at, how does a slice iterator (internally a pointer range) interact with everything else? It's defined as [`slice::Iter&lt;'a&gt;`](http://doc.rust-lang.org/std/slice/struct.Iter.html) which means it tracks a lifetime via its `'a` parameter: this is the slice/vector's lifetime - see [Vec::iter](http://doc.rust-lang.org/std/vec/struct.Vec.html#method.iter), although it's elided, desugared it would be: impl&lt;T&gt; Vec&lt;T&gt; { fn iter&lt;'a&gt;(&amp;'a self) -&gt; slice::Iter&lt;'a, T&gt; {...} } That `'a` lifetime parameter allows it to borrow the `Vec&lt;T&gt;` it came from, without actually having references to it, but by being variant over the lifetime. The other kind of user-defined pointer you might be speaking of is a smart pointer: and we have a few of those: by implementing [`Deref`](http://doc.rust-lang.org/std/ops/trait.Deref.html) (and optionally [`DerefMut`](http://doc.rust-lang.org/std/ops/trait.DerefMut.html) on the smart pointer, explicit dereferences, dot access to fields/methods, indexing and the call operator are all forwarded to the "pointee", while borrowing the smart pointer. As such, in C++, a combination of `operator*`, `operator-&gt;`, `operator.`, `operator[]` and `operator()` would be required to approximate the Rust `Deref` semantics. &gt; Rust and Cyclone and others are good work. This is a very hard problem and having lots of people keep working on it is a good thing and appreciated, and I hope to be educated about how I can improve this design by learning from what others have done. Please send mail or open GitHub issues! Thanks. I am grateful to live in such unique times, thank you so much for this cross-sharing opportunity, and I hope this overly long post will be of some use. Cheers to safer systems programming for everyone! ^(â€œ/u/eddybâ€ terminated by signal SIGSEGV) ^((Segmentation fault)^)
I will try and speak to Gaby about this. -- Bryce, Speaker Liaison 
&gt; I'm not sure why there should be any need to provide additional syntax to invent a name of a region (as both Rust and Cyclone do, for example), when every local variable and parameter already has a well-known scope/lifetime and already has a name, so we can just use its name to denote that scope/lifetime. Using variable/parameter names to name lifetimes was proposed at various times in Rust's development. [Here is one of the relevant discussions](https://mail.mozilla.org/pipermail/rust-dev/2013-February/003099.html) that I found on the old mailing list that gives one disadvantage of that approach. &gt; Another is that I'm not sure whether Rust generalizes to treat user-defined Pointers (such as iterators, ranges, etc.) uniformly with raw pointers. It does. In fact, Rust used to have several "smart" pointer types built-in (`&amp;T` borrowed pointer, `@T` shared pointer, `~T` owned pointer), but the latter two have been replaced by library types `Rc&lt;T&gt;` and `Box&lt;T&gt;`. And iterators and other user types can "borrow" collections just as borrowed pointers can. (Note: The Rust compiler still has some special knowledge of `Box&lt;T&gt;` but this is a left-over implementation detail that will be removed eventually.)
I want that too.
&gt; it's convincing people that the concepts are useful and worth learning in the first place. I'm not sure I've ever met anyone, at least in the C++ community, that thought this wasn't a good idea. But Rust asks for much more than just mastering lifetimes; for one thing, you have to abandon inheritance, which is the bread and butter of most C++, Java, etc programmers. The variable name capitalization enforcement by the compiler is also paternalistic nonsense, but it's a minor annoyance among a thousand other minor annoyances, which end up killing interest. At least for me, anyway. I'm not really convinced C++'s cachet is all that relevant; if one goes by Internet discussions, at least, Rust is already the dominant language in terms of mindshare. As I understand it, most C++ code in existence today is legacy. Most new code---even systems code, I would guess---is not being written in C++.
I seem to recall the compiler complaining when I named types in snake case. That may well not be the case anymore, I haven't followed the language in a while (too much churn is another Rust misfeature for beginners, but I feel it's unfair to judge it on that).
&gt; static_cast(std::is_standard_layout&lt; std::unique_ptr&lt; T &gt; &gt;{}); holds You mean `static_assert` there and no, the assertion does not hold for `std::unique_ptr`. It might happen to hold for the particular implementation(s) you are using. For it to hold, the standard ought to read "It shall be a standard-layout class".
Hey folks, I got him to upload them :) https://github.com/isocpp/CppCoreGuidelines/blob/master/talks/Large-Scale-C%2B%2B-With-Modules.pdf 
Yes, that's the lint I was talking about. It was introduced years ago as a temporary measure for use by the compiler developers when they were codifying the style they were using, but when they went to remove it people asked that they leave it in, so they shrugged and said sure. Not only is it only a warning, but it's trivial to disable (and will probably be disabled by default in the future). The Rust developers really don't care how you format your code (why else have braces and semicolons in your syntax :P ). Even the upcoming rustfmt tool will be configurable instead of dogmatic.
It gives a warning when you don't follow capitalization guidelines, not an error. That is all.
what about publishing onto Channel 9? Youtube is not as accessible as C9 
As a fan of rust, I feel the opposite. This gives credence to what Rust provides, except that rust is built around it.
I'm blown away that they're finally talking about "subsetting" c++ in a way to make it safer. Fixing uninitialized memory and dangling pointers is huge. I liked this guy's atomic&lt;&gt; weapons talk from a few years ago, but he's really outdone himself this time.
Singletons, over used, you mean that people want them and love them while other people have a stick up their ass over them. Choice. That is what is happening. But religious zealots want that choice to be heresy. 
Thanks for that. I've just finished watching the talk, and it is a bit clearer now. The impression I get is that the big 'rule' that will protect us from pretty much everything is the pessimistic assumption that if a function could change an object, then anything that object owns is now gone (potentially), and so any pointers to anything owned by the object being modified are now assumed to be invalid. Assuming that I've understood that correctly, then I'm pretty confident that it will in fact protect us from dangling pointer bugs. But I'm a bit concerned that it might create some roadblocks in design. I'm going to invent a hypothetical example to try to illustrate my concern. Suppose I'm writing a game, and the game has a few different classes... something like this: class World; class Character { public: Character(not_null&lt;World*&gt; w) : p_our_world(w) { } private: not_null&lt;World*&gt; p_our_world; // used to interact with the world } class World { vector&lt;Character&gt; characters; } class Simulator { unique_ptr&lt;World&gt; p_the_world; bool is_running; public: PauseSimulation() { is_running = false; } } The idea is that the_world owns all of the characters, and every character has a pointer to its owner (so that it can call public methods to do various things). The "Simulator" class is kind of the main program that's in charge of running everything and interacting with the user. To me this design doesn't look terrible. But I'm now worried that the (completely innocent) PauseSimulation method is going to set off alarm bells for all of the Characters, because they're going to think that their world might have been destroyed ie. all of the p_our_world pointers might be invalidated when PauseSimulation() is called, because PauseSimulation() is a non-const operation of the owner of *p_our_world. Of course, if the world was destroyed, then the characters would be destroyed too -- so it isn't actually a problem. But it kind of _looks_ like it might be a problem. [edit] This post use to say some other stuff; but I've decided to just cut that out for now, because I'm not even sure whether or not the this example would be flagged by the tools / rules as being problematic! I guess I still need to think about it some more.
Why don't I have? The cite from [your article](http://talesofcpp.fusionfenix.com/post-20/): &gt; 9.2 [class.mem]/19 In a standard-layout union with an active member (9.5) of struct type T1, it is permitted to read a non-static data member m of another union member of struct type T2 provided m is part of the common initial sequence of T1 and T2. [...] I think it is just an omission of current version of the standard. I think there should be `of class type` (in common sense) instead of `of struct type`. What do you think about it? Given a code: union U0 { struct S0 { int i; T0 t; } s; union U1 { struct S1 { int i; T1 t; } s; union U2 { struct S2 { int i; T2 t; } s; ... } u; } u; } u; there should not be a restriction to deny to read a non-static data member m of another union member of struct type T2 provided m is part of the common initial sequence of S0, S1, S2... and of `t`s too (of course, under some reasonable circumstances). Isn't it?
It is sad though. Even so there is valuable stuff anyways: it is multivisitor code, I hope. It is suitable (at least can be adapted in simple way) for any other variant classes. So can you [answer the question](http://stackoverflow.com/questions/32738518/swap-non-active-stdunique-ptr-data-members-for-union) (for me to be correct) please?
Thank you! Static library + IFC seems nice. I guess we can get some CI tools that generate single static library + IFC file for every (release?) build, for each platform.
I'm a C++ programmer who've gone webdev for the meantime (PHP, my life sucks / sucks out my life) because of necessity and the lack of part-time jobs in C++. I'm dodging your real question here, but my suggestion would be to work on C++ side projects, things that really pique your interest even if they seem impossible (really, then you'll realize they're actually impossible and by that time you'll have more interested in a more focused aspect of it). I think the best thing you could present when applying for a C++ job is experience (in C++ of course). Knowledge and expertise in how you do stuff wont do much if you don't know when and where you should apply them. And with that, any sensible job offer wouldn't require you to have experience on all different tools, and would just expect you to be willing to learn them (you'll probably work with their own archaic build systems anyway). Watch cppcon. :) Perhaps one thing that your experience with web dev can help in a future C++ job is a personal testament of nightmares in working with it.
If one regards Rust as a critique to C++, it certainly should be seen as a *constructive* critique. C++ is a tremendously successful language, and still the benchmark when it comes to system programming.
What should matter is that good ideas win over poor ones, not which is someone's favourite language. C++ began life in 1979 (according to cplusplus.com), so thank goodness people are trying to move things forward now in an intelligent way. I really couldn't care which language 'wins' at the end of this process. I *do* care that technology moves forward.
I thought everyone already knew that static checking is great, such things are not available in C++ and Rust provides much better support for these. Yet most people stuck with C++, because of existing codebases and the fact the C++ is more mature and hence tooling is far better. With C++ adding static checking, a major reason to migrate to Rust disappears.
Yea, but his point was that you might want to release some of them early
While I'm not sure if the MS compiler could compete with llvm on non-windows operating systems, I definitely would like to see them open sourcing their compiler.
If they did with C# and .net, eventually they would do their C/C++ compiler
What is so special or difficult about implementing *constexpr*?
Windows or *nix On unix, cmake does a great job finding all the necessary libs if they are installed. On Windows, you will be forced to add the libs to the PATH or instruct cmake to search on a folder on your project (a lib directory were static libs and include files would be placed)
I'm really not trying to downplay the merits of C++, and surely I share your view on constructiveness. Rust is a critique to C++ in the same sense that this work on Modern C++ is: we are not completely happy with what we have, we learned things getting here and we can do better, so let's try to improve our tools.
Thanks!
The question is, why MS chose to keep their own compiler (front- and backend)? Imho they should have either chosen [Roslyn](https://github.com/dotnet/roslyn) or LLVM as Frontend. Now they will have to maintain again much more overhead concerning tooling as IntellisSense for Visual Studio and so on. Also the gap bewteen managed and unmanged C++ could become smaller by the first way. Perhaps it is just too complex to switch and there is no other feasable option for their dilemma?
The problem is that the proposed static checker will break the existing codebases. You can do either: 1) wait until the authors of the libraries modify their code to be compatible with the lifetimes, 2) or just skip the static checker for those problematic libraries. I'm not sure you can choose 1). There will always be some libraries that are not yet updated. Just see the Python 2/3 split. Unfortunately, I believe the C++ crowd is even more rigorous about the backward compatibility, and a bit more resistant to changes (C++11 literally took years to take off, and personally the level of the adoption is still not satisfactory). So it would take much longer than even Python 3. And you can decided to do 2), but in that case you will lose some (a lot?) advantages using the static checker. The libraries you're using will still segfault, and it is even possible that because of the downstream libraries the static checker cannot guarantee your code's safety. There's a reason why Rust (or, Python 3) took the aggressive route. Adding a guarantee while keeping the existing ecosystem is extremely difficult. But I do hope the C++'s approach would succeed.
PauseSimulation can be marked as `[[lifetime(const)]]`. This case is specifically covered in the detailed paper (p25). I don't know whether the implementation of PauseSimulation would be checked for compliance.
I was under the impression that the current compiler uses the EDG front end. Open sourcing it may not be an option for them.
The EDG front-end is used for Intellisense. The C1XX front-end is used for actual compilations.
&gt; What you are arguing is akin to saying that C++ adding lambdas, concepts, optional and await will make teaching Haskell or OCaml easier since they do all of those much much better. Not in the case of lambdas, because C++ was late to that party. But what you're saying *is* true for a different language: Javascript. JS introduced closures and first-class functions to the programming audience at large, and in the span of ten years managed to change the perception of these features from academic curiosities to invaluable tools. Loathe as they are to admit it, functional languages have Javascript to thank for lowering the barrier to entry to functional programming, despite the fact that JS does it so much worse than your typical functional language (try running `["10", "10", "10"].map(parseInt)` for some real lulz).
You reiterate, Rust isn't just aiming to be an imitation of C++ (it specifically just embraces the C++ philosophy of zero-cost abstractions), so having feature-for-feature parity with C++ isn't an especially high priority. That said, Rust has the advantage of a six-week release cycle rather than a three-year release cycle, so features can be designed and standardized upon rapidly. Specialization is in the works as we speak, numeric type parameters are on the table, and APIs are currently being designed with HKTs in mind for when they finally show up... which could be a while yet. :)
Well now we obviously want to see it for humour value ðŸ˜‰, right everyone?
VTK was written by Kitware, the same people who write CMake. They're basically designed to be used together. [Here's their tutorial.](http://www.vtk.org/Wiki/VTK/Tutorials/CMakeListsFile)
Iirc they don't generate a a full AST. [Source](http://blogs.msdn.com/b/vcblog/archive/2006/08/16/thoughts-on-the-visual-c-abstract-syntax-tree-ast.aspx)
&gt; it's a microbenchmark that is barely affected by the issues being discussed here Whether or not that is the case, the fastest Java n-body program shown **takes twice the time** of the faster C++ program shown.
(Quick note for any C++ fans who haven't seen a lot of Rust, that mailing list post is indeed old, and that code sample has a lot of things that have changed. Rust doesn't look like that today.)
VC dev mgr here. yes, we are working on hooking clang frontend to the backend as we announced at Build and then showed a demo at CppCon. We are trying our best to help the llvm guys but it is completely true that we are not "leading the effort". 
it's been that way for some time now. EDG can emulate different compilers. We use it for our Clang intellisense too in Android development.
Correct, but they're "rejuvenating" it The article is from 2006 and specifically points to the compilers age as the primary problem &gt;The sad fact of the matter is, however, that the current Visual C++ compiler doesnâ€™t really generate a complete AST. Itâ€™s whatâ€™s known as a bottom-up compiler, meaning (among other things) that it devours its AST as it produces it, leaving no durable form behind. This is an artifact of the compilerâ€™s age. In the days of the 256K limit, a large, in-memory structure such as a whole-program AST was not feasible. If they're taking this improving of the compiler seriously, I'd argue this is one of the main points of interest
Nice talk, just two questions: 1) Herb says that `array_view` has a runtime overhead, why is that? Does it do bound-checking at runtime? 2) At 33.10 he shows an example with dangling pointer to local objects. He then mentions that there are static analysis tools that are able to detect that... which tools exactly? I tried to analyze the example with `clang-analyzer` but it does not detect it.
I think if the code is so bad then people would mostly ignore it or just take the interesting sections and apply it to clang or gcc depending on the licensing.
I just arrived at 1h:07m, "Overriding defaults" that involves the example of `map`'s `insert` function overloads: one taking a single iterator as insertion hint which needs to be annotated with `[[lifetime(this)]]` to suppress warnings about possible iterator invalidation and another `insert` that takes a range in form of two iterators from some other container where an annotation is used to say that both iterators should refer to the same range. This is all nice and dandy. But: Isn't the iterator abstraction inherently unsafe? Previously Sutter argued that pointer arithmetic is bad and that you should use `array_view` instead because -- among other reasons -- it makes bounds checking fairly easy and cheap. But C++'s iterators are a generalization of the pointer concept that includes "iterator arithmetic". What we would need is a different kind of range abstraction in the superset as a *replacement* for iterators analogous to `array_view` to keep things safe. This reminds me of Alexandrescu's "iterators must go" presentation ([slides](http://de.slideshare.net/rawwell/iteratorsmustgo)). Sure, you could add bounds checking to the iterators as well, but that would make them larger in size and smart enough in which case having *two* of them for a range would be *redundant*. **edit**: Oh, at 1h:28m he mentiones the iterator/bounds problem and refers to Niebler's talk about ranges.
I've seen your code before when we talked about implementing visitor without linear search. It's very sophisticated, but I would honestly be hard pressed to find uses for heap based variants. Usually the types in variants in C++ are relatively lightweight, so a heap allocation on each assignment isn't really acceptable. I can't offhand think of cases where people are so concerned about memory usage that they care about the savings, yet are willing to tolerate so many allocations. Part of the reason that variant types in C++ tend to be lightweight is because if you were going to put big heavy types into a variant, well, that probably sounds like a situation where would just use inheritance. In summary, I think it seems cool, but also a niche of a niche, as it were.
I just looked at the code and yes, it does bounds checking at runtime (if it's not optimized out). In case the index is out of bounds it will invoke [`fail_fast_assert`](https://github.com/Microsoft/GSL/blob/master/include/fail_fast.h) which either throws an exception or calls `std::terminate` depending on the configuration.
He basically said that at around [45:22](https://youtu.be/hEx5DNLWGgA?t=45m22s).
hah I love how relieved they sound after every analysis check
Awesome talk. I'm *eager* for this book.
Also, in the x64 ABI on Windows array_view would have to be copied onto the stack and a pointer to it will be passed in a register, while in the "unsafe" version when the pointer and the size are separate arguments they may each be passed in registers (according to @JamesMcNellis) It's not a "zero overhead" abstraction in this case -- something to keep in mind when optimizing hot spots. 
Unless it is built into the VM you need to go through JNI. What am I missing? And if it is built into the VM and just pretending to be exactly like Java's TCP/IP sockets then you can't get the highest performance from it. A lot of the performance of these stacks also comes from better zero copy interface instead of just aping epoll. If you expose the real interface then you are a JVM with some custom non-standard Java API. All of these paths seem non ideal. And of course you can go to extreme lengths to be able to use some hardware - use custom JVM, modify openJDK etc etc. I think the point some of us are trying to make is that the JVM for all its advantages does not make it easy to hook up to an unknown C API without performance hits. It is just easier to do in C++. That is one of the trade-offs - you get more flexibility in C++ especially with calling into C APIs but also suffer from most(all?) of C's issues. Another example - all of these databases written in Java slowly end up simulating C structs in Java. They write on top of ByteBuffers or Unsafe memory for in memory state (instead of pointer heavy classes) and on MappedByteBuffers for their on disk data. Such work is just so much less painful to do in C/C++ with proper structs. Yet another example - one of the ways to reduce jitter from the OS etc is to pin your threads to cores and then isolate your OS threads to maybe a single core. Again there are JNI libraries to do similar things in Java but your GC threads are running all the same. It is not trivial to isolate those. Further given that Cassandra and other databases written on the JVM are slowly evolving towards using almost no on (JVM) heap data structures now they just look like assembly code (absolute pointer gets with manual offset math). The JVM misses many optimization opportunities when it comes to the use of Sun.misc.Unsafe compared to similar C++ programs. So you end up with a version that (at least in my eyes) looks even more convoluted than an identical C++ program, you don't get all the performance, and you still have the overhead from GC threads and JIT threads running. You also get some really really weird sources of jitter from safe points, deoptimization etc. I think the JVM is a great platform just not a great one for writing databases which need to be able to get the best out of the available hardware (disk, network and cpu).
Hint 1 is not a hint, that's just an error if you don't know how the ternary operator works. Even I wouldn't make that mistake and I only know the basics of C++, nothing advanced, and I know that won't even work right.