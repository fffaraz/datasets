It is, but when you add references to the mix, all hell breaks loose, and some people cannot seem to understand that for **that sole reason** it is not a good idea.
The Rust compiler is set up to target Webassembly without Emscripten at all, and a lot of work is going into integrating it with existing web tooling.
The more basic the type, the more discussion it generates.
To answer the first part of your question, speakers are invited to create posters based on their presentations, but this is optional. To answer the second part, the posters will be displayed in a public area for the entire week. The exact public area is yet TBD; I expect that it will be one of the big halls this year. The "presenting" mentioned in the first sentence of the announcement refers to our requirement that poster authors stand with their poster during the Sunday evening reception so that they can discuss their work and answer questions about it.
can you give a code example of a problematic use or describe it in a few sentences? also, what is a vocabulary type?
we know that. i am asking whether it is a good discussion to have.
Valid question. Have a look at [wasm bindgen](https://github.com/rustwasm/wasm-bindgen), written in Rust, which generates bindings. Additionally, delivering web pages is integrated in Cargo ([cargo-web](https://github.com/koute/cargo-web)). Even complete web applications have been written in Rust: [https://medium.com/@saschagrunert/a-web-application-completely-in-rust-6f6bdb6c4471](https://medium.com/@saschagrunert/a-web-application-completely-in-rust-6f6bdb6c4471) . You can also publish Rust as npm packages with [wasm-pack](https://github.com/rustwasm/wasm-pack) which strips binaries (I think). I am not aware of similar tooling and integration for C++.
References are special because they can't be reassigned, and they then take advantage of the assigned operator to reassign the thing they refer to. So there's a whole discussion on the meaning of this code: int y = 0; int z = 1; optional&lt;int&amp;&gt; o{y}; o = z; When this code completes, there's two reasonable possibilities: 1. o still points at y, and y is 1. 2. o now points at z, and the values are unchanged. I think offhand, if you didn't special case optional at all, you would get the behavior of 1. However this gets really bizarre, because this can't be made consistent with the case where the optional is empty: if the optional is empty and you call `=`, then obviously it can't do anything other than construct a new reference. It would be nice if there was some kind of public presentation on the options; since currently it's simply not allowed it would be possible to add something in a future version.
DAE use ints and chars?
Thanks for the explanation. Could you specify where in the standard defining a buffer of char\* and using placement new is UB? Why can't std::vector work like this?
To be honest, I'm bothered far more by making OOM abort than any possible redesign of STL. Having read some more of the proposals, I have one more question: if the proposed light-weight exceptions are really so light-weight, is there still a need for OOM abort? 
Does every poster go with a presentation? I don't understand if all presentations have been finalized and this is asking presenters to create posters, or if this is asking for posters even if there is no presentation, etc. 
Using placement new on a buffer (of type char*) is perfectly valid. I don't see what you're getting at.
C++ still has a place on my polyglot toolbox. Some devs would gain a bit if they were more open minded, even if we are on r/cpp. This isn't the Highlander of programming languages.
Do you have any hard data on that (code that does the same thing written in c++ producing significantly bigger webasm binaries than in a different language?)
&gt; A unity build can cut down build times dramatically and is HIGHLY underrated and easily dismissed by many senior software engineers (just like precompiled headers). This alone almost made me stop reading. Not knowing the author, it comes across as a junior dev being frustrated with old curmudgeons without recognizing that their greater experience and larger picture view might give them a different perspective than a junior engineer. Really, the reasons people might resist - It seems there is a continuum of where people fall in how strong of "correctness" guarantees people want. The person might be at a different place then you and might, or might not, have valid reasons for it. - Some people, regardless of experience, are insulary and don't take time to learn new things.
My personal opinion is that I don't think they'll actually make the STL containers as noexcept as some think. I think too many people will want to switch on OOM throws, and the committee with baulk at the push back at say making `std::vector&lt;T&gt;::push_back()` noexcept if `T`'s copy and move constructor are noexcept, and the default allocator is configured. But that's okay, it'll open the STL2 door again. In terms of new code however, everything currently indicates a widespread desire for the default to become OOM = abort. So newly added standard library features, and the teaching of soon to become modern C++, would all assume that default OOM = abort. I'm personally highly unbothered about that, but then I am assuming P1031 *Low level file i/o* is into the standard, and that changes everything memory allocation related because doing stuff like constructing a 10 trillion item vector will no longer OOM in any case. If P1031 were not in there, or vector is still zero initialising itself at construction, then I'd be alarmed.
Personally, I'm cautious of the correctness issues but still experimented to see if the gains could justify the hacks. For us, we saw no build time difference between Incredibuild and Unity build on a 570kloc project (that pulls in headers for 10+ other DLLs) compiling with MSVC 9.0.
should be 2. also, with regards to your other problem, you can also not consistently dereference a null pointer. if you use optional references and they are empty, you made a mistake.
Yes but isn't the whole idea/purpose of webassembly to use the speed of the increasing power of the cpu devices that browse to sites? 
Didn't also Autocad created a working version in Webassembly? 
Compared to what?
The posters and the talks are two distinct programs at the conference. You can submit a poster proposal without being a speaker; posters are *not* required to be associated with any talk. We had nine posters last year, and IIRC, only one of those poster authors was a speaker.
Why can't std::vector use it, and then return (T\*)buffer in its data()? It'd be then possible to implement std::vector without UB.
Compared to hand-written (later) JavaScript for that particular task.
Yes, it seems so.
I only just realized: Your experience is based on emscripten which is completely different from webassembly. I'm not sure how this is relevant for the discussion at hand.
Just do what C++ does best and make it un/implementation defined
Is WebAssembly not just an Oracle-less Java?
If I wanted the effect of 1, I would do `*o = z`. There's no alternative for 2, so `o = z` should do 2.
There's an std-proposals mailing list where anybody can propose anything. It mainly full of inane arguments about syntax and people trying to turn C++ into Rust.
No, not [that turbo](https://en.wikipedia.org/wiki/Turbo_button).
You'd need to launder that pointer, but not really. How would that solve the problem of reserve()
The purpose of WebAssembly is to have some code in browser running at (nearly) speed of native code. The question is what you're going to do with it - what applications are made possible by it? So far, the answer mostly has been "games" (with both Unity and Unreal supporting web builds) and occasionally ported desktop applications (like AutoCAD example). WebAssembly might serve as a replacement for ActionScript for small and medium-sized games on the web, though plain HTML5 + JavaScript already has that niche pretty well covered, I believe. Bigger games are still a bad fit for the browser, because of storage space required. Multi-platform (desktop/web) apps? I don't know. Do people actually need them all that much? A few of them, sure, if they can really run smoothly in browser. But will new jobs appear in this sector for C++ devs because of ability to run desktop versions on the web? The world is already pretty used to writing new apps web-first, using JavaScript. And then there is a problem of UI: Qt might be able to work with WebGL as a renderer, but certainly not good old MFC or most other desktop UI libraries.
the GC is ^tiny, maybe a few kilobytes. what usually makes everthing giant is: 1. uncontrollable package madness because tons of transitive dependencies are pulled in and no one cares to optimize them out. 2. very large standard library. the jvm comes with thousands of built-in classes, so does c#, so does JS itself. 3. some (many?) modern languages come equipped with powerful runtime optimizations which (iiuc!) is a bit like needing a compiler in your runtime. C++ has a microscopic STL (in comparison), and there is no runtime optimization, and dependencies are often still manually managed. all things that make it very well suited for wasm. 
What about a shift to reduce API calls on the backend to just move some of that business logic to the frontend with Webassembly? 
I don't see any problem with reserve. It simply allocates a char\* buffer of enough size. And push\_back() only reallocates when the buffer is not big enough. Real objects are only constructed with placement new.
That is a possibility, but only as long as the data for the business logic is already present on the client side, or can be pulled from the backend without wasting too much time or traffic.
Yes it's needed ([basic.life]p8). &gt;It simply allocates a char* buffer of enough size. Okay. &gt;And push_back() only reallocates when the buffer is not big enough. Yes, but it needs to destruct its element and reconstruct them. See below. &gt;Real objects of type T are only constructed with placement new. Okay, but then `&amp;v.first() + i` is not valid, because you don't have an array.
Consider: template &lt;typename T&gt; class RefLike { T * ref; public: RefLike(T &amp; r) : ref(&amp;r) { } RefLike &amp; operator=(T const &amp; val) { *ref = val; } }; The above is very much like T &amp;. Should we special case `optional&lt;RefLike&lt;T&gt;&gt;` as well? 
I see, good to know thanks
I've noticed on std-proposals that if it's a language feature, it'll probably have a low signal to noise, but if a library feature, probably a high signal to noise, particularly if someone has implemented it already. I think actually implementing an idea is a great way of sorting wheat from chaff.
thanks! didn't know about that!
Yes, they demoed it at Google IO.
I just want to put my two cents: There is no guarantee that optimizations will pile up to reduce times. Some optimizations will synergy, others will interfere. That is another reason why measuring is so important. 
&gt;Okay, but then &amp;v.first() + i is not valid, because you don't have an array. I do have an array of char cast to T\*. Is pointer arithmetic not allowed in this case?
`RefLike` is not a vocabulary type available across codebases, and it doesn't error when put in Optional (or at least, it's not supposed to). However, seeing as it's a custom type, you might actually be able to specialize optional for it...? I forgot the rule.
What's wrong with `std::optional&lt;std::reference_wrapper&lt;T&gt;&gt;`?
&gt; (for a vocabulary type that everyone should be able to understand easily). and yet I don't remember anyone ever complaining with boost::optional's reference support 
&gt; Should we special case optional&lt;RefLike&lt;T&gt;&gt; as well? at least for std::reference_wrapper, yes 
&gt; With C++ - certainly, especially if you use templates. The amount of code generated by the compiler in this case is very huge. Presuming ICF/LTO, your C++ is likely to compile to *smaller* code than the equivalent functionality in C. Only intermediate objects tend to be larger. I've had massive template projects that had templates that spawned thousands upon thousands of instances. The intermediate object file was something like 2 GiB. It linked to 16 KiB.
Major: It's not taken as an argument very often, and it's not returned very often from functions either, which means creating wrappers around functions that do requires exceptionally irritating boilerplate permeated all over your code base. It also is not the same: `(*my_op).blah` is a hard compiler error, requiring `(*my_op).get().blah`. Minor: It's obnoxious to type.
I agree that your approach is better. But it's definitely more advanced and it's not immediately obvious how to implement it. The blog post presented a relatively simple experimental project where the author played with optional, any and variant. 
My point being, why would you expect `optional&lt;T&amp;&gt;` to work any differently than `optional&lt;RefLike&lt;T&gt;&gt;`. Or consider the non-logic: `T &amp;` does NOT work like `reference_wrapper&lt;T&gt;` so `optional&lt;T&amp;&gt;` SHOULD work like `optional&lt;refernece_wrapper&lt;T&gt;&gt;` 
`optional&lt;reference_wrapper&lt;T&gt;&gt;` already works the way people want. It doesn't need special casing. Maybe I misunderstand what you are saying.
`optional&lt;reference_wrapper&lt;T&gt;&gt;` has straightforward behavior that is easily understood by the natural combination of the the two classes. Special-casing this sounds like inviting surprising behaviors.
Oops, sorry, I thought I had deleted the comment before someone had a chance to reply. I was asking "what's wrong with std::optional&lt;std::reference_wrapper&lt;T&gt;&gt;"
This survey isn't proposing any behavior of optional; that's a paper, in the works (and even that paper evaluates the 4 existing in-practice and theoretical solutions). It is just an evaluation. That being said, I _am_ writing a paper to propose `optional&lt;T&amp;&gt;`. I plan to make it a Semi-regular type, but still make sure to address `RefLike` `reference_wrapper`, `rebind` and others. The conservative version allows the use cases of using it as a return type and a argument type. The rest of it is deleted to avoid the mess and shenanigans.
My first thought too
Right, I was probably jumping the gun a bit. I'll wait for your paper :-)
You don't have an array of chars anymore. That object'd lifetime ended when you used placement new. Also, you're violating struct aliasing. Pointer arithmetic is only allowed with arrays, yes.
awww, I haven't seen someone mention MNMLSTC Core in a while now :')
&gt; Should we special case optional&lt;RefLike&lt;T&gt;&gt; as well? No, you shouldn't write `RefLike&lt;T&gt;`.
That said, benchmarking with turbo disabled is also dishonest when many/most of your customers run with turbo enabled.
Signed chars or unsigned chars ? And can we defined signed bool ?
&gt; However there is a bigger picture here in terms of scalability over really huge code bases, and I am getting a feeling from the /r/rust feedback that there is an amount of disquiet with the consequences of Rust's choice of Result&lt;T, E&gt; and the current form of panics. This surprised me and I went over that thread and couldn't see what you were referring to. Mind pointing out some examples?
The Master theorem isn't directly applicable here because it assumes an O(1) termination condition, which is not the case here. That's why I said "squinting".
Maybe this isn't the place, but contest mode suggests to me that eventually the total score of each would be displayed. Yet I still don't see last quarter's points.
MSVC++'s library detects this case and dispatches to memmove -- we detect pointers-to-same-sized-integral types. And also pointer conversions that add cv quals. ``` // ALGORITHM DISPATCH TRAITS template&lt;class _Source, class _Dest&gt; struct _Ptr_cat_helper { // determines _Ptr_cat's result in the most general case using _USource = _Unwrap_enum_t&lt;_Source&gt;; using _UDest = _Unwrap_enum_t&lt;_Dest&gt;; static constexpr bool _Really_trivial = conjunction_v&lt; bool_constant&lt;sizeof(_USource) == sizeof(_UDest) &amp;&amp; is_same_v&lt;bool, _USource&gt; == is_same_v&lt;bool, _UDest&gt;&gt;, is_integral&lt;_USource&gt;, is_integral&lt;_UDest&gt;&gt;; static constexpr bool _Trivially_copyable = _Really_trivial; }; template&lt;class _Elem&gt; struct _Ptr_cat_helper&lt;_Elem, _Elem&gt; { // determines _Ptr_cat's result when the types are the same static constexpr bool _Really_trivial = conjunction_v&lt;is_trivial&lt;_Elem&gt;, is_trivially_copyable&lt;_Elem&gt;&gt;; static constexpr bool _Trivially_copyable = is_trivially_copyable_v&lt;_Elem&gt;; }; template&lt;class _Anything&gt; struct _Ptr_cat_helper&lt;_Anything *, const _Anything *&gt; { // determines _Ptr_cat's result when all we do is add const to a pointer static constexpr bool _Really_trivial = true; static constexpr bool _Trivially_copyable = true; }; template&lt;class _Anything&gt; struct _Ptr_cat_helper&lt;_Anything *, volatile _Anything *&gt; { // determines _Ptr_cat's result when all we do is add volatile to a pointer static constexpr bool _Really_trivial = true; static constexpr bool _Trivially_copyable = true; }; template&lt;class _Anything&gt; struct _Ptr_cat_helper&lt;_Anything *, const volatile _Anything *&gt; { // determines _Ptr_cat's result when all we do is add cv to a pointer static constexpr bool _Really_trivial = true; static constexpr bool _Trivially_copyable = true; }; ```
If it was a simple as that it would be settled. The contract/mental model of an optional&lt;T&gt; is "either it's empty or it acts like a T". If optional&lt;int&amp;&gt; does not behave like an int&amp; then you've broken that. Also along this line of reasoning, it doesn't have rebinding because int&amp; doesn't have rebinding, so that's a feature, not a bug. Some would also say if you want a maybe unset, rebindable way of referencing another object then you are looking for optional&lt;reference_wrapper&lt;T&gt;&gt;, or even just a T*.
You're not rebinding `int&amp;`, because the assignment operator is being called on an `std::optional`, i.e. you're changing the value of `std::optional&lt;int&amp;&gt;`. It sounds rather complicated to apply reference semantics to the whole type, and weird because it may be empty.
By that logic `optional&lt;int&gt; x; x = 1;` should be a compile error because "1" is not an object of type `optional&lt;int&gt;`. `optional::operator=()` forwards to `T::operator=()`. To do something different for references is then special-casing the behaviour, and that isn't usually a good thing. I'm not 100% taking sides here, but understand there are valid arguments for both semantics. For `std::` the committee decided not to pick a side and just not support it.
Unity also has a custom build of Mono
&gt; Signed chars or unsigned chars ? or plain chars?
&gt;I thought we had learned our lesson with std::vector&lt;bool&gt;. Apparently not. There still is no way to express dynamically sized array of bits in C++. Other than std::vector&lt;bool&gt;, that is.
As an example, last year I gave a talk/presentation on data structures. Unrelated to that, I also co-presented two posters on different topics - one on game engine architecture and another on an algorithm. 
C++ in a nutshell sadly.
The super-conservative solution is to `=delete` the assignment operators of `optional&lt;T&amp;&gt;`. It would still be useable for all the use-cases people care about, and it wouldn't confuse anyone by unexpectedly having either behavior at runtime. Move error-checking from runtime to compile time!
This is typical pipelining problems in CPU.
It makes sense for a large application, but for microbenchmarks it hurts repeatability.
I agree with you, type erasure has many problems and templates can usually work better.
Why would it be bigger though? Also the comparison only makes sense at equal performance, so if the C++ compiler does more optimizations, it can take more space but perform better.
Linkers are smart and will throw away code that isn't called. So templates only get large if you abuse them. I'm pretty sure they can merge different instantiations of templates that end up being the same code as well (like a `char` and `uint8_t`).
&gt; The contract/mental model of an `optional&lt;T&gt;` is "either it's empty or it acts like a T". Huh. I always thought of it like a `T*` that can't do pointer math and is slightly easier to use. 
I'm not sure that I'd write a menu system in C++.
It's basic in concept but it has the potential to eliminate the need for a lot of exception handling. (It might also become the next Java-enterprise-like nightmare, I can't say because I haven't used it since we're still working on migrating to C++11.)
Isn't the CPU doing this at this point?
&gt; But how many sites, or even web-apps need that speed? We will see &gt; Most of them aren't doing heavy computations in browser, and should not be doing them. Because right now that would be slow &gt; OK, maybe if client-side neural networks will become more widespread, we might need WebAssembly to run them in browser What the fuck are you talking about 
Probably the include had the rest of the template definition. Remember the include is run before compilation... so you can't template it obviously, but you could template whatever is inside it, which _should_ work.
Google has been using [autoFDO](https://github.com/google/autofdo) to achieve continuous profile-guided optimization, which leads to 10.5% performance boost by better-separated cold/hot paths. Unfortunately their patches are based on gcc 4.8. Hope to see some open-source projects to incorporate their work into a popular orchestration engine like Kubernetes.
The key is to do enough runs to give some statistical confidence in the answer. Higher variability requires more runs for confidence.
And what is that supposed to mean?
I don't use any optional, but that's not an option in your survey.
It does make microbenchmarking hard, but your user doesn't care about your microbenchmark. When looking at vectorized code vs. non vectorized code, for example, the additional power consumption of the vector instructions matters. Same for parallelism. I suspect maybe 80% of the time when optimizing stuff at the source level, if this matters for the benchmark, there are bigger fish you can be frying :). (macrobenchmarks are another story of course, but at this level you need fairly big gains to move the needle in real deployment)
Except for many embedded people with a single return policy (see e.g. ISO26262). Maybe allow for copy/move assignment, but disallow value assignment? 
It's true that the additional power draw can be a problem. Also some solutions will work great with HT while some will make it suffer hard. Maybe the additional power draw will reduce frequency enough that the other solution is better... Well you have to measure and it's a pain. Especially because maybe your rig is watercooled so you can turbo harder than your client, so your numbers don't match... It's really hard to optimize a program well, and starting with some performance monitor to actually check where the bottlenecks are is what everyone should do first. Not worth wasting time on optimizing a function you call once in your program.
That's true. It's one of the reasons we avoid this kind of stuff in the standard library unless we get multiple X improvement rather than percents, because we don't know exactly how people use the library, and want to be really positive it's worth it and not a pessimization. Unless we have some other data showing us being stupid, like the _Inside checks I burninated from our basic_string.
I completely get your point. Anything in the single digits tends to be very hard to judge if it is actually positive or negative. I actually wonder how Intel benchmarks their designs with all the small improvements, because many changes improve something but make something else worse (especially tuning on branch prediction and prefetching).
No it doesn't. Because if I have a function that returns a `T&amp;` and I want the optional of that, that's not `optional&lt;reference_wrapper&lt;T&gt;&gt;`. Generic code ends up in `T&amp;`, and having to change all reference types to reference wrappers is an unreasonable burden. struct X { }; struct Y { X x; }; optional&lt;Y&gt; opt = ...; auto r = opt.map(&amp;Y::x); `r` should be an `optional&lt;X&amp;&gt;`. It _could_ be an `optional&lt;X&gt;`. It definitely is not `optional&lt;reference_wrapper&lt;X&gt;&gt;`. So no, it doesn't work.
Optional is mandatory.
&gt; There still is no way to express dynamically sized array of bits in C++. sorry what ? If you restrain yourself only to the standard library maybe, but by that logic you can't write *any* code since every line you will write will be outside of "C++". 
Intel probably uses macro level benchmarks like spec. And they have good ideas about what parts of the chip are busy because they designed it. And they have incredible profilers like vTune.
I haven't looked into autoFDO, but it sounds similar to what Facebook open sourced recently, [BOLT](https://code.fb.com/data-infrastructure/accelerate-large-scale-applications-with-bolt/) ([GitHub repo](https://github.com/facebookincubator/BOLT)).
&gt; The contract/mental model of an optional&lt;T&gt; is "either it's empty or it acts like a T". Strong disagree. I don't think anyone should work by having a "mental model" of what a type is : the only thing that should matter is the code of the type and the syntax &amp; semantics of the language. Everything else is just fluff that is bound to lead you to a mistake one day or another.
Yes. Id rather not write code someone already had written. If the std::vector&lt;bool&gt; was a mistake, it clearly wasn't rectified till now. Just deprecation/removal of it wont be the fix either.
&gt; Yes. Id rather not write code someone already had written. so just use boost::dynamic_bitset or one of the dozen alternative implementations ? 
I will (though since vector&lt;bool&gt; works for me there is no immediate reason to do so). As i did boost::shared_ptr, boost::thread or (gasp) boost::optional.
Mostly because you need more instructions to convey the same meaning/purpose as a high-level JS statement might "encode". Also, JS code will still have its standard library (even it's not a big one) readily available in the browser, whereas any WASM application needs to ship its own. But of course you're right the C++ code will often have better runtime characteristics. The bigger size just makes the startup cost higher. How much it matters often depends on the connection used, in many cases it would be negligible.
One of my old colleagues was profliling a memory bound application (FEM) and he noticed his benchmarks were running faster while he was compiling. It turned out the memory controller frequency was correlated to the CPU frequency. So while the app was memory bound the CPU was mostly idling and clocked the memory controller down. He jokingly showed me his "fix" which gained him \~20-30&amp;#37; performance improvement: std::async([]() { while (true); }); std::async([]() { while (true); }); The performance peaked at 2 threads keeping the CPU busy :P
 const auto d3 = foo.GetData(); &gt; A lot of developers assume that d3 is of type `const Data*`, but in fact, the type is `Data* const`, so it’s a const pointer to a non-const Data! Putting the const after the auto as follows doesn’t help, the type is still `Data* const` So much this. The difference between `const auto` and `const auto*` is huge.
if GetData returns a const Data *, then d3 is const Dara * const or just const Data *?
Why use auto at all in this situation? What does it add to aid code correctness?
What if you have a type named `var`? Hence, must be keyword. 
`auto` was a preexisting keyword. Grabbing `var` probably would've been impossible. 
For me, the simple answer is flexibility: if you use GetData() in 1000 places with using Data* and you want to give the Data type more descriptive name e.g. ErrorData than you'll have a long diff that is mostly renaming the data type.
["Almost always `auto`"](https://herbsutter.com/2013/08/12/gotw-94-solution-aaa-style-almost-always-auto/) is a popular policy for "when to use `auto`" - it makes your code much more useful for generic programming, and it makes it a faster read. As for code correctness, my experience shows that there are arguments on both sides. I've seen mistakes because the writer had misunderstood what type `auto` really was in the expression. I've also seen `auto`-free mistakes where there was an invisible cast because someone got the type of the return value of an expression wrong - something you can at least mitigate by turning your compiler warnings up and by consistent use of `explicit` in your own code. 
If function returns pointer-to-const and you use `const auto` then it becomes const pointer to const.
Isn't that similar to trace scheduling, which is done by GCC PGO?
That's correct.
Incidentally, wasm-bindgen is written in a language-agnostic way; it could be the foundation for similar support for C++.
It is not.
Is that really a bad thing? A large diff tells the reviewer that something big has changed and they're likely to pay more attention to it, instead of a small one-liner that they may gloss over. A counter-argument would be a code change from `int doSomething() { ... }` to `const std::string&amp; doSomething() { ... }` and all the 1000 call sites used `auto result = doSomething();` you're silently making string copies all over. But hey, the diff was small so it must be correct, right?
Understood. But this implies that it's impossible in standard C++ to construct more than 1 object in a pre-allocated storage because you have to use pointer arithmetic in this case. Not being able to construct multiple objects in a single char array and then using pointer arithmetic looks like an oversight rather than an intentional behavior. Especially that it renders standard conforming std::vector implementation impossible.
I never said that. But I will be concentrated on logical changes instead of long scrolling down to find where logic is actually appears.
'AAA' made me cringe when I read it, maybe I'm too old-school. I'd also argue that making something faster to read doesn't make it faster to understand and analyse.
See also the likely and unlikely attributes in C++20: https://en.cppreference.com/w/cpp/language/attributes/likely
Sorry, I can't see how the first approach is considered "inefficient".
naw you should be doing ```auto&amp;&amp; d3 = foo.GetData();```
&gt; Sorry, I can't see how the first approach is considered "inefficient" look at the benchmark in the video mentioned at the beginning. I'm pretty sure there's an explanation somewhere in Odin's blog but I cannot find it : http://odinthenerd.blogspot.com/ 
In the first one, you instantiate a type for each set of template parameters. In the second, you only can instantiate two type. Conditional with true or with false. These two types are memoized and reused. Then, only an alias is used for all other possibilities, which is much faster than instantiating many types.
Most of the time the type of something doesn't actually matter, rather what the variable represents is what matters. If it's not immediately obvious what the variable represents then it's probably poorly named.
Any mildly performance oriented CPU uses cache. And cache has a granularity called cache line size. (Nearly all x86 use 64 byte cache lines) So even if you only read a single byte, the whole cache line is read from memory into the cache. And uses up a whole cache line until it gets thrown out. Cache is a limited resource and you get the best CPU performance if you use it efficiently. If you put all your most used data together and away from data that you need less often (at last in this moment), then you get more use out of the cache. A big part of modern optimization is to be just being nice to the CPU.
const Data* const. You'd need a const_cast to remove the constness.
As for the case const auto* const d7 = foo.GetData(); the first answer to the Stackoverflow post at [https://stackoverflow.com/questions/47291244/behavior-of-const-auto-pointers-in-c](https://stackoverflow.com/questions/47291244/behavior-of-const-auto-pointers-in-c) mentions that one "should probably just use a reference" for that case. Intrigued by this answer, I was wondering if for that case one should *always* use a reference, or are there situations that I'm overlooking where one really would want to use `const auto* const` instead of using a reference?
You'd notice as soon as you use result.
how you notice yourself using a copy of something instead of using a reference to something?
Using AAA became more consistent in C++17 with copy elision and will be a 100% consistent way to initialize variables when aggregate initialization with parentheses lands in C++20.
How good is the JS standard library? It must suck if people need to make left-pad or is-odd packages. Also considering the common JS bloat, it's probably hard to make it as bad.
I'm not saying 'don't use auto'. Herb's article has resulted in me seeing things like `auto i = static_cast&lt;int&gt;(0);` It's not the silver bullet people seem to think it is.
auto i = 0; is the right thing here because the type of the literal is known. Otherwise, auto i = int(0); would suffice.
The real difference between `const auto * const` and `const auto &amp;` is that the former can be null while the latter cannot. I can't actually think of a real world scenario where I'd want to return a `const` pointer though, let alone a case where I'd potentially want that pointer to be null.
Because a `std::string` (whether a copy or a reference) behaves quite differently than an `int`. In generic code this might be harder to detect, but in non-generic code it's most likely going to break compilation very quickly.
that's why I prefer T const*
Why!? What's wrong with `int i = 0;` Nothing, except it's not cool.
\&gt; non-generic code it's most likely going to break compilation very quickly. AAA makes that actually quite unlikely to happen. It will fail to compile at some point if you're lucky.
&gt; aggregate initialization with parentheses lands in C++20. so... back to the most vexing parse it is ? 
s/cool/consistent/g
`auto v = T();` or `T v = T();` is the form I'm talking about. No vexing parse here.
I mean, it makes sense. The base type is 'pointer', which is made const. Why would it make the indirection const?
If you bothered to assign the `int` return value to a variable, you were presumably going to do something `int`ish with it: do math with it, assign it to a member, pass it to a function taking an `int`, etc. All of these would fail, if suddenly given a `std::string`. Sure if you were only planning to assign it to a `std::any` or `std::variant&lt;int,std::string&gt;` that could be a silent bug, but it could actually be doing the right thing automatically depending on what you were expecting.
I mean the change from `int` to `std::string`. There's probably a check like ``` if (result != 1) { ``` which now has to be changed to ``` if (result != "ok") ``` or something like that. Meaning that either the diff won't be so small after all or the code doesn't compile. Anyway: Most of the time you shouldn't be returning a reference anyway.
This is rather clear. But people will likely not spot that adding an asterisk changes the const to be inner-const applied to the pointed object, not the pointer itself.
It's nice how the article demonstrates `const` positioning games won't help you here ([west vs east](https://www.youtube.com/watch?v=oesOC7JvcwQ)), only [comprehension](https://nosubstance.me/post/constant-bikeshedding/#learning-through-comprehension).
&gt; A large diff tells the reviewer that something big has changed But something big didn't change; a class was renamed
I’m sorry but using auto like this is just silly. The whole purpose of auto is to make your code more readable. Passing raw pointers and then assigning them to const auto* achieves nothing, in fact it confuses people. In cases like these be explicit.
The way they derive the acronym at the bottom of the page is pretty funny.
Thanks. But I really think it should be mentioned in the article as it is definitely not "obvious". Especially to someone who doesn't have experience in compiler backends.
Nothing wrong, but that `auto i = static_cast&lt;int&gt;(0);` is ridiculious and no argument against using auto. If you saw someone write that in an attempt to use auto properly they ought to get a refresher on C++ type deduction.
I am aware, that it is possible. AFAIK the generation for Rust is mostly complete in contrast to generation for C++. This is why I left open for which language bindgen generates and only said, it is written in Rust.
I completely disagree. C++ is all about types, and hiding them is going to end in tears. A simple function like this has wildly different semantics depending on whether `GetPointerToBar()` returns a `Bar*` or a `unique_ptr&lt;Bar&gt;`. void Foo() { auto bar = GetPointerToBar(); bar-&gt;Baz(); } Likewise, code like this will have wildly different performance characteristics depending on what types are used to "represent" a list of items. auto items = GetItemList(); std::sort(items.begin(), items.end()); IMO, `auto` is best suited for eliminating redundancy in places where type is obvious. auto foo = std::make_unique&lt;Foo&gt;(); std::vector&lt;Item&gt; items = GetItems(); auto it = items.begin();
Oh totally! If we weren’t in /r/cpp I might not have mentioned it, but I thought it would be relevant here. 
Another day, another CMake guide (practical, modern, ...) Microsoft missed out on a huge press opportunity by making it so easy to compile a bunch of files with that user interface; had they chosen to develop a little mini programming language just to describe that stuff, people would be writing book after book about it until the end of time, like we have with CMake...
do you mean like [MsBuild](https://msdn.microsoft.com/en-us/library/dd293626.aspx) ? /s
In neither of your first two examples does it matter what the types are. In the first example all that matters is that it's a pointer. It doesn't matter whether it's a raw pointer or a unique pointer the usage is the same. In the second example the type of collection again doesn't matter. You made the argument that they will have "wildly different performance characteristics" but how does that change if you explicitly state the type? The function's always going to return collection X and you're still needing to sort it.
auto doesn't specify anything about the indirection type or depth of your variable. The specifier works the best in combination with something like intellisense. If developers are writing const auto and expecting the const to permeate to the indirection object, then its the training that's wrong.
Given that references cannot be reseated, why would you ever expect (2)? 
&gt; The whole purpose of auto is to make your code more readable. Not really. It is to avoid long type names that are obvious and/or irrelevant (eg iterators). Using too much auto impacts readability because you hide information.
This implementation of conditional_T has been used by the kvasir metaprogramming library forum some time and described in one of the first blog posts about the library :p
ISTR that it also can be less efficient under some usage patterns...
AAA is really only useable because Visual Studio shows the type if you hover your mouse over it. Otherwise it would be a nightmare to work with.
So here is a little context on the author Craig Scott. He is currently a co-maintainer of the CMake project and most of his work is behind the scenes doing code reviews, helping other developers figure out new features, and helping first time CMake contributors navigate the contributing process. I can't say enough nice things about Craig, and I am looking forward to reading his book. 
&gt; Since the `bool` type does not support the full set of arithmetic types, it is no longer considered an arithmetic type I don't think that's true (no pun intended)
No.
It certainly does matter in both examples. Whether the code is correct/performant or not depends entirely on what the return type of the function is, and `auto` hides that from the reader. You don't know what `Foo()` does unless you know the type of `bar`. Likewise, you have no idea whether sorting `items` is a good idea or not, without knowing what sort of container you have.
By the standard, `bool` is still an integral type and integral types are arithmetic types. Changing this would also likely introduce a new type trait, too, because the mutually exclusive type classification traits would no longer cover all types.
OK, but what is your alternative?
&gt; You'd need a const_cast to remove the constness. Common now we aren't savages.
That's a fundamentalla missunderstanding though, std::optional has value semantics making it behave wildly different
How is this book ? And why is this not sold in Amazon ?
`auto` takes the place of a type name, so using `var` as the type inference keyword would have broken code that used `var` as the name of a class. Because of where it occurs syntactically, this is not an issue with `final`.
Even if you return const auto* const the caller copies the pointer and may or may not store it as *const
I am unable to crash MSVC with this example, what version are you using?
Wow, something I can use today. Thank you.
Then you just don't fill out the survey. Unless you have a vested interest in optional and the direction it goes, silence is assumed to mean "Don't Know / Don't Care / Not Part Of My Featureset". Because this is a library change, it's very easy to simply ignore it's existence and get along just fine without it.
&gt;Not really. It is to avoid long type names that are obvious and/or irrelevant (eg iterators). ...or to be used with types which can not be named (e.g. lambda). 
indeed, forgot
Are you saying it’s *false*?
Honestly, my few friends encounters with MsBuild convinced me that it's enough like Ant on the surface that I'd rather generate the build descriptions with my own scripts than try to maintain the actual XML with its minimal capacity for abstraction expression in a large scale project. Even better than my own scripts is leveraging cmake to do the heavy lifting.
Terribly sorry my original post wasn't clear enough. I didn't mean it as "Oh no, my preferred answer isn't there! I don't know what to do with myself.". I meant it as: "Dude, there's a big glaring omission in the survey design".
There is no big glaring omission. If you're not using optional, then what exactly are you supposed to contribute to a survey that's asking *about* optional's uses? There's an "Other" answer if you need to say "not using one", but still have to answer the other questions of "this is the direction I would like to see optional move in". But that's only a tangential part of the survey: I am querying user experience right. "How is this used in industry, homebrew, open-source and other locations?" If you don't have any experience (and are not interested in that direction), why do you want to fill out the survey and what is your opinion supposed to bring to the table?
Why did they deprecate `&lt;codecvt&gt;` without coming up with an alternative first? :(
I think they said they are deprecating it to clear the way for a better replacement, I think the idea is it won't be removed until replacement exists. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0618r0.html
Because deprecation != removal. it just says "hey we're doing something with this, be prepared" so we can be prepared for the alternative whenever it comes.
It's true--
The only decision I disagree with is the removal of random_shuffle. It's part of an unfortunate trend of C++ making simple operations difficult. 
depends too, if GetData( ) returns T const *, the constness isn't lost.
Join the postmodernist code movement you ancient traditionalist!
This is why I prefix all names with type identifiers /s
@Supel97 can you tell me how did you get comfortable with template metaprogramming? 
Doesn't change much really: std::shuffle(begin, end, std::default_random_engine {});
`Foo` gets a pointer to bar and `Baz`'s it. Those functions should have clear names that describe what they are and why you'd call them. `Foo` then composes those two operations. The fact that `GetPointerToBar` (whatever is real name is) returns a `shared_ptr` or `unique_ptr&lt;some_type, some_deleter&gt;` or a `some_type*` really is an implementation detail. I mean, for a pure `unique_ptr&lt;Bar&gt;` I know that it did a heap allocation, so that is some performance information, but I don't know if the `Bar`'s **massive and expensive state** is owned by the `unique_ptr&lt;Bar&gt;` or not; to know that I'd have to look inside `Bar`. Well, and at the name of the function; because a function that creates a large expensive object should have a name less innocuous than `GetPointerToBar`. `CreateBar` at the least. As for sorting; returning a non-random access list you'd ever want to sort is considered hostile. Heck, using a non-random access list is generally hostile. Forcing someone to annotate "this isn't actively bad code" with the type of the specific random-access list there isn't very useful. The fact that `GetItemList` was broken, if it is broken, was long before that code was written; auditing it when new code is written seems like a waste of time. 
I don't like how the old style `rand()` hides the fact that PRNGs are stateful. It is not thread-safe. Explicitly passing/instantiating the PRNG state makes it easier to write code that uses a PRNG but is still deterministic, which is important for testability. Plus, `&lt;random&gt;` gave us all the probability distributions -- I'd say that's worth it already :)
Is this it? Is this finally the resource to get me to learn cmake? Has anyone had a look yet or is it too new? Is there a trial intro chapter or two somewhere? I've been spoiled at my current job. The project compiles just fine, and I only have to jump into a makefile every 6 months or so when adding a new feature that could benefit from one. I've always wanted to try cmake, but it's always seemed like a big giant mystery of memorization and confusion. *Heads off to find a free sample, if there's one to find*
--true
Typo in sample PDF, page 103, bottom of the page. The CMAKE_BUILD_TYPE should read [MinSizeRel](https://cmake.org/cmake/help/v3.12/variable/CMAKE_BUILD_TYPE.html)
It's truen't
Because everything needs fancy names nowadays. Just like how you don't have a real security threat without a good name/acronym. The same goes for template metaprogramming patterns.
I really hope not. C++ is only around because it's always been around. I've grown a very Stockholm-syndrome driven love for C++, but if there's no backwards-compatibility motivation involved then C++ shouldn't be an option for any future project. I work on worldclass projects with millionaire engineers who still write unsafe, shitty, goto-laden C++ code. Until the opportunity disappears for such code it will continue to exist. 
I have not yet watched the videos, but they are marked for later viewing. If there is one single language I would like to learn it's `lua`, being able to integrate that with C++ makes this highly attractive. Thanks, good stuff.
Let me paraphrase your own post title: "optional - what's in YOUR codebase?!". No optional, that's whats in my codebase. Furthermore you exclude people that do know about optional, but still don't use it for whatever reason. Perhaps it's not used because it doesn't have those features you're asking for later in the survey? Perhaps I don't want to implement my own version, and am waiting for improvements? Also if you'd really be interested in the use of optional, don't you think that a piece of information such as "x% don't use it at all" would be nice? Limiting your survey to people that already use it is unnecessarily limiting your survey audience.
Just came with time, right attitude, a lot of experimentation, and a lot of learning material such as cppcon lectures. I still have a lot to learn though.
Automatic type deduction in languages, helps a lot during refactoring. But if you are using C++ it is just BS. C++ is a big ball of mud that whenever you try to pick up a shiny simple pearl out of it, that comes with the stink and stickiness of the mud.
http://coliru.stacked-crooked.com/a/3e50d8119a297104
Lua is not the only language you should learn. But if you want to learn an embeddable language then i think Lua is the way to go. I love that it is smiple, has the extensisiblity required to make it do what you need and doesn't do things you don't need.
Yup, `&lt;strstream&gt;` has been deprecated forever but since there's never been any replacement it has never been removed from the standard library.
I do agree that they should have incorporated the `std::shuffle` overload from Library Fundamentals TS v2 that doesn't take an URBG before getting rid of `std::random_shuffle`.
The deprecation/removal of `std::shared_ptr::unique()` (instead of fixing it) is still annoying me.
&gt; Because deprecation != removal. it just says "hey we're doing something with this, be prepared" Deprecation is a precursor to removal. I don't read deprecation as "we're working on it" as in a language that is actively being developed, that's a given. I read deprecation as "we've replaced this with a better alternative and you have a limited time to upgrade, because we will remove it in the future." I mean, *unless* it means that, it's absolutely useless, because there's no action I can take.
&gt; Whether the code is correct/performant or not depends entirely on what the return type of the function is, and using auto doesnt change the return type of the function, making your examples entirely irrelevant because auto or not they still return the same thing with the same characteristics. You're not dynamically calling random unknown functions at runtime or whatever you think is happening. You're choosing to call it. You know the return type, your IDE probably tells you too. Whether you feel like writing the whole type out or using auto, its still the same type, with the same performance characteristics, whatever those are.
And how has it "cleared the way"? What options are now available that weren't before the deprecation? Does the non-deprecation of codecvt somehow preclude the development of an alternative?
Yeah, `&lt;random&gt;` is still a catastrophy usability wise
The deprecation/removal of `std:: shared_pre::unique()` (instead of fixing it) still annoyes me.
Does this cover smart globs (CONFIGURE_DEPENDS) introduced in v3.12? Maybe some in-depth info, for example does it use file system watchers? (Bazel does for the same effect, AFAIK)
It is impossible to fix.
How would you fix it? It suffers from tocttou problems in parallel environments. There's no guarantee the value you see is correct the moment the read of the count completes, since another thread could've destroyed/created a reference at the same time. I guess they could weaken the specification of the function to say it's not accurate, but then what's the point?
I've just read through half or so of the sample PDF and I think it's written in a great way, it mentions many best practices and the common ways that things are done wrongly (and the better/newer alternative). Makes me want to buy the book, and I probably will.
It is actually very simple if you don't share references to shared pointers across threads (why would I do that in the first place?). In that case, if the ref count is one, there is no other thread that could perform a copy at the same time. So if unique returns true, you know you are the only one. This was also discussed a bit in the linked SO post
Sure it is (actually very trivial): You only need to make sure that the read of the ref count in unique() synchronizes with the decrement of the ref-count in the destructor. The decrement has to be an release operation anyway (because it has to synchronize with other destructors) so all that's left is to make the read an acquire operation.
&gt; How would you fix it? My first thought is to add a do_if_unique() function that takes a lambda, all performed within a mutex. But that means it has to use a mutex internally which is less than ideal.
This does not generate any code, so does not reach compiler's backend. It is handled is a frontend. 
&gt; libraries like opencv are pure hell on windows What? Only people who do not know how to use CMake. Yes I am not a big fan of OpenCV's cmake scripts but nonetheless it's dead simple to build on Windows. (And now it got even simpler and you should use vcpkg, as /u/Reallifeniceguy mentioned.) &gt; most devs use linux They don't actually, Windows has a significant share. Don't just believe every bullshit that you hear.
`-B` and `-H` are internal options that shouldn't be used publicly. There's a post about it from Brad on the CMake mailing list from years ago about that, sorry I don't have the link handy,
That's definitely not enough. There is a TOCTOU problem remaining. You are supposedly going to use `unique` is a code like this: if (ptr.unique()) { do_something(ptr); } The problem is that when you reach do_something, the `ptr` may not be unique any more. (How this can happen is left as an exercise for the reader. Hint: `weak_ptr`).
I know, but they are very convenient and I am gonna use them until they remove them, or give them different semantics.
Then let unique() also count weak_ptr?
Yes, that could be done. But that would be backward-incompatible change, so better give it a new name. 
Also, you can break this, if multiple threads have a reference to a single shared_ptr, but my answer here would simply be "don't do this, give each thread it's own copy" (which is generally a good advice anyway). You can't make it foolproof, but very few things in the standard library are.
I would be fine with that too, but as far as I know it just gets removed without any replacement whatsoever. (for my use cases, just counting the strong references would be enough too, but I see the danger there)
Well, there is still `use_count`.
No, c++ is not terrible language. It is a very difficult language to master though. Since there isn't another wildly used language with similar features, programmers that come from other languages have a hard time adjusting to it. 
Lol Elon straight up said yes 
It is not terrible. It's a DarkVador Bible !!
They prefer Matlab. 😂
There are "other" boxes, to fill in extra answers that didn't come as part of the stock survey. As I said, I'm not fully clairvoyant as to what everyone wants: that's the point of the survey. Tick the "other" box, say "no optional", tick the additional box for the question below that, "The optional of my dreams includes ...". Note that the question phrasing says what you *wish* to be in your optional, not what's already in everyone else's. I am, obviously, not All-Seeing. FWIW, other people have already filled it out, said 'Not using it', and many more wrote down special custom features and implementation details for the desired (but non-existent) optional.
It can also mean "we are planning to replace itin the future so avoid using it if possible". No need to have a replacement ready at the moment.
what if weak_ptrs comes into play with it? (i didnt thought a lot about it, just brainstorming problems to the discussion)
In fairness, Elon then goes on to triple-heart Python, which is just as deep a well in terms of difficulty of mastery as C++. I suspect that Python doesn't get as bad a rap as C++ because not as many people have been confronted with terribly written Python, despite that just as much badly written Python exists as badly written C++.
SFINAE, weak typing, no concepts (so far), no modularity, no (decent) sum types, NULL, terrible grammar. Ada and rust are pretty decent in the field.
I’m curious to know what you use it for. Not judging or anything, I’ve just never had a scenario where I cared about the uniqueness of a `shared_ptr`. 
Oh god this again
C++ has come a long way. C++17 feels almost as a new language compared to C++98. Just give it another try.
Yeah, given the existence of Amazon’s print-on-demand service, I’m curious why there isn’t a paper copy available. Call me old fashioned, but I prefer physical books for this kind of reference. 
This looks good! Also, btw, the video link doesn't link to a YouTube playlist, it points to a standalone video right now
Thanks, I've fixed the links in the post to point to the correct playlists.
It's something that I don't understand. People always compare C++98 to any new language, instead of comparing c++17 to that new shiny language. If you are going to have a project in new_shiny_language, you will have to start from scratch anyway, so it's unfair to compare it to the old code written two decades ago in c++ when it was a bad language.
Listing of talks and speakers in august, as I do have to rewrite this part of the CMS now :) Old system isn't able to cross reference between to DataSets, which is needed to link talks to speakers, and speakers to talks... ... but for the CMS this needs to be a general, generic system, which has no idea about speakers, talks or what its actually displaying there...
After glancing over cppreference, my conclusion is: If it doesn't compile without the copy constructor when compiling as C++17, it is not a "candidate" for guaranteed copy elision. Which means that conceptually, the global pointer points to a temporary object that has gone out of scope. So no, I don't think this is, nor should be, valid.
Likely the shared ptr is being utilized more for reference counting/tracking than shared ownership. Not the intended use but I understand the motivation given the lack of a more suitable standard library component for this purposed.
Looks like I misunderstood guaranteed copy elision, so yeah, not valid.
C++ is a great language when you know how to use it. Learning it is the only problem.
I actually wonder if you could arrive at that by just rote applying linter suggestions or other automated refactoring tools without knowing what you are doing. The interesting thing is it seems almost contrived like some kind of strawman argument to beat down AAA but if this is actually code that crosses your path in projects its an interesting observation about *teaching* AAA. Also other people only replied 'consistency' in AAA discussions but say this `int i` is somehow not in a `for` loop but in a block of declarations and assignments then it could make sense to use `static_cast`s if others were as well? But that would be hard because `i` itself isn't a descriptive name outside of the loop case...
It's not just about the language version. A lot of people have access to C++11/14/17 but don't know neither what features it offers nor how to use them.
I think difficult to master is less important than easy to start. Python is a language you try and half a day later you walk away happy and with a useful program. Many people also walk away from C++ after half a day, but they won't be smiling. I like C++, but I only ended here because someone paid me to get past the first few hurdles.
This is the prime example of how throwing random non-arguments looks like. I hope trolling brings some joy into your life.
Python with boost::python is also astoundingly easy. I'm looking at Python and possibly GoLang integration for several of my libraries at work. The Python stuff is already working great. I'm also serializing data to json for web services, but don't really like how the boost library I'm using for that works.
Nö, you are right. My use case didn't have any weak pointers (and actually used proprietary shared_ptr that didn't have weak ones) but technically it shouldn't be a problem to also query the weak ref count. As /u/encyclopedist mentioned that would change the meaning of it - but it would fit perfectly for me ;).
Without a background in computer science, I have been studying C++ over the past year. Granted, I'm not there yet, but I have not found, at any point, the language very difficult, but learning it a very fun and rewarding experience. What's important to consider, I guess, is your limitations when you're learning it and good learning material. In contrast to HTML, for example, where you can quickly learn to build beautiful websites, but even then, you become quite limited if you stick to only HTML. If you want to build websites that actually provide value, you will have to learn PHP, JS, SQL, etc. and need to work with other people. It can take years to fully master that and unlock all of its potential.
What? Which of this terrible flaws of a language are not arguments for proving its dreadfulness? Are you a fun of std::variant abomination instead of safe and sound sum types? Unsound templates instead of neat and sound parametric polymorphism? NULLs instead of decent option types?
Most of the suckage is really in the libraries. STL has been OK (not awesome) for a decade or so. Boost addresses a lot of stuff the STL doesn't cover. Sometimes they even document their libraries! Often boost feels over-engineered. But, in writing my own libraries for the past 8 years or so, I find that if I design the library to accomplish a task rather than just provide a bunch of tools that a domain specialist could use to implement something themselves, it really becomes very easy to use. And so far no other OO language I've tried can touch the speed. I could keep programming in C, but it's MUCH better than C. And I can still bust out some ASM if I ever need it (so far I haven't.) So there you go. YMMV. Don't write or use shitty libraries, or you're gonna have a bad time. It really doesn't matter what language you're using, if you do that.
Python is great, if i have any utility style tasks i need to write, then my goto language is to do them in Python (and very quickly). But i've not tried using it as an embedded scripting language. I'm sure Python works fine, but for me, i really love Lua's appeal of being a bare bones embeddedable language, which then allows me to make it do what i want and nothing more. Being able to embed Lua and run a script in about 3-4 lines of code is such a great thing. What is the saying... "Any fool can make something complicated, it takes a genius to make it simple".
Essentially caching of objects: An array lof shared pointers to those objects is kept inside a factory and if unique is true, you can reuse it with the next request (resetting was much "cheaper" than recreating those objects)
Oh no! Someone famous (but not for programming or anything related) has an opinion! How will we live with ourselves now?
I just checked my copy and it covers what the feature is but doesn't go into details on how it is implemented. CMake doesn't have the ability to launch a daemon or service to watch for file change notifications, so it has to do some form of glob re-execution to determine that the inputs for targets have changed. 
Which is also not "fixed" right?
Amazing! I know it's probably impossible with the bytecode approach, but is there any chance you could let run-time values be used as template arguments?
Well, yes, this should work, but now the function make_thing is completely unnecessary and will likely just be inlined. All the work is being done in the constructor, which will be called regardless. However, now you have a constructor with side effects outside of the object you are creating, which (while useful in some instances, e.g. flyweights) is a bit iffy...
The problem with python is that, IMHO, it's not worth the trouble to learn that, as it roughly (at a basic level) works like C++ (the type system is just hidden, duh) and then there is the crazy idea of white-space relevance, seriously. I'm sufficiently at ease with C++ and the STL that I can write the same code in C++ just as easily as I would be able to write in python (after the effort of learning it). Lua on the other hand adds stuff that neither C++ or python provide and from what I read **in certain use cases** (luajit) has the speed of C (some claim faster, although I don't really understand how that is possible).
Well, yeah, that's my feeling (you know) too.
We could say that you use NULL under your own responsibility, normally you can go safely for nullptr. Anyway, don't forget that C++ inherited from C, so it is normal that at the beginning there were such things. Regarding std::variant, it has been a relief to have it included finally into the language
Yeah, I really only started looking at the language last year because of the whole whitespace thing, and only because it's widely-adopted where I'm currently employed. My whole approach to it is to do as little as possible actually _in_ python. So I provide the interfaces into my C++ code and the idea is you might generate a 30 line test script in Python. Just enough to kick off some processing and query the state of the machine, and ideally never beyond 3 levels of indention (And really 3 is pushing it.) I'd have gone straight to GoLang, but Python is still more widely used in the company, and setting up the objects with boost::python is trivial.
Python is worth learning because it is a powerful, compact language. It allows you to write powerful programs in fewer lines of code. It will never be as fast as a C++ program, but it will certainly be faster to write, and sometimes that is exactly what you want. As for the white space, well that has been done to cut down on number of lines of code in the langage (no { or } are required), so your programs are smaller and thus easier to read. Readability counts. As for white space relevance being crazy, i submit to you that whitespace is relevant in all programs. Take for instance this C++ code.. int i = 0; would it compile if you removed the whitespace? inti=0; no.
&gt; safely for nullptr. nullptr is still unsound. Yes, it's not an integer anymore, but it's still an unsound value and you got UB on deref. Why would you prefer nullptr to a ML-like option type (not to confuse with C++ option)? &gt;Regarding std::variant, it has been a relief to have it included finally into the language Why is it a relief to have another unsound half-baked feature? Wouldn't it be much better to have a decent and sound sum-types, as in Rust or ML? Why to have an option type which enforces no static check of pattern matching exhaustiveness?
Could this be used to allow capability similar to Java's dynamic class loading? 
C++ is amazing. Sure, it's difficult, and it doesn't hold your hand, but that's the point. It gives you control over every bit of you program, and the end result can be made much better if the language is used right.
These conversations about picking on C++ pretty much validate Bjarne's quote: &gt; There are only two kinds of languages: the ones people complain about and the ones nobody uses.
Python and C++ should not be compared like that. They are 2 different languages and serve different purposes. You could just as easily say C++ is a poor mans Python.
If you manually inline the function, then the `assert` fails on GCC and Clang if the type has a default copy-constructor, so that is why I left it. (You also have to remove the printing statement when using GCC.) I am not by any means claiming this good code. (Especially not now, when compilers don't even support it.)
I'm going to make a shameless plug and link to a C++-like language that I'm working on that has all these features :) https://github.com/miki151/zenon
nullptr (and pointers in general) should not be used as "optional" types. That's what std::optional is for. You're just shooting yourself in the foot. Nobody claims that std::variant is perfect, and there's plenty of suggestions for improvements, but it's atleast something, a start. And now that the usefulness is known, we can focus time and energy there, instead of implementing an elaborate advanced system once, terribly.
What a low hanging troll post this is, this has nothing educational attached to it. I could perhaps accept if the source article was linked directly (it's several more clicks to even get there..), but here you are linked to an Elon tweet, responding to a slashdot tweet, that links to a post on slashdot, that finally links to the *actual* article. So ridiculous
&gt; nullptr (and pointers in general) should not be used as "optional" types. Pointers in general should not have a null value. &gt;That's what std::optional is for Which is also rather useless since it does not enforce any exhaustiveness checking, it's pretty the same as nullptr in terms of soundness (possible stack allocation is the only benefit). &gt;but it's atleast something, a start. C++ feels like it's full of such starts, most of which a half-baked and useless, and exist in a sound form in different languages. I don't see why to wait for decades for a shitty unsound std::variable which you could write anyway (or use a boost version), instead of standardizing sum types.
Then use references if you dislike nullptr value? It's their one big advantage over pointers. You keep hamming on sum types, which is a low hanging fruit as many in the C++ community would agree that they'd prefer the full blown compiler implementation (myself included). You're ability to extend this to "this is everywhere in C++" is however far fetched opinion, and a bit ridiculous.
No, many people who tell people the "correct" way to program c++ are terrible people. Advocating the use of complicated templates, move and copy semantics, etc when pretty basic usage of the language would do just fine. These are the same people who make "example" for say saving a file to a drive will not do the 5 lines of code that would be perfect, but instead, have 8 layers of abstraction and are showing off that they know neural network programming and use the most complicated streaming nightmare to drop route the data to disk. Yet, after blah blahing in their commentary about modern c++ won't let go of .begin() and .end() symantics in their designs. 
Neat.
Python is also generally really easy to read. It's conceivable that doing easy level coding exercises that you could end up with some extremely verbose types like std::map&lt;std::string, std::function&lt;bool(std::string)&gt;&gt;::iterator these kinds of things really just cause a beginner's eyes to glaze over and their heart to harden.
I'd take that any day over Python's lack of types. Long types are more readable than no types.
I've been looking around recently for runtime interpreters of C++. Here's a few: * https://github.com/RuntimeCompiledCPlusPlus/RuntimeCompiledCPlusPlus * https://github.com/root-project/cling * http://www.llpe.org/ * https://www.enkisoftware.com/devlog-rcc++ I haven't tried any of them. Does anyone know others?
&gt; but it will certainly be faster to write, and sometimes that is exactly what you want. This is the bit I don't get, if you use the STL C++17, there are f.e. structured bindings (like in python) ` auto [ foo, bar ] = function ( ... )`, range based for loops (again with auto) `for ( auto v : vector ) { ... }, fold expressions (haskell style), std::vector&lt;int&gt; v { 1, 2, 3 };. Heck, there are even auto template parameters. How short **can** it be? Like I said, I don't get it.
&gt; Then use references if you dislike nullptr value? Your reference could be a null reference, no difference here. &gt;"this is everywhere in C++" I've mentioned also weak types, SFINAE (and turing complete templates), nulls, could add noexcept mess, 666 _values, initialization mess, implicit copy. Something is due to C legacy, but there are too much features which as it seems even the authors would redo.
Well I said in this same thread that I don't **get** it, why (and how) is it easier to write stuff in python?
Brainfuck does not have that problem.
This would be *great* for SIMD. At runtime, give the template the arguments for which SIMD instructions have been detecting on the running processor -- no more fat executables / multiple executables!
&gt; Your reference could be a null reference, no difference here. Well if you can't manage your lifetimes, use shared_ptr or use a language that does it for you. I cannot help those that can't help themselves. NULL is a C-ism, and discouraged. It's ridiculous to even bring up.. I haven't used NULL, or seen it used in a long time. Can't see how SFINAE is a "half baked feature"? Weak types? Sure, but I'd say that's more of a strength. You still have to shoot yourself in the foot as it's statically typed. I can't save you from a C-style cast. The author is writing his own language and is just looking for a platform. He's been working on Jai for a damn long time and it's still nowhere. There is no perfect language, not going to sit here and claim C++ is. But from most of the languages I've dealt with in my professional career, it has ranked as the more stable and trustworthy one. Every major language has it's flaws. The ones without flaws are the ones without users to find them.
No, but you said strong ref count is enough for you. 
I'll try to get to why I am interested in lua and not in python. Nothing in python cannot be equally easily expressed in C++, while this is not the case for lua (stuff I cannot do in C++, while it's possible in lua (and that's the crux) at virtually no cost, with luajit).
&gt; Well if you can't manage your lifetimes, use shared_ptr or use a language that does it for you. I cannot help those that can't help themselves. Smart pointers are also a minefield without linear types or something like this, since the does not actually manage the lifetime (i.e. you could wrap a live object in a smart pointer and it will destruct it even if the object is still alive, so you still do all the management manually and there is no type system to help you) &gt; It's ridiculous to even bring up. C++ code is full of nulls and nullptrs, that is ridiculous. &gt;You still have to shoot yourself in the foot as it's statically typed. Actually, the main point of static typing is preventing you from shooting your head off. Types could be used for ensuring the invariants you want not to be broken (for example you could encode a tree balance invariant in types or matrix size or file permissions). Weak typing is ruining this idyll. &gt;here is no perfect language, not going to sit here and claim C++ is. It's not about perfect language, it's about soundness. C++ is way too unsound, and there are sound languages, this "all languages are flawed" argument is silly.
To be fair, for research tasks where you want numbers for a small feasibility study or something like this as a result instead of a software product with a 10 years lifecycle, Matlab and Python are probably much more efficient. They both excel at rapid prototyping and quick visualization of results. In comparison to this, working with libraries like Eigen and using a C++ plotting library is almost always a slower process with hardly any gain. Again, underlining that I'm talking about tasks where the goal is not to write reusable software!
I suggest you better ignore this troll.
&gt;At Zip2, I wrote entire V1 of software for drawing vector maps &amp; calculating point to point directions anywhere in US (first ever company to do so), as well as white pages &amp; business listings w reviews (an early Yelp). Also wrote V1 of classifieds, autotrading &amp; real estate apps. [Link to tweet](https://twitter.com/elonmusk/status/1005596879848030209?s=19)
You can use them for yourself, but maybe don't post it online, or others will see it and think it's a good idea to use them. Also: ``` cmake -Bbuild -H. -DCMAKE_BUILD_TYPE=Release cd build ``` Wouldn't this be exactly the same? ``` cd build cmake -DCMAKE_BUILD_TYPE=Release ../ ``` 
You can get good enough rounding by just casting to an integer with `+ 0.5` (if it's positive).
I think you misunderstood my point. It's not that I care about **input values** close to 5.0 being rounded correctly, it's more the ) slightly irrational) fear that round's floating point return value, when cast down to an int, results in a wrong value. It still begs the question: why does round return a nob-integer value at all? The very point of the function is to return an integer.
Why would it return 4.999999..?
Well if you want pure ultimate speed then don't use Lua or Python, just write everything in C++. Much of the cost in Lua (even if you use luajit), might come from the binding to C++. Every time you have to cross the barrier from script to native you will have costs to pay. That said, i think Python is not known for it's execution speed (i've not tested that), so you wouldn't pick it for that reason (but it would also required bindings). Lua would be your choice over Python for that reason alone. If memory was your problem, then Lua is a good choice. If you want a big library of existing code, then C++ or Python is the choice. If you have an existing team that knows "Language A" like the back of their hand, then "Language A" might be the way to go. Choices, choices, choices. But yes, i really like Lua, hence the videos i'm doing.
My opinion: it's kinda standard, since most mathematical operations in C/C++ return a floating point number (\`pow\`), for example. And sometimes it can be more convenient not having to cast back-and-forth between \`int\` (or \`long\`, \`long long\`) and \`float\`.
No one is saying the new stuff shouldn't be there. What *I* think, and maybe your parent does as well, is that C++ very much misses the "make easy stuff be easy" part of a desirable interface. I've never gotten confused by the fact that `rand` is stateful. I've never gotten caught by the fact it's not thread-safe.
But I still need synchronization with the destructor, which I believe is not guaranteed to happen.
&gt; The problem is that when you reach do_something, the ptr may not be unique any more. (How this can happen is left as an exercise for the reader. Hint: weak_ptr). I get that there are gotchas with this case. At the same time, "let's not provide/deprecate/remove/etc. this useful function because someone might make a mistake using it" doesn't seem to mesh with the design of almost anything else in the language or library...
If round returned an int, how would it return +Infinity, -Infinity or NaN? (Assuming you passed those to the round function.)
I'll give an example of a place where we *I think* are doing something (or at least *could* do something) based on the ref count being unique or not in a similar context, though we're not actually using `shared_ptr`. First, think of Lisp-style, cons/car/cdr lists, and pretend there are no mutating functions (like `set-car!`/`set-cdr!` in Scheme). The really nice thing, or one really nice thing about these lists, is that they fit very nicely into a functional way of thinking. Functional programming is all about not having side effects (or at least that's a key component), and lists are a functional *data structure*. If you have `(define x (list 1 2 3))` then `(define y (cons 0 x))`, then the latter doesn't modify `x`, but at the same time you're not making a copy of `x`. This is useful beyond functional programming. Suppose you need to keep around multiple "versions" of a data structure -- you have one version, make some changes, get another version, make some more changes, get a third version, but you need all three versions of that data structure. Copying everything may be expensive, but using an approach like the one in the previous paragraph means that there's no copying. Furthermore, the above ideas can be extended to other ideas. Trees to get maps, or think the hash-mapped trie that's been talked about at a couple recent C++ conferences, including CppCon. Trees work because you can make a new node with the change you made, then copy all ancestors of the changed node in the original tree, but make those copies point to the original tree. So you only need to copy `log(n)` nodes in a tree of size `n` to make an insertion/deletion/change. (Sometimes these are called persistent, though not in the DB sense, or applicative data structures. Also it's worth pointing out that this kind of thing is of course very cache unfriendly. But I don't know what better options there are besides copy the whole structure every time you make a modification. We *need* the multiple versions, and sharing structure between them means a linked data structure. I'd like to try something that does more copying and see if that does better, but haven't had an opportunity.) But one idea for a performance improvement is the following. If you know that you're the only "owner" of a particular tree, you don't need to do the copying of even the spline, you don't need to allocate new nodes, etc.; you can just update things in place. Actually getting this working automatically I think is maybe possible, though we've not done it yet, but we do this "manually" sometimes. But it can only be done if you're the sole owner of all the nodes from the path down to the node you change. If you get to a node with two owners, changing that node would affect the view from the other root as well.
Because the float could be in an invalid state, i.e. +inf/-inf/NaN or the value that you want to round is not representable by int. You should use lround or llround if you really want an integer. 
The range of float values is much bigger than the range of integer types. Also, you have special values like +/-Infinity and NaN.
So what should it return if the float is so large in magnitude that it doesn't fit in an integer?
I've tried cling. What is your use case for it? 
I’m not saying Matlab is a bad tool or that it’s not useful, but as a language Matlab is pretty poorly designed. :) 
You are genuinely the only person who got the question. I deleted the thread because it turned into a bashing by the people who didn't get it.
perhaps each company top level comment title, should have a suffix "/ &lt;country name&gt; " that might speed up browsing considerably instead of click ... go in .. ah too far ... go back Thanks for the good idea ...
Exactly. 
My use-case includes using clang master. cling requires patches on top of an outdated clang revision.
The new random header is much better technically, but a disaster from a usability standpoint. A new programmer can grok rand() immediately. But they can never use &lt;random&gt; from memory. 
I agree in parts; C++17 has a lot of modern features to help you write better code. However, *most* of the not-so-great features that plagued C++98 are still there, and sometimes necessary, so there's still lots of rope to shoot yourself in the foot :/
If there's a default random number generator, then maybe it should default to the default with a default parameter. Just alias random_shuffle to that. 
Yep. There's absolutely no reason to break backwards compatibility here. Just have it alias to shuffle with the default PRNG. 
I agree with Elon. C++ is a terrible language. Now, if anyone could point to me a language that is as powerful *right now*, letting me achieve the same level of performance with about the same level of expressiveness and a good ecosystem/tooling... Well, let me get you started: - Ada: no experience. - C: expressiveness NO. - D: performance DEPENDS^1, maturity NO. - Go: performance DEPENDS^2, expressiveness NO. - Rust: expressiveness DEPENDS^3, maturity NO. - Zig: no experience. So, yes C++ is terrible, but the lack of all-purpose alternatives is terrible too... In a couple years down the road the situation may be different, but as of today, I don't see how NOT to use C++ for a good number of usecases. ^1 *Need to avoid the GC.* ^1 *Calling into C can be expensive AFAIK, the GC was pretty bad to start with but has been greatly improved.* ^3 *Compile-time computation is still lagging behind, and there's no value generic parameter yet.*
&gt; If you have an existing team that knows "Language A" like the back of their hand, then "Language A" might be the way to go. I'm a one man band, I know neither python nor lua (little bit, I do know modern C++, though), so if I have to put in the effort [of learning], I'd put it on lua for the reasons mentioned as opposed to learning to write the same stuff in another dialect (I know the latter is pushing it, but at the end of the day it's syntax).
Oh yes, definitely. I like Python + its scientific libraries so much more than Matlab because of the huge pile of weird design choices of the Matlab language. But I guess it's ok for people who didn't work a lot with general purpose languages.
I think you can just search for "Location:". (Do you collapse comments by default?)
\[RCRL\]([https://github.com/onqtam/rcrl](https://github.com/onqtam/rcrl)) is my take on doing this in a platform and compiler agnostic way
It doesn't say anything about his competence in C++ or even programming in general. For all I know the zip2 v1 software could be an ungodly mess of PHP scripts.
Just curious: what capability along those lines do you want that can't be done with dlopen (and friends) or one of the libraries built upon that?
this is definitely possible with cling, not sure with the other interpreters listed above
No, it will work, won't it? Or at least the copy elision does occur. [See here](https://en.cppreference.com/w/cpp/language/copy_elision#Explanation): &gt; Under the following circumstances, the compilers are required to omit the copy- and move- construction of class objects even if the copy/move constructor and the destructor have observable side-effects. They need not be present or accessible, as the language rules ensure that no copy/move operation takes place, even conceptually It explicitly gives this example (same as in the OP's code): T f() { return T{}; } T x = f(); and states that no copy or move occurs. `x` is initialized directly, as if done by `T x{}`. It even notes: &gt; prvalues are returned and used without ever materializing a temporary So it seems to me like there must not be a temporary, ie the the constructor is called with `this` pointing to the object that is to be initialized outside the function. Unless I'm missing something?
&gt;Ada: no experience. Disambiguate. Also if you've added such a vague criteria as maturity, I would also add legacy burden and design errors, for C and C++. If you are interested in formal verification and correctness, you may be also interested in Spark and F*.
There is no ABI for C++, so with dlopen and friends, realistically you *must* compile all plugins or extensions alongside the main program or it plain won't work.
Not sure if the libraries are the problem per say (although STL is definitely showing it's age and the fact no one just works on usability improvements). What really annoys me is that the is to much basic stuff in the library, that belongs into the language (array, string, optional, tuple, variant, std::exception)
Alongside? Using the same toolchain, yes. But... that's a looser requirement than evaluating the source code. 
How would you fix it? Besides, as the post says, `shared_ptr::unique()` was introduced primarily for debugging purposes. If you rely on it in the multithreaded environment, then there must be something wrong with the design of your code.
He shipped successful software, that's all you need to know, and all that matters when it comes to software.
But they know how to use go/rust/swift/… and how to use them? Obviously you need to learn, and I'm not saying that C++ is awesome (C++03 was awful in my opinion), but still a really great language. Probably worst than those new language, but not as bad as what people say, and I'm pretty sure that C++20/23/26 is really going to close the gap, while keeping his gigantic backward compatibility.
I'm starting to wonder if this isn't a mantra we keep saying ourselves without having a critical look at how much the language has actually improved. Sure, c++11 has brought some dearly needed refreshments to the language, but in many places, we still keep on pilling fixes onto fixes onto fixes in order to hide the ugly legacy we are unwilling to break compatibility with, but unless we do break compatibility (in a drastic manner) that ugliness is not going to go away. The only aspect of c++ that gets constantly improved is Template Meta Programming, which tells you a lot about the deficiencies in the core language. 
Please first read the other posts/replies to this post. If you have questions afterwards, I'm happy to answer them.
Same toolchain, same *compile options*. And then there is still no guarantee or check you can do at runtime that what you are about to load is not going to implode.
 * C++ destructors are implicit function calls, and eliding types hides them from readers. Foo() performs entirely different operations depending on what type "auto" deduces -- yes, it should be named better, but _hiding information from readers is hostile_. If you are not familiar with Bar, then maybe seeing unique_ptr&lt;Bar&gt; doesn't do anything for you, but if you are, then maybe it raises red flags about ownership or performance of ~Bar(), or whatever. * There's lots of reasons to return a list, and lots of reasons to want something sorted. Sometimes these overlap, and sometimes they don't, and sometimes your reasons change over time. Writing out types makes it much easier for readers to spot problems like this, whether they were introduced through broken refactoring or junior developers. The bottom line is that C++ has tons of implicit behavior encoded in types -- from the performance characteristics of various containers (which is common in many languages), to implicit calls to ~T() (which are not). Hiding types hides what your code *actually does*. 
What's so hard about: std::default_random_engine e(std::random_device{}()); std::cout &lt;&lt; std::uniform_int_distribution&lt;int&gt;(1, 10)(e) &lt;&lt; '\n'; It looks so much better than the old, ugly C method, and I only had to refer to the documentation five times! /s of course.
&gt; In fairness, Elon then goes on to triple-heart Python, which is just as deep a well in terms of difficulty of mastery as C++. The deepest complexity python has to offer is metaclasses, which pale in comparison to SFINAE and ADL. Those are also both in the same usage frequency. The worst work-a-day problem in Python I can think of is how default arguments are evaluated. It might confuse you at first, but then you just learn to default everything to immutable values like None or numbers or strings. There are several work-a-day problems in C++ thay are a lot more annoying. Use of uninitialized variables, returning pointers to locals, template spew, ? 4 I like writing C++ more than Python, but c'mon now.
Because the existing `&lt;codecvt&gt;` solves literally zero problems in the real implementations we have today.
But "give me a random number from 1 to 10" is a disaster from a usability prospective with `rand` too, just in more subtle ways. `rand() % 10 + 1` does *not* produce a uniform distribution from 1 to 10. I'm on board with "an easier to use random interface would be nice" but `rand()` is not an easier to use interface.
C# is far and away the most expressive, easiest to read, and has some of the best tooling. Plus, with .Net Core, performance is rapidly approaching c++.
The justification is that it's called `random_shuffle` but doesn't actually produce random shuffles.
Agreed; abstraction hides things. Disagreed; code should hide irrelevant details. "Hiding" information from readers isn't *hostile*, it is the only way to create a programs that do non-trivial things and can be understood. Good code hides information behind both compile time and runtime abstractions so that the reader doesn't have to know about the details in order to determine what the code does. You don't make the hiding *total* or *perfect*; you permit people to drill down if they need to. But exposing every nut and bolt to every reader just floods them with piles of noise. And yes, when you abstract things there ends up with implicit function calls. This is why there are 2 hard problems in computer science; naming things, cache invalidation and off-by-one errors. You need to name the thing you are returning so users understand what its ownership semantics are and its performance characteristics are. Doing so with the type system is one way. But if you do so that basically ties you to using a small vocabulary of near-raw smart pointers. But it is far from the only way. The flaw in `auto ptr = GetFooPtr()` isn't `auto`, it is that poorly named function name. What is that Foo, what is it pointing to, who owns what it points to, what can make it invalid, what are the resource contention issues, etc etc. The fact that the return value is implemented of one of a dozen different smart pointers doesn't really tell you what the semantics of the returned value is. You can have conventions, but they are only conventions, and they can be handled naming functions instead of naming types. At some point, you do have to trust that the code you are working with isn't crap. If you are just using the types to detect stupid code, I hate to tell you but types don't spot most stupid code. You need a different way to catch stupid code, and the ones caught by programmers using the wrong type will be caught there as well. --- There are exceedingly few reasons in C++ to return a non-random access list. There are very few reasons to return a node-based container with identity stability; and even node based containers can be made random access. Actually returning something like a std::list linked list is 999/1000 times code smell and a mistake. I mean, I've seen situations where it was a reasonable answer, but they are amazingly few and far between. 
If multiple threads are referencing the same shared_ptr then they already have a data race. `shared_ptr` protects against data races *on the reference count*, not on `shared_ptr` instances themselves.
That would have been just as breaking except in a silent way who used unique in a single threaded environment.
`unique` never synchronized with the destructor because it checks `use_count() == 1` -- the only synchronization with the destructor `shared_ptr` does is when `use_count() == 0` (that is, the last shared_ptr is being destroyed).
I think it's more that `&lt;strstream&gt;` was deprecated a long time ago and nobody wants to touch iostreams enough to do the right thing and finally nuke it.
How about we mark advertisement as such?
Which is why I can't use \`use\_count()\` and why I whished the committe would rather standardize a "fixed" version of unique (it can pick a different name if it wants or just ignoring shared pointers would also be ok for me) than just removing it.
The plan is to upstream those patches, but that's not completely done yet.
Not if those multiple threads don't modify the shared\_ptr instance. One thread could check for unique(), while the other makes a copy of it. both are read operations and thus would not produce a data race.
As I already told encyclopedist, I'd also been fine with a replacement that has a different name if that would have been the only concern.
Originally, the function `make_thing` created a `thing`, set the global pointer to point at this new thing, and then returned it. So it was not a prvalue. Copy elision most likely still took place. But since it wasn't a case of guaranteed copy elision, the copy constructor was still needed, since *conceptually* it was necessary to make copies to return `thing` from `make_thing`.
i've been working on one for a while now. it's specifically for DSP programming and i managed to bundle everything needed. i chose the following restrictions: * no STL (i use netlib for maths) * no c library * no new/malloc/delete here is an demo: https://www.youtube.com/watch?v=o1FcBP3Eqrc it's getting very close to release (writing docs and working out the last kinks has been taking way longer than i expected) 
I'm using it in two projects to convert between UTF-8, UTF-16 and UTF-32.
What would be an easier to use interface in your mind? 
Here's another: https://github.com/Keno/Cxx.jl It's a C++ interface to/from Julia, but can also be used as a REPL inside of the Julia REPL.
See the [reasoning for auto](https://www.reddit.com/r/cpp/comments/8xny4u/const_auto_versus_const_auto_for_pointer_types/e24exps/) that /u/TomSwirly presents elsewhere in the discussion. Unless you're trying to evangelize east const, in which case this isn't really applicable. The article even explicitly calls out how the const placement doesn't make a difference.
&gt; be prepared" Be prepared how?
Fun fact: because you're returning via list-initialization, if you change `auto my_thing = make_thing();` to `auto const&amp; my_thing = make_thing();` then this is guaranteed to compile even under C++11/14.
Nope. Its being evaluated at fairly regular intervals, with similar conclusions - that nothing providing similar guarantees exists, so we cant remove it.
&gt; It explicitly gives this example (same as in the OP's code) Note that the OP has `T f() { return {}; }`, which is notably different, though the difference doesn't matter for C++17.
knowing its coming is a kind of preparation in itself. You won't be surprised when it gets removed, you could consolidate uses in your code base so it's easy to replace down the line, look at alternatives, etc, for example.
Not C++, but I think some people here would be interested in [http://terralang.org/](http://terralang.org/) It can call C. It is callable from C. It can produce C-linkable .o files and static exes. Or, it can JIT high-performance, statically-typed, manual memory managed code. Including SIMD support. It's basically a friendly front-end to LLVM.
Or use a [hourglass interface](https://www.youtube.com/watch?v=PVYdHDm0q6Y). 
What a coincidence, so have I, so here is my opinion: COBOL is the future and everything else is a fad. Guess it is time to create a reddit post about my shitpost. :rolleyes:
There is no ABI for C either, but it's a more basic language and vendors tend to be decent at sticking to a fixed ABI
Batch files and hypercard.
So, having shipped software makes one an authorative figure on the quality of languages? Particularly ones they're unfamiliar with?
Even C++98 wasn't *terrible*.
But it can't actually do that conversion, due to codecvt (the facet, not the header)'s "only one inner char to N outer chars" requirements. A correct UTF16&lt;-&gt;UTF8 transform can't meet that. Maybe UCS-2&lt;-&gt;UTF-8 could.
I think there was a proposal for a `rand_int(1, 10)` nonmember function which would be OK. p0347 proposes `random_generator{}.uniform(1, 10)` which would also be OK.
This is interesting to me since it has a focus on embedded systems. I am curious what the thoughts are on an evolution of the STL with this subset in mind.
Melissa O'Neill of PCG fame had some ideas on a simplified interface: http://www.pcg-random.org/posts/ease-of-use-without-loss-of-power.html
I'm in the same embedded boat. The key aspect impacting STL here would be heap and allocators. I wish GCC provided -fno-heap or -fno-default-heap today to test on current codebases. 
&gt; realistically you must compile all plugins or extensions alongside the main program or it plain won't work. Or not write plugins/extensions in pure C++. Afaik most solutions rely on a C interface and the factory pattern for your wrapper. 
Sure. But this is /r/cpp and writing code that wraps a C++ class or API as a set of C functions and anonymous pointers is about the most mind numbingly terrible work I can imagine. Let's face it, that's work for a computer to do, but it can't do it for entirely unconvincing reasons.
The first thing I'm doing for &gt;C++17 compatibility in my library is reenabling the bind1st, bind2nd binders if I find them disabled. I'm also fearful about bind1st, bind2nd since I've read somewhere that there are proposals to *also* get std::bind deprecated, which would ruin the backwards and forwards portability of C++ code. 
Isn't the problem with this that it's not really equivalent because you break the "signature" of ``conditional&lt;&gt;``? Code would expect to invoke ``conditional &lt;bool, T, F&gt;``. Also how did they even invent that acronym, aren't they supposed to at least make sense? i can barely recall what it could even mean from memory. Isn't that... scary?
What do those flags do?
The behaviour difference between declaring the deleted copy constructor and not is allowed by the standard: http://eel.is/c++draft/class.temporary#3 And the difference is in fact mandated by the Itanium ABI (because the object is indeed passed in a register). You can see a similar effect by adding a non-trivial destructor (doing so prevents passing the object in a register): https://wandbox.org/permlink/cUf5eGx8VPDyw8yk
&gt; D: performance DEPENDS1, maturity NO. Eh, depends what you're writing. At least 8/10 times I'd pick D over C++, despite the GC. The language itself is much nicer and performance requirements are wildly exaggerated for most projects. But, like you said, the real problem is the ecosystem (kind of a self-perpetuating problem unfortunately).
Nothing, because they don't exist. The idea is to let one (try to) compile code without heap.
I don't really understand the usecase. You just want to allocate everything at the bottom of the stack instead?
I recommend using lambdas instead of binders.
Yes for certain industries. It is common in embedded systems, gaming, and safety critical software. Allocations present "risk" that the allocation may fail and not be tracked/monitored properly. Removing the heap and allocating everything on the stack at startup means you've eliminated a large source of potential problems.
I need static/fixed allocation, pooled/slab, stack allocations depending on what the memory is for. 
No big difference between allocating a block of memory on the heap at startup vs a block of memory on the stack. Sounds more like OP wants malloc to allocate memory on the stack mid-run, which sounds like a poor idea to me.
How would that even work? If you don't have a heap, I don't think normal data structures are going to be what you want. 
Do you want to allocate permanent objects on the stack? Or just temporary ones? Permanent stack allocation at runtime (not at startup) sounds like a disaster waiting to happen.
Rand is certainly easier to use. We have generations of people who learned it just fine in a first semester class. It exhibits small bias, so is less technically accurate than the &lt;random&gt; options. I've never seen a new programmer be able to code a dice roller from memory. It's a usability disaster if people have to hit up stack overflow every time they need a dice roller. 
That's definitely better, still not good enough for a new programmer to memorize. 
Author of the paper here. As for evolving the STL, the starting point is my other freestanding paper, http://wg21.link/p0829 . That basically avoids all the features that I call out in P1105R0. Longer term, lightweight exceptions (http://wg21.link/p0709) may give us access to the containers that typically use the heap, like vector. One day, I hope to make a proposal that would make vector use lightweight exceptions if the vector is provided with a specially tagged allocator.
Yep. At least for us, in our new mission critical products being developed - malloc (and kin) are strictly forbidden. And, honestly, its a pleasure to work with this paradigm.
Fantastic, thanks!
&gt; but it's not always possible to know everything ahead of time. Yes it is. Source: Ran a project that did exactly that. You can plan for worse case usage, and statically allocate accordingly. Linked Lists are even possible this way. Each Node is statically allocated, then at execution start you join them together. You can do this with Linked Lists in C, or with templates in C++. On a related note, when using embedded devices with SRAM on CPUs that don't know what prefetch is, linked lists have almost the exact same performance as arrays. Just that 1 extra pointer deference. Since SRAM access on those devices is 1 cycle of latency, that 1 extra pointer deference can pretty much be ignored! Embedded has some serious limitations, but can also pull of some insane stuff. 
Ok, fair. s/possible/practical I do software for vehicle systems. We do everything 100% statically allocated, and it's a huge pain in the ass.
You must mean auto const* is not guaranteed, but const auto* as a return type must be respected. `const int* a = GetConstPtrToConstInt();` is valid, but `int* const a = GetConstPtrToConstInt();` is not.
As i said, depending on what i'm doing i sometimes need all of the strategies above
Why is that ? Why wouldn't a std::map or std::vector of ints with fixed-size allocators for instance ? Or a myriad of other allocation strategies that are \_not heap\_ 
I doubt you'd get executables smaller and faster than a assembly handcrafted version for each instruction set that is called through a function pointer that you assign when detecting the available instruction set. CPU are great at predicting these branches as well.
In the world of today, if you don't have a heap, you probably don't have exceptions. In today's c++, allocators are only allowed to signal failure with an exception. Returning null isn't conforming, and your vendor's stl implementation probably isn't checking for null. So that's why those containers don't work today. Tomorrow may be different.
The `conditional_t` generates the same type. `conditional` ends up being different, hence the fact it requires work on the part of the standard to permit it. 
Let's think this through. If you have so little memory that don't want to use a heap, are you really going to want to use data structures like std::map that are allocating small fragments of memory as well as using extra memory for buckets and pointers? 
The thing where C++ puts language features in a library is great. It means a few things. First, it means that the language is usually powerful enough to implement those language features. So when you need an equally powerful concept that isn't already in the standard, you have a language strong enough to do it. It also means that you aren't stuck with the built-in solution. Large companies profiled how std::string performed and determined they could do better by a small amount, and wrote their own string class. This then informed people who implement compilers and the standard itself. One example of this happening is string view; everyone who ever parsed a huge stream of memory noticed that if they wrote a string view they could make it damn fast and expressive. And because the string they where working with was "just a library" type, their string view could be just as powerful. By trying as best they can to ensure that things that *could* be library features *are* library features, they make the language stronger than if they just folded in the "one true implementation" of some language feature. Now there are costs. Maybe we'd have stronger pattern matching and the like if `tuple` or `variant` or `optional` was built in. And the fact that `int[8]` sucks while `std::array&lt;int, 8&gt;` doesn't is an example of the harder thing being better. But we can get those language features while still keeping as much as possible as implemented in-language. 
Yes, all the time. And it's not just a question of having little memory, its about having deterministic memory utilization even with non-deterministic inputs. 
I'm surprised that someone hasn't written an allocator that does this.
Many programming languages have been tried and will be tried in this world of sin and woe. No one pretends that C++ is perfect or all-wise. Indeed, it has been said that C++ is the worst programming language except all those other programming languages that have been tried from time to time. Yes, I'm ripping off Churchill.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8y5hu9/c_tie_a_tree_together/e28jyqs/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Reasons why auto exists: This. `auto iter{myMap.begin()};` `auto iter{myMap.find("key")};`
Another benefit I'm seeing here is better error messages for free and those error messages will be streamlined across compiler implementations. Link-time errors becomes compiler errors, and undefined behaviours can easily warned by compiler. I hope our compiler vendors get this.
Indeed, I believe in this case there is high interest, given cmake is the de facto standard for building C++ projects. I like that is is discussed here.
&gt; We do everything 100% statically allocated, and it's a huge pain in the ass. I honestly enjoyed it. We had a solid set of tools we built up ourselves, the advantage of writing our own RTOS. Not having entire classes of bugs was nice. This is ignoring the huge OMG-WTF-BBQ effort that strings were. Strings were a giant pain that cost us a ton of dev time. But if you ignore strings (which over the projects 3 year life span probably totaled out to 18 months of developer time), static allocation was legit wonderful. It forced us to sit down and plan all our inputs and outputs first thing, it made us consider the size of all incoming buffers and make sure that all protocols were well defined. I would argue that the end result of doing such planning was a far superior product. Rock solid stability was also a big plus. We spent more time investigating memory issues that were due to hardware failures than due to problems with pointers.
&gt; We have generations of people who learned it just fine in a first semester class. Great, generations of people who learned how to use garbage. &gt; It exhibits small bias Considering the incorrect modulo behavior, and that `RAND_MAX` == 65k is fairly common, it's much more than "small" bias. It's bias bad enough to be useless for anything that matters. Oh, and because of the thread safety problem the perf is abysmal too. &gt; I've never seen a new programmer be able to code a dice roller from memory. If you're making a dice roller toy, why not write that in Python? &gt; It's a usability disaster if people have to hit up stack overflow every time they need a dice roller "I don't like &lt;random&gt;'s usability" != "go use rand()". For the former, I agree with you. The latter I think is catastrophic.
&gt; If you know that you're the only "owner" of a particular tree, you don't need to do the copying of even the spline, you don't need to allocate new nodes, etc.; you can just update things in place. Given the presence of weak_ptr, I don't think shared_ptr is ever going to give you what you want.
&gt;Great, generations of people who learned how to use garbage. Garbage is far too strong a word. Even if you're making a non-toy use of rand(), if it's not going to be used in an online casino or cryptographic implementation, rand is adequate. &gt;Considering the incorrect modulo behavior, and that RAND_MAX == 65k is fairly common, it's much more than "small" bias. It's bias bad enough to be useless for anything that matters RAND_MAX is 2147483647 on any system that I care about, which means that the bias on %10 will favor 0 through 7 over 8 and 9 4.65 x 10^-8 percent of the time. It's unlikely you'll even detect the bias in the normal operation of a video game or whatever normal use case a person has. &gt; If you're making a dice roller toy, why not write that in Python? I'd rather have C++'s random functionality be usable by humans, rather than suggesting they switch languages. C++ is just fine for new programmers. There's just a couple areas where the standard has literally gone backwards on usability, and this is one of them. &gt;"I don't like &lt;random&gt;'s usability" != "go use rand()". For the former, I agree with you. The latter I think is catastrophic. It's catastrophic if you're using rand in a secure setting or for online casino gaming. I'm far more concerned with code being easy to read and understand than a negligible bias in a random dice roller in a video game. I'm not suggesting rand good for the long term. As the other links here show, it shouldn't be too hard for the standard to build something that is both usable by regular humans and is also technically correct. But doing stuff like removing random_shuffle, which is a code breaking change, isn't very helpful. 
Yes, that's what I meant. Thanks! 
17? Why go with such an ancient version, 98 is clearly far newer and better... (if we can't even get our language versions to sort cleanly then that does not bode well for the rest of the design!)
I'd be curious to hear about your startup and software for it you have written all by yourself.
How can you say that he is unfamiliar with the language? He wouldn't be making a statement if he wasn't.
Based upon what do you make that assertion?
You were the first one to make an assertion about his familiarity with the language. Your assertion implies that Elon has interest in randomly bashing languages he knows nothing about. My assertion follows common sense.
 &gt; It means a few things. First, it means that the language is usually powerful enough to implement those language features. So when you need an equally powerful concept that isn't already in the standard, you have a language strong enough to do it. The fact that you can implement those types when necessary is great. However, the fact that the fundamental, standardized types are not intrinsically known to the language just means lots of unnecessarily complicated syntax as well as runtime and compile-time overhead and it's exactly one of the reasons, why c++ is often considered ugly. The compiler has to rediscover and re-optimize those types again and again in every single TU and at the end of the day it still doesn't understand that the value of a string aren't 3 random pointers, but la sequence of chars (just consider how many compilers are able to eliminate the dynamic memory allocation, even if the full lifetime is visible and it is initialized from a string litteral - I think the latest version of clang can do it sometimes ...) Not sure, why you mention string_view, when you can implement it in virtually every other language too and I didn't mention it in my post. I'd still like the compiler to understand string_view, but I wouldn't expect big benefits from turning it into a language feature. &gt; By trying as best they can to ensure that things that could be library features are library features, they make the language stronger than if they just folded in the "one true implementation" of some language feature. Imho that is completely backwards. Trying to provide the language facilities that allow those types to be implemented in the library make the language more powerful and more complicated - that is fine with me. But standardizing / implementing fundamental types in terms of those features will almost always result in sub-optimal user experience and (someone's) performance. &gt; Now there are costs.Maybe we'd have stronger pattern matching and the like if tuple or variant or optional was built in. True, and in addition to what you said, it also means less compile-time efficiency and less optimizations. &gt; And the fact that int[8] sucks while std::array&lt;int, 8&gt; doesn't is an example of the harder thing being better. No, it only proofs that c-arrays suck compared to arrays in virtually every other language in existence. Except backwards compatibility, there is no reason whatsoever why native c++ arrays could not behave like std::array (copy, proper size) just with a much nicer syntax - it took 6 years after their introduction in c++11 until std::array was fully usable in constexpr contexts (I think the comparison still isn't) and till it could deduce it's size from the initialization and initialization of and afaik you still can't say "I want an array of type T, but deduce the size". If anything, std::array is a prime example that library types are always lacking in some aspect compared to their native counterparts.
const\_cast? In my code base? What next, nasal demons?
I did so as well, for a college project no less. I liked being able to agree with my team that we are banning dynamic allocation. Then came the deadline (not our fault) and a need for some objects (this is C, so by "object" I meant a struct instance) to outlive the function it's declared in and be "freed" in another function. &amp;nbsp; Due to the deadline, we said "okay, let's lift the ban on `pvMalloc` instead of rewriting a big chunk of code already in place". &amp;nbsp; An alternative would be to say: - At run time, we will need at most 5 of each of these `struct`s. - Let's make pools three times as large. - Make pools an implementation detail and provide a correct API. - Use pointers to those static objects to pass them around (even between threads). I did like figuring this all out, so it's not "a huge pain in the ass" for everyone.
It is: https://godbolt.org/g/AHtU7W The generated move-ctor `A::A(A&amp;&amp;)` contains a string copy-ctor.
If that's what you want to think.
That's 5 minutes of boilerplate at worst.
I skimmed the article looking to see how this works. It looks like you have to install LLVM and Clang to get this working. Considering ABI issues, you'll need to build with the same versions the client installs, and this appears to be *nix only. Effectively OSS only in practice considering those ABI requirements. Unless you're expected to embed clang and LLVM in your application. Whatever, I don't think many people will use this except perhaps on servers.
I think this proposal is great, but perhaps it is worth to propose a version of `operator delete` that supports receiving additional parameters for kernels where deletion requires more context than the address that was returned from allocation. For instance - ExFreePoolWithTag requires you to pass the previously given tag. 
I think this proposal is great, but perhaps it is worth to propose a version of `operator delete` that supports receiving additional parameters for kernels where deletion requires more context than the address that was returned from allocation. For instance - ExFreePoolWithTag requires you to pass the previously given tag. 
&gt; The deepest complexity python has to offer is metaclasses, which pale in comparison to SFINAE and ADL. Those are also both in the same usage frequency. I hate to be so blunt, but I suspect your depth of experience with Python isn't there if you'd say things like the above. Try immersing yourself in some big iron rather than toy Python frameworks like say Zope and Plone, and then come back to me on SFINAE and ADL being complex in comparison. True, those are code frameworks built on top of the language, but when you see how those frameworks are implemented and just what they *do* with the language, its capability and power when a skilled Python programmer is at the helm, it's awe inspiring, and kinda scary. Getting Python to perform well is easily as deep as well as C++. You need intimate knowledge of at least the big three Python implementations, and to construct your Python very carefully indeed i.e. don't do what 98% of what typical Python does. Python, despite being interpreted in its most popular implementation, *can* perform extremely well. A ton of time has been invested into making a subset of it predictable, and it's actually feasible to write fixed latency code in Python, which is an amazing achievement for an interpreted language. I agree with the other posts that you can get to "good enough" code much faster with Python than C++. Packaging is by far the biggest impediment for C++. But unlike other languages such as Rust *cough*, and like C++, Python is empirically proven to work well in large, complex, old codebases used in mission critical uses cases, and in a variety of use cases perhaps just short of the huge variety C++ is capable of - and again, unlike most other programming languages. &gt; I like writing C++ more than Python, but c'mon now. For me I prefer writing Python more than C++, but the two are highly complementary for solving any given problem. A lot of my standards effort is to substantially improve the interoperation between the two.
Aren’t exceptions already optional? Or do they carry a runtime overhead even when the code is compiled without exception support?
No they are not. Some compilers allow disabling them, but doing so is in violation of the standard.
Thank you! Regarding the github link and how to use custom error codes, I didn't get (in vacation, on mobile) what of that you linked I'll have to routinely do, and what is helper implementations. Also, a section on what to consider (technical and a first shot at best practice) when going from the old to new mechanism. A before/after example of custom error and throw, catch would probably help others getting a better picture of all of this. I would be happy to help if I can and can review updates or try to dig deeper by myself. Also, how to port conditional noexcept to use throws()
Though not functionally equivalent I would like to see a ::to_unique(), that would work by decrement of the ref count and transferring owned memory to a unique_ptr if it hits zero instead of destroying it. Might be a tricky implementation given how the difference is how shared_ptrs vs shared_ptrs created from unique ptrs are implemented, but would be quite useful for object reuse purposes.
D has infinitely better metaprogramming capabilities. When it comes to performance, I think it probably is the language that comes closest to C++, even outperforming it for some tasks. Real shame some of their poor choices drag it down so hard.
Python has types now. https://docs.python.org/3/library/typing.html
What I'm referring to is in Java I can simply perform a **Class.forName("MyNewClass.class")** and then can create a new instance and use it. I can also load the MyNewClass.java source and compile it on the fly, adding it to the existing classloader and use it, like how a JSP page is handled. I'm familiar with the dlopen functionality, I was merely asking if this project would simplify the work needed to take advantage of the dlopen functionality and make it a *seamless* as Java dynamic class loading.
Well, Outcome's documentation needs a whole section on its experimental `status_code` support. I'm notoriously bad at writing documentation, indeed Outcome's was not started by me at all. So could you perhaps come up with what needs to be added to https://github.com/ned14/outcome/tree/develop/doc/src/content for documentation to make sense, and email me with a list of code snippets needed? I have no problem writing code snippets, it's just I genuinely don't understand where people have a problem with using this library, so I don't know what to write or how to write them. I need guidance to understand other people's difficulties, if that makes sense.
If you want deterministic memory utilization, why allocate memory in tiny fragments? Why not just allocate an explicit amount ahead of time? 
&gt; &gt; but it's not always possible to know everything ahead of time. &gt; &gt; Yes it is. Source: Ran a project that did exactly that. He said it's not *always* possible and your response was a single sample? Nice.
Holefully this gets in: https://en.cppreference.com/w/cpp/experimental/randint I think libstdc++ already implemented it.
Author of the paper here. If you have feedback, you can leave it here, or you can use the email address in the paper.
this is fixed in 15.8 Preview 3
* Of course code should hide irrelevant details. The full type name of whatever std::unordered_map&lt;std::string,std::vector&lt;const std::vector&lt;std::unique_ptr&lt;int&gt;&gt;&gt;&gt;::cbegin() returns is irrelevant, and should be elided, but _whether or not your function disposes of an object is almost certainly relevant_. As I said, sometimes the type and semantics are clear from context; you gain nothing by writing out "std::unique_ptr&lt;Foo&gt; foo = std::make_unique&lt;Foo&gt;()". I'm not going to sidetrack into good naming conventions, but suffice to say that you often don't have direct control over the names of functions you call (for example, function names in the STL describe none of the attributes you list). * Yes, returning std::list is rare, which is why you should explicitly write it out, and not hide it behind an "auto". If you don't like list sorting as an example, consider the cost of lookups in map vs. unordered_map, or even returning a vector&lt;Foo&gt; vs. a Foo* (and using operator[] on it). Writing out "map&lt;int, Bar&gt; baz = ...." clearly signals to the reader "We make a copy here, lookups are logarithmic, we will likely modify this structure before disposing of it, and baz[1] may create a new entry". That's a ton of documentation about performance, thread safety, intended usage of the variable, and even what exceptions you may need to handle, and you get it for essentially nothing.
for someone who "doesn't have experience in compiler backends", the whole compiler is a backend
Well, this is the first C++ paper I read from the beggining to the end. Here are my thoughts: - Wouldn't it be simpler to make `throw` and `bad_alloc` ill-formed instead of UB (in case of `throw`)? - Forgive my ignorance, but what do virtual destructors have to do with `-nostdlib`?
That'd be awesome
Making `throw ExceptionType` UB is imho a very, very bad Idea, it makes reliable testing of code that uses them essentially impossible. I'd much more prefer terminate/assert or a compilation error.
I also think that performance is often overrated. I've worked on applications in C++ which spent 90% of their time waiting for the database with blocking calls. Needless to say, any language with good async database drivers would have destroyed them performance wise. On the other hand, I've also worked on applications which were squeezing as much performance as they could out of C++. It's those I use as a benchmark for performance: where CPU / cache pressure are the bottleneck.
&gt; Plus, with .Net Core, performance is rapidly approaching c++. Is it? I always thought C# was in the same ballpark as Java, with perhaps a less advanced GC. 
&gt; Ada: no experience. As in, I have no experience with the language (just a couple hours at university, over 10 years ago), so I am in no position to judge its performance, expressiveness and maturity of ecosystem/tooling. &gt; If you are interested in formal verification and correctness, you may be also interested in Spark and F*. Formal verification is a bonus, but I'm primarily interested in an alternative to C++, so performance will come first.
&gt; I have doubts for F#. Fstar, not F#. F* compiled with kremlin is as performant, as C++ or C. It also provides a powerful facilities for reasoning about effects, allocations and so. https://www.fstar-lang.org/#introduction https://arxiv.org/pdf/1703.00053.pdf
Oh, looks pretty neat. How much do the restrictions to a subset of F* to target C affect expressiveness?
"Wouldn't it be simpler to make throw and bad_alloc ill-formed instead of UB (in case of throw)?" There's usage experience both ways. MSVC with exceptions disabled does UB, and gcc and clang with exceptions disabled make things ill-formed. The motivation for UB is to allow the same exception neutral code to be able to build both with and without exceptions. If you make throw ill-formed, then you have to conditionally remove that code. This isn't a deal-breaker, and I even mention in the paper that I will be polling at the standards meeting to decide which path we take. "Forgive my ignorance, but what do virtual destructors have to do with -nostdlib?" A virtual destructor ODR-uses operator delete. If you have no no heap, you probably don't have and don't want an operator delete implementation. The reason virtual destructors use operator delete can be somewhat illustrated with some pseudo code. When someone writes "delete foo", something like the following gets run... void delete_operator(Foo *f) { f-&gt;~Foo(); // call virtual dtor ::operator delete(f); } ::operator delete gets ODR-used regardless of whether you ever create the object with a new or delete it with delete though, and that's a problem. If I only create the object on the stack, the reference to ::operator delete is harmful.
&gt; He said it's not always possible and your response was a single sample? A huge % of embedded projects do not use malloc. There is never a need to use a heap. The heap is a type of memory optimization that allows for re-use of RAM, instead of permanently reserving a chunk of memory for a given bit of code, code can release memory when it is not using it, and other code can then use that memory. This allows a system to function with less memory overall. In systems that do not have a heap, each module reserves as much memory as it will need at worst case, and never lets go of that memory. In C based languages, this is typically done with static allocations when the program (or embedded system) first starts up. If you think of a simple example where you have data coming in, being transformed, and then sent out, the code that reads in data mallocs a buffer for the size of the incoming data. (Importantly, you are still limited by how much memory you have on the system in total, taking into account virtual memory systems and such.) When it is done reading that data, it passes it off to the transform code, that then does its transformation and frees up the read buffer. The code that does the transform might then alloc a buffer for the transform. The code that sends it out then allocates a buffer that is read from to send data out over the wire, or it might re-use the buffer that the transform code used, depending on your concurrency needs. If you have a bunch of threads all reading at once, such as from network connections, you typically allocate buffers as needed. New connection, new buffer. You can get smart about handing ownership of alloc'd regions off, Rust does things like that. You can use C++ smart pointers to automtaically de-alloc when done. You can try and do your transformations in place. Fine and dandy. But the fact remains that these are all optimizations. Because at the end of the day, you can allocate maxIncomingConnections * maxIncomingDataSize maxTransformBuffers * maxTransformBufferSize maxOutgoingConnections * maxOutgoingConnectionBufferSize and avoid the entire problem of ownership and dellocations. Importantly, you can *always* do this. Malloc is MUCH more efficient in terms of memory usage. Without malloc you end up setting some really hard, and lower, caps on how much data you can sling around at once. Using static allocation makes you plan for the worst case scenario, and always code against it. This also means you can precisely define the capabilities of your system. For embedded, this is very important. If I am handling sensor data, and I ask the programmer who wrote the driver that's reading from the sensors "what is the max speed I can read from the sensors at?" A crap answer is "it depends". Sure I can work out a matrix of how hard I can push a combination of sensors before I start to run out of memory, but a much better answer is an explicit definition of how fast each sensor can be read from, and a hard guarantee that the data will always be there, and be valid. *tl;dr* malloc is an optimization that allows for more efficient use of memory. In real world scenarios, e.g. with computers that have finite amounts of RAM, malloc is provably not required, since all code realistically has limits on how much memory it can use anyway, it can never use more memory than exists on the system. I'll admit my initial argument was from authority, where as I should have made my case based on principles of software engineering. 
You seem to be in error about one thing. `#include &lt;string&gt;` doesn't have to be implemented in C++. It is perfectly legal under the C++ standard to make `#include &lt;string&gt;` create a compiler-understood token `basic_string&lt;CharT, ...&gt;` which maps to a compiler-defined structure that is not implemented in C++. Now, that is a pretty bad idea, because you add a pile of extra work to the compiler instead of to the std library implementor. At the same time, when they discovered serious performance overhead problems (say, `make_index_sequence`) compiler writers *did* add intrinsics that made it ridiculously faster. And, with the restrictions on preprocessor tokens and reserved words, what `#include &lt;string&gt;` does can be defined not as C++ text even if it is written as C++ text; it is legal for compilers to "pre compile" `&lt;string&gt;` and when you `#include &lt;string&gt;` to inject the result without reparsing anything. As far as I'm aware, nobody does this, because it is much much easier to just implement it as a library. Libraries can be unit tested easier, bugs can be found, etc. I'm hoping with a modularized std library we can get much of the advantages of such a "pre-compiled modular header" without having to have compiler writers special case it. --- [tag:C++17] introduced a deduction guide for `std::array`: https://en.cppreference.com/w/cpp/container/array/deduction_guides -- it deduces its size. std::array foo{1,2,3,4}; 
The benefit of UB instead of ill-formed is that you can provide out-of-band or compiler-provided custom deterministic behavior. Case in point: nlohmann/json used to unconditionally call abort() with -fno-exceptions on any throws. After [this ticket](https://github.com/nlohmann/json/issues/938) and [PR](https://github.com/nlohmann/json/pull/940/files) each of try, catch and throw behaviors can be defined by user. Not sure how this would look at compiler level but in this solution user macros are actually rather nice as you can customize the behavior per compilation unit, between debug/release builds etc at fine grained level. 
Even if the compiler provides such intrinsics that doesn't help with the syntax problems and it doesn't change the fact that they still have to behave like normal types, so e.g. construction has to be specified in terms of normal constructor semantics &gt; As far as I'm aware, nobody does this, because it is much much easier to just implement it as a library. Libraries can be unit tested easier, bugs can be found, etc. Considering that most c+- compilers are written in c++ what makes you think that an integrated std::string wouldn't be implemented as a library that you can unit test? And are current optimizations not unit tested? &gt; I'm hoping with a modularized std library we can get much of the advantages of such a "pre-compiled modular header" without having to have compiler writers special case it. When and if we finally get modules (I'm not all that sure) then that should indeed solve the compile-time issue (and only that) just have to wait ~5 Years or so until I can use it in production. I'm really not a fan of statement Alla "it's not that bad, because we will get ....". Even if such predictions hold true, it doesn't change wether or not something is a problem right now. &gt; [tag:C++17] introduced a deduction guide for std::array: &gt; https://en.cppreference.com/w/cpp/container/array/deduction_guides -- it deduces its size. &gt; std::array foo{1,2,3,4}; I'm aware of that, which is why I said it took 6 years to get there and I afaik still can't write std::array&lt;double&gt; foo{1,2,3}; Instead of double foo[]{1,2,3}; 
Not that much, 99% of this language are types (effects, lemmas, refinement types, dependent types) which are being eliminated statically, and the language itself does not have that much runtime features (no object system for example). Allocations are done as a first class effect (pretty like state monad), the only disadvantage is LowStar library, which is quite small so far, although it seems they consider C as a main target, so it is getting better. The good thing is it does not introduce overhead (and gives quite a control on inlining and other stuff) and can emit a subset of C99 for the CompCert compiler (which itself is verified). They also have quite a neat examples https://github.com/FStarLang/FStar/tree/master/examples/low-level
Oh, there are plenty, just non-standard. One of my faves here https://github.com/foonathan/memory
If frameworks are on the table, then this discussion is just an e-peen measuring contest of who has seen the gnarliest codebase. Pass.
Eh, modern C++ is a breeze if you know how to use it. You *really* have to know how to use it, by reading forums/books on best practices and watching CppCon (and other) talks. But once you have a strong grasp of it and know most of the catches/intricacies, it's very nice to use. As an example, typedef/using and auto are **AWESOME**. You can abstract away all types, making your code very flexible. Want to use a different container, or want to change a type to be a template? Just change the typedef. All the complex rules give the language great syntactic possibilities. Just look at [this JSON library](https://github.com/nlohmann/json), it looks a lot like JS. You can't find that in C# or Java (AFAIK, correct me if I'm wrong).
Don't even think a tagged allocator is necessary. The containers throw for (1) exceeding max_size limits, (2) illegal parameters (e.g. vector::at()), and (3) allocation failure. Saying "too bad, goto terminate" on the first two isn't so bad?
It alway had types. It's strongly typed (with very few implicit conversions). It's also dynamically typed. Pretty mutch like C++ templates with deduced return types, auto, but at runtime. 
I can confirm that removing this ODR-use from virtual destructors will reduce a significant pain. Are you suggesting that the deallocation part be inlined to the call site of delete in that case? If not - how would you implement this?
&gt; The benefit of UB instead of ill-formed is that you can provide out-of-band or compiler-provided custom deterministic behavior. Wouldn't using "implementation-defined" be a better category for this sort of thing?
&gt; RAND_MAX is 2147483647 on any system that I care about Move the goalposts much? &gt; I'm far more concerned with code being easy to read and understand than a negligible bias in a random dice roller in a video game. So someone is going to write a full game in C++ but finds &lt;random&gt; too difficult? Inane fantasy there mate.
What deleter would you give the unique_ptr? By the time the shared_ptr is fully constructed, its deleter is type-erased.
Python is strongly typed. Different types do not mix (at least not more than in C++). It's also dynamically typed.
&gt; Given the presence of weak_ptr, Given the number of mentions of `weak_ptr` in this discussion, I almost wonder if I've been doing something wrong given that I've virtually never wanted or used a weak pointer...
I've been an embedded software developer doing C and C++ since 1996. One of the things I know for sure is that not everyone who says they need the performance of C really does... and generally C++ is good enough. IMHO unless you are doing microcontroller work C++ is probably fine... (really, we used C++ on Motorolla 68306 chips and it worked fine)... Most of my embedded coworkers need to concentrate far more on writing correct code that does the job and not nearly so much time microoptimzing every line of code (which doesn't generally make much difference anyway).
https://wg21.link/CWG1878
&gt;writing code that wraps a C++ class or API as a set of C functions and anonymous pointers is about the most mind numbingly terrible work I can imagine Write a CLI tool to automate the process and be done with it. There's edge cases of course, but it reminds you what can cross the shared library boundary, and what can't. &gt;that's work for a computer to do, but it can't do it for entirely unconvincing reasons. C++ is never going to stabilize an ABI. Itanium is as close as we will get. It can't be done without breaking decades of libraries, especially on Windows. &gt;The whole plugin and dynamic runtime story is one of the major reasons to choose any other language but C++ The only compiled language where this isn't a problem is C. Rust has some interesting ideas about working around the issue, but if you want to do this in Rust today you need to write a C compatible FFI. I don't disagree with you that it's a headache. But it's reasonable, given the scale of the problem. Forcing a C interface where the only data that can be exchanged are C-language primitives resolves most of the core issues. 
What about some way to mark objects that contain non-owning references/pointers such as iterators and string_view? What about importing Rust's lifetime annotations wholesale? A whole bunch of problems, such as this one, would go away if we had a (proper) mechanism to statically (i.e. transparent to the compiler) tie views to the objects that own their data.
&gt;You really have to know how to use it, by reading forums/books on best practices and watching CppCon (and other) talks. But once you have a strong grasp of it and know most of the catches/intricacies, it's very nice to use. Just for how frakkin auto works. Yeah been there done that, it is called tour of c++. What about universal references, go get another tour of c++. What about move semantics and how to implement rvalue-ctor properly... list just goes on. &gt;You can abstract away all types, making your code very flexible It is just a system that feeds itself. Moreover typedef was there for ages. Using is a bit too late addition to the game where templates were owning the place for like 20 years. Just Google for 'orthodox c++'. Those guys are not joking. They are mostly in the industry where you need to generate most precious pictures in like 10ms budget.
I would be filled with joy if I didn't have to worry about crashes/UB when I accidentally use `auto` with an Eigen class.
The thing is, for many use cases, you don't need to "fully abandon heap". You need to significantly reduce heap allocations, yes, but you don't need to completely eliminate them. And recent C# features like `Span&lt;T&gt;` and `ref` returns should help with that. Also, other possibly coming features like `static` delegates should improve that even further. It will be interesting to see if game programmers embrace them (once Unity updates the C# compiler it uses to C# 7.x).
&gt; objects that contain non-owning references/pointers Isn't that a `std::weak_ptr`?
Come to C#, where the ISO standard may finally be updated this year to C# 5.0 from 2012. And there are at least three common implementations of the underlying framework, all from the same company.
Then you have the good fortune of not needing to represent a graph structure with shared pointers.
I don't think that makes any kind of sense. There actually is a non-standard dialect of C++ that does that: C++/CLI (Common Language Infrastructure is a technically more accurate term for what you call "CLR"). And it has many non-standard features exactly because standard C++ does not map well to CLI: * Templates? CLI does have generics, but they're not even close to being compatible with C++ templates. And I'm not even talking about advanced features like variadic templates or non-type template parameter. Even the most simple templates like `template&lt;typename T&gt; T f(T x) { return x + x; }` have no reasonable representation in CLI. * Types? CLI differentiates between reference types and value types. C++ has no such distinction at the type level. * Move semantics? I have no idea how you would express that in CLI. Etc.
&gt; The new features seem more line what we in C++ land call strong types, such as tagged (fudamental or other) types that don't mix implicitly,and some parts that seem somewhat similar to concepts. Huh, hadn’t thought of them like that.
I think C++20 is more the next “feels like a new language” release since C++11. 
Works fine for me.
I think cevelop does things like that for `const`. Maybe it does more?
What if T's copies throw? I want the "growing" vector methods to be marked as throwing lightweight exceptions, without going through the exception translation stuff in those cases. A tagged allocator seems like one way to accomplish that. It's still a ways off though, and I'm no allocator expert.
My hand-wavey solution is to have the new expression ODR use both ::operator new and ::operator delete. I am imagining having an empty vtable slot for the virtual destructor in most TUs, and those vtables would have weak linkage. The TUs where new is called would have a vtable with a filled virtual destructor slot, and that vtable would have stronger linkage, therefore overriding the ones with weak linkage. This is an area where I am confident I have correctly identified the problem, but I am less confident that I have correctly identified the solution.
I also like having UB because the optimizer is allowed to make more aggressive decisions. In my no exceptions code with UB throws, the optimizer could completely eliminate branches that cause throws.
It is a creative idea to play with the linkage however if the DLL/Shared Object that calls the new/delete is only loaded later, there is no choice but to resolve the virtual table reference from the constructor to the weaker one that does not contain the reference to delete. This will have all created objects point to the weaker virtual table, unless I'm missing something. I believe the only choice is to have another virtual table slot to return `dynamic_cast&lt;void *&gt;(this)`, and have the deallocation be done outside. This way even the `operator new` does not ODR use the `operator delete`. 
Why not define it like this?: struct TypedBase {protected: TypedBase()=default;}; template &lt;typename T&gt; struct Typed : public TypedBase { public: using type = T; operator T () const { return mX; } protected: Typed (const T &amp;val) : mX(val) {} T mX; }; class Foo : public Typed&lt;float&gt; { public: Foo(type x) : Typed(x) {} operator int() const { return static_cast&lt;int&gt;(mX); } }; class Bar : public Typed&lt;int&gt; { public: Bar(type x) : Typed(x) {} }; template &lt;typename T&gt; T default_cast (const Typed&lt;T&gt; &amp;var) { return T(var); } template &lt;typename T, std::enable_if_t&lt;!std::is_base_of&lt;TypedBase, T&gt;::value, int&gt; = 0&gt; T default_cast (const T &amp;var) { return T(var); } Or using the variety of other metaprogramming methods that can detect a member typedef 'like `type`? That way you don't need to create a separate map that has to be kept in-sync with your types.
gcc's -Wsuggest-attribute and friends can do that for a few things, mostly gcc specific though.
I like the idea. The tool might already exist, but I haven't heard about it. I'm not sure how much of LLVM will help, as `noexcept` and `constexpr` are language constructs, which would be removed when compiling to IR. Your rules are not completely accurate (from what I understand), especially for constexpr. As I understand it, the rules would be like this: 1. If a function doesn't have use any `throw` expressions and only makes calls to `noexcept` functions, then the function is `noexcept`. 2. If a function is pure, only uses [Literal Types](https://en.cppreference.com/w/cpp/named_req/LiteralType), only makes calls to `constexpr` functions, and all the expressions satisfy the rules for [Constant Expressions](https://en.cppreference.com/w/cpp/language/constant_expression), then the function is `constexpr`. The challenge is that if a function is evaluated to be `noexcept`/`constexpr`, then any functions that call it may need to be reevaluated for being `noexcept`/`constexpr`. This problem could be solved by keeping track of what functions already evaluated functions call, and add them back to the queue if the callee is determined to be `noexcept`/`constexpr`. Another option would be to run the evaluation repeatedly, so that the results of one pass only consider what is already declared `noexcept`/`constexpr`, and the result of the tool is applied after each pass.
Two overloads would do the same. float default_cast(Foo const &amp; f) { return f; } int default_cast(Bar const &amp; b) { return b; } 
Solving "pass through" marking of exceptions like that is something that the lightweight exceptions proposal will need to fix. Allocator tagging seems like a suboptimal fix there.
If I understand /u/suspiciously_calm correctly, they mean something like a type trait (for example, the mechanism could be something else) for “owns its data” vs ”is a non owning view”. Ex: ```c++ template &lt;typename T&gt; struct is_view; class string_view { /* ... */ }; template &lt;&gt; struct is_view&lt;string_view&gt; : std::true_type {}; ```
It's too bad Eigen is stuck in the C++98 world. Sure they conditionally added many C++11 things, but they're stuck with all that old cruft. I'd love to see a C++14 Eigen 3.4 or 4.0, or even better, C++17 Eigen, which can finally fix [all the alignment issues](https://eigen.tuxfamily.org/dox/group__TopicStructHavingEigenMembers.html). Unfortunately this will most likely never happen (or in 5+ years).
P0672R0 is from June 2017, over a year old now. What happened with it? :-)
better formated: [godbolt link](https://godbolt.org/g/vEfnhx)
That last bit I think is ok, you just add the tags and during the next compile, maybe it will find more. That being said, I think you are right about th rules, I was just kinda going off the top of my head with them. A real implementation would obviously be very careful to get things right.
Visual C++'s Code Analysis has [C26440 DECLARE_NOEXCEPT](https://docs.microsoft.com/en-us/visualstudio/code-quality/c26440?f1url=https%3A%2F%2Fmsdn.microsoft.com%2Fquery%2Fdev15.query%3FappId%3DDev15IDEF1%26l%3DEN-US%26k%3Dk(C26440)%26rd%3Dtrue%26f%3D255%26MSPPError%3D-2147217396), [C26497 USE_CONSTEXPR_FOR_FUNCTION](https://docs.microsoft.com/en-us/visualstudio/code-quality/c26497?f1url=https%3A%2F%2Fmsdn.microsoft.com%2Fquery%2Fdev15.query%3FappId%3DDev15IDEF1%26l%3DEN-US%26k%3Dk(C26497)%26rd%3Dtrue) and other similar warnings.
Agreed. I apologize for that. You can find the C++Now 2018 talk here: &lt;https://www.youtube.com/watch?v=c9Xt6Me3mJ4&amp;t&gt; The talk has a few technical details but it is largely high-level and deals with a few of the problems getting C++ working. For more technical content including code examples, idioms, and guidelines, come to my CppCon 2018 session: "Modern C++ in Embedded Systems - The Saga Continues"
You missed the point. The point is that the frameworks use complicated features of the Python language. It's an argument in the vein of saying, "Oh you think C++ isn't complicated? Well look at Boost or Eigen." It's a valid point.
&gt; What about some way to mark objects that contain non-owning references/pointers such as iterators and string_view? Would love something like that. https://codereview.stackexchange.com/a/86457/30863
[P0936](http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0936r0.pdf)?
I think ReSharper c++ does suggest some `constexpr` changes (and also `noexcept`). If you look [here](https://blog.jetbrains.com/rscpp/), they have an example for switching to `if constexpr`. I'm not sure if it suggests it for functions, but if it doesn't now it is likely in the works. It also suggests `const` for variables, and maybe soon enough it will suggest `constexpr` as well.
Great another cute trick with template programming you can use to impress your blog readers and infuriate your coworkers.
You're right. But I also don't see why a use case that I suspect is a strong minority should scuttle something that could be useful in most *other* cases. (Though as I say in another comment, it seems like `use_count() == 1` would do what I want here. Though honestly, we don't even use `shared_ptr`; we have an intrusive smart pointer that is what we use almost all the time. In part that's a historic "accident", but I suspect it helps us even now.)
Doesn't compile on `VC 15.8 Preview 3`. Apart from that, what's the objective?
&gt; Is there a reason you're 2 major versions behind stable of both gcc and clang? Probably to demonstrate that the technique doesn't require bleeding-edge compilers.
Have to add more overloads as you add types, though. Easier to either inherit from a castable type, or use metaprogramming to detect a 'type' typedef.
As someone who doesn't regularly write types that trivially wrap floats and ints, I have no idea why this would even be useful. Wtf even is this
I understood the point fine. Eigen, boost, ranges, pick your poison. Libraries can be arbitrarily complex and arcane independent of how complex the language rules and conventions are, so I didn't see the point of engaging with that line of argument.
Maybe - If modules, (full) ranges and abbreviated template syntax make it I agree.
How is adding more overloads significantly harder than adding more typedefs, etc.?
Because it's *another thing to keep track of*, that you have to keep in-sync with everything else. It's better to keep such things enclosed/defined by the types themselves, as then it's defined in one place.
It's not a difficult language, i.e. it does not have a lot of features that are difficult to understand. The hard part for people that learn the language is how to combine all those features together. Your comment about software complexity is spot on. In order to build anything useful in any environment/platform, the amount of complexity that must be handled easily approaches and surpasses that of the C++ language alone.
&gt; What I like to achieve, is that I can call one function, let's name it default_cast, which does the cast for me. All the casts which are in 90% of the code the same. What part of this is "safer" than doing explicit casts? This seems like unnecessary obfuscation at best and a recipe for surprising implicit conversions at worst.
SFINAE is a very useful feature. It's hard to write, but it's not something 99% of the language users would have to ever use. I wouldn't call C++'s typing system weak. I'd call it strong with a nuke button. No concepts does not make C++ more complex. We don't have this feature yet in order to be able to fully evaluate it. C++ programs can be as modular as one wants. It does not have modules yet, but this does not mean everything should be stuck in one global source file. Sum types is a nice feature that makes some solutions easier to write, but that's about it. It can be simulated to a large degree in C++ so this isn't really a problem with C++. C++ allows for.value types and hence NULL is not really a problem in this language. The grammar is not that terrible. Yes, it's not context free, but it follows the general logic of C. Ada, despite its advantages, hasn't caught on, and I've seen many people say they prefer the C-style gammar over the Pascal-style grammar. Personally I like Ada though and I wish I had more chances to use it in professional environments. Rust is cool but I haven't used it so far. I've read that it's far too restrictive though. Overall, due to the 80% rule, I don't think C++ will ever be replaced by something better like Ada or Rust.
Reference is always const, as you can’t rebind the reference to another variable.
&gt; `remove_reference&lt;T&gt;` You can't defeat this that easily. Consider using `struct Foo { int&amp; a; };` as `T`, which will also let you modify `a`. IIRC there is a proposal that lets you propagate `const` in such cases.
There are a bunch of ways. The most direct would just be something like a sequence of hardcoded \`if\` statements that print out different things for different input names. A more elegant version might be to use a std::map&lt;std::string, std::string&gt; to map between an input key (one of your friend's names) and the proper description. There's a nice example of how to do the second one here: [http://www.cplusplus.com/reference/map/map/operator\[\]/](http://www.cplusplus.com/reference/map/map/operator[]/)
That doesn't really have anything to do with auto though, or does it? Afaict the problem with auto stems from using lazy vectorization, i.e. evaluation proxies.
&gt; SFINAE Another proof of templates' unsoundness. One does need not SFINAE, but a decent (and sound) metaprograming facilities. &gt;No concepts does not make Concepts *does* make template substitution reasonable, without them C++ is so ridiculously lame. I didn't say they are complex. &gt;It can be simulated to a large degree Such a great language with which you should build lame and unsound simulation of basic types. &gt;C++ allows for.value types and hence NULL Straustrup is bold and hence NULL is a problem.
Is not necessarily the object that is const either as if it was an intrinsic property of the object. After all you can have const and non-const references to the same object. 
any transcript ?
Just Clang 4.0.0 and GCC 6.1 then ;-) For VC, we'll have to wait a bit, till the bleeding has stopped a bit.
I think it was in the 2015 or 2017 current versions.
That was quick! Thanks a lot!
Did you mean *std::experimental::propagate\_const* as discussed here: [https://www.bfilipek.com/2018/01/propagate-const.html](https://www.bfilipek.com/2018/01/propagate-const.html) ?
[p0035r4](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0035r4.html)
I was thinking about that, but apparently that is only for pointer-like types :(. Maybe because it would need overloading of the `operator.` for references?
I think it's a bit unfair to blame the expression template issue on auto. The problem is type deduction. You could easily pass the exact same expression to a template function and have exactly the issues, with no auto insight. Alternatively, while using auto, you could specify the type on the right and have no problems. 
I'm sorry about all the heat you are getting (in terms of downvotes) I thinking most of your arguments are completely valid, but I guess many people react out of reflex when they feel their language of choice is attacked and your tone is pretty aggressive.
For functions at the moment R++ only suggests making them `const` or `static` when possible. We'll look into adding `noexcept` and `constexpr` analyses.
&gt;your tone is pretty aggressive. That's true, sorry for that. I still have to support some C++ code and I could observe such a progress in the PL domain, so any C++ debate implies a silent cry of "why the hell do we still need to endure all these suffering, what for".
I do similar with my MIPS emulator, for which I built a Clang-based toolchain so you can compile C/C++/whatever to target it, and load the binaries into the VM (which is embedded in a dll/so). It can interact with the host program and vice-versa, including the host program supplying it with API calls (via MIPS syscalls).
&gt; There is no such thing as const reference apparently there is : int main() { using T = int&amp;; int x = 34; const T ref{x}; ref = 12; return x; } though since `int&amp; const ref{x};` does not compile I think that this should be a defect report.
The `noexcept` might have been the latest VS version indeed. But I'm glad to see that you're considering it. Also would it be possible to either stop asking for `const`ing value parameters of functions or auto collapsing them? If I have a function with `int, int` I don't want to make it longer to read or take too much space.
wouldn't that indeed show there is no effect adding the const to a reference?
Re `const`ing - sure, just disable the `Parameter may be 'const'` inspection (its severity is lowest possible by default already). What do you mean by auto collapsing?
&gt; wouldn't that indeed show there is no effect adding the const to a reference? yes, it has no effect, but it still exists as a language construct.
That's dynamic, whereas the ownership of Rust's references is completely static. For instance, it's fine to deallocate all the strong references in the dynamic scheme, but not in the static scheme: one has to first ensure there are no outstanding references before something can be deallocated. There's definitely pros and cons to both schemes (e.g. no reference counting overhead for the static scheme) and so Rust also provides reference counting with weak pointers for when that is useful.
Is it useful in practice to mark functions as `noexcept` nowadays, except for well-known examples like move constructor/move assignment/swap function? Can somebody demonstrate optimizations that a compiler will apply because a function is `noexcept`?
But you still have to instantiate the alias template itself each time, right? The speed difference would come from the difference in time required to instantiate a type and an alias template, and it's not really obvious that it would be huge.
I have the impression that the given example could be fixed if the move constructor of ExpressionTemplate is overloaded to evaluate the expression, am I right?
&gt; Another proof of templates' unsoundness. One does need not SFINAE, but a decent (and sound) metaprograming facilities. Agreed. &gt; Concepts do make template substitution reasonable Partially agreed. Better yes. Reasonable? no. &gt; without them C++ is so ridiculously lame Nope, it is not. Error reporting differs wildly from compiler to compiler, which is proof that it's not the language that is lame, but the compiler implementation. &gt; Such a great language with which you should build lame and unsound simulation of basic types. On the contrary...perfection is achieved not when there is nothing else to add, but when there is nothing else to remove. Being able to implement a feature with the base language is a lot better than having to alter the language itself, for a multitude of reasons. &gt; Straustrup is bold and hence NULL is a problem. What?
&gt; Isn’t this baffling? No it isn't. T&amp; is constant, T isn't. I've read various blog posts from this guy, and he is always doing that. I.e. he always splits hairs with the language.
Basically hide the `const` part for value parameters so it doesn't clutter the interface.
I'm using GCC 6 at work and was missing requires. Also I was shocked how simple it was to implement so I though it might interrest someone in a similar predicament as I.
I will check if there's a hack fir VC I can find :)
I can totally relate
Although, clang says that `const` on a reference type has no effect, there is no application of `const` on a reference. That `const` in `const T` is being *ignored and thrown away*, due to the rules about qualifiers on aliases and template parameters. I'm not going to link to those, someone else might, or you might want to look them up yourself (in the standard obv. [here](http://eel.is/c++draft/) or in [pdf](https://github.com/cplusplus/draft/raw/master/papers/n4762.pdf)).
&gt; there is no application of const on a reference. at the semantic level. At the syntax level there is clearly one.
Well, at the syntax level, `T` is not a reference :)
Hi! What kind of game engine are you developing?
Hi, I work for [CRYENGINE](www.cryengine.com) 
&gt; Being able to implement a feature with the base language You are not able to implement sum types in both safe, comprehensible and effective way with a base language. Even the most basic languages (e.g. simple typed lambda calculus implementations) are being extended with sums and products, while C++ have a half-baked abominations like union, enum, enum classes and std::variant, but no sum type. Are you sure there is nothing more to remove and to add instead? &gt;What? I was mocking you logic, which is illogical. Being able to allocate on a stack does not make nullptr sound. It's still there, and you still have no sound and safe way of saying "there is no object available" aka option type.
Do you like it? Have meet you at the GDC Cologne 2016? :D ... then again there were lots of Crytek folks there
**Company**: [ArangoDB](https://arangodb.com/), [ArangoDB Career Page](https://careers.arangodb.com/) **Type**: Full time **Description**: We are looking for a C++ Windows Developer to take care of the Windows version of ArangoDB. ArangoDB is a native multi-model NoSQL database. It combines the power of graphs, with JSON documents and a key-value store. Oh, and did we mention it is open source? **Location**: Cologne, Germany **Remote**: Yes **Visa Sponsorship**: No **Technologies**: Currently using C++ 11, C++ development using Visual Studio, Windows **Contact**: Apply via [Full Job Description](https://careers.arangodb.com/p/4f3df03efaca01-c-c-developer-m-f) on the website or send an email: [gudrun@arangodb.com](mailto:gudrun@arangodb.com)
I’m getting a 404 trying to load
It's allowed so rhat template code doesn't break
I like this. Will you be able to present in San Diego?
&gt; I think it's a bit unfair to blame the expression template issue on auto. I don't think anyone is "blaming" `auto` here. Expression templates are really neat. `auto` is really neat. The two together is really dangerous. Neither is at fault. &gt; Alternatively, while using auto, you could specify the type on the right and have no problems. It's not that this is a hard issue to fix, it's that it's a hard issues to notice. 
David Musser, Alexander Stepanov: generic programming and the STL.
I quite dislike his blog but still, there might be something worthwhile occasionally.
Stack Exchange Stack Exchanges users and Very old forum users with now broken links
In my opinion the initial recommendation was the best one: void fun(Foo arg); // template with concept Foo void fun(foo arg); // function with argument-type foo All we would have to do is show a really tiny amount of professionalism and follow stdlib-naming-conventions as the users of virtually any other language (with exception of C) do.
Don't forget Dennis Ritchie and Ken Thompson, from which most of the core of C++ was pioneered.
The stdlib naming conventions work very poorly for a lot of people including myself. I tried them on a project and found it to be very difficult to work with. Often times variable's have the same name as their type and stdlib's naming conventions prevent that.
&gt; Consensus is a fluid thing, as is the makeup of the committee: there was very strong consensus for several years to pursue 2D graphics and it would be foolish to believe the current consensus will remain forever. Even if another approach is pursued, the TS will offer a starting point. IMO, there was a consensus against this TS because it is as it is. Believing that this could be a "starting point" for something else is just nonsense: same causes produce the same effects. There was a looong list of defaults and none of them has been answered. &gt; The proposal is the result of many thousands of hours of work from a small number of wording experts and graphics experts. Starting again from scratch on something else would delay the introduction of 2D graphics by years. I may be wrong but I feel that many people (a majority) prefer nothing than this. I think this kind of argument reinforces the opposite side and actually prevents another 2D TS from emerging. 
There are several solutions to that problem that cover pretty much all cases in practice: Using namespaces as they were intended to: auto string = std::string{}; auto other_string = std::string{}; Using abbreviations for local variables (since functions are supposed to be *short*, this should rarely be a problem): auto str = std::string{}; auto str2 = std::string{}; Use fully qualified identifiers: struct bar {}; namespace foo { struct baz {}; void fun() { auto bar = ::bar{}; auto baz = foo::baz{}; } In combination these cover pretty much everything. The resulting code is then consistent which is MUCH more valuable, especially since no matter which naming-convention you use, someone will have written a library that removes any potential benefit your scheme is supposed to have.
I think this is very promising, looks good and is backed by pretty much all the big shots
I like the idea of the destructor returning the pointer to storage, but I don't think it works. If a derived class has class-specific operator delete, we should be able to call that... but we need to know which one to call, and that's based on the dynamic type. If we tweaked that idea, and had the dtor return a pair of the dynamic `this` pointer and the address of the operator delete function, we are right back in the situation of ODR-using a (potentially missing) operator delete. Note that a class based operator delete seems fine in kernel and embedded, as those could easily be using a fixed, domain specific buffer. Your points about my hand-wavey solution are well taken though. My suggested solution has some difficult ABI problems.
I think we can merge those solutions and say that the destructor returns `(this, nullptr)` in case there is no class specific delete operator, thus the ODR use of `delete` will still happen outside of the virtual destructor. 
I can't think of good reasons why this shouldn't be how you'd expect code like this to work. After all, if you have a std::unique\_ptr&lt;T&gt;, and take a const&amp; of it (std::unique\_ptr&lt;T&gt; const&amp; ptr2 = ptr1;), you still expect ptr2.get() to return a non-const pointer. 
What's the benefit removed by using CamelCase for types and snake_case for variables? As I said I've used that convention for years and haven't noticed any issues with it whereas there are actual syntactic and technical issues with using stdlib's conventions. Your solution requires shadowing names, which will get rejected by linters and doesn't generalize, for example shadowing won't work with parameters or fields.
Yeah I know a comment would have helped. From measurements, aliases are much faster. Also, aliases are much simpler in general. You cannot specialize or partially specialize them, they are not creating a new type at all etc.. 
In your example, ref is type int&amp;, not int&amp; const (which would be nonsensical).
&gt;&gt; RAND_MAX is 2147483647 on any system that I care about &gt; &gt;Move the goalposts much? You introduced the notion RAND_MAX could be small. &gt;&gt; I'm far more concerned with code being easy to read and understand than a negligible bias in a random dice roller in a video game. &gt; &gt;So someone is going to write a full game in C++ but finds &lt;random&gt; too difficult? Inane fantasy there mate. A full game could be a student project, and yes. Not a fantasy but reality. 
Scott Meyers does an excellent job in clearing the mystery around such nuances. Effective Modern C++. Worth a read.
const explicitly does not work with indirection. This is a basic design principle of the qualifier. If you KISS all the time, you shouldn't run into problems. Hopefully.
 `void foo&lt;Container T&gt; requires EquallyComparable&lt;T&gt; (T &amp; t){}` How about `void foo&lt;EquallyComparable Container T&gt; (T &amp; t){}` ?
Do people really use linters that warn about shadowing types outside functions, especially if those are in other namespaces? I know that even GCC disabled that part from their warning in C after Linus Torvalds wrote one of his rants on LKML. IMHO this is more of an issue with the linter. (Note that I am **not** saying you should shadow variables and that the ability to do so even inside a scope is one of my major criticisms of Rust; I'm talking about shadowing types from different scopes.) The main-advantage that most people point out when using different naming-conventions is that they can supposedly recognize types faster. If you mix styles however you get very fast to the point where every style possible is used by some library for everything, meaning that even your local variables will soon collide with something else. An example are naming-conventions that use UpperCamelCase for functions, which removes the ability to distinguish functions and classes right away, which was often the whole point of deviating from the stdlib-conventions. Granted, this doesn't create THAT many issues with your specific problem (though it isn't irrelevant either), but IMO it undermines the entire rationale of deviating from the standard-conventions entirely.
This made me wonder: How would one construct "unit" tests such that the should always fail to compile, given some specific code. Yes, you can come up with something, but compilers might just give different error message... I wonder if there would be something in future compilers, like: std::can_compile&lt;expr&gt; on which you can std::static_assert - any thoughts? 
This book helps to answer that question: http://www.stroustrup.com/dne.html
&gt; There are still plenty of ways to hit UB or out of bounds accesses UB in general - sure (for example, UB on integer overflow is out of scope), but out of bounds accesses are intended to be covered - see "Enter collections" section in OP. Of course, there might be errors in the rules here and there, but I am confident that going along these lines (and implementing a static checker which enforces the rules), it is possible to get 100% memory-safe C++. [NB: FWIW, work on an open-source framework which implements reactors with all their goodies such as replay of production bugs, and memory safety as described in OP, has already started]. 
hana::sfinae maybe? https://www.boost.org/doc/libs/1_61_0/libs/hana/doc/html/index.html#tutorial-introspection-sfinae
&gt; I don't see anything in the article about races, my guess would be that this guarantees nothing about races The whole thing is intended for (Re)Actors where essentially everything happens in one single thread, so multithreading races won't happen. 
What are you talking about, of all the languages I use C++ is the only one where people don't use the stdlib naming conventions!
Andrei Alexandrescu with his articles, book and talks. Matt Godbolt with [Compiler Explorer](https://godbolt.org/) Me -- I think the [C++ Middleware Writer](https://github.com/Ebenezer-group/onwards) was the first on-line C++ code generator.
Consistency with what? In any sizable code base, the standard library names only make a small portion of the code. If you want.g. use Qt, using PascalCase might actually be more consistent.
I like it. The "template"-less syntax is actually similar to D's terse template syntax for functions and aggregates (e.g., `T foo(T)(T t)` or `struct Vector(T)`) but generalized even further. As I recall it uses parentheses instead of inheriting C++'s &lt;&gt; to keep parsing simpler (from an earlier time when D still tried to keep its implementation simple). This somewhat similar syntax in D is nice and, as far as I can tell, well liked in the D community.
Author here. Sorry, this page was shared with confidence with a few people and was not indexed on google, yet it ended up in reddit.... This work is far from down but I will share it once everything is flushed out. Sorry and thanks for the encouragements !
Just because it's a mess now doesn't mean we shouldn't strive for consistency. More and more 'modern' libraries follow the C++ conventions nowdays. Things like Qt is from an era when people wanted to write Java in C++.
I don't agree with your observation that more and more modern libraries follow the C++ conventions. I'm looking over the libraries I use and only boost follows that convention. Qt, capnproto, folly, cryptopp all use CamelCase. Looking at this list of the most popular open source C++ libraries, only 6 of the 28 libraries listed as Generic use that convention: https://en.cppreference.com/w/cpp/links/libs The others use CamelCase. Now having said that... I am NOT arguing that one shouldn't use the stdlib convention. Feel free to use it, do what works for your project... What I'm calling out is the suggestion that not using stdlib is unprofessional or a detriment to ones codebase. There are legit reasons why the other 22/28 libraries listed use CamelCase, and it isn't because we're unprofessional... it's mostly because we like to reuse the same noun to refer to both variables and types, and so to disambiguate we use different naming conventions.
&gt; The main-advantage that most people point out when using different naming-conventions is that they can supposedly recognize types faster. That's a side-effect but not the main advantage; the main advantage is that nouns can be used to refer to both types and variables without ambiguity, and verbs can be used for functions.
That's the multiple constraint feature of the adjective proposal. The merged proposal don't include this right now, by might be added in the future if there really is a need for it.
I still found it pretty interesting. FWIW, you had a broken link on the text "down with typename". (I think that was the text; I can't verify now of course.) You might have noticed anyway, but figured I'd pipe up.
Could I suggest a minor change to your survey? I think the "is it important" questions would be a lot better off as "how important is it to you", with a scale (e.g., 1..5). Likewise, I think the "would you use it" question would be more useful if it was phrased more about "how much/dependably would you use it?" Right now, (like most others, I think) I use \`static\_assert\` and such--but for a lot of lightly-used code, I don't bother, because it's such a pain. Depending on just how much more convenient concepts made things, I'd undoubtedly do a better job more often--but how much better and how much more often would/will depend on the level of convenience.
At that point, isn't it effectively a metatype?
I'm not saying it's unprofessional, I'm saying consistency matters, I mean isn't that why we have conventions and style guides? A significant fraction of the libraries I use follow the C++ naming conventions, boost, type_safe, GSL, while some like crypto++ and gtest uses Pascal/Java naming conventions. I agree though there are a lot of code out there in CamelCase. I remember when all libraries used the, at the time trendy, convention from Java, nowdays a significant fraction of the libraries you see posted here follows the C++ conventions and frankly I find it refreshing. Maybe one day we we have something like PEP8 or even better, rustfmt/gofmt.
Cache available here, so it seems to have been indexed by google... https://webcache.googleusercontent.com/search?q=cache:dSh96GTgqB0J:https://cor3ntin.github.io/posts/template_syntax2/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=si&amp;client=firefox-b-ab
&gt; You introduced the notion RAND_MAX could be small. I did no such thing; pay attention. &gt; A full game could be a student project, and yes. Not a fantasy but reality. No disagreement at all, only that such a student would be stumped with &lt;random&gt; but not, say, drawing to the screen. Sheer silliness.
FYI, I found it there: https://www.meetingcpp.com/blog/blogroll/items/Meeting-Cpp-Blogroll-153.html
Hahaha. Go figure !
From the article: &gt; So being const doesn’t say much for a reference, since they always are const, since they cannot rebind. 
One strategy that works more broadly than what the language offers is to tell the test runner (e.g., CTest) that this test succeeds if it fails to compile.
I seem to remember at least one of the proposals for this applying it to deduction in general rather than just `auto`. Then again, I could be wrong.
&gt; Many commercial, industrial, governmental, financial, medical and military code shops simply outlaw third-party code, even Boost, allowing only what is provided by the compiler vendor. Show me these shops. Where is the intersection of (A) programmers with a business need for 2D graphics and (B) programmers who are prevented from using anything outside of their vendor. What are these shops doing today? Turning down business because their own rules prevents them from taking it on? Aimlessly shuffling around in the hope that the standard will some day have a solution for them? If these shops exist, they indeed have a big problem.. but shoving a 2D library into the standard isn't going to fix it. The authors of this proposal are doing the right thing by making it available as a library. If it ends up being adopted by projects, that's an argument in its favor. My hunch is that it won't be, and that should eventually mean something to the authors.
I guess the best of both worlds is to have it configurable. Set a certain flag and it builds file by file, otherwise it builds as unity. You have your CI build the file by file incrementally, and build a full clean Unity build in parallel on a 2nd machine. This validates both modes work and they will take a similar amount of time (depending on the changeset).
But it's not just modified files. If I modify A.cpp and it's at the top of the unity list then all other files below it in the list (B.cpp, C.cpp) will have a changed compilation unit. Say some code in B.cpp relies on an include that is in A.cpp, but a change removes that include then B.cpp is now broken even though it hasn't changed. 
[Visual C++ Code Analysis ](https://visualstudio.microsoft.com/vs/preview/)has a number of rules around noexcept and constexpr functions. Specifically: noexcept rules (inspired from [C++ Core Guidelines F.6](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#f6-if-your-function-may-not-throw-declare-it-noexcept)): 1. [C26439 SPECIAL\_NOEXCEPT](https://docs.microsoft.com/en-us/visualstudio/code-quality/c26439): If your function may not throw, declare it noexcept. Checks special operators like destructors that should never throw. 2. [C26440 DECLARE\_NOEXCEPT](https://docs.microsoft.com/en-us/visualstudio/code-quality/c26440): If your function may not throw, declare it noexcept. Checks functions for non-throwing behaviors like if it has no explicit throw statements, etc. 3. [C26447 DONT\_THROW\_IN\_NOEXCEPT](https://docs.microsoft.com/en-us/visualstudio/code-quality/c26447): The function is declared noexcept but calls a function that may throw exceptions. This rule amends another rule, [C26440 DECLARE\_NOEXCEPT](https://docs.microsoft.com/en-us/visualstudio/code-quality/c26440), which tries to find functions that are good candidates to be marked as noexcept. In this case, the idea is that once some function is marked as noexcept, it must keep its contract by not invoking other code that may throw exceptions. 4. [C26455 DEFAULT\_CTOR\_NOEXCEPT](https://docs.microsoft.com/en-us/visualstudio/code-quality/c26439): Same as [C26439 SPECIAL\_NOEXCEPT](https://docs.microsoft.com/en-us/visualstudio/code-quality/c26439) but only fires specifically for throwing default constructors, for making it easy to filter out for certain design patterns. constexpr rules: 1. [C26497 USE\_CONSTEXPR\_FOR\_FUNCTION](https://docs.microsoft.com/en-us/visualstudio/code-quality/c26497): Suggests "pure" functions be marked constexpr for compile time evaluation. Inspired from [C++ Core Guidelines F.4](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#Rf-constexpr). 2. [C26498 USE\_CONSTEXPR\_FOR\_FUNCTIONCALL](https://docs.microsoft.com/en-us/visualstudio/code-quality/c26498): Suggests using constexpr variables for holding the results of certain constexpr function calls. Inspired from [C++ Core Guidelines con.5](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#Rconst-constexpr). Please try them out and let us know your feedback.
These look like exactly what I would want... Except I primarily develop on Linux. Would love to have these in clang or GCC!
Yes, but since you have to recompile the whole thing anyway you can use the occasion to change your setup to compile *(A.cpp) (B.cpp, C.cpp)* instead of *(A.cpp, B.cpp, C.cpp)* So that further modifications in A.cpp do not trigger a full rebuild. 
start with C++11 new features, it's a pretty long list.
IMHO it may be better to stick to the minimum approach as in P1141. I have some concerns about abbreviated syntax being too generalized as proposed here. Sure from a language design point of view it is more consistent that one expression should apply to all cases that are syntactically and functionally equivalent/similar. However, sometimes it doesn't buy you much. For example, from template&lt;typename T&gt; auto foo(T t) -&gt; T {} to auto foo&lt;typename T&gt;(T t) -&gt; T {} I'd say saving an extra "template" may not be a big improvement, just a preference of style. Considering the current proposal has already caused much contention, adding more IMHO may make the case worse and in worst case might be shot down again all together.
+1, with Stroustrup's *A Tour of C++* being a decent starting point for those familiar with syntax and language but not modern C++.
Marry it
 /* A generic lambda with types introducers as per C++20*/ auto foo = []&lt;typename T&gt;(T t) -&gt; void {} /* A function template with a type introducer : proposed */ Bar foo&lt;typename T&gt;(T t); Note however: struct T { ... }; Bar foo&lt;typename T::type&gt;(int t); // a specialization So a compiler will need to parse beyond `Bar foo&lt;typename T` before knowing what it has. Not sure if that is a problem, but we typically try to avoid requiring read-ahead.
Stop thinking objects and pointers/references to them, and think more about values.
For the moment, I'm going to concentrate primarily on people I remember being involved in the relatively early history of C++. Most of this is based on my recollections of old threads on comp.lang.c++, comp.std.c++, and such. In no particular order: - Bjarne (obviously) - Margaret Ellis - Angelika Langer/Klaus Kreft - Steve Teal - Doug McIlroy - Andrew Koenig - Dietmar Kühl - P.J. Plauger - Herb Sutter - Daveed Vandevoorde - David Abrahams - Steve Clamage - Matt Austern - Mike Miller - James Kanze - Andrei Alexandrescu - Hans Boehm - Howard Hinnant - Greg Comeau I've undoubtedly left out more than I've included, but my neurons are old and abused.
I wouldn't worry about it. When job hunting, I'm typically faking it until I'm making it: if I were in your shoes, I'd be pointing at your years of experience during interviews, smirking, and saying that *of course* you're very well familiar with C++. Then, assuming I get the job, I'd make getting up to speed with the newer standards a pretty high priority of mine. I'd get a book, something like Meyers "Effective Modern C++", and have it at my bedside. I don't know where you're from, but where I live, nobody expects a newly hired programmer to function at 100% efficiency from day one, even if they happen to come with years of experience. Instead, you're more likely to be assigned lower-priority bugs to fix, focused more on getting to know your programming environment and the code base than implementing cool new features from scratch. If you're at any place worth a damn, the company will also have coding guidelines in place, and code review routines such that your code is eyeballed by others (and critique frequently given) before it is merged anywhere. So relax. Fake confidence if you can't muster the real thing, and know that things will only be easier over time as you get more warmed up again. In the meanwhile, you'll have colleagues and your own brilliant inquisitive mind there to help you.
See, that's one of the things I did not consider at all and why I wish I wasn't dumb enough to have this draft posted on Reddit yet :( It's a very good point (unfortunately), thanks !
Some places like to focus on the new stuff, but not all. I wouldn’t worry about it at all - none of the C++ stuff you used to know is obsolete, nor has everyone suddenly rewritten their millions of lines of code to fit the new hip thing and asking you to sing songs about SFINAE.
You don't do manual memory management in C++. You do ownership based memory management.
Just write it.
My understanding was metatype is kind of declaration of object layout and constrains, while super-position of different concepts may be more general. Saying of analogy, smth like inheritance (metatype) vs mixins (list of concepts). But really my point was maybe this way "requires" parts is unneccessary, since &lt;...&gt; part may contain all requires with a single approach.
Get yourself the book "Effective Modern C++" by Scott Meyers as well
Pretty impressive list. I might have added Scott Meyers.
I opened R8, skimmed through a few pages, and saw a bunch of overloads like this: template &lt;class GraphicsSurfaces&gt; bool operator==( const typename basic_figure_items&lt;GraphicsSurfaces&gt;::abs_new_figure&amp; lhs, const typename basic_figure_items&lt;GraphicsSurfaces&gt;::abs_new_figure&amp; rhs) noexcept; Nope. This isn't nearly baked enough. 
&gt; What are these shops doing today? Wild guess... It sounds like a description of a Windows-shop, or a shop that is only doing Mac/iOS work. For some things, it's totally reasonably to say that you are only doing Win32/DirectX using Visual Studio, or Cocoa using XCode. I can't really imagine either of those plausible cases adopting a std:: graphics library because it doesn't solve the use cases of either Win32 or Cocoa, and can't possibly do so in a sane way. &gt; but shoving a 2D library into the standard isn't going to fix it. Agreed. To the extent that such shops exist, they exist because their needs are satisfied by what their vendors are offering them, so they don't feel forced to look outside of those vendor libraries!
Honestly I'm reading this templates book and SFINAE and the things people do with it makes my head spin.
The idiom is "fleshed out."
Don't read about SFINAE unless you're a library author and you think you'll really need it. Have a very basic idea about it, just about the concept, so that you can know that *when* you think you could need it, and if that day then ever comes (it's very possible it never comes), then go figure out the hard details about it. Don't learn SFINAE just for learnings sake.
&gt; For some things, it's totally reasonably to say that you are only doing Win32/DirectX using Visual Studio, or Cocoa using XCode. For sure, that's a good point. And as you say, I can't imagine that they are clamoring for a graphics library from the standard. Such a library would ultimately just be a subset of the functionality they already have available. This proposal is a solution in search of a problem. You're on pretty shaky ground if you have to rely on "dark matter developers" to make your equations add up.
I'm more displeased with his mechanism of mapping types to default conversions. It requires a *separate* structure to be kept up to date with changes elsewhere, and that's dangerous.
As a library author that frequently needs it... and much worse things... I will wholeheartedly second this. Our (library writers') job is to present you (library consumers) with interfaces that don't expose the nasty details of how we implemented our solution, including, as much as possible, things like static_assert based error messages before you got the point of an unreadable five page dump of a compilation error. We don't always succeed, but if we're exposing the SFINAE usage to the consumer, we messed up.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8yp7lj/best_resources_to_learn_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; because "students and beginners" that you're ostensibly pandering to certainly do. I'm not "ostensibly pandering" to them. I care very much about the C++ experience for new programmers, and the attitude that one should either 1) use a system that is incomprehensible to new programmers or 2) use Python because a system that introduces a trivial bias that nobody will detect in their student projects is a non-starter for me. You are certainly free to call such concerns silly and a fantasy, but such attitudes will not make C++ better for new programmers.
And the Scott Meyers series. Effective Modern C++ or something.
I just got my copy of *A Tour of C++, Second Edition* a couple days ago. Based on my reading of the first edition, think it's the best broad, concise overview of the language, and a quick read. It's especially good for people with some past experience and want to see a holistic presentation of the language as it exists today. This new edition has info up to the C++20 standard.
He probably knew or used auto_ptr back then, and that really is obsolete ;-)
I would get some coding problems and do them in c++. Leetcode is good for that. You’ll be surprised how fast things come back to you. This will increase your ability to answer basics-type questions, do whiteboard problems and it will reduce stress during interviews. 
I strongly agree. It feels very much like, "I don't like what you are doing, so I assume you don't like what you are doing, and therefore I am going to solve the problem I am telling you that you have." Quite independent of the people suffering from the problem actually suffering from it, agreeing that they have a problem, or wanting that particular solution. And if there are real shops that are actually hamstrung by insane internally-generated requirements that they can't use any library not supplied by their compiler vendor, despite desperately needing other functionality... Nothing in std:: can fix the sort of fundamental issues such a hypothetical company has. That's not a technical problem. It's obviously a human problem. And technical solutions to human problems are useless. People stuck in those places should apply for better jobs, and those companies should go out of business. Boom, problem solved.
Just gotta start reading up on the new features and put in the time to learn how they benefit the language.
We are on same boat...im currently trying to implememt my own thread pool just to warm up and examine the new features
Install CLion, and get somewhat comfortable with Conan.io. Made a huge difference for me on getting fast and efficient in just writing stuff that works quickly. My turnaround time on seeing C++ code changes working are about the same as Python and TypeScript, and debugging tooling is maybe even better
std::haters gonna std::hate
_Implement the rest of the fucking owl._
This is exactly why you want to post it publicly. None of us is as smart/dumb as all of us.
I interview people for C++ positions. I'm unimpressed if they don't know the basics of C++98/03. I'm not bothered if you don't know C++11/14/17. If you have a solid foundation in C++98/03, C++11/14/17 can be taught relatively easily on the job. Sure, there's a lot new in C++11. But it builds upon C++98/03 very nicely. If you don't know what a copy constructor is, when the compiler supplies it, or when you need to write one, that is my biggest worry. And that hasn't changed since C++98. If you don't know what a template is, or how to outline a template member function, or whether that code should go in a .cpp or a .h, I'm worried. That isn't C++11 material. If you've got C++98 down cold, but are unsure about move constructors, I'm not worried at all. But know the C++98 std::lib as well as the language. You should know how to work with C++98 containers, algorithms and iterators. It's like a building. If you've got a solid foundation, anything can be fixed. But fixing flaws in the foundation can be prohibitively expensive.
cppcon. These videos are great and official.
No seriously, how else are you going to get back into it aside from using it regularly
If you are good with "classic" "modern" cpp you are probably very well off as you are. See, synctactic sugar is easy to pick up and lack of it's knowledge probably won't fail your interview -- esp if you are open about it. So forget lambdas, range for, auto, final, override, and water. Ignorance about fundamentals, however, will fail you if you talking to folks like us. You need to know what is node-based and what is contiguous, what is a reference, what is inheritance, why overload operator -&gt;, and so on. Focus on your knowledge of more then cpp. Knowing other programming paradigms typically makes on e a better c++ dev.
Howard, I'm not currently interviewing, but your opinion on what is good and what isn't is valuable because you are a known expert. First, what is to "outline a template member function"? Second, overall. I find it absolutely acceptable to code with cppreference open on another monitor. I think it is ok to not remember the exact syntax of operator overloading outside of class (it is not ok to not find it in 5 minutes). What level of cpp do we expect for a senior dev whose primary responsibility is to code in cpp?
Don't forget Walter Brown.
Which book specifically?
I think your criticism of std::task is fair. It seems like std::task was designed for chaining coroutines together with zero overhead. But that has come at the cost of usability by non coroutine functions (at least not without some assistance from helper functions). In terms of names, std::task is pretty valuable real estate. So I'd prefer it to represent more of an all-rounder type. (More efficient than std::promise but still fairly easy to use). The proposed std::task type should still exist but IMHO should be renamrd to something like std::raw_task or std::co_task. 
Qt has the same issue with [QString and QString holder](https://github.com/KDE/clazy/blob/master/docs/checks/README-auto-unexpected-qstringbuilder.md). There are even clazy checks for this (clang based code checking tool).
What Lovecraftian nightmares are worse then SFINAE?
Companies need to learn how to advertise better. I'd have bought both of these books 7 months ago. Now that I've learned painstakingly the hard way from banging my head against a massive project and reading the "documentation" I don't need it anymore.
Can you expand on this a little bit?
I expected this to talk about the type-erasure of coroutines that is impossible to opt out of...
I think this is exaggerated. At other places auto is emphasised. Here it is bad. Suddenly. And cpprefetence is a strawman at best. As if other std APIs were always clear. Despite the efforts: We lived for decades with preconditions that were only documented. We survived. And I'd argue that preconditions are as important as the function types themselves. In this case future standards could easily fix that if there was a need and if fixing this was feasible. I would also say that you should talk to Gor directly instead of involving people (the community) who in most cases don't have the necessary insight. Yeah, this includes me. And if you talked already to him than mention it. Otherwise you make it personal by not being personal and using us just for an argument. The way to go? Say what you dislike and what you would propose instead. All of this could be done with less words. And guess what: It would be productive. 
/r/cpp is a very good place to stay up-to-date though, both book links as well as a handful of other great "modern" CMake blog posts/talks were posted here in the last year or so.
The rabbit hole of movable types.
You need Anthony Williams' book, "C++ concurrency in action". It really outlines everything one needs to know about the new std:: thread library, memory model, etc.
Bu that's OK, it's just a library feature which the compiler will be screaming about very obviously. I don't think I've seen code in the last 10 years that uses auto_ptr as anything more than a little RAII helper, certainly not passing it around outside functions and methods. Having said that, my biggest worry about the new stuff is not the feature set - it's the programmers who feel they have to use it all, not seeing the forest for the trees. There is still a lot to be said about clean APIs, and simple implementations. OOP is not dead, and neither is void*
I think he means "outline" as the opposite of inline. So converting: `template &lt;typename T&gt;` `class Demo {` `T get() { return t; }` `T t;` `};` into: `template &lt;typename T&gt;` `class Demo {` `T get();` `T t;` `}`; `template &lt;typename T&gt; T Demo&lt;T&gt;::get() { return t; }` I prefer the second version because I think the interface is more readable if it isn't mixed with implementation.
Be aware that different employers adopt new C++ features at different rates. Some of them are quite conservative. For example, my employer was quite slow to adopt lambdas, and still avoids "auto" where possible. I suspect we won't be touching structured bindings. We also have our own smart pointer types and our own string type. When you start a new job, you should probably look around and see how they actually write code, and fit in with that, rather than jump straight to the newest and greatest syntax. And most likely, the new C++ will be a small part of what you will need to learn to get to grips with a new codebase.
I agree with u/wasabichicken that you will figure it out when you get the job, but I would recommend watching (this short 5 video series)\[[https://youtu.be/zMrP8heIz3g](https://youtu.be/zMrP8heIz3g)\]. It gives you an overview on modern tooling to develop C++ which I appreciated very much.
Yes I've been there. Ease yourself in with the C++ features like unique_ptr/shared_ptr. Just try to avoid pointers in general. Know your RAII and perhaps read up on the GSL (https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md)
The latest video has just been posted. In this one, going to work out how to pass numbers by value from Lua to C++ using the RTTR library. It follows on from the previous video #23, so you should watch that first if you haven't already. [Embedding Lua in C #24 - Passing Parameters Using Run Time Type Information](https://www.youtube.com/attribution_link?a=OQ8QHGZXFIA&amp;u=%2Fwatch%3Fv%3DmehhfKiwNHM%26feature%3Dshare)
btw. don't follow the advice of people who tell you C++11 is not important. if you spend your time punching keys, you might as well do an excellent job. C++11 will help you to become a better programmer. Its advanced concepts allow for much better designs. Take for example the flexibility of composition that is enabled by lambda expressions. and after a small investment you will eventually become more productive.
- lexigraphical comparison is useful, but not trivial to write. - comparing sizes is easy with the `size()` method. - Comparing against minimum or maximum values would be weird for the comparison operator, but is easy to do explicitly. - there is a standard library algorithm to do a lexigraphical comparison if you'd rather use that. - removing it is not easy because it will break existing code. - honestly I'd expect, without thinking, for this operator to do a lexigraphical comparison, and don't see why you consider it nonsense. It makes sense when you consider how `operator==` works and no-one would want that changed. 
I ran into the second issue once, until then I didn't realize that inheritance would use the padding of the base to layout new members. I used to think that inheritance was just a more syntactically convenient way of composing, but it isn't that at all. Makes you wonder why you can implicitly convert objects into a reference of their base type, if their memory layout is different, even though the sizes match (in the last example sizeof(B) == sizeof(C)). To fix it you'd somehow need an unpadded_sizeof and make copy family of functions slower, or change how inheritance lays out its memory IMO. Unless I'm overseeing something.
Why wouldn't lexicographical compare be the obvious choice? If you compare two strings, they'll be compared lexicographically because it's what we do. So why wouldn't it be obvious to extend that to arbitrary arrays of any type, provided the elements can be compared? Lexicographical comparison is easy to understand, and it readily allows it to be used as keys in ordered sets and maps. It would be more confusing for strings to be lexicographically comparable and then vectors of chars not lexicographically compared, or not comparable at all. And if it makes sense for vectors of chars to be lexicographically compared, then why not just leave the definition as is for all vectors of any comparable type? Why should things be removed from the standard just because you personally don't understand it?
Doesn't `==` just compare element by element ? Also, I understand lexigraphical comparison may not be easy to write, but that's presumably why the algorithm exists. I'm not saying I don't understand the purpose of the algorithm in the standard library, but I don't understand why a default was chosen for the comparison operator (I'm not even saying it's a bad default, I'm saying it would make much more sense not to have a default to begin with).
&gt; , and it readily allows it to be used as keys in ordered sets and maps. Ah... this actually makes sense. Just to clarify, I'm not saying it should be removed, I'm asking "why is it there ?" is an inquiring manner (but from a critical standpoint, since inquiring is better done from that perspective). And I think your explanation here does actually make sense, as in, lexigraphical comparison does allow certain structures to work with containers as keys since they require the operator to exist and they require the lack of any collisions on values which are "equal"... so I guess it does make sense to have it as the default from that perspective.
Also, I think, there should be more attention to stuff like `sync_(a)wait()`. While we do have examples of `sync_wait()`, there is only small mentioning of `async` waiting for `std::task&lt;&gt;`. Quote from P1056: &gt; Another function could be a variant of std::async that launches execution of a task on a thread pool and returns a future representing the result of the computation. &gt; &gt; template &lt;typename T&gt; T async(task&lt;T&gt;); &gt; One would use this version of std::async if blocking behavior of sync_await is undesirable. For example, how do you integrate coroutines into existing code with something like message loop already in place ? As it was pointed blocking behavior of sync_await can be undesirable. We need async. wait for std::task. And mentioned `async` helper that works on a thread pool and returns future will also not fit all the cases. We need to have proper integration with executors ! But I'm not an expert and can propose proper wording (taking into account that current proposal for executors, IMHO, over engineered). As it was mentioned somewhere we have nice proposals but they interact with each other badly. 
Also, I think, there should be more attention to stuff like `sync_(a)wait()`. While we do have examples of `sync_wait()`, there is only small mentioning of `async` waiting for `std::task&lt;&gt;`. Quote from P1056: &gt; Another function could be a variant of std::async that launches execution of a task on a thread pool and returns a future representing the result of the computation. &gt; &gt; template &lt;typename T&gt; T async(task&lt;T&gt;); &gt; One would use this version of std::async if blocking behavior of sync_await is undesirable. For example, how do you integrate coroutines into existing code with something like message loop already in place ? As it was pointed blocking behavior of sync_await can be undesirable. We need async. wait for std::task. And mentioned `async` helper that works on a thread pool and returns future will also not fit all the cases. We need to have proper integration with executors ! But I'm not an expert and can propose proper wording (taking into account that current proposal for executors, IMHO, over engineered). As it was mentioned somewhere we have nice proposals but they interact with each other badly. 
It's also nice just to be able to sort things and find out that the library already supports it. Now if only they defined hash for container types...
I feel I have gone the opposite way. I spend more time programming C these days and all the extra features in C++11/14/17 etc seem more and more extraneous and arcane. 
Not sure what you mean, the memory layout of the base portion obviously stays the same when using inheritance
Maybe I used the wrong terminology, but basically what I meant was that in that example B is layed out like (simplified) &gt; [B's flieds][padding] whereas C casted to it's base is layed out as &gt; [B's fields][some of C's fields] Both have the same type B, but the second object can't safely overwrite it's padding portion on a copy, because of overlapping. I think one could argue that constitutes a differing memory layout, but that might not be technically true.
Yes i already read it halfway and find it to be the best reference on the subject. Do you know what new additions in his upcoming edition of the book this sept. 2018?
Lexicogrphic comparison is very useful. The only case when, lexicographically, a&lt;b and b&lt;a are both false, is if a==b. This makes it very suitable for arranging elements in a set or map, which you couldn't do with your other proposals.
Using variadic template parameter pack expansion to run an N(1)xN(2)x..N(i) compile-time composition via CRTP inheritance on a tuple of N types across i interdependent policies (i is a fixed size, fortunately, but N was up to the library consumer) without blowing out the compiler's memory - which meant I had to come up with a trick to get type erasure in the template to expansion (introduced a type that hid the expansions into one phase of the evaluation, and derived from that in the CRTP expansion) Using a combination of constexpr, type reference, and a moving "head" to do incrementing non-type template specialization of type-id based "type attributes" across all compilation units Using the address offsets of member function pointers as non-type template parameters in order to set up a static type dispatch that could be composed - once per process run - at runtime, allowing a schema to be loaded and "compiled" into functional type-variant "iterators" (visitor pattern based) for row-based operations on a columnar data store And, outside of the realm of templates: Code generation of an address offset based flow off operations based on the (bitmasked) value of the next byte to process (hyper-performant Unicode collation) Use of virtual memory pointer address value ranges as identifiers in order to perform zero-contention (and minimal kernel invocation) allocation for services that were optimized with NUMA-node bound execution fibers - the memory was always returned against the heap cache of the core it was allocated on, with zero cache or pipeline synchronization
Lexicographical comparison also compares element by element. I'm not sure where you're going with that.
&gt; but composing is sadly a little bit less convenient. [Citation_needed] :p
This is the difference between a junior/intermediate developer and a good senior developer. Hiding the mess of complication behind something simple, as opposed to hiding something simple behind a complicated mess.
but it gives you an elegant way to diagnose the problem with that lambda. :) why exactly is it not possible to set (beg) to (end) of the previous range while splitting the string? you say (beg) iterates through the whole sequence of characters and at a point where a split is possible, (end) is searched for. does not seem like it would be necessary.
min/max as a basis for comparison is mathematically weaker than lexicographical. Lexicographical is the strongest possible ordering (a total order). Both lexicographical and min/max have obvious properties like transitivity, but lexicographical also has: if it's not the case that a &lt; b, and it's also not the case that b &lt; a, then b and a are the same element (or equivalently, either b &lt;= a, or a &lt;= b). This has real implications. For example, max/min ordering is still strict weak, so you can do a binary search on it. But you could have an entire array of "ties" not equivalent to the searched for element, reducing your binary search to a linear search. In a total order this can't happen.
This actually isn't correct. Putting elements in a set/map only requires a strict weak ordering. What you've described is a total ordering. It's not necessary for a==b to be implied, in this example a and b are simply incomparable. I'm pretty sure that ordering vectors by their maximum element is actually a strict a weak ordering and you could therefore put them in a set with it, it's just not nearly as good (see my other comment).
min/max as a basis for comparison is mathematically weaker than lexicographical. Lexicographical is the strongest possible ordering (a total order). Both lexicographical and min/max have obvious properties like transitivity, but lexicographical also has: if it's not the case that a &lt; b, and it's also not the case that b &lt; a, then b and a are the same element (or equivalently, either b &lt;= a, or a &lt;= b, or both). This has real implications. For example, max/min ordering is still strict weak, so you can do a binary search on it. But you could have an entire array of "ties" not equivalent to the searched for element, reducing your binary search to a linear search. In a total order this can't happen. Also, min/max is actually much slower than lexicographical. min/max is definitely O(N) in the size of the vector. Lexicographical depends on the distribution of your input data but generally speaking for anything semi reasonable it will be constant.
Ah you mean for copying *into* a subobject. Yeah you can't do that.
In addition, lexicographical ordering only requires \`operator&lt;\` on the elements, i.e. a bag of comparable things becomes comparable. How would you get the maximum or mean or sum of some \`ReactorType\`s or \`CityCouncilMeeting\`s be?
Ironically, iterators are incredibly well-suited for lazy evaluation. This might be a problem in the API or algo, not the fault of iterators.
I disagree. Iterators in C++ separate access and iteration between \`operator\*\` and \`operator++\`, which makes the kind of duplication of work described above difficult to avoid when you have iterators pointing to things are supposed to be lazily evaluated as well.
Ah. Ok. To me, both versions are good, but I will reach ourt to cppreference for exact syntax for second's implementation.
Paper author here. My philosophy to solve any problem is to first understand the problem as fully as possible, then try to determine the ideal solution to that problem, then figure out how to get there from where we are. I feel like many people do this backward: they start from where they are and try to figure out how to fix it, rather than beginning with the end in mind. I also try to think about what things conceptually are first, then let that guide the details of how it should work. Conceptually, my proposal is for functions with parameters that you can use at compile time. In a world without templates, if I were to propose this feature, no one would say that the current behavior is a design that we want (at a conceptual level). Right now, function templates behave differently from regular functions, and this is a real problem. Consider the concepts proposal. You brought this up as your last example, but to clarify for anyone who hasn't followed it as closely as you have, the main point of contention on concepts recently is a particular syntax known as the "terse", "natural" or "short" syntax. Assuming `Container` is a concept, it is the syntax that would let you write: void sort(Container container); The primary objection to this syntax is that if `Container` is a concept, then we have a function template named `sort`, but if it `Container` is a type, we have a regular function. Some people see this as a bad thing because functions and function templates behave differently. At many companies, "templates" are seen as this weird part of C++ that should probably be avoided unless you really need them, and there is definitely no "meta-programming". I believe that this for two primary reasons: it has "weird" syntax and it does something subtly different from regular functions. If we could give users a feature where the mental model could be "This is a regular function, but these parameters must be compile-time constants", that would be a huge boon for teachability. In my paper, when I talk about being against the "secretly a template" model, I am saying I am against that as the mental model for the feature. The conceptual basis I am going for is "function". All that being said, I presented an updated version of the paper to the committee. You can see a (poorly formatted) version that is substantially the same as what I presented here: https://github.com/davidstone/isocpp/blob/master/constexpr-parameters.md . In particular, I think you will be interested in the section titled "Function static variables". The key line in that new section is "Unfortunately, the rules for templates are the way they are for a reason. There are many examples that, without further work on the topic, seem to suggest that the template model is the only reasonable model". In particular, the only way to make the mental model of "just like a function" work for all cases is to ban all static variables and locally-defined types. This did not sound too onerous to me at first until I realized this also means banning lambdas, which is much too limiting. In short, I always knew this feature would have to be implemented in essentially the same way as a template. My goal was that we could modify a few rules to keep the "function" mental model (which I suspect users have when writing function templates, anyway), but that proved to be either unworkable or too limiting. There is no way that I can think of to keep the abstraction solid. Given this, the mental model of my feature has to be whatever mental model the user has for templates. Now I just have to figure out constexpr references...
This particular case can be fixed by having the split view and the word keep pointers to each other and caching end of the word iterator in split view object. Not sure how to handle a case with multiple references though: auto split = "these are some words"sv | view::split(' '); auto first = *split.begin(); auto second = *split.begin(); distance(first); I don't know much about Java's streams - how do they solve this?
I mentioned this in my longer answer directly to the OP, but the short answer for this is that you do implement it as a template. The confusion arose because my paper was initially (but not any more) arguing against the conceptual basis or the mental model of "template". The fact that the implementation in the compiler would share a lot of the same code (which is true) is a separate issue. The make the example more concrete, consider `optional&lt;T&gt;` and `static_vector&lt;T, 1&gt;`. You could theoretically implement `optional&lt;T&gt;` in terms of `static_vector&lt;T, 1&gt;`. Some people argue strongly that you should be able to treat `optional&lt;T&gt;` as a range of 0 or 1 `T`, just like `static_vector&lt;T, 1&gt;`. Other people argue strongly that the one true mental model for `optional&lt;T&gt;` is `variant&lt;T, none_t&gt;` (that is to say, either `T` or nothing). They are not arguing over how it is implemented, but how we should think about it. How we should think about it determines the interface on the type (should `optional` have `begin` and `end`?).
Can you elaborate? I do not see a problem with that (Also don't really understand what it is trying to archive). However, i am not really that good at c++, and would like to improve.
They combine access and iteration into a single `next()` method and by having each iterator in a chain of streams keep a reference to the previous iterator, essentially as you suggested. The problem of multiple references is avoided because there is no corresponding `begin()` method. Plenty of languages do this incidentally, I named Java because I thought it would be more familiar.
The first one is pretty easy to understand but I don't understand what the second one is doing. 
It just modifies `input` to increment a counter (passed by reference in the lambda capture) every time a character is read.
&gt;My goal was that we could modify a few rules to keep the "function" mental model This is a great goal, but I think it is completely out of scope of this proposal. Maybe you should write a new proposal that fix function template behavior in regards to static variables and local types. If you want to fix that, why only fix it when it's a template that happen to receive constexpr parameters? This bifurcation of behavior will only make thing more complicated for the user, remembering that any temploid function work that same way, except when there's a constexpr parameter? I agree we must think about the user, but there's one more important things for the user above all else and it's constancy. We already have many things that are implemented using template, or don't have the template keyword nearby but behave like a template. For example, a member function of a nested class. If the enclosing class is a template, then the member function is a temploid, even if the template keyword is far away. We have generic lambdas, that don't have the template keyword but behave like a template too. There is a a good chance we will get the merged terse syntax in C++20. auto func(Concept auto p) -&gt; Concept2 {} This is another template-like thing without the template keyword. At that point, there is little going back, there are too many things that behave like templates. If constexpr want to be consistent with the rest of the language, it must introduce a template. This constancy will make teaching better, and will play better with the rest of the language. &gt; My philosophy to solve any problem is to first understand the problem as fully as possible, then try to determine the ideal solution to that problem, then figure out how to get there from where we are. The ideal solution is quite hard to achieve when there's 30ys + of legacy. The solution should be the simplest one that fit the better with everything else. Another exception in the language is not that simple, for implemeters and users. &gt;At many companies, "templates" are seen as this weird part of C++ that should probably be avoided unless you really need them That's unfortunate. The direction of the C++ community is really headed towards generic programming, concept oriented, and friendly towards templates. The merged proposal for concept terse syntax really will make templates and generic programming more accessible to many more users. Maybe you should review your policies in C++20? ;) --- Overall thanks for the response. I understand why it was proposed like that in the beginning. I also know many programmer that are afraid of templates, and many refusing to use them. I hope your proposal get accepted, because even if it is implemented as a template, this will make non-type template parameter something understandable by common programmers, and more useable in general, and I'm pretty sure many that are afraid of templates will be okay to use constexpr parameters + concept terse syntax. I too cannot stand passing parameters through `&lt;&gt;` ;)
What actually calls the lambda and who passes the counter in? Is it transform? I don't think this is very readable without requiring prior knowledge. If we have to write code like this after ranges, I'm not going to be very happy and I don't think people reading my code are going to be happy.
You can't put a value in a tree data structure unless it supports comparison. Prior to C++11, there was only a tree-based set or map type, so to have a set of (immutable) vectors you need them to have some comparison function.
All of this really depends on how you want your bias to work. What should the distribution be if there is no bias ? What should the distribution be if there is a bias ?
I disagree. I had that paper in mind when writing this paper. Class types as non-type template parameters was an important feature to me because I felt it laid the groundwork for constexpr parameters. Supporting class types as non-type template parameters was the primary reason I also proposed [P0432](http://open-std.org/JTC1/SC22/WG21/docs/papers/2016/p0432r0.html) because I was trying to find a way forward to `bool operator==(T, T) = default`. When we got `operator&lt;=&gt;`, I was excited about that and helped work on it in large part because it gets us to where we are now. So believe me, I am with you on P0732 being a nice solution. That being said, it is only part of a solution. It does not solve any of the problems I laid out in the "Before and After" table at the start of [P1045](https://github.com/davidstone/isocpp/blob/master/constexpr-parameters.md). The status quo even with P0732 means we are in a weird place where `std::strlen` is not constexpr, but `std::char_traits&lt;char&gt;::length` is. Fortunately, the implementors of `std::char_traits&lt;char&gt;::length` thought of this problem and knew some compiler internals, so they were able to use a less convenient version of the feature that I propose standardizing (in the case of gcc's standard library, they check `if (__constant_string_p(__s))` and use a `constexpr`-friendly version if it is, otherwise they call `std::strlen`, whereas with clang's standard library they unconditionally call `__builtin_strlen`, which is a compiler intrinsic that is used only in the implementation of `char_traits&lt;char&gt;::length` and it internally just does the `is_constexpr` magic inside. If the standard library implementors hadn't used these special implementation-defined functions, it would mean that constructing `std::string` is slower than it should be, unless your compiler happens to notice that it can optimize it (and it doesn't always). I want to give this power to all users in a standard-conforming way.
Thanks for the quick reply. &gt; What should the distribution be if there is no bias ? I was thinking a value of 1 could represent an equal chance for any number being randomly returned between the min and max value provided. &gt; What should the distribution be if there is a bias ? I was thinking a number larger than 1 would produce an exponential bias. So for example, using a number of 2 would mean there is a x^2 higher chance of returning the min value instead of the max (and a smooth curve between the min and max). Hopefully that makes sense, I'll try and re-word if this isn't clear.
it's a straightforward composition of a function and a lambda. transform calls a function on each member of a sequence and the result sequence is made up of the elements that the function returns. of course you have to no that prior. The counter is a lambda capture. Transform does not know anything about it. Anyway, this line is not difficult, you should be able to parse this.
Could the `operator*` cache the information needed for `operator++`, so that it doesn't have to do another read?
`std::set` and other data structures assume equivalence if `!(a&lt;b) &amp;&amp; !(b&lt;a)`, so if you use a set with weak ordering, inserting one element may remove a totally different element. Typically not what you want.
It's obviously not the common case but it is a fully valid use case. Which std::set method would silently remove an existing element? Also, it should be clear from the fact that set and map don't use equals at all, that their constraint of one equivalent key is totally artificial. In general I agree it's more typical to use these with total orderings, and use multimap and multiset for strict weak orderings.
Views are lazy, so with split actual work is done after `operator*` - in `distance` call. For caching you would need to keep a pointer to split iterator in word iterator and update it if something goes out of scope. So it can be done, but now that I think about this, it would be much better to add that value returning `next` function as customization point to iterators and make range-based for use it.
One easy formula to produce that result would be `biased_rand(0, 1, bias) = uniform_rand(0, 1) ** bias`. Taking the nth power of a number between 0 and 1 shifts everything closer to 0. And taking the nth root would shift everything closer to 1.
Would it be possible to share a code example? I'm assuming it would require std::uniform_real_distribution?
This isn't a fundamental problem with iterators. You don't need to do anything to construct end iterator at all, it can just be some kind of default sentinel value (default constructing an iterator to the end value already shows up in the STL). When you keep calling ++ on the begin iterator, when you run out of data it just sets itself equal to the sentinel value. ++ also does the work constructing the next element and caches it in a piece of storage (which is obviously reused), so that * is also trivial and does nothing but return a reference into that storage. Obviously this is clumsy because the end iterator a) carries no information, and b) has a pointless piece of storage. But this (I assume) is one of the reasons why Eric Niebler was interested in the idea of heterogeneous iterators, i.e. types of begin and end should be able to be different (since you can obviously == between different types there's no reason why they should be the same type in the most general case). I assume that if ranges were standardized, things would be added to help solve these issues. I agree a standardization of ranges where your example requires two passes would suck.To be really honest I don't care that much about ranges anyhow though so I'm not holding my breath either way. There are much bigger fish to fry in C++. Making for loops more elegant looks great in reddit pages but isn't that important in writing real life software compared to the other major things being worked on (concepts, modules, reflection, to name a few. Heck I'd even take better sum types and pattern matching over ranges).
but this algorithm can't be done with java streams?
Having boost::hash_combine (simple fibonacci hashing) in the STL would be a start...
So you're saying giving LESS flexibility (by merging 2 features together) actually ENABLES more optimisation opportunities?
I shouldn't have, but I did.
I thought of Scott, but at least in my opinion, he's not exactly a pioneer. He did a great job of teaching, but I'd think of him more as a guy who followed the tracks of the real pioneers, and drew a great map of where they'd gone. What he did was important, but not (in my mind) particularly pioneering.
std::mt19937 rng(seed) std::uniform_real_distribution&lt;float&gt; dist; float value = std::pow(dist(rng), bias);
Should be able to parse is a must more mundane sounding statement than the reality which is that you "should be able to parse if you have a fair amount of knowledge that is in no way obvious or natural and that relies on multiple levels of prior knowledge that are also not obvious or natural." 
https://www.reactiongifs.us/wp-content/uploads/2013/05/live_on_this_planet_futurama.gif
I feel several of these examples are incredibly expressive and easy to read. if one doesn't trust the implementation they might want to go and read it, but it does exactly what it says it does allows comparisons against "all of" or "any of".
Hah, thanks :) So, how do I use my min and max range values with this example?
Please, don't overload `operator ==` with something that is not an equivalence relation (i.e. it's not a reflexive, symmetric and transitive relation).
I would so much prefer if coroutines were just function objects that you can suspend and resume...
the actual construction of the distribution takes the bounds - 0 and 1 are simply their defaults. So std::uniform_real_distribution&lt;float&gt; dist(a,b); would result in values in [a,b) ( i.e. b itself will never be picked).
Equality on floating-point numbers isn't reflexive, so I humbly suggest that you consider partial equivalence relations instead.
Very helpful, thanks! This looks like it will do what I need. Before you replied, I noticed the highest roll I could get (with the default 0,1) was 0.999~. How do I get the upper bound included so [a,b]? Probably a common question. Thanks!
Yeah, the amount of magic members in and around `promise_type` is... concerning. Why do we even need `initial_suspend` in the definition of the return type, when we can just write `co_await always-suspend` in the body? By the way, is `operator co_await`allowed to be a coroutine?
Also a very tricky question. If you find out tell me :)
Ahah, ok - thanks, I'll keep looking :)
&gt; a fair amount of knowledge that is in no way obvious or natural welcome to the world of computer programming, friend. i guess you have got to get a few thousand kilometers more mileage. the pain you feel right now should not discourage you. just keep looking at the letters while you experience it and the neural pathways will eventually form. concentrate on the information in front of you, not on your inner turmoil. if you look long enough it will become natural. but your nature is just deficient, the complexity of the world is innocent. it just is. lucky for you, you need to learn only 2 handfuls of basic rules to parse a whole lot of complexity. guess what you can do with just transform and lambdas. The ways you can combine these 2 are infinite. The way the combination works is always the same.
Why?
You can't co_await always-suspend in the body without starting the body. Initial_suspend can avoid starting the body at all.
We don't have executors yet! folly::coro has executor-aware coroutines, though, along with various different wait operators.
Replacing something that's perfectly readable and perfectly effective with a bunch of postmodern C++ gobbledygook makes baby George Boole cry.
I'm playing around with some code and getting some huge numbers that I believe to be from the `std::pow` function you shared with as soon as my range is anything bigger than 0 to 1 (the default for the distribution as you showed me). What might I being doing wrong? Here's some code I'm playing around with ` int rolls = 1000; //how many times we will roll a random number float highestRoll = 0; //highest overall roll we get float lowestRoll = 100; //lowest overall roll we get int overCount = 0; //track time's were over a certain number float overTarget = 0.99; //that certain number we want to keep an eye on int bias = 5; //adjust odds float min = 10; //min range float max = 100; //max range int seed = std::chrono::system_clock::now().time_since_epoch().count(); std::mt19937 rng(seed); std::uniform_real_distribution&lt;float&gt; dist(min,max); //shuffle up and deal! for (int i = 0; i &lt; rolls; i++) { float value = std::pow(dist(rng), bias); //track highest if (value &gt; highestRoll) highestRoll = value; //track lowest if (value &lt; lowestRoll) lowestRoll = value; //count number of times a value appears over something if (value &gt; overTarget) overCount++; std::cout &lt;&lt; value &lt;&lt; std::endl; } std::cout &lt;&lt; "---------------------" &lt;&lt; std::endl; std::cout &lt;&lt; rolls &lt;&lt; " rolls between " &lt;&lt; min &lt;&lt; " and " &lt;&lt; max &lt;&lt; std::endl; std::cout &lt;&lt; "Highest roll: " &lt;&lt; highestRoll &lt;&lt; std::endl; std::cout &lt;&lt; "Lowest roll: " &lt;&lt; lowestRoll &lt;&lt; std::endl; std::cout &lt;&lt; "Over " &lt;&lt; overTarget &lt;&lt; " count: " &lt;&lt; overCount &lt;&lt; std::endl;`
The pow only works with numbers &lt;1 as was mentioned
&gt; ( i.e. b itself will never be picked) It may not matter, but that's not true of current implementations. Because of rounding issues current implementations can produce the upper-bound. Here are some relevant links: https://stackoverflow.com/q/25668600/365496 https://bugs.llvm.org/show_bug.cgi?id=18767 https://www.reddit.com/r/cpp/comments/2nelxa/did_i_find_a_gclangc11_bug/?st=jjlzxd2p&amp;sh=cf883ab5 
Oops/sorry, thanks!
I agree. Sum types and pattern matching are big for me, as is the proposal for lightweight static-cost exceptions.
This isn't a problem though. Sample in [0,1), then do value = std::pow(value, bias) * (b-a) + a;
Looks like I've got some reading to do, I'll check this out - thanks.
Hmm, using my example above, would it look like the following: float value = std::pow(dist(rng), bias) * (max-min) + min; I'm guessing I'm misunderstanding b/c you're showing value already declared/getting passed into pow?
Python's `if x in (a, b, c)` is pretty ideal for this.
I think this is more readable and slightly more maintainable than repeating the same item over and over. It also avoids the need for an extra variable if you're comparing against a temporary if (f(x) == any_of{a, b, c}) ... vs. if (auto temp = f(x); temp == a || temp == b || temp || c) ...
That's true, but I don't think it's an example that people should be following. It's one of the things that makes writing code that deals with floating point numbers harder than it has to be.
I think all this does is turn a small amount of irritation into hidden complexity. 
The fact that floating points aren't reflexive is a huge problem and only exists due to practical considerations at the time of their introduction. Basically the reason is at the time floating point operations were very expensive and lacked hardware support, so a decision had to be made about how to actually implement a function like IsNaN. The two options at the time were `!((x &lt; x) &amp;&amp; (x &gt; x))` or `(x != x)`. The former approach was considered too expensive and impractical, so the decision was made to go with `x != x =&gt; IsNaN(x)`. If floating point numbers could be redefined today, the consensus is that (NaN == NaN) == true. You can read over Stack Overflow answers where this question comes up and various members of the IEEE committee weigh in on the issue. Basically, we shouldn't take our guidance about defining equality based on floating points and /u/svick advice is correct, equality should preserve the basic and expected properties. There is no practical reason to even overload `==` in this case. A simple `is_any(x, {1, 2, 3})` is perfectly legible and doesn't violate any axioms.
tl;nr It. Needs. To. Die. 
Preferred is usually `if x in {a, b, c}`; expresses intent more clearly (a set is something that exists to express membership, tuples and lists are primarily about other things), faster more items, can easily combine two sets prior to checking membership, etc. 
Given that you initialized the uniform distribution with 0 and 1 (or no parameters since that's the same) both versions should work.
I'll just throw out Steve Dewhurst -- he goes back to the Stroustrup / Bell Labs days, he's spoken at a ton of conferences (not as much lately), he's scary smart, he's written at least one book on C++ (if not 2, can't recall) and he understands the constraints of embedded systems, which is a topic close to my heart. Just my 2 cents.
It's not usable because `GraphicsSurfaces` is in a non-deduced context.
oh yeah, I forgot about set literals.
wow, thanks for the thorough list!
Just had a dumb moment: I was still passing in my min/max variables to `dist()` by mistake but didn't catch it. Thanks for your patience with me :) Looks like this will do what I need. I will play around a bit and do some more reading with the info/links in this post / I may follow-up with another question if that's OK. Thanks again.
&gt; should be able to parse if you have a fair amount of knowledge that is in no way obvious or natural and that relies on multiple levels of prior knowledge that are also not obvious or natura But the context of this post is about ranges, which in no way effect code you had questions about. For example current C++ without ranges: auto count = 0; auto input = std::vector&lt;int&gt;{1,2,3,4}; std::transform(std::begin(input), std::end(input), [&amp;count](auto val) { return val*val; }) The proposal for ranges is to turn that into (something like): auto count = 0; auto input = std::vector&lt;int&gt;{1,2,3,4}; std::transform(input, [&amp;count](auto val) { return val*val; })
Why someone would want to avoid starting the body at all if that body just suspends anyway?
The body is a scope, things run at the start of that scope. If you are trying to construct infrastructure around this it is safer to know that the coroutine is completely lazily run, than that it might do something at the start. You may also want to control on what executor any user code in the target coroutine runs, which is best achieved by not having any user code run at all until you set that state and co\_await it.
The problem is not with end iterator but with separation of `operator*` and `operator++`: when `distance` is called by `transform` on the result of split's `operator*` it needs to iterate until next delimiter. Then `transform` calls split's `operator++` and it needs to iterate until next delimiter again. It can be solved by introducing combined "dereference and increment" function. I guess it could as well be postfix `operator++`, but then ranges and range-based for loop would need to use it.
The problem is not with end iterator but with separation of operator* and operator++: when distance is called by transform on the result of split's operator* it needs to iterate until next delimiter. Then transform calls split's operator++ and it needs to iterate until next delimiter again. It can be solved by introducing combined "dereference and increment" function. I guess it could as well be postfix operator++, but then ranges and range-based for loop would need to use it.
Not entirely related to your question, but how often do you practice? It's great that you're looking for books to read but you should make sure to reserve enough practice time so that your newly acquired knowledge doesn't go to waste in 2 weeks. I find that it makes books much easier to read in general. I also think a good motivator would be a side project that would be helpful to you in some ways. Mine was a game server emulator (I wouldn't recommend it though... not only do you have to understand the language as it is written but you also have to understand C++ constructs in assembly) and it really got me into the language. Don't worry too much about ending up with something messy, you are learning and you will end up refactoring your code again and again as you grasp new concepts. 
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8yyrrq/sams_teach_yourself_c_in_one_hour_a_day/e2ey66e/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8yuvwc/question_about_random_and_perhaps_exponential/e2ey6rr/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/8yrsdx/pockettensor_run_keras_models_from_a_c/e2ey8nm/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Right, always forget, that you construct a coroutine frame by calling... Ok, then... why would someone want to _not_ avoid starting the body when calling coroutine? As I understand it, you just neeв to call `resume` to have the same behavior? Can't you do it in your task's constructor instead of specifying it indirectly by `initial_suspend`? I'm sorry for questioning what I suspect to be basic and probably already discussed elements of coroutin design - is there some paper with with argumentation for current interface and considered alternatives? Because now I pretty much agree with [p0973](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0973r0.pdf) - it should be possible to express control flow with control flow.
Is buying a book on CMake worth it ? I think one can pick up most practically useful features from docs, StackOverflow and from other projects that use CMake.
I would say that NaNs are not the only (or even the main) issue regarding reflexivity or transitivity of floating points. For example in 64 bits we have `0.1+0.1+0.1 != 0.3`. You may say that technically it's not a violation of reflexivity as this is a comparison of two different bit-patterns, but - 1. The floating points are an (approximate) representation of the real-numbers , and this is a comparison of a real-number with itself. 2. A similar technical excuse can be made for NaN: it does not have a unique representation, and when you're bothered by x != y when both are NaNs, it is because you think of both as representatives for the same thing (so you don't care about specific bit-patterns). If anything, NaNs are well-behaved compared to normal numbers, since NaNs form an equivalence-class of floating points (this is why in principle we could redefine comparison to be reflexive for NaNs), while there is no equivalence-relations of floating points whose equivalence-classes can be associated consistently with real-numbers.
I get a feeling that as C++ gets more powerful with new features it becomes more and more unmaintainable.
There's also this: auto count = 0; for (auto x : {1, 2, 3, 4}) count += x * x; I find this much clearer and much more readable than any of the algorithm-based solutions elsewhere in this thread, ranges or not. 
Every instance I've used composition ends up with large amounts of copy-paste. That might just be due to almost all of my work being in game dev though.
&gt;This is a type that wraps a T … but has no interfaces that mention that T. … The only way for a user to know that co\_await yields a T is to see it in use, or read the comments. The user-facing API for coroutine types like this do not actually show you what you expect to see. I do not understand this, if I see `std::task&lt;int&gt; getCounter();` it is quite obvious what it means, co\_await and get an int. 
I think that `is{x}.any_of(a, b, c)` is quite elegant to start with. However, what I really like about `x == any_of(a, b, c)`, `x &gt; any_of(a, b, c)`, ... is that it avoids having to *name* all those operations. For better or worse `less_than` is always slightly ambiguous (is it strictly less than, or less than or equal?) whereas `&lt;` and `&lt;=` are unambiguous and well known.
What annoys me is the need to type `using namespace std::placeholders` every time I need to use `std::bind()`. Because of this, it's cleaner and faster to type lambda. Compare to the example in the article: auto fprint = [&amp;](page_size size, page_margins margins) { print("Printer", page_layout::portrait, size, 1, margins, 300, 1.0); }; fprint(page_size::Letter, page_margins::maximum); fprint(page_size::A3, page_margins::minimum); Now you see the signature of the function. With `std::bind()` version, you need to go and look-up the original function together with the usage context to understand what `_1` and `_2` means. Lambda is much cleaner almost always. It also supports move-only capture. Another note is about `std::for_each()` usage: isn't range-based for loop much nicer ?: std::vector&lt;std::string&gt; printers{ "Printer", "Default printer", "PDF printer" }; for (const std::string&amp; printer : printers) { print(printer, page_layout::portrait, page_size::A4, 1, page_margins::standard, 600, 1.0); } Btw, the same problem we have with UDL: so cool concept, but usage is almost always too noisy: using namespace std::string_literals; std::string str = "abc"s; You need to type `using namespace std::chrono_literals` when you simply want to use `duration = 2d` once. Sorry about rant :(
&gt;That said, if this is the style of specification and user-facing API for coroutine types, I have concerns. The user-facing APIs produced using this machinery are nonsensical and impossible to understand with normal patterns (like “reading the API”) - all of their details are literally hidden in the coroutine customization machinery. It’s technically correct and functional, of course, but something smells wrong. For me personally, it does not smell wrong. The customization machinery is complex and overwhelming when first exposed to it, but this allows to have very nice library abstractions, like the mentioned [cppcoro](https://github.com/lewissbaker/cppcoro), and also providing full power to write your own awaitable types, like demostrated by Gor in [Naked coroutines live (with networking)](https://www.youtube.com/watch?v=UL3TtTgt3oU). These awaitable types do not have to be private in a function returning auto, as demostrated in the 'naked coroutines' talk, but have a descriptive name, ex with an Awaitable suffix. So having in an API functions returning something like std/cppcoro::task or ReadAwaitable, looks good to me.
Ok, this is gross. Stop over engineering everything. First expression was much cleaner.
This is just a really obscured "find" algorithm. Now the idiomatic way is not really pretty either, so how about this as an alternative: template &lt;typename T&gt; inline bool contains(std::initializer_list&lt;T&gt; lhs, T rhs) { return std::find(lhs.begin(), lhs.end(), rhs) != lhs.end(); } Sure, it does not have infix notation, but I think it is pretty expressive and simple.
Lmao this dude and his pumpkins
Your overloaded operators should require rvalues; both because when not on one line the semantics are broken, and because an efficient any/all of doesn't do proper reference lifetime extension.
Just using std literals somewhere; the literals inline namespace is clean and only uses reserved identifiers.
Doesn't the lambda approach also allow inlining so should be more performant?
in C++ if the function is an inline one, the compiler will change all calls by the body of that function. a friend function, is a function that can access all class members whatever is the access specifier defined of them.
There are several things the author does not understand or is incorrect about. **1. The standard allows user specialization of `pointer_traits` and `iterator_traits`.** The C++ standard does not forbid it. Users already specialize these today. `iterator_traits` was always intended as a customization point for users. The reason the C++ standards committee preferred R1 and R2 of P0653 over R0 _because_ users already specialize `pointer_traits`. Most of the post is predicated on this incorrect understanding that the specialization of traits is forbidden: &gt; The user is not permitted to specialize `allocator_traits` No. The standard does not prevent the user from specializing `allocator_traits`. &gt; with a rationale that explicitly caters to users who do what they’re not supposed to do No. There is no "not supposed to do". The standard allows specializing traits. Users do. &gt; "User specializations of pointer_traits" are exactly what we just said should never happen No. The standard never said this should never happen. &gt; So right now in the C++2a working draft, we’ve got a contradiction: the user both is and isn’t supposed to specialize `pointer_traits`. No. The user _can_ specialize `pointer_traits` and could since C++11. Since C++2a there is just an additional customization point in `pointer_traits`. **2. Users do not _need_ to specialize `pointer_traits` for `to_address`** For most users, `std::to_address(p)` already covers their needs, out of the box. i.e. It will call `to_address(p.operator-&gt;())` for a fancy pointer, and return `p` for a raw pointer. Users designing any fancy pointer type `P` will just provide `P::operator-&gt;()`. For the rare case where a user wants to _customize_ the behavior of `std::to_address` for some fancy pointer type, they can do so by specializing `pointer_traits`. &gt; But who is supposed to make that member exist? Nobody has to make the member exist, because it is an _optional_ customization point. It is even specified in the current C++ standard working paper as section [ptr.traits.optmem] "Pointer traits optional members". **3. Others** &gt; For example, `pointer_traits&lt;P&gt;::pointer_to(T&amp; r)` calls `P::pointer_to(r)` if that member exists; but otherwise it will sensibly default to SFINAEing away. This has never been the case with any vendor's implementation (libc++, libstdc++, Boost). For example: ```cpp #include &lt;memory&gt; #include &lt;type_traits&gt; template&lt;class, class = void&gt; struct has_pointer_to : std::false_type { }; template&lt;class P&gt; struct has_pointer_to&lt;P, std::void_t&lt;decltype(std::pointer_traits&lt;P&gt;::pointer_to(std::declval&lt;typename P::element_type&amp;&gt;()))&gt;&gt; : std::true_type { }; template&lt;class T&gt; struct pointer { typedef T element_type; }; static_assert(!has_pointer_to&lt;pointer&lt;int&gt;&gt;::value); ``` The above asserts.
thanks 
Well, #define RETURNS(...) \ noexcept(noexcept(__VA_ARGS__)) \ -&gt; decltype(__VA_ARGS__) \ { return __VA_ARGS__; } now we can make easy SFINAE enabled lambdas. [](auto&amp;&amp; x)RETURNS( x+7 ) then write test_invoke: template&lt;class F&gt; auto test_invoke(F&amp;&amp;f){ return [](auto&amp;&amp;..args){ return can_invoke&lt; F&amp;&amp;, decltype(args)... &gt;{}; }; } where `can_invoke&lt;F, Args...&gt;` tests if you can invoke F on Args. namespace details { template&lt;template&lt;class...&gt;class Z, class, class...&gt; struct can_apply:std::false_type{}; template&lt;template&lt;class...&gt;class Z, class...Ts&gt; struct can_apply&lt;Z, std::void_t&lt;Z&lt;Ts...&gt;&gt;, Ts...&gt;:std::true_type{}; } template&lt;template&lt;class...&gt;class Z, class...Ts&gt; using can_apply=details::can_apply&lt;Z,void,Ts...&gt;; template&lt;class F&gt; struct invoker{ template&lt;class...Args&gt; using result=decltype( std::declval&lt;F&amp;&amp;&gt;()(std::declval&lt;Args&gt;()...) ); }; template&lt;class F, class...Ts&gt; using can_invoke=can_apply&lt;invoker&lt;F&gt;::template result, Ts...&gt;; --- Ok now the payoff: static_assert( !invoke_test( [](auto&amp;&amp;x)RETURNS(x+7) )( "hello"s ) ); Asserts I cannot add `7` to `"hello"s`. 
Arthur is this accurate?
After reading Titus' blog post [1] I am now certain that 2D graphics does not belong in the standard library. In fact I am even questioning whether or not my HTTP and WebSocket protocol library needs to be in the standard either. What we need is to eliminate any friction that users may encounter when attempting to add a dependency to their project. In other words, we just need a great universal package manager to be part of the specification of C++ or its ecosystem. 2D Graphics would make a great package; a standard library component, not so much. [1] https://abseil.io/blog/20180227-what-should-go-stdlib
The code font is completely unreadable on my pc. Tha being said &gt; sometimes the brevity aligns with simplicity, but more often than not they are very different. unfortunately I have to agree there.
what this post is for ? showing the definition of inline and Friend functions or what ? Coz it ain't a good one. we can't see inline keyword for example. inline functions is related to member functions too (inside/outside the class scope). what are looking for ?
Please check out [the Reddit formatting guide](https://www.reddit.com/wiki/commenting).
i edit the post u again see it and its is just simple intro about friend and inline function. 
yes man thanks for suggestion 
There are several things the author does not understand or is incorrect about. **1. The standard allows user specialization of `pointer_traits` and `iterator_traits`.** The C++ standard does not forbid it. Users already specialize these today. `iterator_traits` was always intended as a customization point for users. The reason the C++ standards committee preferred R1 and R2 of P0653 over R0 because users already specialize `pointer_traits`. Most of the post is predicated on this incorrect understanding that the specialization of traits is forbidden: &gt; The user is not permitted to specialize allocator_traits No. The standard does not prevent the user from specializing `allocator_traits`. &gt; with a rationale that explicitly caters to users who do what they’re not supposed to do No. There is no "not supposed to do". The standard allows specializing traits. Users do. &gt; "User specializations of pointer_traits" are exactly what we just said should never happen No. The standard never said this should never happen. &gt; So right now in the C++2a working draft, we’ve got a contradiction: the user both is and isn’t supposed to specialize pointer_traits. No. The user can specialize `pointer_traits` and could since C++11. Since C++2a there is just an additional customization point in `pointer_traits`. **2. Users do not need to specialize pointer_traits for to_address** For most users, `std::to_address(p)` already covers their needs, out of the box. i.e. It will call `to_address(p.operator-&gt;())` for a fancy pointer, and return `p` for a raw pointer. Users designing any fancy pointer type `P` will just provide `P::operator-&gt;()`. For the rare case where a user wants to customize the behavior of `std::to_address` for some fancy pointer type, they can do so by specializing `pointer_traits`. &gt; But who is supposed to make that member exist? Nobody has to make the member exist, because it is an optional customization point. It is even specified in the current C++ standard working paper as section [ptr.traits.optmem] "Pointer traits optional members". **3. Others** &gt; For example, pointer_traits&lt;P&gt;::pointer_to(T&amp; r) calls P::pointer_to(r) if that member exists; but otherwise it will sensibly default to SFINAEing away. This has never been the case with any vendor's implementation (libc++, libstdc++, Boost). For example: #include &lt;memory&gt; #include &lt;type_traits&gt; template&lt;class, class = void&gt; struct has_pointer_to : std::false_type { }; template&lt;class P&gt; struct has_pointer_to&lt;P, std::void_t&lt;decltype(std::pointer_traits&lt;P&gt;::pointer_to(std::declval&lt;typename P::element_type&amp;&gt;()))&gt;&gt; : std::true_type { }; template&lt;class T&gt; struct pointer { typedef T element_type; }; static_assert(!has_pointer_to&lt;pointer&lt;int&gt;&gt;::value); The above asserts.
that's not the right sub for this
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8z2cbb/help_using_stdshared_ptr_in_circular_doubly/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt;in C++ if the function is an inline one, the compiler will change all calls by the body of that function. No, no, no! The `inline` keyword is not about inlining, it's about ODR. An inline function may have it's definition included across TUs. It's a feature about making a function *inline* in a header.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
This sub is not for teaching the basics of C++. There are plenty of resources for that.
I'd argue the problem is expression templates rather than auto. Expression templates are a back door into the parse tree of C++ allowing you to rewrite expressions after they arr complete. I'd argue we should add a front door to do that instead of improving the back door. Give access to the full expression being assigned or constructed and permit a rewrite then. If you choose not to, let the next layer do it. So when you write Foo a = b+c*d; first `c*d` is evaluated producing type X. Then X is asked if it wants to rewrite its expression; it says no. Then `b+X` is evaluated producing type Y. It is given `b+(c*d)` and asked if it wants to rewrite; if no, it is then given `b+X`. If a stage rewrites we "forget" the old expression; nobody else gets it. Finally we get `a=b+c*d`. Now we just writr naive binary operators, and the fancy work happens in the rewrite. Types of the binary operators are the actual type we'd want to store. If we want to be insane, we could even permit the compiler to check for rewrites over multiple expression, and eliminate unused variables rewritten out of existence. But that possibly goes too far in step 1.
&gt; There was a looong list of defaults and none of them has been answered. Hello Jube Dev! I, and a few others, are actively looking into issues regarding io2d, with the intention of making it a better proposal, and perhaps some day, seeing if part(s) of its interface might be worthwhile additions to the ISO C++ standard, I am curious about the following comment that you made: &gt; There was a looong list of defaults and none of them has been answered. If you have a spare moment, might you be willing to elaborate on what sort of concerns that you see? We are trying to track these sort of things down, but we are human, and are not always able to find everything! 
Something would have to trigger the call to resume. You'd have to define how to make that first call happen - co_awaiting the coroutine is one case, of course, but blocks the calling coroutine. I think calling resume in the constructor might lead to problems - you don't really want to start the task until it has finished constructing. If you want the child coroutine to run greedily, if it is launched on another thread, say, then initial_suspend is as simple a configuration hook as any. I have never asked Gor what alternatives were tried for this aspect of the design. In general, though, coroutines should be lazy. That is the right default. 
But if you want to write a generic task accepting thing, how do you know what T is? Now, in all the actual cases I'm aware of, the unspecified type returned by operator co_await is convertible to T, so you could probably go with that. This is also why we need to have a decision on TS coroutines soon, because we absolutely need the types like `generator` and `task` to go with them, and getting the spec on those right is going to be work. Not just because they're coro related, but because getting the spec on _any_ library component right is a lot of work. 
I strongly agree with you on this Vinnie. I'd even go so far as to say that crappy packaging and distribution is the number 1 threat to the long term future of C++ right now. I'd certainly like to see the Standard C++ Foundation allocate whatever resources are necessary to bring a cargo-like or pypi-like solution to C++. About a million dollars would do it. (And yes, I've already raised that idea and pitched it to all those who would listen at Rapperswil)
This lambda thing reduces readability and produces more biloperate when you want to expose the partial function. I use std::bind for simple wrappers and a mix of decorator, facade and adapter in case of heavy implementation. 
Another video is up. This time after we invoke a native method, we get the value from the [rttr::variant](http://www.rttr.org) and we send that value back to Lua. [Embedding Lua in C++ #25 - Return Values Using Run Time Type Information](https://youtu.be/lByU2hUPtEs)
is that specified in the standard? 
This is an awesome comment. Clear and concise. Thanks for teaching me some things I didn’t know. 
My understanding is the standardization of packaging is out of scope for WG21 or am I mistaken?
Indeed it is :(. I argued as well as I was able that if there was anything which required the ecosystem throwing money at getting a solution ASAP, it is reducing the barriers to entry compared to almost any other programming language. Unfortunately, WG21's sponsors see such issues as a competitive advantage for their particular subecosystem, there is not a desire to fund a portable solution with the kind of funding it would need. Which means the language and ecosystem come second to their specific priorities. Which makes sense at the individual sponsor level I suppose. But it's frustrating.
Indeed it is :(. I argued as well as I was able that if there was anything which required the ecosystem throwing money at getting a solution ASAP, it is reducing the barriers to entry compared to almost any other programming language. Unfortunately, WG21's sponsors see such issues as a competitive advantage for their particular subecosystem, there is not a desire to fund a portable solution with the kind of funding it would need. Which means the language and ecosystem come second to their specific priorities. Which makes sense at the individual sponsor level I suppose. But it's frustrating.
Investigation of packaging solutions falls within the mission of the C++ Alliance (http://cppalliance.com/)
Why can't std::set be used? What am I missing here?
If the compiler can already determine that `noexcept` could be trivially added, then it can automatically apply such optimizations.
This. We have also specialized `pointer_traits` in our code base (we are still on GCC 4.8 and so are using C++11). When we did this, we also checked with a GCC developer who confirmed that it was OK, and they pointed me to tests in the GCC compiler code base where they test for specializations of `pointer_traits`.
I wasn't aware they had the sufficient funding. A million dollars is a lot of money.
 if (auto temp = f(x); temp == a || temp == b || temp == c) ... Why argue against a pathological strawman of an example when a sane alternative is possible? if (f(x).is_any_of(a, b, c))
That is a lot of money, and I question whether a project to make progress on packaging needs such a considerable sum up-front. A more modest outlay would probably still be helpful.
But again, how do you avoid using it if no alternative exists?
Or if you already are using Boost, use `any_of_equal`.
&gt; I, and a few others, are actively looking into issues regarding io2d, with the intention of making it a better proposal This proposal can not be made better, it has already been rejected, whether you accept it or not. So, my very little piece of advice: 1. Erase and rewind 2. Look at existing practices (glm, SDL, SFML, etc) 3. Read the archives of SG13 mailing list (especially [this one](https://groups.google.com/a/isocpp.org/d/msg/sg13/9MweFe7hCDo/ZNELiRp6h6gJ), [this one, probably my favorite](https://groups.google.com/a/isocpp.org/d/msg/sg13/8qPJ5Nc7YcE/nhw5ISwu3pQJ), and [this one](https://groups.google.com/a/isocpp.org/d/msg/sg13/gUr98RZMU7M/o5C2EmkQCwAJ)) 4. Propose a roadmap with little pieces, not a 200 page document (e.g. start with basic linear algebra for small vectors and matrices) 
A few excerpts I would like to highlight on the rationale provided by the author: &gt; **Why do this if WG21 is not interested?** &gt; The work to date is very valuable. It contains the result of extensive feedback from the WG21 committee and can act as a beacon to others. &gt; Consensus is a fluid thing, as is the makeup of the committee: there was very strong consensus for several years to pursue 2D graphics and it would be foolish to believe the current consensus will remain forever. Even if another approach is pursued, the TS will offer a starting point. &gt; There is still demand for a standard drawing library. On the matter of considering another approach for this very problem, the article says: &gt; **Why not try standardising another library?** &gt;The proposal is the result of many thousands of hours of work from a small number of wording experts and graphics experts. Starting again from scratch on something else would delay the introduction of 2D graphics by years. Regarding Packaging manager: &gt; **Won’t package management solve this?** &gt; Sadly, no. Adding the implementation to vcpkg gets this library into the hands of all those who are permitted to use third party code. However, this is by no means a universal privilege. Many commercial, industrial, governmental, financial, medical and military code shops simply outlaw third-party code, even Boost, allowing only what is provided by the compiler vendor. 
Hi Michael, thanks for the link. I'll have to send it to the other guys on my team. Right now we write in ANSI C, but I really want to start moving towards C++. I tried to compile / link a "Hello World" with g++ but I had problems with the linker script. Do you know of anywhere I can go to learn about linker scripts (specifically converting one from C-only to mixed C/C++?) Btw, that's a rather distinctive color on that tree shaker ;)
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8z5lom/what_is_the_c_book_that_you_should_read_as_a/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
There are lots of ways of doing it, and it was back of an envelope estimation during a lunch, but it's probably not far off. You could do something quick and nasty with scalability problems for far less though.
That exact syntax would require `is_any_of` to be a member of `f(x)`'s type (or for uniform call syntax to be adopted). More to the point, though the blog post spends most of its time on the `==` syntax, I think the use of `any_of` in the first place is the salient part. Perhaps I misunderstood him, but I assumed that by "postmodern C++ gobbledygook", /u/NoahFect meant the use of variadic templates and fold expressions, not just the use of `==`.
Who posted this? Why is the account showing as [deleted]?
What we need is an "element of" operator! (/s, maybe)
You mean Kotlin?
The issue with [[nodiscard]] was described in 2015 in P0158R0 [1]. [1] http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0158r0.html
It is interesting that no mention is made of 1. cohesion with stackful coroutines, or 2. the merits of the suspend-down model over suspend-up. I suspect that much of the endorsement of Coroutines TS is uninformed.
You mean like P0114R0? http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0114r0.pdf
I have yet to see a rationale for why a transfer of control from one coroutine to another could not be spelled `std::await(other_coro);`.
For one, `std::set` wouldn't be `constexpr`, right?
There's no question that Coroutines TS "works." But are the changes to the core language something we can live with for the next 50 years? I am concerned about how intrusive this feature is. It used to take an average of 10 years for a paper to get into the standard. This is the most significant change to the C++ language in the last decade, and we seem to be rushing it. Coroutines TS even adds a new kind of loop construct, `for co_await(...);`. This seems risky.
std::set will heap allocate every item you put into it which is *incredibly* inefficient for what this is attempting to do. The linked article won't touch the heap.
I guess my take is that, in the short term, it seems less typing / more DRY somehow, but in the long term, now you have tight coupling, and it makes it much harder to refactor any of your classes. In my limited experience (in game dev, in embedded, and infra-level containers and such), I tend to prefer composition even if it's more typing -- I think I end up with a more readable and maintainable code-base in the end. I use inheritance when 1. ) I really need to have e.g. virtual interface class, and pointers to the virtual interface, to accomplish type-erasure / make some interface generic. 2.) I need to use Empty-Base optimization to get a better memory representation. 3.) I need a "conditional copy constructor" that only exists depending on some SFINAE expression (technique described here: [https://akrzemi1.wordpress.com/2015/03/02/a-conditional-copy-constructor/](https://akrzemi1.wordpress.com/2015/03/02/a-conditional-copy-constructor/)) I generally try really hard to avoid inheritance outside of these limited cases, and look on it as technical debt. Similarly I usually look on it as a code-smell when inheritance is used and the base-class has non-static member variables.
To further add to this we can find in [[namespace.std]/2](http://eel.is/c++draft/constraints#namespace.std-2) &gt; Unless explicitly prohibited, a program may add a template specialization for any standard library class template to namespace std provided that (a) the added declaration depends on at least one program-defined type and (b) the specialization meets the standard library requirements for the original template. With this [footnote](http://eel.is/c++draft/constraints#footnote-177): &gt; Any library code that instantiates other library templates must be prepared to work adequately with any user-supplied specialization that meets the minimum requirements of this document. Nowhere in [[pointer.traits]](http://eel.is/c++draft/pointer.traits) nor [[allocator.traits]](http://eel.is/c++draft/allocator.traits) is it stated that specializing `pointer_traits` or `allocator_traits` is prohibited. In fact it says in [[pointer.traits.optmem]/1](http://eel.is/c++draft/pointer.traits#optmem-1) &gt; Specializations of pointer_­traits may define the member declared in this subclause to customize the behavior of the standard library. &gt; &gt; static element_type* to_address(pointer p) noexcept;
Right, specializing `pointer_traits` is rare, but you're not alone in doing it. It's also why the committee did not want to just add new non-optional member to `pointer_traits` as with R0 and break you or others that are within your right to specialize it. (I had added new tests to libstdc++ (and libc++ and Boost) that involve specializations of `pointer_traits`, when I implemented this feature in them but you're probably not referring to those.)
In any case they seem very committed in that we don't even use their reference implementation, shouting insanities about IP and liabilities on the project page: https://github.com/cpp-io2d/P0267_RefImpl "If you fail to comply with the terms of any employer or institutional policies, [...] and to indemnify every one of them in full in the event that any legally binding judgment is rendered against them." Yeah right. I'll rather *not* use that code. The author says he does not won't to be "facing $50,000+ in lawyers bills". But me neither, thank you very much. 
It may exist outside std. Or it may be possible to do without it. Or it might not exist, but the deprecation might highlight the problems with the current approach and as such help avoid them.
&gt; Similarly I usually look on it as a code-smell when inheritance is used and the base-class has non-static member variables. Much like the copy constructor, inheritance must be used when you conditionally want non-static data members; strongly agreed otherwise.
It's Boost-licensed – how on Earth is that a problem..?
Holy Smokes! Thank you!!!
In Effective Modern C++, Scott Meyers points out that noexcept is often a bad choice for a public API. Essentially, you promise users you will never call any code that could throw exceptions. Changing it affects the API in non-backwards compatible ways. The same might be said about constexpr, but can't think of a practical example where users rely on it being compile-time.
That's an interesting point. I certainly would not advocate saying that any function that can be noexcept must be. But it might be nice to at least be able to easily identify those which can be :-)
I'd also like to have it on Amazon, especially to read it on my Kindle
&gt; That exact syntax would require is_any_of to be a member of f(x)'s type Oh right, makes sense if you can't edit the type. What you could do is a bit of template magic and a helper function like if (is(f(x)).any_of(a, b, c)) that would wrap it in a small helper class that had members like `any_of` and would call the comparison operator for all the arguments. That would actually be a pretty nice interface.
yup forgot about the C++17 feature.
Having slept on it, the quick and nasty with scalability problems first choice for me would be a header only library pypi.org equivalent. Call it unity-c++-libs.org or something. Basically a straight clone of pypi.org, but for C++, and no need to think about build or packaging apart from a single large auto generated file, probably using https://pypi.org/project/pcpp/ or an equivalent. Even that, though, is at least three months of work. I definitely don't have that spare, I'm actually slightly losing money in my current work contract, I'll need to go straight into a new contract in January no time off, and hopefully at a day rate where I'm not slowly haemorrhaging.
Definitely looks like a bug in boost.rational to me. I suggest you post this information to boost mailing list https://lists.boost.org/mailman/listinfo.cgi/boost
It's probably a matter of familiarity, but I find lambdas to be more readable than std::bind pretty much always.
&gt; But in general, I think when compilers can’t decide which branch has bigger probability, they will leave the original order as they appear in the source code. I haven’t reliably tested that, but that’s my feeling. So, **I think it’s a good idea to put your hot branch (most frequent) in a fall through position by default.** Does anyone have recent, concrete knowledge about this for any particular compiler(s)? I remember hearing from a college prof. years ago that most if-statements usually evaluate to false, which would lead to the opposite advice from this.
The leading philosophy of writing code should be to make it as human readable as possible. Allocating 3 integers on the heap is one price I'll gladly pay for having a more maintainable codebase
Oh, he wants it in compile-time, that's what I'm missing. Thank you.
Yep, the solution has an extra copy which could be very expensive: https://godbolt.org/g/fSFnhp
Yes, it is intrusive and the usage is viral indeed. But they are so powerful, I do not see this as a problem. As always, there are tradeoffs, it is hard (impossible?) to find a solution/design that will satisfy everybody's expectations. for co_await is an elegant construct to loop over a generator, why do you think it is risky? I've read the paper you linked (P0158R0), there was indeed described as 'rushing' the push to integrate in C++17. That paper is 3 years old now, the coroutines were in a TS for a while, having working implementations in 2 compilers. I think there is no rushing right now.
&gt;I ran into the second issue once, until then I didn't realize that inheritance would use the padding of the base to layout new members. I first ran into this when I discovered that different platform compilers handle this differently! That was a fun bug. We were using UE3 at that time, and it calculated member variable offsets for reflection itself, and didn't take this into account - which resulted in some native variables being misaligned compared to the reflected version, but only on one platform! As for the issue in the article - I suspect invoking operator= on a base type view of a derived type variable is in some way undefined behaviour according to the standard, allowing this.
It's the opposite. Lambda is clear and concise and compiles to the performant code. bind introduced KLOCs of boilerplate. Stepping through it is such a pain.
Arguably this is a bug in libstdc++, or perhaps in the standard itself. bool q = std::numeric_limits&lt;int[2]&gt;::is_specialized; should compile OK (and result in q being false), but it results in a compilation error. As a workaround, it is possible to modify `boost.rational` so that it doesn't instantiate `std::numeric_limits` for array types (and this is what boost folks should probably do).
The parent comment's implementation is broken anyway, it doesn't actually sum anything. A better example would be: int count = std::transform_reduce({1,2,3,4}, 0, std::plus&lt;&gt;(), [](int val) { return val*val; }); Except that requires ranges-style algorithms, and AFAIK C++17's transform_reduce hasn't been implemented in the ranges proposal. It looks far uglier without it. (I also consider it a bit of a bug in the standard that the reduction (the `std::plus&lt;&gt;`) is specified first in `std::transform_reduce`) If we go full-on ranges we could do something like: int count = std::accumulate({1,2,3,4} | view::transform([](int val) { return val*val; }), 0); Which isn't too bad IMO. It would be improved by a terser lambda syntax, but if the transform was any more complex it would likely be a function call anyway, which transform can just take directly without a lambda and that becomes a non-issue. Algorithms all use std::invoke, so will even work with member functions. auto total_playtime = std::accumulate(steam_library | view::transform(&amp;steam_game::play_time), std::chrono::hours(0)); // vs auto total_playtime = std::chrono::hours(0); for (auto&amp; x : steam_library) total_playtime += x.play_time(); It's a wash IMO - they both have some syntactic sugar that the other doesn't.
Wow, awesome! 
I think the problem here is that there are two competing viewpoints: 1. To bring new developers in to C++, Bjarne himself stated that there are some "batteries-included" features that should be added to the language/libraries (like 2D graphics). A younger developer might become discouraged by C++ when she looks at how easy it is to do simple things in other languages. C++ has a very steep learning curve! 2. On the other end of the spectrum, seasoned C++ developers understand that the Standard is likely not the best place for 2D graphics, because what we REALLY need is a Module System and a proper Package Manager that will kickstart a C++ ecosystem. We need something like pip, so we can type "cpp\_package\_manager install graphics2D" for example. And now we can have TEN graphics libraries, not just one. Am I the only person who feels that (with the exception of Ranges and Coroutines) the C++ committee should pause almost everything and put all of their efforts into getting Modules right? The future of the language depends on getting that right I think. CMake is not the answer. Conan, perhaps Buckaroo, and others like these, are getting closer. Guys, if you want to see C++ explode (again) in popularity, please, get Modules working with a well-thought out design. Then we won't need to have as many debates about what to put in the Standard Library... It will kind of become obvious. We might not even need the Boost-as-testing-ground-for-Standard-Library approach... I mean, a proper Modules ecosystem really does change everything that radically. It's that important.
&gt;Nope, const char\* is OK. It fails to compile for array types. A string literal is an array. Thanks for the correction - indeed, if I cast the string literal to `const char *`, it compiles (whether this is because template instantiation is fine or it doesn't even try to instantiate the template I can't tell). &gt;As a workaround, it is possible to modify boost.rational so that it doesn't instantiate std::numeric\_limits for array types, and perhaps for function types (and this is what boost folks should probably do). Why not instantiate only for arithmetic types? Converting anything but an arithmetic type to a rational doesn't seem to make sense.
I get outlining for larger functions, but do you also do it for trivial ones?
What we need is pure modules that don't allow to export anything in the global namespace (they have to export in their own namespace) and obviously no macros. Then you can have something that can work out well. But it won't happen because too many people want macros even if it's going to be shown as "the worst decision in modules design" in 10 years. 
The STL is algorithms too. There's no technical reason to not have sort, max, min, set_*, priority_queue, pair, tuple, tie, and so on even in freestanding implementations.
I agree with you -- pure modules (i.e., isolated namespaces ) is something that the solution MUST have. And you may be right about macros as well, but that I need to give more thought. Modules is a fantastic chance to make C++ modern, and I agree with you: I hope they don't blow it because some people want to be able to use Modules in their 30-year-old codebase that is littered with macros and all sorts of Bad Things. And you're right -- any such modules solution would be overly convoluted and useless for the future of the language. Keep in mind that I'm not saying that backwards compatibility is bad -- it's certainly one of the reasons C++ has survived to this day. But with Modules, it's a chance to say, "All OLD code still compiles just the way it always has and will. But NEW code can take advantage of this Modules thingy". If they get Modules wrong, I'm going to move on from the language, because then it's just for embedded, and maybe not even that for much longer with some of the new languages catching up in memory/speed benchmarks.
&gt; OK, just went and looked it up: Motorolla 68306 was capable of 2.4 million instructions per second. For comparison, i7 does 238,310 million instructions per second. Small Atmel MCUs support C++ very well (the software part of the Arduino environment is "just" a C++ library after all). They top out at 16MIPS, default to 8MIPS (the internal fast clock), and go downwards from there. The internal low power clock is 0.128 MIPS. It's fully static though so you can go at 1IPS if you like.
What would such a front door look like?
Not a bug in libstdc++. Yes `numeric_limits&lt;char const[N]&gt;` is [guaranteed to be "fine"](http://eel.is/c++draft/numeric.limits#3), but the `min` function is defined to return `T` (with the value `0` if there is no specialization). You can't return arrays from functions, hence the compile error.
Yes. I don't like defining them all on one line, because that doesn't reflect the structure, and if you spread them over three lines it takes up too much vertical whitespace in the interface definition. 
Yes, but I don't care that much about up vs. down, so anything from resumable auto c = coro(1,2,3); c(); coro(1,2,3); to auto c = coro(1,2,3); c.resume(); co_await coro(1,2,3); is fine by me. I guess now it would be awesome if we just get coroutine frame in templated constructor: task&lt;auto&gt; coro(); template&lt;class F&gt; struct task : F { template&lt;class F&gt; //I forgot if need this for constructor deduction... task(F&amp;&amp; f) : F{f} //or erase type here {} };
It is already out? Thanks for the heads up.
Yep, I had it on pre-order.
Hello VinnieFalco, I, and a few others, are actively working on reviewing the io2d proposal, along with similar works in other libraries. I find your comments interesting, however I am curious about one of your comments, in particular. &gt; I am now certain that 2D graphics does not belong in the standard library. I know of several people, including at least one national standards body (the [BSI](https://bsigroup.com)) who do believe that there is room for (additional) standardization on certain aspects of graphics programming. I am wondering to what degree(s) you believe that 2D graphics does not belong in the standard library (which I presume to mean the ISO C++ International Standard, but could be wrong!). There do seem to be an awful lot of graphics libraries out there, many of which seem to be duplicating effort in a lot of places. If you have any time for a reply, I'd be interested in reading or reviewing it. If not, no worries (I know I'm pretty busy these days, for what it's worth)!
Given that Qt is older than Java, and follows conventions that were already present in MS-DOS, OS/2, Mac OS, Motif C++ frameworks, that remark is always funny to me.
Fully agree with you. Nowadays, I only use C++ when Java or .NET need some additional help, or when writing shaders. Regarding 2D graphics it is a pity that it got shot down like that, however C++ seems going down the path of expert's graphics programming libraries for OS vendors, with the user space programming being done in managed languages anyway.
Sure, and this is largely a recounting of my recent post on the LEWG reflector. Titus Winters writes (his personal opinion and not speaking for WG21): "So, what should go in the standard library? Fundamentals. Things that can only be done with compiler support, or compile-time things that are so subtle that only the standard should be trusted to get it right. Vocabulary..." [1] Upon consideration, I have to agree. I have felt for a while now that there are too many papers, too many things going into the standard, too quickly. To my knowledge, the question of "what should be in the standard" has never been officially answered satisfactorily. Titus' definition is compelling. New language and library features come with a cost and inherent risk. It is always better from an engineering perspective when these factors can be offloaded to external components, as external components are easier to change than the standard. It seems to me that 2D graphics (and coincidentally, my own HTTP and WebSocket library) qualifies as a component that can happily exist as an independent library. C++ DOES need a great package and dependency system that eliminates any source of friction for adding libraries to a project. I believe that the advent of such a system will take a lot of pressure off adding libraries to the standard. [1] https://abseil.io/blog/20180227-what-should-go-stdlib
&gt; By the way, you might be wondering what’s the purpose of the extra class... in that primary template. `promise_type` can depend on the argument types of coroutine.
Hello wsgeek! Myself, and a few others, have been reviewing and amending parts of the io2d proposal. If you have a moment, I have question(s) about your comment. &gt; I think the problem here is that there are two competing viewpoints I agree that the sometimes contentious, or perhaps just contentious-seeming nature of the discussions regarding graphics in the ISO C++ International Standard, and perhaps in one or more Technical Specifications, can be time-consuming. I also agree that improved module, as well as package management, system(s), are a critical need for C++ developers. I've lost track of how many times I've failed to complete a project in ideal time, due to dozens (at best) of different approaches to library integration. One of my questions is this: Is having competing viewpoints inherently a problem, when considering adding to a widely-used standard? Here is another, multi-part question, assuming, of course, time is available to consider such: Should the ISO C++ committee, or perhaps any standards committee, **only** work on a single paper, or a single proposal, at a time, and only move onto another when that feature is in the published International Standard? Any which way, thank you for your feedback!
This doesn't properly work when you have traits (enable_if_t) and you need to copy the whole thing when outlining, better inline
&gt; stepping through it is such a pain Not anymore ! https://blogs.msdn.microsoft.com/vcblog/2018/06/29/announcing-jmc-stepping-in-visual-studio/ (note: had no time to check it, but looks super cool)
What, do you not regularly use templated includes?
Finally. Now we can really regularly use this glorious construct.
Yeah, saw it. AFAIK, you could also achieve similar effect with recent gdb with some work. But that's still work vs no work for all-around better solution (lambdas).
Are polynomials with integer coefficients OK to form a ratio? I would say yes. Should they be coloured arithmetic types as far as C++ is concerned? 
Because I am unable to reproduce the issue using the development branch of the compiler I am going to say this is probably fixed. If you are able to reproduce this on your side with the latest preview release then you should submit a bug to us at [https://developercommunity.visualstudio.com](https://developercommunity.visualstudio.com).
I just noticed tmacarios's comment, you can just ignore me.
Boost doesn't call `min`, it is instantiated together with the entire class, as the standard requires. IMHO it's a bug/deficiency in the standard. Why would there be three tiers of types: those that you can verify to have a `numeric_limits` specialisation, those that you can verify don't have one, and those that you cannot ask about? What constructive purpose could it possibly have? It would be trivial to fix `min` and friends to return `std::decay&lt;T&gt;::type` instead of `T` without any ill effect.
Everything glenfe wrote above is correct. I'll just add one thing to the last point regarding `pointer_to`. The standard says "an instantiation of this function is ill-formed if `Ptr` does not have a matching `pointer_to` static member function." It doesn't say "shall not participate in overload resolution if `Ptr` does not have ..." which is how we say something SFINAEs away. It just says it's ill-formed, do not pass Go, do not collect £200.
After seeing other replies, especially the Stackoverflow question/answers, I come to think this is a deficiency in the standard. Basically, `numeric_limits&lt;T&gt;` contains member functions returning `T`. If `T` cannot be a return type of a function (such as array, function, or incomplete type), `numeric_limits&lt;T&gt;` is a hard error. The SO answers provide several workarounds how a user can detect beforehand if it safe to instantiate `numeric_limits` for a particular type, but I believe it should not be needed.
Couldn't this be solved by replacing the `view::transform(distance)` by something like `view::distance`? This would do the same job as `std::distance` but on a range, and implemented for the different iterator types, e.g. here with two `RandomAccessIterator` it would use `operator-` and wouldn't iterator through the range. 
&gt; There is nothing we can do by specializing coroutine_traits&lt;MyCoro&gt; that we couldn’t do more easily by putting members directly into MyCoro. No, this is wrong. First, it is not `coroutine_traits&lt;MyCoro&gt;` at all. It is `coroutine_traits&lt;Return, Args...&gt;`. This trait specifies which promise type to use in the transformation of the function with return type `Return` and arguments types `Args...` to the state machine. Why does it matters? A coroutine is not a return value of function: `std::future` is not a coroutine, `generator` is not a coroutine. A coroutine IS a function. (It would be even better if it can be an implementation detail of a function as Gor said in one of his lectures.) Most of the time you can write functions with same signature with or without `co_await`/`co_return`/`_co_yield` syntax in the body of the function. For example `my::future&lt;std::string&gt; get_name();` can be implemented as my::future&lt;std::string&gt; get_name() { co_return "Text"; } or my::future&lt;std::string&gt; get_name() { return my::make_ready_future("Text"); } and it does not matter to a caller which implementation it is. It can be hidden implementation detail of a function. What can be done with specializing `coroutine_traits` that cannot be done with putting members directly into the return value type? One concrete example is coroutines with return types outside of your control (external types or vocabulary types). For example you want to use optional with different coroutine semantic that one of your dependencies: maybe your coroutine with optional return type needs to propagate exceptions, maybe it needs to swallow exception and return empty optional. Then you would need a way to specify that you want your coroutine semantic instead of semantic of other libraries in your project (including std library). Another case is using coroutines with std library types (std::future, std::optional, std::vector, std::unordered_set) as return type. It is undefined behavior to specialize traits for std library types without user defined types, so you should never specialize `coroutine_traits&lt;std::future&lt;T&gt;, Args...&gt;` or 'coroutine_traits&lt;std::optional&lt;T&gt;, Args...&gt;`. You can change return value of your function to a wrapper type but it have some downsides (for example no RVO). Another way is to use tags to specialize `coroutine_traits&lt;std::future&lt;T&gt;, my_tag_type, Args...&gt;`. Example: namespace std { template&lt;class T, class Args...&gt; struct coroutine_traits&lt;std::future&lt;T&gt;, my::coro_tag_t, Args...&gt; { using promise_type = my::promise&lt;T&gt;; }; } // clean interface without tags if you want to hide implementation details std::future&lt;file&gt; get_file(std::string path) { // coroutine lambda as implementation return [&amp;](my::coro_tag_t) mutable -&gt; std::future&lt;file&gt; { // implementation with co_await from my::promise&lt;file&gt; }({}); // invoking with tag } More general case is parametrization of a coroutine behavior on a type of argument. It can be simple tag: std::optional&lt;R&gt; apply(my::wrap_exceptions_t, Functor f); where `my::wrap_exceptions_t` tag specifies that exception thrown inside coroutine maps to empty optional. It can be allocator for promise internal state, executor model or something else. You can use this method when one return type can be used with multiple compile time selected promise types. &gt; By the way, you might be wondering what’s the purpose of the extra class... in that primary template. I’ll tell you: I don’t know. See above &gt; The Coroutines TS (currently, and controversially, angling for inclusion in C++2a — I think it is woefully unready for prime time) Why do you think so?
To me, Conan has several advantages over vcpkg. As stated before, vcpkg builds everything from source, so it takes longer to get up and running. Especially if you wanted to try several packages. Also to get a local install of a package with vcpkg, you have to reclone the repo and re-bootstrap vcpkg, which will re-install cmake every freakin time! Conan’s documentation is way better than vcpkg, which is practically non-existent. I once tried to install a boost module with vcpkg for a project and it ended up pulling the whole boost lib. Then surprise, no vcpkg remove boost! One advantage of vcpkg is its universal integration on windows, which unfortunately doesn’t work as well on mac or linux. A downside with Conan is the limited package number in conan-center as opposed to vcpkg. You can add other remotes but you still get less packages. So in the end I ended up using both, vcpkg to get packages not found in the conan remotes, then some manual tweaking of cmake. 
Standardizing on a particular implementatioight be out of scope. But standardizing the aspects of it that impact package management could be. And we can do just about anything in standing documents. All the way to a complete design of interoperable package management components.
I agree that a good package and dependency management system would take a **lot** of pressure away from both C++ developers, and I imagine standard(s) developers as well. I do question whether a common package+dependency manager would clear away all problems related to graphics API usage, for C++. There are a lot of graphics APIs out there, some of them I find to be very good. Sometimes, though, it seems (to me) that each of them has their own set of idiosyncrasies. There also seems to be a lot of duplication, arguably more-so in some areas, than in others. This strikes me as ground for some amount of standardization, perhaps only in and of itself, or perhaps not, I am unsure.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8zfbmt/c_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Rational functions form a field, so yeah that should be fine
**Company:** [Beenox](http://beenox.com/en/) **Type:** Full time **Description:** Beenox is a video game development studio created in 2000. Located in beautiful Quebec City, Canada, Beenox is a wholly owned subsidiary of Activision Publishing Inc., one of the world’s top game developers. The studio is proud to contribute to the development of the Call of Duty video game franchise. Beenox has also contributed to the resounding success of the Skylanders, Spider-Man, and Guitar Hero franchises. As members of the Beenox family, we feel as if we’re part of a group of like-minded people who are great to work with. Our studio is a real open world where it’s easy to have discussions with everyone, including our studio co-heads. Here everyone brings their own unique touch to projects that showcase their talent on a global stage. You could say that video games are in our blood! *Responsibilities* The Engine Programmer has different responsibilities related to the game engine. The first objective of the Engine Programmer is to maximize the game’s graphics capacity for all the different game platforms on which it will be published; The second objective of the Engine Programmer is to support the Art team and drive the development of features/tools related to the artistic needs (shaders, textures, etc.); The third objective of the Engine Programmer role is to ensure the stability and performance of the game’s multiplayer modes; Finally, the Engine Programmer provides technological watch for the Programming team and will actively participate in the improvement of the engine over time; Our studio is currently dedicated to the development of the Call of Duty franchise. *Main Tasks* * Ensure the constant evolution of technology associated with different game platforms; * Develop functionalities of the game engine: graphics, networking, optimization, physics, animation system, APIs); * Ensure the quality and performance of functionalities that were developed; * Support users on developed functionalities. *Requirements* * Strong knowledge of C++ and real-time engines; * Development experience for console and PC; * Good analytical skills; * Ability to work autonomously in fulfillment of his/her tasks; * Ability to adapt to internal tools and changing environment; * Positive attitude and desire to work as a team; * Passion for video games; **Location:** Quebec City, Canada. Our workplace languages are French and English. **Remote:** No **Visa Sponsorship:** Yes **Technologies:** We are looking for someone who is proficient with C++ 98/03, but also has knowledge of a few key features of the later additions to the C++ language. We are using Windows with Visual Studio for most of our development, and while C++ is a must-have, proficiency in other languages such a C#, Python, or Powershell are nice skills to have. Engine programmers will also have to deal with graphics code, so knowledge of a modern graphics API such as DirectX or OpenGL is a nice plus. **Contact:** You may apply [here](https://activision.referrals.selectminds.com/beenox/jobs/engine-programmer-2283).
There are many things I don't like with Python, but at least importing modules is easy and clear about what you're doing. If you want to do terrible things like export in the global namespace you can, but the default is sane. Backwards compatibility should stop at macros. Macros should die. There are still a few cases where you need macros, but they are going rarer and rarer with each new standard and added `constexpr` features.
Thanks for the feedback, jube_dev. I think there are a lot of good points in here, especially in terms of reviewing existing practises, as well as communications on various forums, mailing lists, etc. I am wondering about your suggestion that, "This proposal can not be made better". Are you suggesting that it (the "io2d" paper) be disregarded completely, and if so, why? My understanding is that there are many developers who are interested in an amended form of this, and that (at least) one national standards body, notably the [British Standards Institution (BSI)](https://bsigroup.com) is, reportedly, very interested in it. 
Well my goto rule is inline if it's a single statement and outline if it isn't. The IDE can jump to the definition but I do feel like you waste time. But I get your point for consistency I guess. Also if I have a template helper class that has one function, it's going inline.
how do people feel about using std::in_place_t for user in place construction of user defined types?
Hey I hope I did not ruffle any feathers with my comment, and I am flattered that you are asking for follow-up. I will put together a detailed answer this evening for you. Happy to help in anyway that I can.
I don't like it at all. It's noisy, ugly and provides no additional information to a reviewer perusing its callsite. Its location in &lt;utility&gt; instead of the various ADT headers baffles me, considering that only &lt;optional&gt;, &lt;any&gt; and &lt;variant&gt; are its only users (and I guess any other user-defined ADT). Does anyone know the rationale for its addition? Why aren't make factories sufficient?
From a comment of yours on this, on a (related thread)[https://www.reddit.com/r/cpp/comments/8q28id/2d_or_not_2d_that_is_the_question_rapperswil_trip/], from about a month ago: &gt; THIS. NEEDS. TO. DIE. &gt; Seriously. This is the kind of thing that should be implemented as a library, just not as a standard library. And the main reason for it is that a library can be thrown away once it has become obsolete. Ask yourself what a 2D library would have looked like 30 years ago. Would you still use it today? Do you see reason to standardize anything, or find value in any existing standard, C++ centric or other?
Thanks! I look forward to reading any reply that you have, and if you're unable to write anything up, no worries! 
&gt; My understanding is that there are many developers who are interested in an amended form of this I've been trying to understand who these developers are. What are they currently using? How would the proposed (or a modified version of) the 2D lib help them? BSI is being mentioned, what are they basing their interest on?
A new developer has to read your document to understand what `if (any_of{a,b,c} == x)...` does. A 5 years old new developer can understand what `if(x == a || x == b || x == c)` does. Which one is better?
If `optional` didn't have a constructor from `(in_place_t, Args&amp;&amp;...)`, how could you construct a non-copyable `Empire` from `Vader` and `Palpatine` arguments?
Isn't this what unmaterialised value passing is supposed to solve?
No: you need to iterate to the end of word to get second iterator that you can subtract from. I think `distance` already checks for `RandomAccessIterator`.
Only in limited circumstances, which prevents things like library debugging machinery that everyone takes for granted.
Why isn't in-place construction the default way of constructing objects, without using std::in_place_t or helper functions? Is it because of legacy code?
How would you create an empty optional for a type with a default constructor if in-place was the default? Would need a special way to create those then instead it seems.
&gt;Are polynomials with integer coefficients OK to form a ratio? Sure. &gt;Should they be coloured arithmetic types as far as C++ is concerned? Yes, maybe? But note that I wouldn't disable `boost::rational&lt;T&gt;` for non-arithmetic `T`, only the conversion constructor, which uses `is_compatible_integer&lt;FromInt, ToInt&gt;`. Currently, the definition of `is_compatible_integer&lt;FromInt, ToInt&gt;` includes `is_same&lt;FromInt, ToInt&gt;`, but the corresponding constructor could probably be made explicit (i.e. non template)? From a fundamental point of view, what would be the sense of `is_compatible_integer&lt;FromInt, ToInt&gt;` for non-arithmetic (or even non-integral) types anyway? I'm not even sure that `is_compatible_integer&lt;T,T&gt;::value` should be true for non-integral `T`. After all, if `T` is not integral, how can it be a compatible integer?
I don't know where you're from, but usually there is a small exercise to demonstrate your C++ 11 skills...
The licensing situation looks totally schizophrenic. It has a Boost license, and then it tries to tack on an indemnification EULA in the README as well. How on Earth they think that is legally binding, I don't know, but I would not touch it with a ten foot pole nonetheless, as it displays a legal cluelessness that might be pervasive.
&gt; Are you suggesting that it (the "io2d" paper) be disregarded completely, and if so, why? IMO, this paper does not solve any problem. More precisely, there is no target audience for this paper. Event beginners can not be satisfied with this because they don't want to draw things, they want to *interact* with things. And currently, this proposal does not have anything for interaction. This paper, from the beginning, has taken the wrong path. Instead of building something bottom-up, it followed a top-down path. That was two mistakes in the same time because 1) you do not have a standard for a window or an image on which you can draw (and the surface definition in the paper is far too complicated and, at the same time, not generic enough for other purposes) ; 2) the drawing API itself is totally out of date and has a weird scope because if you want to draw simple things (e.g. diagrams), it's too complicated, and if you want to draw complex things (e.g. games), it's not powerful enough. Again, look at existing practices. SDL is the base of so many game engines because it answers to a need: getting a window and inputs in a portable way. SFML too provides a portable API for this kind of things and is used broadly. SDL also provides a very simple 2D drawing API, much more simpler that io2d, and yet more powerful and it has been used countless times to build games. But SDL also provides a bridge to other drawing APIs (DirectX, OpenGL, Vulkan). GLFW is another library that provides windowing, inputs and context creation. These libraries all do the same things the same way (or nearly). This is what I expected from SG13 and that has never happened. Cinder, which was cited by Herb Sutter at the beginning of SG13 is built on top of GLFW and glm (among others), such a library would benefit from standardized windowing and input but would never use a drawing API like io2d. Another example is your `point_2d` and `matrix_2d`. I do not want a `point_2d`, I want a point type (that every other geometry libraries call vector or simply vec) with a template type for the type of the coordinates and a template size parameter because I also want the same type for 3D and 4D and possibly 1D. Same for matrix, I want to be able to define any small matrix with any type and any dimensions. And I want all the classical mathematical operators related to vectors, matrices and linear algebra (dot product, cross product, inverse, ...). Look at glm. As a final word, I do not believe I said something different than many others before. I can understand that it is very difficult to throw hours of work. Do not forget: errare humanum est, perseverare diabolicum. 
**Company:** [RE-liON](http://re-lion.com/careers.html) **Type:** Full time or part time (minimum three days/week), internships available **Description:** RE-liON is a software/hardware company, servicing the civil and defence industries. We are ~23 people strong at the moment. Our main product is a fully immersive, multi-user, full-body motion sensing VR simulator that is building a track record of greatly enhancing infantry and firefighting training. We are also working on bridging the gap between GIS applications and game-like 3D world editors. We are a fully C++ company. We're looking for C++ knowledge in many areas, see the job posting on the link above for more details. **Location:** Enschede - The Netherlands. All technical documentation in English, informal workspace language mostly Dutch at the moment. **Remote:** No **Visa Sponsorship:** We prefer workers from within the EU at the moment. **Technologies:** Whatever C++ level the latest MSVC supports, some Lua, DirectX 11, Boost, Eigen, GDAL, JSonCpp, SQlite3, etc **Contact:** Please find our contact info on our [careers page](http://re-lion.com/careers.html). Recruitment agencies will be ignored. 
I had an implementation of this ref-or-move thing when I was making a lazily evaluated filter/query library (think range_v3, or linq from C#) - it didn't suffer from the following being broken as a result: (unlike range_v3) for (auto&amp;&amp; x : vector{1,2,3,4} | transform([auto&amp;&amp;x]{ return x*x; })) { // ...
This is kinda scary template &lt;class T&gt; class TextDisplayer { public: explicit TextDisplayer(T&amp;&amp; text) : text_(std::forward&lt;T&gt;(text)) {} private: T text_; }; template &lt;class T&gt; TextDisplayer(T&amp;&amp;) -&gt; TextDisplayer&lt;T&gt;; Storing references arbitrarily long can easily lead to dangling references, especially when it's not immediately clear that this is what's happening. It's a lot safer to take a page out of the standard library's book here and unconditionally store a `uncvref_t&lt;T&gt;`. If the user wants you to store a reference, they can do that explicitly by passing `std::ref(value)` instead of just `value`. 
That’s great, this “optimization” is often the behavior you want. The problem is that’s it’s not trivial to implement and it’s not trivial to read &amp; understand - that means real-world code usually boils down to take-param-by-const-ref-and-always-copy. 
What are IN OUT keywords? It's not defined per the c++ standard so I think it's a compiler extension. So if it's a compiler extension I strongly recommend you not using it.
Why not in from argument and out from return value? I personally think mutable argument references are bad practice. I use a custom `out(arg)` wrapper when I need to out to an argument.
first of all your problem has nothing to do with structs, but only with functions. I think the common sense approach is to either not tag at all or only tag those arguments that will be mutated. The default is input argument and output arguments are the exception. Also most professional code by seasoned coders you see tries to avoid output parameters when possible. In your example there is simply no reason not to use the function return, so i guess you should just go with the mainstream and return the OUT value instead.
Visual C++ has had [source-code annotation](https://docs.microsoft.com/en-us/visualstudio/code-quality/understanding-sal) for a long time: void InCallee(_In_ int *pInt) { int i = *pInt; } void BadInCaller() { int *pInt = NULL; InCallee(pInt); // pInt should not be NULL } When you run code analysis on it, it gives: C6387 Invalid Parameter Value 'pInt' could be '0': this does not adhere to the specification for the function 'InCallee'. You'll notice that these annotations are on declarations, not on the call site, where it would make little sense. Note that this is strictly specific to Visual C++. Whether it's a good idea is unclear to me. I've never used them.
Hi thanks for the reply, the function in my actual code is returning more than one value hence not using 'return', I'll edit the question to put my actual code so it's clearer. I think i'm probably going about things in an overly convoluted way. 
It's a WinAPI thing, as far as I'm aware. Definitely not standard.
Thanks for the reply, i'll edit the post with the actual code. My actual code needs two (or more potentially later) returns.
Thanks, i'll take a look at that, still very new to C++ so might be a few weeks before it doesn't go over my head though. 
I would put this sort of stuff pretty low on my list of priorities. In general, parameters are inputs, return values are outputs. If you need multiple outputs, package them in an `std::pair`, an `std::tuple` or a `struct`.
As other people have commented, these annotations are not standard C++. I personally do the following: IN parameters are either plain (e.g. int) or *const references* (e.g. for larger structs) OUT parameters are pointers The advantage of this is that it is directly visible at the call site (&amp; operator) so there are no surprises even if you don't know exactly the function does. I can know which variables are modified from just reading the function invocation, no further documentation necessary. void Func2(int i, const Vec3&amp; v, float *f); int main() { Vec3 v = {1,2,3}; int i = 0; float f; Func1(i, v, &amp;f); // I know only f is modifed just from reading this line } The case where this breaks down is with arrays or if you just want to pass a pointer, but I still find it helpful.
In the win32 API all the parameters are decorated with macros like OUT and IN that make it clear how a pointer or other reference handle is to be used. They don't do anything, they're empty macros that are just reminders to the programmer. This is actually really handy in the win32 API because there are sometimes functions that take upwards of 20 parameters, many of which are pointers or handles to Windows resources. It's just not necessary in C++ though. Things that are passed by value are unambiguous, and pointers or references can be const to denote whether they are to be changed or not. IN and OUT are redundant. They're also unsafe, if you have the correct types for your function parameters then the compiler can check that you're passing the correct pointer types, but with IN and OUT decorators it's up to you to check them and you *will* make a mistake at some pointer. C++ has a strong type system, for almost all things that's what you want to be using.
You can return multiple values in many ways in C++ - either return a pair, tuple, or struct! You have a few functions returning an X/Y, it would make sense to have a `struct XY` that contains both, and then you could do: Room01.origin = PlaceRoomOriginSeedRandomly(Room01.tileEntrance); (where Room01.origin is an XY and PlaceRoomOriginSeedRandomly returns an XY) instead. It's much cleaner
Also depending on the IDE, but most IDE's will show what parameters are expected. If a function expects a nonconst reference or pointer then it's probably some output parameter. Another option is to add a line comment to explain what arguments a function expects so that when you come back later it's easier to understand what you should change.
These annotations are meant for function/method declarations. So, when you want to use a function and go to check its declaration, you will know if a parameter is in or out. They can also be used for static code analysis tools. However, *a pointer or reference to an input should be marked const*. On the contrary, *an output cannot be const*. If I was reading your code, I would expect inputs to be marked as const. Unless you pass by value, in which case it is definitely an input and const is redundant.
&gt; They don't do anything, they're empty macros that are just reminders to the programmer. I think the compiler does checks on those. Either that or the static analyzer.
Passing a pointer makes it clearer that it's modified, but it could... also not be modified. You can still pass a pointer without using the `&amp;` operator. Additionally, pointers are [less likely to get optimizations](https://blog.regehr.org/archives/1307).
/r/cpp_questions 
Like this: std::optional&lt;UserName&gt; u0; // empty optional std::optional&lt;UserName&gt; u1{}; // also empty // optional with in-place default constructed object: std::optional&lt;UserName&gt; u2{UserName()};
Unless I can prove that there is a measurable performance benefit to using out parameters, I prefer that all parameters are inputs. If a function needs more than one output, then I use an `std::tuple`. That way all inputs are on the right, all outputs are on the left.
Output parameters are discouraged in C++, you should either use a `std::tuple`, `std::pair` or pack them in a struct: struct Point // Or whatever name you want to use { int x; int y; }; Point PlaceRoomOriginSeedRandomly(char roomSeed) { /* ... */ } Point CalcRoomDimensionsRandomly() { /* ... */ } If you need to signal an error and you can't/won't use exceptions, use something like `expected` or `boost::outcome`. It may seem cumbersome doing it this way (or just less convenient) but it's less of an headache in the long run.
Thanks, certainly seems cleaner (and i'll almost certainly need a lot of XYs throughout). so in your example i'd have the below? and separate the randomise origin location part of the function into a seperate function from the seed placement itself? struct XY { float X; float Y; }; origin; 
&gt;One of my questions is this: Is having competing viewpoints inherently a problem, when considering adding to a widely-used standard? Differing viewpoints is a GREAT thing! In the C++ community especially I think, since we have a committee-based design rather than a total BDFL. &gt;Should the ISO C++ committee, or perhaps any standards committee, only work on a single paper, or a single proposal, at a time, and only move onto another when that feature is in the published International Standard? Ha! I know that my earlier hyperbolic comments may have made it seem that I think so, so I'm going to respectfully walk that back a tad. There are hundreds (thousands?) of talented, dedicated people who are all working on various bits of the language, the library, etc, and they all deserve a pat on the back (and our help when we can!). That being said, I think that a bit of prioritization is in order. Granted, we are seeing some of this already: [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0939r0.pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0939r0.pdf) This is a fascinating read, but it touches a nerve when it gets to this paragraph: *"C++ teaching is mostly stuck in a pre-graphics, pre-web world. This is a serious weakness, potentially fatal over the longer term."* I think we would all agree with that... But where that sentence leads next is (IMHO) the problem that I stated earlier: *"Teaching C++ to modern students will not be really effective until we can offer* * *Simple standard graphics and simple use of browsers (or GUI).* * *Simple mechanisms for packaging, distribution, and installation for libraries and programs"* Oops. In my opinion, if you solve the SECOND one, you will get the FIRST one (easily). And much more. The focus on adding graphics to the Standard is well-intentioned but dodges the larger issue, which is packaging. Heck, even in this paper they admit this: *"Students cannot be expected to download and install libraries on day #1."* Yikes! But, how true. Can you imagine if that were true of Python or Rust? Then we perhaps never would have heard of those languages. To further drive this point home (and likely beat it to death -- apologies), go to your console and type "pip search &lt;x&gt;", where &lt;x&gt; is almost anything you want (music, graphics, machine learning, networking, blah blah blah). The list that shows up will likely contain some amazing things! Now imagine that these are C++ Modules. Let that sink in. This is why Modules are so important, and yes why I think that the C++ committee should pause on certain things in order to get Modules right; because doing so will likely ACCELERATE all of the other stuff that they are working on. I think even Bjarne himself is starting to see the Insanity of things: [http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0977r0.pdf](http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0977r0.pdf) The people working on these items are certainly awesome and to be commended! But I wonder what would happen if we JUST got Modules working? And as perhaps the most glaring example of why we need Modules (and should really not focus on adding this-or-that to the Standard Library), consider Python's own standard library (which DOES have graphics APIs in it): [https://docs.python.org/3/library/](https://docs.python.org/3/library/) Check out items 25 and 26. Amazing; I'll bet that many people that use Python daily perhaps didn't know that it has Turtle graphics and Tk widgets as part of the standard library. But I'll bet that EVERY Pythonista out there knows how to install any graphics API they want (pip). Sorry to be so long-winded and thanks for reading!
And note that all three of them allow the use with structured bindings: std::tuple&lt;int, std::string, double&gt; void fun() { ... } auto [i,s,d] = fun();
Thanks all
``` template &lt;class T&gt; class TextDisplayer { public: explicit TextDisplayer(T&amp;&amp; text) : text_(std::forward&lt;T&gt;(text)) {} private: T text_; }; ``` Is `T&amp;&amp;` in the constructor really a forwarding reference? I always thought, since the type `T` is bound to the class `T&amp;&amp;` is a rvalue reference?
And moreover, there are plans to have some of those macros turn into C++ contracts in a later standard, in order to standardise a subset of Microsoft's *Standard Annotation Language* (SAL) into all C++. I, in particular, specifically want the ability to mark an i/o function with the exact side effects it has on the C++ object state. So, if you read X bytes into a sequence of gather buffers, you give the C++ compiler a contract saying that the exact side effects on C++ objects are solely those in those gather buffers, and never anything else. That in turns lets the compiler not drop register state or reload memory around every kernel syscall, and that in turns makes proposed iostreams v2 much more efficient.
Correct. T&amp;&amp; is not a forwarding reference, because it's not in a deducing context.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8zkcoa/i_complete_beginner_in_cpp_so_give_me_some_advice/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I am afriad to know what this `mapGenerator` global is. Also, a good way to know if some code is kosher or not is to paste it here : https://godbolt.org/g/ovYsHd and check that it compiles everywhere
There are two kinds of types, those that are compatible integers (whatever that means) and those that are not. However these kinds are defined, `is_compatible_integer` should be able to answer the query and not just fail compilation.
Thanks for confirmation!
mapGenerator is a 2d char array. Bookmarked your link thanks very much, very helpful. 
How wonder how much of an effect that would have on compile-times though... C++ compile times are already so high, and that feels like it would add more and more checks for the compiler to perform. More security is nice, but maybe not on _every_ compilation.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/8zkn59/c_books_used_at_mit/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
nobody mentioned [Microsoft SAL](https://msdn.microsoft.com/en-us/library/hh916383.aspx) which stands for Source-code Annotation Language and goes far beyond IN and OUT but defines a whole set of attributes, a whole language in fact.
So just for my understanding. The article is wrong about the forwarding reference in the class. But through the deduction guide and reference collapsing rules it gets luckily away with it in the `T&amp;&amp; constructor` and the `std::forward&lt;T&gt;`, right?
Arthur on one of his uninformed rants again. Arthur wrong again. What else is new?
inline bool must_use(feature_t f) { return is_standard(f); }
Ah, but the subset in mind isn't about security. It's about giving extra guarantees to compilers, guarantees with which the compiler generates more optimised code. Guarantees, which if violated, equal a branch instruction to an undefined target, because the compiler *quite literally* will not generate code which works if the guarantee is violated. In terms of compile times, obviously nothing comes for free. But relative to other much larger consumers of compile time e.g. free function overload resolution, contracts would currently be expected to be low impact. In fact, WG14 is currently very keen on importing C++ contracts into C22, fully source compatible.
I get what you're saying, kinda sympathize with it even, and you are probably even being a bit facetious. But, please forgive me, I need to get this out: No no no no, "Hello, world!" works the same way it always has. I can accept that a major version release every ~5 years can make changes to the deeper parts of the language. And I totally get that the evolution of smart pointers and move semantics in C++ changes engineering aspects of larger projects. The basics of C++ learned in first semester C++ 101 class hasn't changed much in ~20 years. CMake? The "Hello, World!" of CMake is difficult, and the simplest multi-source-file project is inscrutable: Do we really need to explicitly list each .cpp file, or do we file(GLOB SOURCES "src/*.cpp")? And what's the difference between project, target, library, etc? There are a lot of high-level concepts you need just to get off the ground. Then you need to grok testing, other generated artifacts, installation, handling multiplatform differences... And the "right" way to do these things is a moving target, while the CMake documentation is... opaque. I mean, it tells you what a given function does without telling you anything useful. 
I would consider returning by parameter a bad practice in and off itself. [You should consider creating a struct (or tuple) to pack associated value together and return by value.]https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#Rf-out-multi) Also, you don't have to worry too much about optimization in this case, [Return Value Optimization](https://en.wikipedia.org/wiki/Copy_elision) will most certainly be applied. In all cases, if you are not sure, measure. 
&gt; More security is nice, but maybe not on every compilation. compilers will certainly have a -fno-contracts switch
Would this default-construct then move or copy the object if compiler doesn't optimise it away?
I guess you are right. However, the forwarding references are used in the deduction guide (or alternatively, the helper function text_displayer).
They conflict with each other. For example, string uses the suffix 's' for string literals, but chrono also uses the suffix 's' for seconds.