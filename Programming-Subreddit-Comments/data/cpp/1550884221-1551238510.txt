C++ 2x will likely have metaclasses. That's what this looks like at a glance.
* Using `std::string_view` as an owning pointer: [jsonioutil.cpp#L21](https://github.com/lemire/simdjson/blob/527ee8eace58427c7213d7ed0acc6c1628588b7a/src/jsonioutil.cpp#L21) &amp;#x200B; That `free((void*)`[`p.data`](https://p.data)`())` in the main README really scares me..
The most important reason I can imagine is that we'd like to get new features that aren't going to become part of the OWASP Top 10.
Is the compiler based on clang?
```shared_ptr``` doesn't violate that paragraph. The paragraph requires two conditions to hold (well three but the third one isn't relevant). 1. Two standard library functions must share access to an object via its arguments. 2. One of the arguments by which the shared object is accessed must not be ```const```. Note that it is the argument that must not be ```const``` as opposed to the object being shared. One point you made with respect to ```unique_ptr``` was the implication that, as the name suggests, a ```unique_ptr``` has unique access to the pointee so that you would never get a situation where the pointee could be shared by multiple threads resulting in an thread unsafe operation. I would like to point out that that is not true, it is perfectly valid C++ and even often the case that multiple pointers point to the same pointee, for example: ``` auto x1 = std::make_unique&lt;int&gt;(5); auto&amp; x2 = *x1; auto* x3 = &amp;x2; ``` There is nothing fundamentally wrong or even improper about taking a raw pointer or a reference to the pointee owned by a ```unique_ptr```. You may do such a thing if you wanted to pass the pointee to a function by ```const&amp;``` for example. You could even pass a copy of ```x3``` to another thread. As long as the extend of ```x2``` and ```x3``` are less than the extend of ```x1``` then that's perfectly well defined behavior. I think ultimately based on how I interpret Herb's article as well as the WG21's wording including the paragraph you cited, there is no special property about ```shared_ptr``` with regards to thread-safety that doesn't apply equally well to ```unique_ptr```.
No. I wrote the front-end from scratch. 
It is amazing how big "very small" is these days. The advantage of pass by value is that there is no aliasing, so you open up lots of optimization gains.
can you use it with other C++ compilers, such as msvc?
That is very impressive. Do you support libstdc++ or libc++?
He replied somewhere else that it is indeed custom and not based on clang.
In the intellisense window... you can select which files show warnings...
I really hope we get the index into parameter packs in c++ too.
I believe you are confusing the intellisense popup (which appears when you are typing code, and lists available functions, enums, etc.) with the error list (which lists warnings, and has a dropdown box for disabling output from certain sources).
Mh. This reminds me of inlined PHP. Not sure if it's a good thing :) However this is an impressive looking project. Can't wait for the compiler to play with it! 
absl::flat\_hash\_map is the preferred default hash map implementation for production code at Google. 
Signed overflow is undefined behaviour, so the following isn't safe. void count() { static int8_t c; c++; // UB after 255 increments } 
Inlining is less about eliminating function call overhead and more about facilitating all the optimisations the compiler could perform on the function itself once integrated into the caller.
should be compared to https://cppx.godbolt.org/
&gt; When I look at a new language, I ask "what can this tool do for me, how can I use this to make my life better?" I do too. After all, there's no point using a tool which *doesn't* make my life easier :) &gt; But C++ people especially seem to be hellbent on the question "how can I break this". I don't get this mentality. Part of ensuring it will make my life easier is ensuring it will not break my assumptions/trust. Most build systems assume that dependencies are strictly about files, and that the state of the world doesn't matter. --- *Disclaimer: I have spent more time than most thinking about compile-time computations, the technical challenges, the technical limitations, and the limits I would be comfortable with.* `gmtime` is just the tip of the iceberg. It gets worse. Do you sure 3rd party libraries? How confident are you that their authors can be trusted (security)? That their online identity was not stolen, however briefly? I advise you to look at the hell that is the NPM ecosystem, and specifically the multiple security breaches they have had with 3rd party packages being coopted to run malware during compilation, for an example of how a perfectly reasonable package can suddenly become deadly after a routine update. There are lessons to be drawn from this: - Unrestricted I/O means that compilation is no longer *safe*: a compilation step can "accidentally" wreck your disk, steal your data, encrypt your data, download and install malware/spyware... - 3rd-party libraries must be carefully vetted: both initially and at each update. - Package managers must offer a way to use *internal* registries, so that non-vetted libraries cannot accidentally be integrated. This is not specific to C++, all languages face this new threat. The NPM ecosystem is not even the first to suffer from this; SourceForge was not so long ago planting spyware in the archives it hosted. 
I dunno. I'd probably just disregard the company standard in this case and implement the proper begin/end functions, rather than jump through these hoops. Turns out that if you want to use standard constructs, you should just use standard interfaces...
Looks cool! Will definitely check this out!
I understand the legacy reasons and historical accident that caused the fork in styles and made non-standard naming conventions popular in C++, so I'm fine living with it. It's still the case though that for new codebases you can't just make up your own dialect, stick to the official/idiomatic style for whatever language your using. All other languages do it, surely C++ can to. I've never seen snake_case C#
it's sad when one has to specify what version of C++ one's using. So many versions of C++ on the market now.
There's just one `/std:c++latest`, doesn't seem so hard.
MSVC 2017, GCC 8, Clang 7 all 3 support C++17 and you can use these on most operating systems, except for MSVC which is Windows only.
Unless you're shipping on multiple platforms, some of which have semi-private toolchains, some of which are not on the latest version of cpp, and your codebase has to support cpp98, 11, 14, and 17 simultaneously.
Meh - I had a bit of Python bork on me the other day because it didn't know what collections.Counter was - the machine I'd written it was like one subrevision ahead. So languages evolve, and C++ is by no means the worst offender here.
It's designed totally differently from metaclasses. Metaclasses require a very fine-grained object-oriented API which is supposed to model all aspects of the language. You use this API from inside the metaclass to modify the type. The reflection in Circle has no API at all. You simply do compile-time control flow by putting @meta in front of control flow statements to cause them to go at compile time, and declare your members inside of that. It's all done contextually. If the innermost scope is a namespace, then the real statement inside your meta for will be treated like any other statement inside a namespace scope. If the innermost scope is a class definition, then the real statement will be treated like a member-specifier, and so on. Circle is very Keep-It-Simple-Stupid. That's really the best principal in software design; I feel C++20 and the future proposals have given up on that. 
Then you just use c++98. The later ones are all backwards compatible
&gt; The later ones are all backwards compatible ... Nope, if only it was that easy.
This looks good (especially after checking Wargroove as a sample result). At the bottom of the Modules section, the link for sample is a broken link - [https://github.com/amzeratul/halley-samples](https://github.com/amzeratul/halley-samples) .
Companies: "We will not change anything to be compatible with modern c++" C++ committee: "We will not change anything because we want to be compatible with legacy code"
libstdc++. Haven't tried linking to libc++.
This is a bad idea to me. As pointed out in the article you have to fight against the way unique_ptr works and implement custom manual creation and deletion code. Including unique_ptr is just making things harder. The user of the list shouldn't have to manage the list's memory, but the list implementer should be able to handle the manual memory management. The risk of stack overflow in recursive uniqueptr destruction is an interesting problem I hadn't concidered before.
No allocator, so every node is allocated individually? I'll pass.
compiler devs: rewrite sections of compiler and now stuff breaks anyway companies: üòØ committee: üòØ
Isn't the point of smart pointers to not have to do manual memory management? Otherwise, why not just use a plain pointer? I wonder if it would be feasible to add some sort of keyword to the language, usable only in destructors, that basically tells the compiler "until this destructor finishes its work, please allocate all stack frames on the heap". Then you would still pay a sizable space penalty for destroying a huge unique\_ptr-managed linked list (and similar recursive structures), but at least you'll avoid any stack overflows.
Nice job! I remember read something about Halley in the source code of an old global game Jam (2009 maybe, about ark, Noah or something like that). Is it?
I still prefer PascalCase for classes, but that is the first time I've seen c++ code that uses Pascal Case for functions (camelCase seems popular though)
Wouldn't he also need to implement copy/move constructors and assignment operations since the List class has a custom destructor?
In 2014 I had to develop a server-side marker clusterer. I decided to write it as a C++ binary which takes a list of JSON objects with geographic coordinates from stdin and writes a list of clusters as JSON to stdout. I used Rapidjson. Maybe I try simdjson just for fun.
TBB has a darn nice malloc implementation that could help you I believe.
&gt; A narrowing cast that does the right thing. clamp_cast will saturate output values at min or max if the input value would overflow / underflow. I don't think there's a inherently *right* way of implementing overflow. It depends on the scenario. 
I don't really have a personal preference, it's all about what you're used to anyway. I'm happy camelCase in the languages that use it, snake_case in C, C++. And half/half for languages like Python and Rust that uses PascalCase for types and snake_case for functions and variables. It's much more important to be consistent, and of course to be consistent you need to use the official style. I don't try to use the same style for all languages I write in
I swear, not a week goes by where I haven't looked at a piece of code and thought "this would be so much cleaner with Haskell's do syntax"
`clean` function can be greatly simplified: void clean() { while(head) { head = std::move(head-&gt;next); } } Also, it can be useful to make `pop` return a flag if the list is empty after poping or not: bool pop() { if (!head) { return false; } return head = std::move(head-&gt;next); } then `clean` can be simplified even further: void clean() { while(pop()); } 
*And the award for the best troll of the year goes to...*
Impressive! How many people are behind this project? Is it really one man show?
Is it capable of 3D?
Misleading headline, but Vinnie worked hard on this and should be commended.
Heh thanks.. although, mind you that I didn't write Asio's "stackless fauxroutines" that was Chris Kohlhoff. However, I will take credit for coining the term "fauxroutine" :) :) :)
Is this engine developed or forked by the wargroove devs? Did they select this engine after considering others such as cocos or godot?
That's actually good, because compiler can optimize `x + 1 &gt; x` which can not be done for unsigned types.
Yep, this was a troll but there's a actually a kernel of truth to it. These "stackless fauxroutines" are actually pretty amazing all things considered, I've been using them in Beast and they give you all of the benefits of writing code in a synchronous fashion but at no cost.
I strongly disagree with your understanding of noise. `libue` is noisy to me, because a lot of characters don't make sense to me and it's not a word I can understand. `utility_library` would be a lot easier to understand. There are also random `./` and chained `:` characters. Having something like `executable(name : foo, dependencies : libfoo, sources : *.cpp)` is a lot easier to read. I can read a lot of words per minute, and the length of the word only has a marginal impact on reading speed. What makes reading and umderstanding hard, is having to build a mental modell of the nesting of dependencies, i.e. the `:` elements and having to translate special names and characters into words that actually have meaning to me. You can write ultra short scripts in Perl, but quite a few people describe Perl as write-only language or executable line noise. Just making something shorter doesn't make something easier to read, you have to reduce the mental overhead while parsing.
We just checked. Boost without a pulse confirmed 
Why `clamp_cast` is not `constexpr` itself?
The only thing that has been confirmed (which we already knew) is that r/cpp has no sense of humor. Look at the downvotes on this thing. People really need to get out more and stop taking themselves so seriously!
std::forward_list Mini-rant: Just use the STL. Unless you are doing heavy optimization, the STL will for most cases will be better than anything you write. This is my problem with CS education. In calculus they make you do proofs to learn the rules of integration and differentiation, then you memorize a rule so you never have to do it again. CS classes should teach how algorithms work, and then tell you to use the STL and never write a linked list again. 
Mini-mini-rant the article specifically has a disclaimer in which it directs the reader to use the forward_list from STL. It also mentions that this is an exercise in implementing a linked list with smart pointers.
Travis CI was just bought by Idera and then got all its senior engineers fired, to be replaced with cheap labor. I would look for another service if I were you.
You will need to implement the copy/move constructors only if you want to be able to write code like this: alist = list; blist3 = std::move(list); 
Because there is some runtime code in it.
:(
I didn't find it. Just added `constexpr` and checked it on godbolt https://godbolt.org/z/1SPvK4. `clamp_cast` works in `constexpr` context.
I don't think this kind of misleading title is funny, especially on a non-humor subreddit, and I don't really want to see more like it. This is a grumble, not a moderator warning.
Those are pretty essential operations for a data structure. That's what's so frustrating about the rule of five, so much boilerplate! And the only alternative is to avoid writing a custom destruction, which in this case isn't doable since the recursive destruction causes a stack overflow. 
Do not post committee proceedings before the close of plenary.
It's the engine behind wargroove, looks like [chucklefish has a few programmers](https://chucklefish.org/about) 
This has nothing to do with the committee proceedings (note the time of the post)
I'm not a game dev, is lack of Vulkan support something people can overlook? I feel like it is critical at this age.
Very nice
Ugh.
Holy smokes this is huge. Didn't expected coroutines to go in, and modules... Wow! Congratulations!
I still think that `constinit` is a terrible name for that feature
Do you have a better name?
The difference is that if you indirect a `unique_ptr` or `value_ptr`, you can be certain that this operation is thread safe, as long as you have not previously created a raw pointer to the target. This is a property that does not hold for `shared_ptr`. Yes, of course you can't modify the same `int` or `string` simultaneously from multiple threads. But you can't indirect *distinct* `shared_ptr` objects simultaneously from multiple threads without assuring that they have distinct targets. 
Almost nothing commercial uses Vulkan. And certainly not as the only option.
The bikeshedding working group chaired by Tony van Eerd is still in session and can change anything, while *design* is complete, names are still up for grabs.
Any news on the zip range? Did it end up being fixed or is it 23 timeframe?
&gt;***TL;DR: C++20 may well be as big a release as C++11.*** It certainly seems that way. This is very exciting. I see that the next few committee meetings are in Europe. Just out of curiosity, how do you pick the locations?
This comment is not useful. What is ugh and why?
You missed `std::any_invocable`!
Do you mean commercial engines? I also didn't mean sole option, but as an optional... *option*?
Stuff I'm excited about that aren't my papers: - https://wg21.link/P1278 (an actually good offsetof) - Coroutines (and how they'll be merged with Core Coroutines in the future, but that's misty) - Reflection TS and what it'll do to pybind11 - https://wg21.link/P1306 expansion statements - https://wg21.link/P1328 a constexpr type_info::operator== - https://wg21.link/P0784 constexpr allocation YASS (although we're not getting the one thing we need to roll our own vtables when coupled with Reflection TS)
He's joking; there is no bikeshedding group.
This is awesome! I see a mention that modules were fixed, what was the exact fix to the majority of the complaints? Or were they left mostly unresolved and maybe we‚Äôll do caching or something at build time?
Paper number? Was it moved this meeting?
Rule #1 of the bikeshedding group: don't talk about the bikeshedding group.
We pick them based on who is willing to host.
P0288 -- sent to LWG for c++20
Exactly. Or, in a system with dynamically module load/unload, you can have the cli show only the features of the modules loaded in that moment. Thank you very much. I‚Äôm glad someone likes the design I chose: it‚Äôs been chosen carefully: it‚Äôs not an *emergent* design :-)
This looks like a lot of good stuff! Thanks! But: what happened to `std::mdspan`? Are we still missing a standard multidimensional view?
[Formerly known as unique\_function](https://wg21.link/p0228r3). Yes, just made it out of LEWG this week
Unfortunately not. It involves some tricky machinery in tuple that was too big and too subtle to do this late
A simpler/cleaner solution IMHO, is to leave the CMakeLists.txt simple, and specify the exact compile options directly from the command line. The CMake build types is reasonable list of presets, but if you know your compiler and the flags you need you can as well use the exact flags you want instead of trying to modify a CMake preset to your liking. I believe it also make packagers' life easier. &amp;#x200B; To specify the correct flags, you can specify \`-DCMAKE\_BUILD\_TYPE=None\` and then take the flags from the "standard" \`CFLAGS/CXXFLAGS=...\`, or you can use the CMake argument \`-DCMAKE\_{C,CXX}\_FLAGS=...\`. &amp;#x200B; Example: &amp;#x200B; cmake -G Ninja -DCMAKE\_BUILD\_TYPE=None -DCMAKE\_CXX\_FLAGS=' -O2 -g -Wall -Wextra -fcolor-diagnostics' .. &amp;#x200B; If you want to share these flags with your colleagues, it's way less work to put this understandable one-liner in a \`cmake\_configure.sh\` in your project or maybe this can be put in a CMake toolchain too.
Very true: we cannot create such a group until we decide what it should be called.
You can't fool us that easily. 
23
This is super exciting! Big congratulations! I only wish that C++20 gets a wide adoption as quickly as possible once its released.
There were a lot of disparate issues, and fixes to them are likewise very varied. Anything in particular you'd like to know about? There was a lot of talk about exactly how linkage and partitions behave and I believe they managed to nail that down (but I'll wait for the post-meeting mailing to see exactly what happened there). I also know a lot of issues got resolved by the paper authors merely dispelling FUD and stale information that people with issues had. It's been my impression the module spec is a lot more mature and complete than people who don't keep up with it think.
As soon as we decide on the right name for the group, we will make a group.
Did P1186 make it? It's not clear from the OP report.
Were the issues in the Modules TS that had been reported by basically everyone working on build systems evaluated, or was it incorporated as-was?
Ah yeah was curious about the linkage issues mostly (I think that was the main problem?). I‚Äôd love to hear more when the mailing goes out üòÅ
The minutes are unclear and incomplete (due to typing-speed constraints, I'm sure) and I'm not enough of an expert to piece it all together. That's precisely why I'll wait for the post-meeting mailing, hopefully authors find enough time to put the merged bits on digi-paper.
Can't access the `std::source_location` link
It's obvious the name is *Groupy McGroupface*.
It was accepted with modifications in EWG. It will go to Core in the next meeting.
Aside from anything else, what qualifies as "80's-style syntax"?
Is there still any chance to get std::generator type with coroutines in c++20?
&gt; std::ssize() free function that returns a sized size. A "sized size" ? Perhaps a "signed size" ?
The paper hasn't been released yet. You can find an old revision at the following link: https://wg21.link/p1208
P1144?
That's what I concern after reading the dead-on-arrival article, too.
My company still largely uses C++11 (in fact we were on GCC 4.9.X until very recently) so it's likely going to be a while before we see any of the new enhancements for the standard. Still, this is exciting stuff! Seems like C++20 is going to be a huge release! Me personally, I'm hoping Bjarne Stroustrup releases a 5th edition of "The C++ Programming Language" with the C++20 features, but I won't hold my breath :)
This was seen by EWGI. The minutes are not very clear but I believe the author will come back addressing the feedback mentioned.
Yes, signed size :)
k
Your link for operator&lt;=&gt; does not actually say anything about that operator. &amp;#x200B; In general, it's amazing how poorly presented this information is. You might as well have just said nothing because it's next to impossible to learn about the new features from the links in this post.
Isn't that the same link as above? This is the message I get with a login screen &gt; This site is intended for the use of the WG21 ISO standards committee and its invited members. If you require credentials to access this site, please see your national body representative or send email to wiki@edg.com. I mainly just didn't know what source_location and didn't immediately think to go to cppreference for its purpose. https://en.cppreference.com/w/cpp/experimental/source_location
They were evaluated; there was at a few presentations on how people have gotten it to work, and exactly what kind of support tools need from compilers, etc. Lots of discussion. My impression of the end result is that it's a challenge, but not an unsolvable one, and a so-called *QOI issue*. The speed concerns have been explored as well; Modules support both the "current" model of redundant compilation (go massively-parallel and don't wait for missing module-units, just do them lazily) and an efficient (but with a longer critical path) wait-for-your-deps model. Build tools are unsurprisingly asking for a `-M` equivalent for modules from compilers (which I expect they'll get in short order). If I have the situation correct, `import` directives can be the result of macro expansions, but other uses of the preprocessor are forbidden in the preamble, so you can *almost*, but not quite, use grep and sed to get the dependency tree - you still need to preprocess the preamble of modules, but you don't need a full C++ parser.
Sorry, fixed.
A little sad that executors and networking didn't make it. Hope their integration with coroutine will be better for C++23 time frame.
nice, thanks for the quick help :)
There was a long evening session about harmonizing expectations between modules and build systems that was attended by some prominent build system developers. The outcome was to create a Technical Report describing best practices for building modules.
You may take some comfort that given the size of C++20 your company may leapfrog directly to it instead of stopping by 14 and 17.
The joke makes sense if you use Asio
The information about \`operator&lt;=&gt;\` is currently in a ton of different places (original paper, and about 12 separate amendment papers) and you need to have invested significant time (and, at this point, been at the meeting) to know what the actual state is. Blog posts, talks &amp; compendium papers are in the pipeline. There's a way yet to C++20.
I barely got my workplace into C++14 (not to mention C++17...), and now we need to get into *this?* When will it end?! Joking aside, this is amazing and really going to change how we write C++, making the language easier to use while preserving performance, which is the main sale-point of C++. I know they were *just* merged, but can someone refer me to information about modules and coroutines: 1. What is the exact problem that the merged proposal tries to solve? What are problems that the proposals don't aim to solve and leave to library writers? 2. How do I write a module or a coroutine? 3. How does the merged proposal compare to similar features in other programming languages (e.g. Tasks and `await` in C#) I'm also interested in the merged modules design considering the issue described in the [C++ Modules Might Be Dead-on-Arrival](https://vector-of-bool.github.io/2019/01/27/modules-doa.html) post - were any changes made to ensure that compilation speed will not decrease due to ordering requirements? Last, as I find myself many times trying to read C-style structs from network sockets and files, it seems like that [Implicit creation of objects for low-level object manipulation](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0593r3.html) will finally make my code defined (without using `-fno-strict-aliasing`). Unfortunately, the paper doesn't contain the actual wording changes to the standard. To my understanding, now objects will be implicitly created at the same time as the underlying buffer, ensuring that `reinterpret_cast` returns a pointer to a valid object. Do I understand the proposal correctly?
Here's a better link https://en.cppreference.com/w/cpp/language/default_comparisons
The hope is that it will be not just "best practices" but include expectations from tools. Wherein we can get tools that all agree on common approaches to the processing of modules.
Given the versions mentioned I expect you're gonna have to take that up with redhat.
&gt;To my understanding, now objects will be implicitly created at the same time as the underlying buffer, ensuring that reinterpret_cast returns a pointer to a valid object. Do I understand the proposal correctly? Yeah basically. Some functions that allocate storage will implicitly create objects (memcpy, malloc, operator new, ...). If you create your own storage (e.g. std::byte array, you will need to use a library function to implicitly create objects into it).
I'd run into the issues even before that article, when I was trying to sanely build some modules in a project.
Yes. AFAIK there wasn't enough time and the authors hope that in C++23 we will be able to remove top level comma expressions in subscripting, since they will highly likely be deprecated in C++20.
I just wish that module names were tied to file names. That'd make things vastly simpler.
It's a little alarming after so much drama that modules are all of a sudden ready to be pushed into the standard.
IMO Vulkan-only actually makes a lot of sense. It's supported on Windows, Linux, Metal and Android. And while doing it (right) would likely be harder on the engine team than working with DX11 and OpenGL, they would at least be free to focus on a single backend.
The problem is that I'd already run into many of the issues in that article, plus novel ones, prior to that article being written. Either the build system needs to be pretty darn complex, or you need compiler support, or you need constraints on names. I'm still trying to figure out dealing with potential circular references in modules. While rare, there are situations that they could pop-up. Normally, a normal source file doesn't care at all - however, modules are effectively combined source files *and* interface headers, but without the niceties other languages have allowing for incomplete types to be resolved later. So far, the only solution I have is to use modules *and* supporting source files in those cases... and I'm really not fond of that.
What a joke. Did anyone try modules or coroutines in a project larger than a 'hello world'? It will be the same as it happened with std::async.
&gt; If you create your own storage (e.g. std::byte array), you will need to use a library function to implicitly create objects into it. I'm not sure I follow. I consider the following example from the proposal: char buffer[max(sizeof(int), sizeof(float))]; *(int*)buffer = n; // #1 &gt; The proposed rule would permit an int object to spring into existence to make line #1 valid From this example, I understand that allocating my own storage can be done using either a library function (`std::malloc`, `new`...), or as a regular variable on the stack, without calling a function to "implicitly create objects into it". If I understand the proposal correctly, objects will be created "on demand". From re-reading the proposal, it may be possible that I'm missing the purpose of `std::bless` (which may be the "library function" required in this case). When should it be used, instead of assuming objects will be "implicitly created"? 
can you grunt in a more specific manner?
You're right. You need the library function if you need to reuse existing storage IIUC.
I haven't been following modules closely, but the impression I got from the evening session was that the answer is your build system will required to support you. What's being made available is mostly just proof of concept, not what people will be expected to do now forever.
Reportedly, Microsoft and Google use modules internally on large scale. 
* Modules Might be DOA: refer to this [comment](https://www.reddit.com/r/cpp/comments/au0c4x/201902_kona_iso_c_committee_trip_report_c20/eh4rg0m), please. They are not, and the article has been taken seriously. 1) * Coroutines: there is not yet a merged proposal, but there is a sketch of a way towards serving also the Core Coroutines set of tradeoffs, best described in D1492R0 and D1493R0, which will be in the post-meeting mailing (lots of tables and jargon, and those papers are already *summarizing*). WARNING - LOOSE DESCRIPTION: The tradeoffs are effectively related to how the optimizer and the fronted conspire to make a coroutine frame and, depending on how that works, how you can control its placement. * Modules: A taster: minutiae of how you do them makes it easy or difficult to tool; there were linkage issues; there were partition and lookup issues around types and functions that don't have names; and interactions of exported inline functions that use non-exported symbols that may or may not be visible to ADL for code in other modules that transitively get imports. Deep stuff that you have to think about for an hour before you even see the problem, but fortunately we've got people who make it their mission to do so. Kudos. 2) Since those two are now close to final, blog posts will appear shortly. 3) Those languages have it easy since they don't care about using the heap, and can just do late-split without second-guessing themselves. C++ will let you do most things those languages allow you to do far faster and with more control; also, you can pass C++ coroutines as callbacks to C APIs, which is absolutely fantastic. As for comparisons, I think you'll have to evaluate yourself on your use-cases after the blog posts come out. Implicit object creation: you have the gist right. Wording has been discussed and will probably be massaged a bit more, but it's written, and will be in the post-meeting mailing. As far as I can discern, it solves the problem.
Now it is *any*_invocable? "any" suggests overhead similar to that required by std::any. Not what unique_function wants to be associated with.
That just means we will end up with mutually incompatible usage patterns and restrictions for modules based upon which build system you're using - msbuild, build2, ninja... and I don't see GNU make ever being able to handle this meaningfully without compiler support to generate the dependency lists (as it does for includes). I'm really wary of this. It actually has the potential to create distinct dialects of C++ based upon how modules are/can be used.
Really impressive feature list. I'm currently writing code which would benefit from coroutines (async computation, workflows: step1, step2, etc...). It there some advices to make actual code "ready" for coroutines when they will be available within my project?
No.
Thanks for the report.
Correct.
It would also make it completely impossible for build-farms to cache artifacts with different build-flags. Some companies have really elaborate build systems. Filesystem-based module-mappers have been discussed and will (at least to my reading of the situation) be implemented, at which point something like [evoke](https://github.com/dascandy/evoke) will just pick them up if you structured your project like you would python :). However, C++ is used in many ways, and closing the door on build units not being files at all was deemed a bad idea, let alone having a mandated file structure. Doing things by convention makes things easier, and not tying people's hands is awesome, and mandating something before we've really field-tested modules is a recipe for disaster.
I'm pretty sure he meant "hug" üòÅ
That's what the technical report is for. I believe the GCC poc actually used GNU make...
I usually handle that by using subdirectories indicating build flags, or using symbolic links at build time - you could even use overlayfs, the Windows equivalent I can never remember the band of, aufs, or equivalent when possible. Fixed name relations don't impact that *that* much. As I said elsewhere, though, being dependent on the build system to establish module semantics, acceptability, and use is going to fragment the language on build system lines.
This is just pointlessly hostile. You could say "Hey, the link to `&lt;=&gt;` you provided goes to something that isn't a description of that operator. Can you provide a better link?" ESPECIALLY since /u/blelbach is spending his time here for the sole purpose of helping present information to the community, and he would surely be open to friendly feedback.
Hugging is now the required payment for core wording.
Dialect is the wrong word, though if build systems can dictate requirements for modules beyond the specification, you can have source code that works under one build tool but not another. It also adds another potential level of ABI incompatibility due to the potential for modules being named in ways that are unexpected.
Yes, modules are widely deployed within Google and Microsoft using their respective versions. Apple did a successful test modularization using clang modules. And "instances" of Coroutines are deployed widely in Facebook and Microsoft. You can argue the respective modules implementations have no wide use, but the TS of a fairly straightforward merge of the two. And TS Coroutines have been around for ages.
Drama doesn't always reflect substance.
Warning: advice in that article is wrong, and the article is out of date (quite significantly). Doesn't contain fixes from [P1185](http://wg21.link/P1185), [P0891](http://wg21.link/P0891), [P1186](http://wg21.link/P1186) (wait for the mailing), [P1380](http://wg21.link/P1380R1) and a few other papers it's too late to hunt down.
Can someone explain the difference between `constexpr` and `constinit`?
Well, that is what happen when you are not there. I preferred mo_func
\&gt; Allow constexpr allocation, but disallow allocations that are not deleted at compile time. Well that was unexpected
I'm actually very about that. We need all asynchronous features to be tightly and nicely integrated and we now will get the opportunity to do just that
`ninja` doesn't "find or use modules". It is given build rules from a "generator" tool. Those tools will need to work with artifacts from other build systems. We already have mechanisms for this. `pkg-config`, CMake's `config.cmake` files, etc. Modules are likely going to be a set of extra data these mechanisms need to communicate about module usability of packages.
Was there any SG14 updates?
Someone thought it'd be a good idea to start naming erased types as `any_&lt;concept&gt;`where concept of the interface you want.
You can still write ninja build files or makefiles without CMake or pkg-config. How do I know that each of the build systems will make the same assumltions/requirements about modules and resolving them that won't lead to code incompatibilities?
Red hat/centos is by far the best Linux distro for C++ development. No other distro enables you to install the latest gcc which you can then build binaries that run on a vanilla install.
As it turns out, we write against the working paper, not random proposals that may or may not make it. 
That's why modules were "underspecified" in that regard, so the way you build on one system *doesn't* require source changes. And that's the way it's *always* been. To have to explicitly support each build system you want to use, whether it's a cmake file or a vcproj.
As long as you're not stuck on devtoolset-* and an ancient glibc.
\`constinit\` just requires that the initializer of the variable is a constant. This is useful so that you can require constant initialization and thus avoid problems related to dynamic initialization (requires guard variable, static order fiasco).
My feeling is that the main implementations are willing to provide sufficient tools for build systems and tools that can handle the build-time dependency discovery. The TR is where we can explore what would be useful for compilers to provide for build systems and tools that do not yet support that strategy (in addition to discussion of the support necessary for dynamic dependency discovery).
There is a place for standards that isn't WG21. Python is purely a community standard and it's insanely successful. Why can't build tool developers come together and hammer something out? WG21 has enough on their plate, and they can't police the community, even if they tried.
&gt; I'm still trying to figure out dealing with potential circular references in modules. While rare, there are situations that they could pop-up Ill-formed. Imports cannot create cycles. Full stop. &gt; Modules are more lax than that. I still have to run them through the C preprocessor just for lookups. Full preprocessing isn't necessary. It's just the easiest given the tools we have now. A smarter tool could, e.g., avoid expanding macros inside function bodies. But that is an optimization opportunity.
I really appreciate the thoroughness and detail in these reports. Thank you for preparing and phosting them.
Yeah, Google and MS could've used modules in their 'hello world'-scale projects. But I'm yet to see how modules look like in a large project, in code, and how it would affect compilation time (distributed compilation of course). As for Coroutines, try using them with std::weak_ptr. (inb4 weak_ptrs are no good - it's no good when one standard feature doesn't work with another)
POSIX make (not even considering GNU `make` extensions) supports what is necessary (see CMake's Fortran module support using Makefiles). The burden is on the tool or people *writing* that support.
Well if *you* don't see something it clearly can't exist. I'm convinced.
No love for arch? :( I like Arch more for C++ development.
`constexpr` variable is also `const` and can't be changed. `constinit` can be applied for non-`const` variables to make sure they are still initialized in the [static initialization](https://en.cppreference.com/w/cpp/language/initialization#Non-local_variables) step. As much as I understand, this guarantees they don't suffer from the [init order fiasco](https://isocpp.org/wiki/faq/ctors#static-init-order).
Sorry, was not meant to be a critique of the editors, merely a fair warning to people who might read it and find issues with the status quo that are now fixed. You guys do a fantastic job, and without cppreference I'd often be completely lost. I completely agree that it's mad to expect anyone to write against the current state and not the WP, otherwise the churn is just too much. But since Kona *just finished*, I thought giving fair warning HERE was appropriate.
What assumptions and incompatibilities are you thinking of? Is this any different than, say, expecting `-l` to not accidentally find wrong libraries (e.g, shadowing copies, wrong architecture, different ABI settings, etc.) due to other broken `-L` flags?
P1484. Working on it. Cannot require it in the IS because it's not a thing that the standard talks about (same as header files), but can suggest it in the SG15 / Tooling TR. 
As a C++ dev that knows almost nothing about game development, I found this source code to be fascinating read.
Does C++20 have a tagline? I can imagine something like "Rust remover" being quite effective.
What do you mean by indirecting a ```unique_ptr```? Can you provide a specific example of what an indirect ```unique_ptr``` is? &gt;as long as you have not previously created a raw pointer to the target. What is the significance of doing it previously vs doing it after? Without a specific operation it's hard to know what exactly you're claiming is thread safe about a ```unique_ptr``` vs a ```shared_ptr```. Can you provide a specific sequence of operations that's thread safe for one but not thread safe for the other?
Hooray for [std::format](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0645r5.html)
I use Fedora personally, but building binaries that aren't distro-built is usually made much easier by Red Hat's devtoolset SCLs which allow you to build with GCC 7 but use a 4.8 standard library.
Yeah, there have been multiple (non-standard, obviously) implementations of modules used in production systems for years. 
Main issue is exemplified by `constexpr std::vector&lt;std::unique_ptr&lt;int&gt;&gt;`. If you want to bake that into ROM, you can't, because while std::vector has transitive const, and so you can't get a non-const `unique_ptr&lt;int&gt;` out of it, `unique_ptr&lt;int&gt;` is a pointer to a *mutable* int, which is in ROM. Boom. Fixes sought.
Does someone know whats going on with (constexpr) code injection? I saw a cppcon talk by Herb Sutter once where he talked about that feature. 
there goes Networking for 2023 or 2026.. owie.
Don't start - there was a discussion in Evolution on pointy_mcpointface.
Only three of the GAFAM has been using it. Not enough!1!
Hoe Lee Sheet
I am hoping that we can nail down expected use cases in the TR well enough that compilers can opt-in and claim they support "simple-mapping" or "module dependency scan" and have that mean something. Despite appearances, compiler implentators are not actually hostile to their customers. 
&gt; ‚Äúlots more constexpr‚Äù: broad use of normal C++ for direct compile-time programming, without resorting to template metaprogramming That is weirdly the most understandable, concise explanation of contexpr I've seen.
Most of this is clarification on facts, details, QoI choices and what the actual user experience will be. Some current compiler API designs are very cruel to tool implementers, and some suggest that tools should not even try but instead just tightly integrate with the compiler to use its frontend. That's ridiculous for many, of course - companies have frontends already, and invoking 70000 compiler executions will be slow compared to parsing 70000 files directly. 
Can you clarify that this is a problem with the proposal, or a problem that the proposal fixes?
There was a last-minute paper created to define what it means, so you'll need to read that one. P1498 - which is not on wg21.link for obvious reasons. Probably will be first public in the post-Kona mailing.
That is coming probably, but not right now. We don't even have reflection! If you're lucky it will land in C++23, but not before.
I am not upset, I am not sure what should be the model, but I am pretty sure that my experiences with Asio make me hesitant to have that as "the way"
It's a problem that they (for now) preempted by not allowing such allocations to live until runtime. It still needs a solution in order to support the stuff in parentheses.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/h_n] [C++20 Design Is Complete: Modules, Coroutines in C++20](https://www.reddit.com/r/h_n/comments/au0mne/c20_design_is_complete_modules_coroutines_in_c20/) - [/r/h_n_best] [C++20 Design Is Complete: Modules, Coroutines in C++20](https://www.reddit.com/r/h_n_best/comments/au1fdr/c20_design_is_complete_modules_coroutines_in_c20/) - [/r/h_n_top] [C++20 Design Is Complete: Modules, Coroutines in C++20](https://www.reddit.com/r/h_n_top/comments/au0n61/c20_design_is_complete_modules_coroutines_in_c20/) - [/r/hackernews] [C++20 Design Is Complete: Modules, Coroutines in C++20](https://www.reddit.com/r/hackernews/comments/au21ml/c20_design_is_complete_modules_coroutines_in_c20/) - [/r/latexandloaf] [C++20 Design Is Complete: Modules, Coroutines in C++20](https://www.reddit.com/r/LatexAndLoaf/comments/au129s/c20_design_is_complete_modules_coroutines_in_c20/) - [/r/programming] [2019-02 Kona ISO C++ Committee Trip Report (C++20 design is complete; Modules in C++20; Coroutines in C++20; Reflection TS v1 published; work begins on a C++ Ecosystem Technical Report)](https://www.reddit.com/r/programming/comments/au1ie3/201902_kona_iso_c_committee_trip_report_c20/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
&gt; A smarter tool could, e.g., avoid expanding macros inside function bodies. But that is an optimization opportunity. How do you identify a function body? ``` #define BEGIN_FUNC(name) void name ## _func() { #define END_FUNC } #define MADNESS \ } \ void foo() { BEGIN_FUNC(foo) MADNESS END_FUNC ``` is valid. 
So, as I can see it can be emulated by something like this? ``` int x = [] { constexpr auto v = f(); return v; }(); ```
Hi, I saw this on a thread on /g/. Some people there (who have an irrational hatred of this website) were wondering why the committee chooses this subreddit as an official communication channel over a mailing list or official website. Thanks in advance for your response.
No, because you have no guarantee that the lambda itself is evaluated as a constant :)
I read through five or six of the links he posted. None of them clearly explain the new features being added. I'd rather he post nothing than waste my time linking to pages written be people who are incapable of communicating in the english language. 
Cool story bro.
Yep something like issues with modules or coroutines - they clearly don't exist because you don't see'em.
Understand what you said. Still that means another 3 years without a standardised way to do networking. As Bjarne suggested that we shouldn't wait for the perfect design but prefer an incremental approach.
Wait, \`any\_invokable\` implies that it can store almost any invokable object but \`unique\_function\` explicitely forbid copy-only objects... &amp;#x200B; Looks like \`any\_invokable\` is totally misleading here?
Does anyone know if CWG #2333 is resolved? (discussion about it [here](https://github.com/sg16-unicode/sg16/issues/30))
Yes, but none of that madness can expand to either an `import` or `#include` and can be safely ignored for dependency scanning purposes. Function body was merely an example.
Thanks for the clarification!
This isn't an official communication channel. It's a collaborative report created by a number of committee members. Our data for CppCon and C++Now's websites shows that the majority of traffic comes from Reddit referrals. We post things to Reddit because this is where C++ programmers look for news on C++ evolution.
Ok, thank you for clarifying. I will pass it along.
Aside from being a childish counter (non) argument, they actually *don't* exist if they weren't presented. And I trust the ability of the committee to poke holes in these well founded and long explored solutions than a random on the internet. I await your paper raising issues no one thought of before for Cologne to fix things before it's final.
Although, I guess you could mark the lambda with `consteval`. I think that would work: int x = []() consteval { return f(); };
This is not really true. There's a lot of interest in asio from committee, and asio will continue to exist in TS and standing library form. Until the TS makes it in to the IS, users will have a semi-blessed implemention available in many forms.
flatmap originally came from SG14 iirc.
How so?
Wow, interesting!
See [https://wg21.link/P1342](https://wg21.link/P1342) for one potential direction for merging Core Coroutines with Coroutines in future.
Actually, I'm not sure that an `import` statement can't be synthesized from macros. For header unit imports, the `;` cannot be a macro expansion, but I thought it applied to normal `import` statements as well. I'll ask around.
&gt;/g/ What is \`/g/\`?
`static constexpr` /s
But I think there was some question as to whether we could pursue this path.
I would also like to know.
We do our best to link to descriptive papers, but that's not always possible, as they don't always exist.
Yes, this paper was indeed a hypothetical design direction rather than a concrete proposal. There are indeed many other potential directions to take in this design space.
For those following at home, mathstuf is the person responsible for presenting to WG21 how cmake will support modules.
It's the technology board on 4chan
I mean shipped games. Most new games on Steam don‚Äôt use, or offer, Vulkan. OpenGL/D3D are fine. Vulkan is also fine and some games use it. But Vulkan is definitely not critical.
Move onlyness was not removed -- yet. Keep in mind you can always "move" by copying, so copyable targets are still supported -- it's the container itself that's move only.
&gt;Almost nothing commercial uses Vulkan. yet. It's more that the modern graphics API's are still in relative infancy and most people that want to use it (engine makers) either don't need the extra power or is used in a large product as a side option (for now).
4chan/g/ ?
odds are they'd use DX12 too anyway. I'm sure it'll gain more usage over time but it's not critical atm, especially for the vast majority of indie-level games. 
Maybe... module partitions could solve that circular problem?
Well, I'll just learn all that over the weekend and then ace the interview Monday.
My only gripe is naming the co-routine ops `co_await` and `co_yield`. I like my types to be single-words only. `await` and `yield` just like python or nodejs javascript would do just fine. And I know it's because of this mistake here: https://en.cppreference.com/w/cpp/thread/yield If I could, I'd band together a twitter mob to beg the committee to rename `std::this_thread::yield`to something else so we can have those op names more natural.
I already use an implementation of the proposed `unique_function` in a game, but thanks reminding me that copyable-only objects can still be stored.
Modules, coroutines. Modules: I think an implementation that addresses the problems and proves that it works should come first, not be relegated to a TR later. We should have the proven build systems, faster builds, good solutions for the problems that have been raised _first_ and _then_ standardize. We don't. Coroutines: I want the functionality, but similarly, I think we should have an implementation that addresses the Core Coroutines concerns first, and then standardize. If the committee were willing to make breaking changes then it wouldn't be such a big problem; mistakes could be fixed. But it isn't, so everything has to be perfect from day one, with vanishingly little ability to fix it later.
I've just been to a terrible terrible place...
Wow. Get over yourself.
I don't want perfect, but I am not a fan of Asio. What is easy in every other language, it makes hard. 
How are the issues mentioned in http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1427r0.pdf resolved?
I never programmed in rust, but rust lifetimes are much better than C++ ones. Use-after-free, Use-after-delete, and data races are impossible (in non-unsafe bloc) in rust as far as I understand. And they still have better macros.
mo\_func, mo\_problems :v
Yes, it's already in the queue. It was just waiting for the TS to merge.
Jeeze, the name of it does not match the menaing at all. I hope they fix that before it get stuck in the language for generations to come.
I‚Äôm not sure Vulkan isn‚Äôt a swing and a miss. Rearchitechting for Vulkan is hugely expensive. The *best* case is you squeeze a little extra juice out. But the opportunity cost is huge. Drivers make things harder, if not impossible. Nvidia and AMD have been optimizing D3D and OpenGL drivers for 20 years. They have centuries, if not millennia, of effort behind them. Doom is the only game off the top of my head that has better performance with Vulkan. They also had an army of Nvidia employees dedicated to the project. Windows uses D3D. Mac/iOS uses Metal. Consoles use proprietary flavors. Linux is irrelevant and doesn‚Äôt matter. (Sorry, but true). If you gave me even odds I‚Äôd bet $5 that Vulkan will never be relevant. I don‚Äôt think it‚Äôs delivered any of its promises. Which is sad because graphics drivers are a total mess and I was hoping Vulkan would improve things. üò¢
nothing you said is incorrect, but it all applies to DX12 and Metal as well. The only difference is that Apple is forcing whoever doesn't jump ship to use theirs. I'm sure the same will happen to D3d11 and OpenGL one day, but far, far into the future (like a decade+). Unless you mean some implementation details? I'm not super saavy in Vulkan yet, but is there something about it compared to DX12 that is almost objectively inferior?
Sometimes you need drama to reveal the substance.
\&gt; Coroutines (and how they'll be merged with Core Coroutines in the future, but that's misty) looks like they won't be? \&gt; We looked at all of the various coroutines proposals, and held an educational evening session. EWG decided once again to move forward with the TS. &amp;#x200B; &amp;#x200B;
DX12 is in the same boat as Vulkan :( &gt; Fact is very few of anything need that much power out of the GPU at the moment. Nothing commercial at least; maybe some interna I‚Äôm not entirely sure why you‚Äôre saying this? Every 3D could benefit from faster rendering. Especially in this age of high refresh monitors. I want all my games to run at 144Hz! eSports players want 240.
AFAIK... Google uses clang modules at scale and LLVM is partially modular. But Microsoft used minimally modules, and no longer uses them.
So this `static constexpr std::vector&lt;int&gt; ints = generate_ints()` will be ill-formed? I mean, constexpr allocated memory can't be promoted to static storage?
Indeed! Anything that saves us from `&lt;&lt;` poisoning is a good thing, and long overdue. My only nitpick is that we don't seem to be able to override the thousands separator, but are stuck with whatever the current locale has, unless I am mistaken (and I very much hope I am).
I meant more in the context of this post. Vulkan would be overkill for something like Wargroove, for instance. But also, in terms of man hours/oppurtunity cost. As it is now, it'd be very hard to convince publishers and the like that the payoff is worth the work needed. Not unless we're talking about fields in high performance computing (most of which are B2B anyway) &gt;eSports players want 240. geez, didn't know the demand got that high nowadays.
One of the things the secret bikeshedding group does is look for name collisions in the wild. In the case of yield a *lot* of computational finance people use C++ and yield is a popular type name there.
&gt; I want all my games to run at 144Hz! You must have bionic eyes and matching brain.
C++20 is shaping up to be *much* larger than C++11. This is a first world problem but I actually think it will be a heavy lift for implementers to get this built and for users to get a chance to metabolize these new programming models before 23 rolls around.
I wonder if `auto` caused any troubles when it was introduced. Even so, CTRL + F and Replace &gt; Entire Project I just saved C++ 
&gt; Still that means another 3 years without a standardised way to do networking. 3 years is probably quite optimistic. I wouldn't be surprised if it took until C++29. And since everyone will have moved to TLS by then for pretty much everything it will remain practically useless because we are not going to see TLS anytime soon.
Newbie question: is this just fmt in the standard library or is it something different?
`auto` was a keyword from the start, so there was no existing code to break :) Unfortunately it's not as easy as a find+replace.
It's fmt minus fmt::print and co.
Yes exactly.
&gt;the name of it does not match the menaing at all. It does? It requires a variable to have a constant initializer.
Do you know if there is already a proposal?
and we are back to 1995 gentlemen
Hmmm, so it has the type-erasure of std::any, but not the overhead (by not being copyable) Maybe the name is OK
We were so close to a beautiful C++20 
How many years of C++20 experience are they asking for, probably 5?
We have "constexpr int x" and "const int x" and now we will have "constint x"? Surely you have to agree that the naming of that is painful. Yes, there is a technical diffirence between them all and has good reason to exist given what someone who really knows the languages knows. Thing is, for most people who work with the language they will have no idea what the difference is.
Blech. EDIT: Yeeesch
Oh that's disappointing. I was looking forward to do something like: `static constexpr my_regex re = make_my_regex&lt;"foo|bar"&gt;();` and have the regex bytecode generated at compile time.
I mean, as long as `make_my_regex` doesn't allocate, you're good.
How about module, import &amp; export?
Good question. And why couldn't yield await to be contextual. Dunno.
Holy shit, so much problem just for the fucking case, that is cargo cult on steroids. 
https://www.youtube.com/watch?v=2dDuX5zqNEs
Modules. At long last 
Check P1433: compile time regular expressions.
pybind23?
pybind23?
They could just use `yeild` instead! Half the time I spell it like that anyway.
But, still networking is left outüòê, as far as i know, they were gonna add something like boost.asio to C++20
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/au5fur/c_scrub_needs_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
That was a plan, not a promise.
Oh, my bad. Dude, can you help me out? Can you please tell me some users of this sub, that have a decent experience with boost asio.
There was much discussion on this at the meeting. The decision has been to write a Technical Report which outlines guidelines for compilers, build systems, and so on related to modules. This can be published under ISO as an official document, but is not part of the C++ standard.
No, they can't. Partition imports are still imports and therefore cannot be circular.
Still won't work because you can constant-initialize types that aren't literal? I think?
&gt; Modules We have solutions (see D1483). Clang/LLVM has seen faster builds even with implicit modules (known to be inferior to explicit modules) (see P1482) There are some missing pieces for complete implementation of explicit modules, but I'm working to have them available by the major compiler vendors. The build strategy is shown to work by CMake's support for Fortran modules (which is, in some ways, harder since there can be multiple equivalents to `export module X` in a single TU there.
There is an auto-generated version of Networking TS (based on ASIO) available on GitHub. It works fine and won't need you to modify code once C++23 arrives: https://github.com/chriskohlhoff/networking-ts-impl
`staticinit`? 
There's the slack on cpplang if you want look at boost-users Nd beast channels
Sigh *unzips*
It's amazing but work on documentarion and education is very important...
or just find&amp;replace in all files
&gt; It works fine and won't need you to modify code once C++23 This is categorically untrue. The TS is in `std::experimental`, for example. Also, it is highly likely that aspects of the design will change before it is in the C++ standard. We absolutely do not guarantee that TSes will continue to be supported, or that we will consider compatibility with the TS when we merge into the C++ standard. It's spelled `std::experimental` for a reason.
Fixed.
Will std::ssize be available for all STL-containers?
What name would you suggest for requiring *constant initialization* (That name is preexisting). The Clang attribute is called `require_constant_initialization`
To pick a nit - the whole point is that `make_my_regex` is allowed to allocate, as long as all all the allocations are freed by the time it returns, and the only non-dynamic memory is owned by `my_regex`.
Yes, you are right. I just meant, that its closer in terms of naming, then the original ASIO. 
Not yet. I proposed some wording for it a little while ago, but it needs more work. On my list of things to resume in the not too distant future (I wouldn‚Äôt mind if someone beats me to it). 
o.O I know this feature well, it came out of my study group and I've been helping to shepherd it along. I missed the rename this week.
Seems like a lot of networking will likely change with executors.
Link has been changed to cppreference.com
It does enforce constant initialization.
If you want a note about it added, propose a diff to the post and tell me what section to apply it too.
I think they will probably be passed as optional arguments to templated generic functions. So code with and without executors will look similar. 
If you want a note about it added, propose a diff to the post and tell me what section to apply it too. Or /u/jfbastien can do it.
Also I spoke with the SG20 chair about this a bit.
We had to trim non-transient allocations for C++20, unfortunately. However, I expect they‚Äôll make it back soo thereafter. Also, there are more constexpr extensions in the pipeline (well, ‚Äúmy pipeline‚Äù, that is).
Currently overriding the thousands separator can be done either via locales or writing a custom formatter but we can add a new specifier to make it easier in the future.
It also integrates chrono formatting: [https://wg21.link/p1361r0](https://wg21.link/p1361r0)
module and import are contextual, and export has been a keyword since 1996 (Stockholm).
I like the idea of \`std::ssize\_t()\`, but I'm worring about the return type of that type. \`std::ptrdiff\_t\` is too ugly to type. Maybe it is time to introduce POSIX \`ssize\_t\` type for C++20. [https://cplusplus.github.io/LWG/issue2251](https://cplusplus.github.io/LWG/issue2251)
Thnks a lot again :-)
The issue is that of ‚Äúlinkage promotion‚Äù. E.g., if a module interface unit contains an exported inline function that calls a non-exported internal-linkage function, the internal-linkage function had to have its actual linkage ‚Äúpromoted‚Äù. However, that caused ABI problems. We came up with a set of reasonable constraints to avoid such situations (centered around a notion of a ‚ÄúTU-local context‚Äù).
I believe so.
Pybind20 That is probably going to be a fork, because maintainers of pybind don't seem to have enough time for the project.
Don't tell me you're one of those people who thinks the human eye can only see 30fps.
Sure; it's important that people don't think that TSes are something we provide backwards compatibility with.
If ‚Äúauto‚Äù is replaced by ‚Äúint‚Äù, you do actually have that guarantee. (With ‚Äúauto‚Äù,, you might end up with a no literal type or and non-constexpr conversion.)
[removed]
To be clear, although the main problems were things like vector&lt;string&gt; and vector&lt;unique_ptr&lt;int&gt;&gt;, we cut out _all_ non transient allocations to leave the design space for a comprehensive fix open. So no ‚Äúconstexpr vector&lt;int&gt; x = ...;‚Äù either. Same for string etc. 
See http://WG21.link/p1420 
Wow, looks great, thanks for all the hard work! Regarding [*Monadic operations for std::optional*](https://wg21.link/P0798), does that mean that (currently?) there's no effort to get a *unified* non-member function interface for monadic operations? 
The standard committee considered \`printf\` syntax as an alternative and voted overwhelmingly in favor of a Python-like one.
I think the `toolchain` approach is cleaner. Keeping wrappers like `shell` scripts or even `makefile` to hide this information, doesn't offer much, not to mention the complexity added with CI. Also it's very hard to keep a common build policy with different repositories. 
&gt; Rearchitechting for Vulkan is hugely expensive. The best case is you squeeze a little extra juice out. But the opportunity cost is huge. If you're making a new engine, you should be designing for the API from the bottom up. No architecture changes involved. On top of some performance, you'd get to ignore the idiosyncrasies and bugs of the old driver model. That's the main advantage, as far as I'm concerned. &gt; Drivers make things harder, if not impossible. Nvidia and AMD have been optimizing D3D and OpenGL drivers for 20 years. They have centuries, if not millennia, of effort behind them. What are you saying about drivers? Vulkan and DX12 drivers are slimmed down, massively. While tons of resources have gone into OpenGL and legacy DX drivers, they're still a hot mess. Creating an engine for the light weight APIs is more work, no doubt, but engine makers also get to sidestep a lot of the busywork that the fat old drivers needed, just to run efficiently. &gt; Windows uses D3D. Mac/iOS uses Metal. Consoles use proprietary flavors. Linux is irrelevant and doesn‚Äôt matter. (Sorry, but true). 75% or so of our phones run Linux. 88% of global sales in january. If any platform is irrelevant, I'd nominate Apple. But [Vulkan runs on top of Metal](https://github.com/KhronosGroup/MoltenVK), so.. &gt; If you gave me even odds I‚Äôd bet $5 that Vulkan will never be relevant. I don‚Äôt think it‚Äôs delivered any of its promises. Which is sad because graphics drivers are a total mess and I was hoping Vulkan would improve things. üò¢ It's here, supported, and currently [being adapted](https://en.wikipedia.org/wiki/Vulkan_(API)#Game_engines). Godot is shooting for Vulkan [in their next iteration](https://godotengine.org/article/abandoning-gles3-vulkan-and-gles2). I think there's huge potential for a lightweight engine that does Vulkan only, and gets it right. Porting a rendering engine that isn't built for it probably isn't worth the effort, though.
Interesting. I can't wait to check it out :)
Thanks, please send the link for the same
And that is the real problem c++ has: Inertia.
cpplang.slack.com
Yes. And C arrays as well.
Arch does make it easy because it's always on the latest compiler.
&gt; odds are they'd use DX12 too anyway Why? I can't see any reason to use both, unless DX12 is required for some console.
Xbox is locked exclusively to DX series. So Dx12 if you're insistent on modern rendiering. But Xbox one may not be as important a target for an indie dev.
We are loyal fans of [fmt::](https://github.com/fmtlib/fmt) we don't need to switch sides
&gt; In the case of yield a lot of computational finance people use C++ and yield is a popular type name there. I hear this argument a lot but `long`, `short`, and `return` also are extremely common financial words ;)
To my knowledge, no paper has yet been submitted proposing generator&lt;T&gt;. Although I believe someone has been working on one.
The problem started with the naming of constexpr which conflates constant and "usable in compiletime evaluations" and it went downhill from there.
&gt; we can add a new specifier to make it easier in the future. Yeah, it would be really nice to be able to choose a separator as freely and easily as it is for the filler character. It feels like a similar kind of thing.
Imho c++23 will be just like c++14 (lots of small tweaks, bug fixes and improvements) + reflection, so I think it will be fine. 
&gt;"constint x" It is `constinit x`
None of them use the hybrid that went into c++20 though. 
Most importantly, it was a keyword that literally did nothing as it specified that a variable would be block scoped instead of static, which is true of any non-static variable.
Did you expect the authors to write up a tutorial for all the features in the few hours since the meeting concluded? Those are links to the technical papers from various people that have been discussed and or merged into the standard.
That might actually be not so bad an idea (waiting till early 2020 that is). It is one thing to document features that are stable or in a published TS, but publicly documenting things that are very much in flux and can't yet be used anyway seems like unnecessary work.
Rather "Rust failing catch-uper".
Is there some "Transition from includes to modules" article? It's unclear how to handle non-loop constraint, how to merge and re-split existing TU+header code etc.
Those are existing keywords. The concern here is about existing code using yield as an identifier, and system calls named yield.
/u/EricWF is supposed to be.
This will be covered by the C++ Ecosystem Technical Report.
In "P0593R3 Implicit creation of objects for low-level object manipulation", example 2.1 is UB. If i were to placement new the ints , is p-&gt;a still UB because there is no X object to dereference?
Are you mixing up CMakeLists.txt files and toolchain files? The explicit purpose of toolchain files is to provide a consistent set of compilation flags for all your cmake projects. 
That's rather worrying. No usage experience anywhere?
Or make yield/await identifiers with special meaning (like override/final etc) ?
Please don't use link shorteners as they infuriate reddit's spam filter. I've manually approved your comment.
No, I don't, but I do think that 144Hz is good old fashioned snake-oil. A parallel are so-called audiophiles, they can hear the difference between a cable with gold-plated ends and one with ordinary metal ends [connectors] (whatever that is). Chickens on the other hand seem to be able to see over 50-60Hz. Iff you want your chickens relaxed the fluorescent tubes need to run at least 100Hz [or just install led of course].
I waited to to get in C++20, I do no want to use ASIO relying on Boost since it's way too heavy for my needs.
&gt;without the niceties other languages have allowing for incomplete types to be resolved later. Would you mind explaining what an import cycle could break and what are those niceties? Are they possible to add to c++? 
Are there any updates on the pattern matching proposal ([https://wg21.link/P1371](https://wg21.link/P1371)). I am interested to learn what was the reception from the committee (if it was at all discussed this meeting).
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/au0c4x/201902_kona_iso_c_committee_trip_report_c20/eh60mzs/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
* The vtable is a jump table. Given that it is one, I'm not sure what other thing you expect. * It is possible to be faster than a jump table for small (\~4) number of alternatives. The mpark version of variant achieves that (see [here](https://mpark.github.io/programming/2019/01/22/variant-visitation-v2/) and [here](https://www.reddit.com/r/cpp/comments/ag7l5b/mparkvariant_v140_release_support_for_switchbased/)) * If you don't disable exceptions, than you can't guarantee that the variant won't get into valueless\_by\_exception state. So the compiler will have to check for that. * If exceptions are disabled the extra check isn't required. But libc++/mpark/libstdc++ don't seem to optimize that. Even though supposedly [\#30](https://github.com/mpark/variant/issues/30) is fixed but the branch isn't optimized away [https://gcc.godbolt.org/z/fNCL4r](https://gcc.godbolt.org/z/fNCL4r) .
Ah! I might have read the assembly wrong. I thought it called the vtable location, and from there called the proper implementation, thus doing two jumps. What I hoped for wad to have only one jump (so this what is happening now, I guess) or maybe even inlining the two implementations at their call site so that that one jump can also be avoided. Is there a way to indicate to the compiler that none of the types in the variant will ever throw (and `valueless_by_exception ` will thus never happen), or is the only possibility to pass the appropriate compiler flag to turn off exceptions in the whole program?
What I appreciate is is that C++20 is oriented towards core languages enhancements, rather than to some library enhancement. eg. concepts, contracts, coroutine, modules, and these will allow anyone to build better libraries. Therefore, networking is not a problem IMHO
Of course if you are on C++17 you could use a generic Lambda instead. 
I hope that most of the approved, but not yet merged parts make it into c++20. In particular format, expansion source location and stack_trace would be great.
That is amazing news. I wish they were the other way around from the beginning (size &amp; usize, etc.), but this fix is better than nothing.
how are you going to contextualize it? ```yield value;``` can be either a yield from a function, or a definition of variable named value of type yield, and there is no sane way the parser can disambiguate that. The only real way to do so would be to only consider "yield" as yield statement in a function that returns generator type, but that is stretching the parsers capabilities quite a lot.
Thank you for the effort. Great work. 
The final design hasn't even landed in the working draft yet - let alone any compilers or build systems. How should one give an answer to that that is better than guesswork? As a c++ programmer you should distrust any performance claims that are not backed by actual measurements.
&gt; What kind of speed-up can I expect with respect to PCH? Unknown. On the other hand, it should be more *convenient* and *automatic*. &gt; Will it strongly depend on quality of implementation and/or build system used? Most likely. I would also expect it to improve over time as build systems and compilers gain more experience with what is permissible, and what is not. &gt; Related: will modules make the header/source split obsolete? Yes; a single file can now selectively export only a handful of symbols. &gt; It would be nice to have a logical piece of the library sit all together in a file, like in (all?) other modern languages Actually, like in Java, a single module can be defined across several files. This allows creating large modules without having unwieldy files.
Probably once they learn to inline through jump tables.
It's the global modifier for Perl regular expressions. You should know! (just kidding, I don't know the poster meant.)
"it depends on the quality of implementation" is a valid answer (I even listed it in my post), but I don't agree that, in principle, it's the only one possible. &amp;#x200B; Extreme example: if clang's implementation were known to give a factor 10 compilation speed-up over PCH to template-heavy code, the answer could be "probably much faster". Or maybe it could be the fundamental working principle of modules itself that is, by design, a faster procedure -- I don't know, that's why I'm asking! :)
Thanks! &amp;#x200B; &gt;Actually, like in Java, a single module can be defined across several files. This allows creating large modules without having unwieldy files. Yes but it does not *have to*, that's the thing. Once you eliminate the somewhat artificial (especially when templates come into play) split between header and source files, you can have the physical splitting of your module reflect logical splits in functionality, *if any*.
Is the dot operator dead? I hope a crazy person doesn't lock everyone in the Cologne meeting until it gets into C++20. [https://isocpp.org/blog/2016/02/a-bit-of-background-for-the-operator-dot-proposal-bjarne-stroustrup](https://isocpp.org/blog/2016/02/a-bit-of-background-for-the-operator-dot-proposal-bjarne-stroustrup) &amp;#x200B;
The current best case scenario is: * It's actually possible to implement modules * They are not too much slower than PCH
That's what the empty CMake build type is for. You use it either with `-DCMAKE_BUILD_TYPE=''` or by not specifying `-DCMAKE_BUILD_TYPE` at all. &amp;#x200B; You were mislead by the `CMakeCache.txt` comment which has for `CMAKE_BUILD_TYPE` the following: &gt;//Choose the type of build, options are: None Debug Release RelWithDebInfo &gt; &gt;// MinSizeRel ... `None` in this case doesn't mean "None" as value, but nothing :) &amp;#x200B; Starting with CMake 3.11 you will get the build type `None` and you will get all the `CMAKE_&lt;LANG&gt;_FLAGS_NONE` variables. Which might not be what you want.
Performance always depends on QoI (including performance of pre compiled headers). It usually also depends on input data (I.e. what exactly does your code look like, how is it structured, is it spread over a lot of files or everything in a single). Even with the final spec in the hands of the compiler writers, there are most likely different implementation strategies etc. so I'd really be very careful about any estimates made for now. Also, you are not just asking, if they will be faster or not but also by how much...
I agree, but hopefully you can change the name to your liking: template&lt;class T&gt; using sp = std::shared_ptr&lt;T&gt;; typedef uint_fast64_t uint; #define var const auto
Sounds like an off by one error to me.
i get a 404 error with this link
Nice catch! Thanks. At least it works sometimes ;)
There is one in the Build2 manual but I think it might not match the current modules proposal. Anyway it exposes several strategies to progressively transition and also how to handle both for the same code (I think that will be superseded by `import &lt;header&gt;`
We discussed pattern matching (https://wg21.link/p1371r0) in EWG after the plenary session on Saturday. I would say it was very well received, the committee is largely in favor of the general direction of the feature.
&gt; This is a bad idea to me. As pointed out in the article you have to fight against the way unique_ptr works and implement custom manual creation and deletion code Do you have an idea for a way to implement a linked list container that doesn't require you to "implement custom manual creation and deletion code"? &gt; The user of the list shouldn't have to manage the list's memory, but the list implementer should be able to handle the manual memory management. I agree with the first part, but your second point is unclear to me. Do you mean that the user should be able to manually allocate the memory used by the list and the implementation of the list should have to be able to handle that? Why would that be useful? How could that be implemented safely?
Right, thanks for clarifying :) Wouldn't the constexpr catch non-literal types?
Indeed. Modules are THE thing I am looking out for in C++20. It's going to create a mess in the commit history, and it's not too clear how to best repackage old 3rd-party code that's still in the header/source format, but even if there's no performance improvement the clean-up should be worth it. No more `details` / `Private` namespace! No more anonymous namespace! Life is gonna be great!
I see you've added those constructors to the article. I think you could simply use the defaulted move constructor: List(List &amp;&amp;) = default; You skipped the assignment operators though. They're simple though: Move assignment can be defaulted, and copy assignment can combine copy construction and move assignment. 
[I forgot how mobile friendly godbolt is](https://i.imgur.com/zszOqgz.jpg)
This is an impressive list of upcoming updates. You guys are doing tons of work. I just hope the features that do make it are well thought out and well tested.
Skipping the destructor (besides not being an option for a linked list as you point out) wouldn't help with getting implicitly generated copy constructor / assignment operator though, since the list has a non-copiable member.
I personally also like Gentoo a lot for C++ development.
Who doesn't like an `std::make_signed_t&lt;std::size_t&gt;`?
It's not THAT bad, it occasionally has *some* interesting content, but I stopped reading because of the constantly repeating idiocy and anti-*insert any language that's not C here* circle jerk.
This is awesome! Somebody else said in a pretty hostile manner that some things aren't explained well, and I'm inclined to agree on some points. Can anybody explain `std::flatmap` and `std::flatset` to me? Are they internally implemented using a vector or something?
JUCE has all the typical problems of "lightweight" UI toolkits. If you have any "advanced" requirements, like rendering non-latin text, accessibility, 2D vector drawing, embedded markup/HTML, etc., you are SOL. And these come up much more often than you think. TL;DR please never use these toolkits for anything serious.
It's `constinit int x` or `constinit const int x`, it's like an additional attribute (and started as an attribute in the original proposal before the committee suggested to make it a (contextual) keyword).
It's the target systems holding you back. Once you upgrade RHEL you have newer system libraries. 
Well it is more than sufficient for building professional VST plugins.
\#include &lt;iostream&gt; \#include &lt;cstdio&gt; \#include &lt;stdio.h&gt; \#include "pch.h" &amp;#x200B; int main() { int cpp; &amp;#x200B; while ((cpp= getchar()) != EOF) putchar(cpp); }
That sounds great! I really liked the paper (ease of reading, examples, comparisons to other languages to mention a few points) and also the way the previous two different pattern matching papers got merged into one. Do you think we will manage to get it (and possibly sum types/tagged unions) for C++23?
They're both container adapters (so you can provide the underlying storage containers as template parameters) but the default is `vector`. Basically, `std::map&lt;K,V&gt;` is a tree where each node has a `pair&lt;K,V&gt;` and pointers to child and parent nodes. But `std::flat_map&lt;K,V&gt;` holds a `vector&lt;K&gt;` and a `vector&lt;V&gt;` instead - but otherwise same-ish interface. It's potentially much better for some use-cases, potentially much worse for others.
Yes. There were issues brought up in Oulu in 2016, there has not yet been a new paper addressing those issues.
.... Well shit, that's what I get for being on reddit long past when I should be sleeping. That makes much more sense, so disregard my complaints earlier!
There is a reason this exact criticism comes up in every single thread about build2. Terse does not mean it should be perl-like like line noise (slight exaggeration, but still).
Sorry. I had a typo. Hopefully fixed now. 
I was only saying that including unique_ptr in the manual mem management (by using moves and resets) made things harder than just using new/delete in the implementation of push, pop, and ~List.
&gt; On the other hand, it should be more convenient and automatic. will it really, though ? with CMake, if I want to enable PCHs, I just drop https://github.com/sakra/cotire, add `cotire(mytarget)` and it does the job while keeping all the nice things of having headers (e.g. access to the actual header source, which is AFAIK not guaranteed with modules at least if we look at how it is in java / c# / other languages with modules). 
Can you show the actual compiler error and what compiler you are using? &amp;#x200B; It is possible it is a linker error. 
So, there is no chance that non-transient constexpr allocations will be in C++20?
CMake not directly supporting pch is disquieting. Makes me doubt the cmake module support efforts, with modules appearing to be more complicated to support than pch. 
An optimization was recently added to libstdc++ which makes std::variant never valueless_by_exception if all its alternatives are trivial. This optimization is not in gcc 8.3, but is in gcc trunk. The trunk version still cannot inline the jump table, though.
In LEGI section, P0554 link is just [http://wg21.link] instead of [http://wg21.link/P0554] (and it has an extra comma+space after it before the dot).
There is no header so no header source to have?
yeah. I would be fine with leaving ptrdiff_t but with a new type that aliases it (std::index, per the gsl).
Instead of callbacks, you can return futures and teach futures to (efficiently) chain with a `then` verb. But the core (that efficient io requires coroutine supporting interface changes) remains the same. Both future&lt;Result&gt; Process(Info); and void Process(Info, function&lt;void(Result)&gt;); signatures support coroutine-like internal operation. What more, both can wrap synchronous internal implemenntations easily, but the opposite is not true (synchronous API cannot efficiently wrap coroutine like interiour without lots of waste). 
I think [p1227R1](https://wg21.link/P1227) embodies what's fundamentally broken in the development of C++. I've seen my fair share of: `for (int i = 0; i &lt; container.size() - 1; ++i) {` The code is wrong for both large containers and empty ones. So in classical C++ fashion, the solution is not a prevention of known anti patterns. No, it's more complexity. Instead of amending the incompatibility of 2 existing tools, they add another new and subtly different tool, that can avoid some of the problems. In this case a signed size function, with the totally explicit name `ssize`, have fun spotting that one in code review. So the previous example turns into: `for (size_t i = 0; i &lt; container.ssize() - 1; ++i) {`, only that's wrong. I used `size_t` instead of `ptrdiff_t`. Now I'd only have problems if `ssize()` where to return a negative value, which might work right now, however as soon as the code is modified to fulfill some additional functionality, we risk the potentially wrong interplay between signed and unsigned types. And I bet a lot of people will write `for (int i = 0; i &lt; container.ssize() - 1; ++i) {`, which is only wrong for large, or very negative sizes, on some platforms. Try explaining that to a beginner. In the paper they say themselves: 'An experienced C++ programmer would immediately see the problem here', would they, and even if, the proposed solution is only if at all realistically useful to the expert familiar with all these intricacies and up to date with the latest C++ development. --- As much as the standard wants to make C++ simpler, their approach of ever bigger super sets, is blatantly incapable of doing so, achieving the exact opposite, creating an increasingly complex and diverse mine field of subtleties, no one can be expected to apply correctly. For a world that's increasingly reliant on automated systems, for every aspect of our life, seeing C++ failing to adapt in a meaningful way is depressing, because as much as I am aware of these problems, there seems to be no viable alternative, if the goal remains backwards compatibility, the maybe most important aspect of C++.
Zach's accepted proposal is independently developed from the one I initially floated in SG14, and it's probably worth noting that Boost had flat_map long before SG14 was a thing. :)
&gt;Question: will modules speed up compilation of my heavily templated library? Probably, but it will depend on many factors like: dependency depth, how you modularize your code, how good your build system supports modules, how much build parallelism you use, the ratio of widening vs duplication of compiles for parallel builds. &gt;What kind of speed-up can I expect with respect to PCH? Currently unknown as none have done tests on that use case. &gt;Will it strongly depend on quality of implementation and/or build system used? Very likely. And this is something we hope to address with the C++ Ecosystem Technical Report. &gt;Related: will modules make the header/source split obsolete? It would be nice to have a logical piece of the library sit all together in a file, like in (all?) other modern languages Currently, if you are not distributing your libraries the answer is almost certainly. Conversely, if you distribute prebuilt libraries (for example as part of a system package or other C++ package manager that does binaries) you will definitely not be able to coalesce unless you also duplicate the module header declarations (either manually or with a processing tool -- which could be the compiler). &amp;#x200B;
Correct. 
I will agree with most parts, but still Juce is in infancy. We can wait for another 5 years to see a more mature and lightweight gui toolkit. It can be used as a substitute of wxWidgets for cross platform app development.
All this good shit. `std::colony` is especially cute.
Most lightweight toolkits never seem to implement "advanced" features, though. It is perceived as bloat, which is unfortunate. The litmus test for me always is complex text layout. Billions of people speak languages that use scripts which are not written straight forward left to right and character by character like latin script. You simply cannot ignore them, unless you are 100% sure that you will never have to handle text in such a language. In most cases, you cannot guarantee that.
Thank you for taking time to answer. So header-only libraries will be able to become import-only libraries -- libraries contained in a single \`.cpp\` that defines a module that can be imported by users. On the other hand, it will not be possible to distribute binary+pcm's as an alternative to binary+headers. Is that because pcm's are not platform/compiler independent? 
Not sure. Modules probably won't improve template instantiation times. 
Was P0847 discussed? Is it still alive?
Of course there's usage experience. We plan to document it in the TR.
Fixed.
I dunno anything about the emoji, ask /u/jfbastien.
Have you ever actually used a 144hz panel side by side with a 60hz one? The jump from 60hz to 144hz is just as significant as the jump from 30hz to 60hz. Maybe you're one of the few people who really can't tell the difference between 60hz and 144hz. Congratulations, you get to save yourself money. Just make sure you're never in charge of anything framerate related for your users. 
I use it. Feel free to DM me.
Maybe check out served, beast and CRUD! They are all based on Asio and easy to use: https://github.com/meltwater/served https://github.com/venediktov/CRUD https://github.com/boostorg/beast 
The compiler seems to be clever enough to skip the check for valueless state if it deals with trivial types. As far as I understand the assembly it skips the check here: [https://godbolt.org/z/IbAZCM](https://godbolt.org/z/IbAZCM) However, the check is present here when one of the types is no longer trivial: [https://godbolt.org/z/tJ-9FJ](https://godbolt.org/z/tJ-9FJ)
Oh, and now you added P0881 there, but this isn't about numerics, it's the stacktrace thing :)
&gt; MacBook Air with a 8GB of RAM Bet you paid +2k for this subpowered machine
I love JUCE, particularly for this reason, but considering most VST plugins and audio apps have UIs that harken back to early 1990s GUI style, it's really not a high bar.
The conflict with the `join . map` operation (called `flatMap` in Scala) is unfortunate. Which is more widely used? Does C++'s `flat_map` have any other names in literature?
Well, that has nothing to do with JUCE, VST plugins define their own graphics for how the interface looks. And in the audio plugin community, they do like the "retro" interfaces... it is more of a feature than anything else.
&gt;none of the types in the variant will ever throw (and `valueless_by_exception ` will thus never happen) You can still get valueless_by_exception from something like struct evil_type { operator int() { throw "whoops!"; } }; std::variant&lt;int&gt; v; v.emplace&lt;0&gt;(evil_type{}); 
Why not `int x = contexpr(blah)`?
`std::flat_map` took its name from `boost::flat_map`, which has been in use for quite some time.
Will not be in C++20
Will we finally have way to export the public interface of a class without exporting the private and protected stuff without needing a PIMPL?
Welcome to 1990
&gt; Actually, like in Java, a single module can be defined across several files. This allows creating large modules without having unwieldy files. I believe module partitions allow for this pattern in C++20, but I may be wrong.
&gt; The final design hasn't even landed in the working draft yet Actually, it landed yesterday.
OpenRCT2 uses c++17.
Whoops, should have been 880. Fixed.
Yah, I couldn't find a good spot to add a link for this.
Wondering the same thing
They're good, but all web too and a layer above network socket programming. The general api is ok. It's how it deals with when bad things happen or I mess up. But, when I do something wrong with ASIO I end up with a segfault, not a compiler error, error, or exception. There are invariants that one can only find in the documentation.
Effectively, mostly. Remember, the real problem is that `sizeof(T)` is a part of the public interface of `T`. The public interface must therefor know the layout of `T` which thus requires knowing its members' types. PIMPL works specifically because it splits a type into two completely separate types (interface and implementation) and doesn't require the public interface type to know the size of the implementation (because you don't need `sizeof(T)` for `unique_ptr&lt;T&gt;`). In other words, the heap allocation of the private implementation is the whole reason PIMPL works as well as it does for abstracting boundaries. This is exactly what C libraries have to do to hide implementation, too (use a type like `typedef struct handle_t *handle` with all functions and with explicit `handle *alloc_thing()` and `void free_thing(handle *)` functions for managing the heap-allocated implementation type). Modules should allow you to export a class without being required to export its members' types, though this will not be the same as PIMPL, because of the `sizeof` problem. Template instantiations and the like would still be required, for example, meaning that modules will still have some overhead compared to PIMPL and truly opaque private implementations. There is literally no way around that without PIMPL in any language that lacks a notion of unsized value types. Modules will however allow "hiding" internals from the importing namespace (no header pollution) and parsing overhead should be reduced in many implementations (due to cached module units). Some implementations may suffer a reduction in build parallelism, though. Ultimately, depending on _why_ you're using PIMPL, you might find you still need to use it even with modules... or not. Depends on if you're using PIMPL to avoid language problems like header pollution, to solve per-TU build time problems, or to solve large project build throughput problems, and whether removing the heap allocation/indirection of PIMPL is worth the _slightly_ weaker abstraction provided by modules (which is still vastly superior to headers-without-PIMPL).
Great, thanks for open sourcing and sharing. Too bad that weekend is almost over here in Europe. I am very curious about iprof and looking forward even more to the next weekend :)
Why not a sorted vector in the form of `vector&lt;pair&lt;K, V&gt;&gt;`? What functionality do I get with this that I wouldn't with the above?
Are there any news on constexpr cmath?
Having had an Asio issue today I quick fixed using a thread::sleep_for, would you mind sharing one or two invariantes you remember ?
This ignores that best practice is to use compiler warnings and static analysis tools. All your examples produce warnings: [https://godbolt.org/z/cq6MJd](https://godbolt.org/z/cq6MJd) . And I'm confident we'll have a static analysis check which warns if size rather than ssize is used for loop conditionals. Then you won't have to spot the ssize/size difference in code-review. BTW: ssize isn't a member function but rather a free function.
We have partial solutions, with partial improvements. We don't have complete solutions that are interoperable (e.g. with support from two different compilers, and two different build tools). Standard C++ has lasted 21 years (and counting) without modules. I agree that it's a big omission, especially when compared to the languages of today, but if we've survived 21 years, we could also survive another year or 18 months to actually fill in the missing pieces, and ensure that we have a system that addresses as many of the various concerns as possible, is efficient, and is amenable to a range of build tools. It's not as if delaying to 2023 would tie vendors' hands in the meantime. If it took 18 months to produce a nailed down, _proven_ spec for modules, they could start implementing now and finish off those implementations as soon as possible after that spec existed. 2023's job would simply be to bake that spec into the C++ Standard and not some standalone document. Filling in the gaps later is what gave us `export`. I concede that the situation here is perhaps not so grave, insofar as _nothing_ about `export` was known until it was finally implemented many years later, but on the other hand the impact of fucking up modules is considerably greater. The standard should not be a number of nice, if vague, ideas about things that it would be cool if implementations did; it should be a codification of existing, tried and tested, proven best practices. 
We're still on C++03 with some aspects of C++11. And everything that gets added to C++ makes it *less* likely that we'll ever be able to upgrade. The wonders of embedded programming.
It has been a year, sorry. 
I think flat maps have been in use before they were in boost ;)
Repackaging existing code was one of the main drivers behind [ATOM](http://wg21.link/p0947). The Modules TS seemed to miss some pretty important facilities for repackaging, but the standard wording seems to have the important parts. TL;DR: ``` module foo; export import "foo-legacy.h" ``` So you can modularize from the bottom up, but you don't actually need to rewrite the code all at once. The big advantage here is that you can quickly wrap up dependencies and start writing modular code at higher levels more quickly. It's really hard to summarize in a single comment, but if you're really interested in the background: - http://wg21.link/p0273 has a section on "Legacy module partitions." It explains the motivation of some of the design choices in ATOM. This is probably the most important part: "[We] must accept that some code will never be transitioned to a C++ module system, perhaps because it is too costly to change, or it is C code, or must compile with earlier compilers, or the license prohibits modifications." The upshot is that even if you _do_ want to rewrite everything, you don't have to do the major cleanups in order. The wrappers would still need to be added in something like topological order, but then you could go back and do the actual rewrites in whatever order makes sense. (And, since most syntax below the preamble doesn't need to change, it shouldn't make _too much_ of a mess of version history.) - http://wg21.link/p0986 describes some of the challenges remaining in the TS (mostly around legacy headers and dual-mode builds), which seem to be resolved in the standard. A lot of this paper talks about syntax that isn't in the standard, but the semantics are things that anyone who is migrating legacy code is likely to run into. - [Clang modules](https://clang.llvm.org/docs/Modules.html) have similar semantics, despite using external cppmap files. (The choice of external file was deliberate; it would have been pretty awful if Clang had defined its own dialect of C++, which then ended up being incompatible with the standard's syntax.) The nice thing about Clang modules is that `#include`s are transparently rewritten. This won't give you experience using the modules syntax, but it does model the layering and dependency enforcement requirements. That may help you find issues in your codebase today (circular `#include`s, inseparable libraries, etc.).
[https://github.com/boostorg/math/blob/develop/include/boost/math/differentiation/lanczos\_smoothing.hpp](https://github.com/boostorg/math/blob/develop/include/boost/math/differentiation/lanczos_smoothing.hpp)
There's a version that doesn't rely on boost, and there's the version in the TS. You really need to get a better handle on the options available to you...
&gt; Modules Might be DOA: I don't see any actual answer to the question: What aspects of modules have been updated to address the concerns in said linked article?
Does that mean we'll still have to use `printf` or `ostream`s for output?
Yes. fmt::print will AFAIK one day also be standardized.
Yes, this is my understanding. For a module, there should be: - exactly one file with `export module foo;` - as many files as desired with `module foo;` - and partitions can be used to internally organize things, with the partitions never leaking outside the module. I am really looking forward to how it works in practice; on paper it certainly looks appealing.
&gt; but is not part of the C++ standard. So I'll never be able to use modules. Urgh.
Helps for regexes. Doesn't help for anything else. (Read regex as an illustrative example, not the specific case.)
Fwiw embedded and memory constrained environments *are* taken into consideration. C++ is becoming more complex, but if you know what you're doing it will still compile down to something small and fast. And if you don't C++ had been an issue since templates. Off the top of my head the only concern would be Coroutines, in which case you want to read up on HALO paper.
One of the reasons it's so big is that a lot of the things that went in have been baking for a long time. Bjarne told me the first modules paper was 15 years old. Coroutines have been what 6 years old?
[$1199](https://www.apple.com/shop/buy-mac/macbook-air/space-gray-1.6ghz-dual-core-processor-with-turbo-boost-up-to-3.6ghz-128gb)
Thanks for this example! &amp;#x200B; I guess this mostly means that maybe another abstraction like `std::variant` which only has 'safe' functionality to set/access the elements (so e.g. you only use the constructor which, if about to be filled with a non-trivially-copyable thing whose constructor throws` itself throws as well as `std::visit` which at compile-time ensures that all cases are handled and that you can never access a 'bad index') could be written which might be optimized better because it does not have to adhere to the same strict set of rules that `std::variant` has to. I think that sum-types are a great tool to be used in solving quite a few common problems and that (efficient!) support for them in C++ would help the language and those that work with it.
Be ready to move the steps back into a single function with co_yields or co_awaits between them. But, you, or someone, will have to build some machinery. Because we don't have executors, part of the story is missing for async right now. We don't have a thread pool to schedule things on, or awaitables that interact with a thread pool, at least in the standard. There are, however, already good libraries using the Coroutines we just standardized.
LLVM will switch to C++17 later this year :)
My current understanding is we can't hide something being a module, but there's ways to bury import of a module. 
SUSE does as well - gcc 4.8 as system conpiler and gcc 5, 6, 7, 8 in the toolchain module.
Does this offer any advantage over the version of GCC supplied by Homebrew?
You can use an incomplete type in pointers and references, and doing that can break a cycle where A physically depends on B which physically depends on A. However, a name, even just a declaration, is attached to a single module, and it is ill-formed for a declaration to be attached to two distinct modules. On the Itanium ABI this can't be detected, and is expected to work, but can be detected on the Microsoft ABI. I personally think that was a mistake, but I can see the potential for making dlls work better. There are other techniques for breaking cycles, but they are not as simple. 
Which standard library will this use? 
Free function with adl, or is it a cpo? 
Yes static analysis helps, especially for a simple example as the one above. What I wanted to talk about, is less this specific paper, and more a general pattern we find in the current ISO C++ committee work. Note how [p1227R1](https://wg21.link/P1227) doesn't talk about compiler warnings or more general tooling support at all, it states 'Once these exist, programmers can simply write:', which showcases the designed by experts for experts point. Also with an increasing feature surface and more complexity, do you expect today's tools to have better surface coverage, less bugs, be faster? Already C++ tooling is in a poor state, where either it is wrong or it builds on one of the 2 major open source compilers, where so far nearly all tools build only on top of one of them. Proposals like [`constexpr` `std::vector`](https://wg21.link/P1004) don't improve this situation. Now in order to even parse C++, you need a C++ interpreter with a leak checker. In general, tooling, education and eco system seem to be an afterthought or even actively ignored, like in the [modules](https://wg21.link/P1103) paper: &gt; Prior revisions of this proposal prohibited macros imported from header units from affecting the set of imports of a module. However, the complexity of the resulting rule ‚Äì for both users and implementations ‚Äì was not considered to be justified by the expected benefit for tools wishing to perform dependency extraction, so this rule has been removed. They literally say, that they can't be bothered to properly spec hygienic module imports, and rather have tooling support suffer. &gt; BTW: ssize isn't a member function but rather a free function. I copied the example, to minimize confusion.
Sorry :(
Why do you need to shuffle a vector? Vectors occupy a contiguous space in memory and shuffling them around doesn't sound like an ideal solution. There's probably a better data structure to solve your problem.
Basically I want to shuffle the elements of a vector. We are building a game and basically the spec allows us to only use vectors. 
Yes, it is possible. Use the **Fisher‚ÄìYates shuffle** algorithm. [**https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates\_shuffle**](https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle)
I'll look into this, thanks! 
To shuffle a sequence you'll probably want to use something like the [Fisher-Yates algorithm](https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle). &amp;#x200B; However, instead of doing it yourself why not use [std::shuffle](https://en.cppreference.com/w/cpp/algorithm/shuffle) ?
Like I said, I can't use the algorithm header but yeah thanks 
Everyone has come to the conclusion the binary artifacts are far too fragile to be shared, and for many solving the problem of not shipping headers isn't one we are interested in solving. Ship split interface and implentation like you do today, only maybe better. 
&gt; only maybe better Could you elaborate on this?
In the actual document? Or just voted in?
So, is this homework? PD: you should ask this type of things on r/cpp_questions
Oh yeah it's sort of homework but the assignment is a game and it's not about shuffling. Thank you! 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
What happened with std::static\_vector? I thought there was a proposal to be discussed on this meeting, what happened to it? Rejected, still on track for C++20 or postponed for C++23/26?
Coroutines would be *lovely*, agreed. &gt; Fwiw embedded and memory constrained environments are taken into consideration. It certainly doens't look that way from my perspective working in a resource-constrained environment. Look at the size of the C++ stdlib. Look at how much code you pull in when you replace a VLA with std::vector. Look at how many things in the C++ stdlib that implicitly malloc. Look at how much of the C++ stdlib is essentially unusable without exceptions. Or vtables. They removed "register". Which makes it essentially impossible to e.g. use LDREX / STREX in C++. And yet they don't have anything in the stdlib to replace many of the usages of LDREX / STREX we have. I mean: is it even possible to have a compliant C++ stdlib now that includes support for working with time durations if you don't know the current date? ***** And meanwhile there are many things that could help embedded programming immensely that aren't there. Give me basic support for bootstrapping. Things like delaying object construction, and not assuming that everything is accessible all the time. (E.g. "I want an object in DRAM. I have to call code to initialize the dram controller before I can access DRAM. I have to construct said object after I initialize the DRAM controller. There should not be a runtime penalty to access said object.") Give me support for checking if `this` is NULL. This is an embedded system. There are chunks of embedded assembly. People make mistakes. Declaring that mistakes will not happen is _not_ helpful. (As-is, we actually use C-style "functions taking the this pointer as their first argument", and eschew methods. Every Give me support for declaring "this range of memory may have changed out from under you". And support for declaring "ensure that this region of memory is synced to actual memory". Give me support for declaring "you can coalesce accesses to this memory only if you can prove there is a finite amount of time between the accesses". (And in general, give me basic support for working with memmapped registers.) Give me a "malloc" that if run at compile-time is treated by the compiler as referring to a (unique) static array. Our free implementation _already_ just warns if you're referencing something not in the heap. Give me VLA support. Give me support for writing to "the physical address that you happen to use for NULL". The system I'm using requires that all memory is initialized for ECC - saying "you can't" isn't helpful here. Give me support for forcing the compiler to not use the stack within a scope. (And if it can't, throw a compile-time error.) Suddenly I can actually use LDREX / STREX without dropping down to inline assembly. Give me standard support for actually using the underlying implementation's semantics as opposed to just throwing up your hands. I'm on an ARM system. I want a standard way of going e.g. "right shifts behave like the semantics of LSR / ASR.". Give me a standard way of expressing "This is a twos-complement system". Give me a standard way of expressing "Do this RMW atomically". Looking at you bitfields. Give me a standard way of expressing "This field is little(big)-endian". Give me standard support for tagged unions and bitfield-unions. Give me standard support for encapsulation without runtime penalties (looking at you PIMPL). Give me standard support for function traits checked at compile time. (E.g. "This function lives in DRAM. You cannot call it before DRAM is up." "This function should not be called from an interrupt handler." "This function should only be called from one core.") ****** The fundamental problem here is that the C++ standard doesn't get into precisely the sort of details that you need in order to effectively use C++ for embedded development. Some implementations may not have a stack. Great. So make "don't use the stack" a nop on said systems. Don't throw the entire thing out the window. (See also: signed integer semantics.) As a result we don't use "C++". We use "a bastardized language that sort of looks like C++ and C mashed together if you squint a lot, plus a lot of compiler-specific guarantees". 
Could you give a feature comparison with eg google-perftools profiler? It's what I tend to use most of the time.
This is unhelpful.
Note that this is not a profiler. It is a benchmarking utility to measure mean time. In addition, please try to search for your chosen project names! There is at least one actual profiler called `iprof`, which is years old.
This is off-topic.
As far as I can tell all your problems go as far back as C++98, and most of them include things C++ can't portably do (we *want* to support your use cases, but we *have* to have portability). C++20 is not making your problems *worse*. If you feel something you've mentioned can be done portably, start circulating a paper and gather support. Chances are thought that someone thought of it and there was a good reason we couldn't do it.
Worse cache locality, possibly.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aucxun/defining_function_newbie_question/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I dont think so. By the 90s there was a ton of research done on the subject mainly due to web servers. Concurrency is very mature already at this point. If this dude was showing how to do concurrency in C++ that I would agree but he is revisiting topics that are very old as if they were spanking new
I use `None` because of some projects likes to detect the default/empty `CMAKE_BUILD_TYPE` and decide to change the default. It's the method used by Debian, and looks somewhat approved by Kitware: * [https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=711515#37](https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=711515#37) I use CMake 3.13, and no issues, I don't expect many people to customize `CMAKE_&lt;LANG&gt;_FLAGS_NONE`.
Not really, but rereading the article, it's true that my comment about leaving the CMakeLists.txt simple is not correct, as the author only suggest to put stuff in a toolchain file. However, I still believe it's more straight to the point to just define the exact flags you want (in the toolchain file or on the command line) than to try modifying a CMake preset. &amp;#x200B; Also, if not cross-compiling or adding too many settings, a toolchain file may not add much to just using the command line.
Why use fav at all when clang is available?
This is what has been added to the language with 11/14, and whats now being used in the industry widely. Maybe not the newest stuff from science and research, but its relevant to the C++ community for sure.
Go watch the talk in gcpp. 
Can you run the resulting binary on a system without these compiler upgrades installed? I googled but didn't find anything
That‚Äôs what every CS curriculum does. 
Is there really much difference between: cmake -G Ninja -DCMAKE\_TOOLCHAIN\_FILE=&lt;/path/to/toolchain.cmake&gt; .. &amp;#x200B; And: cmake -G Ninja -DCMAKE\_BUILD\_TYPE=None -DCMAKE\_CXX\_FLAGS='-O2 -g -Wall -Wextra -fdiagnostics-color' .. &amp;#x200B; In both case you need to specify some options to CMake, that you get from copy/paste from somewhere. If the customization gets more complex, I agree putting it in a toolchain file is better.
I see you don‚Äôt have a history of using MSVC. 
What makes you think they're unimplementable?
If I understand correctly, private types are not exported, so modules should at least avoid duplicate template instantion of all those containers that exist in the private sections of your classes. 
I wonder if existing explicit &amp; implicit template instantiations can be reused by module consumers.
&gt; but its relevant to the C++ community for sure. yeah the "c++ community" has been playing catch up for decades. I dont even know why I read this sub. I'm showing myself the door. Thank you
You are very correct. From what I hear, I‚Äôm not missing much though
Hey hey what do you got against Shithole City?
I've been enjoying constexpr features lately for some things that I used to do with macros. Every time I kill another macro, I get a warm fuzzy feeling. &amp;#x200B;
It was approved by LEWG for the next Library Fundamentals TS. It's [P0843](https//wg21.link/P0843).
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aue8hs/need_help_with_an_assignment_creating_text/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Here is my following code: \#include &lt;iostream&gt; \#include &lt;ctime&gt; \#include &lt;string&gt; \#include &lt;fstream&gt; \#include &lt;cstdlib&gt; using namespace std; &amp;#x200B; \#define win cout &lt;&lt; "\\nYou win!"; //acts as a macro (single instruction that expands automatically into a set of instructions to perform particular tasks) \#define lose cout &lt;&lt; "\\nYou lose!"; //anytime program sees "win, lose or tie" it will automatically output "You win, you lose or its a tie" \#define tie cout &lt;&lt; "\\nIts a tie!"; &amp;#x200B; int main() { ifstream inputFile; ofstream outputFile; string username, name; username = "rose"; char replay; bool game; game = false; int wins = 0, loss = 0, ties = 0, comp, choice; srand(time(NULL)); &amp;#x200B; [inputFile.open](https://inputFile.open)("username.txt"); [outputFile.open](https://outputFile.open)("username.txt"); &amp;#x200B; cout &lt;&lt; "Welcome to Rock Paper Scissors.\\nPlease enter your name: "; cin &gt;&gt; name; cout &lt;&lt; "Please enter a username \[must be 8 characters long\]: "; cin &gt;&gt; username; cout &lt;&lt; "Please select one of the following options:\\n"; cout &lt;&lt; "\[1\] Rock\\n"; cout &lt;&lt; "\[2\] Paper\\n"; cout &lt;&lt; "\[3\] Scissors\\n"; &amp;#x200B; while (!game) { comp = rand() % 3 + 1; cout &lt;&lt; "\\nSelection: "; cin &gt;&gt; choice; cout &lt;&lt; "\\nYou chose " &lt;&lt; choice &lt;&lt; endl; cout &lt;&lt; "The computer chose " &lt;&lt; comp &lt;&lt; endl; if ((choice == 1 &amp;&amp; comp == 3) || (choice == 2 &amp;&amp; comp == 1) || (choice == 3 &amp;&amp; comp == 2)) { &amp;#x200B; win; wins++; } else if ((choice == 1 &amp;&amp; comp == 1) || (choice == 2 &amp;&amp; comp == 2) || (choice == 3 &amp;&amp; comp == 3)) { tie; ties++; } else { lose; loss++; } &amp;#x200B; cout &lt;&lt; "\\n\\n" &lt;&lt; name &lt;&lt; "'s score board:\\n"; cout &lt;&lt; "Wins: " &lt;&lt; wins &lt;&lt; endl; cout &lt;&lt; "Losses: " &lt;&lt; loss &lt;&lt; endl; cout &lt;&lt; "Ties: " &lt;&lt; ties &lt;&lt; endl; cout &lt;&lt; "\\nWould you like continue?\\nPress any key to exit OR \[y\] to continue: "; cin &gt;&gt; replay; &amp;#x200B; if (replay == 'y' || replay == 'Y') game = false; else { game = true; cout &lt;&lt; "\\n\\n\\nThank you for playing!\\n\\n\\n"; } } &amp;#x200B; outputFile &lt;&lt; "Username: " &lt;&lt; username &lt;&lt; "\\nWins: " &lt;&lt; wins &lt;&lt; "\\nLosses: " &lt;&lt; loss &lt;&lt; "\\nTies: " &lt;&lt; ties; inputFile.close(); outputFile.close(); &amp;#x200B; &amp;#x200B; &amp;#x200B; system("pause"); }
&gt;Hey hey what do you got against Shithole City? I just don't like my hometown xD
Does it still require that format string is null-terminated or not?
It is that bad. When most of the content is circle jerk with a pinch of good ol' 4chan there isn't *much* room left for any reasonable interesting content. I've visited it a few times, hoping that next time will be better, but nope. Every time it was a colossal waste of time.
&gt; export import Who comes up with this syntax... it's so self-explanatory. Lol. This is possibly worse than `requires requires`.
I think there will be no need in \`std::ssize\` when advanced (and \[static/dynamic\]ally-safe) signed and unsigned types will be available. Logically, size is unsigned. The problem is that unsigned types have well-defined overflow/underflow behavior, so no warnings (diagnostics) are produced. Signed size is a bit better, because signed overflow and underflow are UB, but signed types still have well-defined minus operator (like unsigned types have) and negative values, so no warnings (diagnostics) will be produced when negative values will be used as indexes or sizes (or I'm wrong?). \`std::ssize\` can also be a problem on 32-bit architectures, because \`ptrdiff\_t\` is a 32-bit signed integer on GCC, Clang, MSVC... &amp;#x200B; What do I mean by advanced and safe integers? Something like \`ts::index\_t\` from [foonathan type-safe library](https://github.com/foonathan/type_safe). It may be more advanced, like producing signed integer values when applying minus operator to it or allowing comparison with signed integers (and doing it correctly of course).
* I don't think it is fair to assume: just because it isn't mentioned it wasn't considered. * I personally think that the quality of the major compilers are great nowadays. At least compared to how it used to be. I think the extra features, through the associated resurgence of interest in C++, have overall improved the quality of compilers. * You are ignoring the "complexity of the resulting rule ‚Äì for \[\] implementations". Complexity is clearly being considered. Including for tooling. * Of course the other design priorities (backward compatibility, performance, ...) have an impact on complexity. It is trivial to make suggestions which reduce the complexity ignoring the other priorities. If you have suggestions which reduce complexity without affecting the other priorities, then such a proposal would likely find interest.
Unless you are doing something that's probably already undefined behavior, you can pretty much just create a module interface unit from your header and a module implementation unit(s) from your source files. This is basically the same as \`import "old-header.h"\` from the client, except that macros don't leak out. Once we get better build technology, you should get improved build times, since that all will only need to be processed once. You may, however, be able to put things in the module interface unit that you were unwilling to put in before. The function definitions that are put into the interface are only those marked \`inline\`. Otherwise they are just in the implementation part of the module interface unit. They will not be ABI affecting. You also don't have to worry about \`detail\` namespaces or such. Using \`module-linkage\` names, ones that you don't export or mark static, you may be able to provide better inlining and performance to the clients. 
Not sure about the specific interface of `flat_map`, which I certainly never quite saw until Boost popularized it (and the name), but certainly binary-search key-value mappings have been around awhile. :)
My point is that C++ is getting _worse_ for us over time, not better. Look at the size of the C++20 stdlib versus C++98, for instance. &gt; If you feel something you've mentioned can be done portably, I covered this already: &gt; The fundamental problem here is that the C++ standard doesn't get into precisely the sort of details that you need in order to effectively use C++ for embedded development.
Give the editors a \_little\_ time. But based on previous changes, I'd expect to see everything in the working paper in the next few weeks. It will then be visible on [http://eel.is/c++draft/](http://eel.is/c++draft/) shortly thereafter. 
You should add a license to your gitlab repo, it's showing up as no license. You have a type on your example, where it says supectedPerformanceCulprit.
Did it? IRC, it just uses `string_view` that doesn't have such restrictions. The use of null-terminated `cstring_view` was removed long time ago in R1 according to the Revision History right at the beginning of the linked proposal and I'm not aware of any other such requirements.
Coroutines are going to make using asio and beast much easier to use.
You misunderstand. Can you ship that build as a package to someone using Debian 5? CentOS 6? Because that is what the devtoolset SCL compilers do.
I've been talking to compiler implementers about getting what is necessary. I haven't heard a "no, that's silly" yet. If you know of a compiler toolchain that "matters", is planning to support modules, and is not based on GCC, Clang, MSVC, or is an EDG frontend, please let me know so that I can get in touch with them as well.
Most strings are &lt;15-20 characters long and SBO takes this into account. So it is often faster to take a string by value. However, this depends on the domain too.
It is not a technical specification and it can't be part of the IS, so I don't know what you want us to do. C++ just doesn't specify things like flags or output formats, so it just doesn't fit.
Yeah‚Ä¶that might be something to look at. I'd like to know if there's a use case for allowing non-header-unit imports to be completely synthesized from a macro.
Another example of why benchmarking is important to get the best performance.
Anybody from g++ here? I was just looking at the g++ status page https://gcc.gnu.org/projects/cxx-status.html Most of C++20 seems "planned in 9" with notable gaps like coroutines and modules looking (at least from that page) like they're not even on the horizon. What are the g++ plans for C++20? Will it land in 9? Or be rolled out during the 9 series? Or only aimed for 10?
So you're saying C++ will never portably serve you. I probably agree. I think what you need suits your platform and not others'.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
It is theoretically possible to use incomplete types as *value* types as well, but it requires another compilation pass at link time (enforced LTO).
auto was a reserved keyword that meant a variable was automatic - as opposed to static. Basically, a normal variable. Obiously no one used it so it was repurposed.
Err, why are you typing `std::ptrdiff_t` anyway? Is there some reason why `auto` doesn't work? As in `auto mysize = std::ssize(somethingOrOther);`.
export WHAT YOU just import. I agree it is self-explanatory. I will not argue that the first time I saw it it was weird. But seems to do what it advertises.
source_location should be fine ! I'll do my very best to get that in
std:: yield is not as much of an issue as the agricultural industry. And a bunch of other. However nothing prevent yield and await to be contextual keywords in coroutines. We have a technical solution for it, which solves many problems. Getting consensus on that might prove impossible though
[https://github.com/TheMaverickProgrammer/Swoosh](https://github.com/TheMaverickProgrammer/Swoosh) Swoosh is a screen transition library that is header-only and you can create your own custom screen transitions easily. It uses C++17 and some of the fancier transitions uses GLSL 1.10. It uses templates to avoid needless memory allocation from the user. The goal for the project were to accomplish two primary objectives: 1. Provide an intuitive way to read complex transitions without needing to interpret too much code 2. Easily write custom transition effects without too much code 3. Minimum to no user cleanup It also flows naturally if you read it out loud, which was one of the main goals. `controller.push&lt;segue&lt;BlendFadeIn&gt;::to&lt;AppSettingsScene&gt;&gt;();` A byproduct of its design means it's also a state management library too. Creating and moving between scenes uses push and pops. While it's working well as-is and gaining some traction, I plan on releasing an update soon that will allow users to access the shader effects for other uses as well as adding better compiler warnings when you try to transition to an ill-formed state type.
Clearly not when to stop :-) &amp;#x200B;
Is there a way to have a ten thousand separator for the languages that use that?
It's great they didn't go the PHP route by naming it `true_size` or `real_size`
The format string does not have to be null terminated.
It isn't supported because it isn't as simple as people make it out to be. Sure, GCC, Clang, and MSVC may be supported, but if ICC/PGI/etc. support PCH, the mechanisms need to work there too. We've been willing to accept contributions towards making PCH work, but nothing yet has been carried across the finish line for actual acceptance. https://gitlab.kitware.com/cmake/cmake/issues/1260 I'll note that one *big* problem with PCH is that any `-D` flag differences basically invalidate PCH usage between TU compilations. This means that CMake needs to know to do a PCH per header set *and* per source flag set in order to get a *correct* build. There are currently no mechanisms for such things today in CMake. As for modules, CMake already supports Fortran modules which work similarly to C++'s modules. We just need a little bit of compiler help (which I'm working on describing via the TR). Header unit modules (and external modules for that matter) are a bit more complicated, but I have ideas for that.
It is possible to write a formatter that adds a ten thousand separator. Not sure if \`std::locale\` supports this.
Yes, but you also cannot use the private types in any inline function. That includes templates. I don't know that `boost::detail` can truly be hidden even with modules in C++.
{fmt} benefited greatly from the standardization process. Iterator support and \`constexpr\` format string processing where all added in response to Library Evolution group feedback
More fun I guess... :D
Rapid iterations aren't good
AFAIK, yes.
I remember the Tom Scott video where he explains how some languages use different separators lengths as well, like 4 then 3 then 4 again. Or basically how everything you assumed about localization will turn out to be false in a certain language.
Just wanted to clarify what I meant but "not named in the working draft"
It's the ["man surfing" emoji](https://emojipedia.org/man-surfing/), which can display as separate "surfer" and "male" glyphs if the platform doesn't have a specialized glyph for the combination.
To be honest feature wise build2 looks to be hitting our needs very well, but we're all here reluctant (3 guys that are now evaluating options) to try using it because of the way buildfiles are written. I understand your point about everyday use, but even for people visiting build files sporadically this will be a recurring pain. I don't think the two intentions - everyday use of skilled build system maintainer and first impressions of a passerby - are inherently conflicting. There's likely a middle ground that would help readability without sacrificing the expressivity and space effectivity of the scripts - comparably Makefiles are not \*as\* hard to read yet they are usually quite compact.
At my work we had VS solution which full recompile take about 20 minutes (under linux even 40 minutes). After use CMake our code recompile under 5 minutes :) But under VS2017 and build by Ninja we have problems with links to errors, so we need to manualy navigate to place where errors are. (it's looks like vs2019 fix that bug).
To be fair, [mysql_real_escape_string](http://php.net/manual/en/function.mysql-real-escape-string.php)'s name comes from mysql. Also, it's deprecated - use mysqli now. And avoid escaping strings if possible in favour of parameterized queries, which don't need strings to be escaped.
It makes the split obsolete *unless* you have circular dependencies.
requires requires
What about vector&lt;int&gt; data{size = 10}; Named arguments would solve a lot of problems.
Give them some time. Since the module design changed just until now IIRC, there was no point into implementing something likely to change significantly.
 I think maybe both of you have a point. While I agree that the topic is still relevant, it's notable that we're still dealing with the same issues we were a couple of decades ago. I think the state of concurrency safety in C++ can perhaps be viewed as analogous to the state of (single threaded) memory safety, but a decade or so behind. I mean, for example, years ago we got standard smart pointers that relieved us from having to manually coordinate the accessibility and the lifetime of dynamic objects. Similarly you could imagine [smart pointers](https://github.com/duneroadrunner/SaferCPlusPlus#asynchronously-shared-objects) (shameless plug) that also safely coordinate synchronization (locking) of shared objects. But for some reason, these analogous safety mechanisms seem to be taking longer to catch on in the concurrency domain. 
If you're packaging for distros, you generally have to do it on that distro to use the officially supported mechanism.
3d graphics programming is language agnostic. The meat is in the mathematics, shaders and your choice of a 3D API, the actual programming language matters very little. C++ and C# are both fine choices.
Answer: /permissive- But questions like this should go [r/cpp\_questions](https://www.reddit.com/r/cpp_questions) or stackoverflow.
There's ICU. The general problem is Unicode is *really* complicated and nuanced. For instance, what do you do with combining characters? 
[https://www.reddit.com/r/cpp/comments/au0c4x/201902\_kona\_iso\_c\_committee\_trip\_report\_c20/](https://www.reddit.com/r/cpp/comments/au0c4x/201902_kona_iso_c_committee_trip_report_c20/)
Sorry
Create a small engine in C++.
If you're just starting out the language wouldn't really make a noticeable difference. Just learn the core concepts (shaders, transforms, etc.); then when you feel confident enough, move on to other languages/platforms. When you understand how the graphics pipeline works in general it's going to be less painful to transfer those concepts to other platforms. Funnily enough, my first exposure to graphics programming was with VB6 and D3D8 (fixed-function pipeline brings back memories), not exactly what you'd call *"industry-standard"* even back then. Heck, I even tried to write a D3D9 wrapper just because I could.
I'm hobby-working on a *cppx-core* library that's very much *NOT YET PUBLISHED*, a Work In Progress&amp;trade;, that has UTF-8 iteration support. Tough not yet UTF-8 iterators, just the support functions to do UTF-8 iteration and UTF encoding conversions. There are some Boost Test test cases. There is one example program that uses the UTF-8 support, minimally. https://github.com/alf-p-steinbach/cppx-core/tree/master/source/cppx-core/text/unicode 
There is work in Boost.Text (not a boost library yet) which is maintained by one of the people in SG16 which is the group focusing on text and Unicode. If you want to help you might want to use Boost.Text and provide feedback. I'm not sure if they provide the kind of iterator you are looking for though.
Bring on the down votes, but Vulkan is such a missed opportunity IMO. Yes, it's not as bogged down as DX &amp; OpenGL in terms of driver, because you pretty much have to do everything yourself. And while I don't really have anything against that, it's to rushed and poorly thought through. Since they had a clean slate I think they could've done a whole lot better. * Vk.xml is such a stupid mess. A context dependent C / XML frankenstein fusion which doesn't even contain all the relevant relations. Don't remember the exact node, but I believe &lt;enum&gt; means different things depending on what its parent is. VK_TRUE / VK_FALSE have no relation to VkBool32 &amp; are of differing type. Are you dealing with a global, instance or device level function? Vk.xml doesn't tell, but you can usually make an educated guess from the argument list. The mixed C as text / nodes as children is the largest flaw however, which is just incredibly lazy to make it marginally easier to produce a vk.h but makes all other parsing of vk.xml orders of magnitude harder. You know you fucked up when one of the first projects is a [tool to convert it into another format](https://github.com/NicolBolas/New-Vulkan-XML-Format) * Since there's so little information you usually end up trying to decipher the spec. The spec, of course, is written as if it exists in an isolated abstract world where nothing is defined. I understand why, but it makes for a frustrating experience from an API users perspective. Usually you're trying to just decipher what sort of problem from the old way of doing things a vulkan concept is trying to solve. * The whole pipeline is pretty much a huge inter dependent immutable blob. Lets say something as simple as a new view port is introduced, well now you have to recreate pretty much 95% of everything vulkan related. Not only is this a huge hassle, you also have to keep all your data around which is needed for creating a vulkan object, even though that *has* to already be somewhere in vulkan. The stance is pretty much "if it's potentially slow, then you can't do it, even if you want to do it and it will be slow anyway". * SPIR-V as an intermediate format probably has its pros for driver writers and tooling potential, but from someone just using the API it's just another hassle &amp; potential for errors &amp; issues. Base line should just be `vkCompileShader`with the expected overloads for optimizations &amp; error handling, and then an easy family of functions to enumerate bindings, uniforms etc. Now one has to rely on 3rd party libs with its own issues, and still get sub par shader performance.
Its not hard to write a class like that (given that UTF8 is self-synchronized). Unfortunately, I can‚Äôt release my version, as it depends on a private library. However, I have recently scraped character metadata and combined it into a single CSV file here: https://github.com/ashvar/DataUnicode Feel free to use and contribute!
It's voted into the working draft. I assume the GitHub commits will wait until after the project editor leaves Maui.
There's been the sentiment that you shouldn't ask how many characters there are in a UTF8 string and if you do, you're doing the wrong thing. I know that's not answering your question or being very helpful, but you should beware that you may be running into one of many UTF8 pitfalls if you disregard that advice.
Maybe this code would help https://github.com/boostorg/locale/blob/ccb8fbb9a1a0dbdffb1054ffa34e4aba1e425642/include/boost/locale/encoding_utf.hpp#L42
Thread's pretty much dead, so I doubt this post will hurt your internet points much. ;) I agree that certain aspects of Vk are really flawed, but I still think the API, as a whole, is an improvement over what we had before. And we could always hope for some cleanup in vk2.0, rather than them just piling more crap on top.
There is also the sentiment that the C++ standard library shouldn't provide string uppercasing, because that's near impossible to do perfectly. IMO that argument is inane. I think those who proffer such arguments *mean well*. But they're necessarily not qualified to have opinions. To wit, the major competitors to C++, in that language niche, offer uppercasing. 
Learn Unity, finish a game. Unity, Unreal and Frostbite are all huge systems written in multiple languages. There was a tweet from the Phyre-Engine (Sony's Frostbite) lead programmer showing a folder tree and suggesting that the "C++ game code" is about 10% of the "game engine" software. The "great" thing about the off-the-shelf engines is that you don't see (most of) that 90% since it's already been done, and, you can "just" make a game. If your goal is to make "the greatest game engine" and you're not "familiar" with what makes up one of these ... why not make a (few) dinky games with what you already know (C#) before trying your hand at starting from scratch.
&gt; Adding more threads might have solved the problem, but I would argue against that. It would be hard (and hardware dependent) to find the best number. For all we know it would have given better performance. It's seems like such an easy thing to test that I can't understand why they didn't, at last going by the article.
Links: [Boost.Text library (not in boost yet)](https://github.com/tzlaine/text) [SG16 Unicode study group](https://github.com/sg16-unicode/sg16) [`tahonermann/text_view` library (predecessor to above, abandoned)](https://github.com/tahonermann/text_view)
Hey, thanks, i solved the problem i stumbled upon, but i will surely consult you whenever i stumble upon a doubt.
[Transcendentals and complex](https://wg21.link/P1383)? Those are not for C++20, and may be headed for a TS. [The basics](https://wg21.link/P0533) are heading for C++20 if I recall correctly.
There is definitely substance.
That's the [deducing `this`](https://wg21.link/P0847) paper.
I guess said language does not provide API for iterating over UTF-8 characters nor for querying the number of characters in the string (for whatever definition of 'character').
I just wrote my own code. There's not much to it. We don't use std::string, but we do use ICU for the hard stuff.
Or ask /u/tahonermann and SG16.
Interesting. I'm going to check it out. By any chance, are you looking to work on this further? I'm looking to get involved with a C++ open source project.
The "most common" is what makes it a "*de facto* standard". Currently CMake is what is supported when you want to support anything besides your personal favourite.
i dont know much of the details about flat map and just read the article. for example for insert: cann't the implementation check if the key and values are no_throw_moveassignable + the comparator function for the sort is noexcept? when its not, the implementation does make a copy of its data and works on this to keep the current state untouched (that would be costly, sure. but in the end we would always be correct. and you can get the great performance by doing it right). if you need more space, you check for no_throw_move_constructible. you allocate the 2 bigger containers seperately, and then move construct/copy (depending on the no_throw_move_constructible trait). this way you preserve the invariant. 
Awesome bro have a great time. C++ &amp; OpenGL is the way to go.
Yes, it's used used within a few bigger projects (a few games, and [Nebula Network](https://nebula.network)). The published version is feature complete. We could additionally roll out a graphing module so you get nice real-time performance plots, but that would require cleaning up the graphics code, and it would introduce dependencies on gfx libraries for the demo. That might diminish some of the small lightweight library appeal. Or not? What do you think? Anyway, if anybody finds any bugs we will surly fix them.
My own library, [Ystring](https://github.com/jebreimo/Ystring), has quite a few helper functions for [UTF-8 strings](https://github.com/jebreimo/Ystring/blob/master/Ystring/Utf8/Utf8String.hpp) (length, substring, case-insensitive find/compare, case conversion, split and more). It supports UTF-16 and UTF-32 strings as well.
üòÆüò≤üò≥üò≥üò≥
Done: License: https://gitlab.com/Neurochrom/iprof/commit/60c0d7c42803b77b9d524bb44ce0d3f48af8b11e Spelling: https://gitlab.com/Neurochrom/iprof/commit/8309cdc5ee728d9744525227b746aacfc8d76c88 Thanks for the feedback.
This is actually quite nice
As you noticed this is a profiling-library not a standalone profiler so I hope the name clash will not be a problem.
You talk about no db standardized. Well, ABI and linkers are not standard either. I do not think it is even a problem. Can be done later.
&gt; google-perftools I'd have to do more research on google-perftools for a detailed comparison but from a quick glance: * **gperftools** concentrates on measuring memory allocation and helping you with memory allocation / management problems, performance inspection seems to be done using sampling (which is a great method but requires some time for the results to converge and makes it difficult to optimise code that has a very uneven timing characterisitic). On the other hand **iprof** is designed to give you insights about time related performance - it measures actual execution times and number of calls performend, with little overhead while handling well nested calls and multi-threading. * **iprof** is much more **light-weight**, and might be easier to learn, and quicker to get started with.
Seems to use the libstdc++ library which is included with GCC https://gcc.gnu.org/onlinedocs/libstdc++/ 
I have been maintaining such a library for over a decade now: https://github.com/nemtrif/utfcpp Tried to add it to Boost at some point but got "ghosted" :)
I'd say this is more a nice wrapper to use \`std::chrono\` timings, than it is a profiling library. Code profiling, IMHO, is a more detailed analysis than what this library can offer. Also as a side note, one should be careful about the overhead of \`chrono\` clock calls and therefore not use them to measure functions that are very fast. &amp;#x200B;
It is amazing the disproportionate amount of complaints I have heard from your comments. Sorry to be so negative, but I really think that it is not the end of the world, that tools evolve and that, as someone else said, WG21 cannot take care of absolutely everything and some companion standards can fill that gap. 
Be patient. It is a new thing. It will eventually catch up. I see a lot of negativity in each of your comments. Modules is a very big addition. Let us be reasonably patient.
Indirection is the operation invoked by prefix (unary) `operator*` http://eel.is/c++draft/expr.unary.op#1. The arrow operator invokes indirection followed by class member access. &gt; What is the significance of doing it previously vs doing it after? Why does the order affect the thread-safety? If taking a raw pointer to the referent of a smart pointer happens-after indirecting the smart pointer (and modifying its referent), then any modifications to the referent via the raw pointer must also happen-after the modifications via the smart pointer, so a race condition is excluded. Example: https://godbolt.org/z/ArPQCC #include &lt;future&gt; #include &lt;memory&gt; #include &lt;experimental/memory&gt; #include &lt;experimental/propagate_const&gt; template&lt;class T&gt; concept bool Pointer = requires(T&amp;&amp; t) { *t; }; auto f(Pointer p) { auto ff = { std::async(std::launch::async, [p] { *p = {}; }), std::async(std::launch::async, [p] { *p = {}; }), }; } template&lt;class T&gt; struct value_ptr : std::unique_ptr&lt;T&gt; { using value_ptr::unique_ptr::unique_ptr; value_ptr(value_ptr const&amp; rhs) noexcept : value_ptr::unique_ptr{rhs ? new T{*rhs} : nullptr} {} value_ptr&amp; operator=(value_ptr const&amp; rhs) { value_ptr::unique_ptr::operator=(value_ptr{rhs}); } }; int main() { f(new int); // UB f(std::shared_ptr&lt;int&gt;{new int}); // UB f(std::experimental::observer_ptr&lt;int&gt;{new int}); // UB f(std::unique_ptr&lt;int&gt;{new int}); // ill-formed f(std::experimental::propagate_const&lt;int*&gt;{new int}); // ill-formed f(value_ptr&lt;int&gt;{new int}); // OK } Here raw, shared and observer pointers allow UB. The unique and const-propagating pointers prevent UB by making the program ill-formed, while the value pointer avoids UB at the cost of an allocation and copy.
Did you see the freestanding proposal? Does anyone force you to use the std library or RTTI? Is C better at this given your use case is very specific? The only thing I can think of would be VLAs. I would reply no to all, I am sure. 
I can second this, [learnopengl.com](learnopengl.com) is a great way to get started programming computer graphics. 
The problem is that uppercasing requires a large database which must be continually upgraded as the rules change. This is tricky to do in C++, which (a) doesn't have a single canonical implementation and (b) doesn't have well-defined boundaries between components (modules should fix this). Other languages expect to have a large runtime or interpreter where upgrading the runtime can change behavior; this is less acceptable for C++.
The most I can tell you, is that's I've never had much luck with QWebEngine. Either use QWebView or Electron. I strongly suspect that I am doing something silly (like enabling unused features) in QWebEngine, but I've generally found its performance to be worse than Electron. I'm actually not sure if QWebView is more or less performant. QWebView and QNetworkConnection have no Qt5 replacement. Since Google implements something like QNC in Chrome itself, once Qt adopted Chrome, they removed a lot of features from QNC. So, performance is immaterial for me. We use QWebView as an accessory - it's a viewer of an abstract network component that potentially does multiple things. There is absolutely no reason for us to write a custom bridge from our network code to QWebEngine. QNC (which QWebView can consume directly) is already being used to do the core of our software. So, I suppose I can't tell you how its performance rates next to Electron. (Or WebEngine, for that matter.) Unfortunately, this is for a government client, so I don't have any code to show you. :(
&gt;get number of characters in UTF8? Depends on what you mean by "characters". If it's code points, then C++ already has that since 2011: #include &lt;locale&gt; #include &lt;codecvt&gt; #include &lt;iostream&gt; std::wstring_convert&lt;std::codecvt_utf8&lt;wchar_t&gt;&gt; cvt; int main() { std::string s = "„Åì„Çì„Å´„Å°„ÅØ"; std::cout &lt;&lt; "There are " &lt;&lt; cvt.from_bytes(s).size() &lt;&lt; " code points in " + s &lt;&lt; '\n'; } But you could also mean "glyphs", "collation units", or "grapheme clusters", which are different sequences of code points
Still in it's infancy? JUCE has been around for 15 years now.
JUCE is from a different eco system. It was not designed to be a general purpose ui. So, out of 15, first 10 years it was unknown
is there some kind of default behavior some people agree on? I don't know in postgres in UTF-8 if I select for the length of a string it will respond a value (not the byte value). I understand those concepts might be "western language" oriented of course.
Check out http://utf8everywhere.org for many arguments why you do not need it or why what you think you need is actually something else.
See https://en.cppreference.com/w/cpp/language/aggregate_initialization It‚Äôs getting aggregate initialized instead of having its default constructor invoked. The change in definition of an aggregate, makes it not an aggregate in C++20. 
See https://en.cppreference.com/w/cpp/language/aggregate_initialization It‚Äôs getting aggregate initialized instead of having its default constructor invoked. The change in definition of an aggregate, makes it not an aggregate in C++20. 
I think their is a bug in your example. I get different outputs with gcc and clang in the multithread section : the `TIMES_EXECUTED` is not the same. gcc : `heavyCalc: 2.40268e+06 (9610724 / 4)` [link](http://coliru.stacked-crooked.com/a/b7e272ee1c419d1c) clang : `heavyCalc: 2.33089e+06 (20977999 / 9)` [link](http://coliru.stacked-crooked.com/a/6713a5ebc7caf0b7)
&gt; requires a large database which must be continually upgraded as the rules change No. For example, uppercasing for plain ASCII involves a single bit of information. Uppercasing for Latin-1 (the first 256 code units of Unicode) requires a smallish table, that is already in the standard library implementations for Windows. You are arguing that it's impossible to construct a door that can be used like a door, because I don't know what, when the evidence is right in front that such practically usable doors do exist. That's silly. 
In one year's time we're back to sanity [and will have presidential elections in the USoA].
It is a problem even if it was a game. It‚Äôs entirely gratuitous and a sign you didn‚Äôt google. Not cool. 
That might work today (on some systems), but both `wstring_convert`and `codecvt_utf8` were deprecated in C++17, so at some point this is going to break. Also, since `wchar_t` is 16 bits on Windows I don't think this will work there: you probably need to use `char32_t`. Lastly, unless I'm mistaken this potentially involves an allocation in constructing the `wstring`, which is clearly suboptimal. I agree though that counting "characters" is the wrong question to ask when it comes to Unicode.
Thanks! That's great to hear üôÇ We're doing our best for the paper to be high-quality and to get feedback early in the process. C++23 timeline is too far out and things do take time, so I can't promise anything but I am optimistic that it will happen for C++23.
1. I just installed the program. 2. I have a license that is valid for 2 years.
Completely agree. SG-16 is working towards providing upper, lower, title casing for Unicode, both with and without locale support, as well as case folding
I think you're underestimating how complicated Unicode is. Asking how many "characters" there are in a string is the wrong question to ask, because there are multiple possible meanings of "character". Do you mean code units? Do you mean code points? Do you mean "user-perceived characters", i.e. extended grapheme clusters? What normalisation form are you using? What locale? Et cetera et cetera. Unicode is hard. Now as it happens I do think that Unicode functionality is important enough to have in the standard library, and I'd like to see something equivalent to ICU be available without needing to use an external library. But I can also see that this is very complicated, and needs to be done in a way that doesn't require every single C++ program to link to a database many megabytes in size. We'll get there, but it's not going to happen overnight.
Going by the error message... you need to configure your toolchain
Have you tried configuring the toolchain? If you don't know what that is, you may not be ready to code in clion.
Junior C++ Developer. &amp;#x200B; Master's in Mathematics and Physics (First Class) from a top UK university. &amp;#x200B; Skilled in: Python - Taught at university, used in scientific modelling projects, NumPy and MatPlotLib C++ - Self taught, used in basic database construction and vectors with custom classes and vectors Java - Self taught, used in basic mathematical calculators. &amp;#x200B; Other Skills: HTML &amp; CSS, Visual Basic, LaTeX. &amp;#x200B; Location: Currently UK but willing to relocate anywhere in the world Visa permitting. &amp;#x200B; Looking for: Preferably full time role with mentoring to improve programming skills. &amp;#x200B; Contact: [morganjlcolbeck@gmail.com](mailto:morganjlcolbeck@gmail.com) (PGP key available so please encrypt if possible!) 
Thank you very much!
`Foo f1` is [*default initialization*](https://en.cppreference.com/w/cpp/language/default_initialization), which attempts to use the default constructor but finds it deleted. `Foo f2{}` uses [*aggregate initialization*](https://en.cppreference.com/w/cpp/language/aggregate_initialization), because while the `Foo()` constructor is *user-declared*, it does not count as *user-defined*. Had you said struct Foo { Foo(); }; Foo::Foo() = delete; then `f2` would give you an error as well. This was recognised as a defect and fixed for C++20 -- so a user-declared constructor will inhibit aggregate initialization. I can't remember the issue number off-hand though.
Some object are move-only. I don't see why you should add the constraint of being copyable to the objects you add in your flat_map.
If you want a door that is only useable by speakers of English who never use accents or what-have-you, then I have great news: `std::toupper` already exists! But you want a door that's generally usable for the other ~7 billion people on the planet, well, that's much harder. Libraries exist that can build such doors for you, and ICU is the generally recommended one. Adding this to the standard library in such a way that every single C++ program is not burdened with multi-megabyte data tables describing all the door-making rules for every language on earth is much harder.
Then unless I'm missing anything it's `{}` everywhere unless you want a function like constructor in which case you use `()` which I think it's a pretty simple style guide. And then you get no surprising behaviour? `{}` - value(s) `()` - for `std::string(count, value)` and the like
More like use a third party door design that doesn't need committee approval just to oil the hinges.
Sorry to have concerns.
It is not a profiling library either. Profiling has a concrete meaning, and your library does not do any profiling.
I'm already back to ( ) everywhere [except where **it is** an initializer list], too many problems.
Hey, I managed to handle the Toolchain problem. I am now able to run in CLion. Thanks a lot guys!
Oh I see! You solved the mystery :-) Maybe the "Person surfing" emoji might be more appropriate to use then, or is there anything in particular about Hawaii or the standards meeting that would exclude non-men? ;-)
You need to install mingw or cygwin and install the gcc compiler and gdb debugger for which ever one you pick. Alternatively, you can install msvc either standalone or through Visual Studio. Once you do that, go to your settings-&gt;toolchain and add the ones you've installed and select which one you want as te default. It should auto detect them, otherwise you'll have to point it at the proper directories.
`std::ssize` bothers me, because it's visually similar to `std::size`, and also because we now have so many ways of getting the number of elements of a container: c.size(); // unsigned (for std containers) c.length(); // (for string and string_view), unsigned std::size(c); // unsigned std::ssize(c); // signed std::ranges::size(c); // unsigned, guaranteed to be O(1) std::ranges::distance(c); // signed, O(1) if decltype(c) models SizedRange This isn't great. As to the problems with `for` loops, I think a better approach (also used by modern languages like Rust and Swift) is to avoid having to explicitly specify the type of the loop index at all. For example, with Ranges for (auto&amp; elem : vec | view::take(vec.size() - 1)) { ... } should work correctly even if the vector is empty.
I feel like dealing with unicode is an order of magnitude more complex than uppercase.
Is upper-casing accented text actually easier in Unicode because of composing characters?
&gt; üèÑ‚Äç‚ôÇÔ∏è Probably because it's encoded as "surfer" + "combine" + "male"
Why not rely on the underlying system? Or something e!se, e.g. the de-facto standard ICU?
Nah thats not what i mean. What i said is coupled to the current exception specifications for std::vector for example. https://en.cppreference.com/w/cpp/container/vector/push_back This behaves the way i described (if you push back into vector over the current capacity its moves the element into the new storage only if your types are no throw move constructible. otherwise it copies. if no copy constructor is provided, than it just plain moves but all bets are off when an exception occures)
don't forget the lowley number of code units in codepoints/graphemes/etc
Roll your own. the standard library is a shitshow, clusterfucker, and unmitaged disaster for decades.
Nope. Precomposed "characters" (let's not even begin with that) exist only to facilitate exchange with preexisting standards for round tripping. Most new Unicode codepoints are assigned without precomposed variants at all.
This information shouldn't be compiled in; like most locale-specific things it should be taken from the environment. The environment can decide if and how it wants to support this. And yes, that means that the behaviour can in fact change at runtime. But isn't this actually what you want? 
I'm by no means a unicode expert, but I doubt it. You're still going to need to deal with the fact that different languages have different uppercasing rules -- a famous example is that Turkish capitalises `i` differently from Western European languages, so `toupper()` is wrong even even if you stick to plain ASCII.
Did you scrape it from the ancient pile of shit regular UCD, or are you using the machine readable UCD in XML? I've done something similar with the XML one and it just writes various tables for me, tho it's kinda confusing how the various properties fit together.
Sounds a lot like my StringIO, except you have like 38 gorillion files lol.
I'll throw in [ChaiScript](https://github.com/ChaiScript/ChaiScript), Jason has several talks where he goes over all of the C++17 additions and the effect they had.
I have collected it from the HTML tables on FileFormat.info.
Shameless plug for my open source project, a C++17 image representation, processing and I/O library: [https://github.com/kmhofmann/selene](https://github.com/kmhofmann/selene) 
If you don't want the number of bytes then the only other actually useful count would be of extended grapheme clusters, but you basically need ICU for that. Codepoint count isn't helpful at all, because in UTF-8 a codepoint can be anywhere from 1-4 bytes long, so you're always going to need to do a linear scan if you want to deal with them.
Thanks to Deniz Bahadir for providing the slide recording of his talk, so I could reupload the video with better slide view.
What does it iterate over? Code points? Because that's easy, but almost never what you actually want.
There is a plan to add support for unicode, including all the algorithms and database to the C++ standard starting in C++23 (we won't have everything in 23)
You get an upvote!
&gt; you shouldn't ask how many characters there are in a UTF8 string and if you do, you're doing the wrong thing. So if I have a text editor and want to display length of text content or column number, I'm doing something wrong?
&gt;...or to get number of characters in UTF8? [Boost.Stringify](https://github.com/robhz786/stringify) ( not part of Boost yet ) is able to calculate the number of code points ( to use it as the width of a string ) and also to convert UTF-8 to UTF-16 and UTF-32 in a convenient interface.
i think "almost never" is a bit of a stretch. it's very common in lexers/parsers.
If you want your numbers to make sense universally in every language, then yes. Text editors get away with doing column numbers because they're used to edit code, which is pretty much restricted to just the characters you find on a querty keyboard. As for length of text: I'm not even sure what you mean.
thx :)
Why would you iterate over _code points_ rather than just code units in a lexer?
The underlying system - that's what `&lt;locale&gt;` provides. But that isn't what developers want. What do you do if the underlying system is outdated such that it doesn't understand UTF-8 or provide any recent version of Unicode? ICU is great and it's undoubtedly true that most implementations will use ICU to provide any future C++ Unicode text transformation facility. But the Standard can't require it explicitly, since it can only refer to other standards e.g. Unicode.
If you're deploying to a server environment, you don't want to be at the mercy of your server admins or vendor; you want to be in control. &gt; And yes, that means that the behaviour can in fact change at runtime. But isn't this actually what you want? So sorting of lists can change from moment to moment? This is the sort of thing that causes security holes and data loss bugs.
[https://github.com/p-groarke/clamp\_cast/blob/master/include/clamp\_cast/clamp\_cast.hpp#L107](https://github.com/p-groarke/clamp_cast/blob/master/include/clamp_cast/clamp_cast.hpp#L107) and [https://github.com/p-groarke/clamp\_cast/blob/master/include/clamp\_cast/clamp\_cast.hpp#L60](https://github.com/p-groarke/clamp_cast/blob/master/include/clamp_cast/clamp_cast.hpp#L60) and [https://github.com/p-groarke/clamp\_cast/blob/master/include/clamp\_cast/clamp\_cast.hpp#L76](https://github.com/p-groarke/clamp_cast/blob/master/include/clamp_cast/clamp_cast.hpp#L76) &amp;#x200B; I'm baffled the compiler seems ok to execute the `constexpr` function even for those paths. From what I understand, a variable `constexpr` qualifier is lost when passed as an argument to a `constexpr` function. There is even a paper to add this feature: [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1045r0.html](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1045r0.html) &amp;#x200B; So my guess is, the compiler is inlining and able to deduce the arguments are `constexpr`. I won't base the code on that though. Let me know if I'm missing something. Here is some experimentation https://godbolt.org/z/yG0mlo
\&gt; I know that's not answering your question or being very helpful &amp;#x200B; For the record, I think it's a helpful thing to point out to save people from wasted time. I once implemented this at a low level in a software stack, and propagated it through all the layers of the API, and it took a long time to realize that it was never actually used for anything. Length is such a ubiquitous (and necessary) thing with 8-bit strings, it's easy to just assume you need to implement the "equivalent" (which isn't) thing for UTF-8 if you don't stop to consider it.
This is not he right sub for this though.
That is exactly what I'm doing except that I use empty `{}` if I don't have any parameters or values. The reason is that it works "always" (with the above mentioned exception), doesn't run afoul of the most vex parsing problem, and for containers default construction and construction with zero (no) elements is anyway the same.
&gt; The problem is that uppercasing requires a large database which must be continually upgraded as the rules change. I really don't want any kind of "automatic rule upgrade". The version of unicode should be selected: - either at compile-time, independently from the C++ version. - or at run-time, ideally WITHOUT a global "version". My favorite is the latter, with: - either with an enum containing the versions, and each algorithm taking said enum as a parameter. - or with a constant for each version, all implementing a common interface. This way, users explicitly pick the version of unicode they want to go with, and can roll out migration as their own convenience. *Oh... and proper care should be ensured in the toolchain that unnecessary tables be discarded.*
For sure. And this is why an explicit, clear, design will let you pick apart the things that are slow and fix them. I do find that clear and readable to me generally implies the compiler can have a field day with it and make it fast too.
&gt; the only other actually useful count would be of extended grapheme clusters &gt; they don't even necessarily represent what gets rendered to the screen. extended grapheme clusters don't represent what gets rendered to the screen either. They are for interactive text selection/cursor positioning, not rendering. 
To check character categories if you want to permit non-ascii identifiers.
Is there a transcription somewhere, or a summary article? I like learning about proper ways to use CMake, and submitted a few patches to various libraries to fix their CMakeLists, but I just hate watching videos about anything programming-related: reading is so much more convenient.
Odd question - what is the ideal way to parse syntax where identifiers must be ANSI, but strings and comments can be UTF8? Ideally, the identifiers and such can be randomly indexed in constant time.
The std::byteswap link ([https://wg21.link/P1272](https://wg21.link/P1272)) prompts me for a username and password: &amp;#x200B; This site is intended for the use of the WG21 ISO standards committee and its invited members. If you require credentials to access this site, please see your national body representative or send email to [wiki@edg.com](mailto:wiki@edg.com). 
Thanks for this info. :)
Thanks! Let me know if anything extra comes to your mind ;)
I think [p1282](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1282r0.html) comes closest, other than that I do not know any active proposals
Vinnie, your coroutines are way too simple. Anybody can understand them. This is not acceptable. Design something like [this](https://github.com/lewissbaker/cppcoro), and we'll talk.
It looks nice. I will analyze your project in my scientific work in terms of the C ++ 17 constructions used. :)
Not just that, but it would be great for the hearing-impaired as well. I'm sure there's a lot more that goes into subtitles than just a transcript (timing, editing, etc), but it would be a great start. 
There is a blog post from Stephen Kelly: https://steveire.wordpress.com/2017/11/05/embracing-modern-cmake/ The slides from this talk are available here: https://meetingcpp.com/mcpp/slides/2018/MoreModernCMake.pdf
\\sigh I did not write those! I can't take credit for it...
With the monadic operations on std::optional paper, we spell `map` as `transform` in C++. We used map already to mean relation. 
I really wish some easy Rust type lambdas can be added to C++ (`|x| x + 1`). There's some discussion in the past, but was there any discussion at Kona about it?
In some ways this is an unusual case... A lot of stuff that eventually got into the C/C++ standards where tried out in gcc first. I think coroutines are an unusual case that were tried out in clang first.
Fixed.
They were implemented in Visual Studio first, I believe.
How do namespaces and modules interact? Can you just say, everything public in this module is part of namespace X or something like that? &amp;#x200B;
`#include &lt;üèÑüèÑüèªüèÑüèºüèÑüèΩüèÑüèæüèÑüèøüèÑ‚Äç‚ôÇÔ∏èüèÑüèª‚Äç‚ôÇÔ∏èüèÑüèº‚Äç‚ôÇÔ∏èüèÑüèΩ‚Äç‚ôÇÔ∏èüèÑüèæ‚Äç‚ôÇÔ∏èüèÑüèø‚Äç‚ôÇÔ∏èüèÑ‚Äç‚ôÄÔ∏èüèÑüèª‚Äç‚ôÄÔ∏èüèÑüèº‚Äç‚ôÄÔ∏èüèÑüèΩ‚Äç‚ôÄÔ∏èüèÑüèæ‚Äç‚ôÄÔ∏èüèÑüèø‚Äç‚ôÄÔ∏è&gt;`
YouTube automatic subtitles are pretty good.
Your confusion over move\_only meaning that copy\_only objects can't be stored is exactly why we didn't want mo or move\_only in the name.
&gt; std::toupper already exists! `std::toupper` uppercases a single (template argument) `Char` value or a sequence of *individual* `Char` values, using a specified locale. By choosing `Char` as `char32_t` one can perhaps formally cajole `std::toupper` into uppercasing Unicode code points. But even if one could rely on that in practice, then in order to uppercase a `std::string` you would need to convert it from UTF-8 to UTF-32, and the C++11 machinery for that is deprecated. You're welcome to show how to do it. If you choose to provide such a concrete example of your claim, do note that there's no UTF-8 locale in Windows. 
I'm more concerned about correctness. What if size returns a value that doesn't fit in ptrdiff_t? That seems all too likely for something that wraps a file on a 32-bit platform.
Thanks, sorry I didn't link first, I was in a hurry.
Was there any progress made on deterministic exceptions?
I didn't really follow what happened with modules, but IIRC there were two "competing" designs, one of which from Microsoft and they decided to make a new better design based on those two.
That's not being looked at yet; it's for post C++20.
Will this not cause a lot of issues if one links to other packages that was built with libc++?
I think he has the slides and examples here [https://github.com/Bagira80/More-Modern-CMake](https://github.com/Bagira80/More-Modern-CMake)
[https://i.imgflip.com/2ulldt.jpg](https://i.imgflip.com/2ulldt.jpg)
Sorry, typo, I meant "updated". I'd hope it's uncontroversial that the default for any new build should be the latest version of Unicode available at the date of release of the version of C++ selected, but that it should be possible to select more recent versions at least at compile time, if available. But this means that they can't be an enumeration, because the standard can only specify enumerators for versions that exist at the time of release. At the same time, since Unicode contains bug fixes as well as new features, platform vendors will want easily to be able to update the database used by installed programs. So for at least some subset of programs it should be possible to change the version used at load time. 
Great site on mobile. The content is literally 0px wide.
Thanks for the link to the slides. Don't see anything revolutionary, but progress is nice. One thing that made me wonder is that a lot of time is spent talking about OBJECT libraries. Which I never yet used. I know it's just a collection of object files, but what's the main use case for them VS. creating, say, a static library (which is what I usually do with my sub-projects)? Quicker build time due to lack of linking for object libraries?
That‚Äôs **std::**printf to you. 
`toupper` should work fine with UTF-8 data without any type conversion shenanigans (in the sense that it will will work properly on the ASCII subset and do nothing for the rest of the codepoints).
While I agree with the articles premise, nobody is going to change unless a flush less endl is provided. The author points out how newlines differ between implentations, so I find the "solution" to simply stream in '\n' broken at best.
As I understand it, the scope of coroutines encompasses the following features from the the C# world: 1. C#'s `async`/`await`/Task functionality, 2. The `yield return` statement for methods that return IEnumerable&lt;T&gt;/IEnumerator&lt;T&gt;. 3. The upcoming `await foreach`/`yield return`/IAsyncEnumerable&lt;T&gt; stuff in C# 8 that will unify 1 &amp; 2 above. It took me months of continuous usage (and a lot of reading) to master #1 up there. I pity the poor souls who will have to jump straight into C++ coroutines and grasp all three at once. Hopefully there will be a gifted writer/blogger who can do what Stephen Cleary, Stephen Toub, and a bunch others did for the C# world to tame these ideas for mortal developers.
The author also points out how '\n' turns into the localised variant automatically. As long as you're using a formatted output function it converts it automatically.
I disagree. I changed to simply `'\n'`, and it's not a hassle at all. It's just retraining my mind to type something different. Furthermore, rather than `std::cout &lt;&lt; "Some string" &lt;&lt; std::endl`, I now type `std::cout &lt;&lt; "Some string\n"`, which is easier to type. As for how newlines differ between implementations, that has no effect, as `std::endl` is defined to write `\n` then flush, so differing newlines affect `std::endl` as well.
AFAIK, you can't mix the two. The only reason you'd want GCC on macOS is to build applications that are incompatible with Clang + libc++ and to have a second C++ compiler to check your code for portability. 
It was Eric, and then me, and then Eric again, and I've been recently informed by Gor that it's now me again. (Sorry for the mess: WG21 is all volunteer work and we frequently volunteer for things only to discover that we don't have time to finish them.) The tentative plan is to propose both generator and task abstractions for coroutines for the library fundamentals TS and provide *strong* encouragement for implementors to ship them along with C++20. 
Sounds like you have a bad browser. Works fine for me on mobile Firefox
Yeah completely agreed. I'm actually using tracy https://bitbucket.org/wolfpld/tracy which I would consider a profiler. The code is a bit messy, but being something high performance multiplatform it's kinda understandable. 
Works there but apparently not Android browser.
Nope. There is no way portable way to tell it that the text is UTF-8 encoded. Because it gets that information from the locale, and there's no such in Windows.
Ah yes, you are right. It's a sane behavior.
`std::endl` is fine for interactive console i/o. It's not fine for efficient text file i/o, but then iostreams are not fine for that in the first place. So, the advice to ditch `endl` is ill-conceived, in both mentioned cases, and I can't think of more. 
I totally agree. From my point of view, this session would have been OK some time ago. But it missies today completely the point of how one should today write concurrent code . I much more can recommend Sean Parent's session on "Now raw synchronisation primitives" [https://sean-parent.stlab.cc/papers-and-presentations/#better-code-concurrency](https://sean-parent.stlab.cc/papers-and-presentations/#better-code-concurrency) or Sergey Ignatchenko's recent article in Overload: [https://accu.org/index.php/journals/2623](https://accu.org/index.php/journals/2623)
And to use it, you would have to type: import `std.experimental.coro;`
Is this the same as \[x\]{ return x + 1; } in C++?
I didn't think the author was trying to deny any use cases for flushing the stream, just that std::flush should be used instead of endl in those case.
Nice work! Playing with ranges a bit, the compile times seem somewhat longer than I expect. Is that the LLVM implementation, or just what's needed to do the template gymnastics for this? I'm curious if there's a path to the compile time being as fast as the non-ranges equivalent code.
`fmt::print()` or hopefully `std::format::print()` or w/e soon
Damn, It's starting to get quite difficult keeping up with all these events. The speakers must love the travel.
Iostreams is the worst part of libstdc++ std::print sucks because it makes you care as bout how to print integers and punishes you if you get it wrong.... just print my damn integers thank you!
Consider Python and Perl. The more years pass, the more I am convinced terseness (and in particular symbols) are a detriment to readability in all languages. This is not math, where a extremely hard topic can be modeled by a very small number of variables. This is programming, where we do have a thousand variables around. I have even switched years ago to `and or not` instead of `&amp;&amp; || !` even in C++.
I don't think this is really a problem. Unicode doesn't evolve *that* quickly, and is not that common any more for new scripts and characters to have upper/lowercase or special normalization forms. At this point, Unicode releases mostly are about new esoteric scripts and Emoji (ugh). If you Unicode database is old, so what? It's still good enough for 99% of the text that you will encounter. It is certainly favorable compared to not having any built-in Unicode handling.
Unicode upper casing is actually very... character set specific. In some cases it is a bit fiddle, in others it is a range addition, in others they run every other but with exceptions so it may be odd/even for 40 characters in a row then there is a character with no upper or two characters that upper to the same character so now it runs even/odd. Then you run into the absolute worst case where the upper case of a character is two characters (There are two that I know of and that is only in 13 languages). And about 100 other rules I probably don't know.
Meh, just use /usr/bin/aptitude
My apologies, I misread the section with how \n is in handled by each implementation. Yes "some string\n" is easier to type, but what if the last thing is not a string? Knowing now that \n is handled by the implementation, I still think one could be provided. Something like the one described in the Kuhl12 reference. 
Yes, my bad I misread that section. I still think the nl described in the reference Kuhl12 should be provided however. 
Even that isn‚Äôt a good idea. This especially in texts focused on students that may have issues grasping what a stream is. I kinda consider std::endl as an indication that the stream is actually put to file or terminal. Which is pretty much what this author is complaining about. In my mind it is the right behavior for general programming. The author instead wants to make a more complex approach the general form. Honestly I don‚Äôt see the point. If your goal is some sort of high performance mark streams might not be your best approach to begin with. Beyond that terminal I/O is no longer a problem on most platforms so a modest gain isn‚Äôt (if even possible) a huge deal. Now I must admit that I‚Äôve embedded \n in streams where I‚Äôm thinking in terms of a block of I/O that gets terminated with std::endl. Usually that is the result of being lazy leading me to thinking bad of myself. In most cases I‚Äôm thinking record to device where a flush secured the end of record. 
Try building and running on all 3 of the major platform to see how well this works out. I‚Äôm actually curious because if memory serves me right you will have issues. 
&gt; So if I have a text editor and want to display length of text content or column number, I'm doing something wrong? Not a Unicode expert, but I think that for row and column information in text editor you probably care about grapheme clusters. But even then you need to care about half-width and full-width graphemes, as the latter will take up two columns.
inlining is an optimizer thing - constexpr is a compiler thing. I don't think the two are related (but I could be 100% wrong).
It‚Äôs works on all platforms without issues.
Well you can't turn your static libs into a dynamic lib, so supporting multiple deployments might be one reason.
I thought fmt::print is not gonna be included in the c++20 draft?
Works fine on Android browser.
Is print even being standardised? I thought it was just to a string or an output iterator.
Mysql has also plenty of issues, obviously PHP isn't the only one to blame.
Well if it outputs a string, you can send that through iostream. Performance is perfectly fine when no formatting occurs.
i dont see how std::flush would be hard to understand but std::endl wouldnt be, since they do the same thing. can you not just as easily say std::fulsh is "an indication that the stream is actually put to file or terminal"? I suppose "more complex" is subjective here but i dont find either complex at a high level, in fact I found \n + flush to be more expressive. if i see std::endl i may think "did they really mean to flush the stream here?" with std::flush thats not really a question. in my mind the only real difference between the two is the expressiveness. as you said, the performance conversation is most likely irrelevant.
Have the iterator return a 32-bit code point. No combining whatsoever. It's the only sane interpretation that won't cause more trouble down the line. Combined characters, you can't provide that in a standard library because the Unicode standard changes too much with new characters every year.
 std::cout &lt;&lt; ... &lt;&lt; '\n';
"here's my program written in c++" is off topic here.
The bot can PM instead of comment. Would be less noisy.
If you look at one of the implementations reffered to in the article (specifically Kuhl12) you will see why that isn't the full solution. 
We build our software on CentOS6 with devtoolset which uses Qt and we ship a single binary for multiple distros just fine (runs on my Fedora, customers' CentOS, and other folks use Ubuntu). Granted, we compile Qt too, but we do that just once per Qt change.
... It's how you print a newline after printing something that isn't a string literal where you can put the `\n` at the end. I suppose you could use `"\n"` instead of `'\n'`, but using a string literal to print a single character is something I've always thought was pretty silly.
&gt; Did you see the freestanding proposal? Yes. It helps with "let's add the kitchen sink". It doesn't really help with "I can't use anything in the stdlib because it allocs or throws". It doesn't help at all with "they removed `register`". ...assuming it was actually usable for us. But by standard you can't even rely on e.g. sprintf being available in a freestanding implementation, IIRC. More on this in a moment. &gt; Does anyone force you to use the std library or RTTI? Unfortunately, as soon as you pull in ~any of the standard library, you're forced to pull in large chunks of it. For instance: try to pull in `new` to get operator new? Well, `new` pulls in `exception` pulls in `typeinfo` and `type_traits`. (This is the major issue with the standard's approach to freestanding implementations. What we want is "guarantee that including X doesn't include A,B,C,...Q". Not "B..P doesn't exist".) Our compiler is smart enough to most of the time figure out trivial cases (i.e. virtual with one implementation), which is the only reason why we survive at all. Even then there are problems. And not using the standard library at all - even if were actually doable (there's no way to use e.g. operator new without using the stdlib I believe) - is throwing out the baby with the bathwater. I'd rather not have to (badly) reimplement snprintf, for instance. &gt; Is C better at this given your use case is very specific? We were torn between C9X and C++03 for a while, and ultimately decided on C++03. C doesn't have: 1. Decent compile-time operations. _Very_ handy for embedded devices. Templates are much better than macros in a lot of cases. `constexpr` _would_ be lovely, if we can ever actually update to a version that properly supports them. C++11 is annoyingly restricted, our compiler even more so. (Now if only there was a decent way of including a file as a static const array (or better yet, building it at compile-time) in such a manner that the compiler can optimize based on it... but that's an edge case.) 2. Encapsulation without runtime penalties. private / public / namespaces / etc are all useful. 3. A decent way of doing RAII.
Whining about `std::endl` in this way is a great example of very premature optimization.
wait wait what? what's going here? I've been disconnected from c++ lately, what is this fmt:: thing?
&gt;If you're talking about using it with wide streams, you'd just use a `L'\n'`. That's exactly what I'm talking about, there should be a standard way to write a new line without flushing the stream. It should work without the user having to know about the underlying stream as std::endl does.
The most annoying bit of `std::endl` is simply that it's too long to type. For just getting some quick output, like in print-debugging, I find `'\n'` is a pain to type as well, so I use this little [header](https://github.com/degski/Sax/blob/master/include/sax/iostream.hpp) and just write `std::cout &lt;&lt; something &lt;&lt; nl;` or `std::wcout &lt;&lt; something &lt;&lt; nl;`, no rocket-science, but convenient.
There is /r/cpp_review 
But again, some of your arguments like ‚Äúif I want to use any‚Äù I have to pull RTTI are true. But the standard library is implemented to serve more uses. If you know what to choose I am sure you can have a better experience (toolchains apart) than in C. Just do not use any, as you say you can still have templates, constexpr, rely on non-virtual funcs and compile-time abstractions. What you ask for in many cases are in my view extreme corner cases. Extreme to the point that I think no system language supports that. But I do not know your field in as much detail as you do.
This is not really a C++ question, try /r/VisualStudio.
It looks more like disproportionate and apocalyptical whining.
That one is far less intuitive, agree. But it still makes sense gramatically speaking.
it's not like Rust supports any of that either...
I am not a moderator, but have been here for a while. &amp;#x200B; First of all, a lot of projects have been posted to r/cpp [https://www.reddit.com/r/cpp/search?q=github.com&amp;restrict\_sr=1](https://www.reddit.com/r/cpp/search?q=github.com&amp;restrict_sr=1) &amp;#x200B; I think that FOSS projects can be suitable for posting here. I think it depends on the project. 1) Is it just a toy project that would for example be something that you would do in an undergrad class? For this project, I do not think it should be posted here. &amp;#x200B; 2) Does it illustrate some neat C++ techniques or a new way to use a C++ language/library feature? I think this would be useful to post here. Example is compile time regular expressions or magic\_get, etc. &amp;#x200B; 3) Does this provide a modern C++ way to do something that is useful to a lot of C++ programmers? I think this would also be useful to post here. Examples are stuff like http libraries (Boost.Beast), text formatting (fmtlib), json(nlohman::json), language binding libraries (pybind11,sol2), unicode handling, pattern matching(mpark/match), error handling(outcome, LEAF), etc. &amp;#x200B; I know I definitely like seeing posts about libraries in categories 2 and 3 below, and I would be sad if all such libraries got relegated to another subreddit. &amp;#x200B;
I'm not sure if this is _exactly_ your problem, but it's close: https://gcc.godbolt.org/z/y_ENdF I have stopped trying to rationalize uniform initialization -- for me, it sits right behind `vector&lt;bool&gt;` in the realm of unintended design consequences. It fixed one annoying problem and replaced it with a half-dozen more.
This talk introduced the concept of OBJECT libraries to me. Previously I would have compiled the sources into a STATIC library and then link to it from multiple targets. Is the only added benefit of using an OBJECT library that you skip a linking step?
The one place I've used OBJECT libraries is in a form of nVidia Textue Tools, because the existing cmake broke the overall libraries down into a few static libs and four dynamic libs. The bundled can projects worked, but trying to build via cmake on windows did not. I was able to fix the cmake build with minimal effort by turning every static or dynamic lib, except the top level one into an object library.
modern c++ library for printf style, and the formatting portion of the library is set to be in the c++20 standard. https://github.com/fmtlib/fmt
`L'\n'` is not needed. `operator&lt;&lt;` automatically widens the character with `theostream.widen(c)`: https://en.cppreference.com/w/cpp/io/basic_ostream/operator_ltlt2
This is absolutely not a "premature optimization." It's a simple change that doesn't harm readability (at least once the reader get used to the style) and gives you extra performance for free. Is it premature optimization to take parameters by `const&amp;` instead of by value? Of course not. So why would it be premature optimization to use `\n` instead of `std::endl`?
Yea but symmetry. `std::cout &lt;&lt; "Hi" &lt;&lt; std::endl;`
The [Unicode Standard itself is versioned](https://www.unicode.org/standard/versions/enumeratedversions.html), if mindless paranoia rules out against common sense, it seems safe to just use that as the version. But seriously, I _want_ users to be able to install system service packs and get automatic upgrades to my apps without me having to constantly re-release just because some dependency is updated somewhere. There's a reason people use shared library dependencies, after all. :)
Try Crow. It's a tiny Rest api, header only library. It's syntax looks very similar to Java annotations. https://github.com/ipkn/crow
What does it do and how does it work? There is no description. 
Hi, I'm a lead engineer in the team building the Linux extension. We support build events, and in theory you can orchestrate what you want using rsync as post/pre build events. You can also orchestrate it using a pre build event, the Visual Studio Linux extension will automatically sync the sources back to the Linux machine. 
Ok, so Unicode 11 has: &gt; * Georgian Mtavruli capital letters, newly added to support modern casing practices &gt; * Hanifi Rohingya, used to write the modern Rohingya language in Southeast Asia &gt; * Medefaidrin, used for modern liturgical purposes in Africa &gt; * Mazahua, a Mesoamerican language recognized by law in Mexico &gt; * Mayan numerals used in printed materials in Central America &gt; * Historic Sanskrit, Gurmukhi, and the Buryats &gt; * Five urgently needed CJK unified ideographs: three for chemical names and two for Japan's government administration Only one of those points is about "esoteric ancient scripts". And wrt emoji, users will want to start using new emoji the moment they are released. This is a good argument for having an external database, btw. If the facility is optional, is it still mandatory for implementations to make it available? We don't want a situation where implementations leave it out and claim full C++ compliance. 
Crow, Civetweb, h2o... :)
My opinion is that mixing configuration and text template languages with a Turing complete language is in the long run more pain than the immediate productivity gain is worth. I believe that configuration and text template languages should be deliberately non-Turing complete. If you want to do complicated stuff when producing the text from the template, write a separate program in Lua or C++ or your preferred language and have that use the templating library to produce what you want.
The mere thought of typing `&lt;&lt; '\n' &lt;&lt; std::flush;` makes me want to slice my wrists
I think Jason Turner made a good video on `endl` usage: https://www.youtube.com/watch?v=lHGR_kH0PNA
It seems more readable (at least for me) writing `std::cout &lt;&lt; "hello world" &lt;&lt; std::endl;` than `std::cout &lt;&lt; "hello world\n" &lt;&lt; std::flush;` &amp;#x200B; but maybe I am just a n00b.
Has any of them support for exploring an API that implements HATEOAS? Like [Traverson](https://github.com/traverson/traverson/blob/master/readme.markdown) from the JS and Java world. Most so called REST libs are more or less simply http libs. And it's only useful for the client side, because they lack functionality for the server side like URL generation and so on. 
I would be fine with that. What I look for is mentioning all 8 sections, which seems to be the most common deficiency.
Sadly the author died a while back and the project is abandoned (last commit a year ago)
I must sadly tell, i was secretly hoping, that [New error/exceptions model](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r2.pdf) proposed by Herb Sutter will make it. IMHO results are one of the biggest c++ pains(not that many other languages would have this issues solved).
Qt alternatives. I believe they end up at the end.
I think the point is the 2nd point of the Zen of Python: `Explicit is better than implicit.` Most people just use `std::endl` out of habit, and not because it's the behaviour they want. You should instead say what you want to do. If you want to flush the stream, you should use `std::flush`. If you want a newline, you should use `\n`. You shouldn't tie them both together into one operation just because that's common.
You mean [this](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0709r2.pdf)? Ah... so there went my dreams.... :-(
At no point was that intended for C++20.
Using `std::endl` is a great example of a premature pessimization. It manages to be slower, more verbose and more complicated than just not using it.
If you say so. Some of us aren't willing to dismiss concerns just because we don't like them, but you do you.
A special syntactic case should have been made for it in order to avoid the redundancy. There is no real reason the equivalent of `resolve resolve` could not be automatically inferred.
Key/Value sizes could dramatically change the statistics of your benchmarks. `Map&lt;int,int&gt;` would be great for a flat map, but `Map&lt;string,shared_ptr&gt;` might be a whole other story.
There was no time for that. It'll get serious attention for 23.
&gt; Not using endl and so misinterpreting what the output says about where the crash occurred, is a common beginner's problem. Isn't cerr non-buffering? So not using endl on that would not lose any of the output?
I know, that's why i said **secretly** :-)
testing libraries such as [doctest](https://github.com/onqtam/doctest) or [catch2](https://github.com/catchorg/Catch2) have trouble with self-registering test cases in static libraries, and object libraries [help](https://github.com/onqtam/doctest/blob/master/doc/markdown/faq.md#why-are-my-tests-in-a-static-library-not-getting-registered)
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/autvyt/how_can_i_import_remote_linux_c_project_into/ehb4vps/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I believe that translates to \`\[\](auto&amp;&amp;x){ return x + 1; }\`
Unicode contains many characters, such as most East Asian ideographs, that do not require casing. Most of the characters that are cased follow regular patterns. Unicode 11 case mapping (base -&gt; folded, upper, lower but not title casing) requires about 6K (and possibly less with some more cleverness) excluding some locale-specific cases. Here's [some code](https://sourceforge.net/p/scintilla/code/ci/default/tree/src/CaseConvert.cxx) I wrote to do this for all the locale-independent cases. There are also 7 special cases for the Lithuanian locale and 9 special cases for Turkish/Azeri locales which I haven't implemented. Its likely that title casing could be added with another 2K. Less than 9K all up which doesn't seem excessive to include in the C++ standard library.
eastl::hash_map cf. https://github.com/electronicarts/EASTL 
 std::cout &lt;&lt; '\n' Emits a correct line-end sequence on all platforms. 
Yes, but downside of (possible) later adoption is, that i expect quite a few new amazing libraries emerging because of many interesting C++20 features. Though they will unfortunatelly be stucked with old exception/error reporting system. :-(
Casing is just one operation. There's lots more operations that `&lt;unicode&gt;` would need to support: classification, width, decomposition, confusables. It would be reasonable to expect `&lt;unicode&gt;` to be able to provide the *names* (and aliases) of each character. 9K isn't a lot to add to an implementation but it's still too much to add to a compiled binary if it isn't specifically required.
Zen of Python lines 1, 3, 7, 9: beautiful is better than ugly, simple is better than complex, readability counts, practicality beats purity. &amp;#x200B; These all make me think that Guido van Rossum would like &amp;#x200B; std::cout &lt;&lt; my\_str &lt;&lt; std::endl; &amp;#x200B; better than &amp;#x200B; std::cout &lt;&lt; my\_str &lt;&lt; '\\n' &lt;&lt; std::flush;
I have been using restinio: [https://bitbucket.org/sobjectizerteam/restinio-0.4](https://bitbucket.org/sobjectizerteam/restinio-0.4) &amp;#x200B; Very easy to setup, runs in windows with mingw, cross platform, very easy to create routes, quite good documentation.
As far as I know only the `format` API from {fmt} is going in C++20, not the `print` API.
Units would be a great addition to the resulting graph.
u/rtessil the king of hash maps
I have his maps included already :)
&gt; Only one of those points is about "esoteric ancient scripts". I wouldn't say that. Maybe I should have clarified: esoteric *or* ancient scripts. These new "modern" additions affect small minorities for the most part and are only needed for very specific niches. Also, if your Unicode character database is outdated, it doesn't mean that these new additions to Unicode cannot be used. It just means that they might not be handled correctly in all cases.
Arguing about which one is the better default is a waste of time.
yep, that was a praise :p 
I use the C++ Rest SDK for client code, as others mentioned it doesn't seem that useful for server code. The REST stuff in my Windows project is relatively small so at least having the SDK in vcpkg was handy, and client code was simple enough. For another project (Linux this time) I was in the same situation as you are -- old code needs to expose a REST API. The original code was a C+/- mess (C++ code using the old C socket API for no good reason? In 2018?) and was properly replaced by boost::asio based code. Then the REST API was the next step... After a lot of testing with all C++ libs I could find I decided to create a Rust router to the C++ service, first using Rocket then, after I got fed up with build errors caused by nightly changes, actix-web. The router processes and validates the JSON input, converts it to the format already in use by the C++ server and calls it, then re-processes the results to JSON plus HTTP status code. I would advise you to do the same, if possible. You'll have sanitized input to your C++ server (you can clean up error handling code in the C++ side), nice JSON and HTTP status handling, low resource usage and high performance. No need to change tried and true C++ code, just keep it where it belongs -- and that is away from your exposed API ;)
`vector&lt;pair&lt;K,V&gt;&gt;` has worse cache coherency when iterating than if you separate the storage. Also, having `std::flat_map` be an adapter makes it easy for consumers to use any possible underlying container to suite their needs.
I don't think this is a good idea. For one thing, this pessimises the case where you don't mark the comparison `noexcept`, forcing the code to allocate, copy everything over, insert, swap, destroy and deallocate. A **huge** overhead, for forgetting to write a single keyword. All this without a warning. As the article said, this is &gt; burdensome on the programmer-in-the-street who rarely uses the noexcept specifier in practice But let's disregard the fact that not everyone writes `noexcept`, and just assume that all programmers are perfect in this regard. It should **still** not do the whole allocate, copy, insert, swap, destroy and deallocate dance. Why? Because we have no clue if the user actually cares about using the container. If it throws, I would assume the cases where a comparison might throw are quite exceptionally rare, like being out of memory, where continuing as if nothing had happened isn't possible. You probably just want to abandon whatever you were doing, display an error message and maybe recover. And lastly, if the user actually want this behaviour, *they can already implement it themselves*. Copy the container, insert the new element and swap.
Very nice lineup.
Would there be any problems with `std::print`? AFAIK the part of `fmt` that's in C++20 isn't in a nested namespace so would be inconsistent for print.
Unicode support in the C++ standard library wouldn't need to support everything. There are a few common things needed, and supporting those would be just fine. And names are something that is rarely needed, yet they need much space, so it would be quite fine to omit them. If you need everything, you can still use ICU, or some other external support library. Again, Unicode support doesn't need to be perfect (or full-featured) to be useful. Especially when the status quo is "zero".
sure! I'm still figuring out how plotly.js works.
That's much less readable then `std::cout &lt;&lt; "Hi\n";`, expecially if you use a proper text-editor with good highlighting.
An "esoteric" script is only esoteric if you aren't a member of that minority and don't interact with members of that minority. Being able to type or display a character but then have it handled incorrectly leads to confusion and disappointment; it's clearly preferable to at least have the option to be able to upgrade the character database without recompiling.
The status quo is "use ICU". Deciding what should and shouldn't be in C++ - what is often and what is rarely needed - is going to be contentious and will require a lot of committee work.
&gt;seems to be in active development. It's not so easy, unfortunately :( We have some ideas to be implemented in RESTinio but have no time because we are quite busy with other projects. Because of that the further development of RESTinio is frozen for last several months (only bug fixes and minor tweaks). But if someone has a problem or a question related to RESTinio we are trying to respond as quick as possible. PS. I'm just one of devs behind RESTinio project.
I would suggest looking at it from the user's side and use `constexprinit` :-P The fact that `constinit` doesn't have much to do with `const`, but rather with doing the initialization during compilation is something that makes sense if you read standardese too much, but not if you want to use the language.
&gt;So we can figure out the set of headers that a given translation-unit depends on. Now, we need to ensure that if we depend on any header, we also link to its corresponding translation-unit(s). But it's not 1:1 relationship. There are headers without translation units, headers with multiple translation units. And with templates it can get even more complicated. How compiler is suppose to determine that if someone included "foo.h" it should link to "foo.cpp" ? 
Thanks a lot for your work. Your library is great! It is ok that you are not actively adding new features. To me if you are still fixing bugs, adding tweaks and helping the users it still counts as active development unlike some libraries that sometimes are mentioned here that don't receive any support at all (e.g. [crow](https://github.com/ipkn/crow/issues/308)).
try test my hash [https://github.com/ktprime/ktprime/blob/master/hash\_table5.hpp](https://github.com/ktprime/ktprime/blob/master/hash_table5.hpp)
You're right about ranges and whatnot, but character set isn't the right term, Unicode is a character set, you mean a range. Also, (tho Unicode uses the terminology confusingly as well) "character" isn't the corrrect term. A "user identifiable character" is called a Grapheme, which is composed of one or more CodePoints (the things UTF-8 and UTF-16 are decoded to or encoded from, which is further subdivded into CodeUnits). I know, it's confusing at first, but you'll get the hang of it, and it's really important to not make it more confusing than it has to be.
There are multiple definitions of "length" that are useful in text editing. E.g. the string "shelf‚Äåful" contains 8 visible characters, but one needs to hit backspace 9 times to delete all the characters (because there's a zero-width space between 'shelf' and 'ful').
Thank you!
I test some fast hash one case as follow
&gt;After a lot of testing with all C++ libs I could find Could you name those libraries and tell what is wrong with them? I think that information will be very useful as for authors (maintainers) of those libraries and for C++ developers who are looking for tools for RESTful API.
I would be interested in your hashmap implementation if you also had a hashset and good test coverage to ensure correctness. At the moment i am using absl instead, but i would prefer a header only solution.
Isn't the most problematic part of headers is the maintenance of declarations? This is the reason why functionality such as "Move to Source" / "Change Signature" is always first class citizen in any C++ IDE / refactoring tool. The other thing - knowledge of what you can forward declare (which is btw thechnically just another boilerplate) is actually pretty arcane and people end up with unnecessary headers included in headers more than needed most of the time. I understand that these two points are more related to the name of the article rather than content but I do think it still needs to be pointed out.
&gt; But it's not 1:1 relationship Correct. To be more precise we need a map from header-file to a set of translation-units as mentioned in the notes. The set can be also empty. &gt; How compiler is suppose to determine that if someone included "foo.h" it should link to "foo.cpp" ? The build-system should use the compiler to know who included "foo.h". The build-system can then check if target that uses "foo.h" also links in the corresponding translation-units, in this case just "foo.cpp". The compiler does not know, but the build-system should. &gt; with templates it can get even more complicated Can you elaborate? - I don't see how this is related.
Not sure if it's active but Google has a repo doing something similar https://github.com/google/hashtable-benchmarks
`Forgotten break is quite common error in C/C++.` Not really. And most compilers warn about it. Hence `[[fallthrough]]`.
Linking a static library into an executable only brings in those symbols that are actually referenced in executable's code (or other libraries). While this is usually a nice optimisation, it means that static data and static objects (that do interesting things when initialised) can be silently dropped. Object libraries allows you to treat such code as a library and build it only once, while ensuring all of it is linked into multiple executables. If you haven't yet had a need for them, just consider yourself lucky, and remember that they're an option for the day when you do.
&gt; the corresponding translation-units What do you mean by corresponding? Do you plan on having the compiler parse the header &amp; spit out forward declarations then look for object files that have global symbols for them? If you're going that way, why not ignore the fact that I included foo.hpp and just note that I have the symbol `int foo()` undefined and look for who has it defined?
&gt; It would be *really* nice to write: &gt; `case SUNDAY =&gt; System.out.println(6);` No! I don't want to write `System.out.println(6)`... Oh, I missed the point? OK. How about [P1371](wg21.link/P1371) Pattern Matching? It seems to have even less typing. inspect (x) { 0: std::cout &lt;&lt; "got zero"; 1: std::cout &lt;&lt; "got one"; _: std::cout &lt;&lt; "don't care"; }
I've just tried it, you still have debugging output with printf() in the code. Also it would help if emplace() was available.
I've added it, looking forward to the results!
I've tried to use their benchmarks and integrate my hashmap there, but I could not figure it out and got annoyed enough to create my own benchmarks.
Like /u/neiltechnician said, what you're looking for is called pattern matching and it is coming in C++23.
&gt;The build-system should use the compiler to know who included "foo.h". The build-system can then check if target that uses "foo.h" also links in the corresponding translation-units, in this case just "foo.cpp". The compiler does not know, but the build-system should. &amp;#x200B; Let's say in the project five cpp files include "foo.h". How the build system can know which one of those files is the corresponding translation unit and which ones are supposed to be link against that one? You can't assume they will have the same file name and different extension. Or, different scenario, you have declared class A and class B in foo.h, but definitions of the methods are in A.cpp and B.cpp. Because, why not? Some project have common include file and split cpps. Or, the other way around. A.h and B.h, but "common.cpp" file. &amp;#x200B; Build system would have to scan header and map classes and methods to cpp files. But, when there is no cpp file or linked library, how it's supposed to know where it can be? I don't see how it can know and not just tell you there is an undefined reference. &amp;#x200B; &gt;Can you elaborate? - I don't see how this is related. &amp;#x200B; When you use a template, a new instance of the class is generated for each translation unit. They are merged during linking phase (at least GCC does it this way. I think Borland compiler tries to map every template usage and generate only one instance). That's why templates are often implemented in headers, so you don't have to worry about linker errors. But, you can implement them in .cpp files, if you only require few predefined instances. So, I think your smart build system would also have to map template instances across the whole project. &amp;#x200B;
The killer feature is IMO to provide an OpenAPI swagger codegen interface. From the swagger-codegen github... **C++** (cpprest, Qt5, Tizen) clients **C++** (Pistache, Restbed) servers So far I only see C++ rest SDK and pistache as supporting a flexible license.
Thanks for the slide! `include_guard` is amazing! I want to try it! Currently, I am using CMake 3.6 with GCC 4.1 on the build server. Time to upgrade.
oooooo this talk of slicing wrists is making me hot for std::flush! fwiw I would write endl in that case too lol. But if it's "text\n" &lt;&lt; std:: flush that sounds more appealing to me after reading the article. Otoh maybe take a break before the next time you write to the console (;
How about switching on ranges? &amp;#x200B; inspect (x) { &lt; -10.0: ...; &lt;= 0.0: ...; \&gt; 10.0: ...; } &amp;#x200B; Can it do that?
"By default , operator() of the closure type is const." - no, it's not. For example: `int x;` `[&amp;x]() { x = 6; }();` Is completely legal. On the other hand, If you capture \*by value\*, you have to use the `mutable` keyword to be able to mutate the captured variable. The reason for this decision is a bit subtle: a lambda which captures by value is look like a "pure function" without any internal state, so it will be non-intuitive if such a lambda will be able to change the captured values (and become stateful). Since this is only relevant to value-captures, a lambda which captures by reference can change the captured variable even without the `mutable` keyword. &amp;#x200B; So, the operator() is not const by default, and actually cannot be const in any way. 
&gt; Version 0.1 released 1 year ago &gt; Last commit 1 year ago
I really like what that proposal is suggesting. However the example you gave here is the weakest one imo, considering it can already just be done with a switch statement.
&gt;just note that I have the symbol int foo() undefined and look for who has it defined? Unfortunately, the C++ grammar doesn't allow for easy identification of what is a type and what is an unknown variable. The lines: a b(c); b(d); Could be: a b(c); // a and c are types, this is a function forward declaration b(d); // d is a variable, `b(d)` is being called or: a b(c); // a is a type, and c is a variable or function - this is a variable declaration b(d); // d is a variable, `a::operator()(d)` is being called note that in the second you're not needing to import a function called b, you're importing a function called a::operator() instead!
&gt; I'd hope it's uncontroversial that the default for any new build should be the latest version of Unicode available at the date of release of the version of C++ selected, but that it should be possible to select more recent versions at least at compile time, if available. Well, it's not. Changes may cause, or reveal, bugs, and therefore it's important to be able to control when a change makes it in production. In this case, I think the safest would simply be for the standard to *pass the bucket*. That is, there's no reason to enshrine a specific Unicode version in the C++ standard, instead you could standardize the *interface* and a way to *discover* which versions are available and to select which to use.
1. I don't think you should try all the combinations of hashmap*hashfunc, which makes the result figure hard to read. Just stick with one hash function that is not identity (identity hash works great on random input but is mostly a bad choice for real-world applications). The effect of non-identity integer hash functions is usually small. 2. I prefer to vary the number of elements, and show memory and runtime in one figure, like [the one I did here](https://github.com/attractivechaos/udb2). That benchmark is simplistic, but I think the figure is good (IMHO, of course). I know someone in your other thread asked you not to benchmark memory and that post got lots of upvotes. However, a benchmark without measuring memory is pretty much pointless. If all we care is performance, we can often pre-allocate a huge hash table to avoid the costly rehashing. 3. For benchmarking, don't use `-march=native`. Specify the architecture explicitly. [Intel i7](https://en.wikipedia.org/wiki/List_of_Intel_Core_i7_microprocessors) is associated with many architectures. 4. What do you mean by "Iterate"? Insert all elements in random order and then iterate?
Bytell hashmap
I think the idea is to be able to express the relationship of headers and translation units in your build-description. You are right it may not be possible without extensive static analysis to figure out the *minimal* dependency graph, if there are no conventions in place. However it is quite easy for the library author to group headers and translation-units together and assert that if you need one of those headers you need also to link the appropriate translation-units.
Short answer: yes, but not with that syntax. Long answer: read P1371 section 9.4
Good examples and a nice refresher on lambdas. Thanks
I have it already
Oh I don't see it in the post
It's the skarupke flat_hash_map, it's actually the ska::bytell_hash_map, but the repository name is flat_hash_map so this is a bit unfortunate naming
Oh okay. Nevermind.
Even `std::cout &lt;&lt;` is quite painful to type. I always find myself collecting energy when I want to write a few lines of code that print something in C++. It is like "agghh...here we go..." Printing text is overengineered in C++. It always feels like a small tech demo showing how the fancy stream operators work, yet it does not accomplish much. C-style `printf()` is much more relaxing to use.
Believe it or not, IEEE did this with C a while back - see https://standards.ieee.org/standard/1003_13-2003.html for some info.
I've been thinking this for a while. Why isn't there a build system that builds automatically using the header dependencies the major compilers can spit out, along with a simple rule mapping local headers to source files and system headers to libraries? Or is there? Such a system could probably build a decent fraction of C++ projects without any build definition file at all, or a trivial one that just specified an output name and a few #defines.
When a user really want an invariant to hold, could he not use a library function to get that guarantee, via copy+swap? template&lt;class T, class F&gt; void strong_invariant_invoke(T&amp; x, F f) { auto y = x; f(y); using std::swap; swap(x, y); }
&gt; C-style printf() is much more relaxing to use. I have to dis-agree here, remembering the format-string to pass in is a real pain it the proverbial behind, particularly when you want to print 64-bit int's.
I don't like it because it goes against C++'s spirit: don't pay for what you don't use. &gt;subC++ will have modules, concepts, contracts, auto and lambda from the start Cool, C++20 already has that. Given that the language isn't used, it's basically has the same effect. &gt;subC++ will not have headers at all Bad idea. Sometimes headers are needed. &gt;strings literals are always implicitly objects, "hello" is actually std::string("hello") hence you can only work with std::string, no need for const char* and no string_view. copy, move or reference strings throughout your code. Why are you against std::string_view? std::string is the wrong choice since it gives you a heap allocated array, which for arrays stored in the data segment. &gt;no exceptions, as contract can fill their role Exceptions are sometimes useful. Just don't abuse them for programming errors. &gt;no pointers, only references, iterators, smart pointers and copy/move are needed Huh? You can't rebind a reference, and if you could by default you basically reinvited. &gt;some runtime-provable UB's like dividing by zero would just resort to some global contract especially for that specific UB. That's dumb, why not make it an assertion/pinch 
Yes. That was exactly my point.
The major selling point of Herbceptions is it's semantically equivalent drop in replacement
We get this topic fairly often so there are some people interested (definitely not me though). Now, one immediate issue I see with this is for you guys to reach a consensus on what to keep and remove. Wouldn't it be easier to modify a compiler so as to be able to remove features to your discretion?
Other way around.
&gt; subC++ will not have headers at all Sure, but keep in mind that there are other preprocessor uses that C++2a/C++20 still has no replacement for. &gt; strings literals are always implicitly objects, "hello" is actually std::string("hello") hence you can only work with std::string, no need for const char* and no string_view. copy, move or reference strings throughout your code. This is throwing away "don't pay for what you don't use" principle. &gt; no exceptions, as contract can fill their role Contracts can't replace exceptions completely. &gt; no pointers, only references, iterators, smart pointers and copy/move are needed There are data structures that can't be implemented without memory leaks or without breaking some invariants. &gt; subC++ library code can use the greater C++ language, but the user can't. How would that work? &amp;nbsp; All that aside, the issue with breaking backwards compatibility in order to create a cleaner language is the same as creating a new language - you have to persuade people to jump ship. - There is a clean "fork of C++". It's called D and isn't used much. - Python made a fork when Python 3 came out. - Python 2 will reach EOL in 10 months. - Some statistics say Python 2 still covers 70% of the market share. - You'll leave behind people who can't switch and you'll effectively create another Python2/Python3 split, only much worse. Those are my thought. Herb Sutter thinks we can eventually get a safer, more restricted language, but it has to be opt in with something like "using C++ strict;" directive.
Unzip (and zip, which I'm more familiar with) do not take lamdas so I have trouble seeing how transform can be a special case of them.
There's also copy-list-initialization: \`int w = {5\];\` When more than one works, the author (via C++ Core Guidelines) recommends uniform initialization: [ES.23: Prefer the {} initializer syntax](http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Res-list), but you will surely hear other recommendations.
Actually there are considerably more variants, but most people just use copy initialisation for basic types like int, direct for classes (or variants like `myclass a = myclass(b);` or `auto a = myclass(b)`), and list (`int a[] = {1,2,3};`) when it makes sense. As of the C++17 standard adding "guaranteed copy elision", it no longer involves any actual copies and is equivalent to direct initialisation, but most people seem to like initialisation to have an `=` in it.
Ah, that's great news! I'm even moderately enthousiastic about the syntax ;-) What does the ^ symbol mean in some of the examples in P1371? Like this one: 
I mostly use uniform initialization unless its a basic type like int. Then I use copy initialization. 
I think the Evoke build system does something like this
Nomenclature discussions often get opinion/preference based. They can also get heated quickly as people tend to fight strongly for what they are already used too. My preference is to view the definitions of benchmarking and profiling somewhat along the top answer here: https://stackoverflow.com/questions/34801622/difference-between-benchmarking-and-profiling Based on that since "A profile result might be a table of time taken per function, or even per instruction" I'd argue the term profiling fits better. But leaving nomenclature aside the library is just like you somewhat point out **designed just to do one thing** (that is **measure performance** of selected fragments of code) and to **do that one thing well**. And as long as it does that thing well, and helps people to improve their code we might also call it banana-library. Or not. That might confuse some. Thank you for the feedback. I too hope this encourages beginners but also seasoned veterans to optimize their code and share. Slow software is really a pain to use.
Tracy is cool but it's something quiet different. It has a client server architecture, and it understandably introduces a lot more overhead.
Can I access the asset using extern std::byte const varname[]; extern std::byte const varname_end[]; ? 
If you are going to do that direction, dump the standard libraries altogether. Go back to a core, safe LANGUAGE that has no assumptions as to run-time libraries. Obviously then run-time libraries can be built on top of it, but it itself wouldn't impose (and hence have to deal with the legacy issues of) any existing libraries. Have only the concept of an object, the scoping of objects, standard operators and methods supported, etc... but impose no classes or hierarchy itself. Someone might argue that then no one would use it. But of course no one is going to use it anyway :-) That's always the problem, getting any new language up to any remotely significant level of adoptions such that young Johnny programmer wannabe feels like it is of any reasonable career benefit to learn it. The benefit of such a tabula rasa is that it could be used in many ways, from the smallest embedded applications up to large systems that come with a very well defined and extensive class hierarchy. People could use it to create very unique systems that they can impose their own structure and semantics on from the ground up. &amp;#x200B;
Thanks! That was the aim of this blog post :)
Agree, the only realistic way forward is with compiler flags, ideally that are common across major compilers.
News flash: capitalisation rules and sorting order are _already_ defined by the locale! If that works for type `char`, it can also work for unicode. The machinery gets more complex, but the principle remains the same. 
Google did not come up with any tool called iprof for at least the first for pages of results (as of today for where i searched from). There is a finite amount of good names, and they are going to clash especially if something has no seo and has fallen into oblivion. That's just the unfortunate reality. Just check out ios by cisco &amp; apple. Sometimes something good can even come out of it: [https://www.youtube.com/watch?v=rBjyl1LvBF4](https://www.youtube.com/watch?v=rBjyl1LvBF4)
Thank you for the encouragement.
I agree with the idea of measuring memory usage, but... &gt; If all we care is performance, we can often pre-allocate a huge hash table to avoid the costly rehashing. ... is not true in hash maps. I learned the hard way that a very sparsely populated hash map^1 can have abysmal performance: - Cache misses: each insert is a cache miss, as L1 (data) is only 32KB, so when doing quick insert/erase, it HURTS. - Iteration: the simplest iteration scheme is to check each bucket for the presence of element(s), with a mostly empty map, it's a lot of cache trashing for not much. And therefore pre-allocating a huge hash table which ends up getting sparsely populated leads to bad run times. ^1 *A `dense_hash_map` with an occasional large peak working set, but frequently small working set, in this case.* --- Ideally, you want to measure the cache access patterns of your hash map. You can create specific *cold cache* scenarios where between each operation you purposefully trash the cache, for example by writing random numbers to a large array, then reading it back to sum them all and sending the sum into a black hole. And then the run-time of the operation is dominated not by the speed of the hash, but by the number of cache-lines that the map needs to access, as they are all cache misses.
Trying all combinations is time consuming, but actually quite interesting, especially for the find benchmark. There it quite a big difference in performance. E.g. absl with FNV1a hash takes 170 seconds, and with robin_hood::hash 135 seconds, that's 30% faster. I agree that memory is important. I also want to add a memory vs. runtime chart like you did.
`std::shared_ptr` is barely 16 bytes; a good `std::array&lt;...&gt;` on the other hand. However, I am not sure that artificially inflating the size of the key or value is of much worth. If the size of the value is an issue, it's easy enough to move it behind a `std::unique_ptr`, and done. Pushing the key behind a pointer might cause more cache trashing, but in my experience keys tend to be smallish, with `std::string` closer to the upper-end with its 24 bytes.
Having implemented such a function, I can tell you where I needed it: to generate the correct number of asterisks for use in the password entry field, and to shorten certain log messages if they happen to exceed 1000 user-readable characters. &lt;rant&gt;Maybe it gets both of these wrong because an illiterate peasant like me wouldn't know a grapheme cluster from a hole in the ground, but I'm going out on a limb here and state that I don't actually give a fuck about that. So what if it shows an asterisk too many? So what if it shortens by a couple of characters too much? Did you think that limit of 1000 is the result of a five-year standardisation process by 200 experts? Or was it maybe just a number I pulled from thin air? Take a wild guess...&lt;/rant&gt; So now my software supports all manner of funny characters. Maybe there are entire classes of characters it handles wrong? Who knows! Not me - I'm not a unicode illuminatus. If someone sends in a bug report I'll be happy to look at it, and until then I won't lose any sleep over it.
According to section 5.3.1.3 `^` denotes a pattern that is a primary expression.
I had actually forgotten that "Undefined References" issues existed until I switched jobs. Before the switch, the company I was working for had its own build system + package manager. Nothing grand. And it had its shares of bugs. But I'll give it to the authors: this they got right. The configuration of the build system required, for each library, to identify the directories containing source files, private headers and public headers. Also, the build system came with sane defaults, so that nigh every library followed the default layout. As a result: - If you didn't depend on a library, you didn't depend on its headers either, so you got a preprocessor error. - If you did depend on the library, then its public headers directory where injected on the compiler command line and its library was injected on the linker command line... and it just worked. That's it. No magic, no database, just an atomic "depends on" relationship^1 . ^1 *Actually, the system understood both public and private dependencies, so you could link against a library without having its public headers in the path... but this doesn't cause issues so it's all good.*
On Windows it is indeed a problem, but note that iprof \*\*does not use chrono\*\* but rather wraps QueryPerformanceCounter to be usable like chrono. On modern Linux system chrono when using std::chrono::high\_resolution\_clock is surprisingly good. Older versions used inline asm and x86 CPU instruction counters, but that was not portable and started producing bad results now that all CPU's adjust their frequency dynamically. Please see the \[hitime.hpp\]([https://github.com/Neurochrom/iprof/blob/master/hitime.hpp](https://github.com/Neurochrom/iprof/blob/master/hitime.hpp)) and \[MS docs\]( [https://docs.microsoft.com/en-us/windows/desktop/SysInfo/acquiring-high-resolution-time-stamps](https://docs.microsoft.com/en-us/windows/desktop/SysInfo/acquiring-high-resolution-time-stamps))
What about using binutils' `objcopy -I binary` ? (see https://stackoverflow.com/questions/42235175/how-do-i-add-contents-of-text-file-as-a-section-in-an-elf-file/42238374#42238374 for example)
&gt;no exceptions, as contract can fill their role How? If I open a file, but it fails to open, how is a contract going to give me any kind of error reporting capability, or recovery capability? Exceptions are not only for aborting your application!
Size of `std::pair&lt;const std::string, std::shared_ptr&lt;T&gt;&gt;` is 40 which is "largish" and enough to cause cache misses with flat maps with unified storage, like `absl::flat_hash_map`. Iterating over those with a "largish" pair can be a performance hit over a plain old `std::unordered_map`. More specifically, for me `std::unordered_map` was much faster than `absl::flat_hash_map` when the data structure was `unordered_map&lt;string, shared_ptr&lt;unordered_map&lt;string, shared_ptr&lt;set&lt;const Foo*&gt;&gt;&gt;&gt;&gt;`
So anyone got recommendations for good talks?
Looking at p1004r1 (constexpr vector), shouldn't `constexpr` be applicable to classes and structs? constexpr class vector { /* ... */ }; &amp;#x200B;
&gt; Bad idea. Sometimes headers are needed. For now. There's a handful of things we need them for, and most of them involve things for which we're still stuck using the preprocessor. As C++ addresses those features (reflection and a lazy function argument proposal would kill the two biggest, IMO) we should find that we can finally for real deprecrate headers (and the preprocessor as a whole) and then kill them 40 years later when back-compat concerns are resolved. :) 
The linker behaviour is different, as others mentioned (all objects are linked in an OBJECT target while only objects with referenced symbols are linked in a STATIC target). There's some benefits in terms of DLL linkage models, too; it can be troublesome building a DLL comprised of static libraries in a few cases (particularly if the DLL needs to export variables and not just functions). The other case that can really matter for some is faster link times (for some projects only; slower in others probably), via avoiding having to copy your object files into a library file (e.g. network share builds can improve thanks to the heavily reduced IO). Mostly only a win if you actually are going to reference/use all or most of the target's TUs, I'd expect.
Good to know! I've always been building my own framework on top of Poco libraries. 
I like where you're going with this. A subset of C++ were a lot of the "cruft" has been cut out. But then I looked at your list, and I started to disagree with your choices. 5, for example. Without `char*` or `std::string_view`, there's no way to express a substring without making a copy, and that's just unacceptable. Or 6, because exceptions can be a good thing, and contracts don't fulfill that role at all. Or 7, because raw pointers are an essential tool. And herein lies the problem: you're never going to come up with an acceptable subset of C++ that everybody will agree on, or even a general consensus. There's just too many opinions on which subset is acceptable in which situations.
Actually you've discovered an important bug. Thank you. Here's the fix: https://github.com/Neurochrom/iprof/commit/c10c4c7b538e119ece0c9a1b893a56c02716dc26 
This is an easy and efficient approach that works for a homogeneous codebase. I have the similar thing at my work (inherited it). Small differences: private headers are with sources; public headers have their location inferred from the base directory of the sources (no need to specify headers location at all).
&gt; std::hash (Identity hash, as used by libstd++) Uh, on what types? And on that note, what kinds of keys are you testing here? That can have a _huge_ impact on some hash tables' performance characteristics (e.g. strings vs integers vs large value structs, etc.). &gt; robin_hood::hash Would be nice to link to implementations in your write-up. :) https://github.com/martinus/robin-hood-hashing/blob/23ed3606eae9fb3d121d40775c9998e9778ceb02/src/include/robin_hood.h Looks like it's a mixture of different hash algorithms, depending on the key type.
Thanks :) though I start to lag a bit behind. Otherwise as some others have said: * Try with larger keys, `std::string` of the same size can be a good base. When the key is small enough the 'Small String Optimization' will enter into play, with bigger strings (of the same size) each comparison may incur a cache-miss as the content of the string itself is allocated on the heap. * Vary the number of elements and save the load factor in addition of the time and memory. * With hash functions which are long to calculate (like on large string), setting the `StoreHash` parameter of `tsl::hopscotch_map` and `tsl::robin_map` may be interesting (but not really good on too simple hash functions). * The `tsl::ordered_map` may also be nice, it'll be slower on most operations but it should be the fastest on iteration and rehash while keeping a good memory footprint. Note though that you should use the `unordered_erase` of this map for the deletions tests, the normal `erase` operation is in O(n). 
Highly recommend https://youtu.be/ZfP4VAK21zc . Hope it helps!
&gt; strings literals are always implicitly objects, "hello" is actually std::string("hello") hence you can only work with std::string &gt; some runtime-provable UB's like dividing by zero would just resort to some global contract especially for that specific UB. I believe these contradict with &gt; every valid subC++ program is a valid C++ program Probably other restrictions can be enforced by clang-tidy or the like.
Because zip is a special case of zip\_with (zip takes the function make\_tuple).
Two questions: 1. Was the issue *iterating*, rather than find/insert/remove? 2. Did you have a good or bad quality hash? I find the issue intriguing, I really don't see how `unordered_map` could perform better: it's a sea of pointers so every time it moves to the next element in a bucket, it dereferences a pointer. I would expect an open-addressed map to actually perform *better*, in this case, since with linear access comes prefetching, and in the case of `absl` the mix of linear/quadratic probing should defeat clustering issues while preserving prefetching! Did you ever identify the exact source of the slow-down?
Okay, I'm not sure how that relates. Are you saying that zip and transform are both special cases of zip_with? Could be, but zip_with was not under discussion.
You are right. When I say "often", I was exactly thinking about the two things you mentioned. I should have put it in a different way: it is easier to implement a fast hash table if you don't care about memory.
I think a more informative benchmark is to have a custom hash function that records the number of times the function is called. This will directly show the impact of a slow hash function. As a side note, I don't know how FNV1a is implemented in MSVC. It seems a bit weird why we'd use FNV1a on integers.
&gt; Because all of those limitations the Committee started to design a new feature I suspect the proliferation of mutually incompatible lambda libraries had something to do with it, too. I recall using at least two kinds of boost lambdas in production.
Was this yours? As someone who's been coding C++ less than a year but just started with it professionally, this was extremely useful!
It is completely trivial to read either of them...
The overhead of tracy is actually surprisingly small and I wouldn't be surprised if it would be as fast as iprof. &amp;#x200B; The only overhead (as far as I know) is that it introduces from the application (/server side) is that it writes to a lock free concurrent queue, which is surprisingly fast. I noticed a slowdown of 2-3% doing something like 100k+ measurements/second.
Honestly, I disagree. Hash tables have become so fast these days that to be competitive you really have get into a mechanical sympathy mindset. I mean, algorithmically speaking, implementations such as Robin Hood with Backshifting Deletion look super good: they have very nice algorithmic complexity bounds on most operations! And yet Abseil. The Swiss Table in Abseil is literally one of the dumbest hash map implementation in the world, algorithmically speaking: it's a text-book Open Addressing implementation, with Quadratic Probing. That's it. Implementation-wise, however, it's full of mechanical sympathy: - Unrolled: because modern CPUs love array accesses. - 16 elements: because nigh every x86 processor running today has SSE2 instructions (16 bytes). - Group Index/Byte Index split: see aforementioned SSE2 instructions. Abseil's Swiss Table is literally the revenge of the hacker over the academic, it's very much centered on CPU/memory considerations, and outperforms superb theoretical algorithms as a result.
And who decides on this subset that everyone else is happy using :) ? The only reasonable thing at this point is a compiler switch + "#pragma (langauge\_feature, xxx)" for external headers so that one can enforce their own subset. 
FNV1a is actually not so bad, it's not so fast but the code is so short that it will be easily inlined everywhere
I'm a little out of the loop, I expect I'd be terrified of a change in semantics towards lazy argument evaluation, but I'd be curious to see a proposal. But IIUC that's more of a concern for macro definitions (probably an even-more-egregious use of the preprocessor, but) not specifically header includes. When I last left off C++, templates still had to be defined entirely in headers. I assume that's probably solved by now if we're talking about better packaging mechanisms. In that case, I'm not sure why headers would be "sometimes needed," and I'm just hoping we're not talking about xmacros.
I think it would have been nice to have an example of the old C++03 functor store a member that's then used in the operator as an introduction to how captures work.
Currently only int and uint64_t, but I'm now adding std::string too
People are giving absl too much credit. OP has already shown a figure where absl is not ranked high. In [my benchmark](https://github.com/attractivechaos/udb2), absl is not that good, either. I have seen a couple of other informal benchmarks where absl is slower. I am sure absl shines for some applications, but for others, it is often not the best.
The difference between direct-initialization and copy-initialization is that direct-initialization can invoke `explicit` constructors. `vector&lt;int&gt; v(3);` constructs a vector of size 3, but `vector&lt;int&gt; v = 3;` is an error.
My argument would be that UTF-8 is purely an exchange slash persistence format and that internally we should move towards UTF-32. A world in which all text is UTF-8 and all manipulation of text is done on UTF-8 would be an epic disaster, IMO. There would be so many ways that it bugs could silently introduced into that sort of code that you might not catch for years, and the overhead for various types of text manipulation would be brutal. So, just internalize to UTF-32 and use that as the in memory format. I can't see how anything else would be remotely practical as a long term solution. If it was possible to treat all text as a black box and just call standard methods that operated on them, that would be one thing. But an awful lot of code exists explicitly to manipulate text in non-trivial ways. Just the overhead of having suddenly to treat single characters as a byte array would be stupidly ugly.
The trouble with uniform initialization is that sometimes it calls a regular constructor and sometimes calls an initialization list constructor. So I mainly use it when I want to do aggregate initialization, and use parens to call constructors. = is just fine too, especially for things like int x =5;
Yes. Have a look at how zip is implemented in range-v3. It's a special case of zip\_with. zip just set zip\_with's function to make\_tuple while taking any number of collection. transform, on the other hand, set the number of collection to one and allows the use of any function. Usually transform has a separate implementation that does not rely on zip\_with's one to benefit from performance optimisation. Still, from a design perspective, they remain very close. Hence /u/blelbach's remark about the other way around.
I guess we'll all have to use a good old \`#define\` for those two. 
&gt; Was the issue iterating, rather than find/insert/remove? &gt; Did you have a good or bad quality hash? I used the default. So the question is "how good is `absl::Hash&lt;std::string&gt;`?" &amp;nbsp; Two other interesting things - `google::dense_hash_map`/`google::dense_hash_set` outperformed everything else I have tried. - Taking a step back and going back from `absl::flat_hash_set` to `std::set` in the innermost structure made abseil almost reach the performance of `google::dense_hash_{set,map}`. I even had an issue open on the abseil repo about this. The conclusion was that abseil hash tables aren't optimized for iteration. &amp;nbsp; Though I'm starting to think that nested maps are the wrong data type for modeling a simple database and am currently looking into sqlite.
Use std::expected for the return type of your file opening function, instead of throwing an exception on failure. Something like [https://foonathan.net/blog/2017/12/04/exceptions-vs-expected.html](https://foonathan.net/blog/2017/12/04/exceptions-vs-expected.html) Of course then you lose backward compatibility with all existing interfaces that rely on exceptions, so for many purposes you might as well consider it a new language, rather than a language subset with new standard libraries.
Not everyone agrees with this way of development. I certainly don't.
&gt;Have we ever thought about having a contained, safer subset of the C++ standard? Yes, Visual Studio includes a tool (called the [Lifetime Profile Checker](https://devblogs.microsoft.com/cppblog/lifetime-profile-update-in-visual-studio-2019-preview-2/) to enforce such a (memory safe) subset. Unfortunately the tool is still incomplete and prone to false positive violation warnings. But presumably they are working on it. The strategy of the Lifetime Profile Checker is to make traditionally unsafe C++ elements (like raw pointers) safe by restricting the ways they may be used to ways that can be determined at compile-time to be (memory) safe. Even when it's complete, as planned, the resulting language subset [will be too small/restricted](https://github.com/duneroadrunner/misc/blob/master/201/8/Jul/implications%20of%20the%20lifetime%20checker%20restrictions.md) to implement some algorithms efficiently without some crucial additions to the standard library. Those [additional](https://github.com/duneroadrunner/SaferCPlusPlus#registered-pointers) [elements](https://github.com/duneroadrunner/SaferCPlusPlus#norad-pointers) are [available](https://github.com/duneroadrunner/SaferCPlusPlus#make_xscope_vector_size_change_lock_guard) in the SaferCPlusPlus library (shameless plug). In fact, while we wait for the completion of the Lifetime Profile Checker to make existing unsafe C++ elements safe, we can instead, as you suggest, simply avoid C++'s unsafe elements, substituting them with (mostly) safe, compatible replacements from the SaferCPlusPlus library. Also, the Lifetime Profile Checker restrictions do not ensure (or in any way address) data race safety. But avoiding unsafe C++ elements (using the SaferCPlusPlus library) [does](https://github.com/duneroadrunner/SaferCPlusPlus#multithreading).
Missed noexcept and perfect forwarding...
Will `std::variant` be fully `constexpr` in C++20? As I can see `constexpr union` is here, so there should be no blockers for that.
**Company**: [Giant Squid](http://giantsquidstudios.com) **Type:** Full time **Description:** Giant Squid is looking for a senior programmer to lead a small internal team in the development of game port projects on several different platforms. The projects are built in a customized version of UE4. Our ideal candidate will have a mastery of programming in C++ and experience seeing game port projects through from beginning to end. We are looking for someone who loves to wrangle large codebases and optimize them holistically. If deep programming and complex problem solving is your passion, this role is for you. We are looking for a team player who shares our excitement for learning, researching new techniques, wearing multiple hats and stepping outside of regular workflows to innovate and make things happen. You will be working closely with technical artists and other programmers to create optimized and fluid experiences on a variety of platforms. A collaborative mindset will be crucial as you help us find solutions to unforeseen challenges requiring cross disciplinary teamwork that we discover as we bring these projects to life. Responsibilities: * Lead the technical development of game port projects * Ensure great game performance on different platforms by optimization * Oversee a small team of programmers and technical artists working on port projects Requirements: * Mastery of programming in C++ for games * Experience with Unreal Engine 4 * Have shipped at least one game port in an engineering role * Wide breadth of programming knowledge and experience (shaders, SIMD and multi-core techniques, memory management) **Location:** Los Angeles, CA **Remote:** No **Visa Sponsorship:** No **Technologies:** Unreal Engine, C++14, various game consoles **Contact:** Please send cover letter + resume [here](mailto:jobs@giantsquidstudios.com)
Templates, for now, still need to be declared in headers, but when modules arrive (C++20) that won't be necessary any more.
\&gt; using #define We know it's wrong but if it achieves a greater good it must be the right thing to do
shouldn't be needed for simple/common cases
Could you speak a bit more about expansion statements? It's not clear to me why this is superior to a range-based for loop.
The [google style guide](https://google.github.io/styleguide/cppguide.html) for c++ uses ThisStyle for functions. Personally I used to use camelCase for everything except types due to my background with JavaScript, until &lt;companystyle&gt; tore that out of me and now I hate every style equally :)
Interesting point! Unfortunately, even trying to make `flatmap.swap(flatmap)` exception-safe is a problem. ``` void swap(flat_map&amp; other) { using std::swap; swap(keys, other.keys); swap(values, other.values); swap(keycompare, other.keycompare); } ``` This implementation breaks flatmap's invariants if `swap(values, other.values)` throws; or if `swap(keycompare, other.keycompare)` throws; or if `swap(keys, other.keys)` throws-without-the-strong-guarantee. Flatmap addresses these concerns by refusing to compile if `keys` or `values` is `!nothrow_swappable`, and then making sure to swap `keycompare` *first* before anything else; and then having UB if swapping `keycompare` does anything other than "do absolutely nothing and throw" or "swap and don't throw." An example of a type that might do something other than "do absolutely nothing and throw" or "swap and don't throw" is `struct L { std::list&lt;int&gt; lst; };` on MSVC where `list`'s move-assignment is non-noexcept and `L` has no built-in ADL overload for `swap`. 
I appreciate the big job you put into producing these videos. Thank you for your effort and some interesting videos.
I enjoyed 50 Shades of C++. It‚Äôs not very technically oriented, but I appreciated it from an introspective point-of-view of the community. I also enjoyed the candor and low-keyness of the speaker. Andrei‚Äôs talk was entertaining as always, but felt a bit like C++ vs D venting. It had some of his experiences with metaprogramming in D which were insightful (some of it made me uneasy imagining projects turn into metaclass soup). I haven‚Äôt seen the more recently released ones. 
Debugging programs that fail to flush because someone thought of saving nanoseconds is a big fucking waste of time. Form good habits for the common case and then optimize.
Have fun debugging your programs that fail to flush important messages before crashing because some fucker learned that endl is wasting a few nanoseconds!
You have never had to debug a program that failed to flush an important message before crashing. That is why endl is the default idiom, and I'll fight anyone who gives me grief about using it in virtually all cases. If optimization is needed then we'll talk, otherwise I'm fine with burning a few nanoseconds on every line of text.
Isn't this kind of overkill? In the past I've just done something like: BYTES=`cat ASSET_FILE | xxd -i`; echo "const unsigned char varname[]= {$BYTES};" &gt; ASSET_FILE.cpp Then just include the .cpp in your project like anything else, extern it to use it or make the file generation fit however you feel like exposing the static data. Cross platform and no need for LLVM :P
thanks and great work 
Yes, that also works. I just ran a test example, and did not have any problems. I was a little surprised, as I had thought that name mangling would cause link errors. You should probably use the following for portability: extern "C" std::byte const varname[]; extern "C" std::byte const varname_end[];
Thank you for the link. I hadn't see this approach yet, and it looks pretty good. I've added it to the list of related projects.
Yeah, LLVM is a pretty big dependency :) However, check out the benchmarks. While xxd works well for a lot of use cases, it has some limits.
I like that you're using llvm to do this but the dependency hell isn't worth it. I usually write some Python code to do just this. I think you'd get faster uptake if it was easier to consume. Though I did notice that I think you've got binaries, so that's nice.
Thanks for sharing these videos
The problem I have with uniform initialization is that if you get it slightly wrong, especially when using it against a highly templated standard type or similarly from Boost, is that you fall back into template compiler error hell. I mean, I've seen 20 screen fulls of vague errors for a simple typo using uniform syntax, when if you switch it back to classical constructor syntax, can get a screen full of error that actually tells me the problem. 
The dependency is super easy on debian or ubuntu. Windows was a bit harder. However, LLVM has a solid build system, so it isn't too hard to get it built, but it is a bit of a lift... Using C or C++ as an intermediate step can get you pretty far, but for really large assets the compiler will choke. &amp;#x200B;
Remember, you're asking each dev to pull in a LLVM dependency on Windows, Mac and Linux (my dev platforms) to just attach binary resources. If I have to choose between that and writing it myself in Python, that's what I'd choose as devs are likely to have Python than LLVM-dev on their machines. &amp;#x200B; I think the way you've done it is fantastic and I want it to be used by my next project, so may I simply recommend that you encourage people to use your prebuilt binaries (I thought I saw them, but can't find them now). This is what I do with Ninja and CMake where I add both these dependencies in binary form to source control and move on. &amp;#x200B; Good luck with the project!