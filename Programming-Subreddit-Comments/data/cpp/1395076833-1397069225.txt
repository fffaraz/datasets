even STL said only reason to use CPP is performance... (or something like that) and I can tell you 100 irritating things about CPP, STL can prob tell you 1000 :) but the article is just written in a such way that I have no respect for authors complaints... If you wanna learn CPP watch STL lectures, read Herb and Scott, dont bother with trolls. 
btw regarding runtime performance, I already asked you this, but then the answer was no: I made a vector of my class that is movable and when I specialized swap to use memcopy sort performed faster. You said you need rvr v3 or something to get that speed from compiler. Is that in VS2013, or in the next release ? 
You probably want to do something to ensure that nobody copies the property directly. They could accidentally do it with `auto`, where they'd expect value semantics and not expect having to keep the original object around.
2013 RTM (and all Updates) doesn't support rvalue references v3, but the Nov 2013 CTP and the next major version do.
Great solution!
Resources in Win32 have their own internal reference counters. Implement your class copy methods so that it calls [DuplicateHandle](http://tinyurl.com/nhsd3bt) and then call [CloseHandle](http://tinyurl.com/7f79rdw) on your duplicated handle from the destructor. The actual resource that the handle is referencing will only be closed when the internal reference count reaches zero. HWND handles OTOH are different and should only be owned by one object at a time. This because window can only have one parent. There you have, if you want to support detaching of windows from parents, implement your own solution since you may have to remove subclassing etc.
Mate, I graduated in Computer Science 10 years ago. That's the only back ground that I can share. I have never worked for a game studio but let me tell you. If you read the AMA from Gabe Newell you will see that companies like Valve are not like Google. Do you need to know your algorithms? Sure but how many games have you finished? I suggest you let go of the books for a couple of months and create something with you already know. Ship games.
&gt;1) Is it worth to be a computer programmer, just for the love of programming? Absolutely. Honestly I think that's the only reason anyone should get into this field. &gt;How is the work environment in good game studios like? Is it stressful? It depends on the studio. I've heard plenty of horror stories ("crunch time", the period leading up to release or going gold, in particular being rough). However I'm of the opinion that crunch time is due to poor management and you should avoid studios like that. But there are also plenty of good studios too. &gt;Are they restricted into not being creative and working under a small domain. (You are supposed to finish this, better do it by X, or else you are fired) types? This really depends upon the studio, the type of work you have, and the size of your team. Large teams have to rely on programmers doing their part of the project and can't really let you just work on whatever because that can lead to duplication of work and loss of productivity. You can certainly be creative in your implementations, within reason. If you're on a team of, say, three people and your responsibility is to create the tools for an engine, you get a lot more freedom and autonomy. &gt;Is the choice of my books good, or should I read other books before moving onto these? They seem fine, especially if that's generally how you prefer to learn things. I personally just jump into things and learn as I go. Last summer I decided to give making a 3D game engine a go so I'd have a project to learn C++ with. Writing all of the tools, the content pipeline, the API etc. forced me to learn a great deal of C++ to the point that now, 9 months later, I'm very confident in my C++ skills. Ask yourself these questions: What do you hope to gain from more books? What knowledge are you lacking that is preventing you from starting to work on a game right now? You know about game loops, presumably you know a bit about how 2D graphics work, why not dive in and start making something right now? Books won't give you an end-all be-all framework for creating video games. The common design in modern games is very high level and the details are left up to the type of game or engine you want to create. Remember: games are simply programs that visualize the interaction between objects. Don't overcomplicate things. For blackjack, you have a model of a card, a deck containing cards, a dealer that dispenses cards, and a player that can make a few moves and make bets. If you can model those interactions in code (for example by using a simple console app with text commands for testing your implementation), then you're really not that far from creating the bits that draw it on the screen.
Thanks a lot, really appreciated your time and effort in replying to me :) &gt;This really depends upon the studio, the type of work you have, and the size of &gt;your team. Agreed. A more specific way I wanted to ask the question was, is it worth being a game developer than being a software developer? Like can I enjoy my life as a game programmer more (given my love for programming and gaming combined) or do software developers (non gaming )enjoy better facilities. (Income, family time etc) I should have said this before, but i forgot. Even I tend to learn by doing. For eg, I wanted to learn web development so I went ahead and made a prototype for my college and I ended up being the lead web developer of my college website. I made a game long back for my grany, which could solve her daily newspaper word puzzle. I also remember my self learning the ncurses library for making games! Thanks for your input. Appreciated! 
&gt; It depends on the studio. I've heard plenty of horror stories ("crunch time", the period leading up to release or going gold, in particular being rough). However I'm of the opinion that crunch time is due to poor management and you should avoid studios like that. Yeah, there are some studios that still do it, but it does seem to be happening less now, from the studios I have visited (in the UK) none of them do crunch, which is obviously a good thing :D. I guess if you work at a small studio then it might be required more. &gt; Last summer I decided to give making a 3D game engine a go Did you have a book to help with this? Any recommendations?
I am very very new, but I want to learn! I have made many small programs in cpp, and other languages, but when it comes to game development, yes I am very new!
&gt; Sure but how many games have you finished? This is a pretty important one for working in games, if you apply to a studio you're expected to have a portfolio of games you have worked on, personal projects, game jams (working in a team is a good selling point), etc. It's ok to have projects which you are currently working on.. but it's also important to have projects which you have finished and perhaps published. Another requirement for games is strong maths skills, linear algebra - vector maths and physics are all fairly important.
Thanks a lot! Never knew about this subreddit! I think I should I x-post there? 
&gt; Like can I enjoy my life as a game programmer more (given my love for programming and gaming combined) or do software developers (non gaming )enjoy better facilities. (Income, family time etc) You'll probably make less money as a game developer, but you have the enjoyment of working on games. As for family time, it depends on the studio really.
Yes, I won't applying for a job right away! I will first acquire the required skills! 
/r/cscareerquestions would be much more appropriate for this question. This subreddit really isn't the right place, this is for discussion about the C++ language.
1. Yes. If you don't love programming you won't survive. Loving the craft is the difference between a hyper-stressful environment and a high-energy one. Those deadlines and restrictions have not been felt by me but may exist depending on the studio. If you ever get an interview, remember that you are vetting the employer as much as they are vetting you. 2. C++ is one thing, but you'll need to learn a lot of other stuff too. Understand how rendering works, how game engines are built, how to use them. Learn a few asset pipelines. Implement a bunch of algorithms (pathfinding, camera behavior, simple physics, etc). Learn OpenGL/DirectX and get experience writing shaders. 3. Honestly you could spend years just reading stuff and never get anything done. You're better off writing code on your own and winging it until you get stuck. Reading 100000 lines of code might give you the experience of writing 1000 but it's not an efficient way to learn (not to say you shouldn't be doing it) 4. Write your own game and open source it. Publish it on game dev and ask for feedback. Pay attention when others do the same. The faster you are able to create your own content and code, the better off you'll be in the long run. *edit*: I should supplement this by saying not to *only* study C++. You'll need a solid foundation of scripting languages under your belt as well. Learning a functional language is also highly recommended.
Oh, I am sorry, I will xpost the question to the relative subreddit! Cheers
That sums up what I actualy want to do! Thanks for your for valuable feedback! I should start writing small games in curses and then port/upgrade the same games, learning many things as they come by! Maybe I'll get a job as a software developer or an intern somewhere and learn more about all this before I finally land a job as a game developer! 
Actually, I decided to use CreateFontIndirect and CreateBrushIndirect (and the like) with graphics related handles on copy, and then DeleteObject on destruction. So yeah, I'm relying on Windows's internal reference counting for that now. I actually came to this decision while looking at the .net framework reference code and saw that's what it did. I'm not even giving components that own windows the ability to be copied yet. They're construct-destruct-move constructs for the time being. That said, I persist the child windows by moving them to a process wide, hidden window if their parent is destroyed. It's looking more and more like I'm going to have to implement this via a lookup table.
I can only speak to your question 1. Is it worth it, to go into software engineering, for the love of it? My immediate reaction starts off with "if you have to ask..." I went into this field "for the love of it" -- I can't *not* produce software. This may not be a good thing but it is what it is. Sometimes it is frustrating. Whether working in the field is "worth it" or not is a very personal decision. Would you do it for free? Would you take vacation time to work on an interesting personal project? ... to study up on some math or physics or whatever, because you need it for a bit of code you are writing? For some of us, the answer is simply yes. For others, no, or perhaps maybe, or it depends. And no elitism in this. No answer makes you a better or worse engineer. Build something. Then build something better. See if you have the bug, then decide. 
Personally I would pay around with c# and unity and make some games for phones, xbox and steam. 
I would [read this first](http://www.reddit.com/r/gamedev/wiki/posting_guidelines_faq) to find out if it's necessary. They link to a lot of good stuff there. I mainly lurk, rather than post there, so if anything message one of the mods to see if your question would be appropriate. Good luck and have fun!
Seeing the other comments, my best advice is : take it easy. Game dev is an huge field, with plenty of people dedicating their whole life to just a small part of it. I know how you feel; you want to learn everything now! Plus, everybody is suggesting a ton of different things to learn, and I feel dizzy just looking at this thread. Slow down a bit, you will not be able to learn everything. I came to this realization recently. I'm working in a big AAA studio since a couple of months and it's not until you see more than 50 programmers working together on different part of the game on an already gigantic codebase created by another team over multiple years that you realize that you will not be able to fit all this knowledge into your brain. From the tiny assembly tweaks to the build machines, passing by all more and more complex rendering techniques, it's just impressive to see all that work come together to form a game. So if you want to work in a big studio, I'll suggess that you learn C++ first. This is without a doubt the de facto language in the industry and will stay for a long time. Get a good book and try as much as possible to use C++ in your remaining assignments. Don't read the whole book without having some real world practice. I might suggess "A Tour of C++", which will give you a nice overview of the language without holding your hand. With that and some googling, you should be able to start using the language quickly. After that, read "Effective C++" and then if you really want the full picture, read TC++PL. To get you started with game programming, don't get lost into too much low level stuff. I started with Flash, which has a pretty awesome API that abstracts a good layer of stuff for you. Sadly, nothing come close to Flash in the C++ space in terms of speed and ease of developpement, but there is some good candidates like SFML. It has an excellent documentation, nice, modern and simple API and you'll get something on screen quickly. Finally, if you want a good overview of how a game works internally, I cannot suggess enough "Game Engine Arcitecture" by Jason Gregory (there's a new edition coming out soon so I'd wait for it). It gives you a really good overview, with some real life examples, of how a game engine works. Once you get a couple of experiments running, look at how some of the free engine works, like CryEngine and UDK. Don't become an expert, since the studio you'll be working in might not use those, but it will at least give you an idea of how things work at a professional scale. So anyway, my only real suggestion is get a good overview of the field and selectively dig down into what you find interesting. Oh and checkout /r/gamedev, there's a ton of good resources!
Hey, I've been working as an engineer in the games industry for a while, I'll answer as best I can. &gt; 1) Is it worth to be a computer programmer, just for the love of programming? Yes and in my opinion, it's the most important quallity to have. Studios like to talk about having a passion for games ect. but I prefer working with people who have a passion for their craft. There are even roles in studios that have almost nothing to do w/ the game itself, like Build Engineer, Platform or Systems engineers. &gt; How is the work environment in good game studios like? Is it stressful? Can developers enjoy their work with a open prespective? This varies from studio to studio, but the general rule I've noticed is the larger the studio, the better the quality of life. The smaller the studio, the better the pay/perks but larger the work load, hours and deadlines. At larger studios, you have so many different people working on so many moving parts that each person's individual work load is generally lower. That and it's more difficult to coordinate, so you have very strict and well defined processes for scheduling and dealing out work within a team, giving the team more power over how and when things get done. Smaller studios tend to have less management but want to compete w/ larger studios so they are trying to accomplish around the same amount of work. So you end up having to rush more or work longer hours to get things done in time. You can enjoy your work in both and you'll usually learn more and get better faster in a smaller studio where you are given more responsibility and have to work on a wider variety of problems. If you want to specialize or are a specialist then a larger studio is probably a much more comfortable fit. &gt; Are they restricted into not being creative and working under a small domain. (You are supposed to finish this, better do it by X, or else you are fired) types? I've never seen anyone get fired for missing deadlines. Games is very team oriented, no one takss you with something comes back in two weeks and wants to see it done. You are constantly giving updates on your day to day progress. If (when) unforseen things come up, you can leverage advice or help from seniors or other team members. Bugs can be split between the team if you are working on something. You usually don't code in a vacuum, at least one other person has input on the design and scope of your task. Basically, whatever you're working on, the lead could do it too so it's not like it wont be done, but you will be the one responsible for doing it so the lead doesn't have too. If you aren't done in time, well that's why studios tend to avoid ship dates on new projects until a couple months out. &gt; 2) I have finished reading the first edition of the book, Beginning Game Programming! By Michael Dawson. I am currently skimming through the third edition of the book to make sure that I am up to date with the standards of C++. This book was a good book, and though me the game loop and applied it in two games like tic-tac-toe and blackjack. Cool, never read it myself. I honestly haven't read very many books and probably wont actually read any books in the future. I can use them for reference sometime, but honestly you can find references to things online faster. As far as techniques and concepts, especially with games I'm not sure it's worth it. Maybe it is, so you learn one way to do the things you'll likely never have to do (like writing a game loop) or implementing an animation system. Most places use engines that already have the ground work features. You'll mostly be writing gameplay code in either scripts or C++. Your day might look like this: * You sit in a meeting w/ your team while design goes over a bunch of features they want to get into the game this sprint * You and your team bids on each feature, giving them a numeric value that represents how long you guys think the feature will take to implement * Once you're team is out of the time and the designer is happy w/ what he's getting you're done and you guys divy up the work amongst your team * You then begin working on building a system to allow npcs to take notice to the player when the are within a certain proximity and perform an action. This involves writing some game logic and maybe some tools work so designers can specify what npcs do what actions at what proximities. That's what it was like at larger studios for me. At a smaller studio, it's more like * Design/Marketing: Hey we need this, you're on it * You: Ok, when is it due? * Them: Uhh, we need this ready in two weeks so we can present it to the CEO or Invenstors * You: Alright.. I think this is doable in that time, but maybe not this other part here * Them: Ok whatever Then you scramble to at least get it into QA for a few days before it goes out. That's been my experience so far in a smaller studio :p &gt; 3) I know there is tonnes and tonnes of information on the internet regarding game programming and I am refering [Gamedev!](gamedev.net) forum to get me started. Please share any other resources for game programming. Just get really good at programming. Get good at reading other people's code, making changes that get the job done w/o causing any side affects. Learn about designing API's so when you build your systems, other people can leverage them easily. Avoid code duplication, go out of your way to search the code base to find if something already exists that accomplishes what you're trying to do. If some day you're tasked w/ hooking up an xbox controller to the game, you'll be able to pull up the Microsoft API read it and implement it in an intelligent manner that fits nicely with the input system you already have established. There's no reason to read up on and know a bunch of solutions to game programming problems because each game or studio is going to require a slightly different or unique way to solve it so it meshes nicely w/ the code that's already there. &gt; 4) I love opensource, and I am really looking to contribute to an opensource projects. Although I am going through the supertuxcart game source code and trying to understand how things work, is there any other opensource game which I should look into? No idea, but I'd say just get Unity and script a game in that. Or try an open source engine and build a 2d tic tac toe or frogger game.
Makes you wonder though why the default is to have the destructor non-virtual. I guess, like most annoying things in C++ its for historic reasons and then didnt get changed for several decades because of backwards compatibility with code from the first moon landing? Sorry for being slightly cynic here ;) Is there another rational for that other than backwards compatibility/historic reasons though?
&gt; Some smart pointers like shared_ptr can know the actual type of the contained object due to template magic Even in this case? Base* b = new Derived(); std::shared_ptr&lt;Base&gt; smart(b); 
No, if you pass in the an object of the actual type (or use make_shared).
For getting feet wet, I actually always recommend [love2d](http://love2d.org/). Although there are few commercial games that use it, it is very common in the indie scene and indispensable for fast prototyping and game jams. You'll need to learn Lua eventually anyways (most likely) as it is the basis of most scripting engines. After getting your feet wet, you can push down the stack if you want (imagine how you would build something similar to love2d on your own). Alternatively, you can venture into 3D and use something like the gameplay engine or MoaiSDK. Another option is to go the backend route and learn networking and server programming. The cool thing about game development is that there is really no limit to how much you can learn. All the directions I mentioned above branch out further and you'll never get bored. At least I never do :)
&gt; I do see people declaring "interface" classes, especially in articles about COM, where they do not declare a destructor in many a web site, but I've never seen a justification for it. In COM you cannot delete an object, you call Release() and COM itself handles the lifetime of it.
If the coding standard is for COM it should be safe to omit the virtual destructor, you never ever use "delete" on a COM interface pointer, and if you did you would have worse problems than lack of virtual destructor anyway.
Thanks a lot, it really matters to me! I feel I am long behind the technical skills required, so I should first strive to be a better programmer, then anything else. So game development similar to other software development workflow with specialization offered in big studious. Do you advice me to get placed in a small company and learn the tips and tricks of the trade and then move to a bigger studio. Or learn from the massive resources around, keep making games for fun, and then try to go into a big studio! There is only one unit of ubisoft in my country and it also happens to be in the city where I live. This unit is specialized in handeld devices. I can try for this one for starters!
I finished with the tour of c++ book, I should admit I have enough knowledge of c++ to start making small games. I am thinking to make some console games based on the ncurses library first. I should get a good gist of the co-ordinate system with that. Is it good for starters? Thanks a tonnes for your time. I am realy happy looking at the response here. You know, it actually one of the most crunching period of my life. You can say my happiness and satisfaction of my future life depends of the decision I make today! 
Yes you are right, there are tonnes of resources there! :) 
Never seen it that way, makes kind-of sense to me, thanks!
Sure. I actually had a somewhat weird history since I worked in finance for a while (I had a math/physics background and could code). I learned to build web applications on the side and got to work on the backend for a persistent game. I implemented a bunch of the game networking/server code for a new game after that. I jumped to the other side shortly after and wrote a rendering engine, followed by a framework for building isometric games. Throughout all this, I had learned SDL, SFML, Love2D, Ogre, and some other engines/frameworks on the side. I will be working at Riot games soon. The foundation of all of that learning was books. Books upon books upon books. And then more books. Contributing and reading open source code is a great way to get good fast. Always stay humble and realize that no matter how much you learn, do, or know, there's always more. You can learn something from almost anybody if you listen/pay attention enough. The last tip I would give is to establish good habits early. Discipline is extremely rare and it's a pain to be meticulous about things but it pays dividends. Think of it as doing your future self a favor now. Discipline = writing tests, writing good commit messages, documenting your progress/learnings consistently, staying up to date with the tech ecosystem, exercising, eating right, and obviously all the good coding practices as well.
Thanks a lot! sums it up! 
smart_ptr here does need destructor - but it does not need to be virtual. Even in this case - shared_ptr - knows that it has inside ptr to class Base* - the Base - destructor is itself virtual and it will be called by smart_ptr destructor - but smart_ptr destructor in this case - does not need to be virtual - unless you are planning to inherit from smart_ptr and us array of smart_ptr&lt;SOMETHING&gt; * array. 
Well, if you are creating an interface, it means you are using multiple inheritance. When it gets destroyed, the issue of whether the interface gets destroyed first or the base class gets destroyed first comes up. If the base class gets destroyed first, then any code in the destructor of the interface is basically guaranteed to fail. I would guess that this is something that happened at the company in the past.
&gt; I do see people declaring "interface" classes, especially in articles about COM, where they do not declare a destructor in many a web site, but I've never seen a justification for it. From what I can tell this is an error of omission, but it's around enough that I'm very curious if there's some justification for it that I'm just missing. Find a copy of "Essential COM" by Don Box - the answer is in the very first chapter. It is all about using COM components with different compilers.
Well, you don't put any code in the destructor just to make it virtual or protected. Also, I'm not sure how you could create the scenario you're talking about with a construct that wasn't stupid in a different way. You are assured that your current object is still valid when your destructor is running...leaving aside possible race conditions or deletions of invalid objects.
So what's it say?
Doesn't your Coding Standards document have a Rationalle listed for each rule, giving the reasons for (and, if a good one, against) each rule? Since you are asking here, I'm guessing it's not part of the main document, search around for a larger companion document. Such documents can and should be generated from the meeting notes where each rule was discussed, the wording tuned, and each rule adopted or rejected. Of course, maybe your coding standard is a three-page document listing a bunch of rules that a senior software engineer originally wrote as an extended rant. I've ~~written~~ used those, and they are hard to fix once they get entrenched, because nobody can point at the rationalle and say "all the reasons behind this rule are no longer applicable" ... 
This is the line of reasoning you need to take up with the folks who control your coding standards, both as a rationalle for granting an exemption for this sort of code, and relaxing (or refining or eliminating) the rule in the next version of the coding standard. 
1000$ registration fee. I think I'll just stick with forums and irc channels.
Is this a joke I'm not getting? 
Wow! And I was contemplating asking the boss whether the company would be willing to send me to this. Now, not so much.
It is actually $695 right now.
Well, the stated rationale doesn't make much sense to me so I was looking for something more technical that I could dig my teeth into. After much talking though I think that it just boils down to someone's preference that's possibly based on incomplete information. It's an old document. I did gain a deeper understanding of some of the associated constructs during the conversation, but this particular part left me a bit uncomfortable. Easy enough to live with though so I figure I've rocked the boat enough :P I know enough now to dispense good advice during code reviews and such.
Yeah sure. The worst thing with virtual functions is that they create optimization barriers, that is, compilers cannot inline virtual functions calls (and other optimizations), as only at runtime it is known which exact function is being called. My line of thinking just was the paradigm "make the thing most people will want the default, and specality/optimization extra work" it didnt occur to me (after *several* years of c++ experience now) that C++ would not break with this idea because of merely compatabtiliy/historical reasons but because it rather persues the idea "make the efficient thing the default", that just explains a lot of design decisions. (Although some, especially syntactic quirks are really not justifiable with anything else than backwards compatibility, but let us not drive into that discussion here, rather in a new topic)
Easy to illustrate. You have two third party IO stream-type classes (say one is class TPFTP and the other is class TPHTTP), and you want to access them through a common interface. So you create: class IOStreamInterface { public: virtual void CloseStream() = 0; virtual bool IsStreamClosed() = 0; ... } And you implement them: class MyFTP : public IOStreamInterface, public TPFTP { public: virtual void CloseStream() { EndSendFile(); }; virtual bool IsStreamClosed() { return FinishedSendFile(); }; virtual ~MyFTP() {}; } where EndSendFile() and FinishedSendFile() are functions of the third party TPFTP class. So far this is pretty normal. Where you get an error is if you now add a destructor with code in it to the IOStreamInterface interface. Since IOStreamInterface is pure virtual, the only functions you can possibly call will all call back into the TPFTP class. Something naive like: IOStreamInterface::~IOStreamInterface() { ASSERT(IsStreamClosed()); } So now you have a problem, because if TPFTP gets destructed before IOStreamInterface, the IOStreamInterface destructor is calling a function on an already destroyed base class. This is one of the gotchas of multiple inheritance. One solution that people have is to create rules about very specific allowed cases of multiple inheritance, with "interface" type classes that only consist of pure virtual functions one allowed model of multiple inheritance. Making sure that there is no code in the destructor is paramount.
Hmmm. Here's an idea. See if you can get them to let you include a destructor in an #ifdef, so that normally it is ignored but it can be turned on to explicitly do compile-time checks that nobody by mistake is doing anything that might trigger deletion through the base pointer. You'd be testing with it disabled, so no issue with violating any "test as you deploy" rules. Not sure if this is beyond your acceptable boat rocking threshold. Worst case, you do the insertion locally during your development, then cut it away once you are sure the destructor is never called -- before committing. Nobody but you sees it. No harm, no foul, right? :) 
Hmm. I doubt my current gig has budgets for this kind of thing. I might see about inquiring as to whether we do have a budget for this sort of shenanigan.
I think that the reason this fails is technically because the object at time of deletion is IOStreamInterface and not MyFTP. As such you're calling IOStreamInterface's version of IsStreamClosed and it's a pure virtual. So you're correct, but I think you're associating the failure with the wrong thing. This is one of those not-uncommon stupid things to do in C++ similar to calling a virtual during construction. It's just inadvisable to do that because it generally doesn't do what you want, and in this case clearly won't. I believe this problem still exists without MI. Edit: BTW not saying anyone that does this is stupid. It's a subtle issue that I've seen many times. I've probably done it more than once myself, but of course just being smarter than me doesn't mean you're not stupid.
Not sure how applicable this will be to your system but... My pet peeve with pacman (the system package manager for arch linux), is that installing an optional dependency is only possible as an explicit install. So when you remove the parent package the optional dependency will still be installed. Other package managers tend to have a --asdepof &lt;parent&gt; flag that help automate removal.
Using a random value doesn't have any benefit over a simple incrementing counter. Furthmore, debuggers generally have such functionality built in, so although this is a useful idea, there are easier implementations of it. VC++, for example, lets you view the hit count for breakpoints, and also lets you conditionally skip breakpoints automatically based on the hit count: [Breakpoints: Use Hit Counts, Call Stack Functions, and Conditions to Break When and Where You Want in the Visual Studio Debugger](http://msdn.microsoft.com/en-us/library/5557y8b4.aspx). GDB and LLDB offer similar functionality. Here's an article about Xcode's GUI frontend to LLDB's breakpoint options: [Xcode Breakpoint Wizardry](http://blog.bignerdranch.com/4247-xcode-breakpoint-wizardry/). 
Rust just announced that they were launching a new attempt at a package manager (Cargo), and that Mozilla had hired the authors of Bundler (most popular Ruby package manager apparently). As a result, it might be interesting for you to look at their progress: they seem intent in a transparent process so you could probably check what their objectives are. Regarding particular guidelines, if I may: *ensure semantic versioning*. It's easy to accidentally break the ABI, so if you decide to package a new library the system should check that its ABI correspond to the ABI of the previous one(s) according to the rules of semantic versioning. If you can manage that, even ignoring inline methods and only focusing on libraries public symbols, it would be awesome.
ah the old downsell
I'll be there. maybe. ;)
Integration with the systems package-manager would be a cool thing.
Say it out loud.
Ah, yes. I guess you are right! Thanks for reminding me! I will do that asap! 
Oh...
This. So very much. I have seldom ever had a positive experience with a language-specific package manager. As soon as something of consequence is built in that language, every Linux distro is going to have to bundle its dependencies into its own package management system anyways. Then you have two entities competing for control of the 'true' place gems are install, eg. In short, I think a C++ package manager is just a bad idea. But there is a closely related great idea if you take many of those bullet points and turn them into a library (accessible from shell scripts) that can integrate with whatever package manager the system already has.
Your coworkers must be really bad if you're willing to pay for their training out of your salary.
I haven't heard about GoingNative either, but as this event is also in Seattle, it might replace it. I can't give you any update on the schedule, its the first time this event happens. It is the "official" C++ Conference from isocpp.org, the whole Committee and a lot of other C++ people are behind it. And the price is ok for a 4 day event. And I think you can wait till they release the schedule. Its not like C++Now which was sold out before they released the program... ... and from my own conference Meeting C++ I know that only a few people will buy before the schedule/program is out.
Early bird registeration is $695 dollars. The conference planning committee has made every effort to keep prices down. We understand that this fee may be restrictive for some attendees. However, the registerations fees are necessary to make this conference possible. Source: I am on the conference program committee.
Just asked my boss, and he said if I was on the Standards Committee it may be possible to swing it, but probably not just as a "Learning exercise".
GoingNative was incredible, and for much less than this event.
GoingNative was also smaller (fewer attendees, one track) and shorter. =] The hope is to have a *lot* more content.
As one of the organizers, I would urge your boss to reconsider (and feel free to forward this message). I *am* on the standards committee, and if anything that will limit how much I benefit from attending (Although I'm still planning to go and have an amazing time). This is a conference for people who are not (yet) C++ experts, who are learning, using, and practicing C++ every day and in whatever field they happen to be, from industry to academia. I think you will find that it would be one of the most worthwhile investments of training money for your boss if your day job involves a non-trivial amount of C++ code to send you to this conference. I'm certainly planning to encourage many of those who work with me to attend, and will be paying for those who work for me.
Re GoingNative: We-the-GN-organizers think CppCon is a great idea, and instead of running another GN this year and going forward, we expect to retire GN in favor of this event and to throw our weight behind CppCon. We're still finalizing that decision, but that's how it looks right now and once it's finalized we'll announce it officially, hopefully soon. I view CppCon as an order-of-magnitude superset of GoingNative -- it includes all the content we'd have in the next GoingNative, but the entire GoingNative conference is literally ~10% (one half-week track) of the content there'll be at CppCon (~5 full-week tracks). Re length/cost: Note CppCon is big -- a five-day multi-track event -- at a high-quality venue. The organizers have worked hard to try to keep the cost accessible and still have a high-quality experience -- not "champagne and caviar," but a venue that isn't shabby and makes sure it facilitates rather than gets in the way of everyone getting the most out of this très cool event. Re hotel cost: If this is an issue for you, there are lower-cost hotel options in the surrounding area beyond the recommended hotels, and/or note that CppCon is also offering one-day and two-day passes which may well make sense for you once the schedule is posted (after the Call for Submissions and session selection process happens) and you see what talks are on what days.
From my other reply: Just for the talks/content, my view is that the entire GoingNative conference is ~10% (one half-week track) of CppCon (~5 full-week tracks). It's an order of magnitude. And that's not counting CppCon evening content which is looking likely... Man, am I looking forward to this.
I would say take what you can get at first. Your first job will be the hardest to come by and the experience you get will take you a long ways. After some time, if you feel like you want to branch out more or would like more responsibilities and you can't get that at your current job start looking around for smaller studios or projects. If you would like a more relaxed work environment and are ok working in one discipline look around for an open position for your role at larger studios. Good luck!
I believe we would like to record every session, yes. As with C++Now, speakers may opt out of recording (sometimes they need to do this to protect the intellectual property of their employeers).
As far as I can tell everytime I forgot to declare the destructor virtual gcc/clang emitted a warning. Dunno if it does so for every polymorphic class with a nonvirtual destructor. 
I suspect you mean that if my package manager is called to install a package ie cps install boost 1.2.3 it will check the system package manager first e.g. apt-get install boost-dev and then use the installed system dependency? 
Yeah that's an idea. It should be easily possible when calculating the dependency graph
I'm self-employed, and I'll probably go. I plan to submit a talk. You might consider that!
You want to pay for a poor college student, too? :P
You could almost start using CPAN to host and test C++ library packages right now. It already has the web front end (metacpan.org) and testing (cpants.cpanauthors.org) infrastructure sussed. There's barely a reason to reinvent this wheel for C++.
Do you have such a low opinion of your fellow C++ programmers?
$695 for the first 100 registrants. Pretty good price for a 6 day event.
A probably incomplete list of my requirements: * Must support building and installing all of my project's dependencies with a single command on Linux, OS X and Windows. * Must support letting me choose between static and shared libraries (or even both) * Must support having multiple copies of each dependency installed (on Windows, I need 32-bit and 64-bit versions, both linked against both the debug and release runtime, for a total of four copies per library) * Must be able to package libraries using their native build systems, regardless of how insane they are. * Notably, this means using msys or cygwin on Windows to run most build systems (but still compiling with cl.exe), and being able to install programs which are build dependencies. * Preferably would even support things like fftw3, which is an ocaml program which generates a C library, and then compiles that. * Must expose library's optional settings in a sane manner * Many libraries have a bunch of optional dependencies. These need to be exposed, and not using an optional dependency even though I happen to have it installed needs to be an option. * Must be able to trivially package up all of my dependencies in an installer on Windows and OS X * Convenient distributable Linux packages would be a nice bonus. * Creating packages must be simple enough that the tool is worth using even if nothing I want is already packaged (or no one will ever use it) * Should be able to automatically use system packages on Linux if they satisfy the requirements * At the minimum, building with system packages need to not involve an entirely separate build system, as that is generally a hard requirement to get into distro packages. * Should not dictate what build system I use for my actual program * At the minimum, it needs to be straightforward to integrate with msbuild, xcodebuild, and some not completely terrible unix build system. 
Student registration is relatively inexpensive, but there are very few. Don't wait.
&gt;Some people will tell you to learn C before learning C++. *They are wrong* The kind of people who say this are the kind of people who think of C++ as a bunch of syntactic sugar added to C, which is definitely the wrong way to think about the language. Their C++ code is usually hideous too.
You "know" many languages, including Java and C++? What is your definition of know? Sorry to be the cause of a shipwreck but very few people truly know C++. 
Relatively is right! But thanks -- that puts it in the realm of possibility.
No, it is obviously someone who has learned a subject that is old enough and sophisticated enough that at least for anyone who wasn't some absurd genius, developing a depth of understanding to match that which had already been extracted by predecessors would require a lifetime of study. So basically anyone with the least bit of curiosity.
I think, unfortunately, you simply have no idea about what you are talking about. This is the language where at one point everyone was stumped on how to write a proper exception safe stack. Even the folks who are on the C++ committee read each other's work to fully appreciate the possibilities of the language. Probably the closest I can imagine to would be Andrei Alexandrescu or Dave Abrahams, and I suspect neither would claim they could get by without reading the works of others. &gt; "Whereas smaller computer languages have features designed into them, C++ is unusual in having a whole swathe of functionality discovered, like a tract of 19th century Africa." --Verity Stob
&gt; I would be 100% happy hiring someone for a C++ job if they hadn't used C++ in 10 years and had forgotten most of what they knew. Yeah, I would not. &gt; In fact the developers who knew too much about a single system were the ones that I have seen causing the worst problems. Often they have a "my way or the highway" approach and tend to over-complicate things. Are you implying that it is impossible to know how to implement a specialized copy of a type, read a few books, have a sense of what the most useful new features are... of more than one language/platform? &gt; Basically I have worked with too many programmers who would use multiple inheritance, exception handling, some #ifdefs, and templates combined with a bit of inline ASM to do hello world. From this you have concluded that you are able to effectively screen for good C++ developers? I just think maybe you've accepted too many C++ project offers to build "hello world". ;-)
&gt; I am not a manager at any company, I have no intention of hiring you, and you haven't given me your résumé. If you are at all a good member of a programming team, you're going to be expected to screen other candidates. You will be asked to screen people. Sure, you might not have a resume in front of you, but during an interview, the interviewee should be interviewing the interviewer as much as the other way around. By the time you get to the end of the interview the question you'd have for the interviewer ought to be a good way of distinguishing you from other candidates.
&gt; Calling a virtual function is generally no more expensive than calling any other function, especially on modern hardware. Modern hardware does have lots of tricks to make the cost of an unconditional jump cheap, but particularly given the sensitivity of modern CPU infrastructures to memory architecture, there is a cost (that one doesn't _always_ have to pay)... which you seem to acknowledge with: &gt; Another example is the fact that it decreases the amount of information in the class that can be stored on the cache. Then there is this nit: &gt; For example, the fact that a virtual function cannot be inlined. Yeah... though that is not [strictly true](http://www.drdobbs.com/inline-redux/184403879 "inline redux").
The point is, if you have a rule that says the destructor must be defined as private, the reason is to prevent the class of errors of "calling delete on an interface-type class which is not designed to have delete called on the interface". If you have a rule that says there must be not destructor, the reason is to prevent the class of errors of "calling a pure virtual function from within a destructor". They are the same idea: create a rule to prevent a class of errors. In an ideal world, you wouldn't need this because programmers would never make mistakes. What I meant by my original comment is that your company probably had an issue in the past where somebody wrote code in the destructor of an interface class, which created a hard-to-track-down bug. So they banned destructors. They didn't have problems with people called delete on interfaces, so there is no rule on creating private destructors. Edit: And as for the failure I described above, you'll notice that the code is fine if the ASSERT is moved into the destructor of the MyFTP class. Of course, you now have to put that same ASSERT statement into every class that inherits from IOStreamInterface, which is why it is tempting for someone to move the code into the interface. It's something that you can easily see people doing, especially since it would be valid code in most other languages that allow a similar construct.
Seriously dude, it's increasingly clear that the problem is quite the opposite.
This seems like a knee jerk reaction to me. The proposed solution doesn't really stop what you're talking about. A developer who doesn't understand how destructors work can just as easily make exactly the same mistake in a class that is not pure-abstract. It's also fairly easy to modify the rule to say that the defined destructor must be empty, and it's easy to justify that requirement because pretty much anything you might put in the destructor of a pure abstract base is going to result in trouble. Education seems the right thing here, and you get an excellent opportunity to instruct the inquisitive devolper when they ask, "Why even have a destructor if it has to be empty, doesn't the compiler make one for me?" The code is fine if you move the assert into the derived class not because the original problem was MI or that your sibling base was deleted already. It's fine that way because the derived class has a definition. In destructors the dynamic type of the class is the one the destructor running is defined in. In your MyFTP class it's MyFTP, but in the IOStreamInterface it's IOStreamInterface even though the object you're deleting otherwise has the dynamic type of MyFTP. It's as if you called `IOStreamBase::function_that_doesnt_exist()`. 
I compiled a test program today: struct test_base {virtual void fun() = 0; }; struct test_derived : test_base { void fun() { return 5; } }; int main() { test_base * base = new test_derived(); delete base; } Compiled it with `g++ -Wall -pedantic -std=c++0x` and it compiled without warning. Also stuck the program in various websites that provide compiler service and got the same result, though of course I have no idea what the flags were. So if g++ gives that warning it must be something you have to turn on and it's not included in -Wall.
Actually I have used C++ since the late 90s. My first web projects were in C++. I have released about 10 shrink wrapped commercial products in C++. And I have implemented many server systems that use C++. Presently I have been doing more C on an OpenCL project but generally that isn't very complicated code just complicated math. But it is my full intent to abandon C++ as soon as I can. If Kivy keeps cooking along then all app development will switch from C++ (which was a switch from Objective-C). My server development has switched to Python. My present desktop development (isn't shrinkwrap) is being ported to Python mixed with OpenCL C. And my pet robotics project is now Python on the Pi and simple C++ on the Arduino. The reason for all that python: It is the opposite of what C++ is becoming. Months ago I had close to zero working Python development under my belt. Quite simply modern computers are powerhouses. Getting a product working quickly is so much more important than saving some memory or optimizing things that don't take any time anyway. Then for those few things that are demanding C++ then I will use C++. It all boils down to the fact that I am a huge multiple faster in Python and it is not that Python is awesome but that C++ has taken some seriously wrong turns. But much more importantly my code is readable; people might not understand much of the math behind it but the non mathy parts are easy as dirt to understand; even if you don't program Python. But what I would love is for C++ to get back on the rails. I have made some pretty cool things that run so fast that I impressed myself. Managed data in ways where I played cool games that were optimized right down to the specific chip, its registers, and its L1 cache; those are not things that are doable in Python. But my reality is that for 99% of tasks throwing more power on is cheap and easy. Knuth said, "Premature optimization is the root of all evil" and I have realized that the very use of modern C++ is premature optimization itself. So when I have to use C++ as an optimization I will first try to keep it simple. 
Performance/footprint. Make sure to hide operator new/delete tho 😉.
TLDR - Make some extremely simple games with lua and love2D to get really comfortable with the start to end process, then fill in the blanks. Basically to become a game developer, you need to start making games. Make them as small and as simple as possible at first. Make your first 5 games so simple they could run on an atari 2600, except that graphics are better ( or not, it doesn't matter at this point). The easiest way to start creating games will probably be the following path: Learn lua (very easy) and make some simple games with love2d (also very easy). Once you feel good about pounding out simple games with sound, graphics, a menu, and a score, make a couple more. Then look in to either Unity or learning libraries with C++. C++ is all about the libraries. Look at GLFW (many people also use SDL). You will have to learn basic openGL, but that isn't bad. Create the same very simple games. You will have to pick up an audio library, and before you will be able to do anything you will realize that you need to learn some of the STL (standard template library). C++11 is your friend, it is much better than C++03 so there is no reason to dwell on the past. After that look at Ogre or go for Unity. ThreeJS is also a good webGL library similiar to Ogre. This will take a lot of time, trial and error, googling of solutions and hard work. But the big take away is to make SUPER simple games with love2D first, I can't stress how much this will accelerate your path to creating games yourself. 
I'd say: - provide debug and release packages ! 
&gt; Actually I have used C++ since the late 90s... I'm not sure which of my points you think you were intending to address with your comments...
Yes, Nimbal posted an example of a shared_ptr that does need a virtual Base destructor. The original point was that there are examples when it doesn't (as an example of why you might not need to give Base a virtual destructor). auto b = std::make_shared&lt;Derived&gt;(); std::shared_ptr&lt;Base&gt; smart(b); // remembers to call the Derived destructor Now if you can only create a Base object using a class factory that returns a shared_ptr created this way, then you could have a case for avoiding a virtual destructor. std::shared_ptr itself doesn't ever need a virtual destructor. I think you misinterpreted the discussion.
So its it or is it not live streamed?
G++ 4.8.2 here, your test with -Wall gives: &gt; warning: deleting object of abstract class type ‘test_base’ which has non-virtual destructor will cause undefined behaviour [-Wdelete-non-virtual-dtor] [Here](http://gcc.1065356.n5.nabble.com/patch-add-Wdelete-non-virtual-dtor-td525998.html) is the discussion in the Gcc ML about this feature. Probably comes with a relatively recent version of Gcc. 
Along with `bad()`, `good()`, `fail()` and `eof()`, they should introduce a method `last_read_was_successful()`. This would simply be the same as `operator bool`. This might seem pointless, introducing a new method that's the same as an existing conversion. But I think it would be good to have this in the documentation so that everyone can see this is the canonical way to test if the most recent extraction operation was successful. It might encourage some people to do: string line; ifstream f ("file"); while(getline(f, line).last_read_was_successful()) { process(&amp;line); } which would be a bit weird, instead of using the bool conversion. But I think the important thing is to discourage use of `eof()` and `good()`. People who aren't familiar with C++ will instinctively avoid bool conversions and other 'funny' stuff and will want to deal with well-named methods. I know I was like this when I first started C++.
I'll just join in and say that I don't think I'd be interested in such a feature. But of course, everybody's different! I tend to run a quite conservative system and the system's packaged libraries tend to be quite out of date. Also, there is one machine I don't have root on and therefore I can't install system packages even if I wanted to. But a compromise might be to simply offer a warning to the user if there is a system package that offers the same functionality, along with any further information about versioning. Then the user would have to option to cancel out of your package and install the system package, or to proceed within your package manager. But I guess there might be problems with that. Maybe the broader question is: if a particular library is already on the machine 'somewhere' (system-wide, or merely in the user's home directory), is it possible to point your system at it, instead of forcing a redownload and recompilation of the same code?
Based on the nitpicking, holier-than-thou responses I get on StackOverflow.com, yes.
&gt; I already know many languages like C/C++, Java, PHP, SQL, VB, &gt;Shell scripting etc on a syntax level . I have studied these languages as a part of the curriculum, and I know the syntax of all the languages, was what I meant to say. Sorry if I want clear. 
Normally, you should be able to list the exported symbols. On Linux I can do it using the `nm` command line utility. This lists the mangled names, by default, which mean for function the full function signature for example. So basically, it's just listing the list of exported symbols in both the old and new library, and check that the new includes the old. You might want to go further, however, for example verifying the memory layout of `struct` and `class`, of `union`, of `enum`, etc... which might be a bit more complicated. In any case, such an endeavor would probably benefit from a tool that is capable of dumping the ABI of a library in a binary/human readable format (json ?). I guess this could be built upon Clang, and used if available.
Correct me if I'm wrong, but I don't think the standard connects fstream operations to errno, so I don't think this will work in general. Also, there are other reasons file access can fail, ex., network drive went down while getline was executing; file is not really a file, but a device that is not ready. At some point I think you just have to say "operation failed". EDIT: Not to say that you shouldn't diagnose, but if I were to do that I think I would go all out and use the platform's IO functions (since this is going to be platform dependent anyway). And if I were going portable I'd leave it as "couldn't open file (for whatever reason)" and "read failed (for whatever reason)".
&gt; Not everyone wants/needs more fat in things like IO - More "fat"? There is no runtime cost. I'm just talking about an extra method that has a different name, but identical meaning, to an existing conversion. Maybe I misunderstood what you meant by "fat"?
Oh shit sorry I didnt notice that you said that. Sorry for my prejudice.
C++ is super duper complicated but you can do 95% of the stuff you need to do wit relatively easy subset. ofc stuff like serialization, enum to string will be irritating as hell to newbies when look my managed lang can do it in 4 lines...
By that logic, why not just get rid of `operator bool` and `fail`, and instead force everyone to explicitly check `badbit` and `failbit`? &gt; IMHO, if someone lacks the proficiency to safely read a line of a text file into a string, Actually, why not just get rid of all the C++ libraries, and force them to fall back on `stdio.h`?
since clang is plattform independent it would fit to the requirements. It is a pretty amazing feature but I think it will have to go on the wishlist for now and maybe be implemented as an extension/package itself. It would also be a problem to find out which changes are going to be backwards compatible and which will not. (e.g. the syntax of a method signature does not change but its semantics change -&gt; undetectable). This could be circumvented by running the unit tests of the last version against the new version (if it compiles and tests its backwards compatible if not -&gt; new major version) However this requires unit tests for all of the public api(if they are missing and the public api changes in an untested part it would not be noticed) and setting up the unit tests from a previous package version to run with the current version could be very hard( maybe it can also be very simple, I have no idea) But Thanks for your reply. I have had a couple of interesting ideas :D
&gt; Very true but... this is basically the "Fizz Buzz" question in the interview. It's nothing like "Fizz Buzz". Knowing the intricacies of C++ copy construction just tells me you've written C++ code lately. It doesn't help me determine if you're a good engineer or a lousy one. Fizz Buzz at least demonstrates that a candidate can put together an algorithm, albeit a very simplistic one. They might have memorized the C++ standard, but if they can't do Fizz Buzz, I don't want them. 
You make some valid points. But especially the last point would be simple if the packages only come from the package manager. (use cached versions of the package) Also it would still be possible for external dependencies to be set up and used (as is the default for build systems) and thus circumvent the package manager. besides that It would be possible to create a delegating package, which uses apt-get, chocolatey to install a dependency and set it up for the current project to use. 
&gt; People who aren't familiar with C++ will instinctively avoid bool conversions and other 'funny' stuff and will want to deal with well-named methods. I think there is plenty of non-idiomatic C++ code already, it would be a bad idea to introduce something that is inconsistent with the rest of the language (*into the standard*) and encourages such style. If you want to learn C++, then learn C++, not "C++ pretending to be something else".
I have interviewed people, but when I did so I asked questions pertaining to the things we were interviewing for. (And either way, I'm not the one being interviewed in those situations.)
This is a great tutorial. "c++ programming abstractions stanford" http://www.youtube.com/watch?v=kMzH3tfP6f8&amp;list=PL24126B3A47B69CB5
This answer has the potential to maybe be helpful if it were expanded upon.
I talked to my wife last night, and for a 6 day conference, she thought the $1000 was a steal: Apparently her 1-day seminars (Supply chain management) are easily $1k a piece.
Herb states elsewhere in this thread that this is likely replacing GoingNative (Nothing official yet), as this is much larger and in-depth than GoingNative and it doesn't make sense to split the organizational and speaker talent.
Oh boy. I think this article really show how and why the C++ Standard Library dropped the ball with its I/O components, not least `&lt;iostream&gt;`. The API is inefficient and hard to use. A much better solution (in my opinion and experience) is to use a thin wrapper around POSIX calls, that takes care of resources RAII-style *and* doesn't make you check tons of rarely-occurring error conditions in a fragile way *and* lets you allocate your own memory. My favourite so far is to use a variant type (I call it Either — it's also a monad, if you're into that kind of thing). auto stream = FileStream::open("...", FileStreamMode::Read); std::array&lt;char, BUFSIZE&gt; buffer; Either&lt;size_t, IOError&gt; result = stream.read(buffer.begin(), buffer.end()); result.when&lt;size_t&gt;([&amp;](size_t read_bytes) { // Do something with the buffer. }).when&lt;IOError&gt;([&amp;](const IOError&amp; error) { // Report an error. }); Type-safe, exception-safe, and doesn't encourage you to gloss over IO errors.
They could return errno equivalent in their ios_base::failure()'s .code().value(), except gnu didn't implement stream errors yet and libc++ returns the same error code for all stream errors... but there's hoping. The standard says "Errors arising from the operating system would typically be reported ... with an error value of the error number reported by the operating system" (27.5.3.1.1[ios::failure]/2)
&gt; I'm not the one being interviewed in those situations. As I said before, if you believe that, you are already doing it wrong.
&gt; Fizz Buzz at least demonstrates that a candidate can put together an algorithm, albeit a very simplistic one. I look at Fizz Buzz as validating that they've got an ability to code, not as any proof of problem solving ability. &gt; They might have memorized the C++ standard, but if they can't do Fizz Buzz, I don't want them. A memorized C++ standard isn't going to get you through that question. FTA: &gt; What I’m looking for here is someone that knows how important copying is in C++, where it takes place, and how it can be avoided. I’d expect a decent C++ programmer to be able to talk for around 15 minutes on this, with me asking subsidiary questions The question isn't "tell me how the standard defines the copy constructor", it's "tell me how anyone who actually has coded in C++ thinks about the copy constructor".
Ah yes indeed, unfortunately while API changes can easily be detected semantic changes would be very hard to automate. Not only that, but it may be that a semantic change is actually *necessary*; though of course one could argue that if the old behavior was meaningless then it was probably not tested. Regarding the ability to run the tests with another version of the software (ABI compatibility assumed), I suppose this would require to ask of people a "normalized" packaging with one set of sources and one set of tests.
&gt; // Report an error. So, how would that look like specifically? (I do not really expect you to answer in all detail on this, just want to point out that this is one of the major questions here)
`std::cerr &lt;&lt; "Oh crap, " &lt;&lt; error &lt;&lt; '\n'` presumably ? He did say "thin wrapper around POSIX calls," implying that `IOError` wraps an integer value from errno.h. I'd expect it to have a string conversion that passes that integer value to [`strerror`](http://pubs.opengroup.org/onlinepubs/009695399/functions/strerror.html).
As Dascandy points out, you're over-engineering this: static int counter = 0; counter++; If you have multiple threads, then use atomic_int. Also, every debugger I've ever seen lets you break on the nth execution of a line, do actions on the breakpoint (e.g. print something), &amp; continue execution afterwards. Using the debugger appropriately is a much more efficient way to shorten those iteration cycles.
I see, my apologies for jumping to cynicism rather hastily. With that said, it still is a bit steep for students. 
Would be much better if the section "The test results (important things to know: part 2):" delineated standard requirements from stuff that's specific to the author's system. Also, -1000 style points for passing `std::ifstream` by pointer instead of by reference
Does this read the entire file in one go into a file buffer?
&gt; The API is inefficient and hard to use. It is trivial to use: `while ( std::getline(f, s) ) { process(s); }`. Everyone knows this (except for college programming courses, judging by the number of posts on stackoverflow that start with `while (!f.eof())`). IDK why the posted article had so much preamble. &gt;A much better solution (in my opinion and experience) is to use a thin wrapper around POSIX calls What if you're on a non-POSIX system? 
Yeah, I/O error-reporting is kind of a hassle with C++ streams. Since I have the luxury of coding against C++11 and target LInux/OtherUnix, I usually do something like that: errno = 0; infile.open(filename, std::ios::binary); if (errno != 0) throw std::system_error(errno, std::system_category()); if (!infile) throw Exception(Error::IO_FAIL); Of course you can handle the error locally instead of throwing an exception. That works really good, but wrapping every I/O call in such a wrapper quickly becomes a chore to type :-P.
We also have a limited number of student rate spots available. I'm actually hoping that in future years we will be able to do even more for students.
Others explained the first part, yeah? The second part: if you delete a pointer to base, you might leak. A way to prevent that is to make it impossible to allocate derived classes in free storage, which is done by putting operator new/delete in "private". Drawback: that prevents you from using free storage completely for such derived classes. About COM: when doing COM, one almost always uses multiple inheritance. Freeing of objects is handled through IUnknown::Release, and that can be forced to always be called through a pointer to a most derived class. ATL does that through a sneaky use of the curiously recurring template pattern.
I believe that should be up to the application. Libraries should not enforce a specific error handling mechanism. Some applications may throw an exception. Others may return it in another Either. Others may wrap it inside their own error handling structure, or even an error code (if the public API is in C, say). There is no silver bullet to error handling, but "just" using exception is not a solution because they: 1) Encourage you to ignore the fact that errors can happen, and often aren't exceptional at all in the case of IO. 2) Incur significant overhead in terms of binary size, which is important in some of the most important markets for C++.
I would except this API to read the distance between `buffer.end()` and `buffer.begin()` into the buffer, though whether iterators should be used for this is debatable. Often I find using a raw pointer is acceptable.
Well, done deal, you've won this negatron over. 
Is it me or this looks quite the same as Boost.Compute mentioned on /r/cpp few days earlier? Only a lot broader and not implemented. 
As a veteran C++ developer I can say that I've *never* used fstreams professionally. Sure, they're pretty damned slow, but that wouldn't kill it for me if it was simple to use. But slow and over-complicated is the worst combination. Faster, simpler alternatives abound. fstreams are for CS students. Professionals use something better.
&gt; Others explained the first part, yeah? Not sure. If so you poorly spoke when describing the first part. I don't think adding a destructor of any kind to an abstract base has any performance or footprint impact at all, but I'm open to being corrected on that. &gt; The second part: if you delete a pointer to base, you might leak. &gt; A way to prevent that is to make it impossible to allocate derived classes in free storage, which is done by putting operator new/delete in "private". Drawback: that prevents you from using free storage completely for such derived classes. I wouldn't respond to the problem that way. It's unnecessarily convoluted and doesn't actually do much to address the problem. I could just subclass your base, not privatize delete because it's a really weird thing to do, it's hidden in the implementation class, and nobody told me that's what's wanted, and then we're back to the original issue. Alternatively I could directly call the destructor (placement free) and we're back to being hosed yet again. Just declare the destructor protected and be done with it! Totally absolves your base of dealing with the issue and pushes it down to the derived classes in a certain and clear way that obeys the standard. The best answer is to make the silly thing virtual, but if for whatever reason you're against doing that in a class that is already polymorphic, then at least make it protected.
I guess it's got the benefit of being 'official'. Whether that translates into anything useful will have to be seen.
It looks more like C++AMP. I wonder if someone who knows both could specify the exact differences in terms of what operations are supported on kernels and so on. They seem pretty similar, in kernels: no virtual functions, no function pointers, no exceptions, no RTTI,... although they talk about exception support in one slide, they say it is not supported in another. ~~From skimming the presentation what is missing (and I really hope I missed it) is support for function overloading depending on device.~~ It seems that there is overloading based on address space, I still don't know if this can be use to create overloads for different devices. Both CUDA and C++AMP support this and is immensely useful. slides here: http://www.khronos.org/assets/uploads/developers/library/2014-gdc/SYCL-for-OpenCL-GDC-Mar14.pdf
Do you have an implementation of such a thin wrapper?
Your smart pointer isn't likely to be used as a base class though, or at least probably shouldn't be.
Maybe because learning programming by video is terribly inefficient. Of course everybody learns differently so it’s hard to generalise but I’d maintain that a written tutorial can always beat a YouTube video in terms of efficiency of learning. I actually agree that the videos you’ve posted are pretty good – most other videos are certainly worse.
Bleh, for the two cases highlighted on the article (printing/not-printing error) it seems very simple. That's more or less what I do when I use fstreams. If someone wants more control on errors, then it gets complicate... But at-least there is support for them.
&gt; Of course everybody learns differently so it’s hard to generalise but I’d maintain that a written tutorial can always beat a YouTube video in terms of efficiency of learning. TL;DR: Less eye strain and pace set by someone else eases the mental burden of learning something new. Efficient - I couldn't agree more. But there are other values that can be considered. Somehow having a guy talking to you and walking you through is less eye strain. You can shift the burden back and forth between eyes and ears. Personally I like reading via audio books because at the end of the programming day my eyes are exhausted. It also makes it easier (for some) to not skim over something important. Basically: having the pace set for you is kind of nice sometimes: especially when you are learning something completely new. Again you completely acknowledged that people have different learning styles so I'm not arguing, I'm just hopefully casting some light. Also I bet there are more reasons to watch videos! Maybe you learn something new about development workflow that you would have missed in a written explanation. But if in the hierarchy of your values efficiency is at the top, then videos are not the way to go!
What I mean by "it won't work in general" is that I don't believe the C++, POSIX, or any other standard guarantees any particular value in errno when a stream operation fails. Even if it appears to work on your machine/platform/compiler for some cases, it could do something else under a different environment. That being said, I've no problem with diagnostics messages. To do it reliably, though, drop fstream and go straight to the platform IO functions. You'll lose portability, but the problem is *by definition* platform dependent.
It's even more of a pain that Windows *does* implement many equivalents to the POSIX functions, because they don't actually work when passed UTF-8. For the most part you have to use Windows-specific functions and convert all of the strings to UTF-16 to pass in the parameters...
serious question, what is THE windows package manager? cgywin's package manager or that visual studios package manager?
Hmm, in case of virtual functions and function pointers, for them to exist in C++ they have to be supported by OpenCL and it does not support them. In case for exceptions, my guess was, that by support exceptions they meant in c++ side: if something goes wrong, the c++ side throws exception not returns error code somewhere. I don't think they meant exceptions from OpenCL. 
&gt; I don't think adding a destructor of any kind to an abstract base has any performance or footprint impact at all Impact is obvious: one more virtual pointer table entry. Whether that **matters** is another thing. (I never measured but don't think a scenario where it does is easy to find 😉) &gt;I could just subclass your base, not privatize delete because it's a really weird thing to do, it's hidden in the implementation class, and nobody told me that's what's wanted, and then we're back to the original issue. I don't get this. What, we have abstract base -&gt; derived (operator new hidden), and you derive from derived, ,or...? &gt;I could directly call the destructor (placement free) You could, but if you want to break stuff, you could also trivially derive from base, expose destructor, cast to trivially derived and hey, presto! Having said that, my idea was more about preventing free store **allocation**, not freeing. That forces you to rely on runtime to destroy the most derived class and needs no virtual destruction.
Nice, added it to the description ... is that ok on reddit? I guess we're splitting off a bit from simply discussing the original videos.
Indeed, I find that things tend to stick more for me if I watch someone discuss them, and for some beginners they may seem less intimidating(though the videos posted were not exactly beginner lessons).
I'm not really getting the sense that this input is valuable or answers my original question in any way. More like a confused sort of tangent into WTF are you doing?? land. If the few bytes needed to push one more virtual on your table matters then you can protect the destructor and leave it non-virtual. Solves the problem and keeps anyone from screwing up because of your micro space optimization. The key is to force the cast so the person writing the code knows they're doing something stupid. Hiding it deep in the bowels of your concrete implementation, far away from the base you expect people to work with, doesn't exactly provide that kind of documentation. Any construct I can think of that "forces" you to use the most derived class's destructor (and as I already showed your plan doesn't) won't be harmed in the least by yet another layer of protection by making the destructor protected. In the end the best I can gleam from your frustratingly opaque obfuscation and terseness is an excuse to be lazy, not any reason why one of the two constructs I asked about would be harmful or get in the way. So, congratulations on getting me to dig this out of you, but nope...not really finding it helps answer my question.
Note that I'm not complaining about lack of virtual function support (AFAIK neither CUDA, OpenACC, nor C++AMP support them). I just went through the slides again and the point about exceptions it is still unclear to me (does memory allocation on device throw?, can you call throwing functions from kernels as long as you swallow all exceptions?) Anyhow they should probably ask for peer-review in the Boost mailing-list (and offer to pay peer-reviewers for their time) as well as send a draft to the standard committee to give this more exposure such that fundamental flaws can be found.
My thoughts too. I normally use just the OS functions. I wouldn't even know how to do an asynchronous read with fstreams.
Good point. That's kinda funny too :-)
Realistically it would be a nightmare. Different distros have different versions of libraries. They might even have their own custom patches on it. Install to various different locations. And so on. For example Clang didn't install the .a files for libtooling on Arch for some reason :( Also there all continuously in motion, there will be new Ubuntu release, then a new Debian then a Fedora, Arch is rolling release, etc... any of them could potentially change something under you that breaks your build. And now the developers have to test their build on 20 different Linux distros in case their specific setup is broken. And if you are distributing your software as standalone you will need to bundle all your libraries anyway. Also if your statically compiling then theres no real point in using the system ones. Also that kind of system library usage is only useful for some kinds of development (ie people making packages for a distro). Maybe a way to soften the transition between a standalone build to a system build would be useful. For example allowing you to add in something to mark the system libs as ok on a specific platform/version for your project. But worst case scenario people can just get the build working on those systems the manual way, they already have their own package management systems anyway. There will also be some times when you need to use the system libraries (things like Xorg). Maybe make a few key packages support systemwide installs. Also it would be useful to get tools like CMake/compilers/codegenerators system wide. But even then there can be requirements that building the latest in a sandbox would help resolve.
Something like Travis-CI would be useful. But it would need to build the package multiple times on different platforms so you can see where it works (and where it doesn't). It doesn't have to be as fine grained as Travis (actual releases only rather than every commit). I would drop SVN, I don't really see why 2 systems are necessary. If someone is using the package manager then there already using extra software so installing Git shouldn't be an issue and if their building their own stuff then there going to have to meet some requirements for putting it into the repos, one of them ight as well be a git repo (people can just sync it to github or setup something with git-svn if they are stuck on SVN) . There's also Mercurial, BZR, Darcs and so on so some other solution would be needed anyway... Don't limit it to C++ but also do C. Going to need the libraries anyway.
wow, how does that even work?
An abstraction layer will be a complicated beast to write for opengl, due to things like being able to share server side objects over multiple contexts. The fact you can copy rendering states. The wrapper would need to be aware of every single possible state of the opengl context + all extensions. OpenGL's threading model .. I could go on. Not saying the idea is bad, but pushing for a c++ utopia for a C api will be a real challenge without losing some functionality. That said I generally wrap some of the extensions into manageable objects like for textures off-screen rendering targets etc.
This targets SPIR, not OpenCL directly. Which is comparable to PTX in Cuda cards.
Except this targets OpenCL via SPIR, nothing to do with C.
Shameless self-plug:[Playlist](https://www.youtube.com/playlist?list=PLTEcWGdSiQenl4YRPvSqW7UPC6SiGNN7e) 
oops :) shame, gl could do with some sort of official wrappers too
Yeah, Windows is profoundly broken. :)
honestly, chocolaty is OK, but I have found msys2's package manager to be great. In fact it is pacman! The same pacman as found on arch linux.
No, that requires an implicit conversion from `istream` to `bool`, but `istream` only has an explicit conversion to bool. You'd need to do the casting to bool yourself, which makes the line less convenient and reads worse.
I once wrote a ray tracer using template meta programming. It could render a 32x32 image by compiling for 30 or so minutes. The end result was an executable that would spit out an image that it had stored as constants in the program. The ray tracer ended up creating a whole bunch of fprintf calls with the values of the pixels computed at compile time. EDIT: Code can be found here https://github.com/Lexdysic/MetaRaytrace. Should look something like [this](http://i.imgur.com/jUWRFct.png).
Well, now that depends on your operating system. And then your preferences. If she comes from a Linux background, she probably prefers the command line compiling approach. Note the difference between an IDE and a compiler. An IDE uses a compiler. They are not the same. Personally, I can use either, but the thing about IDE's, is that it's easier for newer users to learn. The thing about using command lines and makefiles is that you have more control and less confusion once you get comfortable with the commands and options. IDE's like Visual Studio can be daunting because of the sheer number of *exposed* settings. If you're new, I'd suggest picking up either Visual Studio or some other IDE. Write your code, and just hit F5 to compile and run. Later on, once you're comfortable, you can learn more about makefiles and the such to compile via command line. You just cd to the project dir and type "make" and then "ProgramName.exe" (or "./ProgramName" on non-Windows machines). Efficiency is entirely dependent on your competency and understanding of the processes. Sure, Visual Studio is a single key press to compile and run and has all kinds of debugging tools to help your development, but that's the thing about it. It's an IDE. Not a compiler. GCC doesn't offer these things because it's *just* a compiler.
If I said that I don't believe you, would that goad you into posting the source? I never wrote anything more exploitative than a very simple static asp solver that was horrid with tmp.
I will try to dig it up when I get home.
Thank you. 
Building C/C++ code goes through these stages: * Write the code in a text file. * Preprocess the source code. * Compile the preprocessed code into assembly. * Assemble the assembly into machine code. * Link the machine code into an executable. An IDE still does these things, it just automates these things. Using an IDE is fine - not only for learning, but it can make you more productive when you are very experienced, too. **But you should understand the process that's going on, too** if you want to be an effective C++ programmer. 
&gt; I wouldn't even know how to do an asynchronous read with fstreams. You don't. They're just now getting around to thinking about asynchronous operations with improvements to std::future and the like. I'd expect AIO in C++2x or 2y, after they (hopefully) sort out general asynchronous operations in C++17.
Russell's paradox isn't a paradox at all according to Clang. Haha
How did you do this without floats?
Why bother with `f.is_open()` instead of just relying on `!f` and `f.bad()`? Given that it's usually fairly easy to distinguish between open and read failures based on the error code, I generally write code like this: std::ifstream f(filename); std::string str; while (std::getline(f, str)) process(str); if (f.bad()) perror(filename); // or other error handling I'm also somewhat surprised about the commentary wrt "invalid" lines. If you want to know if the last line ends with a newline, either don't use `getline()` (which is spec'd to silently consume the delimiter) or use `f.seekg(-1, std::ios_base::end);` and check the last character manually. That said, I'd personally really like it if iostreams got an update to use `error_code&amp;` like the [Filesystem TR2 Proposal](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3335.html#Error-reporting)
Integer math. If you make everything large enough, then you no longer need fractions of a unit. Or you can think of it as fixed point math if you want, essentially the same. Probably the hardest part was implementing functions like Sqrt in template metaprogramming.
&gt; 4) I love opensource, and I am really looking to contribute to an opensource projects. Although I am going through the supertuxcart game source code and trying to understand how things work, is there any other opensource game which I should look into? Shoutout for /r/opensourcegames! The sub-reddit itself isn't terribly active, but it's a good resource of projects worth looking at.
&gt;Solves the problem and keeps anyone from screwing up because of your micro space optimization. It's not "mine", and I didn't push for this to be relevant, what's with the aggravation!? &gt;won't be harmed in the least by yet another layer of protection by making the destructor protected But I didn't say it would. Eh!? I find you worked up. Don't see much the reason for that, but don't care either. I did anything to upset you, sorry, wasn't on purpose.
&gt; I didn't push for this to be relevant I wish you would have mentioned that in your first post so I wouldn't have wasted the time trying to get you to say what you meant. IMO throwing some terse comment out that doesn't even mean anything is rude on its own. When you didn't even intend for it to be relevant to the conversation...that just takes the cake.
yeah, I want to try it out with all the new C++11 toys. I wrote it a few years ago, so I had to do everything "by hand", so to speak.
When you hit the compile button in codeblocks, hit ctrl-F9 and look at the window on the bottom. Those are the commands that the IDE gives to the compiler. You'll get exactly the same results if you type those commands in manually at the command prompt (as long as you're in the right directory), the IDE just makes it easier to keep track of the different options.
Wow I never knew this! I'll definitely do this to get to understand the command line commands more. Thanks!
&gt; I actually wonder whether clang is right here, i.e. whether the above code snippet is in fact equivalent to: I think that clang is correct here. It's valid for a class to refer to itself, and the fact that this class is a template shouldn't matter. So that code should be the same as: struct SelfRec { static const int value = value; }; Normally, initializing a variable with itself like `int i = i;` initializes it with an indeterminate value, but static variables are zero initialized before any other initialization, so initializing a static variable with its own value should be the same as zero initialization. &gt; Clang, however, thinks that the initializer is not a constant expression, and rejects the code. The initializer looks pretty constant to me, since it is declared as static const. undefined behavior prevents an expression from being a constant expression. I would guess that both the program for self contradiction and Russell's paradox have undefined behavior as well, though I'm not sure.
You have made a spelling mistake. You declared: int nOperend1; int nOperend2; And tried to store them into nOperand1 and nOperand2 notice how you changed an e into an a. Also, you should indent your code better. It will make things like scopes changes a lot easier to see and will make your code a lot easier to read.
switch is misspelled on line 17. (just saying)
Questions: http://reddit.com/r/cpp_questions
normally the number of template instantiations is limited (you can explicitly remove the limit).
As mentioned by other posters, there are several spelling errors. This is a fantastic reason to use an IDE, even a barebones one!
Thanks for alerting us to this issue; it has never occurred to me before. This should go on a list of pitfalls to keep in mind when interfacing with C APIs.
This isn't an API, this is a fundamental data type in C: the char* that comes from std::string::c_str() The issue arises when one assumes a std::string is the same thing as a char*. They're two different beasts, and the conversions between the two are imperfect.
Good idea thanks very much
Yes, I know. My point was that the times you are most likely to use c_str() are when you are interfacing with C APIs that require the use of `char*`. The idiomatic thing to do in C++ to store text is to use std::string, so the problem doesn't really manifest if no conversion to char* is required.
Edited my post with links. Enjoy!
Everyone should be aware of the difference between pascal vs. C style strings, and where they are used. Many a security issue has arisen from this exact misunderstanding as well.
This part doesn't look quite right... &gt;Whereas a string literal has signature: &gt; double operator "" _s (const char* text, size_t len); THIS SHIT SHOULD RETURN A `std::string` RIGHT GUYS? edit: downvotes, really?
std::string is often used to store buffers in network code in C++. 
If you are not able to use Qt 5.*, have a look at https://code.google.com/p/qtboostintegration/, which allows to boost::bind stuff into signals (and has some bugs, but meh.). That's most likely enough.
Inner null bytes are also valid in UTF-8 encoded strings, so it's not just a problem with binary. https://en.wikipedia.org/wiki/Null-terminated_string#Character_encodings
#####&amp;#009; ######&amp;#009; ####&amp;#009; Section 4. [**Character encodings**](http://en.wikipedia.org/wiki/Null-terminated_string#Character_encodings) of article [**Null-terminated string**](http://en.wikipedia.org/wiki/Null-terminated%20string): [](#sfw) --- &gt; &gt;Null-terminated strings require of the encoding that it does not use the zero code anywhere. &gt;It is not possible to store every possible [ASCII](http://en.wikipedia.org/wiki/ASCII) or [UTF-8](http://en.wikipedia.org/wiki/UTF-8) string in a null-terminated string, as the encoding of the [NUL character](http://en.wikipedia.org/wiki/Null_character) is a zero byte. However, it is common to store the subset of ASCII or UTF-8 not containing the NUL character in null-terminated strings. Some systems use "modified UTF-8" which encodes the NUL character as two non-zero bytes (0xC0, 0x80) and thus allow all possible strings to be stored. &gt;[UTF-16](http://en.wikipedia.org/wiki/UTF-16) uses 2-byte integers and since either byte may be zero, cannot be stored in a null-terminated byte string. However a null-terminated string of 16-bit words can be used and some languages implement this (again the NUL character, which encodes as a single zero code unit, cannot be stored). &gt; --- ^Interesting: [^Null ^character](http://en.wikipedia.org/wiki/Null_character) ^| [^Exec ^\(computing)](http://en.wikipedia.org/wiki/Exec_\(computing\)) ^| [^Empty ^string](http://en.wikipedia.org/wiki/Empty_string) ^| [^FastCode](http://en.wikipedia.org/wiki/FastCode) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cg81zg8) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cg81zg8)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
[Yes, yes you can](https://llvm.org/svn/llvm-project/cfe/trunk/test/SemaCXX/constexpr-nqueens.cpp). There might also be a few other impressive feats in the Clang test suite.
&gt; struct SelfRec { &gt; static const int value = value; &gt; }; This simple code snippet is accepted by Clang, and rejected by GCC. And no templates involved here. Looks like they really cannot agree, what tricky C++ means.
Yeah I'm using it in my hobby game engine, considering it for the [Wayward Web Framework](https://github.com/simonask/w) as well (don't use, early alpha!).
Um, I thought it's quite old news that C-style strings (`const char *`) are terminated by `\0` and std::string specifically makes use of the object structure to carry additional length information, which cannot be done with C. However, the difference between `std::string("\0foo")` and `std::string("\0foo", 4)` is worth to know. That'll produce the kind of bug one can spend hours of debugging.
String literals are not required to return `std::string`.
Related: "C++14: Even Simpler C++" [Slides, PDF] http://wiki.hsr.ch/PeterSommerlad/files/2013ESE_Cplusplus14_4print.pdf 
As most compilers require text files as input you need to copy the text from your PNG input file into a *.ccp file if you want any chance for this to compile.
Maybe you should crosspost this to [r/badcode](http://www.reddit.com/r/badcode), even though it's not quite on-topic there...
I'd rather learn about good code :)
&gt; I'm hoping to have a full draft of the book by the end of April Excited! I'm probably preordering this book if there will be an option to do so.
yeah, that's not how you make friends in /r/cpp
Like all high level languages it takes a little effort to learn them properly. Problem with C++ is sometimes that it is so easily mixable with C, and that older styles which predate Modern C++ and C++11 are still in use.
I so hope I can preorder this book!
Nice. Looking forward to it :)
I am compelled to use that hex value for something in my code... I just need to figure out for what and be able to justify it.
trie if you are into data structures... note this is not a decent size project for a prof dev, but since you are junior i think you will suffer enough. :) 
Look for a nice open source tool which is interesting to you (e.g. for your hobby). Get in contact with the project team and offer your help. 
like a second volume? or a new edition? I JUST bought Effective C++ :( 
I dont mean to derail the topic but I just wanted to say Scott Meyers hair is fantastic. A appropriate haircut for a coding rockstar.
_Effective C++_ will still be relevant, except if/where it is superseded by the new book. I just browsed through the TOC of _Effective C++_, and I only see a few things that are outdated (e.g. using TR1 and parts of Boost that are now in STL).
I'm not looking to specifically focus on a bad code show, I know that I could present 90 Minutes of horrible code, but rather I prefer to analyze, classify and help people to deal with bad code. Readability is important, but it says nothing about the code quality. An experienced java developer might still use new everywhere, and forget about delete.
&gt; An experienced java developer might still use new everywhere, and forget about delete. I'd classify that as _incorrect_ code. Code can be horrible, ugly, whatever adjective you want to describe reading it, and still be 100% correct and working. Or it can be a beautiful flower that segfaults if you look at it funny. The former is what I'm thinking of when I hear "bad", the latter is simply incorrect or non-functional.
Someone might hope that string has COW, which might be a performance boon. I don't remember hearing of COW-ed vector (and am not sure it's feasible).
Well, I guess this is a strongly opinionated topic. For me memoryleaks is clearly bad code. And yes, incorrect code is of course also bad code.
It's as feasible as `std::string`, meaning that it's horrid: any call to a non-const operation (even as basic as `begin` or `[]`) must incur the cost of a copy unless the current object is the sole owner of the underlying buffer. In general, I've found using `StringRef` (and `ArrayRef`) much more reliable where performance is a concern.
I did not know that. 
ah ok that's fine. I'm ok with the stl/boost related stuff. I mostly bought this book to find out how much little I actually knew about the subtleties of const and other C++ features I use often. So far the book has been really really useful. 
Scott Meyers even mentioned it himself, *Effective* and *More Effective* aren't superseded by *Effective Modern*. From the TOC, it looks like there are a couple things that become easier with the new features though... `=delete` functions you don't want the compiler to generate instead of using private inheritance, etc...
Note that this contains links to a [video (YouTube)](http://www.youtube.com/watch?v=BFnhhPehpKw) and [slides (PPTX)](http://nwcpp.org/talks/2014/ISeeAMonadInYourFuture.pptx) from a presentation on a topic introduced in a previously submitted blog post (from February 26, 2014). For completeness, here's the related discussion of the aforementioned blog post: http://www.reddit.com/r/cpp/comments/1z1b1q/c17_i_see_a_monad_in_your_future/
There is also "[Effective STL](http://www.amazon.com/Effective-STL-Specific-Standard-Template/dp/0201749629)" if you're a big STL user.
Announcement http://isocpp.org/blog/2014/03/faq
Added it, it would have been a little bit more interesting if you had continued on with the theme of an SFML game(though it may be tricky to find a use for everything).
Your post got me googling about C++ books and I found this stackoverflow. I think it's probably worth it for me to gradually go through everything starting from best practices. Possibly skipping the template metaprogramming stuff. 
Try making something you need, or have a strong desire to do so you don't quit the project before it's done. Project completion is _very_ important. You could make something with SFML, maybe a pacman clone for a larger project, or maybe networked pong(or just pong, with focus on it being feature complete)
So, how long before someone puts up an FQA for this?
Yeah outside of some previous employment where we had older codebase issues I tend to use C++11. Mostly because I'm frequently accessing the file system and I feel more at home with the threading api. auto is also pretty cool coming from a c# background. So far I'm really liking it, I always hated having to do platform dependent threads and filesystem code. MISRA I had to google. That's a new one. 
As long as it will take for someone who has no clue about the language, too much free time and an unreasonable hatred for the language to write one. ;-) 
I say go for it, college kids lack humility
Will this book be beginner friendly? If not, can someone please point me in the direction of a good beginner friendly book? Cheers.
check out the definitive C++ book list at stackoverflow
Now we need *C++: The Good Parts*. &gt;Item 6: Be aware of the typed initializer idiom. What's that idiom?
Spend some time in node-land, and you'll see that its amazing success is largely due to its **language-specific** package manager, npm. Every node enthusiast will tell you how awesome it is to need a package, and have it immediately available with zero compatibility problems.
I really do believe that it is important to get information from people who have varying perspectives about and experiences with C++. Looking at the language from more than one angle enables you to make better-informed choices about when and how to invest in learning about C++. The Cline FAQ accepts C++ for what it is. Its purpose is to show the mindset that you should be using when you use a certain feature of the language. The FQA tells you that devotion to C++ pedagogy will not solve the problem that C++ is sometimes just not human-friendly, or downright badly-designed (e.g. iostreams). A lot of this is due to backward compatibility with C. Knowing when using X feature of the language might not be a good idea (e.g. exceptions on embedded systems) is an important part of understanding the language. I would definitely like to see a FQA alongside the FAQ; it's good to be open about which parts of the language could use improvement. I think that this would also help the committee look for ways to clean up the language in future standards.
IE has the most splendid option. This and its Favorites menu are what keep me using it. Tools &gt; Internet options &gt; Fonts &gt; Verdana, Consolas then: Tools &gt; Internet options &gt; Accessibility &gt; Ignore font styles, Ignore font sizes This overrides the entire Internet to Verdana/Consolas 12, which is actually readable, unlike everyone's stupid fonts and *stupid* tiny sizes. It breaks sites to varying degrees but most remain quite readable. Other browsers have similar options but I prefer how IE renders fonts.
Yeah, I won't lie. IE's rendering looks the best even though I don't use it.
It's completely different content. It doesn't duplicate any information in any of my earlier books. For more information about the goals of the new book, please check out [this blog post](http://scottmeyers.blogspot.com/2014/02/help-me-name-my-book.html).
Cheers!
The 'self-recursion' and 'mutual-recursion' examples in the post also make GCC loop indefinitely, despite having a limit on template instantiation depth. This is obviously a bug in GCC, since one would generally always expect a compiler to terminate.
Yes. I think in general one can make a better choice between products A, B and C by focusing more on what people complain about than what people say they like in a product. In this respect, the FAQ and the FQA serve different purposes. FQA is helpful when one considers using C++ or alternatives for a given project. However, once the choice of C++ has been made, the FAQ has a lot of advice on how to use C++ properly.
#evil :P
Oh certainly if you *think* about using the `const` version (you can create a const-reference alias for this) then you are okay; but it's a bit annoying that the non-const `operator[]`, `at`, etc... can be O(N) in some conditions.
Unfortunately the FQA is so biased and repetitive that it's not even funny. The author rejects a couple C++ idioms (RAII and exceptions) and then wonders why the language falls apart... and why it does not have Garbage Collection. There *are* valid criticisms to C++, off the top of my head the insane requirements of backward-compatibility is perhaps the most annoying (dragging the language down) and of course the "undefinedness" of so many constructs. But those are really ill-treated in the current FQA.
That seems like a pretty standard way to define it in a C library. Why do you actually need to know what is in the X509 struct? It really shouldn't matter to you as a user of the library. The API should abstract that from you. If you are trying to write it yourself instead of using the API you are doing it wrong.
This has got to come down to personal preference. Your comment made me visit the site in both Chrome and Firefox on both Windows and Linux, and I even opened up IE on Windows for the first time this year. The site looked fine in both Chrome and Firefox, either Windows and Linux. But I did not like the font rendering in IE. As for STL's comments about font sizes, I almost never have to tweak anything beyond a couples presses of CTRL and + or - to change font sizes these days. I certainly would not lock all fonts on every website to the same font and size, but to each their own.
I'm sortof an uber geek. I want to know how it works when I use it. Not only that, but our app keeps saying that the certs aren't valid when verifying that a cert isn't in the CRL, when the CRL is empty. So, I decided to dig a little deeper for a better understanding before moving forward. I just thought it was super funny/annoying that it took me so long to find the definition of a type that we were using in our app.
This is however the completely wrong way of doing this. C++11 outlawed COW and even libstdc++ will be moving to the small-string-optimization soon. If you need a COW-container, use one that specifies this or write one yourself (shouldn't be that hard in case of arrays).
Ah, indeed. You learn something every day. I wonder if that standard change is accidental or not.
AFAIK it was made because COW could interact badly with multithreading.
While many of his items sound reasonable, I have the impression that there isn't much that you wouldn't already know if you follow the development of the language (via this subreddit or otherwise). So, my comments on some of his points: * Item 3: Know how to view deduced types. I am not entirely sure what this is about? `typeid(T).name()`? * Item 6: Be aware of the typed initializer idiom. Again: I am not sure what this is about. Google only finds Scott's blog. * Item 24: When using the Pimpl Idiom, define special member functions in the implementation file. I am interested in his rationale for this, since the defaults are perfectly sufficient for non-copyable classes if you use std::unique_ptr; * Item 27: Prefer lambdas to std::bind. I guess that this one is about performance. If this is his only reason, I disagree with him there, since std::bind can be way cleaner. * Item 41: Employ sequential consistency if at all possible. Well, if you don't, your program isn't C++ anymore because it contains undefined behavior. I fail to see how this is something new.
Yeah, I see what you mean. Even though the app that I'm trying to fix is written, this post is all about a C library. Sorry.
There's also w3m if you only want to read text.
Where I can see requirements/specs/user stories/anything?
Bollocks. Learn by doing.
Recording is still very much up in the air. I wouldn't assume anything. =] We should be able to start figuring out these details as the conference nears.
Just FYI, while this would be nice, it is still very much up in the air. When we have concrete information about this, it'll be posted.
Item 6: I'm guessing this is a name Scott has come up with for auto-with-an-explicit-conversion: `auto foo = bar_t{value};`, which is funky as hell to someone who isn't familiar with [AAA-style](http://herbsutter.com/2013/08/12/gotw-94-solution-aaa-style-almost-always-auto/). Item 24: Typically the implementation class is incomplete and nested in the interface class definition: class interface { class implementation; std::unique_ptr&lt;implementation&gt; impl; // ... }; The `interface` default constructor, destructor, copy constructor, copy/move assignment all need to be implemented where `implementation` is complete, even if it's a simple defaulted implementation like class interface { class implementation; std::unique_ptr&lt;implementation&gt; impl; public: interface(); ~interface(); interface&amp; operator = (interface&amp;&amp;); // ... }; // ... class implementation {}; interface::interface() : impl{new implementation} {} interface::~interface() = default; interface&amp; operator = (interface&amp;&amp;) = default; Item 27: `std::bind` expressions often end up with unreadable syntax and `reference_wrapper`s and `std::placeholder`s, I feel like lambda syntax is more comprehensible. Item 41: On the border between the lands of sequential consistency and undefined behavior lies the dark land of relaxed atomics, ruled over by madness and chaos. Abandon all hope ye who enter here.
Oh thanks. I've waisted 3 hours reading that! :)
Could be, but AFAIK, bad interaction is a performance hit in high-contention scenarios (in which case, one can switch to a different implementation), not a correctness one. Herb Sutter made some performance tests on that some time ago. Is there more? (Honest question).
I always picture him in a feudal medieval setting, who's about to wield a morning star at any given moment.
In his previous talks he mentioned just that.
&gt; Relaxed atomics are something for people who think juggling with burning swords is boring. So true. I was burned in shared_ptr (fixed in 2013, further optimized in the next major version - we're confident now that relaxed increments and acq_rel decrements are correct. weak_ptr::lock is probably suboptimal but I am not eager to mess with it at this point).
To expand on the case against `bind()`: * Writing `bind()` expressions, especially nested `bind()` expressions, requires learning a mini-language that is Not C++. In contrast, a lambda's body is ordinary C++. (The lambda-introducer is special syntax, but it's focused on simple operations: capturing and now initializing members.) Doing anything complicated is significantly easier with a lambda. * `bind()` misuse generates truly awful messages - and I say that as someone who eats templates and drinks compiler errors for a living. `bind()` errors are going to complain about implementation details, and `bind()` needs a lot of complicated machinery - much more than something like the containers or algorithms. Sure, if you try to use `remove_if()` on a `map` you'll get an apparently-bizarre error, but it doesn't require that much experience to figure out what it's complaining about. With `bind()`, you basically need to have an implementer you can ask. * `bind()` conceals what it's doing, in ways that are not obvious to users. For example, bound functors are given bound arguments as lvalues, so they can be repeatedly invoked. This (and the resulting compiler error if you expect rvalues) is not obvious, and requires a careful reading of the Standardese. Although lambdas generate an invisible class, their transformation is simpler (and compilers can emit better errors). If you call `takes_unique_ptr(up)` from a lambda, of course you're passing an lvalue, because you can see it right there. * `bind()` can be slower than lambdas. Specifically, bound functors are stored as data members, and it is difficult for optimizers to reason about this. If you bind a function pointer, you're probably going to get an indirect call (certainly for VC; I've asked). In contrast, if you call a function in a lambda, that's an ordinary call with ordinary eligibility for inlining. * `bind()`'s advantages have eroded over time. It was developed in an older, simpler era before lambdas and generic lambdas. While `bind()` still has a few tricks up its sleeve (e.g. it auto-adapts for pointers-to-members mixed with references/pointers/smart-pointers to objects), lambdas have almost completely superseded its functionality. While I ordinarily recommend using Library tech instead of Core tech (e.g. `unique_ptr` instead of `new`, `string` instead of `const char *`, etc.), I believe that `bind()` should no longer be used, ever.
So you were the guy who was responsible for the bug I mentioned above? [Any change that you will describe in detail what happened?](http://display.crystalscomments.com/1/974469152168ac4e9b46.jpg)
http://blogs.msdn.com/b/vcblog/archive/2013/06/28/c-11-14-stl-features-fixes-and-breaking-changes-in-vs-2013.aspx &gt; * On ARM, we realized that we were decrementing shared_ptr/weak_ptr's refcounts in a multithreading-unsafe manner (DevDiv#455917). (Note: x86/x64 were absolutely unaffected.) Although we never observed crashes or other incorrect behavior even after focused testing, we changed the decrements to use sequential consistency, which is definitely correct (although potentially slightly slower than optimal). More details: In 2012, we took Dinkumware's code (which used SC) and looked for opportunities to improve its performance on ARM, the new platform we were releasing, where SC is quite expensive (unlike x86/x64 where it is almost free). We believed that relaxed increments and release decrements were correct, so we shipped that. When I mentioned this to Herb ("hey look, we're using weaker-than-SC to be fast on ARM"), he explained that we were totally wrong, since release forms a handshake with acquire, and the decrement synchronizes with itself (a bunch of objects can be decrementing the refcount, and only one can be allowed to proceed to delete the resource; the other threads can't be allowed to observe the deletion happening before their decrements, and the deleting thread can't be allowed to observe other threads' modifications happening after its decrement). I was determined not be burned again, so I shipped relaxed increments, SC decrements in 2013. Herb heard about *that* and convinced me that relaxed increment, acquire-release decrement is safe, so I've made that change for the next major version. All that work for just two lines. To emphasize, x86/x64 were completely unaffected (they have always used SC) and we never observed a crash on ARM despite attempting to trigger one. Nobody outside MS would even know about this if I hadn't blogged about it.
I've detected a hexadecimal color code in your comment. Please allow me to provide visual representation. [#455917](http://color.re/455917.png) *** [^^Learn ^^more ^^about ^^me](http://color.re) ^^| ^^Don't ^^want ^^me ^^replying ^^on ^^your ^^comments ^^again? ^^Respond ^^to ^^this ^^comment ^^with: ^^'colorcodebot ^^leave ^^me ^^alone' 
colorcodebot leave me alone
Sorry, I will never reply to your comments again.
if I was in your position I would be SO tempted to look at gcc clang std lib implementations :P anyway good to know you made shared_ptr fast on arm. :) 
Well, bind has to be used before we can rely on the C++14 generalized lambda captures, for example to capture move-only types.
How about a device driver for a popular, but currently unsupported piece of hardware?
I also like 0x8BADF00D, but have never found a good use for it either
These guys did a nice job! In any event what is all the noise about font sizes pinch to zoom on the iPad fixes that. OK so it is rather fine print. Speaking of iPad I'd pay a couple of bucks to have this FAQ installable as an app on the iPad. I just hate burning up bandwidth for reference works. 
well, can you include an example?
ah, i dont have atl. time to install. do you have to use c++11 stuff? :/ What is the minimal VS version required to use this?
Finally I got to run provided [example](http://pastebin.com/VsV0hxf0). I tested it on Visual C++ 2013 Express with November CTP. To test it with VC++ Express is also needed [Windows 7 WDK](http://www.microsoft.com/en-us/download/details.aspx?id=11800) (for ATL) - on installation is need to select just headers. [Here](https://onedrive.live.com/download?resid=EF417D1F5473D302!541&amp;authkey=!AA0wHhwyXUfdXNQ&amp;ithint=file%2c.zip) is my test solution (uitk is included in project, $(CPP_LIBS) macro in includes is an [environment variable](http://i.imgur.com/7yNATl7.png) which point to path where all libraries are stored, also will need [this](http://stackoverflow.com/questions/9559547/atl-library-warning-lnk4254-and-lnk4078) to do). Overall I think is a very good start. Headers only library is great, till now I used WTL (which btw updated to version 9), but this library is a lot more elegant and simple in use. C++11 promotion is also a big plus for the library.
I fail to see which license this project is distributed under. Is it freely usable inside commercial applications ?
In my second job, when I got there there was a single method for handling keyboard input and reflecting the results on the screen. It was 1700 lines long with 23 gotos. Despite numerous requests over the years - we were never given the time to refactor the method into something reasonable. If we wanted to kill any proposed change, we'd say we think it that would require an alteration in that monster method. Worked almost every time. 
As you can read in the sidebar this post really belongs to /r/cpp_questions and is off-topic here.
If i understand this rightly then you could just use an overloaded constructor as such: example_text(const int rowIn, const int columnIn){ row = rowIn; column = columnIn; } and then reflect your class to have 2 private ints. I don't entirely understand your question though.
There are multiple ways: Usually you don't want to (or cannot) access private members in the main program, but you can make so-called "accessor" methods. To give a function (not a class method) access to the private members, you could also make it a "friend" function. I put together some commented example code on GitHub, I think it should help you understand how this can be done: The class header: https://github.com/rasbt/cpp11_code_examples/blob/master/class_header.h And the class_main: https://github.com/rasbt/cpp11_code_examples/blob/master/class_main.cpp
Wow I am keen for this. C++11 and google standards bar styling. Check check check. Do you have a testing scheme? I am going to check this out when I get home.
At least from what I saw library make use of uniform initialization, lambdas, variadic templates, override/default/delete specifiers, strongly typed enums, auto, range for etc. (and the resulting code is really compact), so minimal VS will be [2013](http://blogs.msdn.com/b/vcblog/archive/2013/12/02/c-11-14-core-language-features-in-vs-2013-and-the-nov-2013-ctp.aspx), also STL is used extensively (vector, string, set, map, unique_ptr/shared_ptr). I don't think author will or should make it C++03 compatible, I always wonder how compact and clean many boost libraries would be without all that compatibility layer to support.
Doesn't seem to bring much to the table if its not cross platform. Tons of windows developers already know the ins and outs of the forms stuff, etc.
I would love something like this for other platforms :-).
Write a college project idea generator.
Your question is wildly unclear but I think its because you dont have the right terminology. It sounds like you want to take in two input values and make use of it across multiple functions of the class. First of all; what you have in your example is not a "private class." You created a class; a class can have public functions and variables (accessible to anyone outside the class definition) and a class can have private functions and variables (available only within the class definition). It sounds like you want two variables declared as private members of the class which can be done like this: class MyClass { private: int A, B; public: void SetVars( int in_a, int in_b ) { A = in_a; B = in_b; } void YourOtherFunction( ... ) { ... } } You can now use the private vars in any function in your class. Hope that helps, good luck!!
 #include &lt;iostream&gt; class Foo{ private: type array[][]; public: Output(const int row, const int column){ std::cout &lt;&lt; array[row][column] &lt;&lt; std::endl; } };
FYI, your example header has `using std::string;` which is generally a terrible thing to do. `using` statements should not appear in a header file unless specifically lifting symbols into a namespace. Your `using` is to the global namespace, so anyone including your header is now victim to `string` being in the global namespace. http://media.tumblr.com/tumblr_ls7u7x70ph1qa54sa.gif
Also, unless you're planning to support some awfully esoteric (IMO) compilers, `#pragma once` is a nice alternative to manual include guards. http://en.wikipedia.org/wiki/Pragma_once#Portability
&gt; Tons of windows developers already know the ins and outs of the forms stuff, etc. know ≠ like or want to use I, for one, would love to have used something like this when I used to work on Windows.
We have full release notes on the [Github tag page](https://github.com/USCiLab/cereal/releases/tag/v1.0.0), but here are some highlights: * Out-of-order loading of JSON and XML archives * Support for Visual Studio 2013 * Proper handling of smart pointer linked lists with loops. * Full compatibility with boost.serialization's API. * Plenty of minor bug fixes, usability improvements, and documentation.
I just wanted to say that cereal is my favorite serialization library. Thanks for making it. Also I like both types of cereal.
I would start by looking up "scope." For example, in your Item_Name_Process(...) function, you declare a local vector that has the same name as your class's attribute; the Name_List variable hides your class's Name_List attribute.
Thanks! We have had a lot of fun making it, and learned a ton in the process.
Thanks for the reply! Honestly I didn't know what you we're talking about until I did some digging into scopes and then I realized since I had initialized Name_List twice, I was deleting any data that I had put into it in the first function correct? I'll work on that and I'll make sure to initialize the vector once in the class! thanks!
Because C++11 stuff is amazing. Get the newly Microsoft C++.
Tell me more about.
Funny how I decided to use this exact library yesterday for a [small project](https://github.com/FlorianJW/owl) of mine. It's mostly awesome so far, except for this one thing: Is there any chance to improve the error-messages if parsing a json-file fails? “Error: rapidjson internal assertion failure: IsObject()” really isn't helpfull.
Yeah definitely - this is something I've been meaning to get around to for a while. When you get a chance, please [submit a bug report](https://github.com/USCiLab/cereal/issues) with a simple code example and an associated JSON file.
We could always catch an error upon parsing the JSON and re-throw it as something more descriptive. You should make an issue on the github for this - but the only real difference is that you'll get a message saying something like "JSON parsing failed - likely due to ill-formed JSON" or something like that.
Any reason for choosing RapidXML over Pugixml? The latter is still being maintained, while the former is not.
I think the only reason is that RapidXML came up before it when I searched for header only XML libraries. I'll take a look at this, it looks like it could be a sensible swap to make in a future release.
Interesting. I built something that looks a lot like this, but as a general visitor pattern thing. So, you did things like: template&lt; typename Archive &gt; void reflect( Archive &amp;ar ) { R( m_x, ATT_COMPRESS_BITS() ); R( m_y ); R( m_z ); }; R was a macro that got the string name of the item. Something like that. Save/load was just another visitor, along with inspecting, printing, getting sizes, etc. The attributes was to get something like C# or Java attributes into C++. 
Main difference of interest I noticed from the boost versions of things is that `variant` can use lambdas for visiting, which hopefully will make it not quite so horribly awkward to use. Will need to try it out. I am a little confused about why cmake is required as it appears to be header-only.
I've always wondered what the point of using something like this over using thrift/protobuf would be? The latter are language agnostic &amp; the serialization/deserialization code is generated for you automatically from the schema. This also means you get free backwards &amp; forwards compatibility. With this approach it seems like we're stepping back to having to manually serialize/deserialize everything.
Interesting, never heard of cereal before. A quick skim reveals an easy to use facility - I like. 
(disclaimer: I haven't used thrift/protobuf/capn-proto, this is based on my understanding form reading their documentation) I would say the biggest reason for something like cereal is ease of use. There's no schema to worry about or worrying about mapping your types into the serialization format. Some people want their data in a different format and cereal makes it fairly easy to write new serialization archive types. cereal also comes with XML and JSON support, which a lot of people seem to like. cereal supports pretty much everything in the standard library already, so a user can very quickly give even complicated types serialization support. Writing serialization functions is a small amount of work, which I would say is easier than making a well defined schema. Something like capn-proto is better suited if you need to talk to other languages in a binary-like format, and currently I would say also much better for communicating over a network in a streaming fashion. There's a better response [here](http://www.reddit.com/r/programming/comments/218zzx/cereal_a_crossplatform_c11_serialization_library/cgaty0i) describing the key differences.
And his point was that knowing the right macro to use imposes an unnessecary cognitive cost which doesn't exist in Catch it simply does it for you. Thinking is expensive, I prefer to use it on things that actually matter.
Can someone more familiar with C++ standardization please give us a summary on the state of affairs regarding compile-time reflection in C++? There doesn't seem to be [a committee](http://isocpp.org/std/status) working on compile-time reflection for C++ 2017, so from what I can tell, there are no plans to introduce it into the standard.
[This](http://i.imgur.com/C1k5UT8.png) is what it looks like on my machine (OS X 10.9). I think it's a very legible and aesthetic serif font. Is this similar to what you are seeing?
Check SG7 Reflection working group and the reflection@isocpp.org mailing list here https://groups.google.com/a/isocpp.org/forum/#!forum/reflection
Why would someone choose cereal over boost serialization?
CMake is only required if you do an install (and make sure your current environment meets the minimum requirements) from the source directory. I simply placed it as a requirement for package maintainers. Of course support for RPM or DEB is not complete, but if you wish to build a custom MSI for windows, CMake will do most of the work for you.
Here's a [bunch of good reasons](http://uscilab.github.io/cereal/transition_from_boost.html): 1. cereal is header only 2. support for far more of the standard library than Boost 3. significantly easier codebase to understand 4. you don't need to pull in half of Boost 5. less verbose than using Boost 6. Meaningful static_assertions when you make mistakes 7. You need JSON serialization Here's why you might want to stay with Boost: 1. Need to serialize raw pointers or references 2. Don't have access to a C++11 compliant compiler 3. It's been around for a while
Why there isn't a cross-platform application framework that is simple, lightweight, fast and native? I guess is because is pretty hard to get such an abstraction over all this park of OSes at native level. As was pointed out library in current form is pretty compact and is a Windows-only OOP library based on WinAPI and relying on C++11. Bloating the code just to make another cross-platform library doesn't really make sense, is better to have a polished single platform library that a mediocre cross-platform one. If is need cross-platform then better to use a library that have a lot of support and is mature like Qt. Anyway as the library is open source I think those that will want it to be on their platform might just try to adapt it, ehm... once there will be no ATL dependency.
You are basically asking the compiler to do flow analysis and if it can prove that a copy isn't needed to use a move instead? I'm not sure I'd be happy with a compiler that may or may not optimize a copy into a move depending on how good the optimizer was for a particular piece of code. The performance implications can be huge. The current rules make it fairly simple to know what the compiler will do and to manually state you want a move if it's not one of those circumstances.
Everything that has a name should be an lvalue. So something&amp;&amp; x is also an lvalue to the compiler, to make it an rvalue (temporary) you'll need to apply std::move(x), which will apply a rvalue-cast. And Compiler + Optimizer are already very smart to issue moves where they can...
If you really want to learn C++ then the start point will be [The C++ Programming Language (4th Edition)](http://www.stroustrup.com/4th.html). At the same time read about some coding styles, I use [these](https://cfx.svn.codeplex.com/svn/All-In-One%20Code%20Framework%20Coding%20Standards.docx). About the above code: just by looking at it is clear that it will not compile. If you want to write in a more natural oriented language then C++ is not the right choice, it is very complex and even with C++11 is need a low level understanding of what you are doing, you'll better try something like [python](http://learnpythonthehardway.org/book/) to begin with.
Thanks, that was very helpful. I didn't know that there was a forum for this.
Dear God that is horrible. I'm surprised that the font rendering on Chrome is so bad.
you are a dingus
Herp derp how do I programming
NEED MOAR CODEZ NAO PL0X
Saying `std::move(x)` is how you promise to the compiler that you're done with `x` and that you don't care about its value, and that it can be treated like a temporary. Temporaries don't have names, which means it's impossible to refer to them again later, but lvalues do, and the compiler needs to know whether you're going to need `x` later. Like jbb555 said, you don't want to make the compiler have to infer whether `x` is going to be used again later. That would be incredibly difficult and error-prone, especially considering that it's actually perfectly legal to use the dead carcass of a moved variable -- the standard requires that it must be in a valid state after the move, although it's likely to contain no useful data. In the example it's trivial to prove that `x` isn't needed later, but that's of no real comfort because it's not always so clear. Even if the standard allowed the freedom for compilers to guess in trivial cases, you'd still end up having to write `std::move(x)` because that's still an optional optimization that isn't guaranteed to happen, so you'd want to be explicit and gain the optimization in every case under every compiler. 
Thanks for linking the books, I'll make sure to look them up. I knew it wasn't going to compile because after reading and looking up the different things that I could do for the code, I took my best shot at it. Anyone can tell it wasn't going to. I'll keep trying at C++ though I'll check out Python after what you told me.
Yup - I am asking it to do flow analysis. The compiler should be good enough that I never need to explicitly do std::move unless I've identified a bottleneck the compiler has failed to optimize (in which case I'd file a bug report against the compiler for a missed optimization). I'd flip it around and say that with respect to move the compilers are still so immature that they follow the rules exactly. For example, given a piece of code, it's almost impossible to tell what optimizations are applied (e.g. variables are often omitted wholesale).
I'm not saying that you shouldn't be allowed std::move. I'm proposing that compilers should be smart enough that in 90% of cases you're OK never needing a move &amp; relying on the compiler to do it for you. The problem with std::move is that it's no different than static_cast&lt;T&amp;&amp;&gt;() &amp; AFAIK casts tend to be problematic &amp; indicate you somehow don't have the correct type somewhere (i.e. code smell). Additionally, I'd rather rely on the compiler auto-generating moves for me than relying on me making sure manually that the std::move() annotation I made doesn't result in me then trying to use the object later.
Wouldn't **std::copy from cin to cout** be more idiomatic?
Casts aren't automatically evil, they have plenty of valid and necessary uses. They do deserve extra scrutiny, because they can allow dangerous things to happen which can lead to errors. But so can `std::move()` -- it's explicitly saying "I'm giving permission for this variable to be wiped away and cannibalized, as I won't need it later." That's something that if used indiscriminately could certainly lead to problems, just like a cast. And having the compiler automatically add an implicit `std::move()` is not an optimization that the compiler is allowed to do, because it breaks the "as if" rule, changing the observable behavior of the program. You would need special dispensation from the standard to be able to do that, such as the case with copy elision during copy-initialization and for return values. The compiler is not being "immature", it's flat out forbidden from doing this. 
Thrift and protobuf (and cap'n'proto) are *messaging*, not *serialization*, so we can elevate the debate on whether to use messaging or serialization. In general, serialization is about restoring the exact same state: there is no translation (direct-mapping) and it can even be automated provided you have reflection in the language. Things get blurry when you start versioning the archives you create with serialization code since suddenly you get a less direct mapping between the code and the archive format (missing fields, fields moved from one object to another, etc...). So, when to use serialization over messaging ? 1. When direct-mapping works: less code to write 2. When efficiency is a premium (messaging introduces an intermediary in general, except maybe Cap'n'Proto) 
Yep, that works. You need to wrap the streams in stream_iterators, though. #include &lt;iostream&gt; #include &lt;iterator&gt; #include &lt;algorithm&gt; void stream_centipede(std::istream&amp; in, std::ostream&amp; out) { std::copy(std::istream_iterator&lt;char&gt;(in), std::istream_iterator&lt;char&gt;(), std::ostream_iterator&lt;char&gt;(out)); } int main() { stream_centipede(std::cin, std::cout); } 
&gt; I'm not sure I'd be happy with a compiler that may or may not optimize Isn't this already the case for (N)RVO? Depending on which compiler you use (N)RVO might or might not be applied.
I'm not sure I see the problem. Maybe you can point it out. First of all, moving a lock doesn't unlock it in the STL. In fact, unique_lock is move-only so I'm going to assume that lock &amp; cond_var in this example is some arbitrary third-party code. Let's take a look at how this would work: The possible signatures for wait are wait(lock &amp;l), wait(lock l) or wait(lock &amp;&amp;l). If it's wait(lock &amp;l) then we have no problem as promoting l to &amp;&amp; in this usage would result in a compilation error. If it's wait(lock l), then we still don't have a problem since moving a lock shouldn't change the state of the lock. In fact, let's say a copy was possible due to lock being a recursive lock; the only thing that happens is that an additional recursive lock is elided since it's unnecessary. If it's wait(lock &amp;&amp;l) we have no problem since the above code would have resulted in a compile error to begin with. If there's some combination of those as overloads, then yes the program changes behaviour but only because copies are automatically elided into moves the same way that NVRO elides copies for you.
Yup. (N)VRO is explicitly called out in the standard as a possible optimization since as someone else pointed out the as-if rule isn't sufficient (the user can easily write a program to detect (N)VRO &amp; this optimization). I think my original hope that this could be a pure compiler optimization was overly optimistic. This would require clarifying language in the standard. I'm still hoping someone can point out a case where this optimization would break otherwise-valid code.
No. Since condition_variable::wait(std::unique_lock&lt;std::mutex&gt;&amp; lock) takes its parameter by lvalue reference, moving into it is not even legal. OP suggested this optimization only for parameters taken by value.
Works great until you have whitespace coming from std::cin. Add: std::cin &gt;&gt; std::noskipws;
 01: // skyscanner_sdk_jni.cpp ... 08: #ifdef __cplusplus 09: extern "C" { 10: #endif \#ifdef __cplusplus in a cpp file is a pretty unexpected construct ;)
You're right; `lock` was a bad name. Let's call it `shared_lock` instead, and say it's a custom reference-counted lock. So the signature is then `wait(shared_lock l2)`. What happens now is: 1. `l` is created, locking the mutex and setting the refcount to 1. 2. `l` is copied into `l2`, bumping the refcount to 2 3. `wait` returns, destroying `l2` and decreasing the refcount to 1 4. We pop a value off the stack and return 5. `l` is destroyed, decreasing the refcount to 0 and unlocking the mutex. Under your rules, this happens instead: 1. `l` is created, locking the mutex and setting the refcount to 1. 2. `l` is moved into `l2`, leaving the refcount as 1 3. `wait` returns, destroying `l2` and decreasing the refcount to 0, which unlocks the mutex 4. We pop a value off the stack and return 5. `l` is destroyed, doing nothing This is valid C++98 code, which worked before move semantics, and works with the current move semantics, but breaks with your more eager move semantics (and does so silently).
&gt; Ultimately, this pattern is about expressing behavior in a user-friendly, high-level format. This is pretty much the whole goal of TCL and such like, right? With plenty of good embeddable interpreters and various efficient data structure serialization formats, I'm having difficulty imagining a case where it really would be a good idea to implement a custom byte code interpreter. Am I missing something?
That's a different thing, regarding newline handling.
Yeah. That's a very good point. The lifetime of the lvalue is shortened by this eager move which can result in a lot of messy situations. Great. This is exactly the counter-argument I was looking for.
sad there's not a widespread alternative that does what streams does in a sane way. What I mean by that is that it's extremely useful to write unit tests that write to and read from a stringstream to test serialization instead of requiring a file to read/write (for example). I actually did cook up some lightweight classes to provide more c style operations to several types without multiple inheritance stuffs. I got really tired of iostreams attaching a locale to every binary stream (file or buffer) forcing a mutex hit every time.
Not that I can find. Great article, but it reeks of wheel reinvention. As soon as I saw an AST appear I got a bit apprehensive...
http://yosefk.com/c++fqa/ That is probably a decent starting point.
Because Python 3 has shown how successful throwing away compatibility can be for adoption of new versions of a language.
Maybe there's a setting I can tweak or something.
Thanks for the link. Reading further, I discovered this is one section of a 95% completed book that is available online: http://gameprogrammingpatterns.com/index.html Which is about architectural patterns found in game code, written by EA Tiburon lead programmer Bob Nystrom. I also cross-posted the link to /r/TheMakingOfGames.
It looks like someone doesn't understand how that works and is just copying those three lines as a magic "prevent name mangling" voodoo incantation they read somewhere. Oh yeah, and... 01: # buildToolchain.sh 02: 03: #!/bin/sh ...doesn't understand how the shell works either. 
It seems to me that the extra comment in "line 1" is, in fact, added just for the article to make it clear what the file is. Perhaps not the best way to do it, but I've seen it before.
I *really* hope a file named `skyscanner_sdk_jni.cpp` is not a header file.
Hold on, though- in this case, the compiler wouldn't make that optimization. There's an invisible destructor call at the end of the block that can't be reordered with stack.pop(). In your original example, the call (presumably) happened at the end of the function, meaning that an rvalue promotion was allowed to occur because all the side effects (destructor call ordering) are the same. I actually came up with what I think is a fairly good rule of thumb definition of an rvalue reference, to help reason about control flow like this: an rvalue reference is a reference to an object that will be destroyed as soon as this scope exits. 
As you said, it's the style of error inherited from c and it's really cumbersome and error prone. In the same time, error will not always be catchable, for instance new call abort when an error occur if no exceptions are used. I have the same kind of thing at work, our CTO is an old c hacker guy which doesn't understand anything and don't want to hear a thing about modern programming end even less about modern c++. Things kinda work but our technical debt is huge and they spend a lot of time fixing over and over the same problems. If you want to program in c++ you have to take the whole package to make things works, for instance you can't use exceptions without value semantic. BTW, is the entire code looking like C, does they have other rule like the out parameter and error code return ? The only escape I found is to work on new project where he is didn't involved, on these projects things run far better for my team. Hope you will find an escape, it's really frustrating to work in these conditions.
I think it depends on the situation. The argument for exceptions tend to be return codes tend to be ignored and are easily and silently done so. But, they have their place. I'd return codes should preferred when there is a high probability of expected failure. i.e. parsing user input. Exceptions should be for exceptional cases (i.e. not common), or for cases where you know that the only place it can be effectively handled is 10 levels up the call stack (and you know the code in between is exception-safe). Additionally, writing truly exception-safe code is surprisingly difficult (see http://herbsutter.com/gotw/_102/). RAII only gets you so far (but is a great start - don't get me wrong). One thing I would absolutely advise against is mixing return codes with values unless there is an absolutely clear means to differentiate between success and failure. (i.e. you're doing a lookup into some data structure, that returns a pointer where null indicates failure and non-null returns the result). An example of a bad interface that does this would be the C stdlib function "atoi". It is impossible to differentiate success from failure with "atoi".
When a completely befuddling bug crops up that started 5 layers deep in the call stack or even as a result of some result computed in another thread that has long since completed, you'll realize there's no such thing as "excessive error checking". Coding defensively, while it seems like you wasted 20 minutes now, will save you _hours_, if not days or weeks in the future. Future you will thank present you.
&gt; old c hacker guy which doesn't understand anything Are you sure about that (I'm not ragging in any way regarding the typo btw)? 
In my experience investing in exception handling produces a lot of return. It was designed to reduce error handling clutter and it achieves precisely that. You don't need to alter function signatures to multiplex error returns, and it forces you to handle errors all in the same way and in very specific locations. Just studying what errors are fatal (most) and letting the compiler route them to the handler do charms in code clarity. If your process is multithreaded you need at least a handler per thread. You can have (I think) RAII ctors/dtors that throw, as long as your RAII scopes are exception safe.
About "modern" programming idiom, sure, I will not say the guy is a total idiot but he hate the change and love to reinvent broken wheel. C is not a trademarks of quality by default.
Well, I can't say I don't know a guy who sounds very similar. He's probably about 50, and he's still opening up Notepad++ to write C, and everything is garbage spaghetti code that violates the "Don't Repeat Yourself" rule about once every 10 lines of code. I just don't understand people who learn something, one way, once, 20 years previous, and decide to stick with it until they die. It's like learning to add and when it comes time to multiply, they decide to just add to stick with repeated addition.
Slightly unrelated to your question, but I wanted to say that great error *handling* should be a much higher priority than great error *recovery*. By this, I mean that you should focus on code that *throws* errors rather than on code that *catches* errors. Here's a quote about Unix that I like: &gt; I remarked to Dennis that easily half the code I was writing in Multics was error recovery code. He said, "We left all that stuff out. If there's an error, we have this routine called panic, and when it is called, the machine crashes, and you holler down the hall, 'Hey, reboot it.'"
Yes but it's complicated with error codes to return the full information through all the layers. Exceptions are far better in that domain. Obviously exceptions are for exceptional errors and should not be used when an error is expected.
[Part 1](http://www.skyscanner.net/blogs/developing-mobile-cross-platform-library-part-1-exploring)
I remember reading somewhere that the guidance systems for some fighter jet were written in a very constricted subset of C++ that did not allow exceptions. They (the committee included Stroustup) felt they needed to do that in order to keep the system real-time. That's about a hard a real-time requirement as you can get, and knowing EXACTLY how long a given chunk of code will take to evaluate (in the "I can prove this mathematically" sense of knowing) is pretty important. If your new company is doing stuff for real-time systems, they might have a totally valid reason to avoid using exceptions. But it's more likely that you're seeing "C with the class keyword and some other stuff" instead of C++.
Sounds similar, we to have a large technical debt, though I doubt it's due to just wrote handling. &gt;If you want to program in c++ you have to take the whole package to make things works, for instance you can't use exceptions without value semantic. Thus is what made me start thinking that style wasn't ideal in c++. With this style you can't use the auto keyword. And why add it off it wasn't supposed to be used? &gt;BTW, is the entire code looking like C, does they have other rule like the out parameter and error code return ? Out parameters and return a Boolean for a success state. No actual codes. &gt;The only escape I found is to work on new project where he is didn't involved, on these projects things run far better for my team. &gt;Hope you will find an escape, it's really frustrating to work in these conditions. I actually enjoy working there a lot and not all of the code is this way. But still if rather work with cumbersome c++ code than modern VB.net code like my old job. 
No real time work like that needed, I work on machine simulations. But I knew a guy who was an embedded systems real time veteran. I don't think he was against exceptions but knew the disadvantages when it came to real time. 
&gt; Use `static_assert` when you can to catch problems at compile-time. It's especially useful in templates, since problems with those are both known at compile time and not known at the time of writing the function.
Good recollection, [F-35 Joint Strike Fighter coding guidelines [Word file]](http://www.jsf.mil/downloads/documents/JSF_AV_C++_Coding_Standards_Rev_C.doc), page 59, Rule 208: &gt; C++ exceptions shall not be used (i.e. throw, catch and try shall not be used.) &gt; **Rationale**: Tool support is not adequate at this time. This document was dated December 2005 - they might choose differently today. 
You left off "by default." Those projects are reliable because they are written by large teams of competent programmers. They aren't reliable automatically because they're written in C. There's plenty of utter crap C code floating around. 
Current undergrad assigned to create a meta-language using C. Can confirm that most of my code is utter crap.
I literally just saw the original article yesterday. It focused on the author's love-hate relationship with Java, so I find it interesting it'd get twisted into this.
&gt; C with the class keyword and some other stuff Why do people rag on this so much? It's a very comfortable environment to program in. Throwing in some C stuff here and there makes the code feel more homely, while using strict C++ can feel like getting into a space suit to do a little gardening. And why not go crazy, especially on your own projects? For instance, I love the core of C++, but there isn't enough syntactic sugar, and using std::something::something_else&lt;whatever&gt; makes code look fucking disgusting, almost as bad as objective-C. I spend all day looking at code; it does have aesthetic value. I enjoy the artificial cleanness of C#. So when I design C++ classes, I make sure that, when used, they will look as much like C# as possible. Minimize the '-&gt;' and maximize the '.' etc. I call it C+#. :) Is it bad style? Maybe. But the code is clean and pretty, which makes it easier to read and see bugs. But this is personal projects, obviously.
I've been involved with an effort to build domain specific scripting language for an audience which includes targets a wide range of people (some with exposure to C#, others who could struggled with the concept of variables). The target environment had hard performance constraints (measured in milliseconds) and memory constraints (ideally would thousands of mini programs in a few megs of memory). Strong typing and static error detection were crucial It was designed to constrain people to a narrow subset of a full languages functionality. After evaluating options, we ended up building a system which generated Lua (and automated the binding generation with C++). The users wrote in a custom language with a syntax inspired by C# but with extremely narrow functionality. We hand rolled a recursive descent compiler which translated the proprietary language in to Lua (which will likely be rewritten at some point in about 1/8th as much code using ANTLR as a translator). Crazy as it may sound, it worked extremely well. The indirection allows us to explore other languages for the runtime, consider a native implementation via LLVM, etc. Users have a early error detection and limited scope of functionality they wanted. A custom editor supported autocomplete, edit time error highlighting, etc. The limited syntax meets their needs (and can slowly be widened as people become more advanced). The runtime is proven as it runs as Lua under the hood. I'd estimate about 2 man years spent on the development (concept through implementation, spread across 4 engineers for all facets of the system). Clients of the language have probably put about 60 man-years in to using it. I'm sure there are off the shelf solutions we could have found but after evaluating a bunch of options, this met our needs, the productivity of the users was worth it and we have plenty of ability to expand in the future.
I will note that one headache is still the garbage collection. Ideally we'd run it incrementally, with a budget of 0.1 ms (~33 times a second). Unfortunately that doesn't seem to be sufficient given how we're using it, resulting in some special case long runs in time slices where other systems run short. It would be awesome if there were a solution out there which did not require garbage collection but I doubt that would exists which meet the other requirements.
Reference counting based garbage collection systems such as in Squirrel solve the pausing GC problem to my understanding.
You only need `std::remove_reference` if there's a chance that `f()` returns `T &amp;`. That's because `decltype` preserves the return type of the call-expression. If the function call is going to return a reference, then that's what `decltype` evaluates to. That's important to be able to write code that does forwarding/wrapping. You don't want to lose that information, otherwise it's difficult or impossible to write generic code that preserves the return type of the function being wrapped. For a motivating example, and justification of the chosen design, see &amp;sect;4.1 of [N1607](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1607.pdf). 
Yeah, I find it stupid too. With this new standard I am forced to use this decltype stuff everywhere, literally everywhere. I was expecting to write more compact code with this new standard, but instead of it I now need to write vector&lt;remove_reference&lt;decltype(f(c[0]))&gt;::type&gt; v; every time to make a vector of values.
There's a lot of C++ crap too. I suppose many of us were unfortunate to experience it first hand, so can relate. I don't understand the approach where you ignore good code "by default" and focus on bad stuff when forming opinions on a programming language. The only reasonable way for me is the opposite: to look at the work of the best programmers and see how the language served them. For me it's an obvious and easily observable fact that many great programmers do choose plain C over C++. This means the language has qualities that appeal to educated, experienced folk and that's why I refuse to accept OP's blanket statement that "C is a trademark of low quality". I agree that C++ is better, but my blood boils when people put such a great language as C in the same hall of shame as PHP or Javascript.
Doesn't have anything to do with the C++ language.
Yep, assertions for pre conditions (I usually wrap assert in a further MACRO so I can print/log messages) and exceptions for post. "invalid argument" exceptions are a code smell of the highest order. (perhaps with the exception of some library code).
That is where assertions come in. Make sure all your data is correct at each step and layer saves so much time. 
The first step in fixing a problem is knowing you have a problem
Or install Qt SDK and you will have qt creator + MinGW after a few "next" clicks.
`remove_reference` still doesn't remove const. You can do this: std::vector&lt;std::decay_t&lt;decltype(f(c[0]))&gt;&gt; v; But I strongly recommend this: using value_type = std::decay_t&lt;decltype(f(c[0]))&gt;; std::vector&lt;value_type&gt; v; But I totally agree with /u/Rhomboid that it is extremely important that decltype returns the real type, since we can easily remove cv-qualifiers in usercode, but it would be impossible to find out what they are, if we only got the decayed type.
&gt; Rule: Don't return an error code unless that's an expected, non-exceptional situation. Just throw instead, and return void or some non-error-type. If you throw then you don't need to return anything as the code never takes that path. Or am I missing something? &gt; Rule: Use RAII if you use exceptions. They're much easier than manual coding too. I would say **always** use RAII regardless of how you handle error. That it's ideal for exception safety is only one of it's advantages.
There are plenty of shops that have fairly modern, sophisticated C++ code bases that do not use exceptions. 
&gt; and it forces you to handle errors all in the same way and in very specific locations. ... wut? It does nothing of the sort. &gt; Just studying what errors are fatal (most) and letting the compiler route them to the handler do charms in code clarity. Compiler? 
&gt; With this style you can't use the auto keyword. And why add it off it wasn't supposed to be used? Do you know how many features of C++ this could be said about? There's plenty of badness in C++ to avoid. 
I think the point is, language features are no panacea for lousy engineering... that includes use of exceptions, RAII, etc. There seems to be a common refrain that if someone eschews the use of something new, it's because they like their crufty old way of doing things. Often, it's the case that a wizened old veteran might avoid some of these things because s/he's used them before, and knows they might solve one set of problems that is being myopically focused on, but introduces a raft of other new problems that are just as bad, if not worse.
The problem is not enough time haha. We have a month to write this meta language in 5 languages we're unfamiliar with. C, python, ml, prolog, and post script. Fun stuff haha
The new world of Java and Python programmers is absolutely littered with these types of programmers. 
Saying "C is not a trademark of quality" is not logically the same as "C is a trademark of low quality." The comment you're talking about said the former and not necessarily the latter.
To me, its begs the question, When should yo and should you not check for errors? To some degree I like the stance of "crap in, crap out" and I feel it's more in line with the do one thing and do it well approach.
Thanks for that link, I never really thought about righting exception safe code and it certainly pointed out some areas I never thought of.
I really like how you put this, and solidifies what I was thinking. That rather than returning and error code assume the routine is being called correctly, and provide the methods for the user to check. Thus there are find functions and get functions, where returning an error combines the find and the gets. 
While more people indeed can do more work if organized correctly, I still think that its not going to speed up the process. But it will help to keep up with rising workloads as the standardization gets broader. As you're an STL Maintainer: What impact do you expect concepts to have on the standard library? How much work will it be to make the implementations also support concepts?
It feels to me like to do stuff like RAII right, you kinda need exceptions. I guess it depends how you define "fairly modern, sophisticated C++ code".
They might indeed! It's also possible that the F-35 project is not exactly an example to follow ;) But I could still potentially see there being some argument against using exceptions in systems that need to have extremely well defined behaviors. I'm thinking about how the JPL C standard required loops to have hard limits on the number of iterations. I would hope that code analysis tools would be up to the task of analyzing exception behavior these days, but I could see very conservative shops still making the case against using them. I don't think any of those concerns affect people outside of the realtime or embedded worlds.
It isn't just an issue of coding style. It's very possible to make very readable code with C++. typedef std::something::something_else&lt;some_other_thing&lt;wat&gt; &gt; readable_type; means you can replace all that malarky with "readable_type". The "using" keyword can also help out. And with C++11 we get things like the "auto" keyword that free you from that too! I don't understand at all why you think "-&gt;" is less readable than "."
* agent.m_ptr is being casted to an unsigned long* * agent.m_ptr's value is being accessed by the deference operator * * shift is storing the value (that just got dereferenced) 
A type with `**` in it is a pointer to a pointer. If you dereference it, you get a pointer, which you can then dereference again to get a value. In your example with `unsigned long shift = *(unsigned long*)agent.m_ptr;`, what that does is say "set `shift` to the value you get if you interpret the bits pointed to by `agent.m_ptr` as an unsigned long". The `(unsigned long*)` part means "interpret `agent.m_ptr` as a pointer to an `unsigned long`", and the leading `*` dereferences the result of the cast.
Hi Jason, casting in (void **) enables you to make a double indirection ** on an address, typically its allows you to access a memory space pointed by a pointer itself pointed by the pointer on which you do the double indirection (you could also do a simple indirection instead of a double, but you would only access the second pointer). In your case, "*(float) address" just means that you perform an indirection of size sizeof(float) on address. What is an indirection ? It's an access to the memory space located at the given address. Hope this help !
The value that a pointer holds is a memory address (of some memory presumably in a different location than the pointer itself). That value is intrinsically an integer, but since the more common use case is using the object it points to, you have to do a bit of hackery to interpret that value as its integer value. ... Though I'm not sure if that explanation really made it any clearer, even to me.
In the olden days (AKA pre-2000) it was... perhaps not "common", but "less unusual" to cast function pointers to integers and data to `void*` as a way to pass them around in a signature agnostic way. Intermediaries didn't need to know that some number was actually a `void(float*, char*, ...)` function or an array of strings, only the caller on the far end of the transaction did. That's the main reason I've seen it done, though there are doubtlessly other applications.
That's some ugly code you have there. unsigned long shift = *(unsigned long*)agent.m_ptr; Pretend that agent.m_ptr is a pointer to some number, instead of a number itself. Then take whatever it is pointing to and assign that to shift. shift = *(unsigned long*)(shift + 0x30); Add 48 to that number, pretend again that the result of that is a pointer to a number and then read that number, and store that in shift. shift = *(unsigned long*)(shift + 0x28); shift = *(unsigned long*)(shift + 0x178); Same thing, but with different offsets. Remember that it is every time updating "shift". float cHealth = *(float*)(shift + 0x8); This says "Add 8 to shift, and then pretend that this number is the address of some float. Then give me that float, and call that cHealth." It looks like there are some structures of data that you are reading, where you don't have the actual structure. Are you reading code for some kind of game "trainer" or cheat?
 &gt;Obviously exceptions are for exceptional errors and should not be used when an error is expected. Well. I'm using exceptions to signal parsing errors in deeply nested data, because the alternative would be unreadable. `throw this_happened( context() )` followed by a catch where appropriate seems to me more reasonable than providing error-code error handling. This way, the programmer neither has to provide a plethora of output parameters, which is especially relevant when they can't deal with them anyway and just has to use them to be able to move the error up through the call stack, nor unwrap every single return value because it may be an error (if f.e. Maybe&lt;int, errorstruct&gt; were used). At the point where the error happens that doesn't make a difference, I can write `return Maybe&lt;int, error&gt;( errorstruct( reason, context ))` just as easily, but it makes the life of everyone *using* the thing easier.
Can you explain what the smell is with "invalid argument"? Supposing a function were passed an invalid argument I would consider it a logic error (by the caller, and hence out of my control). Consequently, an exception may be appropriate. EDIT: For example, consider the square root of a string function, where sqrt("ABAB") =="AB" and sqrt("ABC") is undefined. In the latter case, I think invalid_argument is fine. Returning "" doesn't make much sense since it is a valid return value.
I'm sorry I still don't understand. If you `throw` in a function (and don't `catch` in that function) then the function never returns anything, regardless of it's signature.
Yes, and I'm saying that you don't make the function signature *look* like it would return an error code either. Don't make the function confusing. Give it one way to indicate failure.
&gt; This is pretty much the whole goal of TCL and such like, right? With plenty of good embeddable interpreters and various efficient data structure serialization formats, I'm having difficulty imagining a case where it really would be a good idea to implement a custom byte code interpreter. Am I missing something? Not if you need a general purpose language. However, if you need something more restricted, you do. In many situations you don't want turing completeness, or the features you need are completely lacking from, e.g. lua, because they're to bizarre. This kind of thing isn't so uncommon in game development, and is often tangential to any embedded scripting language. The example he gave, with the magic spells and whatnot, is reasonably representative of the situation where you don't want turing completeness. For example, we have an embedded VM in the game engine I use at my current workplace, it's used to describe lookup tables for object states. The basic idea was so that we can declarative say things like `highScoreList = sortAscending('score', userList)` (this is a simplified and trivial example) and have it automatically be updated on changes without polling. This is not a feature you could get in any off the shelf interpreters or VMs.
Ah ok, that makes perfect sense now. Sorry for the confusion.
It's a strange personal preference. I was stuck with C# doing CRUD work for so long, and it became ingrained in my brain that obj.SomeMethod() is prettier than obj-&gt;some_method(). I can see the value of both, but it's just what I got used to, just an aesthetics thing.
Why was there this large gap between '03 and '11 in the first place? And why is interest rising again? Did something fundamentally change?
Maybe Moore's law coming to an end (the Mhz part at least and power usage became an important consideration). http://www.gotw.ca/publications/concurrency-ddj.htm Were any C++ specific factors also involved? 
It's not a `Maybe` if there are two types, but an `Either` (in which case in Haskell the order is reversed, because the non-error is the RIGHT result...). If you always use the `error` type though, you might easily create a `Result` class.
Because if you have code which calls functions with arguments it can't handle then your program is fundamentally broke. It should be asserted. your strsqrt function is a bit abstract but perhaps a better solution would be a functor. auto f=strsqrt("ABAB"); if (f) f.get(); or whatever you want. The point is, if your function is DESIGNED to evaluate the input then I would hardly call that exceptional thus would be an abuse of the exception system.
Raymond Chen wrote an interesting post about the differences between error codes and exceptions for his own programming: http://blogs.msdn.com/b/oldnewthing/archive/2005/01/14/352949.aspx He basically concludes that exceptions are ok but he's not smart enough to use them and understand what his code will do. I tend to use them still but I always think back to this article when seeing error codes and think how they really do make sense sometimes (and not just to be old school C style code).
&gt;It's not a `Maybe` if there are two types, but an `Either` (in which case in Haskell the order is reversed, because the non-error is the RIGHT result...). Of course, thanks. I was fairly tired when I wrote that post. But it's still very explicit and necessitates writing boilerplate code in contexts where no error handling can happen anyway. I still think that "exceptions are for exceptional errors" isn't really a good guideline. 
I think it's a combination of things. Microsoft was focusing on Java and later .NET, and it was expected that any performance problems (for some applications) with VM languages become nil when the processors become really powerful. That did not happen, so now (especially for the mobile platform where power usage matters) they are again interested in C++. Also, for the longest time it was OK for compilers to not support the language completely. I think this is due to the fact that there was 10+ years between the inception and first standardization of C++. Now this changed. Then with Apple endorsement, the LLVM project rose and created a C++ compiler that ended the status quo. Both GNU and MS stepped up their game in supporting C++. Which is great.
[I'll just leave this here.](http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml#Exceptions) 
I'm excited!
&gt; The following headers are for concurrency features and are not supported in the Oracle Solaris Studio 12.4 release: &lt;array&gt; &lt;atomic&gt; &lt;future&gt; &lt;thread&gt; &lt;mutex&gt; &gt; The following headers do not yet compile with the C++ compiler in this Beta release. &lt;bitset&gt; &lt;chrono&gt; &lt;codecvt&gt; &lt;complex&gt; &lt;condition_variable&gt; &lt;regex&gt; that's going to take some time..
Someone has to make MSVC look 'acceptable'.
It's great to see companies adopting the new features provided.
The only scenario that might be possible is if you're returning an lvalue from a function where (N)VRO would not otherwise be possible so a move return would be automatic. For example: void foo(string s) { bar(s); } The compiler cannot promote foo's s to an rvalue precisely due to the reason m42a pointed-out; the lifetime of the contents of s is shortened to where it's promoted to an rvalue as opposed to the end of scope it would normally have. Now that the problem is understood, generating problematic counter-examples is easy: void foo(string s) { // SomeObject stores the pointer to the string SomeObject o(&amp;s); bar(s); // this uses the pointer we stored earlier. o.doSomethingWithStringPointer(); }
Since this document is most of the time brought up as an argument against using exception here some quotes from the text: "On their face, the benefits of using exceptions outweigh the costs, especially in new projects. However, for existing code, the introduction of exceptions has implications on all dependent code." "Given that Google's existing code is not exception-tolerant, the costs of using exceptions are somewhat greater than the costs in a new project. The conversion process would be slow and error-prone." "Because we'd like to use our open-source projects at Google and it's difficult to do so if those projects use exceptions, we need to advise against exceptions in Google open-source projects as well. **Things would probably be different if we had to do it all over again from scratch.**" [emphasis mine]
Very good talk.
I've been waiting for this for a long time. I do a lot of experimental data acquisition. It would sure be nice to be able to loop over variables in a class and save write them into a file format automatically instead of having to specify them. ROOT implements reflection by generating separate files called class dictionaries. Having this built in would solve a LOT of headaches for those who use ROOT.
I think people just automatically goto MSVC because Visual Studio is one of the extremely limited selections of okay-enough C++ IDEs (at least after you rip out all of their boilerplate crap).
Okay, could it mean just make one up?
Agree with the first part, but not sure why you'd assert rather than throw. Assert is a horrible way to end a program. The last bit, however, is tautological: if your function is DESIGNED to handle all arguments, then throwing invalid_argument is bad. Well, ok sure. I'll be sure to not throw invalid_argument from functions that don't need to. EDIT: I guess, on reflection, it fits the smell test. I just don't see it being a frequent problem.
whats the difference with algorithm and pseudo code?
If you read down the comments on the Hacker News coverage of Warp, you'll find DannyBee demonstrating that Clang's preprocessor is 40% faster than Warp. Seems like much ado about nothing. https://news.ycombinator.com/item?id=7488994
throws only terminate on debug builds, that's the whole point. Termination is brilliant in debug builds because I can then just go and attach my debugger and back trace from the point at which it happened, view all of the local vars and so on. Throwing an exception is far worse, I have to handler that where it's caught and pass any information to the exception about the site from where it was thrown.
Don't know what debugger you're using, but GDB at least will break on throw. It provides the exact same information as you would get using an assert. And the throw is much cleaner if you're using RAII. And it's preferable in multi-threading.
its just another sales pitch for 'd' actually.
A `to_string` function is so useful, it's [part of C++11](http://en.cppreference.com/w/cpp/string/basic_string/to_string). Not a 'universal' one, but the type specific ones there are probably more efficient than going via an ostringstream.
This is easier, but giving your exceptions unique IDs at every call site is better, especially if you have some automated process to do so. That way, as the code changes, bugs that reference exceptions (or asserts) by unique ID are still meaningful. With the approach in this link, every time you add or remove a line from the source, such bug reports become harder and harder to figure out.
It's not just companies, the program I'm attending at university is teaching current C++11, the coming C++14 standard and also giving info on the future C++17 (?) standard at the basic course in programming (the first course in programming) on the first semester.
I'm not completely convinced by your arguments, but would adding a compile-time hash of some part of the message solve the unique-ID problem? 
What's not convincing? Seems pretty matter-of-fact to me. If you just have the line number in a bug report, finding your way back to the code isn't always easy, and sometimes it will be impossible. As for hashing the message: if your exception message is already always unique, you don't need a unique ID on top of it. You can just grep your code for the message to find the exception. But I don't know any projects where all exception messages are the same.
What platforms are you targeting that you'd need both Clang and GCC?
I would need a more clear explanation f your workflow to understand why the combination file:line_number (along with the function name) isn't sufficient to find your way back. Note that I assume that a bug report indicate the software version at least. Given my own workflow, it seems pretty matter-of-fact to me that I would be far more rapidly at the bug point by typing ":e file.cpp113G" than by having to grep the error message ("ag &lt;select&gt;&lt;middle-click&gt;:e file.cpp113G"). Anyway, apart from my difficulty to understand your point clearly, I find the idea interesting. And having an ID seems better than using the message, since it may contains variables in it (which is one of the reason I designed the RAISE macro in the linked project). Maybe we should also consider printing the version number somewhere too. And the computation of a hash at compile-time seems a cool thing to learn :-)
&gt; such bug reports become harder and harder to figure out Exceptions really should not be used to report bugs, **especially** in C++, where bugs more often end up in an UB, and that means no exception handling in the world saves us.
&gt; The odds of my investigating a bug report that was filed against the exact same version of a file I have checked-out on my machine is extremely low, less than 10%. But that is your original sin. When you investigate a bug report, you do so looking at the exact sources that produced it. How hard can it be? The bug is coming from a particular build of the software. That's easily identifiable (well, it really should be). And from there, sources are easy to find (well, they really should be).
This doesn't give more than exception type and the text. Only those two just isn't enough. File and line are OK IMO.
&gt; Do not try to handle exceptions unless you can handle them Actually, most of the time, it's "Do not try to handle exceptions unless you **have to** handle them". And then, most often there's no handling, just reporting. :-) As for RAII, it's absolutely **always**, anything else is substandard.
The only missing thing is the backtrace :) It's unfortunate than obtaining it is platform-dependent and that its output may change with optimizations levels (because of inlining) however it is really handy. Another really interesting feature is to use "RAII-style" notes: instead of catching the exception and add a note "Unwound through here and this variable had the value X", you can use an RAII class that will do so for you automatically in its destructor. It limits the number of try/catch whilst helping enriching exceptions as they fly by.
Obviously YMMV, but this benchmark shows `stringstream` edging out `to_string()` ever so slightly: http://zverovich.net/2013/09/07/integer-to-string-conversion-in-cplusplus.html
It's an annoying problem with `ostream` that you hit (did I say I loathed the design of IOStreams already ?), however there is a much simpler fix: lower down the left-hand member to the lowest class available, so that only conversions on the right-hand member come into play. That is: template &lt;typename V&gt; std::string to_string(V const&amp; v) { std::ostringstream oss; std::ostream&amp; os = oss; os &lt;&lt; v; return oss.str(); } And then you will note have any warning on either Clang or gcc.
Post this to /r/cpp_questions, this sub is about C++ discussion
&gt; The odds of my investigating a bug report that was filed against the exact same version of a file I have checked-out on my machine is extremely low, less than 10%. It should be 100%, because you should check out the version it was filed against first, *especially* with a rapidly changing codebase. Why would you try to diagnose a problem by looking at a different version of the code?
Yeah, pretty much.
_Unwind_Backtrace is relatively standard across a lot of platforms.
If I put std::cout &lt;&lt; d &lt;&lt; ", " &lt;&lt; e &lt;&lt; ", " &lt;&lt; q &lt;&lt; ", " &lt;&lt; w &lt;&lt; std::endl; in before line 65: a[d][e]=a[q][w]; I get 1, 1, 32767, -148729432. I guess your q and w is wrong.
The static array: int a[m][n]; cannot have its size determined at runtime as you have written it. Try allocating that on the heap instead of on the stack. Edit: I would also suggest compiling with -Wall -Werror on the command line.
Except Windows. It's also not provided by `unwind-arm.h` of the Android 2.3.3 NDK. And it doesn't have libcorkscrew either. So all I'm left with is the program counter (PC) and previous counter (LR). Yes I spent an entire Thursday trying to get a backtrace on a platform that doesn't implement `_Unwind_Backtrace` and that's all I have to show for it.
&gt; Is it possible to explicitly instantiate this template? Yes. &gt; What effect does the enable if have on explicit insantation? If you're constraining the member function template with `typename enable_if&lt;MyCondition, MyType&gt;::type`, you need to say `MyType` in the explicit instantiation. That's what's produced when `MyCondition` is `true`, regardless of what `MyCondition` is. (`enable_if` defaults to `void` if you don't provide `MyType`.) &gt; What effect does the perfect forwarding have on explicit instantiation? (i.e. do I need to instantiate it for types T &amp;, T const &amp;, ect...) A perfect forwarder taking `(T&amp;&amp; t)` will deduce `T` to be `X&amp;`, `const X&amp;`, `X`, and `const X` for modifiable lvalues, const lvalues, modifiable rvalues, and (unusual but possible) const rvalues of type `X`, respectively. This is caused by the "template argument deduction tweak". Reference collapsing then makes the signature take `(X&amp; t)`, `(const X&amp; t)`, `(X&amp;&amp; t)`, or `(const X&amp;&amp; t)`, respectively. You'll need to spam out all four if you want to handle all possible inputs of type `X`. Similarly, if you take `(Stuff&amp; stuff)`, you have to consider modifiable and const inputs. Example: C:\Temp&gt;type meow.cpp #include &lt;type_traits&gt; #include &lt;utility&gt; using namespace std; // Class definitions (you can put this in a header file) struct Entity { template &lt;typename Attribute, typename = typename enable_if&lt; is_class&lt;typename decay&lt;Attribute&gt;::type&gt;::value &gt;::type&gt; void Set(Attribute&amp;&amp;) { } }; struct X { }; // See: http://isocpp.org/files/papers/N3797.pdf 14.7.2 [temp.explicit] // Explicit instantiation declarations (you can put this in a header file) extern template void Entity::Set&lt;X&amp;, void&gt;(X&amp;); extern template void Entity::Set&lt;const X&amp;, void&gt;(const X&amp;); extern template void Entity::Set&lt;X, void&gt;(X&amp;&amp;); extern template void Entity::Set&lt;const X, void&gt;(const X&amp;&amp;); // Explicit instantiation definitions (you can put this in a source file) template void Entity::Set&lt;X&amp;, void&gt;(X&amp;); template void Entity::Set&lt;const X&amp;, void&gt;(const X&amp;); template void Entity::Set&lt;X, void&gt;(X&amp;&amp;); template void Entity::Set&lt;const X, void&gt;(const X&amp;&amp;); int main() { X x; const X c; Entity e; e.Set(x); e.Set(c); e.Set(move(x)); e.Set(move(c)); } C:\Temp&gt;g++ -std=c++11 -Wall -Wextra meow.cpp -o meow.exe C:\Temp&gt; 
Hi STL! This response really helps. Thank you. I have a follow up: I'm not actually using a typical enable if. My enable if actually looks something like: std::enable_if&lt;Pred&gt;::type* const &amp; = /*some ref*/ I imagine if I pass in the same reference to a void pointer instead of void it will work the same? 
I recommend against doing that. The `enable_if` I demonstrated above is the one I use in production code. Using a non-type template parameter achieves nothing but additional complexity. Still, if you're set on doing this: C:\Temp&gt;type hiss.cpp #include &lt;type_traits&gt; #include &lt;utility&gt; using namespace std; extern const int global = 0; // Class definitions (you can put this in a header file) struct Entity { template &lt;typename Attribute, typename enable_if&lt; is_class&lt;typename decay&lt;Attribute&gt;::type&gt;::value, const int&amp;&gt;::type = global&gt; void Set(Attribute&amp;&amp;) { } }; struct X { }; // See: http://isocpp.org/files/papers/N3797.pdf 14.7.2 [temp.explicit] // Explicit instantiation declarations (you can put this in a header file) extern template void Entity::Set&lt;X&amp;, global&gt;(X&amp;); extern template void Entity::Set&lt;const X&amp;, global&gt;(const X&amp;); extern template void Entity::Set&lt;X, global&gt;(X&amp;&amp;); extern template void Entity::Set&lt;const X, global&gt;(const X&amp;&amp;); // Explicit instantiation definitions (you can put this in a source file) template void Entity::Set&lt;X&amp;, global&gt;(X&amp;); template void Entity::Set&lt;const X&amp;, global&gt;(const X&amp;); template void Entity::Set&lt;X, global&gt;(X&amp;&amp;); template void Entity::Set&lt;const X, global&gt;(const X&amp;&amp;); int main() { X x; const X c; Entity e; e.Set(x); e.Set(c); e.Set(move(x)); e.Set(move(c)); } C:\Temp&gt;g++ -std=c++11 -Wall -Wextra hiss.cpp -o hiss.exe C:\Temp&gt; 
It seems there are other features apart from being faster than GCC's: &gt;**andralex**: I'd be curious to see how clang does, too. What matters to us is that warp is easy to get into so we can easily adapt it to our build system (in particular multithreaded preprocessing that saves on opening same included files multiple times).
Actually detecting bugs is one of the uses for exceptions, as you can see at the `logical_error`-class which is used for things like out-of-bounds-access in arrays and should rarely be caught outside main(). Though I agree that there are many situations in which `std::terminate()` is the best choice.
OSX/iOS is clang by default. Targetting a RHEL clone as well means GCC (unless your company want to custom build, deploy and support clang). Also, clang builds faster but for certain cases GCC still builds a more optimised version.
you should checkout google breakpad for android. Takes some time to setup. It gives c++ backtraces.
If you are a Windows developer: http://blogs.msdn.com/b/vcblog/archive/2013/04/26/nuget-for-c.aspx
I would suggest to always use CMake, as its one of the only plattform independent build systems. CMake is actually not a real build system it generates code for a build system (be it makefiles, visual studio, codeblocks, eclipse,...) In CMake many popular libraries can be easily found with the find_package command. (if they are installed) The sad truth however is that coming from C# you will miss alot of features... There is no plattform independent package/dependency management as far as I can tell. Nuget has started with supporting C++ packages for msbuild/visual studio. If you work with CMake and your dependencies stem from git/svn/hg repositories there is a solution from James Hughes (iauns on github) called cpm, which automatically installs and configures dependencies. Cmake itself also has the external_project module which can download repositories or tarballs and initialize them. I myself am working on a package manager for c++/cmake which is plattform independent and works very similar to npm or nuget (and its package manager console) It can setup all needed dependencies (includes, libraries, reources) and also allows easy publishing of packages. It is however not stable enough to share yet. Maybe in a month. All of the package managers have one major downside: Very little packages are availabe in contrast to npm, nuget, maven, ... (there are even less packages available than apps in the windows store ;) ) Those are my two cents to the matter.
It's C rather than the C++ and from none other than Brian Kernighan unsigned int v; // to count the number of bits set in v unsigned int c; // c accumulates the total bits set in v for (c = 0; v; c++) { v &amp;= v - 1; }
const rvalues? is this real life?
The reason why this works and is much faster than testing the least bit while the value is not zero is that subtraction's inherent carrying allows you to skip large gaps of zeroes. It's apparent when the least set bit after subtraction is always set to zero (along with lesser bits trailing it to be set but that doesn't matter since the original operand's bits remains unaffected by masking)
not that today there are much faster methods to perform popcount and this piece of code should not be used anymore if performance is an issue.
My `concat_string` helper: inline void build_string (std::ostream&amp; o) { } template&lt;class First, class... Rest&gt; inline void build_string (std::ostream&amp; o, const First&amp; value, const Rest&amp;... rest) { o &lt;&lt; value; build_string(o, rest...); } template&lt;class... T&gt; std::string concat_string (const T&amp;... value) { std::ostringstream o; build_string(o, value...); return o.str(); } Use it like: * `std::string date_string = concat_string(year, '-', month, '-', day);` * `unlink(concat_string("/var/tmp/user-", getuid(), ".lock").c_str());` * `throw Error(concat_string("Unable to open ", path, ": ", errno));` It's ~~more efficient than~~ as efficient as using `std::string`'s `operator+` and it supports any type which can be written to a `std::ostream`. It's also a nice example of how to use variadic templates. Edit: see qdii's comment below - in C++11, `std::string::operator+` is more efficient than I was giving it credit for. Another edit: you can also use iostream manipulators with `concat_string`: * `concat_string("Charge USD ", std::fixed, std::setprecision(2), charge_amount / 100.0, " to your credit card?")`
I'd like to post Herb Sutter's favorite snippet that he [presented at Going Native 2013](http://channel9.msdn.com/Events/GoingNative/2013/My-Favorite-Cpp-10-Liner) (with slight editing): std::shared_ptr&lt;widget&gt; get_widget(int id) { static std::map&lt;int, std::weak_ptr&lt;widget&gt;&gt; cache; static std::mutex m; std::lock_guard&lt;std::mutex&gt; hold(m); auto sp = cache[id].lock(); if (!sp) { cache[id] = sp = load_widget(id); } return sp; } The code snippet above is a thread-safe ref-counted object cache. It's interesting because in less than 10 lines of code it expresses a relatively complicated structure. Widgets are held in existence by shared pointers given to those who request them. The cache doesn't participate in ownership, it simply observes the widgets it distributes and is able to determine whether they are alive or dead. C++'s smart pointer types are what make this code snippet so expressive, I think it's pretty cool.
Well I didn't mean to imply that it was the recommended method, just that there are some who don't explicitly use supplementary compatibility such as `popcnt`. (In that chance, portability)
Except that the braces are wrong ^^^I'm ^^^joking ^^^guys, ^^^don´t ^^^kill ^^^me...
They can be generated unintentionally. For example, moving from a map's value_type, because the key is const. Generic programmers need to be prepared for this situation.
What's considered the standard way to do a breadth first tree traversal? In one of my courses my professor's example used a dequeue, but my friend and I were able to do it with two queues.
Note that `cache[id]` is an O(log N) lookup, which the compiler is highly unlikely to optimize away when performed repeatedly. Therefore, this should be written as `auto&amp; wp = cache[id];` followed by referring to `wp` repeatedly. It's easy to miss because `op[]` is cheap and (usually) optimizable for vectors.
Reverse loop iteration: for(size_t i = myVec.size(); i--;) cout &lt;&lt; myVec[i]; It's a tiny bit faster because you only need one register to keep track of the index, rather than two (one for the index and one for the limit). Some compilers have tricky ways to optimize a forward loop which works by identifying invariants in size() and in myVec, but they can't always be inferred in complex loops. And sometimes you just want to go backwards.
Could you develop on how more efficient it is than operator+?
 int main( int argc, const char * argv[] ) { vector&lt;string&gt; args( argv, argv + argc ); if ( std::find( args.begin(), args.end(), "-h" ) != args.end() ) { print_usage(); return 1; } } **EDIT**: as pointed out by /u/Dascandy, std::vector does not have a find member function. Changed to std::find.
But is it not bad design to have a global cache and mutex?
but why would the stream be faster?
I believe i-- takes one more register than --i tho, because what the former expression returns is its value before the decrement operation meaning it needs to store the old value in a register (this goes for increment as well). This is often optimized away but can't be here.
For those of use who haven't yet gotten around to adopt C++11: [Variadic templates](http://www.cplusplus.com/articles/EhvU7k9E/).
.. if you ignore that std::vector doesn't have a find function. Your compiler's vector might, but the standard one doesn't.
What makes you think it is?
Think about concatenating n strings, each of length m. With `operator+` you end up copying O(mn^(2)) characters and you do O(n) allocations. With a buffer that grows by some multiplicative factor you only copy O(nm) characters, and you only do a logarithmic number of allocations.
&gt; Nope. You start at N and go down to 1, while you should've iterated from N-1 to 0. That's wrong. The `i--` happens before the loop body.
well that depends? take this example: string result = string( "some " ) + string( "message" ); if the temporary object `string( "some " )` holds a dynamic buffer which is large enough, then the call to string `operator+( string&amp;&amp;, string &amp;&amp; )` could just append "message" to it, and move-construct the return string. In that case, no memory allocation is done, and there is no compiler trickery involved. On the other hand, the `std::ostringstream` does not just "fill up". It holds a `std::stringbuf` object internally, which dynamic buffer will be resized when characters are appended to it, so memory re-allocation is also performed. That being said, I believe you are right: in practice, there will be a lot more reallocations from `operator+` than `std::ostringstream`.
Hey, thanks for the tip! Google Breakpad gives a *lot* better backtraces than my own botched-together solution. It even saves crashdumps, which is something I've wanted for my app for a long time. :)
Neat, but wouldn't the map retain all those unused weak_ptrs and potentially grow very large?
The generated assembly is something like this: looptop: dec eax jb loopexit ; loop instructions here jmp looptop loopexit: The "dec" instruction will set the overflow flag when the decremented value gets below zero, any good optimizing compiler knows how to optimize a trivial postfix-decrement test-for-zero.
Possibly, because the above loop is also a forward loop. I'd recommend looking at the generated assembly to see. The speed is likely to be quite marginal, though, unless you're doing a whole heck of a lot of math stuff in the loop body.
I learned long ago that looking at the assembly doesn’t help me figure out how well it will perform. My short versions were always slower than the compiler’s longer versions.
What does this do?
Beautiful! 
Unlikely. std::strings can (and are known to) overallocate. Now, it's implementation-defined how much, ostream might have the bigger buffer (hehe!), but that's not guaranteed. *Before C++11,* std::string could even use a rope implementation, only referencing instead of copying sub strings. I've never seen one that does, though, partly because referencing data sucks in multithreaded environments. 
OK, I think I understand you. For instance, instead of one GUI, we would have two GUI, each one using a different `get_widget` function to retrieve a widget from cache. Would it be hard to make such a change? I am not sure, I can see two ways of doing this: 1. you could simply use a different namespace for each function (`gui_one::get_widget` and `gui_two::get_widget`). 2. you could templatize your function template&lt;int GUI&gt; std::shared_ptr&lt;widget&gt; get_widget(int id) { ... } and then call it using helpers: `get_widget_one(int id) { return get_widget&lt;1&gt;( id ) ; }`
Hard to say why that happened in your case, but one of the most common reasons is that compilers will unroll loops and this tends to generate much longer code. Short does not always mean fast, and this is true in pretty much every language. With sufficient knowledge of machine architectures (though it's hardly ever worth it), you can always match or beat the compiler if you roll your own assembly.
This is what I was thinking, but qdii made a good point that C++11 added `std::string::operator+` functions that take rvalue references, so with that in mind I think they'll have equivalent efficiency in practice. concat_string is still better though because it works with arbitrary types ;-)
Something I wrote a while back; the idea is to have a generic way to call cleanup functions (i.e., CoUninitialize) by defining them at the start of a code block. It's easier to read in some regards, in that when you call an init function, you can see the code right there that the deinit function will be called whether the block exits naturally, through a return statement, or an exception: template &lt;typename T&gt; struct ExecuteOnUnwindHelper { ExecuteOnUnwindHelper(const T &amp; _functor) : mFunctor(_functor) { } ~ExecuteOnUnwindHelper() { mFunctor(); } const T &amp; mFunctor; }; template &lt;typename T&gt; boost::shared_ptr&lt;ExecuteOnUnwindHelper&lt;T&gt;&gt; ExecuteOnUnwind(const T &amp; _functor) { return boost::shared_ptr&lt;ExecuteOnUnwindHelper&lt;T&gt;&gt;(new ExecuteOnUnwindHelper&lt;T&gt;(_functor)); }
It's not. Actually, given that streams (and their many layers of indirections) are involved, it's slower unless the compiler does an amazing job (which I seriously doubt). On the other hand, it does handle all kinds of streamable objects.
Why return 1? Program behaved as expected, you should return 0 (EXIT_SUCESS).
It would, although the memory print of a `weak_ptr` is small, a map node also adds 3 extraneous pointers on top of the `int`; so we are looking, at least at 40 bytes of storage per node, which themselves may have some overhead depending on the memory allocator efficiency. It is suitable if the set of id is small-ish; if it is not, it should be augmented with a mechanism that scans the map to remove (or reuse) expired entries.
Note: `boost::ptr_vector` (and other pointer containers) are quite useful, although unfortunately do not use C++11.
That would also be my favorite. It's typically called a `Guard`, and can be implemented easily using C++11 `std::function`: class Guard { public: Guard(std::function&lt;void()&gt; f): func(std::move(f)) {} Guard(Guard&amp;&amp;) = delete; Guard&amp; operator=(Guard&amp;&amp;) = delete; Guard(Guard const&amp;) = delete; Guard&amp; operator=(Guard const&amp;) = delete; ~Guard() { if (not func) { return; } try { func(); } catch(...) {} } void cancel() { func.reset(); } private: std::function&lt;void()&gt; func; }; // class Guard
Don't you need to expand Bases when inheriting from them?
Very cool! Would be nice if exceptions could bubble if we knew we were *not* already being called as a result of an exception being thrown.
You can, thanks to C++11's [current_exception()](http://en.cppreference.com/w/cpp/error/current_exception). ~Guard() noexcept(false) { if (!std::current_exception()) { func(); } else { try { func(); } catch (...) {} } } Whether this is a good idea or not (or whether silently swallowing the exception is a good idea or not in general to begin with) is a matter of debate.
There was a [significant amount of drama](http://flyingfrogblog.blogspot.ca/2013/10/herb-sutters-favorite-c-10-liner.html) over this. Herb responded in the comments.
How many times has someone blown up the compiler and not understood what the heck the error being generated was telling them? :) 
You're reading past the end of the array.
Oops, that's true. That's what I get for typing on my phone.
I use a similar thing like this: class sformat { public: inline operator const char *() const { return stream.str().c_str(); } inline operator std::string() const { return stream.str(); } template &lt;typename T&gt; inline sformat &amp;operator &lt;&lt;(const T &amp;toPrint) { stream &lt;&lt; toPrint; return *this; } private: std::ostringstream stream; }; Use it like this: std::string date = sformat() &lt;&lt; year &lt;&lt; "-" &lt;&lt; "month" &lt;&lt; "-" &lt;&lt; "day"; const char *cStr = sformat() &lt;&lt; "My name is " &lt;&lt; name; Not technically as awesome as agwaman's, but a little more concise and converts to both std::string and c strings!
&gt; std::string could even use a rope implementation This is forbidden in C++11 where string is required to be contiguous. (All known C++98/03 implementations were contiguous.)
&gt; a map node also adds 3 extraneous pointers 4 pointer-equivalents, because of the color bit. (It's easy to forget, even if you're a maintainer!)
Additionally, `x == y == z` is equivalent to `(x == y) == z` which compares a `bool` to `z`. You meant to say `x == y &amp;&amp; y == z`.
Actually, you can't, although the reason why is extremely subtle. The problem is that `current_exception()` doesn't actually tell you whether you're being destroyed due to EH unwinding or ordinary destruction. It's possible for an object to be destroyed normally while an exception is in flight and `current_exception()` returns true - for example, when an object destroyed by EH unwinding calls an ordinary function with local variables that are destroyed normally.
Ahh yes, now that you say it - I remember having read this before. 
Aha, I knew this seemed too reasonable given the subject matter. I originally wrote here that current_exception would also be non-null in a catch block, but I guess there's no unwinding happening at that point so throwing an exception is safe. Sigh, exceptions...
Yes, it is something to consider. There are two attitudes then: - allocate the guard first (requires a null resource) - not worry about memory allocation failure I must admit that most of the times, I don't worry about allocation failure.
Unless you're using boost::container::map where the color bit is stored in the LSB of one of the pointers, if alignment permits. Why don't other implementations do that anyway?
I was wondering if implementations employed dirty tricks for storing this bit, such as using some unused bits in pointers (64-bits) for example, in order to pack the representation as much as possible. (The question being even more of circumstance as with the last talk about the Mill CPU it seems that *it* will be using the full 64-bits for the pointers and thus those "compression" tricks will no longer be available)
Woah... Well spotted! I've only ever used the std::string version in my code so didn't notice... Is there any way around that though other than just using the std::string version and doing .c_str() in the calling code?
Yeah, but if you know that the bridge will be used by no more than maybe 40 cars a day, it would be total overkill to build it with four lanes. It is way better to expect that case not to happen and then build a bigger bridge in the extremely unlikely event that you actually need it. This is especially true if the cache just stores expensive to calculate values that are often requested but only occasionally gets added new ones. **tl;dr**: often: YAGNI
It should be noted that `__PRETTY_FUNCTION__` is nonstandard, while `__func__` is standard but at least on gcc only prints the mangled name without arguments or returntype.
Of course, I didn't try it out before posting, sorry. It's fixed now.
If you leave off the `&amp;` you copy the element out of the container. That would not work, because when you try to assign to that you'd be modifying the local copy, not the one in the container. With the `&amp;` you create a reference to the element in the container.
&gt; You could add a private std::string member to sformat, initialize it in operator const char*() to stream.str(), and return c_str() on that string. Another reason to avoid that - it prevents the operator from being const. If you attempt to make the data member mutable, now you've broken the usual thread safety guarantee (the Committee made the same mistake in C++11 reverse_iterator, fixed in C++14).
Trickery has complexity and occasionally performance costs. Some joker might be giving us an unaligned allocator, or the bitwise operations may be expensive in terms of time when space is plentiful. At a minimum, this makes the data structure harder to visualize. We do engage in trickery from time to time, but it is not free.
Looks like that can't support map's invalidation guarantees. Map is required to be a node-based container, where elements can be erased without invalidating other elements. Attempting to pack elements together is hostile to these guarantees.
If you have a bunch of classes with a `do_something()` method and want to run them all with: derived&lt;ClassA, ClassB, ClassC&gt;().run(); On its own this is not that useful, but I imagine the author intends it to be combined in a way to be more meaningful.
[](){}(); Lambdas bitchs
Duff's device: register n = (count + 7) / 8; /* count &gt; 0 assumed */ switch (count % 8) { case 0: do { *to = *from++; case 7: *to = *from++; case 6: *to = *from++; case 5: *to = *from++; case 4: *to = *from++; case 3: *to = *from++; case 2: *to = *from++; case 1: *to = *from++; } while (--n &gt; 0); }
You don't actually need to rely on alignment to be dirty, depending on the platform. There are (currently) only 48 usable bits in a virtual memory pointer on a x86_64 machine for instance. https://www.kernel.org/doc/Documentation/x86/x86_64/mm.txt std::map is too painful for small types and large data sets imho, especially on 64bit machines. I recommend people look at [Googles B-tree class](http://code.google.com/p/cpp-btree/wiki/UsageInstructions) for such purposes (although you lose iterator stability). Boost flat_map is another good option.
Martinho Fernandez has a series of post [0] on optimizing memory requirements of tuples by sorting the fields. Would it be possible to implement that in a std library (from a standarese pov)? AFAIK libc++ doesn't implement this optimization. I also think that it would increase compilation times. Still, if one is using tuples a lot, the chances that one is also using Boost.Fusion to operate on them are high (and in that case compile time would be large anyways). [0] Size Matters Part 1: http://flamingdangerzone.com/cxx11/2012/07/06/optimal-tuple-i.html There are also Part 2, 3, and 4. Part 5 is promised, but was never delivered :P
Is `boost::fusion::for_each` a compile time or runtime loop?
Note that inserting in a boost::flat\_set is O(N) even tho it requires re-sorting. Still, traversing and copying/moving elements through an array is way faster than performing random lookups in memory through a tree of pointers. In particular, even tho insertion in a std::set is O(logN), it involves logN random traversals through memory (if you get cache misses, boost::flat\_set _can_ be _way_ faster). Still, insertion invalidates iterators in a flat\_set, which is not the case for a set. So for me the rule-of-thumb is, can you live with iterator invalidation? If the answer is yes, flat\_set/map/multis are generally _way_ faster than the std:: datastructures.
Compile time. Note that the number of elements in the tuple is known at compile time and that the lambda is polymorphic to handle the tuple elements of different types.
And this is what I get for not testing my code before giving it to the public.
The way of the tuple: auto tup = std::make_tuple(1, "hello world", 2+3i); boost::fusion::for_each(tup, [](auto&amp;&amp; i) { std::cout &lt;&lt; i &lt;&lt; "\n"; }); &gt;&gt; 1 &gt;&gt; hello world &gt;&gt; (2, 3i) Note that boost::fusion::for_each will be unrolled at compile time, calling a different function for each element in the tuple. The polymorphic lambda is just a struct with a templated operator(), thus accepts any argument and will compile if the values passed have an overloaded ostream &lt;&lt; operator.
I think the chrono library is cool. For example I can do this: // legacy code timeval tv; gettimeofday(&amp;tv, nullptr); // convert to modern code auto duration = std::chrono::seconds(tv.tv_sec) + std::chrono::microseconds(tv.tv_usec); // what is type of duration? It doesn't really since I can always convert it a known type: using namespace std::chrono; auto s = duration_cast&lt;seconds&gt;(duration); auto ms = duration_cast&lt;milliseconds&gt;(duration); Note: duration_cast only is needed in case of narrowing conversions. 
Well.. then I can only say that I didn't know about it. This, and the fact that I like to avoid boost as much as I can, just to cut down on dependencies. If you're interested, I've used it widely [here](https://github.com/jrk-/xpp/blob/master/src/event.hpp#L41) and [here](https://github.com/jrk-/xpp/blob/master/src/connection.hpp#L28).
 register n = (count + 7) / 8; /* count &gt; 0 assumed */ switch (count % 8) { case 0: do { *to = *from++; case 7: *to = *from++; case 6: *to = *from++; case 5: *to = *from++; case 4: *to = *from++; case 3: *to = *from++; case 2: *to = *from++; case 1: *to = *from++; } while (--n &gt; 0); } You were short one space for your indentation to work.
If dependencies are a problem for you, I hope that you are not relying on the standard library, the C++ run-time, and libc either. Those are _actually_ the most troublesome dependencies that one can have. Seriously now, I hope boost::fusion::for\_each is just the beginning, it is a pretty useful library, _if_ you need this kind of stuff. I guess that without Boost I wouldn't be writing C++. So _if_ you think that for_each is a better solution to this problem (and I hope you do think so when you discover boost::fusion::transform/fold/accumulate....), give Boost a second chance. 
A multithreaded message queue, whcih allows any thread to send messages to a processing thread. Boost goodness. Eg. for my game engine, any thread can ask the sound manager (who runs in its own thread) to schedule a sound job. I also use it for a subscriber / publisher loop (Observer design pattern) - eg embedded devices notifying observers about significant events. Header file: #include &lt;queue&gt; #include &lt;boost/thread.hpp&gt; #include &lt;boost/thread/condition.hpp&gt; template &lt;typename T&gt; class MessageQueue : boost::noncopyable { public: void Push(const T &amp;data) { boost::mutex::scoped_lock lock(fMutex); fMessageQueue.push(data); fAvailable.notify_one(); } T PopWait() { boost::mutex::scoped_lock lock(fMutex); while (fMessageQueue.empty()) { fAvailable.wait(lock); } T data(fMessageQueue.front()); fMessageQueue.pop(); return data; } bool PopTimedWait(T &amp;data, const unsigned int milliseconds) { boost::system_time const timeout=boost::get_system_time()+ boost::posix_time::milliseconds(milliseconds); boost::mutex::scoped_lock lock(fMutex); while (fMessageQueue.empty()) { if (!fAvailable.timed_wait(lock, timeout)) return false; } data = fMessageQueue.front(); fMessageQueue.pop(); return true; } private: std::queue&lt;T&gt; fMessageQueue; boost::mutex fMutex; boost::condition fAvailable; }; Processing loop, in a thread: while (1) { // Wait for messages const MessageType aMessage = queue-&gt;PopWait(); // Process message ... } 
Yes, it is possible - there are no guarantees about tuple layout.
A dictionary provides more guarantees concerning iterator-invalidation than the standard-sequence-type… There are these moments in which I doubt my usual opinion that the committee tends to think about what it is doing… What would be your personal opinion about adding both btree- and flat- associative containers to the standard and what do you think would be the chances of such a proposal? Nonetheless: Thanks for your answer. 
If you have separated insertion/lookup phases, it does make sense to use a data structure that is friendly to insertion first: e.g. a std::vector, and then move the data to a look up friendly data structure like flat_set which has a constructor from an ordered unique range: vector&lt;T&gt; ts; ts.reserve(10e6); push_back(input_range, ts); unique(sort(ts)); flat_set&lt;T&gt; sorted_ts{ordered_unique_range_T{}, ts.begin(), ts.end()}; unless you are extremely tight on memory usage. Otherwise, if you have much more insertion than lookup a boost::flat\_set is not a good fit.
Pasting code from a mobile phone. Yuk. Thanks btw. 
Have you considered the TBB concurrent_bounded_queue? http://www.threadingbuildingblocks.org/docs/help/reference/containers_overview/concurrent_bounded_queue_cls.htm 
You can save yourself from the C API by using std::chrono::high_resolution_clock::now() rather than gettimeofday(). 
Tuples are cool, especially with std::tie and std::ignore. Function with multiple return-values: std::tuple&lt;int, std::string, float&gt; fun(); int x; std::string str; std::tie(x, str, std::ignore) = fun(); easy compare: struct rgba { uint8_t r; uint8_t g; uint8_t b; uint8_t a; }; bool operator&lt;(const rgba&amp; l, const rgba&amp; r) { return std::tie(l.r, l.g, l.b, l.a) &lt; std::tie(r.r, r.g, r.b, r.a); } 
Simple scope guard class that runs a function at construction and another one at destruction. Very useful for enforcing RAII principles when interfacing with C-like libraries. You might also want to use this in conjunction of lambdas to for RAII purposes inside a method, or a subroutine, but you don't want to create a dedicated class to do same the job. I often use this to set and clear flags inside a specific block scope. I use this to wrap `std::thread` clean-up; check if it's joinable, then detach (which prevents you app terminating if you forgot to join or detach a `std::thread` before destruction). class ScopeGuard { public: using FunctionType = std::function&lt;void()&gt;; ScopeGuard(void) = delete; ScopeGuard(const FunctionType&amp; NewConstructorFuction, const FunctionType&amp; NewDestructorFuction) : ConstructorFuction(NewConstructorFuction), DestructorFuction(NewDestructorFuction) { if (ConstructorFuction) {ConstructorFuction();} } ScopeGuard(FunctionType&amp;&amp; NewConstructorFuction, FunctionType&amp;&amp; NewDestructorFuction) : ConstructorFuction(std::move(NewConstructorFuction)), DestructorFuction(std::move(NewDestructorFuction)) { if (ConstructorFuction) {ConstructorFuction();} } ScopeGuard(const ScopeGuard&amp; obj) = delete; ScopeGuard(ScopeGuard&amp;&amp; obj) noexcept = delete; ScopeGuard&amp; operator = (const ScopeGuard&amp; obj) = delete; ScopeGuard&amp; operator = (ScopeGuard&amp;&amp; obj) noexcept = delete; ~ScopeGuard(void) { if (DestructorFuction) {DestructorFuction();} } private: FunctionType ConstructorFuction; FunctionType DestructorFuction; }; 
The WG21 page on isocpp.org has descriptions of all the committee members, and many of them mention their favourite C++ snippets: http://isocpp.org/wiki/faq/wg21 Of them, I liked Roger Orr's the most; his snippet of choice is simply } He says "The C++ rules on block scope of objects provide the hooks for deterministic finalization. I miss this automatic and non-intrusive management of resources when I’m using other programming languages."
boost one: return accumulate(s, s + size, char(), (_1 ^ _2)); std one: if( equal(s.begin(), s.begin() + s.size()/2, s.rbegin()) ) std::cout &lt;&lt; "is a palindrome.\n";
im gonna write my proposal for declval and declref and ppl are gonna love it, not :) i mean even if i would write a proposal and spelling was correct they will be : well you can achieve same behavior with... anyway i think they should used i.type to say type of i(and i.val_type and i.cref_type... ), but some ppl sure like to prefer free functions to member ones even when it comes to core language :) 
as an STL maintainer you prob know A to this: does cpp give you any mechanism to implement *const* map as a sorted vector for increased perf(ofc sometimes you may suffer because you cant just move tree map into a const map implemented as a sorted vector, but lets say that by measuring perf of boost flat_map and looking at usage patterns you decide you want to do this... question is CAN YOU ? :P 
I like some things about D, but I agree in that whenever it pops up on /r/programming, I feel like I'm being sold on something
would you like "for each member of a class" syntax in cpp? to make serialization, hashing, implementing operator == (though idk if you could do SCEval with that or you would have to suffer through all comparisons although member x is different... )... simpler if so would you like for subset of elements of a class aka for (a, b, d, f, z) in class that has 26 members and all are named as diff lowercase letter of English alphabet :) 
Your link is better since it specifies a queue capacity (and handles these limits better). I'll look into adding that functionality to my MessageQueue. +1
I don't use boost. Mind explaining what your boost code there actually does?
For code demonstrations it forces explicitness, also, a lot of libraries enhance the std namespace and as such importing the entire namespace is excessive.
Generally speaking - and this is always true in programming - you want to be careful about letting too many names flood the scope of whatever piece of code you're working on to avoid confusion. By not using namespace std, it's like you're keeping all those names wrapped up in one place where they can't get mixed in with other names.
Interesting. The trick I have seen looks like this: #define ARRAY_SIZE(x) (sizeof(x)/sizeof(x[0])) but I like yours better.
Ah. Thanks. I figured as much!
Since this already has a few good answers, I'll just add a quick point. If you want to have using statements in your cpp files (never in headers!) then prefer explicit using statements over the global using namespace std. For example if you are only using std::vector in your cpp file you don't need to import the entire namespace, you can write "using std::vector;" and that will allow you to omit the std:: for vector but still require you to use it for anything else. The less you pollute the global namespace with things you aren't using the better.
Some styleguides explicitly forbid it to increase readability and avoid confusion. For instance: http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml#Namespaces
Just to define some terminology (mostly for OP's edification): a **using directive** (e.g. using namespace std;) imports all the names from that namespace; a **using declaration** (e..g using std::vector) lets you selectively import items from a namespace.
Enhance how? Except when explicitly allowed (i.e. defining specialization of `std::swap` for your own type), the user is not allowed to add anything to the `std` namespace. (`n3337 § 17.6.4.2 [namespace.std]/1,2`)
 #ifdef _MSC_VER #define DEBUG_BREAK __debugbreak() #else #define DEBUG_BREAK __builtin_trap() #endif #define ASSERT(x) (void)CHECK(x) #define CHECK(x) check(x, #x, __FILE__, __FUNCTION__, __LINE__ ) #define IF(x) if(CHECK(x)) bool check(bool b, char * pzExpression, char * pzFile, char * pzFunction, int iLine) { if (!b) { DEBUG_BREAK; // log file printf("check %s %s %s %d\n", pzExpression, pzFile, pzFunction, iLine); } return b; } int main(int argc, char* argv[]) { bool bOK = true; int i = 0; int * p = getPointer(); unsigned int uiCount = 1; bOK = bOK &amp;&amp; CHECK (uiCount &gt; 0); ASSERT(i &gt;= 0); if (bOK) { IF(p) { //use p } } return 0;
Note that the google style-guide forbids it in headers only. In the actual source files (.cc/.cpp/etc), it's OK. This is also echoed by Herb Sutter in his blog.
That's a maintenance headache. The STL is so rich in functionality that a using namespace std; at the top is fairly innocuous. In the rare cases where you get a conflict, the worst case is a compilation error in code you've modified.
I'm pretty sure you get a compile error specifically because of the ambiguity forcing you to either explicitly state which one or to resolve the using at the top. using namespace std; is not bad style when restricted to .cc since they won't pollute any other code.
No. An object's constructor can't sense its constness. Additionally, maps and const maps need to have the same iterators.
Maybe. Compiletime only. Runtime reflection is an abomination.
And remember, there's no such thing as partial specializations of function templates. Anything that looks like that is actually an overload, and you can't add overloads into std. (I like to think of this as the "get off my lawn" rule.)
There's a reason for namespaces: avoid name conflicts. That is a nice thing. Why would you throw that away? If the answer is "type less" then think again. We type code once, and read code many times. Make it easy to grok, not to type. Sometimes it might make sense to bring particular names to scope. For example, to get a fallback with ADL. But I don't recall the last time I brought an entire namespace to scope. In fact, ADL and aliasing is the only proper reason I can think of off the top of my head for using "using". Well. There are some crazy inheritance scenarios where a "using" might be a trick for some benefit. But these are very rare. Rarer than my memory serves me ever needing any of those.
In a header file, using namespace std is pure evil. 
Even in cc files, google only allows using methods/classes/functions a la carte. 
The [classic answer](http://www.janko.at/Humor/Computerwelt/using%20namespace%20std.htm): Do you remember the scene in Star Trek Old Generation where they could not get the hatch to a grain silo open, and when Kirk finally opened it thousands of tribbles rained down all over him? Kirk represents your source file. The grain silo represents all the header files your source file includes. The tribbles each represents an identifier declared inside 'namespace std' in those headers. Raining down all over Kirk represents all those identifiers polluting your local namespace. 'using namespace std' represents sliding the hatch open. The purpose of the 'using' keyword is to prevent this pollution. You must keep all the tribbles in the grain silo, and only take down the one or two that you need: using std::cout; using std::endl; Folks use 'using namespace std' in this newsgroup because trivial example code often uses it; the code is not large enough to have enough of its own identifiers to potentially conflict with the 'std' ones. But nobody should use 'using namespace std', and those who post sample code to this newsgroup should set a good example. 
See [here](http://stackoverflow.com/questions/10426428/invalid-template-dependent-member-function-template-deduction-thinks-im-tryin) for an example of how `using namespace std` can cause such a headache
+1 - the stackoverflow answers are very comprehensive
I like to be explicit so I don't have to scroll around a file to find out which namespace the function I'm calling resides in. Code readability/maintainability is important to me.
Nice trick. I use template&lt; typename T &gt; void reset( T &amp;t ) { t = T(); }
&gt; If the answer is "type less" then think again. We type code once, and read code many times. It's not such a clear-cut case. Consider: `set_difference(begin(x),end(x),begin(y),end(y),back_inserter(out),greater&lt;int&gt;());` vs. `std::set_difference(std::begin(x),std::end(x),std::begin(y),std::end(y),std::back_inserter(out),std::greater&lt;int&gt;());` The second version is less readable to me.
Much better, since 1) idiomatic and 2) exception safe. In gorlak's code, if `T::T()` throws, `*p` is left in an undefined state.
Breaking on throw is not the same as just running it, THEN when it asserts connecting the debugger. &gt; And the throw is much cleaner if you're using RAII. And it's preferable in multi-threading. What? I am not against exceptions, they have their place, but for preconditions to functions Asserts are much better.
I have made some simple [tests](http://pastebin.com/MCUuf1g1) on VC++ 2013 x64 release build max speed. For TXT1 I get (on average): concat_string: 35 ms append new vector: 12 ms append preallocated vector: 9 ms For TXT2: concat_string: 86 ms append new vector: 39 ms append preallocated vector: 28 ms Append operator will be slower in case of very long strings. On every reallocation string/vector grow about 1.5 times its previous size (when appended chunk size is not known), so if you are doing small appends to a string there will be a lot of no reallocation operations, thus not slower than streams. Of course stream operations have manipulators and other useful stuff, but it will be better to see something like boost::format for strings formatting (only that boost::format is slow).
I don't think increasing the line count sevenfold is good for readability, but it's a matter of taste, I guess. That said, you should be able to write set_difference(begin(x), end(x), begin(y), end(y), back_inserter(out), std::greater&lt;int&gt;()); anyways, due to argument-dependent lookup.
Feel free to propose ... { using namespace std; set_difference(begin(x), end(x), begin(y), end(y), back_inserter(out), greater&lt;int&gt;()); } ... as a compromise, so that your readability preferences do not conflict with others' global-namespace-tidiness preferences. My sympathies are with the tidy camp. For me the bare "begin" is *less* readable, because I cannot ignore the concern that there is another *begin* in scope somehow so I won't know for sure until compile time. 
That's clever, but it won't work for standard arrays, which is why I'm not using method begin in the first place.
No, I didn't think you were against exceptions, I just couldn't figure out why you would use an assert instead (in this case). I think it probably comes down to us having different priorities. I'm guessing you like the assert because the function "ought not" to have invalid arguments passed to it, so why pay the price of checking that in the release build? To me, the function is a unit in the unit test sense. The throw is testable; the assert is not. Even though the code "ought not" to get invalid arguments, that makes a lot of assumptions of the context in which the function is called. I would rather not make those assumptions, and instead provide fault tolerant behaviour should an error occur (say, the function is copy-pasted to another project). A unit test can capture that behaviour. An assert would either crash the rest of my tests (in debug build), or happily continue with the bad arguments (in release build). From this perspective, asserts are quite inferior.
&gt; Breaking on throw is not the same as just running it, THEN when it asserts connecting the debugger. And there's little reason to core in this case. invalid_arguments aren't like segfaults or stack corruptions. Being logic errors, they can often be reproduced. In fact, in my experience at least, they are persistent.
Yes, it absolutely works for std::array. If you meant a raw array (ie int[]) then stop, those things should be considered legacy.
xor checksum using boost lambda,&lt;3 (sooooo much nicer than core lang lamdas ) s is c string size is his len, and accumulate is std::accumulate :) 
I guess you could lie that your iterators are only bidi, not ra, or are you saying that they must have the same implementation, aka you cant have pointer increments decrements for const and tree jumping :) for non const? btw as a bonus question, would you like to have the option to sense constness? :) for eg it could make vector's size 20% more cooler (aka 1/3 smaller, since you dont need to know capacity, only size). one pointer doesnt look that much but like you said (when you shrunk STL containers sizes in VS2012) if you had a vector of vectors.... :) 
Looks good. If you want it to be more compliant with STL-like containers, as a first step, I would add some typedefs. For example, `value_type`, `reference`, `const_reference`, etc. You will also probably want to incorporate iterators too at some point so you can use the built-in algorithms with your containers.
The linked style guide forbids "using directives" entirely. It only forbid using declarations in headers. "using namespace std" is a directive, not declaration.
No, it's still relevant; look at the code. Without the `&amp;` the weak_ptr in the map would never be updated, which means the cache would never actually cache anything. Edit: a testcase: #include &lt;iostream&gt; #include &lt;iomanip&gt; #include &lt;memory&gt; #include &lt;map&gt; struct widget {}; int main() { std::map&lt;int, std::weak_ptr&lt;widget&gt;&gt; cache; #ifdef USE_REFERENCE auto&amp; wp = cache[1]; #else auto wp = cache[1]; #endif auto sp = wp.lock(); if (!sp) { wp = sp = std::make_shared&lt;widget&gt;(); } std::cout &lt;&lt; "cache[1] refers to something? " &lt;&lt; std::boolalpha &lt;&lt; !!cache[1].lock() &lt;&lt; "\n"; } ===== $ g++ -Wall -Wextra -pedantic -std=c++1y -O2 20140331.cpp &amp;&amp; ./a cache[1] refers to something? false $ g++ -Wall -Wextra -pedantic -std=c++1y -O2 20140331.cpp -DUSE_REFERENCE &amp;&amp; ./a cache[1] refers to something? true 
Also, allocator awareness.
You've corrected a misunderstanding I had; thank you. I was under the impression it kept the reference internally; so when you copy it, the new copy has a reference to the same underlying structure. How else could it know when the `shared_ptr`s it creates are all freed? I see now that that isn't true; there is no internal reference to a shared structure -- and `weak_ptr` doesn't keep a copy of it when the `share_ptr` reference count becomes zero. 
&gt; //srand(time(0)); Don't let STL see that ;P Consider using &lt;random&gt; instead, it's a beautiful header :)
Strange. It won't run when compiled with clang unless you put a return statement at the end of the match_heaps and match_queues function.
thanks for looking at it and for the suggestions. Can you be more specific on the typedefs by any chance ? An example would be very helpful! Trying to elevate my skills here, hopefully through useful code...
It doesn't seem like clang's preprocessor would really be that difficult to get into. I'd think it would be easy enough to use their preprocessor library to create a non-integrated preprocessor that processes many files at once and which uses gcc predefines instead of clang predefines.
You should take a look at [this video](http://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful)
Yes I am well aware of that. But that's not an excuse to keep using raw arrays. And I agree with your points. Same applies to swap, and to less extent 'to_string'.
Yes, that should work. I didn't consider it. &gt; I don't think increasing the line count sevenfold is good for readability.... In general, no. But most of my source files have very few lines that look like this, so I'm only increasing the line count of this function call by sevenfold—the rest of the code remains the same number of lines.
You'll be told by the compiler fairly quickly if you try to name your variable if it conflicts with a type. Also, naming your variables after something that *could* be a C++ STL type/function is just evil. Name your variables something more descriptive. Aside from min/max, it's very difficult to find a reasonable variable name that would conflict with a type.
yes but for capacity you dont need to "remember it" since it is always same as size, you can always say your capacity is size(), aka if ptrs in normal vec are begin end capacity in const vector you claim capacity to be (end - begin), same as size. anyway if cpp is so much about perf and control at least highly used libs as STL should be implementable without non const overhead for const values:) but then again im const Nazi so I am biased :P 
Yeah, those functions never return anything. Calling them has undefined behavior. The static analyzer also reports a use-after-free error in delete_fibnodes.
just remembered one magic one from TMP wizard Eric Niebler: int main() { std::map&lt;std::string, std::string&gt; rep; rep["alpha"] = "a"; rep["beta"] = "b"; rep["gamma"] = "g"; rep["delta"] = "d"; local&lt;std::string const *&gt; pstr; sregex const rx = (a1 = rep)[pstr = &amp;a1]; std::string str("alpha beta gamma delta"); std::cout &lt;&lt; regex_replace(str, rx, *pstr) &lt;&lt; std::endl; } to see what it does : http://ericniebler.com/2010/09/27/boost-xpressive-ftw/
Ha! He updated the readme to use g++. Problem solved!
Looks like we'll never reach the N'th core C++ video. Damn, I really enjoyed that series.
Thanks for pointing this out as well, will look into this, as the destruction of these trees is annoying at best. Their structure makes it awkward to use smart pointers, as it would impact the destruction time through the full depth first search of all trees and loop (that is, as far as I understand). Though, could you share how to repeat the use after free error please ? Running valgrind on the test exe does not reveal anything. Thanks! [Edits]: precisions
&gt; how to repeat the use after free error please ? [It's right here:](https://github.com/beniz/fiboheap/blob/master/fiboheap.h#L70) if (x-&gt;left == x-&gt;right &amp;&amp; x-&gt;left == x) delete x; FibNode *cur = x; while(true) { /*std::cerr &lt;&lt; "cur: " &lt;&lt; cur &lt;&lt; std::endl; std::cerr &lt;&lt; "x: " &lt;&lt; x &lt;&lt; std::endl;*/ if (cur-&gt;left &amp;&amp; cur-&gt;left != x) if `x-&gt;left == x-&gt;right &amp;&amp; x-&gt;left == x`, you delete the node x points to, and then immediately start to examine it in the loop.
I simply compiled the program with clang and the flag `--analyze`, which performs static analysis. I don't have a testcase that actually triggers the leak at runtime. http://coliru.stacked-crooked.com/a/9d02bff59028b265 The command line report just points out the leak, but if you use the analyzer from an IDE or if you pass the right options I believe you can get a pretty annotated view of the source that provides a step-by-step walk-through of how the leak occurs. (edit: [here's the html](http://pastebin.com/X5hwH1Gj). Save it and view in a browser.) Clang has a bunch of other warnings that you can turn on too. They point out some minor or stylistic things such as extra semi-colons, old-style casts, and signed/unsigned comparisons. http://coliru.stacked-crooked.com/a/bc2b2733c9c8bcc1
Having used protobuf and cereal I can say that protobuf with it's separate schema language and .proto files AND an additional build step introduces additional complexity especially in trying to represent complex structures. Implementing protobuf in an existing project is also much more disruptive than the (often very short) serialize methods cereal provides. There is tremendous value in simple object serialization provided by cereal vs having to define separate schemas in separate files alongside your actual code. From a purely subjective standpoint protobuf looks like an ugly ass sandwich syntactically, and forces you to write goobly code to get it to run, it is extraordinarily invasive. The only reason I'd use it again is because it is well supported and has well defined interaction across languages. For single-language projects cereal is superior syntactically and work-flow wise. I took an existing library and was able to get the whole scene graph serialized with cereal without modifying *any* code except for the basic serialize functions which I added.
Did you read the messages in this chain of replies? The original snippet computes the expression `cache[id]` twice. It was pointed out that, unlike a vector, that can't be easily optimized away, so it might be nice to only compute it once rather than twice. The discussion about `auto &amp;` has nothing to do with `sp`, but about `auto &amp;wp = cache[id];`. It was asked why `&amp;` was necessary for `wp`, and the answer is that the code is incorrect without it, as the cache is never actually updated. 
Is there a per-thread or threadsafe instance of / interface to the &lt;random&gt; generators? This seems to be the trickiest part about avoiding rand().
Sadly, unreadable on the phone. The left side bar overlaps the text when zooming in on the text. Android 2 standard browser. I've seen this on a few other pages before. If you're using a template, please consider informing the respective author about this issue. *EDIT:* Same issue in Dolphin Browser 10.2.8 on the same phone (Samsung Galaxy S2 Android 2.3.4).
Parenthesis, not brackets. We speak English here in Murica!
Use a namespace alias instead
Yes, clang supports them since 3.3-3.4. The support in 3.5 is perfect.
Why not have your constructor take `std::initializer_list&lt;T&gt;` in that case? 
So what you're asking about is a way to have a variadic template pack that is supposed to be all the same type, and has the compiler yell at you if it isn't?
It would break dependency information if you were to suggest that this optimization should occur across object files.
If anyone's slightly confused by this comment, he's referring to [Stephan T. Lavavej](http://nuwen.net/stl.html) and not the Standard Template Library.
I'm more impressed people still support/use SPARC processors
I knew about loop unrolling. That wasn’t it. And it was long enough ago that I can’t remember the details of any specific cases. Pretty sure it was 68K code, and I knew it fairly well back then. I’m won’t argue whether sufficient knowledge will always win out, but “hardly ever worth it” is the important point.
Well...keep in mind that compilers are written by humans. At the end of the day, SOMEONE has the knowledge required to roll fast assembly.
What if I'm extremely confused or even baffled? Is there something I can do for that?
you could use the .data() method.
&gt; Failure to declare a function noexcept when you know it will never emit an exception is simply poor interface specification. So very wrong. You simply can't compare const and noexcept specifications. When I declare a function const, I can be pretty damned sure it will stay that way. Changing a function's constness is a very fundamental change in the meaning of the function. I have none of that confidence about nothrow. To declare nothrow, every function I call must also be nothrow. If an implementation changes somewhere, and I now need to call a function without a guarantee, what am I supposed to do? Catch and eat the exception? Not happening. Perhaps you're still wondering, why are these concepts so different? I suggest that *exceptions* are a flexible implementation detail, while const is a very fundamental concept. A const function is specifically limited in what it can do, but exceptions are just an alternative to error results. More importantly, const functions can call non-const functions. Nothrow functions can't do so safely, because it's not safe to eat exceptions. Were I to write a collection of nothrow objects and functions, consider how much work it would be if I suddenly had to call a normal function as part of a bugfix. I'd have to remove nothrow from whole chains of functions. What a pain in the ass. I fully intend to use nothrow for simple functions which are very unlikely to ever change. I intend to use nothrow in libraries where nothrow is a key feature, and very unlikely to ever change. I do *not* intend to use nothrow casually or preferentially. I suggest you do the same.
I'm not a friend of those... `std::initializer_list` is a ... questionable connection between the core language and the STL (in my opinion). Also I don't want to have another object of some class to construct my really simple Vector struct...
Yup. I don't see any reason to forbid something like that: void func(int... args) This should be possible in my opinion. And I would like to understand why it's not possible..
Well, he did state "when you know it will never...". I'd assume that "never" also includes any plausible future updates to the function, and in that case it should be fine. Might not be too many such functions though, outside of your swap:s and move:s. 
To add a code-sample: std::size_t random_int(std::size_t min, std::size_t max) { thread_local static std::mt19937_64 gen{std::random_device{}()}; std::uniform_int_distribution&lt;std::size_t&gt; dist{min, max}; return dist(gen); } ~~(AFAIK STL likes `int` better than `std::size_t`. As you can see in my sample this is one of the few places where I disagree with his opinion.)~~
`rand()` isn't thread-safe either.
so what is noexectp really good for?
You "guarantee" with it that no exception will "leave" your function.
Mainly for allowing the compiler to generate better (faster/smaller) code. Client code might also find the promise useful. This post gives a very good overview of the motivations for noexcept. http://akrzemi1.wordpress.com/2011/06/10/using-noexcept/ 
You should throw a link to your random numbers talk as well. It's pretty good.
In principle the rule is correct, but the wording makes it sound like it's frequently appropriate to apply noexcept, when in reality it's quite rare. If you're writing a library whose only dependency is the standard library, then I think you have a reasonable expectation of when you can apply noexcept, as the stl clearly documents exception flow. Personally, I wouldn't tag a function as noexcept unless its only dependencies are the stl. So yes, use noexcept whenever possible -- which is almost never.
If I remember correctly, there is a difference here between exceptions excaping from a `noexcept` (a C++11 addition) function and from a function declared `throw()` (been around in earlier versions). I think in one case the program *may* call `terminate`, but it also has the option to silently ignore the exception. I forget which though. Update: I find [this](http://en.cppreference.com/w/cpp/language/noexcept_spec) a bit confusing: &gt; If a function marked noexcept allows an uncaught exception to escape at runtime, std::terminate is called immediately. &gt; noexcept is an improved version of throw(), which is deprecated in C++11. Unlike throw(), noexcept will not call std::unexpected and may or may not unwind the stack, which potentially allows the compiler to implement noexcept without the runtime overhead of throw(). The words "may or may not" are interesting. It suggest that `noexcept` is less well defined than `throw()`, which allows more optimizations.
Never is a very long time in software development. 
&gt; If you're writing a library whose only dependency is the standard library, then I think you have a reasonable expectation of when you can apply noexcept How so? Much of standard library are templates, and therefore you can't reason about noexcept at all - it al depends on the specializations. 
On msvc at least it is; the internal structures are in a per-thread block managed by the CRT... assuming the multi threaded CRT of course. 
What do you mean by "it's fine"? Are you expressing the opinion that it should be allowed or stating the fact that compilers won't issue such warnings. In the latter case, I think that raises the question: Shouldn't they?
Nope - for the record, I strongly prefer unsigned integers. Perhaps you're confusing me with other GoingNative speakers. I also prefer fixed-width types. I'll use `size_t` if that's what I need, but otherwise I'll explicitly request `uint32_t` or `uint64_t`.
Even though it's 2x slower, I would prefer the STL answer to read: &gt; if( equal( s.begin(), **s.end()**, s.rbegin() ) ) Also, how does the Boost answer account for the order of the letters? 
&gt; Perhaps you're confusing me with other GoingNative speakers. Definitely that. I just membered how everyone on the panel hated on unsigned and was in the wrong believe that you were among them. &gt; I also prefer fixed-width types. Certainly a sane choice. What I really don't like about them is their inconsistent behavior that results from the underlying types (uint8_t+uint8_t=int32_t,…), though this is true for size_t too. 
I doubt that this is standard-conforming, because it would result in the following code ending with assertion-failure, which is definitely an observable optimization: int main() { std::srand(1234); std::rand(); auto val = std::rand(); std::srand(1234); std::thread{[](){rand();}}.join(); assert(val == std::rand()); }
I know it's tiny and dumb but... bool = !bool To flip a bool.
&gt; Shouldn't they? No. This isn't something that can reliably be checked at compile time. For example consider a member funciton `at(int)` which guarantees that it will never throw when the parameter is in the range [`0`, `size()`), and that it will throw otherwise. I can write code that is guaranteed not to throw, but the compiler doesn't know how to prove it. If the compiler warns that my code could throw when it cannot it's a false positive which is noise that prevents real issues from being found.
Isn't this only true for Visual Studio on i386? Don't other compilers/ABIs use zero-cost exceptions? Would noexcept still alter the code generated*? * Aside from a different algorithm being selected depending on the noexcept'ness of a function a function.
boost is not palindrome check, just xor checksum :) And I guess you could do s.end(), but TBH i think this is not a case of microoptimization but clear choice to not waste resources. :) 
Use noexcept when you _need_ it. Doing otherwise is just a form of premature optimization.
I wonder if the two Erics's time could be better spent fixing the numerous compiler and code-gen issues, rather than preparing for and presenting at what is pretty much a fan fest. That is just my humble opinion.
I thought in the cow world they were slightly different. though in c++11 I guess there's no more cow.
There is more than one answer. I personally prefer the 2nd one.
Yes, that sounds like a good use case. I would take the time to use nothrow in those narrow circumstances.
I love Eric Brumer's presentation style. He's one of these people that are quiet but extremely enthusiastic about things. It just so happens that one of the things he's enthusiastic about is the optimization stage in a compiler. 
From the comments within the link, in response to the same question. Eric Battalio 1 Apr 2014 3:43 PM @Concerned CPP Dev Developer events like BUILD, customer visits and other community events give our team insight on other scenarios, problems, and potential features that we just cannot get locked away in our offices :) If you are at BUILD, swing by the Visual Studio booth and say hi to Eric (Brumer) and other folks from the team! 
Even worse, much of the standard library is generic code that does not propagate noexcept. E.g. std::plus&lt;&gt; adds two values. For a given type T, operator+ might/might not be noexcept. However, even if it is marked noexcept, std::plus&lt;&gt; call operator won't propagate this (it is always noexcept(false)). That is, conditionally propagating noexcept in generic code that does use the std library is kind of pointless, since it will only propagate noexcept(false). **The only advice I have is very conservative**: &gt; Make sure that your move constructor/assignment are noexcept(true) _iff_ they need to be. And that doesn't mean make them noexcept(true), but rather _static\_assert_ that they are noexcept(true). If they fail the assert, find out why they fail first and try to fix that instead before you consider making them noexcept(true).
So how does this differ from Boost.Fusion? Their RTI_STRUCT_ADAPT macros look just like BOOST_FUSION_ADAPT_XXX macros and there are just so many buzzwords in the "article" that is hard to tell what their library does (besides wrapping Boost.Fusion macros around other macros). &gt; Advantages of RefleX &gt; [...] &gt; &gt; - No Redundancy: Maintaining redundant IDL type descriptions is a burden. RTI_STRUCT_ADAPT is indeed a duplication. So _it is_ redundant. Or I am missing this point completely?
Still no C99 support?
I'd rather have no C support at all.
~~Is there anything C++ specific on the agenda? I can't see anything just skimming it..~~ EDIT: sorry it's right there in the blog entry
Using rand even remotely correct is way more code: int random_int(int min, int max) { auto diff = max - min; if(diff &gt; RAND_MAX) { /* make it even more complicated */ } auto remainder = RAND_MAX % diff; auto max_acceptable = diff - remainder; auto divide_by = RAND_MAX / max_acceptable; while (true) { auto candidat = std::rand(); if(candidat &lt;= max_acceptable) { return candidat / divide_by + min; } } } int main() { std::srand(std::random_device{}()); std::cout &lt;&lt; random_int(3, 23) &lt;&lt; '\n'; } Note that this is still strictly inferior to the above code and nonetheless requires std::random_device for seeding.
Who cares about C anyway? It is 2014, C++ provides lots of improvements over C for writing secure code. It still has lots of issues caused by its C compatibility, but it is surely much more secure.
1) `inizializer_list` can not be constexpr (at least in C++11, dunno about C++1y) 2) In this case you have a fixed number of arguments. If you made a mistake and pass an initializer list with the wrong number of argument the error can be detected only at runtime.
The *real* problem here are not the error messages. You might want have something like Vector( A, A, A ) { /* does something */ ... } Vector( B, B, B ) { /* does something entirely different */ ... } And have the overload resolution to automatically pick the right overload. AFAIK there is no way to do so if you write your constructor using variadic templates: template&lt;class ... Args&gt; Vector( Args... ); This can be done for member functions using some sfinae tricks tho.
Very little of interest for CPP Devs :( Herb Sutter's talk tomorrow should be interesting, but it's the only "Pure C++" based talk. The talk on "Native Code Performance on Modern CPUs" on Friday may be interesting. 
Here are all the talks tagged "C/C++" (sic). http://channel9.msdn.com/Events/Build/2014?sort=sequential&amp;direction=desc&amp;term=&amp;tag=cc%2B%2B
Except the two I mentioned, I feel like the C++ tag is an "Afterthought" on those other presentations.
initializer_list is effectively two pointers so pretty cheap to construct.
I've used a stack for doing this.
I'm clueless. Good luck to the entrants!
GNU Unifont?
Boost Fusion is means to an end, not the end itself. This library uses Fusion to build TypeObject and DynamicData objects. The blog posts included link to those. The RTI_STRUCT_ADAPT macro "calls" BOOST_FUSION_ADAPT_XXX macro but does more things too. For example, look for "KEY". 
This thread has been linked to from elsewhere on reddit. - [/r/OpenCL] [Boost.Compute v0.1 Released](http://np.reddit.com/r/OpenCL/comments/22316v/boostcompute_v01_released/) *^I ^am ^a ^bot. ^Comments? ^Complaints? [^Send ^them ^to ^my ^inbox!](http://www.reddit.com/message/compose/?to=totes_meta_bot)* 
Got suspicious page 2. Scrolled down, _I knew it!_
You're a few days late.
and a few years actually...
Wrong subreddit ;)
*Many* years.
Let me guess. This is posted every year around the beginning of April?
&gt; However, to avoid absurdities That's where I knew it had to be fake. C++ is a walking absurdity.
Is it april fool?
A quick question about the schedule: what will one miss if one cannot attend until monday morning? Ie what happens on the sunday?
That's one of the biggest issues with Stack Overflow IMO. The person asking the question choses the "correct" answer, and that is the worst person to decide that. 
Thank goodness it's not real.
I wonder if they're going to share the videos like they did for GN. Ch9 is simply superior to youtube in that regard.
"KEY" seems to be like some way to access the reflected field (like in BOOST_FUSION_ADAPT_ASSOC_STRUCT?). I read the post again and the library seems to be a serialization library for some kind of object format (similar to Boost.Fusion + Boost.Serialization). Are you using Boost.Serialization under the hood too? It looks like a nice project!
url is dead
Yes. The last sentence in the "paper" &gt; this project is usually referred to as "Project April Fool."
Based on my experience of attending C++Now, I can honestly say that I learn more about C++ in that week than I learn for the rest of the year. CppCon will probably be even better in this regard since you will have more content to choose from. And I wouldn't call myself a novice (I've been giving talks in the past couple of C++Now's).
`std::iota` is really awesome, but the name is just terrible: In my last project there was huge dislike by some other programmer who believed that it made the code much harder to read than coding it hard or using `std::generate` with functor. 
from comments herbs talk wasnt even streamed. pathetic
&gt; Frankly every C++ programmer should know the STL algorithms inside out. It is their profession after all. To be fair: It was a students project and that person had never programmed in C++ before. In the end he surrendered (I am not certain that he was convinced).
Ah ok, though now it sounds like the should have been showing a little more humility, given his inexperience :)
Similar but without boost: (on phone so idk how whitespace is being pasted) template&lt;std::size_t I = 0, typename FuncT, typename... Tp&gt; inline typename std::enable_if&lt;I == sizeof...(Tp), void&gt;::type for_each(std::tuple&lt;Tp...&gt; &amp;, FuncT) // Unused arguments are given no names. { } template&lt;std::size_t I = 0, typename FuncT, typename... Tp&gt; inline typename std::enable_if&lt;I &lt; sizeof...(Tp), void&gt;::type for_each(std::tuple&lt;Tp...&gt;&amp; t, FuncT f) { f(std::get&lt;I&gt;(t)); for_each&lt;I + 1, FuncT, Tp...&gt;(t, f); } struct Functor { template&lt;typename T&gt; void operator()(T&amp; t) const { std::cout &lt;&lt; t &lt;&lt; ", "; } };
What is 3[a]?
Here I wrote a helper for you that checks if all elements in a parameter pack are the same. Make your constructor private and give it a friend helper variadic function called make_vector (for template argument deduction), then make that function use enable_if to only be valid when all types are the same. #include &lt;type_traits&gt; template &lt;typename T, typename... set&gt; struct all_same; template &lt;typename T, typename current&gt; struct all_same&lt;T, current&gt; { static const bool value = true; typedef current type; }; template &lt;typename T, typename current, typename... set&gt; struct all_same&lt;T, current, set...&gt; { static const bool value = all_same&lt;T, set...&gt;::value ? std::is_same&lt;all_same&lt;T, set...&gt;::type, current&gt;::value : false; typedef current type; }; AntiProtonBoy's reply will help you limit the number of arguments (personally I'd also use enable_if for that). I'm not entirely sure why you want to limit the number of elements though.
What does it do?
The problem with companies is that you might have to support various compilers with some handling C++11 more than others :( It's nice to see that Solaris 12.4 Beta with C++11 support was released today... now it's going to depend on how long it takes for IT in my company to adopt it :) (most likely not the beta).
When some of your customers demand it you don't really have a choice unfortunately :(
It's available now as an MP4 Download. The "High quality" copy is 1.3GB. EDIT: Go watch it. Great information and some great performance data- Linked Lists Suck!
From the linked MSDN "GoingNative announcement": &gt; [CppCon] will truly be an honorable and better replacement for GoingNative – GN on steroids, if you will, but also more than GN was by itself. Strong wording. I hope this includes downloadable videos of the sessions being made available. It was impressive how quickly Channel9 got the videos out last year. I'm not too worried about live streaming; while nice, I have other things to do during the day. If videos will not be made available, I will be truly sad to see GoingNative disappear, and would consider CppCon to be strictly less than GN was by itself. Edit: In an [announcement thread two weeks ago](http://www.reddit.com/r/cpp/comments/20prho/cppcon_has_been_announced/), before GN was preempted by CppCon, they were unsure if [sessions would be recorded](http://www.reddit.com/r/cpp/comments/20prho/cppcon_has_been_announced/cg91415). I hope the involvement of GN organizers due to GN being rolled into CppCon tips the balance in favour of recording.
I wondered the same in [another thread about the matter](http://www.reddit.com/r/cpp/comments/2257yo/goingnative_effort_rolled_into_cppcon_2014/). I really hope they do, as for many people being able to travel to the United States during a specific week for a programming language conference is a luxury unlikely to be afforded to them.
It's probably from the ι function in APL, where `ι n` creates the list `1 2 3 4`
One of the best parts about the GoingNative conference was the quality of the videos of the sessions. Professionally done, where the speaker was on camera then the slides all properly rendered. Compare that to the quality of say the BoostCon videos that look like they were taken with a gas station security camera sitting on a paint mixer, if there's not going to be a crew as there was at GN for CPPCon, I think we all know what this is going to be: A conference for privileged white obese american males, and as a result perhaps not something for the rest of the world's astute C++ developers. 
The not-quite-offscreen window at the bottom is making me twitchy. Skimmed through the video. It's targeted at non-C++ programmers, so not a lot of interest to me, but it seems like a good talk for the target audience. Bits of interest to me are http://parallelstl.codeplex.com/ (Parallel STL TS implementation, coming next week), and that VC++ is targeting full C++14 + Concepts in 2014-2015. "CTP.next" features: http://i.imgur.com/DcFg4V1.png. Probably a "small number of months" away.
Yes, but that doesn't really help if you all you see is std::iota, with the first thought being “that looks like the non-standard-function itoa that you should never use in C++”.
I really like LINQ but GroupBy and nested containers are very verbose and painful without C++14 generic lambdas which is what currently holds me back from actually using any of the available C++ implementations. 
Shouldn't the first thought be "that looks like the STL function iota()! If they brought that back, where's STL power()??"
&gt; Is predicate an accepted term for the generator function? No, the author is clearly misusing "predicate." [Why use non-member begin and end functions in C++11?](http://stackoverflow.com/questions/7593086/why-use-non-member-begin-and-end-functions-in-c11) 
It's going to be hard to have full C++14 compliance in the 2014-2015 range when they still have no ETA on the remaining requirements for C++98 compliance.
Full C++14 compliance obviously includes the remaining C++98 things other than `export`.
I don't understand why `from_array` and `from_range`, could not overload suffice ? template &lt;typename T, size_t N&gt; auto from(T (&amp;s)[N]) -&gt; ... template &lt;typename ItB, typename ItE&gt; auto from(ItB begin, ItE end) -&gt; ... ?
nice exercise, but imao person that chooses to use your code over boost one must be insane. 
seriously, when it beat map, I was a bit shocked. great talk.
Can you be specific? Name a specific topic about C++ or programming in general that was learned from a conference like this? I've attended conferences before and they are fun and I'm not telling anyone not to go, but don't go because you think it's a place where you'll learn exclusive information about C++ or become a better programmer. Typically what you learn about has more to do with the industry, or overall C++ community, like a who's who. This makes it a valuable overall business gathering, a great opportunity to network and meet with like-minded individuals who might be working in your field or using similar technologies you do. But if you're a programmer and you think going to this conference is going to give you a better understanding of how to make use of advanced C++ features well yeah you're going to come away disappointed. But anyways, feel free to let me know what specific talks were given in the past that were not basically very superficial introductions to basic concepts that could be found on the Internet.
I asked elsewhere, but your claim is that the stuff taught during the 1 week at CppCon is something that can not be learned throughout the remaining 51 weeks of the year using other resources such as books, the Internet, lectures etc...? Yes I do find that hard to believe, I've attended C++Now and I intend to go to CppCon as well. Can you name a particular talk given or series of talks that validate the idea that this 1 week at CppCon is roughly equal to 51 weeks of learning outside of CppCon? Thanks.
Also, the examples should drop the `std::` in front of `std::begin()` and `std::end()`. They will automatically be found under the `std::` namespace by [ADL](https://en.wikipedia.org/wiki/Argument-dependent_name_lookup). And it's not just to save typing; by using unqualified IDs you open up the possibility of seamlessly working with user types that have implemented their own begin/end functionality in their own namespace that isn't `std::`. The range-based for loop is explicitly specified to call unqualified `begin()` and `end()` for just this reason.
Video doesn't play. Mirror anyone?
something something clang
One of the best parts about the GoingNative conference was the quality of the videos of the sessions. Professionally done, where the speaker was on camera then the slides all properly rendered. Compare that to the quality of say the BoostCon videos that look like they were taken with a gas station security camera sitting on a paint mixer, if there's not going to be a crew as there was at GN for CPPCon, I think we all know what this is going to be: A conference for privileged white obese american males, and as a result perhaps not something for the rest of the world's astute C++ developers. 
[Direct link](http://video.ch9.ms/sessions/build/2014/2-661.mp4) to the video file.
I posted this in /r/programming, worth mentioning it here. It's a good talk but those benchmarks are pretty rigged and don't reflect real world usage. I mean for the Array vs. Linked List, no one would ever claim that a linked list is faster for insertion if you need to traverse the linked list in order to perform the insertion. That defeats the whole point of having O[1] time complexity if before the insertion you're going over the entire list, changing the complexity from O[1] to O[n]. At which point you're basically just comparing the constant factors and I think most people know that arrays have lower constant factors compared to linked lists, so obviously the array will win. I'll have to double check the game loop example but from the looks of it, the information is also being presented in a slightly misleading way. The performance increase was 15x iterating over the elements and doing no work. In other words, it's 15x performance increase if on every iteration you do no work. Once you actually have each member perform some kind of work then the cost of the iteration becomes negligible compared to the cost of doing any work. Also he argues that using a linear search is faster than a binary search because of the huge performance boost of prefetchers. This is false, prefetchers are no doubt great and can be leveraged to boost performance, but they do not violate the basic principle that logarithmic search will outperform linear search, and actually a binary search will quickly outperform linear search prefetcher or no prefetcher. This is a basic benchmark to show that binary search does indeed outperform linear search even for relatively small lists, for example it will begin to outperform when the size of the list is somewhere between 128 and 256 elements. #include &lt;algorithm&gt; #include &lt;array&gt; #include &lt;ctime&gt; #include &lt;iostream&gt; #include &lt;tuple&gt; #include &lt;vector&gt; static const int TIME = 5; template&lt;typename Sequence&gt; std::tuple&lt;int, int&gt; PerformLinearSearch(const Sequence&amp; elements, int size) { std::time_t startTime = std::time(nullptr); int count = 0; int sum = 0; auto sbegin = elements.begin(); auto send = elements.begin() + size; while(std::time(nullptr) - startTime &lt; TIME + 1) { int value = rand() % elements.size(); auto i = std::find(sbegin, send, value); sum += *i; ++count; } return std::make_tuple(count, sum); } template&lt;typename Sequence&gt; std::tuple&lt;int, int&gt; PerformBinarySearch(const Sequence&amp; elements, int size) { std::time_t startTime = std::time(nullptr); int count = 0; int sum = 0; auto sbegin = elements.begin(); auto send = elements.begin() + size; while(std::time(nullptr) - startTime &lt; TIME) { int value = rand() % elements.size(); auto i = std::lower_bound(sbegin, send, value); sum += *i; ++count; } return std::make_tuple(count, sum); } int main() { int linearSearch; int binarySearch; int size = 16; int sum = 0; std::srand(static_cast&lt;unsigned int&gt;(std::time(nullptr))); do { size = 2 * size; std::vector&lt;int&gt; c; c.resize(size); for(int i = 0; i &lt; size; ++i) { c[i] = i; } int s; std::tie(linearSearch, s) = PerformLinearSearch(c, size); sum += s; std::tie(binarySearch, s) = PerformBinarySearch(c, size); sum += s; std::cout &lt;&lt; linearSearch &lt;&lt; " " &lt;&lt; binarySearch &lt;&lt; std::endl; } while(linearSearch &gt; binarySearch); std::cout &lt;&lt; size &lt;&lt; std::endl; } I had to add some junk variables and code like taking the sum of the retrieved elements in order to avoid the optimizer just eliminating whole chunks of the benchmark. I also even generously give linear search an entire extra second to run and it still ends up performing a lot worse than binary search. The reason why binary search wins is because binary search can also take advantage of pre-fetching. It may not take complete use of pre-fetching the way linear search does, but it's not like binary search spends all its time randomly jumping about an array. A binary search will converge rather quickly (logarithmically in fact) towards a small neighborhood at which point it too will benefit both from caching and prefetching. Anyways, the problem I have with talks like these is now you'll have a bunch of guys who don't really understand the talk, and will superficially just think that vectors and linear search outperform maps and binary search just because Herb Sutter said so. Unfortunately it's just not true, there are a lot of disclaimers and caveats to this presentation which are omitted, and what was shown represents some extreme case scenarios presented as if they represent common case situations. They don't. The basic principles about logarithmic vs. linear search are still valid and still hold true even in C++. The very very rare exceptions where those principles do not hold can not be summarized in a 1 hour informal talk. Do not watch this video and now go and replace all your maps and binary searches with vectors/linear searches.
He didn't say that linear search was faster than binary search. He said that with this test case, using a linear searching a *vector* was faster than the binary search that implements element look-up in a *map*. Clearly binary searching a vector is faster than linear searching a vector, and he even mentions something like "this line in the graph is still for using linear search, it would be even faster with binary search."
Not necessarily, given that C++11 and C++14 deprecate stuff from C++98. Additionally there is this interview session where they state the plan is to support the standard, the customers use, not the full one. http://channel9.msdn.com/Events/Build/2014/9-015 
Yes, that is the correct ADL dance. No scare quotes needed around "right".
Silverlight? http://whatyearisit.info/img/what_year_is_it.jpg
&gt;If, as you say, it ends up quitting after an array with 256 elements, it is using at most 1K of memory, which comfortably fits inside L1 cache This is a good point but I ran the benchmark without the exit condition (linearSearch &gt; binarySearch) to see how much better binary search scales over linear search as the input size increases. Honestly binary search REALLY outperforms linear search after 256 elements. Even at 512 elements binary search is already three times faster. By the time you get to 16k elements binary search ends up being 75x faster. And beyond that binary search quickly ends up being 1000s of times faster, as one would expect. I mean it should be expected that a O[logn] outperforms O[n] as your data set increases, even Herb Sutter knows that and he doesn't say anything to contradict this in his talk. The question is at what point will the O[logn] overtake the O[n]? Will caching and prefetching and C++'s unique nature allow linear search to outperform binary search for even surprisingly large data sets? Is C++ unique in that it can accommodate large data sets compared to Java or C#? Well the answer is no. std::vector doesn't even outperform std::set for lookups beyond a couple of hundred ints. I mean really my point is that Herb Sutter's thesis is actually wrong. His thesis is that C++ is unique among languages like Java and C# in that it can really exploit prefetching and caching and hence you can use a vector as your default container. My thesis is that C++ really isn't special from any other languages in this specific regard, and that you should use the same data structure in C++ as you would in Java or C#. That is... if in Java you would use a Map, then use an std::map in C++. If in C# you would use a linked list, then use a linked list in C++. The choice of data structure in C++ should be picked along the same principles as in any other language.
Hi STL, I really respect your work and sessions at Channel9. I hope that is now the case for future versions, as I always had standard compliance issues with Visual C++ in regards to other compilers. Using it since version 5.0.
You could also go Quicktime (Apple WWDC) or Flash (Google IO).
So I ran some micro-benchmarks myself, and what I found was a little interesting (if only to me). It is true that binary search pretty much always outperforms linear search, since it actually takes advantage of its knowledge about the data, but if you have a cold cache it's a much smaller margin: if I completely trash the cache between iterations, linear search is "only" 5 times slower than binary search on 64K ints (if I don't trash the cache it's about 40 times slower). Which is of course a result from a purely fictitious setting, is not actionable, does not invalidate conventional wisdom, and has nothing to do with whether or not C++ uniquely unlocks potential performance from direct data layout control. It's just that keeping cache behavior in mind is very important, because the constant in front of your logarithm term might be very large indeed.
Of course there are. Boost.Fusion is written in C++, so it is clear that you can rewrite it. But why would you prefer to: - put time into reinventing the wheel, - come up with a less general solution (boost fusion works for tuples, arrays, boost tuples, mpl sequences, compile-time vectors, compile-time associative sequences... and is extendable to other types of sequences) - use a suboptimal solution (do you know how to optimize programs for compile-time performance? e.g. using templight for profiling and Boost.Wave?) - do it again for transform/accumulate/foldr/filter/find/find_if/copy/copy_if/replace/remove/ remove_if/push_front/push_back/pop_front/pop_back/any/all/none/count/zip/join... to use Boost.Fusion? And keep in mind that Fusion is a foundational library (header only and with almost no dependencies) so you can really strip it out from the rest of Boost. So yes, it can be done. If I were your boss, I dont think you could justify to me investing any time into reimplementing any of those. So should you do it on the clock? God no. Should you do it in your free-time? Yes, I think it is a great learning experience. 
Reformated: template&lt;std::size_t I = 0, typename FuncT, typename... Tp&gt; inline typename std::enable_if&lt;I == sizeof...(Tp), void&gt;::type for_each(std::tuple&lt;Tp...&gt; &amp;, FuncT) // Unused arguments are given no names. { } template&lt;std::size_t I = 0, typename FuncT, typename... Tp&gt; inline typename std::enable_if&lt;(I &lt; sizeof...(Tp)), void&gt;::type for_each(std::tuple&lt;Tp...&gt;&amp; t, FuncT f) { f(std::get&lt;I&gt;(t)); for_each&lt;I + 1, FuncT, Tp...&gt;(t, f); } Nice function! But then this only works for std::tuples (not for pairs, or std::arrays, or other types of sequences like mpl::vectors, associative sequences...). Boost.Fusion is like a range-based STL. It works on _any_ sequence that provides a pair of iterators or a range. So this is like comparing std::for\_each (which works on _any_ pair of iterators) with a hand-rolled for\_each function that only works with C arrays. Of course you can do it. But if you wouldn't do it for std::for_each, why would you do it for fusion::for_each?
A pattern I found really useful is the following: Lots of programs have separate insertion/lookup phases. That is, in some part of the program you want to do lots of lookups really fast, and in some other part you want to do lots of insertions really fast. Welcome to boost::flat_set/flat_map and friends [0]. They are sorted vectors. When you want to do insertion: - get the underlying vector, - reserve enough memory, - push_back at the end, O(1) - sort it once, O(NlogN) - unique it once (unless you are using flat_multi_set/flat_multi_map), O(N) - give it back to flat_map/flat_set (which will make sure to keep it sorted for you from now on). When you want to do look-up, just use flat_map/flat_set as normal std::map/std::set. This way you get O(1) insertion in your insertion phase, and O(logN) look up in your look-up phase, and O(N logN) transition from insertion to lookup. When you don't need lots of very fast insertions, you can just use the normal insert operations of the flat_set/flat_map. They are O(N) but still really fast since it is just like inserting to an already sorted contiguous vector. Furthermore, for small sets of data, if you know at compile-time an upper-bound in your set/map capacity you can remove all memory allocations completely (and all expensive calls to new) by using a stack_allocator (e.g. like Howard Hinnant's allocator [1]). If everything is on the stack, returning them from functions doesn't even incur moves. Your pen_and_paper/blackboard are happy, and so is your CPU/prefetcher :) [0] http://www.boost.org/doc/libs/1_55_0/doc/html/container/non_standard_containers.html#container.non_standard_containers.flat_xxx [1] http://home.roadrunner.com/~hinnant/stack_alloc.html PS: in node-based containers like list, the algorithms constant factors _do not_ depend on the size of the elements. OTOH a vector of ints is faster for insertion in the middle than a list of ints because ints are small, i.e., for contiguous containers the constant factors do depend on the size of the elements. My rule of thumb is: start always with contiguous containers unless it is clear that I have a _small_ sequence of very _large_ objects. However, even in the case when list and other node-based containers are faster, you can generally do even better by still using a vector for storage, but an intrusive container from Boost.Intrusive for your operations. This allows you to use sequential/node-based access when each one is faster. Ah, and profile, profile, profile!
I've started to watch it and I spotted a problem at around 11. I'm a full time Python developer, I know Python and similar languages problems in some areas and that's why I like C++ (although I don't know it very well yet). The comparison between current Python and a future version of C++ surely wants to illustrates how C++ can now write a "mean" function in an elegant way, just like a dynamic language can do. But when required to write a "mean" function in python, I'd go like this: mean = lambda seq: sum(seq) / len(seq)
did standard f*ck up this or there was no way to pretend raw arrays should also be in std namespace so ADL will use std::begin/end (when you write begin/end) on them ? I mean during C++11 process, Im not talking about Koenig imagining future global begin/end and adjusting ISO cpp accordingly . :D
&gt; sort it once, O(N) Umm....
Right. I said this on the slide -- the roadmap chart explicitly includes "C++98" features on the right-hand column, including the few remaining C++98 things like two-phase lookup and preprocessor conformance that we don't currently do. C++98 is part of C++14 (except export which we won't implement as such though future modules are looking promising and might include export-like functionality that's actually reasonably implementable).
The example was mainly intended just to show basic code like functions/variables/loops in both languages. But yes you could write that particular code in other ways in both languages. In C++, using only std:: facilities your version would look like this (note, also using a lambda, also using type deduction for the variable): auto mean = [](const Sequence&amp; seq) { return accumulate(begin(seq),end(seq),0) / seq.size(); } If I can cheat slightly by writing the "sum" once (pending getting it into the standard library I would write it once and then use it everywhere): auto mean = [](const Sequence&amp; seq) { return sum(seq) / seq.size(); }
Did you try the **MP4** links?
Yup, the speaker mentioned Clang as already shipping a fully conforming implementation. :)
Jon Bentley's example was intended to illustrate a difference, not reflect real world usage. Because people ask about real world usage Bjarne also added (and I showed) mention of a tree. And even for Jon's actual example the slides showed (and I tried to repeat) explicit disclaimers of "your mileage ***will*** vary [emphasis original]" and "for small elements and relatively small numbers (up to 500,000 on my machine)". Please note the caveats. That said, I'm interested enough in this example that I think I'm going to develop a detailed set of benchmarks and present them in an extended form at [CppCon](http://cppcon.org), including things like measuring the impact of elements larger than small fundamental types which also changes the numbers. (NOTE: This is not a promise I'll do this extended talk, just that I'm thinking of doing it and sat down this morning to start sketching it.)
oops, copy paste from unique. Fixed now, thanks!
This website is just a somewhat nicely formatted version of [cppreference.com](http://en.cppreference.com/w/)'s content. If you want to run any of the code examples there, you need to go back to cppreference. In addition, this site may not update as cppreference does, so it may become out of date for things like optionals in the future. Also cppreference provides an offline version found on [this](http://en.cppreference.com/w/Cppreference:Archives) page.
I'm seeing a blank page. Is the server down or are the creators of this site incapable of displaying text without javascript?
&gt; give it back to flat_map/flat_set (which will make sure to keep it sorted for you from now on). Afaict you can't gift a vector to a flat_set/map, it always takes a copy. There's only a constructor which will take your word on the sort order. An immutable version which just held a reference would be pretty great. 
Amazing, thanks. I was surprised to find "accumulate" under &lt;numeric&gt; and not under &lt;algorithm&gt;, though. "reduce" (or "fold") is one of the basic operations in functional programming, and they're all under &lt;algorithm&gt;.
The Meyers books *Effective C++* and *Effective STL* are good references to have on the "right" way to wield C++'s many bits and pieces. They've not been updated to C++11 yet, but I hear the new versions are on their way. Soon, I hope.
It's ripping off content from cppreference and ripping off design ideas from Apple. What's the point?
I'm a little late to the party, but C++11 allowed me to easily implement my own intrinsic refcounted smart pointer system and then wrap any object I want w/out having to explicitly implement each and every constructor the wrapped object supports: namespace Core { // ============================================================================ SmartWrapper // SmartWrapper // // A wrapper class to give SmartObject support to outside classes // ---------------------------------------------------------------------------- template &lt; class class_t &gt; class SmartWrapper : public class_t, public SmartObject { public: // -------------------------------------------------------------------- Construct template &lt; typename ...ARGS &gt; SmartWrapper( ARGS... args ) : class_t( args... ) {} }; }; Wrapped STL objects: // ---------------------------------------------------------------------------- Map template &lt; class key_t, class value_t, class compare = std::less&lt;key_t&gt;, class alloc = std::allocator&lt; std::pair&lt;const key_t, value_t&gt; &gt; &gt; using Map = SmartWrapper&lt; std::map&lt;key_t, value_t, compare, alloc&gt; &gt;; // ---------------------------------------------------------------------------- Unordered_Map template&lt; class key_t, class value_t, class hash = std::hash&lt;key_t&gt;, class key_equal = std::equal_to&lt;key_t&gt;, class alloc = std::allocator&lt; std::pair&lt;const key_t, value_t&gt; &gt; &gt; using Unordered_Map = SmartWrapper&lt; std::unordered_map&lt;key_t, value_t&gt; &gt;;
As jrandom said, Effective C++ is a must read. [Here are a few video tutorials as well](http://www.reddit.com/r/cpp/comments/20tfxh/decent_c_youtube_tutorials/). CS251 Goes through C++, I believe from a C#/Java standpoint, and there are a few C++11 videos as well.
Insertion in a flat_ container is O(N), and if you want to use the pattern above without this, you have to copy the data out, insert, sort, unique, and copy the data back in. It is not much slower, but requires twice the memory which is IMO totally unnecessary. I'm so used to this that forgot it is non-standard! The flat containers interface specifies that it internally stores its data as a sorted vector: a boost::container::vector to be precise, which is a private member of detail::flat\_tree, a class that all flat_ containers inherit of. If you need the speed, just add some getter/setters. Specifically what I do is I move the vector out of the flat_x, change it, and move it back in. This makes the flat_x empty while I'm modifying it so no-one can screw up with it, and when I move it back in, I assert the container invariants in debug mode to check everything is fine. It works smoothly, is as dangerous as the constructor you mention (which assumes you are giving it a sorted uniqued range), but faster. This modifies a detail implementation of the flat_ containers, so it can change in the future and break your code, but since it hasn't changed much in years I really doubt it. There is a thread [0] in which people agree that this would be an useful feature, but AFAIK no-one sent a patch. [0] http://boost.2283326.n4.nabble.com/Containers-Should-flat-expose-implementation-vector-td3722533.html
A very dense but relatively complete overview of the things that are new in C++11 is the [wikipedia-article about C++11](https://en.wikipedia.org/wiki/C%2B%2B11). Then there is this video by Bjarne Stroustrup that every C++-programmer should have watched: [C++11-style](http://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Keynote-Bjarne-Stroustrup-Cpp11-Style) Concerning pointers: Try to avoid them completely. If this is impossible (sometimes it is), try hard to just use `std::unique_ptr`. If this is still not possible go long ways to ensure that a std::shared_ptr is enough. Exception: Sometimes you might want to implement your own smart-pointer (for instance an “`observer_ptr” that states with it's type “I am not owning this, I'm just looking at it”), in that case don't hesitate to use blank pointers, just make sure that your class(-template) really does nothing besides being some kind of pointer). Concerning new: Don't use them! Instead use `std::make_shared` and once you can use C++14 `std::make_unique` (until then: copy the template into your project yourself, [it's only four lines](https://stackoverflow.com/questions/7038357/make-unique-and-perfect-forwarding)). Concerning delete: If you need to write delete, you almost certainly did something wrong somewhere. Always use the stack or appropriate smart-pointers. **Never** use blank arrays: They just aren't worth the trouble. Almost all of the time just use `std::vector&lt;T&gt;` or `std::array&lt;T, Size&gt;`, and rarely other containers like `std::list` or `std::deque`. 
&gt; (for instance an “`observer_ptr” that states with it's type “I am not owning this, I'm just looking at it”) Just a sidenote for OP, the only real use for this is a "nullable" reference. Something with similar semantics was going to be in C++14 as `std::optional`, but it was voted out (it's available in Boost, though).
The Boost implementation is a bit complicated to use (see the doc...), and AFAIK is not part of older versions of the library. But this is an exercise yes, though I use it throughout scientific libs and apps.
As a practical matter, do you have access to a C++ compiler that supports all of the modern features that you are interested in?
Get Bjarne's latest book, "Tour of C++", it describes how to write modern safe C++. http://www.amazon.com/Tour-In-Depth-Series-Bjarne-Stroustrup/dp/0321958314
Thanks for catching this! it is now fixed.
It sounds like you are Win32/x64. Are you using MinGW, clang, or VS? Choice of compiler/platform may limit how much C++11/C++14 you can utilize. Any cross-platform portability concerns? Also, and this may be utterly obvious, it might be more practical to transition 'eventually' to more modern C++, vs complete rewrites of existing (working!) code. I.e., you can start with easy drop-ins, like use of vector&lt;&gt; (or array&lt;&gt;) instead of C arrays; string vs char arrays; easy conversions of code to use RAII, etc.
Special cases increase language complexity. Saying that `int[3]` has no associated namespaces is a uniform rule.
Scott Meyers is writing Modern Effective C++. Should be out soon. http://isocpp.org/blog/2014/03/effective-modern-c-book-status-scott-meyers 
From a practical point of view, you first need to consider the platform versions your product must support and the native C++ compilers on each of them. For a reasonable set of C++11 features, your need to be using gcc4.5, clang3.2 or Visual Studio 2012 on every platform you wish to support. Otherwise you probably don't need to bother knowing about C++11 at this point because your code won't work on any platform that doesn't support these versions. Nonetheless, you certainly don't wanna be using raw pointers and C arrays even in C++98. You should focus more not on the language but on the libraries. Mastering the STL goes a long way. Also keep an eye on boost. Oftentimes you'll find a boost library that does exactly what you need in a clean and modern C++ way.
&gt; Also he argues that using a linear search is faster than a binary search because of the huge performance boost of prefetchers. You misunderstood, he explicitly on multiple occasions mentioned that doing a binary search would improve the performance. His point was that even though it was using the naive linear search the performance was still better. However I will certainly agree that the actual access method broke list due to being not lined up well with how list performs.
Correct, Windows x32 and x64 exclusively here and Visual Studio. Really no cross-platform concerns for the foreseeable future. Certainly a fair point on the gradual progression thing. Though a lot of what I wrote was so early on my learning of C++ that I cringe any time I open it and want to just burn it all down :) It's that ugly. And it's not so many lines that it would be impossible. But we'll see, I may start on writing modern code on some smaller side projects and then go back to revamping the bigger stuff once I've got more down pat.
&gt; His point was that even though it was using the naive linear search the performance was still better. Better compared to what? My understanding is that he was comparing it to an std::map, which is required to be a binary search tree and typically implemented using a red-black tree. But in fact, a linear search is not faster than a binary search regardless of whether it's on a tree or on an array. Binary search outperforms linear search beyond a couple hundred ints.
Meyers will get you almost all the way there IMHO, add in a little Herb Sutter to fill the gaps: http://herbsutter.com/ and you are rocking it. 
I live exclusively in Windows x32/x64 land (primarily the former) for the foreseeable future, so Visual Studio 2012 - or whenever I hop on 2013.
`make_shared` is more efficient since it can allocate the object and the control block in a single allocation. `make_unique` is no more efficient, but fixes a memory leak in the case of `f(new A, new A)` (even if `f` takes two `unique_ptr`s, the compiler can allocate both `A`s, run both constructors, then construct the `unique_ptr`s, resulting in a leak if the second `A`'s constructor throws). Mostly it's just that it's much easier to verify that "never use `new`" has been followed than "only use `new` when you're absolutely sure it's safe".
What is the problem with that? This has a good reason, so you can be sure the object is not deleted, until you have done everything with the pointer. If you type something like auto ptr = myWeak.lock(); this makes sure that the underlying object is not deleted before ptr is out of local scope. I think its a pretty nice solution. I actually have no idea what you want to achieve with your observer_ptr...
Would like to correct that: "only use new when your writing your own resource managing class AND you make sure, its perfectly safe". Because programmer assume far to fast that "its safe"...
The best part about C++ is the library, and you need templates to use it, so learn about templates. Use the standard containers and avoid C-style arrays. Use references; avoid pointers (but you will need them occasionally). Avoid Boost; it is for advanced users only.
Sorry for asking: I don't quite understand... `std::shared_ptr` and `std::unique_ptr` are nullable. `std::optional` is a type which is nullable for NON-pointer types, for instance `std::optional&lt;int&gt;`
That's the point of the weak pointer, you only get the shared when you want to use it, and check if the object is still available before using it. Then, the shared pointer is released when you exit the scope. If you need to access it all the time, you certainly need to use a shared ptr instead.
The basic problem that it's solving is that if a function returns a bare pointer, you don't know whether or not you need to delete the thing it returned without checking the documentation, while an `observer_ptr` explicitly signals to the reader that it doesn't own the thing it points to, but it otherwise identical to a bare pointer. In the long term it seems unnecessary (since you should be adapting the convention that a bare pointer *never* owns the thing it points to (except within the implementation of a smart pointer)), but I could see it being useful when modernizing an existing code base that uses owning bare pointers.
Thank you. I'll keep this one in mind if I need a singleton without static lifetime.
Didn't say it was a problem, just that it was the only use I'd found. Another reply points out a second use which is quite interesting.
I have to say that keynote presentation by Stroustrup was excellent, just finished watching it. The bit about people writing "ghastly style" code because it's what they see in some examples and only can reference ancient books or other novices strikes *very* close to home. Until now my naive view of things was that if you want nice abstraction, easily safe code, and helpful libraries.. that's the land of C# etc. C++ is the land of scary incantations and cryptic code. Really quite nice to get this refreshing perspective, and *the guy* for C++ basically saying, "Don't do this low level or cryptic stuff unless you need to... there are much friendlier solutions."
I appreciate the note on Boost. I see it mentioned quite often, but wasn't sure if it was something I definitely *should* be using or am better off avoiding for now.
In addition to separate allocation overhead and worse locality it's also exception-usafe, see: http://herbsutter.com/2013/05/29/gotw-89-solution-smart-pointers/ // note that #3 applies to `make_shared`, too
The point of those smart pointers is to assure the object pointed by them is valid, that's why you "convert" the weak pointer to shared, then test if it isn't null. You're observer_ptr could point to an invalid object since you don't use ref count.
Personally I'd strongly recommend the books listed here: http://isocpp.org/get-started In particular, "C++ Primer" (5th Edition) by Lippman, Lajoie, and Moo is excellent -- it doesn't just cover the syntax, but smoothly integrates C++11 throughout, together with a lot of good best-practices advice. Videos, as the one you've discovered, are actually a pretty good source, too. For more high-quality C++ talks see http://channel9.msdn.com/Events/GoingNative/ Lectures by Stephan T Lavavej are awesome: http://channel9.msdn.com/Tags/stephan-t-lavavej For more choices, see also [The Definitive C++ Book Guide and List](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) (it's also mentioned in the sidebar).
The only way you'll really learn C++ is to consistently talk to people who use it. Get their ideas and feedback, and see what they're doing. If you don't have 10 years available to master C++, you could surely master a handful of other languages instead.
If you're into numerics (and I'm assuming you might be since you're coming from MATLAB), I'd actually *highly* recommend using Boost -- especially since often the only practical alternative would be rolling your own libs (or using some ghastly C-style lib, like GSL). In particular, Math Toolkit is extremely useful: http://boost.org/libs/math (IMHO it's a good example of how this is the _easier_ way to proceed if you want to solve problems and get things done -- reinventing the wheel, especially in numerics, is what I'd consider to be the experts-only area). Most of the Boost libraries are header-only, so they're also one of the easiest ones to install and deploy (no build systems / dependencies / makefiles, etc.). For more, see: http://boost.org/doc/libs/?view=category_Math In addition, data manipulation tasks can certainly benefit from libs like [Boost.Filesystem](http://boost.org/libs/filesystem) or [Boost.Range](http://boost.org/libs/range) (that being said, I'd actually agree that it's good to first become thoroughly acquainted with [`&lt;algorithm&gt;` and `&lt;numeric&gt;`](http://en.cppreference.com/w/cpp/algorithm), since their knowledge is commonly assumed -- and for very good reasons). So, yeah, Boost is definitely worth looking into! That being said, there are more libraries worth looking into. For numerical linear algebra in particular I'd strongly recommend Eigen: http://eigen.tuxfamily.org/ It's very fast, header-only (again: no installation / deployment hassles) and has a user-friendly syntax: http://eigen.tuxfamily.org/dox/group__TutorialLinearAlgebra.html Here are the docs: http://eigen.tuxfamily.org/dox/ In particular, you may find this one handy, since it contains MATLAB translations: http://eigen.tuxfamily.org/dox/AsciiQuickReference.txt
&gt; vector using a linear search outperformed std::map Yes, I know he said that. std::map is a binary search tree. What I'm saying is that it doesn't outperform it. You can run a benchmark yourself to see that the claim is false.
Are you claiming he falsified his data, or that he asserted that linear search could outperform binary search? The former is an odd claim, so I will assume the later, but it will be a bit repetitive. He never claims that linear **search** outperforms binary search. He only claims that the overall algorithm outperforms std::map.
Easier said than done :) That is at least, talking to someone in person. We only have a handful of experienced programmers at work... myself and another guy are quite proficient with Matlab but are much more classical engineering background than computer science. The senior application developer is more CS than classical engineer, but is mostly focused on C# / .NET and by his own admission hasn't touched C++ in ages and hates it! (Thus propagating my earlier belief that C++ is a scary place full of dragons, to be avoided at all costs). But for better or worse, C++ is something I need to know. Conversation with my manager last fall basically went like this: **Me:** *Well, to do X, Y, and Z, we really need to write our own library for this solver.. and we don't have much time to get some functional prototype together* **Manager:** *Okay, I agree - so how do we do it?* **Me:** *From what I can tell, pretty much needs to be C or C++ .. but nobody here is proficient in either.* **Manager:** *Well, you're on own here if you want to take it on yourself, which would be great. Alternative to farm it out to the software vendor isn't cheap and will have a long lead time. Good luck.* So here I am!!
In this particular application I've worked on most recently the math is actually quite straight forward. Sine of this, cosine of that, arctan of another thing, raise it to exponent and add it to some other value, etc etc. With that said there's *a lot* of much more hardcore number crunching which I do in Matlab and my end users are reliant on many times a day, every week, all year. There was no way on earth I was going to re-write my own libraries for it (generally not a big fan of reinventing the wheel), so as an interim solution we wrap it all up in a compiled .NET library (built from Matlab's deployment tools.. which ultimately still rely on their MCR, JVM, etc) and plug it into some of our existing software. It certainly gets the job done.. isn't super fast but isn't unacceptably slow either. Longer term I could potentially see re-writing some of this in C++ directly, especially if Boost or these other libraries do have some good stuff for numerics. Thanks!
Just to clarify, what was the actual cause of the 60% performance regression on haswell? My current understanding is that the 128 bit store couldn't be forwarded to the 256 bit load, even though they overlapped. Or was it due to something else? 
It's important to keep in mind that boost is a *collection* of libraries, and there's a lot of variation between them. Some are high-quality, widely applicable things that really should be in the standard library (and in some cases have become part of the standard library), and those you'd benefit from using from the beginning. However, the documentation doesn't really separate them from things like low-level support libraries that are pretty much only relevant to people writing the "end-user" boost libraries, or from the libraries that would be broadly applicable if they were easier to use, but in practice are only usable for C++ experts.
Other way around - the 256 bit store couldn't be forwarded to the 128 bit load in the next iteration of the loop, while the two 128 bit stores could.
No of course not he absolutely did NOT falsify his data. What I'm saying is that the benchmarks are misleading because he's comparing using an std::map vs. an std::vector for use cases where it is already well known that an std::vector outperforms an std::map. But because the presentation doesn't make that clear, a lot of people in this comment section as well as else where are getting the wrong impression that an std::vector outperforms an std::map even for "large" data sets. It's simply not true. &gt;He never claims that linear search outperforms binary search. He only claims that the overall algorithm outperforms std::map. An std::map IS a binary search tree. That's the purpose of an std::map, it is a data structure that implements a binary search tree. And no, linear search on an std::vector does not outperform an std::map, which implements a binary search tree except for smaller data sets that contain maybe a couple of hundred elements.
Because weak-pointers only work for objects owned by shared pointers, which rules out the use with the stuff that it was actually created for. Further reading: [Proposal by Walter Brown](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3840.pdf)
&gt; Avoid Boost; it is for advanced users only. That is just wrong. While it is often nice to just use the stdlib, boost is usually the best fallback if something is missing (like filesystem, network or until C++11 threads). Unlike many other libraries boost follows the stdlibs conventions closely and offers many usefull things. The main problem about boost is that it is quite strongly interdependent which is one of the reasons for it being able to hugely increase compile-times. 
I plan on learning clang and gcc - I know one of those 2 is a little behind...is there some other compiler I should consider using that supports most of 11 or 14?
But at least I know for sure that it is not my responsibility to delete the object it points too.
&gt; Don't do this low level or cryptic stuff unless you need to... Somewhat relevant: [I posted something about how highlevel isn't slower a few days ago. \(including a short comparison at the generated machine-code\)](http://www.reddit.com/r/cpp_questions/comments/21s5zm/is_there_a_way_to_make_inline_member_functions/cgg41n4) 
I have heard the "prefer std::vector" mantra so many times and since it tends to come from people who know c++ way more than me, I have tried on several occasions to replace std::map with std::vector (e.g. boost::container::flat_map, Loki::AssocVector) but in all cases I reverted back to std::map or std::unordered_map after observing poorer performance. So in my use cases at least, I haven't found situations where a std::vector provides faster searches.
About halfway through this so far.. pretty good, very interesting. The bit about ratio of CPU vs. memory performance now seems *very* relevant in context of the other talk floating around here.. discussing how great pre-fetch is when you have memory to be accessed sequentially.
Couldn't agree more - something like that would be extremely useful.
What's your degree in? MechEng where I went to college there wasn't really a coherent focus where you'd gain proficiency in any one particular language. You touched on many - an approach which to this day I question, but the department believes / believed was the way. Freshman year intro to computing (2003 for me) we touched on Java, some other professors / sections did VBA. Sophomore year in applied math classes anything that was learned in Java went out the window in favor of Mathematica. Junior year computational methods all of that went out the window and you got waterboarded with Matlab. Etc, etc. So by the end of all that you have a very partial and scattered grasp of things, maybe you remember how to do a for loop and do plot(x, y). But as far as actually being able to do any practical programming - forget it. As a result -&gt; teaching myself Matlab over the subsequent years. Really only knowing that language and having no concept of unmanaged memory *or even static typing* can make for a bit of a rough transition.
I think everyone is thinking the same. If they don't share the videos this is a bad thing, rather than a good thing, for the C++ community.
Code not working consistently is way more annoying than a couple of using-declarations.
My undergrad is in IT and I'm working on a Master's in computer science. The CS department does a bit more C++ but every department teaches Java as the primary language, to the point where, when given a choice of language on a project, everyone chooses Java because they haven't been given the opportunity to learn others. I think there's some theory in that school that Java will take over and literally everything will be programmed in it within the next decade. Here's hoping that's not the case--part of the reason I moved on to CS was because I want to program, but not in primarily Java. I had an offer as a Java developer a couple months before I graduated undergrad but I eventually turned it down, partially for that reason and partially because when I researched stats on starting salaries for that position in similar types of areas, they were offering way too little. Anyways, since starting CS I've learned Matlab, and I'm doing all my cryptography assignments in C++ (by choice). In undergrad I got a bit of exposure to Perl and Bash but those aren't quite the same thing.
&gt;Concerning new: Don't use them! You don't mean `my_obj a = new my_obj(param_a, param_b)` do you? &gt;Concerning delete: If you need to write delete, you almost certainly did something wrong somewhere. Always use the stack or appropriate smart-pointers. Could you expand on this? I thought one of the aspects of C++ was that you have to manage memory. If not delete, how do you manage memory? Did I miss something?
That is why he means by `new`. You avoid writing `delete` by using stack-allocated objects when possible, `unique_ptr` when not, and `shared_ptr` when you actually need shared ownership (you rarely should).
Clang 3.4 supports all of C++14. GCC 4.8 supports nearly all of C++11 (missing &lt;regex&gt; and a few minor things).
thank you
You can try Ceemple, it's a new software based on c++. The advantage is that the code is very easy to write, like matlab, but the final result is in c++. www.ceemple.com
I would also suggest to follow these up with [Modern C++ Design](http://www.amazon.com/Modern-Design-Generic-Programming-Patterns/dp/0201704315) by Andrei Alexandrescu, which really opens your eyes to the power of C++ templates and template meta programming.
&gt; rarely other containers like std::list or std::deque I have to downvote you for this advice - each STL container has certain characteristics which will make it more or less useful for a given problem. Learning each container's characteristics will allow you to make the correct choice of container given a particular problem at hand. For example, `list` is a linked-list. It therefore provides O(1) insertion and deletion of elements, but O(N) lookup. `vector` is a contiguous block of memory, which therefore has O(N) insertion and deletion (linear in complexity to the end of the vector), and O(1) lookup. If you know you're going to be doing a lot of insertions/deletions and not a lot of lookups, `list` will outperform `vector`, and should be your first choice. 
fair enough, but I still don't see the point. 
That's the point of smart pointers...
2013 greatly improves C++&gt;=11 support :)
&gt; You don't mean my_obj a = new my_obj(param_a, param_b) do you? Yes, basically every code that uses new to allocate an object on the heap. There is also a so called placement-new which isn't evil (unlike the above one), but still only for experienced C++-programmers. &gt; I thought one of the aspects of C++ was that you have to manage memory. This is an urban legend. Yes, you can manage all resources manually, but doing so is usually a very bad idea. C++ may not have automatic memory-management, but it has what I call “implicit resource-management” which is in my opinion a way cooler thing because we have to write **less** cleanup-code than we would have to in managed languages. Consider the following Code: std::string synced_read(const std::string&amp; identifier) { auto path = "/base/" + identifier + ".txt"; std::unique_lock&lt;std::mutex&gt; lock{some_global_mutex}; std::ifstream file{path}; if(!file.is_open()) { return ""; } std::string first_line; std::getline(file, first_line); return first_line; } The above code contains no leaks of any kind (memory, filehandles, locks). In managed languages you would have to write much more code for this. The reason for this is that C++ supports cleanup via destructors (RAII), which is usually superior to garbage-collection. Edit: Bugfix: it has to be `std::unique_lock&lt;std::mutex&gt;`, not just `std::unique_lock`
Even if you write your own resource-managing-class, you should usually not use allocating-new but an allocator with placement-new.
what about adding .begin and .end to C arrays ( prob .size also while you are at it :) ) 
fwiw google also bans unsigned ints in cpp code.
I generally hate Microsoft products, but I Visual Studio is really excellent. Particularly the debugger.
I remember hitting the linear vs binary wall even sooner with `std::string` as elements; around 30 or 40 elements for the case I was considering. It may have been due to `std::string` having a bigger foot-print, and therefore being able to stash less objets per cache line. In any case, I much prefer using an algorithm that does not blow out when N grows, rather than trying to micro-optimize the small Ns cases, even when those are the majority. I'd rather sleep on my two ears, than keep worrying about which assumed small N is gonna blow my code up.
This doesn't technically answer the question, which is not about what happens when the mutex is destroyed while being held, it's about what happens if the mutex is destroyed after someone has unlocked the mutex but before they leave the unlock() function.
except that you don't - const &amp; unique_ptr works just fine so long as you never need to hand off ownership. The only problem is that unless I read the spec wrong it is writable since it's full signature is const&amp; unique_ptr&lt;Foo&gt; not const&amp; unique_ptr&lt;const Foo&gt;. Can someone clarify since I don't think there is a way to pass a unique_ptr somewhere with a guarantee that the function can't modify the contents (like you can when you take a void* and pass it as const void*). The only thing const does for unique_ptr is guarantee that ownership can't be transferred.
If not new, then how? I'm sorry, I'm learning a LOT reading your guys responses in this reddit. What happens to `path`, though? How does the runtime environment know that once we get out of `synced_read` that `path` is no longer necessary (as GC would do) and then remove it from memory?
come on... here is an example since I get downvoted each time I post something... With your observer_ptr, you test if it's null before using it, but then the object gets deleted somehow because your observer_ptr doesn't have ownership. If you would fall in this problem, you'd have to make sure the object isn't deleted (in another thread) when you access it, and that's exactly what weak_ptr does. About the relation to unique_ptr, I'll reply to your other post.
Pretty sure that's already undefined behavior for the same reason that destroying *any* type while it's in an active thread of execution is undefined. Interesting bug though... seems counterintuitive that you can't destroy a mutex that you just verified was not held!
It's actually ok to pass raw pointer to functions if they don't require ownership, or const ref. [read this](http://herbsutter.com/2013/06/05/gotw-91-solution-smart-pointer-parameters/).
Right, it's clearly undefined if you are still inside the unlock() function. But it's also possible that the very, very last thing in the unlock() function is releasing the lock and there is no further work and thus no chance to be caught in the mutex's code when it gets destroyed (perhaps the only reason this bit the Linux kernel is that it has to manually go awaken the first person waiting on the lock).
This "standard" would drive me nuts, I usually promote the opposite. To the people who bring up the performance and memory footprint implications of this I say this: ever notice how the performance of your code is dominated by a few critical sections? Your making your life much more difficult if you write every line of your code like it's an inner loop... Our focus should be on correctness first, maintainability second and then performance. The last thing I'd like to say is that if you focus on correctness and maintainability it's amazing how often you get performance without even trying.
I see the concept of observer_ptr as being effectively a const * created from a const &amp; unique_ptr. Not my idea honestly I'm just exploring the space. OP was the one who suggested observer_ptr.
&gt; Concerning new: Don't use them! &gt; Concerning delete: If you need to write delete, you almost certainly did something wrong somewhere. Okay, I know nothing about C++ anymore. Isn't the point of C++ to be able to use pointers and manage your own memory?
std::deque is often implemented using an array.
Thanks for this! I'll have to give Fusion a look.
In all likelyhood, there will be some complimentary information in Eric's GoingNative presentation as well: [Compiler Confidential](http://channel9.msdn.com/Events/GoingNative/2013/Compiler-Confidential) &gt; Modern CPU and instruction set architecture improvements are critical to the performance of software, but it's the compiler that can make your code sing. Come learn how compiler optimizations are enabling the next generation of native code performance. This talk will go deep into the guts of the Visual C++ compiler optimizer, focusing on compiler optimizations from the point of a view of modern CPUs. Down to the metal we go!
A mutex cannot guard the object that owns it. It can guard other data inside that object, but not access to the object itself. For the same reason, a mutex cannot guard itself. Debugging this when it does happen is never fun, since it's generally a race condition that ends up crashing occasionally inside unlock().
&gt; If not new, then how? 95%-99% of the time: Just throw it on the stack like in the code above. There is no advantage of any kind but many disadvantages in creating stuff on the heap, if it could just be local: std::string good = "The metadata are all stored on the stack, the actual string on the heap"; std::string* terrible = new std::string{"This put's the metadata on the heap too, adding an expensive allocation and another layer of pointer-indirection"}; auto still_bad = std::make_unique&lt;std::string&gt;("At least this one doesn't leak"}; &gt; What happens to path, though? The destructor cleans up the memory: Since `path` is not heap-allocated the compiler knows the exact lifetime and will insert a call to it's destructor which will call the appropriate function to return the memory to the operating system. This has in fact the great advantage over GC that we 1. don't need a complicated runtime that figures stuff out that is actually known at compile-time 2. don't waste memory that is no longer in actual use but not yet collected by the gc.
&gt; Isn't the point of C++ to be able to use pointers and manage your own memory? The point of using C++ is that it is a beautiful language that offers sane and intuitive behavior once you understand the basic concepts of it, learn about what features are suitable for what application and forgot all the insane design-decisions that Java and the like made and are now considered as “truly” OOP. Now, this is my personal opinion and the primary reason for my love of C++ (I don't really care about performance that much). And yes: I am 100% serious with that! For an answer that is less of a rant: C++ offers manual resource-management, which is a very important thing in order to implement efficient data-structures; the main purpose of the language is however the added ability to wrap these data-structures into fast high-level-interfaces so that it becomes very easy and nonetheless fast to use them. Bjarne Stroustrup calls C++ a “lightweight abstraction-language”: This means that you are able to create extremely easy to use abstractions that cost almost nothing. Well written C++ has an abstraction level that is WAY above everything that Java offers.
Then how are objects not representable by a literal initialized? From what I understand of your explanations, the stack allocation is used by avoiding new and instead using literals, though from what I have heard a (string) literal is the same thing as `new string("hello")`? Or is that just in languages like C#? So saying that C++ requires programmers to manage memory is a relic of the language then if modern style avoids primarily heap allocation? I did some research into stack and heap differences so I'm definitely learning a lot!
I always though that the beauty of C++ was that it was simple, and that you could use pointer to manage memory manually. Now, it seems that doing that a bad practice in C++, and everything seems overly-complicated. But I haven't been doing much in C++ for a long time, I know as much as I did when I was first learning it a few years ago.
looks interesting, its built ontop of armadillo which is nice and easy to use, matlab like but faster, what do they use to for scalability? mpi? pthreads? some other message interface?
std::mutex is likely a wrapper around the platforms pthread_mutex. On Linux this is the lock/unlock code for pthread_mutex: https://github.com/heyc/glibc/blob/master/nptl/lowlevellock.h It does suffer from the same problem. THREAD 1 holds the lock: mutex_lock(obj-&gt;lock); dead = !--obj-&gt;refcount; THREAD 2 calls lock: mutex_lock(obj-&gt;lock); ... if (atomic_bit_test_set (mutex, 31) == 0) return; atomic_increment (mutex); THREAD 1 calls unlock: mutex_unlock(obj-&gt;lock); ... if (atomic_add_zero (mutex, 0x80000000)) return; THREAD 2 continues lock: while (1) { if (atomic_bit_test_set (mutex, 31) == 0) { atomic_decrement (mutex); return; THREAD 2 is able to return from lock and free obj: dead = !--obj-&gt;refcount; mutex_unlock(obj-&gt;lock); if (dead) free(obj); THREAD 1 wakes up to finish unlock and ends up accessing freed memory pointed to by mutex: lll_futex_wake (mutex, 1, // XYZ check mutex flag LLL_SHARED);
Boost is a good one stop shop for 'easy to use' libraries. Many are simply headers to include. http://www.boost.org/
You are half correct and half incorrect. What you may not realize is that on linux or mac at least, the package managers already do allow you to "get" the libraries you want in the form of source or precompiled libraries. For XML for example, you may want to look at libxml (http://xmlsoft.org/) which on my machine is pacman -S llibxml2 but for your distro it could be different. Many of these libraries are C (libpng is another one for example) but not all. Usually when you install it, you'll get headers and a library to link to. I've used bundler/eggs/npm and what have you. It is true that there is no "central server" for *all* C++ or C libraries. Just many decentralized ones. Honestly, there are pros and cons to this. When a central authority, you have to think about things like what you do if that central place gets compromised, hacked, or ddosd (see npm for example). It's much safer in general to get code directly from the originator, before it's exchanged many hands and undergone several transformations. The other issue is that package code that needs to be compiled natively versus code that runs in a VM or bytecode interpreter is very different. It's more challenging to bundle software for arbitrary target hardware. It's challenging enough that there are many alternatives for build systems and none of them get it quite right. Cmake and scons probably come closest and then there are numerous backends like ninja and make that solve other problems (building the dependency graph, etc). tl;dr people have thought about this. It's harder for C++/C than it is for other languages like Ruby. *edit, typo and added last sentence to second paragraph.
&gt; His thesis is that C++ is unique among languages like Java and C# in that it can really exploit prefetching and caching and hence you can use a vector as your default container. He didn't say that. He even said you could exploit structs and unsafe code in C# to get the same performance benefits. What he said was that C++ makes achieving this simple, whereas in C# you have to fight the type system a bit, and in Java is just isn't possible. (Of course there are other languages; he didn't mention anything about them.)
You'll be happy to hear that the committee agrees with you and are working on "modules" for C++! You can find a decent amount of information on google.
Well, for qt you already have most basic stuff (like xml parsing), for the rest you have inqlude.org. When I write just "pure" c++, I just use my distro's package manager, like patchill says. And how does the random package managers for node, ruby, etc. let you discriminate between "industry standards and random weekend projects? 
I also have some questions on your slides. * Why do you use std::for_each on slide 45 instead of range-based for? Is std::for_each very useful anymore given range-based for? * On slide 14, are you trying to show a 1-to-1 correspondence python and C++ statements? The C++ code could be shortened by using std::accumulate: &gt; auto mean(const Sequence&amp; seq) { &gt; return std::accumulate(seq.begin(), seq.end(), 0.0)/seq.size(); &gt; } 
Good analysis, thanks.
Yes, seems it boils down to this. Thanks for the thoughts.
Will modules make it easier to find (central repository) and use (compiler/OS independence) good libraries? My understanding of that is currently, no they won't. Not even when finally supported around 2017 or later. 
Well, first, what do you mean by "random"? They're community maintained official repositories. The latest version of Python even adopted "pip" as a standard feature. npm for Node and gems for Ruby are not "random package managers", are *the* package managers for the language environment. If you search for "xml" among node libraries, for example (https://www.npmjs.org/search?q=xml), you can see how each package is voted (number of stars) and used by the community (number of downloads). The same goes for Ruby gems (http://rubygems.org/search?utf8=%E2%9C%93&amp;query=xml). For Ruby, there is also a semi-official site that analyzes and gathers those metrics (https://www.ruby-toolbox.com/search?utf8=%E2%9C%93&amp;q=xml). Search for xml and you'll see, for each project, how many downloads it has, how old is the last commit to the project, when it was first released, and so on. The very same thing goes for Python. Even if they didn't have centralized repositories, when trying a packages is as hard as writing &gt; pip install someXMLPackage import someXMLPackage it would be much easier to try out one that might work for you. Mind that all these package managers work both for python/ruby/javascript code **and** for native code. Yes, they do compile C libraries under the hood, resolving their dependancies and handling different OS before installing the python/javascript/ruby wrapper. Ignoring the thing that this is being done now with success by projects much younger than C++ (node is a 4 year old project, C++is in its 30s) and that it *is* a time saving convenience, is just hiding the head under the sand for no rational reason, I think.
It makes it easier to build a search. Go lacks centralization, but has a great searches at http://go-search.org and http://godoc.org -- as well as other places I am sure. These search and documentation points reference the real Github, Bitbucket, Code sites the source lives at... Central repository is not the only answer to this question, and IMHO, isn't even a great one. NPM started falling down, then requested (borderline blackmail it felt like) money to run their servers from the community and is now is looking to get corporations to pay again. 
A good "bundler" alternative for C/C++ would have to: - Manage compiler versions and compatibility. - Support cross compilation. - Support multiple build systems. At least Autotools, CMake, Scons, and old-fashioned Make. Probably more. - Manage dependencies. - Define a "package" format for a complete, isolated package of binaries (both dynamic libraries, executables, and dependent data files). Think OS X .app's but for system-level binaries. - Be a standalone binary itself that doesn't rely on a specific scripting language. Some binary packages are difficult, because they hardcode paths at install-time. Some packages assume that they are the only version running on the system. All in all, it should be possible, but it's hard.
&gt;You can find a decent amount of information on google. Oh, the irony 
I thought that initiative was primarily LLVM's? Or was it the committee's first?
It is like anything else. Dependency management is a feature of the IDE. You can go without an IDE and roll your own - just like all other IDE features such as multiple windows, debugging, code completion, etc. 
There's not one for C#? NuGet does exactly this. In fact, it supports C++ as well, but only for Visual Studio projects of course.
No, you don't have to build everything yourself. &gt; pip install mercurial This will download the mercurial package, *build the C dependencies*, and place it in Python's path.
I stand corrected :)
True.
&gt; Think OS X .app's but for system-level binaries. There's frameworks on OSX / iOS for this exact thing. First thing I do when wanting to use a particular library - compile the library in question for all intended target architectures (I use separate frameworks for OSX and iOS - simply because you can't use shared libraries in iOS targets) and then use a little script to copy the headers and library into a framework with an appropriate name. Using it then becomes as easy as clicking in Xcode to refer to the framework. The closest analogy under Linux would be a single directory containing library, headers, data and pkgconfig configuration information that you can just point to and compile / link against. 
Frameworks are slightly different. They're meant as development bundles (i.e. both libraries, debugging information, headers, etc.), not necessarily deployment binaries. A native app bundling framework would have a different but similar purpose.
&gt; Well, first, what do you mean by "random"? &gt; &gt; As arbitrary and different for all languages, not official distribution package managers. Well, of course they are different, because we are talking about different languages. We are talking about Python libraries that must go in your site-packages directory, or about Node packages that you can install either in the global node_packages or in the local one. We are talking about supporting rvm for Ruby and virtualenv for Python. About installing libraries *and* headers for C/++ because it has the concept of "headers" that other languages don't have. How could you have one system for them all? &gt; So you have to build everything yourself? What an enormous waste of time when you have distributions doing this for you. Waste of time? Build by yourself? What are you talking about? The only shorter thing to writing pip install PACKAGE / npm install PACKAGE / gem install PACKAGE is my computer telling me "Ser, I sense like you want to work with PACKAGE today, I already installed it for you". Unfortunately, we're not there yet.
https://packages.debian.org/search?suite=wheezy&amp;arch=amd64&amp;searchon=names&amp;keywords=xml%20dev A better question might be why everybody feels the need to re-invent the wheel continuously.
&gt; They're meant as development bundles (i.e. both libraries, debugging information, headers, etc.), not necessarily deployment binaries [Not really](https://developer.apple.com/library/mac/documentation/macosx/conceptual/BPFrameworks/Concepts/WhatAreFrameworks.html) - OSX system libraries like the UIKit and other services are frameworks. It's not exclusively development. 
This is indeed a problem with C++. I believe the main underlying issue is the lack of binary compatibility across C++ compilers/standard libraries. Whether you can use a C++ library from a given compiler is can be dependent on what type of compiler the library is compiled with, the compiler settings (debug vs release), and what the standard library is. Taken together this severely complicates making libraries that just work. Node, Python, Ruby, do not have this as they are interpreted languages and if you make a library, you can reasonably expect it to work with other libraries. The proposed module extensions to C++ will NOT solve this problem, as they do not provide cross-compiler compatibility. I am currently working on finalizing a solution to this issue. I already have a library that allows you to create a library that can be from different compilers and standard lib implementations. I am finishing work on a package manager. I plan on presenting this system at my C++Now talk in May. http://sched.co/1fTIPo6
You are not alone my brother. (In my thing I mention Python but this really covers many higher level languages) I have been happily programming in C++ for years, and I too was enjoying the new idioms such as the excellent for loop for iterating through things. But then I hit upon Python. Now my code is 90% python and 10% C++. Generally Python does exactly what you are describing, it just works (95% of the time). But the reason I bring this up is not just to blah blah about Python but to say that the C++ leaders need to think. My productivity with Python is massive and one of these factors is due to things like pip. But one of the arguments against things like Python is the fact that C++ is so much faster. Well keep in mind that a good desktop can process at around 7.5 Teraflops. This is as fast as the most powerful machine in the world in June 2001. So what happens is that for many things a language like Python can do things in the blink of an eye, while C++ will do it in a blink of an eye that might even be 100 times faster. So while for many things C++ is still the only way to go, I find that what you are describing with the libraries also even applies to the syntax. Templates should make our lives easier, but instead hard core C++ types are making template code that I simply don't understand. It is just a mess of brackets and whatnot that does something simple but has somehow made it hard. I would say that C++ has been heading in the wrong direction for a long while. Things like QT have been trying to reverse that direction but the risk is that if a language like Python can ever produce better shrink wrap code and maybe even embedded code (Can you imagine an Arduino like chip with embedded Python?) that C++ might find itself with a significantly dwindling user base. 
Strangely, I have not really had problems with this, at least on OS X. Macports has ports of most of the C++ libraries I use (Boost, Eigen, Intel TBB, ffmpeg, etc.). It essentially serves as the npm/gems/rocks/whatever equivalent for C++. The only time I have issues is when a library (usually not well-written, but useful nonetheness) is shoddily-ported to OS X, requiring me to manually patch up a few header files.
well, build everything that can be built...
I never needed to use any other package manager than apt for Perl, Python, C/C++ and Java (actually all languages I know).
And there are several for Python.
Then make a repository for C++ :) 
&gt; Pretty sure that's already undefined behavior for the same reason that destroying any type while it's in an active thread of execution is undefined. Is that really true? I believe `delete this;` is legal, defined, and used fairly commonly. The only caveat is that you must not look at the `this` pointer in any way after the object is destroyed. 
yeah your right its linked to MKL by default on all intel processors that can support it. You can do the same with armadillo if you'd like as well, it just requires more work, https://gist.github.com/bdsatish/5646151. Matlab is faster in prototyping however
&gt; armadillo if you'd like as well, it just requires more work, Yeah and an MKL license. That said, the likes of OpenBlas and ATLAS (and so on) aren't far off MKL.
&gt; Define a "package" format for a complete, isolated package of binaries (both dynamic libraries, executables, and dependent data files). Think OS X .app's but for system-level binaries. You are just describing Linux package formats, except portable. Hell, Archlinux packages are just compressed folder trees of the content in the FS layout with a text document of dependencies and metadata. The problem is the binaries in that package are never portable, so having a portable package format seems moot. Only Windows doesn't have a format for packing binaries, libraries, and dependencies.
thanks for sharing!
I guess what we could really use would be a site that collects libraries that are high-quality, still maintained, use modern C++ and follow the stdlibs conventions: * No C-libraries * Use of move-semantics where appropriate * copy-ctors that really copy (aka: **deep**) * Naming-conventions: Consistency is the most important one here, so please do what the stdlib does * plattform-independence if at all possible * No language-extensions in the interface
The C# BCL and general Visual Studio IDE experience have spoiled me immensely. By comparison, as I'm trying to pick up Visual C++, it's just not even close IMO. Not to mention if I *do* end up needing something I grab it from NuGet in seconds.
Unfortunately, nothing seems to have happened in the last two years. [blog](http://isocpp.org/blog/2012/11/modules-update-on-work-in-progress-doug-gregor) [last known spec](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3347.pdf)
I've found that the repo versions of packages can be drastically out of date, especially if you're working in Ubuntu LTS or a similar distro. In these cases you either have to track down a PPA with the latest version of the package you want, or just use pip. Like it or not, many projects move much faster than a distros maintenance cycle, making packages in apt nearly useless unless you've particular requirements that allow for an ancient version of a package.
Use: certainly. Find: well.. being easier to publish would be a step into the right direction
Any debugger is more useful than VS. 
Although nuget is available as a standalone exe, so if you really want you can use it without msbuild.
Well, building ruby/python/js code is dramatically faster than building C++ code of similar complexity. Usually, production quality libraries are compiled with heavy optimizations enabled. I think the original poster was referring to the build time itself, not how long it takes to type a command. It is true that some of them will compile and link C code through some FFI (aka oilypng or something) but this REALLY is not comparable to a general build system. Each project probably manually includes scripted directions to do this and I doubt they'd be able to bundle a heavier duty C/C++ application without doing something really hacky. FYI, I find your tone generally offputting :P. It's fine to voice criticism and complain about things, but I don't think you're nearly informed enough to feel as strongly as you do about anything.
&gt; JavaScript: npm &gt; Java: Maven Not standard. RubyGems and Luarocks don't look standard to me, though I can't tell for sure. For C++, there are OS package managers that will install C and C++ libraries such as pacman. They are not standard for C++, but they are "standard" for the OS in question. &gt; Shell: Nothing &gt; &gt; ... &gt; &gt; In conclusion, C and C++ are the only languages other than Prolog in this top 20 list without a standardized package manager So is 'Nothing' a shell manager?
"Standard" as "everyone who wants to use a package manager for this language uses it", not as in "there's a formal specification". It is very easy on Linux only if you only care about a single version of a single distribution, and don't mind having no control over what versions of the libraries you use.
&gt; So is 'Nothing' a shell manager? Yes. It is a symlink to /bin/true and has packages for all but a handful of shell libraries.
That's exactly what std::array is.
STL is incredibly useful! Each of the developers you've listed there have issues with the STL in very specific ways related to the requirements of their primary problem domains. 
here are a couple tweets recently from Carmack. "I don't like STL much and rarely use it, but I do really like standards. The library situation with C++ is really a shame." and "You don't use STL where you need max performance, but performance isn't the top priority for most code, even in games." well if there are areas that you dont care about getting every single last ns out of it, why dont you use STL? I agree, it saves time. There is a lot there. Also I've heard in the last few years STL has really made some great changes internally (exception safe). 
"Linux package formats" is not really a clear term here, I think? Which are you referring to? .deb/.rpms? Those represent single packages and not a full, isolated software distribution (i.e., they cannot be installed in an isolated subdirectory in parallel with other independent packages). To fill out the space that Bundler et al represent, our hypothetical package manager must be *isolated* from system packages, and ideally it should not have to rely on binaries for distribution (i.e., you can distribute a single source package that describes its dependencies and that can be deployed to multiple servers of many architectures and built as needed).
This is because C++ libraries often target specific systems. C++ is a systems language where you sooner or later call native API's. There's no standardized XML libraries because writing one for Windows is different that writing one for Linux. Yeah there are a few that are cross-platform but they have large chunks of system specific code. If you're writing XML code on windows you'd just use COM and MSXML2. On Linux you'd pick one based on your requirements. Some are big and complete, some are small and have less features.
Don't know who Blow is, but * Carmack is a game programmer, and requires every minute performance gain possible from the engine. STL isn't great at that because dynamic memory allocation is a bear. I work in RealTime Embedded C++ and we do all dynamic allocations before we go to "run mode" because of this. * Torvalds is Torvalds. He's opinionated and is a C guy. Of course he doesn't like the STL. He's also an OS guy, and historically OSs have been the domain of C as they also need the best performance necessary. The STL has come a long way; the initial implementations were slow, buggy, and sometimes incompatible. It also was hard to troubleshoot syntax errors as the compiler output was a bear. Since they were standardized and have matured they're much better, and modern compilers have improved the error message situation greatly. 
&gt; Am I alone in this? No. Herb Sutter talked about this a bit last year at Going Native in his talk [Keynote: Herb Sutter - One C++](http://channel9.msdn.com/Events/GoingNative/2013/Keynote-Herb-Sutter-One-Cpp). Somebody queried about it as well during the interactive panel, but it was brought forth in an awkward way by Charles and got dismissed in the end by Herb as "more news tomorrow" which ended up just being a hand wave about NuGet, which is a non-solution to the general problem. You're getting the expected replies in this thread: it's a hard problem, and specific languages don't need their own package managers. I'm not saying that these people are wrong, but sometimes worse is better and ecosystems like pip, npm, gem etc. are valued by their users for a reason. Oh, and boost exists! Yes, you should look into boost when you're looking for a library, but plenty of us avoid boost for a reason. In the end, it's just another one of those incidental complexities that we have to deal with as programmers. It's a lot easier these days, but still everything is strewn about multiple sites, on GitHub and BitBucket, CodePlex and still sometimes SourceForge, hidden on an implementers website, etc. As nice as it is to daydream about some ideal world where this isn't the case, I don't see it happening at any point in the near or far future.
Funny, I just submitted [this reply](http://www.reddit.com/r/cpp/comments/22eoiu/what_bothers_me_about_c/cgmlax7) to that post, which contained a minor point about how I felt NuGet was a non-solution. You're right that it is a start, and I am happy to see that NuGet exists and is being used.
NuGet for C++ suffers from the same general problem as linux packages or homebrew/macports/etc. in that it only addresses a single platform. OTOH, it doesn't suffer from the other problems that Linux package managers have (most of which derive from that they're designed for managing system-wide packages).
Carmack's gripe with STL also was some years ago, he recently admited perhaps today he would be not so no-no about STL
The STL's distro is located at [http://nuwen.net/mingw.html](http://nuwen.net/mingw.html). &gt; but plenty of us avoid boost for a reason Could you tell me what reason? The Boost libraries contain lots of macros, that's one downside I know, so debugging is difficult. Are there more?
This is the same concept, but allows you to **build the string with a stream** rather than a comma delimited list. Maybe a bit OCD / pedantic, but I prefer creating strings with streams rather than variadic function templates. It works by having a single `template ostream operator` which streams the input to an internal `std::stringstream`, and then access to the underlying string is via 2 implicit conversion operators, one converting to `std::string`, the other to `const char*`. #include &lt;iostream&gt; #include &lt;sstream&gt; #include &lt;stdexcept&gt; class concat_string { public: concat_string() {} // streaming operator template&lt;typename T&gt; concat_string&amp; operator&lt;&lt;(T t) { _os &lt;&lt; t; return *this; } // implicit conversion operators operator std::string() const { return _os.str(); } operator const char*() const { return _os.str().c_str(); } private: std::ostringstream _os; }; int main() { try { throw std::runtime_error(concat_string() &lt;&lt; "Help " &lt;&lt; 5 &lt;&lt; " " &lt;&lt; std::fixed &lt;&lt; 22.0/7.0 &lt;&lt; ", I've fallen and I can't get up!"); } catch(const std::exception&amp; e) { std::cerr &lt;&lt; e.what() &lt;&lt; std::endl; } return 0; } **Output:** &gt; Help 5 3.142857, I've fallen and I can't get up! **Your examples would then become:** - `std::string date_string = concat_string() &lt;&lt; year &lt;&lt; '-' &lt;&lt; month &lt;&lt; '-' &lt;&lt; day;` - `unlink(concat_string() &lt;&lt; "/var/tmp/user-" &lt;&lt; getuid() &lt;&lt; ".lock");` - `throw Error(concat_string() &lt;&lt; "Unable to open " &lt;&lt; path &lt;&lt; ": " &lt;&lt; errno);`
IIRC the committee is interested too. In order to avoid another debacle like `export`, the committee is hesitant to (or maybe they flat out wont ever) accept features that haven't been implemented by any compiler.
It actually won't be more efficient - they will be exactly the same. The reason is because `std::stringstream` uses `std::basic_stringbuf`, which in turn defines `__string_type`: typedef basic_string&lt;char_type, _Traits, _Alloc&gt; __string_type; and uses `__string_type` for it's underlying storage: __string_type _M_string; `std::string` and `std::stringstream` both use `char` and `std::char_traits` as the template parameters for `std::basic_string`. Hence, the underlying storage in `std::stringstream` is a `std::string`, and therefore, both grow at the same speed. (Above code snippets taken from `gcc-4.8.1`: `/usr/include/c++/4.8.1/sstream`)
what resources did you use to get into C++11?
Certainly one of the most elegantly crafted libraries in Boost in my opinion, and I think that's very high praise, since all their libraries are of the highest qualities. I think they made a good decision.
Perhaps. Now that you mention it we do something similar in Qt/KDE code a lot (usually with this-&gt;deleteLater due to event synchronization concerns but almost the same idea).
A lot of that is because a few of of the libraries are far too general. It's like instead of a library to do something they've written a library which you can use to write a library to do that something. Some more concrete code for common cases would be nice instead of a library which you have to finish yourself in order to be able to use sensibly (simple example: a simple random range function using boost::rand. It's three fairly obtuse lines to implement and makes it so much easier to use the library. Why is it not in the library?)
Very true, we use Ubuntu at work, and seldom do I actually get to just apt-get something. Recent examples were Gcc and doxygen
The most important takeaway is that it's important to think about how data is arranged and managed when approaching a problem. There are a lot of material about Data-Oriented Design available that is worth reading (I'm actually kind of shocked that /u/hpsutter never said "data-oriented design" in his talk, given that three-quarters of it was basically a DOD primer in disguise). e.g. http://dice.se/wp-content/uploads/Introduction_to_Data-Oriented_Design.pdf and http://gamesfromwithin.com/data-oriented-design
no std array has horrible syntax, esp for multidimensional arrays... and yes everything is syntax sugar, please dont use that as an argument, since for loop is a syntax sugar for a while... we may remove for loop also... and i++ since we can increment i by 1 using good old i=i+1; if somebody can give me a good reason why c arrays werent extended and instead we got templated class std:array please do tell, but please dont use argument if it can be done in library it should be done in lib not in core lang.
You're essentially right. If it's not in the stdlib, I go to Boost (which is basically the "apocrypha to the stdlib") and then I start apt-cache searching around. I just about always find something in the Debian repos which has at least a slightly higher level of reliability than "this source code I found on this forum." Now that I think of it, I'm not sure how I would go about developing on a PC or Mac. Let's hope the issue never arises...
I love vectors, maps, and even sets; those are great examples of templates. When those came out I was happy. Then when the new for loop made iterating through them easier then yeah. But then boost came along and every library seems to be written to impress some CS professor instead of for human consumption. I started using boost and then said, screw this and stopped. My thinking is quite simple. My desktop right now is a powerhouse, a mad mans powerhouse. In 5 years it will be yardsale junk and my phone will be of similar power. Years ago I wrote C++ with ASM optimizations; Now I write Python with C++ optimizations; and soon I suspect I will write XXXXX with Python optimizations. The XXXXX will make me 5 times more productive than I am now. I heard a story from the guy who grew Blockbuster into the monster it became. He had maybe 200 BBs at the time. He was at a video rental conference and over and over mom and pop operators came up to him and told him the 1000 different ways their stores were better than his. He said something like, "You are 100% correct, except that I have 200 stores and will soon have 20,000 stores." Another good one was a Google programer talking about the founders' code saying that neither would be hired into Google now with that code. 
Why is this being downvoted? This is indeed a version of the cppreference docs that is (IMO) much easier to read and navigate, especially on my phone. Each page has a notice with a link to the original website, and cppreference is released under a permissive license that allows for modification and redistribution. So it's not like the developer is stealing content without attribution. It would be nice if the code listings were given in the interactive environment used by the original website. But as it stands, I like the design as it is already.
Because Microsoft? All the solutions for other languages discussed in the other thread were multiplatform.
boost::xml::parse? No way, better have Property_tree ಠ_ಠ
No, Microsoft doesn't factor into my sentiment. I was agreeing with the submitter that the solution was not ideal, but at least a start. That it exists at all is what I am thankful for. I don't even use VS for my C++, so I have never used NuGet. If you had read my other post, you would have seen that I held up the solutions for other languages as positive examples.
I looked into using NuGet for a C++ project and could only find http://coapp.org/tutorials/building-a-package.html. Does anyone know of more compete documentation?
This sounds so reasonable and I just wanted to bitch about Boost because is cool.
We'll, if you're on a Mac, use Xcode. 
And I suppose, if I'm on windows use Visual Studio. Thank you for that insight. 
Alternatively, Boot Camp Windows and just always use Visual Studio.
Sorry, couldn't resist. :)
Google's house style is fucking whack, don't look to them to be the orator of style.
I tried to use it for something a bit complicated a few years ago and found the documentation lacking. For a lot of the functionality you have to read the source and tests.
In my experience Xcode is buggier but its UI is vastly better in general. VS2012 has made a couple UI improvements that are pretty significant to me, but still has a ways to go IMO. Some random examples, in no particular order: - I like Xcode's inline warning/error messages. If a diagnostic comes with a fix-it there are key commands to automatically apply it. ([example](http://stackoverflow.com/q/5325278/365496)) - Visual Studio's build output and error list windows are separate and not well integrated. VS's build output is just a plain text view. Xcode displays its full output nicely so the full command and its results are easy to read ([example](http://stackoverflow.com/a/18173138/365496)). It's also filterable so you can easily narrow the results it shows. - Visual Studio's properties window is terrible. It's not searchable, it's not resizeable, it always defaults to showing just the active configuration/platform, it can only show a single configuration at a time (or a merged view of all configurations), it doesn't show where values are inherited from, etc. Here's what Xcode does [instead](http://meandmark.com/blog/2011/03/xcode-4-accessing-build-settings/). - If you're writing a console program the fact that VS doesn't integrate at all with any kind of console is a pain, leading many beginners to dumb solutions like `system("pause");`. Xcode has an integrated console, and also helpfully saves the results in its log navigator so you can go back and see previous runs. - I really dislike tabs in VS. VS2012 added the ability to single click to view a file without opening a new tab every time, which helped a lot, but I still don't really like having tabs correspond to open files. When Xcode introduced tabs I was worried they were doing this too, but it turned out they went with having each tab be a workspace (e.g., like vim tabs), which I like much better. - I dislike VS's behavior of shuffling the UI around between modes, and how if I make a change to the UI it only applies to the mode I happen to be in. In Xcode you can control the UI shuffling behavior via the ['Behaviors' dialog](https://developer.apple.com/library/ios/recipes/xcode_help-alerts_preferences/Recipe.html#//apple_ref/doc/uid/TP40010508-CH1-SW1). You can nicely integrate this with Xcode's tabs. - Xcode provides a nicer interface to breakpoint configuration, and LLDB's integration with python is nice. some of Visual Studio's pros: - more stable than Xcode, and features are generally less buggy. - more configurable code formatting (although not as good as clang-format) - better plug-in ecosystem - some handy features like integration with remote symbol servers 
STL is a double sided coin, both good and bad. A bad I came across was using the c++ lib assimp. It fucking crashes and burns unless you add these STL options _HAS_ITERATOR_DEBUGGING=0 _SECURE_SCL=0
I'm all about tabs and splits, xcode makes this so difficult
Because not everyone runs debian. (Yes, yes, I know, LSB, yadda yadda. But have you ever installed a .deb on a distro that doesn't have the package in question but that *does* have `deb`?)
&gt; Linus is low-level developer, he prefers to write C over C++ because he wants to know what the assembly representation is by just looking at the code :-) No, he prefers C [because it keeps the shitty C++ programmers away.](http://thread.gmane.org/gmane.comp.version-control.git/57643/focus=57918)
That problem is already solved in a near perfect way by Nix package manager. Just a simple introductionary example: let pkgs = import &lt;nixpkgs&gt; {}; stdenv = pkgs.useGoldLinker pkgs.clangStdenv; in with builtins; stdenv.mkDerivation { name = "myproj"; src = ./.; buildInputs = [ pkgs.re2 pkgs.libyamlcpp]; } Save it as "myproj.nix" in your source tree which already can be built with any common build system and then just "nix-shell ./myproj.nix" and that is it! You'll be dropped in a shell, with Clang is configured as default compiler, Gold linker set as a linker and RE2 and Yaml-CPP libraries installed and available for immediate use with no additional '-I' flags required. And rest of your system (or even other projects with similar .nix files) are not affected by this change at all! It can't be done in easier way, have a look at Nix, it is awesome, once you try you'll never go back. PS. To install nix just do as a user "curl -L git.io/nix-install.sh | bash; . ~/.nix-profile/etc/profile.d/nix.sh"
all that (and more) is solved by Nix package manager, check my answer above
[Blow =&gt; Jonathan Blow](http://en.wikipedia.org/wiki/Jonathan_Blow), a game programmer. /u/jenison-condev was probably referring to [this talk](http://the-witness.net/news/2011/06/how-to-program-independent-games/) where he talks about pragmatic approaches to writing code in game development. Don't remember specifically what he said about STL. He's less about performance, but probaby still factors that in (the data structure tracking the frame-by-frame timeline in Braid probably didn't use an STL container).
&gt; I've found that the repo versions of packages can be drastically out of date, especially if you're working in Ubuntu LTS or a similar distro Of course a LTS version will contain older, known working software. That the whole point of such a distribution. You want a stable environment and as few as possible risk of breaking changes and new bugs. It you want all the new things it's the wrong distro for you.
This seemed like one of the most interesting C++-themed Google Summer of Code projects, will definitely check it out.
No arguments there. I typically only want the latest versions of whatever development stuff I'm using at the moment, which tends to be easy enough to compile as needed. The rest of the stuff is fine to be whatever version the maintainers provide, save special circumstance. The biggest reason I got 12.04 LTS was to avoid some of the junk coming from Canonical these days. I really either have to ween myself off of apt, or just get Debian itself. If anyone has a few good Debian based distros with no Ubuntu lineage let me know, there's nothing keeping me on Ubuntu, save familiarity.
Visual Studio is great for C# work. Xcode is great for Objective-C work. Both are slightly above adequate for C++ work.
Yes and that is exactly boost.
In my experience, Xcode is nicer (better designed, uses Clang by default which means great autocomplete and error messages, etc.) but is a massive memory hog to the point where it can become almost unusable due to disk swapping.
Still holding out for the rest of C99. Slackers.
Yep, tabs all the way.
Most Boost-libraries certainly meet all these requirements, but there are some other libs that are also very nice and do the same like png++. One could also add a section „violates the stdlibs naming-conventions but meets all other requirements“, which would really extend that.
Try using it on a memory constrained machine! I actually commented about this on one of the XCode mailing lists. In the end I had a brief affair with Eclipse but that was cut short by nasty Eclipse bugs. I program a lot less now and that has resulted in a greater willingness to use other IDEs and experiment. One thing that fascinates me at the moment is iPython and the web interface. It is a concept that might be interesting built around C++ and the required libraries to support similar behavior. Obviously I'm dreaming a bit here but right now I avoid XCode and haven't been near Visual Studio in years. On the Mac I've been using AquaMacs some, though EMACS isn't my idea of an IDE, however it is bug free relative to XCode. 
Never tried Xcode but KDevelop is way better than VS at the moment. The semantic color feature is so awesome, and the autocompletion is smarter than the VS' one. Also highly customizable, integrated with git/svn/whatever and tons of plugins.
If you had to set those macros to get your code to not "crash and burn" then your code was probably broken. Iterator debugging is there to help you find bugs, you're not doing yourself any favours by sweeping what it fings under the rug... Granted, there may actually be a legitimate bug in the debug code, but that seems far less likely...
Can you use nix to build for windows?
&gt; Google's house style is fucking whack, don't look to them to be the orator of style. sure, you and STL are correct, rest of the GN panel and Google are the insane ones... to make it more specific: i prefer to be able to substract sizes without special casing for the case when diff is &lt;0 
Sometimes extreme increases in compile times and binary sizes, even when only including one or two headers.
So, it's by no means trivial, but you can definitely acheive this. Basically, the idea is to do something like this: template&lt;typename T, std::size_t N&gt; struct Vector { T data[N]; template&lt;typename... TArgs, class = typename std::enable_if&lt;validate_me&lt;TArgs...&gt;::value&gt;::type&gt; Vector(TArgs... args) { // Initialize here } }; Where the trick is that `validate_me` is a variadic template metafunction the returns true if and only if the paramters passed are acceptable to you (in this case, only if they are all of type T and if there are N or fewer of them). You can read up on template metafunctions in the Boost.MPL documentation if you are unfamiliar. This will properly SFINAE fail to match as you would expect. IE, if you give it the wrong number or type of parameters, instead of giving you some kind of static assertion fail, you will just get the usual no-such-constructor error. Ninja Edit: /u/rybxjfpq below gave a good starting point for whatj the validate_me I proposed might look like.