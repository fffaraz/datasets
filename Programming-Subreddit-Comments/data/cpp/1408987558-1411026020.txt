Typedefs don't create distinct types (is_same will report true). char16_t must be a distinct type (is_same must report false when comparing char16_t to anything else).
With Windows, you're almost lost. There is only one possible solution and that's [msys2](http://msys2.github.io/) which is a bit like Arch Linux but for Windows. There is a fairly good chance that it will in fact work just like Arch Linux. That means update packages and sane default paths.
&gt; With Windows, you're almost lost. Actually no, that's kind of the point. By including the source for all the dependencies such that all you need is a compiler with the standard libraries, I have 0 issues. CMake generates a VS solution which builds perfectly. Works on a totally virgin windows system, only needing visual C++. &gt;There is only one possible solution and that's msys2 which is a bit like Arch Linux but for Windows. After working on porting a large linux program to windows, I came to absolutely loathe doing any kind of nix-emulation on windows. I'm much happier doing everything platform-independent. In my case, I have all standards-compliant code, the only exception being the boost::filesystem libraries which I have building along with the source. I think forcing users to set up msys/mingw is much worse than just packaging some extra source and building everything natively.
Indifferent on the article, but can we all stop using the ___ considered harmful phrase? Spend ten minutes thinking up something original.
I'd call it more of a multimedia library. I don't believe it helps with physics, entity management, resource management, etc.
It is now featured in ISOCPP's home: https://isocpp.org/ https://isocpp.org/blog/2014/08/cpp14-garcia
Can you give me an idea why that matters ? If a compiler does what the article says, what changes would the user/creator of a lambda function see ?
The parameter type taken by the lambda would be fixed at the point of the lambda expression, because the template class would be instantiated at that point in order to instantiate an object of that type. Since it's the member function that's the template instead, instantiation is done when the member function is used, and so the template can be stamped out differently for each different use.
What about statically compiling all libs and ignoring system libraries?
What if he's the packager too, and are not developing open source applications, and don't want to depend on certain distro libraries ?
Not a very good overview, couldn't you cover the cost-value tradeoffs of using these different techniques? There are some high profile serialization libraries that are also not mentioned here. Where are FlatBuffers?
I'd like to try it sometimes, but having no linux support (as well as some other important platforms being missing that other things like e.g. SDL support) is a real bummer.
On Linux, BSD, etc it's easy: just use system libraries and you are done On Windows, or if you want to build your dependencies, you can use ExternalProject_Add. Check [winstng](https://elpauer.assembla.com/code/winstng/git/nodes) to see a rather complex example.
Good point. I saw cross-platform and assumed Linux was one of them. It seems fairly rare to see Mac supported but not Linux when making claims of being cross-platform.
Sorry to hear it didnt work for you on Linux, we have many users working in Linux and ourselves develop mostly in linux, and we have not encountered such a problem yet. Would you please post your issues in the forum.biicode.com with detailed steps you followed in the installation so we can try to help? Thank you!
I did a search and found this: http://channel9.msdn.com/Events/GoingNative/2013/Herb-s-UI-Challenge Not directly about cinder, but the fact that people could pick it up and immediately do anything at all is pretty cool. Edit: here's another where he does actually use Cinder. It's at around 55 minutes in. http://channel9.msdn.com/Events/GoingNative/2013/Keynote-Herb-Sutter-One-Cpp
I have used Biicode under different Ubuntu versions and never had such problems :S
For the record, my statement of the deb package not conforming to Debian guidelines is based primarily on the existence of the command "`chmod -R a+rx`" in the `postinst` script, which is a *huge* red flag, and is not at all appropriate for any package to ever do under any circumstances (for a variety of reasons)... Especially since it's redundant (all the files in the package already have the execute flag set, another red flag). (Also, why are you shipping a copy of pytz? Every Linux system is basically guaranteed to have the tz database installed anyway, making this a pointless waste of space.) ... And you're shipping private copies of a ton of things that are also part of any standard system - any LSB distribution should work fine if you just use the system libraries. Yet more wasted space. Notably, the version of libreadline you ship with biicode is broken on systems with Bash 4.3 or later. IOW, you're shipping a package that's probably terminally broken to start with. If you guys go back and re-read the debian packaging guidelines and fix the glaring problems with your package, I might have a chance of giving you the information you need to fix the "Cannot open self" error I encountered. Also, I'm on Arch Linux, if you care.
I believe CMake can do this with the concept of [ExternalProjects](http://www.kitware.com/media/html/BuildingExternalProjectsWithCMake2.8.html). It can download, unpack, build, and then link a specific revision of version controlled source code hosted internally or externally. For an example of this in use see [OpenChemistry](https://github.com/OpenChemistry/openchemistry)
A better reference: http://www.parashift.com/c++-faq/serialization.html Other frameworks: [s11n](http://s11n.net/), [cereal](http://uscilab.github.io/cereal/) 
I have used cereal in a couple projects it is fast, and easy. I have used it for binary which is extremely fast and also json output for user editable structures.
It works with two caveats: your total size is generally bigger and you don't get to update 3rd party code without rebuilding.
&gt; What's really hold this back is the lack of a standard ABI... This is an often-heard complaint, but somewhat I disagree with it. C++ lives in the native world as opposed to bytecode one, so machine code it is. Then you get the freedom between the compiler implementations, which serves optimizations. Name mangling is a batch, too, but that is one bit I see as "subjectable" to standardization. Finally, this all stems from C language who has no ABI whatsoever (de jure). The C++ "ABI" is therefore one of: * C * the likes of COM * one compiler version / build settings This already offers options. The thing is, people want the power of C++ and the ease of, I dunno, Python. That is **hard** to achieve.
This is the one I use for all my projects in OpenGL and C++. Usually with a bunch of Git-submodules in order to get none cmake packages. Only downside to using submodules is that you have to code specific build code in cmake for most projects. 
That was in response to a guy who complained that his company didn't use the standard library.
nix maybe? ed: actually for windows doesn't look like its supported. 
"Spending Ten Minutes Considered Harmful"
correct, but the theme of "outdated tools" is common enough to warrant the same reply, IMO :-)
Just to nitpick :P std::vector&lt;int&gt;&amp; add_one(std::vector&lt;int&gt; &amp;v) { for(auto&amp; it : v) { it += 1; } return v; } I think `it` is a really poor name here. `it` is conventionally a short form for iterator. The whole point of range based for is that it is not an iterator. `i` would have been better.
Has anyone used both Cinder and OpenFrameworks? How do they compare?
g++ work quite hard to ensure a [consistent ABI](https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html), also clang is compatible with certain g++ ABI levels
I added the following contents since the last update: - [Project management with Projectile](http://tuhdo.github.io/c-ide.html#sec-5). Projectile got a new command that allows you to switch between .h and .c/.cpp files anywhere in your project, not just current directory with stock Emacs command with ff-find-other-file - [Debugging with GUD - Grand Unified Debugger](http://tuhdo.github.io/c-ide.html#sec-9-2)
Do you still need to write **std::**hex even if you're using namespace std? Because this guy does this in [his first video](http://youtu.be/Z42YZmepbBE?t=3m48s)
They do pretty much the same. OpenFrameworks is easier for non coders, no templates, no smart pointers etc, the api almost doesn't look like c++. If you have some c++ experience, or you want to learn c++, go for Cinder. It's much cleaner in my opinion.
Pulling in complete namespaces with using directives is usually a bad idea since it might lead to name clashes (e.g. of a local identifier `hex` with `std::hex`), so being explicit is better. In is not *required* in the example, but good style. 
&gt; On the other hand, keeping std::pair used by std::map lets you call some functions without converting, for example std::swap. Not sure how to use `std::swap` with pairs coming from map. They are really `std::pair&lt;const K, V&gt;`, I gues swap would not work with them unless type `K` can be swapped even if its `const`.
Can anyone tell me reliable way how to serialize a `double` or `float` (or `long double`) into binary format cross-platformly? I guess its very hard because floating types have not defined "binary representation". Not all platforms are using IEEE format. So far best way (by my opinion) is to limit myself to specific platform(s), or to save floating numbers as two integers - significant and mantissa.
No, he does not need to write the **std::** before hex.
If the platforms don't have the same binary representation for floats then odds are high that there are numbers on one platform that simply can't be represented on the other; perfect serialization is going to be impossible. There *is* a standard format for serializing floating point as binary, and it's IEEE 754. Might as well use that - it'll make serialization easy on all sane platforms, and you can do best attempt / lossy conversions on others.
Only if he needed to qualify that he wanted **std::hex** instead of something else named **hex** that was visible in that scope. In that video, it was unneeded.
I'm going to be that guy who complains about curly braces being on a new line. Just goes against my preference, except when using initializer lists.
Maybe they could implement `char16_t` as `struct char16_t{/*stuff like operator+()...*/}`, but maybe this is not possible for some reason. Think of auto conversion/promotion rules, etc.
I think in practice it's extremely reliable. x86, x64 and ARM devices are all binary compatible (little endian and IEEE-754 compliant), and they make up the vast majority of the market (Windows, OS X, iOS, Android, and current consoles). It's really hard to stumble on a consumer device that is not, basically only the PPC-based consoles and some MIPS routers are optionally big-endian. And they still support IEEE-754, so it's a matter of flipping the bytes. So yeah, go ahead and send binary floats!
I would guess the non-cpp languages supported by protocol buffers.
&gt; * Added Support for list values, including lists of mesaages, when parsing text-formatted protos in C++ and Java. For example: foo: [1, 2, 3] It's official, Protobuf now better than JSON. The one thing that's still missing is the ability to define your own types. What I want is to be able to type this: position: { 100, 20, -50 } instead of this: position { x: 100 y: 20 z: -50 } But, I guess with the new list type, I can at least use this now: position: [ 100, 20, -50 ]
How does Meson differ from [GYP](https://code.google.com/p/gyp/)? What I like about GYP (and what I don't like about CMake) is that it allows me to generate perfectly usable Visual Studio projects that don't differ from handwritten ones. As long as I keep adding source files to the GYP project, I can generate working Visual Studio and Xmake solutions and makefiles as well. The downside is that the common build file looks like [this](https://bitbucket.org/knight666/utf8rewind/src/7e05f5e66a1480fe5fec3290961ffa17764b6357/build/common.gypi?at=default).
One way of looking at Meson is that it's like Gyp but with a saner syntax (and built-in support for a bunch of more stuff). Meson generates VS2010 and XCode projects too, but to be fair they are not as polished as the Ninja backend.
Sure it's a lot of work, but many many other libraries (SDL, SFML, love2d, ...) do support android, iOS and linux, which makes cinder a non-option for me. For a "basic 2D framework" to not even support OSX/windows/linux (and maybe android/iOS on top of that) nowadays means I'll just go straight to one of the alternatives that let me get more out of the code I write.
&gt; The problem with these managers, however, is that there's only a few packages available. Agree, but it's a one man project, yet :) You can contribute or at least file a [bug](https://github.com/ruslo/hunter/issues) with the name of package you need. &gt; I'd embed it right into the repository (deps/) The problem with this approach is that if you have two libraries which have the same dep then you have a conflict. "A" use boost-1.56, "B" use boost-1.55, "C" use "A" and "B" -&gt; welcome to dependency hell. &gt; For anything larger I would either download it via ExternalProject Good, but if you create a superbuild for one project and now you want reuse it you need to copy all the superbuild files. What if you need to change something (version? link library?) - you need to modify all the copies you made. &gt; on the system's package manager to provide the correct version. Any CMake-friendly solution for Visual Studio? iOS? Package manager that can build static boost with clang sanitizers Linux/Mac?
Xcode is Apple's IDE for Mac OS. You can get it in the App Store. You can also install just the command line tools used by Xcode behind the scenes. You can find them on Apple's developer web site, or if you're on Mac OS 10.9 you can get them by typing the command: xcode-select --install in the Terminal. &gt; bloodshed dev-C++ bloodshed comes with an ancient, bug-ridden, non-conformant C++ compiler. The web site lists Windows XP as the latest OS supported, which is four generations old now. It's a bit frightening to think this software still being used to teach new students. You're probably going to run into problems where some code which works on modern compilers will not work in the lab. If the graders use bloodshed dev-c++ to grade your work then you need to remember to leave plenty of extra time so you can make sure your code works on the older compiler after you get it working with modern tools. You'll also have to put more effort into learning the difference between C++ and bloodshed's idiosyncrasies: just because something works in bloodshed dev-c++ doesn't mean it's correct C++, and just because something doesn't work in that tool doesn't mean it's not correct c++.
[Eclipse CDT](http://www.eclipse.org/cdt/). Plenty of people have mentioned Xcode but it has zero refactoring support for C++ (as of Xcode 5).
&gt;type People type JSON?
For small projects, the Oovcde project uses CLang to parse the source files and find dependencies. It also provides a GUI front end to pkg-config to set up packages. At the moment, it requires each directory to be defined as a component, but that will change in the next few weeks so that components can be assigned to a directory tree. It will create some basic CMake files that may need some hand modification at the moment.
For an introductory class, you should be good with a text editor (Sublime, TextWrangeler) and compile (just as in Python) in a console window. You then compile with `clang++ myFile.cpp` or somesuch command. (See [this answer](http://stackoverflow.com/questions/13752233/using-clang-with-libc-and-c11-from-the-command-line-with-mac-os-x) for more details). In addition to Xcode, there are a lot of cross-plattform IDEs for Mac OS X: * [CodeLite](http://codelite.org/) - looks nice and not too cluttered * [KDevelop](https://www.kdevelop.org/) Cheers!
Clang or GCC combined with a text editor.
Handy for small data collections, especially those for JavaScript. It's hell to write without a linting plugin though.
A couple of points about Xcode. * It's free. * It uses clang, which has some of the clearest error messages I've ever seen coming out of a C++ compiler. 
One more thing, they are moving to github https://github.com/google/protobuf . 
LMAO. The guy is just learning C++ and you think that refactoring is actually relevant.
It uses less memory in the struct...
You have two options: use `new[]` (of course wrapped by `make_unique`) or (not yet standardized) `dynarray`. std::size_t const n = computeAtRuntime(); auto myArr = std::make_unique&lt;MyType[]&gt;(n); std::dynarray&lt;MyType&gt; myArr{n}
Whoa... indeed looks huge to me, too, just as TFA claims.
You are right, thanks! 
mac, windows and linux too ;)
The semantics are clearer. It isn't strictly implemented as a union. It's just a guarantee that only one of the fields will be populated.
Thank you all for the positive comments! I'll try to include the aforementioned tips for my next blog entries. By the way: I've had a look and made some tests with Cereal and I'm pretty impressed how well it performs, even though I had to make some adjustments to target the Android platform.
Git-submodules is all you need. You can make cmake check for the installed dependency version and if not compatible, download and build the submodule. 
Allow me to add [JenSON](https://github.com/hrobeers/jenson). [JenSON](https://github.com/hrobeers/jenson) is a JSON serialization library for Qt5 with a very low code overhead, but allows you to write custom serializers if necessary. (It will be ported to CMake soon)
Clang should be defact on OSX. In fact gcc in a symlink to clang now. Also OSX comes with Vim which is awesome.
No one here has yet mentioned Eclipse CDT. It's really a pretty great environment to work in. It has some quirks if you're trying to do something unusual (I usually work in GCC4.9 even though I'm on a Mac). All of that being said, if you get used to working on a text editor and compiling and linking in the command line you'll find it much much easier to suss out problems with your IDEs.
I have trouble with this level of abstraction. =/
&gt; We are in the 21th century, go out and try a real IDE for a week or two. You say that like you think they haven't. &gt; It means you can rename things easily and refractory your code semi-automatically. All that is totally out of scope of emacs, even pimped like that. It's amazing you'd level that criticism not having tried out Emacs "all pimped like that". CEDET, which these days is built in to Emacs (so, no pimping out needed), has all those lovely refactoring capabilities. They're actually kind of trivial in the context of a programmable editor once you have a parse tree, so people don't make a big deal about it. There are also a bunch of stand alone refactoring implementations out there. It's a common project to embark on when learning elisp, as it is fairly straightforward and well understood.
&gt; Those things are perfectly possible to do in Emacs. It's just that not everyone has skill or dedication to do it. As you can see above, it requires quite a big effort. It's really not a big effort. In fact you can do it with srecode as it stands right now.
&gt; Anyway, just because one guy uses something does not make that the one true solution for everybody else. Ah, so now you're coming around to the idea that maybe a full blown IDE isn't the best solution for everyone. ;-)
Oh, you are free to use whatever you want, you just should know the new generation of tools. The more people know about those tools, the more we will see them implemented.
When you might think c++ can not get less readable - it gets less readable.
What is your basis for thinking that people are likely ill informed about "the new generation of tools"? Do you feel that the tech press &amp; advertising is dominated by discussion of previous generation technologies and products?
This is such an obvious attempt at click-bait recruiting it's not funny. Come on mttd I'm sure you can do a better job at filtering out such things. 
I think I started with manually adding points to create boxes, then I rotated them, moved them, applied texture to them... For testing and developing the algorithm it was all right. Later when I wanted nicer pictures I think I used the [obj](http://en.wikipedia.org/wiki/Wavefront_.obj_file) format.
That's the definitive architecture book in my mind. Mostly because it was the assigned text in college. Bonus: read it with a Hennessy on the rocks.
[Prism: A Principle-Based Sequential Memory Model for Microsoft Native Code Platforms](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2197.pdf)
Most of this stuff is defined in the ABI. A popular one is the [Itanium ABI](https://refspecs.linuxbase.org/cxxabi-1.83.html) although I don't think Microsoft uses it. [Calling Conventions](http://en.wikipedia.org/wiki/X86_calling_conventions), which are part of the ABI, are also architecture and OS dependant.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**X86 calling conventions**](https://en.wikipedia.org/wiki/X86%20calling%20conventions): [](#sfw) --- &gt; &gt;This article describes the __[calling conventions](https://en.wikipedia.org/wiki/Calling_convention)__ used when programming __[x86](https://en.wikipedia.org/wiki/X86)__ architecture [microprocessors](https://en.wikipedia.org/wiki/Microprocessor). &gt;Calling conventions describe the interface of called code: &gt; &gt;* The order in which atomic (scalar) parameters, or individual parts of a complex parameter, are allocated &gt;* How parameters are passed (pushed on the stack, placed in registers, or a mix of both) &gt;* Which registers the callee must preserve for the caller &gt;* How the task of preparing the stack for, and restoring after, a function call is divided between the caller and the callee &gt;This is intimately related with the assignment of sizes and formats to programming-language types. Another closely related topic is [name mangling](https://en.wikipedia.org/wiki/Name_mangling), which determines how symbol names in the code map to symbol names used by the linker. Calling conventions, type representations, and name mangling are all part of what is known as an [application binary interface](https://en.wikipedia.org/wiki/Application_binary_interface) (ABI). &gt;There are often subtle differences in how various compilers implement these conventions, so it is often difficult to interface code which is compiled by different compilers. On the other hand, conventions which are used as an API standard (such as stdcall) are very uniformly implemented. &gt; --- ^Interesting: [^Calling ^convention](https://en.wikipedia.org/wiki/Calling_convention) ^| [^Name ^mangling](https://en.wikipedia.org/wiki/Name_mangling) ^| [^Visual ^C++ ^name ^mangling](https://en.wikipedia.org/wiki/Visual_C%2B%2B_name_mangling) ^| [^X86 ^assembly ^language](https://en.wikipedia.org/wiki/X86_assembly_language) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ck2izz3) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ck2izz3)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Honestly, I've gotten some pretty good mileage by using platform native packaging, pkg-config, and GNU Make (even eschewing CMake). I tend to default to dynamic linking of all libraries, which probably simplifies a lot of issues you might be dealing with. If you really need to be platform neutral, then CMake or autotools might make sense, but I've gotten tremendous mileage just from GNU make.
Agreed. It's just a serious hassle to manage git submodules compared to a cmake file. So I'd like to use them as sparsely as possible. 
what is better in this case: for_each/lambda or a c++11 for range? I guess the lambda is like a function call and will push on the stack each time it's called.
Yeah, I guess it will take some time to get used to nested generic lampdas mixed with templates using parameter packs. At least it makes it easier to write functional code.
Personally, I would prefer the use of for-each in these cases, because the syntax is more intuitive and there is less "line noise" in terms of brackets, braces, and commas.
I strongly disagree with the "How to pass smart pointers to functions" section. There is almost no reason to pass a shared_ptr by value. The article mentions that it increments the refcount which is true. It's also utterly unnecessary. If the shared_ptr is valid, you know that the caller already holds a reference. You don't need to take another strong reference. The only situations where this can matter are: * Another thread may inadvertently delete the object while you're using it * You inadvertently do something in your function that ends up freeing the shared_ptr A contrived example of the second is the following: shared_ptr&lt;Foo&gt; g_foo; void Frobnicate(const shared_ptr&lt;Foo&gt;&amp; f) { g_foo.reset(); f-&gt;Bar(); // boom } Frobnicate(g_foo); But that's not specific to shared_ptr - that could happen with *any* type. If you're running across either of these cases you have way bigger problems then the shared_ptr, so there's little advantage to pass a shared_ptr by value.
Very cool stuff. I assume this is further development on Shevlin Park. Some summary slides here on C++AMP and Shevlin park here: http://llvm.org/devmtg/2012-11/Sharlet-ShevlinPark.pdf
In "How to pass smart pointers to functions", the correct way to do things is most often "don't". In particular, with testSharedFunc, what should be done is testSharedFunc(*sp); Smart pointers seem to make people forget why pointers are bad ðŸ˜‰ And, unique\_ptr will equally crash the auto\_ptr example.
&gt; And, unique_ptr will equally crash the auto_ptr example. Incorrect - you can't call `doSomething(unique_ptr&lt;T&gt;)` with `doSomething(up)`, because `up` is an lvalue, and that would attempt to copy. You have to call `doSomething(move(up))`, at which point it's clear that you're moving from `up`.
 bool IsLeapYear(const int year) { return ((year % 4 == 0 &amp;&amp; year % 100 != 0) || year % 400 == 0); }
I would say single return because then you gain NVRO. However, you can structure it the way you structured the second, multiple-return if you want. Of those two structures, I prefer the second. It is easier to read to me.
There is great name for this if it is in Python: pythonic! I'm a rookie here, is there any, beside *optimization*, term for this in C++? 
I'd say it depends on the function. If it's something more complicated, I'd rather check preconditions and return/throw early and only then consider a single return. In any case, unless performance of this particular piece of code is critical, the most important thing is readability for the next programmer. And safety. So I think sticking to one convention (god forbid: religiously) may not be the answer hereÂ¹. Â¹ Not talking about naming types/apis/whatever.
Thanks JonathanCaves for sharing this widely. I agree that each call to func is evaluated in some order. left-to-right or right-to-left and others are all valid orders. However, that does not change the fact that func(&lt;z0&gt;) is 1 and func(&lt;z1&gt;) is 2 and so on. The result of func(&lt;z0&gt;) must appear *before* the result of func(&lt;z1&gt;) in the list of arguments to the function when the order of expansion of a variadic parameter pack is well-defined.
I'm aware of that, I just ask is there a real philosophy and act as it is in Python and some associated programmers which tend to be **pythonic** "24/7" in their publicly presented code?
temporaries does not matter here...the compiler probably removes them during the compilation...
Temporaries matter for readability. Every single version of the function found in this thread is equivalent performance-wise.
&gt; I don't know Python. For me, this is just the rule to not have temporaries if they are not needed and to have the minimum lines of code needed. @amrix: Python is the language tends to be optimized in running if that code is some kind of *prettyprinted* by its author. Beside that there is a whole philosophy behind which IMHO is "developed" by Python's scripting native. **Pythonic** is elegance mixed with undoubtedly strong knowledge. This entry example of /u/wung is a pure transformation of it to C++ world and I just used to that and miss to not have a name for it. :) 
URVO works well too. As long as you don't construct more than one value before deciding which one to return, you get return value optimization.
This looks really awesome! I hope that effort continues.
Huh. You are right. Learn something new every day. For some reason I was under the impression that URVO required only one return statement. Looks like maybe it actually only requires that all values being returned are rvalues. Is this something that has changed over time and I just didn't keep up? Or was my initial understanding incorrect? Thanks!
There used to be a school of thought that you only wanted a single exit point on your functions. I agree with the potential clarity. However, I don't agree with making this a strict rule, because of potential technical overhead. When I see coders work to leave a single exit point in their complicated functions, I usually also see a lot of crap code left behind in order to accomplish this. In particular, I see things like boolean flags and staggered conditionals. (And for really poor coders I used to see gotos, but those haven't popped up in my production code for nearly seven years now, thank goodness.) In general, I would consider any convention that forces you to add extra variables -- like boolean flags or int flags or whatever sort of flags you feel compelled to use -- a discardable convention. Every time you add a boolean, you at least double the probability of a bug. KISS -- keep it simple, stupid. But simplicity means different things in different situations.
I'm a little worried that the only optimization seen here is *premature* optimization.
Not sure how big impact this would have, but I checked assembly emitted by icc/clang/gcc (thank you, Mr. Godbolt for gcc.godbolt.org !) and the terse version checks for divisibility by 100 first: http://goo.gl/MlVkOb
Haha. Hrmmmm nahh, I don't think so. This is more like just establishing good habits and using your tools correctly. Premature optimization to me is more like spending time and making your code less readable for the sake of optimizing something that hasn't been proven to be a problem. I see how using RVO as a habit isn't measured. But I also don't think it is spending time nor making the code less readable. It's just writing it more correctly and potentially seeing a gain (but not aiming at the gain).
I agree, the standard has always allowed copy elision as far as I know. But I'm not sure if maybe what I had been thinking is a restriction compilers imposed at the time.
Are there any STL implementations of std::map which use an AVL tree instead of a Red-Black tree? I am pretty sure an AVL tree would satisfy the standard.
Coding avl and red black trees was the hardest assignment in my data structures class. Splay trees are a cool alternative; they have a bad worst case but they're much simpler to code. They're still log n amortized and they can actually perform better if a small subset of elements is accessed more often than the rest. 
&gt; Except that code wont compile, due to the fact that you hand in the pointer via const ref and std::shared_ptr::reset is a non-const member function. Read it again. `f` is not modified. `g_foo` is. 
Have you seen http://sourceforge.net/projects/stlavlmap/ ?
My bad.
Why is this in this subreddit? Code is basically written in C, raw pointers, no templated key, value type, etc.
&gt; Code is basically written in C, raw pointers, no templated key, value type, etc What? So code that uses raw pointers, does not uses templates but compiles with a conforming c++ compiler cannot be considered c++ now.?
Well, I'm not saying the article is bad, just that it doesn't really fit in a C++ subreddit, which focuses on the C++ language and novel uses of it. It would be better in a data structures or general programming subreddit.
Can you program in C++ without the C subset?
That has an actual performance benefit. If you're re-using the string on each loop, it greatly reduces memory allocations.
[Almost](http://stackoverflow.com/questions/3082113/calculating-factorial-using-template-meta-programming).
I remember when I first had all those questions asked in your link. Boy, was that guy in for a treat.
In C++ we call this "not braindead". No need to make a cult out of the obvious.
Yes, if it's really performance critical code then yes - try to pass your shared_ptr as reference if that brings a speedup. But everywhere else I prefer by value - mainly to be safe that fuckups like your example won't happen. After all I'm using smart pointers to be safe - not to be fast.
I agree. Probably due to the twisted nature of the code, I totally overlooked the obvious fact that "func" prints the number. I was focused on what "func" returns. As the order of the calls to func is not guaranteed printed numbers are not in a guaranteed order. Thanks for exploding the code. Looking at print(1), print(2), print(3), print(4) I realized what's going on.
I suppose this comes down to a difference in philosophy. Consider the following two snippets of code: vector&lt;int&gt; v; v.resize(5); v[10] = 42; vector&lt;int&gt; v; v.resize(5); try { v.at(10) = 42; } catch (...) {} The first application will likely crash irrevocably (and in debug mode in most implementations, it will fire an assert). The second will catch the error and continue unabated. But in both cases the code is fundamentally broken. I'm much more in favor of the first - if the code is fundamentally broken, we should *fail fast and fix the code*, as opposed to attempting to recover from broken code. Similarly, if you're performing unprotected access via multiple threads to a shared_ptr or doing bizarre things with aliased references, you should *fix your code* instead of using some mechanism to hide its broken-ness.
&gt; you should fix your code instead of using some mechanism to hide its broken-ness. Yes, that's why I prefer to be clear about possible dangers in such cases and usually use raw references/pointers. A ref to a smart pointer gives you a false sense of safety. A raw pointer screams "watch out here". 
I think I know what you are asking. They usually refer to it as "idiomatic C++".
[Eric Niebler](http://www.reddit.com/user/eric_niebler) disagrees in this [blog post](http://ericniebler.com/2013/10/13/out-parameters-vs-move-semantics), and proposes a IMHO much better API, even if it does take some setup.
IMO as long as you keep your functions short and readable, it doesn't really matter. As for this function, I'd write it in a way that treats the most common cases first in order to exit as early as possible (I know, premature optimization...): bool isLeapYear(const int year) { if (year % 4 != 0) { return false; } if (year % 100 != 0 || year % 400 == 0) { return true; } return false; }
Indeed, that's why I choose Multiple returns for this case, it's more readable.
Raw pointers do not necessarily show bad C++ / C with classes. Until something like [the world's dumbest pointer](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3840.pdf) is taken into the standard, they are the best / easiest way to represent non-owning pointers. Especially in circular-referenced data structures like trees (which often hold a pointer to parent nodes and/or the root node) they should not be "forbidden". However, that is not the case in this implementation from what I can tell since nodes only store its children. So it **is** a bad use of raw pointers here.
Might satisfy by it, but why bother if it's worse?
First sentences from the main DLib page: &gt; Dlib is a general purpose cross-platform C++ library designed using contract programming and modern C++ techniques. It is open source software and licensed under the Boost Software License. The introduction contains everything you need to know to get started using the library. Yeah... you may want to actually say wtf DLib is. As far as I can gather, it's a bunch of random classes. It certainly looks like there is some good stuff in there, but I had to go hunting for it. Too many open source libraries suffer from this, unfortunately. 
The numerical algorithms for optimization look very useful. It's a nice collection of the "big guys". Parts of the machine learning, image processing and graphical models stuff looks very interesting too! For some of those things, there's not much open code available, and even less C++ code.
Well, they have a lot of good stuff for different purposes, but its very speciallized. DLib is not a general purpose library. But what I dislike that they seem to have somehow an internal copy of boost: http://dlib.net/dlib/noncopyable.h.html Instead of making it a dependency. Not even sure which version they copied.
For larger functions, single return leads to a mess of a function: if (someCondition) { if (!someOtherCondition) { value = ... } else { value = ... } } if (yetAnotherCondition &amp;&amp; !someCondition) { if (...) { value = ... } else { if (oneMoreCondition &amp;&amp; whyNot &amp;&amp; value != 42) { value = 42; } } } return value; For smaller functions like this, it doesn't matter. I personally dislike the single-line version presented by some people here as I find it is hard to keep all the conditions in my head to understand what the output of the function is (i.e. it's impossible to find a typo or a reversed condition). YMMV. As others have pointed out, single-return is an idiom for managable resource-cleanup. If you have no resources (&amp; in C++ you should always be using RAII for resource management), then multiple-return doesn't hurt so write the most readable code you can.
It has even a small and very easily plugable-in-your-project HTTP server according to documentation
&gt; One key point is that the queue should not grow too large as the provider is placing items on the queue I may be blind (or its just due to strange braces positioning), but where is the limiting for 'full' queue? I can only see 'empty' conditions. If i understand the code correctly, the 'queue' only holds at most one item (ie its full if its not empty). This is pretty bizarre IMO.
It looks to me like the library is actually significantly more documented than most. Dlib is a collection of utilities that makes some things simple.
I was just curious. I would suspect for some type of data an AVL tree would be marginally better. 
There isn't an internal copy of boost. It's just a copy of the noncopyable class, which doesn't even have any code in it. It would hardly be reasonable to require dlib users to install boost to get a tiny thing like that. 
scoped_ptr is still trivial and not worth adding a dependency on boost. There are also a lot of dlib users who take a long time updating their compilers so requiring C++11 to use dlib is also a non-starter right now. Moreover, that was certainly the case years ago when I added scoped_ptr to dlib. But yes, at some point I'll deprecate dlib::shared_ptr in favor of the std:: version. Just not today.
I don't know if the newer versions do this, but I remember for a while OS X came without a compiler. You'd have to download xcode cmdline tools, or LLVM/Clang from the website. I haven't used a Mac in a few months, so I could be wrong.
While I kind of agree, I find tricks like the small string optimisation similarly bad, in terms of unexpected behaviour. Andrew Koenig explains this better than I ever can: http://www.drdobbs.com/cpp/is-optimization-immoral/240151916
If you're using gcc (or clang with libstdc++) there's a similar thing with `std::string` which also uses copy-on-write. If you call [non-const `operator[]`](https://gcc.gnu.org/onlinedocs/libstdc++/latest-doxygen/a00998_source.html#l00853) or [non-const `.begin()`](https://gcc.gnu.org/onlinedocs/libstdc++/latest-doxygen/a00998_source.html#l00614) on a string, it can make a copy. In the libstdc++ source, that's termed *leaked* as opposed to *detached*. Those calls to `_M_leak()` find their way to [`_M_leak_hard()`](https://gcc.gnu.org/onlinedocs/libstdc++/latest-doxygen/a00999_source.html#l00452) which calls `_M_mutate(0, 0, 0)` which forces the string to become unshared and reallocated, all on the premise that it's possible to modify it through the returned reference or iterator, even if you don't. [Yes, CoW for `std::string` is disallowed by the C++11 standard which says that those above member functions aren't allowed to invalidate iterators. But gcc/libstdc++ can't change without an ABI break which would be painful for the Linux world that uses shared libraries.] 
the issues around smart pointer of array types should go away if you use std::array instead of c-style array syntax.
What could have been the rationale of mixing begin and cbegin? Edit: heck, why is it even possible?!
This is guaranteed to be true for all STL containers. Iterators have always been comparable (and implicitly convertible to) constant iterators.
IMO, you should only pass a shared_ptr into a function if that function is intended to extend the lifetime of the shared_ptr. With shared_ptr, in many cases you're likely better of using move + value-semantics instead of shared_ptr (not all cases). Leaving aside the performance reason of why you want to pass by const-ref as one would with C++-03, the code is more readable, re-usable &amp; maintainable: 1) You know exactly at the call site whether or not the object lifetime will be extended or not (no need to dig into the code). 2) The call-site doesn't care how you came to have an instance of an object. Could be a shared_ptr could be a unique_ptr or a stack value. 3) If you change your shared_ptr to a unique_ptr or get rid of it all-together, it's one less function signature you have to fix &amp; change.
Which makes writing your own things to fit STL concepts an even bigger PITA. Even Boost.Iterator has [two](http://www.boost.org/doc/libs/1_56_0/libs/iterator/doc/iterator_facade.html#interoperability) [gotchas](http://www.boost.org/doc/libs/1_56_0/libs/iterator/doc/iterator_facade.html#telling-the-truth) on this very issue, and it exists to make writing iterators as painless as possible.
Key points: 1. grow size by a factor two means no conjunction of previous allocations is sufficient for a new allocation, because sum(0..N-1){ 2^i } = 2^N - 1. A growing vector will always wander forward in memory. Growing by a smaller factor (e.g. 1.5) allows reusing coalesced previous allocations 2. vector should be able to use its allocator's granularity. 3. tagging elements as relocatable allows to use more efficient reallocation First point was incredibly "ahhh!" to me. Trivial in retrospect, but still. 
I disagree with your first point. I think that's a detail best left to the implementation. If you want to roll a vector class with its own growth rate, C++ certainly gives you the tools to do so.
Rolling your own allocator aware &lt;vector&gt; with conforming iterators and operations, and reaching full compatibility with std::vectors interface and exception safety guarantees isn't trivial. QVector proves that. Even if you do so, you're throwing away API-level interoperability with std::vector, which is huge, for the sake of just tiny bit of configurability.
It was [briefly discussed](https://gcc.gnu.org/ml/libstdc++/2013-03/msg00058.html) on the libstdc++ mailinglist, but apparently their measurements are inconclusive.
If anyone is curious, here's how it works in libstdc++: void push_back(const value_type &amp;__x) { if (this-&gt;_M_impl._M_finish != this-&gt;_M_impl._M_end_of_storage) { _Alloc_traits::construct(this-&gt;_M_impl, this-&gt;_M_impl._M_finish, __x); ++this-&gt;_M_impl._M_finish; } else _M_emplace_back_aux(__x); } `_M_emplace_back_aux` is: template &lt;typename _Tp, typename _Alloc&gt; template &lt;typename... _Args&gt; void vector&lt;_Tp, _Alloc&gt;::_M_emplace_back_aux(_Args &amp;&amp;... __args) { const size_type __len = _M_check_len(size_type(1), "vector::_M_emplace_back_aux"); pointer __new_start(this-&gt;_M_allocate(__len)); pointer __new_finish(__new_start); try { _Alloc_traits::construct(this-&gt;_M_impl, __new_start + size(), std::forward&lt;_Args&gt;(__args)...); __new_finish = 0; __new_finish = std::__uninitialized_move_if_noexcept_a(this-&gt;_M_impl._M_start, this-&gt;_M_impl._M_finish, __new_start, _M_get_Tp_allocator()); ++__new_finish; } catch (...) { if (!__new_finish) _Alloc_traits::destroy(this-&gt;_M_impl, __new_start + size()); else std::_Destroy(__new_start, __new_finish, _M_get_Tp_allocator()); _M_deallocate(__new_start, __len); throw; } std::_Destroy(this-&gt;_M_impl._M_start, this-&gt;_M_impl._M_finish, _M_get_Tp_allocator()); _M_deallocate(this-&gt;_M_impl._M_start, this-&gt;_M_impl._M_end_of_storage - this-&gt;_M_impl._M_start); this-&gt;_M_impl._M_start = __new_start; this-&gt;_M_impl._M_finish = __new_finish; this-&gt;_M_impl._M_end_of_storage = __new_start + __len; } The calculation of `__len` calls this: size_type _M_check_len(size_type __n, const char *__s) const { if (max_size() - size() &lt; __n) __throw_length_error((__s)); const size_type __len = size() + std::max(size(), __n); return (__len &lt; size() || __len &gt; max_size()) ? max_size() : __len; } The doubling comes from `__len = size() + std::max(size(), 1)`. (These have been run through the preprocessor and `clang-format` to be somewhat easier to read, so the actual source will differ a small amount.) 
Temporaries tend to *improve* readability. In this very specific case it would achieve virtually nothing, but the rules for leap years are also a lot more complex than this and if you wanted to capture them more strictly the situation might change. Of course, you may be able to define a new function instead of declaring a temporary, but I consider the two comparable.
I was under the impression that std::deque uses that technique (maybe not to the letter, but in spirit, i.e. a list of chunks).
I mean writing a parser that is comformant to the a language spec , and make it right, and fast, is not a trivial effort, especially for language like C++. As far as I know, Srecode is a code generation tool. How can it help me parse and perform static analysis to detect semantic error for a language?
I don't think that using a parse tree and perform static analysis are new ideas for the next generation of tools. In fact, until the tool has dynamic extensibility from trivial to advance tasks, I will consider it "next generation", not by modifying the actual source code of the editor and recompile it to add new features.
Same principle, but the ds described in ORAiSaT has chunks that get exponentially larger as the array grows. The paper actually goes on to detail how to use the same ds to implement efficient (discontiguous) stacks and queues.
I really hope that GCC will take the chance of version 5.0 to do these breaks. It really isn't **that** painfull for a distributor to recompile all the open-source-programs and even for the relatively few closed-source ones this should be manageable. It's not like it would happen often.
Last I checked, Visual C++ also used a factor of 2.
Are there slides of this somewhere? Because after seeing first slide i think my time would be wasted there ... If anyone has a link to slides or just agenda, that would be nice.
You should find the slides in the githup repository: https://github.com/boostcon/cppnow_presentations_2014 The talk it self is actually quite good, but not always C++ centered.
What's the difference between IsRelocatable&lt;&gt; and boost::has_trivial_assign&lt;&gt; ?
So... no allocation on the stack?
&gt; It should probably let you specify the growth factor on construction (with a good default). Nope. Then it would have to be stored, with two negative consequences: (1) the object would be 33% larger, and (2) the codegen for reallocation would be poorer (since it would have to do math with runtime values). Also, since we're talking about non-integral values here, there would be quite a bit of complexity in specifying and using the factor. &gt; This is kind of what std::is_trivially_copyable does. is_trivially_copyable is exactly the type trait to use when you want to ask "can I memcpy this". I have a todo to use this in the STL. Since at least 2008, VC has used a weaker form of this optimization: copy() and everything that flows through the same codepath (including vector reallocation) senses scalars and calls memmove. &gt; copy() and move() algorithms that can be specialised for arbitrary user classes. Nobody does that. There are several reasons why: * Providing algorithms for user-defined types is a whole bunch of work - that's the whole reason they're provided by the Standard Library. * Algorithms care about iterators, not just elements. * There's no such thing as partial specialization of function templates. Anything that looks like that is actually an overload. You're allowed to explicitly specialize Standard templates, but you're not allowed to inject overloads into namespace std. Instead, ADL is necessary, and the Standard must be specified to use the ADL dance. This is done for swap customization (and range-for), but basically nothing else.
I just checked myself and stand corrected. When I think about it, last time I looked it was probably still called "Visual Studio .Net", so I apologize for the FUD.
I don't actually disagree, I just think it's a pain in the arse ;) These days I lean toward Stepanovs position in realising that a lot of this pain comes from the lack of associativity being defaulted in to the language. 
Which would be even more of a reason to ignore them here.
The amount of code-duplication due to const/mutable versions of the same function is painful for itself; we'd really need a more simple version for this, though I have difficulties to imagine how one would look like.
But did you ever test 1.5x vs 2x? Apparently the libstdc++ folks had a hard time improving on 2x (see thread I quoted above).
Dinkumware did, originally. 1.5x is somewhat more work to implement, so it wasn't chosen arbitrarily.
&gt; (1) the object would be 33% larger, and (2) the codegen for reallocation would be poorer (since it would have to do math with runtime values). Not convinced. Since you can't allocate a fraction of a 'T', the exact factor can never be honoured anyway. If it were specified as a hint, a fixed point implementation would provide adequate range and speed, and you only need to perform the calculation when you're about to allocate. Extra storage needed? But you already have 24 bytes! How could you ever need more? ;) First idea that pops in to my head: Overload the size() field such that it holds the factor when capacity() == 0, and copies it to the heap when you first allocate. Storing it on the heap shouldn't have much of an impact since you mostly need it when you're about to grow and touch the heap anyway.
but wouldn't that outcome somehow depend on the relative speeds in the cache hierarchy? I would have expected that such performance tests would be redone from time to time.
Yes - but the last time I mumbled about possibly changing this, many people said they preferred the more conservative space consumption (it's not a big difference, but it's there). I'm not terribly inclined to mess with it.
Well the things I mentioned were about building a proper parser and then perform highlighting based on the parse tree, and perform proper indentation, as written in the link for building js2-mode. You said using the Semantic parse tree, but then that is the result of writing the parser from scrath that generate the parse tree that Semantic can understand and use for its applications. The hard part is writing a usable parser that can output the parse tree.
That *is* a much better API. Now for the Ranges Study Group to propose it...
That was a terrible recording. Unfortunate.
Not in practice unfortunately. It has been known for some time that Microsoft's implementation of std::deque really suffers from having a tiny 16 byte block size: https://connect.microsoft.com/VisualStudio/feedback/details/509141/std-deque-performance-is-sub-optimal https://stackoverflow.com/questions/4097729/stddeque-memory-usage-visual-c-and-comparison-to-others This makes it effectively the same as std::list, with all it's inherent performance problems, for all but the smallest types. On the other hand libstdc++ goes for a more reasonable 512 bytes but that just seems to be an arbitrary number as well. I'm surprised this subject seems to have been so widely ignored for so long.
In order to be trivially assignable, a class must not have a user-provided assignment operator and must not have any virtual functions or virtual base classes. This applies transitively -- all of a class's base classes must be trivially assignable for it to be trivially assignable, and each non-static data member must be trivially assignable. Essentially this means only POD classes. Relocatability is a much more general concept, since it can be signaled by a type trait rather than a list of criteria. For example you might have a class with a user-provided assignment operator, making it non-trivial, but if it's valid to `memcpy()` it you could still mark it a relocatable. 
std::vector already has that problem though wrt allocators. It's not all that different really--you'd not want to have two vectors with different growth rates just blindly swapping content and such. Edit: Of course it's the same problem as telling developers to make a new vector class if they need a different growth rate. You couldn't ever make something type compatible with std::vector, only convertible. I do think that's the right way to go though. If something like this were done, in any way, we'd not want it to be std::vector but some added thing or something...or third party library since I don't see a lot of utility in it beyond what was done with this fbvector thing, which targets a specific and custom allocation library. So I think you're right in that we wouldn't want this change, but it would be feasible to do so without adding a data member to the class.
Thanks!
Yup. And I was honored that this talk was voted Best Presentation of C++Now 2014, especially since there were so many other great presentations.
Great talk. Since you're here, I'd like to ask for a clarification to make sure I understand. Are these assertions true? Sink's are arguments that are held onto (added to a container, or otherwise). Sink's should be passed by value because if the type implements move semantics it will take advantage of it, and it avoids a proliferation of set()ers?
A C++ Now video that doesn't have utterly atrocious audio? What is this? Seriously, pretty much all the C++ Now videos on YouTube are a total waste of space, because they're inaudible.
&gt; Sink's are arguments that are held onto (added to a container, or otherwise). That's one kind of sink argument. Another is when the algorithm must mutate the value -- or some copy of the value -- while it executes. A sink argument is when a copy needs to be made *anyway*, for one reason or another. &gt; Sink's should be passed by value because if the type implements move semantics it will take advantage of it, and it avoids a proliferation of set()ers? Setters really don't have anything to do with it. Taking sink arguments by value is about copying when you need to (i.e, when the argument is initialized with an lvalue), and moving when you can (i.e., when the argument is initialized with an rvalue).
Wait. So, did RES fail me?
Can you be more specific? I don't see any problem with the content.
I don't see any problem with the content at all, which is why I don't want them to get in trouble. It's in the [reddiquette guidelines](http://www.reddit.com/wiki/reddiquette) if you control-f "ratio". You don'e even need to be particularly spammy to do it, and I'm not saying that they are *going* to get banned, but having a single content creator flood a subreddit goes against the community news aggregation ideology behind reddit.
I don't see them posting only their stuff...
Sure, they're posting all the talks from C++Now 2014. I don't know why you're getting so defensive, I'm not saying that this is poor content, rather that this is behavior that may upset reddit admins, and I don't want that to happen.
Not sure why they needed to post each one individually. A single, TOC posting would have gotten the job done and been a lot less annoying.
The main thing would be as Crazy_Eddie says which is that it's better to post a TOC than one video at a time in short succession. Not sure what the etiquette rules say about that.
Why did this need to be a public post instead of a private message? Is there anything you want from people who are not them? Are you sure they will see this post?
They get shadowbanned, they make new accounts, and the admins have wasted everyone's time once more. They aren't spamming, they aren't in a default reddit, and this community likes their submissions well enough. The admins should keep their distance.
It probably didn't need to be public, you're right. It was sort of a spur of the moment "what happened to this sub" post. I'll remove it, and probably message the sub mods about my concern and they can choose to talk to meetingcpp and mttd or not. 
I give two examples from real-world code where I `use expected&lt;T&gt;` [here](http://adityaramesh.com/ccbase/error.html). I also wrote a library for system topology enumeration (lists all NUMA nodes, processor cores, SMT threads, cache levels, which threads share which caches, etc.) which uses `expected&lt;T&gt;` extensively. [Here's](https://github.com/adityaramesh/ctop/blob/master/include/ctop/system_query.hpp#L512) the relevant header file. My implementation of `expected&lt;T&gt;` documented in the first link differs from the standard proposal in a few ways. I have found the following additional features to be critical in many of my applications of `expected&lt;T&gt;`. 1. My implementation works with references -- it's easy to see why this feature would be useful. 2. The destructor throws by default if the state of an expected object is not read at least once prior to destruction (this behavior can be turned off by using a macro). This helps ensure that errors do are not silently ignored.
Having trouble replicating the double delete issue. Here's some test code: template &lt; typename T0, typename T1 &gt; struct chain { static utility::expected&lt;T0&gt; call(utility::expected&lt;T1&gt; e) { return utility::expected&lt;T0&gt;::from_exception(std::move(e.error())); } }; template &lt; typename T &gt; struct chain&lt;T,T&gt; { static utility::expected&lt;T&gt; call(utility::expected&lt;T&gt; e) { return std::move(e); } }; template &lt; typename T0, typename T1 &gt; utility::expected&lt;T0&gt; chain_invalid(utility::expected&lt;T1&gt; e) { return chain&lt;T0,T1&gt;::call(std::move(e)); } BOOST_AUTO_TEST_CASE(chained_call_invalid) { auto val = utility::expected&lt;int&gt;::from_exception(std::runtime_error("hello")); auto t0 = chain_invalid&lt;int&gt;(chain_invalid&lt;int&gt;(chain_invalid&lt;int&gt;(chain_invalid&lt;int&gt;(val)))); auto t1 = chain_invalid&lt;char&gt;(chain_invalid&lt;double&gt;(chain_invalid&lt;short&gt;(chain_invalid&lt;long&gt;(val)))); } Are you refering to something else or did I somehow magically avoid the problem in my implementation? Edit: I noted you said, "...moving the exception pointer out...," so I tried some variations of that. Added a "remove_error" function that returned the pointer through "std::move(exception)". Tried returning rvalue-ref and returning value. Didn't cause crash either. Are you sure there wasn't a bug in the implementation when you were first experimenting with this? Seems to me these uses should function according to standard.
I'm sorry but this explanation doesn't make any sense to me. Surely the reference count cannot be driven to zero so long as there's a valid reference of any sort from which to build a copy. There has to be a valid value somewhere to build a value from or you've already done something really wrong (like trying to build a new value out of whatever resides at address 0). I just don't see how returning by value would alter that? Are you talking about calling "error()" on an expected after you've moved the exception such that it attempts to copy an invalid exception_ptr? That would probably cause the double free you mention. Returning reference doesn't solve this if that's the case. It might happen to work some of the time, but once you've moved something you should forever consider it invalid from then on. I'd also think twice about attempting to move objects partially. That really seems to me to violate encapsulation in a major way. If you want a way to construct a new expected without the check then I'd consider something more akin to `from_invalid(expected&lt;T&gt;&amp;&amp;)`. Thus making sure that the fact the source is destroyed completely is clarified. You'd want to make sure that source no longer thinks it should make sure the validity was checked when it goes out of scope.
So warn_unused_result? https://gcc.gnu.org/onlinedocs/gcc/Function-Attributes.html
â€¦ Yes, I'll shut up now. :) 
I've been looking into tinyformat, so it's cool to find something similar. However this appears to be faster than sprintf? How? A nice feature would be support of printf format specifiers, eg %s and %d so it could be more easily dropped in as a replacement.
[Your use](https://github.com/adityaramesh/ctop/blob/master/include/ctop/system_query.hpp) of expected&lt;T&gt; is how you write Go code, not C++ code. I have serious dislike for all this if (!r) return ... business. I think you are abusing the purpose of Alexandrescu's idea. Its goal isn't to systematically use error-return. You can do that by systematically writing error-return code. The goal is, rather, to allow both styles in rare cases it is really interesting to use that error-return. Finally, as soon as this style of coding is mixed with anything else that might throw, it gives the worst of both worlds: it looks like it's an error-return, but it actually throws (either that, or any function that wants to *make sure* to return expected&lt;T&gt; has to be wrapped in a try/catch.
Is Cinder a good library for developping video games, or more generally a good library? The documentation seems very, very poor, and most of the integrated samples, at least for VS 2013, lag as hell on my computer (it has a gaming PC configuration). And I don't really understand what the library can be used for. No showcases of released products made with it and a very evasive feature list...
**Edit:** what I was doing (and my argument below) are stupid; see [this reply](http://www.reddit.com/r/cpp/comments/2f2bpv/alexandrescus_expectedt_code_style_and_idioms/ck61lsw) for updated usage. In my use cases, all functions are noexcept. This may not be how Alexandrescu envisioned the idiom to be used, but expected can be used as an optional that stores a value or an exception. Rather than using throw to propagate exceptions, I use expected instead. You can debate the pros and cons of both approaches, but I definitely like using expected more. The compiler doesn't generate any stack unwinding code, and the fact that all functions involved are noexcept may allow you to make some useful optimizations. This also allows you to defer dealing with any errors until you actually care, so it carries all of the benefits mentioned in Alexandrescu's talk. That I am mixing expected&lt;T&gt; with error-return is not an argument for why this approach is bad. I was considering replacing the if (!r) ... with a macro to clean up the syntax more, but decided against it.
After seeing his talk I implemented a version of Expected&lt;T&gt; that has been used to great effect. Largely it has been used to re-factor code that populate a parameters with the result or error string and return a bool. We also use them a the return results for threaded commands but I may replace that usage with actual futures once we drop vc10. Initially I implemented expected very explicitly but have over time introduced more implicit behaviors most recently implicit construction from exception_ptr and objects derived from std::exception. This leads to very clean looking code and so far has not caused issues. Overall I think it has been a big improvement for our code base and code style. 
One issue I have noticed with the examples is that they have pretty inefficient use of draw calls. This could be one reason that they appear to be slow.
I'll reply with a MWE soon. Sorry for the sloppy explanation, I was about to go to sleep after not doing so for a while =) Regarding your use of from_invalid: yes, I agree with you. Implementing something like that is on my TODO list. I will probably change the code and add something like from_invalid in a little while.
sprintf is often not as savagely optimized as people seem to expect. For example, in all released versions of VC++ it's actually a fprintf wrapper with a `FILE` implementation which writes to a memory buffer rather than a file (this is changing in VS 14). This isn't a *huge* performance hit, but it is an extra layer of abstraction. This also doesn't implement all of `sprintf`'s functionality. It's probably not gaining a ton of performance from that, but it is something.
Regarding &gt; In these cases, the library can forego the boilerplate required to catch and propagate exceptions. and &gt; This also allows you to defer dealing with any errors until you actually care But you haven't removed any boilerplate, instead you've added in a load extra. Most of your functions don't deal with any errors but rather pass them higher up the call stack. If you used exceptions then you wouldn't have needed to write any try/catch blocks, the exceptions would propagate up naturally. Instead you've gone the error-code approach which forces you to write the error propagation code manually via plenty of `if (!r)`. And you've also been forced to write code to convert exceptions like `boost::bad_lexical_cast` into error codes. Of course you're free to write your code anyway you want, and the exception v. error code debate isn't resolved in any sense, but for this example your two claims above are incorrect.
Honestly speed is not one of the reasons I use sprintf. It's simplicity. The code for using sprintf usually ends up being a lot smaller, a lot more concise, and a lot more understandable than almost any C++-like formatting code. 
&gt; In my use cases, all functions are noexcept Yes, but the caller has to check the return, otherwise they are *effectively* throwing functions. &gt;The compiler doesn't generate any stack unwinding code ... and if you forget one error-return check, all hell breaks loose. Quite frankly, that is worse than a normal error-return. &gt;This also allows you to defer dealing with any errors until you actually care So does the use of exceptions, but without "if (!r)..."
You should really consider trying to model monads. You're *so* close.
You're right, what I was doing was pretty stupid. I'm not really sure what my thinking was at the time; I had just implemented expected&lt;T&gt;, so perhaps I was trying to find some screws to hammer. Updated usage [here](https://github.com/adityaramesh/ctop/blob/master/include/ctop/system_query.hpp#L512). The internal functions no longer return expected. &gt; In these cases, the library can forego the boilerplate required to catch and propagate exceptions. Regarding this comment, I was talking about library optimizations in concurrency libraries. If the user lambda is noexcept-qualified, then (as the library writer) you can make some useful optimizations in the internals when implementing things like continuations.
What I was doing was stupid; see [this reply](http://www.reddit.com/r/cpp/comments/2f2bpv/alexandrescus_expectedt_code_style_and_idioms/ck61lsw) for updated usage.
&gt; No showcases of released products made with it Cinder has been used in [some extremely impressive stuff](http://libcinder.org/gallery/).
There is also a collapse function and a version of apply that returns a Maybe&lt;Maybe&lt;T&gt;&gt; :) I add things in this direction when I get a need for them, I guess eventually the monadic similarity will approach 1 as time goes to infinity. This stuff is really easy to write though, just a few lines of code.
I am a dumbass. I didn't even see the Gallery section. Thanks!
Maybe not the perfect solution but a better one than the current state would be to introduce a macro which could be set by the compiler. That would give you run-time efficiency, both memory-wise and speed-wise, and compatiblity across vectors within your program.
At first I thought this was a bug but I see a problem in your code that I don't think exists in `exceptional`--though I have to admit to not really understanding the implications of all the new rules about `union`. I verified that your code crashes with clang 3.4. I also checked that simply creating a variable from calling `test2` didn't. I'm not sure why that latter doesn't happen. So far as I know, once your user-created destructor exists the destructor for the exception_ptr should be called. Placement new and placement destruct aren't meant to be used in the manner you're using them in the example code. So I wouldn't expect your code to work. Interesting to me though I can't seem to fix it. Making the p member instead a member of an internal union just doesn't change the story. It reflects better the use in expected&lt;T&gt;, but somehow the problem doesn't go away. IMO there's something here the two of us don't get, or there's a bug in our implementations that span most OSS c++ compilers. Here's my changes: struct foo { union { std::exception_ptr p; }; foo(std::exception_ptr p) { new (&amp;p) std::exception_ptr(std::move(p)); } foo(foo const&amp; f) { new (&amp;p) std::exception_ptr(f.p); } foo (foo &amp;&amp; f) { new (&amp;p) std::exception_ptr(std::move(f.p)); } ~foo() { p.~exception_ptr(); } }; foo test1() { return foo(std::make_exception_ptr(std::runtime_error{"hi"})); } foo test2() { auto r = test1(); return r.p; } foo test3() { auto r = test2(); return r.p; } int main() { auto f = test3(); } Edit: This really looks like some sort of compiler bug to me. Calling `test2` should be no different at all from calling `test3` and yet it works. Edit2: I replaced exception_ptr with a shared_ptr to see if it was indeed the reference counting at fault. Calling `test3` there works just fine.
More like that, given what exists in C++14: auto add(int i, int j) override { } (Even though it may not play nice with many things, I am no expert)
AFAIK override is a contextual keyword so it can't be used like that.
If you are a team programmer (i.e. not just you in your bedroom), then I would suggest Multiple Returns is the way to go. It's clear to both the 'expert' (who would probably think that @robinjam is the right way), and the novice. I would suggest it's probably also easy for the lay-person to work out. As for efficiency, for something as simple as IsLeapYear, there's probably not much difference in a modern compiler. For more complex functions, clarity, clarity clarity, maintainability, then efficiency (unless the function is being called 100,000,000 times a second). 
Exactly my thoughts. At my day job for past 4 years, majority of my work is maintenance of a large complex codebase. I spend most of my time reading code written by others and modify to for maintainability and add it to the core codebase. I see 'smart' programmers, doing some some 'very hacky' stuff all the time. Somebody learns this new MACRO hack, and they sprinkle it all over the place. I can tell you that code becomes a Tyrannosaur after 6 months. Here's few tips that I give to any novice programmer, for writing code that's easier to maintain: 1. Keep variable/function names expressive. strcpy(), might have felt awesome in the 80s, but today I see no reason for not naming it StringCopy() 2. Nobody wants to read the comments, if there are any. Nothing beats the code that is self-documenting. 3. Multiple returns. Return as soon as possible for trivial tests, like invalid value. Majority of the code in a function should be the actual functionality, preferably at the first indentation level. type SomeFunction() { if (trivialTest) { return } actual code return } 4. If some hacky code is saving a lot of cycles, the code should be accompanied with an equivalent pseudo-code. 5. Unit test. It not only makes maintenance a walk in the park. But, also forces the programmer to write good modular code. 6. Don't repeat yourself. If you have to, it's a design error. 
Btw you have same namespace name as in [cppformat](https://github.com/cppformat/cppformat). Is this somehow related?
Macro modes are problematic because they lead to mismatch issues (among object files, static libraries, and DLLs). VC's _ITERATOR_DEBUG_LEVEL is valuable but also headache-inducing (and while we've added linker validation over the years to reduce the headaches, they can't be eliminated). That's why I avoid adding further macro modes.
This a nice clear explanation, but I'm still not sure C++ is heading in the right direction with move semantics, it feels like everything is getting more obscure, not clearer.
This power is generally intended for people who write libraries and to be easy to use if deemed necessary for Joe Programmer. Think about how often you care about passing by value, move AND reference except when writing reusable code. As Joe Programmer, you'll likely be satisfied using std::move or writing the odd move constructor.
Until I read your post I had no idea there was a soul alive who actually *didn't* like type inference. TIL.
Programming language design is about usability. Type inference is only about minimizing physical typing that can be addressed with a good IDE using code completion. In modern programming, one should never consider language design independently from tool design.
When writing models I found a lot of common errors and wrote the model_test which is worth mentioning in a tutorial as it can help catch a lot of bugs and make development go faster for those writing models from scratch. http://qt-project.org/wiki/Model_Test
&gt; For example, MSVCâ€™s std::string employs the small string optimization (SSO), which makes moving small strings more expensive than moving large strings. This sounds like an implementation/compiler issue. Either way you're copying ~24 bytes: either the representation that holds the size, capacity and pointer, or the ~24 chars making up your small inline string. Move assigning small strings should, in fact, be faster since the destination string doesn't have to be deallocated if it is also small. libc++ does SSO, so I tried benchmarking this myself with [this program](http://rextester.com/DLQ89485), (Note: uses about 2.5 GiB of RAM for the last test), compiled with Clang 3.4.2 against libc++ on x86-64 Linux using clang++ -std=c++11 -stdlib=libc++ -march=native -Ofast -flto time_string_moves.cpp -lc++ -lc++abi and got the following results (fixed CPU frequency, Turbo boost disabled on a Haswell) 1st run 2nd run 3rd run 22 22 22 8236 Âµs 7420 Âµs 7413 Âµs 7298 Âµs 8185 Âµs 7176 Âµs 7110 Âµs 8426 Âµs 7190 Âµs 7167 Âµs 7618 Âµs 7135 Âµs 7249 Âµs 7823 Âµs 7789 Âµs If there is a difference then it's lost in the jitter on my machine, and it's so fast as to be essentially insignificant anyway. The articles point regarding moves having no advantage over copies for a std::array of fundamental types is true, though I'm not sure why you'd use it for anything sizable enough for it to matter
This article is likely MSVC specific, since it's from Microsoft. If you use clang or GCC, it's basically a no brainer to pass by value, because those compilers are smart enough to elide the copy/move operation. Basically I've found in C++ that doing things the simple straight forward way is usually very close to optimal because in many cases the compiler can usually fill in the gap for you. GCC and clang have made huge strides in the past few years to perform some really kick-ass optimizations that allow straight forward code to perform at least as good, and sometimes better, than obscure code.
A key point I think from the article: &gt; Is the code Iâ€™m writing likely to be a performance bottleneck? If not, I wouldnâ€™t bother optimizing, and would stick to passing by value. Ultimately, too, it may not be a performance bottleneck. Hopefully, in the future compilers can be smarter about eliding moves(just as elides copies in places).
Getting the type wrong (especially with respect to const-ness) is a real issue, not just saving keystrokes. I use auto to prevent that class of errors.
Things get obscure when one tries to squeeze that last drop of performance out, even more so when one tries to do it from a high-ish level language and support a wide array of uses. The thing is, these things just do not exist on other languages. There, people either drop the speed outright or they do it rather painstakingly, and various people do it in various, slightly different and incompatible ways. (Which is not to say that C++ adopts the right direction ðŸ˜‰)
I use it for everything at work (Interactive installation/kiosk dev) and it's a very solid library. The examples haven't been updated for quite a while unfortunately, so they're not representative of proper cinder usage anymore. Thankfully this is because the library itself is undergoing constant development so the examples have fallen behind. Make sure you're compiling for release too, there's a marked difference, especially on shitty windows.
&gt; I was a little surprised to see that copying a small string was always slower than moving it. Makes sense. Move generally leaves the source string in an empty state, so has to zero it out. &gt; You should double check when the small string optimization kicks in for clang. I knew it was 23 chars, which is why I tested 22 and 23. Here's your code on Clang/libc++. It looks like Microsofts move implementation is suboptimal for small strings. Perhaps [STL](http://www.reddit.com/user/STL) can tell us why. Move tests. Sample size: 10000000 String size: 24 String size 1: 64 ms String size 2: 64 ms String size 3: 63 ms String size 4: 64 ms String size 5: 63 ms String size 6: 65 ms String size 7: 63 ms String size 8: 64 ms String size 9: 64 ms String size 10: 64 ms String size 11: 65 ms String size 12: 63 ms String size 13: 64 ms String size 14: 64 ms String size 15: 63 ms String size 16: 63 ms String size 17: 63 ms String size 18: 64 ms String size 19: 65 ms String size 20: 63 ms String size 21: 63 ms String size 22: 63 ms String size 23: 65 ms String size 24: 69 ms String size 25: 66 ms String size 26: 65 ms String size 27: 72 ms String size 28: 76 ms String size 29: 68 ms String size 30: 66 ms String size 31: 64 ms String size 32: 63 ms String size 33: 65 ms String size 34: 63 ms String size 35: 64 ms String size 36: 63 ms String size 37: 65 ms String size 38: 79 ms String size 39: 63 ms Copy tests. Sample size: 10000000 String size: 24 String size 1: 46 ms String size 2: 56 ms String size 3: 57 ms String size 4: 55 ms String size 5: 54 ms String size 6: 55 ms String size 7: 54 ms String size 8: 55 ms String size 9: 54 ms String size 10: 55 ms String size 11: 54 ms String size 12: 54 ms String size 13: 54 ms String size 14: 54 ms String size 15: 54 ms String size 16: 54 ms String size 17: 54 ms String size 18: 54 ms String size 19: 56 ms String size 20: 54 ms String size 21: 54 ms String size 22: 54 ms String size 23: 365 ms String size 24: 351 ms String size 25: 370 ms String size 26: 350 ms String size 27: 365 ms String size 28: 347 ms String size 29: 375 ms String size 30: 356 ms String size 31: 378 ms String size 32: 388 ms String size 33: 410 ms String size 34: 369 ms String size 35: 414 ms String size 36: 362 ms String size 37: 411 ms String size 38: 383 ms String size 39: 431 ms 
Qt's MV design is way more complex than what it needs to be, to the point that if one creates a small MV framework himself, development is much faster than with Qt. 
Just like QT in general. Best of a bad bunch, but *needs* an overhaul without denying the existence of the stdlib.
Well, I think it fits pretty well into Qt, and with views and proxyfiltermodels is quite useful. The complexity comes from the one size fits all approach.
it would be deduced as B* because the method it overrides has declared B*. You would still have to be able to define covariant return types (like you are able now). Or you can use the c++14 auto return syntax. The suggestion is meant only for ease of use in the general case. 
It's simple: if you are interested in move optimization semantics, you need to either write your functions twice (one that accepts an lvalue and one that accepts an rvalue) or create a template one, using a universal reference. 
I agree very much. I still follow the C++ community and watch a lot of lectures from its leaders (Going Native!) because there are some very smart people who give fantastic, thoughtful presentations; however, because of the needless, arcane complexity of the language itself and how nearly impossible it is to actually write something correctly, I've switched to a certain, well... competing language known in the wizard world only as You-Know-What. Rumors are it has not yet taken physical form, but its influence and power can already be felt.
[Here's a link to the slideshows for the videos](https://github.com/boostcon/cppnow_presentations_2014). You'll have to search Unicode to get to this one.
Thanks for this tutorial. I found it clear and to the point. One thing I might have, maybe add a *.pro file to your repository, so people like me can compile your code without having VS. I have some questions about TableViews and models, maybe you (or anyone) can clear the fog for me a bit. How does your TableView know which columns to display. You never assign any TableViewColumns. I don't have much background in QWidgets so maybe I am missing something. If you use your approach in QtQuick, I need to assign TableViewColumns to my TableView with a designated role for each column. I need to akwardly introduce user roles for each column of data I want to display. Do you know of any method to use the associated column() of the QModelIndex with TableViews? I have looked into custom delegates but this approach seems even more akwardly. E: One more thing. What's the difference (adv/disadv) in using Model/Views with respect to just a custom QObject with exposed properties?
I have an active bug to investigate move perf. Currently we're branching on whether we're local, which I believe we can avoid.
I much prefer the way move semantics work in Rust. IMO the destructor being called after a move is a design flaw in the language.
OH BOY MY FAVOURITE TOPIC
Boost Locale isn't a panacea atm. Brownie points for anyone who can come up with some code that converts ISO8859-15 (Latin-9) to UTF-16 *on Linux* without going to wchar_t externally first. Arbitrary character set conversion should be trivial in 2014.
Look up the iconv() function.
&gt; IMO the destructor being called after a move is a design flaw in the language. The problem is some member variables are moved and some others are copied, so a destructor has to be called for the members that were copied. Unless they added a special move-destructor, but this will just complicate the language more. How does rust handle the situation where some member are copied and others are moved? EDIT: Oh I see, it can be done using a [destructive-move](https://github.com/sean-parent/sean-parent.github.io/wiki/Non-Proposal-for-Destructive-Move) in the language, which combines the move constructor and destructor together.
I like it.
You referred to "Sean's Talk" and "Chandler's talk" throughout the presentation. Do you know links to videos of those presentations? Awesome talk by the way, really enjoyed it. It's one of those presentations which provided both questions *and* answers, the best kind!
Now what would be interesting is the discussion on the ml. Sadly the patch author didn't want to subscribe there so we have to wait for moderator approval (which can be kinda slow). *EDIT*: kay, it is now [here](http://lists.cs.uiuc.edu/pipermail/cfe-commits/Week-of-Mon-20140901/114048.html)
**tldr**: libc++ uses quicksort, guy constructs worst case tests for quicksort thus O(n^2 ). Runtime will still be nlog(n) for most cases.
That's no easier to use, and not much more portable than the broken codecvt interface we have now. std::locale en_gb ("en_GB.ISO8859-15"); using codec_type = std::codecvt&lt;wchar_t, char, std::mbstate_t&gt;; auto&amp; codec = std::use_facet&lt;codec_type&gt;(en_gb); auto euro = "\xA4"; std::mbstate_t state = {}; wchar_t out[16] = {}; wchar_t* next_out = nullptr; char const* next_in = nullptr; codec.in (state, euro, (euro + 1), next_in, out, (out + 16), next_out); // Should output 20AC, magically unicode. std::cout &lt;&lt; std::hex &lt;&lt; std::uppercase &lt;&lt; out[0] &lt;&lt; std::endl; works on Linux (provided the en_GB.ISO8859-15 locale has been generated), broken on Windows. In theory this should work for char16_t/UTF-16, instead of wchar_t, but it doesn't. Boost Locale won't do conversions to char16_t either. I'd quite like something like a a unicode string_view.... i.e. something that takes a charset/encoding and a pair of arbitrary bidirectional iterators on construction, and produces bidirectional const_iterators over unicode code units. 
right, but if some server is using `std::sort` on user-supplied data, you could conceivably slow it down by supplying the "killer" input.
What is the algo for libstdc++ ?
For [`std::sort`](https://gcc.gnu.org/onlinedocs/libstdc++/libstdc++-html-USERS-4.4/a01027.html#g152148508b4a39e15ffbfbc987ab653a)? [Introsort](http://en.wikipedia.org/wiki/Introsort).
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Introsort**](https://en.wikipedia.org/wiki/Introsort): [](#sfw) --- &gt;__Introsort__ or __introspective sort__ is a [hybrid](https://en.wikipedia.org/wiki/Hybrid_algorithm) [sorting algorithm](https://en.wikipedia.org/wiki/Sorting_algorithm) that provides both fast average performance and (asymptotically) optimal worst-case performance. It begins with [quicksort](https://en.wikipedia.org/wiki/Quicksort) and switches to [heapsort](https://en.wikipedia.org/wiki/Heapsort) when the recursion depth exceeds a level based on (the [logarithm](https://en.wikipedia.org/wiki/Logarithm) of) the number of elements being sorted. This combines the good parts of both algorithms, with practical performance comparable to quicksort on typical data sets and worst-case [O](https://en.wikipedia.org/wiki/Big-O_notation)(*n* log *n*) runtime due to the heap sort. Since both algorithms it uses are [comparison sorts](https://en.wikipedia.org/wiki/Comparison_sort), it too is a comparison sort. &gt; --- ^Interesting: [^Quicksort](https://en.wikipedia.org/wiki/Quicksort) ^| [^Introselect](https://en.wikipedia.org/wiki/Introselect) ^| [^Sorting ^algorithm](https://en.wikipedia.org/wiki/Sorting_algorithm) ^| [^David ^Musser](https://en.wikipedia.org/wiki/David_Musser) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ck7g9k4) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ck7g9k4)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Depends on how it picks the pivot. If it uses first or last, it dies on sorted input. If it picks the middle, it does badly on concatenated sorted lists. Both of those are reasonably common.
Thats a good question. A function works as well, but there are some advantages to declaring a global function object instead. First, a function object can easily passed to other functions(you can't create a function pointer to a templated function). However, there is a proposal for a lift operator to help with this issue. Secondly, using function objects are more expressive, that is, we can create "abstractions" on top of these functions. For example, we can easily make the function [pipable](http://pfultz2.github.io/Fit/doc/html/pipable/): const constexpr auto add_one = pipable(STATIC_LAMBDA(auto x) { return x + 1; }); So we could do this: auto number_4 = 1 | add_one | add_one | add_one; Of course, this is not a very useful example, but this is useful for doing extension methods in C++. It is similiar to the `$` function in Haskell. Finally, by defining the function using a lambda it is simpler(but I guess that is debatable), so instead of writing the function with all the template boilerplate, like this: template&lt;class T&gt; auto add_one(T x) { return x + 1; } We can just write it using an `auto` parameter: const constexpr auto add_one = STATIC_LAMBDA(auto x) { return x + 1; }; Perhaps it is debatable whether the latter is simpler than the former. 
Chandler's talk: https://www.youtube.com/watch?v=YJIaGRDIyEE&amp;list=UU5e__RG9K3cHrPotPABnrwg Sean's talk: https://www.youtube.com/watch?v=mYrbivnruYw&amp;list=UU5e__RG9K3cHrPotPABnrwg And thanks! I'm glad you enjoyed my talk.
You forgot the part where he submits a patch to transform it in introsort. Which would make it conform with the standard (and faster).
I thought so too, and was quite reluctant to accept the quadratic behaviour claim until I saw the code. I don't think it's something to pass off as unimportant, and I don't think it's a minor thing that was missed as some other comments have hinted. As I put it when the author presented it to me, it's MSVC-level negligence. If you're writing `std::sort`, the specification clearly says O(N log N) comparisons: quicksort is not an option, period.
I can't see how it could get missed. Quicksort's quadratic worst case is not an obscure secret. It's a well-known property of the algorithm.
Hey! VC has guaranteed O(N log N) since at least 2005.
This title is inaccurate. `std::sort` is in general O(n log n) and not quadratic - however, there are specific inputs for which it is quadratic. This is a serious issue, and needs addressing - but it doesn't mean that you need to rush to replace it in your code because if you're getting "random" inputs, it's still going to be O(n log n) on average.
Historical note: C++03 guaranteed O(N^2 ) worst case, while C++11 guarantees O(N log N) worst case.
I've fixed a lot of spurious and a few physical leaks over the years - I am currently not aware of any leaks in stringstreams. What you're saying does sound familiar - I recall fixing a spurious leak that had been improperly closed as Won't Fix by my predecessors (a spurious leak is merely a persistent allocation that is physically cleaned up later, but not marked as internal, so it shows up in our debugging machinery, confusing users).
I was under the impression timsort was currently the generally accepted sorting algorithm to avoid quadratic run-time and avoid pathological cache behavior.
Just because they say std::vector is a good default, doesn't make it perfect for everything. Here's a few reasons why you might want deque sometimes: a. std::deque never invalidates references on push_back b. std::deque can be manipulated at the front and even does so without invalidating iterators c. std::deque doesn't grow exponentially thus wasting less space and being less susceptible to a fragmented heap. d. std::deque may return memory when shrinking I'm sure there's more if I dug a bit. 
I have not looked at the details myself, but do you really think the person used first element as pivot quicksort? This is an incredibly bad idea for a general sort. If the implementation uses something like median of 3 then pathological cases are incredibly rare. Only really come up if someone constructs them. Though this cause allow an exploit if users can supply the data. And all (fast to compute) pivot choices have quadratic worst case. Though regardless one should put in a safegaurd to O(nlog(n))
Quicksort (with a reasonable pivot choice) is still faster on most data/machines. Often by a factor of 2 or so. 
&gt; std::deque can be manipulated at the front and even does so without invalidating iterators Incorrect. N3936 23.3.3.4 [deque.modifiers]/1: "An insertion at either end of the deque invalidates all the iterators to the deque, but has no effect on the validity of references to elements of the deque." &gt; std::deque doesn't grow exponentially thus wasting less space and being less susceptible to a fragmented heap. I have to grumble at this, because "exponentially" usually means "bad", but in vector's context it's good. I prefer to say that vector grows geometrically. vector is surprisingly space-conservative. It has very small fixed overheads (the vector object itself, plus one occurrence of invisible allocator overhead if any), and zero per-element overheads, so the only "wasted" space comes from the capacity. If a vector's growth factor is 1.5x, and vectors have random lengths, then on average they'll be halfway between the previous and the next reallocation. 1.5 / 1.25 = 20% overhead. Even for a 2x growth factor, 2 / 1.5 = 33% overhead. That's not zero, but it's also not a terribly big deal. It's possible to do worse than this (e.g. if the lengths are *just* right to barely trip allocations), but the worst case is still bounded and small. (If your vectors have a habit of becoming significantly smaller, there's shrink-to-fit.) And the typical case is likely to be *much* better. Many vectors have exact capacities: e.g. after range-construction or copy-construction.
Libc++'s sort is a little more complex than that. I wonder if this patch preserves libc++'s performance on non-random sequences: slide 54 http://llvm.org/devmtg/2010-11/Hinnant-libcxx.pdf (edit: It looks to me like it does.) Here's how libc++'s algorithm was explained to me by its author: --- libc++'s sort is fairly simple. It is a quicksort with a few twists: The partition is done about the median, denoted by `*__m` such that `[first, __m) &lt; *__m` and `*__m &lt;= [__m, last)`. The median element is not removed from the range [first, last) during the partition, but rather `__m` is updated to follow it if it moves. These actions have the effect that if the partition algorithm is given an already partitioned sequence, no swaps are done. Additionally, during the partitioning, the number of swaps are counted. If after the partitioning is complete, the number of swaps is 0, then the algorithm takes note: I've been handed an already partitioned sequence. Might it also be already sorted? To check, the algorithm does a "partial insertion sort" separately for both the lower partition and the upper partition. "Partial" here refers to the number of inserts that are allowed to happen during the insertion sort. There is a low limit (like 7 or 8) allowed insertions, and if that limit is exceeded, the "partial insertion sort" gives up and returns the information that it gave up. Else it will complete the insertion sort and return that information. Recall that if you hand insertion sort a sorted sequence, no swaps are done and only N comparisons are done. So in the case of a pre-partitioned sequence there is an O(N) check to see if the sequence is sorted, and this "check" will also sort "nearly sorted" sequences. And the check is done on lower and upper halves separately to catch the case that only one half of the sequence is "nearly sorted". Recall that this "nearly sorted" check is *only* done if the sequence is already partitioned, and the added cost of determining if the sequence is already partitioned is virtually zero (an int increment with each swap). And that's it! As an example consider a reverse sorted sequence: The first pass swaps every element during the partition (N/2 swaps and N comparisons), and then you recurse as you would during a normal quicksort. The second pass on both the lower and upper sides notes that it is given a perfectly partitioned sequence (0 swaps and N comparisons). Then an insertion sort is done on each of the 4 subsequences, all of which succeed without any further swaps (0 swaps and N comparisons). The total cost of sorting a reverse sorted sequence is N/2 swaps and 3N comparisons. You can intuitively extrapolate that if you had a "nearly reverse sorted" sequence, the cost would be only slightly greater than the precisely reverse sorted sequence. And in practice I observe that this algorithm teases out and rapidly sorts all subsequences that contain a non-random structure. 
I think it depends on the situation. Timsort is used in python where list element swaps are always cheap and comparisons expensive, and then timsort is very competitive.
It probably didn't get missed so much as it doesn't really matter too much because the cases described are rare. Of course that's no reason not to improve it :) And it should meet the standard for complexity too...
It's also used in Java. 
I did not get how it works, isn't the constexpr auto objects always set to the nullptr? How do you actually get at the lampda body? 
Pipable? Seriously? C++ is not the shell, and that code is completely unreadable. You've really abused operator overload there. Finally, pipable isn't a word. You're looking for pipeable.
I'm generally skeptical that introducing a HTTP server as a library is the most useful thing ever. Sometimes I want different URI endpoints running different applications, possibly in different languages, and, unless you have an abundance of IPs and run everything across subdomains (*sigh*... IPv6), you end up having to run a HTTP proxy anyway, which is fairly inefficient. HTTP servering isn't a simple process these days, with rewrite rules, SSL/TLS considerations, various [HTTP headers to improve security](https://github.com/twitter/secureheaders), and HTTP/2 (which extends the simplistic request-response model with things like push) Whatever happened to [Boost CGI](http://cgi.sourceforge.net/)?
Hey, it's the author here (Orson Peters). It wasn't so much I didn't _want_ to subscribe, it's more that I didn't know I had to to post, and I didn't want to cancel my post after finding out.
This case clearly demonstrates the advantages of open source software. 
Your myth busting comments are 70-80% of the reason I visit this subreddit. Keep it up.
Ever since I first became familiar with C++11 macros I've been looking forward to replacing most (all?) functions with lambdas. With C++14, being able to just add an `auto` parameter is really convenient. Perhaps, when prototying, everything should be done with generic lambdas and we should only use more explicit types later when we are finalizing our work. I would like to see more work towards getting rid of the differences between (generic) lambdas and functions. A (non-capture) lambda should, in my opinion, be able to do (almost) everything a function can do. Then, lambdas could become the normal way to define a "function". But I guess that I'll be much happier if we can have `auto` parameters in non-lambda functions.
This is not true, the libc++ implementation has a special case for pre-sorted arrays as well.
I've done some algorithms with deques and vectors, and I always found the vectors being faster. The advantages of continuous memory blocks in relation to caching cannot be overlooked. 
I wonder if we will ever see an Nvidia AMP implementation. Does anyone know how performant or possible it would be to build an an AMP implementation on top of CUDA or OpenCL?
&gt; That means this documentation is wrong where specifically? 
I believe it can target OpenCL and SPIR.
In addition, std::vector guarantees to produce a contiguous memory area. Not so with deque.
After reading more closely, it looks like the documentation is correct, but STL's comment threw me off. Specifically, *insertion* at the front invalidates iterators, but removal does not, which was my original meaning. Sorry for the confusion.
Are there any benchmarks for these tricks? (EDIT2: [Well, there are now](http://www.reddit.com/r/cpp/comments/2fc92y/bit_twiddling_hacks/ck89wpf?context=8675309)) I suspect that optimizing compilers are already pretty good at bit twiddling. I've had at least one case where I simplified/optimized a bitwise expression, only to find out that the compiler had already turned the complicated version into the simple one. EDIT: Surprisingly, when I tried out some of the bit-counting ones, my own clear solution and two of the ones from that page all failed to generate the single assembly instruction. I'm using g++ 4.9.1, compiling with `g++ test.cpp -O3 -march=native -std=c++11` on an i5 4670K, and the result is: Source: #include &lt;iostream&gt; #include &lt;cstdint&gt; uint64_t popcnt_loop1(uint64_t n) { uint64_t count = 0; for (int shift_amt = 0; shift_amt &lt; 64; ++shift_amt) { if (n &amp; (1ULL &lt;&lt; shift_amt)) { ++count; } } return count; } uint64_t popcnt_loop2(uint64_t n) { uint64_t count = 0; for (; n; n &gt;&gt;= 1) { count += n &amp; 1; } return count; } uint64_t popcnt_loop3(uint64_t n) { uint64_t count = 0; for (; n; ++count) { n &amp;= n - 1; } return count; } uint64_t popcnt_intrinsic(uint64_t n) { return __builtin_popcountll(n); } int main() { } Generated assembly (omitting noops and demangling names): 0000000000401540 &lt;popcnt_loop1&gt;: 401540: 31 d2 xor %edx,%edx 401542: 31 c0 xor %eax,%eax 401544: c4 62 eb f7 c9 shrx %rdx,%rcx,%r9 401549: 4c 8d 40 01 lea 0x1(%rax),%r8 40154d: 41 83 e1 01 and $0x1,%r9d 401551: 49 0f 45 c0 cmovne %r8,%rax 401555: 83 c2 01 add $0x1,%edx 401558: 83 fa 40 cmp $0x40,%edx 40155b: 75 e7 jne 401544 &lt;_Z12popcnt_loop1y+0x4&gt; 40155d: c3 retq 40155e: 66 90 xchg %ax,%ax 0000000000401560 &lt;popcnt_loop2&gt;: 401560: 31 c0 xor %eax,%eax 401562: 48 85 c9 test %rcx,%rcx 401565: 74 18 je 40157f &lt;_Z12popcnt_loop2y+0x1f&gt; 401567: 66 0f 1f 84 00 00 00 nopw 0x0(%rax,%rax,1) 40156e: 00 00 401570: 48 89 ca mov %rcx,%rdx 401573: 83 e2 01 and $0x1,%edx 401576: 48 01 d0 add %rdx,%rax 401579: 48 d1 e9 shr %rcx 40157c: 75 f2 jne 401570 &lt;_Z12popcnt_loop2y+0x10&gt; 40157e: c3 retq 40157f: c3 retq 0000000000401580 &lt;popcnt_loop3&gt;: 401580: 31 c0 xor %eax,%eax 401582: 48 85 c9 test %rcx,%rcx 401585: 74 18 je 40159f &lt;_Z12popcnt_loop3y+0x1f&gt; 401587: 66 0f 1f 84 00 00 00 nopw 0x0(%rax,%rax,1) 40158e: 00 00 401590: c4 e2 f0 f3 c9 blsr %rcx,%rcx 401595: 48 83 c0 01 add $0x1,%rax 401599: 48 85 c9 test %rcx,%rcx 40159c: 75 f2 jne 401590 &lt;_Z12popcnt_loop3y+0x10&gt; 40159e: c3 retq 40159f: c3 retq 00000000004015a0 &lt;popcnt_intrinsic&gt;: 4015a0: f3 48 0f b8 c1 popcnt %rcx,%rax 4015a5: c3 retq So the moral of the story is, use intrinsics.
&gt; std::deque and its complicated blocks-of-n linked list structure Thatâ€™s not what a `std::deque` is, at least not necessarily (and Iâ€™m currently unsure whether itâ€™ a legal implementation). [In libstdc++, at least, a deque is implemented as a vector of vectors](http://stackoverflow.com/a/6292437/1968), i.e. a vector of blocks of fixed size. It should be noted that this fixed block size depends on the size of the element type, and is very small for even moderately large types (itâ€™s `512 / sizeof(T)`), completely arbitrary and [has never been tuned or investigated](https://gcc.gnu.org/onlinedocs/gcc-4.9.0/libstdc++/api/a01503.html#a87949eb8a238d15bbc7d30d84cd3b8cf) since being inherited from SGIâ€™s implementation. As a consequence, Iâ€™m not at all convinced of the quality of implementation of `std::deque` and would advise against its use as a general policy. `std::vector` by contrast has been repeatedly tuned and benchmarked, and there exists extensive know-how of how to improve it, e.g. [from Facebook](https://github.com/facebook/folly/blob/master/folly/docs/FBVector.md).
I had always assumed until a couple of years ago that dequeues were implemented as ring buffers and grew like a vector. I did it that way years ago in a Smalltalk interpreter I wrote. I'm surprised that STL uses a chain of blocks. With the ring buffer approach, if your dequeue stays within a certain bound, you never need to allocate again once it gets up to size. What is the advantage of the chain of blocks approach? 
No, I meant he could enhance the software because it was open. 
It uses the null pointer to the type to create the function wrapper: template&lt;class F&gt; constexpr wrapper&lt;F&gt; make_function(F*) { return {}; } It uses the type `F` to construct `wrapper&lt;F&gt;` but it doesn't use what the pointer is pointing to, since its practically useless because it is null. Then in `wrapper&lt;F&gt;` it casts itself(ie `wrapper&lt;F&gt;`) to `F`(ie the lambda) because both the lambda and `wrapper&lt;F&gt;` are empty. template&lt;class F&gt; struct wrapper { static_assert(std::is_empty&lt;F&gt;(), "Lambdas must be empty"); template&lt;class... Ts&gt; decltype(auto) operator()(Ts&amp;&amp;... xs) const { // The cast of itself to the lambda return reinterpret_cast&lt;const F&amp;&gt;(*this)(std::forward&lt;Ts&gt;(xs)...); } }; It also asserts that the lambda is empty, just in case there is some insane implementation out there that doesn't make non-capturing lambas empty, highly unlikely, but at least it can catch it at compile-time, if it were to happen.
This is one of the most requested features in any HTTP framework. I achieved it creating a clearly documented "wall" to [separate HTTP producers and HTTP consumers](https://boostgsoc14.github.io/boost.http/reference/server_socket_concept.html). This will be more useful once I deliver other HTTP producers beyond the HTTP standalone server. The standalone server is useful for services that also depend on HTTP like some ReST services and UPnP.
You're right. I'll fix these issues. Thanks for the time following the documentation and for the detailed feedback. &gt; Anyway, good idea but needs polish. Yep. There are a few non mentioned things that I want to improve before submitting, but I feel the core is ready and that's why I started to look for feedback.
This page hies from the olden days when compilers couldn't yet match a master writing assembly by hand. Nowadays these tricks are useful for very little. I have only used them once or twice. An example: I am writing code in C where I want to find the Hamming distance between two bytes. It is next to impossible to write C code which will actually cause the compiler to emit the simple POPCNT instruction. GCC has an intrinsic, but what if someday I'm compiling my code on something other than GCC? Therefore I set a macro that, based on whether the compiler has the intrinsic or not, uses it or one of the techniques on this page. The only faster way to do it would be to use inline (or maybe even external) assembly, but there are limits to my madness.
Spoiling what you'll be able to find in the future documentation, Boost.Http follows the Boost.Asio threading model, so the user can handle HTTP requests in the same thread as all other network traffic. That way the application can be single-threaded, which is useful on small devices that expose a simple ReST service. Also, there is this document that will be updated and included later: https://github.com/vinipsmaker/gsoc2014-boost/blob/master/other_frameworks.md#cpp-netlib
&gt; GCC has an intrinsic, but what if someday I'm compiling my code on something other than GCC? You can get around that by using the Intel intrinsics rather than compiler-specific intrinsics. (Well, I suppose the Intel intrinsics are technically icc's compiler-specific intrinsics, but all the other compilers implement them as a pseudo-standard): #include &lt;nmmintrin.h&gt; #include &lt;stdio.h&gt; int main(void) { unsigned foo = 0xfeedbeef, bar = _mm_popcnt_u32(foo); printf("%x %u\n", foo, bar); } This works under icc, gcc, MSVC, clang, and probably others. 
("deque" is a data structure, pronounced like "deck". "dequeue" is a verb, pronounced like "D Q", meaning "to remove from a queue".) deque implementations are very clever. VC's uses a modulo trick, so balanced push_backs/pop_fronts or vice versa don't allocate memory. (The cost is that they're horrifically complicated; deque is one of my least favorite things to hack.) std::deque can't be implemented with a contiguous buffer, due to its invalidation guarantees. Specifically, push_back is not allowed to invalidate pointers/references, so that mandates some type of chunks being used.
libc++ attempted a new algorithms, which much like TimSort identifies sorted (and reverse-sorted) subsequences to speed up processing of mostly sorted sequences. I guess the author thought it was not susceptible to the same issues than quicksort; benchmark have repeatedly show it operated in the same ballpark as gcc on random inputs and much better on sorted sequences, but apparently missed a specifically crafted input.
&gt; I suspect that optimizing compilers are already pretty good at bit twiddling. Yes, but anyone studying compiler optimization should know these tricks. Just because the compiler can do it for you (and you should let it 99% of the time) doesn't mean you shouldn't be familiar with the tricks the compiler is doing. 
I used one of these for Hamming decoding for a class assignment. bool maskedParity(int byte, unsigned char mask) { byte &amp;= mask; byte ^= byte &gt;&gt; 4; byte &amp;= 0xF; return (0x6996 &gt;&gt; byte) &amp; 1; }
&gt; However whether it needs to be it's own lib under boost is arguable This. It used to be that boost was a set of generic libraries meant to be useable for everyone--as in they solved problems that all C++ developers faced. Now it's just an ever growing pile of stuff, a great deal of it quite niche. Everyone and his brother wants to get a library accepted into boost and unfortunately it seems that everyone and his brother gets to, even if the addition is only useful in a subset of domains.
Well, that's brilliant. Thanks!
Primitive arrays in java still use a quicksort variant (which is still technically quadratic worst case). It looks like introsort actually preserves most of the cache properties of quicksort while avoiding quadratic run-time, which would make it the safer choice. It looks like it could avoid memory allocation as well.
When used properly these aren't the kind of "tricks" a compiler does for you.
Good to see MS working on the future. But MS, don't forget the present. Specifically, C++14 is a real thing now.
~~references would never be invalidated in a ring buffer~~, which is contiguous except for the discontinuity at the wrap. [edit: obviously incorrect]
Repeated insertions without erasures will cause reallocation, invalidating everything.
Did you try std::bitset&lt;&gt;::count()? It's been compiling to popcnt for me since years ago.
&gt; Are there any benchmarks for these tricks? &gt; *[snip]* &gt; So the moral of the story is, use intrinsics. Can I just add the that, make sure you still benchmark :) Different instructions can have vastly different performance characteristics. So though probably not the case here, sometimes a few elegant asm instructions run slower than what seems like a horrid mess of others. This can happen for example if the "elegant" also means "rarely used", in which case Intel probably hasn't optimised them in the cpu.
 uint64_t popcnt_bitset(uint64_t n) { std::bitset&lt;64&gt; set = n; return set.count(); } 00000000004015a0 &lt;popcnt_bitset&gt;: 4015a0: f3 0f b8 c1 popcnt %ecx,%eax 4015a4: 48 c1 e9 20 shr $0x20,%rcx 4015a8: 48 98 cltq 4015aa: f3 0f b8 c9 popcnt %ecx,%ecx 4015ae: 48 63 c9 movslq %ecx,%rcx 4015b1: 48 01 c8 add %rcx,%rax 4015b4: c3 retq 4015b5: 66 66 2e 0f 1f 84 00 data16 nopw %cs:0x0(%rax,%rax,1) 4015bc: 00 00 00 00 It does use `popcnt`, but it only does it 32 bits at a time for some reason. Still nowhere near as concise as the intrinsic, and probably not as fast either. EDIT: [benchmark results](http://www.reddit.com/r/cpp/comments/2fc92y/bit_twiddling_hacks/ck89wpf?context=8675309): the `bitset` version takes about 1.3 times as long as the intrinsic, which is much faster than the loop-based versions, so you should probably prefer that unless you absolutely need that little bit of extra performance.
You didn't specify but, if you're on Windows, then you're probably using MinGW, and if you're using MinGW then you're stuck with 32-bit.
Benchmarks: #define BENCH(func, total_out) do { \ const uint64_t limit = 1ULL &lt;&lt; 30; \ for (uint64_t i = 0; i &lt; limit; ++i) { \ total_out += func(i); \ } \ } while(false) int main(int argc, char** argv) { uint64_t total = 0; switch (argv[1][0]) { case '0': BENCH(popcnt_loop1, total); break; case '1': BENCH(popcnt_loop2, total); break; case '2': BENCH(popcnt_loop3, total); break; case '3': BENCH(popcnt_bitset, total); break; case '4': BENCH(popcnt_intrinsic, total); break; default: break; } std::cout &lt;&lt; total &lt;&lt; std::endl; } Designed to call the function a crapton of times in a way that it can be inlined. Although that turns out to be a moot point, since GCC just decided to make an array of function pointers and do indirect calls on every iteration of the loop. Function|Time :----|----: | popcnt_loop1 | 43.590s | | popcnt_loop2 | 11.801s | | popcnt_loop3 | 6.650s | | popcnt_bitset | 0.980s | | popcnt_intrinsic | 0.740s | Not surprisingly, the intrinsic is fastest. I'd suggest using the standard library version for portability, though.
Timsort also handles reversed runs, which might outperform quicksort in practice (almost certainly heapsort).
&gt; It's still probably necessary to keep the bit twiddling version around for non-x86 platforms, or for use on older x86 systems that don't implement popcnt. Isn't that logic typically contained in the intrinsic itself? I'd assume that the compiler's logic is something like if (this fuckwit doesn't have SSE4.1) { count_them_slowly(); } else { emit_popcnt_instruction(); }
See those `r`s in the register names? I'm using /u/STL's MinGW distro, which he builds from mingw-w64. I suppose it's possible that this standard library is built to only use 32-bit numbers, though[.](/title_text "Also, hi famous person!")
No. The intrinsics are expected to map directly to a single machine instruction. It would seriously hamper your ability to write performant SIMD code if all that goo resulted from using an intrinsic. These are things that are expected to be at the heart of tight loops. For the example I gave, gcc and clang will fail with a compile error if you don't build with `-msse4.2` or another flag that includes that flag; and even if it didn't, the link would fail with an undefined reference, as the intrinsic would not be enabled and it would be treated as an actual call to a non-existent function. MSVC compiles it without extra flags. But in all cases, the generated code will cause an illegal instruction fault on hardware that doesn't implement that instruction. There is no detection, you have to wire that up yourself. Gcc for instance provides [some assistance](https://gcc.gnu.org/onlinedocs/gcc/X86-Built-in-Functions.html#index-g_t_005f_005fbuiltin_005fcpu_005fsupports-3783) for doing that, and in C++ mode even allows [multi-versioning](https://gcc.gnu.org/wiki/FunctionMultiVersioning) of functions. But then you're back to using gcc-specific features, although they'd almost certainly work under clang too. Unfortunately, the [Intel Intrinsics](https://software.intel.com/sites/landingpage/IntrinsicsGuide/) don't seem to have anything for CPUID, so it looks like you have to resort to a bunch of ifdefs if you want portability. For gcc there's the thing linked above, MSVC has [its own intrinsic](http://msdn.microsoft.com/en-us/library/hskdteyh.aspx), and I don't know off-hand what icc has. And there's always inline asm. 
That's useful to know. So I can expect things like vector math libraries to have `#ifdef __SSE__ simd_way(); #else normal_way() #endif`, but if I'm writing one myself, I need to take care of that myself.
Well, that explains it. The `bitset` is implemented as an array of 32-bit integers, so even though the processor supports 64-bit operations, it doesn't use them.
I don't know if this HTTP library should go in Boost but I think it would be great C++ to have a standard library somewhat equivalent to that of .NET, Java and such. 2D stuff is going this way for example.
C++ isn't Java, Python, or the rest. We don't want it to be. The long standing tradition in C++, and it's a good one that we should keep, is tying together multiple libraries from many sources that do what we need the way we need it to. The difficulty has been having a baseline that provides the basic functionality we all need in order to make that composition easier. This is what Boost was meant to achieve. Instead of having 5 different versions of mutex lock for example, boost provides a single one. Boost was meant to be a testing ground for the standard library, not a gigantic framework that has a kitchen sink, pile driver, monkey wrench, router, welder, car jack, jet fuel dispenser, guitar tuner, pocket pussy, ...etc...etc... Now it seems boost has become a catch-all library for every single experimental whatever someone wants to shove into it. If someone came up with a generic blow-job library it would probably be accepted...so long as it made adequate use of fusion.
Come to think of it, any branch like `if (this CPU has this feature)` should be basically free on modern processors, since the branch predictor will get it right every single time.
Yeah, the simple fact that AFAIK every implementation uses a completely arbitrary number in a place that would probably benefit greatly from tuning makes me distrust `deque`'s performance on general principal.
In order to implement that branch requires executing the `cpuid` instruction which clobbers four registers (eax, ebx, ecx, and edx.) In x86 mode that's either 4 out of 7 (non-PIC) or 4 out of 6 (PIC) of all your general purpose registers clobbered that would need reloading, which would be a complete performance disaster, particularly in a loop. It's really not meant to be used like that â€” you're meant to run it once during startup/initialization and use the result to set some function pointers. 
Heapsort (any form) overall doesn't use CPU cache efficiently even though it's memory efficient and run-time optimal for worst case. One of the nice things with quicksort is that elements have good locality after partition (as long as there's a good pivot). Have you done any tests using radix-sort?
It's worse than just clobbering some registers. CPUID is a serializing instruction, which means it flushes the CPU's execution pipeline. This instruction is a performance disaster. GCC 4.8+ has the ability to specify a target instruction set for a specific function, and to "overload" a function by writing multiple versions with different targets. I haven't looked at the assembly, but I assume that the emitted code does some table shuffling as part of dynamic initialization, such that CPUID is only ever called once. This might prevent these functions from being inlined though.
I took a look and it's using the special ELF `STT_GNU_IFUNC` symbol type (explained [here](http://www.airs.com/blog/archives/403) by Ian Lance Taylor) which unfortunately means function multiversioning only works on Linux, not on MinGW or OS X, which is rather disappointing. It essentially uses a slot in the GOT and PLT just as if the symbol had was in a shared library, with special code in glibc to handle the case where the binary is statically linked and there's no PLT or GOT. The resolver function is called during early startup in a constructor with high priority so that it runs before normal constructors, from what I can tell from the [`__builtin_cpu_init` documentation](https://gcc.gnu.org/onlinedocs/gcc/X86-Built-in-Functions.html#index-g_t_005f_005fbuiltin_005fcpu_005finit-3781). And yes, that means they can't be inlined, although that seems like a reasonable restriction. 
Your wish is granted: http://utfcpp.sourceforge.net/
I imagine some of these actually aren't practical to rely on the compiler doing, since there's at least more than one way of deriving the values (computing `log10` for example). You still very much run the risk of indirectly using inefficient instructions for an architecture or a sub-architecture though. Compilers can still handle some fairly incredible feats (bit rotates, etc...).
&gt; A nice feature would be support of printf format specifiers, eg %s and %d so it could be more easily dropped in as a replacement. No, it would not. Why do we need to specify the type?
* I loved what you did. Keep going, please. * I understand input string is not always captured at compile time and this is required to some forms of translatable strings that aren't available at compile-time, but do you think it would be possible to add some template trick to guess the optimum value for `stack_print`? * I suggest you forget about the scripting idea. [Translatable strings should be entire sentences](https://www.gnu.org/software/gettext/manual/html_node/Preparing-Strings.html#Preparing-Strings). And take a look at the [gettext manual on plural forms](https://www.gnu.org/software/gettext/manual/html_node/Plural-forms.html#Plural-forms). * Is there a delimiter to indicate the end of the numeric arg? I mean, `"%0 %{1}0 %2", "a", "b", "c"` should print `"a b0 c"`. Is there something similar? Do not use a [unreliable design like bash](http://www.phoronix.com/scan.php?page=news_item&amp;px=MTIyOTA).
While I agree with you, I would say the majority of C++ devs is still stuck with C++ 98 compilers, given the usual IT upgrade process. EDIT: downvoted due to stating the sad reality of enterprise devs.
Actually, there is. When it becomes too damn large and full of crap hardly anyone needs then it degrades. We've seen this happen as library authors move on to who knows where and the library remains un-adopted by anyone. Then it just becomes work to maintain. There was a time when the boost library set really was meant to be a proving ground for standard proposals. That was its charter. The committee needed real world evidence that something worked out there before just throwing it into the standard library or language. Boost was the community's way of doing that experimentation and growth. It can't serve that purpose if it's filled with a bunch of stuff that has no business being in the standard library. &gt; Boost is an add-on optional framework. This is exactly what it was NOT meant to be and exactly what I mean.
Still good to make something or else nothing will change.
Thanks! &gt; return {}; I initially misread this as returning an empty function/lambda, but instead it's returning a default constructed wrapper&lt;F&gt; object. Not used to the new braced initialization syntax as the compilers I use is yet to support it! 
Still only Mac OS X and Windows support. :( Does anyone know about mobile OSs support status?
&gt; I'd drop half the libraries from Boost in a minute. Spirit, meta programming, huge heavyweight stuff that I'm never going to use for the reasons you mentioned. But I don't think there's a way back. Except that's the issue. If you don't use that stuff then it doesn't effect your project. The very worst it could be considered is a waste of bytes on your hard disk. They're header only, and those that aren't have their own .so/dll. It's not like using boost filesystem means you've had to use Spirit or MPL.
So what do you propose? That we stop working on new compilers and standards becaus of the poor people who are stuck in a shitty job? 
This sounds and looks fantastic. CMake is becoming more and more the standard project description for C++ and many tools support it nicely. Can biicode coexist with cmake? Other than this concern, I'm very excited to try this out. Edit: its cmake based! Hooray!
OK so next concern is totally the matter of being able to leverage this at work using our internal git repos. Doesn't appear to be possible yet.
I should have been more clear. tinyformat allows the use of any format specifier for any type.
I don't propose anything, I was just stating a fact. But it seems people like to downvote facts.
I like the idea of it, but be sure to check the [Terms and Conditions](http://web.biicode.com/legal/terms-and-conditions/). Unless I'm misreading things, unless you're using the premium version of the service, it appears you must give away all rights to the code you host in the service. That's a pretty onerous licensing agreement.
Yes, but how relevant is that fact to the discussion? It's totally irrelevant if there are still people using C++98 when we talk about MS adding/extending C++14 support. 
You're not giving away all rights "Biicode does not acquire any intellectual property or industrial rights or similar legal positions of economic content related to the code made â€‹â€‹available by the user on the Biicodeâ€™s platform." You can specify your license if it was GPL, MIT, Apache or anything else "However, the code that you store may include conditions or limitations of use, which must be embedded in a clearly visible way in the code itself. All other users must respect these conditions and limitations of use." So it sounds sort of like github.
It is relevant, because commercial compiler vendors, like Microsoft, tend to focus on features their customers will pay for. As an example, most other C++ commercial compiler vendors are even worse than Microsoft in terms of compliance. Personally, I don't like their Visual C++ team tends to have other priorities than ANSI/ISO C++ compliance, but I imagine those product managers have their reasons ($$$$) for which features get given more priority.
There are other pieces of that section that give me pause, though: &gt; Consequently, when storing code or content of any kind in Biicode except under the PREMIUM category, you will be assigning Biicode its users the right to reproduce, distribute, communicate publicly and to transform the code, without any time or territorial limitations and in the categories necessary to carry out the activity developed in Biicodeâ€™s platform, including the commercialization by any means of the code or the derivative programs which it may be incorporated to or in which your code has been reused. This assignment is free, unlimited and irrevocable, and shall be deemed granted the moment you store code on Biicodeâ€™s platform. I'm not saying you're wrong, or that they don't intend to have it used the way you imply (like Github). I just know I'd be apprehensive to use it for anything that wasn't BSD (or similarly) licensed, since you might cause license violations without ever meaning to. Licensing is a giant nuisance, sometimes (most of the time). 
Disclaimer: I work for biicode. Hi, /u/NotUniqueOrSpecial that's not what the ToS say, however I do understand the confusion: it's legal jargon and it's difficult to understand for us devs too. In fact, we have decided to sit down and talk about it because we might need to give it a twist to make it clearer. What those paragraphs mean is that the code uploaded by free users WITHOUT any licence will be by default shared with the rest of biicode's users. HOWEVER, if that code is uploaded with any kind of licence, then the conditions of the licence will be respected always. We are a **code reuse** platform, it is normal that we encourage users to share their code but if they decide to apply other kind of conditions ot their code, that's something we will always respect. 
Where I work some parts of the codebase can't leave the intranet without a lot of lawyers getting involved. 
Hi! I'd love to be able to recommend biicode to my supervisor for overhauling our builds. I'm in the middle of evaluating our options. The biggest reason I can't recommend biicode is a lack of an intranet concept. If the premium service would allow this it would be a very big deal. I can understand however that this is challenging given the service oriented nature of biicode. Food for thought though. 
I looked at it briefly. The phrase "share code and success and we will share revenues" on the front page as a major bullet point seemed like a bad sign. Their business model seems to be letting you upload code for free, which they then sell to their "premium" users, possibly giving you a cut. That's why the T&amp;C are full of "you will be assigning Biicode its users the right to ..." terminology, and why you can't revoke that contract. From the other side, it seems to be "pay them for access to code others have uploaded" - so you're either paying for MIT and GPL code you could get from github at no cost, or for murkily licensed code that may bite you later. Combine that with other bad signs, like no API and a contractual requirement that once your data is in their system the only way to access it is via tools they provide you and it's not good. I can't tell whether it's a well-intentioned idea incompetently turned into a bad business model or whether it started as "lets monetize something like github" - but they won't see any of my code.
I don't see any problem with this (edit: the money bit). This is win-win-win. They provide a platform for people to re-use your code and get paid for it.
Is this a replacement for `dpkg`/`yum`? Last I heard that's what people mainly used for managing dependencies of C++ projects: package it with dependencies specified.
I vouch for git-submodules. They all download to a deps/ directory. Then since I build with premake, each dependency has a .lua file defining the build, and the main project's premake4.lua aggregates what it needs so that the solution has all the deps defined as subprojects in VS/Xcode. For binary deps I would make those small lua scripts download the lib or use the distro's package manager, depending on the platform. Versioning in git ensures that a tagged revision will always compile by checking out the appropriate versions of its deps. 
Just to inform redditors of what you posted on your blog: O'Reilly has a sale that let's you purchase the early release version for half the price until Sept.9. 
&gt; Actually, there is. When it becomes too damn large and full of crap hardly anyone needs then it degrades. Well, my library is not crap. I invested a lot of effort in the design front (together with my mentor) and I gathered feedback and use cases from several communities to be sure I was doing the right abstraction to be standardized. And before submitting to Boost, I intended to increase the implementation quality as well. I feel ofended due to this plain "full of crap" statement. Can you point where do you think my design is bad and why?
Awesome, that's good to know. I take it said verbiage already been run past legal counsel, then? My worries stem from being the guy who our own (admittedly strict) legal team comes to every so often about various open source licenses and what certain terms mean with respect to how we develop and distribute software. Having been on the other side of that discussion, where our legal team didn't feel some particular verbiage was clear enough (and so we couldn't use a library, for instance), it'd suck to have something like that happen to you.
libc++ isn't a standard quicksort though, so none of the 'normal' worst cases for quicksort apply. libc++'s implementation does well with sorted, reverse sorted, partially sorted, etc. Pretty much any sequence with patterns in it: See slide 54 http://llvm.org/devmtg/2010-11/Hinnant-libcxx.pdf So to construct the worst case the author runs libc++'s sort with a special comparitor which observes the comparisons that the algorithm makes and it constructs the worst case as it goes. The result actually does exhibit patterns, but positioned just such that the libc++ doesn't catch it. For example, if you rotate the worst case by one element then suddenly libc++'s algorithm sees the pattern and is back to being faster. http://coliru.stacked-crooked.com/a/c325a51cd5040654
&gt; I don't see any problem with this. Does not make it [the approach] universal, does it now?
&gt; "lets monetize something like github" This is what it looks like. Any serious developer already has or should have a methodology to reuse own code, so I don't see any benefit of giving up rights to my work to some leech.
&gt; their ToS appears to give them the right to remove copyright notices. This alone would prevent me from dealing with them. 
Absolutely not. Biicode has not the right to remove copyright notices. They will be fully respected. Nowhere in the ToS says so.
Baffled to see where you got that from. Edit: Again, we are open to revise the content of the ToS because they are legal jargon, and make them clearer and even modify them to improve them but I cannot manage to see where you read that from, to be honest.
Think in terms of things. While the "bicycle" model is kinda bad for leaning about oop, it serves a purpose. IANA networking guy, but: The overarching goal is to establish a connection with another computer. You can receive, and send arbitrary data though it. This outlines some methods and data to implement. Connection.handlerFunction Connection.send() You can use different proticalls to do this. So you might have a UDPConnection class that still has that handle and send that method, and then TCPConnections as well. An OOP model is to say "hey! These things have similar uses, and so should behave mostly the same way". It shouldn't matter what exact type of protocol we use, but the abstraction of sending and receiving data is the same. To get from end to end, I want a "transportationObject" be it feet, bicycle or elephant. 
&gt; However, you hereby authorize Biicode to use, update, adapt, transform, enhance or modify in any way the code stored on the platform, especially to make it compatible with other programming languagesâ€‹â€‹, applications, programs, platforms or devices, and to make it accessible to any user at any location, with no territorial or time limitations. This authorization is free, unlimited and irrevocable, and shall be deemed granted at the time of the publication of the code on Biicodeâ€™s platform. An irrevocable authorization to modify the code in any way pretty unambiguously covers modifying the code to remove all copyright notices. I don't have the slightest clue what the purpose of this paragraph is if it isn't to give you additional rights beyond what the code's license grants you.
I generalized the example in order to avoid leaking some details. 
It takes four spaces at the beginning of each line of code for reddit to display a properly formatted block of code. Should also be in r/cpp_questions Make it easier for us and tell us what strange thing you are seeing. When dividing floats, get in the habit of using float constants: 4.0 instead of just 4
[Image](http://imgs.xkcd.com/comics/pointers.png) **Title:** Pointers **Title-text:** Every computer, at the unreachable memory address 0x-1, stores a secret. I found it, and it is that all humans ar-- SEGMENTATION FAULT. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=138#Explanation) **Stats:** This comic has been referenced 23 times, representing 0.0710% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_ck9aqm8)
Regarding the `sort` example, couldn't a similar shortening be achieved with Concepts? Edit: ok maybe I should read the whole thing before posting. I'd say that Iterable as a concept name is a little ambiguous though, maybe Traversable?
Or maybe you were down voted because you are talking about something tangential to the discussion at hand.
Cool. Thanks for a lengthy explanation; I, for one, definitely will be keeping my eye on you guys, the product _is_ intriguing.
Ambiguous with what?
Iterable could also be read as something which can be iterated itself, like an iterator or an integer. I might be over-thinking it, I've been messing with Haskell a lot recently. The temptation to treat Concepts like typeclasses is immense.
As much as we hate it, money makes these things work. Github does not make Github issues universal, yet tons of projects use it. Github could not survive without the private model. Consider this another avenue to monetizing your code and distributing updates for the same. There is nothing wrong with that. Feel free to publish it any other way you like as well. Would I use this? It all depends on the pricing and licensing. For long as I'm selling my code, I'm happy to pay a developer to develop a core library that I use to do so. I want the ecosystem to thrive, not be starved of resources.
This ... &gt; you hereby authorize Biicode to use, update, adapt, transform, enhance or modify in any way the code stored on the platform, especially to make it compatible with other programming languagesâ€‹â€‹, applications, programs, platforms or devices, and to make it accessible to any user at any location, with no territorial or time limitations. This authorization is free, unlimited and irrevocable, and shall be deemed granted at the time of the publication of the code on Biicodeâ€™s platform ... is a problem. It's a click-wrap contract to sign away most of a developers rights. This ... &gt;you authorize Biicode indefinitely, freely and irrevocably to host and offer its users the code you have posted under the FREE category, even after the closing of your account and the termination of this agreement ... doesn't fill me with the warm fuzzies, either. It's basically saying that anything uploaded to you is yours to host, use and give away or sell forever. It no longer belongs to the uploader. Users can't delete their code, nor revoke your permission to use it, sell it or download it, even if they close your account with you. (I understand, given your product architecture *why* you ask for that, but it's still a problem). A contract is generally much stronger if there is something of value involved, even if it's just a token amount. You see a lot of nominal sales of something otherwise of minimal value for a dollar [or a cent](http://www.foxnews.com/us/2014/05/09/uss-saratoga-destined-for-dismantling-after-one-cent-deal-with-texas-firm/), for that reason. If a developer agrees to your contract, then accepts a nominal payment from you then you have much stronger legal grounds to do whatever you want under the terms of that contract. I'm sure that's not what's going on at all; that you have wonderful intentions that you're just terrible at explaining in English. But I can't tell for sure. If you want people to upload code to your service you need to be crystal clear about what terms that's under. And once that's done, you need to try and explain what value you're bringing - that's not something you've done so far. And *then*, if you want this to be used by anything other than unskilled hobbyists, you probably want to explain what your business model is - will you be around in a year, or will any effort expended learning and integrating this workflow be wasted, and leave people screwed once you go bust? It's easy to throw together a minimum viable product where you're offering something to the public for free - they can try it out, and if they don't like it they can walk away. It's very different when you're asking them for something of value, and then attempt to (contractually) prevent them from walking away. You've not reached the level of MVP yet, even assuming the software you've written is complete and perfect.
[Networking for game programmers](http://gafferongames.com/networking-for-game-programmers/) would be a good idea to look at. The most interesting thing I found was the method for preventing packed loss, where you basically use a squence number and a 4 byte bitmap to represent the last 33 packets sent. ...01000 would be 4 packets ago, ...00010 would be 2 packets back, ...01111 would represent all of the last 4 packets but not the packet 5 ago. As for the OOP side of things. Try not to fall into the OOP trap too much. C++ doesn't force you to use OOP. In most cases actually thinking in terms of things as 'Objects' can result in bad architecture. The 'real world' in most cases doesn't map into the programmers model. Try and handle things in terms of interfaces or components rather than fixed objects. For example you can just store your packet in a std::vector&lt;char&gt; and pass an iterator around your functions that reads from the received packet, advances the iterator and returns a result. In this case the iterator can be though of as a reader interface (in a language like Go, you actually have a reader interface). You might have functions like: Packet readPacket(std::vector&lt;char&gt;::iterator &amp;it); Header readHeader(std::vector&lt;char&gt;::iterator &amp;it); int readInt(std::vector&lt;char&gt;::iterator &amp;it); Alternatively you might pass an ifstream around. You could take actions directly in the parsing, but I think it would be best to separate it out. If your using C++11/C++14 you have access to std::function. So you could just return a function to execute. Otherwise you can make a bunch of packet classes, in this case OOP inheritance does make sense: class Packet { int packet_type; Client* sender; } class SetValuePacket: public Packet { int value_id; int value; } class SendMessage: public Packet { std::string message; } Then your going to need to implement an execute function for the specific packet type. It can either perform the action or return a std::function. Remember to verify your packets before execution though. Make sure they where received from who they where claimed to be from and that person has permissions for that action and that the action is valid. If someone send a string and claims it's length 10 bytes, only read 10 bytes (rather than until a terminator) and don't read past the length of the packet. Don't let a string claim to be a bazillion bytes. You might also have to deal with being DoS resistant, for example if a new packet allocates memory, you might need to prevent 10,000 packets a second by implementing some kind of rate limiting. If the packets received are modifying object's state directly then you will need to find a way of indexing all your objects with a unique identifier that is shared between all the peers. You might also need to implement a ownership concept, so a client can only modify things it owns.
I hope you'll flesh out Appendix 3 - I want to know what you meant by qualified :-)
&gt; I don't see any problem with this. What I meant was that the world does not revolve around you. You don't see a problem with this but it does not mean someone else might. &gt; As much as we hate it, money makes these things work. What's that got anything to do with anything? Who's we who hate money? I, for one, love money. Not money so much as the amount of money (and the freedom it provides me with). &gt; yada-yada-yada Cool story, bro.
The OP initially said: &gt; The phrase "share code and success and we will share revenues" on the front page as a major bullet point seemed like a bad sign. Then you went on to say: &gt; What's that got anything to do with anything? Who's we who hate money? I, for one, love money. Not money so much as the amount of money (and the freedom it provides me with). TOS-specifics aside (those **can and should** be fixed), the concept is sound. &gt;&gt;yada-yada-yada &gt; Cool story, bro. Why would you do that?
Andrei knows. He and I discussed the implications of D ranges on a hypothetical `is_word_boundary` algorithm with bidirectional iterators vs. bidirectional ranges. We couldn't find a way to express it with ranges that didn't cause the algorithm to go from O(1) to O(N).
There is precedent. Python uses the same "iterable/iterator" naming. See http://www.shutupandship.com/2012/01/understanding-python-iterables-and.html. &gt; * **Iterable** - A container is said to be iterable if it has the `__iter__` method defined. &gt; * **Iterator** - An iterator is an object that supports the iterator protocol [...] EDIT: Ditto for Java. Ditto for Dart. Ditto for JavaScript.
Go away.
If this gets in C++17, I think it'll be my favorite new feature (concepts are up there, too). It seems like a really fun and interesting and challenging library to design. Eric, I'm wondering about your thoughts on a D-style "sorted&lt;RangeT&gt;" type. If you called std::merge or std::upper_bound on a non-sorted type, it would give you a compile error. Some of the range algorithms could take advantage of it, such as concat/sort: merged = sort(concat(some_previously_sorted_vector, sort(some_range_generator()))); And find(): sorted_v = sort(move(v)); for (foo : w) { something(find(sorted_v, foo)); // find uses binary search for sorted types } And maybe std::map/set could return a sorted_range&lt;T&gt; type that would be splittable, a new kind of range concept between bidirectional and random_access. (Although this would require those trees to store their sizes in each node, so it's probably not worth it...) Another idea that would really make ranges useful would be a "yield" keyword for writing functions that generate ranges. Similar to lambda functions, the compiler could mechanically convert code like this: [] (auto x) -&gt; int { int some_local = 17; // do stuff yield something(x); // ... do more stuff... yield some_local; // .... etc... } Into a function/range object like this: struct anon_generator { int entry_point; int some_local; some_type x; // more "locals" anon_generator (some_type x_init) : entry_point(0), x(move(x_init)) { } int operator() () { switch (entry_point) { case 0: entry_point = 1; some_local = 17; return something(x); case 1: entry_point = 2; // "more stuff" return some_local; case 2: // ... etc... } } struct iterator { int curr; anon_generator&amp; gen; iterator(anon_generator&amp; g) : gen(g) { curr = gen(); } iterator&amp; operator++ () { curr = gen(); return *this; } int&amp; operator* () { return curr; } }; iterator begin() { return iterator(*this); } iterator end() { ..... } }; These "generators" would be so easy to compose, and would make async I/O such a pleasure... But it's probably too much to ask. It's a good thing you're designing this library and not me, cause I'd get lost in the possibilities and end up with nothing... I wish you the best of luck on this project. I'm pretty excited about it. :)
Your wordpress is terrible. You must be a horrible person. :P Lot of people who've apparently never been to Eric's wordpress or missed the tagline.
I agree. Actual iterators have their own concepts. They're also not enough to describe something that is "iteratable", which is something I'd expect you can move through from a starting point to some possible end point. Iterators in C++ are just a pointer, they don't have an end point in and of themselves. So I think Iteratable is a good name for the concept.
Well said. I feel like a lot of the developers chiming in that the ToS doesn't matter because of Biicode's intent, or otherwise excusing them for some reason, have either never worked on a commercial product, or have never been bitten by a licensing issue. A lot of the responses seem to naively think that good feelings and warm fuzzies will protect you, when instead the harsh reality is that the wrong licensing problem at the wrong time can completely destroy a product.
~~The big news is D is now a LLVM language.~~ How is LLVM on Windows doing these days? Not so much worried about binary compatibility with VC++ necessarily, but more about support for stuff like SEH.
Thanks for doing this work. I was sold on the concept of ranges from Andrei Alexandrescu's advocacy a few years back. Regarding the advance overload, wouldn't that be better as: template&lt;BidirectionalIterator I&gt; void advance(counted_iterator&lt;I&gt; &amp; i, DistanceType&lt;I&gt; n) { i.n_ -= n; advance(i.it_,n); } To allow for any other specialization of `advance` on type `I` to apply?
LDC is an external project and has been available as such for quite some time.
Ahem...
Oh my! :-) Yes, I think so.
Do compilers always inline such thin wrappers like `advance(i.it, n_)`? I vaguely recall that pre 2010 (before lambdas became mainstream) most compilers would stop at half a dozen of layers, whereas currently clang/gcc (haven't been using MSVC for a long time now) seemingly recursively inline all such silly one-line wrappers to almost arbitrary depth. I wonder if someone is aware of any explicit compiler advancements that make this possible.
I haven't thought too much about a sorted range adaptor. It's an interesting challenge. Range adaptors are generally lazy, and writing a sort algorithm that sorts on demands is a super-interesting research project. Certainly, just sorting all at once might be easiest and fastest, but it would be nice if `rng | view::sorted | view::take(10)` only partially sorted the sequence. Regarding `yield`, I wrote a blog post about range comprehensions. My website is FUBAR at the moment, but you can see an example [here](https://github.com/ericniebler/range-v3/blob/master/example/comprehensions.cpp). The relevant bits: // Define an infinite range containing all the Pythagorean triples: auto triples = view::for_each(intsFrom(1), [](int z) { return view::for_each(ints(1, z), [=](int x) { return view::for_each(ints(x, z), [=](int y) { return yield_if(x*x + y*y == z*z, std::make_tuple(x, y, z)); }); }); }); This defines an infinite range `triples` that generates the Pythagorean triples. What's more, it requires no special `yield` keyword. Such a keyword might be a nice addition, but that would be a separate proposal. I have my hands full at the moment. :-)
LLVM for Windows seems relatively complete, I tested it on a large project and didn't run into any problems. However, I did not understand the benefit since I was stuck using Microsoft's STL. Without libc++ I did not see any benefit to using Clang on Windows. Not sure how it is for other languages though.
Have you tested sanitizers when using MSVC compatible clang? Those and great diagnostics are more than enough to use it on regular basis.
I'd found some boost mailing list discussion related to this ([here](http://lists.boost.org/Archives/boost/2009/07/154225.php)), but the specification for is_word_boundary wasn't clear from the example. Could you please elaborate briefly?
No, I didn't know about that functionality, it looks incredibly useful. I am currently using linux for the first time in 5 years and working with clang for the first time ever. So I am very behind the curve on what is possible with clang. If I wasn't so excited about everything I am learning I might be overwhelmed.
There are the benefits you always get from targeting multiple implementations: problems that might not be picked up under one can be found on another. It would be nice if libc++ were available as well so that dependencies on the standard library implementation might be detected as well, but even just distinct compilers is enough to catch some problems. Part of the above is simply implementation differences, and part of it is the different warnings offered. Clang has a bunch of compiler warnings, and now optimization pass remarks, that can help you fix things in your Windows codebase. `-Weverything` is useful for finding new warnings. There are also the well known benefits of clang: clear diagnostics and faster compilation. Clang also provide some handy tools, like its static analyzer and sanitizers. At the moment only the address sanitizer 'officially' supports Windows, but it wasn't too difficult to hack ubsan to work too. If you can give up VC++ compatibility then clang also supports many pure language features on Windows that VC++ does not: expression SFINAE, extended constexpr, binary literals, digit separators, generic lambdas, variable templates, etc. Clang also implements C99 and C11.
(This is the same reply I wrote to /r/programming) As the author of [The Meson Build System](https://github.com/jpakkane/meson/wiki) whose high level goal is roughly the same (do what CMake does but with a better syntax) let me put in a few words. Attempting to improve CMake from a user point of view is an admirable goal. Unfortunately it is also, for practical purposes, impossible. The reasons include the following. The true usability elegance of object orientation does not come from getter and setter functions, but from the better syntax that they provide. Just the fact that you can say v.do_something() instead of class_name_do_something(v) makes all the difference. Your code is denser, easier to read and all around more pleasant. CMake core syntax does not permit this. The second thing is that CMake does not provide a good type system. Everything is a string. As an example, arrays are strings which contain a semicolon. But you may also use it as a string. If a semicolon appears in your string by accident, it might be interpreted as an array. Or it might not. This leads to all kinds of fun things. Most people append things to strings like this set(FLAGS "${FLAGS} -myflag") But what happens if someone uses the append command? list(APPEND FLAGS "file with spaces.foo") You end up with a string that, when expanded, looks like this: -flag -myflag;file with spaces.foo This contains two different separators mixed in one string. Feel free to think about how you would split this out into command line arguments reliably. Remember that it needs to be properly quoted to go through Make + the shell. Or not, if you are using Visual Studio. 
I agree with you that the core of cmake is just wrong (especially the string escaping and scopes and automatic string evaluation, I also think that generator expressions are not the solution) However with a couple of extensions the cmake languange could easily be converted into a useable scripting language with backward compatibility. That being said: CMake has a huge following (probably because its the first plattform independent build system which got traction) and is sometimes a requirement for a project (like in my case) and because of that making cmake easier and extending its functionality makes alot of difference. Often changing the build system is just not an option. 
/u/NotUniqueOrSpecial sorry for an un-prompt reply but I'm recovering from surgery. :) We have the situation where we support 4 OS variations requiring us to maintain builds of various third party dependencies across each platform. Some versions are specific to the platform. This is a rather large chunk of software too. From there we get into our plugin layer and python modules. Some of these are built against several different versions of a host application as well. Finally you have our layer of stand alone applications. At the moment I'm looking at a combination of Rez and CPM to overhaul a mountain of bash scripts and Makefiles. I would be very interested to hear any suggestion you might have.
A couple weeks ago I was thinking about that very problem (a lazily-sorted range), and I realized that it was fairly easy to adapt quicksort for it. If you have some random-access [index] operator, you (recursively) partition only the side of [index] and leave the other side "to-be-sorted-later-maybe." The lazy-sorted range-type ends up with a strong resemblence to a binary tree, with the chosen pivot being the "root" of each subtree/subrange. The type could look something like this: template &lt;class RanIt&gt; struct lazy_quick_sort { RanIt lo, hi; // the begin and end of the range to sort RanIt piv; // initialized to equal hi, meaning unknown unique_ptr&lt;lazy_quick_sort&lt;RanIt&gt; &gt; lower_sorted, higher_sorted; // null-initialized ValueType&amp; access_index (RanIt k) { if (lo + 1 == hi) return *lo; // "base case" if (piv == hi) { set piv to some median of 3 or something; partition [lo, hi) with *piv piv = the pivot's position in the partitioned-range; allocate lower_sorted and higher_sorted; lower_sorted-&gt;lo = lo; lower_sorted-&gt;hi = piv; lower_sorted-&gt;piv = lower_sorted-&gt;hi; higher_sorted-&gt;lo = piv; higher_sorted-&gt;hi = hi; higher_sorted-&gt;piv = higher_sorted-&gt;hi; } return (k &lt; piv ? lower_sorted : higher_sorted)-&gt;access_index(k); } }; Anyway... something like that. I was all proud of myself, then I found [an exact description of this idea on Wikipedia](https://en.wikipedia.org/wiki/Selection_algorithm#Incremental_sorting_by_selection). So I just figured it was already well-known. The above code could be adapted to access regions rather than individual indexes, and it could do insertion-sort on small ranges, and it could do heapsort if the depth is bad, and it could be more efficient with memory by only storing piv in most nodes, and it could "get out of the way" once both sides are sorted etc. etc. It's more reusable than a conventional sort because it can do partial_sort and nth_element efficiently. EDIT: Another cool thing about this: you don't need the underlying range to be RandomAccess. You need bidirectional (for the partition), IndexCompare for the (k &lt; piv) part, and "just give me three random things in O(1)" for the pivot selection. A slightly enhanced std::map could support this by providing its root and a couple "near-roots", then you could use this to (partial_)sort a std::map by ValueType (of course it's already sorted by KeyType).
agreed. Yes the syntax is terribly ugly in cmake, but the problem with cmake isn't that the syntax is ugly. The problem is that not everyone is using yet (still). It is growing every day, but the day that every project uses cmake will make building your applications and all it's dependencies trivial. The last thing we need IMO is 5 new build systems that split the projects among all these options. An under-used project is likely not going to have the support for random / rare tools. If anyone has done CUDA development with cmake knows how easy it is. The best part of cmake is the great support for projects: qt4, qt5, cuda, OpenGL, osx frameworks, etc, etc. Are all the new alternatives going to support all these as well? 
Ah, okay. I'd rather use some sort of compile-time tool rather than this type of syntax though.
std::sort is a template, unless someone went out of their way to hide their std::sort implementation it will be "open" source .
so what you're saying is that somebody should create a cmake project generator?
yes. even though its pretty meta, having cmakelists for your project greatly increases its usability for other users. I know of some projects which actually use python or java to generate cmake which is used to generate the the ide projects. 
Sure, something like this http://www.codesynthesis.com/products/odb/ would be great, a compiler plug-in that generates the boilerplate stuff for you.
cool, i understand none of this.
I learned C++ 10+ years ago in college and now I can barely read these programs. There's so much noise.
Some partial_sort might work, where you keep sorting the remaining part of the array @ a constant partition size (e.g. sort next 100 elements).
It's noise if you don't see what it's doing. It's information when you do. I learned C++ a little under 3 years ago on my own, so I've never been exposed to the older stuff (I immediately went to C++11 resources). It definitely has quite a learning curve, but you can do a lot of really awesome stuff with it now. I think a lot of the difficulty in learning the newer stuff is due to being in a habit of expecting 100% stability and writing code with a certain set of features in mind. Now the committee is going for an update every 3 years, alternating between major and minor updates (one to add new features, one to smooth out the edges), so keeping up with what they do is more important than it was before.
So just kind of thinking off the top of my head here but it could be useful for implementing the equivalent to Dart's [method cascading](http://news.dartlang.org/2012/02/method-cascades-in-dart-posted-by-gilad.html) operator. 
i know what piping is, i just don't understand any of the code.
So a meta-meta-build system? Seems like overkill.
I watched this sometime last week. If you've been paying attention to the evolution of C++ (C++11/14/17 etc.) there isn't anything new or interesting here. If you haven't, it's a pretty good overview although not the best source for this kind of information. After the fact, it seems a bit sloppy at times so it definitely leans towards being a live event.
That's because the source code represents [meta programming](http://en.wikipedia.org/wiki/Template_metaprogramming) and not the instantiated code, which would look more like a normal c++ source code. Meta is programming at a higher abstract level than concrete c++ ... groovy man ;)
aa a f
Well this can help when you have many nested functions that are chained together, for example, like this: auto r = select(where(numbers, [](int x) { return x &gt; 2; }), [](int x) { return x * x; }); Because of nesting this can be hard to read(and even write). If we can make the function pipable, the above can be written like this: auto r = numbers | where([](int x) { return x &gt; 2; }) | select([](int x) { return x * x; }); Which it is easier to see what this does. 
&gt; I learned C++ 10+ years ago in college and now I can barely read these programs. Well i do use a lot of C++11/14 features such as vardiac templates, rvalue reference, generic lambdas, and auto type deduction. I can see how this could seem foriegn to someone who has never used these newer features. &gt; There's so much noise. All these C++14 features make implementing this easier and simpler. I have implemented this before in C++03, but it has a lot more "noise". It would not be simple at all to write a blog post about it. 
Yes if all the functions are implemented trivially based on the plus operator. However, `pipable` is useful for chaining non-trivial functions. I just used a simple trivial function to try and make it clearer what is happening.
Would it be possible to do this with a streamed data source so you could filter data live?
It's also useful in that it can work in conjunction with other operators with a much higher precedence. Where one could write auto i = vector1 + vector2 | normalize; You automatically group the plus operating together at a glance, similar to looking at shell script piping.
I feel like I'm stuck somewhere between old English with the thou's and wherefores and such, and twitter-eze with the YOLOs and stuff. Books I read show c++99 style plain vanilla c++ 8-cylinder carburetor stuff. Blog posts have exotic c++14 V12 dual electric hybrid flux capicators. Actual code at work has starter cranks on the front of the car and home-made power steering pumps that have to be primed before you drive and engine chokes and shit. I'm ready to throw it all out and just start fresh from the latest. What's the best resource that won't spend three chapters on pointers and will instead explain all this new magic you guys are talking about: such as select and &gt;vardiac templates, rvalue reference, generic lambdas, and auto type deduction an instant best seller would be C++ for C++ developers.
Thanks for the info that could prove useful for a few projects at work.
The C++ Programming Language by Bjarne Stroustrup, the original creator and a member of the committee. It's both a reference manual and a tutorial, so like a very boring tutorial or a great reference manual, take your pick. It's exhaustive, something like 1,2xx pages and covers *everything* in the language from both the user, implementer, and designer point of view. I have it and use it whenever I run into something really weird and want to get info right from the source. However, the current version is only for C++11. Since C++14 is only a minor update, most of the info will be fine. There's [cppreference](http://en.cppreference.com/w/) for all things in the standard library (not so much language features, though). It's like good documentation more than a guide or tutorial. Beyond that, it's just following these blog posts. They usually link to other blog posts that act as an explanation. I actually learned about the difference between rvalue-references for concrete types and for template type deduction.
I would have personally liked to see an example at the end of the article that showed how pipable functions would be better than composing the functions.
Well at the begining of the article I linked to a prevous post where I gave an example of that. This post I was just showing what is needed to be done to implement it.
hey. its a lifestyle choice ;)
Pipable still isn't a word, as I mentioned the other day. The word is pipeable. Unless you intend user to pip these functions, rather than pipe them.
PDF on the library: http://actor-framework.org/pdf/cshw-nassp-13.pdf
Glad to see this posted. I saw it a few months back on the boost incubator site. Also, love the choice of license. Good work. Questions for those who might know: - Does it integrate with ASIO or does it have its own loop? - How are exceptions handled? The manual is a great start, but I think an example of a non-trivial networked app would be a good way to get an idea of its capabilities.
There's been a bunch of work recently to bring libc++ to windows. It may be a reality soon.
I haven't heard about Allegro for a while, will look at.
Deserves to be cross-posted to /r/misleadingthumbnails
Wrote my first real game with Allegro back in 2001. It's a nice framework, but it was and still is C. I very much prefer OOP in game development. Stuff like entity frameworks is not really possible in pure C. I would actually recommend [gameplay3d](http://gameplay3d.org) over Allegro for those who want to have a cross platform engine and C++.
It would be nice to have a comparison with Boost.Fusion (in particular the BOOST_FUSION_ADAPT_XXX macros since they seem to be doing the same thing and allow you to use the Boost.Fusion/Boost.MPL algorithms with your class.
With BOOST_FUSION_ADAPT_STRUCT for example, you need to write the same thing twice, and also it doesn't support inheritance. With BOOST_FUSION_DEFINE_STRUCT you don't need to define structs twice but it doesn't support inheritance either. I also think that defining classes using macros is even uglier than by the way REFCPP proposes. I've implemented some reflection APIs based on Boost.Function, as for example here https://github.com/catedrasaes-umu/corbasim, but I've always used a code generator for the instances of these macros.
It works wonders in data analysis. My R code (statistical data analysis) is heavily piped because chaining makes the workflow more readable than nesting (F# programmers have known this for a long time). The R community at large is currently discovering this with [dplyr](http://blog.rstudio.org/2014/05/21/dplyr-0-2/). Hereâ€™s a great example where chains really help to emphasise the structure of the analysis, and make it more readable: data.frame( "date"=format(index(french_factors_xts)), french_factors_xts ) %&gt;% gather(ff_factor,roc,-date) %&gt;% mutate( date = as.character(date), ff_factor = as.character(ff_factor), roc = paste0(format(roc*100,digits=4),"%") ) %&gt;% group_by( ff_factor ) %&gt;% top_n(n=5,date) %&gt;% htmlTable %&gt;% cat [Taken from [Rethinking R with Chains %&gt;% tidyr + dplyr + magrittr + rCharts](http://timelyportfolio.github.io/rCharts_factor_analytics/factors_with_new_R.html#slide-4)]
&gt; We couldn't find a way to express it with ranges that didn't cause the algorithm to go from O(1) to O(N). That's not the way I'd put it.
Thanks! Yes your approach looks more cleaner without the macros.
&gt; Distributed So which letter(s) of the CAP theorem does it sacrifice? I'm asking for a friend.
Is this library typesafe? For example self-&gt;sync_send(testee, atom("plus"), 2, 1) Will it throw an compiler error if I send to few arguments? Will it throw an compiler error if the arguments have the wrong type?
&gt; Edit: its cmake based! Hooray! ... And I just decided to switch away from CMake just before I found out about biicode! Boo! In all seriousness, I can't get excited about it. It works precisely the way I don't want it to work, and it uses the very build system I want to switch away from. I clicked this link hoping it would be an announcement for a competitor to biicode. Nope. :(
What'd ya switch to?
Looks interesting. I'm not familiar with the actor model. Would it help me to implement [fault tolerant systems](https://www.youtube.com/watch?v=xrIjfIjssLE)?
I want to play devil's advocate here, and while I understand the joke you are making, I want to go deeper into the issue. Are we sure that this approach to C++ is actually sustainable? What i've seen in my experience is that all this aggressive templating has the following results: - templates tend to "bubble up" in the class dependency. You have to explicitly instantiate sooner or later or you end up with classes templated on 10 arguments each one templated further. - the compilation time increases, a lot. - you are no longer programming the program. You are programming the compiler to program the program. In the end, it's like glorified, type safe macros. - Refactoring becomes a complete nightmare, because you are so constrained with the typing system that you have extreme rigidity for change. - You end up having a large majority of your code in the header, meaning that you can't release the header publicly if you are closed source, and every time you modify it, it is very likely to trigger a full source recompile. I am aware of workarounds, but this adds even more clutter to an already cluttered code. - If you are working at the python interface like I am, the produced swig module becomes insanely huge ( you have to instantiate all the templates manually). - The syntax quickly becomes unreadable. I have the feeling that we already passed the limit of practicality. See http://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Gartner_Hype_Cycle.svg/320px-Gartner_Hype_Cycle.svg.png for the expected trend.
Sorry for being completely off topic, and please donâ€™t take this to imply that your approach is invalid (itâ€™s not!) â€¦ but: why are you not using Boost.Spirit for parsing? Itâ€™s got a steep learning curve but the pay-off is huge. Iâ€™m assuming that youâ€™ve probably considered using it so Iâ€™d like to hear your thoughts. (Especially considering that you seem to be keen on using monads and Boost.Spirit offers (something very close to) monadic parser combinators.)
It was just a few days ago that I was wondering whether JetBrains will develop a C++ IDE sometime. Really love their PyCharm and ReSharper tools. Best thing is it being cross-platform.
I was in the private beta and my main complaint is that even though it's cross platform you have to use the base minGW for it to work on windows which means limited c++11/1y support. If it supported MinGW-w64 or msys2 it would be a lot more useful on windows.
The matching is done at runtime so its unlikely though it would be best to have some compile time safety especially in large systems.
That would be a vapid remark in itself but the fact that the OP is already using Boost in their code makes this downright stupid.
"Limited C++11 support" isn't quite true. MinGW pulls gcc 4.8.1.
&gt; Best thing is it being cross-platform. This is a very good thing. But I also like the fact that Windows will get a very good (I haven't tried it yet, but I'm speaking as a long time user of their Java IDE) IDE which can use GCC or Clang. The compiler in Visual Studio is horrendous. Their support for C++11 in 2014 is a joke. And now they are implementing C++14 before being done with C++11? 
That's a fair point, but you can do a whole lot of significant C++11-aware development on 4.8.1 without ever using &lt;regex&gt;. Basically all of the language-features are present.
Yup, sure are.
Isn't also clang fully supported? That had had concrete support for quite a while, might be the source is the claim?
Not a fan of IDE's, but this looks slick.
I would call something that dosent support std::thread or even std::to_string limited.
Looks like an awesome substitute for Visual Studio on Linux and OS X. I really hope the put out a community edition like with IntelliJ.
So, I just finished a major overhaul of the library which allows it to wrap over David Stone's bounded_integer, so you can have a bounded fixed point integer type! By design though it should be able to wrap over any arithmetic type, built-in or user defined, integer, float, rational, or anything else I can't think of, with minimal or no modifications. If you have any feedback, ideas or doubts please don't hesitate to contact me!
Judging by the second screenshot, they appear to have solved the [halting problem](http://en.wikipedia.org/wiki/Halting_problem), which is no small feat.
Cross-post question from the thread on /r/gamedev, maybe someone will be able to help me: So far I could not find the possibility to use auto completion on the constructors in variable declarations. For example, I'd like to type "std::vector vec(" and have a list of all possible constructors in std::vector shown to me. I really miss this since I have to check the header of a class everytime I instantiate an object.
libc++ doesn't pick the pivot that way. in fact it picks the pivot in a clever way that leads to very good performance on most sorted or partially sorted sequences. See slide 54: http://llvm.org/devmtg/2010-11/Hinnant-libcxx.pdf. I've posted elsewhere in this thread a detailed explanation of libc++'s implementation.
I'm just starting to learn C++, and wow, that's a lot of stuff.
Yeah. C++ is a very complex language. It's a love-hate relationship for most of us, I think.
How about: `bool is_word_boundary(Range left, Range right);` which tells you if there's a word boundary between `left` and `right` as if `left` and `right` are consecutive ranges (but of course they don't have to be). Should be constant time with bi-directional ranges. I see now this is exactly what Andre proposed: http://lists.boost.org/Archives/boost/2009/07/154185.php http://lists.boost.org/Archives/boost/2009/07/154241.php
I'm trying premake. Deepening on how that works, it might be my go-to for the foreseeable future.
&gt; Iâ€™m assuming that youâ€™ve probably considered using it so Iâ€™d like to hear your thoughts. Nope. I used it in the past and I doubt it would ever cross my mind to do so again.
My point being: The text makes it appear as though it detects *all* algorithms resulting in infinite loops, when that has been proven impossible. Hence the snark.
In /r/programming their staff member mentioned it will be close to appcode in pricing http://www.reddit.com/r/programming/comments/2fsmyw/clion_the_new_cc_ide_from_jetbrains/ckcdd2b
My money is on [John Paul Jones](http://riffraf.typepad.com/.a/6a0120a7b5f86a970b017742974046970d-pi) from Led Zeppelin.
I installed and then immediately uninstalled it because of this. 
Looks pretty good at first glance. Works fine with C++14 under g++-4.9 &amp; clang++-3.5 on my Linux box. I think using CMake as the project format is a very good idea in today's world. I'm especially eager to wring out all the refactoring tools. C++ is probably **the** hardest language to do this well in, so I'll be interested to see how CLion fares in this department. If it works reliably in this area, I'll probably spring for a purchase. Question: Will my license work on both my dev boxes(one Windows, one Linux)?
The context for this was Scott Meyers for some reason thought a talk on type deduction needed some livening up :) (there were also lemurs)
Ambassador Soval http://img2.wikia.nocookie.net/__cb20070707074323/memoryalpha/en/images/9/97/Soval2154.jpg http://images2.fanpop.com/images/photos/8500000/Soval-star-trek-enterprise-8530509-550-825.jpg 
Honest question (haven't had time to download/play): it seems from the comments that they're backing things with CMake. If that's the case, why on earth is it stuck with MinGW on Windows? CMake will more than happily suss out the right stuff from an appropriate environment. 
I'm surprised they chose that as the intro speech. IMO would have been nice to have a "State of C++" session that covers where things are at and where things are going. Apple does this every year at WWDC and it seems to flow nicely. Anyways, I'll leave feedback and not complain to much :)
This looks neat but frankly these days with vim + YouCompleteMe I have everything I need.
Speaking of C++ guys that look like rock stars, am I the only one who thinks that Bartoz Milewski looks like Tony Iommi?
This poll just made my day. Well done!
I used std::to_string and std::thread just fine with GCC before moving to Clang 
I always thought he was the lost member of the Ramones.
It's nothing to do with GCC it's to do with the distribution that contains GCC on windows. MinGW doesn't have those but MinGW-w64/msys2 does.
I always felt like Bartoz Milewski looked like a rockstar, but now I know it for sure. 
I agree.
Sounds like you've got your O(1) is_word_boundary algorithm for bidi ranges, usable for iterating. Another way to use `is_word_boundary(Range left, Range right)` in iteration would be to create `left` from the beginning of `right` each iteration, rather than growing the left range.
Can YouCompleteMe work well with a large code base (&gt; 1MLOC)?
I think it entirely depends on the structure and build process of your codebase. If compiling a single file takes ten minutes, then no. Note that you don't have to enable semantic completion if you don't want to. You will still get completions, but of course they won't be as relevant.
Looks very nice. Thanks for sharing!
That or Slash.
He's always reminded me of Gallagher.
Here is variadic templates: [run](http://rextester.com/VMMBR51843)
After this interesting discussion, at biicode we have started to work on reviewing and improving out ToS: http://blog.biicode.com/tos-dont-like-well-others/ Would appreciate to hear your feedback. 
I don't know D's range primitives, but I am familiar with the 'only shrinking' property of ranges from Andre's 'iterators must die' talk. Anyway, here's what I meant. `is_word_boundary` is O(1) and finding all the boundaries in the list is O(N). range left = empty range range right = all(linked_list_of_text_elements); while (!right.empty()) { if (is_word_boundary(left, right)) { found_boundary(left, right); } left = take_one(right); right.pop_front(); } 
I don't understand what this code is trying to solve. Why can't you just write this: template&lt;class T, REQUIRES(has_whatever&lt;T&gt;())&gt; void somefun(T&amp; x) { x.whatever(); } struct herp { void whatever() {} } herp derp; somefun(derp); This seems much simpler, plus it decouples the policy mixins from the classes. 
And for debugging?
Could it be because you capitalised "int"? 
tried making it proper before it didn't work. :/ 
I just ran up the code and the two biggest issues are 1) Capitalizing keywords like "int" and "if". Very few, if any, of c++'s keywords are capitalized 2) Not scoping your functions that are part of the standard namespace. You either need to prefix functions like "cout" with std:: (std::cout) or type "using namespace std;" near the top of your code. 
1. Sorry I didn't knew next time i'll make sure I post over there. 2. Over 200 errors C2017 : Illegal escape sequence C2146 : ; missing (I really have no idea why this is happening because there are ; before cout statements) C4430 and many different errors. 
You have a lot of this kind of thing in the file: o.write((char*)&amp;R,sizeofÂ®; I suspect something went sour when you tried to enter sizeof R, and you get the special symbol instead.
Oh my God i didn't realize this code was typed in Word so that could have done this.
Before C++98.
Oh.... oh, my. Why would you write code in Word? Did your professor not instruct you to use an IDE? Visual Studio, perhaps? 
If there's anything you should learn it's that the number says nothing. It's either 0 or not 0. If it's 0 your code compiles (and turn on warnings!). If it is not zero, look at the top error, fix that, then recompile. Quite often your compiler will be confused by your forgetting a semicolon or something, and then in trying to skip that error introduce hundreds more. The number says nothing.
Yes I figured it out it. The compiler will go in a loop and give more errors than it should.
I use GDB. I very seldom use step by step or breakpoint debugging, so I'm probably not the right person to ask. I mostly use the debugger to track memory errors.
conio.h, that's a blast from the past.
Yeah, that I understand. From an implementation perspective, though, without embedding CMake as a library, it's almost harder to hide VC from CMake. 
Check the climits definition, it should be INT_MIN.
You'll find INT_MIN in limits.h. stdint.h might be interesting too.
Dude...you're copying and pasting code? This looks like it might be CS 100 or 200 level stuff, covered by an older professor. And it's homework? I don't have to say anything about academic integrity. What I will say is that you should at least try to understand the code that you're looking at and come up with a different method of doing it. Or even modified. Show that you know how to code. Since you have the source files anyway, manually re-write it in an IDE. You already have Visual Studio 2013, so just use that instead of word, otherwise you'll have formatting problems with others trying to read what you wrote. I only took a quick look at your updated code, but lines 91-98, you forgot to include the quotation mark at the beginning of the cout statements, and only added them at the end. cout &lt;&lt; [output statement here]" should be cout &lt;&lt; "[output statement here]" 
Use `std::numeric_limits&lt;int&gt;::min()` if you're using a pre C++11 standard library
I'm not going to wish you good luck, because I sincerely hope you fail. Learning to program takes real, dedicated effort, and you insult us all by asking us for help when you've made little to no effort to understand what you're doing.
Thanks, changed it to use the `min()` function in my reply since it only differs for floating point numbers anyways. Also I gotta remember not to assume everyone having C++11 just because I can use it.
Ah, I see. You're taking special advantage of the fact that `is_word_boundary` only needs access to the 1 prior character. You solved the stated problem, but missed the spirit of the challenge.
Thank you for addressing my complaints about the package. I don't see any other obvious problems with it, and this is a huge improvement.
What was it before you changed it?
The `lowest()` function which is only available in C++11. They only differ for floating point values tho. `min()` would give the smallest positive **normalized** value and `lowest()` gives the smallest overall value.
All kinds of stuff. This kind of thing is an important part of face recognition systems. You could also use it to do head tracking for video games (e.g. http://facetracknoir.sourceforge.net/home/default.htm) and various other similar projects. And it's just cool :)
Okay, if you don't like that then there's: while (!right.empty()) { if (is_word_boundary(left, right)) { found_boundary(left, right); } left = combine_ranges(left, take_one(right)); right.pop_front(); } Now this will work generically for any bidi ranges, but in order to avoid the memory overhead of joining N arbitrary ranges `combine_ranges` will have to be specialized for the particular bidi range type in order to grope around their insides and recognize that they are adjacent.
Not everything with the word "distributed" in it is subject to the CAP theorem. CAP specifically concerns some sort of object store (objects could be rows in a database, json documents, etc) that is replicated across multiple discrete processes. This framework is a lower level component than can be used to build distributed systems. In other words, this library could be used to construct an AP or CP system.
&gt; ComputerType.cxx:52: error: â€˜rdâ€™ was not declared in this scope You haven't declared a variable named rd within that function, and the ComputerType class has no member variable named rd, so there's no instance of ComputerType to return the labLocation from. I'm guessing you want to return this-&gt;labLocation at any rate. (Same for ProcessorIs, actually) In runComputer, you're trying to use a bunch of variables that you have not declared within your main function. You probably meant to use "rd.idNumber", "id.proc", etc, except that those would all be private.
I may be wrong here, but I'm pretty sure you have to declare a variable type in your constructors ComputerType::ComputerType() { int idNumber = 9999; int ramSize = 999; int discSize = 999; string processor = "BAD"; string ramType = "BJ"; string discType = "BJ"; string computerType = "NONE"; string labLocation = "NotAvailable"; float cost = -99.99; } 
&gt; but in order to avoid the memory overhead **[and increased algorithmic complexity]** of joining N arbitrary ranges `combine_ranges` will have to be specialized for the particular bidi range type in order to grope around their insides and recognize that they are adjacent. (Bold is mine.) And that's precisely my point. To make this efficient, a new range primitive would need to be added. What form the new primitive should take is an open question. *D ranges as they currently exist are not up to this task.* That is why I describe D ranges as a *qualified* success.
I don't think this is an appropriate place to ask this. You don't know C++ (judging by your overall question, you don't know other programming languages either), and this is not the way nor the place to learn. Kudos for framing a question sneakily ("nobody knows", basically, although the answer is quite trivial) though. ðŸ˜‰ I see that people already tried to help, however... Kindly read books and find online forums who deal with complete beginners. comp.Lang.c++ is a better place.
As a professional Character TD and Animator in the film and vidya industry I use stuff like this in our actor MOCAP toolkits all the time. Ever price out a modest Vicon mocap rig before? Especially one suitable for facial MOCAP? These kinds of frameworks and resources are part of an industry-wide effort to reduce costs of asset creation for studios of all sizes. When combined with inexpensive lightweight head-mounted cameras this type of software can yield very good realtime results for 3D facial mesh character retargeting on the day (while still on the soundstage I mean), and this is of very high importance cost-wise to keep from having to schedule a reshoot later, because something wasn't quite right for one reason or another but no one knew atm because everyone had to wait until the offline render was performed afterwards. Most of the high-quality work that's been done in this arena has been completely proprietary and closed-source in-house stuff, or has a prohibitive license. Having a free open-source codebase (and one of extremely high-quality I might add) of this type is a boon for anyone in this specialty field of film MOCAP. There are also plenty of other uses outside of this narrow domain, as davis685 (+1 for link) alluded to.
Not at all. Thanks to you for pointing out the problem.
This technique is also known as [X-macro](http://en.wikipedia.org/wiki/X_Macro).
Even the non-specialized range join should be constant time, and the time complexity of `is_word_boundary` is not increased because the algorithm still only uses the last element out of the left range, and given the construction of the left range `.back()` is constant time as well; algorithmic complexity is not increased. In any case, does D not have the join_ranges operation? Does it not offer specialization? (edit: oh, of course copying the generic `combine_range` result takes N time, but specialization fixes that, and I don't think that requiring specialization in order to attain the desired complexity is some kind of partial failure.)
This is a great post. I didn't realise it was so easy to embed Common Lisp. I was recently debugging a vexing issue in an app of mine and lamented that I didn't have a REPL. Seriously considering it now. Any ideas or suggestions on how you'd expose domain objects from C++?
Thanks for the reply but sadly that does not work.
Nice, thanks for explaining.
While ECL is a great choice if you want to embed a full-blown Common Lisp implementation, if you just want a lisp for scripting or plugins, you could be better of with more light-weight Schemes. For instance, I believe GIMP (the image processing tool) uses a modified [TinyScheme](http://tinyscheme.sourceforge.net/) for their plugins, which seems to be one of the more popular embedded Schemes.
Hi, as far as I understand the documentation, it can only be used when the the x's are on a grid, correct? Just curious: Is that a fundamental limitation to the approach? Would it be possible to have a similar approach that does not rely on this? Like.. "here's a bunch of random samples I have from a function - go approximate that function for me"? Thanks
But I think you can't pass this 'real matrix' as an argument to a function? double (*realMatrix)[N] = malloc(sizeof(double[N][N])); If N is known only at runtime, then how to I do this: foo(realMatrix); I think it's impossible, but I don't know VLAs very well. I think I can see how a compile *could* implement it, but that's not the same *Update:* When I searched for my question, I came across another of his posts [about it](http://gustedt.wordpress.com/2011/01/13/vla-as-function-arguments/). It's good!
Thanks. This stuff is all outdated and I know I should work hard but this is a small project about which I just don't care. Sorry if I annoyed anyone about this.
&gt;When sampling is expensive and/or scattered (not on a grid) the radial basis function splines may be utilized for function approximation. The user should expect a high computational cost for constructing and evaluating a radial basis function spline, even with a modest number of samples (up to about 1 000 samples).
I do take c++ seriously in class and I know how to code. I was just too lazy to re-write this code because I had to do this project for my friend also and due to tuition and stuff I was really exhausted + this code was written by someone whom I don't even know. Thanks I'll correct that.
Hi Dtag, you are correct. A tensor product (or simply multivariate) B-spline is constructed on a regular grid (see http://en.wikipedia.org/wiki/Regular_grid). The grid defines the domain of the B-spline (outside of it the B-spline has no support and evaluates to zero), and the samples are closely related to this grid when constructing the B-spline. Even though this is a "fundamental" limitation there are techniques for taking "a bunch of random samples", filling out some gaps, and then creating a B-spline from the new set of points. However, to my knowledge, these are heuristical techniques. If you are "missing" a lot of points from having a regular grid I suggest that you use the radial basis function splines instead. They will happily digest a bunch of random points, but be careful that you don't overfeed them - they will become ill (they will have to solve an ill-conditioned linear system, that is). 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Regular grid**](https://en.wikipedia.org/wiki/Regular%20grid): [](#sfw) --- &gt;A __regular grid__ is a [tessellation](https://en.wikipedia.org/wiki/Tessellation) of ___n___-dimensional [Euclidean space](https://en.wikipedia.org/wiki/Euclidean_space) by congruent [parallelotopes](https://en.wikipedia.org/wiki/Parallelotope) (e.g. [bricks](https://en.wikipedia.org/wiki/Brick)). Grids of this type appear on [graph paper](https://en.wikipedia.org/wiki/Graph_paper) and may be used in [finite element analysis](https://en.wikipedia.org/wiki/Finite_element_analysis) as well as [finite volume methods](https://en.wikipedia.org/wiki/Finite_volume_method) and [finite difference methods](https://en.wikipedia.org/wiki/Finite_difference_method). Since the derivatives of field variables can be conveniently expressed as finite differences, structured grids mainly appear in finite difference methods. [Unstructured grids](https://en.wikipedia.org/wiki/Unstructured_grid) offer more flexibility than structured grids and hence are very useful in finite element and finite volume methods. &gt;==== &gt;[**Image**](https://i.imgur.com/skBKUpW.png) [^(i)](https://commons.wikimedia.org/wiki/File:Cartesian_grid.svg) - *Example of a Cartesian grid.* --- ^Interesting: [^Graph ^paper](https://en.wikipedia.org/wiki/Graph_paper) ^| [^Unstructured ^grid](https://en.wikipedia.org/wiki/Unstructured_grid) ^| [^Voxel](https://en.wikipedia.org/wiki/Voxel) ^| [^Trilinear ^interpolation](https://en.wikipedia.org/wiki/Trilinear_interpolation) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ckee0kv) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ckee0kv)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Thanks. Must have missed/skipped this part somehow
http://root.cern.ch/drupal/content/cling
You can embed this in an app??? Nice.
No idea. It's a C++ REPL.
Same here, although it was a second game :)
Looks pretty cool: http://www.reddit.com/r/cpp/comments/2g0tnp/qt_cling_the_llvm_based_c_interpreter/ Main problem is it wouldn't work correctly on Windows for me since I still use MSVC :(
In C++ we can use `std::vector`, `std::array` or `std::dynarray` instead.
wow, It's amazing !
I could use it, but any particular reason you're limiting it to cubic interpolation? I regularly make use of Lagrange tensor interpolations in 3D, but I have a need for arbitrary order.
Okay, so I downloaded the actual code and popped it into Visual Studio for a better look. It's probably correct to assume that your professor is teach C-styled C++, coming from a C programming background and they had him or her cover C++ as well. Or that the code is from someone with a C programming background. Some of the code is deprecated for today's C++. I can tell you for sure that one of the things that you had wrong in your pastebin was because you copied the files from Word back into your IDE, there are some crazy formatting errors. The quotations marks ", apostrophes ', (and pointed out earlier) parenthesis (R) were changed. That's why I wanted you to re-write it manually in Visual Studio. You were also missing one or two closing brackets } . Something among these things is probably why it's still not compiling correctly. There was a problem with the use cases not exiting properly. Here's what I did to clean it up for legibility and without compiling errors (warnings may be present still though). http://pastebin.com/0U6JviWj You don't have to create a new cout &lt;&lt; for each line if you want to make a long continuous section of outputting to the console. It'll all be piped through until you end it with a semicolon. This makes it look nicer to read. Here's what you need to do: The way that the code was written (in C) writes the newly created class to an output file, which it will read back in when you make any menu decisions. To prevent problems, you should modify the code so that when you exit out of the program, it deletes all of the data written to the text file. The reason why this is important is because the next time you start up the program, it will have old data from the previous writes, which was causing problems with me brief testing. I would suggest that you request more time so you can do this properly. And please do it properly. 
&gt; I noticed the squiggly line error highlights in the editor being incorrect for some other things (e.g. a declaration using decltype) while the code compiled and ran just fine. Ugh, that doesn't seem like its well integrated with the compiler. The things is that clang provides a library and tooling for use in an IDE, theres really no need to reimplement a parser. So it looks like it won't be replacing sublime and clang. 
Thanks alot for giving good advice I will make sure that next time if I ever get a project I'll do it on my own and won't ever try to write a code in word. Its fine I gave him the project the way it was before and it was on paper so he also really doesn't care because no one checks it after him signing it and I will get the marks for this anyway. This is one of the main reason no one studies properly which sucks. Thanks alot for the comments in the code it helps me understand better.
JetBrains chose to implement their C++ parser themselves unfortunately.
Yeah, I was surprised by that too. It would be interesting to know why they didn't (presumably) use those tools.
Once again, GDB is the weak link in the software stack. 
It does with their other IDEs, so I'd hope so.
&gt;implement [...] C++ parser Sounds like they have a death wish.
Why? QtCreator use this. Doxygen created a parser for c++ as well. IDEs need a different kind of parser.
I suppose this is hardly a question of choice. From the three big C++ compilers (GCC, LLVM and VS), I think only LLVM has a "detachable" parser library that could be used in an IDE. Maybe GCC could be used too, but then the IDE would have to be GPL'd. However, even if they picked LLVM as a parser, there are differences between the compilers that could result in incorrect error reporting. And, to be fair, I've seen Visual Studio (2010) report errors in the editor in code that would compile just fine with its own compiler. Parsing C++ isn't an easy task. Maybe something like flymake from Emacs would be a better choice, but it's somewhat heavy on CPU and disk use.
Nice work. A small question concerning the license: Why did you choose GPLv2 instead of MPL2 (like eigen) or something like boost license? It's very restrictive to use GPL for a library.
&gt;However, even if they picked LLVM as a parser, there are differences between the compilers that could result in incorrect error reporting. So instead they'll roll their own, so there's four parsers to worry about rather than three, one (the one they happen to be using) of which isn't even maintained by professional compiler developers/C++ language lawyers. What a great choice!
I tested this IDE this week and even though it claims to be C AND C++ IDE, I was not able to find any C related preferences. Yes, it handles .c files and compiles and runs without any error or whatsoever (haven't found any), but once you create a new project, the default is language is C++. If anyone faced this and found a solution for it, please enlighten me with your wisdom and let me know how to do so. Apart from that it's a really cool IDE 
QtCreator now uses libclang
I think in the comments to their blog post, they mentioned that C support is still in development and that's why there is no UI for it. I believe the solution for now was what you mentioned (just add .c files to the project).
I think technically clang would be the parser. And it's designed to be used by programming tools like this, in addition to having a BSD style license. 
Qt Creator supports clang as code model provider. Unfortunately, it's slow to the point of uselessness (though it works perfectly even with heavily templated types).
are there any schemes that play well with c++ (as opposed to c)? i'd be very interested in seeing one if it exists; i've searched several times in the past and not found anything.
It wasn't mentioned, is there something similar to Qt Creator's locator? I can now press Ctrl+K and get to any class/type/file/function without taking my hands from the keyboard.
This is split between two shortcuts. Double-Shift searches file names, while Command-Option-O (Navigate to Symbol) searches class and function names.
I have always had good experience with JetBrains products, although I do think that they are tackling their biggest project yet. As of right now my 5 years of VS use have made me very proficient, so switching over would require some good intensives. 
For win and mac, this is not interesting, there's entrenched IDEs there. So, a comparison with eclipse, qtCreator and the like is needed. ðŸ˜‰
Both [Gambit](http://dynamo.iro.umontreal.ca/wiki/index.php/Main_Page) and [Chicken](http://www.call-cc.org/) should support C++ integration. [Chicken example](http://wiki.call-cc.org/eggref/4/bind).
If setting up Clang on Windows wasn't so complicated I would seriously consider ditching Visual Studio in favor of this when it hits version 1.0.
thanks!
It's just a mix of clang and our own parsers. And clang annotator will come later to CLion to help with this little incorrectness in the editor.
We will add more project templates to the New Project wizard a bit later with some C projects possibly. But anyway CLion is ready for C-development now.
You could have just stated what is the purpose of this code without being snarky or mention some non existing trolls. Doesn't need to be a troll to ask what this code you publish is supposed to do.
is there an alternative? ive never heard of anything remotely close to microsofts.
Hm... when the IDE was announced a couple of months ago, they wrote on the webpage that it was going to have a clang analyzer. Since they deleted it from their webpage, it only remains in the Google cache: http://webcache.googleusercontent.com/search?q=cache:cyhKVdX_wXkJ:www.jetbrains.com/objc/features/cpp.html+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=de Thats a huge disappointment for me to be honest. Their custom parsers might work quite well (QtCreator's parser works quite well already as well!), yet the core issue is that it will never be able to do proper code completion _everywhere_, without FULLY understanding the code. I seriously doubt it is viable for someone making an IDE to develop a fully compliant C++ parser as a side project... I was hoping for this to become the first IDE that really understands the code (okok.. it would not really be the first since there is QtCreator with a clang plugin already -- I am not quite happy with that though...) Edit: Google Cache Link doesn't work anymore -- archive.org still has it though: https://web.archive.org/web/20140819120431/http://www.jetbrains.com/objc/features/cpp.html
Coworker of OP here. Care to quickly explain the limitations of GPLv2 for libraries? We were really unsure about what license to choose.
Hmm, then the bottle neck must be with Qt Creator's plugin architecture. Because XCode uses libclang for the IDE part and it's fast.
The only reason for limiting it to linear and cubic splines is that I wanted to make it easy to use. I plan on opening for any degree in the next version (hopefully to come within a few days).
I could change it to something cool and random... I got it! I'll call it: Ice Cream Splines! Then I can later release an extension called Ice Cream Toppings. It's perfect!
I agree with you there. The RBF interpolation is easy to implement, but it does not scale very well with the number of samples (unless you can produce a very good pre-condition matrix when calculating the weights, which is difficult). Which approach did you end up using?
Posts like this remind me why we desperately need compile time reflection in Cpp.
I have a block of code that looks roughly like: bla *ptr=NULL for(collection::iterator i=foo.begin(); i!=foo.end(); ++i){ if(somecondition) ptr=i; } if(!ptr) return errorcode; dosomething(ptr); For some reason, CLion claims that the `if(!ptr)` condition is always true and the `domesomething(ptr)` code is thus unreachable...
+1 for the VIM support
There's [lldb](http://lldb.llvm.org/), but it's not any better than gdb at basic debugger functionality.
&gt; I, for one, would never start anything new in pure C. Could you please elaborate? I'm not the most brilliant guy when it comes to C and C++. I've started coding in C not long ago and my knowledge with compilers is zero, my only experience is compiling my simple C programs with GCC in linux. 
It depends. If what you actually want is a 2d data structure than vector&lt;vector&gt; is okay. (it's not great if you want to guarantee it to be regularly sized, and if you do want that property then it's not all that efficient). If you actually want a matrix for use in Maths, then you really should be using a dedicated Matrix object. And given that you *really really* shouldn't writing your own linear algebra routines (if you have to ask...) then you should just use what ever Matrix type is defined by the library you are using.
Well.. I find C to be **dumb** compared to C++. There's just too much menial work which C++ eliminates. And it does it without affecting performance (for the code I need to write at least).
File a bug. Sounds like a code introspecition issue. http://youtrack.jetbrains.com/issues/CPP
Oh Nice! I posted a pass-key pattern [some years ago](http://stackoverflow.com/a/3218920/147192), but never thought I could easily industrialize the production of the Key with C++11 extension of friendship to template parameters! Let me amend that ;)
Uh... actually given that Clang is *specifically designed and built to capture this information*, doesn't it make it a perfect fit for an IDE parser?
I use a wrapper class around a private 1D `std::array&lt;16, T&gt;` and perform 2D element access through class functions (along with a bunch of math operator functions). This way the object memory footprint will remain exactly the number of elements the array contains, and `std::array::data()` also allows me to buffer its elements to an OpenGL uniform.
Do you have a public reference and timetable for this? Your choice to reimplement a C++ frontend is an almost crippling flaw for your product. A smart IDE isn't any good to me if it can't be trusted.
How about first part of the quote?
School. Once I'm out, I'll probably make time regularly.
Open content events (panels, etc) are free. Feel free to come join us - theres a BoF session at noon, and some events tonight at 8:30. The schedule is [here](http://cppcon2014.sched.org).
Two primary reasons: 1. travel expenses from Huntsville, Alabama to Seattle are too high 2. I wouldn't be able to justify the conference expense to my employer (we use C++, but not cutting edge)
Couldn't get my employer to sign off on the conference. The attendance fee was too high.
I did, but I think mostly just because I got them to do it early (so it was only $700) and I live in the area. Wouldn't pay for gas and hotel though...so I'm stuck on that much larger expense. I doubt I'd do it again next year. Signed up before the schedule and there's just not as much that I'm interested in. Those I have been ended up being mostly re-hashes of things I've seen before or done before. I did learn that a lot of ideas I had that I thought were unique in fact were not. Tidbits here and there. Mostly though the talks have catered to people new to these ideas and I am not. Was hoping for depth because there's much I could still learn--that's just not the level these talks have been at though. Or maybe I've just attended the wrong ones. I missed Meyers and Sutter earlier because I wanted to check out some new presenters I'd not seen before. I probably should have at least hit up Sutter's talk on atomic weapons instead. John Lakos did have an interesting talk on design by contract and the description of an interesting assertion library I'd like to try. The subject isn't new (and he said as much) but I found his approach intreguing. I'm also suffering serious burnout really bad right now. I thought the conference would help but I can't dig out of this funk. I have hope for STL's and Sutter's next talks. The talk later on mobile development should have a lot of new things for me since that whole thing is a black box from where I sit. Still though...gas, hotel, food, bar prices...gotta be close to 2k or more. I think I might have been happier watching the vids from my living room. What could make the conference well worth attending would be an employer workshop or something. Not quite a job fair, but something where we could check out who's looking for C++ devs, what they do, toss them a resume maybe. Of course, then we might not get so many employers willing to pay for the trip where they might lose their best devs to other shops...and I'd feel like an ass having them do so. If that was going on though I might pay for the trip myself. Edit: and of course I didn't pack enough clothes. With all the walking and such I've sweat quite a bit. Instead of one set per day it's been more like 2 at least. Now I'm out and going with the least smelly. So uh....sorry :P
I'm following it closely and looking forward to all the recordings. But for me there'd have been no way to attend it. Given that I'm still in school in Germany it would have been way above my tight budget. I like that there are student rates though even if it didn't help in my case.
Doesn't seem like there is much reason for a beginner to go, despite there being such a large volume of knowledgeable people there.
Nah, you should go next time if you can. How else will you learn but from knowledgeable ppl? Also the videos will be posted sometime, so you can check them out to find something you're interested in learning more about. I think modern C++ is a great beginner language personally. Here's a [good place](https://isocpp.org/get-started) to start. I recommend Bjarne's PPP2 for beginners, but C++ Primer 5th is also great. 
I would like to go. How far it is from Brazil?
Sweet!
I have found that the issue with GDB is really about remote controlling it. When I started using GDB inside emacs I discovered that it worked perfectly, and I suspect that's its because both pieces of software were written by GNU (possibly even the same guys?)...
about a 15-20h flight
Flying from Australia is prohibitive. 
Yeah I've been through a lot of resources on how to get started. I got Primer 5th a few months back and I find it really dry or at least on how it starts to approach teaching the language. The whole teaching of pointer and references seems irrelevant since it doesn't teach the user a case in where you would use such a thing. Also I try to watch and follow some of the things on here and nothing seems to be on a level where I can understand, which is okay because the majority of people here are fluent with the lang.
Hmm, I see. Welp you might try Bjarne's freshmen text then. He certainly goes extensively into these topics and gradually builds on them to teach the learner how to produce a high-quality vector&lt;&gt; implementation, among many other things. I'm currently kicking some ideas around myself for a beginner-friendly C++14 book. A tutorial-style approach that explains in detail how to create 2D style games and animations. Think that'd be interesting to you?
Not everything is cutting edge, there are plenty of things that apply to C++98.
Will the talk be recorded or streamed? If so, where?
I don't really think I want to go into games necessary but I think that would be a step in the right direction. It's just that I come from languages that feel lower level than c++ like ruby and java. So when the author gives me things like pointers, constexpr, and references, I just don't know when to use them or how to use them. So it just feels pointless. I like the other literature I've read on programming where you get set up making a program and you implement what you learned. Yeah sure I might know how pointers work, but will I use them in my projects? No, I have no clue what point they serve. I think that's the best way to teach is to show an example of how you use something, doesn't even need to be with games. "What an array does is it holds objects/values. You can use these to store information in so you can iterate over it. For example, if you wanted to put everyone in your building into organization for you to access neatly, make a sub-array for each floor, then list the people in their respective floor"
I'm surprised how many people from across the ocean are here. seems like almost every other person has an accent. I'm impressed so many traveled this far.
Suggestion for next year, stream the talks on Twitch.tv or something similar. If there are too many talks going on at once, at least stream the bigger ones!
What level of beginner do you consider yourself? I've only been doing C++ for 3-4 years (Objective-C much longer) so I feel definitely in the minority noob group but still learning a lot. However, exceptions still seem to be a big controversy :)
Last time I checked, I'd have to pay ~$4000 for transit. That's way too much for me. Plus, I kinda hoped it'd be streamed or at least recorded. We're in 2014, after all. BoostCon can do it. DConf can do it. Going Native could. Overall, there's simply not enough added value over recordings or even blog rehashes of the talks to enter the humiliating process of getting an US visa (I'm from Poland) and pay for it.
I downloaded this and got a open gl demo project going and for me learning cmake was the hurdle, the code completion was nice, and the UI had only what you need. Found some bugs thinking that functions from GLM where wrong but I would totally use this once its a 1.0 release.
Yes, I see your point. In modern C++ you can often not have to use pointers directly, even if the types you work with use them extensively 'under the covers'. This is exactly what the STL containers and other 'handle' types are there for: to free you from messy resource management issues and let you focus on solving your problems at a higher level instead. Heh, your explanation example is pretty good. :) In my planned approach I won't pretend pointers don't exist, but the learner will practically never have to use them directly--certainly no raw owning pointers. Stuff like that will be kept inside a 'handle' user type, like std::vector&lt;&gt; or std::string do.
Welp I spent tons of hours over the summer getting myself ready to pick up programming again(learning linux and CLI stuff, vim, and the sort). I have a history of doing minor stuff with Ruby and took a MOOC for Java at the Uni of Helsinki, but in terms of C++, definitely a huge beginner. Concepts from Java but unaware of how they implemented in C++ I guess.
I blew my conference budget on C++Now 2014.
I think my biggest thing holding me back is I don't know if I want to settle into c++, it's the lang im leaning towards hardest, but I hear tons of bad things about it and every other language, so I guess I'll go with it. Programming communities are tons of fun :^(
Hah! I know that feel. I've programmed in 5 different languages and personally I really like modern C++ best. I can get all the high-performance I crave, and still usually I can keep my design work at a pretty high abstraction level for elegance. And C++14 has even brought C++ into the functional programming world too now which is kinda cool.
If you're in Europe you could go to C++ and Beyond 2014. Alexandrescu, Meyers and Sutter. For just 4k ... and I mean â‚¬ not US$. I guess it comes to about the same price as flying to Seattle but at least in Stuttgart you don't have to deal with TSA. To be honest, the only conference C++ related in Europe that's affordable is MeetingCpp. Not all talks were great last year but it was enough to get some interesting ideas and so it was worth the journey.
I'd expect so. But as a 43 year old junior, it takes everything I have to keep up. I couldn't imagine taking the time out of class to go, even if I had the money, which I do not. I barely have the money to feed myself throughout the year.
It was literally just timing for me! I was very excited about the con, but unfortunately it took place right as I was traveling back from a summer internship with my wife and daughter. I hope to attend next year.
1. I still consider myself a "newbie" of C++ (I have not been using it for many years and I am still catching up) 2. I never heard of CppCon 3. Due to some health issues, I currently do not travel more than 10 km from home :D
I had no idea it existed. And a week is a lot of time to invest on something that's not a huge part of my job (I'm a C++ developer, but I spend more time on product development and infrastructure than grinding out well-defined C++ code).
Interesting, thanks.
GPL forces the application using this library to also be opensource (ref: http://programmers.stackexchange.com/questions/47032/can-i-use-gpl-software-in-a-commercial-application)
I would have loved to go, but as a student, the combined conference fee, travel from Europe and lodging is just too much. Maybe if there was like a 100-200$ student fee, then the complete package would be affordable with a little bit of savings. Or even better, make a combined offer with an affordable hotel or something like that. Also if the complete schedule was available a few months beforehand, it would strongly help the decision if it's worth to burn private money for it or giving your faculty a few good reasons to give financial support. Last, it has already been posted here, but I strongly second the fact that live streams would be really great and should be possible in 2014. Going Native was able to do it.
All talks are being professionally recorded, btw
I think all the videos will be on YouTube later I believe.
I think it's based on a flawed premise; what makes conventions something people enjoy, like ComicCon, etc? the fact that it's fun, and they're interested in it solely for the entertainment. by organizing a convention around a programming language, you've mistakenly assumed that there's a large audience that 1: wants to attend a convention about it in the first place, and 2: that it would be fun to begin with. how much fun is it to talk to programming geeks about programming? you're not likely to learn something from them that you couldn't from a multitude of books and websites centered around it, and you probably program as a job, so you don't see it as fun... Honestly, I don't see programming conventions working.
I never saw advertising that suggested any part of CppCon was free. Sounds like at least part of the problem is marketing.
There are many professional conferences that are huge and very successful. As two examples WWDC (Apple) and OracleWorld (Oracle, obviously) are both huge, well attended and very successful. OracleWorld is up around 60,000 attendees, I believe.
I wasn't aware that it was actually going on. :) 
Yes, all the talks are recorded and will become available online in the coming weeks.
Liked the talk. Plauger's trick was pretty neat and would have helped me last night. Don't recall why but I did make that mistake...or recognized it before I did...something like that. I'm confused by your statement that in C++03/98 lower_bound can't compare different types. By CPPreference.com I would expect that it can. I ran into an implementation that did not, stlport, but I thought it was wrong. Unfortunately I did not bring the big book with me so can't look it up. I'm sure you're right but now I must find the standardees that says so. The (void) strick also was pretty neat and something I would not have considered. In fact I totally missed it was there until that guy asked about it. Glad you talked about tag dispatching. I'm quite familiar but I see people reach for the TMP buzzsaw before trying it too many times. Most of the time because they just don't know about it. Simple function overloading solves a lot of problems that otherwise take quite a mess of SFINAE.
Travel time and travel costs. How about branching out and launching CppCon Europe? :)
That's fantastic news. What's the expected timeframe of uploading them? Is it going to be more like BoostCon or more like Going Native?
In many cases, talking to other devs over drinks or food is the most valuable part of the conference. You find out that the problems you are running into are not new and have a multitude of solutions. The thing about websites and books as your only source of information is that those things are self selecting. Hearing about how a fellow programmer on the ground solved the exact problem that you are trying to solve is Extremely valuable. If you don't enjoy talking to other people about programming, then it isn't for you. Turns out, there are at least 600 people in the world for whom it IS fun to talk about programming. 
Ankle surgery. I'm really hoping it's in Bellevue again next year so I can attend. I had already lined up approval and funds from my boss but yeah... ankle surgery.
For the same reason Node is asynchronous: To handle lots of simultaneous (long-lived) requests without eating up a lot of OS resources and stack space.
I'm not *so* involved with C++ that I would travel to a convention about it, even if I could afford to. Nor am I likely an advanced enough user to get much out of it. Plus, I'm canadian. Hope the people there are having a good time, though! (And sorry if amateurs are frowned upon in this section.)
98/03 lower_bound's specification was simply unclear, and was interpreted by some vendors as requiring sorted homogeneous input. VC had debug checks that rejected heterogeneous types. Glad you liked the (void) trick, I was trying to optimize for time which is why I skipped it on the first pass.
After missing Chandler Carruth talk I learned the hard way not to leave the Pascal room for anything :)
Renting this place for a week, plus two decent snacks meals a day, WiFi, hotels shuttles, A/V recording of everything, all do have a cost. I doubt if they even break even by the end of the day. 
In a lecture you can learn about stuff you would never have thought to look up yourself.
You should probably come up with a more rigorous process to review the 2nd-tier talks and presenters. There was a pretty consistent high level for the 1st-tier talks (the Keynotes and the ones in Pascal) but for the rest of them it was very much a crapshoot. There was equal chance to find something really insightful and creative or to have to endure listening again to someone talking for half an hour about how "in our day and age microchips are starting to scale in cores rather than speed". Seriously I must have heard this in four of five lectures by now. Also, you need to ban John Lakos next year. That guy is the worst troll.
What are your goals with these events? Are you aiming to gather professionals and industry reps only? Or do you want to welcome a much broader community, irrespective of their background and professional level? If you want to promote C++, attract novice programmers and participate in your events, that $1000 fee is going to be a major barrier. 
I think Meeting C++ is what you should look into.
This was the 3rd week of classes for me at the local community college where school policy is to automatically drop students after 3 absences. Perhaps if it had been a few weeks earlier I would have been able to attend, particularly with the student discount. Looking forward to the online videos in the future!
It's called a tax-deductible holiday ;)
The convention being about C++ is a big deterrent for those of us who don't even know how to use C++.
#1 reason is that I hadnâ€™t heard about it until it was too late. #2 is that I donâ€™t fly well, but thereâ€™s not a great alternative for central Texas to Seattle.
It could be helpful if you wrote where the organizers could have advertised in a way that could have reached you. CppCon was all over /r/cpp and /r/programming.
I think your idea of attracting and engaging with novices is great. I never felt out of place going to SIGGRAPH for example, even when I was still just a student. I managed to go back then only through the charity of my family covering both the travel and conference admission--i didn't even have food or lodging costs covered (thankfully some friends there helped me out a great deal). But even as a broke student bumming my way through to the event, I was grateful to be in attendance and it had a very positive impact on my eventual career. But if the admission fee had been too high, I never would have made it there.
A little of both - many of the boostcon/GN organizers are the organizers here as well. Same conference chair, same program chair, etc. The recordings are being done and postprocessed by a professional firm, not by volunteers (as C++Now/Boostcon) does.
While completely acknowledging your point, I'm just answering the man's question about what held me back from attending. After factoring in all of *my* expenses I probably could have attended this first year if the admission was half it's current rate. But as it was, I just couldn't swing it.
Student registration is 150 USD
*I* certainly don't frown upon amateurs here. Frequenting decent forums is a good way to learn after all!
&gt; It's designed to connect C++ with either Java or Objective-C. I can understand Java, but why wouldn't one just compile as Objective-C++ in second case?
I'm a student attending CppCon, and it's really awesome, but I almost couldn't go, and it still costs a lot for travelling and lodging, plus I'm taking a week off school too.
/r/rust
C++ must be the language that generates the biggest emotional reaction. 
Yeah I am not going to travel around the world to only go to the free content. 1000USD is way outside of any solo devs price bracket.
Combining what some others have said... I use C++ at work, but not a ton. More C# and Matlab. If not for VS Express supporting C++ for free, I might have gone Fortran :) My C++ usage just isn't high enough right now to justify business cost of travel from NC, and more so being out of office. Usually I'm good getting the filtered down blog bits and video after the conference is over.
I donâ€™t know that thereâ€™s anything they couldâ€™ve done that would have necessarily meant Iâ€™d have known about it sooner.
That might be worth a consideration, but when I factor in the flight from Germany and stay in the US it still comes prohibitively expensive. Just as a side-note: The Chaos Computer Club Germany manages to have a much larger congress with an attendance-fee of ~100â‚¬; the Chaos Computer Karlsruhe manages to have a somewhat smaller congress (still the second largest annual hacker-congress in Germany) without mandatory fee (we recommend 20â‚¬ donation).
Afaik CCC achieves this with many, many volunteers. And guess the speakers there don't get any money.
I find C to be liberating on small (less than 1kloc, roughly) stuff, in that it helps me avoid over-engineering. It's also a surprising amount of fun. With C++ I'll start a project by writing the classes and modules for the domain, and then I'll think about how they interact and what the API for the them should be, taking into consideration how I can prevent misuse, how errors should be handled. For a small program, this is overkill. With C I can just start writing the code I need to. Most of that stuff up there doesn't matter anyway for a small project. It's also sort of fun to use pointer arithmetic, unions, and raw pointers in ways you don't typically use them in C++ because they're vaguely dangerous and/or better abstractions are available. It's like living dangerously. Lack of RAII makes the, uh, novelty of it wear off somewhere around the 1kloc mark though. Lack of STL, boost, and friends isnt a huge deal because there are a billion C libraries (klib does well to replace std vector/map, even if it is hacky and macro-based).
&gt; appears to do the same job without the extra interface def step? SWIG actually recommends that you write an interface file. They provide a good rationale in their [documentation here](http://www.swig.org/Doc3.0/SWIGDocumentation.html#SWIG_nn8) explaining why an interface input file is a good idea.
What is the (void) trick?
Many algorithms want to say `++it1, ++it2` in loops. (Ordinarily, the comma operator should be avoided in favor of separate statements, but using the comma operator in a for-loop's incrementing part is justifiable.) This is problematic for generic algorithms that want to be bulletproof. The iterators can be user-defined types for which the comma operator is overloaded. (In the worst case, it might be `operator,(T&amp;&amp;, U&amp;&amp;)` found through ADL, i.e. grabbing everything.) The STL is required to tolerate this scenario, because nothing in the Standard gives the STL permission to fail here. The fix involves realizing that the comma operator cannot be overloaded for void subexpressions (just as the plus operator cannot be overloaded for integers on both sides, etc.). Either `static_cast&lt;void&gt;(expr1), expr2` or `expr1, static_cast&lt;void&gt;(expr2)` would be sufficient. This can also be written with C-style casts: `(void) expr1, expr2` or `expr1, (void) expr2`. I chose the last version, because `(void)` is far less verbose than `static_cast&lt;void&gt;` (and not dangerous, unlike all other C casts). Putting it in the middle is visually unambiguous for C casts (putting it at the beginning is unambiguous for compilers but confusing for humans), and also works for 3 operands. Specifically, `expr1, (void) expr2, expr3` defends both commas from being overloaded, since the operator is left-to-right associative. The first (left) comma has a void right-hand side, and the result of a comma expression is the result of the RHS. So the second (right) comma has a void LHS, and is also defended. As I noted (quickly) in the talk, this does not extend to *four* operands (you'd need another cast) but fortunately there are no occurrences of `++it1, ++it2, ++it3, ++it4` in our STL implementation. Previously mentioned [in my VS14 blog post](http://blogs.msdn.com/b/vcblog/archive/2014/06/06/c-14-stl-features-fixes-and-breaking-changes-in-visual-studio-14-ctp1.aspx): "C++11 requires STL implementations to tolerate overloaded address-of operators. VS 2013's containers did, but not all of its algorithms (DevDiv#758134/Connect#797008). Additionally, STL implementations are required to tolerate overloaded comma operators ("because nothing forbids them"), which is problematic for algorithms that take potentially-user-defined iterators and say things like "++iter1, ++iter2" in their for-loops (DevDiv#758138/Connect#797012). We've audited all STL algorithms, with all permutations of iterator strengths, for address-of/comma issues. We've fixed all of them (by adding a handful of addressof() calls and eleventy zillion (void) casts), and we've added a test to ensure that they stay fixed."
In C++, we use compiler options to control how directories are searched for headers and libraries. GCC-style options are `-I` for including headers and `-L` for linking libraries, see [the documentation](https://gcc.gnu.org/onlinedocs/gcc-4.9.1/gcc/Directory-Options.html#Directory-Options). This allows you to use libraries without putting them in system-wide paths.
&gt;With C++ I'll start a project by writing the classes and modules for the domain... &gt;For a small program, this is overkill. That's your problem, not one of C++. 
I think you should have a look at tools like [vagrant](http://www.vagrantup.com/) or [docker](https://www.docker.com/). Vagrant is VM manager, it allows you to configure your desired environment and its built on top of existing virtual machines (VirtualBox, VMWare,etc). The problem with is the required overhead. Docker is different because it shares the kernel host. Here is a quick description from the website: &gt; The Docker Engine container comprises just the application and its dependencies. It runs as an isolated process in userspace on the host operating system, sharing the kernel with other containers. Thus, it enjoys the resource isolation and allocation benefits of VMs but is much more portable and efficient. So, docker might be what you are looking for.
Great explanation of the (void) trick! &gt; ADL I'm still somewhat unclear how operator,(T&amp;&amp;, U&amp;&amp;) works with argument-dependant lookup but thanks for the detailed explanation (and your great talks too, btw) of the approach. I'll try to study it further on my own. 
In addition to this, there are environment variables such as DYLD_LIBRARY_PATH (OSX)/LD_LIBRARY_PATH (linux et al) to control where the loader looks for dynamic libraries and in what order.
The project [slides](https://bit.ly/djinnitalk) from the CppCon 2014 presentation are available and explain why they chose a different approach than SWIG. 
I'm looking for a new job while trying to hold down a job that's dying. I'm pretty much booked up. You know how hard it is to find a decent coding job in Silicon Valley? (Particularly when you're an old engineer.)
Thanks for the explanation. Actually, I used something similiar when I specify multiple expression for type requirements: struct Incrementable { template&lt;class T&gt; auto requires_(T&amp;&amp; x) -&gt; decltype( (void)x++, (void)++x ); }; I used `void` cast to avoid problems with types with crazy comma overloading. I actually cast each one instead of trying to decide which one is better to cast, and its simpler when you add more than two or three. However, forgetting to add the `void` casts is still a problem. So instead, I use a type list like this: struct Incrementable { template&lt;class T&gt; auto requires_(T&amp;&amp; x) -&gt; valid&lt; decltype(x++), decltype(++x) &gt;; }; So if I forget the `decltype` the compiler will yell at me. You can read more about it [here](http://pfultz2.github.io/Tick/doc/html/design/). 
It would be nice to have a CppCon in central texas maybe around february time.
Why is he a troll? What happened?
try home-brew, it puts everything in a directory it calls "cellar" and then symlinks the headers and such into /usr/local/ Removing things is super trivial!
&gt;in C++11 and up Praise Bjarne, may the old standards die abruptly! 
Last I checked (a month or so ago) that was still considered experimental.
There was this one talk about type-erasure in which he interrupted the speaker multiple times because he didn't understand the talk and he didn't like the way it's presented. He did that until others in the audience told him to stop. Other than that he just strikes me as a pompous guy who did something mildly interesting 20 years ago and lives off that glory ever since.
Yes the problem is you. You think because you paid to be at the conference and that you waited in line to ask your question that you're entitled to have the speaker which obviously is not being paid for presenting to stand there listen to your half-assed question and then come up with an answer that will not only satisfy you but all the other yous that are present. Typical entitlist mentality. Go write a blog or something and stop posting on this reddit, don't know why the moderators keep on allowing your lame posts on this sub. 
dude probably sees 'entitlists' in his cereal bowl every morning
I picture him cursing Obama while he was writing that response.
You forgot to tell him to get off your lawn, oldie.
What does that idiot (Obama) have to do with this thread. By the way I agree with you about the rude behavior and have seen such at other conferences some totally unrelated to programming. A good Q&amp;A session would have a moderator managing the microphone. I think it is more that rude actually, it is pretty pathetic and identifies these people as self important tools. 
Interesting. In the version I had, I recall that you had to specifically enable it. That may have been 3.1; 3.2 came out on August 19th. Though they don't mention changing the default in the [changelog](https://qt.gitorious.org/qt-creator/qt-creator/source/165f759e184b28be8bb071e6ed3308436e404238:dist/changes-3.2.0).
That's true. I guess it's just easier for me to restrict myself by enforcing a subset of the language. Even then, I wasn't saying there's anything wrong with C++. I just don't think C is stupid. I actually think it's valuable in a lot of other cases too, but the only time I really ever use it is for the 'small problem, don't want to overengineer' case.
&gt; I heard that someone shouted at a published author and presenter (who will remain unnamed) in one of the break-out talks the fifth time he interrupted the speaker to tell everyone his barely-on-topic opinion. I think I was there for that :P I think the shouting was half in jest ("Stop it!!"), but it was getting a touch annoying. Part of it was a seemingly inexperienced presenter that wasn't making himself entirely clear maybe. I understood what the guy was getting at but I also saw why (he who shall not be named) was missing the point. It wasn't a breakout talk though, it was a real presentation. Perhaps it was a different instance. But I did see an event like that happen. Edit: the real issue there was I think that the questioner was expecting to learn something from the presentation but what the presenter was talking about wasn't new. It was perhaps a somewhat new take on an old subject but someone like 'the published author' wasn't going to learn anything new from that talk. There were a lot of talks like that. Earlier I lamented that the con seemed mostly geared toward people less experienced and I hope that wasn't taken the wrong way. I think that's necessary and also a good thing...I just wish I'd known or that there'd been some more clearly labeled "Advanced subject" items vs. "this be for students". I would never suggest people not teach and every so often even intermediate/advanced devs pick up a different take on a basic subject. My particular interest is in fact how to make advanced subjects trivial and "meh".
It is a good thing that this is a CPP forum because what I'm about to say would likely raise hell in a Python thread. In any event I see the Virtual environment concept that is popular within the Python community as totally fubar. Seriously why would you want to keep dozens of slightly different libraries around unless of course you are a library developer. It strikes me as a sloppy solution. In any event people have already pointed out a few things related to CPP development so im going to assume that you are going to be using either Linux or MacOS. In both cases the operating systems keeps system files separate from user files. You really don't want to be updating the software in the system areas except when patches or updates are supplied by the vendor. You never want to become root to install trivial libraries in these areas. The UNIX world provides for a few ways to separate user files from the system supplied stuff. This includes /usr/local. Package managers (HomeBrew, Mac Ports) approach management of their supported libraries in different ways so you need to refer to their documentation. With all of this said though you don't always want a bunch of stuff going into /usr/local. I prefer to leave that managed by HomeBrew in my case. So where do you put the stuff that you develop personally or isn't managed by your package manager. Right in your home directory where you can create a system of subdirectories to cover your personal development needs. If need be you can create sets of subdirectories but that can get ugly. So you end up with a bin, src, lib &amp; etc directories for your code common to most of your projects. Libs and other stuff specific to one project can live in that projects subdirectories. Also I see the Mac and Linux platforms doing a bit better handling library revisions than say Windows. Unfortunately I've yet to find a good online reference that helps an individual come to grips with how to use the various features of the UNIX (POSIX) environment for development. If anybody out there has a list please post it. This isn't even covered in most programming texts. In any event if you find yourself needing a whole bunch of slightly different files (libs) to accomplish whatever, you need to consider that you are doing it wrong. I've have never come to grips with the virtual environment Python approach. I like using Python too. You have a lot to learn so I'd suggest getting documentation for the system you are likely to be programming on. 
&gt; What does that idiot (Obama) have to do with this thread. Nothing. Nothing at all. Edit: Which is kinda my point and a running joke in the US where everything that happens is Obama's fault. Granted, I'm disappointed...but it gets silly and the whole "entitled mentality" just struck me as something that would be said in parallel with an Obama rant.
&gt; WTF is the context for this?? CppCon &gt; Who is sutter... THAT you'll want to know. He's a very good C++ developer (that might not actually write code anymore due to his leadership positions) who has a rather incredible tallent for simplifying complex C++ rules behind easy to follow idioms. You should buy ALL of his books. At the worse it could be shit you already know, but he tends to be able to point out subtle crap you didn't think about and then wrap it up in a simple response you can follow from then on and simply forget why...because it just works and it's easy now. So learn who that guy is. Here's his blog: http://herbsutter.com/ And his really old one: http://www.gotw.ca/gotw/ All of that shit is quite relevant and enlightening.
You have a weird definition of "completely ignore."
He usually does. I queried on his blog.
Aw I missed out on the drama, had to leave that session early. Kind of related, I noticed how often people would interrupt the speaker, and it seemed to be 100% non-Americans. WTF? Learn some manners people. Edit: removed personal details.
There actually wasn't much drama until I created it with my post. Just annoying people doing annoying things. I'm that guy though. Was sitting in the back at STL's presentation and some dude came in 20 minutes or something in. It was standing room only and this ass-hat decided he'd stand in front of me. I said, "Dude, you seriously going to stand in front of me?" He grinned at me for like 30 seconds and then eventually went away. Like I want to be looking at your asshole instead of PPT. vOv I might have fingered it if he hadn't left.
Slides will appear on CppCon's official website soonish, and recordings will be available in about a month, but I thought it'd be nice to post my slides immediately (they can be read standalone, unlike some presentations).
&gt; 100% non-Americans Yeah, those pesky foreigners with their uncivilized foreigness ... &gt; and I almost said something Alpha male detected.
&gt; You can't really help the awkward people at a convention, but at least try not to become one yourself. God that's true. Instead of a "Questions" slide it should say instead "If you like the sound of your own voice asking the question better than the answer itself, step away from the mic". There was this guy with Scottish accent and a green shirt who was a prime offender of this every single day.
Somehow, the Q/A sessions in PAX seem to have been pretty consistently good
&gt; British He was Scottish I believe
&gt; He's a very good C++ developer (that might not actually write code anymore due to his leadership positions) And that's what I don't understand. Why do people want practical advice from an "evangelist" type? C++ changes fast - and being part of the committee and holding a few keynotes a year doesn't make up for practical experience. 
&gt; I just wish I'd known or that there'd been some more clearly labeled "Advanced subject" items vs. "this be for students" Yes. I know people who would have preferred each track. &gt; It wasn't a breakout talk though, it was a real presentation. Yes, my mistake. I meant it wasn't one of the talks given in the big room where everyone attends. &gt; My particular interest is in fact how to make advanced subjects trivial That's when you know you're really starting to understand the topic at hand.
Definitely one of the better talks I attended. Right up there with Scott Meyer's talk and Walter Brown's. Do you always talk this fast?
I'd love to hear your observations on black people patterns.
Thanks. Yeah, I have difficulty with my speed in presentations that are prepared in advance. When my thoughts are organized and I have coherent slides to walk the audience through (which took over a solid week of work, as usual), my natural impulse is to deliver them at the speed of thought. I tried to restrain myself (compared to GoingNative 2013) but I guess it was still pretty fast. At least I had an extra 10 minutes for questions! :-&gt; When my thoughts are vaguely formed *and* I have to sketch or type material along the way, I go much slower - like in my Channel 9 videos.
So you are actually human... that's a relief. No, wait a minute... Today in Shutter's talk you seemed to have groked one of his final examples and found a problem with it even before I finished reading it off the slide... so something is still fishy here. Do you remember that example? what was it that was wrong with it? 
&gt; that could be something like reference_wrapper. The STL is actually required to have "unrefwrap" machinery to deal with this specific case (it is internal and not available to users). For example, N3936 20.3.3 [pairs.spec]/8: "template &lt;class T1, class T2&gt; constexpr pair&lt;V1, V2&gt; make_pair(T1&amp;&amp; x, T2&amp;&amp; y); Returns: pair&lt;V1, V2&gt;(std::forward&lt;T1&gt;(x), std::forward&lt;T2&gt;(y)); where V1 and V2 are determined as follows: Let Ui be decay_t&lt;Ti&gt; for each Ti. Then each Vi is X&amp; if Ui equals reference_wrapper&lt;X&gt;, otherwise Vi is Ui." That is, given reference_wrapper&lt;string&gt; rw, saying make_pair(rw, 1729) returns pair&lt;string&amp;, int&gt;. I do not know how to do this "generically", only by special-casing types like reference_wrapper.
CppCon does not pay speakers.
I was not sitting next to you, I think most of the people in the room heard you shout it was incorrect :). Thanks for the explanation! BTW, do you have any idea why Bjarne was missing from the last 3 days or so? I was hoping to get a book signed...
&gt; I do not know how to do this "generically", only by special-casing types like reference_wrapper. OK, maybe `reference_wrapper` was a poor choice for that example because the generic case is what I was getting at. I've let myself get out of date recently. Does auto work this same way? So if I have: std::reference_wrapper&lt;int&gt; fun(); And then I say: auto i = fun(); Do I get an int?
These are great, thanks. I think I understood everything without needing to see the video except one thing â€” why do you consider `for(auto elem : range)` bad even for int? I created the following testcase: #include &lt;vector&gt; void foo(const std::vector&lt;int&gt; &amp;range, void (*callback)(int)) { #ifdef BY_VALUE for(const auto elem : range) #else for(const auto &amp;elem : range) #endif callback(elem); } I compiled this both with and without `-DBY_VALUE`, and compared the generated assembly. The result was completely identical on every compiler I tested, which included gcc 4.7, 4.8, 4.9; clang 3.4, 3.6; and VS2013. So it can't be an argument about performance, and in the const case I can't see it being an argument about being able to accidentally modify a temporary copy. 
`auto elem` permits `elem = 1729` to be dropped on the floor. More subtly, that and `const auto elem` permit `&amp;elem` to be stored somewhere, only to evaporate during the next iteration.
No, you get `reference_wrapper&lt;int&gt;`. The only transformations that `auto` performs are those performed by template argument deduction for function parameters passed by value (namely, decaying away references, top-level cv-qualifiers, arrays to pointers, and functions to function pointers).
&gt; Why do people want practical advice from an "evangelist" type? Because his previous advice throughout the years was pretty fucking good. We can always disagree with his advice, but sure as hell we'd want to hear it.
Take a look at my blog post where I implement a library based solution. http://jrb-programming.blogspot.com/2013/12/a-workaround-for-type-inference-with.html The disadvantage is for the types in which you are interested, you have to specialize a template. What do you think if this approach?
To exploit this machinery, you could write `auto x = get&lt;0&gt;(make_tuple(fun()));`. Definitely comment on why you're doing this though. 
seems fairly over-engineered, but this looks useful.
Thank you. Since we want people to use and improve the library we will be changing the license to MPL 2.0.
I might not understand the issue but is this the type of thing you are looking for? decltype(var) cpy = var; I'm guessing if this worked there wouldn't be a question about it though. 
Sure, there are a bunch of C++ conferences. But the question was why I didn't attend CppCon. ;) But honestly, it's not really comparable to CppCon's lineup, is it? ;)
&gt; Why do people want practical advice from an "evangelist" type? Human nature, and the practical limitations of of our day to day reality. Simply put, there is too much advice out there already and it the quantity of if increases faster then any one person can process it. Therefore we have to apply some sort of filter to select a subset of advice to listen to. With a perfect filter, that subset would contain only the best of the good advice. Obviously that is impossible so we aim to build ourselves the best approximation we can. One common criteria is to select advice from sources which in the past have given good advice. Like I said, this is basic human nature. It happens subconsciously most of the time, and much like C++, it's stubborn refusal to go away in spite of obvious flaws suggests it is actually quite good in practise. Of course, bad filters are depressing common also, e.g [following celebritiesâ€™ medical advice](http://www.bmj.com/content/347/bmj.f7151) and [Morton's demon](http://rationalwiki.org/wiki/Morton's_demon).
How do you become a C++ guru?
But... Why not multithreading? 
Interesting approach. I may use this in cases when I'm in a generic context.
The rules about decltype changed a bit I think in C++14 and I don't know in what way. I don't believe that responds to the issue though. The thing is that the type of `var` could be a proxy object when what you really want and need is the true value type. The worse ones are ones in which you get a reference value so that `cpy` in your example behaves like a reference rather than a value. In these cases if you assume you have your own copy, which would make some sense because that's what you implied you wanted by not saying `auto &amp;`, you can cause undefined behavior when you invalidate the proxy. So far as I know, your example code would not behave any differently from `auto cpy = var`, but again the new rules are in that grey area of half-igorance, half-understanding in my brain.
This. Sutter's advice is generally sound and he explains his reasoning behind it. You don't need to accept him as an authority and he seems the humble sort of expert that wouldn't want you to. Should also be noted that one of the other foremost experts we use for advice as a community and professional group has actually never worked in C++ professionally. Meyers has never been a professional C++ developer and instead calls himself a C++ anthropologist. He goes around talking to the experts that DO work in the field and sort of collates their methods into something understandable and general. He does write some C++ code but it's generally experimental and if you've ever frequented usenet you've probably seen him asking the community for help. You don't have to be in the trenches to understand what is needed and give advice, especially if you explain yourself such that your reasons can be accepted or not on their own merrit.
General utilities like [`void_t`](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3911.pdf), among others.
converting new types into strings EDIT: also: * splitting a string * scaling a vector depending of another vector: return Vec2(a.x*bx, a.y*b.y) * many function like vector_length when it's not present in libraries * a configfile class to load text which is inside a text file to directly set variables depending on their name * a long list of geometry function like arcs, angle of three points * generating a list of random values * calculating a color from a hue value
Would you say that there are two kinds of TMP utilities: those for library authors and those for Joe Programmers? I just looked in a couple of my projects and aside from the library I linked above, I found that I hadn't made a single one in favour of stuff from Boost.
Hmm, if there are two objects that will take the value of operator= wouldn't a compiler error be thrown, but if decltype(var) is used it has to be that type's operator= and not a reference proxy type? 
I don't know. Isn't serialization just converting plain data to something like XML or another format to write to a file ?
Yeah. I'm trying to understand your use case. Why do you need to convert new types to strings?
Well, I assumed that we were talking about the same thing and you used `var` as a shortcut. The real problem is when you're calling a function: proxy&lt;int&gt; fun(); Now if you do either of these: auto i = fun(); decltype(fun()) i2 = fun(); You end up with the `proxy&lt;int&gt;` type and not the `int` type you needed.
While we're constrained in some ways, we're given latitude in other ways. This allows implementers to do sneaky things, and prevents users from observing those sneaky things.
A windows handle wrapper; or nowadays just specializing default_delete so unique_ptr can handle it. 
Not an addition to your list. But I would suggest looking at Intel's TBB for your threading needs. It's open source, too
The point of virtual environments is the same as the point of keeping "system" and "user" files separate, it's just a finer grained separation.
My header comment template usually. Never satisfied.
I think ICU can be statically linked and it's license is liberal enough to be used in most projects. You can cut the data size down to about 1MB I believe if you exclude most of the obscure encodings it supports. Still though, we roles out own UTF8 library that mimics std::string but wraps utf8cpp and another C library. I keep suggesting to our main engineer for that project to open source it... Maybe one day.
Not necessarily needing, but definitely wanting: a small header-only unit testing harness. I ended up writing [this](https://github.com/wallstop/SlimTest-) which has helped a ton.
Not sure I get the distinction between "library author" and "Joe Programmer". Does Joe never intent for any of his code to be reused? Ever? By anyone (even himself)?
Ah yes, the rite-of-passage unit test library. Nice work open sourcing it!
&gt; Still though, we roles out own UTF8 library that mimics std::string but wraps utf8cpp and another C library. Same here. I'm going to take another look at ICU when I get a chance. I wonder what devs who use ICU have to say about it.
And of course you use [autoinsert](http://www.emacswiki.org/emacs/AutoInsertMode) to insert it, right? :)
Modern c++ (c++14) it's very different from old versions of c++ and to use it effectively one must have to program in a different way.
Thanks for the suggestion, totally forgot about TBB. In any case, I think TBB is great for only certain types of parallelization. My uses are generally less intense.
Clever.
Build systems. Compiling a set of source files with no external dependencies into a single executable is a well solved problem; anything more complex is not, especially if you want to do things like provide fully repeatable official builds while also being well-behaved on Linux and using system libraries there.
I just gotta say, that code reads terribly. Assigning an iterator to a pointer? Even if the underlying iterator type *is* a pointer, it just feels wrong.
To print them?
CHandle of ATL?
Serialization streams objects (to binary, text, whatever, stream can be a file, but also a network connection or memory). "Plain data" doesn't do it justice.
Shouldn't pimpl\_ be mutable in order co compile object::impl * pimpl() member?
Ah! There's a [time-honored Japanese technique](http://en.wikipedia.org/wiki/Kancho) for that.
Back when I used Python a lot for scripting (2003-4), virtualenvs did not exist as such. Never understood why such thing came to life. Luckily I seldom use it nowadays.
Iterators are convertible to pointers, even though they usually aren't just pointers. The alternative is something like `&amp;*i` or something. Although, as it happens, the actual code in my case is `i-&gt;second` because I'm using a map (although it's not the STL implementation, because the code has to compile 'freestanding'). 
I really love to see and hear Bjarne do these presentations. He has a very natural way of presenting that works really well for me. I hope one day to be able to attend one of his talks in person.
I use ICU. The APIs are not of particularly modern design, but they're more than workable and everything you need is there. They're also designed for performance: You have pretty precise control over buffers that will be used and when allocations will be performed. One potential downside is ICU's use of UTF-16 as the "native" string encoding. This is actually not a problem for me, since the code base I'm integrating with also settled long ago on UTF-16.
Please realize that most of the operations an application waits for are already asynchronous and take no CPU time most of the time (like IO, and all modern APIs provided by OSes), so there would be no benefit in introducing multi-threading at this high level of flow control, but just the opposite. These operations use threads under the hood but provide an asynchronous interface to the user. So this programming model is rather about task coordination than concurrency.
The [Meson build system](https://github.com/jpakkane/meson) aims to solve exactly this problem. (Full disclosure: I'm the main developer.)
Oh, oh yeah sure... [.__.](http://www.consoletuner.com/wp-content/plugins/wp-o-matic/cache/1d98762f41_277441-sequwl1.jpg) ^(I use VS2013, I'm gonna get crucified for not knowing this)
I wasn't directly watching the video and heard "vector of cheese". (vector&lt;T&gt;) Now I can't stop hearing Bjarne say it.
Haha, no worries, I'm just pulling your leg :-) 
On what boundaries do you use ICU? Do you generally separate it from the rest of your code?
Ah, now your use case is more clear. So general debugging utilities. You just reminded me that I have a few of these as well!
Check out Catch.
oddly that's the bread and butter, it's not really a wheel that needs reinventing
Better than having a comment: wrap it into an appropriately-named function. That said, a `static_cast` to the wrapped type does the same and is less arcane (but, like STL said, itâ€™s not generic).
How do I get these new versions (kdev too)? I tried apt-get update/upgrade and nothing was upgraded. :/
I'm not a C++ expert, so I'm not sure I should comment on the content of the article, but two things I think you could do are: (1) put code in some monospace font, and (2) increase font size. Good luck with your blog. You could also ask for feedback in hackernews and the ##c++ irc channel @ irc.freenode.com.
But, is it modern enough? I mean, is it ready to replace its direct competitor: Java? If not what is so modern about it? Modern rock wheel is still a rock wheel.
&gt; mutex and RAII lock wrappers, until std::thread I work on RTOSes and the functionality I need out of threads (setting priority) and mutexes (configuring to change thread priorities on priority inversion or not) are beyond what the standard has defined. So even with std::thread, I tend to use my own versions.
Odd, you misspelled /r/vim ;) 
It's funny to see "C++", "Java" and "modern" in a single sentence. IMO if C++ defines an ABI, and maybe gets (optional?) separate compilation of templates, then it can replace pretty much anything.
&gt; vector and matrix classes Good God, please don't write your own LA library. Use on of the many outstanding libraries like NT2, MT4 or Boost uBlas. 
I like Eigen too. Template header only, powerful, and simple to use.
Yep Eigen is great too.
Oh vim, that's the thing I used to launch in other people's terminals in uni to frustrate them. "HOW DO YOU GET OUT OF THIS THING? IS IT FROZEN?!!!"
`Ctrl-z` and `kill -9 %` of course. That's quite easy to remember... 
I have always wondered who are these people who create such massive softwares like KDE. I know its open source, but where do they get people to volunteer? I once tried to volunteer but there was no guidance, I was lost in the massiveness :( and then quit
How would you compare it to that copy on write document thing that Sean Parent presented a while back? I'm on the phone, so I can't give a link. But it should pop up on Google. 
I still use it to quit vi occasionally
I use both actually... emacs is great for VHDL since the whole tool integration with QuestaSim. That's an instant subsccribe for me, thanks!
Mostly if I'm messing with a server and haven't bothered to use tramp (Emacs package) to connect. I don't actually use it for coding!
the alternative would be to have it already present in the language or libraries. it's true that it might be better to let developers come up with their own tool and way to not clutter/bloat the language and library (I'm talking about vector length or geometry functions for example). I don't really see an alternative as the possible solutions to a problem is always different. The code will change depending on libraries and even language updates. So no I don't think there's an alternative, but it's important to note that this list of small bits of code keep getting smaller. Libraries and language update make things better. Well my misc.h and misc.cpp are getting bigger, but they're no so big. templates reduce code size. To be honest, a lot of those small function and classes were made because I use SFML which is object oriented, while I could just have used gl_* functions to diagnose and debug my code. kinda ironic. &gt; What are the things you reinvent for every new project? Basically I'm always trying to use a minimalistic approach to programming, my goal is always to write the least amount of code possible, until it's too painful to do so. So I'm using the language without tweaking it too much. Re-usability is very often solved with libraries. I don't try to make my code re-usable, I always adapt my code to libraries.
VC's version 11 (year 2012) didn't support variadic templates, version 12 (year 2013) fully supports them.
&gt; splitting a string Use `std::regex_token_iterator`. &gt; generating a list of random values Use `&lt;random&gt;`.
Don't know that I've seen that presentation but it's probably very similar.
There is now a [comparison page](https://github.com/jpakkane/meson/wiki/Comparisons) on the wiki.
would be better to have string split(input, separator) I do use random. there is a wide choice though, it's good but you have to make a function if you want it to be simpler to call inside your code.
yes indeed. I'm not using it because I did not manage to compile SFML with it. SFML doesn't provide binaries for it.
Is it worth watching when you've already seen his Going Native 2013 keynote talk, which seems very similar?
 videos, or it didnt happen :-) Were these sessions recorded? if yes,where and when are they going to go up so that the rest of us could watch what we missed.
umm, comment below? :) &gt; Also, videos are currently being edited, but it's going to take a while to edit the 100+ hours of content, so stay tuned! 
&gt; New comp sci student, trying to visualize some of the programs possible with c++ Probably every console game you've ever played (if any) was written in C++. All of the browsers available right now are also written in C++.
I tried, its not that easy.In some other OSS project, after fixing the feature which really annoyed me, I mailed the patch to the dev mailing list which was then categorically refused as most users like the software behave in specific way. Even if I ask some OSS project gurus to give me some feature/bug they think is low priority but they would like to have in their project, I always get the reply that chose your own which is really difficult given the huge feature wish list and bug list.
Photoshop. 4.5 million LOC and growing, an overwhelming majority of which is C++. Source: I'm an engineer on the team.
&gt; Probably every console game you've ever played (if any) was written in C++. It should be clarified, however, that it's more often the game *engine* that is written in C++, but the game *logic* is typically written in another language, because it's cheaper and has faster turnaround on changes to use an interpreted language than C++. For example, Naughty Dog's games are all C++ game engines where all of the game logic is done in a Lisp dialect. Civilization 4 was done mostly in Python that is executed by a C++ game engine. Many other games use Lua or some other interpreted or bytecode-compiled language.
C++ underlies software ranging from the smallest programs to the largest, most complex. The famous Arduino microcontroller (an Atmel ATmega328) is usually programmed in a simplified C++ dialect (with several C++ features disabled), using the same GCC compiler that is used on every Linux and BSD system. Windows is written in a mish-mash of C and C++. Almost all game engines are written in C++, so every game based on the Unreal Engine, Unity, CryEngine, or any of a dozen others is written in C++ with game logic developed in any one of a hundred other languages. All of the major graphic design software - Adobe's Photoshop and Acrobat, Maya 3D, Blender 3D, and anything else that does 3D modeling or vector graphics or anything of the sort is written primarily in C++. Your web browser is written in C++. The Java Virtual Machine, on which everything Java-based relies, is written in C++. Even the most popular C++ compilers are written in C++. You would be hard-pressed to find something you use every day that isn't, or that at least doesn't rely on, something written in C++.
Stranger's Wrath on the first XBox. It was a from scratch game engine. I got to build the nav system, AI, steering behaviours, a custom scripting language for designers, tons of other random things, ohoh, and invented a component system long before they were a thing (in games anyway). The pathing system could support dynamic modifications to it, like doors opening and closing or walls breaking. The scripting was very C like and couldnt crash the machine. The scripts compiled down to a custom VM I also wrote. Scripts could also dynamically reload while running, which massively reduced iteration time (in fact, all our assets could, geometry, shaders, textures, scripts, nav etc). The faster your iteration loop is, the more things you can try out, which means a better game. All pretty cool. Fun to write. Very modern C++ style. Smart pointers (strong and weak, custom written), RAII, STL (stlport with a custom vector set of classes), shallow hierarchies. But still very fast, locked at 30fps no matter what (which means it was really around 45fps most of the time).
How bad is the code really? I've heard horror stories. 
Back-propagation neural network used to predict outpatient re-admittance post heart surgery to 85%+ accuracy.
Rudimentary games (card games, tetris, stuff like that), basic data structures and algorithms implementations, system tasks automation, and so on. The list is endless, really.
This looks similar to [boost hana](https://github.com/ldionne/hana). Could someone provide a comparison of the two libs?
- header only file-system library - header only logging library
Thank you! We have decided to change the license to MPL 2.0. Expect it to be done within few days.
Yes, now i want to check stuff from CppCon even more (ãƒ»ã¸ãƒ»). Now i need to wait for videos...
That's really cool! Wonder what the compile time is for something like that.
Excellent start - looking forward to the others and videos 
std::string sprintf(const char *format, ...); printf formatting tags is still the best for me.
Warning: you might start wanting to live in Emacs after a while.
I don't remember about std thread but boost thread lets you get at the native handle. That would probably allow you to set priority.
For those interested into starting hacking on KDE software [this book might help get you started](https://flossmanuals.net/kde-guide/).
Are you my Chipdesign Prof? Because he actually said that. But yeah, Emacs is hella lot awesome, altough I still prefer IDEs for the right job. I guess /thread? Don't want to get caught in an endless circle with deltacycles popping up everywhere.
Any idea when videos are going to be released?
must. have. videos.
The code quality of a long-running software project proportional to the square root of the projects age and 'shop is old :-).
I've listened to it just for this. For anyone interested jump to min 28:21 
/u/STL said in about a month.
Yeah, but often you want to set the priority at creation, not afterwards. I think the comittee did a great job standardizing threads, but it just doesn't meet the needs of some RTOS systems. I'm OK with that.
The API is sufficiently C-ish (error return codes rather than exceptions, naked pointers for buffers, etc.) that I do like to isolate it from the rest of my code. I've written wrapper functions for common operations like UTF-8&lt;-&gt;UTF-16 transcoding and lower-casing. Things like the latter are, again, easier to implement given that strings in the rest of my code are already 2-byte. If the rest of your code is UTF-8 or UTF-32 you'll have to think carefully about when and where to do conversions to avoid performance becoming a drag or your own API becoming awkward. More involved uses of the library such as regular expressions typically end up requiring entire class wrappers to do resource management on, say, the pattern object pointer.
[EntityX](http://github.com/alecthomas/entityx). It's a library, not an application, but unlike many things I've written I'm still fairly happy with the code years later. That makes it stand out for me personally because my old code usually leaves me with a feeling of distaste :)
I can't tell you the hours I spent marveling at that game while playing. Thank you.
C++ and C are the languages that everything is possible in. There is nothing you can't do, since you can interface with the OS and hardware fairly directly, since OS and drivers are written in C++ (or plain C). The question is more 'what limitations to other languages have'. If you are new though C++ is not what you want to learn first. I would choose python. Modern C++11 may be where you eventually want to go though.
I admit to being ignorant on the restrictions of RTOS systems.
Can't wait for the videos!
All of the shaders, materials, and artist tools for feature animated films. It was a great job. A few more specific examples: * Post processing motion blur * 2D-&gt;3D toolset * Color management software to convert renders from our in studio colorspace to digital cinema, film, etc. * Lots of shaders. Grass, wool, and other materials Tons more good things. 
I always wonder why they take so long to turn this stuff around. By the time all the videos are released a lot of people will have forgotten about it. Is it that hard to edit a clip down to size, stick a title on it and upload? They could employ someone to do it at the end of every day.
Bjarne had a meeting that he was not able to reschedule back in New York. I know that he tried very hard to get it rescheduled right up until the conference started. He was disappointed that he wasn't able to stay for the entire conference.
I am an undergraduate student and went to this conference, and have nothing but praise for the committee, organizers and the speakers at this conference. I learned more in 5 days than I ever have in the past 2 years of university courses. In addition to this, there is more content that will soon be available than I will be able to process in the next 6 months. Great conference, great people, great C++
I wrote a chess engine for chinese chess back in school. I continued with it for a couple years or so but eventually just stopped. It's still the thing I'm most pleased with though I've worked on much larger things professionally. http://xiangqi-engine.sourceforge.net/ I actually started writing it on my own but our senior project got so large that we decided to switch out. The teacher let us leverage what I'd started to create a full "product".
I have a 24-core Mac and can build it top to bottom in about 15 minutes. The Windows build takes hours. _hours_.
That's pretty wild!
It's not too bad. There are certainly differences between files given who has owned the code over the years. As the language/compiler support has evolved so too have the programming paradigms and methods used. If the code works its unlikely we'll go back in and touch it without good reason. Skeletons certainly do fall out when we do go back and touch it, however. Fortunately there is an encompassing architecture that has managed to hold fast for many years and has kept the core application code in a good state. I also work with some of the most brilliant devs in the business, and we're slowly cleaning things up. Slowly. It took me about two years to get comfortable enough with the code base to make far-reaching, architectural changes. Even still, there's a lot about the application I know nothing about. Edit: Grammar and words.
&gt; Is it that hard to edit a clip down to size, stick a title on it and upload? Yes, it is. We have ~100 hours of HD video to process. We have a professional team doing the video editing (same guys who did the recording).
A cpp video is a dish best served, uhm, after-removing-lengthy-periods-of-mumbling-when-asked-to-explain-a-rationale.
Fucking egoraptor in the wild. Nice.
You gotta admit, his Sequelitis vids are full of good reaction shots.
Awesome! Thanks!
Not to undermine others' answers that showcase things C++ really gets used for, but asking "what kind of things can you write with C++" is kind of like asking "What kind of places can I drive to with a Ford?" You _could_ write most programs with most programming languages.
Ah, so not quite as bad as I thought, however I've heard that adobe really hates to drop legacy code. It's the reason OSX kept Carbon compatibility around so long.
Some maintainers can be ... difficult to deal with. I guess I just had more luck. It is a shame when someone willing gets turned down - it is not like the free world has too many contributors that we don't need more. The only thing that I can add is to try and try again - once you find your place, it can really be gratifying.
Dropping legacy code is complicated by a number of factors, but the biggest justifier to keep/drop code is an attempt to stay customer-relevant. For example, we drop legacy code to reduce QE burden, which is a Good Thing - it lets us focus our testing on features we trust customers are going to use. However, we also have several defunct file-format readers within the application that are kept around in the off chance someone might want to open an ancient file. It's a tricky balancing act to pull off, to be sure.
Terminology note: At CppCon a breakout session is any non-plenary session and these are "real presentations."
Same experience for me, also, whats ur name dude
There was a big discussion about this in the CLion thread and someone in the [issue tracker](https://youtrack.jetbrains.com/issue/CPP-668) found this workaround so I figured it was worth posting.
Jason
I only skimmed it, but this is the same principle as QSharedData/QSharedDataPointer/QExplicitlySharedDataPointer, right?
The coolest and most fun thing I ever wrote in C++ was my own playstation emulator of course! Pretty fun to beat a good game on your own emulator!
http://m.imgur.com/FEsg8bL My error message after adding the number then the first name.
A CRM system for handling abuse complaints (spam, hacking, child porn, you name it) into telcos. It's the backbone of abuse handling at some Very Big telcos in several countries, and it's all my code. C++/Qt with some embedded perl, lua and javascript. Client-server, builds from the same source tree on Windows, OS X, Solaris, FreeBSD and a bunch of Linuxes. About 400 kLOC++.
Photoshop's core framework is [MacApp](http://en.wikipedia.org/wiki/MacApp), an object-oriented framework originally built by Apple in Pascal. Many decades ago it was abandoned by Apple and the easiest thing to do for Adobe was to keep Photoshop ratcheting forward on it. Since then it has been ported to C, C++, parts of it to Objective-C, and more. Some might call it a monster of Frankensteinian proportions, and this is true to some degree. Realistically some parts of it are certainly antiquated, and its core elements use nothing similar to the more modern programming techniques that are common today. The important bits, when we have to roll up our sleeves and ratchet something forward, are often updated and modernized, though still in limited form as they have to integrate with older code still. Photoshop's MacApp looks nothing like the MacApp it was when it left Apple's hands. Nevertheless the last vestiges of that core framework still echo throughout the codebase. As to the specifics of your question, we custom draw all our widgets in an effort to make the experiences identical regardless of the platform you are working on. Some things we keep "native", however, like the relative locations of OK/Cancel buttons, OS dialogs for alerts, saving, etc. As for events, and without going into too much detail, messages are received through an event pump and are passed around a known, semi-global list of event handlers - the first one to pick it up and act on it wins. Welcome to 1990.
It's possible.
But beware, another thread or piece of hardware may change his name at any time.
I believe they'll be available in about a month. Something like 100 hours of video content to edit down...
Don't think we will have to wait too long (hopefully): http://www.bashfilms.com/event-video-production/ "Bash Films specializes in post-production media services and has developed a workflow that provides you the videos within a day, not weeks."
In what way is Java a direct competitor to C++? That's like comparing chalk and cheese.
I've been to CppCon, here is my trip report: http://meetingcpp.com/index.php/br/items/my-trip-to-cppcon.html Its been a blast to be there, and some of the highlights I'll never forget. And this event was just the start...
I know this is an early alpha, but i really hope they support Mingw-w64 on the release. Otherwise this will be useless on windows. At least for me...
I think that the coolest thing with the C++ is not the programs you can do with it, but the weird tricks you can put up in order to make neat things. http://stackoverflow.com/questions/1995113/strangest-language-feature And the best one imho : http://www.eelis.net/C++/analogliterals.xhtml
Could everyone please stop with this terrible habit of sharing .pptx or similar formats that look terrible on every platform in every program that is not the authors configuration. If you want to do something like that at all, at least use open-document. But preferable to everything like that: Just use pdf. They work! (Unlike everything else!)
Chandler Carruth's talk on data structures and algorithms was very important, but most of the content has already been covered by Herb Sutter in a previous conference. Most of the parallel talks were good, the first one pretty much just described what parallel vs concurrency was, and showed some c++ parallel libraries. Herb Sutter's keynote was probably the most informative to me, but Bjarne's was pretty good too. If you want to get your brain pooped on, watch all of the lock free data structures.
Honestly I wouldn't care if they released raw videos, having access to the videos sooner would be pretty nice.
Not sure why they didn't do the same for desktop.
ive only looked at sutter's slides. the passing smart pointers slides seem a bit over my head but everything else was nice
This is the proper public reference for this task: http://youtrack.jetbrains.com/issue/CPP-81
My distro is mingw-w64 now.
I use PPTX because of the appear-animations. Sorry (I know I'm usually Mr. Flat Files - all of my Standard proposals are plain text).
This might be a somewhat legit reason to use it in the presentation itself, but I fail to see why you wouldn't export it to pdf for the repo. I should however mention, that unlike Bjarnes horribly broken presentation, yours just has one title that contains a line-break. Concerning LibreOffice: This is what I am using. It might render correctly, if the fonts are installed. This is however not everywhere the case, but pptx obviously assumes that it is; which is the main reason, why it is such a horrible format. (Not all of Microsofts fonts are installed on my GNU/Linux.) PDF does not have this problem and can be viewed with lots of different programs, most of them much more lightweight than a full blown office-suit.
Me too. I was (/am) really excited for this IDE but the hard dependence on cmake and only supporting old MinGW means I have not been able to have a try yet which is a shame. 
I have long used QT for desktop apps, I gave it a try for mobile and it just didn't turn my crank. The resulting apps were too big and the initial load time was basically forever. I will check in with each new significant version to see if these issues have been resolved. 
I hope the author does not mind but I converted the pptx to PDF for those who prefer PDF. I changed nothing, just did an export from PowerPoint 2013. There are two versions, the [first](https://www.dropbox.com/s/gg8il8e175xhxdo/CppCon%202014%20-%20Introduction%20to%20Microsoft%20C%2B%2B%20AMP%20Slides%20Only.pdf?dl=0) is just the slides exported to PDF and the [second](https://www.dropbox.com/s/n13t5vzuqlc4vlb/CppCon%202014%20-%20Introduction%20to%20Microsoft%20C%2B%2B%20AMP%20with%20Notes.pdf?dl=0) is the slides and notes (this makes the slides smaller in the PDF). Any problems please let me know and I will take them down, as the files are publically available in pptx I hope I am not upsetting anyone by doing this. Cheers!
Yeah, I bet my lack of complaints with the rendering is because I am using LibreOffice on Windows. I know the general pain though, I made the mistake of formatting my resume in LibreOffice on Linux, and then having it look retarded when opening in Windows. I thought the entire point of a document format was that it was stable, and I learned that is not the case the hard way. Spent some time fixing it up, exported as PDF, and haven't worried about it since.
**Awesome!** Would you mind doing this for the other presentations [on github](https://github.com/CppCon/CppCon2014) as well and create a pull-request? (I hope that the maintainer is reasonable and accepts it.) As I mentioned: I cannot do this myself since they are extremely broken for me.
I'm an Italian student and hobbyist game developer that had a chance to attend and [speak at the conference](https://github.com/SuperV1234/cppcon2014). It was a **fantastic** experience. I got to meet all my "idols" *(even took a photo with Bjarne!)*, I spoke about what I love doing (game development in modern C++), I made new friends and most importantly **I've learned a lot**. Can't wait for next year! It was truly an amazing experience!
As a speaker and an attendee, I have to say that this is amazing! There were many occasions where I wanted to attend 2-3 talks that were at the exact same time - can't wait to learn even more thanks to CppCon :) 
What introductory book would you recommend for c++11 and c++14 features?
Because on desktop you can distribute the shared libraries (DLL/dylib/so) under the LGPL and it's not a problem. There's plenty of hard disk space and RAM. This works fine for commercial sofware developers who have not purchased a commercial Qt license. On mobile platforms, however, space and memory is tight and you want to link statically. Doing this under the LPGL is a headeache* for commercial software developers who have not purchased a commercial Qt license. This is why this new Indie Mobile license makes sense. * Either you provide your source code (big no-no) or you provide the object files so that your customer can relink with a different version of Qt (and that's assuming you the customer will use the same configuration options you used, otherwise your Qt and his Qt are ABI-incompatible). 
Congrats Vittorio, it sounds like you had a blast at CppCon. I coulnd't attend this year but I look forward to seeing the video of your presentation--the slides for your talk seem a little...sparse. Thanks for the very good videos for writing simple C++11 games. I've watched all 4 of them and I like how clean your code looks. It's very easy to understand and follow along with. I hope you will continue on with this career in C++ you have a lot of talent Vittorio. Maybe you'll give another talk at CppCon 2015? Edit: Please don't misunderstand my comment about your slides. I think they are excellent quality I just meant I expected to see tons of code like in your earlier videos--I guess watching the presentation will clear things up for me. Your slide's graphics are great.
Whether or not it's technically grammatical, it's highly non-idiomatic and sounds wrong to a native English speaker. Questions just aren't phrased in this manner. (Statements can be, for emphasis. Compare "it happened", "it did happen", and "it *did* happen", with increasing emphasis. Kids learn this quickly: "I brushed my teeth." "Did not!" "Did too!") If somebody knew what happened, but wanted to know more, we have a word for that: "why".
I've been using Qt for a few years now and Its a pretty well done framework; I hope it continues to do well.
1) I care about content so I prefer videos, tnx for that, If you offer a way to give some money to the conf I would give you some as sign of gratitude. 1.1) I am not some hipster humanist(can you guess about which lang/con Im talking about) so I dont really care about conferences(meeting ppl...), just the juicy content(presentations). 2) Too expensive since I am from EU. I could afford it but I prefer not to.
Audio is really hard.
slides fatal / docs / cppcon2014.pdf 
Worked on the production renderer used at a feature animation studio for several animated films. Currently working on a new renderer. Graphics is fun.
I'm the author of the blog post, thanks for posting it here! :)
I'm certain they will. [This tweet](https://twitter.com/clion_ide/status/511838593242112000) by @clion_ide at least says so when reading between the lines.
Dunno why, but I had never heard about biicode before (which isn't the main theme of this blogbost obv), it sounds absolutely AWESOME! Seems to me like biicode, cmake and git (together with jenkins and google test framework) would be a killer software configuration suite for C++ devs. ZeroMQ also seemed neato'
As an Englishman, I would use the phrasing in the title in a situation where I'd heard an explanation of what happened that turned out to be false (with emphasis on "did"). Probably with "so" prefixed.
Thanks very much for your comment. I am one of the founders of biicode, long time developer in C/C++. Biicode is definitely something me and my colleague developers wanted. I left my work to start this humble start-up. We have been working a lot to reach this state, so really appreciate that you liked it. But we still have a lot to do. We are improving fast with our current users' feedback, but we still need to spread the word even more, and get more active people working on it. As you said "dunno why, but I had never heard about biicode". Please, help us with this, so we can enjoy as developers and community a better biicode. Try it, share it, give us feedback and suggestions and we will do our best to fit your requirements and build an amazing tool for all of us. 
I've been seeing a lot of posts here about CLion. As someone who uses Vim, will this IDE actually save me time? Enough to be worth the price tag? I used Eclipse about 7-8 years ago when I was learning, but promptly put it down once I wasn't in intro classes anymore.
Right but a similar indie plan for desktop would convert the LGPL users like myself.
Did any of the microsoft guys update their 'roadmap to C++14' ? Is full conformance not coming by the end of the year or what?
By the way, google test also works in biicode out of the box. Have a look at: http://docs.biicode.com/c++/gettingstarted.html
I've already mentioned it to one of my colleagues. But after reading the FAQ, unfortunately I don't think it would fit our company, at least not in its current incarnation. As a company, we would definitely need support for binary-only libraries and probably either a self-hosted version of the server or a secure subscription option. Personally I would also prefer the software itself (both the client and server) to be open-source, as I'm one of those that usually don't bother with pushing proprietary tools. More like how git or subversion has done it (then biicode.com would be more like github as a provider of services).
I did that, as an experiment writing one using C++11 features. I've since found [Bandit](http://banditcpp.org/) which I use instead now...
Awesome content again from Charles at Channel 9. &gt; What happens when you put three titans of programming language design and computing in a room and turn a camera on to capture what takes place? &gt; That's the thought experiment that led to this conversation with C++ language creator Bjarne Stroustrup, Self language creator Dave Ungar, and actor model creator Carl Hewitt. Thank goodness all three of them were present at Lang.NEXT 2014. Many topics are covered, as you can imagine. It's best that you find some quality time watch and listen and learn from some masters. This is a long conversation and there is great programming history herein! Also recently posted: [Checking In with Erik Meijer](http://channel9.msdn.com/Shows/Checking-In-with-Erik-Meijer/Checking-In-with-Erik-Meijer-Erik-Meijer). Hoping STL finds time to do some content for C9 again soon.
&gt; As someone who uses Vim, will this IDE actually save me time? Enough to be worth the price tag? Impossible to answer.
Thanks for sharing with your colleague. Totally legitimate concerns: We are working in propietary-private subscriptions, hopefully be available by the end of the year. Current users under our "friends" program will get them for free. An in-house deployment is a little more complicated, though we are trying to collaborate with another company that could manage it, and we keep focused in the product. If you are really interested in this option, please send us an email to info @ biicode dot com and we will try to address your dev needs. As for the binary-only libraries, it is also in our TO-DO list, we can certainly manage to do so, but still not a very requested feature. But it increases priority with your comment :) We haven't managed to be open-source ourselves yet for some reasons, but it is something that is definitely in our roadmap. But please consider that github started development when git was already a reality, and they developed just the service, a service that is not open-source. We are building both things (client-service) at the same time, and it is not that we dont want to go open-source, we definitely want and will. But it is not very straightforward from the engineering point of view, we are slowly fixing things toward this goal, but it is not a technical priority, we have a lot of higher priority feature requests. The key here is that we are very focused right now in the core technology and functionality, and open-source contents, and not prioritized so much the companies and private development needs. Just give us a few months trying it out and helping us to improve and tune it, and you will have it :) 
Yeah, I've heard and used variations like, "What really did happen...," or, "What exactly did happen..." Can't really say what the difference is but it seems to carry more importance or urgency, and usually spoken with some emphasis on "did". Perhaps its an active vs. passive thing? It's weirder to see it written that way though. There's also a lot of variation in idiomatic English, especially regionally.
I still don't know when to use `[[deprecated]]` in projects ...
In that context it would sound correct, yes.
I'll follow up with authors who haven't provided PDF to see if I can coax it out of them. I'd prefer to get a PDF from the authors for a variety of reasons (but primarily so they can make sure they're happy with the outcome). Right now my priorities are getting the other ~35 presentations in there (a bunch should land tonight), and amending path names so that the repo can be checked out on Windows. For what it's worth, we did encourage authors to submit PDF. Some people really seem to want to preserve their animations though :/.
As someone who did attend I am glad as well. Made choosing a much less stressful thing.
When you don't control all of the code that uses the class/function, but you want to tell people to not use it in a gentler way than a compiler error.
Might as well try it out for now since the EAP is free. There is a vim plugin for the editor that you can use so your shortcuts are familiar. Beyond that it'd probably be best-answered by you trying it. I will say that I personally I'm more productive with a GUI debugger and IDE, mostly because that's what I'm used to (but I like being able to see the call stack, locals, and current code window without jumping between them).
Ok, so convenient for collaborative projects
More for library writers, really. On collaborative projects, if it's that important that everyone stop using the thing, you can just tell everyone.
Particularly convenient for libraries. I have a library with a function `foo`. I've updated the API, however, and now I have a function `bar` that should be use instead of `foo`. I shouldn't just remove `foo`, however, otherwise I'll break all the projects that use my library. Instead, I deprecate `foo` so that they get a nice warning when they compile their projects. I can even deprecate `foo` and provide a special message that tells them to use `bar` instead. I have my own [article entirely about `[[deprecated]]`](http://josephmansfield.uk/articles/marking-deprecated-c++14.html), if you'd like to read more.
Thanks for the reply, a vim plugin sounds intriguing.
What about something like auto x = copy( input.somefun( ) ); where copy is a template like template&lt;typename T&gt; T copy( T val ) { return std::move( val ); }
https://github.com/bloomberg/bde
Thanks
I admit that I was a bad boy and only skimmed it, but since I saw you using `enable_if`: There are definitely situations where enable-if is a valid approach, but nowadays I think that a templated tag-type is often cleaner: https://github.com/Florianjw/libyoga/blob/354906178013e7dc0b4a045c363a0d566b515b71/src/include/format.hpp#L37 Please don't mistake this for criticism of your code, I just want to point out a technique that can often (but not always) be a better alternative.
This is known as double-checked locking, and your code is in fact not a correct implementation of it: you need memory barriers before the first read of `table` and between the construction of the table and the assignment to `table`.
And if whatever you're using for threading has an equivalent to `std::call_once`, use that.
OK. I was worried about the barrier stuff and had my original implementation using atomics (which cause barriers on my target). Someone higher up wanted it done with a mutex though and I'm uncertain enough that I believed him. Oh how I wish we had call once. We use boost but are only allowed to use our homegrown synch stuff...which lacks a lot of stuff and is all based on a really ancient std implementation (yes, we chose to override the host). I'd get bitch slapped if I used call_once. One thing it lacks for example is any sort of barrier. I think the right way to fix this is to force default initialization to cover it. According to my reading of the standard, if I move the invocation of `call` into a default constructor it's guaranteed to happen before all this threading bullshit can take place. Or am I wrong about that too? Edit: oh, and also make sure it's not a function scope static but class or global scope.
2010 doesn't implement threadsafe static initialization (14 is the first version of VS to do so), so moving stuff to a constructor won't help. If you can't even use the Win32 threading stuff, I think your only options are to either always acquire the lock in `get_table`, or ensure somehow that the objects get initialized before the threads are spawned.
I don't know how VS works, but GCC wraps function local statics with a mutex. That allows you to do the following: template &lt; typename Vtable, typename TypeList &gt; Vtable const* get_table() { static Vtable const table = builder&lt;Vtable, TypeList&gt;::call(); return &amp;table; }
And the [link](http://stackoverflow.com/questions/6915/thread-safe-lazy-construction-of-a-singleton-in-c) to the SO question which addresses just this linked in the above answer.
&gt; [E]nsure somehow that the objects get initialized before the threads are spawned. I know that 2010 doesn't do thread safe statics, but don't class-level statics get default or 0 initialized before main is even called? If that assumption is true, AND it's true that all behavior in a default constructor is called at that time, then threads won't even have spawned yet and I can then just access the immutable data. Edit: I think my assumption is wrong. *Zero* initialization does not include *default* initialization even of non-aggregate, non-pod types. Even the calling of the default constructor can be delayed up to just before the first use. I'm going to have to lock always or use a much fancier metaprogram that can force constant initialization.
2010 is a pre-11 bastardization. It has some c++11 stuff, like rvalue references, but absolutely none of the memory model stuff. With that and the screwy std library I'm coding in a sort of limbo world of ancient and new C++.
A yeah, I see now. I guess this is one of the cases of not using auto. He does say "Almost always use auto"
Your `THolder` needs to use "type-erasure", which is indeed a fairly common idiom in C++...though not commonly known unfortunately so don't feel bad. The term "type-erasure" though is REALLY generic so where you go from there is probably specific to your problem. There is some libraries, all of them in boost (I'm sure there's others): * boost::any - can store anything, use a cast to pull out the real type. * boost type-erasure - can virtualize anything and additionally provide casting if you want it. Much generalized version of boost::any and in fact the main class is `any`. * boost::variant - Basically a union. Use visitors on a known collection of possible stored types. They serve different purposes. There was also a couple CppCon talks on type-erasure: https://github.com/CppCon/CppCon2014/tree/master/Presentations/Practical%20Type%20Erasure%20-%20Cheinan%20Marks%20-%20CppCon%202014 https://github.com/CppCon/CppCon2014/tree/master/Presentations/Pragmatic%20Type%20Erasure%20-%20Solving%20Classic%20OOP%20Problems%20with%20an%20Elegant%20Design%20Pattern%20-%20Zach%20Laine%20-%20CppCon%202014 The former appears to more or less describe the boost type-erasure library (I didn't attend). The latter is more of an argument/proposal to use type-erasure to replace public inheritance as the method of runtime polymorphism (is-a). Edit: and here's an SO answer I gave a couple years back or so: http://stackoverflow.com/questions/4988939/how-do-boostvariant-and-boostany-work/4989141#4989141
seriously, that's like the most important thing, with auto for return types
Also https://www.youtube.com/watch?v=_BpMYeUFXv8
Generic lambdas really help a great deal. I've found all kinds of useful places to use them. This feature alone makes moving to c++14 worthwhile for me! (The other features are great, too...) Oh, yeah! I almost forgot-- Having move semantics in lambda captures makes them much, much more useful in lots of contexts, especially used in conjunction w/ the standard library. Edit: An extra word.
Carl Hewitt's comment about the future of freedom around the 55:40 mark is probably the most important part of that discussion. In my opinion.
`nullptr` is C++11.
&gt; It's really that simple. Isn't it always though.
For the solved problems, yes. In this case, the one gotcha is initialization order, but you have to deal with that in your current design as well.
Yeah, but should be present in msvc '10. (Ah. Possibly only for C++/CLI, in which case, sorry)
Native `nullptr` [was added in VC 2010](http://blogs.msdn.com/b/vcblog/archive/2010/04/06/c-0x-core-language-features-in-vc10-the-table.aspx).
[This](http://blogs.msdn.com/b/vcblog/archive/2014/08/21/c-11-14-features-in-visual-studio-14-ctp3.aspx) is the latest publicly available table. Note that VC14 RTM is scheduled for 2015, and while it will feature significantly improved C++11/14 conformance, it will not achieve full C++11 conformance (notably, Expression SFINAE will still need to be implemented).
&gt; An in-house deployment is a little more complicated, though we are trying to collaborate with another company that could manage it, and we keep focused in the product. If you are really interested in this option, please send us an email to info @ biicode dot com and we will try to address your dev needs. It seems that my company has as company policy to prefer self-hosted solutions, as many of our contracts have stringent security demands... &gt; As for the binary-only libraries, it is also in our TO-DO list, we can certainly manage to do so, but still not a very requested feature. But it increases priority with your comment :) In addition we sometimes receive precompiled libraries we must use from customers (I really dislike this, but what do you do?). This necessitates that a library/dependency framework handles that scenario when it inevitably pops up. &gt; We haven't managed to be open-source ourselves yet for some reasons, but it is something that is definitely in our roadmap... The open source part is more of a concern for me personally as I really dislike the thought of promoting vendor lock-in. In addition I usually don't spend much of my own spare time on exploring proprietary tools, and I don't promote stuff I haven't used myself. &gt; But please consider that github started development when git was already a reality, and they developed just the service, a service that is not open-source. We are building both things (client-service) at the same time, and it is not that we dont want to go open-source, we definitely want and will. But it is not very straightforward from the engineering point of view, we are slowly fixing things toward this goal, but it is not a technical priority, we have a lot of higher priority feature requests. I can definitely sympathize with your situation, however that doesn't mean I necessarily would let it influence my stance on proprietary vs FOSS tools. I'm planning on trying out the ZeroMQ example at least, and if I like the feel of the software, I'll probably explore it a bit more =)