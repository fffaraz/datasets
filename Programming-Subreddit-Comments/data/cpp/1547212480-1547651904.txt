A class inherits by default with the private access specifier, a struct with a public one.
CMake as a Service? ;-)
How much memory does a pointer take up?
I think thats an idea worth debating. Have colours for categories like conference, committee etc.
This is something I've been waiting for since their original announcement on the LLVM mailing list in April 2018 outlining their vision for clangd tooling updates: https://lists.llvm.org/pipermail/cfe-dev/2018-April/057668.html Overall, I think this could shape up to be a great addition to clang tooling and will likely improve the C++ IDE experience for any editors using LSP (Vim, VSCode, Emacs, Eclipse, etc). 
A feature with identical syntax to what they proposed in the paper was once in the language and has been deprecated: [Dynamic exception specifications](https://en.cppreference.com/w/cpp/language/except_spec).
Andrew Kelley of the zig language quit his job to work on OSS full time. He noted that he would be drawing down on savings while doing this, but his patreon is growing to the point of allowing him to sustain this for much longer. With a bit more growth, he could reach a livable monthly income in many cities.
I agree. A majority of the vcpkg patches applied are to allow for exactly this. Passing a different CMake build flag allows easily toggling between the two.
Exactly that!
Most of our code is statically linked, and therefore compiled non-PIC. We have some use cases where it would be convenient to dynamically load some code, but to do so would require compiling all our code twice: non-PIC for static linking and PIC for dynamic linking. The shared aspect of dynamic libraries have no benefit for us.
I noticed that `now` can be slow as well. If you only need 1-second resolution (a common use-case for network programs), this implementation provides a clock which caches the value of the time: https://github.com/ripple/rippled/blob/develop/src/ripple/beast/clock/basic_seconds_clock.h#L149
no, I just despise software subscriptions.
The C++ has: + A UTF-8 character literal : u8'a' + A UTF-8 string literal: u8"hello" Until C++17, type of these literals are `char` and `char [6]` Yes. I can write a scoped enum 'enum struct char8_t : char { }' and call it a UTF-8 character type. So the others. If C++ doesn't define a standard UTF-8 character type. Our industry will have many incompatible these user defined types which is a pain when you want to use multiple libraries. If char has implicit conversion to/from char8_t, we can't overload it based on character encodings. So char means both implementation defined ordinary character encoding or UTF-8. `&lt;filesystem&gt;` created a function `u8path` and expect the programmers to pass only the UTF-8 string. There is no compiler check to enforce such contract. With the recent change, char8_t is introduced as a fundamental type, just like char, wchar_t, char16_t and char32_t. No implicit conversion between char, and u8path was deprecated. So it should had been in C++11. I'm really angry at the situation because I had warned about the absence of char8_t 10 years ago and it wasn't heard at face value. I decided that I need to voice my opinion my strongly. The Japan is responsible for the unfortunate status of wchar_t. But that's another story.
One difference here is that the triples aren't output sorted by Z - where they are in the original. Not that I much liked the original. I also second coroutines being a better choice (like the article mentions).
It has the same issue than gsl::span though, signed integer for span::size(). Not a direct replacement of std::vector :/ [https://github.com/Microsoft/GSL/issues/559](https://github.com/Microsoft/GSL/issues/559)
Qt creator is free and far better in my opinion in most cases (CLion makes my laptop reach temperatures suitable to fry an egg).
Open source for free as long as you bend the knee. Also, since it is a subscription service it doesn't matter that they offer it for free for students. They know damn well that unless the software project is their schoolwork, students do not have time to work on programming projects.
VS it's std::steady_clock, GCC it's std::system_clock. I forget what clang does with libc++ does.
I think everyone is focused on syntax. Thatâ€™s a google search away. I think the main thing is if given a big code base how quickly can you be productive. How do you debug? Whatâ€™s a data breakpoint? How comfortable are you using a debugger gdb it visual studio. Callstack is not what you expect to be, some shit was inclined. What now? How do debuggers work? 
Okay, why this over clangd, at least for C++? I thought Apple was interested in clangd.
&gt; there's only quick sort(std::sort) in STL. [What are you on about?](https://en.cppreference.com/w/cpp/header/algorithm)
This is one of the reference websites for C++. Youâ€™ll find data structures in the â€˜Containersâ€™ section, and popular algorithms in the â€˜Algorithmsâ€™ section. I hope that answers your question :) 
&gt;SourceKit-LSP is built on top of sourcekitd and clangd
Pure guesswork, but maybe it acts as a wrapper for clangd, so a LSP client can talk to SourceKit-LSP instead of clangd and sourcekitd.
OP probably meant: "there is only one sort algorithm in the STL (quick sort)". On a sidenote, I don't think `std::sort` is required to do a quick sort.
What about [stable_sort](https://en.cppreference.com/w/cpp/algorithm/stable_sort) and [make_heap](http://en.cppreference.com/w/cpp/algorithm/make_heap) + [sort_heap](https://en.cppreference.com/w/cpp/algorithm/sort_heap)
Done :-)
Thing is: Writing (or copy/pasting) simple cmake files for simple projects is easy. I don't need a separate tool for that. Where cmake files do become complicated and where I'd need help is when I have to write cmake files for different compilers and architectures, with multiple targets, compile options. If you support all of that you are effectively inventing your own build description language with cmake as an execution engine, which may be not all that simple to use and of course rquires maintenence, documentation and so on. If you don't support all of that I'll probably need to know cmake anyway and it probably becomes very difficult for you to hit the sweetspot between the "functionality is too trivial to use an extra tool for" and "this tool/language is too complex to learn / to maintain". That being said, cmake is incredible verbose and has a lot of boiler plate and defaults I wouldn't call best practice , so there certainly is the possiblity to put a better language on to of CMake, even if it only covers the common cases.
Excellent articles. I will re-use it if I ever got question about ranges. &amp;#x200B; One thing that surprised me a lot was how complicated it is to write our own ranges. I guess it's not something that will have to be done a lot anyway since we can use composition over existing ranges.
I'll see what I can get going and will post to this sub when I have something working. Thanks for the feedback on the idea.
Does this compile? in your implementation you have constexpor auto end() const
Glad to see the filename placeholder in the fmt syntax. Now everything that prohibits me to use this is our C++98/stlport stack :(
What about cquery?
Thanks. Have you created any Cmake projects in Qt creator? Does it maintain the CMakelists.txt for you?
It turns out that "abi stabilized forever" and the kinds of stuff people do in regex libraries to make them fast don't go well together...
&gt; it blew all other regex libraries out of the water (at least for benchmarks that were showcased in the talk) I don't want to defend std::regex implementations or its API, but this on its own doesn't say a lot about the implementation quality. You can implement almost all functionality in the standard library more efficiently, if you are working against a different API specification and only satisfy a part of the requirements the actual stl types have to. 
A few guesses: - Maybe they didn't want to drag in all the boost-internal dependencies - Maybe compile time of boost version was deemed unacceptable (is there any difference?) - Maybe there are some subtle differences in the API between the bost and the stl version.
It looks like they're mostly just updating clangd to work on the macOS only XPC transport layer to communicate with LSP, which is honestly kind of disappointing. I was optimistic that they would bring better IDE based refactoring features to the clangd backend, which it looks like they have to a small extent. This is all based on a quick review of LLVM code reviews on clangd by an apple developer (Jan Korous) https://reviews.llvm.org/search/query/_GvHUxuXrvRZ/#R Not sure if he or anyone else on the Apple dev team hang out here, but would be good to have some clarity if anyone has more info.
It is more or less required *not* to do a quicksort.
It looks like the unix shell pipe symbol, where you have a pipeline: output | filter0 | filter1 and it's available to overload for a range as an operator.
what deeringc said - especially with regards to allocation. `std::deque`'s have their storage allocated in large fixed size blocks, sequentially as storage is needed. thus they have a higher minimum cost to setup, but can have cheaper "reallocation" strategies when compared to `std::vector`
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/aexix1/im_learning_programming_on_my_own_and_i_need_some/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Could you elaborate how stable ABI comes into play when it comes to regex performance?
The fast engines add a zillion special cases for common patterns their engines recognize. But we canâ€™t ever do that. And given that our engines were somewhat stupid initially now we canâ€™t replace the engine with something better because that breaks ABI.
&gt; I don't want to defend std::regex implementations or its API For the record, I don't see anything bad about the API. &gt; but this on its own doesn't say a lot about the implementation quality. Fair enough. Though quick googling along the lines of "std::regex slow" will return quite a few results showing how much slower `std::regex` is compared to even the often called slow `boost::regex`. I've done benchmarks for my very specific use and didn't get drastic differences like the CTRE author, but `boost::regex` was still ~2.5 times faster. &gt; You can implement almost all functionality in the standard library more efficiently, if you are working against a different API specification and only satisfy a part of the requirements the actual stl types have to. Did someone say hash tables?
Yes. constexpr non-static member function doesn't imply const-qualifier. If I remember it correctly, constexpr was used to imply const-qualifier in C++11, but it was changed in C++14 or 17 I don't remember.
Alright, that makes a surprising amount of sense. Thanks for the clarification. If I understand you correctly, the standardized regex implementation can't be iteratively improved over time thanks to ABI? Does that mean that, in cases where performance matters, people just shouldn't use `&lt;regex&gt;`?
First, `std::sort` is not a Quicksort. In fact, the standard does not allow classic quicksort as an implementation of `std::sort` because of `O(n log n)` worst case complexity requirement. All implementations of STL I know use [Introsort](https://en.wikipedia.org/wiki/Introsort) as an implementation of `std::sort`. Second, as already mentioned in the comments, standard library provides two other sorting algorithms: `std::stable_sort` and `std::make_heap` + `std::sort_heap`. And last, the standard library strives to provide facilities that would be reasonably useful for a vast majority of the use cases. Of the multitude of sorting algorithms you can find in the textbooks, most are only of academic/educational interest, some are well-balanced, and others excel in specific circumstances. Introsort was chosen by implementers because of it's good combination of average-case performance (thanks to quicksort) and optimal worst-case complexity (thanks to heapsort). If your application is critically dependent on the properties of sorting algorithms, you would write your own implementation tailored for your specific use case anyway. If you want to play with different sorting algorithms, I would recommend [cpp-sort](https://github.com/Morwenn/cpp-sort) library by /u/morwenn
I was trying to not deviate from the proposal doc. Feel free to change it to `size_t` if you do end up using it.
Yep, high_resolution_clock is pretty much useless as it is in practice always an alias of either steady_clock or system_clock. Better to just choose one of those directly instead, so that you know which clock you are dealing with. For performance measuring steady_clock definitely makes the most sense.
Commenting to see if anyone has a response to this as cquery is pretty great
Clarification would be nice. To me it looks like additional functionality somebody wants added. 
I wonder how can CLion update the cmake files reliabily ? what if you generate the targets / source files with macros / functions for instance ?
At my last job I had fun overloading the `&gt;&gt;` operator to use spdlog logging levels on the command line with boost.program\_options. 
\&gt; I need it to work on MacOS \&gt; Visual Studio 
The concept has both pros and cons. On pros side, you can use concept based overloading which allows you to pass ranges and views to the algorithms and `operator |`, but if you pass a type that doesn't satisfy a range concept, the compiler correctly issues a compile error, saying your type X doesn't satisfy concept Y. On cons side, it's really hard to write generic concept based library. Because you have to figure out the necessary constraints and write it down everything or it's just good old unconstrained template.
Because there aren't many choices. `&lt;&lt;` and `&gt;&gt;` has some issues. Well, `|` has some issues too. I didn't follow the discussion of why they decided to use `|`, but it resembles pipe in unix shell. At least, that's something. There is a proposal of workflow operatorr: `&lt;|` and `|&gt;`. and I hope it is accepted to the standard. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1282r0.html
Because 95% of applicants who think they know C++ really just aced a poorly-taught "C with methods and vector&lt;T&gt;" course at university, taught by someone equally clueless about the language.
There is also ccls which is a fork of cquery which is being more actively developed and has better support for Emacs
This release is essentially the layer I put on top of spdlog in my projects: default logger and source location of the logging. Looking forward to trying to use their solutions.
https://gitlab.kitware.com/cmake/cmake/issues/18317
Do you mean that the actual engine exposes too much of its internals in header, which is why changing it would lead to breaking the ABI? Or is there another issue?
Why does the ABI keep you from improving std::regex\_replace() ?
It's useful when multiple conferences are emitting posts/videos at the same time. We could choose slightly different shades of the same basic hue, though.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/aewkyi/library_for_algorithms_and_data_structures/edtvb0y/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Don't forget partial_sort and nth_element, for when you want just a little bit of sorting.
I purposely avoided leaking the specific topic.
I can honestly say Iâ€™ve never seen that warning and I compile *everything* with `/W4 /WX`. Weird! Now Iâ€™m concerned that `/W3` is silently overriding my config. I build projects using `cmake â€”build .` in the shell and donâ€™t use Visual Studio. Maybe thatâ€™s something to do with it. Canâ€™t see why though; it still uses *MSBuild* under the hood.
We recommend things like RE2 on a regular basis.
Because regex supports arbitrary character and iterator types that forces pretty much everything to live in the header.
That's correct. For MSVC, high_resolution_clock is a typedef for steady_clock, which is powered by QueryPerformanceCounter. system_clock is powered by GetSystemTime[Precise]AsFileTime.
Because the slow part of regex_replace is the matching bit thatâ€™s embedded in the type std::basic_regex; which thanks to ABI basically canâ€™t change under the current ABI regime.
This is also recommended by Howard Hinnant, the designer of the chrono library.
Well, its also only present in the old mode of reddit, in the new UI its all just a grey tag.
unordered_fooâ€™s inefficiency is minor compared to regexâ€™ inefficiency; but the smaller inefficiency there is compounded due to widespread use.
In the 2008-2010 era, it was unthinkable for MSVC to ship Boost code in the product. Now, Microsoft has changed, and we're shipping two Boost-licensed components in the product (Boost.Math for special math, Ryu for charconv), with more possible in the future. But we can't go back and deal with regex until we can break ABI (and even then, regex is big, so it'll be a lot of work).
That code doesn't need yield. Is only necessary to know how many rows are still available before getting the next chunk of triples. struct pythagorean_triplet { int x, y, z; }; struct pythagorean_triplet_generator { xt::xarray&lt;int&gt; state = {{ 3, 4, 5 }}; size_t available = 3; pythagorean_triplet next() { if (available &lt; 3) { state = next_pythagorean_triplet(state); available = state.shape()[0] * 3; } available -= 3; const auto i = available; return {state[i], state[i + 1], state[i + 2]}; } };
Also that code doesn't need yield. Is only necessary to know how many rows are still available before getting the next chunk of triples. struct pythagorean_triplet { int x, y, z; }; class pythagorean_triplet_generator { xt::xarray&lt;int&gt; state = {{ 3, 4, 5 }}; size_t available = 3; public: pythagorean_triplet get() { if (available &lt; 3) { state = next_pythagorean_triplet(state); available = state.shape()[0] * 3; } available -= 3; const auto i = available; return {state[i], state[i + 1], state[i + 2]}; } };
Replacing `unordered_map` with `absl::flat_hash_map` yielded ~20% better performance in the hot path for my project. The `&lt;regex&gt;` one, while having a more drastic impact is in a cold path, so I'm more concerned about `std::unordered_map`s.
Surprisingly, re2, for my very specific use case of parsing ctags files, was a tiny bit slower than Boost.Regex, but I'd like to get rid of boost completely, with filesystem and regex being only components still in use in my project.
That seems like a bad design decision :(
Awesome. I use spdlog a ton, glad to have the new features for adding source line information. Also, default logger is great!
The tl; dr of why I think this reflective enum implementation is useful, even if you may feel like you've seen a bunch of these: 1. It doesn't have any dependencies, require any user codegen (and therefore no build system integration), but only uses macros. 2. The enums it creates are actually enums (or enum classes), not classes (unlike Better Enums). This has a lot of implications for avoiding issues when upgrading from a normal enum, avoiding edge cases, and making it easy to "adapt" enums that you don't control. 3. It supports C++ 11, 14, 17, and tries to be idiomatic about it in terms of the types used. 4. No dynamic allocation or use of exceptions; uses optimal approach (switch-case) for to-string conversion and will be further exploring user-facing features that allow using switch-case conveniently. 5. Reasonably polished: it's documented, constexpr friendly, tries to keep as many features as possible (controlling enum values, implicit/explicit storage, declaring enums nested in classes). This was roughly my list of requirements for a reflective enum at work (other than 11 support which I added to be nice) and I wasn't able to find any libraries that met this list of requirements. I actually wasn't able to find any implementation that even met 4/5 (I think, although I didn't look very carefully at things that violated 1). I briefly discuss Better Enums and Meta Enums on the github page in the section on alternatives, if you think there are other alternatives I should discuss please let me know. Other than that, hope you enjoy the library, and feel free to give feedback here or to open an issue. I'm hoping the API is relatively stable now. I'm looking to try to get this into boost as well (it also uses the boost license; hoping that makes it easier as well for people to adopt).
I don't know of any in the open source world, but it's would be trivial to implement if your allocator already has a way to label allocations. 
Really sad that you can't hide private members of c++ classes without an additional level of indirection even though there is effectively no difference between between a member function and a plain c-function taking an opaque pointer as an argument. 
I wish people wouldn't do this it's a monumental pain in the ass. The fact is that static and shared libraries are two different artifacts and should be identified and available to the consumer as such. The problem of ensuring that all transitive dependencies use the same type is orthogonal, and shouldn't be solved by using a flag to get them to masquerade as the same thing. If I have a project that uses both types of library for different targets for different deployment scenarios, how am I supposed to do that? Run the build twice and selectively enable what targets I build? Use different projects all together (with the same sources somehow)?
&gt;Have getters and setters for the private members. In some cases where private variables can only be given access and not write access, can opt for read-only objects. This is however, a standard practice in object oriented programming. Well one would argue that this is still imperative way of thinking about code. OOP is more about objects reacting to events than setters and getters.
Well at least this question is effective. If somebody answers that, you know what to do :)
Use this library and absolutely happy. 
And they are cheaper performance wise than C++ exceptions. Maybe C++ exceptions can be enhanced with the potential to simply (and reliably) translate to setjmp/longjmp calls under the proper circumstances (e.g. no destructors to call, no dynamic_casting to perform on the return type, setjmp buffer saved and passed around by the programmer).
While I have given answers that represent what I would be looking for specifically as part of an answer. None of these questions are "closed questions" or have a "right answer" or are suitable for every environment. I tend to work in high performance computing environments, so my questions are tailored towards problems we encounter frequently. Each of my questions is designed to start a conversation between employer and interviewee regarding a subject area. It you look at each questions, I would be interested in responses/discussions focused around: #1. Re-allocation and manual memory management #2. Unexpected allocation behaviour/knowledge of allocation behaviour #3. Coding styles and principles, flexibility and willing to use company enforced ones. I'd further expand on this during discussion on how they ensure coding styles are followed etc (knowledge of toolsets/CI/CD etc) #4. Error handling techniques, philosophy when dealing with exceptions. Mitigating performance impacts of try..catch blocks #5. Manual memory management, understanding of how memory is allocated and works; performance impacts and dangers of different approaches. #6. How they handle declarations of methods. Do they like/use const? If so why, if not why not? #7. Basic check of their language skills. If you're looking for "right answers", then the interview technique is never going to work because C++ is such a versatile language and a candidates technical expertise should be fairly low down on the list of requirements. I have interviewed multiple developers for C++ roles; and have always built successful high performing teams. In many scenarios I have chosen the candidate who did not display the highest level of technical expertise. This is because you can teach technical skills, you cannot teach personality. The way the interviewee engages in the answer and discusses their rationale for each of those questions would give me a very good sense of their language, personality and flexibility as well as potential team fit.
Agreed. â€˜Tis what we get for copying a design decision that made sense for Boost, which gets to break ABI every 6 months, in the standard library. But time machines and all that. At least regex is a leaf; just use RE2, CTRE, et al. instead.
See my response to your other question :)
Correct :) Someones "pure" knowledge of the language isn't as important as many people think. They understanding of how it's applied and used in real world environments can tell a lot about the candidates potential fit within your team. &amp;#x200B; The reality is, paying for someone to learn C++ is going to be significantly cheaper than the cost of hiring a new person if they're crap and need replacing. Skills in development and development philosophies is just as important as language knowledge. Candidate personality is significantly more important.
The reason why I don't really like questions like this is that they are "closed" by nature. I prefer a question that starts a discussion, or requires the interviewee to rationalise why they're picking something. 
&gt;will be generated for a given chunk of C++ cod I don't see this as a negative. If you look at my questions each one of them is "open" encouraging the interviewee to give me what they think is the right answer as a starting point; but all of these questions will basically start a two way discussion with the candidate. It's through the discussion that I'd be able to get a true understanding of the persons potential fit within my development team.
Yea sorry you're correct. I wrote that out in a hurry :) 
From a language standpoint you're correct. But as /u/TomSwirly points out, it's easy to reason about logically and this will start a conversation between interviewer and interviewee. If the interviewee says "that is dumb, why would you do that?" then it's a very good indication of their personality and flexibility. The reality is.. they may be a tabs only person, but our coding style is spaces. I don't want to hire someone who will refuse to use what the company is mandating because they don't agree with it. &amp;#x200B; The candidate also having knowledge that structs are commonly used as POD shows me that they have real world experience; likely at a larger organisation where they actually got their hands dirty on some code and followed an established coding style guide. This is a very a common paradigm, and is the way it is done at Google and documented in the Google C++ coding style guide.
I just someone on their understanding of common paradigms when using C++ and their flexibility to work within a paradigm they have not previously. I'm asking a C++ language question here sure, but I want a discussion about it so I can learn more about the candidates previous experience and flexibility.
Yes. You can teach technical expertise. You cannot teach personality. :)
20% is tiny compared to the performance differences we're talking about here. Try 800x (yes *times*) https://www.boost.org/doc/libs/1_69_0/libs/regex/doc/html/boost_regex/background/performance/section_id3752650613.html
Nice I'm mentioned in the release notes ðŸ˜ŠðŸ˜Š
Speaking of which, does anybody knows the status of p1089 ? [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1089r2.pdf](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1089r2.pdf)
**Company:** [Microsoft Visual C++ Libraries Team](https://careers.microsoft.com/i/us/en/job/570421/Software-Engineer) **Type:** Full time **Description:** Join the Visual C++ Libraries team and be part of the Modern C++ renaissance! Our mission on the Visual C++ team at Microsoft is to build the best tools and libraries for any C++ developer, any app, any platform. The Libraries team delivers Microsoftâ€™s Standard Library (STL) implementation of the latest ISO C++ standards. Often, we are at the forefront of new language features of the Visual C++ compiler. Also, we work on a variety of open source tools and libraries helping native code components connect to Azure and other foundational technologies for C++ applications on Windows and other operating systems. Our code ships both as open source and/or as part of Visual Studio. *Responsibilities:* * Contributing to the design and implementation of large C++ codebases * Delivering product milestones *Qualifications:* * Bachelorâ€™s degree or an advanced degree (Master, PhD) in Computer Science, Engineering, mathematics, or related field * 2+ years of professional software engineering experience * Design and development experience in C++ **Location:** Redmond, WA **Remote:** No **Visa Sponsorship:** No **Technologies:** C++20 working draft. **Contact:** Email msaleh at microsoft.com (Software Engineering Manager, Visual C++ Libraries Team)
I like having them on separate lines because it means I can enable / disable easily, and I find it more readable, too. Nice that I can get rid of the quotes, though, didn't know about that.
&gt;constexpor note the spelling
Wow... that's worrying. I already mentioned I'm only using regex to parse ctags files and for that use case `std::regex` is only two times slower. Considering it is only executed once at the start I could probably live with `std::regex`, though performance wasn't the only concern when I was migrating away from boost and onto C++11 - gcc 4.9 managed to generate code that killed the application when a user tried a ~2k characters long ctags entry.
One of the few shared\_ptr uses I've personally seen that's made sense.
Not to distract from this post, but another way to approach this is via code generation, which allows for a lot to be done in a simple way, with full compile time safety and all that. It's not a competitor to or replacement for this package in any way, but may be useful to folks considering how to approach enums in C++. [https://www.reddit.com/r/programming/comments/a33i7n/making\_c\_enums\_first\_class\_citizens/](https://www.reddit.com/r/programming/comments/a33i7n/making_c_enums_first_class_citizens/) &amp;#x200B;
Which leaves us with the question: when is the next time you can break ABI?
For MSVC, we know how to do that and probably in the next few years. For POSIX, Iâ€™m at a loss. Their shared namespace .so model is pain.
Rough, man
&gt; Now everything that prohibits me to use this is our C++98/stlport stack :( Oof
Should you want to play with the source code, you can always take a look at [https://github.com/BartVandewoestyne/Effective-Modern-Cpp](https://github.com/BartVandewoestyne/Effective-Modern-Cpp) :-)
&gt; gcc 4.9 managed to generate code that killed the application when a user tried a ~2k characters long ctags entry Current GCC probably wouldn't fare any better, as the stack overflow due to recursion in regex _still_ hasn't been fixed: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=61582
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/af12bn/cpp_help_c_programming_7th_edition_ds_malik/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Unpopular opinion: This (enumerate) is one place macros should definitely be used. The greater simplicity, compile time, and (likely) codegen vastly outweight any upsides here. Something like this that I just whipped up: #include &lt;iostream&gt; #include &lt;vector&gt; #define fori(i, x) if(size_t i = size_t(0)-size_t(1)) for(x) if(i++, true) int main() { std::vector&lt;std::string&gt; xs{"hello", "world", "!"}; fori(i, auto const &amp; x : xs) { std::cout &lt;&lt; i &lt;&lt; " " &lt;&lt; x &lt;&lt; std::endl; } } seems to work: g++ -std=c++17 -O2 -Wall -pedantic -pthread main.cpp &amp;&amp; ./a.out 0 hello 1 world 2 ! http://coliru.stacked-crooked.com/a/24e4e122c7431600 I'm sure there are more robust solutions in the wild.
I'm currently using boost.log in my application; not wild about it but it works. What's your pitch to convince me to switch to spdlog?
&gt; Even if this new feature is different, reusing syntax of another feature (even a deprecated one) would be a BAD idea. `auto` would like a word with you... ;-]
Both examples fail to compile on Visual C++ 16.0 P1: wise_enum_generated.h(30): fatal error C1112: compiler limit: '258' too many macro arguments, only '127' allowed
I heard that the fork was caused by political issues where original owner of cquery removes an active contributor (now ccls maintainer) from the team. If that's true I'd say it's sad to witness such fragmentation.
I've been using C++ for over 10 years and never heard of this "other auto"... Can you explain?
That's strange, because with gcc 5 and that user's ctags there was no stack overflow.
https://en.cppreference.com/w/cpp/language/storage_duration
&gt; If I have a project that uses both types of library for different targets for different deployment scenarios, how am I supposed to do that What does that even mean? Like you depend on both a static and a shared version of OpenSSL for some project? That doesn't make sense. It's extremely rare that someone wants a given library as both a static and a shared build. The onus of dealing with that case should be on that subset of people to figure it out, rather than making life difficult for other consumers of their library. 
Oh that!
Oh... I guess technically, that auto is not incompatible with the new auto. But `auto auto var = 42;` would be weird lol.
That's quite unfortunate. I assume that's the latest Microsoft compiler? The readme discusses the procedure to raise the maximum number of enums. The same procedure could be used to lower it in order to accommodate msvc. I could maybe lower the default number of supported enums so it at least works out of the box. I'm not sure what else I can do short of completely changing/compromising the syntax. This is limit is pretty bad and there isn't even a compiler flag to change it seems like. Open to any possibilities I've missed here.
&gt; I assume that's the latest Microsoft compiler? Yes, it's the most recent preview version for Visual C++ 2019. I'm pretty sure it's been like that forever, and it's documented in a list of [limits that are lower than the recommended minimum](https://docs.microsoft.com/en-us/cpp/cpp/compiler-limits?view=vs-2017). This is basically the number of enumerators you can have, right? I'm not sure I've ever seen an enum with 100 values, let alone 250. Lowering the limit might be a good idea.
/u/quicknir can we get runtime benchmarks versus BETTER_ENUM? I currently rely on better enum a lot. I'm open to switch but what do I get apart from template specialization? I saw what you wrote on your repo but I'd like to see more reasons why you did this and why it's better. I use C++17. 
At my company we've had some enums for example, every financial exchange in the world which I think exceeded that. Initially I wanted to error on the side of more because there was little downside but I suppose MSVC compatibility is a decent reason to reduce it. If you'd like, open an issue on the github and that way you'll see when it's resolved (also if I run into more issues maybe I can ask you a bit because I know nothing about MSVC).
Meson out of the box: ( to be fair fewer packages available) $ mkdir subprojects &amp;&amp; meson wrap install SDL2 In your project: sdl2_dep = dependency(â€˜SDL2â€™, fallback: [â€˜SDL2â€™, â€˜SDL2_depâ€™]) Now u can detect sdl2 system package and as a fallback the subproject. Of course, in order to cross-compile u need direct support in the subproject. But in general I find this pattern easy to use for my needs.
&gt; open an issue on the github Sure. I don't plan on using your library in the short term, but I can give you a hand if you need anything.
I really doubt that there will be any significant differences in runtime performance. They both use quite "shallow" abstractions (or none at all in many cases in wise_enum) and ultimately the compiler is going to have very little difficulty fully stripping them down. I'd say there are a lot of small pros, mostly coming back to the issue that the object you deal with in BETTER_ENUM isn't actually an enum. 1. BETTER_ENUM doesn't support declaring enums nested in classes at all. wise_enum does. 2. BETTER_ENUM doesn't support adapting enums declared by another library, AFAIK. This is very useful; say for example another library or even another team at your company declares a normal vanilla enum somewhere. You want this enum to work properly with your generic logging code that uses the wise_enum machinery. This is no problem, there's an adapt macro that just works. In BETTER_ENUM afaik there's no solution. 3. BETTER_ENUM enums, AFAIK, will not detect correctly in standard library type traits, potentially screwing up standard TMP. 4. You have to use weird syntax for them sometimes, like e.g. with comparisons: `channel == +Channel::Red`. 5. The templating issue, as you noted. 6. There's only one entity, the BETTER_ENUM. wise_enum supports both enum and enum class, both of which have clear rules regarding scoping and, slightly different implicit conversion behavior. I'm actually not even sure what BETTER_ENUM's implicit conversion behavior is; and that will of course be the case for any new developer that looks at your code. wise_enum is only non-standard in the behaviors that aren't standardized, but everything that is standardized behaves identically to vanilla, making it unnecessary to teach this behavior or wait for mistakes. Personally I think taken together it's a pretty persuasive list, though I can appreciate maybe it's not enough to overcome the costs of switching.
I get coding style guidelines. google's coding style guideline, as published, reads like the unholy marriage of a Java snd C programmer who thinks everything in C++ that isn't Java-esque or C-esque should be banned. Now, some of it is due to tooling issues (they had a wide range of compilers to support). But a lot of it was ridiculously dumb and backwards. If you aren't the size of google and are hiring a sr. developer, you should be hiring someone you'd trust to *change* your coding guidelines. As an example, use `struct` for regular and semi-regular types. Use `class` for things that are not regular (including abstract interfaces). Now, going from `struct` to `class` is a deep change; nobody should be "oh, it would help if I do X, but I cannot without renaming struct to class and having to sweep forward decls, painful" or whatever; if a type is becoming irregular, changing struct to class is the least of your worries. Legacy C++ will probably use struct and class correctly 90% of the time (as regular types are relatively recently in vogue). 
Thanks. No it is a good list. Do you mind explaining though how enum to string doesn't allocate?
Yup: that's essentially what I have done. The CI testers use `-Werror` or equivalent to prevent the silly stuff from getting through.
&gt; What's wrong with vector&lt;bool&gt;? They bit off more than they can byte. &gt; How can you break the one definition rule? With panach, usually with methods defined in thd body of a class. &gt; How many pages are in ISO/IEC 14882:2017? African or European? 
Bah, committee membership implies at most a 6.
You can expect a small overhead. Lets say you want to add up the ascii values of the words of a sentence and return them in a vector. With ranges what you do is first split the string at whitespace and pipe that into an accumulate transform. That means you'll iterate over each character twice. Now if you did it by hand and filled the vector at the same time as you scan for the delimiting whitespace, you only do one pass. So, don't do it in the innermost loop of your game engine. For the parts that are not the most critical performance wise, it will be ok. Many people would probably implement the above algorithm inefficiently without ranges, scanning for white space first. Comparing the 2 suboptimal solutions, the overhead of ranges if there is any will of course be smaller. I think some performance degradation is inevitable if you raise the abstraction level like that. At least if you are not super careful to understand what is actually happening in your code.
It says it doesn't _dynamically_ allocate: everything is on the stack and all the sizes are known at compile-time. A quick look shows that it stringifies the names with the preprocessor and stores them into either a `const char*` or `std::string_view`, depending on `__cplusplus` (which isn't great for Visual C++, since it's still at 199711). It then puts everything into an `std:array`. 
i think everyone being a proficient physical keyboard typist may have already passed. many young people primarily interact with computers through mobile devices and may be less proficient at using PCs.
&gt; The main goal of this project is to create a cross-platform text editor that's fast and extremely customizable vim? emacs?
&gt; depending on __cplusplus (which isn't great for Visual C++, since it's still at 199711) Not so, as of 15.7 preview 3: https://blogs.msdn.microsoft.com/vcblog/2018/04/09/msvc-now-correctly-reports-__cplusplus/
Maybe compilers will be able to perform loop fusion to some extent. We can make coroutines disappeat. Then why not range transformation fusion?
&gt; vim? emacs? More like just: &gt; vim
You're correct, but it needs the `/Zc:__cplusplus` flag, which isn't on by default anywhere.
There's a youtube presentation from a (am thinking 2017) Rust conference where a editor engine is presented that is written in Rust. It' runs as a service and then the GUI front-end has to be written in something that meshes well with the particular host platform. So on Mac OS, one might write the user-facing code in, say, Swift. Or some Electron app could be coded in, say, JavaScript while still using a performant native code engine to do the real work.
you mean it does A LOT LESS
There's no point competing with vim/emacs as they practically dominate the CLI. However, for people who want a more "modern" experience with animations, special fx, etc. it can be appealing to have one that's free and doesn't take half a minute to start up.
I heard that X-Ray (the one that GitHub started) supposedly uses a similar architecture. It can be hard to ensure a consistent experience over all platforms if one frontend is to be coded for each. The slow startup of electron apps is still a problem, let along their memory consumption and package sizes. Something I don't understand about such architectures is why - you would think that any computer would be adequate to run a simple text editor. If the purpose is to effortlessly enable remote editing there are virtual file systems.
It's very fast -- it's in the name! Async loggers are essential in my book. 
Aren't range algorithms single pass /lazily evaluated ? And are you sure std::strings would be created? That is news to me.
Are you really interested in ranges-v3 or ranges in c++20? I know there was at least one blog that did compare the performance of the range-v3 library and the result was noticeable, but I don't remember how much it was (anything between 20% and 3x).
try it. shouldn't be more than 3 lines of code.
Don't have a computer available, but will do once I have. 
Why did you not chose a UI framework like Qt?
Sounds like Xi: https://xi-editor.io/
I have made some performance test you can find them in the end of this presentation https://slides.com/filipsajdak-1/range-v3-how-to-start
Oh man i cant wait to see the andreis keynote up. Really interested to see the reactions to it!
boost:xpressive is regex's forgotten cousin. Even faster, header only, but limited to ASCII domain only.
I was expecting something much more shorter, maybe something like a function `make_view_interface&lt;T&gt;` take a lambda that returns tuple of lambda `{ base, begin, end, size }`. ``` template &lt; InputRange V &gt; requires View&lt;V&gt; using drop_view = make_view_interface&lt;V&gt;( [ V base_ = V(), ] ( V base, iter_difference_t&lt;iterator_t&lt;V&gt;&gt; count ) { return { return base_;, return std::next( begin(base_), count ), end(base_), size(base_) - count_; }; })::type; ```
I inplemented sueve with ranges and it did not have any overhead (but the lib is an old versions of ranges-v3). Here: https://github.com/germandiagogomez/the-cpp-abstraction-penalty
Hey, I've never used 'smart enums' before but it sounds really cool. Also thank you for explainig the difference and benefit of using this library over others, this post definitely sold it for me. 
QtCreator? 
Thanks. Makes sense. P.S: not a game developer so not sure why you're talking about "my game engine" :)
I did not realize they're different. Is the C++20 one available in GCC yet?
Useful thanks
For Apple, Objective-C and Swift support are all that matters. C++ is mostly used on IO Kit and Metal Shaders, nothing else, as far as I am aware. They even removed the documentation about Objective-C++, which only us grey beards still have copies of.
That looks incorrect. Python ranges would have one vector read. Are c++ ranges different? Why?
For me, it's very similar to [why sublime text did not use any pre-existing UI framework](https://stackoverflow.com/questions/7102378/what-gui-library-is-used-by-sublime-text-editor). Additionally, Qt was (and still is) rather unfamiliar to me. The UI components that I came up works great in this context as they offer great flexibility. The entire layout, including element layout and composition, is controlled by the skin. In this way skin authors and users can, for example, put the tab list below tab contents, or put it on the left and make tab labels stack vertically.
I realy like conan's solution to this: static/shared can be declared an option of the package; every package with a dependency on it can declare its default options for that dependency, but the end user has the final say for all dependencies options, including transitive dependencies; packages being exported can export multiple builds to account for different options and usualy include sources so that unusual configurations can be built by users as needed
Simply calling it a "political" issue might lead to confusion. I knew the cquery code base quite well last January. I knew its strength and weakness and wanted to make some drastic refactoring, different design choices and breaking changes. It was a tough situation when committers had different opinions. The result was I creatd ccls, gradually rewrote it component by component. I was glad that people turned their attention to ccls. Yes, it caused fragmentation but it was unavoidable and might not be a bad thing. Language Server Protocol decouples client-side and server-side implementations and many language servers emerge. Users choose what they like. https://github.com/MaskRay/ccls/releases summaries many features that are only implemented in ccls. 
Only when you want to forward declare at the same time too. Otherwise you don't need to.
Really depends on the OS. For Windows I can recommend using Visual Studio (possibly with clang) for compiling and debugging, vcpkg as a package manager and ReSharper with clang-today and core guideline checks for linting.
Sorry for not mentioning the OS. I am on a linux machine. Thanks for the answer :-)
What you're on to is that people confuse peak theoretical performance with average performance. By using higher level abstractions, it's often easier to construct a solution that's of acceptable performance, and given that programmer time is a resource, this is often a good trade. But your description of how this affects ranges is off. For starters, doing multiple passes through a data set may be slower, or it may be faster. It depends on things like whether the data fits in cache, and if we're trading one complicated loop for multiple simpler loops. Also, the point of ranges is to evaluate things lazily so I would expect splitting into a range of ranges on spaces would not convert to a bunch strings, but would be an iterator pair. This is one of the things that's easy to get wrong when coding by hand and is a good reason why ranges would be an advantage. 
My set up is: - run linux on a VM - use QTCreator as an IDE - build on the command line with CMake - for networking stuff, getting to grips with ASIO might be useful, but buckle up! 
What should I be using instead? Man msvc makes me sad, I thought I was relying on straightforward standardized behavior :-(.
Thanks, and you are welcome!
At work we use Qt Creator + CMake (with GNU Make generator) + GCC (C++14, -Wall -Wextra -Werror). Also clang-format for automatic code formatting, doxygen for documentation generation, and Google test framework for unit tests (although QTest is good too). We also use Atlassian products for continuous integration, wiki, bug/task tracking, git server, and code review. We tried CLion for a while, but we probably adopted it too early because it had a lot of performance issues for us (I think caused by hosting the source code on an NFS mount).
Try CLion from Jetbrains(extremely powerful and easy for beginners). [It's free if your're a student](https://www.jetbrains.com/education/programs/). Good Luck!!
git, cmake, g++ or clang++ and the editor of your choice (i like atom, others edit just as well). done. Maybe add clang-tidy to check for things in your code you might want to improve. 
CMake A modern (C++14 or 17) compiler (GCC or Clang are pretty even) Visual Studio Code with CMake Tools extension from /u/vector-of-bool Clang Tidy and Clang-format Boost Asio for network programming
I use GNU autotools, g++, and make. I edit in ViM. I'm just old school. :)
Do not have getters and setters for private members. OOP is about encapsulation. Having 'ters for everything breaks encapsulation. Don't use private. Use protected. Child classes are tighter coupled than independent classes. They, by definition, bend the principle of encapsulation. They should has access to all their members.
That's also my setup. For testing I can recommend using [doctest](https://github.com/onqtam/doctest) (previously I have used [Catch](https://github.com/catchorg/Catch2)) or [gtest](https://github.com/google/googletest). Also if possible I develop [with](https://clang.llvm.org/docs/AddressSanitizer.html) [Sanitizers](https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html) enabled (available for both GCC and Clang) to (1) see bugs as early as possible and (2) get detailed information (stacktrace of invalid access and free code, memory addresses, etc.). For package management, I mostly use CMake `add_subdirectory` in combination with Git submodules. This way, you are very flexible to compile with different tool chains, etc. and don't depend on external package managers.
+ [Conan](https://conan.io) for package management 
yes you are absolutely right with the iterator pairs. i was confusing this with a different example i recently came across where it was so that std::strings were created en masse (it was even an example directly from eric niebler). &gt; It depends on things like whether the data fits in cache, and if we're trading one complicated loop for multiple simpler loops. in my example it will be slower.
Seconding Conan. It's great.
No it means that I have a CMake project that creates a number of different targets. For example a JNI library for use by a Java application that is necessarily a shared library and requires shared library dependencies, and also some separate executables for other use cases and different users that are most convenient to statically link and therefore require static versions of dependencies. Take a look at HDF5 1.8 for an example of an open source project doing this kind of thing. There's nothing unusual about this and no reason why it should be difficult. Modern target based CMake supports this perfectly well.
If you are using macOS Xcode is very friendly for a start, works out of box.
I haven't seen Conan before. Is it essentially a package manager like npm, pip, or cargo? Is it gaining popularity/maturity? I've always wondered why C/C++ has such a terrible build/package management story so I'd love if something came along to fix that.
As much as people complain about the committee, I've think they've been pretty open and reasonable with respect to new ideas, as long as others are willing to contribute. &amp;#x200B; Also out of curiosity, is Andrei just funded by the D Language Foundation now?
If you just want VS2017+ support then check `_MSVC_LANG` instead of `__cplusplus`; the same values apply.
To add to this, on Ubuntu 16, it takes some effort to get gcc7 working (which allows most of C++17). If you're ok sticking with C++14, there's no issue, but if OP needs/wants to look into more of the cutting edge, it may be worth it to upgrade to Ubuntu 18 for the simplicity. :-)
It's slower (and way slower in terms of compilation time), but IMO seems more like a proof-of-concept than something you'd use in production.
Conan has been introduced in the outstanding C++ conference, CppCon, from 2016 to 2018. It might be hard to summarise all the benefits into couple of sentences so I will just include the link of those talks [here](https://docs.conan.io/en/latest/videos.html) . Hope you enjoy. &amp;#x200B; For me, the way it handles dependencies is a great relief. It liberates my soul from the dark abyss of add\_subdirectory() and conflicting FLAGS ... &amp;#x200B;
How realistic is it to change if constexpr to not introduce a scope?
Like a macro?
Can you elaborate on the regex pattern you are using? 
Of course: - [pattern](https://github.com/Valloric/ycmd/blob/master/cpp/ycm/IdentifierUtils.cpp#L31-L42) - `regex_search` used like [this](https://github.com/Valloric/ycmd/blob/master/cpp/ycm/IdentifierUtils.cpp#L180-L197). - Input string generated by reading a ctags file [here](https://github.com/Valloric/ycmd/blob/master/cpp/ycm/Utils.cpp#L29-L42). - When generating a file `--fileds=+l` must be passed to `ctags` command to make `ctags` emit `language:FOO` in the output file. &amp;nbsp; - Google benchmark written for benchmarking this is [here](https://github.com/micbou/ycmd/blob/benchmark-extract-identifiers-from-tags-file/cpp/ycm/benchmarks/IdentifierUtils_bench.cpp).
If you contribute to open source you will be forced to use whatever they are using
Thanks for the info!
Sublime Text 3, EasyClangComplete and GCC. I generally set up the project with qmake. Linking is as easy as adding a compile flag in the Makefile.
Thanks!
Knowing that "static if" (the version like D, no scope) was proposed by Alexandrescu first and quickly rejected by a paper from several people including Stroustrup, paper which had a surprisingly negative tone... I would say that it's difficult to change just because of the people's perception of the feature, even before being technically correct. I know some people that are working on papers showing that the main rejection arguments were wrong in retrospect (with examples using \`if constexpr\` that doenst work but should, even in scope) but without a general agreement about what we want C++ to look like, and agreement from the Direction Group, I don't see that change easilly. If people in the Metaprogramming/Reflection group have strong arguments for that change, there might be a reasonable chance to have it someday.
It's not design by committee that is the problem, it's the reluctance to let go of backward compatibility and the crazy religion of "zero cost abstraction" even when this zero cost has a very real cost in terms of productivity.
I've never had a very good experience with xcode, though my experience with it is mostly limited to swift w/ iOS apps. It just consistently seemed slow and buggy, but maybe it was an isolated experience.
Why qmake?
You're starting with an aged OS, iff you cannot be bothered or are to scared to run an up-to-date OS, why do you even want to talk about "modern c++"? Surely that must be scary as well? Maybe those structured bindings don't work, maybe you're the first one to discover this bug. &gt; Since in the c++ world there are lots of option when it comes to tooling I would like to know the community's recommendation on things like build tools, compilers, linters, package managers, testing frameworks, etc. Seriously, one could write an encyclopedia about these subjects. What do you expect to gain from a very broad post on reddit/cpp?
just because you don't use it in a rocket engine does not mean you don't use it in production. 80% of the code is irrelevant performancewise and a lot code hardly ever gets recompiled if you spend a bit of time to properly modularize (meaning paying attention to superfluous includes and maybe using pimpl). when you parse a config file, it does not matter one bit whether you do it in assembly or with ranges. it's just a question in how many places you can allow yourself to pay a performance penalty. Ranges have a pretty good runtime performance, you can pretty much just use them, expect for special sections. now compilation time is another issue, but a lot of software is smaller than 500k LOC. This is also not a problem that compiler writers will not make progress on. Ranges goes beyond proof of concept.
What were the arguments for adding the scope? 
There is a `std::ranges::subrange` library which take a pair of iterator or an iterator and an sentinel to act like a range and the document said it also model the view concept. By using deriving and inheriting constructors, it should eliminate some of the boilerplate code. However, there is no range adaptor object for `subrange`. You can avoid some boilerplate by composing existing views. But at its current state, C++ can't beat the Haskell on the ease of writing the custom views. It should be trivial to write your custom monad if you understand the Type classes and if you can make Monad out of your computations. You don't need to write any bolierplate code. But for C++, even if you understand Concepts and Range library, you still need to write a lot of boilerplate.
https://isocpp.org/blog/2013/03/n3613-static-if-considered Found
Autotools support for modern C++ is barely existent. It can be done with a lot of effort, but it's not pleasant. I switched to CMake 5 years back due to this [I'm the person who wrote the C++11 and C99 support for autoconf].
yip, that's the one
I just have a sense that "static if" is the naive solution that would work but be very hard to understand, where there's likely a more elegant compile-time construct that people haven't come up with yet. Not sure what that would be, but perhaps it could simply be built from "static if" in combination with constexpr. I just think that run-time c++ is moving in a more declarative direction, and maybe compile-time programming will too.
I suggest using as much cross-platform open-source software as possible: - build system generator: CMake - build system: Ninja - compiler: clang++ - IDE: - Visual Studio Code - Qt Creator - static code analyzers: - clang-tidy - Cppcheck - Clazy - source code formatter: clang-format - documentation generator: Doxygen - package manager: - Conan - vcpkg - libraries: - Standard Library - Boost - string formatting: fmt - logging: spdlog - automated tests: Google Test / Google Mock - GUI: Qt If using Windows the latest MSVC compiler is also a good choice (use permissive-). For Linux g++ is an alternative to clang++. Using all three major compilers would be the optimum, imo. Visual Studio Community Edition is also a great IDE and provides another static code analyzer CppCoreCheck. For code coverage one can use OpenCppCheck on Windows and gcov/lcov/gcovr on Linux. If using Linux, LLVM sanitizers (ASan, TSan, UBSan, MSan, LSan) are a bonus, currently not available if using Windows. For CI one can use Jenkins and as a VCS I recommend Git. Now the bad news: It is a pain in the a** to setup all of the above in a generic and cross-platform fashion, since there is no toolbox and/or CMake convention-over-configuration framework that properly includes all of this. And: I recommend reading the following: - A Tour of C++ (2nd Ed) - Clean C++ - C++ Core Guidelines
The feature check macro for string view: https://en.cppreference.com/w/User:D41D8CD98F/feature_testing_macros
I was in situation in 2015 of coming back into C++ after years of being away from it. C++11 interested me to come back and plus I had a project that demanded a systems programming capable language. I went with CLion (which was pretty much brand new at the time), and thus my projects are CMake-based, and I've stuck with gcc/c++ (though one could switch to Clang if preferred). Though CLion has a built-in use of clang-tidy, I also run the stand alone clang-tidy tool as I find it much easier to tweak which inspections are in effect as I'm examining different source files. I've then experimented with using clang-format to get systematic source code formatting into effect. I've liked what I've done with these experiments but I've still not integrated clang-format as part of the CMake project build process. And, alas, I haven't looked into any unit testing solutions for C++...
Letting go of those two... well... you might as well create a new language. Let's call it C+=2. If I remember correctly committee estimates ~5 billion lines of C++. Let's guess 30% is going to migrate to C+=2 soon. What do you get? A community split along the lines of Python 2/3, only much much worse. Python will drop the old version after 10 years, in 2020, which means that the aftermath of the community split will be felt for a few years more. I know some projects that are going to *start* using compatibility libraries only once Python2 reaches end of life. &amp;nbsp; C++ would be in a much worse position in case of C+=2. It is much more widely used and, f you remove macros from C+=2you'd have no way to create compatibility libraries that would check for presense of `__cplusplus` and `__cplusequalstwo`, because there would be no `__cplusequalstwo`. At that point say goodbye to ever unifying what used to be a unified C++ community. ___ In other word, *DON'T* fork C++ at the language level. ___ &gt; What about forking at the library level? Ah, yes, the abandoned idea of STL2. Same story, with a slim chance of maybe one day possibly migrating most of the libraries to STL2.
C++ with all the backwards compatibility removed and cleaned up already exists, it's called D and no one uses it
"another language"
&gt; real cost in terms of productivity if only. buffer overflows have real monetary and possibly life costs. 
That's a good point. `__has_include(&lt;string_view&gt;)` may also be an option.
Thank you for all the hard work you've put into `ccls` :)
That's what C++ would be if you removed backwards compatibility yes
Ah right, especially because the macro is defined by `&lt;string_view&gt;` (or version in C++20)...
Why did you decide to switch from Catch to doctest?
Why limit yourself to running linux in a VM? Are you stuck to using mac or windows as daily driver?
CMake + CLion IDE 
&gt;I've think they've been pretty open and reasonable with respect to new ideas, as long as others are willing to contribute. I don't think anyone would argue that Andrei has contributed a lot to the community without working closely with the committee. He's a consistent source of interesting ideas. I have to agree, for example, with his synopsis of Concepts -- "bo-ring". No offense to the committee, but like Andrei, I've taken a [different approach](https://github.com/Ebenezer-group/onwards) to things. Andrei said, "We want to generate code that matters". That's what I'm trying to do. &amp;#x200B;
I very, very much doubt that the committee will be willing to risk such a major change for C++ 23. Doesn't mean that compilers won't support it though, perhaps even as early as next year.
For four and a half years every month a release with incremental changes and additions. Well done :-)
The main reason I say it's not suitable for production is that it creates a ton of tech debt that'll come due when the source and ABI incompatible standard ranges library drops.
i am sure you are not the only one holding back on using ranges. heck, 50% of c++ probably haven't even heard about it. hopefully the c++ gods will finally be able to curb those horrid error messages with the arrival of templates and somebody will take the time to sprinkle a lot of useful static_assert throughout the ranges code.
Interesting, thanks. Looks like there was a bit of a culture clash over static checking. 
While that may be true in general, I think you over-state the consequences for specific cases. This `if constexpr` case is rather similar to the previous case where `for (int i; ...` changed to make `i` scoped to the `for`. That broke existing code. It was accepted anyway, and the sky didn't fall. C++ didn't fracture. We got away with it partly because at the time, `for (int i; ...` was new syntax. Old code wasn't affected. Newer code that used it was being actively maintained, and so could be fixed. This also applies to `if constexpr`. `if constexpr` is new syntax, not found in old, unmaintained code. Another mitigation is that the fix for `for (int i; ...` was easy enough. The fix for `if constexpr` is even easier - add braces to force a scope. A big mitigation is that where the change in `for (int i; ...` semantics caused a problem, that problem usually caused a compile error. There were theoretical situation where in code like `for (Object obj; ...` the destructor of obj would happen earlier, but they weren't significant in practice. I think the same is true for `if constexpr` \- but oppose it of course. Objects constructed within the `if` will now be destructed later. I doubt it matters in real code. There were also cases where the new rules for `for (int i; ...` would cause code after the loop to use the wrong variable. That was a serious issue, and I don't think anything analogous can happen with `if constexpr`. I believe the biggest reason for the change is that the vast majority of programmers who expressed an opinion believed that the `for (int i; ...` change was for the good. They were willing to accept the pain. The same should be true for `if constexpr`. If it is truly superior, and if it is widely agreed to be superior, then the change can be made.
Naive guess (only halfway through talk), but this sounds like a combo of D's [traits](https://dlang.org/spec/traits.html) - for introspection - and [mixins](https://dlang.org/articles/mixin.html) - for codegen / contracting of sorts. If so, I would be extremely excited for this, but, of course, tentative on what it would cost (as he mentioned in the first half).
I like both but the main difference for me are compilation times. Regarding features, the two both have what I need and Catch noticeably increases the compilation: [benchmark](https://github.com/onqtam/doctest/blob/master/scripts/data/benchmarks/header.png) on doctest GitHub.
I think OPs point was regarding the language, not the content. You set out to make a technical document succintly summarizing a technical subject. Wherein which you made a non-objective remark towards the creators of the very subject that you were discussing. A technical document is not the place to inject subjective topics, let alone attacks to another person
CMake is basically the \_de facto\_ standard, but meson build is also very good, and conan supports it. 
In this case you can make it much quicker if you enable possessive cycles... const char *const TAG_REGEX = "^([^\\t\\n\\r]++)" // The first field is the identifier "\\t" // A TAB char is the field separator // The second field is the path to the file that has the identifier; either // absolute or relative to the tags file. "([^\\t\\n\\r]++)" "\\t.*?" // Non-greedy everything "language:([^\\t\\n\\r]++)" // We want to capture the language of the file ".*?$"; Now the RE doesn't need any backtracking. It will be much quicker in every implementation (CTRE included). The backtracking in CTRE is not really optimized for long input. The benchmark I did was grep-like scenario with lines short around 200 chars.
Compile time programming is already ultra-declarative in C++. Metafunctions are types. The way to do "does this compile" is to declare more functions and types and hope you covered enough cases for SFINAE. The opposite needs to happen, and is happening if you look at the more recent talks about introspection and metaclasses.
Okay, I was definitely talking about the general case, just as /u/dnesteruk said that the problem is clinging to backwards compatibility in general. In my defense, people to tend to talk about a hard fork of the language more often than calculated breaking changes. while I think I already said enough about "forking C++" (in short: don't), let's talk about small calculated breaking changes. `operator&lt;=&gt;` is a breaking change. Here's a simple code that breaks once `operator&lt;=&gt;` becomes a thing: template&lt;auto&gt;class Operator{}; struct Foo { bool operator&lt;=(const Foo&amp;) { return true; } }; Operator&lt;&amp;Foo::operator&lt;=&gt; op{}; Granted, that's terrible code and clang (version 7 at least) warns that: '&lt;=&gt;' is a single token in C++2a; add a space to avoid a change in behavior Was committee aware of this? Yes. Did they find a solution that wouldn't break existing (arguably terrible) code? Yes. Why wasn't it fixed? They thought t wasn't worth having another special case in the required parsing logic. &amp;nbsp; In other words, a tiny breaking change is fine. slightly larger changes, like removal of old and objectively non-ideal STL classes has a much bigger impact. Compilers can warn us, but the solution isn't "just add a space". So these things need (long, possibly very long) deprecation periods. This has also been done in the past. With careful coordination it's feasible. Note that many small breaking changes, even tiny ones shouldn't be done in one go, because that makes switching to the new standard intimidating. The problem isn't the 30% that will dive in and deal with broken code. It's the other, usually corporate part, that's playing safe to the point where banks are still using Windows XP (or RHEL5) to keep your money "safe" - those aren't going to switch to C++2a any time soon. &amp;nbsp; Then there are changes that just won't happen, else we're in the dark ages of Python 2/3 - like banning macros. &amp;nbsp; Possibly there are changes in the grey. "How painful would it be to redefine `unordered_map` to allow more efficient implementations?" That's probably something none of us can answer, though Titus Winters has an idea. I'll get back to that later. &amp;nbsp; Now specifically `if constexpr` vs Andrei's `static if`. `if constexpr` is fairly new, maybe not even the above 30% didn't switch yet. Maybe that gives us some room for a breaking change. Also, there's an obvious fix to get the current behaviour back (that's a weird thing to say) - `if constexpr (some_bool) {{}}`, like Alexandrescu said. First time I used `if constexpr` I was thrown off when it failed to compile, because it introduces scope. So no, I am not categorically against breaking changes. Let's just make sure everyone can migrate easily so we don't fracture the community. I almost hear someone saying: &gt; Easy for you to say! What do you propose? Not me, but Titus Winters, the chair of the tooling study group in the committee. When we talk about breaking changes, we're facing two problems: 1) estimating the risk upfront and 2) making sure people can migrate huge codebases. #### Estimating the risk of a breaking change Currently committee has no way to know how many codebases will be broken due to "operator&lt;=&gt; is a breaking change". Considering Google has specialised tools they use internally to make such queries of their own codebase, committee can make an educated guess. Now let's imagine for a second an open source indexer on par with the Google's internal one. Now everyone can query their codebase and that is left is having a way for everyone to submit their query's result as a statistic, so committee can know instead of make educated guesses. #### Helping people migrate Abseil, on their website, claims they won't ever break API, but in case they do they will create a migration tool (think of python's `2to3`, but imagine if it worked). So after committee got a significant amount of statistics, they (or toolchain vendors) could create a migration tool. This could even greatly raise the "30%" (again, that number is pure guesswork). &amp;nbsp; Unfortunately, according to Titus, if everything goes perfectly according to his vision (not even a plan, just a vision), the first tool could be possible in about 10 years. Take into account that the tool would need a widespread adoption to be useful.
The fact that equifax hasn't paid a cent yet is a proof that this doesnt't actually matter 
I greatly prefer vcpkg, both to use and as a recommendation. It's easier to set up (no concept of remotes, private federation), and supports a much larger selection of libraries out of the box. And what's in the box is well maintained, which is something I absolutely cannot say of Conan's package recipes on bintray/conan-center/wherever...
&gt;what's in the box is well maintained \*cough cough\* 1307 open issues, literally half a person from MS tending to them, and important stuff like OpenCV regularly broken (and still not working properly on Linux). But in general I **do** agree with the vcpkg recommendation ;-) I wish it was getting more maintenance love from MS.
Do you use some kind of api versioning in the library, e.g. via namespaces? wouldn't that help in improving performance without breaking abi for existing users?
I honestly do not care if there is 5 quadragozillion lines of existing C++ because under what I'm proposing, there's only a finite amount of that bad, old, difficult-to-maintain C++ that you can take into C++2 anyway and the whole point is to preserve the good parts of the language and allow people to migrate, with reasonable difficulty, to the new format. For example, suppose all of a sudden `if (x = 5)` causes an error because you killed int-to-bool promotion. Can people go around fixing this in their code? They sure can. We'll force them to do it, and their code will be better for it. Will there be cases when this behavior is leveraged in libraries or in difficult scenarios? Sure, but once we make it break, there will be no choice but to fix it. Macros absolutely, definitely, have to go. They are bad, they impede the adoption of modules (am I the only one who couldn't care less if modules support macros?) and yes, you will need to scrub macros from all the standard libs, so all that `#ifdef` garbage will have to be rewritten using something meaningful. I don't know about you, but exactly 0% of my code are macros, so apart from dependencies (yes, that would be STL2) I'm totally fine with this and many other people will be, too. Macros are cancer. Speaking of STL2, I think its existence ties directly to the breaking of backward compatibility. You cannot expect to design STL2 around the idea of providing `begin()/end()` pairs for things. You basically need to provide the equivalent of C#'s `IEnumerable` with all the associated performance costs related to virtual dispatch, you *probably* want extension methods so that you can enable LINQ-like operator calls on sequences, you have to do a stupid amount of renaming and general reshuffling so that stupid approaches like the erase-remove idiom just go away completely. Properties (a language feature!) should also be on the table because there is no way that `std::string`'s `length()` is a member function and it should not be treated as such, ever. I can continue forever but until there's consensus that the language needs to change, there is no way of making STL2 that's actually easy to use. Now, you talk of the dangers of a split between C++ and C++2, but you know what's worse than that? Zero adoption. Don't know if you noticed but not many entry-level developers go into C++ unless their respective area (e.g., quant finance) is C++ heavy to begin with, and even there, you have alternatives (e.g., Unreal vs Unity). So to keep C++ relevant it has to move with the times, even if this move alienates the user base and causes a schism. From what I know, we already have this schism since modern C does not compile under modern C++ anymore, so there you have it: a chunk of legacy that seems to be existing just fine for its own purpose.
Pretty complete list. But if you are already using Boost, it's worth to note that it comes with a Log library and a Test framework.
D is primarily a garbage collected language. It can run without it, but then you're sorta out there on your own when you do. That axes a significant use case for C++. 
Other than the package manager (which ... long story) this is exactly the suite of tools I use. Theyâ€™re extremely good for a zero budget suite. My only warning would be that Qt Creator is not the most stable beast at the moment, and itâ€™s code completion has been getting worse. Itâ€™ll probably get better again, but itâ€™s the sort of app where you either need to put up with a lot of flakiness or stick to a particular revision thatâ€™s more stable with your code (at least on macOS, which is my main dev platform despite mostly targeting Windows and Linux).
There are many good suggestions here. To those I would add look into using Docker to manage your build and test environments. I use this to keep build environments in version control and enable me to early build and test both linux and windows versions out of the same checkout. 
Qmake become a legacy since qt 6. 
It is one of the best books to start studying programming with. You can check out my solutions for the exercises and theoretical questions here [https://github.com/thelastpolaris/Programming-Principles-and-Practice-Using-C-](https://github.com/thelastpolaris/Programming-Principles-and-Practice-Using-C-)
To the best of my knowledge * modifying `if constexpr` is not possible * adding `static if` would be technically easy - but as others have said, it might be technically difficult. For me the major benefit of `static_if` is that it makes writting platform specific cleaner and more toolable //microsoft.win32.cppm export module microsoft.win32; export { #ifdef _WIN32 # import &lt;windows.h&gt; #endif } - export module cor3ntin.logger; import microsoft.win32; import fmtlib::fmt; void log(const std::string &amp;s) { fmt::print(s); static if(std::meta::has_function&lt; void(char*)&gt; ("OutputDebugStringA")) { OutputDebugStringA(s.c_str()); } }
Andrei's experience with introspection in D is interesting, but in order to get [strong optimization and more portability](https://dlang.org/download.html), you have to use one of the secondary compilers. I think on-line code generators will be more portable than the most portable D options.
Actually this is the latest attempt at improved clang timings, which has also been abandoned with some other guy claiming he will redo it: https://reviews.llvm.org/D47196
Great list, the only things I would add: - catch2 as an alternative to Google test - book: effective modern C++ [Scott Meyers]. This book is amazing!
Can you comment on how this differs in purpose or features vs. clang address sanitizer?
I'm guessing people who haven't watched the talk downvoted this lol, it makes a lot more sense now
As for msvc Eric Brumer stated 1 year ago there would be a whole new time reporting feature: https://developercommunity.visualstudio.com/content/problem/181010/demangle-d2cgsummary-output.html No news since then. Also related: https://developercommunity.visualstudio.com/idea/351601/document-d2cgsummary-and-other-internal-compilatio.html
Conan doesn't have decent recipes for OpenCV at all. The ones that exist either only work on one or some platforms, with one particular version, and are likely not maintained (i.e. outdated versions). I couldn't find a single one that really worked! OK, OpenCV is a terrible library that's relatively awful to build, due to its myriad of dependencies. So, yeah, complex things are complex. But you also don't find recipes for other common libraries "out of the box". In theory, the concept of public package maintenance and everyone being able to set up a "remote" sounds great. But I'd rather have one good, well maintained package recipe for important libraries than 10 half-broken ones from all over GitHub, where I have to search for the most usable one. And yes, vcpkg doesn't get as much maintenance love for its package tree as it should -- that would require a lot more people tending to it, it seems. (I've been waiting for a PR to be merged for over a month.) But it's still much, much better than Conan, from what I perceive. And it has CI over the whole package tree, AFAIK, so inter-dependency incompatibilities should be much more detectable.
So you're saying we should fork the language and leave behind ~50% of the community? Telling half of the community "we don't need you any more, bye" doesn't seem smart at all. Another thing that shows that's not a good idea is the sheer number of languages that were called "C/C++ killers". What currently available language is as portable as C++ while giving you as much control? C and Assembly? Rust? That's not much of a choice. Also none of those languages is planning compile time reflections or static exceptions (well, C might get exceptions that are compatible with C++). &amp;nbsp; Yeah, C++ isn't the first choice of new programmers, but guess what. No language with no garbage collector is going to be the top choice for wider audience of new programmers. Should we turn C++ into a managed untyped language in order to attract more people?
Richard Smith, as cited in [N4461](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4461.html): &gt; The "controversial" parts of N3329 are that: &gt; 1) it does not introduce a new scope, and &gt; 2) the non-selected branch is completely ignored (the tokens aren't even required to be parseable) &gt; This makes it fundamentally incompatible with the template model used by at least two major implementations. &gt; If, instead, it introduced a new scope (as proposed in this thread) and we had a requirement that it is possible to instantiate each arm of the static if (that is, the same requirement we have for other token sequences in templates), then I believe the over-my-dead-body objections from implementors would disappear. Worth keeping in mind. 
I couldn't agree more! And thanks a lot for telling about the status of Conan with respect to OpenCV.
Thanks for looking into that. However, the possessive regex was slower with `++` instead of `+`. With ~25 character the difference was negligible, but with line ove 100 characters long, thte difference became noticeable. Results of running the benchmark: https://gist.github.com/bstaletic/8668526909e277f154e4e91b1a57dee3
Thanks for your question. &amp;#x200B; AddressSanitizer is a fantastic tool, so is Valgrind. It has very high compatibility with existing libraries. Stensal SDK has a completely different design goal. It's designed to achieve memory safety with a very high probability and user friendly error messages. As a result, the big difference is that Stensal SDK can catch all runtime memory errors with a very high probability. However, the most obvious difference to developers is [https://stensal.com/features/#feature\_reporting](https://stensal.com/features/#feature_reporting) &amp;#x200B; Stensal SDK is intended to fortify potentially vulnerable code. &amp;#x200B; I actually have a comparison chart against AddressSanitizer and Valgrind. I can send it to you if you are interested in the details. &amp;#x200B; &amp;#x200B;
MSVC doesn't define those.
I think `++` was a typo for `+?`.
Last time i ran linux natively i had to reinstall everything after upgrading a graphics card. With windows i know everything will work
That doesn't help because users put standard library types in their own types, and they aren't affected by whatever scheme we use. 
*Your* view does. You use inconsistent naming, and nobody has to use *your* implementation, especially when it comes to the standard library. We can't redesign STL and therefore we have to make everything as good as possible at the very beginning, thus the committee decided to use `span` instead of `*_view`, it was done in order to assure that mutable and immutable storages are distinguishable. Furthermore, terseness matters. And also "views" for non-contiguous containers can be replaced with ranges as well.
I'm interested in this but why is such a comparison datasheet not published openly?
Because I haven't polished the UI yet. It should be available in the next website update. In the meantime, I can just send out the raw chart. &amp;#x200B;
This wouldn't be the place even if your question made sense and you spelled all the words correctly.
Interesting format of interview , I had 2 rounds recently with Bloomberg London . My recommendation to people who want to try their luck: You will be solving code challenge over shared code pad in real-time with another Engineer at Bloomberg. You don't have a whole day to do it. The challenges are not hard but you have to think quickly. I failed on the second round of interviews and did not make it final stage e.g. on-site. I have 10+ years in C++/Boost/Linux/Cmake and currently on C++17. Here is my profile if other recruiters want to check me out. https://github.com/venediktov/
I think it boils down to the trade off of being simple and easy-to-use versus being highly configurable. I do have some experience using Vcpkg to setup OpenCV as well. I recalled that some configurations would cause the building process to fail and then we have to search for the â€œthe right combination â€œ of the toolsets as a workaround. Perhaps OpenCV is so complex that requires a lot of care to be built properly.
How long ago was that? Linux these days have good support for GPUs. I think you should give linux another try :)
You may try ccls. It can be used with any editor with a language client plugin. &gt; that generates cmake files and updates them as the project grows Read https://github.com/MaskRay/ccls/wiki/Project-Setup You may send `workspace/didChangeConfiguration` (with your language client) when `compile_commands.json` changes.
&gt; Your view does. Yes, that is exactly what I said. "*My array_view does...*" Interestingly, I said it that way to distinguish its behavior from what the standard library does. Evidently, I failed. &gt; You use inconsistent naming Where? I fail to see how the naming is inconsistent. The `stream_view` is a little weird, but that's because it's a view of compressed data and is part of the compression runtime. It can also act as an `array_view` via magic. &gt; and nobody has to use your implementation Says you. Clearly, you were unaware that you were breaking *the law*. &gt; We can't redesign STL and therefore we have to make everything as good as possible at the very beginning, thus the committee decided to use span instead of *_view, it was done in order to assure that mutable and immutable storages are distinguishable. So, will we later have `view` for mutable array views, and `string_span` for immutable string views? Otherwise, it's somewhat disjoint. &gt; it was done in order to assure that mutable and immutable storages are distinguishable. `array_view&lt;char&gt;` and `array_view&lt;const char&gt;` are not distinguishable? &gt; Furthermore, terseness matters. The length-difference between `array_view` and `span` is negligible (6 characters). You can pass them around as `view`, even, if you want to lose the guaranteed array-access semantics. &gt; And also "views" for non-contiguous containers can be replaced with ranges as well. Which is substantially more complicated than `views` that represent the underlying storage mechanism in some fashion.
The more elegant we make that, the slower things will be to compile and the harder it will be to understand. A brute-force, simple `static if` would be fast *and* simple.
I wouldn't mind having an optional GC equivalent to C++/CX's `T^` handles. Would be a good, terse alternative to `shared_ptr`/`weak_ptr`.
I'm all for having that, but I can imagine that beyond a certain level of complexity, "static if" could get hard to understand. I'm imagining deep hierarchies of conditional code. Not introducing a scope doesn't change the fact that the possibilities increase at each condition. Perhaps there shouldn't be so much going on at compile time, but having the option to do so can lead to amazing results in some cases. I do think we might need to improve errors/debugging during compile time to get very far though.
I took a quick look of sourcekit-lsp. I believe it is a wrapper speaking LSP. For textDocument/completion, it forwards requests to https://github.com/apple/swift/blob/master/tools/SourceKit/lib/SwiftLang/SwiftCompletion.cpp#L201 For textDocument/{definition,references}, it (sourcekit-lsp/blob/master/Sources/SourceKit/SourceKitServer.swift#L391) leverages functions in https://github.com/apple/indexstore-db lib/Index/SymbolIndex.cpp swift-clang libIndexStore requires a tight integration with the build system: index is stored as a byproduct while building the project. For C/C++ programmers, it does not bring more features to the table (over clangd, the underlying C/C++ language server it talks to), but it may merge results from the two backends (sourcekit and clangd). Swift can call C functions, so it may merge textDocument/references results.
&gt; But I'd rather have one good, well maintained package recipe for important libraries than 10 half-broken ones from all over GitHub That's what conan-center is for. Remember, Conan is still pretty new. I've yet to run into a package on conan-center that didn't work flawlessly. If a package doesn't exist, make one and contribute it to bincrafters. If a package doesn't work correctly, provide a fix. I haven't used OpenCV, but there's a 4.0.0 package in conan-center. Have you tried it?
VS 2017 is available on mac.
Qt 6 will not be out before 2020.
Here for an opinionated setup. C++ with emacs + prelude works pretty well. Learn projectile and the thypical shortcuts. Install cquery + lsp-mode and activate it. Create a top-level compile-commands.json to your compile-commands.json for cquery to index your code. As for the build system I highly recommend Meson above everything else unless you need XCode support. I think but did not check that Visual Studio support is more than decent in Meson as well. Meson saved me a TON of time compared to CMake when things get a bit more tricky. For other IDEs, anything that supports compile-commands.json should work. CLion for example can use it. 
Well. You will have it with concepts. That should improve things. I think it is a good thing that we do not meed to spend 1 hour for what we can do in 5 minutes witha good library. And if that is not enough, profile and do well-thought fixes. I am sure you can get 95% of the optimal performance like that.
You could use: Pistache (http://pistache.io) as a Rest framework. JSON for Modern C++ (https://github.com/nlohmann/json) to parse/serialize to JSON.
Then use it. There are libraries that implement GC for C++.
I'm using [libmicrohttpd](https://www.gnu.org/software/libmicrohttpd/) for a project right now. It's straight C, but it's easy to wrap. Works great. For json, I've had performance issues with nlohmann-json. I prefer [RapidJSON](https://github.com/Tencent/rapidjson). Funky interface, but again, easy to wrap, and _much_ better performance.
should stental detect use-after-free stack usage in this test case [https://stensal.com/a/428bkcQPTaLbOfSO](https://stensal.com/a/428bkcQPTaLbOfSO) &amp;#x200B; and you also need to incorporate MemorySanitizer results on your testscases ASAN does not handle every memory problem &amp;#x200B;
very interesting thanks.
Thanks for looking into that! What your analysis tells me is that for C++ it offers nothing new (it's even behind ccls), but has potential for swift. That doesn't sound bad.
What do you mean by implicit conversions of a returned type to void? Is `[]() { return false; }` really convertible to a `std::function&lt;void()&gt;`?? That doesnâ€™t seem right to me, since implicit conversion to void isnâ€™t a thing as far as Iâ€™m aware.
If you want to be like Google, use Protobuf and gRPC when communicating between services. Not sure what is used for regular clients though.
I haven't used it, yet, but I've been curious about [CppCMS](http://cppcms.com/wikipp/en/page/main).
Really? If I was trying to understand programming expertise 8 wouldnâ€™t doc points for knowing how `fopen` works under the hood, as itâ€™s platform specific, and the whole point of it is to fufill itâ€™s contract while the caller doesnâ€™t have to know any implementation details. You could be an absolute expert in the nuances of C++ and (rightfully) have spent no time understanding the implementation of fopen. In fact, Iâ€™d argue that platform specific libraries like std::filesystem are the least interesting to ask about the internals of if you want to understand someoneâ€™s grasp and curiosity around the language. std::optional or std::variant for example, are super interesting from a language perspective, as they run up against all the thing C++ is good at / not good at from a memory / type system perspective, what tradeoffs can be made, etc.
These sound very much like OS / C related qurstions, not C++ expertise related questions. If youâ€™d ask, what happens when you call `new` you can get into placement new, SBO, heap / stack allocatoon, overloads, etc, but `malloc` isnâ€™t asking about anything C++ specific.
I'm currently building a web server using [Boost's Beast](https://github.com/boostorg/beast). It's verbose but probably the most mature if you want to use WebSockets and Boost.Asio. I recommend watching the author's talk at CppCon this last year: https://www.youtube.com/watch?v=7FQwAjELMek I also considered using [Restinio](https://github.com/Stiffstream/restinio) and [Proxygen](https://github.com/facebook/proxygen). 
Thanks for providing this very interesting testcase. I added some printf stmts to print out the address of c.\_b, and the high and low addresses of the current call stack, so we can see what really happen. This is the new code snippet: [https://stensal.com/a/JhMQljem7BywqnHh](https://stensal.com/a/JhMQljem7BywqnHh) &amp;#x200B; As you can see the address of c.\_b is between the high and low, so theoretically speaking its storage is still valid. As a result, the use of c.\_b is not detected. \~B() does not really free the storage, it's a function called before its memory is freed. However the free does not have to be happened immediately. As a matter of fact, the storage of c.\_b is freed only if the enclosing function returns. This is really a tricky situation. If this code causes some troubles to you, it's possible to make this detection happens by treating destructor as free. I don't know what side effects this will cause. &amp;#x200B; I didn't compare with MemorySanitizer yet. Thanks for pointing it out. What memory problems MemorySanitizer can detect? &amp;#x200B;
#4 is my favorite, I feel like itâ€™s * very optionated (good, prompts discussion) * brings up how much they value tradeoffs between debuggability, performance, etc (possibly leading into war stories) * gets into boundaries of language expertise (performance, compatiblity with other languages, optimizations, how other languages handle it, etc)
Curious what the motivation of these questions are. 1. I don't hate javascript and I actually really like typescript. 2. No. 3. I work on designing high performance ML hardware. When you need fine grain control over the hardware, C++ is much easier to use than C# or Java. 4. Modern C++ is great. I find many of the new features to be useful and use the STL all the time (along with Eigen, Boost, etc).
This video is the eye-opening one. Two well-known persons in C++ community are discussing about pain points of C++ initialization and how to teach it. The main paint point is the initializer_list constructor which takes precedence over other constructors if provided types of arguments match. This has been a source of confusion since it has been introduced in C++11. For this reason many codebases ban initializer_lists or {} initialization syntax altogether and that is a shame because the new syntax was supposed to unify and replace all other existing syntaxes. Interestingly Nicolas as a committee member fails to see the issue here. He arguments confusing constructors are a historical problem of std::vector only. Well if std::vector - the most used container in standard library becomes confusing to construct that I think should be enough reasons to rethink the initializer_list feature when it was proposed. But as JK mentions it is not only problem of std::vector. Any class with existing constructors to which you add initializer_list constructor becomes potentially confusing to initialize because of initializer_list precedence rules. At the end more initialization issues and inconsistencies are mentioned like auto {} syntax where committee chose different meaning for auto x{5} and auto x={5}, template constructor which takes precedence over copy constructor. Other existing gotchas like double brace syntax for std::array, possible aggregate initialization of an object with deleted constructor etc. were not even mentioned. I can't help but the video leaves a sour taste about the current development of C++ language. Sure we get some very interesting features and libraries but the complexity of the language is quickly increasing for no good reasons. Interaction of some features was probably not thought out very well. Initialization syntax is a prime example of that. At the same time the C++ is known for its strong focus on backwards compatibility so that fixing any of the mistakes from the past is almost impossible.
Those are all good answers!
 I love asio/beast. Saying this as someone who hasn't had much network programming experience. I use beast along with nlohmann json for my game server side project.
Donâ€™t template template parameters satisfy this to an extent? template &lt; typename T, template &lt;typename&gt; typename Cs... &gt; concept AllOf = (Cs&lt;T&gt; &amp;&amp; ...);
\&gt;If this code causes some troubles to you, it's possible to make this detection happens by treating destructor as &gt;free. But I don't know what side effects this will cause. Perhaps, we will get some false positives. i tooked me hours(days) to find this type of bug in a customers codebase, it was just a matter of luck that one of my tests where able to let this explode very hard &amp;#x200B; i think the ASAN or MSAN is able to detect this, wrote this bug report years ago, but did't recheck maybe as default or a additional activateable asan-feature see: [https://github.com/google/sanitizers/wiki/AddressSanitizerFlags](https://github.com/google/sanitizers/wiki/AddressSanitizerFlags) use ASAN_OPTIONS=help=1 ./a.out to get all asan options, i would also dig through the asan bug reports lists to find other cases use very lastest gcc/clang if do comparison - ubuntu 18.10 comes with gcc 8.2 and clang 7.x i think &amp;#x200B; \&gt;I haven't compared with MemorySanitizer yet. Thanks for pointing it out. What memory problems &gt;MemorySanitizer can detect? uninitalized memory access and some others - but all linked libs need to be instrumented &amp;#x200B;
Do you have the sanitizers enabled in your production builds? If yes, how is performance affected? 
That's not visual studio proper, that's a rebranded monodevelop 
Tons of loaded questions- which probably explains most of the downvotes. Otherwise an interesting topic imo 1) No, C++ has, historically, had issues with frontend development. The biggest drawback of C++ UI is lack of [WYSIWYG](https://en.wikipedia.org/wiki/WYSIWYG) and hot-loading compatibility, followed by complexity and prototypability. Pairing it with HTML/CSS would help, but not much- esp in SPAs. 2) No. They're different tools for different purposes and carry their own knowledge sets. Any given C++ dev has the potential to be as talented as any JS dev- driven only by their passion for programming. 3) UI / Generalist Programmer for Games, and yes it's used in financial, robotics, application backends, high-performance server architectures, etc... All of our server code is C++ (and I'm jealous because they can update their language support whenever ;_;) 4) I love the emphasis on safer memory access patterns, constexpr support, copy elision and move semantics, etc.. The STL is fine in my opinion- many newer features can be debated, and I do feel like the committee is out of touch with their user groups, have allowed too many issues to fester (exceptions), and that their methods of community interactions are a bottleneck, but honestly most of the STL we don't need in games. We can just do the same as always and stick to a specific subset of it; not all of the STL has to apply to us. That said, elevating the importance of other issues would be wonderful: prioritizing modules, tooling (mostly in debugging), build performance, auto-casting, strong typing, compiler language support adoption, runtime enum names, etc... Things that everyone could benefit from
For some reason the idea of "C++ backend" reminds me of this: https://i.imgur.com/INBvStO_d.jpg?maxwidth=640&amp;shape=thumb&amp;fidelity=medium
lol thats good
Very appreciate your advice and testing it out. I will add MemerySanitizer to the comparison. Yes, I use the latest clang 7.x, I might just skip gcc 8.2 as its detection mechanism is the same. &amp;#x200B; &amp;#x200B;
using cpp as a backend to do some cpu Intensive tasks is a common choice.
clang could be enough, but don't forget all the ASAN extensions in the stdlib/stlibc++ &amp;#x200B; for example - detection of c++ container missuse: &amp;#x200B; #include &lt;vector&gt; #include &lt;assert.h&gt; typedef long T; int main() { std::vector&lt;T&gt; v; v.push_back(0); v.push_back(1); v.push_back(2); assert(v.capacity() &gt;= 4); assert(v.size() == 3); T *p = &amp;v[0]; // Here the memory is accessed inside a heap-allocated buffer // but outside of the region `[v.begin(), v.end())`. return p[3]; // OOPS. // v[3] could be detected by simple checks in std::vector. // *(v.begin()+3) could be detected by a mighty debug iterator // (&amp;v[0])[3] can only be detected with AddressSanitizer or similar. } &amp;#x200B;
Im using poco net but not happy at all, a lot of boilerplate code needed and you have to parse url strings to build a rest service... Furthermore is pretty opiniated, installs signal handlers for you, does forking etc... a lot behind the scenes witha java like pattern Something simple like expressjs would be great in c++
have a look at [doctest](https://github.com/onqtam/doctest) if looking for a faster alternative to catch.
Perhaps this is detected as using uninitialized value by MemorySanitizer? It would be strange to me if ASAN can detect this. Perhaps, ASAN has some mode that I'm not aware of. &amp;#x200B; In general, I fine tune my detection to avoid false positives. This bug can be detected too if it's required by customers. Stensal SDK should have very low false positive rate. Another valuable comparison is to compare the false positive rate, but this is hard as I don't have many test cases. &amp;#x200B;
&gt;Perhaps this is detected as using uninitialized value by MemorySanitizer? i think the stdlibc++ is using __asan_poison_memory_region in its implementation read "could" be detected by msan - but only on first access
&gt; I don't have many test cases. maybe some of these are useable [https://github.com/llvm-mirror/compiler-rt/tree/master/test/asan/TestCases](https://github.com/llvm-mirror/compiler-rt/tree/master/test/asan/TestCases) &amp;#x200B;
Used [crow](https://github.com/ipkn/crow) header only c++11 to build micro services, works fast and has built in REST and json support 
No, for production builds the performance penalty is too high. For our application it's approximately a 2x slowdown with address sanitizer and approximately a 4x slowdown with the address and UB sanitizer enabled. Though we do all CI tests (unit tests, integration tests, tests with real datasets, etc.) with (and of course also without) sanitizers, Valgrind and MSVC debug mode. I think most applications written in C++ need every bit of performance offered by the language and therefore don't want to take a hit on performance at runtime.
Got it the poison memory region trick can be utilized by my detection too. It's too late here. I will catch up tomorrow. Thanks a lot for your help. 
Ok, just what I assumed. I was thinking building our application with Clang and sanitizers enabled on the build server and then run all tests again. Our regular build is GCC, because of defined tool environment. Clang build is done just for catching different warnings.
Sanitizers are available for GCC builds, too. :-) But as you say, building with different compilers always makes sense!
So, this generate the file (cmake) aimed at generating the file (make) aimed at compiling the project. That is some high level abstraction stuff here !
This is just the beginning, we can go deeper.
... why?
For smaller prototypes I use https://github.com/yhirose/cpp-httplib together with https://caddyserver.com, since itâ€™s easy to get going.
Same; running multiple servers on Beast and they're doing fine. Scalability issues stem only from databases that have not yet invented doing more than one thing at a time on a connection.
The Facebook thing for this I believe is called "folly". Not used it but look at AsyncServerSocket.h as a start. 
Considering what Oracle is now doing licensing wise to major enterprises with Java, it could be a common choice for other spaces as well.
I don't know why this is being downvoted, crow is excellent.
We need modern cmake generator from old cmake.
&gt; It's verbose &gt; &gt; talk at CppCon this last year Just for comparison of verbosity of Beast with more high-level and user-friendly tool: [an reimplementation of Vinnie Falco's example from CppCon-2018](https://bitbucket.org/sobjectizerteam/beast-cppcon2018-vs-restinio).
&gt;crow is excellent Yes, but it seems that the project is abandoned. The last commit was year ago :(
Someone's a fan of cargo I see. I can definitely see the use for something like this to quickly generate a starting off point sort of like a cookie cutter project Your Readme mentions you auto download dependencies but doesn't have any details about from where and where it puts them. Might be worth adding in there
 dependency auto installer uses cppkg. cppkg uses https://github.com/injae/cppkg as its default repository If you put a repo defined by cppkg in the $ HOME / .cppm / repo directory, it searches automatically. You can add it to your local repo locally by using the cppm cppkg init command. A detailed description can be found under readme. 
Not saying this is perfect, but: https://wandbox.org/permlink/obyZyoqWqR98V5tt
&gt;Interestingly Nicolas as a committee member fails to see the issue here. Interesting. IMHO Nicolai got it perfectly right and Jon's ranting stampede went way overboard. The 'legacy' constructors are the actual problem here. Why should `std::vector v(3,3)` result in 3 elements of value `3` while `std::vector v{3,3}` results in 2 elements? The latter is totally intuitive and the result is obvious whereas the former one is quite the opposite. And why should `std::vector v{3,3}` carry on doing the same nonsense as `std::vector v(3,3)` did? Strong types to the rescue and down with this unintuitive semantic overloading of fundamental types.
Sounds like we're now in agreement. The only thing I'd add is that in this case, it would be feasible to leave `if constexpr` as it is and add some new syntax. Possibly `static if` literally, but given some of the objections to that spelling maybe `if static`, or `static_if` or even `if constexpr2`. I'm guessing most people would rather `if constexpr` were fixed than having two ways of doing the same thing. I think the real problem in this case is that the semantics of `static if` are still controversial. Not everyone agrees with this talk. 
How deep can this baby go?
I think there is an unreasonable expectation towards open source maintainers to keep the project "active" (meaning that you would have to have a commit at least 2-3 months ago at any given time). Large projects can easily pull this off; one-man shows, after the initial bulk of work is done, can't.
I've updated my post. Thanks to commentors!
Problem is then using it in a project becomes hard to justify, run into a bug? Time to become a domain expert.
Booting into the previous kernel would have solved the problem.
Try [RESTinio](https://github.com/Stiffstream/restinio) for implementing HTTP server. See sample projects using RESTinio: [shrimp-demo](https://github.com/Stiffstream/shrimp-demo) or [beast-cppcon2018-vs-restinio](https://bitbucket.org/sobjectizerteam/beast-cppcon2018-vs-restinio). IMHO JSON support is better to be considered as a separate concern. You can use about a hundred of ready to go libs (a kinf of mainstream libs: [RapidJSON](https://github.com/Tencent/rapidjson) or [nlohmann/json](https://github.com/nlohmann/json)). Here I can suggest a handy lib for converting json to data structs and back: [json_dto](https://github.com/Stiffstream/json_dto).
Even swift support is still abysmal on xcode, and practically non-existent outside of Apple devices. 
Company: MayStreetâ€‹ Type: Full time Description: Weâ€™re a financial technology firm that builds next-gen capital markets software for market makers, hedge funds, top tier banks and asset managers. Our software empowers these firms to thrive in the incredibly fast-paced environment of today's highly-distributed, highly-regulated, highly volatile global capital markets. Developers will be further developing MayStreet's global capital markets data platform. We primarily use modern C++ with an emphasis on performance, code quality and scalabilty. Location: New York, NYâ€‹ Remote: No Visa Sponsorship: Yes â€‹ Technologies: C/C++( C++98/03, C++11, C++14, C++17 ), Linux, gcc, library design. TCP/IP, multicast, multi threading and distributed system design. Python knowledge is useful. Contact: Apply at [http://jobs.maystreet.com/apply/Vj5fB0/C-Software-Engineer-Working-With-Capital-Markets-Data](http://jobs.maystreet.com/apply/Vj5fB0/C-Software-Engineer-Working-With-Capital-Markets-Data)
Proxygen is an amazing library from Facebook, for http / web stuff. I presume Google has a similar library internally. C++ based web servers can be (tuned to be) insanely performant! 
So? Naturally Apple only cares about developers on their platforms. Why would Swift be any different than Objective-C on non-Apple platforms? Even GCC only supports it due to licensing issues with the original implementation.
I'm not sure having two separate things to do related stuff is a good direction, I think I'd prefer a breaking change here but I'm not sure. Maybe a new syntax wouldn't be bad if it were verbose enough to make the distinction clear? Something like `if constexpr_noscope`. The argument against not parsing the not taken branch at all makes sense to me. It is one step away from making `static if` equivaleent to macros. I don't see an appeal in fighting macros so hard only to replace them with something that doesn't really differ that much.
I'd be curious if a functional alternative has been considered, e.g. permit "late assignment" to an alias, like you'd do with a nominal `if` statement who wants to mutate local state outside of its immediate scope: ``` using CellIdx = auto; // Define scope for alias, but make it unusable at first. if constexpr (maxLength &lt; 0xFFFE) { typename CellIdx = uint16_t; // Or whatevs syntax } else { typename CellIdx = uint32_t; } ``` Will peruse isocpp links to see if they did...
Second this. Hard to imagine setting up an HTTP server in C++ being much easier than with httplib.
And here I thought that everyone was using Java EE. I understand that C++ might have a slight performance advantage (perhaps not if taking scale-ability, clustering etc into account?) but what other advantages do the choice of C++ on the backend give you?
POCO is great for this 
Devs less likely to learn a language only useful for a single platform, less likely to contribute to the technology, less likely to buy into that technology...etc. It also says a lot when the lead dev of llvm, clang and swift, canâ€™t port his language nor support it on windows, while others using his technology are able to create cross-platform languages! I know the reasons why swift canâ€™t be easily ported, but I donâ€™t believe thatâ€™s an acceptable excuse. Itâ€™s only a form of vendor lock-in. Sorry for the rant!
Devs less likely to learn a language only useful for a single platform, less likely to contribute to the technology, less likely to buy into that technology...etc. It also says a lot when the lead dev of llvm, clang and swift, canâ€™t port his language nor support it on windows, while others using his technology are able to create cross-platform languages! I know the reasons why swift canâ€™t be easily ported, but I donâ€™t believe thatâ€™s an acceptable excuse. Itâ€™s only a form of vendor lock-in. Sorry for the rant!
&gt; C++ would be in a much worse position in case of C+=2. I agree, but not because of the reasons you stated. If C+=2 came with a compiler and a transpiler for C++ to C+=2, the preprocessor issue wouldn't be a problem. C++ libraries could still make use of the preprocessor and have conditional `__cplusequalstwo` glue, but C+=2 would be unaware of the preprocessor, since there would be a transpiling prebuild step before C+=2 would even see the source. But C++ would then be in a very awkward state, where library writers would basically write code for 2 or maybe even 3 languages at once (C/C++/C+=2 libraries).
We currently use GTest and GMock, and it's become apparent with time that `EXPECT_CALL` is actually much more difficult to use that necessary. Rigorous use of `EXPECT_CALL` requires pairing it with `VerifyAndClear`, lest the call is fulfilled by a later interaction with the mock: EXPECT_CALL(mock, foo(_)); dosomething(); // nothing happens // &lt;-- Introduce VerifyAndClear call here. dosomethingelse(); // calls mock.foo(_) It's error prone, and also not so practical as it clears *everything*. I haven't found a way to assert that *just* a particular method had been called. --- A colleague has been looking in [`FakeIt`](https://github.com/eranpeer/FakeIt), which seems to solve this issue, and even seems to dispense altogether with pre-declaring mocks. I have yet to check out exactly its limitations... and the magic behind. Did you hear about it? Any feedback?
Christian Laettner is not the lead dev of llvm, clang and swift. Once upon a time, yes he created the projects and drove them while at Apple. Now there others calling the shots.
This is more from a learning/curiosity point of view rather than real world application.
What kind of game server? What kinds of information does the server process? How many concurrent connections and what amount of data is being transferred and processed on avg?
I am pretty excited for his follow-up post, would love to know where my compile time is spent.
This also works: target_link_libraries(target PUBLIC SDL2 SDL2main SDL2_image SDL2_gfx )
&gt;Discussions, articles, and news about the C++ programming language or programming in C++. For C++ questions, answers, help, and advice see r/cpp_questions or StackOverflow.
The comparison table is added to the website. Any feedback would be appreciated. 
I have updated the website with the comparison with ASAN and Valgrind. 
ninja is a standalone binary, which you compile if you want. Just drop it in your PATH or call it directly from wherever you want to keep it. It's all on their website and documentation. 
Several years ago I used [davidmoreno/onion](https://github.com/davidmoreno/onion) as a backend. Haven't tried any other libraries or **frameworks** yet but I think Onion's simple enough.
That is assuming we'd be able write a working transpiler. Python couldn't pull that off. As for writing libraries for both languages (C++ and C+=2, C is already a different beast), I wouldn't be surprised if the majority (especially people who would keep working with C++) would just say "it's too much work to support the other thing, so fuck it".
A shitty game server that doesn't even have a proper client or any user. We are doing it for learning mostly(or simply killing time and having fun). Clients are in javascript, talk via ssl'd websocket in json. We have a simple codegen script for generating structs and serialization code. Database is postgres and we use this asio based client lib https://github.com/yandex/ozo From our preliminary tests, it handles few thousand requests on a single thread without breaking a sweat. Our intended number of user/player is at most 1000. So we are pretty satisfied. Response latency is mostly bottle-necked by db access.
If your project involves a large chunk of C++ running on the server and/or shared with the client, it makes sense to not involve another language when all you need to do is open a socket and handle some HTTP. That case aside, I can't see C++ making much sense for most commercial Web projects, since support for it in the webdev world is scarce. The only time the performance advantages would matter are if you already have millions of users, otherwise you might as well just go with the Java/Python/JS flow.
I think that is overvalued (or people are carelessly racking up technical debt by not properly evaluating libraries). There is no correlation between activity and number of bugs (note, I'm not saying maturity). A big name library can have terrible bugs and you might have to fix it yourself even if the project is active (maybe the authors have other priorities or simply aren't interested in fixing that one issue for you).
Why is this guy so screamy? Itâ€™s super off putting. Sounds almost like Hitler giving one of his rally speeches.
check this [Swoole](https://www.swoole.co.uk/)
because if you want to be cross-platform then you have to generate *at least* makefiles and visual studio solution files ; it's much easier to target the declarative subset of cmake which will then happily generate makefiles / vcxprojs / ninja / xcode / whatever. I've contributed to a project which generated vcxprojs through Ruby scripts, ... welll ... https://github.com/jamoma/JamomaCore/blob/359fe7ddd20d75c3194ed94c1ca1201325b545b8/Shared/jamomalib.rb
Popular languages in the backend are often weakly typed, like PHP, Python or node. In my experience, strongly typed languages like C++, C# or Java scale much better and are usually a better alternative for anything but very small projects. YMMV. After that, it's a matter of preference. I dislike Java and I'm more proficient in C++ than C#, so that's what I tend to chose. As for "support for it in the webdev world is scarce", I'm not sure what that means. There's plenty of libraries available for backends (as you can see in this thread). C++ is not always just about performance, it's a valid choice on its own.
This is insane. C++ has a million ways to do even the most basic stuff lmao. People should just let this language die. Just waiting for Jai to be released and gamedev can say bye bye to this mess 
Interesting. This really sounds like something I was interested in doing. I have zero DB experience but there's some info I've been wanting to know. Mind if I come back later with some questions? I'm busy now :D
Still don't see why you need this, but ok.
Can anybody explain how this works? `int i = (7, 9)` &amp;#x200B;
Just might know the comma operator from a for loop with multiple initialized or incremented variables. You can chain statements with comma and the value of the last statement is returned. 
Yea, maybe in next 30 years 'cause c++ is well rooted into the industry and Jai is not even finished, no need to say how much time it would take to accomodate it
&gt; integer to sting conversion call the police
&gt; over-my-dead-body objections from implementors Any idea who these implementors are? &amp;#x200B; ie. Who they are / which compilers they represent give us a sense of how likely it is that if constexpr will be fixed.
Evaluates 7 as 7, 9 as 9, and (7, 9) as 9: #include &lt;stdio.h&gt; int getLast() { printf("2"); return 3; } int main() { printf("%i\n", (printf("0"), printf("1"), getLast())); } 
The language will die naturally if there is no longer a need for it :)
This isn't exactly how the comma operator works, but if you are familiar with operator overloading here is what an implementation might look like: int&amp; operator, (int&amp; left, int&amp; right) { return right; } All the , operator does it evaluate all the expressions and right the rightmost results.
Unless some big studio picks it up, Jai will be yet another language that nobody uses.
Ranges are just syntax sugar Fucking waste of time 
That last one isn't a comma operator. All 4 expressions are passed to the outter `printf` as `VA_ARG` array.
For those you want to look more closely at the checkedint example... &amp;#x200B; [https://dlang.org/phobos/std\_experimental\_checkedint.html](https://dlang.org/phobos/std_experimental_checkedint.html) &amp;#x200B; That has the documentation with a link to the source buried in it... [https://github.com/dlang/phobos/blob/master/std/experimental/checkedint.d](https://github.com/dlang/phobos/blob/master/std/experimental/checkedint.d) &amp;#x200B; The main surprise point for C++ programmers is foo&lt;bah&gt; in C++ is foo!bah in d
&gt;Boost.Log Great summarisation. &amp;#x200B; Besides, I am a bit curious about your opinion on Boost.Log and Boost.Test. How do they compare with those counterparts in your list? &amp;#x200B;
Ooooer.... &amp;#x200B; \&gt; The static if feature recently proposed for C++ \[1, 2\] is fundamentally flawed, and its adoption would be a disaster for the language. The feature provides a single syntax with three distinct semantics, depending on the context of use. The primary mechanism of these semantics is to avoid parsing in branches not taken. This will make programs harder to read, understand, maintain, and debug. It would also impede and possibly prevent the future development of other language features, such as concepts. Furthermore, the adoption of this feature would seriously compromise our ability to produce AST- based tools for C++, and therefore put C++ at a further disadvantage compared to other modern languages vis a vis tool support. &amp;#x200B; Ok. &amp;#x200B; I guess that answers that then. &amp;#x200B; Unless the author's... Bjarne Stroustrup, Gabriel Dos Reis, and Andrew Sutton eat a serious amount of crow... "static if" isn't going to happen in C++ in my life time. &amp;#x200B; Sigh. &amp;#x200B; I use to be on the side "we need an API that understands the AST". &amp;#x200B; Then some of the tools like gcc-xml and clang came out with an inkling of what would be required...... &amp;#x200B; ....now I really do see what Andrei is saying. &amp;#x200B; We're all already experts in our language of choice. &amp;#x200B; Having an API on the AST will require us to become experts in a particularly cumbersome parallel language.... to extract information we don't particularly care about. &amp;#x200B; It's info like "will this compile?" , "does T have this feature?", "What is the state\_size of T?".... that we care about. Not for instance the AST representation of say a switch statement.
Boehm and such aren't real equivalents to an optional manage backend. They are intrinsically leaky, slower than a true managed backend, and Boehm replaces malloc and free, making it non-trivial to have managed and non-managed types.
I agree with you about weak typing, and I'm not personally against using C++ for anything, web dev included, because it's a language I'm quite comfortable with (although I'm pretty proficient with lots of other languages too). However, my experience is that most beginner/intermediate web devs are *not* comfortable with C++, and when I was looking for work, I came across a deluge of Python/Django, Java, .NET, and JS/Node web dev openings and zero for running C++ on anything besides workstations, game consoles, and embedded stuff. In most commercial environments advocating C++ for web dev seems to me like it would get raised eyebrows at best (and knee-jerk condemnation at worst), but I would love to be wrong.
You are correct that C++ isn't a popular language in the backend. It's getting even worse nowadays because frontend programmers who know nothing else than JavaScript are getting into the backend, and instead of learning a new language, they try to reuse their JavaScript skills. That gave us the catastrophe that is Node.js. There's not much we can do about it, except educating other programmers and managers so they understand that there's more to life than a WAMP stack.
Precisely. D is another - arguably better than C++, but the tooling isn't there and the compiler isn't mature. It probably never will be.
Why don't you look up the official website?
Watched this with coworkers at lunch. This guy is awesome!
The last time a language was going to be released and supplant the industry standard, it was 40 years ago and it was C++.
I don't think they are?
I keep wanting to use kdevelop more but I keep getting lazy and never learn the shortcuts. Itâ€™s always my go to with a big project. 
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
You sure about that? 
Including expats in Poland?
Sneak peek: http://lists.llvm.org/pipermail/cfe-dev/2019-January/060836.html
Jai is not the only candidate to replace C++, and I seriously doubt that it will turn out any better or more popular than any of the other languages which have attempted to completely replace C++.
I'm not holding my breath.
Oh, I didn't notice the `()` parenthesis around *all three* function calls. I read it as `(printf("0"))`. My bad.
OpenCV is a fricking nightmare. It doesn't even need to be, it's just so badly engineered, and it's trying to support and supply everything under the kitchen sink. And no one has looked at their CMake files in over 15 years - at least that's what it looks like (and no big difference from some of its core code). I pity everyone who wants or needs to maintain a package management solution for OpenCV and all its dependencies, and keep it correct under various configurations.
You should edit your comment with `~~` to ~~strikethrough~~. It's still positive karma and misleading. 
I would recommend to use CPack for packaging and binary repo like Bintray. By the way if you will write a library it must be covered by tests (gtest, boost or some kind of). And there is really not important which kind of a library you wanna get after building. You can describe building process according to a custom flag with possible states like headeronly/static/dynamic or anyhow you want and after all you will have got artifacts depends on this state
Fair point, though it's currently at -1.
To be fair, it took until the late 90s for C++ to take any kind of hold in gamedev.
There *might* be some chance of Rust doing the deed, because there's a lot a hype behind it and a somewhat large supporter - Mozilla, but it will take a long time and legacy code is not going anywhere.
Java ee for speed of devel and not requiring serious processing, if you are doing stuff I'm hundreds of millions of transactions a day but each is serving some miniscule request that is mostly network bound then interpreted jit will be fine, ingest the optimisation built into the jvm will probably get you what you need, most people don't actually need speed for their services. If you do actually need to process something and poor possibly be space efficient then compiled languages with good target architecture optimisation will be invaluable.
Oooh! Cool. I just may have to adopt this style.
Cute! I assume the next step in your exercise is a multi-layered XOR gate? :)
Thanks for sharing your experience, sorry you didn't proceed this time, you could always try again in a year or so. Hope you find the right place for you though. I'd just like to add a note of explanation about our interviews for anyone else reading this. Our coding interviewers are aimed at checking a candidate can: 1. write code, 2. to solve real (ok, a bit contrived due to the time constraints) problems. We try to avoid "trick" questions. I think a lot of companies do interviews that don't include the second part, so I think sometimes people aren't expecting it, and aren't prepared for it. But we aren't trying to catch anyone out; we'll happily drop a few hints and help you talk through the problem. People can find out more about what to expect [here](https://www.bloomberg.com/careers/technology/engineering/software-engineering-experienced-hire/) ([here for grads](https://www.bloomberg.com/careers/technology/engineering/software-engineering-student-recent-graduate/)).
But can it learn at compile time via templates?
libexpat?
I think the chances of anything like this happening is practically nil. The current module proposal is just meant to replace headers, and to do so with relatively small incremental changes. Your proposal is probably fine for another language (C# works like this already) but will not happen in C++. Sorry.
I don't know if I like the *export lib* syntax, however I super agree about the fact that module names should **NOT** be specified in the module code. 
Before trying to give any opinion, I think you should modify your points by adding these sections in each: - What does the current Merged Modules proposal allows and doesn't allow that this point try to change? (not everyone here follows the details of modules proposals - I do but I'm thinking about others). - Can that proposition be done as an addition to the Merged Modules proposal? (I think several of them can) 
Can you re-post the form in english?
And herb Sutter speaks about making c++ programming simpler, by adding things to the language... As long as c++ tries to stay backwards compatible adding things can be useful, but it will almost always add more and more edge cases and complexity to the language. Adding another patch to a patchwork will not simplify programming. At some point we will need to break some stuff to be able to move forward. My hope is that after modules are introduced and we no longer need to rely on textual inclusion, they will allow to write different modules in different language dialects (e.g. different defaults or simplified initialization rules, fewer ways to spell exactly the same construct etc). It's probably not realistic for this ever to happen, but I think it is necessary if c++ wants to be used for more than existing code bases.
No not yet. But yes can be implemented like that but why do you want training at compile time ? 
I would love to try that out
&gt;My hope is that after modules are introduced and we no longer need to rely on textual inclusion, they will allow to write different modules in different language dialects There was a proposal for this in San Diego which died right there. You're right that it will never happen.
Do you have a link please?
The other way around would be more useful I think.
[P0997](https://wg21.link/p0997)
The GitHub repository is just a mirror - I do not think that PRs are considered there. 
Holy shit, why are you getting downvoted? [Similar](http://aras-p.info/blog/2018/12/28/Modern-C-Lamentations/) [statements](http://www.elbeno.com/blog/?p=1598) have been made recently by prominent devs about the absolute mess that this language is devolving into. Are there really that many evangelists here still desperately clinging onto this sinking ship? Most of us in the gamedev business don't pay much attention to all the cruft that gets slapped on every few years. The only reason it's survived for so long is because there isn't a decent alternative with similar tooling and debugging support. The moment that happens this shit is gonna get dropped so damn fast. But hey, you can always just close your eyes and ears and just downvote anyone who disagrees if that makes you feel better.
It's a single tiny executable; there's precious little to set up. Install it with your package manager, or get a copy from the project website and stick it in `/usr/local` or `/opt`.
That seems entirely sensible to me. "Triaging" simply means "determining the priority". That's usually the first step for any bug in any software, not just compilers. 
I know, this is just an easy way to post something for initial feedback stage.
It seems that SObjectizer's announces have no interest here. Maybe it is because SObjectizer is not similar to other modern C++ projects with main repository on GitHub and fancy landing page on some site in '.io' domain. Maybe it is because Actor Model has no big attention in C++ community at all and our community doesn't need "universal" Actor frameworks. Or maybe the community just happy with the single famous one that was PRed on CppCon. Despite the actual reason(s) it seems that there is no sense in publishing new announces here because they don't produce any useful feedback and I won't disturb users of /r/cpp anymore. But because this post is already exists I will try to invite those who maybe interested in SObjectizer to look at our plans on SObjectizer-5.6: [On the road to SObjectizer-5.6](https://github.com/eao197/so-5-5/issues/20).
Our team have recently moved from FakeIt to [trompeloeil](https://github.com/rollbear/trompeloeil). The main issues we encountered were lifetime issues with functions that are called with a `const &amp;` to a temporary, the temporary no longer exists when you call `Verify(Method(mock,foo).Using(1));`. The killer issues for us though was [segfaults mocking unique_ptr](https://github.com/eranpeer/FakeIt/issues?utf8=%E2%9C%93&amp;q=unique_ptr), I believe this is still failing on Visual studio in debug mode with the latest develop branch of fake it.
&gt; Triaging Triaging in medicine is applied when there are not enough resources to help all patients, typically in an external crisis situation (though this situation is a crisis in itself). One then choose which patients to /not treat/. I.e., one choose which patients one should just let die, and use minimal resources on. Determining priority is for a normal case load. Triaging for internal compiler errors, deciding which ones to NOT FIX, implies there's a heck of a lot of the internal compiler errors, compared to the resources available. And that may be so for Visual C++. I've run into a Visual C++ ICE about once a month for the last 20 years or sp, and I've reported a handful of them (I suspect many are really the same, just not fixed). 
I misread the title as 'tragic internal compiler errors' and had a slight sympathetic moment to recall different template evaluation crashes ... among other fun things. :D Guess I'll need to up my coffee dosage before I get back to work.
So there's still no direct function for getting the size of the file open in an ifstream? Seeking to the end and back is a bit of a hack. Methods than use a path are vulnerable to a race condition between querying the size and opening the file to read its contents.
Yep, there are many good reasons for that.
Well, I don't agree with your definition of "triage". Even in medicine, triaging about determining the order in which patients are treated - it's much more than a simple will/won't decision. You're making an assumption (an invalid one in my opinion), that a status of "triaged" and a status of "won't fix" are synonymous, and I really don't think that's the case here. I'm guessing that you write software for a living, probably for a company, and that every so often a customer calls up to report a bug. For most customers, "their" bug is the most important and has to be fixed "right now". What your company probably does is take a look at the bug and a) make sure it's actually a bug in the product, not just the customer doing something wrong b) make sure it's a new bug, and hasn't been analysed before (there's a chance it's been fixed on the internal dev. builds already, but not released to customers yet, for example) c) determining when it will be fixed, since very few companies have developers simply sitting around, waiting for bug reports to come in, so they can start fixing them immediately. Those three things are called "triaging", and that's what the Visual Studio team were doing.
&gt; Triaging in medicine is applied when there are not enough resources to help all patients, typically in an external crisis situation (though this situation is a crisis in itself). One then chooses which patients to /not treat/. I.e., one chooses which patients one should just let die, and use minimal resources on. That's not true at all. Triage is the entirely normal first stage of emergency medicine, where patients' needs are assessed and prioritised (although the term is sometimes eschewed in favour of less "scary" sounding words like "streaming"). The only time you wouldn't perform some form of triage is when you have no other patients. Only in the most extreme of circumstances (e.g. on a battlefield) would that lead to a "don't bother, too far gone" type diagnosis. The same term is used for the initial analysis of incoming bug reports in many, if not most, software teams. It doesn't imply anything about the amount of resources available or the amount of errors. Seems this whole thing is down to your misunderstanding of terminology.
Quoting Wikipedia about the medical "triage", it's called "triage" because it divides the patients into three categories: &gt; * Those who are likely to live, regardless of what care they receive; &gt; * Those who are unlikely to live, regardless of what care they receive; &gt; * Those for whom immediate care might make a positive difference in outcome. &gt; &gt; For many emergency medical services (EMS) systems, a similar model may sometimes still be applied. In the earliest stages of an incident, such as when one or two paramedics exist to twenty or more patients, practicality demands that the above, more "primitive" model will be used. However once a full response has occurred and many hands are available, paramedics will usually use the model included in their service policy and standing orders. When you say that's "not true at all" I conclude that you're gray-washing. Or white-washing. 
https://en.cppreference.com/w/cpp/experimental/fs/file_size: ``` std::uintmax_t file_size( const std::filesystem::path&amp; p ); std::uintmax_t file_size( const std::filesystem::path&amp; p, std::error_code&amp; ec ) noexcept; ``` &gt; The size of the file, in bytes.
Wikipedia is not the arbiter of all human knowledge. That's a simplified set of categories that helps explain the word's etymology and historical context. As the same page lists further down, modern systems have more than 3 categories. Besides, modern medicine (except possibly battlefield medicine) would never abandon a patient even if their chances of survival are definitely zero. However, what I actually disagreed with was your unsourced assertion that triage is only used when there aren't enough resources to help every patient. That's what I said wasn't true. Nice selective reading skills...
libexpat-pol?
&gt; Well, I don't agree with your definition of "triage". OK, but it would be nice if you could describe the disagreement, then we could disagree in public. :) &gt; Even in medicine, triaging about determining the order in which patients are treated - it's much more than a simple will/won't decision. Yes. Doctors are not stupid, and I apologize if I gave that impression. Also, triaging is applied in situations where resources are too scarce but patients' lives are not in danger. &gt; You're making an assumption (an invalid one in my opinion), that a status of "triaged" and a status of "won't fix" are synonymous, and I really don't think that's the case here. I don't make that assumption, but it's likely. Because triaging of an internal compiler error implies a /possibility/ of won't fix. And I've experienced that "won't fix" for a Visual C++ ICE. Which means that Microsoft has just not changed that policy, of possibly not fixing an internal compiler error. &gt; For most customers, "their" bug is the most important and has to be fixed "right now" There should be no need to evaluate whether to fix because the compiler team, with the most knowledge, has already decided that the ICE is critical. As opposed to a normal bug where source code is mis-interpreted or incorrect machine code is generated, or both. An ICE is a ready-made evaluation, and another part of the Microsoft organization, those who evaluate bug reports, take it on themselves to override that original evaluation made by the most knowledgeable. &gt; Those three things are called "triaging", and that's what the Visual Studio team were doing. If it is called "triaging" then what do they call real triaging. Remember, it's an ICE. It's not an ordinary bug. In any normal situation there would not be a question of priority: that was decided by the compiler team long ago. 
Tw things to keep in mind: * terms are adopted from other areas (in this case software engineering taking a term from medicine), and their meaning shifts as part of the adoption * you can't take the original literal meaning as a basis for understanding at the current time. As a couple of examples of the second point, electronics is based on the Greek word for amber, but very little electronics actually contains any amber these days. The word atom is from the Greek meaning indivisible, and everyone still uses the term, but no-one insists that protons, neutrons etc don't exist I would agree with [https://www.reddit.com/user/mallardtheduck](mallardtheduck) - this appears to be a terminology misunderstanding.
`std::string` would only be created if the functor you pass `ranges::split` accepts `std::string`; by default this would not be the case.
Yeah on Windows they should just include ETW tracing in the compilers.
The default logger API is a good idea. I recently made use of spdlog in one of my company's projects and I had to create an API very similar to this to make usage more convenient. Excellent library, by the way!
Why is this still in the `std::experimental` namespace?
here is non-experimental version: https://en.cppreference.com/w/cpp/filesystem/file_size
yes. experimental version appears in the uppermost link in my google search page
I've added the requested information. If I got something wrong, please let me know.
&gt; because there would be no __cplusequalstwo in the "ideal" C+=2 you would have reflexion, so the code would look like import std.version; int main() { if constepxr($.in_scope(__cplusequaltwo)) { // we're in a C+= 2 scope } } because `std.version` would define `auto __cplusequaltwo = 202004L;`
FWIW Stack overflow has a kind of [review](https://stackoverflow.com/review) called "Triage", which means "Help identify the quality of questions"
from [Wiktionary](https://en.wiktionary.org/wiki/triage#English): &gt;triage (countable and uncountable, plural triages) &gt;Assessment or sorting according to quality. &gt;(medicine) The process of sorting patients so as to determine the order in which they will be treated (for example, by assigning precedence according to the urgency of illness or injury). &gt;(computing, by extension) The process of prioritizing bugs to be fixed. &gt;That which is picked out, especially broken coffee beans.
Once the file is open can you not just use the path version of file size command? Or does that still suffer from races? (Depending on OS?)
C++ is already complicated enough in English :) I'd be happy to answer if it was in a language I'd understand. 
Good point, but it would still not let you write code that can be compiled as C++ or C+=2, thus not really helping the migration.
I presume you missed the irony, but yes in principle, you'd end up with a trained network, hard-coded in your binary, seems like a good plan.
Honestly I don't know. While Linux allows a file to be replaced while a program has it open for reading, and I think Windows does too if you open it with the appropriate options (it's not the default though), I don't know if a program with a file open would get the size of the new file or the version it has open.
But would not that will require to recompile program again and again if training data changes , I think it would make more sense to train data at runtime and write modified coefficients to a simple file which can be loaded again at restart of the binary 
first step when Someone goes to ER is triage
Agreed, that's a common source of hassle for me (a European) as well.
There can be lifetime issues involved when dealing with temporaries. 
What you are referring to is called Method Chaining. The C++ STL does use this type of call method like operator&lt;&lt; in iostream.
It makes error handling difficult in case something goes wrong in a method call. 
Are there actually any advantages of using WinApi and `ReadDirectoryChanges()`?
As far as I understand this implementation, it uses polling to determine changes. `ReadDirectoryChanges` uses event based mechanism with operating system support. Event based solutions are almost always more efficient than polling. There are also event based file system watcher APIs for other operating systems.
Like Cobol, right?
&gt; CPack, tests The application template I made already uses CPack and has unit tests set up and ready to go. The unit test target uses Catch2, but it's easy to swap that out if you'd rather use a different framework. Of course, I plan on making the library templates the same way. &gt; You can describe building process according to a custom flag with possible states like headeronly/static/dynamic or anyhow you want I plan on having one template for header only libraries and one for compiled for simplicity. Of course, the compiled libraries will have static and dynamic options.
If you target Windows only, yes, *ReadDirectoryChanges* should be more performant.
`ReadDirectoryChanges()` is a push API where your code is more or less immediately notified of relevant changes without polling. The code provided by OP is a polling implementation. The disadvantage of course is that `ReadDirectoryChanges()` isnâ€™t portable.
To be honest, relying on timestamp by regular checks is a terrible idea IMHO. Especially since you can miss several changes while the thread is waiting. Of course, if it's not a high-performance application that may wait so long, there is no problem using this method though. Checking if a directory added a file to be registered in a music/video database comes to mind. That said, I would still create a portable wrapper that uses inotify on Linux and other functionalities elsewhere and then use this wait-poll method if not implemented yet.
Why is objB-&gt;setA( A().load_from_file("data/asset.dat").set_name("foo") ); better than A.load_from_file("data/asset.dat"); A.set_name("foo") ); objB-&gt;setA(A); I doubt there'd be any difference in the code the compile generates, and I think the second is more readable. It's also much easier to step through in a debugger, since it's immediately clear which part is currently being executed.
&gt; ER Quoting (https://www.verywellhealth.com/medical-triage-and-how-it-works-2615132): &gt; When Is Triage Used? &gt; &gt; Triage is used when the medical-care system is overloaded, meaning there are more people who need care than there are available resources to care for them. There may be mass casualties in a war zone, terrorist incident, or natural disaster that results in many injuries. There may be need for triage when a school bus accident or a large pile-up of cars on a highway results in too many injured people for too few ambulances or EMTs. &gt; &gt; In the United States, emergency rooms may be full of people who need immediate attention plus people who are seeking treatment for less serious conditions. The department may be staffed just to meet the expected need. When there are too many patients arriving and not enough personnel or other resources, triage is used to determine who gets care first. 
Actually quoting Wikipedia it says "The term comes from the [French](https://en.wikipedia.org/wiki/French_language) verb *trier*, meaning to separate, sift or select". It goes on to say that in World War One, the three categories you list were used. Both medicine and software engineering have advanced since the First World War.
If anyone knows of a decent inotify wrapper in C++ please let me know
Maybe this will help http://doc.qt.io/qt-5/qfilesystemwatcher.html#details
Can't use QT unfortunately. Thanks though
`std::string` uses it so it's possible to write ```c++ void f() { std::string s = "but I have heard it works even if you don't believe in it"; s.replace(0, 4, "").replace(s.find("even"), 4, "only").replace(s.find(" don't"), 6, ""); } ```
&gt;If lots of checks are done within a minute, several disk writes will be done as accessing a file/directory also write to it (especially to update the access timestamp unless it is disabled on the system). This is not healthy for SSDs. I've read somewhere that Windows automatically disables updating the last access time on SSDs. Then I went and checked for myself, and was disappointed that it doesn't do that. Then I disabled it. Damn you Microsoft, do I have to do everything myself?
Wow, polling, really? That sucks.
Wouldn't the lifetime of the temporary be extended until the end of the statement?
The article uses last **write** time as a check for modification, not last time when the file was accessed.
Debugging is a good point, but regarding readability: A objA; objA.load_from_file("data/asset.dat") .set_name("foo"); That's how I've always used this pattern and it seems more readable than either of the alternatives you mentioned.
It will still perform a write unless access time is disabled.
It's only for Polish so why didn't you post it in Polish?
I've never used libuv to watch directories, but I've used it for lots of other stuff and it works super well for my network-related needs. It's a C-style library, but there are C++ wrappers out there, or you can make your own for just the parts you need. https://nikhilm.github.io/uvbook/filesystem.html
bibexpat :)
The not healthy for SSD's thing is massively overblown, the fear that they'll die if you write to them too much is essentially false - even if you mash them super hard they'll massively outlive spinning disks
There's no other way to implement it with &lt;filesystem&gt; api though.
I can't think of a reason to choose this over inotify in Linux.
If your code is written for Linux only and you care about performance you should obviously use inotify.
I agree. I think that the possibility of even wearing out an SSD makes people think that it will happen sooner than it would. It makes the SSD something that is 'consumeable'. Therefore you'd like to make it last as long as possible, that's why you fear of wearing it out.
You may try to rise the same suggestions/concerns somewhere in [https://groups.google.com/a/isocpp.org/forum/#!forum/std-discussion](https://groups.google.com/a/isocpp.org/forum/#!forum/std-discussion). There could be more people involved with the modules proposals with opinions on the subject.
boost.asio works well for that (at least in my prod experience)
Only if you are using the return value for error handling. If you are using exceptions this doesn't have any impact on error handling.
&gt; Actually quoting Wikipedia it says "The term comes from the French verb trier, meaning to separate, sift or select". Yes, it is a selection of categories for patients, and a separation of patients into those categories. Originally the three I listed. Nowadays it's common with 5 categories in medical triage, and a color coding where black is used for the middle category above. &gt; Both medicine and software engineering have advanced since the First World War Is your point, if there is a point other than the associative, that status "triaged" now means something positive, that Microsoft, at that point, were going to do something about the crash? 
Method chaining allows declaring, configuring, and passing a temporary to a function all within an expression. With the alternative you pollute your scope with non-const lvalue objA that persists past the end of its intended lifetime.
It doesn't return a reference, but a new object. Keep in mind that each time you're calling `replace` you're constructing a new string.
Why did it die? The proposal seems to only restrict potentially dangerous features like implicit conversions, signed/unsigned comparison etc. So compilers which don't want to implement this feature can just ignore it and everything would work fine. Similarly to attributes which are also allowed to be ignored.
What alternative do you propose?
But then you get code that works on one compiler and not there other. Either way, the language will split up. 
Okay for configuration use-cases where youâ€™re just creating a temporary, setting some values at runtime, and returning it. Not really necessary otherwise. Of course, this is all personal preference. Pick a style and remain consistent. 
Oh please work on the title and text. &gt; Furthermore, C and C++ are *weakly typed* programming languages that allow the type system to be bypassed, including: &gt; - C style cast &gt; - UB &gt; - UB Do you want to be downvoted? Because that's how you get downvoted. The C language don't enforce strict rules for types. C++ does. Use `static_cast`, ban C style casts, enable sanitizers, test your code, use a static analyser. &gt; The Effective Type Sanitizer (EffectiveSan) is a tool for instrumenting C/C++ programs with *dynamic type* checks- Ooooh! You are making a sanitizer! Didn't knew before the half of the readme. You should have stayed with that. And it has nothing to do with dynamically typed C++. With your title, I was expecting something like `std::any` or a template technique. If you want to show your tool to C++ programmers, write as if you address yourself to C++ programmers. 
Particularly in the last few years, wear of SSDs has massively increased. I am wondering though, around 8 or so years ago, it was strongly recommended not to write many many very small files too often, for example I believe one strong guideline was not putting \`/var\` in Linux on an SSD or something like that because there's many many small files written there very often. Is that at all still relevant, like a few millions or billions of small files written a few times, will that bring a good 2019 consumer-grade SSDs lifetime to an end?
https://github.com/berkus/dir_monitor originated in the asio mailing list, handles inotify and ReadDirectoryChangesW
But you can check the implementation ;)
Imo it is a hard API to maintain over time. If later one of these methods may throw or return an error condition, it breaks the chain. I think certain operators like the stream operators are expected to work this way though
True. Not a good enough reason to use exceptions though.
I'm not sure if this question was directed at me, but I have absolutely no idea, sorry.
My point was very simple: interview is a two way process. Your questions and how you formulate them affect not only the answers but also the opinion about you and your company. You told several times how good you are, but your proposed questions and wording of them just don't correspond to such claims. Is C++ market in Australia so much "employee's market"? 
Why do you need a wrapper? For simple functions like this it isn't that difficult to make something lightweight yourself.
&gt;D is another - arguably better than C++ Doesn't their standard library force you to use garbage collection?
Yes, this was my point.
is it a surprise to you that 'let it die already lol' is an unpopular opinion on a cpp sub? 
Thanks for the laugh. Oh. You're serious.
Use range-v3 then.
["no one"](https://dlang.org/orgs-using-d.html)
It's disappointing that they couldn't wrap the native event based API if available and fall back to a generic polling mechanism otherwise. I don't see this getting much use by people who know the difference.
Is there some reason not to use the C standard library function call (stat/fstat)? Those are pretty standard across operating systems, there's generally a way to do anything the operating system can do with a C library function (Although sometimes you might have to go digging for the correct function,) and I'm pretty sure that's the main reason they left compatibility with C in the language in the first place.
I agree the existing std::vector(n, value) constructor is not intuitive but using same "uniform" {} syntax for all the constructors and giving initializer_list priority is not the right way to push it because that just creates confusion of which constructor is called (priority of initializer_list depends on matching types). Also while {} syntax is the newest it already comes with warts - just google how brace elision behaves for std::array&lt;std::complex&gt;. Because of these two issues the new {} syntax is the most confusing one. So I fully understand people who don't want to use it. And the worst thing about it is I don't know how to fix it it without breaking backwards compatibility. Compiler warning about hiding constructors when additional initialize_list constructor is introduced and [[deprecating]] some std::vector constructors would be probably helpful but certainly not enough.
His entire presentation was actually a big marketing push for D :P. I was a lot more interested in it after his talk, although [this section on garbage collection](https://dlang.org/spec/garbage.html#pointers_and_gc) was pretty off-putting.
In general I find exceptions to be more readable than using the return value, so I tend to prefer them in my code anyway.
or the Win32 API if you're in Windows... Seriously, I don't see the merits of preferring polling over the event-based native implementations just so you can tout "true portable" in your code, especially when it's trivial to use ifdefs
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/afxhjy/miscellaneous_files_no_configurations_in_visual/ee1zz9i/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Perhaps the README was not as clear as it should have been, apologies. But basically, EffectiveSan is a "sanitizer" that automatically instruments C++ (and C) code with dynamic type and bounds checking. The idea is to detect runtime bounds errors, type violations, and related bugs. EffectiveSan works with any C++ code, including "low-level" C++ with arrays, manual memory management and C-style casts, without the need for code refactoring. Unlike C++ polymorphic classes and `dynamic_cast`, EffectiveSan will automatically check *any* type, including fundamental types such as `int`, `float`, pointers, etc.. It also checks array bounds, including sub-object bounds and use-after-free errors. 
AFAIK it was never the size of the writes, it was frequency. 
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/afmd0v/how_to_setup_ninja/ee209on/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
That's not the C Standard Library, that's POSIX.
I was referring to the first sentence "C++ has a million ways to do even the most basic stuff". The language is broken on a fundamental level. Maybe "let it die" is an overreaction, but given the attitude of the committee and the fact that any criticism is downvoted to hell, it sure looks like it's heading that way.
I've been using Qt Creator on Windows for about 7 years. I've never had it crash and the code completion is fast and error-free (compared to VS). On Windows at least, I highly recommend Qt Creator for both gcc and Microsoft C++ compilers. It's a fantastic IDE.
http://www.cppgm.org/ ?
Interesting, thanks!
Bingo!
I actually prefer using copy-list-initialization everywhere, without auto (unless it's something like an iterator or smart pointer). `std::string str = {};` is more sensible to me. This reads as "initialization str, which is explicitly a std::string, during definition, and initialize it with 'nothing'". This is the same as in C: `int i = 0;`, except now I can do `int i = {};`, and it means initialize i with nothing. It forces me to think about, "what does mean to initialize something with nothing?" or more clearly, "what is the base state of this type?" The only time this would be a problem is explicit constructors which I don't run into too often.
To me this screams use the right tool for the right job. if &lt;filesystem&gt; does not use native event based os api's than it should not be used for file watching. 
I'm on the Microsoft VC++ team (mid-level optimizer), and also drive our efforts to make our team's interactions on DevCom as good as possible. So this thread caught my attention :), and maybe I can contribute a bit. First, to clarify the confusion: DevCom reports can be in a number of different states, exactly in an attempt to clarify the state of the bug. I guess that's sort of backfired here :). The link here: [https://docs.microsoft.com/en-us/visualstudio/ide/report-a-problem?view=vs-2017](https://docs.microsoft.com/en-us/visualstudio/ide/report-a-problem?view=vs-2017) hopefully clarifies what we mean by "Triage" in this case. To say it here: DevCom tracks bugs for all visual studio, so "triage" essentially means "we think we've alerted the right team about this report". I don't know why we chose Triage, but it wouldn't surprise me if we were trying to be in line with SO, as cpp\_learner may have guessed (I didn't know that about SO, by the way -- thanks!). I hope that reassures you in part that we do take ICEs very seriously, and I hope you aren't discouraged from filing them. We strive to flush them out and fix all bugs, ideally before anyone sees them. In addition to attacking customer-reported bugs, we maintain a rolling test suite of a lot of real-world code -- including Windows, AAA games, and 60+ OSS projects like Chrome and LLVM all to that end (and to make sure our code-generation is also correct). The unfortunate reality is that bugs are in every piece of software, including compilers. In addition to filing the bug-report proper, I would encourage you (and everyone!) to try to explain the impact of the bug it has on them. For instance, an ICE that only manifests after the compiler reports some user-level source-errors is bad, but not nearly as bad as an ICE that arises from legal code, preventing compilation of a product. We want to fix all of these! But, all else being equal, we'd want to fix the more impactful ones first.
That sounds... ominous :(
There's a few reasons that used to be a problem. A big one was a combination of the OS and the SSD controllers themselves. To avoid wearing out SSDs, writes should be spread out across the SSD; e.g., avoid rewriting the exact same physical blocks repeatedly. Modern OSes and controllers will move the physical location of logical blocks around as they're written, effectively spreading the wear out across the whole SSD. A second one was just that SSDs were smaller. When you only have a "handful" of physical blocks, you can't spread writes out _that_ much and you rewrite the same physical blocks more often. In general, larger SSDs tend to perform better (both in I/O speed and lifetime) than smaller SSDs, when everything else is equal. A third one was the TRIM command support, needed both in controller and OS. This supports the first item in a way: it's used by the OS to inform the controller which logical blocks are unused, which gives the controller a lot more freedom to efficiency move logical blocks around to improve both I/O speed and lifetime. The fourth big reason of course is just that the quality of SSD cells has improved over time.
You can set your [user flair](https://www.reddit.com/r/cpp/comments/4tm8k9/user_flair_is_now_available/) to identify what you work on (and you can mention multiple things).
A function call to construct and configure the thing is fine, too. Scope isn't polluted by using {}.
&gt; It doesn't return a reference, but a new object. Keep in mind that each time you're calling replace you're constructing a new string. I guess you are confusing `std::string` with string in other languages. The signature of `std::string::replace` used here is ([\[string.replace\]](http://eel.is/c++draft/string.replace)): basic_string&amp; replace(size_type pos, size_type n, const charT* s); (BTW the example is from TC++PL)
Access time is disabled on almost all filesystems today Linux, Mac and windows. Because doing a write for each read is performance issue everywhere. 
Yes it's more performent. And it's battery efficient because windows don't give cpu time to thread waiting for an event.
Yes. Finding good developers is incredibly difficult. Many positions go unfilled for months. As for my skillset. Pure C++ standards and semantics I'm average. My expertise is in delivering high performance, stable and easily maintainable software. Of that I have been very successful.
Thought I was in r\ProgrammingHorror for a sec. OP can you see the issue?
This is called a [Fluent Interface](https://en.wikipedia.org/wiki/Fluent_interface) and is fairly common, though perhaps more so in other languages. I think it is handy and gives you more flexibility with little cost. Assignment and stream operators usually behave this way. It does causes friction if there's other data you would like to be returning from the function so that's a trade off.
Implementation for Linux, Android, BSD, MacOS and Windows. Excellent solution
Yeah, that's why I asked. A proper cross-platform directory watcher should use the native APIs
Oh the horror! I can't even imagine the C++ code that might work on one compiler and not on another! /s Honestly, there are many successful examples of such "transitions". Can't remember any bad ones from the top of my head (though it could be the survivor bias).
I think this is the example that had a bug because order of operations wasn't guaranteed, although that may have changed recently.
I really dislike chaining. I find it typically is a code smell. Covering other misgivings, like a class with too many things to set, which implies a class that does too much, etc. It is OK in places, but I avoid it. YMMV.
I have reported a few compiler/library bugs, and a couple are under investigation. A few were actually errors in my code, and u/STL himself actually got back to me to let me know my code was doing illegal things. So no, i think microsoft is doing a swell job, and nobody is perfect.
It's because triage is done at the counter informally. But it is done.
I like the idea of showing the assembly! --- Using milliseconds for the last two graphs make them unreadable; have you considered switching to microseconds? Or scaling up the size of the buffer to copy? --- Now, however, before adding more graphs, you need to add more words. The result of a benchmark is pointless until it has been explained and lessons have been drawn. The first few benchmarks are particularly representative: why is the old-style sieve behaving in such a drastically different manner when compiled with gcc vs clang? And that formatted read, how come the results between gcc and clang are opposites? Getting numbers is only the first step; the easy one. Explaining the numbers, telling their stories, is the most valuable step. And it may well be that it points out flaws in the benchmarking method that requires tweaking the benchmark and getting new numbers... rinse and repeat.
That's what I've thought. However when it was set to 'System Managed' in Command: fsutil behavior query disablelastaccess Output: DisableLastAccess = 1 (User Managed, Enabled) then viewing the file attributes for a file caused the last access time of it to be updated. I assume it doesn't update it every time the file is accessed, and there is a minimal time window between updates, but it was updated nonetheless. After I've set the value to fsutil behavior set disablelastaccess 2 The last access times are not updated at all. I like this better.
[std::contitional](https://wandbox.org/permlink/1qsiAsblhUTbpsta), no?
It isn't hard to ifdef on Windows or Linux and switch the implementation.
Does anyone *not* disable last access time? The main situation I can see it used in is caching heuristics, and in that system it's better to keep a table of access times in memory (preferably kernel-side) rather than relying on writes all the time.
\&gt; Using milliseconds for the last two graphs make them unreadable; have you considered switching to microseconds? Or scaling up the size of the buffer to copy? &amp;#x200B; Late here. I have to review that I saw it. :) I will in the next days or week if I can find some time. &amp;#x200B; \&gt; Explaining the numbers, telling their stories, is the most valuable step. And it may well be that it points out flaws in the benchmarking method that requires tweaking the benchmark and getting new numbers... rinse and repeat. &amp;#x200B; Totally agree. Have a very limited amount of time so FWIW, I will at least put those benchmarks, its source code and its assembly (need to add gcc also). People can inspect it even if the explanations are not there. &amp;#x200B; &amp;#x200B;
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
It's a good way to run into undefined behavior due to accessing an deleted object at some point. Might be fine in languages that guarantee memory safety but is just not worth the risk in C++.
How? All three `.replace()` calls are sequenced. The arguments of each `replace()` *are* unsequenced, but also independent so them not being sequenced doesn't really matter.
*Push-based
Well, in same way helmets "pollute" your outfit, right? I think there's a safety benefit to the longer and clearer lifetimes of explicitly declared local variables: auto str1 = std::string("abc"); // rhs: is a genuine lvalue std::string_view sv1 = std::string("abc"); // rhs: is a temporary (rvalue) masquerading as an lvalue std::string_view sv2 = std::string("abc").append("d"); // rhs: is just an rvalue std::string_view sv3 = std::string("abc"); My understanding is that the forthcoming ranges will not support construction from rvalues for safety reasons. But this safety feature would be circumvented when (rvalue) temporaries are presented as lvalue references (as chaining does), right? Of course, if/when we get a powerful enough static analyzer (lifetime checker), the safety concerns will be less of an issue.
Does `s.find("even")` happen before or after `s.replace(0, 4, "")`.
Windows disabled it in 2 iterations. First they write last access with bigger granularity 1minute, then completely removed. Today NTFS disabled it for all by default. I think they return mtime. On Mac(hfs+/apfs) or Linux ext4... we stoped read access time too it's completely disabled on all our customers os/distros for performance and unreliable at best. For Fuse filesystems access time is most of the times mtime too.
Shame on me, you're correct. 
Thanks!
I don't think that is allowed. I could be wrong and I don't see anything about member access on this page https://en.cppreference.com/w/cpp/language/eval_order
In principle I can not modify or create new ones questionnaires , but - if you have a really big heart - I can translate the questions here (You will learn Polish - you will be able to enter that skill the CV :-)) &amp;#x200B; **1) Choose the C ++ 17 constructions / functions that you have used (at any time)** *^(1) Wybierz konstrukcje / funkcje standardu C++17, z ktÃ³rych miaÅ‚eÅ› okazjÄ™ korzystaÄ‡)* *Inicjalizacje zmiennych w wyraÅ¼eniu warunkowym ---------------------------&gt;* If statement with initializer *Zmienne inline (wielokrotne definicje zmiennej o tej samej nazwie)* \----&gt; Inline variables *OkreÅ›lanie zasad wykonania algorytmÃ³w zrÃ³wnoleglonych* \--------------&gt; std::execution *shared\_ptr dla tablic* \------------------------------------------------------------------&gt; shared\_ptr for arrays *SkrÃ³cony zapis zagnieÅ¼dÅ¼onych przestrzeni nazw* \---------------------------&gt; nested Namespaces *Nowe algorytmy przeszukiwania std::search() ---------------------------------&gt;* new search algorithms std::search() &amp;#x200B; **2) What you lack in C ++ 17?** *^(2) Wybierz konstrukcje, ktÃ³rych brakuje Ci w C++17)* *TrÃ³jznaki* \------------------------------------------&gt; Trigraphs *Przydomek register* \----------------------------&gt; register keyword *Operator inkrementacji dla typu bool* \---&gt; incrementation operator for bool type *Brak aliasÃ³w dla biblioteki iostream* \-----&gt; No aliases for the iostream library *Niczego mi nie brakuje* \-----------------------&gt; I do not lack anything ;-) &amp;#x200B; **3) How would you rate changes in C ++?** *^(3) Jak oceniasz zmiany jÄ™zyka C++?)* \[Choose 1 if you think C ++ goes in the wrong direction, 10 if you rate C ++ changes horny\] &amp;#x200B; **4)** **Have you ever refactored the code to adapt it to the C ++ 17 standard?** *^(4) Czy kiedykolwiek przeprowadzaÅ‚eÅ› refaktoryzacjÄ™ kodu w celu przystosowania go do standardu C++17?)* *Tak* \--&gt; Yes *Nie* \--&gt; No &amp;#x200B; **5) C ++ 17 constructions facilitate the write of software** *^(5) Konstrukcje C++17 uÅ‚atwiajÄ… tworzenie oprogramowania)* \[Choose 1 if you completely disagree, 5 if you agree with this\] &amp;#x200B; **6) C ++ 17 constructions help increase the readability of the source code** *^(6) Konstrukcje C++17 pomagajÄ… zwiÄ™kszyÄ‡ czytelnoÅ›Ä‡ kodu ÅºrÃ³dÅ‚owego)* \[Choose 1 if you completely disagree, 5 if you agree with this\] &amp;#x200B; **7) C ++ 17 constructions help increase the efficiency of the created software** *^(7) Konstrukcje C++17 pomagajÄ… zwiÄ™kszyÄ‡ wydajnoÅ›Ä‡ tworzonego oprogramowania)* \[Choose 1 if you completely disagree, 5 if you agree with this\] &amp;#x200B; **8) Do you feel old?** *^(8) Czujesz siÄ™ staro?)* *Tak* \--&gt; Yes *Nie* \--&gt; No &amp;#x200B; **9) How old are you?** *^(9) Ile masz lat?)* *Mniej niÅ¼ 8* \---&gt; less than 8 *Ponad 50* \-----&gt; Over 50 &amp;#x200B; **10) You're a woman?** *^(10) JesteÅ› kobietÄ…?)* *Tak* \--&gt; Yes *Nie* \--&gt; No &amp;#x200B; **11) You have a job?** *^(11) Pracujesz?)* *Tak* \--&gt; Yes *Nie* \--&gt; No &amp;#x200B; **12) Job position** *^(12) Twoje gÅ‚Ã³wne stanowisko)* *PowiedziaÅ‚em, Å¼e nie pracujÄ™...* \------&gt; I said I'm not working ... *Programista C++* \--------------------------&gt; C++ programmer *Programista innego jÄ™zyka ------------&gt; Other language programmer* *(you can type other)* &amp;#x200B; **13) I use the most often...** *^(13) NajczÄ™Å›ciej wykorzystujÄ™)* \[Choose the name of the compiler. *Nie wiem* \--&gt; I don't know ;-) \] &amp;#x200B; **14 You can tell me how much you earn net (but you do not have to)** *^(14) MoÅ¼esz siÄ™ pochwaliÄ‡, ile zarabiasz netto (ale nie musisz))* \[ Use the currency converter ;-) Polish zloty (ZÅ) = PLN \] *Skoro nie pracujÄ™, to nie zarabiam. Proste?* \---------------------&gt; I'm not making money. *JeÅ›li nie muszÄ™, to siÄ™ nie chwalÄ™* \------------------------------------&gt; I'm not bragging! PracujÄ™ charytatywnie, tzn. odprowadzam tylko.... ---------&gt; I work charity, i.e. pay only taxes on income and I give back the whole salary to the boss (**please do not mark this, because the answers will go to the trash)** &amp;#x200B; **15) You can write here about anything related to C ++** \[Type your greetings or whatever you want ;-)\] &amp;#x200B; === Thank you for your understanding ! &amp;#x200B; &amp;#x200B;
&gt;C++ is already complicated enough in English :) I'd be happy to answer if it was in a language I'd understand. Look at my answer above, please. Maybe it will be easier now. Thanks, bro.
Because English sounds more scientific and professional. ;-) I added the translation here. 
&gt;the non-selected branch is completely ignored (the tokens aren't even required to be parseable) Well this is not the case in D, the non-selected branch must pass parsing. But in D parsing is separated from semantic passes, I guess that why N3329 is like this.
&gt;something about the level of introspection suggested makes my security senses tingle. not based off any hard evidence or examples. CTFE in D cannot write files or call system functions [https://forum.dlang.org/post/p9ee8n$18b6$1@digitalmars.com](https://forum.dlang.org/post/p9ee8n$18b6$1@digitalmars.com)
This seems perfect for a phoronix article! Very interesting! Though it seems that in most benchmarks modern C++ is actually faster than old style? Maybe I get data wrong...
Better document in the benchmark relevant data, too. What compile flags were used? Which C++ standard library is being used? What exactly are you testing with "modern" C++? (C++03, C++17, etc.) The overhead and costs of excessive template magic in older C++ versions can change dramatically with more recent additions like variadic templates, `constexpr` metaprogramming, `if constexpr`, and various library helpers, not to mention the overhead of even more library-based solutions to what used to be language-level problems like smart pointers, `optional`, `string_view`, etc. I can look in the benchmark code, but summarize it better. :) Also, perhaps provide measures of the _compile-time_ overhead of the modern C++ vs traditional code; especially as this is far more a common complaint of C++ than run-time overhead.
Sometimes. Easy enough to roll your own replacements if it's a requirement. Still, apart from a few niggles like that, it's objectively a far less broken mess of a language.
You know, its portable, i think that the true solution is not using ifdefs. Its creating a native event generic for all OS
As far as I know Stephan T. Lavavej has been doing a great job for the community both by maintaining the STL for Microsoft, and by providing the Nuwen distro of g++, and by moderating this Reddit group, and by participating in video debates, and so on, and on. And also, the Microsoft response in this thread was great. I was distracted when I read it so haven't yet got up to thanking the guy. But, that was informative: I like facts. Microsoft-the-compiler-vendor is something else. From what you write I gather that I have reported a far greater number of compiler/library bugs than you have. Over the years they improved from â€œimpenetrable wall of Microsoftâ€, an idea that Google later adopted, to being almost as responsive as the g++ folks. But still that wasn't enough to establish trust. When some C++ experts joined Microsoft we talked, tongue in cheek but not entirely in jest, about them joining the enemy. When I got became an Microsoft Most Valued Profession (MVP) in Visual C++ 2012 I felt in two minds about it: I could use the free tools, certainly, nice!, but I wasn't happy about MS possibly trying to influence a critical voice. And the distrust is deep-rooted in the community. E.g. it surfaced here on Reddit two years ago with [the Visual C++ "phone home" incident](https://www.reddit.com/r/cpp/comments/4ibauu/visual_studio_adding_telemetry_function_calls_to/). As it surfaced again with this thread, where it was a foreign idea to me that they could really be doing the Right Thingâ„¢, as it's now apparent that they did, when there was something opening up a different possibility. I don't know what MS could do to repair that distrust, except possibly listening more to the community, e.g. in recent times about the VS colors and uppercase text (off by default now I believe but then I may just have a fix in place); about the default MS-specific code generation for new projects in VS (they asked here on Reddit I think it was last year, but then did not take the feedback to heart, it's still needlessly and impractically MS-specific, a vendor lock-in thing); about e.g. for Pete's sake support **standard `main`** by default for the most common target, instead of the vendor lock in monstrosity called `WinMain`; and so on. Perhaps even fixing the scroll-away-under-the-mouse bug complex in Windows. Something. 
Thanks! I was hoping to get some feedback here first, but obviously it's quite a lot to chew on ;-) 
That exact example (the `f()` above) was discussed in committee emails for months and months (it comes from Stroustrup's book I believe). I'm only guessing what the problem is, but the gist of the emails is that there is/was an evaluation order problem (discovered by automated tools, it doesn't show up with current compliers - but it _could_, ie it is allowed). And thus the committee spent months arguing about whether we should standardize evaluation order. I'd rather just avoid writing code that is sensitive to order, and hard to understand. 
While I agree that the chances (for any change, not just this one) may be low, I also think this is an excellent time for rethinking some old constraints (in particular, the symbol visibility thing, which I feel strongly about) and in the process hopefully make the language that much more pleasant to work with. 
Personally, I'd prefer the following, if the builder pattern makes sense in the context: objB-&gt;setA( A::from_file("data/asset.dat").with_name("foo") ); 
https://godbolt.org/z/GW9bhJ
&gt;solarianprogrammer.com/2019/0... I wouldn't use it on production code neither, this polling style for files was dropped years ago as it simply doesn't scale. I can't see any benefit, if I have to make a portable library I would wrap the os provided tools (kqueue, inotify, WinApi) into my own events using ifdefs. Additionally your code needs to keep a map of files to check things like "creation", "modification", etc. That is simply duplicate data that is not necessary to have, consuming resources and again, it doesn't scale, it can lead to have unnecessary data in your memory, etc. The OS APIs do this for you, another point is as you poll you may have inconsistencies like create and modify a file super fast, that would be reported as creation instead of creation and modification. Nice idea but I would put a note in your blog to not recommend it for production, really, you don't want people to use this in Production code.
There are a huge number of cases in such comparisons where really all you need is the assembly, since the entire entire goal of the modern C++ will be to compile away the abstractions. This won't work for more complex things though since there will be likely incidental differences that are too numerous to easily parse. However for things like simply comparing e.g. memcmp vs std::equal, or fill vs memset, I'd expect to often see identical assembly. You also have to be careful with certain things. For example, your program that does memcmp and your program that does operator== do different things. That's because one of the members is a double, and for instance two doubles can be bitwise equal yet compare false (if both are NaN). You also need to do document the optimization settings used, for example O2 vs O3 (I recommend O3), front and center on the main github page (I couldn't easily find it). I'd also recommend using a standard benchmarking framework (like Google's) unless there's a specific reason. It just instantly lets users know that a whole class (and there are many) of classic micro-benchmark errors have been avoided. I would also pick a more neutral name personally (it's putting the cart before the horse to call it a "penalty" to begin with as it can easily be faster).
It did have changed recently, in [P0145R3](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0145r3.pdf). (Actually that's where I copied this example.)
This isn't about member access, this is about function call expression. In the expression A(B), the two sub-expressions A and B were unsequenced before C++17, so if side effects of A conflict with side effects of B, you had UB. 
Yep, that's the link we need. Thanks.
In general, I don't think it's a good idea to use std::chrono::milliseconds, especially if the measured times are in the range of few hundred milliseconds as the definition of std::chrono::milliseconds is duation&lt;int64_t, milli&gt;. What's the deal with std::sort vs qsort? In other benchmarks / articles / blogposts I usually saw std::sort outperforming qsort. Maybe the data size?
I was mentioning member access because of `s.foo()`. In this specific case `A(B)` is fine, what the was about is if `A.B(C).D(E)` is fine if `B` and `E` conflict and `C` and `D` conflict. I'm still not clear on that.
&gt; Late here. I have to review that I saw it. :) I will in the next days or week if I can find some time. You could just do a y-log plot?
No, in this specific case, A(B) is only "fine" as of C++17, which added a sequence point after A. 
All I'm saying is that so far I've had good experience. And since coming from using mostly g++ and VS Code on Linux, I noticed that the transition has been *not too bad*. I have learned some things as well and learning is good for the brain;)
The bar chart shows std::sort outperforming qsort by a large margin. Are you reading it wrong?
Wait, so before C++17 `str.replace(str.find("x"), 1, "");` is UB?
Indeed, I was reading it wrong! No idea why I made that mistake...
It's not 'extended' per se, but the temporary lives until the end of the full statement, which in most cases is a semicolon. You could have a problem with `std::string&amp; s = std::string("foo").replace(0, 1, "");` but that's a pretty standard mistake and should be easily found in a code review. 
No, there are no side-effects in A (which here is just an id-expression `str`). In the problematic example, A calls into string:;replace.
If you want your type to prevent chaining on an rvalue then simply qualify the chaining methods with a normal reference: like [this](https://godbolt.org/#g:!((g:!((g:!((h:codeEditor,i:(j:1,lang:c%2B%2B,source:'%23include+%3Ctype_traits%3E%0D%0A%0D%0Astruct+chain+%7B%0D%0A++chain%26+get()+%26+%7B+return+*this%3B+%7D%0D%0A++chain%26+set_i(int+i)+%26+%7B+i_%3Di%3B+return+*this%3B+%7D%0D%0A++chain%26+set_f(float+f)+%26+%7B+f_%3Df%3B+return+*this%3B+%7D%0D%0A%0D%0A+private:%0D%0A++int+i_%3B%0D%0A++float+f_%3B%0D%0A%7D%3B%0D%0A%0D%0Aint+main()+%7B%0D%0A++//+auto+fails+%3D+chain%7B%7D.get()%3B+//+member+function+of+rvalue+is+not+defined%0D%0A++chain+lvalue%7B%7D%3B%0D%0A++auto+succeeds+%3D+lvalue.get().set_i(42).set_f(3.14f)%3B%0D%0A%7D'),l:'5',n:'0',o:'C%2B%2B+source+%231',t:'0')),k:50,l:'4',n:'0',o:'',s:0,t:'0'),(g:!((h:compiler,i:(compiler:g82,filters:(b:'0',binary:'1',commentOnly:'0',demangle:'0',directives:'0',execute:'1',intel:'0',libraryCode:'1',trim:'1'),lang:c%2B%2B,libs:!(),options:'',source:1),l:'5',n:'0',o:'x86-64+gcc+8.2+(Editor+%231,+Compiler+%231)+C%2B%2B',t:'0')),header:(),k:50,l:'4',n:'0',o:'',s:0,t:'0')),l:'2',m:100,n:'0',o:'',t:'0')),version:4)... It is not foolproof but is a good tool if you know why you're using it. 
&gt; This seems perfect for a phoronix article! Someone call the hospital, that is a sick burn
The problem when you have 15+ million lines of code is that the quality of code invariably will go down because the number of different groups and engineers involved. It is really up to the code reviewers to maintain the quality of the code, and we all know that many code reviewers do not do that good of jobs, particularly when deadlines are involved. The maintenance of such large code base is often political. Once a piece of bad code is checked it, it is very hard to get fixed. Oftentimes, the risks involved in fixing it can be quite high. The person who wrote the code may have left the company, or forgotten about the code. So most people who fix the issues choose conservative fixes that adds a lot of flags, which further complicate the issues. Then code refactoring is always difficult in C/C++. When you have a 100 line switch statement that gets expanded to 10K lines over the years, it gets difficult to refactor it. And duplicated functions, or tons of flags inside a function all create challenges. Personally, I find C much easier to maintain. Bad C++ coders can create nightmare situations that are extremely difficult to diagnose and fix, particularly in the area of memory management.
Thanks for the feedback. Really appreciated. I will consider the move to a standard bench suite bc as you said it saves some headaches. I think the name is ok. If I call it something else it will be less catch the eye less.
My only comment is that clang++, unless installed manually, on Apple isn't Clang clang but Apple Clang. It is different and I think should be considered it's own entity.
How could \`memcpy\` is slower than \`std::copy\` with GCC 8?
This seems to be relevant here: https://blog.tartanllama.xyz/initialization-is-bonkers/
I don't know about this benchmark in particular, but memcpy is sometimes slower than std::copy because std::copy is a template which understands the alignment of the data it's operating on and thus doesn't need branches to copy the unaligned bytes that may appear at the beginning/end of the copied region. There's an excellent post on Stack Overflow on the subject: https://stackoverflow.com/questions/4707012/is-it-better-to-use-stdmemcpy-or-stdcopy-in-terms-to-performance
Also note about the ==. I will fix that when I have some time. 
Well, you can't define structs inside it, but you can do it with function, so the second part of the example from the talk is implementable too. And the whole point of static if and if constxepr is that people want their if look like if.
Lately I've been messing with tartanllama (Simon Brand)'s expected and optional implementations with a fluent design. It works well, so far. Looks like this for me: std::unique_ptr&lt;device&gt; devicePtr = {}; device_builder{} .add_queue_family(queueFamily) .physical_device(physicalDevice) .build(*instancePtr) .map(move_into{devicePtr}) .map_error([](auto error) { REQUIRE(false); }); Where .map handles the success case and .map\_error handles the error case. `device_builder` is a helper struct, and .build() returns an `expected&lt;unique_ptr&lt;device&gt;, error&gt;`. .map and .map\_error are part of the `expected` interface. This is just me experimenting, but I like how it feels so far.
I would start with std::function. Because of lamdas, it enables a syntax very close to what you would have in js. &amp;#x200B; libray.onEvent(eventType, [](const eventData&amp;){ // operate on eventData here }); &amp;#x200B; &amp;#x200B;
&gt; They know damn well that unless the software project is their schoolwork, students do not have time to work on programming projects. That is absolutely not true.
[https://github.com/idea4good/GuiLite](https://github.com/idea4good/GuiLite)
i'll definitely check it out! thanks!
&gt; Better document in the benchmark relevant data, too. Takes time also, the source code is there. As nice as it is, it is not top priority right now. The point of the benchmark is that they should be doing something equivalent (I know that is not informative enough without seeing the code, but... nothing is perfect) &gt; What compile flags were used? Sure &gt; Which C++ standard library is being used? Standard stock things for everything. That means libc++ for clang, libstdc++ for gcc. I could improve that, sure, but assume for now that I do not tweak, just use stock things :) &gt; What exactly are you testing with "modern" C++? (C++03, C++17, etc.) Thanks for the feeback. My amount of time is fairly limited. I prefer to add benchmarks than to explain everything in deep detail at this point, but that could happen in the future, of course. As for "Modern", take this definition, from the README file: "This is a set of benchmarks in C++ that tries to compare â€œraw/C-ish codeâ€ or old C++ style implementations vs â€œlibrary-based, modern C++â€ implementations of some algorithms and compares their execution time. For every benchmark, two implementations are introduced: raw implementation. modern C++ implementation. The goal is to put them front to front to see how they perform against each other, on a per-compiler basis." So assume C++17 or anything that can be or become a best practices as C++ evolves. Also look at the code if you want, it is nicely linked in each benchmark and it is quite short! &gt; Also, perhaps provide measures of the compile-time overhead of the modern C++ vs traditional code; especially as this is far more a common complaint of C++ than run-time overhead. Thanks. Worth considering. Actually I was myself worried about run-time performance more but you have your point and it makes a lot of sense.
Probably the main reason is that C# has a language defined comment format for parameter and method descriptions (as well as return values, examples and other errata). C++ doesn't. Nothing is standardized in this regard. You might have javadoc, doxygen or some other notation, but nothing is standardized. Hard for the IDE to guess, let alone support them all (and what happens if you intermix?).
There is, but as it's MSVC-specific no one really uses it: https://docs.microsoft.com/en-us/cpp/ide/xml-documentation-visual-cpp There are addons that make Doxygen comments work but I don't know the specifics (Visual Assist, probably).
&gt; Hello MCU has only 100+ lines code for beginner, showing you how to use GuiLite on MCU. I mean... I'm counting [_a lot_ more than 100 lines](https://github.com/idea4good/GuiLiteSamples/tree/master/HelloMCU). This project seems to be a simple widget hierarchy, plus [some rendering code](https://github.com/idea4good/GuiLite/blob/master/core/src/surface.cpp#L203) operating on bitmaps. The user has to create the platform-specific window and find a way to blit the bitmap to it, then create event handlers and forward them to the library. &gt; GuiLite can run on iOS, Android, GNU/Linux, Windows and macOS platforms Sure, but if I understand correctly, calling this a "UI framework for all platforms" is somewhat misleading. It's a framework that sets bytes in a bitmap. Which is cool, I guess, but it's certainly not what I'd call "cross-platform".
So basically I should just always have tabs pulled up on my browser with documentation and just pull info from there
Umm I'm not sure you should recommend anyone sublime text 3 When it's closed source and costs money. There are much better free alternatives out there which are better to use
Ah ok, thanks man
&gt; g++-8 5.2.0 Something doesn't add up...
I personally find that much harder to understand than a more traditional version like: device_builder builder{}; builder.add_queue_family(queueFamily); builder.physical_device(physicalDevice); std::unique_ptr&lt;device&gt; devicePtr = devicePtrbuilder.build(*instancePtr); if (!devicePtr) { REQUIRE(false); } Yes, builders lifetime now extents beyond the creation of devicePtr. I don't remember the last time I ran in to problems caused by this. Where it is a problem a scope can be added either by declaring the pointer early and manually scoping builder or by putting the builder in a function and returning the result. The chaining case has an implicit 'and then' each time it chains. Throw in side effects - like writing to the devicePtr or the error handling - and the cognitive load to track whats happening increases. Each time it chains, there is an implicit 'and then' as I read the code, making harder to skim and concisely understand. The traditional form makes the separation between the construction, configuration, finalization and error handling more distinct. I'm a firm believer "Everyone knows that debugging is twice as hard as writing a program in the first place. So if you're as clever as you can be when you write it, how will you ever debug it? " In absence of other constraints, I'd rather optimize code for being simple to comprehend. That often overlaps with code thats highly malleable as well as testable. Chaining effectively removes the return value as a tool in my toolkit to meet those objectives. 
Looking forwards ! Hope to see an std async one !
Sure, I knew a review. Last update was too fast. U know... work all week, did this in a tight schedule at around 1:00-2:00 a.m. Singapore time...
I did a talk about using Boost.Asio and Boost.Hana for composing events as promises for full duplex stuff: https://www.youtube.com/watch?v=UalTAQmP3iE (shameless plug)
I agree.
I find it more horrifying that there are a lot of people agreeing with OP and upvoting this post. In any of the companies Iâ€™ve worked with, this code would get shut down real hard
I just ran the '02-formatted-read' benchmark on my local laptop with gcc-8.1 and the following Makefile all: sscanf_formatted_read stringstream_formatted_read stringstream_formatted_read: stringstream_formatted_read.o $(CXX) $&lt; -o $@ sscanf_formatted_read: sscanf_formatted_read.o $(CXX) $&lt; -o $@ %.o: %.cpp $(CXX) -I.. -Wall -Wextra -O3 -march=native $&lt; -c -o $@ clean: rm -rf *o sscanf_formatted_read stringstream_formatted_read dump: objdump -D -j .text -M intel sscanf_formatted_read | c++filt &gt; sscanf_formatted_read.asm objdump -D -j .text -M intel stringstream_formatted_read | c++filt &gt; stringstream_formatted_read.asm run: ./stringstream_formatted_read 10 20000 ./sscanf_formatted_read 10 20000 Of particular note, I am turning on the optimizer which doesn't seem to be the case in the provided cmake files (as far as I could tell. I don't use cmake.) I modified the source to print all of the sorted timings instead of just the median. Here are the results of `make run`: &gt;./stringstream_formatted_read 10 20000 &gt;2 2 2 2 2 2 2 2 2 3 &gt;./sscanf_formatted_read 10 20000 &gt;55 56 56 56 56 56 56 56 57 77 This is substantially different from the provided results^1. Using the optimizer is key when doing these kinds of benchmarks. Indeed, it is interesting to see what happens to the timings and assembly as the optimizations are changed. --- [1] I'm a bit dubious of the stringstream results, but these are my data.
just watched it. Very good video. I REALLY like the idea of polymorphism being an implementation detail.
There are quite some libraries to handle it already. Such as Boost::signal2, libsig++, and my [eventpp library](https://github.com/wqking/eventpp)
We use it and it absolutely sucks! As one can imagine xml is cumbersome to write by hand. Also you can't use the ``&lt;&gt;`` chars of course. So you either need to use escape sequences (which sucks for reading at source code level) or CDATA sections within examples. 
Also look into std::invoke, which allow you to call anything function-like
In addition to the alternatives, you can also take a look at my library I use often for work: https://github.com/CihanSari/observer
Maybe something like this? https://github.com/facebook/folly/blob/master/folly/docs/Futures.md 
What is the problem with using milliseconds?
Cmake automatically turns on optimization in release builds.
Qt has QFileSystemWatcher 
Wait are you joking? * you famously cannot make an XOR gate with a perceptron * any number of perceptron layers is just another perceptron * Yet surely, you can stack logic gates to make other logic gates There must be a hole in my understanding somewhere. You sound like you might know!
I realized later that it's also not an issue, just didn't edit my answer. However, if the results were 1-2 msec away, then the casting could result in a misleading comparison as std::duration::count returns the same type as Rep (int64_t in this case).
.. you really don't like underscores ?
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ag618u/i_am_trying_to_find_the_easiest_way_to_learn_and/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Just remember it's LGPL.
Idk. Original UNIX was 10k LOC. That feels like an embarrassing fail if it has 5k LOC. I feel like the word LITE in its title shouldn't be there. 
std::unique_ptr should only differ from a raw pointer at compile time. If you see a difference between the two at runtime, it's a compiler bug imo. 
Nah, it's just an example how to use an API, not some algorithm protected by patent. Copy-paste, reformat and you are perfectly fine.
Could you share your top 10 talks list?
My experience with \`system\_cateory\` and \`generic\_category\` is that the Standard Library functions that wrap system calls will use \`system\_category\` to **store** information about the error. Whereas you, the programmer, will use \`generic\_category\` to **retrieve** the information about the error. &amp;#x200B; \`generic\_category\` is associated with an **error condition**, whereas \`system\_category\` is associated with an **error code**. The difference between an error code and error condition (as I treid to indicate in this post: ([https://akrzemi1.wordpress.com/2017/09/04/using-error-codes-effectively/](https://akrzemi1.wordpress.com/2017/09/04/using-error-codes-effectively/)) is that error code is used for **storing** and communicating numeric values of errors and from which subsystem they originated, whereas an error condition is used for **querying** about what happened. Only \`generic\_category\` has standardized numeric values, and you can effectively use only \`generic\_category\` in the if-statements in your code. The numeric value of an error from \`system\_cateory\` is only good fro logging. &amp;#x200B; This distinction becomes apparent when you try to signal an error yourself. You cannot just return \`std::errc::not\_enough\_memory\` because it is associated with \`generic\_category\` which is associated with an error condition, which can be used for querying (in a system-agnostic manner) but not for storing. 
Boost::Signals2 gives you a pretty decent event/callback system. I use it all over the place, from object factories of satellite coordinates to decoding video packets with ffmpeg. It's compatible with boost::bind and std::bind from &lt;functional&gt;.
Given that OPs project is obviously of an educating nature, I was sort of hoping (s)he'd discover your point #1 on his/her own. Your point #3 is obviously valid, so I believe #2 is flawed. Wikipedia tells me multi-layered perceptrons can distinguish data that [is not linearly separable](https://en.wikipedia.org/wiki/Multilayer_perceptron), which I believe is the hold-up for single-layered ones and the XOR gate. That said, I'm rusty AF on the details. OP ought to trust something like Russel &amp; Norvig's book over random redditors like me.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/ag6inj/c_competition/ee3xz9u/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
isn't the current advice that bind is pretty much deprecated?
MSVC could agree with MSVS on something though...
Newsflash: on unix C++ defers everything with extremely rare exceptions (eg regex) to the glibc. Next time it would be worth checking how this sausage is done buddy.
Worth to be shown to the people who do not believe C++ vodoo with raw numbers
Go look at the libstdc++ code It is mostly calls into the Glibc
The footnote 18 leads to a dead link. It should be [https://github.com/isocpp/CppCoreGuidelines/blob/master/docs/Lifetime.pdf](https://github.com/isocpp/CppCoreGuidelines/blob/master/docs/Lifetime.pdf) I think.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/ag7041/help_needed_to_write_a_code/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
AFAIK at least on msvc std::copy falls back on memmove instead of memcpy for trivial types. Might be the same thing on libstdc++.
&gt; You could just do a y-log plot? [Not with a a bar chart](https://www.graphpad.com/support/faq/graph-tip-dont-use-a-log-scale-on-a-bar-graph/) (because bar charts must start at 0, and log 0 is undefined). But, as mentioned by /u/matthieum, a bar plot is really not appropriate here. The plot should either be of all the points (Iâ€™m less sure than Matthieu about plotting the CDF â€” a boxplot is easier and just as informative; alternatively, a density plot); or, at minimum, a summary boxplot. Any of these plots can be put on a log-scale.
If I remember that one correctly it's a good talk, but I really dislike the attitude of "absolutes" that do more harm than good (a bit same with the cppcon2014 "data-oriented design"). I'm of that age that I was taught "never use GOTO" without actually going into nuances of why and when to use or not use it. It just does more harm than good to be so fanatic about flexible ideas where most of the time there is no best way to do everything.
If OP does go for \`std::function\` as others have suggested, that already has \`invoke\` semantics.
Yeah, it's essentially a library implementation of a lambda wrapper, more verbose and with a limitation or two thrown in. Just use a lambda.
They differ at runtime too because passing a `std::unique_ptr` by value disallows moving the value inside a register (due to the nontrivial destructor) by the Itanium ABI, whereas a raw pointer can be inside a register.
\&gt;- Added memcmp vs std::equal \&gt;- Added memset vs std::fill &amp;#x200B; your benchmark time is just short - what about a factor of 100? &amp;#x200B;
I had no idea. Thanks! 
Optimization is activated with flags at configuration time, so yes, it is optimized output what the benchmarks show.
I do need to fix that :) I will when I get some more free time.
Right, but no execution time is zero. That's only because you are measuring time too roughly 
What would be cool is to be able to make something i call "lambda structs" or "named tuples". It would make the use of functionality like map much easier. Consider `std::map&lt;std::wstring, std::wstring&gt; someMap;` What is the key? What is the value? Programmer have to specify it in the name of the map, in the comment or do some using-fu like "using CompanyName = std::wstring". Also, the user have to type mapEntry-&gt;first, mapEntry-&gt;second, or specify the names himself (auto&amp; \[key,value\]), but what if we could write the code like this: `std::map&lt;std::wstring CompanyName, std::wstring HeadquartersCity&gt; someMap;` Compiler would generate the "lambda struct" from that and you could use mapEntry-&gt;CompanyName instead of mapEntry-&gt;first. It's much more expressive this way.
I think it's just a matter of an sync vs async events system. I'm my old company we referred async callbacks as subject/observer and sync callbacks as signal/slots. That naming varies though and is nothing set in stone. You can Asio - A cross-platform C++ library for network and low-level I/O programming that provides developers with a consistent asynchronous model using a modern C++ approach. ##Async Boost.Asio - A cross-platform C++ library for network and low-level I/O programming. C++ Actor Framework - An Open Source Implementation of the Actor Model in C++ libev - A full-featured and high-performance event loop that is loosely modelled after libevent, but without its limitations and bugs. libuv - Cross-platform asychronous I/O. [BSD] uvw - C++ wrapper for libuv. [MIT] ##Sync sigslot - C++ Signal/Slot Library Signal2 - boost SimpleSignal - High performance C++11 signals
Sure the compiler can eliminate the abstractions. But if they don't actually simplify the code, you have to use brain cycles to see through the abstractions when you read it. Just look at the simplicity of the old code: for (int i = 3; i &lt; ct_sqrt(NatNumber); i += 2) isn't that easier to read than this new abomination: r::for_each(v::stride(v::ints((std::size_t)3u, ct_sqrt(NatNumber)), 2) Even if we get rid of the namespaces it is still a mess: for_each(stride(ints((std::size_t)3u, ct_sqrt(NatNumber)), 2) Note that the stride width 2 is written very far away from the word stride and you must mentally parse the parens and commas to match it up. I belive we can improve it with the new c++ syntax: for (int i : iota(3u, ct_sqrt(NatNumber) | stride(2) ) But in this case, it is not really any better than the C-style loop we started with.
The key ingredient to an event driven design is the ability to wake up the receiver when there is something incoming. Any other time the worker code should be able to sleep without consuming CPU cycles. In async architectures this is done by using async queues where the receiver can go to infinite sleep on waiting.
So the gcc generates calls to memset and memcpy in all cases? Absolutely fascinating what modern optimizers can do. I noticed that this only happens with -O3. With -O2, gcc generates explicit loops for the lambda cases and only uses memset for the first test. 
There's an extension that makes it look like this: [https://imgur.com/a/JIqzEbc](https://imgur.com/a/JIqzEbc). But the msvc library headers don't have any documentation comments. I don't know why MSVS doesn't have something similar already.
It reminds me of Objective-C. I donâ€™t like it. It makes the lines too long so itâ€™s hard too read and there is no consistent place to break a line especially you use lots of operators.
[learn how docker works](https://docs.docker.com/get-started/) (parts 1, 2, 3 and 6 should give you enough information on how to make simple deploys) if you have trouble getting it to work [get inspiration from others](https://github.com/pathtrk/docker-cmake-opencv-boost) 
Yes I agree. this is a nice library that I also tend to use.
Please stop deploying stuff via docker only. Make a proper package and then deploy this package via docker eventually. Making a package for the platform is not complicated, and will avoid some black boxes unable to troubleshoot. And also, if you deploy your docker where you have built your app, you're doing it wrong. Please ensure proper separation from build and deployment.
I think I am a bit late to the discussion. [Bun](https://github.com/BrainlessLabs/bun) is a library that I have been working on as an ORM for C++. It has scope for lot of improvements, which I am trying to take up. Hope it becomes useful. Here is an article with tutorial on usage: [https://www.codeproject.com/Articles/1100449/Cplusplus-Object-Relational-Mapping-ORM-Eating-the](https://www.codeproject.com/Articles/1100449/Cplusplus-Object-Relational-Mapping-ORM-Eating-the)
If you want to see all of the options, I suggest taking a look at the CopperSpice cs\_signal library: [https://github.com/copperspice/cs\_signal](https://github.com/copperspice/cs_signal)
Why is the programming community so unreceptive? Let OP try whatever he wants. You donâ€™t even know what he is building and already telling him he is doing it wrong?
[https://bitbucket.org/SpartanJ/efsw](https://bitbucket.org/SpartanJ/efsw) Small, quick to build, decent high level C++ API.
That's not the point. The point is that the bars in a bar chart need to *start at zero*, so the number needs to be on the axis, and with a log axis it can't.
That's not really accurate. Signals2 supports multiple subscribers/slots and invokes them all when the signal is fired. In addition, the connection objects it returns can be used to unsubscribe a single subscriber. The convenience (and thread-safety) of all of this is not supported by lambdas alone.
Introspection + metaclasses will help you, but you will have to wait C++23 or more probably C++26. In the meantime, you can use structured binding \`auto \[key, value\] = getKeyValue(myMap);\`.
I would recommend you to use a [`unique_function`](https://github.com/Naios/function2) rather than a `std::function` because you probably also want to support non copyable types too. Depending on your underlying executor it could also be beneficial to wrap the callable into a virtual interface and store that on the heap but then you'll loose the benefit of small functor optimization. Some asynchronous libraries like boost asio which you probably will need for the underlying implementation tend to be single action based which means that you need to call a method like `async_read_some` repetitively with a new callback. For such a single shot promise implementation like [continuable](https://github.com/Naios/continuable) could be beneficial since the one to many listening you are intending to implement always burdens a high abstraction overhead. 
Eh, you don't need to start a bar graph at zero. You can start it at 0.0000000001
At a very high level of knowledge on a subject we begin to be able to formulate constructive criticism on it. So if you realy want to check if a coder masterize c++, ask him what is wrong with the language? Why those deffects were included in the language? How do we circumvent to these deffects? What is the cost of these deffects? You could also check its creativeness by asking him how he would modify the language? On one hand if the coder passes this test it could proove he has a disruptive or creative mind which usualy not what is expected from an employed. You can test its servility by asking him how he would propose such modification? Would he do it for free? How much should he be paid for doing that job? Also show him that you do not have any knowledge but you are at a higher position and check how much close to the ground is the knee.
It sounds like he wants to release to the public, in which case docker is the wrong route. It would be different if he were deploying to servers or the cloud.
Thanks /u/mcypark and /u/quicknir! Will the upcoming blogpost have benchmarks?
If you're staying on Linux platforms, flatpak and snap might be easier, and you could later use that process as the basis for creating a docker image. However, I would also consider mili42's comment and look at properly packaging your product. Docker, flatpak, snap, etc is just the bad old way of distributing a VM image to run a single app, with less overhead. &amp;#x200B; You end up putting a lot of resources into scripting and verifying the image building, which might as well be spent on packaging. Or you don't put the proper planning and resources into it and end up with a snowflake distribution system, which hurts you and your users. &amp;#x200B; In the end, it's a lot cheaper in the long run to do the job right the first time.
Some people who come from C# where LINQ is a thing like writing things like this: A.Select(i =&gt; i.Property) .Where(p =&gt; p.Number / 2 ==0) .SortBy(p =&gt; p.Number) // and so forth And they're bringing it to C++.
That is such an utopist point of view. The aim of an HR interview is not to measure knowledge but obsequiousness. What ever is the personnality category, obsequiousness of an interviewed is a mesure of its controllability. Modern recruiting technics only focus on that. So I will bet the HR will ask technical question to the interviewed and he will show he has absolutely no knowledge on the subject. Then he will see if the interviewed fill like the boss, or as an obsequious slave!
No, *by definition* bar charts **must** start at 0. Starting it anywhere else strongly distorts the proportions and leads to misleading charts. This is especially true when using a log scale. This is explained at length, with examples, in the first link in my answer above.
One thing to consider - the last example of yours features name of `i` only a one time instead of 3, this can be utilized to give it longer, more specific name for example without much clutter.
With [std::condition_variable](https://en.cppreference.com/w/cpp/thread/condition_variable/wait) you can wait for an event, no need to poll.
To clarify hidden friends, I believe if the only visible declaration is inside the class, then it's only accessible via ADL. Otherwise if there was another declaration outside the class, it could still be used for normal overload resolution.
I think unique_ptr is as efficient as raw with the only overhead of destructor of moved from unique_ptrs doing a check. Already documented somewhere but I do not remember where exactly to provide a link. Needless to say that unique_ptr is far less error prone and much more maintainable. 
&gt; wait causes the current thread to block until the condition variable is notified or a spurious wakeup occurs, *optionally looping until some predicate is satisfied*. Not exactly without polling though.
In my experience you should always prefer `std::fill` over `memset`. Worst case it is just going to default to `memset`, best case is compiler will understand your intent and optimize it.
( unrelated except in name, but if anyone is interested in extending lambdas to structs... https://groups.google.com/a/isocpp.org/forum/?#!msg/std-proposals/vYsnIbdI_lQ/fbchd25MBAAJ )
Shameless plug: https://www.youtube.com/watch?v=lmIc0MgWBEI Also I have a WIP: https://github.com/ricejasonf/cppdock
The only reason to loop is to avoid spurious wakeups, which are not that common. Here is a quote from the Wikipedia article on spurious wakeups: &gt; According to David R. Butenhof's Programming with POSIX Threads ISBN 0-201-63392-2: &gt; &gt; "This means that when you wait on a condition variable, the wait may (occasionally) return when no thread specifically broadcast or signaled that condition variable. Spurious wakeups may sound strange, but on some multiprocessor systems, making condition wakeup completely predictable might substantially slow all condition variable operations. The race conditions that cause spurious wakeups should be considered rare."
Cool! Thank you a lot for this excellent and enlightening post. That's very useful knowledge.
I understand and agree that it *can* be misused either knowingly on by mistake and appear to be deceptive. As long as the chosen interval is reasonable and you aren't stacking bar graphs I don't see that big of an issue. A XY plot suffers from the same issue when intervals are chosen poorly. 
Very easy to quantify the "abstraction penalty" of C++. Very hard to quantify the "missing abstractions penalty" of C.
memset is just initializing the array to all 0. In different optimizations, you get different results, but the 3 functions still come out the same, per optimization. Also, clang does explicit (somewhat unrolled?) loops in all cases, under varying optimizations, never memcpy (not sure which is better).
So the one-and-only instance of this class has been running since 2013?
What do you mean when you say "proper package"? And what is "the platform"?
&gt; A XY plot suffers from the same issue It fundamentally doesnâ€™t because, unlike for a bar chart, *thereâ€™s no expectation in the reader that the plot starts at 0*.
This is great advice though. If the program is released as a package first, it can be used to create the docker container. Also, doing this allows one to use any container system they want. Now, what I think the OP wants is a docker container containing only the bits needed to run the program. This is going to require knowing exactly what you're linking to, and what they are...etc... Such is discoverable from the application itself and a script could surely be created that would do any such executable and build a container out of it. I would bet someone has written this so I'd search in that direction. If you made a package it should know that stuff already. Cmake already does this quite easily so there's no reason not to. You do have to depend on the package maintainers to not depend on system tools they don't need though, so the above method would probably be best.
Iâ€™ve tackled this recently by making addListener a template function that takes a â€œCallableâ€: Anything that can be called with the expected arguments. It can be tricky depending on your compiler version to get reasonable error messages if you do something wrong (I eventually got this to work with VC10). Concepts would make this a lot nicer if you are lucky enough to have access to them. Inside of the object you can store it as a std::function and any incoming types that are convertible to a std::function can be converted, and others can be wrapped in a lambda. This allows all sorts of things to be used as a callback: lambda functions, boost::functions, function pointers, function references, other objects with operator(), etc.
The claims you make about the speaker violating the CoC are very serious and unexpected. I've talked to that person at past conferences and I've always had the impression they were well-mannered and good-natured (even prior to me joining Bloomberg). Is there any evidence/official statement from the conference proving that they were actively mocking the death of an innocent person (opposed to - for example - making a tasteless joke)? 
I am interested in what they teach, not the class itself. And odd that there isn't a C++ certification, given that we have a standard for the language.
Yes, I know, but OP wanted no polling at any level. 
RxCpp
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/agb72w/while_loop_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Which extension?
You might consider using http://quick-bench.com/ to allow running these examples live. (It will also give disassembly.) The graphs on the Github page are pretty fantastic, too.
I mean, that sounds cool... but why do these kind of quasi-syntactic libraries never include a simple example somewhere in the README? What the fuck does a "switch-based visitation" look like? I don't see an `examples/` directory. Do you expect me to reverse-engineer your unit tests in order to figure out how this is used? The [unit test for visit](https://github.com/mpark/variant/blob/master/test/visit.cpp) doesn't appear to contain the keyword `switch` anywhere within it, so I'm not quite confused about what this does at all. And this is just normal for C++ libraries. "Introducing grognar-list, a zero-cost API for g-list concatenation"... and then everybody talks about it like it's old hat, like everybody should be able to intuit the interface for a g-list from the pre-release notes from that talk Sam's giving at BumpkinCon++ next June, and debate whether the g-list is superior to the old trivalue sieve and maybe the standards committee just wants to copy trendy concepts from the functional languages, and do we really need to replace the trivalue sieve that's been in steady production use since SGI pushed it in '94? Or is that precisely *why* we need to immediately adopt `grognar-list` into the standard in an emergency meeting?
I think â€šswitchâ€™ based refers to the internal dispatching on visitation.
First off: chill. Second: visitation is a well worn term in the context of variant. It refers to an API like \`std::visit\` which is already in the standard library and documented in the reference. So it doesn't need a usage example. You've quite missed the context here. Third: the change here is referring to the implementation of \`visit\`, I think this is made fairly clear by the released patch notes. Fourth: the purpose of the change is to improve the quality of the generated assembly, i.e. code size, runtime performance. This seems to be fairly well implied but I agree it could have been a little more clear. Next time if you have a question just ask instead of ranting.
Youâ€™ll have to ask the CoC committee. They arenâ€™t doing public statements of their process until 2019 afaik. That said, saying â€œblock lives matterâ€ and â€œI canâ€™t breatheâ€ makes it pretty clear (to me) that the punchline is Eric Garner.
&gt; In my opinion, professionalism is another agreeform of oppression. It is used to other, reduce the work of, and lambast those who donâ€™t fit within one persons idealogy of what professional entails Disagree. Professionalism is not an ideology, it's a contract. When you join a company you agree on adhering to their principles of professionalism. Likewise, if you participate at a conference (like CppCon) you agree on their way of behaving *professionaly*. Sure, different people have different opinions on what professional means, but saying that professionalism oppresses individualism is like saying rules oppress my freedom to do whatever I want. If someone likes "sharing the state of their genitalia" on slack they're most likely violating the contract of professionalism they signed up for. Also is it just me or is everyone becoming more sensitive these days? 
I think it will though I can't speak for Michael. Michael wrote some perf benchmarks prior to the change being merged, if you want a preview you can see for example: [https://travis-ci.org/mpark/variant/jobs/474776465](https://travis-ci.org/mpark/variant/jobs/474776465). Generally the gains are better on clang than gcc; in this example clang7 shows an over x3 speedup for the 2 type variant (this is all unary visitation). The assembly is smaller in size too Michael told me. I plan to write a benchmark that sorts variants this week; sorting requires comparison and swap both of which (IIRC) are actually implemented internally via a binary visitor.
Since MPark.Variant is an implementation of a part of the standard library (specifically the `std::variant` utility), one can just refer to cppreference for the documentation. &gt; What the fuck does a "switch-based visitation" look like? Like a regular use of `std::visit`: `visit(visitor, variants...);`, but the underlying machanism is implemented in terms of recursive `switch` statements, so the visitation is likely faster.
See, and I interpreted it as a replacement for `std::variant` that might let me dispatch with a `switch` instead of the verbose type-overload-operator approach.
By and large, yes. It boils down to "what's an event to you". If the event is something that tiggers the OS / hardware, that's it. So for example, user input of any kind is an event that needs no waiting for. Data coming from the network - the same. Data coming to disk, too (operating systems offer notification systems for that and they works with the hardware). If the event is an arrival of a record in a database - hm, no, you're too far away (there's DB systems that allow "listening" on that though). And JS does not need polling.
I think this person misses the point of the talk. Number of bugs is super linear with code size so terse syntax reduces bugs. if constexpr is a feature lifted from D but neutered to not improve terseness. It's not about whether you can achieve the same effects but can you do it with fewer bugs through reduced code size. I have personally run into this where if constexpr turned out to be useless and I had to stick with duplicated implementations to handle the void template specialization case.
It would be great if scoped enums had a convert to base function that could convert to the base type.
I think it's a stretch to say that terse syntax inherently reduces bugs. If it's less terse because it's more explicit and it expresses more semantics, then that's a good thing and very likely to reduce bugs. If it's more terse because it is less explicit and more auto-magical things are happening, then that's likely to increase bugs. Maybe neither here nor there wrt to this discussion, but just a side comment on the general concept which is often stated but I think is often not true. &amp;#x200B;
...don't fix it?
ABI stability for libraries is great with this.
A+ would read again
I watched this talk too and felt much the same way. I always thought of if constexpr as a way of making it possible to create constexpr classes like vector or do constexpr things with optional. Like in your post, there are other ways to do compile time decision making for selecting implementation details, even in C++11 (if you are up to having to write some of the STL tools yourself)
Proof?
Great read
I can load reddit but not isocpp.org. Using latest Tor browser.
&gt; But there's a huge difference between an offensive joke and mocking the death of a person. Is there?
I like how the author conveniantly only shows samples where each block returns. Still all but one of his examples are much mure readable in D than they are in Cpp. Also static if in D completely discards unvisited blocks and doesn't semantically check them, which leads to a lot less code written in practice. Speaking as someone who has seen and written tons of code in both languages, if constexpr is utterly useless compared to static if.
This blog post sums up my feelings on OOP and does a much better job articulating my thoughts than I could have. I feel like OOP has been inappropriately and arbitrarily taken as the gold standard. I think a lot of this has to do with OOP being a newer, relatively speaking, paradigm than procedural programming. This leads a lot of programmers getting the false impression that OOP is inherently better than procedural when they start learning computer science and programming. I think educational institutions and how programming is taught is much to blame for this false assumption. It seems like many computer science and engineering curriculums teach students that OOP is objectively better than procedural programming and only emphasize the strengths of OOP but fail to highlight its shortcomings. Instead, newcomers should be made aware of the different paradigms of what their strengths and weaknesses are and when they should be used. It also doesn't help that Java has been the de-facto choice for an introductory programming language since the late 90s. One point that this blog post really hits the nail on the head is about programmers spending so much time on defining objects and thinking about how to implement OOP principles before they even start solving the problem at hand. I feel like all this accomplishes is adding extra boilerplate, which usually manifests itself as bloat. I don't think OOP is necessarily bad, I just think it is extremely over used and shoehorned in as a solution to problems that don't really benefit from OOP. Areas like simulations / scientific modeling, video games, and GUI libraries are perfect use cases of OOP, but outside of those areas, I don't see much benefit.
Personally, I strongly like the idea of C++2.0 and I see no problem to make it opt-in. The only problem is that the committee is under the control of large companies which have large existing code base to maintain and gain no professional benefits (for individuals) for adopting this because it will not make their projects better in 1/2 years (since mixing semantically different code would definitely be a disaster in such huge "mountain of s****"). That's why we witnessed bunch of "conservative treatment" proposal passed while breaking but long-term-beneficial ones stuck. The progressivism of committee will eventually cause more problems, but I can't see any way to avoid this. I really hope C++ is not on the way to "die slowly".
Great! I think compilation time would also be a nice metric.
[ReSharper C++](https://marketplace.visualstudio.com/items?itemName=JetBrains.ReSharperC). It supports both Doxygen and MS XML comments, will show them in completion/quick info/parameter info and allow to quickly generate new documentation comments.
Good idea.
VOP (Value Oriented Programming) for the win!
My "favorite" C++2.0 "feature" might be "immutable by default;" *mutable* (or *override*) can be used everywhere *const* can, and *const* (and *final*) is the default. In this fictitious language, writing struct Foo { int i; }; would be the same as writing the following in C++17 struct Foo final { const int i; }; 
&gt;Personally, I strongly like the idea of C++2.0 and I see no problem to make it opt-in. Isn't that what Rust wants to be anyway?
&gt;doesn't semantically check them, which leads to a lot less code written in practice. Also makes it a hell lot harder to write AST based tools...
Thank you for this Arthur! This summarizes the problem quite succinctly. 
At this point, all you're doing is just forking the language, removing bits from it and have it link to C++. So... why not just do that?
I've never used Rust, but as far as I could defend, it has a very different set of capabilities and constraints. 
const members are rarely what you want though
Pretty much, the standard anti-OOP fare. Most of the article is extremely vague, and doesn't make many concrete points. Any article these days that doesn't actually start by defining OOP carefully, and discussing what exactly is being criticized, is basically a waste of time. Things that people have had in mind under the general OOP moniker: * Any usage of inheritance * Deep inheritance * Implementation inheritance * Encapsulation of data * Objects holding references to each other Another tip: if you are reading an article about C++ and OOP, just hit Ctrl-f and search for "invariant". If you can't find it, there's a good chance you're safe to move on. Some particular parts I found objectionable: &gt;Even though C++ is described as a [multi-paradigm programming language](https://en.wikipedia.org/wiki/C%2B%2B), the truth is that most programmers will use C++ exclusively as an Object Oriented language Citation needed? Especially if you predominantly associate OOP with heavy usage of inheritance. I would say that over-use of inheritance is down significantly. Every C++ developer I know, knows about and uses lambdas and std::function when appropriate. Everyone writes free functions regularly. Etc. &gt;I prefer simple solutions, that add the minimum amount of nodes and edges to the dependency graph of the code. Don't we all? But this article doesn't show what exact aspect of OOP is over-complicating (or even what it is). &gt;Thereâ€™s also the fact that OOP features are inherently poor performance-wise. I implemented a simple OOP hierarchy with an interface and two derived classes that override a single pure virtual function call in [Compiler Explorer](https://gcc.godbolt.org/z/1nftf-). This example code either prints â€œHello, World!â€ or not, depending on the number of arguments passed to the program. This comparison is so bad and unfair it borders on parody. OOP provides totally open ended run-time polymorphism; that is you can add new behavior to existing code without changing the original code, without even re-compiling it. Because it's so open ended, it tends to be a tough barrier for compiler optimization. The same way that totally non-OOP techniques like function pointers and std::function tend to be difficult barriers for a compiler as well. If you know based on the domain that only 2 behaviors are possible, or only N data types are possible, then indeed a bool or a variant is probably a better choice than using inheritance. &gt;Over the years, though, Iâ€™ve seen three main arguments that prevent people from giving the other side a chance: &gt; &gt;â€œGood OOP wouldnâ€™t do this.â€, â€œThis is badly designed OOP.â€, â€œThis code doesnâ€™t follow OOP principles.â€ and similar variants. Iâ€™ve heard this one when showing examples of OOP gone bad (Iâ€™ve already talked about why OOP code [invariably goes wrong](https://marccgk.github.io/blog/on-c-and-object-oriented-programming/#on-entropy-as-the-hidden-force-behind-software-development)). This is a clear case of the [No true Scotsman fallacy](https://en.wikipedia.org/wiki/No_true_Scotsman). No, it's not. Articles like this one however \*are\* a clear example of the Strawman fallacy. You don't get to tell people that are advocating using OOP, or using OOP as a tool, what their view is. This article doesn't have any code at all, but most such articles typically start with a horrible example of a class with getters and setters for every single data member, no discussion of invariants, virtual used strangely, implementation and interface inheritance mixed together, etc, and then rip it apart. I would definitely agree, most OO code written in this vein of articles, is bad code! But it doesn't show anything. As for OOP "invariably going wrong": all code goes wrong. If the requirements change more than refactoring efforts are put back into it, over time the mismatch will continue to increase. Really the question is how to write code to minimize the amount of effort and mismatch over time; this trait could be called robustness. I've yet to see even a half-decent case made that OOP techniques in C++ have no place in robust code.
I don't know about others, but I would rather write 30% less code and have it be more straightforward than have advanced tooling. Code completion works fine in D. Anything beyond that is luxury to me.
It is much more than just linking. All the compiletime capabilities and fundamental semantics would stay intact. Also, I wouldn't consider this anymore a fork than adding a new, easier to use interface to a library.
Maybe not; or maybe they're just too "hard" in C++17 and would be easier to use in C++2.0? In any case, you could write `mutable int i_;`.
This is a semantic argument. It has no real bearing on the discussion. Fine, let's say we "fork" the language, that doesn't actually address any of the points being made or the questions being asked about what features or functionality should be included in this fork. I think there is a significant audience of mainstream (non-template metaprogramming obsessed) C++ developers that the language took a bad turn at some point, and many of us are wondering at what point it took that turn and what can be done to correct it in a way that is favorable to this audience. That's fundamentally what this discussion is about. It's not about the name or how the linker works, it's more a conceptual discussion about how C++ as a language evolved to this state, where it's headed in the future, and how to restore C++ as a language for a large audience of developers who are seeing that the future of C++ is just not for them.
Yes, unfortunately, I also don't think there is a big chance for 2.0 either. They didn't even want to have a v2 library. I think companies are concerned with more than the next 1/2 years however, because most of what's happening in the committee will only have an effect on them several years from now.
So did I. Such a disappointment!
At some point you say that C++ is the only language you know. I think that you should explore a little bit other langs, even if that shows you what a lang should not do. It can give you ideas on how things are solved in other languages, and you can apply that to C++
The upcoming blog post indeed will include benchmarks, specifically from the one that quicknir linked to. The compilation time benchmarks are actually already captured in https://mpark.github.io/variant. There are many other variant libraries there already for comparison, and I've recently added `mpark-1.3.0`, so that we can see if we have regressions. `mpark` is the `master` branch, and `mpark-dev` is the `dev` branch where we perform experiments.
Aw. Sorry about the miscommunication here. In retrospect I should've just kept the commit message "Replaced the visitation mechanism to be switch-based." 
But it *is* a fork, IMO. You're not just adding a new interface to a library, but changing some fundamental semantics for how the library used to work. It's not backwards compatible. You can't compile old code in the new dialect, as there are going to be significant breaking changes to deal with (not all of which are compile-time errors). Someone working on the code will by necessity need to know which "dialect" the language the file is written in before they can work with it. It's a fork of the language, plain and simple.
The author here. This suggests that I cherry picked examples to make my point. I did not. There were no samples in Checked that I saw that did not return. You'll note that I went out of my way to include an example in which D is superior - `split_view`. Whether or not the examples are shorter in D is besides the point - the argument was that if constexpr is broken and cannot even solve this problem without a redesign. The fact that I can line-for-line reproduce the solution suggests to me that this is not the case. The notion that if constexpr is "utterly useless" is silly and reductive and needs to stop. But if you have examples demonstrating good code that you can write in D using scope-less static if, I would like to see them.
Regards to documentation... part of it is my being lazy, but I also thought "MPark.Variant is an implementation of **C++17** `std::variant` for **C++11**/**14**/**17**." and a link to [https://en.cppreference.com/w/cpp/utility/variant](https://en.cppreference.com/w/cpp/utility/variant) would be sufficient ðŸ˜•
I say no such thing, and it is not.
I think pretty much all the examples have the same number or lines of code in C++ as they did in D. I think only cases where it's not a straight rewrite are the member initialization case (which is clearly noted in the post) and the constructor case (which I split in two because it's more understandable to me that way - and would actually obviate the need for the static if in the body, so evens out). So the D code isn't shorter. The void/non-void case is not a good example of a motivating case of scope less if because it can be solved by (a) making void a real type or (b) wrapping void up in a different type earlier - both of which obviate the need for an if at all, which is better on the readability front. And you can implement (b) in C++11 without much effort.
It is only a fork if both versions continue to get updates, otherwise it is a breaking change, with an easy migration path. What is being proposed here (as I understand it) is a way to say that some of your code uses the old syntax/semantics and some of it uses the new, allowing the language to fix things that are currently problems at the core of the language without breaking all code that currently exists (because you could compile parts of your code with c++98/11/14/17/etc. and other parts with this mythical c++ 2.0.
I agree with the main message of the article that there is a way to do these thing in C++ as well but while I was reading the C++ code I found myself looking back at the D code to get an idea what the C++ code is supposed to achieve. Which is a bit surprising considering that I have never used D but have been programming in C++ since 1993 and thought I was reasonable proficient with C++ 11/14 by now.
So the committee introduced a new keyword and right off the bat assigned two meanings to it, making it ambiguous and hard to understand. It seems no lessons were learned from noexpect(noexcept(...)).
So you consider every new version of a library a fork? I want this to continue within the ISO standardization process. It would be a fork if I would write my own standards document. And just in case you overreacted it: Old code would continue to compile. You'd have to explicitly opt in into the new syntax.
With modules-ts you need none of this cruft. You can `export` classes without exposing their guts.
If you are referring to: &gt; I have written 0 lines of â€œanother languageâ€ in my life The quotes are important. IIRC, Andrei Alexandrescu never mentioned D by name during his talk, but used the term, "another language". u/sphere991 is using Andrei's terminology. Think of "another language" as a proper noun.
Using Range V3 library is a sure way to make your project a technical debt in the future if you were working on a project that is expected to be used in production for decades. I'm not whining for myself. I'm a textbook writer. I can even use features that hasn't been adopted to the standard since I don't need to compile and execute my code. In that sense, Range is available for me. But for the majority of real world projects, Range is not available now.
Whenever I read something like this, I conclude that I must be entirely confused by what OOP is. That, or the author is just attacking a strawman. I am also very confused as to why this author believes that his example is actually representative of OOP design. Presumably, if this is his mindset, then if he were writing a procedural equivalent, he would assign a function pointer to a heap-allocated variable based on argc, and call the result.
This is a really good post. I am (was?) in the camp of people who think "requires requires" is completely stupid and should've never made it into the language. No explanation, however good it is, can explain away the stupidness of such a construct. However this is actually the first post that I read that really kind of convinces me that maybe it's okay or at least there are ways to NEVER have to write it, and those ways are actually always better than writing "requires requires" in the first place. So at this point I can get over the "requires requires". Thanks for the excellent and easy-to-understand post. (Small bikeshed - the word "incrable" doesn't exist, does it? I'd say "incrementable"?)
That discards the current usage of `mutable`, though, which is arguably pretty important despite its relative rarity.
I went in a slightly different direction - I'm working on a new language that compiles to C++, can use most C++ libraries, including STL with minimal user effort, has similar syntax to C++ and most of the features that you suggest.
Its proponents have claimed that it has basically the same principles ("leave no room for a lower-level language") but in practice, it's a lot farther from that than C++, and it seems to be a lower priority than safety. It also still eschews class inheritance and they don't seem to think it's important, which is probably not what most C++ developers think of for "C++ 2.0".
pImpl is very useful in many cases such as a stable ABI or polymorphic functionality, but I personally believe code should not be redesigned or restructured purely for faster compile times \**unless* it is generated code such as templates or constexpr classes/functions. Maybe I'm wrong...
&gt; Personally, I strongly like the idea of C++2.0 and I see no problem to make it opt-in. That's D 
&gt; const members are rarely what you want though This statement is high on my list of c++ advice that makes no sense. I want const almost *all the time*. The only reason the core guidelines say not to use const members is because it creates a throwing move, which is just an implementation detail of broken compilers.
What about compile times? That's the first thing that popped in my mind after the recent rants about "modern C++". Truth be told, compile time is the penalty paid by the programmes hundred times a day, scaled to the size of the codebase (factored only by its modularity). Maybe we could benchmark also the Pythagorean triples, the example chosen to showcase C++20 range-v3 library (Aras has written already a couple of implementations here https://aras-p.info/blog/2018/12/28/Modern-C-Lamentations/).
First of all let me apologize for my condescending tone. I wasn't familiar with the source code of Checked and wrongly assumed that it would have conditional inclusion of scoped symbols. &gt;Whether or not the examples are shorter in D is besides the point True, but I believe it is related, because at the end of the day we're trying to reduce unneccessary code complexity. &gt;The notion that if constexpr is "utterly useless" is silly and reductive and needs to stop. &gt; &gt;But if you have examples demonstrating good code that you can write in D using scope-less static if, I would like to see them. How about something like this (from actual code): ... static if (isScope!Node) { scope_ = new Scope(arg, scope_); scope (exit) { scope_ = scope_.parent; } } ... Also I'm not fully familiarized with the new concepts features yet, how would you from inside a function check for a regular member function on a template parameter value and call it, without having the compiler fail if it doesn't exist. I tried replicating your samples on wandbox, but they don't seem to work with gcc9 and -fconcepts.
OK, but how does one achieve this exactly? PS: I'm not even sure if OP is referring to a desktop application or something that sits on a server, but feel free to answer for either.
&gt; [OP] My only issues with the CoC is how vague it truly is. In my opinion, professionalism is another form of oppression. It is used to other, reduce the work of, and lambast those who donâ€™t fit within one persons idealogy of what professional entails. You will find it changes from industry to industry and person to person. It is entirely subjective. **Some people might not find it unprofessional to constantly ask someone about the status of their genitals over the C++ slack and receive no punishment from the administrators, others would find that to be extremely unprofessional.** ^ Let's include that entire paragraph from the blog post, plus highlighting the main take-away, so we can stop with this context manipulation. &gt; but saying that professionalism oppresses individualism is like saying rules oppress my freedom to do whatever I want To clarify, OP was decrying an imbalance of the application of "professionalism" (see my highlight) with social/political intent, not necessarily the concept itself. Granted, it *was* worded poorly imo. &gt; If someone likes "sharing the state of their genitalia" on slack they're most likely violating the contract of professionalism That's not what the paragraph was talking about at all; you're making an incredible stretch here- inventing statements in a context that makes it appear as if OP claimed that- to be wholly dishonest. **To the topic at hand:** what's your opinion on OP's problem point relative to the concept of professionalism? Namely about the character making light of a sensitive topic (regardless of where you stand on it) by imitating and making joke references to the death of Eric Garner?
This has nothing to do with throwing move. You are preventing your type from ever being assigned. In a language where we value value semantics and try to minimize dynamic allocation, that is a huge disadvantage, for little gain. You couldn't even do things like swap or sort. You certainly want to make most of your variables const, but just most not all.
&gt; You certainly want to make most of your variables const &gt;const members are rarely what you want though Those statements are contradictory. 
Pretty sure they block PIA as well. Pretty silly. 
Sounds interesting. Drop me a note when the us something to try out. 
If you are actually writing software with the right mentality then there should not be a difference in the end result when comparing "\_\_\_\_ Oriented Code" styles to each other. The purpose of C++ is to take your abstract representation and turn it into a concrete set of instructions to get a job done. If you are using an abstraction for syntax/aesthetic reasons then you better understand the common underlying mechanisms used by said abstraction, otherwise you end up doing things you did not intend to do without even realizing it. The reality is that there is no "one true way", do what works well and is easy to understand.
He meant locals and globals should be const whenever possible. 
XML comments do indeed work (with per-parameter comments showing up as you type out a function call) in VS C++, but they have very poor support. They only show up if the comment is in the same file as the one you're working in. 
I think the best solution would be at the hardware level, like user-level CPU interrupt that you can set handlers for. I don't know a lot about assembly or existing ISAs maybe that already is a thing.
There is a VS extension called CPPTripleSlash that auto-generates comments the same way C# does. 
What this post imho shows is that - as always - you can achieve everything in c++ somehow, it is just more complex and difficult than in other languages. Not sure if that is actually a good rebuttal of Alexe's talk. 
True, he didn't make that verbatim statement. I am on mobile and couldn't bother to look up the exact quote. Although It doesn't make much difference to me, it's inappropriate behaviour either way and does not change the bottom line of what I said in any way or form. My opinion: I don't know who Eric Garner is and I honestly don't care. If it's really as much of a sensitive topic as some claim it to be then the speaker should probably give a public statement on how his "joke" is supposed to be interpreted. You know, some people have dark humor, some people struggle to estimate the gravity of their jokes and - true - some intentionally try to hurt or offend others. Needless to say that all three cases can be considered unprofessional behavior. 
What does that code fragment do?
No, for me it's a practical argument. I do recognize that there is some unsettling within the community, and I also do not like the way C++ seems to be headed. To me, std:: has become a cancerous growth as people try to shoehorn features into the library that should become part of the language itself ( and by that, I mean any code that should build without any #include anywhere ). It feels it's going to come to a point where "using namespace std;" will be recommended... Hell, I'm even part of the "old school" as I like to use raw pointers (because I know what I'm doing), manage memory on my own when I feel like it, and shun auto ( if I wanted auto crap, I'd code in Python ). Yet at the same time, others want those old features I cherish removed and backward compatibility broken because they don't look "modern" enough. We're at a point where I see a schism happening very soon, as different people try to steer away from the comitee, and to that I say: just fork. Maybe this fork will prevail and take over at this point, and what we call C++ will become a thing of the past. Or maybe all the ultra-modern stuff will join it and C++ will move back to something simpler, I don't know. It's just that my guts tell me something is going to happen without the comitee.
Just *try* running a website without blocking Tor, Russia, and China. I'll wait.
&gt;Whether or not the examples are shorter in D is besides the point But this is for me a major argument of him during his talk. Short code contains less bugs, thus we should strive for shorter code. This is no argument for or against fixing if constexpr, if that it's broken at all. Just a point I think, you didn't pick up in your arguments and I thought while scrolling through long C++ code ;) Anyway, I liked the way the code was "translated" to C++. Helped me rethink something's. Thanks!
I used D myself for a mini-project. The feeling I got from it is that, yes, C++ can do most of all, but in D it was more convenient to do some of the stuff. Things that in C++ usually take me a while to do or cannot be done easily: 1. static foreach (have to on Boost.Hana or similar to keep up to speed and not roll my own impl) 2. I could generate code with opDispatch without explicitly listing every 3. static if could help me generate the class layout (yes, I can use std::conditional_t and it works, but is quite more dirty if you have more than one condition) 4. interface/class/struct differentiation save some boilerplate, though I think the future is something more like Go interfaces or Rust traits honestly. All in all, I found D to be the convenient version of C++ :) I stick to C++ because of the huge amount of libraries, I know it well and it is very well supported, but I must say that the effort done by D guys for interoperability wiht *C++ also* is worth a mention. 
It would be if they didn't have GC by default.
&gt; I like to use raw pointers (because I know what I'm doing) No, you don't
It really isn't. When ranges are available in the standard, range-v3 would presumably call them when possible. There's no reason to switch away.
&gt; No, you don't Mind your own business.
lmao okay
if constexpr can only be used basically in templates in C++. That is much more restrictive than static if in D. Yes, true, in C++ we can do most of that. Something similar has happened with foreach and static foreach in D vs C++. We do know expanding something at compile-time and traversing at run-time are different things (in foreach). We also know that static if to conditionally compile members is also different from static if inside a branch of code in a function: yet conceptually they are the same thing: conditionally compile. So they should have the same syntax *or* at least a very similar one if someone is worried about code generation. Why? Because the conceptual model in D saves me time when coding. I do not care they are not the same thing exactly. But if someone cares, we should adopt similar syntax with some little differentiation, but not omit the feature. That is why things like Boost.Hana exist, because you cannot just say: gonna traverse this tuple. In D, you do: ``` static foreach (e; myTuple) { } ``` and you do not have to think anymore. In C++, go find a library or roll your own, and I do *not* recommend you to roll your own if you want a general solution.
I could be wrong but from what I understand one of the major gripes with modern c++ is debug performance in the gamedev arena, wouldn't using optimizations hide any 'debug specific' cost of abstractions of modern vs c style?
You should read the purpose of the projects. I did not do a benchmarking of compile-times because someone is worried or of debug builds because it sucks for game dev. All of those are valid points, but the purpose is to compare the abstraction penalty of optimized C++ code compare to C-style code. I will keep it focused on that area for now :) What you are suggesting could be an entirely different project and research.
This project is not related to those lamentation, though I agree about the compile-times. I have to keep it focused for now. When I have something bigger or more consistent, maybe I can think of how to expose some of those pain points :)
Fair point somewhat, but the set of things that you can do with ranges is not just looping. Maybe for that I would stick to C-style. But what about: ``` for (auto &amp; [_, v] : container | v::filter(...) | v::transform(...) | take(5)) ``` Writing that in C is already more difficult. Ranges is basically a query language somewhat.
I understand and no worries. I am just thinking someone would run this and come to the conclusion of oh hey modern c++ is basically the same or better as c style, but not really understand what drives people to write c-style to begin with which likely is not the general abstraction price price. The more I think about this the more I think it would be nice to have a set like this for debug runtime perf comparisons, oh well maybe if I get bored. Good work tho.
&gt; We also know that static if to conditionally compile members is also different from static if inside a branch of code in a function: yet conceptually they are the same thing: conditionally compile. Just pointing this out here: if constexpr doesn't technically do conditional compilation, it still verifies if a function exists, etc. but only forces down one path, the only thing in C++ that can do conditional compilation at this point in time is the pre-processor. Sorry, I'm being overly semantic, but a minor annoyance of mine.
I use a simple idiom to reduce dependencies between header files in my project that I call `Heap&lt;T&gt;`, which puts a member variable behind a `unique_ptr`, for example // class_a.h class B; // "class_b.h" doesn't need to be included here class A { A(); Heap&lt;B&gt; b; }; // class_a.cpp #include "class_b.h" // ... `Heap&lt;T&gt;` behaves much like `unique_ptr` except that it has a copy constructor that copies `T`. I believe that if I find the cost too high at some point, I can easily change the implementation of `Heap&lt;T&gt;` to have a direct `T` member and will only have to add all missing #include directives. One could even use two variants at once for debug and release builds, just juggling the #includes would be a bit annoying.
What happens? I run a website without blocking them, but it's small. Minimal incidents so far.
That's a problem with the language specification. If you logically want things to be const, but some optimization details of the existing compilers (like swap or sort) are preventing you from doing that efficiently, the answer isn't "make the code less descriptive of what it is supposed to intend."
I wanna see that :D I think it is very compelling to have a 100% C++-compatible thing that is cleaner. 
Does it need to be a member function? template&lt;typename T, typename = std::enable_if_t&lt;std::is_enum_v&lt;T&gt;&gt;&gt; constexpr auto as_underlying (T e) noexcept { return static_cast&lt;std::underlying_type_t&lt;T&gt;&gt;(e); }
I dislike rust "classes". If you can call them that. Rust is a language that I want to like, but it makes it too difficult to do simple things, while abstracting what is really happening. People like to say it's a systems programming language, but I find it hard for it to live up to that when it hides the entire system from you.
Do you need any GPU acceleration stuff from OpenCV? Dealing with any sort of GPU/GUI stuff from Docker may add some complexity. Past that, put your binary and the libraries and data that it depends on into the Docker image. voila. It doesn't necessarily involve any magic. There's no "C++" Docker base image because you are just compiling to native code. You probably need to include libc++/libstdc++ in the image, but that's not even guaranteed if you are doing something intentionally minimal. 
I meant in the language itself (though it would be great if enum classes could have member functions). However, your suggestion works. A question, since I am getting started in TMP: template&lt;typename T, typename = std::enable_if_t&lt;std::is_enum_v&lt;T&gt;&gt;&gt; constexpr auto as_underlying(T e) noexcept what happens if someone does: enum class availVals : int {one}; as_underlying&lt;availVals,float&gt;(availVals::one); Does this fail to compile? I.e., does having the second template parameter without a name (e.g., T is the name for the first one) mean that the caller cannot specify something for it?
Can't templates do conditional compilation?
The second template parameter is only there for SFINAE purposes â€“ explicitly passing an argument will bypass that SFINAE, but your example would still be fine since you're still passing in an enum.
&gt; That discards the current usage of `mutable` The point wasn't to accurately describe some new C++-like language; it was to illustrate how things could be fairly easily more `const` by default.
Damn, I had written some code where I had to give the caller the option to overrule the default template parameters and then prevent the caller from doing it by inserting static\_asserts. I was I could use your example to remove that necessity.
It's not true conditional compilation, but it comes damned close, it can choose based on pre-existing conditions or pass in parameters, but it still checks syntax and doesn't allow for you to say, use windows functions or posix functions depending on the platform...
**Company**: RobotWits **Type**: Full Time **Description**: RobotWits is a small robotics company specializing in the development of robust software systems for prediction, planning, and decision making for autonomous (self-driving) vehicles. RobotWits is led by a CMU professor in Robotics and has a highly talented team of roboticists and programmers. We are currently seeking an experienced software engineer passionate about developing and deploying software for self-driving vehicles. *Desired Skills* 1. Degree in Computer Science or Robotics, or equivalent working experience; higher degree such as MS/ Ph.D. is a plus 2. Proficiency in C/C++ 3. Excellent analytical skills and problem-solving ability 4. 3-7 years of programming experience with strong software development skills 5. Familiarity with Robot Operating System (ROS) 6. Experience implementing planning algorithms such as A-star 7. Familiarity with machine learning techniques such as Bayesian Regression, Ensemble learning methods, boosting, etc *Responsibilities* 1. Research, develop, implement and test state-of-the-art algorithms for automated decision making, planning, and prediction 2. Travel occasionally to clients and perform demonstrations of the technology on real vehicles **Location**: Pittsburgh, PA **Remote**: No **Visa Sponsorship**: Yes **Contact:** If interested, email at mike AT robotwits.com . Please include '[Reddit]' in the subject when emailing your profile. 
lmao this guy and his pumpkins
I feel like if the `requires` clause were given an expression, it should just treat it as an expression to evaluate and then use the boolean result... which would *also* eliminate `requires requires`. Or use a more meaningful keyword for the expression form, such as `expressable` or `can`. Or `co_requires`.
It's not compatible in the same sense as C++ is with C. You can just make bindings very easily and even inline C++ code. You can find some examples here: https://github.com/miki151/zenon
Focusing on compile times is a huge money saver in the long run, I definitely focus on making sure compile times are as low as can be. 
You can find the compiler here: https://github.com/miki151/zenon It's not intended to be used by others at the moment, it's more of a personal playground.
I have done it for no other reason than to keep a bunch of macros from polluting the global namespace.
Thanks for your response. The 100+ lines code means uicode.cpp, it's the code for all GUI you see. The rendering code come from GuiLite, the UI engine for this demo. In order to package UI code for more platform, we create very simple platform-specific APP for Windows MFC, STM32-keil in this demo Just like HostMonitor(another demo), we also can package UI code on Android, Linux, iOS, Mac. So I call GuiLite "cross-platform".
So, how many LOC would be called LITE?
What i mean is that you probably shouldn't trade runtime perf for compile-time.
True. you are right, but you got my point: discards the code to execute I meant :D
Is the second to last example a typo? is_nothrow_incrable_v vs is_incrable_v
You can have thousands of conclusions: - C++ is very fast... - but is slow to compile... - but my application is small enough... - there is some more code size in using these libs... - but for me it is not a problem... - but for me it is!!! (I am using microcontrollers!) You get it. I cannot do tests for everyone in every scenario. My point is C-style vs C++ run-time performance. And for now it is all there is to it. If you want to extract other conclusions, maybe there are better places to look at, for sure, where they test other areas of C++. It is very difficult that a tool replaces another for absolutely all use cases. C++ is better than C most of the time, but if you look hard enough, in practical terms there could be the need for C (for example some toolchains for embedded as of today). 
`value_ptr`? `heap_opt`? A problem with `value_ptr` (or `Heap`) is that move construction must either throw (as you have to allocate in the old element), they have to be maybe-empty (if moved-from), or every other operation must possibly throw (as it conditionally creates the `T` when used when logically empty). A `heap_opt` -- an optional that lives on the heap -- means you constantly have to check for empty, but at least avoids that insanity.
Your RobinHashTable example conveniently omitted all the alignas annotations. It's not the same thing that was on Andrei's slides.
I went the "empty after move" route, I don't think it causes me any problems. 
Kinda like TypeScript for C++, that's pretty cool
&gt;If you contribute to open source you will be forced to use whatever they are using Not necessarily &amp;#x200B;
CFront++?
My example did not conveniently omit anything. I would appreciate if people stopped impugning the honesty of the comparison. Or at least offer an example instead of just calling me dishonest. The RobinHashTable example had two, separate, conditional type introductions. The way we would treat them in C++ looks the same in both cases. It's just that the `CellIdx` example is shorter and actually more favorable to D so I used it. That does not imply that the `KV` example is not doable: static constexpr auto get_kv() { if constexpr (sizeof(K) % 8 &lt; 7) { struct alignas(8) KV { K k; uint8_t cellData; alignas(8) V v; }; return type&lt;KV&gt;; } else { struct alignas(8) KV { K k; alignas(8) V v; uint8_t cellData; }; return type&lt;KV&gt;; } } using KV = typename decltype(get_kv())::type; Yes, this is 3 lines (out of 18) longer than the D example. And I'm also not questioning that this is more complex than not having to add that extra indirection due to scoping. But the point is that this is, in fact, doable in C++ with minimal gymnastics. I don't know what metaclasses have to do with the discussion.
-1: modules is already going to have an uphill adoption; this would be supplying a stick with a stick.
So I'm not gonna pretend to be an expert or to be particularly up to date on C++2a, but the question I'm forced to ask is why does checking whether an expression is well-formed use the keyword `requires`? That seems like an *extremely* non-intuitive word choice. I'm not seeing the logic here, besides the obvious point that adding new keywords tends to be dangerous in a language as old as C++. Seems like `requires wellformed(...)` or something would be perfectly understandable without needing a blog post to explain it
efficient moving actually does require mutation though...
&gt;And on a related note, when Boost libraries achieve standardization, why do they remain in Boost? Probably for the opposite problem, if you want to use Boost but not the STL.
If I could wave a magic wand and change something about C++, I wouldn't require east const, but do something more like this: @ const type_t type; //pointer to const type_t &amp; const type_t type; //reference to const type_t That way it reads left-to-right. 
Moreover, standard facilities evolution can occur in boost. Consider monadic interfaces to future and optional.
I think `requires` specifically has been reserved for a while in some common implementations (for example GCC). I havenâ€™t looked specifically at the spec, but it may also be like `final`, where youâ€™re free to use it as an identifier in contexts where itâ€™s clearly not a keyword.
I came back into some C++ programming when C++11 appeared on the scene and I very quickly discovered this technique on my own. I wanted something that could be used right on the spot to deal with adhoc resource cleanup situations much like the `defer` statement in Golang programming. The C++11 unique smart pointer, the fact that it can be customized with a cleanup callback, that C++11 introduced lambdas, that a lambda can be declared locally as `auto`, and that `decltype()` enables taking the type of locally declared lambdas - that provided all the necessary ingredients. My 8000 line C++11 project is very heavily dealing with Java JNI programming and this proved to be just the right medicine for dealing with managing the JNI objects on the C++ side of things. It would have been a really big chore to have applied RAII to all that with pre C++11.
I don't think OOP is a problem: the overuse of it can be a problem. Sometimes I opt for a more value oriented design, but the API of the code look pretty much like object oriented.
&gt; Standard libraries can't have dependencies on Boost, after all. It's the interfaces that are standardized, not the implementation. Besides Boost has to be built on some ground, such as the MPL and so on. &gt; And on a related note, when Boost libraries achieve standardization, why do they remain in Boost? You don't want to break existing code that depends on Boost's version. 
THE most reliable, ultra bullet proof file watching service I ever wrote (for Linux file systems) is one that's been in production use for over 2 years, and written in Golang taking advantage of Go channels and the Go `select` statement inside an infinite `for` loop idiom. (I wrote my own golang wrapper over the Linux SYS call mechanism to interact with `inotify` because the off-the-shelf Go library for file event notification was inadequate and not really a very good design - but the Java class for file system events is also inadequate.) The infinite `for` loop, `select` statement, and go channels are just awesome for these kinds of scenarios (where different channels are feeding in different kinds of events from a variety of sources - with the ability to have a channel to communicate back to the event producer - this can be file system events, POSIX signals, periodic timer events, etc., etc.). Channels can be typed (usually are) and support different kinds of semantics - and go functions can have as many channel arguments as needed.
Those big companies are literally inventing their own languages to be able to write better software, having large existing codebase is hardly a sticking point here.
I sort of wish all programming languages would get more keys on the keyboard to work with. It'd be super nice if we had the equivalent of {} but that did NOT introduce scope, and could then write non-scope-changing `if`, `while`, `for`, etc. statements with it -- including with `if constexpr`. 
Actually we are on the same point. People/companies prefer inventing their own things over going through the tedious proposal stages. Especially when it's impossible to get some features that are extremely useful in field A but disfavored in field B passed in a committee with members from both A and B. Moreover, for individuals (re)inventing wheels is rewarded much better in office space than maintaining old stuffs. That's why we witnessed the paradox over and over again that people keep creating new languages and abandoning old languages, yet refusing to make radical changes to existing ones.
Thank you for taking the time to respond and I apologize for diminishing your post. I agree that `if constexpr` should not be changed, but that's more because it already is what it is rather than an objective measure of choosing the best thing. 5/18 is still 27%, though honestly line count is not a big deal to me (I can add another five lines to your example by changing formatting! :P). What makes me grumpy is that even the minimal gymnastics of type functions in C++ like what you wrote in your reply to me are relatively arcane despite all the machinery added recently to make them much simpler to write. You acknowledged this in your article. Yes, you learn the idiom and it's fine. But so many of C++'s idioms are...let's say "fairly acrobatic". It would have been nice to take `static if` as an opportunity avoid more of that. For my point about metaclasses: `static if` and metaclasses are not the same thing, but `static if` is equivalent to the code injection operators that were demoed for metaclasses, and in the API style where you add member definitions you can achieve the same effect procedurally. That's how they're related. I don't think Andrei gave metaclasses a fair shake by dismissing them as a tool for automating boilerplate. It's true that automating boilerplate is a large benefit of metaclasses, but the same can be said for `static if` and such a characterization does a disservice to both those features.
Ironically, D is not less fragmented than C++ right now.
Oh jeez
I wholeheartedly agree! Also, with respect to backwards-compatibility: The people who want backwards-compatibility are -- for what I suspect (but don't have the data to back it up) -- the same people who are conservative enough not to upgrade their toolchain anyways... And even if they do upgrade their toolchain, they could still use an --std=c++03, if this is really what they want. Have their been any market studies regarding the actual need and benefit of backward-compatibility concerns? We should have plenty of data by now, given the 3-year release cycle. &amp;#x200B;
Thx for mentioning. But the slashes are only more manual work to do... The problem lies in the xml itself. But I will try this extension anyways. 
Nah, `requires` is an actual keyword.
I fear that such market studies would be geared towards authors prejudices. The problem is always what **weight** is given to whatever factors are at play. Say, the extreme conservatism of an ~~old~~well-established project where a small change in behavior has wide-reaching consequences. Or the disinterest for a change in any unused feature of a new project (I am presuming a new project will have used less older language/stdlib features, I think that's fair to do).
Wouldn't the private members still be visible outside of the module, indirectly via sizeof if nothing else? So pimlp would still be needed for ABI compatibility.
`s/an offensive joke/arbitrary vulgarity/g` to fix the ambiguity.
As you grow in life you learn how to write customs allocators, same way you learn how to turn off GC when required because both seem possible.
As [the if constexpr paper](https://wg21.link/p0128) noted, scopeless token-soup "static if" is "fundamentally incompatible with the template model used by at least two major implementations". Features with that kind of cost had better be the best thing since sliced bread, which this one is not.
Brrrrrrrr
Bring back volatile? 
Another reason for keeping it in Boost is for older compiler support for those that have to maintain software on legacy systems and donâ€™t get fancy new standardized features. 
Every other language has addressed the packaging issue. Including libraries is a fucking pain in the ass. I'm trying to do work with Beast and catch and Linux right now, and I spend more time fighting with the tooling than I do actually writing code. As much as I want to continue writing C++, I'm not sure it's worth my time. Vert.x and Groovy are looking splendid from my point of view. It's frustrating. I can understand not piling on a bunch of libraries into the core language - great. But give me an easy way to expose and include libraries. 
&gt; lmao okay mr. hardcore true programmer As I learned in arduino-land - there is a lot of unspecified cruft when using the Smart shit in the standard. Sometimes raw pointers and self-managed memory make sense, especially in embedded. 
The requirement that the [an] `else` condition of `if constexpr` needs to compile as well (for no use, if not taken) I feel is a burden.
that was my expectation. If it was like C, then all the backwards-compatible ruin would come with it :)
Mine is by far sane initialization, especially not hijacking with {} and initializer_list.
It sets the scope\_ data member to a new value. Then at the end of the function it restores the previous value to the data member. (`scope(exit) {...}` is a scope guard)
Well, could start with these changes after the current module proposal has landed in the standard. That said, I doubt it will ever happen. Probably better to move on the newer languages for bigger changes and stick to C++ for maintenance of existing code.
He literally said nothing other than he wants to dockerize it and that he has two lib dependencies. Nothing implies if he wants to deploy to server or to the public.
I'm not saying this should be a feature of c++20 modules (impossible anyways) and as I said: This will not prevent old style code being written inside modules. It would be an opt in, that gets possible thanks to modules. 
Shouldn't you check the version of Boost you're compiling against into your revision control system?
He used the word releasing in the title.
What if you want to use new libraries included in newer version of Boost however the old libraries are removed?
Boost libraries are depending on the stl anyway
I think it's more like: why have if constexpr when we could have the unscoped version which does all that *and more*? Nobody is forced to use it unscoped, it's just a possibility. You can keep using it scoped or do so the stuff shown in the article still, no problem. It's similar to the debate about auto: an additional way to do things without taking away any of the existing.
Imho that should be new library versions then that build as much as possible on the new standard facilities.
You are right, didn't read the title.
- Just because they are adopted in the standard doesn't mean they are available yet in actual toolchains - Even when new versions of a toolchain already provide thos standardized types, most people cannot immediately use them in production - Even when they are available in production, the stl facilitates might not have the exact same functionality as the boost version. All that being said: I really think by know, boost libraries should stop depending on other libraries whose functionality is available in c++11. That would make some of them much more lightweight (in terms of dependencies) and probably faster to compile.
Using new tool (say, C+=2) to compile the new code and having a separate dialect just to get rid of typedef (which is not used in modern c++ anyway) and C arrays in the arguments (which are not used in modern C++ anyway)? No thanks. Adding size to C arrays, whaaat? How are you going to have binary compatibility then? Or you will still have the old style arrays in your dialect, just to be able to link with C/C++? Than itâ€™s not even better than current situation. Honestly, I donâ€™t get all this histeria about new standard. The language evolves, and long term support of old syntax is a feature, not something to nag about. If C++ seems too complex to you, well, thatâ€™s the price you have to pay to be able to use all its huge codebase. You can switch to any other language anytime.
Thing is: Lots of what MPL offers is available in newer standards anyway - either in library or in language (or they could move to mp11 at least).
I think one problem in this group, at least, is that it seems to attract mostly people who write really clever libraries that use lots and lots of template magic, and not a lot of people that actually write applications. That group has to deal with release schedules, and cannot sit down and spend six months doing nothing but upgrading millions of lines of code. Not only is there no benefit for them in it, but it actively costs them since the market is moving on while they are standing still. The often-heard argument that "they can stay on an old compiler" is false. Soon enough those old compilers stop being supported, and then what? Rewrite from scratch at massive cost? Forget about supporting new platforms or using new libraries and stay on an old and increasingly obsolete system? The prime selling point of C++ is not performance, although that is important. It is backwards compatibility: the guarantee that your investment in code does not become worthless overnight because some dude on the internet had a brainwave.
No. Vendoring dependencies isn't really the C++ way, particularly for large libraries like Boost. The point of having one big collection is that you can just tell people they need Boost, and you have access to the whole thing.
Disagree on the point on bin compatibilities. Most modern languages do not guarantee bin compatibilities on all language features because that would be a great burden on the evolvement(just count how many useful proposals get rejected because of breaking abi). Instead, users should only be allowed to export things through a well-designed export syntax that restrict features to a minimal subset. In a word, C compatibility shouldn't be the default - better be opt-in, while opt-out is also OK
So `type&lt;T&gt;` is a variable template with a nested member type `type? It was also used but not defined in your blog, or did I miss something?
&gt; just to get rid of typedef (which is not used in modern c++ anyway) and C arrays in the arguments (which are not used in modern C++ anyway)? No thanks. F for reading skills. I gave you lots of examples what could be improved (and that list is absolutely not exhaustive) - array was just the example I explained in more detail and apparently you didn't even read that completely. &gt; Adding size to C arrays, whaaat? How are you going to have binary compatibility then? Why should the size information of an array be a dynamic property stored in memory? It can't be resized anyway. Just as with std::array, that information is part of the type. &gt; Or you will still have the old style arrays in your dialect, just to be able to link with C/C++? Than itâ€™s not even better than current situation. I gave you a number of reasons, why a built-in array is superior to a library solution. And non of the functionality std::array ptovides would require abi breakage when added to a native array or any information the compiler isn't already aware of. It would be a pure syntactic problem. &gt;The language evolves, and long term support of old syntax is a feature, not something to nag about. That's why I don't want to remove the old syntax &gt; If C++ seems too complex to you, well, thatâ€™s the price you have to pay to be able to use all its huge codebase. Thing is: A lot of the complexity in c++ is completely unnecessary. It doesn't add to the power of c++, it doesn't increase the number of things you can do. It just means that code is harder to read and there are more special /corner cases to be aware of. I'm trying to find a way to be able to use existing c++ code and all it's compiletime properties but still have a cleaner language at some point. 
You do not need to poll in the loop. For example, the linux system call `select` will put the calling thread in an idle state until, e.g. data arrives on a socket. After calling `select` your thread will not execute code until an event happens. When data arrives on the ethernet port, the network hardware will raise a CPU interrupt. The OS will examine its internal data structures and see that your thread is waiting on events from that socket. It will then change the scheduler state of your thread from "waiting for I/O" to "ready". Then the scheduler will eventually run your thread, and `select` will return with the appropriate result. The whole thing is truly event driven. The origin event is a certain electronic signal on the ethernet port.
Okay, donâ€™t blame my reading skills if you modify your initial post : ) There ARE things in c++ syntax which can be improved breaking the reverse compatibility, but in the same time itâ€™s syntax is one of its features. But why use c++ anyway? You have Rust, for example.. As for the array: I misunderstood you. But it makes even less sense this way! You want to add some kind of new syntax to replace std::array. But no one even uses std::array anymore! I mean, there is 1% of cases when itâ€™s handy of course, but to make major syntax changes because of it..?
I didn't modify my original post. 
Instead of C++2.0, it should be C+=2
This. C++ 2.0 would be just added complexity if I still have to know how C++ 1.x works; and if I don't, then the whole point of coding in C++ (not relying on a lower-level language) disappears.
Well, than Iâ€™m sorry.
Changing/migrating code incurs developer time which increases cost and subjects to new bugs. That's why ABI/API stability is important: you don't want your code broken. I used MPL just as an example and it applies to all libraries.
Then you upgrade your compiler.
Boost comes out of the box with utilities to help you do this, _explicitly because_ it is not a large library, but rather a collection of libraries.
_This is why_ you would check your dependencies into version control â€“ include the new libraries you use and the old libraries you use. If you're using the monolithic Boost distributionl this isn't an option.
Boost is 100% volunteer-based â€“ feel free to submit PRs using as much as possible on the new standard facilities, as I'm sure they'd be most welcome.
If I could wave a magic wand, I would make const modify the thing directly on its right: const char* p; // non-const pointer to const char char const* p; // const pointer to non-const char
Note you cannot include two versions of the same library in the same project, which violates ODR. You may argue that you use different libraries from different versions, but chances are they may share a same dependency.
Yeah, use the newer dependency and upgrade the old library if something broke. Again, the entire point is that this is why you have it in your own source control.
Why force your customer to change their code when you can just keep the old library, which actually saves time for both of you.
It's not the same. A transpiler can benefit from all the tooling of the target language, a fork does not. Of course native tooling would be better, but in the meantime... 
Literally no one mentioned changing code.
IMO the standard committee really should start seperating queries and non-queries. noexcept-expression would be much more intuitive if it was is_noexcept-expression instead. Same with requires-expression which should be something like is_wellformed-expression. The learning-curve for these features is much steeper when the same keyword is used for multiple purposes instead of using actually descriptive names when applicable.
\&gt; we are not impressed with ranges and despite the monumental effort I'm sure Eric Niebler put into it, it's just not the kind of program anyone of us ever would consider writing The poor Eric Niebler did himself a lot of wrong by choosing a very complicated example. Ranges are actually very easy and comfortable to use. Compare for instance `for (auto i : vec | reverse) do_sthg_with(i);` with `std::for_each(vec.rbegin(), vec.rend(), [&amp;some_context](auto i) { do_sthg_with(i); });` \- or with `for (int x = vec.size() - 1; x &gt;= 0; --x) do_sthg_with(vec[x]);` for that matter, which is prone to bug (`vec.size()` is not `int`, `0` is not `std::vector&lt;T&gt;::size_type`, out of bond access is just a keystroke away, etc.). The `iota` story is in the same vein, as the range library offers `ints`: `for (auto index : ints(0, 20)) // ...`. I'm pretty sure it's a kind of code you'll find yourself writing once the polemic has died down.
c++20 looks so foreign and out of touch that I believe it will mark the end of C++ and a fork
I agree. To achieve something similar, methods should probably be `const` by default. Rust does something similar, with methods that borrow `self` being immutable by default. Maybe we could get something like `T class::method() mut {...}` someday. 
&gt; I'm sure they'd be most welcome. I've had the exact opposite experience. Many library maintainers are heavily opposed to breaking c++03 compatibility.
And I've had the exact opposite experience of _that_. ;-] It's not breaking compatibility if you put it in an `#ifdef` and document it; half-assing the PR surely gets it rejected, though.
I'm no expert, but I'm pretty sure boost has many mechanisms to default to using the compiler's internal capabilities whenever possible.
That's me! We're still using a compiler that doesn't even fully support C++11 on an embedded ARM. It's older then RHEL6's, which we also still support.
Have a versioning strategy. Try not to make sweeping changes that require new libraries, just for bug fixes. Save the big changes for major version increments that make it worthwhile for your customers to change their code.
Yes
&gt; It's not breaking compatibility if you put it in an #ifdef And that is exactly what I don't want to do, because it - increases the chances of odr violations - increases the maintenance burden (if you want to make a semantic change, you now have to adapt two places - makes code less readable - makes tooling less reliable - increases the chance of bugs slipping through, because there a more versions of your program to test and more possible combinations of different features. - Most package management systems have no way to detect that a certain dependency is only necessary in e.g. c++03 mode (that may be more of a problem with how boost is packaged than a fundamental limitation though). In summary, you loose many of the benefits of of using a newer standard in the first place. All that being said: Thank you for investing the time to make boost better. 
Some libraries do and some don't. However, doing this inside of ifdefs brings its own set of problems and limitations which I outlined in another comment here.
Some dependencies could be cut without influencing the API and the ABI is generally not stable between boost versions anyway (at least as far as I know, this is not something most maintainers are concerned with). Also, if you are not able to confidently upgrade to a newer API from your dependencies from time to time, you have a whole different problem (that is not to say, that many real world codebases don't have exactly that problem). Titus Winters gave a lot of good talks about this. It is certainly not feasible for everyone to live at head, but the opposite extreme isn't viable either.
I'm not so convinced that it's a good idea to create a concept which merely expresses the requirements for one particular operation or algorithm. This example is often used: `void sort(Sortable auto &amp; c);` Is `Sortable` really a good concept? It doesn't help the user of a `sort` function: it tells them that in order to call `sort`, the argument must be sortable. Well, no s\*\*t! Can you reuse the concept in other functions? That's not very helpful from the user's point of view either. Maybe one day you'll end up writing a different algorithm that happens to have the same requirements, and you can write `void frobulate(Sortable auto &amp; c);` Is that helpful? A user will probably say, quite reasonably, "why the heck does frobulating something require it to be sortable?". Maybe the concept does express a useful reusable set of requirements, but naming it after the algorithm is a poor choice. So I don't think `Incrable` is an improvement over `requires requires`. If instead it expressed a *set* of operations, say not just `++t` but also `t++`, and also included a requirement that these had appropriate return types, then *that* would be a useful concept.
I definitely agree on the \`is\_noexcept\` name. For a "requires expression", an equivalent name would be \`is\_well\_formed\`.
Yes - it should be `requires is_incrable_v&lt;T&gt;;`
&gt;std::empty vs std::is\_empty (and also std::filesystem::is\_empty) is also part of this, but also a discussion on its own. Gah. I knew about `std::vector::empty` (which should now be tagged `[[no_discard]]` to prevent mistakes) I didn't realise that there were both `std::empty` and `std::is_empty`, and both are queries...
1: If you're linking together TUs compiled for different standards, you already have much bigger problems. 2-4: Implement it sanely with typedefs and policies and the real code won't change meaningfully. 5: Yes, but Boost has a massive test harness. 6: A) Again, implement it sanely; B) This is neither a new, nor Boost's, problem. In summary, FUD. ;-]
There's work ongoing but the discussion centers around removing the pre-c++11 support. Should you keep the existing stuff and not rely on c++11 existing, or should you ditch C++03 support and have less crud when only a few use it?
Did not explain where the left parenthesis between requires and requires disappeared. Guess they are optional?
What is an appropriate return type in the context of expression template libraries e.g. Eigen?
[this?](https://cppinstitute.org/)
I agree there are real limits to c-style loop and I'm excited about the new ranges stuff. But when the source data for the loop gets really complicated I think python generators are the gold standard and I wish c++ had them.
Like everything it's a trade-off. Do I care that my startup non-hot code path has a few extra pointer chases, if it means I can decouple a heavily included header?
You also have the upcoming `std::ranges::empty` which again is a query...
Very nice work! It definitely looks clean. Iâ€™ll keep an eye on it!
&gt; I sort of wish all programming languages would get more keys on the keyboard to work with. Absolutely agreed. &gt; It'd be super nice if we had the equivalent of `{}` but that did NOT introduce scope I can't image how it would work. E.g. would `for (int i = 0; i &lt; 20; ++i) auto f = [i] { return i; };` leak 20 `f`s into the current scope?
I could not agree more, and I know people get really upset when anyone suggests 'forking' the language. So what about a Typescript-esque superset that transpiles to C++? Remove backwards compatibility, std::allocator, and other such annoyance from the language but have a 'legacy' namespace that's parsed as standard C++. As much as I like Jonathan Blow and I'm chomping at the bits to try out Jai; having a group like SG14 'properly' rework it would be preferable.
In a perfect world the decision to join or detach a thread would've been made in its ctor, saving us from this madness of inventing and reinventing RAII joiners/detachers for non-RAII threads.
afaik D does syntax check (and probably AST generation) for discarded branches: void f() { static if (false) { +; // syntax error } static if (false) { void x; // semantic error in discarded branch, no diagnostics } } But I don't know whether C++ can do the same (since C++ has `allocator&lt;foo&gt;::rebind&lt;bar&gt;::type` whose syntactic structure depends on the semantic analysis of `allocator&lt;foo&gt;::rebind`'s definition).
How would that be applicable here? Usually the volatile keyword is used for warning the compiler that a variable might be changed by another thread of execution, so don't optimize reads by caching it's value.
That's reasonable.
Volatile does not have anything to do with threads. If you use it in this sense you are sure to introduce undefined behavior. Volatile is used for example with memory mapped io, where reads and writes have no effect on the internal program logic within the processor, but where they do have external side effects. For example if you were to write to a memory location to toggle a GPIO, the compiler might remove the first write because it has no possible effect if the variable is not volatile. Making it volatile will ensure both writes actually occur.
Really well written, succinct and accessible. Thanks for this!
Again, that *should* be a compiler concern.
Where... did... you read that? ðŸ˜•
Yea, number one reason: prevent windows.h from spreading trash.
&gt; 1: If you're linking together TUs compiled for different standards, you already have much bigger problems. Yes, but that is unfortunately still quite common because package managers (at least apt and vcpkg) usually don't distinguish between builds for different language versions. Also, most ifdefs in boost are actually not around language standards, but individual features, so even if you compile all dependencies with the same standard version, but with e.g. different compiler versions (or - God forbid - different compilers like gcc and clang, different code paths can become active. &gt; 2-4: Implement it sanely with typedefs and policies and the real code won't change meaningfully. Depending on what you call "meaningfully" that is just not true. Whatever technique you are using, you are either introducing another level of indirection and/or tight coupling between different code paths as well as more combinatorial possibilities. You can minimize them, you can hide them to some degree, but the code becomes more complex to read and write than when you are writing against fewer / a single standard. And all that assuming you are actually able to implement it "sanely" in the first place. Also, certain things that would increase readability just become not usefull when you have to keep the old version around (e.g. using `std::map&lt;std::string,std::vector&lt;T&gt;&gt;::const_iterator it = my_map.cbegin()` vs `auto it = my_map.cbegin()` vs `for(const auto&amp; e : my_map)`). &gt; Yes, but Boost already has a massive test harness covering all standards. Right, an never has a boost library been released that had a bug in it right? That test-harness tests a lot, but not all possible combinations of compilers, standard libraries, build flags, library configurations and usage scenarios (not by a long shot). Also, as you have already submitted a PR to boost, you might remember how long it takes until your PR gets scheduled on Travis due to the enormous load the boost project generates. &gt; 6: A) Again, implement it sanely; B) This is neither a new, nor Boost's, problem. It is a problem for me as a boost user and one of the reasons why we try to cut down our boost usage internally. And yes, it absolutely isn't a new or boost specific problem, but it is a problem nevertheless and it increases with every supported standard, so I'd prefer to see it reduced rather than increased. What I believe is pretty unique to boost is the amount of conditional compilation - either through the use of TMP or through macros. &gt; In summary, FUD. ;-] I think YMMV is more appropriately here. Maybe I'm just not an experienced enough c++ programmer and maybe I'm using the wrong tools that get confused too easily, but codebases with lots of conditional compilation and boost in particular are - in my experience - significantly more difficult to work with - both for tools (refactoring, code completion, static/dynamic analysis) and for humans. To end on a more positive note: Most of boost is of very high quality and well documented, so in absolute termns the number of problems we had is pretty low, but everytime there was a problem it was a nightmare to track it down. 
Come to think of it, here: https://www.reddit.com/r/cpp/comments/8wbeom/coding_guideline_avoid_const_member_variables/
It's funny that it comes from Simplify C++. About a year ago my colleague and I took ownership over a component cluttered with pimpls. Apparently, it was a rule or a habit to put them everywhere. We decided to get rid of them unless they do exactly what they are meant to - reduce dependencies. We thought we'll clean up maybe half of them in trivial structures or stateless operators. If there is a dependency we can't hide without the pimpl, the pimpl stays. We cleaned them all eventually. It turned out, no actual dependencies were hidden it was all a bluff. Code became simpler. Simpler to read, to debug, to maintain. 
See the boost dependency graph in the monster diagram here: https://steveire.wordpress.com/2016/08/21/boost-dependencies-and-bcp/
Module level. Defining c++ compatible templates in rust modules - is this even possible in the future?
I haven't been following C++20 but isn't compiler error messaging one of the big improvements that concepts is supposed to bring? So if the user passes in something that isn't Sortable the compiler can just say so, rather than some long list of substitution failures.
Hmm... sounds a lot like [Nim](https://nim-lang.org/) (definitely give it a try - its more powerful than D)
Boost is designed to still compile for (with the exception of specific libraries that are explicitly stated not to compile for) MSVC 2005. The last standard supported under 2005 was C++03. Boost cannot depend on any libraries that have "gone in" and maintain compatibility with C++03. Now, *you could* theoretically ask why not switch the underlying implementation to the adopted standard when available. My best guess is a combination of "I think some of the libraries do this" and "Adopted libraries rarely get adopted as is, making the interface change necessary would break compatibility in obscure ways with the original boost implementation and effectively 'freeze' feature development in that library."
Does the `switch`-based visitation work with `std::variant` or is it specific to `mpark::variant`?
That's a new one. Usually it's the post or article that people don't read.
&gt; And on a related note, when Boost libraries achieve standardization, why do they remain in Boost? because the boost libraries are less constrained than the standard and thus can provide more new features / better fixes (at the expense of requiring a rebuild at best or code changes at worst). e.g. for instance `boost::optional` supports references, `boost::shared_ptr` can reliably be made non-thread-safe on all platforms with BOOST_SP_DISABLE_THREADS, etc... Also, the performance with boost is much more predictable across platforms. If you use the default stdlib of all your platforms, you cannot guarantee that, say, libc++, libstdc++ and MSVC's unordered_map will have the same performance characteristics, maybe one or the other will have some weird corner case. Likewise for bugs, etc. Another big interesting thing : you cannot legally specialize C++ types that only depend on std or core types, e.g. you cannot specialize legally std::hash&lt;std::pair&lt;int, int&gt;&gt; : it causes (imho stupidly) undefined behaviour and evil compiler maitainers could choose to make your code crash when you do so. But you can with boost::hash since it isn't covered by the standard - worst case is that if boost adds a custom hash specialization at some point for this you will get a compile error. 
Qt allows both sync and async signals.
"Every C++ developer I know, knows about and uses lambdas and std::function when appropriate." That I don't understand. Classes are lambdas on steroids. Lambdas preserve data that can be accessed later by calling the lambda. Classes preserve data that can be accessed and changed later by calling one or more methods. Classes are a superset of lambdas. The problem I find with C++ is that it still has pointers. It's managing pointers that can cause real confusion.
&gt; This is a CoC violation, and I violated it willingly and intentionally This seems like a failure of the CppCon organizers. Have they apologized for letting you attend wearing that, or for letting you get up on stage? Or have they explained how their procedures will change to prevent such violations?
I feel like I've said this before. Oh, wait... I have. A year ago. [https://www.reddit.com/r/cpp/comments/7jxq8r/does\_anybody\_know\_why\_requires\_requires\_was\_not/drd39zt](https://www.reddit.com/r/cpp/comments/7jxq8r/does_anybody_know_why_requires_requires_was_not/drd39zt). Except that I also explained the origin of the syntax and why some of the alternatives being suggested in this thread aren't workable. Of course, I don't have a blog, so that's easy to overlook. Maybe I should get my own soapbox.
i really don't like the idea of defining a variable and making it not variable by default. Things should always the same no matter where they are defined. if i write int i; i usually want it to define a variable that i can change. Making it const in structs or classes and behave differently as it would in a function is just horrible in my opinion. 
It doesn't do that. On a declaration, it introduces a constraint expression (something that can be true or false). As an expression, it introduces a nested sequence of requirements, which have their own syntax own distinct syntax for expressing what expressions and types are well-formed, along with some other information. &amp;#x200B;
&gt;I'm not so convinced that it's a good idea to create a concept which merely expresses the requirements for one particular operation or algorithm. This example is often used: &gt; &gt;void sort(Sortable auto &amp; c); You probably shouldn't. Of course, there are at least 4 algorithms in `std` with exactly those constraints, but if you wanted a really robust set of sorting algorithms, you could easily expand that by a half dozen (if you really wanted e.g., `insertion_sort`). I doubt that Arthur thinks `Incrable` a big improvement either (I hope so). I read that as showing an example of how to avoid it.
[cpptruths](http://cpptruths.blogspot.com/2018/10/chained-functions-break-reference.html?m=1) blogpost regarding Chained Functions Break Reference Lifetime Extension. Also discusses 4 ways to avoid the pitfall.
This is not an optimization detail. I want to be able to assign new values to a variable from time to time. I want to be able to grow a vector, I want to be able to insert and remove values from datastructures in general. Most of the time you are much better served with making your actual variables and parameters const by default and allow for the odd instance where you do have to change one, instead of making a completely immutable type (and then trying to use cow techniques and similar under the hood to make the creation of "modified copies" cheap). Also, the kind of optimizations you are probably talking about are quite tricky in a language such as c++, where a) you don't have a garbage collector, b) you are referring to objects by their addresses in memory, c) heap allocations are pretty expensive and d) programmers want to have control over their data layout. In languages like java, or many functional programming languages, the trade-offs are totally different and there it might make more sense.
I would never recommend anyone a language that doesn't take backwards compatibility seriously. If my code is worthless in 10 years or i have to keep an old compiler handy i have tons of unnecessary work. That's why i will never support a breaking change in C++. I'd even go a step further and say if the breaking change is worth breaking backwards compatibility, it justifies founding a new language that doesn't have to worry about all that stuff and can just be better on its own. If it is better people will slowly start using and adopting it, while you can still keep backwards compatibility and new features for C++ (until it slowly fades out, but looking at other old programming language that will take a while). The nice thing about that is that if people don't think its worth it they will just keep using C++ and you've only wasted your own time. Making a breaking change to C++ instead will cause huge amounts of trouble for everybody with C++ code. And it might be for something people value a lot less than backwards compatibility. And let's be honest a breaking change is the same as making a new programming language you just force it on everyone. 
Saw it but seems pretty vague. Still not entirely sure the whole thing isn't a scam, judging by the website and the lack of community visibility.
I meant in regards to build system and such
What is not great is that you have to 1) consider this tradeoff and 2) do a mechanical transformation on the source to toggle it :/
Maybe you should? I find your comment to be suuuuper helpful. Would subscribe. 
&gt; why do they tend to depend on Boost libraries? Because if something is already accepted into Boost and you reinvent the same concept in your library it will not get merged into Boost until you have refactored your code to used the boost dependency instead of your own implementation. This reduces the LoC and makes everything more maintainable in general.