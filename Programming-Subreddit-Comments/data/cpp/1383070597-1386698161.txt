Have some upvotes. I didn't see any SFINAE explanation less than a chapter so far, and you managed to get it onto one screen.
http://www.cppreference.com/store/ has a bunch of puns.
I never really thought of this, thanks for that! Also, I'll have to give D a try, seeing the strong recommendations I've been seeing lately.
If you're not going to go all out, don't bother with a gag. It seems lazy. Anything that doesn't require at least a modicum of effort is just a poor costume.
Go as Bjarne Stroustrup
Get a wooden leg from a pirate costume, then add a toy bazuka labeled "C++". Relevant quote "C makes it easy to shoot yourself in the foot; C++ makes it harder, but when you do it blows your whole leg off". 
these are so lame i love it
Grab a friend and make both of you use a t-shirt with "class" written on it. Now, just keep touching each other privates... You can use lots of std's to spice things up.
The probability of anyone truly enjoying these is very slim
I was going to suggest a prosthetic index finger hanging down, covering the real one up with gory make-up. It's a dangling pointer!
It'll be a costume that will be worn at the office only, in an office comprised of 90% Software Engineers, of whom, the vast majority write C++ for a living. I'm just looking for a smile and an eye roll, really.
This one actually made me laugh out loud :P
Wear a headset with a mic and carry a huge sack on your back: overloaded operator. Dress up as a number with a tag on you that reads "AUTHOR:_______" : unsigned integer.
&gt; Frankly, to me this looks gibberish. I agree that this document looks gibberish. I don't know much about Concepts Lite, but I was really impressed by [Bjarne's talk (about it and lots of other things across C++) at GoingNative this year](http://channel9.msdn.com/Events/GoingNative/2013/Opening-Keynote-Bjarne-Stroustrup). It's easy to use, and it seems easy to explain and should give sensible error messages. So, they're easy to use, but how about writing new concepts? I'm surprised at all the shiny new stuff in this document. I think/hope that it will be easy to just write a typical `bool` function when that is more convenient.
I'd go as something that would still be funny to look at even if I didn't tell anyone. Go as an electrocuted repair looking guy (need to do something with your hair or wear a wig). - *What are you? an electrocuted dead guy?* - *Nope. I'm an overloaded operator.* - *&lt;crinnnnnnnge&gt;* 4th doesn't really work. what are you, a ray? doesn't get into an array ~= an ray.
or a t-shirt that says: "baby, your place in memory is so important that i'll never let your pointer go NULL"
This guy is almost as bad as Andrew Koenig's Dr Dobbs column with how little content he puts in each of his blog posts.
Go as a [pimpl.](http://www.youtube.com/watch?v=DZN4r8p6KbU&amp;t=1m50s)
Another resource that I found useful for learning about the cases when set shouldn't be used: http://lafstern.org/matt/col1.pdf This article came at a pretty useful time for me, as I'm thinking about how to go about writing a program that reads in historical stock market data and runs some calculations on it. My initial thought was that since I'd like to do lookups by date (to calculate the return between two given dates), and would also like to iterate through in sorted date order (for moving averages), I should use something like a map&lt;date, float&gt;, since an unordered_map wouldn't allow iteration. But after reading this, I realized that since I won't be changing the stock market data once read, I can just read everything into a sorted vector instead, which would be much simpler.
I meant "the code samples look gibberish to me", meaning "there is too much words and punctuation in there". Anyway, thank you for the link to Bjarne's talk!
I just read the tutorial for B (located [here.)](http://cm.bell-labs.com/who/dmr/btut.pdf) It did in fact have pointers (Source, page 10 &amp; 15.) For the record, that pdf is a super interesting read. 
`#pragma I_HAVE_NO_IDEA_WHAT_IM_DOING`
please, ealborate on these "alternatives".
Code::Blocks with the GNU compiler is among the favorites.
&gt; Now let’s look at some examples of rvalues. Literals such as 7, ‘a’, false and “hello world!” are instances of rvalues: Incorrect. N3797 5.1.1 [expr.prim.general]/1: "A string literal is an lvalue; all other literals are prvalues."
This. Meyers et al have been crying themselves hoarse about this advice for the last, oh, 10 years.
In the summer of 2007, I wrote approximately 20000 lines of code for a popular operating system, and I had zero pointer-declarations in my own code, and zero invocations of delete. Smart pointers may be sparingly used in your experience, but that says more about your experience than about the rest of the world.
&gt; const_iterator find(const T&amp; t) const { &gt; const_iterator i = lower_bound(begin(), end(), t, cmp); &gt; return i == end() || cmp(t, *i) ? end() : i; &gt; } There is a bug: operator || has [bigger priority](http://en.wikipedia.org/wiki/Operators_in_C_and_C%2B%2B#Operator_precedence) than operator ?:. It should be like this: return (i == end() || cmp(t, *i)) ? end() : i;
No need to be snarky. I wasn't calling into question your experience as in your skill-set, merely your experience as what you see around you. If you haven't seen smart-pointers commonly used pre-C++11, your experience (as in the surroundings you inhabit) is unquestionably limited.
You might also want to look at `boost::stable_vector`, the stable relates to memory stability as this vector attempts (succeeds ?) not to move items when doing inserts/erases.
&gt; The members actually have to pay $1200 a year to participate. Could some committee-member elaborate on that? Is it what you have to pay to be member of the American standards-body, or is this for everyone? Did I understand it wrong, that anyone can take part for free but isn't allowed to vote then?
T** set; set[i] = new T; This doesn't seem right. You have a member variable declared as a pointer to a pointer; but you are not allocating it before you use it. As far as your question goes; Why not create a copy constructor to make a copy? Is this an academic exercise that prevents you from using [std::set](http://en.cppreference.com/w/cpp/container/set)
I found my problem, I changed it to be an array of T, instead of a double pointer.
string, streambuf, and iostreams are part of the standard, but not the STL. STL is the name for Alex's submission to the committee it included the vector, deque, list, set, map, and the algorithms, but not the string or IO classes.
I think this is a blog post where a guy &lt;emphasis&gt;does&lt;/emphasis&gt; brag about knowing Alex Stepanov. Guilty as charged. The problem isn't that allocators were inadequate. That is just a issue that we are having to deal with and part of the solution is better allocators and part is alternative implementations like tcmalloc. Part is making fewer allocations. This approach is covered in later installments. Of course heap allocation doesn't inherently have to take a lock. But if you are sharing a heap across multiple threads, which is more and more common today, then you have to manage that. This was not the common situation when the STL was originally developed. Although memory hierarchies are not new, their size and depth have a much greater impact than they used to. The STL was designed without taking them into account because the effects weren't significant in most case. Things have changed.
The fundamental design of the STL is sound. What needs to change, in my opinion, is a shift way from node-based containers where possible. I'll discuss this more in the later installments.
Man, Bjarne Stroustrup as Heisenberg (Walter White) "Hail to the RAID" or dressed like a PIMP "So, you know pimpl, eh?" (just kidding)
Hi Jon, not that you requested this, but maybe I can give you some feedback as to why people could think this. The article feels like it is written for people who are already know what they are talking about. Mainly because most of the points you raise are taken as already known by the reader and therefore never backed up with evidence, e.g. &gt;It has always been true that for small values of N, vector beats containers with better order operations. Since no links to proofs or evidence is given, readers unfamiliar with these claims have to go and search for appropriate proof themselves. These users don't learn much from *your* article, but will learn from others with relevant evidence. If you are already familiar with these claims, by definition you still aren't learning anything new. So you read through all of these assumed facts at the beginning and you start to assume that, since you know all of these non-obvious facts, the article is aimed at the more intelligent/experienced/etc developer. So now that you're in this frame of mind, you're looking forward to this payoff at the end, which must be at least as complex/interesting as these points we are already meant to know. However, the payoff is a link to the boost container library. The most interesting focal point in your article imo should be that vector beats out other containers in areas it wasn't designed to for smallish N. But this doesn't feel like the focus, this point is taken as already known and never backed up. The focus of the article is "if you know that vector beats other containers for small N, try this boost library". Since I am new-ish to C++, I came away with the knowledge of flat_ * and a cool quote by Stepanov (it was a good one and I had not heard that before). But this wasn't half as interesting as the stuff the article explicitly assumes I should already know. I can imagine more experienced C++ developers would know about flat_* and therefore just read an article telling them that they should know what they already do. I would add more relevant and interesting links to back up all your claims, or write some test programs and show us the benchmarks yourself. You obviously know what you are talking about so I hope you keep writing articles. But I think there needs to be more meat in them. Also I think "advise" should be "advice" at the beginning of the 4th paragraph. EDIT: Just realised you are the Jon Kalb of the "Exception-Safe Coding in C++" talk. I very much enjoyed that talk, I think it was the first big jump learning about exception safety for me.
&gt; But I think there *needs* to be more meat in them. Why? It's a blog post, not a journal paper or textbook chapter. If you find some of the thoughts or claims interesting, then you can discuss those here or do some of your own exploration (maybe posting the results back in another post). If a blog post gives you some insight into what someone's thinking about and sparks further interest, then it has more than done it's job. 
As I posted in /r/Cplusplus: Not a great tutorial as not a lot of coverage is given to why and when you'd want to use rvalue references. Move constructors get a mention (and a link to [a much better tutorial](http://blog.smartbear.com/c-plus-plus/c11-tutorial-introducing-the-move-constructor-and-the-move-assignment-operator/)) but nothing about forwarding. Instead it uses contrived examples when are (IMNSHO) terrible style: int &amp;&amp;func2(); int&amp;&amp;rr; Returning or storing `T&amp;&amp;` is basically only useful for forwarding, e.g. `std::forward` and `std::forward_as_tuple`. There is nothing gained in these examples from using `int&amp;&amp;` over `int` and it promotes terrible style to use it that way in a tutorial. It's not terribly clear as a technical explanation either. For a terse, but complete, version I'd check out [cppreference.com's value category page](http://en.cppreference.com/w/cpp/language/value_category). Or for a less formal, but still fairly complete explanation (including the history and why of the names) I'd suggest getting [straight from the Stroustrup himself](http://www.stroustrup.com/terminology.pdf) (PDF) or Andrzej's blog post ["Lvalues, rvalues and references"](http://akrzemi1.wordpress.com/2011/11/09/lvalues-rvalues-and-references/) which has less history and more code. (While Andrzej includes `T&amp;&amp;` variables, it's at least in the context of explaining what an xvalue is and he doesn't claim its a tutorial.)
Still no linux support :(
OP is a good guy and is following through. http://imgur.com/a/2ddn9
TIL there is another c++ subreddit, thanks :)
If it's anything like emscripten (and it looks like that's basically exactly what it is) it outputs ASM.js, which can run a lot faster or a lot slower than hand-written javascript, depending on whether the browser has support for ASM.js or not. However, most javascript just does a bunch of DOM manipulation and such, and for those cases, this will not get you much of a speedup either way (plus, you'll need to come up with some sort of interface to manipulate the DOM, since I don't think this compiler would provide you with it (emscripten doesn't))
It should support DOM manipulation &gt; You can access all browser APIs directly. Duetto inher­its the C++ phi­los­o­phy of expos­ing the plat­form capa­bil­i­ties (and lim­i­ta­tions) to the users. There is no mid­dle man. For just DOM stuff, I can't imagine it's worth the hassle but I'm interested in high-performance server-size apps and game development. It would be great if I could get closer to native performance in the browser. As you said, I think this is largely dependent on how well a given browser supports ASM.js.
Hm, I don't know how they do it in duetto, but in emscripten, you *can* manipulate the DOM (because you can call javascript functions from C++, or even inline it into your code) but it'd be a major hassle, because there is no pretty tree defined or somesuch that allows you to stash your callbacks into it, et cetera. So as you're saying, it's probably not worth the hassle, unless you only do the computationally intensive part in C++ (no DOM usage in C++), or do everything in C++ without manipulating the DOM (which a game that only uses OpenGL ES 2.0/webgl could)
Are any of these talks webcast?
.NET only?
It's actually native code only
good. I get suspicious when they explicitly say "visual c++" too often.
The truth is they probably don't understand memory. If you don't care how the computer is actually working a managed language is perfect for you!
The good shops use it for keeping queue position, but it's not like the entire strategy is in there.
Alternatively you could get stoked about finding a good CPP compiler. 
There isn't much info. At least is open source.
&gt; what's a langue with all the benefits of a modern language and all the benefits of decades of development (╯°□°）╯︵ ┻━┻ 
What's wrong with bool(x)? 
Try -Weffc++ for more warnings if that's what your intention is, don't know about cppcheck. 
I've use it occasionally over the years but I tend to not any more. In general, for integer variable _x_, I prefer "x!=0" because I feel it expresses the actual semantics better. The only situation where I reliably find myself using it is in the odd case where I have integer types that represent boolean values (e.g. Win32's BOOL) and I need to compare them, I'll do something like this: if ( !!x == !!y ) ... ... 'cos the obvious alternative: if ( (x!=0)==(y!=0) ) ... ... is ugly as sin.
This is really important. Since making these changes to our large project, we have had a huge increase in productivity.
Indeed, the windows BOOLs were the catalyst for me doing this in the first place. I suppose I am also wary of any equality comparison of bool other than to false. 
I've seen it at work when integrating with Win32 functions. Most of them return HRESULT which is easy enough to cast to bool with the SUCCEEDED/FAILED macros, but some of them return a BOOL - note the all caps - which is basically a typedef'd long. By using !!, you get the result of the function as a bool (lowercase), preventing this bit of Win32 ugliness from seeping any further into your code.
Honestly, it's fine. It's utterly obvious to anyone who knows C++. There's no subtle surprise waiting to bite you. It's easy to search for in source code. You have better things to worry about than this.
After the "3-state BOOL" fiasco with the Win32 [GetMessage function](http://msdn.microsoft.com/en-us/library/windows/desktop/ms644936%28v=vs.85%29.aspx) (where the return type is BOOL and can have 3 possible values: 0, -1, and other non-zero), I always compare directly to a value (i.e. (x != 0)).
The warnings I use: -Wall -Wextra -Weffc++ -Wshadow -Wnon-virtual-dtor -Wold-style-cast -Woverloaded-virtual -Wundef -Wshadow -Wsuggest-attribute=pure -Wsuggest-attribute=const -Winvalid-pch -Wno-multichar
implicit conversion is what's wrong, it lets you do things like #include &lt;iostream&gt; using std::cout; struct foo {operator bool () {return true;}}; int main() { foo f; auto x = f + 5; // implicitly converts to int though bool cout &lt;&lt; x; // prints 6 return 0; } instead you can write operator! to do your bool conversion explicitly, and use !! to get the typical value. This will then give you compile errors on the code above. In c++11 it's a non-issue, thanks to explicit conversion operators
You do know Xcode has clang's static analyzer built in, right? It's under Build-&gt;Analyze in the menus or you can search for "analyze" in your project settings and enable it there. (I do the second one, as this gives you static analysis any time you build.) And it's really good too…
I believe that zorkmids was proposing `bool(x)` in the context of explicit conversion.
What's wrong is that it's a c-style cast. Surely you mean static_cast&lt;bool&gt;(foo)
And that false sense of security is precisely why C++ has the _bool_ type.
Thanks. I'll probably use clang's -W options from the command line.
Thanks! ... you put -Wshadow twice.
None of this explains your TRUE/FALSE comment and why it is relevant.
Why wouldn't you do "if (x &amp;&amp; y) ..."?
I never found much use for this idiom until I went to implement my [double_integer](http://mx-3.cz/tringi/www/int128) template (to get me fast 128-bit or wider integers) where it proved quite useful to simplify code.
Your code is trivial. There's nothing to be found in it.
Different semantics. "x == y" is true if both x and y are false. "x &amp;&amp; y" is false if both x and y are false.
I think the point is, that if you're dealing with the WIN32 BOOL type, it's safer to simply treat it as though it were just an enum and compare to either TRUE or FALSE, typically in order to explicitly convert to the c++ bool type.
i.e. XNOR
We use this all the time at my office. Our lint rules does not allow implicit convertions like this. Same goes for putting explicit keyword on every single parameter constructor.
&gt; OVR_Std.h:46:33: error: 'itoa' was not declared in this scope The `itoa` function is declared in `&lt;stdlib.h&gt;`. I can't say why it's not included by the SDK itself, but try putting an "`#include &lt;stdlib.h&gt;`" before the "`#include &lt;OVR.h&gt;`" line.
'x == y' is not what i am responding to edit but a moot point as i am wrong
xnor is something else entirely
No it's not, look at a truth table. 
So do I, but it's nice to give a reason for what's wrong with it in some cases.
Last I looked sprintf takes up to 6000 cpu cycles, awesome. So if it's in the critical path it's probably not acceptable speed wise. There are some fast itoa implementations out there, each has its own pitfalls. If speed isn't an issue sprintf is probably the best choice for compatibility reasons.
xnor is true is x and y are both true or they are both false. so yes, he is talking about xnor, but that is different than what i am talking about. edit because i am wrong 
As /u/Nimbal has noted, `itoa` isn't a standard function. The `OVR_Std.h` header is checking whether you're compiling on Windows and then using `itoa` if you are. Of course, this is problematic because you *can* be compiling on Windows with the GCC library implementation, in which case `itoa` isn't available. This sucks. A quick hack is to remove the following lines from the header: #if defined(OVR_OS_WIN32) inline char* OVR_CDECL OVR_itoa(int val, char *dest, UPInt destsize, int radix) { #if defined(OVR_MSVC_SAFESTRING) _itoa_s(val, dest, destsize, radix); return dest; #else OVR_UNUSED(destsize); return itoa(val, dest, radix); #endif } #else // OVR_OS_WIN32 and the corresponding `#endif` after the remaining definition of `OVR_itoa`. This leaves only the cross-platform implementation of `OVR_itoa`.
Ah, wasn't aware it wasn't the standard. Should have google'd, sorry!
Some thoughts on that: * -Wextra implies -Wall, so there is no need of adding both * Weffc++ often warns on perfectly innocent code to a degree that makes it useless IMHO * -Wold-style-cast would be great if it would do what it promises: `int(x)` is totally equivalent to `((int)x)` but sadly doesn't trigger the warning * In addition I recommend -pedantic to enforce iso-cpp * -Werror for release-builds should be mandatory
I managed to get it working 100% with Visual C++ 2010, but I prefer NetBeans (call me crazy, heh), so I want to figure out what's wrong. I've seemed to fix that OVR_itoa issue (in NetBeans), by adding the Library directory rather than the actual .lib file itself. So, I'm not badgered by OVR_itoa issues anymore. However, this is what I'm getting now, for the same code (in NetBeans): `*** No rule to make target 'libovrd.lib', needed by 'dist/Debug/MinGW-Windows/minimaloculus.exe'. Stop.` libovrd is the lib I'm attaching to (under the Debug configuration of Project Properties) Additional Dependencies. But that's the error hitting me on NetBeans. Any ideas? EDIT: I should note, adding libovrd to the same configuration/place under Project Properties in VC++ worked. I know they're two different IDE's, but following the same configuration I used for VC++ entirely got rid of my `OVR_itoa` issue and seems to have solved the lib links. EDIT 2: Not to mention, the Project Properties have the exact same layout and options for both IDE's.
`int(x)` isn't an old-style cast, and in the specific case of `int` the semantics are identical to that of a `static_cast` anyway.
CppCheck is a conservative checker. On a million LOC project, it found about 80 errors. I fixed them all, then evaluated some professional tools (Coverity &amp; Klocwork). Both professional tools found about 1000 defects in the code. CppCheck and clang are the best free tools available. If you want something more in depth, you'll have to pay for it. ... except some tools do offer free use for open-source code. I know [PVS Studio](http://www.viva64.com/en/b/0222/print/) does this. (I am **not** associated with PVS Studio at all and frankly found it wanting in many areas -- it's has a significant rate of false positives, runs only in the IDE, etc...; but it does catch many problems and is free for open source projects.) There may be other tools out there too that are free for open source projects.
no, it's only safe to compare BOOLs against FALSE -- which is exactly what 'x!=0' does. TRUE is only one of many possible _true_ values.
My English is suck, so, just put a Chinese version. lol, Maybe you can see a link in the article discussed on stackoverflow.
I don't know Chinese, but that's a very common technique done in c++ to convert an array of pointers to an array of vector objects (not std::vector but like a position vector x, y, z). you should do stuff like static_assert(sizeof(Vector2D) == sizeof(float)*2, "can't convert") to ensure memory it's packed as expected
it's not about this. it's about an arbitrary pointer convert to an object pointer, then call the methods and members of this object it still works.
so it shadowed the first one? ;)
Thanks for the comments!
You claim (or at least that is what the google translation claims) there to be a virtual function and virtual function table which is not true for your foo. Indeed, your foo ends up with the size of a struct with one int member, so basically just the size of an int, and the compiler does all the remaining leg-work when using the member functions. It would probably fail the moment you put in a `virtual ~foo`.
exactly! that is what i want to say. seems the google translation work great!
Sorry, but this is completely wrong. Try this on a 32-bit machine: int("foobar") and then compare it to static_cast&lt;int&gt;("foobar") on 64-bit machines just replace int with long. int(x) ist totally an old-style cast with new syntax, see also this post: https://pay.reddit.com/r/cpp/comments/1pscpd/using_for_bool_conversion/cd5yt0a
I would prefer to use: bool(x) to convert x to a bool type. It's more readable.
&gt; ... but it can not be used with a custom deleter. Why do you say this? Any custom deleter around the original shared_ptr is respected. The goal here is is to enable an object that is already inside a shared_ptr to return a second shared_ptr that shares ownership with the original one. Are you asking that it be possible to change the deleter even after multiple shared_ptrs have been created?
You are right, I missed something
Good find. The Oculus devs should probably be notified of this. I can't imagine /u/AvidOxid is the only one that has run / will run into this problem. Unfortunately, the Oculus developer page asks for a login, so it seems like only registered developers can suggest a change like that.
Better one: http://pluralsight.com/training/Courses/TableOfContents/learn-programming-cplusplus Why? The author, [Kate Gregory](http://pluralsight.com/training/Authors/Details/kate-gregory) knows the distinction between the old style / legacy C++ and the current, modern C++ -- and this shows in the choice of the topics and the overall structure (std::vector before C style arrays and pointers, etc.). [\*] Another possibly of interest: http://pluralsight.com/training/Courses/TableOfContents/modern-cplusplus-libraries [(\*)] This distinction is rarely seen in most (on-line *or* off-line) courses and is IMO one of the most important things distinguishing the good ones from the bad ones -- whichever up you end up doing, it's at least one thing I'd pay attention to (also, e.g., std::unique_ptr before C style pointers). Another useful source may be the entries on &lt;http://isocpp.org&gt;: http://isocpp.org/blog/category/training For instance Scott Meyers offers pretty good training: http://www.aristeia.com/training.html With all that being said, if you're really serious about learning C++, I'd still recommend to go with a good book as your primary resource -- see the list from the sidebox: http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list Going through a good book (ACTIVELY -- i.e., doing all of the exercises and doing independent research and mini-projects exploring each topic in a personal context -- e.g., writing simple games if you're into game development) offers an IMMENSELY deeper level of knowledge than any course can possibly offer (let alone the on-line "tutorials" on YouTube/blogs/etc., which are mostly of *negative* value). Personally, I'd recommend "C++ Primer", 5th Edition by Stanley B. Lippman, Josée LaJoie, Barbara E. Moo: http://www.informit.com/store/c-plus-plus-primer-9780321714114 Reason: its focus on smoothly integrating the [current version of C++ -- C++11](http://en.cppreference.com/w/cpp/language/history) -- throughout the material. 
I'm not sure it's an issue with the SDK though, cause I got it to work in Visual C++, and set it up where I'm reading the roll/pitch/yaw of the headset, as well as the acceleration (in G's). If `itoa` was the issue, I don't think it'd be working here. It's just netbeans (or my inability to configure netbeans) which is the issue. I tried compiling on the command line (using same command Netbeans used), and it's unhappy, still.
As /u/sftrabbit has noted: &gt; The OVR_Std.h header is checking whether you're compiling on Windows and then using itoa if you are. That doesn't account for the possibility of using a GCC toolchain (which doesn't have `itoa`) under Windows. So either the Oculus SDK is fixed to check for the GCC / Windows combination, or someone convinces the GCC developers to add an `itoa` implementation (good luck with that). Otherwise, the SDK will continue to be broken in that environment. Edit: Just to clarify, Visual C++ uses the MSVC compiler, which is very different from the GCC compiler. MSVC offers an `itoa` implementation, GCC does not. So it's no wonder you got it to run in Visual Studio.
Ahh, thanks for the simple explanation. I guess I should read up on my compilers a little better. I guess Visual C++ it is, when the time comes! They do have Unreal Engine integration (UnrealScript/.uc files), though - I'll be working in UDK for now, and godawful UnrealScript, unfortunately. Sucks working on a language that has an expiration date (public release of UE4 on UDK w/ C++ instead). EDIT: There does appear to be an MSVC compiler for NetBeans, I'll give that a shot and report back. 
noob question: In this case, I'm wondering whether the author's approach provides any benefits over: struct student { // ... friend void offer(shared_ptr&lt;student&gt; s, course&amp; c); } void offer(shared_ptr&lt;student&gt; s, course&amp; c) { if(s-&gt;interested_in(c)) { c.enroll(s); } } The only one that comes to mind is that the author's approach allows for `offer` to be virtual, but are there any others? 
Casting through a union triggers undefined behavior.
Isn't union a hold over from C so that the two remain compatible? Otherwise you'd have to be a masochistic moron not to use a template.
This is really helpful! Also fascinating, especially to me as I'm taking a theory of stats course this semester. :)
I'm glad you liked it!
Awesome presentation!
Ah, I see, fair enough. In that case, I'd agree with your other reply, i.e., to avoid attempting to learn both at the same time (esp. via a single course or a single book, or, for that matter, any single source). // Somewhat related: http://www.parashift.com/c++-faq/buy-several-books.html The only all right course that *introduces* both topics I can think of would be Stanford's CS106B: - syllabus: http://see.stanford.edu/materials/icspacs106b/H02-GeneralInformation.pdf - videos: http://see.stanford.edu/see/lecturelist.aspx?coll=11f4f422-5670-4b4c-889c-008262e09e4e As they mention: "CS106B is a course in programming abstractions and although we use C++, there is much more to the language that fits with our pedagogical goals." It's also from 2008, so it won't cover any of the useful C++11 features (like implementing containers with move semantics -- which I wouldn't think of, say, as a "merely" C++-specific implementation detail, but something that will have a fundamental impact on performance--often O(1) vs O(N)). That being said, for its time (C++03) it covers the ground pretty well (with its focus being on introducing the algorithms &amp; data structures, as opposed to focusing on teaching C++ -- so, even though it uses custom libs, it should not be a problem, since one shouldn't attempt to learn both at once anyway), does a good job motivating the material (being an intro course it illustrates the topics solving nice, simple examples) and if supplemented with other (e.g., C++-specific, listed above, so as to actually learn C++) materials won't steer you in a wrong direction (and is obviously, without a shadow of a doubt, better than the VTC materials).
I love the humor - totally drives the point home in the first couple slides. :) "No! It's AWFUL! It's terrible!" Also, nice inclusion of the Ramanujan number.
Cool article. It nice to see some C++ posts by people who seem to actually know the language. P.S. this is definitely also one of the nicer intros to Windows Runtime.
I am somewhat new to C++. What does the "::" mean? In for instance ::TranslateMessage(&amp;msg); I know that it is used for namespaces like std::cout, but without anything before the "::" what do they mean?
STL gave another talk at GoingNative 2013 that was also very good: [Don’t Help the Compiler](http://channel9.msdn.com/Events/GoingNative/2013/Don-t-Help-the-Compiler). The majority of the talks at GN2013 were excellent. Find them all here: [GoingNative 2013](http://channel9.msdn.com/Events/GoingNative/2013?sort=sequential&amp;direction=desc#theSessions).
Some thoughts on the covered topics: Is it really a good idea to have the ranges of distributions flexible until runtime? I doubt, that this is great for performance: Once I had a discussion with a friend on C vs C++ and it turned to a comparison of his handwritten mersenne-twister and the one of libstdc++. The later one clearly won, but when we came to the distributions, his handwritten algorithms made uniform_real_distribution look really bad. Also, concerning inclusive end: wouldn't it be nice to write something like: std::uniform_real_distribution dist_in_ex(std::inclusive(3.0), std::exclusive(4.0)); std::uniform_real_distribution dist_ex_ex(std::exclusive(3.0), std::inclusive(4.0)); std::uniform_real_distribution dist_ex_ex(std::exclusive(3.0), std::exclusive(4.0)); where in-/exclusive() would wrap the argument in some type that would result in different overloads being called? This could also be done with compiletime-ranges; imagine something like this: std::uniform_real_distribution&lt;double, std::inclusive&lt;3&gt;, std::exclusive&lt;std::ratio&lt;33,4&gt;&gt; ct_dist{}; You declared that you are not a fan of default_random_engine and advised towards preferring mersenne twister. But wouldn't it be better to use default_random_engine if random_device turned out to be faster on a certain platform so that whatever you needed could be provided. Aren't your complaints about rands usual implementation unfair, since you are one of the very few guys who are both responsible for it and able to change it? 
&gt; if you're prepared the type the full name to access it, then you type std::cout or whatever. This is like the absolute file path, beginning with /, that you might use for a filename. No, it's more like the relative path. For example: namespace A { void print(); namespace A { void print(); } } Here `A::print()` will call different functions depending whether or not you're already in the `A` namespace. The "absolute path" would be `::std::cout`. &gt; If you don't include any ::, then you rely on the compiler searching around for you You always do. The searching/matching rules are pretty complex and include things like promotions and Koenig lookup. &gt; Will this last line find the `foo::bar::function()`? Yes. But it might also find others. For example, if your code also included `namespace bar { void function() {} }`, then your function call would cause a compile error.
Doh! I've just edited my comment after doing some quick experiments, before I noticed your reply. Thanks for the clarification! I've only recently discovered [Koenig lookup](http://en.wikipedia.org/wiki/Argument-dependent_name_lookup), and it's fun/crazy/useful.
&gt; everything is in exactly one namespace. I don't think that's a very useful mental model. The using-declaration for example essentially copies an identifier into multiple namespaces, e.g. #include &lt;iostream&gt; namespace Foo { using std::cout; } using std::cout; int main() { ::cout &lt;&lt; "1"; std::cout &lt;&lt; "2"; Foo::cout &lt;&lt; "3"; } 
Aha. That's an interesting example.
Unions and templates are orthogonal. Unions are useful to implement things such as `boost::variant`, a highly useful and safe type. As with many other C-level constructs, you shouldn't really be worried about them if you aren't implementing a variant type in C++.
&gt;Is it really a good idea to have the ranges of distributions flexible until runtime? It's a valid use case. Why forbid it? The alternative would be horrible modulo operations, which skew the distribution, and might not even be faster. Distributions are rather quick to construct, so what's the problem? &gt;Also, concerning inclusive end: wouldn't it be nice to write something like: [...] As was covered in the talk, half-open ranges don't really make a lot of sense of you talk about random numbers (or mathematics in general). In other words: the primary advantages of `[0:last+1)` ranges in the STL are: (1) empty ranges are easily described by `begin == end`. (2) compatibility with C pointer arithmetic (`&amp;a[0] == a.begin()`). There may be more advantages to zero-based indexing (and half-open ranges), which I hope somebody will link here.
&gt; It's a valid use case. Why forbid it You are right, I should have said that I want the static-versions in addition. &gt; half-open ranges don't really make a lot of sense of you talk about random numbers If we talk about integers: I won't discuss that. But the second we start with fp, exclusive ranges are clearly something you might want on occasion. 
&gt; Is it really a good idea to have the ranges of distributions flexible until runtime? From an implementation perspective, working with compile-time ranges would be trivial. However, a sufficiently aggressive optimizer should be able to achieve equivalent performance. (Mostly it needs to be able to see through arithmetic data members; as usual, aliasing is probably the problem.) &gt; Also, concerning inclusive end: wouldn't it be nice to write something like: Write a proposal for the Library Evolution Working Group! :-&gt; &gt; You declared that you are not a fan of default_random_engine and advised towards preferring mersenne twister. Yes. I later learned that some actual implementations have (what I consider to be) terrible taste in default_random_engines. &gt; Aren't your complaints about rands usual implementation unfair, since you are one of the very few guys who are both responsible for it and able to change it? Standard-wise, the problem is that rand() is permitted to be horrible. Implementation-wise, fixing VC's rand() would require changing RAND_MAX, breaking an unknown amount of code at runtime. I'm a big fan of making users fix their broken code (e.g. we shipped C++11 immutable sets without an escape hatch), but silent runtime breaks are scary, so I despair of ever changing rand().
uniform_real_distribution is half-open, unlike uniform_int_distribution which is fully closed.
Ah, but using-declarations don't affect the True Name of a thing, and Argument-Dependent Lookup cares about True Names. (C++11 inline namespaces add additional twists.)
Thank *you*! I'm also taking a course in computational physics, and anything pertaining to RNGs is also quite critical here. Did your parents already know that you would be maintaining the standard library when choosing your name to have matching initials? :)
What about the use case mentioned in the article, where a class needs to "register" itself in another collection? Say you have an event handling class that derives from an `IEventHandler` or something, and you have a set of `lists` containing pointers to the classes responsible for receiving notifications for each type of event. So for example, you'd have: list&lt;shared_ptr&lt;IEventHandler&gt;&gt; mouseEventHandlers; list&lt;shared_ptr&lt;IEventHandler&gt;&gt; keyboardEventHandlers; //.... In response to some event, conceivably our class could want to register itself for some other type of event, in which case it would have to add a shared_ptr to itself into the other collection. In general, how would such a situation best be handled?
The problem is, how does your IEventHandler know that it's lifetime is determined by reference counting? If I have something like: class MyWindowThatNeedsEventHandlers { IEventHandler m_HandleMouseEvents; } Then now we have a problem. Our IEventHandler gets put into a shared_ptr, but it gets deleted explicitly when the window is deleted. It's a mixture of explicit create/destroy and implicit via reference counting. The best way to handle it is to not have shared_ptr on the IEventHandler, since your event handler is going to be explicitly destroyed with the window, and will be explicitly removed from the list as the window is destroyed. If you absolutely had to use shared_ptr for some reason, (which would be weird because it would mean that your event handlers are being hung onto way past when the window is destroyed), the way I would handle this situation is by splitting into two classes: class IEventHandler { class IInnerEventHandler { ... } shared_ptr&lt;IInnerEventHandler&gt; actualEventHandler; ... } This will ensure that you don't get mixing of reference counting with explicit create/destroy. Edits: Trying to get formatting right.
Makes sense, I hadn't thought of that case. So in this case, would it be acceptable to just store raw pointers in the lists, since these pointers are non-owning? 
Yes. I think that'd be best.
The progress on this front is amazing. Is the goal eventually ABI compatibility with visual c++? And PDBs? I've had the misfortune of messing with the PDB format. Personally I would love to get involved with this work but it's been tough finding a good entry point. 
!!x was very popular in the console world as the CPUs had horrible branch prediction and x != 0 could cause all sorts of stalls if done in tight loops.
Ha. I am older than the STL, although soon enough we'll have college hires who aren't...
&gt; “How To Do Random Numbers Right (and How Not To Do Them).” We should ask STL to do his talk from Going Native as a tutorial. /u/STL , will you do your talk from Going Native as a tutorial? :-)
Please read the blog post.
The example given has two compilation units, main.cpp and printer.cpp. One that clang can compile, one that it cannot.
Clang supports the VC++ ABI.
Yes and it doesn't explain how the 2 compile units can link together. It just says they do. I suppose clang-cl mimicks Visual Studio mangling scheme, calling convention and such, but my question is how? Especially since nothing guarantees that VS2008 AND VS2012 use the same one. Not even two different minor versions of the same compiler. I suppose it queries cl.exe to know which version to mimick but I'm interested in knowing more about that.
OK, so it is even worse… (inconsistent and unable to easily express closed or open ranges)
&gt; Write a proposal for the Library Evolution Working Group! :-&gt; I have been interested into getting involved in the further development of C++ for a while, but as a student my current options to visit the meetings are pretty limited to non-existing. Now, if you would champion it… ;-) &gt; so I despair of ever changing rand(). I do not see how preserving the value of RAND_MAX is preventing you of changing to mersenne-twister: // as global variable: std::mt19937 __rand_engine{1}; void srand(unsigned __seed) { __rand_engine.seed(__seed); } int rand() { thread_local std::uniform_int_distribution __dist{0, RAND_MAX}; return __dist(__rand_engine); } Not as nice as what is proposed as rand_int(), but definitely better than what you said is currently used.
&gt; Now, if you would champion it... ;-) Unfortunately, I have difficulty finding enough time to write my own proposals. &gt; I do not see how preserving the value of RAND_MAX is preventing you of changing to mersenne-twister: Part of rand()'s evil is its [0, 32767] range. Replacing the LCG with MT but keeping that incredibly tiny range would make it slower, yet not fix all of the evil.
&gt; There may be more advantages to zero-based indexing (and half-open ranges), which I hope somebody will link here. [Here](http://lmgtfy.com/?q=advantages%20to%20zero-based%20indexing%20%28and%20half-open%20ranges%29) you go, good fellow.
&gt; would make it slower, yet not fix all of the evil. Well, it would fix at least some of the evil. Concerning the part of the decreased speed: &gt; I'm a big fan of making users fix their broken code
&gt; What about the use case mentioned in the article, where a class needs to "register" itself in another collection? This is an anti-pattern that has lead to problems both in my code, and in other codebases where I encountered it. There are several issues - but the most scary one occurs because you have to do this registration in the constructor - which means that you are exposing `this` to other parts of the program before the object is fully constructed - specifically, before the vtable is set up. In one system, we had intermittent crashes - because occasionally another thread would be going through the registered classes (the "handlers" in your example) and try to call a virtual method that didn't yet exist on the class that was in the middle of being constructed! I have a pretty strong rule now that I simply never allow the `this` pointer out into the world during the constructor unless I'm totally sure that it can't be used until the constructor is finished (for example, it's fine to pass `this` into constructors of members). In the case you cite, you can easily fix the issue by putting the construction, and the registration, into a factory function or static factory method.
In the second example, I don't understand what it did to the third SetWindowPos() call. Why didn't it just add more line breaks?
It probably collapsed it like that because of the long expressions in the arguments list. I guess it made more sense for the formatting algorithm to line the arguments up like that. Looks fine to me, still plenty easy to see the arguments block.
I believe that it attempted to use the minimum number of lines, given the selected maximum line length. Because the 2nd and 4th arguments are long (computations), they would have had to stand on their own lines if aligned to the opening parenthesis; this in turn would have mean 5 lines instead of 4. I agree that personally, either all functions arguments are inlined or, if it does not fit, I use one line per argument (at least).
&gt; but my question is how? It's entirely possible to examine what VC++ does and mimic it even if Microsoft doesn't provide documentation. AFAIK the compiler's ABI doesn't generally change between versions. (Mostly it's the C++ standard library that changes in ABI incompatible ways from one Visual Studio release to the next). Even if calling conventions or mangling were changed it would still be no more difficult to support different versions of cl.exe than it is to support all of the other ABIs that clang supports. It just has to use the right ABI for the version of cl.exe it uses. Look for example at how Intel's compiler manages link compatibility with VC++: http://software.intel.com/en-us/articles/intel-c-compiler-compatibility-with-microsoft-visual-c#a_generalcompoptions &gt; The following Intel® Compiler options provide compatibility with different versions of Microsoft Visual C++: &gt; - /Qvc8 Microsoft Visual C++ 2005 &gt; - /Qvc9 Microsoft Visual C++ 2008 &gt; - /Qvc10 Microsoft Visual C++ 2010
there's a configuration option in clang-format to do exactly this, don't know if this extensions exposes it though
I think the PenaltyBreakString = 1000 default setting is responsible for this behavior. So the format algorithm try to minimize the line breakings. I just guessing...
Thanks for the tip! I've uploaded the file [here](https://drive.google.com/file/d/0B-ncg8I3AXqQX2E0cy1pclBvVFk/edit?usp=sharing) for the lazy.
...why can't VS do that automatically? Sure, pop up a warning that it may not be compatible, but why block installation when it takes so little to make it work?
Sorry, I didn't mean to be rude. Your expertise (and Andrew Koenig's, for that matter) is beyond question. Some benchmarks between the different containers would have been very insightful.
Never used clang before, much less clang-format. What do the various penalties do? I can't seem to find any documentation on it.
Recycling my presentation would be lame given that it's on the web. Preparing new presentations takes me forever (GN 2013 took me maybe 2 weeks for the big one and 1 week for rand). Still, I'll think about it...
I saw a talk about that: http://llvm.org/devmtg/2013-04/ http://llvm.org/devmtg/2013-04/jasper-slides.pdf 11. slide So basically the format algorithm builds a decision tree on where to cut the line. And every line cutting possibility got a penalty score, and the lowest win.
On my phone and can't really check out the talk, but what's better with clang-format than for example astyle? (Might add that I haven't really used any formatter very much.)
I just added a caveat to users of Boost's range adapters, and a call for Boost.Range to support C++11.
&gt; Boost.Range can and should store a copy of any adapted rvalue ranges. So are you saying that when an rvalue is given `boost::adaptors::filtered` should return a special `rvalue_filter_range&lt;&gt;`(instead of `filter_range&lt;&gt;`) that will store a copy of the range? I don't think that scales well, as it will copy the range everytime you compose another adaptor, which should really be lazy. This was discussed before on the [boost ML](http://boost.2283326.n4.nabble.com/Range-Range-adaptor-approach-for-temporary-range-lifetime-issue-td4631411.html) with some suggested solutions. Honestly, the Boost.Range library has been stagnant for quite some time(it still hasn't merged in the proposed [Boost.Oven](https://github.com/faithandbrave/OvenToBoost) features), I don't really see it supporting any C++11 features anytime soon. Hopefully, once boost makes the transition to git, it can be forked and improved a lot. 
No, we can do better. Rvalue ranges can be *moved* in. And each application of an adapter creates another rvalue range, which can likewise be moved. So it will probably be just some simple pointer copies, and there's a good chance the optimizer will eliminate dead stores and inline/elide a bunch. At least, that's how it works in my imagination. Benchmarks are needed. And no special `rvalue_filter_range` would be needed. We can make do with `filtered_range&lt;Pred, Rng&gt;`, where `Rng` can be a reference or a value, and perfect forwarding can take care of the details.
Nice! I never liked the redundancy you have in a pair of iterators that wraps a functor or something else that is not really related to what the iterators' actual job is: referring to something. But obviously, if we go into the direction of moving the "smart stuff" from iterators into range objects (a move that I welcome!), we really should be careful about iterators outliving the range objects they depend on. The thinking "a range is just a pair of iterators" won't be valid anymore and it's important for everybody to understand that. I guess it would be a good idea to allow generic code to query whether iterators depend on their range object (like in the case of a vector or your istream_range thingy) or they can live on their own because the range object was just a cheap wrapper with reference semantics. Maybe the copy semantics is even more important: What is a "range" object and what happens if I copy it? Some probably want to write reference-like range objects (like array_ref), others want to write value-type-like range objects (vector&lt;&gt;). Would be nice if generic code could query that.
&gt; And no special rvalue_filter_range would be needed. We can make do with filtered_range&lt;Pred, Rng&gt;, where Rng can be a reference or a value, and perfect forwarding can take care of the details. I see so we would always store a reference for lvalue ranges. However, for rvalues references, we would want to store by value not by reference since rvalue references do not extend the lifetime of temporaries.
Thats awesome. Boost.Range has been needing some updating in a long time.
try /r/cpp_questions 
thank you! didnt know of this sub reddit I will try there. 
Can you use a for loop? That would be much easier: int nameCount = 0; // Stores the number of names entered while (name != "End") { outputFile &lt;&lt; name &lt;&lt; endl; cout &lt;&lt; "Enter Another Name (End to quit): "; cin &gt;&gt; name; nameCount++; // Increment nameCount by 1 for each name entered } //outputFile &lt;&lt; name &lt;&lt; endl; // ^^^ this statement is what's writing 'End' to the file. //close the file outputFile.close(); cout &lt;&lt; "Done Writing File to the Disk. \n"; inputFile.open("demofile.txt"); inputFile &gt;&gt; name; // Iterate n times where n is the number of names previously entered for (int i = 0; i &lt; nameCount; i++) { cout &lt;&lt; name &lt;&lt; endl; inputFile &gt;&gt; name; } inputFile.close(); cout &lt;&lt; "Completely Done. \n"; system("pause"); return 0;
Yes, that's my thinking.
Basically your program works like this: Read the first name. While the name isn't "End" Write the name to disk. Read another name Write the name to disk. &lt;- here's what writes "End" to disk So for every name the user inputs, it gets written to disk whether that name is "End" or not. If you delete the last write to disk, "End" won't get written. However, as a rule of thumb, try to keep the logic for input and output to a single place when possible. That way, if you do something wrong, you just have to fix it in one place. Your order is also a little odd. Try doing input, processing and output in the loop, in that order. Another issue, since you use the cin &gt;&gt; , if the user enters a name with a space in it, the program will write every part of the name on a separate line in the file and display the prompt once for each part of the name. I suggest using getline instead, which reads an entire line. In the second part of the program that reads the file back, you check for "End" again. Since you don't want to write "End" to the file, you can't check for "End" in the file when you want to stop. Instead, check if there's something left in the file to fetch. This can be done in streams with the methods, good(), bad() and eof(). You can also just do if(stream). Here's the program using getline. (Note that getline() returns the stream, so if(getline()) checks if the stream still is good). #include &lt;iostream&gt; #include &lt;fstream&gt; #include &lt;string&gt; using namespace std; int main() { string name; ofstream outputFile; ifstream inputFile; outputFile.open("demofile.txt"); cout &lt;&lt; "Now Writing Data to the file. \n"; //write four names to the file cout&lt;&lt; "Enter A Name (Type End to quit): "; while(true){ getline(cin, name); if(name == "End") break; outputFile &lt;&lt; name &lt;&lt; endl; cout &lt;&lt; "Enter Another Name (End to quit): "; } //close the file outputFile.close(); cout&lt;&lt; "Done Writing File to the Disk. \n"; inputFile.open("demofile.txt"); while(getline(inputFile, name)){ cout &lt;&lt; name &lt;&lt; endl; } inputFile.close(); cout&lt;&lt; "Completely Done. \n"; system ("pause"); return 0; } 
thank you! I was unaware of the getline function in this program as I had just started learning a few weeks ago. i pretty much wrote it using everything i remembered when it came to mind so that may be why its in an odd order. i appreciate your help and input! anything i can learn about this language will help me out. 
im going to try to rewrite it tonight once my visual studio updates. ill try a for loop. i know we've covered those in my class but i didn't quite understand them. since you've pointed out the line of mine that writes "end" to the file can i just remove it? or add some kind of assignment statement that tells the program if name==end do not output? thank you so much for your help. 
The Mac versions are the only ones listed as complete. I would imagine this is due to Apple's heavy involvement in the project. The next largest group of developers would be Linux which is why that version is in reasonable shape. The C++ library is optimized enough that slight platform differences end up causing more issues than you would think. This plus less developer time spent on Linux and especially Windows is why it is the way it is. Short of there suddenly being more Linux and Windows developers volunteering I don't see that changing soon.
Where does it show the status for each platform? The cxx-status page makes no distinction between the platforms ..
You can just remove the line. I commented it out so you could see I was intentionally omitting it. The reason that statement alone writes 'End' to the file is because after the user enters "End", your while loop exits correctly, but you've assigned "End" to 'name'. So after the loop exits, the next statement adds the current value of 'name' to the file (in this case it is always "End" since until the program receives that input it's in the while loop). For loops are pretty easy to understand. They're declared in this format: for(&lt;number type&gt; &lt;variable name&gt; = &lt;initial value&gt;; &lt;expression&gt;; &lt;increment expression&gt;) { ... } In the code I pasted, the for loop declares a variable 'i' of type 'int' and sets its initial value to 0 ("int i = 0;"). The expression is just like the expression in a while loop declaration: it specifies that while the expression evaluates to true to continue running the loop until the expression evaluates to false. i &lt; nameCount is true for i values of 0, 1, 2, and 3 when entering 4 names and becomes false once i = 4 because 4 &lt; nameCount(4) != true. The increment statement specifies how the value 'i' changes for each iteration, or run, of the loop. In this case, it increments 'i' by 1 ("i++;"). You can specify stranger things, like i = i + 2 if you wanted to increment by 2 every iteration or i--; to decrement by 1 each iteration. The reason I changed your second while loop to a for loop is because counting is easier than validating input (e.g., "End" will exit the loop as intended, but lowercase "end" will not so you have to account for that. It's easier to count). Since the user inputs names one at a time, every time a name is entered we can increment an integer that represents the number of names entered so far ("nameCount"). When the loop exits, 'nameCount' contains the number of names entered. So to make sure when reading input that we only read the number of names specified by nameCount we can use a for loop because thanks to the automatic incrementing it makes it really easy to count things. To put all of that into terms of a while loop which you clearly already understand, you could rewrite the for loop like so: int inputNames = 0; while (inputNames &lt; nameCount) { // input logic inputNames++; // increase inputNames by 1 } And it would do the same thing :) 
There are many things in the standard library that aren't implementable in pure C++, or for which sticking strictly to C++ language features or the C library would provide an implementation of inferior quality. Here are a few examples. `std::chrono::high_resolution_clock` could be implemented with using the C `time()` function, but that's usually not really a 'high resolution clock'. Instead accessing some platform API with a higher resolution provides a higher quality implementation. The atomic and threading libraries can't be implemented purely through C++ language features. C11 isn't widely available yet. `std::random_device` should be implemented using a non-deterministic pRNG. Different platforms offer different platform specific sources. The standard C locale API supports only a global locale but C++ provides independent locale objects. If a C++ library implementation is going to provide access to the platform's available locales then it has to access them using non-portable code.
The standard C++ stream objects are convertible to `bool`. What this means here is that you can extract data from an input stream and check that the extraction succeeded within the same statement. `std::operator&gt;&gt;` as well as `std::getline()` return a reference to a stream object. for( std::string name; std::cin &gt;&gt; name &amp;&amp; name != "end"; write(name) ); or for( std::string name; std::getline(std::cin, name) &amp;&amp; name != "end"; write(name) ); In the `for` loop above we `write()` as long as we haven't reached the end of stream or the input was not "end". The check for end-of-stream is done by evaluating the stream as a boolean expression, done in the left-hand side of the `&amp;&amp;` expression in the `for` loop condition. I notice you explicitly close the file. That is not necessary: use a `std::ifstream` for reading a file and a `std::ofstream` for writing to a file, and don't open nor close the file. The two operations are done automatically for you by the constructor and the destructor of the class: { std::ofstream out_file("file.txt"); // out_file constructed and opened } // out_file destructed and closed This is a common technique in C++, called RAII, for Resource Acquisition Is Initialization, and you will see it throughout the standard library as well as any C++ library that respects itself.
I was going off of the [Windows](http://libcxx.llvm.org/results.Windows.html) and [Linux](http://libcxx.llvm.org/results.Linux.html) result pages and other comments I've seen by developers in the past.
I like the idea of use generalized attributes. It could increase adoption speed. I don't know if the $ operator is a good idea. I didn't reasoned enough about it. What do you guys think?
Thanks!
Support on FreeBSD is also excellent. Clang + libc++ is the native toolchain there, starting from FreeBSD 10.
Yeah. Basically, the C way is rubbish. :-P (I really dislike x != FALSE. It's inelegant. Also really dislike that (x != FALSE) === (x == TRUE), here using === to indicate identity.
This is more exciting to me than it should be. I know it takes a huge amount of effort to make this possible, and really do appreciate it, but I can't help being disappointed when a standard is finalized but can't be used for years since there are no widely available implementations. I'm still a fairly green professional programmer, and appreciate that this has likely always been the case concerning standardization and availability. I think Herb has said that going forward we can expect there to be much less lag time between standardization and usable implementations. Clang and GCC are blazing the trail on this one. That being said, [Jim Radigan's excellent GN2013 talk](http://channel9.msdn.com/Events/GoingNative/2013/Compilerpp-) made an argument for why VC++ is slower on this front.
Meanwhile at Microsoft... *crickets*
It's not like they are idle. They just released 2013! More like "wait up guys!" than crickets. That said I am curious how many people are actually working on the teams for the compiler and stdlib. I have every hope that once clang's Microsoft extensions and ABI support are stable, it motivates their native development some more.
Honest Question - Does Microsoft have a single high-quality world-leading product in any domain? Or has it ever had one? Off the top of my head I cant recall a single thing. In any of their product categories, you'll find they have competitors who have a demonstrably superior product. They are just about average/below-average across the board - software, hardware, services, whatever..
Why this over other unit testing libs... why not gtest?
I think he once said that he is the only person *at microsoft* who is working at the STL but since they are using the implementation of Dinkumware, there are of course more people who develop it. As far as I know the library isn't so much their problem too but the compiler that lacks all the features (somewhat the opposite to gcc where the problem is more on the library and less on the actual compiler).
Also stuck on 2008 at work; it is painful. 
Yes, CATCH is my personal favourite. Its main drawback is a completely ungooglable name, but other than that it's pretty much my ideal unit testing framework -- and sections are indeed very nice.
Seriously? It's hard to objectively say superior, and each client has their own needs. Windows and SQL Server are high quality products with some of the best support services and great administrative and management tools. And backwards compatibility that can't be beat. I can still run a stupid proprietary financial application from 1992 on Windows 8. Word and Excel are de facto standards. C# is a great language with cross platform implementations and used extensively. I'm no Microsoft fanboy but let's be real here. 
I have heard some people say that Visual Studio is a great IDE (sometimes along the lines: „the only good product from them“). As Linux-guy I cannot confirm this however. Concerning Hardware: Kinect seems to provide a really great product for it's price. And their mice are fine too (that one is from experience). Aside from that: C# as a language is clearly better than Java (between the blind men the one-eyed is king). The question is whether this isn't exactly what you meant with average if you take C++, Haskell… into this calculation.
Kinect is an example of what I would call average. The depth sensor is average, and the device as an input to games is laggy as hell. Visual Studio is most definitely not a great IDE. Maybe compared to tools on Linux it might be. Intellisense still breaks, solution/project files still get fucked sometimes when you upgrade versions, indexing is slow as hell, and the compiler is constantly behind the competition. Their Mice are Okayish. They are most definitely non-ergonomic. For ergonomic mice you have to have your wrist supinated, which they dont do. I remember my Intellimouse Explorer 4 having a particularly horrendous sensor. It constantly alternated between different mouse sampling rates causing weird mouse behavior in games. I am no fan of Microsoft products. However I am no particular fan of Linux either. I think many distros are shoveling broken junk to their users. I rarely complain about Linux because I'm neither their target user, nor am I paying for the product - and I ship products on Linux so it makes me some money :P
 &gt;This is more exciting to me than it should be. I know it takes a huge amount of effort to make this possible, and really do appreciate it, You should be excited! Seriously, LLVM and CLang have come a very long ways in what is really a very short time. The project has literally knocked GCC off its throne as the open source compiler. OK maybe not off the throne but it is a rocking. &gt;but I can't help being disappointed when a standard is finalized but can't be used for years since there are no widely available implementations. I'm still a fairly green professional programmer, and appreciate that this has likely always been the case concerning standardization and availability. Well if you are on a platform using LLVM / clang you won't have this problem. The nice thing here is you get a significant number of platform choices now. &gt;I think Herb has said that going forward we can expect there to be much less lag time between standardization and usable implementations. Clang and GCC are blazing the trail on this one. That being said, [Jim Radigan's excellent GN2013 talk](http://channel9.msdn.com/Events/GoingNative/2013/Compilerpp-) made an argument for why VC++ is slower on this front. I didn't even bother to read Radigans blurb. VC++ suffers from association with MicroSoft, frankly it has always been a mess. 
Windows Server is good *ONLY* if you buy into their entire office/sharepoint/active-directory enterprise ecosystem. In other words, It integrates well with their other products - which I think should be a basic expectation since they make the other products and associated protocols/specs! C# as a spec document, its of little use to the end users. And maybe their tools surrounding C# are good - according to developers, but then again, nobody else makes C# tools. (Other than the Mono ppl I guess)
Those are an effect of rehashing or change of bucket array size, as explained [here](http://bannalia.blogspot.com/2013/10/insertion-complexity-of-c-unordered.html).
iterators as half open intervals are the right paradigm for operating on n dimensional surfaces...thinghs inherently floating point. A good example of how that paradigm work is when performng lots of subpixel operations on imagery.
&gt; I didn't even bother to read Radigans blurb Awesome. Only on this forum could a post on Clang elicit so much Microsoft hate. I find it painfully telling that Linux fanboys feel the need to whine about Microsoft at every opportunity, The lady doth protest too much, methinks. 
Ofcource, its popular. I use it as well. But is its implementation of a high quality? 
I prefer lest, to be honest, which is based off CATCH but is much more lightweight. 
I think on the slide #3 is mistake, in the line erasing all '5': v.erase(remove(v.begin(), v.end(), 5)); should be given iterator v.end() to indicate the interval, not single element to erase. It should look like that: v.erase( remove(v.begin(), v.end(), 5), v.end() );
redditor___ is right. `erase(pos)` erases a **single element**, while `erase(first, last)` erases a **range**. Therefore, you always need to use `erase(first, last)` with `remove()`, `remove_if()`, and `unique()`, otherwise you'll leave garbage in your container.
Slightly better is static_cast&lt;bool&gt;(x).
Well parhello-c++11 is pretty poor. Far better would be something like this: string msg = "Hello World!\n"; tbb::parallel_for(tbb::blocked_range&lt;int&gt;( 1, msg.size() ), [&amp;](std::size_t n) { std::cout &lt;&lt; msg[n] &lt;&lt; '\n'; } //although note that cout isn't thread safe. );
Could you steer me towards a better discussion on how tcmalloc works? I don't think I'm quite skilled enough to understand the source code but I'm definitely interested in learning more about it. 
From the looks of it there are a few instances where Boost 1.55 doesn't work too too well with MSVC 2013, although the bulk of it will be fine. From the boost mailing list, it seems like MSVC 2013 has a substantial number of C++11 related bugs that the boost developers haven't had time to work around yet. Hopefully that will be fixed by the next release.
&gt;doesn't work too too well with MSVC 2013 It's almost as though you shouldn't use an awful C++ compiler!
Predef documentation is lacking some love
MSVC and shitty C++ support? How unexpected!
Excellent, thank you!
Possibly an excuse to try [clang-cl](http://blog.llvm.org/2013/11/the-clang-cl-fallback-mode.html)? It''s a reasonably safe bet it doesn't work well for platform specific things though.
7 years since last release. wow. 
If you have a better solution for Windows development - be my guest.
I'm still trying to trace the exact date myself - but it seems that boost::GIL was updated in either 1.54 or 1.55, but without any notes on the release information, or any updated documentation. It's a pretty significant update, making it a very attractive solution for any image file conversion, handling and in-memory access. I'm personally taking a look at some of its inner workings right now to get a feel for it.
MSVC 2013 was released a few weeks before the planned release. No surprise they can't support it fully. boost is mostly volunteers, there -afaik- isn't a single paid maintainer, like Qt has. But both releases 1.54 and 1.55 weren't perfect, but I guess they never could release, if they wanted to fix ALL the bugs first...
The Intel compiler has a free trial of several months. Not a perfect solution, but if you really want to get rid of the MS compiler, it's an option. Not sure why anyone would hate on the MS compiler. It's one of the best out there.
How does Wx compare to gtkmm and Qt these days?
you can write platform independent code without having to use a platform agnostic toolchain / compiler (as I do myself, using STL, boost, Qt and other cross platform libraries almost exclusively). The problem with using MinGW is that, regardless of which fork you take, the Windows support for STL features is actually behind that of MSVC. You may have a larger selection of C++11 features to choose from, but threads and asynchronous tasks aren't available in any MinGW distribution I've found so far. If you're working on Windows - MSVC is easily the best option for you. Write code that supports MSVC and GCC / Clang and ensure it's platform agnostic - there's your cross platform support. The only use I have for MinGW is for when I don't have a Linux VM handy or just want to test some library free C++ code.
Have you discovered a way to use boost signals without bloating the binaries? Or perhaps a way to make boost serialization quick and efficient?
Does anyone know if if wx works with directfb now? 
There is an on-line one book also: http://en.highscore.de/cpp/boost/frontpage.html
How it bloats the binary?
I transitioned a project from using Qt 4.8 signal/slot to boost::signals2. It more than tripled the compilation time with gcc 4.7 and I'm pretty sure I was careful with unnecessary includes, using forward declarations and private implementations wherever possible. On the flipside, the application was significantly faster after the transition (about double on average, 20% minimum improvement, in some cases four times as fast).
That's a pretty weird release note. It doesn't state at all what has been added/deprecated/changed/upgraded/fixed. I couldn't care less about loc counts.
The MinGW-builds distribution (http://sourceforge.net/projects/mingwbuilds/) actually does support std::thread, though I'm not sure how well since I've only used std::this_thread::sleep_for from it. However, I did find that their std::random_device is broken: it always returns the same number! Which is about the last thing you want from a random number generator, especially one that is described as being non-deterministic. So, using MinGW does seem to be a toss up as to which standard library features will actually work...
...until you need to debug.
make it go yellow 
Make it go blue. 
using the keyboard is a lot harder than using the game pad you would be better off waiting to use the keyboard till next year when we are aught next year 
Intel ICPC and hopefully soon clang.
&gt; It's one of the best out there On the grand scheme of things it's really not. It allows atrocities like and the underlying build system is a bit of a joke (our windows builds always take considerably more effort and time than any other platforms). void f(my_type&amp; v) { } int main() { f(my_type()); //passing rvalue to mutable reference. }
Yes, break your project up, espeically the more expensive boost elements for example in a recent project I parse user input with spirit. I have the function that does that along with all the other spirit related stuff (includes and so on) in a separate file. That way if I am working on another function in the same class or area then I don't end up recompiling the parser too. Also don't forget, a lot of the boost stuff takes a while to compile because it's actually doing a hell of a lot of leg work for you.
My problem isn't so much that it isn't truly random (which I probably wouldn't have noticed), more that, at least on my computer, a call to random_device always returns 0 :-P
There is a minimal wxDFB port which is actually used on some commercial embedded devices but which would need more work to become usable for general purpose applications. Unfortunately there doesn't seem to be much interest for it in the community.
Qt still uses its MOC compiler for some magic (foreach keyword, slot/signal, QObject stuff) and does not use native widgets. signal/slot stuff in latest version is using C++11 features, like range-for instead of foreach. Wx uses native widgets and it is 100% C++ compilable, it does not use something like MOC but for signal/slot for example it uses horrible macros. Of course this is a very gross and fast comparison
I recommend you to create something like an Input class. That class will read keyboard, joypad or whatever and will have a public interface like "up()", "down()" and so on. Then in your game loop you can check that class' instance and move accordingly: if(input().up()) { hero.move(0, Speed * deltaTime); } This is just an example, of course you need to handle it somewhat differently if you want to allow diagonals, etc.
LFLL is a C++ fuzzy logic library designed to be fast and to use as little memory as possible. The library is heavily template based and is header-only. Moreover, IT DOESN'T ALLOCATE, so it can be used in embedded real-time systems. It doesn't use any third-party dependencies other than the standard library. It is also thread-safe. Any sugestions or remarks are very much welcome!
I must say that this book is actually a better read than OP's. While I like the content of "Boost C++", the book is written in an extremely hard to read English, thankfully I know Russian enough to figure out what author tried to say. Also the examples are a bit hard to grasp. TL;DR: it's hard to write a good book on boost. 
So basically it boils down to: "If you want to keep compile times as minimal as possible, do not expose boost headers in you interfaces"
&gt; Qt still uses its MOC compiler for some magic (foreach keyword, [...]) `foreach` doesn't need moc, it's just macro magic like `BOOST_FOREACH`. And with C++11 you don't need either.
Depends what it is, I would allow for signals in my interfaces because not doing so would make the code pretty hideous. However for example I made with spirit, it makes more sense to use a fixed interface (string iterators, rather than templated iterators) and compile the spirit code into it's own .o. If something is taking a really long time, something like the pimpl might help too. Watching includes is also important, if you can use forward decs then that often helps; and not just for boost types but your own, say if your own ADT has a boost signal, including it's header is going have to pull in all of boost signals. Where as if you can just forward decl' your own ADT (say if you just have a pointer to it, or take it by ref in function) then you can avoid that. Hopefully tooling that will help reduce dependencies is right around the corner.
Read boost asio's doc, they convinced me that you really it need it for that library. However I do agree it's not something that should be used liberally.
I don't know about those things, but pure performance-wise (on a Windows system) it's leagues ahead of most compilers.
The tool will be great for libraries like zlib that can be translated to native js. As a C++ optimist, c++ code will be available in more places, proving yet again that C++ is here to stay. As a C++ cynic, I put sweat and tears to get the last bit of performance from the hardware... and then it's translated to js :)
Here too, random_device always return 0 =/. It should atleast return chrono::system_clock::now().time_since_epoch().count() ...
Always compile with /W4 - there's at least a warning for the Evil Extension.
Too lazy to write it out, but what is that last solution with that giant array doing?
It's an array of digits representing a large number (up to 10,000 digits). It starts out set to '1' and then they go and multiply it by each number up to the input number, thus the array ends up being 1 * 2 * 3 * ... * p, or factorial(p).
I don't have a fair way of comparing GCC on linux versus MSVC on Windows, so I can't answer that. I can tell you the Intel compiler doesn't work significantly better for my code on a Windows platform, but it's been a while since I tested. Since there's a new MSVC out it's probably a good moment to compare, though. I'll see if I have time tomorrow. On our HPC, the Intel compiler runs circles around the GCC one. [again: for my code. I wouldn't know how to build a proper test. Then again, what's more relevant than the code I'm trying to run?]
I really can't say I do, despite having spent a large amount of time using it and reading about how to use it.
You can blame stupid users or you can take the position that it's an opportunity for better API design.
`reserve` is mostly used for optimising insertions into a `vector`. You shouldn't be applying optimisations that you don't understand, and likewise you shouldn't be using `reserve` if you don't understand it. But if you can think of a better API feel free to share.
&gt; using Ints = std::vector&lt;int&gt;; wat?! i didn't even know this was possible, typedef please...
Wow. This is garbage. I actually remember this blog from the another shit [post](http://en.reddit.com/r/cpp/comments/1p03bw/stl_is_dated/) that was made. Please stop posting and upvoting this guys blog, it is crap.
I did wish the STL was made more accessible when I was first learning about it. Ive just come to accept it for what it is now. I have a feeling me being comfortable with the language has blinded me a bit to how steep its learning curve is. The APIs do say exactly what they do and don't do though. Always irks me when issues like these pop up because of the APIs being misread or ignored. 
It's what all the cool kids are using (hah!) these days. Seriously though, read up on this thing called `C++11`.
Uh. you mean [this](http://stackoverflow.com/questions/10747810/what-is-the-difference-between-typedef-and-using-in-c11) or [this](http://stackoverflow.com/questions/11224336/c-typedef-vs-using)? Seems they are equivalent, and I would choose typedef because it doesn't require newer versions of tools.. The only C++11 features I pay attention to are the ones that actually add something to the language..
I find it somewhat difficult to blame somebody for writing this: people.reserve(people.size() + 1 + sisters.size() + brothers.size() + parents.size() + aunts.size() + uncles.size()); people.push_back(self); people.insert(people.end(), sisters.begin(), sisters.end()); people.insert(people.end(), brothers.begin(), brothers.end()); people.insert(people.end(), parents.begin(), parents.end()); people.insert(people.end(), aunts.begin(), aunts.end()); people.insert(people.end(), uncles.begin(), uncles.end()); The `reserve()` is perfectly cromulent *if* this will not be called in a loop on the same `vector`. Called for a thousand `vector`s, great. Called for one `vector` a thousand times, boom quadratic. I view this as neither a failing of the API, nor a failing of oblivious users. This is a higher-order subtlety which requires understanding not just the code itself but the context in which it may be called, which is especially difficult for compilers/libraries to warn about, but also not trivial for humans.
Wow. Can you explain your scenario in a little more detail? I've never used Flyweight and I'd like to get some idea of situations where it'd be useful.
I have always just done this but creating a new class, doesn't seem that horrible...(and the syntax is almost identical..) template&lt;typename T&gt; class MyVector : public std::vector&lt;T, MyAlloc&lt;T&gt;&gt; { } But alright..
ickysticky, It is alway nice to hear from a fan. I'm sorry that my posts are not to your liking, but I am happy that they seem to be memorable. Although perhaps not for the right reasons. If you'll continue to give constructive criticism, I'll continue to improve. Thanks for your comments. Jon
It seems that you did learn something from the garbage.
Doesn't mean it isn't garbage, that is a problem that was solved in C 20 year ago, another solution doesn't seem particularly useful..
I do appreciate your positive attitude. Especially in light of overwhelmingly negative comments, not only from myself. :) Glad you are getting something from it.
You wouldn't blame someone for writing the code you just posted? Why not? It is doing something very simple, that is hard to determine from that code. That seems like good criteria for *bad code.*
`MyVector&lt;int&gt; a{ 1, 2, 3 }; // error`
I just don't understand why you seem to think this makes sense, they way reserve behaves is straightforward... If you decide to override the default resizing behavior of std::vector, you better understand that behavior.. EDIT: If you disagree and decide to downvote, the least you can do is explain why you disagree so that I can potentially learn..
I consider it to be an honest mistake that an enlightened but novice programmer could make. (I would blame someone for gross negligence, like rolling their own container with arithmetic growth.) I am not saying that such code is good - in fact, I strongly recommend against `reserve()` except when an invalidation guarantee is needed, and then it should be used with caution - I am saying that it is not the kind of code you can look at and say "ha ha stupid users".
I guess I kind of figure these kinds of posts assume "good code." If they weren't there is probably more simple and much more basic issue mucking up the code than this..
&gt; This seems like a good use, until you realize that this code is being called in a loop. Well d'uh? Who would have thought that memory reallocation in a loop is not cool? &gt; nasty performance bug that some of my co-workers found By that you surely mean their work performance?
&gt; better API design. Yes, the best API design would be that the user doesn't have to care about a vector's memory usage. But ... this is still C++ where many use cases require that you care about it. If you want "better" API design there are lesser languages like Java or Python for you.
I am not swinging the downvote hammer - that's somebody else. It is entirely possible for somebody to be familiar with vector's geometric growth, yet want to avoid multiple reallocations when inserting several batches of elements, yet not consider the next-level subtlety of what happens if this is called in a loop. I don't understand what you mean by "seem to think this makes sense". What I have been saying is that relatively knowledgeable programmers with good intentions can walk down this path to doom, which is actually unusual for a C++ gotcha.
`vector` reallocation in a loop is totally cool. You can `push_back()` a million times, or `v.insert(v.end(), kilo.begin(), kilo.end())` a thousand-element range a thousand times, and you'll get linear complexity, because vector grows geometrically. The gotcha here is that because `reserve()` is allowed to (and typically does) give you exactly as much memory as you ask for, you can trigger quadratic complexity.
&gt; The gotcha here is that because reserve() is allowed to (and typically does) give you exactly as much memory as you ask for, you can trigger quadratic complexity. Yes, that's what I mean by reallocation. Calling reserve() in a loop is like calling realloc/malloc repeatedly. The automatic reallocation that std::vector performs is the best behaviour for this case (final buffer size unknown). In fact I resorted to the same behaviour for manual managed memory in a C project where the final size of the buffer couldn't be known ahead. Though my growth algorithm was pretty primitive: Always double the allocated memory size ;) /edit: typo
All *recent versions* of major compilers have support for these things. Are you going to claim that recent version of all major compilers are readily available for most platforms? If there was an easy way for me to provide the most recent version of gcc to all my devs then that would be great, but there just isn't.. EDIT: But thank you, that is a good point. Inherited constructors are definitely useful, but again the work around is just to declare a method. I typically try to avoid using constructors for more than initializing everything to default values. Since doing anything complicated in a constructor is a recipe for trouble.
I completely understand what you are saying. The thing about reserve is that you don't need to use it. You are actively making the decision to "optimize," when you do that you should understand what you are doing. Plain and simple. Hell you should have hard tests with profiles to show it makes sense IMO, but most people don't go that far.
&gt; Calling resize() in a loop is like calling realloc/malloc repeatedly. Calling resize() in a loop is totally cool. Calling reserve() in a loop is bad. for (int i = 0; i &lt; 100; ++i) { v.resize(v.size() + 1729); // LINEAR complexity, yay! } for (int i = 0; i &lt; 100; ++i) { v.reserve(v.capacity() + 1729); // QUADRATIC complexity, boo! } I don't think you can look at this difference between resize() and reserve() and say "duh, of course". (As an STL maintainer, I do feel that way about lots of things that other people apparently consider non-obvious - e.g. the iterator invalidation rules are almost always transparently obvious to me - but even I view reserve() as non-obvious.)
Again I will repeat what I said about reserve, you don't *need* to use it. You need to make the choice to call it, and if you don't read and understand the documentation and still decide to use, I don't really know what more can be done to help you.. EDIT: Basically it sounds like bitching about unexpected behavior, when the person was not in a position to know what behavior to expect in the first place.
Sorry, typo. I of course meant reserve. &gt; but even I view reserve() as non-obvious What is non obvious about it when you have read the docs? Are you a STL maintainer for MS maybe? ;)
Thanks for the correction :)
Which is the whole point of the blog post... so that next time someone tries to 'optimize' some `vector` code, they have better knowledge of the semantics of `reserve` and it's potential misuses. &gt;you should understand what you are doing This blog post is meant to contribute to that factor
Shouldn't it be on by default? Especially now C++ has Rvalues.
Using is much nicer than typedef; the real issue is using the name `Ints`.
The whole backwards compatible thing is a red herring. If you are writing good idiomatic C++11 then you're code will probably not be all that easy to convert to C++03. Given heavy usage of auto, C++11 lib features and lambdas (and so on).
Hats off to your ability to take criticism gracefully. Most people would be yelling at the guy now.
Looks interesting. Could you include some examples of using this library to solve example problems?
C being praised in a C++ /r/? Stroustrup sheds a single tear.
you forgot the constructuve criticism he was asking for... why is this one bad and why was the last one bad?
&gt; Are you a STL maintainer for MS maybe? He is *the* STL maintainer for MS.
&gt; Not sure why anyone would hate on the MS compiler. It's one of the best out there. Its very buggy. It always requires workarounds for perfectly correct C++ code. It breaks it mysterious ways. When I was writing my [Linq](http://pfultz2.github.com/Linq/) library, I had to switch to using manual type deduction instead of `decltype` and `std::result_of`, and add several other workarounds for msvc, and Linq still only partially supports msvc(it fully supports gcc 4.5 which has experimental support for these features). I can't seem to get the rest of it to work. In one place, msvc gives an error, because it incorrectly uses the wrong return type for the lambda. If I reorder my tests, then some other lambdas that did work, will now break. This is a complete mystery to me, as there shouldn't be side effects. Futhermore, I usually need to randomly add `mutable` to my lambdas(or make my function objects non-const), or wrap them in `std::function` which has a performance cost. Sometimes, I have to avoid using `std::bind`, as that will break as well. I think their compiler is one of the worst out there. A feature in msvc will work on a small test case, but it will break when it starts to interact with other features. Its extremely difficult to write good libraries for msvc because of this. Ultimately, I get the feeling that the code for msvc is this big legacy code with some architectural issues that they keep hacking on to add new features. It needs to be rewritten from the ground up, but project lead sees that as too costly, so they just hack the new features in. It becomes a slow process to add new features, and the code breaks when it used outside of the simple test cases. 
Hopefully everyone who knows about std::vector::reserve() knows that std::string (by way of std::basic_string&lt;&gt;) has ::reserve(), too. Every += on a string is potentially a reallocation, and I've seen dramatic performance increases by reserving enough space in a dynamically built string to avoid them.
Can I ask when this was? I've read the more recent versions (I think 11+, but not sure) have been cleaned up significantly to improve compatibility issues and whatever. Anyway, I should have been more nuanced in my reply. My programming is purely focused on algorithms. I don't use much fancy stuff, it's basically just simple math in loops with the occasional function pointer and lambda. There's just not much that can go wrong. What matters for me is performance and the MSVC does it well. All things considered, I guess I do understand why people would hate on the MSVC, but I wouldn't go so far as to call it an awful compiler. Personally, GCC has given me more trouble than MSVC and I don't even want to get started on the asshole who thought XCode was a better idea than an actual C++ compiler for iOS. Now that thing is shit.
&gt; Can I ask when this was? This is with msvc 11. Msvc 10 would just crash. &gt; I don't use much fancy stuff, it's basically just simple math in loops with the occasional function pointer and lambda. Yeah, and my code(aside from the macros which do work in msvc) was just some simple functions calls, with some lambdas or function objects, nothing fancy. Of course, it turned into something more complicated because of workarounds for msvc. &gt; I guess I do understand why people would hate on the MSVC, but I wouldn't go so far as to call it an awful compiler. I would. Plus, I don't think it should be called a C++ compiler, since its clearly documented that it will produce different runtime output than a standard C++ compiler. &gt; I don't even want to get started on the asshole who thought XCode was a better idea than an actual C++ compiler for iOS. I'm not sure what you are referring to. Xcode is just an IDE, it uses clang or gcc to compile, which are actual C++ compilers(unlike msvc). 
All of us, no matter how talented, are bad programmers on some days.
Not sure why this is an issue? Usually classes are capitalized, right? It's a bit short, but it's clear enough - if I saw it in code, I'd understand it perfectly well, though I might say something like IntVector myself.
&gt; Usually classes are capitalized, right? Hell no. My mantra when writing code is "do what the standard does". For Java that means camel case, for C++ that means "snake case". It's not `Vector`, it's `vector`, it's not `UnorderedMap` it's unordered_map. The problem with `Ints` is not because it is capitalised, it is because it doesn't tell me ANYTHING about the actual types involved. using vec_int=std::vector&lt;int&gt;; whilst not as snappy tells me all I need to know. Even `vec_i` would be better. `IntVector` would be fine too, but as I said I strongly abide by my mantra. EDIT: A note on my mantra, this is actually important when you start writing libs. Consider the following class MyContainer { //... void PushBack(const_reference r) { ... }; All well and good, right? Up until you want to do anything generically like use a `std::back_inserter` which relys on the presence of `push_back`. (Qt "gets around" this by providing both which I think is hideous).
&gt; I would. Plus, I don't think it should be called a C++ compiler, since its clearly documented that it will produce different runtime output than a standard C++ compiler. MSVC is standard-compliant. I'm not sure what you're trying to say here. The standard XCode compiler (I don't know which one that is; I don't use it myself) refuses to compile code that works perfectly for MSVC and the Intel compiler. (No, the code did not include Windows-specific code. The bits I remember is that certain STL container constructors would not be accepted by XCode compiler.)
Probably. I believe the IDE defaults to /W3 because /W4 is somewhat noisier, but in my experience the noise is worth it.
yes I agree, with GCC and Clang I always crank up the warnings. I still think they should be default. Although I really really do think that MSVC should just start rejecting the reference thing altogether unless you enable it.
Yep. Mail `stl@microsoft.com` to confirm and I'll meow at you. (I had to request that - they initially gave me `slavavej` but nobody can type that.) The non-obvious part is that `reserve()` is allowed to bypass geometric growth. It *could* be specified the other way, but then people would complain about `vector` allocating unnecessary memory in response to an explicit reservation request.
My flyweight success story: https://github.com/Aegisub/Aegisub/commit/d5aae26d838db103fe84f6b4c3ae72ca65403019. Twice as fast and a quarter of the memory usage (on Windows with VC++ 2012) without any significant design changes. The code in question is essentially just a vector of a struct with several std::strings [1], which is copied in its entirity after each change for the sake of undo. Typically all but one of these strings would fit within the small-string buffer, and those short strings are heavily duplicated between the individual structs in the vector. I had planned to switch to a copy-on-write scheme where only the rows modified would be copied each time, but before doing all that work (it was going to require a significant redesign) I decided to see if just flyweighting each of the strings would be good enough. As it turns out, in addition to being much easier, flyweight was actually better than what I had planned, as it also eliminated the duplication of strings in different structs of a single vector. The fact that flyweights are pre-hashed and can be compared with pointer equality also sped up some other parts of the program. [1] In that commit it was using wxStrings, but the effects of flyweighting them stayed about the same after switching to std::string.
&gt; MSVC is standard-compliant. I'm not sure what you're trying to say here. Im talking about [dependent name lookup](http://msdn.microsoft.com/en-us/library/w98s4hs8.aspx), which is clearly documented as not standard-compliant. This is huge. Name lookup is not undefined behavior in C++(and it shouldn't ever be considered undefined), its actually well defined. However, in some cases, when your program compiles with msvc it will call a different function, and have completely different behaviour. &gt; The standard XCode compiler (I don't know which one that is; I don't use it myself) refuses to compile code that works perfectly for MSVC and the Intel compiler. There are two compilers that can be used with xcode, clang or gcc. I don't recall which it uses by default. However, gcc is version 4.2, so its very old, and has no C++11 features in it. &gt; (No, the code did not include Windows-specific code. The bits I remember is that certain STL container constructors would not be accepted by XCode compiler.) I'm not sure what this issue is, it could be a bug in libc++, or it could be that you were calling one of the additional constructors added in C++11, but is missing because you are using libstdc++, which is a very old version that came with gcc 4.2, and has no C++11 features. Also, I'm not sure which one xcode picks by default, but I do know if you compile from the command line on the mac, you have to explicitly tell clang to use libc++ otherwise it will always default to lidstdc++, even in C++11 mode.
I think history has left you behind. Google, Microsoft, JUCE and Qt all use CamelCase - indeed, I wasn't able to find any major C++ library that doesn't, with the exception of the STL. I'm aware of the fact that the STL doesn't use capitalization at all - but that makes for hard-to-read code since you have no way to tell between variables, functions, classes and constants. It's been over 30 years since the STL first came out. I'm quite certainly that if they did it today, they would use mixed case. I'm interested, however, to see if you know of any other major C++ libraries that follow the STL's convention? I did manage to find a couple of drop-in replacements for STL classes, most notably btree, but that seems to be it...
Thanks for posting this! Now I can finally update my [stackoverflow answer](http://stackoverflow.com/a/11583676/554283) on header-only library targets in CMake. Also, the idea of "Compile feature specification" is really good! I'd love to see that in a future version of CMake.
Tom, I don't think it is "the STL's convention." I would call it the standard convention or perhaps the K&amp;R convention. The convention comes AT&amp;T's Bell Labs where C was invented. That convention was adopted by the C Standard Committee and then the C++ Standard Committee. This predate's Alex's submission of the STL. I believe that Alex used the same convention while creating the STL--before he even considered submitting the library to the Standard Committee. But then he came from Bell Labs, so it was a natural for him to use it. I think any code from the Standard Committees will follow that convention. I would think that Boost counts as a "major C++ library" and it follows the standard's convention. Boost uses it because the original idea for Boost was to be a stepping stone to standardization. If Boost used a different convention, then every library from Boost that was submitted for standardization would have to have its API re-rewritten. Ugh. I don't think that the Google, Microsoft, JUCE, or Qt libraries that you reference were created with the idea that they would one day become part of the standard. That gave them a free hand in establishing style conventions. If any of these libraries are proposed for standardization, the committee will be faced with the decision to either change the style of the API to be consistent with the rest of the standard, or to accept the API "as is" as a standardization of existing practice. That will be an interesting decision to watch. My money is on them changing the existing API to be consistent with the standard convention. 
I didn't mean that you learned a better solution. I simple meant that you learned that this is possible in C++11. Whether you think it is better or not, you will see it in C++11 code and (IMHO) need to know that it is possible.
Microsoft is a big C++ proponent, and at one time they were ahead of the rest on implementing C++11. I think they have more interest than you're giving them credit for and without support from big users like them C++ would become less popular for new projects.
&gt; return Number(std::rand())/Number(RAND_MAX); Killing me, you're killing meeeeeeee - http://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful
All good points. I can't believe I missed boost as a library! 
Listen to his advice, please use boost::random or c++11's random 
all right it's time for me to look into this whole functional programming business.
Okay, do you believe that a company like Microsoft does not have the resources to produce a fully conformant optimizing C++ compiler if they wanted to? Their C# implementation isn't lagging the spec. And look, its *perfectly fine* to have business priorities, but then at the same time you don't get to pretend you're this "big supporter" of C++ without actually doing the work. AFAICT, their only interest in C++ is to produce a compiler that can compile Office, Windows, Visual Studio, MSSQL, etc.
Haha, I love that this comment is from "STL"
&gt; Google, Microsoft, JUCE and Qt &gt;indeed, I wasn't able to find any major C++ library that doesn't, with You didn't look very hard, boost, nt2 (and other numeric libs), intel TBB, utfcpp, **microsoft parallel paterns**... (I could keep going if you like?) NB: you point to include microsoft was wrong. (I mean we aren't talking about win32 api or c++RT). Not to mention that I use the stdlib more than I use those combined. It's not that I don't use capitalisation at all, I use CamelCase for compile time entities. template&lt;typename InputIerator&gt; void f(InputIterator iter) { ...
&gt;They still need to create a conformant implementation which does not deviate from the spec. You're missing the point. Presumably they make the spec because they own the language. They won't release a spec before it's already decided and implemented I think, at least not by much. &gt;Why are we talking about education? Because you're making this all about their compiler, and being the world leader in making compilers is not a prerequisite for being pro-C++. Your complaints that they aren't spending enough resources on it instead of the GUI are unfounded. The skills needed to make a nice GUI are different from the skills needed to make a compiler, and the GUI is for all supported languages not just C++. To work at Microsoft both teams have to be made of specialists and leading experts, and the projects are basically independent code-wise so they won't interfere with each other anyway. Shit happens in software development. I remember hearing that it took *several years* to get template support on major platforms (yes, even gcc). Language features won't necessarily be implemented right as soon as the ink is dry. &gt;A lot of the features were pretty much decided on long ago if you have been following the work of WG21 - Whch Sutter is a member of. You're right but if they had included them it would have cost them money and made them non-conforming, and developers on other platforms would be complaining about "non-conforming proprietary extensions" all the while. Sure I guess they could have privately started developing those features, and they might have for all we know and just not made them public yet. My main concern is that they don't become partially conforming then stop progress, then we'll be walking on eggshells sometimes trying to see if things will compile on Windows.
&gt; c++11's random Does the MSVC STL have this already? \*g\* 
It's not too late by any means but apart from the marketing talk, Microsoft does not genuinely seem invested in C++ as a development platform. From their point of view there's likely little to be gained from investing heavily into a standard compliant C++ compiler that can facilitate at least a decent level of cross-platform development. clang and gcc seem to be getting all the attention with Google and Apple doing really really cool things with clang. But MSVC seems to be a mostly niche product among Windows developers compared to Microsoft's primary language, C#. EDIT: My argument is about standard C++, which admittedly I was not clear about. MS is certainly invested in non-standard C++.
&gt;They won't release a spec before it's already decided and implemented I think, at least not by much. Not exactly. They submitted a language spec to ECMA before implementing their compilers and other tooling. Anyway that is a side point. &gt;Because you're making this all about their compiler, and being the world leader in making compilers is not a prerequisite for being pro-C++. No, but having a compiler that can compile the latest C++ is a prerequisite :) &gt;Your complaints that they aren't spending enough resources on it instead of the GUI are unfounded. Why? The GUI team seemingly is adding features left and right. The compiler is lagging behind. Whats unfounded about that? Why cant they hire more compiler developers? That would be "walking the walk" in my opinion. &gt;Language features won't necessarily be implemented right as soon as the ink is dry. Their competitors have managed to do so. (compilers, not the standard library)
&gt;What do they say about adding people to a project that's already behind? Who knows...Feel free to take it and apply whatever they say to a project thats actually behind. MSVC is not 'behind' , MS is simply not that interested in its progress as other compiler vendors are. Anyway, you're no closer to convincing me of your point than I am to you - no point in discussing any further. &gt;As you can see, they are making progress, I think they'll get there soon enough. I've switched to clang for personal projects. My use of their compiler is only where I require it for work purposes.
Haha well what I was getting at is that you can't make a baby in 1 month with 9 women. If they're behind, adding people may well slow things down due to the training needed to even start working. &gt;Anyway, you're no closer to convincing me of your point than I am to you - no point in discussing any further. Yeah I agree. It's really a minor disagreement.
Microsoft is definitely heavily invested as C++ as a platform - both for internal reasons (the entire company is built on C++) and external reasons (C++ provides the best level of performance for apps running on their platforms). As far as cross-platform, by which I think you mean C++11/14 conformance, the gain here is that there is a huge customer demand for these features: both internally and externally. Plus, Herb works there. Several other voting WG21 members work there. It's a high priority. I disagree that C# is getting all the focus. Sure, it's important, but looking back at the trends over the past few years if anything I see development on Windows platforms drifting back towards native. 
I feel the same way about C#. Either both are not feeling MS love or we are both missing something.
Well, lets see: - Since Windows XP, most of the new APIs are COM based, hence C++ - Since Windows 8, the DDK allows for kernel space drivers written in C++ - C++ AMP for GPU computing - PPL for multicore programming - Casablanca for REST services - NuGET support for C++ libraries - WinRT is built on COM - C is considered legacy and C++ is the language to go for native coding in Visual Studio - Visual Studio 2013 has lots new tooling support for C++, even if it playing catch up the .NET parts It looks that it getting enough attention to me. Of course the main focus is game development and applications that demand high performance. 
&gt; Sure, it's important, but looking back at the trends over the past few years if anything I see development on Windows platforms drifting back towards native. It seems that even on the desktop .NET might go to a route similar to the native compilation used in Windows Phone 8. It was mentioned briefly in the .NET talk from the VS 2013 launch, but without giving specific details.
Yes you are absolutely right and I was going to make those points myself. When it comes to adding proprietary extensions to C++, Microsoft has actually invested quite a bit into the language. My argument is about standard C++.
They are invested, but also I think lacking man power, if we are talking about the actual compiler. Which Company did innovate its C++ Compiler with an AST this year? Right, that was Microsoft ... so, I guess in the coming years MS will be able to catch up. Still clang is the hyped new platform, which makes it easier to implement new features, so more people do so. Thats just the power of open source, that a lot of people can contribute. And regarding Intel, I've heard some people loudly thinking that they might switch totally to clang.
Ok, I fully agree with you. Although to be fair, all compiler vendors do extend the standard and there is a C and C++ world outside clang and gcc. If you look at the embedded market, commercial UNIX systems and game consoles, remaining Windows vendors, Microsoft is not that bad.
&gt; NuGET support for C++ libraries This was huge to me when I found this out a few weeks ago. I was getting so frustrated manually setting up linking and include directories for 4 different configurations and now I just make packages as I need them and keep my own personal nuget repository. As for the new tooling in VS2013, it's nice but from my perspective not much different from VS2012. Peek Definition is very cool, but the Visual Studio team *really* needs to do a UI polish pass on VC++ stuff. Adding additional include directories? The dialog box has remained virtually unchanged since VC6. The nice, full-screen, easy-to-edit project properties from .NET are nowhere to be seen in VC++, requiring you to edit tiny little property grid lines like a caveman. Seriously who thought putting a list of directories on a single line was a good idea? .NET projects get nice big multi-line text boxes and VC++ gets absolute shit. And don't even get me started on custom property pages. I thought, oh hey, I'll create a set of .props files so I can have my output, include, library directories etc. use a project variable instead of hard-coding the workspace path! Nope! Shit barely works and there's very little documentation on the whole thing. Also, for whatever reason, the Property Pages dialog occasionally spazzes out and screws up its own layout. Also sometimes creating new project configurations either doesn't take at all or it does work but it's not reflected in the UI. And good luck figuring out what your app will look like if you're using the Win32 Application Wizard. No explanation or pictures of what any of the UI styles look like, and there's nothing on MSDN about it other than "Visual Studio style toolbars" or whatever. Explorer style? Like old Explorer or new Explorer!? JESUS GIVE ME A HINT. Shit, in the modern age of x64 applications, why can't I have a blank project with Win32 AND x64 configurations by default? So much about VC++ pisses me off. I was already writing an extension to automatically manage linking to libraries when I came across the nuget solution. I should write one for their god-awful project properties.
&gt; clang is the hyped new platform Yeah, but there's substance behind the hype: Complete C++11 and C++14 (in the svn) support. While MSVC doesn't even have complete C++11 support yet. (And let's not talk about C99).
&gt; Complete C++11 and C++14 (in the svn) support. The compiler, not library, if I am not mistaken. &gt; And let's not talk about C99 It is called Visual *C++*, not Visual C. Microsoft has officially communicated more than once that they won't provide C99 and you should go to other compiler vendors for C99/C11. Actually even on the ISO C++ update video from Herb it is mentioned there are no plans for such support.
libc++ has been C++14 feature-complete since September (before the compiler).
Stephan T. Lavavej - he knows more about the STL than you. ([proof](http://channel9.msdn.com/Tags/stephan-t-lavavej)) He's also the maintainer for Microsoft's STL implementation.
C++11 random is very nice, lots of generators to choose from and even a non-deterministic one. Mersenne twister is probably what you want if you need fast random number generators. (Beware its not cryptographically secure if you need that)
Actually, it is called Microsoft Visual C++ and the standard library that ships with it is not a Microsoft implementation. 
We shipped TR1 &lt;random&gt; in 2008 SP1. As TR1 evolved into C++0x and C++11, &lt;random&gt; has been significantly updated. Notably, [in 2012](http://blogs.msdn.com/b/vcblog/archive/2012/06/15/10320846.aspx) I totally rewrote `uniform_int_distribution` so it returns perfectly unbiased results. [In 2013](http://blogs.msdn.com/b/vcblog/archive/2013/06/28/c-11-14-stl-features-fixes-and-breaking-changes-in-vs-2013.aspx) we fixed even more bugs so you should definitely be using that now.
You can read [my slide deck](http://view.officeapps.live.com/op/view.aspx?src=http%3a%2f%2fvideo.ch9.ms%2fsessions%2fgonat%2f2013%2fSTLGN13rand.pptx) in PowerPoint's web viewer (which even displays my gradual reveals).
I've heard microsoft say this many times, and I fully believe they mean it, but I cannot for the life of me understand WHY you would not implement C99. What is the disadvantage in doing so? If I want to use C you are seriously going to require me to declare all of my variables at the beginning of the scope? Are you serious?? Lots of open source projects are written in C, many of them don't support windows at all simply because setting up another compiler on windows is already a hassle. Honestly, it's a 14 year old standard now, surely it can't be that hard to do?
I am glad that it was brought to attention. I wrote about the shift operations, but no one hears. My article: [Wade not in unknown waters. Part three](http://www.viva64.com/en/b/0142/). My examples of errors in open-source projects: [V610 examples](http://www.viva64.com/en/examples/V610/). 
Thanks for letting me know. Of course it has Microsoft in the name, like most products have the company name. As someone that uses Visual C++ since the 2.0 version, I guess I am pretty informed about it.
Having two languages in many C++ compilers is just a consequence of the initial effort many vendors had to bring developers into the C++ side. Personally, I don't care about C and really like that Microsoft is helping pushing it away as we need better languages for systems programming. Of course you are right, in the sense that it makes hard to integrate open source projects that are C based, but on the Microsoft's target market for C++ seems pretty ok with it. I haven't written a line of C code since 2001.
Have you used any of the languages based on C, such as Python? Wouldn't they benefit from having a native compiler in order to build extensions?
It's not the shift by 0, it's *rotating* by 0; specifically, the shift by `(8*sizeof(T)-rot)`. Really could have been written more clearly.
Where clang has much more man power and the advantage of a modern code base. As I said, MS introduced an Abstract Syntax Tree this year to their compiler, imagine writing C++11 and C++14 features in a 30 year old code base without. The whole industry has people working on clang, no wonder they are faster...
No, all recordings are more or less lost. Some are with out sound, some are corrupt, and some feature noise instead of sound. So, this approach of recording has failed, and for next year I'll switch to videocameras with audio line-in. As C++Now is recording.
Where did you see that their compiler now has an AST? 
Was mentioned by Herb Sutter at BUILD and afaik also Going Native.
&gt; Crypto code is nice and mathy: a perfect target for formal methods. Actually, that can make it harder for formal methods. Imagine for example that you're analyzing the implementation of a protocol that includes checksum verification and the program you're running on the code tries to look for code paths that put your protocol implementation in a bad state. Now it will possibly have to invert that hash function used for checksum verification.
Ok, why not just use glm?
the anti microsoft delusion is overwhelming
GLM is very capable and certainly has more features, it doesn't get it right completely. I can't go into lengths right now, so just a few reasons from the top of my head: * GLM is highly susceptible to ambiguity errors (int vs float vs double); in GLSL you don't have to add 'f' to the floating point literal for it be single precision, hence if you just grab a shader from the web and try to run it you'll likely get errors due to that * GLSL allows you to use higher-dimensional vectors when constructing lower-dimensional ones; GLM supports only limited cases of this - this code won't work: vec2 p1 = vec2(0.25,0.5); vec2 p2 = vec2(0.75, p1); * GLM has no means of fighting global scope name polluting that standard library headers cause; for that reason when you call sin function with a scalar argument you will always call the one defined in &lt;cmath&gt;, not glm::sin. Unless you qualify it explicitly, but it is a no-no for shader emulating When it comes to less practical reasons, my personal opinion is that GLM suffers from "code diarrhea" - too much repetition, too many macros, too many types. For instance, it has a separate type and a header file for each vector and matrix dimensions. It is just a terrible design in my opinion. EDIT: just playing with it and it seems GLM can't handle operators on swizzled vectors: vec2 a; a.xy += 1; // error C2659: '+=' : function as left operand Tested on MSVC10.
Turns out emulating fragment shader environment is easy with just a handful of macros. Please take a look at the [glsl_sandbox](https://github.com/gwiazdorrr/CxxSwizzle/blob/master/sample/main.cpp#L49) namespace from the sample. EDIT: To elaborate, this really isn't a problem. Simplistic sampler is implemented in the sample, as well as uniforms. Attributes and varyings can be "implemented" just like uniforms.
Ok, then why do that instead of using one of the countless GPU debuggers / shader development environments out there? I can see using something like this for general vector/matrix manipulation (how glm is intended to be used) but this seems to be trying to be a shader emulator... I only see a handful of cases where this might be more useful than a shader debugger and I see many cases where people will make incorrect assumptions or decisions about shader performance and behaviour by developing it on a CPU instead of on a GPU where it will actually be running
These debugging tools certainly have their place when diagnosing shaders problems. However, there's nothing to my knowledge that lets you just step through a shader. Or put an assertion. Or log intermediate values to a file. Or set conditional breakpoints. Basically when "emulating" a shader as C++ you get all the benefits of C++ mature debugging. The way I look at it it can be useful for prototyping or reverse-engineering. Or maybe just to get a better understanding of what's going on.
AFAIK he only talked about adding an AST, not that it's been completed yet. Plus they've been working toward adding an AST for years.
Well, then it explains it even more why they are yet not fully C++11 compliant. I was quite shocked as I heard, that they seem to have no/full AST support in their compiler yet.
It's a shame C++ doesn't have something like D's opDispatch. With that a swizzling implementation takes just a [dozen lines of code](https://github.com/Dav1dde/gl3n/blob/master/gl3n/linalg.d#L361) or so. C++ seems to be getting some inspiration for D lately though so hopefully we'll see something like that in the not too distant future.
No, it doesn't! Some compilers at some levels of optimization do. Frankly, I don't know why the Standard doesn't make at least some performance guarantees for tail recursion. This is similar to the situation with RVO (return value optimization), which is also allowed but not guaranteed. Except that lack of TRO may result in a much more serious problem: stack overflow.
Fo' shizzle!
Both Nsight and the visual studio 2012/13 GPU debuggers should allow you to set conditional breakpoints
It's doing a shift by 32. The function as a whole does a rotate, if you want to rotate by 0, a shift of 32 is performed.
A few tips: * This smells like homework; if you are asking us to do your homework for you, we (hopefully) won't, and you look extremely lazy for requesting it. If it's not, explain *why* you want this behavior - whats the goal of it? On the other hand, if it is homework, most people will happily nudge you in the right direction. * Whenever you ask a question, include a minimal example that demonstrates your problem. In this case, it's the whole program. If I type `cout&lt;&lt;x%2` into visual studio and hit compile, do you think it will? Give the full source needed to simulate the problem, along with expected and perceived input/output. Having this example properly formatted with highlighting helps immensely (various free sites on the web provide this service - then just add a link to your code in the question). * Along with the above, what else have you tried, and what were *those* results? Once you have a working program, you can often google the problem you are seeing "does cout print right to left?" would be a question that can likely be found with a simple search. * Clarity. I have no clue at all how to answer the above question as it's worded. I understand not everyone speaks English as a first language, and working in code further complicates things, but really try your best to have proper grammar, etc. * Debugging: There are 2 great ways of debugging code easily. One is to run it in your favorite IDE and set break points. If a multi-part `cout` expression isn't doing what you want, change `cout &lt;&lt; x &lt;&lt; y;` to `cout &lt;&lt; x; cout &lt;&lt; y`. Also, simplify the problem when debugging an algorithm - if your program is crashing when passed in a huge data set - what about a smaller one? Divide and conquer is your friend.
My c++ language is basic, but here is what I did. void dec_bin(int x) { if(x&lt;1) //if x is smaller than 1 program ends { cout&lt;&lt;goal_bin; //spits out goal return; } goal_bin = goal_bin + pow(10,k_bin)*(x%2); //each time assigns goal a number between 1 and 0 based on x%2 k_bin++; //adds 1 to k dec_bin(x/2); //divies x by two and recursively starts the function } I defined both goal_bin and k_bin globally and reset them to 0 everytime I call main.
sorry about that I didn't really know where to put this in the first place.
Oh, I didn't know that, sorry again. won't happen again. I just needed help with my homework and didn't know where to ask!
&gt; Clang’s undefined behavior sanitizer revealed all of these problems trivially. Use it, folks. Miam!
this sentiment belongs in the 90s. you're likely old and haven't gotten the memo that google is the new man to hate good luck have fun
Noticed it here: http://www.techempower.com/benchmarks/#section=data-r7&amp;hw=i7&amp;test=query
These graphs could use a legend. I have no idea what is meant to be along the left axis. 
Y-axis is insertion time in microseconds/element, I've added an explanation to that effect in the article.
Why GPLv3 for something like this? Doesn't that rule it out for a huge fraction of potential users?
Comparison with only one stdlib implementation? Lame!
I AM NOT A LAWYER: Only if you are selling it as part of a piece of software to a customer. If you are running it on your own servers and presenting a web interface to end users this is not the case. That said, its still a library, and I really wish people would put those under the LGPL/zlib/mit instead of GPL. But it's their stuff, so they can put it under whatever they want in the end.
So, can someone explain this to me? I understand that different operating systems or compilers ship with their own standard libraries, but are there many alternative standard lib implementations that people use? A lot of the C++ book I read imply that there are.
Its not necessarily that there's many standard lib implementations (although there are quite a few too) but that a lot of the algorithms and containers might be implemented in other stdlib-like libraries. There are for sure tons of various implementations of hash tables, which is what /u/klemensbaum may be referring to.
The whole point of this was to hack together simple linear regression solver as fast as I could this is not production code. I learned about the linear regression, task accomplished. This took me about 20 minutes including debugging. I am not familiar with the C++11 random API as I have only used it once, but when I need secure random number, or quality random numbers I will look at it. I am familiar with crand so it saved me time.
I've found google's dense/sparse hashmaps: https://code.google.com/p/sparsehash/ to be far superior to anything in this article. On my test machines I got ~0.3 usecs per insertion. std::unordered_map had similar performance as well. Honestly, the cost of the hash function itself should always far outweighs the container's insertion costs. Check out spooky hash: http://burtleburtle.net/bob/hash/spooky.html if you're looking for a good general purpose hash function.
There are five standard library implementations of note: the original STL and its derivatives SGI STL and STLPort, Rogue Wave/Apache C++ Standard Library, gcc's libstdc++, clang's libc++, and Dinkumware's stdlib. All of these are portable to some degree, and have been used for real purposes with compilers other than their "primary" one, but these days there's rarely a reason to. The non-compiler affiliated ones are long unmaintained; Dinkumware is not free and so is generally only worth using outside of VS if it's your only choice (i.e. for some embedded stuff); libstdc++ and libc++ aren't different enough to justify the hassle of using something other than the platform-default stdlib. The problem with only comparing with Dinkumware is just that it doesn't really tell anyone on non-Windows platforms about whether or not it's worth using the boost containers over the stdlib containers, and of course there are a lot of non-boost, non-stdlib containers that could be compared as well.
I am an equal opportunity hater. I hate many things about many companies. Google is on that list too. 
I honestly do not get why a header-only library is something you'd ever need. If you don't want to explicitly install the testing lib, you can always add the *hpp and the *cpp files from the testing lib to your test project and compile them all together. The advantage would be that large portions of the code coming from the testing lib are only compiled once in the life time of your test project. libunittest comes with some unique features that are hard to find with other testing libraries: Tests can be run in parallel; Support for test templates; Support for test contexts; Support for setting timeouts etc.
Because libunittest comes with some unique features that are hard to find with other testing libraries: Tests can be run in parallel; Support for test templates; Support for test contexts; Support for setting timeouts etc. 
I am not sure about this. With GPLv2 you would probably have been fine running it serverside but it seemed to me that the goal of GPLv3 was specifically to lock that down.
Nope, GPL doesn't cover output of a program. For example, you can use gcc (GPL v3) to compile non-GPL programs.
I was more thinking about the fact that being a library you would need to link it with your own custom libraries that use it to actually produce said output; it seemed to me that with GPLv3 anything linked to the library had to be released as GPLv3 too, though I may of course be off-mark, those licenses are way too hard to read for my taste.
If they're your own libraries, then you'd be fine - GPL doesn't force you to share your code if you don't sell the software - just the output of it, so you could make "release" them under GPL3 internally. I have no idea how that would work 3rd party closed source libraries, though. 
AGPL is the license which requires that you distribute source for servers. GPLv3 closed some loopholes where getting the source would not actually let you compile and run your own binaries, but did not extend the situations in which source has to be provided.
I believe 3 was a shot at things like TiVo that use Linux but don't let you modify the system.
Header-only libraries seems to me like trying to get around the drawbacks of the language, such as that C++ does not feature a module system. It is probably (and unfortunately) true that there are developers out there that don't want to be bothered with compiling and linking against external libraries. But that's the language and a testing lib is not a second class citizen. I don't really have 'selling points' for libunittest because every developer has different needs and requirements. The features I mentioned are important for my development with C++ and might be for others too. To see what I mean by test templates, please check out this example: http://sourceforge.net/p/libunittest/code/ci/master/tree/examples/templates/ And for test contexts this one: http://sourceforge.net/p/libunittest/code/ci/master/tree/examples/flexible/test_something.cpp Cheers! 
Does the BOOST_ASSERT stuff have any facilities for working with formatted strings? It's not instantly clear you can't do that.
&gt; You submit your control program to the C++Robots server via eMail. Your program is compiled by the GNU C++ compiler and loaded into a robot. Your robot then fights each of the robots "on the hill", one at a time. You get a duplicate test platform? Do you have more details?
Well yes you can use `BOOST_ASSERT_MSG` the following way: #include &lt;boost/assert.hpp&gt; #include &lt;sstream&gt; int main() { float min = 0.0f; float max = 1.0f; float v = 2.0f; BOOST_ASSERT_MSG(v &gt; min &amp;&amp; v &lt; max, static_cast&lt;std::ostringstream&amp;&gt;(std::ostringstream().seekp(0) &lt;&lt; \ "invalid value: " &lt;&lt; v &lt;&lt; ", must be between " &lt;&lt; min &lt;&lt; " and " &lt;&lt; max).str().c_str()); return 0; } Now which do you prefer? I know which I prefer. #include &lt;pempek_assert.h&gt; int main() { float min = 0.0f; float max = 1.0f; float v = 2.0f; PEMPEK_ASSERT(v &gt; min &amp;&amp; v &lt; max, "invalid value: %f, must be between %f and %f", v, min, max); return 0; } 
Hmmm.. reverse connect back to the developer, write a GUI to display it, and control it with the keyboard. That'd be fun.
It's on the main page: http://www.gamerz.net/c++robots/c++robots.tar.gz
I'm so stupid, I thought this was for physical mobile robots. Nevermind. 
I thought it only mattered if you distributed the software, and selling / price was irrelevant? 
You're still not allowed to break the license. If you want to use two libraries, one of which is disallowed to deal with the second, unless you can change (= own) the second, you'd be breaking the license. Sure, it's nearly impossible to detect if you don't distribute the code, but that doesn't mean that the breach is not there.
No I don't mean sneaking, I mean afaik only redistribution of the software without source isn't allowed. &gt;For example, if you distribute copies of such a program, whether gratis or for a fee, you must pass on to the recipients the same freedoms that you received. You must make sure that they, too, receive or can get the source code. And you must show them these terms so they know their rights. I don't think it applies to non distributed software. &gt;8. Termination. You may not propagate or modify a covered work except as expressly provided under this License. Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11). &gt;To “propagate” a work means to do anything with it that, without permission, would make you directly or secondarily liable for infringement under applicable copyright law, except executing it on a computer or modifying a private copy. Propagation includes copying, distribution (with or without modification), making available to the public, and in some countries other activities as well. &gt;9. Acceptance Not Required for Having Copies. You are not required to accept this License in order to receive or run a copy of the Program. Ancillary propagation of a covered work occurring solely as a consequence of using peer-to-peer transmission to receive a copy likewise does not require acceptance. However, nothing other than this License grants you permission to propagate or modify any covered work. These actions infringe copyright if you do not accept this License. Therefore, by modifying or propagating a covered work, you indicate your acceptance of this License to do so. So you are free to modify it, not distribute the modifications, and it will be still under gpl+no legal issues from not releasing the source to your unreleased program. This is my understanding of it, although I'll admit I am better acquainted with the wtfpl &amp; mit. edit: On second reading, I perhaps misunderstood you. 
Yes, these are two separate problems. If you don't distribute the software - only its outputs - then GPL doesn't force you to share the binary code of your application. The second problem (the one I was writing about) is that GPL v3 requires the rest of the program to use a compatible license. If you're using your own libraries you're fine - you can say "in this case they're under GPLv3" and be done with it, since you're not forced to share them anyway. But you can't do that if you're using a 3rd party library with non-compatible license. The only way to work then is to write a thin wrapper over one of the incompatible libraries and connect to it via sockets or other similar mechanism. That said, I'm no expert - this is all just my understanding.
clang looks very promising - too bad it contains some weird, but still very bad errors. Look at the chrono error for example. It is a too normal feature to allow a bug with it. But using clang with vim and C++ development looks awesome - give [this talk](http://channel9.msdn.com/Events/GoingNative/2013/The-Care-and-Feeding-of-C-s-Dragons) a look-see.
&gt; I've always found it bizarre C++ people stand by iostreams so much while Java people healed and added printf like formatting ;) They are not perfect sure, but there flaws are *most* syntactic. Their functionality is good. Being able to add `op&lt;&lt;` and `op&gt;&gt;` for ADTs is a god send in comparison to printf. Of course with variadic templates there are cleaner ways to do the same thing, but currently it's not worth the hassle. Also I actually find streams very easy to read; actually in addition to a boost format assert the following would be useful too. ASSERT(x &gt; 0) &lt;&lt; "x must be larger than 0 x: " &lt;&lt; x; That said whenever I write my own assert it just remains a macro var and is streams into `std::cerr` so it can be anything with a `op&lt;&lt;`;
I confirm, this is the first autocomplete to work out of the box as expected. 
I get your point. Beside personal preferences, there are circles were STL and / or Boost are banned.
Streams aren't in the STL. And if you are writing C++ without the C++ standard library then I don't really think you are writing C++ at all. Anayway, I see you're point, but it would give me a reason to use your lib; as I am a big believer in assertions.
&gt; The problem with only comparing with Dinkumware is just that it doesn't really tell anyone on non-Windows platforms about whether or not it's worth using the boost containers over the stdlib containers, and of course there are a lot of non-boost, non-stdlib containers that could be compared as well. I don't have easy access to other testing environments, but if you do I'd more than welcome your gathering the data for a further entry devoted to compilers other than MSVC. All the necessary material (the test programs and Boost 1.56) is available online. Please come back if you're interested.
what chrono bug?
I have been using it for quite some time. works really great, the only problem I had is that it required Clang 3.2+ to compile, but that has been solved on systems where default Clang package was updated to version 3.2.
Doesn't look very future-proof: the width of the vector is static, so if I want to utilize full potential of e.g. AVX, I have to use float32x8 vector type, which decomposes into two __m128 values on SSE. This results in almost doubling of instructions in critical loop bodies. This may not be a huge problem currently, but I would rather not have to inflate the loop bodies four times if I want to support AVX-512. Having said that, it's very nice that this library lets me write code that compiles to almost optimal assembly for instruction sets that cover more than 90% of the market. The library would be much more appealing if the issue with vector widths was solved somehow.
&gt; If only MSVC++ had it... It does. Something very similar at least. http://msdn.microsoft.com/en-us/library/ms182032%28v=vs.110%29.aspx Does not work during normal compilation though, you have to run in "analyze" (= slow) mode.
[This one](http://urfoex.blogspot.dk/2012/06/c11-fixing-bug-to-use-chrono-with-clang.html)
If I would write a blog-post for every compiler-bug that I encounter… Though: Clang has more bugs then gcc, I'll grant you that.
I wouldn't consider async/await to be more than a prototype to gain some experience before standardization. If requiring 8.1 allowed to get it into a preview state sooner, then I'm all for it. If they're going to use it to force migration to their new OSes, then sorry, no. I'm also glad they are making progress. Those C++14 (generic lambdas, return type deduction) features will make my life easier once they hit RTM.
thread_local would have been nice.
You can write a pretty nice cross-platform await implementation now using boost::coroutine. See https://github.com/jbandela/cppcomponents_libuv/wiki/Easy-Asynchronous-Programming-with-cppcomponents_libuv#resumable-functions-and-await for an example.
The one that I am really happy about is thread-safe static init. This is the one feature that if you don't implement it, there is no compiler message, but your code is thread unsafe and you will experience weird failures. Got bit by this bug before, so glad it is being fixed
It looks like it's a libstdc++ bug (according to R.Smith, please see their bugzilla entry). I think they've made some workaround for it in 3.2 (which is almost a year old). It definitely compiles with clang 3.3 and libstdc++ from gcc 4.8.
It would be interesting to see what the actual cost is in "binary bloat" from using templates and what the improvement to runtime performance between templates and a solution like this.
&gt;In Qt you could use the QMap::contains() typically you'll write: if(contains(key)){get(key);} bam, 2 hash map hits. &gt;for(set&lt;string&gt;::iterator i = b.begin(); i != b.end(); ++i) { &gt; a.erase(*i); &gt;} since you don't use std::copy but iterate, this will be sub-optimal on a vector of PODs that can blast through with the equivalent of a memcopy. &gt;I’d prefer to go with the plain old C rand() sure, for your project that doesn't truely need random numbers and uniform distribution. http://channel9.msdn.com/Events/GoingNative/2013/rand-Considered-Harmful have no fear though, you can wrap those into simple functions once (takes 5 minutes, never need to look at the code again): https://github.com/matthewaveryusa/averyws/blob/master/stable_libs/utilities_random.hpp regarding boost::asio &gt;I implemented a quite complicated machinery, with an asynchronous timer and an asynchronous read operation... Bad implementation, what can I tell you. I've implemented timeouts with an 8-line callback... https://github.com/matthewaveryusa/averyws/blob/master/libs/ws_session.cpp#L589 The bottom line is that C++ is a language for professionals concerned about performance and correctness. Clearly you care little about performance and correctness. If you want to write code quickly, which is perfectly comendable, then don't go with C++. This has nothing to do with stl/boost and more about what _kind_ of code you're writing. If it's string manipulation for a non-critical system, don't write it in C++, you're not using your time efficiently. 
Damn, looks promising too bad it requires the latest and greatest everything to run it. Didn't install or build right out of the box, fixed the python configuration errors and it just errors when launching vim. MacVim dosn't seem to work at all and installing the latest version of vim w/ python support greater than 2.5 causes vim to just segfault. GL to people trying to run this on MaxOSX 10.8.5
Nice to see another Core C++ video. Thanks STL! I might not be on VS2013 for awhile, but it'll be nice to know what the latest features of it are. Charles must be busy with other stuff? I used to be able to check [http://channel9.msdn.com/Niners/charles](http://channel9.msdn.com/Niners/charles) every so often and pretty much be guaranteed not to miss the best videos of Channel 9, but this one was posted under [golnazal](http://channel9.msdn.com/Niners/golnazal). Edit: Started to watch the video. Just a note on my wording above: the features being talk about are in a Visual C++ compiler CTP, which doesn't have anything to do with VS2013. That is, it's an alpha compiler. Either way, nice to see some new features being made available to play around with.
As a user of YouCompleteMe, the only real downside it has is that it takes massive amounts of memory if you are working with decently sized codebases and have more than one tab going.
http://ctags.sourceforge.net/
The whole blogpost just seems to be full of inexperience. Yes, boost can be hard to use. Don't like it? Well go ahead ban it on your project. But don't tell me that rand is fit for consumption by anyone. Boosts trade-offs don't bother me so I'll continue to use it on my own projects.
I believe in this case you can also write a shim layer wrapped in a plugin to use. This still requires you to implement a plugin system to get around the license, and publish the interface code of the plugin. But it doesn't require release of the main code of the program, just that shim.
That little library is the kind of thing that should be in boost. By all means have powerful general interfaces which you can use if you need, but provide for the common case as well, standard, and it'll make for more readable, less buggy code. There's more than a few similar libraries in one of my projects, and I hate that they have to exist (one's a three line function to calculate a CRC32 because apparently that's not general enough for boost...). Code which is hard to write is even harder to debug and reason about, and is therefore less likely to be correct.
I've used boost.geometry a few times and it's not a geometry library. It's components for writing a geometry library. That's not terribly hard to do, but one is left scratching one's head as to why there isn't a higher level collection of classes wrapping up the lower level stuff for common use cases. Very similar experience with boost.graph.
Package includes all of Boost? Is that really necessary?
&gt; * (Proposed for C++17) Resumable functions and await Ohoho what is this? Python-style yielding/generators, perhaps? Are there any more detailed articles about this? EDIT: well, I found this http://meetingcpp.com/index.php/br/items/resumable-functions-async-and-await.html. It's... really really ugly. I have to say I am not a fan of the line between language and standard library getting more blurred. It introduces a new keyword, `async`, which marks a function as a resumable function. That function's return type can now only be `void` or `std::future` (or `std::shared_future`). At that point, some fancy-shmancy stuff happens involving another new keyword, `await`, that allows other things to be called in parallel. EDIT 2: I finished reading the article. At the bottom he talks about another proposal- real generators for C++, using the new keywords `resumable` and `yield`. This has me much more excited. EDIT 3: Went ahead and read the paper he linked (http://isocpp.org/files/papers/N3722.pdf). Now that I understand how `async` and `await` are supposed to work, I like it a little better- the idea is that the function returns the future immediately on the first call to await, and `get`ting the future causes the function to resume. Clever.
It's annoying but it's a consistent philosophy. What if they wrote a really good, big, complex geometry or graph library and then it wasn't quite right for my needs? The whole thing is now useless. Have toolkits is, generally, a lot better than having libraries.
&gt; The bottom line is that C++ is a language for professionals concerned about performance and correctness. Clearly you care little about performance and correctness. I would say that C++ is a language for people who care about performance. It is incidentally for professionals because only professionals who care about performance will bother using it and its needlessly verbose APIs or read more than a handful of terse compiler error messages before they decide their time is better spent with another language. That performance minded professionals are also anal about correctness is true. Not sure how you read his article and came away with the impression he doesn't care about correctness. Unless your definition of caring is that people care as much as you.
I'm saying, Why not both? People would surely use boost::graph::simplistic. I'd guess it would offer some virtual base classes to inherit from to implement nodes and there'd be a graph container class that uses std::vector adjacency lists, rather than offer a choice. As it is the hyper generic approach (vice some inheritance and sane defaults) makes the whole thing effectively inaccessible to many, I'm betting. It's daunting the first time you try to use it.
I love You Complete Me. Though admittedly it was a bit of a pain to install.
Two other resources: * Straight from the horses mouth: WG21 [post-Chicago papers](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/#mailing2013-10). There are actually no results for await (on the page, I'm sure there are in the papers) but there are results for resumable functions, async and futures. * The Going Native 2013 talk [Bringing await to C++](http://channel9.msdn.com/Events/GoingNative/2013/Bringing-await-to-Cpp). My (fuzzy) memory of the talk is that it is overly VS specific and only tangentially about possible future standards. If you're at all familiar with C# async/await, it does some comparisons with how they work in C#.
Everyone goes through this when you first start using C++. It takes time before you really appreciate the way things are done and why they are great. http://i.imgur.com/lVmi3iL.jpg
http://stackoverflow.com/questions/8610571/what-is-rvalue-reference-for-this
True, I may have been a bit harsh. I was particularly thinking about rand() and how it's incorrect. 
i spent an unreasonable amount of time trying to get this to work on windows. never could.
RCU? http://lwn.net/Articles/262464/
Sounds to me like this person should be trying harder to learn C++ idioms or shouldn't be programming in C++. Boost documentation is not the easiest to read, but that's hardly an excuse for not using it.
It's the sort of complaining you hear from junior devs all the time.
check out https://github.com/Valloric/YouCompleteMe/issues/18 specifically, [this](http://stackoverflow.com/questions/11148403/homebrew-macvim-with-python2-7-3-support-not-working/12697440#12697440) worked for me.
Notice how I emphasized "this 2013 is a date, that 2013 is a brand" in the video. :-&gt;
I don't think you need your -MT. (I use it to keep sources, objects, and dependencies in three different directories.) You're making it say that both the object file and the dependency file depend on the stuff, but you're generating them together, so mentioning only the object file as a target is sufficient (you don't need to worry about somebody coming in and messing with the dependency files). I also recommend adding -MP, otherwise you won't be able to delete headers.
The problem with ctags is it uses a simple token parser to extract symbols. This works kind-of-ok for C but completely falls apart with C++ once you introduce templates. To do C++ auto-completion right you really need a full blown C++ parser. This is also the reason why MS shelled out for the EDG parser to use for Visual Studio's Intellisense.
Yes, you being so clear on that in the video is what made me come back to do the edit.
I asked the compiler dev who implemented await, and he confirmed that the Win 8.1 restriction is CTP-only - we're planning to eliminate it for the next RTM.
First, /r/cpp_questions would have been a better fit for this. Second, it would be helpful to be more specific than "does not work". What's the problem? Compiler error? Crash? Unexpected behaviour? And finally, the snippets you posted are incomplete. At the very least, what's `Vect2`? Better yet, post a complete, self-contained example of how to reproduce this error.
agree with nimbal here, you should really comment your code when having others read it. It becomes a huge waste of time when people have to ask the specifics on everything before they can even start telling you what's wrong.
I keep hearing that Microsoft is out of the C++ game compared to Clang and even GCC. They're behind the game, but they've worked hard for the last few years. I think they got burned when they implemented DRAFT features that got canned, but MS had to keep supporting them because they'd shipped. The reason they're behind probably had more to do with culture and politics than anything. I hope they've fixed that problem.
The documentation is **not** a tutorial and nor should it be. A tutorial takes into account various things like previous experience, current familiarity, expectations, etc which a documentation wont ever do. Its not a good idea to learn about any programming topic by reading API docs. If you are still interested in boost, take a look at this and see if it satisfies your needs. http://en.highscore.de/cpp/boost/index.html 
Are you serious when proposing this crap for working with C++ source code? Completion via clang is good, but what do vimers use for convenient code navigation in large C++ projects? Is vim usable at all for large C++ projects?
So, this CTP won't work with VS2012?
(Genuinely interested in hearing an answer, pretty confident I am not the only one who would love some sort of vim ide. Maybe emacs with plugins?)
constexpr constexpr constexpr ! *opens champagne* 
I wish Microsoft would just give up now. Drop Dinkumware get STL (Stephan) working on clang and get the compiler guys working on clang as well. Open up the C API properly and have a complient suite for developers. People purchased 2012 expecting c++11 complience, then move to 2013 and now it will be more cash and still non-complient. Money for failure is not good. Don't get me wrong I think MS has millions to contribute, take all the await etc. it's great to push this, but, and a big but. The current release capablity of the biggest company with the bigget budget being outpaced and outperformed at every level by open source porjects is becoming embarrasing. I think MS has to pull together with the other communities, especially clang and add their own debugger/ide and even charge for it, but the basics of complient compiler and stl just need to be provided. Forget c+14/17 etc. and do c++11 at least. It's extremely poor and a waste of great resources to continue this route, it's costing developers cash and companies time to try and work with Microsoft and it's compiler/c++ implementation. I re-iterate I thank the MS devs for the work but there is an obvious problem that looks like it would be simple to fix. 
After some point, Qt start to look messy and leak prone, while boost/stl concise and beautifully extensive...
The reason they're behind is the monstrosity that is their compiler front end. They have no AST (source: STL at GoingNative 2013), and only a handful of people are willing and able to even touch the front end code base. 
It sort of makes me wonder why they don't just use EDG's frontend, since they're already using it for intellisense. Too expensive, or do they just think that fixing their frontend will be easier than replacing it (which is entirely plausible even if it's a total mess).
&gt; And as a consequence, I’m currently banning boost from agentXcpp, and I’m going to ban the STL, too. Wait a minute.... The public API uses std::string, std::vector, and std::shared_ptr. How do you plan on banning the STL? Or are you going to require users use QString, QVector, and QSharedPointer instead? I understand possibly replacing boost::optional with something lighter-weight if you don't want to require users to use boost. But I don't understand why you'd replace std::string, std::vector, and std::shared_ptr.
&gt; Most Microsoft shops have volume licenses that allow them to upgrade for free. &gt; &gt; Besides, most enterprises take years to upgrade compiler versions True, but I am not sure that's a reason to behave like this. I know more people now work in projects that are c++11. MS state they think developers are important (soemtimes a little to enthusastically :-) ) and c++11 is important to them according to Herb and many others. I think their current position must be difficult to square in company meetings. If the position is to focus on the enterprise markets and volume license slower moving shops then perhaps it should be made clear. Their presentations do not portray this stance though. Again I am not Microsoft bashing, but would love to nudge them a little.
VCBlog&gt; Visual Studio 2013 is a prerequisite for using this compiler.
&gt; Drop Dinkumware get STL (Stephan) working on clang What do you dislike about Dinkumware/VC's C++ Standard Library implementation that clang's libc++ does better? We're still squashing bugs (bugs keep me employed!), but we have aimed for and generally achieved full TR1/C++0x/11/14 conformance modulo missing compiler features, with the major exception of not shipping threads/atomics in 2010 because we were rewriting the whole STL for rvalue references. &gt; Forget c+14/17 etc. and do c++11 at least. I think generic lambdas are more important to implement before unrestricted unions, to take one example of a tradeoff we had to make.
&gt; but what do vimers use for convenient code navigation in large C++ projects? Nothing that can be called "convenient", unfortunately. Some combination of grep and ctags. &gt; Is vim usable at all for large C++ projects? No IDE is able to handle the kind of C++ projects I've been working with in the last five years or so (MLOCs). Therefore, vim. But I wish there was some good code navigation tool that could be used in such environment.
I guess if libc++ is good enough then working on anything else could be considered duplicated effort, but multiple high-quality standard library implementation is a good thing, and libc++ clearly isn't in desperate need of more manpower. libstdc++ is the one that could use some help.
[cscope](http://cscope.sourceforge.net/) is helpful, so is [doxygen](http://www.doxygen.org/) [opengrok](http://opengrok.github.com/OpenGrok/) is another tool, but it's all generally less convenient than having a local full parser there's also [eclim](http://eclim.org), but it could be considered a thin veneer over the monolithic ide
It's very easy to take "over-generalized" libraries and create the exact functionality you need. It's not so easy to use overly-specific libraries which don't happen to do *exactly* what *you* need.
&gt;What do you dislike about Dinkumware/VC's C++ Standard Library &gt;implementation that clang's libc++ does better? I do not dislike Dinkumware pe se'. I believe the collaboration between them and Microsoft has not produced a c++11 implementation anywhere close to the time of others. In terms of which is better, I would not get into a vim / emacs (vim !! Andrei is totally wrong on this) argument, but I am standards focussed and MS is chasing standards without implementing any fully by the looks of it. (I personally use clang an awful lot so may be biased if I compare them) &gt;I think generic lambdas are more important to implement before unrestricted unions, to take one example of a tradeoff we had to make. I would agree in terms if usefulness (perhaps), but this is where the quandary sets in. I do cross platform c++ so multiple compilers and std libs is great (the more the merrier), but to have a compiler that implements what it thinks is cool really breaks the cross platform thing. We have to code for the lowest common denominator and that's increasingly the most expensive of our compiler toolchains. I would just love MS to be at some known level of compliance, otherwise it makes cross platform really much harder than it should be. Even developers reading books on a c++ version (like the new c++11 books out and coming out) will be amazed when stuff does not work. Sorry if you are misunderstanding my 'nudge' we invest in MS software so believe in it, but it's getting harder and to see gcc/clang outpacing msvc so much is frustrating when we have to code in pseudo c++11. I also do not want to be telling you what job you should be doing though, so apologies for putting you in a position, but Howards a really cool dude :-). It would be interesting to ask the c++ community what they want, a c++ implementation proper or the current 11/14/17 situation. I think the current situation may suit MSVC only shops, but that is not today’s target market I don't think. I think that if MS want apps ported to windows architectures then perhaps it makes sense to adhere to a baseline that can be met across platforms in terms of compilers (just to make ports a little easier)? 
&gt; Why? I dislike that they're slow enough to be able to choose, but I'd much rather have useful parts of C++14 implemented than not very useful parts of C++11. It seems to be the opinion here and I may be in the minority, but I think having all the decorators (default, delete), inheriting constructors, constexpr, non static member initialisation, noexept etc. are very useful parts of c++11. I think these should be in the release product and not the alpha product. Doing c++14 with these in alpha products is cool, but my point is these c++11 features should be in the release product. Although as I said I am possibly in the minority and do not shout too much :-) 
&gt; The reason they're behind is the monstrosity that is their compiler front end. They have no AST (source: STL at GoingNative 2013), and only a handful of people are willing and able to even touch the front end code base. can you comment on that? What is the reason you are so far behind? 
Yes. Is this tool working for you? For example, are you able to rename a member variable? Edit: OK, I see how this tool works now. It was not actually going to rename the "false positives" it was reporting (the checkbox was not checked). I just now noticed the correct changes were in fact checked on the list. I take back my comment (ant I will edit it). The tool does in fact seem to work. I have to think about it, but you might want to put the changes that would take place in the list first. There were so many items on the list (100 or so) that the "checked" changes (~6) got lost in the list and I never even realized they were there. Edit2: Rats! I did not mean to delete the top comment! I meant to edit it!!! Sorry!!!
C++14 features didn't delay any of those (some are in the 2013 RTM, and the rest are in the first alpha that introduced C++14 features), so not implementing C++14 things wouldn't get them to you any faster.
I still wish that the C++11 `random` module had an RNG that was as simple to use as the ones in other languages, where it just automatically seeds with the current time and gives a uniform [0,1) random double. However, I recognize that if the project I'm working on takes so little time to code that the time it takes to wrap the RNG is significant, then I should probably just use another language.
&gt; std::auto_ptr&lt;int&gt; p(new int(i)); I hope that once C++14 will be supported this will not be converted to: &gt; std::unique_ptr&lt;int&gt; p(new int(i)); but to: &gt; std::unique_ptr&lt;int&gt; p = std::make_unique&lt;int&gt;(i); or: &gt; auto p = std::make_unique&lt;int&gt;(i); Asside from that: The project itself is totally mind-blowing and shows what people will build, once you give them a real compiler to built upon instead of some mediocre parser (same for the clang based „intellisense“ for vim). Edit: Fixed mistake, thanks to /u/Malazin
+1 I have used this in anger and it's extremely capable and valuable. Add in the format options and it can transform a scatty code base to something easier to read and therefor debug. Great job clang team !
You should add one to n inside the loop, otherwise "n &lt;= number" will always be true. You might also try using a "for" loop. 
Silly me! I forgot to change the accumulator!
Isn't it `auto p = std::make_unique&lt;int&gt;(i);`? Easy mistake to make and fortunately that wouldn't compile, so you would catch it easy. `std::make_unique` takes arguments to pass to the types constructor, *not* a pointer to take control of. The whole point is to wrap the whole construction process in a safe context, after all.
It's not hard, but a typical use-case is to "have" the iterator if the map does contains the key. I can see novices doing the following because they quickly scan the api listing for std::map see something that looks about right but don't realize the underlying implementation: if (m.contains(key)) { auto itr = m.find(key); ... } This is probably more efficient for the use-case: auto itr = m.find(key); if (itr != m.end()) { ... } or even: auto itr; if (m.end() != (itr = m.find(key))) { ... } 
&gt; I believe the collaboration between them and Microsoft has not produced a c++11 implementation anywhere close to the time of others. Just to make sure we're on the same page - are you aware that Dinkumware is a Standard Library vendor, not a compiler vendor? VC's compiler front-end, C1XX, is solely maintained by MS. (For Intellisense, we've licensed the EDG compiler front-end from the Edison Design Group, but again they don't touch C1XX's sources.) In fact, in the past, Dinkumware's master sources have contained machinery that was too advanced for C1XX to understand, so they sent us workaround machinery to simulate missing features (faux variadic templates, faux scoped enums, etc.). I just want to make sure you're grumbling at the right company. &gt; vim / emacs nano!
Ok, that was before my time - I switched to DevDiv in 2007, so I'm not familiar with what happened before VC 2005.
I would prefer not to comment on the compiler team's planning and scheduling. (As a library dev, I am their client - I usually refer to the STL as the compiler's first and best customer because the STL uses new compiler features before anyone else and finds lots of compiler bugs so they can be fixed before they affect anyone else.)
thread_local for PODs is simple (we already have __declspec(thread)), but thread_local for non-PODs involves dealing with ctors/dtors and is non-trivial. As the compiler team figures out what order to implement features in, they take implementation cost into account, as well as the usefulness of the feature itself (and, occasionally, how loudly their STL maintainer is demanding something).
Yeah I got that too. I think I fixed everything up. Thanks y'all!
Yes you can but it is limited in functionality. The compiler is technically free, as is the basic Windows SDK in general. However, various non-essential Windows libraries that are sometimes used by third party libraries or programs are not included in the Windows SDK and only ship with the full blown version of Visual Studio. In practice this isn't a major problem in my opinion. You can search on Google for Windows SDK or find it here: http://www.microsoft.com/en-us/download/details.aspx?id=8279
Ok. Thanks for the reply, though. Good to see one of the MS tech guys to "out there". keep it up!
&gt; Since this guarantee is not relaxed even if the user calls erase(), a implementation that chose to reduce capacity would be required to... It seems to me that this is a bug in the specification - I'd sure as hell hope that if I call `erase(); shrink_to_fit();` then all the iterators would be invalidated.
Yes, this was definitely an error since the whole idea behind my post was getting rid of the new. 
His hand-coded version of set difference is not quite equivalent to the library method. Set is a _sorted_ container, so difference can be computed in O(min(M,N)) time, by a variation of merging.
Since you seem to be new in C++, I suggest you to learn it the modern way. For starters, use auto in your loop iterators. 
They are invalidated: since `shrink_to_fit()` is allowed to invalidate them, you cannot use them after the call. It's true even if the function is a noop in some implementation of the standard library.
I'm not sure I understand the problem. If a SL implementer decides to implement `shrink_to_fit()` as a noop, it's because there's a very strong reason for that. (It could be that the contents are on hard disk swap, and it's better to waste virtual memory that to recall the contents to copy them.) And if the implementation does it without a very good reason, then it's a shitty compiler, that you shouldn't be using in the first place. 
I do. Vim + Fugitive + YCM works pretty well. On shitty project with shitty code however I have to sometimes get eclipse and do a reference search in the project. I've setup some binding to switch between header/source and replace a variable in the current context (not perfect, of course, but not too bad either).
I completely agree. But I do get a small sense of unease. Their good reasons for 99% use cases, my reasons for reducing capacity, implementations lagging behind, and STL code being illegible - all these things kinda blend together into chaos - I prefer simplicity - if I tell the damned thing to shrink my vectors - I want it to happily oblige and tirelessly work until the heat death of the universe. I guess that's it really. C++ used to be about power and showing your coworkers how close you can shoot a high caliber gun between the toes on your own foot, and occasionally causing damage in the process for everyones amusement. Now they are taking this brutish language in a new direction, which causes some old timers to cringe a bit. I think it's great. 
No worries! **Down with `new`!!!**
What is auto?
The blog post seemed to be implying that nothing is allowed to invalidate them after a reserve, not even `shrink_to_fit`. (I've not read the standard, only this blog post about it.)
Every implementation I've tested does the proper thing with `shrink_to_fit()`. No one should be tempted to avoid it simply because the behavior is not strictly guaranteed. Also there's no need to test the capacity before calling `shrink_to_fit()`; That can be left to the implementation to do. It couldn't be left to the swap trick, because the swap trick is combining a constructor call and `swap()` in such a way that the neither one can know that the swap trick is being used in order to check for that condition. I think it's unfortunate that this article concludes with a doubtful tone and will perhaps encourage developers to avoid `shrink_to_fit()`, and thus cause exactly the problem it's concerned with.
The missing libraries, as in, do you mean ATL? I think DDK has that no? What else? Just wish to make sure. I only do a little programming on Windows so I'm not aware about the more recent changes.
You've misunderstood; He didn't say that `erase(); shrink_to_fit();` won't invalidate iterators. Here he's talking about `erase()` on its own and not in conjunction with the swap trick or `shrink_to_fit()`.
If iterators couldn't be invalidated then there wouldn't be any way to implement shrink_to_fit.
&gt;If a SL implementer decides to implement shrink_to_fit() as a noop, it's because there's a very strong reason for that. Im sure they may have very strong arguments, but lets put the problem from the coder point of view. When would you ever call shrink_to_fit? The answer is - you wouldnt * If you _need_ the optimization of space reduction, you need it, thus calling shrink_to_fit is a bug. * If you dont need it, you dont even call the function. I look into the standard for guarantees. shrink_to_fit gives me none, its effectively a hint. Specifying behavior this way is only harmful IMO. Its akin to saying, 'std::sort will have O(nlogn) average complexity, but its not required to'. I know id just use external sort in such case, because i can then guarantee its behavior everywhere my software runs. Also, swap trick is well known by now, and also pretty much relies on implementations playing nice so the gain is pretty negligable from having this function. All that said, its so meaningless little function that arguing about it seems silly (not quite sure actually, why the committee plays with such things anyways, even if it took minimal amount of time to push for), im more concerned about precedent it sets than the function itself.
&gt; if (c.capacity() &gt; c.size()) { c.shrink_to_fit); } We're going to do this check for you, and in fact, we can do it more efficiently than you can, as shipped in VC 2013. As a user, you can call capacity() and size(), which perform pointer subtractions, which perform divisions by constants (if your element size is a power of two this is cheap, otherwise it's less cheap). But as near-omnipotent implementers, with our endless concern for efficiency, we can do better. When shrinking to fit, we want to know whether we have any unused capacity, not how much we have. We can check this by comparing the size-pointer against the capacity-pointer, and that doesn't involve any pointer subtractions. &gt; Given this, and faced with the fact that shrink_to_fit() may be a no-op, I think conscientious coders will choose to skip the new shrink_to_fit() and continue to use the Swap Trick. "Do you think that's air you're breathing now?" This is a terrible idea. Either way, you're asking the Standard Library to determine the ideal capacity for N elements. Smart implementations will exhibit the same behavior for both. (I haven't checked VC, but I would consider any discrepancy here to be a bug.) &gt; And they may avoid it because the old way gives them guarantees that the committee didn’t see fit to apply to the new call. Incorrect. There are no guarantees for the capacity of a copy-constructed or random-range constructed vector - if you give us 100 elements, we can decide we like 128 capacity. shrink_to_fit() gives implementers exactly the right amount of latitude. We know really detailed stuff about our implementation and our platform, and we should be given the power to use that knowledge. One of these days I should interrogate the Windows heap devs to better understand the behavior of HeapAlloc so we can potentially tune our reallocation accordingly (VC's string has tricky growth behavior which I suspect is an attempt at doing this, although vector's growth behavior is smooth).
This was certainly not my intent. The section you are quoting was in the context of "Before shrink_to_fit()..."
Well, (http://en.cppreference.com/w/cpp/string/basic_string/swap)[cppreference] says, swap has to be constant time. That means, copying all the data to a new buffer is not allowed, unless it is done only for strings shorter than a constant limit (2^64 bytes, for example).
&gt; It's Error That is one &gt; Guesses = Counter; That is two.
That's good. The swap trick also assumes that the construction of the copy will use a minimal amount of capacity. Assuming that, and combined with the requirement that `swap` be constant, I guess that pretty much guarantees that the swap trick will keep the capacity small. This makes sense in many cases, in particular where you don't care about speed. &gt; 2^64 bytes, for example :-) Anyway, I don't believe any implementors will leave `shrink_to_fit` as a no-op. If your implementation does, then you've probably got bigger problems throughout the implementation! And, at the very least, the implementation of `shrink_to_fit` could simply use the swap trick. In this case, `shrink_to_fit` would always be at least as good as the swap trick, and possibly better.
Consider this (perhaps contrived) function: const std::vector&lt;int&gt; read_ints(std::istream&amp; is) { std::vector&lt;int&gt; result; std::copy(std::istream_iterator&lt;int&gt;(is), std::istream_iterator&lt;int&gt;(), std::back_inserter(result)); result.shrink_to_fit(); return result; } I think using `shrink_to_fit` is a better choice here than the swap trick as it leaves it up to the standard library implementation to decide whether to shrink and callers can still do the swapping themselves if profiling has shown it necessary.
&gt;&gt; it will be at least as fast &gt; Sure. But will be as memory-efficient? I meant to say it will be *at least* as fast and memory-efficient as the swap trick. To clarify, a (sane) implementor will either implement `shrink_to_fit()` via a swap trick internally, or perhaps an alternative implementation if it is better. I suppose it depends how the define 'better', they might choose a faster method at the expense of memory. But, more than likely, it will be better (or at least as good) in both ways. Taking a step further back, I'm not worried about the fact that a no-op `shrink_to_fit()` is a *legal* implementation. If implementors just did the bare minimum for all standard library functions, then we'd be in a sorry state. In the real world, we are interested in what implementations are actually implemented.
&gt; &gt; But are the capacity()s guaranteed to be swapped? &gt; Well, no. That's why the swap trick works. I think you have this the wrong way around. The swap trick works (*if/when* it works) because it does the following: - step 1) Begin with a string whose `capacity()` may be much bigger than its `length()`. - step 2) Create a copy (which may be slow) of the string just using its `begin()` and `end()`. Typically, this will be done with a constructor that just allocates the minimum memory necessary to store the string (i.e. barely bigger than `length()`). - step 3) Swap *everything* between the original string and the copy. In effect, the capacities will be swapped also. The last step is the point of confusion here.
The biggest one is MFC.
(responding to myself.... ) When I mentioned 'real-world implementation', I decided to check a little of what g++ does. I've just checked the implementation of `shrink_to_fit` that's in g++4.6. It simply calls `reserve(0)`. On the face of it, that seems reasonable. But it depends on how `reserve` is implemented and what it does when the arguments is `0`. You might assume that a good implementation of `shrink_to_fit` is one which will invalidate iterators. But that's not fair. It is possible to shrink an already-allocated block of memory such that current iterators remain valid. In particular, this avoids copying (which can be slow). I have no idea how `reserve(0)` is implemented in g++ but I suggest that it makes a low-level call to the memory system with the pointer and says "you can make this smaller if you like". Perhaps it calls `realloc()` from the C library. The memory subsystem knows the size of each block of memory that was allocated. Realloc *could* be implemented such that the size of a given block is decreased and the leftover memory is packaged into a new block that's added to the list of free blocks. In other words, the memory is dealt with very efficiently (and, as a bonus, very quickly) *Extra:* A forced copy will not only invalidate iterators, but will invalidate your cache. In some cases, memory-efficiency is just a means to an end towards speed. We want our data to be tightly packed so that we can fit it into the cache, and for it to remain there as long as possible. So, if we can keep iterators valid (*) then the cache can do its work better. (*) When I say "keep iterators valid" i mean that "future calls to begin()" will, usually, point to the same place in memory and your cache will get to do its job.
The standard (I'm actually quoting from n3290.pdf) says: &gt; Remarks: shrink_to_fit is a non-binding request to reduce capacity() to size(). [ Note: The request is non-binding to allow latitude for implementation-specific optimizations. — end note ] Even though the standard doesn't guarantee it, I can't imagine a (non no-op) implementation not checking and I'd personally consider it a premature optimization to manually do the check.
~~Incorrect~~ (maybe not incorrect after all, see responses). It is possible to tell the memory subsystem "I currently have 100 bytes at this address, but I'm not going to need the last 40 of them". The memory subsystem can then add those 40 bytes to a list of of free blocks which are available the next time somebody wants to allocate memory. Memory has been freed, and the existing data stays in the same place. In fact, I guess that related functions such as `realloc` will usually do exactly this.
I think, if you need guarantees about the allocated size of your containers in memory, you need to write your own containers. Ultimately, as far as I understand it, the standard doesn't *require* an implementation to listen to you when you try and ask for a specific amount of memory. If you `reserve` 100 elements, the standard doesn't have to give exactly that. If you `shrink_to_fit()` 100 elements, the standard doesn't have to give exactly that. Due to alignment requirements, it might not be *possible* to be given exactly that (for some definition of possible).
STL allocators don't have a `reallocate` function.
Some Modernizer transformations I'd like to see in the future: * Use trailing return type syntax for function and method declarations * Replace typedefs by `using` aliases * Convert enums to enum classes * Mark deleted default methods with `= delete` instead of declaring them `private`
Mmm. OK. That's a problem. But this [SGI page](http://www.sgi.com/tech/stl/alloc.html) discusses `reallocate`. Perhaps there is nothing stopping c++ implementers from including `reallocate` methods as extensions, an implementing containers that will call `reallocate` if (and only if) that method is available? Maybe some/all implementors do this already?
In C++11 you can do this: int total=0; for(auto n=1; n&lt;=number; n++){ total += n; } 
/r/learnprogramming has almost 100x the subscribers, so there's a much better chance of getting good answers there.
&gt; The standard provides the guarantee that if reserve() is called, then any subsequence addition to the container will not invalidate iterators (until an addition increases the size of the container above the reserve() point. 'provides' being present tense is what confused me.
I dislike your read_ints. I'd rather let the caller decide whether it shrinks the vector. What if my next move is to add something else?
The author did a good job collecting all the examples and mixing them without give the feeling of "non-related things together".
But I like Stack Overflow.
Both. VC checks (because I overhauled it a year or two ago) and all implementations should check if they care about quality, although they aren't required to. The cost of the check is so cheap compared to the cost of a necessary or unnecessary reallocation. (shrink_to_fit on already-shrunk containers should be a no-op.)
Yeah. Also, returning a vector by const value is a massive pessimization - you're inhibiting move semantics. [Don't help the compiler!](http://channel9.msdn.com/Events/GoingNative/2013/Don-t-Help-the-Compiler)
There are a few things in the Standard that are allowed to be no-ops and actually are no-ops in most/all implementations - I am not aware of anyone who has implemented regex::optimize (I don't think even Boost does, although I could be wrong about that), and the minimal GC support is implemented as no-ops on implementations without GCs.
&gt; One of these days I should interrogate the Windows heap devs to better understand the behavior of HeapAlloc Let us know if you ever do so! I find it very interesting and yet there is little documentation on it. Of particular interest is how it varies among OS. I know it has changed drastically, but would be great to have some insight into the inner workings and block sizes etc. Of course this isn't your area, but my interest was piqued. 
It's kind of embarrassing when he talks about how the compiler can't infer the return type of fmap when it totally can. Also, there's a big difference between "Some compilers do" and "All of the major compilers do it if you ask them". Especially also since there's that whole, "std::function&lt;T(Args...)&gt;" isn't properly constrained on many implementations, thing. So the is_convertible check is a bit of a joke.
You better set total to 0 to start int total = 0; otherwise it's going to be whatever happens to be in memory. This isn't an obvious bug, because it's often 0 to start, but if you want to exacerbate the problem compile with optimizations turned on (-O3 in g++).
&gt; Use trailing return type syntax for function and method declarations Everywhere? I think it's horrible and should be avoided at all costs but is an excellent, not to say necessary, feature of the language. I would definitely disable that.
Lol at the complaint about the rng engines. It's really not that bad, or overengineered even.
I don't like the syntax either, but I think of it this way: The cases where I can use trailing return type syntax are a proper superset of the cases where I can use the old syntax. So, if I want to use one universally consistent syntax for function declarations, I have no choice but to use trailing return types. I think I'll get used to it after some time.
&gt; Note that you cannot use const keyword for get_length and get_unit methods, cause their values are changed during first access. Well you can define those objects as **mutable**.
"The question is whether this isn't exactly what you meant with average if you take C++, Haskell… into this calculation." You are aware of course who Simon Peyton-Jones works for? http://research.microsoft.com/en-us/people/simonpj/ 
I've been idly playing while code is compiling and I've already learnt a couple of new things. Thanks for this!
Great stuff! A suggestion: when I skip a question, make it possible for me to see correct answers. If I genuinely don't know something, this would be a great way for me to learn.
What I find annoying about these quizes is they often boil down to reading comprehension rather than understanding of the language. For instance, in one question I missed the "A a;" global above main. I think a quiz where the problems evolve by adding complexity to existing code in stages, where new lines were highlighted, would be more useful as a pure language test.
or you could just learn to read.
Oh my Drupal!
&gt; What do you dislike about Dinkumware/VC's C++ Standard Library implementation that clang's libc++ does better? I'm not sure if you're going to see this this late, but I wouldn't mind if you looked again (if only for curiosities sake) at the performance of std::deque with regard to its 16 byte minimum page size. Afaik all other stdlib implementations have (unscientifically) set the page size to around 512 bytes (this figure seems to originate in the SGI days). My dumb and blind intuition is that something as large as a few CPU cache lines makes sense. There's been a bug open about this since 2009 on MS Connect: https://connect.microsoft.com/VisualStudio/feedback/details/509141/std-deque-performance-is-sub-optimal Here's a good summary I stumbled upon of the different memory profiles of different implementations: http://www.prelert.com/blog/speed-is-not-the-only-consideration-with-stddeque/ Perhaps your defaults are optimal because the common case is to use a deque with larger structures. Or maybe nobody actually uses deque anyway... the GNU implementation seems to be completely broken atm with C++11 conformant custom allocators (which wasn't helpful when I was poking at this). Any thoughts?
Some thoughts, stemming mainly from my own lazy data type implementation: The `lazy&lt;T&gt;` class keeps the initialising computation around forever; if that happens to be a lambda that captured a bunch of variables, this implementation will eat a bunch of memory it doesn't actually use anymore. Worse, any copy of the lazy value will keep an additional duplicate of that closure. A possibly neat improvement would be to add data sharing: if you make a copy of a lazy value that has not been calculated and end up eventually using both the original and the copy, the initialiser will be run twice, even though it doesn't have to be. Using e.g. `std::shared_ptr` it's quite easy to set it up so all copies of a particular lazy computation share the data and benefit from just one of them forcing its evaluation. Of course, the latter is rather unsafe when data is mutable. One could conceivably implement some type of CoW behaviour, but as long as there is any way at all of accessing the actual object, you could mutate it without going through whatever CoW-interface was put in place. There is also the issue of circular references if there is data sharing. It's possible to do some pretty cool stuff with lazy values and circular references, but without cycle detection in whatever mechanism is used for the data sharing, there'll be memory leaks. Anyway, those were just some thoughts.
I just run it myself when I can't figure it out.
I am pretty sure that this does exactly the same job as `std::asnyc` with the `deferred` launch policy, no?
C++14 mostly eliminates the need for trailing return types, so I'd be inclined to just accept the inconsistency for now rather than getting used to something that'll become unnecessary in the hopefully not-too-distant future.
This is great!
Two remarks: 1. In a world where memory is often the bottleneck, your `Lazy&lt;T&gt;` can be a performance drag. Not that you can do much about it, `std::function` is a memory hog, but keep in mind there are other ways to circumvent your initial problem. 2. You should revise how to write multi-threaded code; while no expert myself, I can already point 2 important issues in the first method. Method posted: lazy&lt;T&gt;&amp; operator= (const lazy&lt;T&gt;&amp; other) { m_lock.lock(); m_initiator = other.m_initiator; m_initialized = false; m_lock.unlock(); return *this; } And the two issues: - `std::function` requires dynamic allocation, and thus `m_initiator = other.m_initiator` may throw, in which case `m_lock` is never unlocked. **Exception Safety Primer: use Scope Bound Resources Management**, and in this particular case: `std::lock_guard&lt;std::mutex&gt; guard(m_mutex);` (it's a mutex you have, not a lock) - You have forgotten to lock `other`, and thus may be exposed to a data-race whilst reading `other.m_initiator`; do not forget that `X const&amp;` means that YOU cannot modify it, but does not imply anything for others with access to the object. *Note: beware of potential deadlock issues AND potential self-assignment.* On another point, you are missing several optimizations; so I would propose (non thread safe): template &lt;typename T&gt; class Lazy { public: Lazy() {} explicit Lazy(T t): m_value(std::move(t)) {} explicit Lazy(std::function&lt;T()&gt; f): m_initiator(std::move(f)) {} T const&amp; get() const { this-&gt;initialize(); return *m_value; } private: void initialize() const { if (m_value) { return; } if (not m_initiator) { throw std::runtime_error("No lazy evaluator given."); } m_value = m_initiator(); m_initiator = std::function&lt;T()&gt;{}; } mutable std::function&lt;T()&gt; m_initiator; mutable boost::optional&lt;T&gt; m_value; }; // class Lazy A brief summary of the changes: - Not all classes are (cheaply) default constructible, we leverage `boost::optional` to make this possible. - Sometimes an API expects a lazy object, but you already have the value around, let's not waste an allocation for this. - `get` is `const`, which is *logically* coherent. - The storage for the `initiator` is released as soon as we are done with it. - The class is now movable. - The copy &amp; move special methods will not re-execute the initiator even though it was already executed; though an initiator may still run multiple times if the copy occurs before computation. As said, not thread-safe, but it a tad more difficult than just sticking a mutex on it as I explained, and I would probably trip on this.
In case the result is undefined or unspecified, the answer you get is worthless though :/
That's on my todo list as "argh deque block size". I asked about it in 2007 when I joined VC, and Dinkumware said that they were tuning the block size for programs with lots of small deques. 7 years later, and I still think we should use larger blocks, except now I have more experience to be confident in my judgment. Doing something about this has been lower priority than fixing actual correctness bugs though, which is why it's still a todo.
I was trying to give a short self-contained example where we're returning a container that's unlikely to be changed. It was probably badly chosen (and/or too terse). 
Can I suggest coming up with some kind of style guide? It's a minor distraction that you can find all of the following variations of the same thing: class A { public: ... }; vs. class A { public: ... } vs. struct A { ... } Also, could you please add `autocomplete="off"` to the `&lt;input&gt;` element that receives the answer? It's kind of distracting when you begin to type e.g. "1" and the browser presents you with a drop-down list of every other previous answer that you gave that also began with "1". Otherwise, I quite enjoy this. 
Whoops. I did see this and your other great piece at GN2013, but I'd completely forgotten that part. Guess it's time for a rewatch! In my defense C++ has quite a few details to keep track of :)
I would suggest getting rid of the manual input entirely. It's fine if you have a few very good ideas for the outcome but it can seem overwhelming otherwise.
a "i have no fucking clue, show me the anwer" button would be helpful for when i really dont know the answer.
Pure, unadulterated FUD and ignorance.
KDevelop has this, and it works quite well. It also renames the header/source filenames if you change the name of the class defined in that header.
His inability to read the documentation or fathom concepts and how they work in C++ pretty much leads one to conclude just that, yeah. http://www.boost.org/doc/libs/1_55_0/doc/html/string_algo/usage.html#idp206847064 http://www.boost.org/doc/libs/1_55_0/doc/html/boost/algorithm/split_idp58609016.html http://www.boost.org/doc/libs/1_55_0/doc/html/string_algo/quickref.html#idp207009464 I'll give him that the predicate concept isn't documented there, but it's straight out of the standard set of concepts. Having it in the documentation for split would be a bit superflous, though it could have been mentioned explicitly that it matches the definition in the standard library functions. It's one of those things that a non-junior knows so well that they don't even think about it...sometimes we forget what being ignorant was like.
Qt also fairly universally destroys type safety. You may as well code in Java, really. It's not "bad", but it fairly well misses the point.
I ran into a team lead that did this once. Banned exceptions and the STL. He wanted us to use char* everywhere and hard-coded, global array buffers. Had these fucked up, inherit-from-node lists and very deep inheritance structures that violated all principles. Guy was an idiot, just like this blog author.
vtable will be cached, code at votable entry will be cached, branch prediction will already know to jump there. Probably not worth thinking about at all.
g++ has [an extension](http://gcc.gnu.org/onlinedocs/gcc/Bound-member-functions.html) to do exactly this. ... but I think there's a more portable way to do this. Where's my thinking cap. (and maybe it won't make any difference anyway if the cache is working well!)
You're most welcome! :) And thanks for your kind words. Better than http://xkcd.com/303/, eh? ;)
[Image](http://imgs.xkcd.com/comics/compiling.png) **Title:** Compiling **Alt-text:** 'Are you stealing those LCDs?' 'Yeah, but I'm doing it while my code compiles.' [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=303#Explanation) **Stats:** This comic has been referenced 15 time(s), representing 0.487963565387% of referenced xkcds. --- ^[Questions|Stats|Problems](http://www.reddit.com/r/xkcd_transcriber/)
That's a very interesting idea, I didn't think of anything like that at all.
Hey, don't blame Drupal for this! :) The horrible design is solely my fault. If you're interested, the site is open source: https://github.com/knatten/cppquiz It's written in Python and Django, with a tiny bit of JQuery.
Thanks! :)
Id maybee leave it without. I got stuck on one for awhile but didn't skip it because I wanted to know the answer, eventually I worked it out myself but if it gave us the answer on skip I wouldn't have!
I really liked the complex ones with manual input, makes it impossible to guess. Felt like a badass when I got it.
Yes, I might add something like that, you're not the only one to suggest it.
I'm not sure I get your point? Do you mean dropping the entire text box and replace it with a dropdown or something?
I assume you are speaking of hardware caching, while I explicitly indicated that I am referring to software caching --- i.e., to eliminate the need to do vtable lookups at all. As you've pointed out, modern memory hierarchies may well have the code and data for these things somewhere close to the core, but there is still an instruction penalty for it. I agree that in most cases, it isn't significant in overhead. I am specifically interested in the (admittedly niche) case where any difference in vtable cost is significant: the virtual function itself is inexpensive to compute and the loop has a high trip count. 
Here's a more portable solution [on ideone](http://ideone.com/BkYodm). It does require a bit of boilerplate code to be written for each new derived class. And also, I'm hoping/assuming that some of these calls can be inlined into each other. (If in doubt, just copy-and-paste the relevant functions together - who needs `inline` when you have copy-and-paste?) The code there on ideone might be the best documentation of what I've done, but I'll attempt an explanation here in this comment: You have `virtual double apply(double x)`. First thing to do is to make a *non-*virtual function in each class called `apply2` that will actually do the work. Then, each of the virtual `apply` will call `return apply2(x);`. Next, we want to get rid of the call to `apply`. The next step is to create a *static* (and therefore also non-virtual) method called `apply3` that will take a `Doer*` argument as it's first member and will call `apply2` on it. Within `apply3` we use a `static_cast`. It might be tempting to use a `dynamic_cast` here, because it feels safer. But that's going to slow it down. We need `apply3` and `apply2` to be as simple as possible within each derived type. Now, each derived type will have a *static* method called `apply3` that all share the same signature and will do the 'applying'. If you like, you could even copy code the code from `apply2` directly into `apply3`. But beware, keeping them separate might be easier in cases where you actually are using some state with the `doit` object -- in the example you gave, there is no such state, but that won't always be the case. (If you are using stateless `Doer` objects, then this can be simplified a bit more.) Anyway, finally we need the `virtual apply3_t get_apply3() const = 0;` This is then implemented in each derived class will return a function pointer for the relevant non-virtual static member that actually does the work. In summary, you'll need to have an implementation of `get_apply3` and `apply3` in every class. You can either directly put your algorithm into `apply3`, or instead write an `apply2` inside every derived class.
(: Just talking about the blog, heh
That's been my view as well. It's a tough tradeoff, because I know some people will not have the time/patience/skills to figure it out by themselves, and they might be better off being told the answer. Still not sure about this one.
Ah, I didn't think about casting static member functions to global function pointers. Neat! 
Oh, the blog is Wordpress. 
Is the Garland theme a bad thing? One thing is not being able to make a good design, I seem unable to even pick one! :)
ASL isn't dead yet. We've moved development to https://github.com/stlab. We're in the process of updating to C++11 and just moved the licensing to the boost license. The TBB dependency is no more (we were just using it for atomics, now we get that from C++11). Foster Brereton has managed to free some cycles for ASL improvements and has been quite busy. Pull requests welcome! I've been collaborating with Jaakko Jarvi from Texas A&amp;M recently who is doing research in the property model space (AKA the Adam library in ASL) - that work is funded by an NSF grant and ongoing. We have some seriously cool work in the pipe so expect papers and library improvements / additions during the next year. Unrelated to ASL - I gave a recent talk at GoingNative &lt;http://channel9.msdn.com/Events/GoingNative/2013/Cpp-Seasoning&gt;.
An `async` returns a `future`, calling `get` on that `future` will wait until the calculation is done and will then return the result. (That's my understanding from reading the docs, but I've never actually used it!) But my question is: if we call the same `future` repeatedly, will it simply return the value again, or will it call the function again? I'm pretty sure it will *not* call it again, but I'm just being paranoid? If this is correct, then yes, I think this blog should replace `lazy` with `future` and initialize that `future` via an `async`. Except, of course, for the understandable desire to keep everything on the stack as much as possible.
The answer for #48 says: &gt;Scott Meyers writes more about this: http://scottmeyers.blogspot.com/2013/03/stdfutures-from-stdasync-arent-special.html That link seems dead. P.S. This is AWESOME.
Improvement: add title tag, so the web browser will display something meaningful instead of URL of the page.
Really, do not try to outsmart the compiler. I mean really. The trick you're attempting is quite nasty so you should really profile whether it is worth it. I just tried: ideone.com/tc2Gr4 Tested on my machine (gcc-4.8.1, ubuntu) Using plain -O2, the first version (extracting the function pointer) is faster (about 5-10%) which seems neat. The main difference really is that gcc does not cache the function pointer from the vtable, an optimization that seems rather simple to do. There might be a reason they don't which I'm not aware of. Things change with different flags: with -O3, the virtual version is almost 3x faster. Why? At -O3, thee is a constant-progagation optimization that kicks in (-fipa-cp-clone) that basically devirtualizes and inlines the entire loop. The optimization does not kick in in the static version. You can now say okay, this is a synthetic example and the real world will look different. May be, however: Compile the code with -O2 -flto (link-time-optimization), and the virtual version again is 3x faster, but this time because the function was inlined for real, again, that did not happen with the version which extracts the pointer from the vtable. So my concolusion to this is plain and simple: do not outsmart the compiler!
I'm sure I read somewhere that it used to be a template parameter pre-standardisation. In any case, making it a parameter (template or otherwise) would then imply a specific implemention. GNUs implementation actually allows you to override the block size using a macro... but doing so is kind of desperate.
It's really cool that you're at least aware of it. I'm not sure how the current implementation optimises for small queues... weird. Anyway, keep plugging those bugs.
Imagine that you've got a million deques with three elements each. If each deque has a block of a hundred elements, that's a lot of wasted space.
&gt; there is still an instruction penalty for it. There is no fixed performance cost associated with an instruction beyond the memory for the instruction. In the case of a vtable's unconditional jump, that's going to be as compact basically anything you might do (and that's assuming your linker and runtime aren't smart enough to do inlining when invoking vtable calls).
My experiments with that code show similar results, but that is because this is a pretty simple microkernel. Consider a case where the object (and therefore, virtual function that I call) is chosen at random from an array (built at run-time) of heterogeneous objects that each implement the virtual function (which is then invoked). The compiler has to recourse but to do the lookups. If that array can be replaced/augmented with these 'cached' vtable lookups outside of the loop that is randomly calling the virtual functions, we can potentially improve throughput. As an aside, this random-call scenario is actually not contrived: it is actually what the algorithm I am implementing does. The current code uses function pointers and void pointers, and I was wondering if it was possible to do it in a more type-friendly way. It can indeed be hard to outsmart the compiler. In some sense, I feel like I am trying to outsmart the language. The super-cool ninja way to do what I am aiming for would be self-modifying code that inlines the functions right there, but that is not portable, straightforward, or even possible with most modern systems.
Good idea, but that is something that can only be done in the contrived example. I should have done a better job with that --- the code I am interested in has a tight inter-iteration dependency (and the virtual functions called at not deterministic)
There is some syntactic funkiness to what you are doing (does not compile, particularly because you aren't allowed to do "doit-&gt;apply"), but I think the compiler already has all the info it needs to move the vtable lookup outside of the code. Are you sure the compiler isn't already doing the smart thing? Think of it this way (which is closer to the "proper" way to do this anyway): void go3(std::vector&lt;double&gt; &amp;values, Doer&amp; doit) { using namespace std; transform(begin(values), end(values), begin(values), bind1st(mem_fun(&amp;Doer::apply), &amp;doit)); } The compiler has all the hints in the world here it can resolve the vtable lookup of doit-&gt;apply prior to applying it the elements of values. If you think about it, it really already has all those hints with the original "go" version of your function: it has a loop where the first thing it does in each iteration is double deref a pointer *that it knows never changes to a vtable that also never changes* through each iteration through the loop. Any compiler worth its salt ought to realize it can move the pointer lookups outside of the loop. However, even with a more rudimentary version: void go4(std::vector&lt;double&gt; &amp;values, Doer* const doit) { for (int i = 0; i = values.size(); ++i) { values[i] = doit-&gt;apply(values[i]); } } You can see that the compiler can recognize that doit isn't changing from the call to one element to the next. Let's just say, for arguments sake, that it actually *cannot*, it would be trivial to add the visitor pattern on the Doer to force resolution of the pointer to create a version of the apply function that takes a vector as the parameter. Basically what you'd be doing is using static polymorphism to create all the functions that iterate over the elements and apply the logic, with a wrapper runtime polymorphic function that selects which statically polymorphic function to call without doing the iteration.
See my reply - it seems gcc isn't doing it. Check the assembly of my benchmark and you'll see that using vtables, the call is done using 0x8(%rax), and in the case of the function pointer, it uses %rax. That was the only difference I could spot in the generated code, so I assume this is where the 5-10% performance come from. But this comes at the cost of confusing the compiler which then in turn prevents devirtualization in some cases
I really doubt the issue here is cache misses; as I explained at great length a few minutes ago, I have a tiny working set. Instruction overhead is the mind - killer here. I know that I can't avoid a function pointer dereference and call without self - modifying code, which is not on the table. I want to see if virtual functions (which is thunk/vtable lookup /plus/ dereference and call) can be made to as cheap as the plain C - like function pointers. It seems conceptually possible, but I have reservations about the willingness of the compiler to do this automatically for proof or aliasing reasons. My experience with C++ compilers is that they will eventually give up in the face of plentiful abstraction. 
I am going to stick with the input as it is today. I think the open format encourages more thinking and reflection.
Thanks! :)
Thanks for the heads up! Turns out there's a bug in my code, I'll fix it tonight: https://github.com/knatten/cppquiz/issues/20 And thanks for the great feedback! :D
Good idea, I'll fix it tonight. Thanks! https://github.com/knatten/cppquiz/issues/21
You should make the get-answer button really shameful? 
Agreed, I am trying out way to many answers as it is. 
Haha, maybe that's the way to go. I'll consider it.
&gt; I don't know what you mean by 'fixed performance cost' I meant that just because there is an additional instruction in the middle of a loop doesn't necessarily mean it takes any longer to execute an iteration of the loop. &gt; they are fetched, decoded, shipped to functional units, and retired. On modern CPU's, the instruction fetch, particularly inside a small loop whose instructions are already in the instruction cache, the fetch is very fast indeed and fed into the processor ahead of actual execution to avoid impacting performance. Similarly, on modern x86 CPU's, instructions are decoded and converted to an internal instructions set while prior instructions are still executing (superpipelining FTW!), and the decode results are cached. Once decoded, branching instructions are often routed to dedicated branch prediction units, designed to reduce the probability of cache by guessing branch directions and initiating a load before the data is needed. To aid in this effort these units might have support for very basic arithmetic (like increment) to aid in this endeavour, but the one thing they can universally execute on is an unconditional jump instruction. Assuming the branch destination is in cache, this effectively makes the execution of the unconditional branch "free". Retirement of the instruction also can effectively be "free" as the only change that must execute is an update of a register. &gt; Sticking it in a function incurs the overhead of the call (which cannot be avoided if you expect run-time polymorphism) Not at all. Java runtimes do this before they get up for breakfast. C++ compilers/runtimes aren't always this smart, but they can be. It's fairly simple: you identify the most likely types, and then setup up a switch on those types, with each case filled with inlined logic for the relevant member function. Have a default case that falls back to calling the vtable as per usual. &gt;The 'real' application I keep alluding do is actually totally compute-bound, since it repeatedly transforms the same few doubles with these functions and thus has hardly any working set to speak of. I wasn't suggesting you couldn't be compute bound. I was suggesting that if you were compute bound, having the additional instruction wouldn't necessarily change your performance.
Well the cool guy thing to do would be to run in the question text through clangs code tidier when new questions are submitted.
In my opinion, it is a design mistake to need such small virtual functions if the code is time-critical. I'd reimplement using the CRTP pattern (static polimorphism) and get the code inlined. Yes, this has implications as well, but I consider them less severe than what you're proposing here. With this small optimization (which in my opinion the compiler should do), you get 5-10%. With inlining, you get 300%. Your choice... ;) And on top of that - I already said that the compiler should do the optimization you want to do here
Love the idea! I'll definitely have a look. https://github.com/knatten/cppquiz/issues/23
I hope by linking me to the github page you didn't expect me to do it. :P
this belongs to /r/learnprogramming This is not how you extract functions to a separate file. The function declaration goes into the .cpp file, the definition in the .h file and you include the .h file. http://www.cplusplus.com/forum/articles/10627/
I would normally agree, but these are unusual circumstances where would I would like to have run-time polymorphism and inlining is not possible because the function internals are not known at compile-time. I'll see if I can cook up a more representative example here, since people don't seem to want to take me at my word :) 
I am totally on your side on the LTO thing, but it isn't going to work for this code. As to the original code not compiling, I cop to that: the second go function was designed to show what I would like to happen conceptually, not in reality.
*Will the compiler hoist the virtual dispatch out of the loop ?* If you look at this example, you would think: *D'oh! It's obvious it will, hoisting is soooo trivial*. But you are actually wrong, in most cases it will not. The issue is subtle, and has to do with how `virtual` methods are implemented, so let me explain it with code: // C-object typedef double (*Applier)(Doer&amp;, double); struct DoerTable { Applier applier; }; struct Doer {}; DoerTable const DoerTableInstance = { 0 }; struct MyDoer: Doer {}; double MyDoerApply(Doer&amp;, double x) { return 2.0*x - 0.5; } DoerTable const MyDoerTableInstance = { &amp;MyDoerApply }; void go(std::vector&lt;double&gt;&amp; values, DoerTable const&amp; table, Doer&amp; doer) { for (double&amp; v: values) { v = table.applier(doer, v); } } If you implement this code, then the load of `table.applier` is hoisted out of the loop. With the very same compiler. At the very same level of optimization. So what is going wrong ? Actually, it's a question I raised to the Clang community a couple years ago (with a question as to why so much devirtualization happened in Clang, and not in LLVM, which both complicates Clang and means that it is not performed after inlining/constant-propagation and the like), and I strived for some time compiling to LLVM bytecode to witness this and try to understand what was happening, and the result is: *bloody v-tables*. The heart of the issue is a poor interaction with the way virtual dispatch is implemented (v-tables) and low-level bytecode: - at low-level, `MyDoer::apply(...)` is represented as `apply(MyDoer*,...)` - the virtual dispatch is implemented via a v-ptr nested within `MyDoer` This is great to save registers (think back to x86), however it also means that *as far as the low-level bytecode is concerned, the v-ptr might change at each call to `MyDoer::apply`*! And that is why this load is not hoisted. It cannot be hoisted, unless the compiler manages to statically resolve `apply` and deduce that it does not alter the v-ptr. This is surprising only if you reason at C++ level: *an object dynamic type does not change during its lifetime*! Unfortunately it's slightly more complicated. The v-ptr does change during both construction and destruction, and from the point of view of the byte-code the compiler is manipulating the border between construction/normal lifecycle/destruction is completely unclear: after all construction and destruction are functions. So, no, unless the example is trivial (all objects implemented with the same TU/library depending on optimizations levels), current compilers **cannot** hoist that call. There has been talk of `freeze`/`thaw` intrinsics in LLVM so that Clang could delineate the border (freeze after construction and thaw right before destruction) but this is non trivial; and actually, construction is multi-step so it would be in this case: - set-up v-ptr for `Doer` - freeze - execute `Doer`'s constructor - thaw - set-up v-ptr for `MyDoer` - freeze - execute `MyDoer`'s constructor - ... things ... - execute `MyDoer`'s destructor - thaw - set-up v-ptr for `Doer` - freeze - execute `Doer`'s destructor - thaw (of course, `freeze`/`thaw` would generate no CPU instructions, they are just here to help the optimizer) And of course, this would be a local hint in general, so in every single function you would need to `freeze` every object when entering (hopefully, the `thaw` on leaving would be automatically managed in case of inlining).
Boosting their VCS...
But but ... November 23 is Saturday ... &gt;When that is done, the boostorg repo on GitHub will open for business Please, be careful not to force pushes there ;)
Now if only they'd move to a decent build system...
&gt; If you reserve 100 elements, the standard doesn't have to give exactly that. It *does* have to give you *at least* that, though. 
There is work done on having a CMake build, but well, decent build system you say... Also ryppl is worth a look, but still a phantom of its future I think.
CMake would still be preferable to the bullshit they have now.
good ... good
I think you mean &gt; -DCMAKE_WOULD_STILL_BE_PREFERABLE_TO_THE_BULLSHIT_THEY_HAVE_NOW
I beginning to think that Git is in wider use than Linux. 
Not at all, I just wanted to allow you to monitor the issue :) I have however decided to give up on it, since my web host doesn't support clang-format. Using vimperator and the vim clang-format plugin it however only takes two seconds to open, format, and save a question manually, so I've done that for now. https://github.com/knatten/cppquiz/issues/19
Done: Set title to CppQuiz.org (...) Where for quiz mode (...) is the quiz key, and for training mode (...) is the question id.
Fixed: https://github.com/knatten/cppquiz/issues/20
Great article. The only thing that really needs adding is type deduction during template instantiation ;). This is already referenced at the bottom with re: Steve Meyers talk. First, sweet sanity: struct Bar; template &lt;typename T&gt; void foo_val (T x) { // T will always be a value type ('Bar'), no matter what you pass. // x will be a value of type T } template &lt;typename T&gt; void foo_cref (T&amp; x) { // T will always be a value type ('Bar') when you pass an lvalue. // You can only pass lvalues, so the above is always true. // x will therefore always be an lvalue reference (Bar&amp;) } The new crazy hotness: template &lt;typename T&gt; void foo (T&amp;&amp; x) { // You can now pass rvalues. // T will always be a value type ('Bar') when you pass an *rvalue* // T will have lvalue reference type (e.g. 'Bar&amp;') when you pass an *lvalue*. // T is *never* an rvalue reference type. // x will always be an lvalue reference (like Bar&amp;) when foo() is passed an lvalue // x will always be an rvalue reference (like Bar&amp;&amp;) when foo() is passed an rvalue } Easy ones: Bar b0; foo (b0); // T is 'Bar&amp;', x is of type T Bar&amp; b1 = b0; foo (b1); // T is 'Bar&amp;', x is of type T Bar&amp;&amp; b2 = std::move(b1); foo (b2); // T is still 'Bar&amp;', x is of type T Bar const&amp; b3 = b1; foo (b3); // T is 'Bar const&amp;', x is of type T Bar const&amp;&amp; b4 = std::move(b3); foo (b4); // T is still 'Bar const&amp;', x is of type T Tricky ones: foo (Bar()); // T is just 'Bar', x is 'Bar&amp;&amp;' foo (std::move(b2)); // T is 'Bar', x is 'Bar&amp;&amp;' foo (std::move(b3)); // T is 'Bar const', x is 'Bar const&amp;&amp;'
I've seen something like this before... our solution was to make the apply function take vector references rather than single values. I think it makes the performance really easy to reason about, and in practice you'd rarely use both a single-value and batch interface in the same program (although it's still possible to expose both).
I planned to cover this in [Don't Help The Compiler](http://channel9.msdn.com/Events/GoingNative/2013/Don-t-Help-the-Compiler), but I didn't have enough time and I couldn't talk faster than .3 c, so I moved them to my Bonus Slides. See slide 60 of [my slide deck](http://view.officeapps.live.com/op/view.aspx?src=http%3a%2f%2fvideo.ch9.ms%2fsessions%2fgonat%2f2013%2fSTLGN13Compiler.pptx) in MS's cool web viewer. (Click on "SLIDE 1 OF 61" at the bottom, then "SLIDES 51-60", then "60: CONST X&amp;&amp; IS..." to jump there.)
Ah, actually saw that talk (great one!) and checked the bonus slides, but didn't remember this. Thanks!
I have a proposal for native concepts: https://github.com/hun-nemethpeter/cpp-reflector-mini/blob/master/Proposal.md
Is there a full offline boost documentation archive hiding somewhere? Most of the libraries in boost don't actually have documentation other than the web pages. I've been doing a 'wget -r' thing every now and then, which seems ridiculous to me.
I guess there are many ways to achieve this, but using constexpr has also its advantages, especially if you want to do those checks at compiletime.
Both ways have checks at compile time. I really see no advantages using constexpr.
[PVS-Studio for Visual C++](http://www.viva64.com/en/b/0222/) [PVS-Studio Standalone](http://www.viva64.com/en/b/0219/)
This is very useful for those involved with corporate development, thank you! For those who want to dig this subject deeper, there are also tools like [Zip Utils](http://www.codeproject.com/Articles/7530/Zip-Utils-clean-elegant-simple-C-Win32) and [gzip](http://www.boost.org/doc/libs/1_48_0/libs/iostreams/doc/classes/gzip.html). You might find those useful too for more low-level programming without referencing large frameworks like Qt or WxWidgets, expecially if you're doing some kind of small utility.
It's a sensible question. A Boolean metafunction (trait) and a constexpr Boolean function are identical in power. It's really about syntax. It's the difference between a requires clause like this: Iterator&lt;T&gt;() &amp;&amp; UnaryPredicate&lt;F&gt;() and a requires clause like this: Iterator&lt;T&gt;::value &amp;&amp; UnaryPredicate&lt;F&gt;::value or like this: mpl::and_&lt; Iterator&lt;T&gt;, UnaryPredicate&lt;T&gt; &gt;::value I prefer the first. You're thinking in terms of manipulating traits using all the metaprogramming tools that have been invented in the absence of compile-time function evaluation. But just because those tools exist and work doesn't mean that we still have to use that style of programming in C++11. Your `conditional_adaptor` is nice, but it requires a tad more boiler plate than tag dispatching. Do you see an advantage?
I think that's more a proposal for compile-time reflection. It's interesting. I'd like it better if it hid the clang AST API. That API is a moving target. I'd hate for all my code to break because someone in the clang team decided to tweak the AST.
Thx, I don't want to stick with Clang AST Api, but I want a similar subset of it. I will extend my proposal.
&gt; -DCMAKE_WOULD_STILL_BE_PREFERABLE_TO_THE_BULLSHIT_THEY_HAVE_NOW=YES 
Is this a problem on g++ or clang? Or just a problem with VC++?
Clang with -Os or -O2 generates this code (with `std::min&lt;int&gt;`): pushq %rbp movq %rsp, %rbp cmpl %edi, %esi cmovlel %esi, %edi movl %edi, %eax popq %rbp ret So no, Clang does not seem to have this problem.
Meh, `std::min/max` are generally going to be used directly and will be inlined. If you call it in a simple loop such as for (size_t i = 0, e = a.size(); i&lt;e; ++i) c[i] = std::max(a[i], b[i]); then it is as efficient as the `FastMax` template presented in the article. And for what it's worth, various combination of `const T&amp;` versus by-value `T` for the arguments and return value have no effect. It's still somewhat interesting that, when you go to effort to force the compiler to instantiate the templates as non-inlined `*Test` functions, you get such different results. However in practise it is nowhere near as relevant as the article, or it's sensationalist headline, claim. BTW, I did this test on VC++ 2013 with `std::vector`s and tried `int`s, `float`s and `double`s. Because my test was specific to `vector`s the results may not hold true for other scenarios.
I'm not sure, if "nullifying" is required. As far as I know, accessing a value after it's being moved is undefined behavior. So the cost of moving an object is only the shallow copy, not the nullifying. If it's done, it should be only for debug purpose, but not in production code.
very useful. thanks.
 constexpr int windowWidth{800}, windowHeight{600}; Why do you use constexpr and not plain const?
This is not true. A moved-from object is still valid and will have its destructor called when it goes out of scope. If you don't nullify the pointers inside the moved-from object, you will double-free the memory it points to, which *is* undefined behavior. The contents of a moved-from object are *unspecified* (not undefined) in most cases, but not in all; for example, a moved-from `unique_ptr` will always compare equal to `nullptr`.
To force it to be a compile time constant.
I'm pretty sure const (when in global scope or static) is compile time constant... The next code works on gcc 4.8.1 const int size = 10; int oldStyle[size]; std::array&lt;int,size&gt; newStyle; EDIT: Besides, the functions the variables are passed to are not constexpr functions so not sure what will it accomplish differantly than using const. I guess he just wanted to show the constexpr key word , which is a good reason. 
But `constexpr` *forces* it to be constant. The following code is valid int foo; cin &gt;&gt; foo; const int bar=foo; even though `bar` is not a compile time constant. If you replaced `const` with `constexpr`, the code wouldn't compile because `foo` can vary.
I suppose I am missing something, but isn't that the code he timed? int MaxManySlow(const int* p, size_t c) { int result = p[0]; for (size_t i = 1; i &lt; c; ++i) result = std::max(result, p[i]); return result; }
This article seems to get a little off topic by mentioning macros. The issue seems to be VC++ not recognizing when copying the entire value is more efficient than passing a reference. But the find is interesting, don't have a copy of VC++ to investigate.
I wrote my reply on my phone so I couldn't (at least I was too lazy to) say everything I wanted to say. But essentially I agree with you, and I think the real reason he did it in the video was to show it as an example. Although I'm interested in what the difference in code gen would be if they were just const instead of constexpr, or indeed enums, ie: enum {width = 800, height = 600}; I am too lazy right now but I suspect they would all be treated differently but only in specific circumstances.
So here's what I think, and correct me if I'm wrong: If you bind the const to an rvalue, the compiler can make it a compile time constant (I assume), but the compiler isn't required to do so. Constexpr's are required to be compile time constants and can only be bound to rvalues. Not entirely sure if rvalue means what I think it means in this scenario either :/
Which is great, but it still doesn't explain why it is constexpr in the tutorial code :)
Interesting yes, I'm glad I added that cautionary note at end so, or I'd be eating my words. So for my tests with 3 vectors I couldn't tease out any real difference, but for calculating the minimum of 1 vector it does seem there is a real difference. For what its worth here's the x86_64 assembly, note `FastMax2` takes and returns it's parameters by-value. **Also note**, this is without loop unrolling, but with unrolling the code was much the same anyway, though repeated 4 times. **`int`**s r = r &gt; a[i] ? r : a[i]; cmp ecx,dword ptr [rsi+rdx*4] cmovle ecx,dword ptr [rsi+rdx*4] r = FastMax(r, a[i]); mov eax,dword ptr [rsi+rcx*4] cmp edx,eax cmovg eax,edx mov edx,eax r = FastMax2(r, a[i]); cmp ecx,dword ptr [rsi+rdx*4] cmovle ecx,dword ptr [rsi+rdx*4] r = std::max(r, a[i]); lea rax,[rbp+40h] cmp edx,dword ptr [rcx] cmovl rax,rcx mov edx,dword ptr [rax] mov dword ptr [rbp+40h],edx **`double`**s r = r &gt; a[i] ? r : a[i]; comisd xmm0,mmword ptr [rdi+rax*8] ja wmain+16Ch (07FF7EEE81318h) movsd xmm0,mmword ptr [rdi+rax*8] r = FastMax(r, a[i]); comisd xmm0,mmword ptr [rdi+rax*8] ja wmain+1EBh (07FF7EEE81397h) movsd xmm0,mmword ptr [rdi+rax*8] r = FastMax2(r, a[i]); comisd xmm0,mmword ptr [rdi+rax*8] ja wmain+301h (07FF7EEE814ADh) movsd xmm0,mmword ptr [rdi+rax*8] r = std::max(r, a[i]); lea rax,[rbp+58h] movsd xmm0,mmword ptr [rcx] comisd xmm0,xmm1 cmova rax,rcx movsd xmm1,mmword ptr [rax] movsd mmword ptr [rbp+58h],xmm1 While it doesn't really surprise me that passing by value is faster, I mean the compiler is doing exactly what it's asked to do, i.e. work with pointers to the data rather than the data itself, I still would have thought the compiler would optimise this simple case. Maybe it's a bug, or maybe it's not allowed too. Any insight would be fascinating. Mind you, the conditional move of the pointers for the `double` `std::max` code is a neat trick to avoid the jump, it still runs slower in my test. I guess, my original test, where everything was pointers anyway meant the issue didn't arise.
Maximum safety out of habit?
It is a great idea, but very hard to design. I tried one question and learned something. I will save judgment for latter, but I liked it. 
Intent. `constexpr` clearly expresses the intent of a *compile-time immutable value*. `const` is a modifier that can even be casted away, so it doesn't really mean *compile-time immutable value*. When using C++11, in my opinion, the first keyword that should come to mind when dealing with *compile-time values* is not `const` but `constexpr`. 
Thanks for the feedback. I'm using the [**free unregistered beta of Sublime Text 3**](http://www.sublimetext.com/3). I'm also looking forward to use an open-source clone, [lime](https://github.com/limetext/lime), currently work-in-progress. When working on my big projects, however (such as [Open Hexagon](http://www.facebook.com/OpenHexagon) or [Operation Bloodshed](https://github.com/SuperV1234/SSVBloodshed/), I prefer using [**QTCreator**](http://qt.gitorious.org/qt-creator/qt-creator/commits/master), a great IDE with amazing C++ (and C++11) support.
I'm using Xcode because I love the static analyzer integration there, and I haven't had much luck with Lime, though I have high hopes for it in the future. Unfortunately QTCreator has been a little buggy for me on OSX, so I'll stick with Xcode there. While on Linux, I usually work with Emacs (depending on the size of the project I'm working on) or Vim with [YouCompleteMe](https://github.com/Valloric/YouCompleteMe) for auto-completion. I look forward to your future videos :-)
The reference to the macros might have been triggered by the fact that the Windows SDK's [windefs.h defines "min" and "max" macros](http://support.microsoft.com/kb/143208). I've seen a lot of Windows-specific code that uses these without a second thought, and they collide badly with attempts to use std::min or std::max.
The results on my machine (OS X 10.9, i7 3720QM): https://gist.github.com/tgoyne/7645206 libstd++ version was compiled with GCC 4.9 (built Nov 11) and the libc++ version was compiled with Apple LLVM version 5.0 (clang-500.2.79) (based on LLVM 3.3svn), both with -O3 and no other options. I just noticed that I used boost r86382 (Oct 21) rather than 1.55, though. Are there any relevant changes after that which'd merit rerunning it?
I have a dedicated test to ensure that the STL defends itself from those macros. They are... unpleasant.
Awesome. Blows my mind what's already possible with C++11. Thanks for the update!
 * this is hardly news; MSVC having nervous breakdowns about const &amp; vs passing by value for PODs is a venerable tradition; would take all the charm out of dealing with an asinine implementation of __m128 otherwise. * one shouldn't liberally use rdtsc without first pinning the process/thread to a single core: either cores have their TSC vaguely synchronized or not at all; your timing code is in fact a rather deficient RNG. disclaimer: i only gave the code a cursory look and haven't had the privilege to deal with MSVC in years. 
If you want an education you won't get it by having other people do homework assignments for you. If you don't want an education then just blow off class and do something else. If you have some specific problem you can ask classmates, TAs, or at places like stackoverflow.com on the internet. If you just don't know where to start then review your notes, or talk to a TA or a classmate.
&gt; Maybe it's a bug, or maybe it's not allowed too. Any insight would be fascinating. `std::max` has to deal with pointers, and return them. For example, what if you did `std::max(a,b)--` to decrement the largest number? It can't do any optimization, except if it can inline the call in a context where the return value is only used as a value. I know nothing about MSVC and its compile options, but if Link-time Code Generation is required to enable inlining, then there isn't a story here. ... although maybe my real issue is that I have no idea what is meant by *"a release build with link-time-code-generation (LTCG) disabled and /FAcs enabled"*
Since the compiler is inlining the function it has full knowledge of what is going on, therefore it knows that doing everything via pointers (which is what references imply) is not necessary. The fact that gcc and clang manage this proves that it is possible. &gt; It can't do any optimization, except if it can inline the call... It inlines the call. If it didn't inline calls to std::max then that would be far worse. I talked more about Link-Time-Code-Generation (LTCG) and /FAcs in the linked article ("This technique was described in more detail in How to Report a VC++ Code-Gen Bug."). LTCG is also known as whole program optimization - it allows optimizations such as inlining across source files, which complicates benchmarking. /FAcs creates an output file for each source file that contains the assembly language generated.
None of them use `maxsd`? I wonder what's going on there.
maxsd is for double. The examples used int, and some reference was made to float. Double was never tested. I don't know why maxss is not used in the float case. It may be that it does not offer the precise semantics required, or it may be that it requires a higher instruction level than I was compiling for.
Right, but Eoinoc's second set of examples use doubles. Hence the question. Regarding semantics, I investigated gcc's output: it seems to be happy emitting `{max,min}{ss,sd}` in some cases but not others: float test_std(float a, float b) {return std::min(a, b);} test_std(float, float): minss xmm1, xmm0 movaps xmm0, xmm1 ret float test_lt(float a, float b) {return a &lt; b ? a : b;} test_lt(float, float): minss xmm0, xmm1 ret float test_lteq(float a, float b) {return a &lt;= b ? a : b;} test_lteq(float, float): movaps xmm2, xmm0 cmpless xmm2, xmm1 movaps xmm3, xmm0 movaps xmm0, xmm2 andps xmm3, xmm2 andnps xmm0, xmm1 orps xmm0, xmm3 ret Whereas using `-ffast-math` results in the single `minss` for all three cases. That suggests that there is indeed an issue with semantics. Note: gcc version 4.4.5
Relevant papers with much better descriptions; a must read on the topic: * Efficient applicative data types by Myers * Concurrent manipulation of binary search trees by Kung And what's the deal with using shared_ptr for pointer fields that should be private anyway? He could at least have used an embedded reference count.
&gt; std::function requires dynamic allocation, and thus m_initiator = other.m_initiator may throw, in which case m_lock is never unlocked. Also, the default initiator always throws.
Hi, STL. Are you free to say something about the topic at hand? Does the VC++ compiler have problems with generation code for min/max? Is there a reason for it? Should/can we compensate in some ways?
Amazing tutorial, thanks! Quick question - do you always do all your code in the .hpp files or was that just for the purposes of the tutorial? Apologies if you answered this in the video, I was watching on mute :)
&gt; Willful ignorance? "See, when you use shared_ptr everywhere C++ is really slow". Relevant quote from the text: "With proper optimization tricks (unboxing and eager evaluation) the Haskell code should perform as well as its C++ translation." Yup, optimized Haskell should perform as well as deliberately crippled C++ code. Plus, it's not a "translation". Reference counting (esp. with a separate heap-allocated counter) is usually slower than proper GC. 
The problem with the `&lt;=` case is NaNs and negative zeroes. If either `a` or `b` is NaN the value to be returned is b, and if `a` is `-0.0` but `b` is `0.0` the value to be returned is `a`. `minss` would return `b` in both these cases, so it can't be used. The `&lt;` case would return `b` in both instances, so it can use `minss`.
Bjam looks quite efficient to me, why they should move to something else ?
Yes, I have problems when using *std::numerics_limits&lt;float&gt;::max()*.
I think It's cause he's trying to make functional (aka read only) data structures. He doesn't want to go through the hassle of manually implementing a reference counter, so he just used this instead.
I'd be perfectly happy to _help_. However you seem to be asking for someone to do your homework for you. If classmates can't help then perhaps you should ask the teacher or teacher's assistants. There's plenty of information on the internet about all the things you need to write this program. You might be having difficulty finding anything because you're searching for a complete program that does what you want. You should instead think about the parts that the program should be divided into and search for information about those specific tasks. Then you need to figure out, mostly on your own, how to combine the parts into a program that does what you want. For example you might search for: - [simple c++ program](https://www.google.com/search?q=simple+c%2B%2B+program) A good result will show you something like #include &lt;iostream&gt; int main() { std::cout &lt;&lt; "Hello, World!\n"; } You need to know how to build and run this program. - [open file c++](https://www.google.com/search?q=open+file+c%2B%2B) A good result might show you: #include &lt;fstream&gt; #include &lt;iostream&gt; int main() { std::ifstream input_file("foo.txt"); if (input_file) { std::cout &lt;&lt; "The file 'foo.txt' was successfully opened for reading.\n"; } else { std::cout &lt;&lt; "Opening the file 'foo.txt' failed.\n"; } } - [read numbers c++](https://www.google.com/search?q=open+file+c%2B%2B) A good result might show you: #include &lt;fstream&gt; #include &lt;iostream&gt; int main() { std::ifstream input_file("foo.txt"); if (input_file) { int i; if (input_file &gt;&gt; i) { std::cout &lt;&lt; "The number " &lt;&lt; i &lt;&lt; " was successfully read from the file.\n"; } } } - [store number in array c++](https://www.google.com/search?q=store+number+in+array+c%2B%2B) A good result might show you: #include &lt;vector&gt; #include &lt;iostream&gt; int main() { std::vector&lt;int&gt; v; for (int i=0; i&lt;10; ++i) { int number_to_store = 5-i; v.push_back(number_to_store); } for (int i=0; i&lt;v.size(); ++i) { std::cout &lt;&lt; "number in array at position " &lt;&lt; i &lt;&lt; " is " &lt;&lt; v[i] &lt;&lt; '\n'; } } And so on for the other parts of the program, but this will get you started on writing your own program that opens a file, reads numbers from it and stores the numbers in an array.
I discussed the use of shared_ptr and ref counting in great detail in my previous blog. I always use std::make_shared to co-locate reference count with the object being allocated. It's a pretty basic technique. The main reason to use shared_ptr though is its thread safety.
I discussed performance in the first blog in the series. In particular, under what circumstances, a shared pointer is "slow" and what other options there are.,
Compiler back-end (code generation/optimization) stuff is incomprehensible magic to me. I can't do anything differently in the library, so this should be reported through Microsoft Connect.
&gt; when you use shared_ptr everywhere C++ is really slow I don't get it. Nodes have to be allocated so they can be shared. And they need to be reference counted because C++ doesn't have GC. And ideally, the node should be co-located with the reference count. And updating the reference count should be done with atomic operations. `std::make_shared` achieves all of that. What exactly is the problem here?
1a) This is about return types, not about argument passing. 1b) If you know of code-gen issues then file a bug -- otherwise it's just unproductive ranting. 2) rdtsc is fine for this type of testing, on my machine, and those were my requirements. The alternatives were less convenient.
Yep, bug reported already.
&gt; 1b) If you know of code-gen issues then file a bug -- otherwise it's just unproductive ranting. Amusing. How productive is ever going to be doing unpaid work for a paid-for product exactly? &gt; 2) rdtsc is fine for this type of testing, on my machine... Obviously, it isn't. Just SetProcessAffinityMask(-1, 1) or something and call it a day. 
Hmm, you're right, flyweight and geometry don't seem to be there. If I remember correctly, those PDFs are just offline versions of the online documentation and reference manuals. Unfortunately, I've not been able to find any good boost books which comprehensively cover the library. Probably because its so big and changes so quickly! If you ever do come across one, let me know, I often find myself googling whenever I have to solve a particular problem if boost has already solved it :)
shared_ptr === I'm too lazy to think about resource ownership (what gets acquired, must also be released at some point), so I'll let the computer handle it for me. Substitute "too lazy to think" with "I made a mess of my program", "the program grew organically", "the teams didn't communicate", etc. These are all real-world problems solved to a certain degree by shared_ptr. A data structure like a binary tree is a cohesive unit with its own invariants, and in such cases the ownership *must* be clear. shared_ptr is there an implementation detail used for concurrency and reference counting, not because it inherently expresses some kind of ownership. (Though: whether a node owns its children, or whether the tree owns all of its nodes is somewhat philosophical.) Exposing left and right fields as public is a bad idea because the user code can break the tree invariant; for example take a leaf node and point one of its (necessarily null) pointers back to the root node. Voila, you have created a cycle, so, a normally terminating tree algorithm, like DFS, will end up in an infinite loop. Lastly, shared_ptr is a weird beast. For example, you have to pass it around by const reference to functions, unless your intention really is to make the receiving function another owner (in a collection of many owners) of the resource. So you're back to thinking about when to transfer ownership (or make a new owner). If you don't think about that, you'll end up passing shared_ptrs by value everywhere, and reduce the speed of your program to that of Java or probably worse. But if you *do* think about ownership, why would you need shared_ptr at all?! PS: The name implies a "pointer". But it's less than a pointer because you can't do pointer arithmetic with a shared_ptr. It would better be named like ref_counted_object, but the limitations of C++ make it impossible to overload the member access operator (dot). Thus, the pointer dereference operator is overloaded, so the unfortunate "pointer" in name. Bah, this was a half-rant. C++ is a mess. You'll get used to it, but you'll never like it.
Or just use Intel's brilliant TBB library. tbb::parallel_for(0, n, [](int i) { //whoops, streams aren't (currently) thread safe //std::cout &lt;&lt; i &lt;&lt; std::endl; std::printf("%d\n", i); } ); No need for hack-job-macros Also, you're contructor should be a template, like so: template&lt;typename Func&gt; thread_pool(std::size_t num_threads, Func func) { for(std::size_t i=0; i!=num_threads; ++i) the_pool.emplace_back(func); } EDIT: streams aren't thread safe.
&gt; Define NOMINMAX project-wide. Thank you, I know about this option. This will break some other Windows header file using macro max, it is [Gdiplus](http://stackoverflow.com/questions/4913922/possible-problems-with-nominmax-on-visual-c).
Or just do this... gcc4.8+ or something with std::thread support // // __THREAD_POOL_H__ #ifndef __THREAD_POOL_H__ #define __THREAD_POOL_H__ #include &lt;glog/logging.h&gt; #include &lt;vector&gt; #include &lt;queue&gt; #include &lt;memory&gt; #include &lt;thread&gt; #include &lt;mutex&gt; #include &lt;condition_variable&gt; #include &lt;future&gt; #include &lt;functional&gt; #include &lt;stdexcept&gt; namespace ted { namespace utils { class ThreadPool { public: ThreadPool(size_t); template&lt;class F, class... Args&gt; auto enqueue(F&amp;&amp; f, Args&amp;&amp; ... args) -&gt; std::future&lt;decltype(std::forward&lt;F&gt;(f)(std::forward&lt;Args&gt;(args)...))&gt;; ~ThreadPool(); private: // need to keep track of threads so we can join them std::vector&lt; std::thread &gt; workers; // the task queue std::queue&lt; std::function&lt;void()&gt; &gt; tasks; // synchronization std::mutex queue_mutex; std::condition_variable condition; bool stop; }; // the constructor just launches some amount of workers inline ThreadPool::ThreadPool(size_t threads) : stop(false) { for (size_t i = 0; i &lt; threads; ++i) { workers.push_back(std::thread( [this] { while (true) { std::unique_lock&lt;std::mutex&gt; lock(this-&gt;queue_mutex); while (!this-&gt;stop &amp;&amp; this-&gt;tasks.empty()) this-&gt;condition.wait(lock); if (this-&gt;stop &amp;&amp; this-&gt;tasks.empty()) return; std::function&lt;void()&gt; task(this-&gt;tasks.front()); this-&gt;tasks.pop(); lock.unlock(); task(); } } )); } } // add new work item to the pool template&lt;class F, class... Args&gt; auto ThreadPool::enqueue(F&amp;&amp; f, Args&amp;&amp; ... args) -&gt; std::future&lt;decltype(std::forward&lt;F&gt;(f)(std::forward&lt;Args&gt;(args)...))&gt; { typedef decltype(std::forward&lt;F&gt;(f)(std::forward&lt;Args&gt;(args)...)) return_type; // don't allow enqueueing after stopping the pool if (stop) throw std::runtime_error("enqueue on stopped ThreadPool"); auto task = std::make_shared&lt; std::packaged_task&lt;return_type()&gt; &gt;( std::bind(std::forward&lt;F&gt;(f), std::forward&lt;Args&gt;(args)...) ); std::future&lt;return_type&gt; res = task-&gt;get_future(); { std::unique_lock&lt;std::mutex&gt; lock(queue_mutex); tasks.push([task]() { (*task)(); }); } condition.notify_one(); return res; } // the destructor joins all threads inline ThreadPool::~ThreadPool() { { std::unique_lock&lt;std::mutex&gt; lock(queue_mutex); stop = true; } condition.notify_all(); for (size_t i = 0; i &lt; workers.size(); ++i) workers[i].join(); } } // namespace utils } // namespace ted #endif use it like this ted::utils::ThreadPool pool(thread_cnt); std::vector&lt; std::future&lt;void&gt; &gt; futures; futures.push_back( pool.enqueue([](void) -&gt; void { LOG(INFO) &lt;&lt; "whatever'; //glog is thread safe... }) ); for (size_t i = 0; i &lt; futures.size(); ++i) { futures[i].wait(); }
Because there's a lot of value in an open-source cross-platform library like boost using a more widely used system like CMake. I know of no project but boost that uses bjam, while CMake is used by an ever-increasing number. It makes integration with other projects simpler, gets the benefit of a bigger community, and means they can focus on improving the library, not the build system. 
use std::thread_group if you'd need an container for threads.
From [N3690](http://open-std.org/JTC1/SC22/WG21/docs/papers/2013/n3690.pdf), 20.9.2.2.6/6 regarding `make_shared`: &gt; Remarks: Implementations should perform no more than one memory allocation. [ Note: This provides efficiency equivalent to an intrusive smart pointer. — end note ] In standardese, "should" means non-binding requirement, IIRC, but an implementation would be bloody stupid not to perform this optimization, and I don't know of one that doesn't.
You're trolling. Does `shared_ptr` get overused? Yes. That doesn't mean it isn't the right tool here. And yes, the child pointers would be private in real code. So what?
I implemented something like this as part of [Async++](https://github.com/Amanieu/asyncplusplus), which is a very lightweight C++11 framework for parallelism: async::parallel_for(async::irange(0, n), [](int i) { std::cout &lt;&lt; i &lt;&lt; std::endl; }); It also has a lot of other features, such as tasks (similar to C++11 futures but with more features). See the documentation for more examples.
My [MinGW distro](http://nuwen.net/mingw.html) intentionally doesn't come with an IDE, but it's super simple to install and should definitely work on your system as long as it's x64 (which it is because I can see "* 32" processes in your Task Manager).
Can you try running your compiler manually from the command line? If you installed the version of Codeblocks that comes with a compiler, there should be a directory located in its program files directory that has the compiler executable, a program called "g++.exe". Navigate to the folder that your C++ source code is stored in and run the following command: C:\full\path\to\your\mingw\compiler\g++.exe your_cpp_file.cpp And tell us what the result is.
Still doesn't mean CMake is a good build system.... if ("${VAR}" STREQUAL "mystr") ... endif() ..think i've said enough. 
Actually, N3797 27.4.1 [iostream.objects.overview]/4: "Concurrent access to a synchronized (27.5.3.4) standard iostream object's formatted and unformatted input (27.7.2.1) and output (27.7.3.1) functions or a standard C stream by multiple threads shall not result in a data race (1.10). [ Note: Users must still synchronize concurrent use of these objects and streams by multiple threads if they wish to avoid interleaved characters. -end note ]"
What am I missing here ? The good thing about OpenMP is that it allows me to parallelize loops (albeit not perfectly/with some overhead) for exactly zero dev-cost and zero-boilerplate code. This is why I use OpenMP for. If I need more, I will use something else and write more code. Also, I think this article needs bench to compare the respective performances of this solution and OpenMP. 
What do you use as a debugger (if any) with your MinGW distro? Would it be easy to use gdb with this?
You're searching for the wrong term. Where you are saying "parallelism," you probably mean "concurrency." Which is why the book you got was more about parallel algorithms. For concurrency programming in C++, you need to understand how the execution model works. Take a look at Boost coroutines. To see what it might end up looking like, Erlang and Go have good concurrency primitives. Erlang takes a fully shared nothing approach but you can do something similar if you really wanted to roll it out in C++. tl;dr, search for concurrency. also, read up on the difference between a native thread and a green thread.
Yes, but in my example: std::cout &lt;&lt; i &lt;&lt; std::endl; The newline (beit endl or '\n') has no guarantee of being printed with `i`?
It started working, but Basic "Hello World" program takes ~3 seconds to start.. Process returned 0 (0x0) execution time : 3.569 s
And i found out that cstdlib library is doing that thing (not letting me close the program or terminate it through task manager)
I second this. I know that you asked for C++, but this is really Erlang's problem domain, not C++. Technically you can do pretty much anything in C++, but it's not always the best way to do it. The great thing about Erlang is that it is a very small language, so it is very easy to pick up. The only slightly challenging hurdle to jump over is the whole functional programming thing, but it's really not that bad. Also, on the plus side, you really can't go wrong with any of the currently available Erlang books, they're all great.
Or you could use any of the 2.8.x versions of CMake and just write: if(var STREQUAL "mystr") ... endif() I'm not going to argue that the CMake scripting language doesn't have warts. I will argue that CMake is the only tool that even comes close to providing the kind of cross-platform build system generation a developer needs to correctly target multiple OSes easily.
This is THE c++11 book on the matter of concurrency, but I believe it focuesses on shared memory machines and the C++ standard rather than distribution. C++ Concurrency in Action http://www.manning.com/williams/
No guarantee - it is a separate function call. `i` itself may be interleaved with other characters (same for printf).
Surely `std::printf` it is guaranteed to get this following right: std::printf("%d\n", i); Whereas std::cout &lt;&lt; i &lt;&lt; std::endl;# Could get garbled? Of course two independent printf calls could intermingle but that's not what's happening here.
There are no such guarantees in either the C or C++ Standards. In practice this is sensitive to the buffer sizes chosen.
Oh ok thanks, that's interesting, thanks. Am I right in thinking there is some work being done for some synchronisation for streams for a future standard? Although I for the real world it's just better to only handle IO from a single thread.
It may be a good point, but when someone says they work on a project in C++ it's not really relevant what some other language can do. Professional developers don't get to just rewrite everything in some other language. I could also count the number of people I've met who know the language with my fingers...if I'd been born without arms. I'm not the one that tossed in the -1, but it is quite beside the point for me.
LOL. When did "green thread" become a term? Used to use "user-space thread". Boost's coroutines have interested me. You know of any good, thorough material to learn how to use them...you know, beyond the basic 'this is how the api works' thing but actually how to apply them to real problems?
I just didn't know if you were aware how perfect Erlang is for the problem domain you were describing. I really was just trying to help. I love C++ as much as the next guy, but if there's a better solution to a problem, I'd rather use it.
?? Green thread has been a term for a long ass time. Coroutines are too new in the C++ world to have actual usage literature. But they're as old as Knuth's first AoCP book where they are described. It's just message passing on a lower level between functions. The main keyword I suppose is continuation which C++ does not support natively (as opposed to, say, C#). I don't know of any literature that would help you in the specific area you are requesting. I imagine it will be sparse because this is not a natural fit for C++ in general (at least, with the current feature set). The real killer is that it's hard for the user to define when context switches should occur without assembly hacking, which is not generally portable. Boost is making good strides though so we'll see what happens to the language in C++14
There isn't a `std::thread_group`. There is a `boost::thread_group`, I believe the rational for not bring it into the stdlib `vector&lt;thread&gt;` was as-good.
Sigh... There's at least one in every group.
boost has this as boost::scope_exit
I guess it can be useful but the examples are pretty weird. Written by a Java / .NET programmer? &gt; If something looks strange to you, then something could really be wrong. For instance... Mutex m = new Mutex; Instead of simply... Mutex m; And why not call unlock() from the Mutex destructor? The destructor will run regardless of exit method in the example code since 'm' is not a pointer, thus no need for any special scope code. Why not make it simple. class Scope { public: Scope(std::function&lt;void(void)&gt; _onExit) : onExit(_onExit) {} ~Scope() { onExit(); } private: std::function&lt;void(void)&gt; onExit; }; MyClass::MyMethod() { Mutex *_m = nullptr; Scope _scope([this](){ delete _m; }); _m = new Mutex; foo(); } 
Or do as C++ currently does using lock guards. my_func() { std::lock_guard&lt;std::mutex&gt; lk { my_mtx }; //do whatever }
This code doesn't work (for the success/failure cases) because it's based on `std::uncaught_exception`. This will fail if its called during an already-unwinding stack. See: http://www.gotw.ca/gotw/047.htm This is the reason boost only implements exit() and not success() or failure(). (edit: in /r/programming, andrei's comment links to much more information: http://www.reddit.com/r/programming/comments/1rp8es/c_secrets_ds_scope_statement_in_c/cdpl6er)
&gt; But if you do think about ownership, why would you need shared ptr at all?! One use I found was threaded scenarios, where stuff is shared between threads. It allowed me to work with an object without worrying that it might disappear on me. It requires discipline in a sense that "users" need to hold weak pointers, and only switch to shared when they actually want to work with the object, whereas "owners" hold shared ones. And because threading is nondeterministic, shared per keeps me afloat without much worry. But yeah, shared ptr is overused. 
In fact, as a professional C++ (and Java) programmer I often look at how other languages solve problems for ideas and inspiration. Haskell's Maybe (aka optional) and Go's channels, for example, are very useful abstractions and they can (at least partly) be implemented in C++. Also, I would say that the problems that you have to solve to get a failure-tolerant distributed system (like reliable election algorithms and such stuff) are often independent from the specific implementation language.
EDIT: Followed the discussion in the /r/programming thread you linked to.
The committee considered a proposal but it wasn't accepted. I don't know its current status.
Awesome practical introduction to writing games!
Apparently Bjarne gets asked often enough about whether this interview is real that he has it in [an FAQ on his personal website](http://www.stroustrup.com/bs_faq.html#IEEE).
Having programmed in both C and C++, there's a lot of times I think like this. C++ is a mess...
Made some changes to the article and now explicitly handle those cases.
This is so amazing
AFAIK the whole point of the licensing is to force you to buy a license in order to distribute a proprietary application using it. http://software.intel.com/en-us/intel-threading-building-blocks-purchase
Related library: https://github.com/Neverlord/libcppa
I wrote a library that uses boost::context, which is the layer below boost::coroutine. I use it for distributed systems with many connections and thousands of requests a second. https://github.com/toffaletti/libten. There isn't much documentation, but plenty of examples and tests. libcppa is also great if you want Actors.
I like it how you can't read a single word in Japanese, but understand what this guy in the blog is saying.
I guess, the idea is that all the data is packed nicely in the vector and locality is high. In my opinion, a better approach is to use a block allocator.
LOL I noticed that too!
Isn't that effectively the same thing? It's the same trade off as with variant/tagged-unions that "wastes" memory for the smaller objects.
But is that better performance wise ? In both case, there is a dynamic lookup anyway right (I guess Boost Variant use a field as a dispatcher) ? Couldn't this be achieve with CRTP ?
Any reason [SFML](http://www.sfml-dev.org/index.php) isn't in the running?
SDL contains much more functionality than GLFW. What's your goal? If you just want to create a window/context and react to input/events then GLFW is good for you because it's superior in OpenGL support. SDL on the other hand gives you a 2D graphics API (sort of), audio output, and the other stuff you can read on their website. For OpenGL applications I personally prefer GLFW. It is less intrusive than SDL, you just set it up and that's it. I also like its API and the much better OpenGL support.
What bugs? I am using SFML with MinGW and except a very high cpu consumption of Texture::update() I didn't found any other bug, as far as I remember.
It is not exactly the same thing. When you call a virtual function you still have to access the vtable, which is probably "far away" from your data.
We have a [questions](http://www.reddit.com/r/cpp_questions) subreddit specifically for questions :)
GLFW is more lightweight. SDL2 does lots of very cool stuff - for example, it can remap all of your controllers to act like a standard controller using the help of Steam's Big Picture mode controller mapping settings.
The actual names used are completely arbitrary, and every declaration is different, so you really need to post some context. Generally we can infer that `_Elem` is an element type, `_Traits` is a character traits type, and `_Alloc` is the type of the allocator. 
Glfw is great. It works well, very simple, and you can do input by callbacks or by polling. I love it. The new version lets you open up multiple windows easily. I have used SDL before but am very sold on GLFW.
I like SDL2 because it seems to handle fullscreen windows on linux more easily than the alternatives when you have multiple displays. 
It is. TBB exists to help Intel sell hardware. Short of republishing their code as your own, they don't want the licensing to get in your way.
It doesn't matter though. The table location is equal for objects of the same dynamic type**, it's a reliable cache hit after a couple of iterations. I'm pretty sure that branches in Variant are tricky to predict and will cost you way more than this additional level of indirection. ** Not guaranteed and not true if dynamic linking is used.
GLFW API is clean, I would go there first if I needed an openGL window and an event loop with a registry of input event callbacks. Of SDL I disliked their idea of [redefining](http://blog.debao.me/2013/07/link-confilict-between-sdl-and-qt-under-windows/) main().
I couldn't agree more! I love /u/STL's videos. They should be compulsory viewing for all C++ developers. He is probably my favourite presenter from Microsoft now. He explains things so well (unlike most developers). 
Being c++ lectures, shouldn't that be part 0 of n for the first one?
Don't copy their naming scheme. You're not allowed to use names that begin with an underscore followed by a capital letter; those names are reserved for the compiler/standard library.
You might not get as much locality with a block allocator... after a couple erase/insert.
Some of the Going {Deep, Native} are just talks which doesn't need the visual part - and that you can download it as audio as well and just listen to it while in transit is awesome.
Should the "first one" be the "zeroed zero" then? :)
Question: Do the compiler writers and the standard library developers have some sort of meeting to decide who gets to use which underscored words? Is there some sort of annual meeting where they compare notes? "Um... sorry about using \_Elem. You guys can take \_Elem\_, we won't use that one."
Excellent. Best cakeday present EVER!
Installation was weird with the way threads were handled, it would cause an immediate segfault when the simplest example from the website was used. There was an alternate version with compatible threads somewhere, but I can't seem to find it on their site.
Why the N/As for a few things? Did those just formalize the existing behavior so there's nothing to change?
In practice, Standard Library devs are the major users of `_Ugly` names. Compiler devs take a few (e.g. predefined macros, type traits compiler hooks) but not many. VC further avoids conflicts because the library typically uses `_Ugly` while the compiler typically uses `__ugly`. Also, as compilers and libraries typically ship together, the library devs know how to contact the compiler devs.
Reworded Sequence Points is N/A because I am unaware of major differences between the C++03 "sequence point" wording and C++11's "sequenced before" wording for single-threaded code. Memory Model is N/A because I am unaware of any impact on compilers that already supported (non-Standard) multithreading. It is possible that C++11's memory model strictly bans some optimizations that compilers previously attempted to get away with, but I am not aware of any for VC, and such things would really have been bugs in the olden days too. Extended Integer Types is definitely N/A - it permits but does not require types longer than `long long` to exist. VC doesn't support such types, so there's nothing for us to do. (Stuff like `__m128` is totally different.)
OK, ready for someone to explain to me why git is any good. I used it a few times, and I didn't find it any better than svn. Someone explain to me why I am wrong.
I think it would be faster. AFAIK applying a visitor results in generation if/else code at compile time. This generated code is inlineable. (Correct me if I'm wrong.) CRTP should be even faster because it eliminates the branches. However you lose the type erasure. (I.e. you can't have a vector with instances of different sub-types.)
Here's an idea: You are allowed to see the explanation even if you don't answer correctly, but only after having tried to answer the question three times. Does that sound reasonable?
And ok I made a stupid joke, but I want to add that these are really good.
&gt; Expression SFINAE No No come on guys.
Does this mean that VC++ finally supports all of C++98?
Yes, they've been very clear about that from the beginning (unlike with 2012, where it sounded like the CTP stuff would eventually be shipped in an update). 2008's the only version to have gotten new C++ features in an update, and that was purely a library update.
Alright, thanks for the info. Any idea when the next VS may possibly come out? It seems like MS has recently switched to a much quicker iteration model, so would it be reasonable to expect VS 2014?
It may not be called VS 2014, but it certainly sounds like there will be a new version of VS in some form in 2014.
No. The most significant omission is that two-phase name lookup hasn't been implemented. Also, dynamic exception specifications are almost entirely unimplemented, but they are deprecated in C++11. (VC will never implement export, removed in C++11.)
&gt; No. Gotta love MS :) 
Nowadays these announcements from MS have a lot of humoristic value. Earlier it was always like: "Come on, C++ is hard. Of course there can't be a complete implementation of the current standard! MS is just a multi billion corporation - they are not omnipotent". And then the LLVM/Clang project came along ... I don't know. But to me it looks like either MS doesn't give a shit about C++ or they hire ... well ... not top-tier developers.
Guess the reasoning goes as "If they managed to do without it for 15 years, they can wait another two until we have full C++11/14 support" :P
All your questions can be answered by following the [link](http://isocpp.org/get-started) from the sidebar :)
C++ is a very complicated language for a novice to pick up. If your interest is in games, I suggest working with a higher level language to start. Either way, there's a lot of ground to cover, and if you find you're not learning from online sources, you should consider a school or other tutor. The first language I learned was through a technical college night course in C. Consider that it's generally considered to take ~10,000 hours of practice to master any field, and if you're thinking of making games in C++ you're better off starting sooner than later.
I honestly think you'd be better off downloading Unity and learning some C# or Javascript or Boo. They're all relatively simple, higher-level languages and plug directly into the Unity engine.
Writing video games is nothing like playing them. It's programming, which isn't the same thing. This may sound obvious and pointless to point out, but it's actually very important. Often, folks who love gaming hate programming because of the relative lack of immediate reward that programming has. It can take a long time to get something to work the way you want it to. Also, coding is only part of creating a video game. Level design, writing, and art are all important parts of the process. Figure out which one of those things you enjoy most and work on that. Learning C++ because you want to mess around with video game creation is like learning mechanical engineering because you want to tinker with your car.
c++ is a decent language to start out gamedev in. I hear cinder (http://libcinder.org/) is a good easy to use graphics library but I have never used it myself.
Okay, first of all. ~~Which language are we talking about? C++, C, Matlab, Java, Haskell?~~ Oh, It's posted in /r/cpp. *Damn you, multireddits!* Next, what is the format of the file? Are record seperated by newline? Are numbers stored in binary or text format? Are they integers or floats? For instance in C++: int readRecords(ifstream &amp;fstream, double * pScore1, double * pScore2) { unsigned int recordCount = 0; //What should we do with this? unsigned int identifier; while (!fstream.eof()) { fstream &gt;&gt; identifier; fstream &gt;&gt; pScore1[recordCount]; fstream &gt;&gt; pScore2[recordCount]; recordCount++; } return recordCount; } Please op, give more information.
Oh, they must have fixed it. I'll have to update my version, then!
They've been able to since the initial release of Windows 8 and the WinRT API. This book doesn't suddenly and magically enable that functionality.
const cannot be cast away. Once windowWidth is a const int, it is const int for the rest of its lifetime. (I agree on the use of constexpr though)
You need to check the status of the stream after reading from it, not before; it would e.g. test OK just before EOF, but reading from it then will return garbage and only then set the EOF flag. This is bad practice even in toy examples. int readRecords(std::ifstream&amp; f, int* pScore1, int* pScore2) { unsigned int recordCount = 0; unsigned int identifier; std::string line; while (std::getline(f, line)) { // only proceed if a line could be read std::stringstream ss(line); // always assume that each line has 3 entries ss &gt;&gt; identifier; ss &gt;&gt; pScore1[recordCount]; ss &gt;&gt; pScore2[recordCount]; ++recordCount; } return recordCount; } 
No it doesn't brake it, but it easily enables you to write non portable code.
What @mrmcgibby said, up till the last paragraph. Your goal is not to tinker with your car, but to build one. It's an important distinction, because it makes clear why you need to learn a great deal before you can even start.
I disagree, but I may be wrong, if so, correct me please. &gt; Swap trick: With C++11, you can replace the helper function with a call to the new vector::shrink_to_fit() method, which does the same thing. No, it doesn't, it can do just nothing. &gt; vector resize operations will sometimes invalidate existing iterators Resize (grow) will always invalidate iterators, resize (shrink) will invalidate iterators to destroyed elements (and *the end* iterator). &gt; vector of vectors are expensive Not with C++11 and move semantics. If outer vector needs to reallocate, the inner vectors should be moved (FAST!, six pointer swaps) to new buffer. &gt; Pre-allocate &amp; *clear()* trick. Isn't *reserve()* better/easier? Plus not calling 20 times cFace constructor (is cFace some kind of int or some complex class?). &gt; One vector for all queries per thread. Does C++11 vector support statefull allocator? I don't know. If yes, keeping one allocator per thread and element type and distribute it to various vectors seems better idea to me (and I think easy to implement, but not sure). &gt; Check that *clear()* isn’t freeing the buffer. It doesn't. Link to [clear()](http://en.cppreference.com/w/cpp/container/vector/clear) in cppreference.
&gt; Resize (grow) will always invalidate iterators No, resize (grow) only invalidates iterators if the capacity increases. &gt; Isn't reserve() better/easier? Yeah, reading the article, I get the distinct impression the author didn't know about reserve(). 
&gt;I don't think the inner vectors will be moved; vector doesn't have a noexcept move constructor. It doesn't? What part of moving a vector can throw? It's just a few assignments to fundamental types.
Have to believe this will get fixed in c++17...
The allocator.
But doesn't the pointer stealing prevent the need to allocate any memory?
It can only move the allocator if `propagate_on_container_move_assignment::value` is `true` otherwise it needs to construct a new allocator, which can throw. For `std::allocator` this is `false`.
&gt;&gt; Swap trick: With C++11, you can replace the helper function with a call to the new vector::shrink_to_fit() method, which does the same thing. &gt; No, it doesn't, it can do just nothing This was discussed here recently, /u/STL helpfully [explained](http://www.reddit.com/r/cpp/comments/1r1s58/did_the_committee_blow_it_with_shrink_to_fit/cdix8vs) that this leeway in the standard was to allow the implementator, who understand the low level details of their STL, to choose the best approach. The example given was strings with the small string optimisation. They have a minimum buffer size so calling shrink_to_fit when they are at or below that size will (correctly) no-op.
&gt; Isn't reserve() better/easier? reserve() doesn't save you from a pair of allocate/deallocate calls if your std::vector is using automatic storage. The idea is that you need a buffer to perform an operation, essentially as temporary scratch space. Rather than build up and tear down that buffer every time the operation is called, you keep it around for repeated use. An alternative is to have your caller pass in a buffer for your use. Then the burden is on your caller to avoid the repeated allocate/deallocate if calling multiple times. But unless your caller needs fine-grained control over resource allocation, an internally managed buffer makes for a simpler API. The article's scheme works well for std::vector but beware trying to generalize it to std::string. Up until C++11, std::string could be implemented using reference counting, and as a result you could still see unexpected reallocations. GNU's libstdc++ still worked that way last I checked.
These links are surprisingly clear given I don't understand Japanese. I suppose a huge help in that regard is the use of English names in the code.
Allocator copies/moves are forbidden from throwing, see N3797 17.6.3.5 [allocator.requirements].
&gt; the same mistakes STL highlighted in it as as well Are those mistakes pointed out in the talk, or in a separate article, I'd love to read them?
Yes it is in c++, The two test scores are on the same line separated by a space. Each new line represents a new students score. I would like the numbers to be stored in text format and they will be integers because they are just numbers 0 to 100. The text I posted earlier is ver batim from the programming assignment and that is what i've been dealing with all year. Thanks so much for your help.
I like nuwen.net and MinGW-W64
You can't have SBO based implementations for std::vector/std::deque et al, because of the requirements for std::swap. The std::string example is not applicable in this context. 
Great series, very much enjoying it. In the examples that use abs(XX) then you need to include cmath to get around ambiguous calls to abs. The Vector2 struct in your thoughts example does not compile on my rig (clang 3.4). The Vector2 getMyVector1() { return Vector2(5.f, 5.f); } will not compile as there is no matching constructor for that call. You can create the constructor in the struct, but it's not required for the brace initialised version though. I have cloned and will do a pull request with some of these fixes and a cmakelists.txt for cross platform use of these examples. Realy good. 
`std::basic_string` is a standard container which has a `shrink_to_fit` member. So I was just giving one example of a circumstance where calling it might not actually shrink the container's capacity. 
I use [mingw-builds](http://sourceforge.net/projects/mingwbuilds/), since they also provide Qt and other libraries. Be aware that with TDM the compiler itself is a 32bit application (also the 64bit targeting compiler), i.e. if your compile process might need more then 2GB of memory, you're out of luck.
Well, there are a bunch of criteria to consider: 1. How important are ease-of-installation and avoiding-system-modification to you? My distro (nuwen.net) tries to be super easy to install, and is 100% non-modifying. mingw.org has some wacky mingw-get installer (which I've never used), and the other distros fall somewhere in the middle (I have no experience with them). 2. Do you want mingw.org headers or mingw-w64 headers? mingw-w64 is more comprehensive and better maintained. 3. Do you want to target 32-bit (both mingw.org and mingw-w64 can) and/or 64-bit (only mingw-w64 can, currently)? Note that I hate modes, so although my distro is mingw-w64 based, it is x64 native and I will never build another 32-bit hosted or targeting distro again. Ever. 4. Do you want static or dynamic linking? Some distros offer you options. I hate DLLs, so everything is static. 5. What prebuilt libraries and utilities do you want? I have a bunch (including Boost), which I keep updated and patched. But I don't use/build gdb. There are other things that people occasionally ask for that I don't use/build (e.g. SFML), although I provide my build environment so people can add whatever they want. 6. What kind of C++ EH do you want? There's SJLJ, DW2, and SEH. If you don't know what this question means, you have to trust your distro maintainer to choose appropriately. I choose SEH because I know what I'm doing (hint: it is the best). 7. How long has the distro been maintained? Mine's been available since 2005. Obviously I like my distro and I'm happy when people use it (I'm also happy that they're testing my home environment), but it's not for everyone. I recommend against mingw.org, but any of the mingw-w64 distros are good alternatives.
&gt;Missing two-phase lookup doesn't break correct code AFAIK Of course it does, otherwise it would be irrelevant. The following example will produce different runtime behavior in GCC and MSVC. GCC's output is the correct output. void f(void* p) { std::cout &lt;&lt; "This is GCC/clang/standard C++."; } template&lt;typename T&gt; struct S { S() { foo(0); } }; void foo(int v) { std::cout &lt;&lt; "This is MSVC."; } int main() { S&lt;int&gt; s; }
I guess I'm kind of an asshole for commenting _during Andrei's talk_ that his approach was all wrong. But it was, and when the C++ part of my brain sees bad code, every other part shuts down. However, this guy (Hatena?) is making different mistakes - he's not plagiarizing Andrei. First, let's look at Andrei's code from [his slides](http://channel9.msdn.com/Events/GoingNative/2013/The-Way-of-the-Exploding-Tuple) (there's a Zip link below the video, it's a zipped PDF). My copy-paste has smashed the indenting, sorry: template &lt;unsigned K, class R, class F, class Tup&gt; struct Expander { template &lt;class... Us&gt; static R expand(F f, Tup&amp;&amp; t, Us... args) { return Expander&lt;K - 1, R, F, Tup&gt;::expand( f, forward(t), get&lt;K - 1&gt;(forward(t)), forward&lt;Us&gt;(args)...); } }; template &lt;class F, class R, class Tup&gt; struct Expander&lt;0, R, F, Tup&gt; { template &lt;class... Us&gt; static R expand(F f, Tup&amp;&amp;, Us... args) { return f(forward&lt;Us&gt;(args)...); } }; template &lt;class F, class... Ts&gt; auto explode(F&amp;&amp; f, const tuple&lt;Ts...&gt;&amp; t) -&gt; typename result_of&lt;F(Ts...)&gt;::type { return Expander&lt;sizeof...(Ts), typename result_of&lt;F(Ts...)&gt;::type, F, const tuple&lt;Ts...&gt;&amp;&gt;::expand(f, t); } template &lt;class F, class... Ts&gt; auto explode(F&amp;&amp; f, tuple&lt;Ts...&gt;&amp; t) -&gt; typename result_of&lt;F(Ts...)&gt;::type { return Expander&lt; sizeof...(Ts), typename result_of&lt;F(Ts...)&gt;::type, F, tuple&lt;Ts...&gt;&amp;&gt;::expand(f, t); } template &lt;class F, class... Ts&gt; auto explode(F&amp;&amp; f, tuple&lt;Ts...&gt;&amp;&amp; t) -&gt; typename result_of&lt;F(Ts...)&gt;::type { return Expander&lt; sizeof...(Ts), typename result_of&lt;F(Ts...)&gt;::type, F, tuple&lt;Ts...&gt;&amp;&amp;&gt;::expand(f, move(t)); } Problems: 0. Typos that would prevent this code from compiling (e.g. `forward(t)` being called without an explicit template argument). 1. This is unnecessarily complicated. (Some complicated code is necessary; this is not.) 2. It handles `const tuple&amp;`, `tuple&amp;`, and `tuple&amp;&amp;` (those are the `explode()` overloads). However, it doesn't handle `const tuple&amp;&amp;`. Const rvalues are rare and weird, but they are legitimate, and certain situations can form them, so they should be handled by highly generic code. (They're a perennial source of headaches in the STL, for example. Even the Standard's `get()` is deficient, bad Standard!) This deficiency is subtle - as written, const rvalues will be absorbed by the `const tuple&amp;` overload, so most code will appear to work. 3. Each overload is asking `result_of&lt;F(Ts...)&gt;`. This is wrong, which I can describe at a high level and a low level. At a high level, `decltype` gives us the ability to ask "what is the type of this expression", and it is always right (as long as you know how `decltype` works). `result_of` is TR1-era tech - and although it has been enhanced for C++11, and it can still be useful, it is not suitable here. The problem is that `result_of` has to be fed types, and you have to ensure that those types match the arguments you're going to feed to the actual function call when it happens. At a low level, in this case, the `Ts...` in the `tuple` are being fed to `result_of`, but the function arguments are `get&lt;K - 1&gt;(forward&lt;Tup&gt;(t))`. If you look at how `get()` is specified, the value category and constness of the `tuple` affects the output type - for example, given a `tuple&lt;string&gt;`, `get&lt;0&gt;` will return `string&amp;` for an lvalue `tuple`, and `string&amp;&amp;` for an rvalue tuple. Since the same `result_of&lt;F(Ts...)&gt;` is being repeated each time, this is bad. 4. Nitpick: trailing return types are being used in `explode()`, but they're unnecessary. 5. The other major problem is that `Expander::expand()` is using runtime "recursion" to get elements one-by-one, before finally invoking the functor. At a minimum, debugging through this in debug mode will require many steps. The optimizer will *probably* inline everything, so this is not lethal. So given all of that wrong stuff, what's the right approach? The general guidance here is kind of hard to describe (and harder to learn from first principles - I've picked it up over years of library development), but basically you want to avoid looking at types and arguments too closely. You should start by taking arbitrary *stuff* (perfect forwarding is great for this), and then *carefully* asking questions about the stuff you got. In this case, knowledge of one more trick is necessary - the fact that parameter pack expansion is ultra-awesome, and works with template non-type parameter packs. Hatena's code is closer, but it's messed up in other ways: template &lt; typename F, typename Seq, std:: size_t ...Indexes &gt; constexpr auto invoke_impl( F func, Seq const &amp; seq, std::index_sequence&lt;Indexes...&gt; ){ return func(std::get&lt;Indexes&gt;(seq)...); } template &lt; typename F, typename Seq&gt; constexpr auto invoke(F func, Seq const &amp; seq){ return invoke_impl(func, seq, std::make_index_sequence&lt;std::tuple_size&lt;Seq&gt; {} &gt; {} ); } This uses Jonathan Wakely's C++14 `integer_sequence&lt;T, I...&gt;`. For example, you can say `integer_sequence&lt;int, 11, 22, 33&gt;`. This is especially useful if you form `integer_sequence&lt;size_t, 0, 1, 2, 3&gt;` because that can be passed to a helper function, and then you can say `get&lt;Indexes&gt;(some tuple)...` and have that expand into `get&lt;0&gt;(t), get&lt;1&gt;(t), get&lt;2&gt;(t), etc.` in a single variadic "blast", as I like to call it. There are problems here, though. First, his `invoke` takes `const Seq&amp;`, so modifiable tuples get constness applied to them, and rvalue tuples have their move semantics inhibited. Second, C++14 `auto` return types are cool but undesirable here - if `func()` returns `X&amp;`, then `invoke()` will return `X` by value. The **correct** solution is in the current C++14 Working Paper, [N3797](http://isocpp.org/files/papers/N3797.pdf), 20.5.1 [intseq.general]/2, as amended by [LWG 2314](http://cplusplus.github.io/LWG/lwg-active.html#2314) (I filed that, and it hasn't been processed by the LWG yet, but Jonathan Wakely agreed that the problems and fixes were correctly described): template&lt;class F, class Tuple, std::size_t... I&gt; decltype(auto) apply_impl(F&amp;&amp; f, Tuple&amp;&amp; t, index_sequence&lt;I...&gt;) { return std::forward&lt;F&gt;(f)(std::get&lt;I&gt;(std::forward&lt;Tuple&gt;(t))...); } template&lt;class F, class Tuple&gt; decltype(auto) apply(F&amp;&amp; f, Tuple&amp;&amp; t) { using Indices = make_index_sequence&lt;std::tuple_size&lt;std::decay_t&lt;Tuple&gt;&gt;::value&gt;; return apply_impl(std::forward&lt;F&gt;(f), std::forward&lt;Tuple&gt;(t), Indices()); } This is only 7 actual lines, yet it's complete and correct (unlike the previously analyzed approaches). It might be easier to understand if you read top-down, helper first. Imagine the user is calling `apply_impl()` with some functor `f` and some tuple `t`, which we take via perfect forwarding (so we handle modifiable/const lvalues/rvalues). Also imagine that the user is giving us an `index_sequence&lt;0, 1, 2, 3, blah&gt;` object. (This is an alias template (a "typedef") for `integer_sequence&lt;size_t, 0, 1, 2, 3, blah&gt;`, that's all.) With the proper indices, we can say `std::get&lt;I&gt;(std::forward&lt;Tuple&gt;(t))...` which is just `get&lt;0&gt;(forwarded tuple), get&lt;1&gt;(forwarded tuple), etc.` Remember, we need to say `forward&lt;Tuple&gt;` to respect rvalue tuples. Then we can give that to the functor. Its function call operator might care about its value category (with C++11 ref-qualifiers) so we should say `forward&lt;F&gt;(f)` before invoking the function call operator. Finally, `apply_impl()`'s return type is C++14 `decltype(auto)`. You can go look up the rules for this, but basically it's the exact type of the return statement, with references and cv-qualifiers preserved. So if the functor returns `X`, then so does `apply_impl()`. Same if the functor returns `A&amp;`, `const B&amp;`, `C&amp;&amp;`, or even `const D&amp;&amp;` (always remember to think about const rvalues!) Now look at `apply()`. We take and pass `f` and `t` by perfect forwarding, we just need to construct that magical `index_sequence`. There's library tech for this (courtesy of Mr. Wakely), although we have to do a little bit of work ourselves. `make_index_sequence&lt;N&gt;` is an alias for `index_sequence&lt;0, 1, 2, stuff, N - 1&gt;` which are exactly the indices we want. `tuple_size` will tell us the size of a tuple. However, we're using perfect forwarding here, so `Tuple` might be `tuple&lt;blah&gt;&amp;`, and (annoyingly) `tuple_size` handles const tuples, but not references (this is probably a defect, it's on my list of things to write up solutions for). We can strip away references from `Tuple` using a type trait - `remove_reference_t` would do the job, but `decay_t` is shorter to spell and just as good here. `Indices`, by the way, is just a typedef, but in the C++11 alias syntax. It could be completely omitted here, at the cost of making the return statement very long and in need of wrapping. Moving it out into a separate typedef increases clarity. That's it! The same lessons, except 10 times stronger, apply to `tuple_cat()`. (It took me a whole weekend, and all of my skill, to reimplement `tuple_cat()` along these lines - I shrunk its code from about 150 lines to 50 lines along the way. I have a very weird job.)
Cheating is unethical.
I am curious why they cant release a single compiler with configurations for all of the targets. I would be willing to have GCC occupy another 200 megs so I can change from 32 to 64 bit or windows to linux or SJLJ to DW2 to SEH without having to download and install a brand new compiler. Is this not possible in GCC at all? Clang seems to be able to as long as you have reference headers/libraries.
mingw-w64 supports simultaneous 32-bit and 64-bit targeting (there's an -m32 compiler option), I just disable that.
I personally only have experience with two of those distros; MinGW-W64 and TDM-GCC. The first one I tried was MinGW-W64. I have a game engine I am working on and I wanted to test the build of this engine using DirectX 9, since I was able to hack something together with MinGW32 using the DirectX SDK. Come to find out a lot of the DirectX error utilities have been split into DX8 and DX9 versions. The files and methods have been labeled as such. So I got a bucket of errors in both CMake and when I tried to compile. No bueno. I really don't understand why you would attempt to support something like that and completely break it's API in the process. During my research I found that TDM users didn't suffer the same issue. So I tried it and despite having the same file names and such, it has some magic that just makes it all work. Don't know how, don't care enough to find out so long as it works. It builds fine and my game runs fine. Haven't had any issues with it thus far. TL;DR: MinGW-W64...never again.
nuewn seems to "just work" and be more painless than the others I've tried. The only issues I have with it are :- * No 32 bit support. I have some potential users for my program still running 32 bit windows. * It's maintained by a single individual rather than a team. That significantly increases the risk that one day it won't be available / maintained any more. Other than that, it basically has zero impact to just install it and try it (as installing seems to consist of unzipping the file somewhere)
Yeah I currently use TDM-GCC 4.7.1 32/64 and it has always worked great for me. With the release of 4.8.1 I was thinking of checking out some other distros of MinGW. I think I will stick with TDM though. 
Do any of them support threads?
Current versions come with C++11 thread and they should all come with pthread
&gt; I have some potential users for my program still running 32 bit windows. I won't help you there, sorry. 32-bit usage is down to 17% according to the Steam Hardware Survey (ignoring XP) and it's going to keep falling. &gt; It's maintained by a single individual rather than a team. On the other hand, I distribute my build scripts/patches/environment. In fact, every copy of the distro contains all of the information needed to regenerate it. So while I might get hit by a bus, nobody can take my distro away from you. (In fact, there's nothing stopping you from building a 32-bit flavor of my distro, I just won't donate my time to do so.)
Stephan, * Why don't you use gdb? Are you using the Visual Studio debugger with gcc, or are you using something else? * Is SEH the reason you no longer build 32-bit? (according to mingw-w64 developers, the 32-bit SEH implementation would be patente-encumbered) * Has your gcc distribution ever been the cause for any trouble or anecdote at work? (I mean, you are the freaking STL maintainer at Microsoft! :-) ) * Have you ever considered doing an AMA? 
Why do frameworks so often feel the need to reinvent the resizable array and linked list? Is there really so much of a problem with vector and list? Related: what's the reasoning for "wxWidgets tries to stay a framework, that is not related to the C++ Standard?" This just seems like they're shooting themselves in the foot on purpose.
gdb would be a deal breaker for me (although I don't use windows so my opinion is moot).
Well, if you compile in STL Mode (--enable-stl), you'll get wxVector to actually be a define for std::vector. But you'll have to explicitly build wxWidgets with this. Its not default afaik.
I believe Stephan does not use gdb as he prefers to write bug free code to begin with ;) (I believe they were his words from another comment I read not too long ago). 
Lack of gdb isn't that big of a deal as you can just grab it from another distro like MinGW-W64, however as the Nuwen distro is x64 only you can't use a 32-bit built of gdb. 
Yeah I share your opinion personally. gdb should be default as part of the base system. 
Mingw-builds merged with mingw-w64 now. I had used official mingw32, TDM, and mingw-builds before. Personally, I prefer and currently use mingw-builds. 
[Image](http://imgs.xkcd.com/comics/random_number.png) **Title:** Random Number **Title-text:** RFC 1149.5 specifies 4 as the standard IEEE-vetted random number. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=221#Explanation) **Stats:** This comic has been referenced 17 time(s), representing 0.36543422184% of referenced xkcds. --- ^[Questions/Problems](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Website](http://xkcdref.info/statistics/)
Rather than manually creating function objects to wrap overloaded functions, I quite like this macro you can use in C++14: #define LIFT(X) \ ([](auto&amp;&amp;... args) -&gt; decltype(auto) { \ /* Can't use (X) as it disables ADL. */ \ return X(std::forward&lt;decltype(args)&gt;(args)...); \ }) And now you can generate a forwarding function object just by writing `LIFT(std::pow)` or `LIFT(foo)` that also respects ADL. You can disable ADL with `LIFT((foo))` (two pairs of parens). Something like this was proposed for standardisation with the syntax `[]std::pow`, but I don't know of its progress.
Misleading title. The transitivity of `const` *is* correct in C++, it’s simply not what the author wants/expects. However, it’s logically consistent and, I’d argue, the right thing in most cases. In particular, I’d usually declare the pointee `const` (i.e. `int const*`), which avoids the problem the author points out. This should arguably be the default stance: make things `const` unless there’s a compelling reason not to.
I don't know much about wxWidgets in particular, but many C++ frameworks (MFC, Qt) were developed before C++ had a usable standard library - therefore all of them introduced their own strings and collections.
Hehe I don't expect help with the 32 bit issue, you do more than enough making this great distribution anyway. I simply use visual studio to make 32 bit builds (which restricts the language I can use which is a shame, but on the other hand it's good to use multiple platforms/compilers anyway). Thank you for maintaining this build anyway. It works wonderfully well :)
Well, what if you want the pointed-to object to be const *if and only if* the holding variable is const. In that case, you can't just mark the member as `int const * x;`. Instead, you would need two methods: struct A { private: int* x; public: A(): x{new int} {} ~A() { delete x; } int * get_x() { return x; } int const * get_x() const { return x; } }; This is pretty much what the author did here. Seems pretty reasonable to me. There are other approaches too.
I have something similar implemented in my current pet [project](https://github.com/beark/ftl), where a call to `curry(funobj)` results in a curried function object. There is also a version of `std::function`, except supporting curried calling. Though it needs a bit of love, as it currently only allows providing either one or all parameters. Finally, there's a bunch of other functional/Haskell-inspired stuff in there that might amuse you too, if you're in to that sort of thing.
That’s not wrong, but my whole point is that this is usually not a good approach since the member should probably be *always* `const` anyway. The fact that setters (or publicly settable members) are a bad idea has been written about enough, I won’t repeat the arguments here, just point to [one of the relevant papers](http://www.idinews.com/quasiClass.pdf). That said, there’s no need to dogmatic about this. Where it makes sense, do use the setters introduced by OP. This is entirely fine – I just don’t think that it supports the argument that C++ gets `const` propagation wrong.
&gt; I don't know, std bind and std function may create a pretty significant overhead: it's seems easy to forget it if you lay some syntactic sugar on it. &gt; It is true that std::bind and std::function have a performance overhead because they copy the arguments and/or the functor. IF you need to create a function object, these costs are inevitable and the shorter, more concise code might be worth it. The overhead argument applies more to people who use std::function instead of passing functors as template arguments. That's a (mostly) unnecessary overhead. My only point is to clear up the syntax when you need to create function objects anyway. 
That does look fun. Thanks.
This is OT, but how are the linking times nowadays? Last time I used MinGW (which was close to 10 years ago, so I'm really outdated) I experienced abysmal linking performance, taking 45 minutes to link something that took like 2-3 on Visual Studio. (Big project, old computers.) I'm hoping that's changed since then?
I said the same thing in the crosspost to /r/programming: http://www.reddit.com/r/programming/comments/1s5cpp/c_secrets_correcting_the_transitivity_of_const_in/cdu9dmi What's worse is it's called "C++ secrets" over there. It's not a secret and the problem description is completely in error. What the author needs to do is differentiate between composition, aggregation, and simple association. All of those use pointers or references and only the first should clearly follow constness; it's there that the tool the author invented again has use.
Never, **ever**, publicly inherit from a value object: class transitive_ptr : public std::unique_ptr&lt;T,Deleter&gt; And as an illustration of the woes it cause, this just undermines the whole purpose of the exercise: struct A { transitive_ptr&lt;int&gt; x; A(): x{new int} {} }; int main() { const A a; *a.x = 3; // ERROR *static_cast&lt;std::unique_ptr&lt;int&gt; const&amp;&gt;(a.x) = 3; // OK }
hence "This may be desired behaviour in some cases, but in others it is not."
The interface is backward compatible with functions accepting `shared_ptr&amp;`, you just lose some safety guarantees. Oh well, it was not meant to be production-ready.
Actually, I am fairly disappointed in gcc here. In the CRTP case, we have this code: uint64_t counter = 0; for (unsigned i = 0; i &lt; 4000; ++i) { for (unsigned j = 0; j &lt; i; ++j) { counter += j; } } And I am very surprised that gcc does not completely omit the loop code. // Step 1 uint64_t counter = 0; for (unsigned i = 0; i &lt; 4000; ++i) { counter += i * (i-1) / 2; } // Step 2 uint64_t counter = 10658668000ull; Unless the limit (`N`) is provided dynamically, I would actually expect the compiler to be able to optimize the CRTP case up until step 2; and if it is dynamic, then I believe it should be able to advance up to step 1 (before vectorizing). Regarding devirtualization, I am surprised that this is so new in gcc, are you sure 4.7 did not improve it ? Clang has had it for as long as I can remember, although it's imperfect: it's done by Clang itself, so does not benefit from further opportunities exposed after inlining/constant propagation.
According to Wikipedia, WxWidgets was initially released in 1992.
&gt; A simple 'mingw-get install mingw32-base g++' gets you a base MinGW C and C++ environment. "Simple", heh. &gt; The best thing about your distro is all the included extras. Reduces a lot of time getting extra bits. Thanks for that! You're welcome! &gt; I know you provide all of the packages for your distro, do you also include all of the build environment setup details? Yes: http://nuwen.net/mingw.html#build
&gt; Why don't you use gdb? Awful command-line interface. (I don't use windbg either.) I try really hard to avoid making mistakes, and I arrange my code so that I can quickly figure out runtime bugs when they happen (e.g. I check all APIs for failure and emit diagnostics with their location). The only time I need a debugger is when I'm working with someone else's code, which is why I use VS at work. (At home I haven't yet figured out why grep -r doesn't work with grep 2.11 and above.) &gt; Is SEH the reason you no longer build 32-bit? No. I just don't want to have to build two flavors of all of my libraries, for a platform that's dead to me. &gt; Has your gcc distribution ever been the cause for any trouble or anecdote at work? Herb has used it - see the first link on http://isocpp.org/get-started . &gt; Have you ever considered doing an AMA? Yes, then I quickly return to my senses.
&gt; Quite frankly, the whole idea of having a function that returns a pointer to a pointed at section of data that you believe is part of your class is all kinds of fucked up. It totally nullifies the whole point of encapsulating the data in a class. Fucked up, except when it's impossible to do otherwise :) If you're representing a binary tree, you need a `Node` class to contain pointers to its children. A `Node` cannot be directly *composed* of two other `Node`s, but it can point to its two child `Node`s. Given a `Node const *`, it's reasonable to want a design where a `get_left_child()` method would return a `const Node *`, and the non-const method would return non-const.
Damn I never read that bit, apologies! Would be really cool if you could include gdb in your build process, I know you don't use it but us mortals do ;) It would be very handy!
&gt; Never, ever, publicly inherit from a value object: I disagree with that. While you have to know, what you are doing and what the implications are, there are valid use-cases. For instance: CRTP depends on that. And it is ok in general if everything you are doing is adding completely new functions or widen the preconditions of existing ones. For example: template&lt;typename T, typename Alloc = std::allocator&gt; safe_vec : public std::vecor&lt;T, Alloc&gt; { using vector::vector; T&amp; operator[](size_type index) {return at(index);} // widen preconditions for [] const T&amp; operator[](size_type index) const {return at(index);} // dito }; The beauty might be debated, but safe_vec doesn't add a trivial way of creating more problems than just using vector (anyone who is tempted to create vectors of any kind on the free store should die in a fire anyway). So it isn't a good idea often, but never is certainly untrue too.
Excuse my ignorance, but what requirement for std::swap? Is it "Does not invoke any move, copy, or swap operations on individual elements" ?
std::function also involves type erasure so the main problem is usually not the copy but the virtual function call that prevents inlining (and it also involves some overhead).
&gt; Yes, then I quickly return to my senses. Not sure exactly what you mean by that. [Andrei Alexandrescu did an AMA](http://www.reddit.com/r/IAmA/comments/1nl9at/i_am_a_member_of_facebooks_hhvm_team_a_c_and_d/) two months ago, and I thought it went well. There will be trolls regardless, but the community keeps them in place, especially if we know about the AMA ahead of time. Alternatively, do it directly in /r/cpp. Of course, if it's lack of time or interest, then don't bother. We get enough useful content from your responses already.
That bot is really interesting. Vist the `Website` link at the bottom of its post and you get all the goodies: &gt; Since October 16th 2013, /u/xkcd_transcriber has picked up 4718 references to xkcd comics, excluding those from xkcd subs. A total of 771 unique comics has been referenced so far, with a mean value of 3.646 references/comic (out of all comics) and a standard deviation of 12.331. So, that is only since the middle of October, which probably aligns exactly with your expectation that there would be many more references.
"When will you improve the project properties dialog? It is resizable in Visual Studio 2013, but it definitely needs more improvement." It's been virtually unchanged since VC6! Scrap it and make a new one. I *hate* working with the project properties dialog. Does anyone know if I can replace it by making my own extension? I feel like I could make a better properties dialog in a week. EDIT: Macro/env variable auto-complete would be amazing. And a much more intuitive and easy way to add libs/dlls to projects. Any other ideas?
I have made a few notepad games which I enjoyed programming and I have thought of C++, I just don't know what I should use as a start for programming. Thanks for the ideas, I don't want to just mess around with video game creation I would love to take it seriously yet in the Scottish city for game making there isn't much of a way to get you into game making at all.
Interesting point. But we don't have to stick with `set`. It might often be the case that you're writing an object A that's going to own an object B (by holding a `unique_ptr` to it, perhaps). For my point to make sense, it is not necessary for the contained object (e.g. node) to 'leak out'. You might feel that any `const` method on A which accesses B should do so via a `const` method in B. Logically, you might feel the entire object should be const, or should not be const. This seems quite a logical design you might use in many circumstances. There are situations where A will need to modify B, and therefore we can't simply make the owing pointer point to a const object. Extra: There are other ways to achieve this, without having to write getters and setters for everything, and without having to *hope* that the const methods in A 'do the right thing!'. A simple wrapper type around the pointer member that converts to a reference to the member, and doing so while respecting const.
This is very interesting but would that imply that is irrelevant to use a generic programming approach for classes having no methods small enough for inlining? From the post, it appears that inlining is the major reason for the boost, and dropping inlining would give basically the same result for both approaches. Am I wrong?
It would be interesting to see a benchmark where only the `tick` function was not allowed to be inlined, and the rest kept as-is.
Is this by the same author of the http://functionalcpp.wordpress.com blog?
Just want to briefly comment that I love how the C++14 version is a million times simpler. I implemented this in C++11 (using the `std::invoke`, and it took way too many lines of code, just so that I could do `invoke(unpack, tuple)` where unpack is a special constexpr variable, and tuple is a type of &lt;Callable, Args...&gt; on which std::get&lt;I&gt; can be called. I should note it works with std::array, but that usage should be rare. I also got it to do runtime unpacking on containers using the arity of a function to figure out how many indices into the container it should call. It was a fun exercise but man, what a pain in the ass. I also think I ran into the same issue you mention with result_of, though I did an 'invoke_of' that relied on the INVOKE pseudo-expression instead. However that is neither here nor there.
I fail to see what that clone function does that a simple copy can't do.
Cognitive load is less for you to implement two overloads than for everyone who ever calls your interface to have to explicitly determine if they want to clone or move their lvalue arguments. You've also missed the third option, which is to use perfect forwarding to capture both lvalue and rvalue parameters, e.g.: template &lt;typename T&gt; void do_something_with_copy(T&amp;&amp; t) { auto localcopy = std::forward&lt;T&gt;(t); // or std::string localcopy = std::forward&lt;T&gt;(t); } which even allows for arguments of different types that are convertible to your target type.
class X; std::vector&lt;X&gt; values; void f(X&amp;&amp; val) { values.push_back(std::move(val)); } void g() { X x; f(x); // ERROR X x2; f(clone(x2)); // OK X x3; f(std::move(x3)); // OK } 
oh
Note that `apply()` above can be implemented in C++11 with the exact same structure, you just need to write `index_sequence` by hand, spam out the expression for `decltype`, and use `decay`.
That's basically what I did, but I used INVOKE semantics (and also implemented `invoke`), and just decided to not call it apply, but instead `invoke` with an additional parameter.
I've looked again at this thread, and I think I agree with you! Sorry about that. Your initial comment wasn't really about transitivity of const, but about the wisdom of all objects to return (publicly) pointers to owned objects.
VS has used MSBuild for c++ since 2010, and you can add custom property sheets in pretty easily to projects. It's more than possible to write a custom editor, the property sheets are just XML.
No, I'm the author of FTL. I'm a bit surprised and quite flattered to see FTL linked to by someone other than myself. And also a bit embarrassed, as the readme is a bit outdated and the API reference significantly so. Anyway, I'm happy to answer questions, listen to suggestions, and fix any issues people may have found (I notice my repo suddenly has a couple of forks extra).
Please read your texts again after you've written them. I am not a native speaker (too?) and make mistakes myself, but your text is extremely difficult to understand. Concerning your question: Perfect forwarding has been mentioned but often you might just want to take the arguments by value: class foo { std::string str; public: foo(std::string str): str{std::move(str)} {} // copy lvalues only once, always move rvalues }; Edit: BTW, if you want a clone-method it should probably use universal references: template&lt;typename T&gt; clone(T&amp;&amp; value) -&gt; typename std::decay&lt;T&gt;::type {return value;} If the argument is a (const) lvalue of type T, reference collapsing makes sure that this turns to: T clone( (const) T&amp; value) {return value;} Edit2: fixed returntype of clone(). It has to be decay&lt;T&gt;::type of course.
Are you sure that's correct? Granted, last time I checked is some time ago, but C++11 threads were a big problem on windows, even some time after GCC and libstdc++ were announced C++11 feature complete. I think OpenMP did work, though. EDIT: I just downloaded the latest weekly snapshot of the Equation Solution gcc x64 build, which should be the most up-to-date from the list I guess. If you just copy&amp;paste the std::thread sample code from [here](http://en.cppreference.com/w/cpp/thread/thread/thread), you will see that it still is *not* supported. EDIT 2: That said, the nuwen.net one comes with boost, and as far as I know boost::thread implements std::thread almost 100% and works on windows.
Sorry for my bad English. Will review more next time. Your version of clone is perfectly good. Thank you for showing universal references and reference collapsing for this function.
To be fair, this is strictly a fairly complex simplification. The "step 1" is only valid, if no overflow happens (because unsigned integers have guaranteed modulo arithmatic), so the compiler would have to know the identity you used and also check if the range is ok, etc. 
Taking args by value seems to be the most efficient for lines of code and maintainability. If you honestly need to tweak the extra performance then selectively break out a const ref and rvalue ref pair. Those should be few. the clone stuff seems like an unnecessary workaround that just adds more layers. Almost seems java-ish. I almost always set up constructors as explicit, been burned way too often by implicit type conversions so the perfect forwarding intuition wise seems wrong but may be a good but messy looking option.
With regard to automatically currying, I suggested just such a thing on the Boost mailing list in 2011. I even posted code. It was considered a bad idea. Thing is, in functional languages, there is no difference between a nullary function and the result of calling that function, but in C++ there is. This was a major a-ha! moment for me. You can read the whole thread [here](http://thread.gmane.org/gmane.comp.lib.boost.devel/222736/focus=222736).
If you are going to use universal references shouldn't you make it like this? template&lt;typename T&gt; auto clone(T&amp;&amp; value) -&gt; typename std::remove_reference&lt;T&gt;::type {return value;} Your version does not work (in VS2012 at least) if you call clone as X x2; f(clone(x2)); 
Ah, now we're talking. I am actually wondering what prevents gcc from doing this optimization, I've seen optimizers being pretty aggressive with constant folding in the past. I have actually two suspicions: - the structure is too complicated and does not match any of the patterns known to the compiler (oops) - the compiler hits a road-block (most optimizations are conditioned by stringent preconditions to make sure that nothing breaks) Indeed, I considered modulo arithmetic as a possible roadblock; however I would point out that seeing that addition is commutative (even in modulo arithmetic) and that `4000` is too small to cause an overflow of `unsigned` (if 32 bits), I had rejected this hypothesis.
yes, that is clearly a bug. Your solution is however incomplete too, since it still has the problems with const. The easiest solution is probably to use std::decay.
Ooo, did not know that was a standard function! TIL. Edit: Not sure if its safe to use decay here. It will convert a T* to a T. Maybe this? template&lt;typename T&gt; auto clone(const T&amp;&amp; value) -&gt; typename std::remove_reference&lt;T&gt;::type {return value;} 
Correct, I just tried pasting that snippet into a function and compiling with both -O3 and -Ofast (and -s). It generated code rather than just returning a constant. Clang also generated code with -O3.
Oh, believe me, I tried that (and I was super stoked when I found out about it) They don't seem to quite 'stick' in VS2013. Sometimes they work, more often they don't.
Haven't upgraded to VS2013 yet, but I've never really had any issues with them besides being horribly inconsistent in how you set some things. What's not 'stick'-y about them?
Actually since your comment I went back and was able to use them properly. I had to have them in a specific order but they did work. I think where I messed up the first time was when adding them, not all of the fields they affected were automatically checked with 'Inherit project or defaults' in my project settings.
I would definitely suggest looking into the above blog I've posted, it has a great deal of interesting posts, you should definitely reach out to the author as he was looking into making his own templated C++ functional programming library.
Huzzah
Hey STL! Huge fan of your talks. Do you have any comments on the removal of std::optional and std::dynarray from the C++14 draft? Any ideas on the possible inclusion of coroutine/user-defined context switching in C++?
This can also be nasty if you're converting #defines like this: #define DEG_PER_RAD 180 / M_PI double torad(double n) { return n * DEG_PER_RAD; } to constants like this static const double DEG_PER_RAD = 180 / M_PI; double torad(double n) { return n * DEG_PER_RAD; }
If you're using unparenthesised macros, it's your own fault. 
&gt; [...] in functional languages, there is no difference between a nullary function and the result of calling that function [...] That depends on the language. Not all functional programming languages are pure, or have non-strict evaluation rules. This is not mentioned at all in the discussion, leaving some unstated assumptions. While I haven't read the *whole* thread, I think I can shed some light: there isn't anything more to currying than making the similarity between `X * Y -&gt; Z` and `X -&gt; Y -&gt; Z` apparent. This is absolutely orthogonal to evaluation rules. If there is a goal to make e.g. // will call binary_f(x, y) for all y in input_range transform(input_range, output_range, curry(binary_f)(x)); 'consistent' with // as if passing [] { return not_a_function; } give_me_a_callback(not_curry(not_a_function)); then you want *more* than currying. I suppose an argument can be made that in the limit of an empty tuple of arguments, currying should make `() -&gt; Z` and `Z` similar, it's not something that's usually done as a matter of fact. (With good reasons imo.) OTOH, I know that languages with eager evaluation rules sometimes introduce a `delay`/`force` pair of functions (other names for it: `suspend`, `defer`) which purpose is exactly to transform a value of type `Z` into a value of type `() -&gt; Z` (where `force` means 'recovering' the value by making the trivial call). That is something a non-strict language doesn't explicitly need. By making the two notions separate I think it's easier to argue the merits and drawbacks of either. For instance, currying in C++ *is* hard due to e.g. the absence of anything like arrow types, and the pervasiveness of ad-hoc polymorphism via function overloads. It also becomes obvious that a Phoenix-like approach where `auto bundle = lazy(f)(x, y)(z);` does not call anything until a final `bundle()`, resulting in `f(x, y, z)` is *not* currying, strictly speaking. It's a `delay` mechanism (since `lazy(x)()` evaluates to `x`) together with an arbitrary capture mechanism, both taking place under a similar call syntax. It's true the latter alone is a very straightforward way to implement currying, but the resulting combination is quite apart from it.
Why "nasty"? You'll get better performance after you convert!
How come the compiler does not reorder the operations to achieve folding? Due to the fact that the actual result will be slightly different due to floating points? That is X * (180.0 / M_PI) != (X * 180.0) / M_PI Edit: Running this code with msvc11 in 32/64bit and debug/releases #define PI 3.1415 void main() { double X; bool diff = false; uint64_t same_cnt = 0; uint64_t diff_cnt = 0; for (X = 0; X &lt; 100000; X += 0.00001) { diff = ((X * (180.0 / PI)) != ((X * 180.0) / PI)); if (diff) { ++diff_cnt; } else ++same_cnt; } cout &lt;&lt; "diff: " &lt;&lt; diff_cnt &lt;&lt; endl &lt;&lt; "same: "&lt;&lt; same_cnt &lt;&lt; endl; cin.get(); } Outputs diff: 3460939769 same: 6539058024 So this could a reason why the compiler refuses to reorder? 
Seems like a serious case of premature optimization if you ask me. I'd love to see an actual example of an inner loop where it was worthwhile to rearrange floating-point operations, along with actual metrics showing how much it helped.
I just tested it out, and there are a lot of numbers that don't satisfy that (using my machine's default floating point rounding): #include &lt;iostream&gt; #include &lt;cstdio&gt; using namespace std; const double pi = 3.1415926535897932384626433832795028841971693993751058209; // probably enough precision double torad1(double n) { return n * (180.0 / pi); } double torad2(double n) { return (n * 180.0) / pi; } int main() { for (int i = 0; i &lt; 1000; ++i) { double val1 = torad1(i); double val2 = torad2(i); if (val1 != val2) { std::printf("%d - %a : %a\n", i, val1, val2); } } } Result: 11 - 0x9.d903a9124aadp+6 : 0x9.d903a9124aad8p+6 15 - 0xd.6dbf2c5ec2ecp+6 : 0xd.6dbf2c5ec2ec8p+6 22 - 0x9.d903a9124aadp+7 : 0x9.d903a9124aad8p+7 30 - 0xd.6dbf2c5ec2ecp+7 : 0xd.6dbf2c5ec2ec8p+7 44 - 0x9.d903a9124aadp+8 : 0x9.d903a9124aad8p+8 60 - 0xd.6dbf2c5ec2ecp+8 : 0xd.6dbf2c5ec2ec8p+8 88 - 0x9.d903a9124aadp+9 : 0x9.d903a9124aad8p+9 120 - 0xd.6dbf2c5ec2ecp+9 : 0xd.6dbf2c5ec2ec8p+9 176 - 0x9.d903a9124aadp+10 : 0x9.d903a9124aad8p+10 240 - 0xd.6dbf2c5ec2ecp+10 : 0xd.6dbf2c5ec2ec8p+10 241 - 0xd.7c121a6bf4cdp+10 : 0xd.7c121a6bf4cd8p+10 273 - 0xf.466fdc1230ec8p+10 : 0xf.466fdc1230edp+10 289 - 0x8.15cf5e72a77ep+11 : 0x8.15cf5e72a77e8p+11 352 - 0x9.d903a9124aadp+11 : 0x9.d903a9124aad8p+11 353 - 0x9.e02d2018e39d8p+11 : 0x9.e02d2018e39ep+11 417 - 0xb.aa8ae1bf1fbdp+11 : 0xb.aa8ae1bf1fbd8p+11 480 - 0xd.6dbf2c5ec2ecp+11 : 0xd.6dbf2c5ec2ec8p+11 481 - 0xd.74e8a3655bdc8p+11 : 0xd.74e8a3655bddp+11 482 - 0xd.7c121a6bf4cdp+11 : 0xd.7c121a6bf4cd8p+11 545 - 0xf.3f46650b97fcp+11 : 0xf.3f46650b97fc8p+11 546 - 0xf.466fdc1230ec8p+11 : 0xf.466fdc1230edp+11 578 - 0x8.15cf5e72a77ep+12 : 0x8.15cf5e72a77e8p+12 641 - 0x8.f76983c279158p+12 : 0x8.f76983c27916p+12 704 - 0x9.d903a9124aadp+12 : 0x9.d903a9124aad8p+12 706 - 0x9.e02d2018e39d8p+12 : 0x9.e02d2018e39ep+12 769 - 0xa.c1c74568b535p+12 : 0xa.c1c74568b5358p+12 771 - 0xa.c8f0bc6f4e258p+12 : 0xa.c8f0bc6f4e26p+12 834 - 0xb.aa8ae1bf1fbdp+12 : 0xb.aa8ae1bf1fbd8p+12 897 - 0xc.8c25070ef1548p+12 : 0xc.8c25070ef155p+12 899 - 0xc.934e7e158a45p+12 : 0xc.934e7e158a458p+12 960 - 0xd.6dbf2c5ec2ecp+12 : 0xd.6dbf2c5ec2ec8p+12 962 - 0xd.74e8a3655bdc8p+12 : 0xd.74e8a3655bddp+12 964 - 0xd.7c121a6bf4cdp+12 : 0xd.7c121a6bf4cd8p+12 Seems they differ on the last bit in most cases.
 #include&lt;iostream.h&gt; Drop the .h. #include&lt;conio.h&gt; #include&lt;process.h&gt; clrscr(); Non-standard. cout&lt;&lt;"\nEnter your target percentage: "; cin&gt;&gt;tar; Missing namespace. getch(); Don't. Configure your cmd to stay alive after the application terminates. exit(1); Don't exit() from main(), but just return. int tar,a,held,ans,ta,th; Declare variables locally, not before doing anything. for(int i=0;;i++) { ans=calculate(tar,ta,th); if(ans==1) break; else { ta++; th++; } } Use formatting. And more spaces! if((int)x&gt;=target) return 1; else return 0; Use booleans. Just return x &gt;= target. (int)x Use static_cast&lt;int&gt; (x) or ctor-style int (x). float x; x=(float)att/(float)total; Declare and initialize at once. Use const. a Use verbose variable names. #include &lt;iostream&gt; float attendence (int classes_attended, int classes_held) { return static_cast&lt;float&gt; (classes_attended) / static_cast&lt;float&gt; (classes_held) * 100.0f; } bool is_target_reached (int target_percentage, int classes_attended, int classes_held) { return static_cast&lt;int&gt; (attendence (classes_attended, classes_held)) &gt;= target_percentage; } void main() { int target_percentage, classes_attended, classes_held; std::cout &lt;&lt; "Enter your target percentage: "; std::cin &gt;&gt; target_percentage; std::cout &lt;&lt; "Enter the total number of classes held: "; std::cin &gt;&gt; classes_held; std::cout &lt;&lt; "Enter the number of classes attended: "; std::cin &gt;&gt; classes_attended; std::cout &lt;&lt; "\n"; if (target_percentage &gt; 100) { std::cout &lt;&lt; "Your target can not exceed 100%! or be less than 0%!\n"; return 1; } if (target_percentage == 100) { std::cout &lt;&lt; "Since your target is 100, you need to attend all the classes held!\n"; return 1; } if (classes_held == 0) { std::cout &lt;&lt; "There are no classes held! What do you want to calculate?\n"; return 1; } if (classes_attended &gt; classes_held) { std::cout &lt;&lt; "You can not have attended more classes than are held!\n"; return 1; } int additional_classes (0); for ( int classes_attended_it (classes_attended), classes_held_it (classes_held) ; !is_target_reached (target_percentage, classes_attended_it, classes_held_it) ; ++additional_classes, ++classes_attended_it, ++classes_held_it ) { } std::cout &lt;&lt; "Your attendence is: " &lt;&lt; attendence (classes_attended, classes_held) &lt;&lt; "%\n"; if (additional_classes == 0) { std::cout &lt;&lt; "Your attendence is already over your target of " &lt;&lt; target_percentage &lt;&lt; "%\n"; } else { std::cout &lt;&lt; "You need to attend atleast " &lt;&lt; additional_classes &lt;&lt; " more classes to reach your target of " &lt;&lt; target_percentage; } }
As the author says, the two aren't equivalent. It's nasty because you can't make the second version equivalent to the first without touching the code everywhere DEG_PER_RAD is used. By the time you come to debug some subtle floating point issue, this change will probably be ancient history.
Unless you didn't write the original code.
Thanks for the code review, it saves me from doing it ;)
It's only really premature optimization if you decide to take an already existing code base and refactor it to apply this. If however you are aware of the issue and are writing a new bit of code, then since each approach is equally legible and quick to write, consciously choosing the wrong one is a case of premature pessimism. 
I would point out a minor, but substantial, way of improving this program: int additional_classes (0); for ( int classes_attended_it (classes_attended), classes_held_it (classes_held) ; !is_target_reached (target_percentage, classes_attended_it, classes_held_it) ; ++additional_classes, ++classes_attended_it, ++classes_held_it ) { } This is slightly more complicated than necessary, instead you could compute the threshold (number of courses you should have attended) and then deduce by how many classes you are ahead/behind this threshold in a single subtraction. #include &lt;cmath&gt; int const threshold = static_cast&lt;int&gt;(std::ceil(classes_held * target_percentage / 100.0)); if (classes_attended &lt; threshold) { std::cout &lt;&lt; "You attended " &lt;&lt; (threshold - classes_attended) &lt;&lt; " less classes than necessary\n"; } else if (class_attended == threshold) { std::cout &lt;&lt; "You are perfectly on target\n"; } else { // classes_attended &gt; treshold std::cout &lt;&lt; "You attended " &lt;&lt; (classes_attended - threshold) &lt;&lt; " more classes than necessary\n"; }
If you force the order via parantheses I agree, but its a freestanding statement like X * 180.0 / PI I see no real reason why the compiler can not collapse the two constants. Though there is also the fact that if the compiler uses the FPU instead of SSE extensions it can do the calculation in 80bit precision instead of 64bit. It can't load a 80bit variable into the register (I think), so it has to actually calculate the result of 180.0 / PI to get the 80bit value into the FPU.
The [WTL (Windows Template Library)](https://en.wikipedia.org/wiki/Windows_Template_Library) is a good example of a real-world library that uses this pattern. It was created in response to the horrible bloat of the old [MFC](https://en.wikipedia.org/wiki/Microsoft_Foundation_Class_Library) library.
That's just begging the question. _Why_ is it nasty if they're not equivalent? Why would you think it would cause issues?
There is a real reason -- the standard specifies that \* and / are left associative, and must be evaluated in the order specified. It is not up to the compiler to reorder things, because, again, floating point arithmetic is not associative. 
Seems like it should be pretty easy to find an actual example of substantial speed gains then, huh?
The pass by value method is actually often faster, and assuming you make your classes have fast move operators, no slower. Make your function accept by value. Then let the caller decide if they should move or not. Should they pass in a temporary no move is even needed, the value will be built directly into the call stack when the optimizer has at the code. http://cpp-next.com/archive/2009/08/want-speed-pass-by-value/
I guessed that it is using the loop for learning purposes, so I left it there. Obviously, we are only solving an equation here.
&gt; I am not a native speaker (too?) Either.
So, they teach C++ in India? What kind of C++ do they teach you in the schools? Seeing iostream.h in 2013 really scares me...
If you really have things in your code like `#define DEG_PER_RAD 180 / M_PI` then debugging subtle floating point issues is probably the least of your worries. And it isn't really clear what problems you could introduce this way. There might be changes in the last decimal place in your results - but nowhere near the magnitude of the error that they'd get because of their definition `#define PI 3.1415` at the start of their code.
Upvoted for a correct use of "begging the question". :-D
I'm currently fixing both issues at my workplace 😞.
&gt; This will in turn cause the definition of interface to be instantiated, but not its declaration —which is the one making use of Derived—. I think you've got a typo there: the words "definition" and "declaration" need to be swapped. 
I have a proposal for Domain Specific Language parameters: https://github.com/hun-nemethpeter/cpp-reflector-mini/blob/master/Proposal.md ex.: // full grammar is here: http://www.json.org/ struct JsonParamGrammarItem : meta::grammar { meta::id_name key; meta::op_name colon = ':'; meta::expr value; }; struct JsonParamGrammarTail : meta::grammar { meta::id_name comma = ','; JsonParamGrammarItem item; }; struct JsonParamGrammar : meta::grammar { meta::symbol open_brace = '{'; JsonParamGrammarItem paramFirst; meta::vector&lt;JsonParamGrammarTail&gt; paramMore; // this can be used for varargs ... meta::symbol close_brace = '}'; }; class JsonParamDriver { JsonParamDriver(JsonParamGrammar grammar); }; /* grammar rules or - meta::or and - member in struct optional - meta::optional any - meta::vector so JsonParamGrammarItem is meta::id_name &amp; ':' &amp; meta::expr */ // usage class SomeWidget { template&lt;astnode Node&gt; SomeWidget(Node) $use(JsonParamDriver driver) { ... // We should process with an other driver that associate member names with param names. } SomeWindow window; SomeLabel label; }; SomeWidget widget({ window: "Hello world", label: "Foo" });
I like the 2nd part a bit more, but its better to understand with Part 1. Especially its a nice tutorial into boost::type_erasure.
Indeed, good catch! Fixed already.
floats usually can't represents the full range of an int. e.g.: #include &lt;stdio.h&gt; #include &lt;limits.h&gt; int main(int argc, char *argv[]) { int i; for (i = 0; i &lt; INT_MAX; i++) { float f = i; int o = f; if (o != i) printf("%d != %d\n", i, o); } return 0; }
Sadly, this also disables hints. $ g++ -c test.cpp test.cpp:2:5: error: redefinition of ‘int a’ int a; ^ In file included from test.cpp:1:0: test.h:1:5: error: ‘int a’ previously declared here int a; ^ vs. $ g++ -Wfatal-errors -c test.cpp test.cpp:2:5: error: redefinition of ‘int a’ int a; ^ compilation terminated due to -Wfatal-errors. 
&gt; When using arrays in c++ Long story short: Don't. Use containers: http://en.cppreference.com/w/cpp/container Replace your array with `std::vector&lt;T&gt;` and see whether the issue persists.
&gt; ‥ you can use valgrind to find the place where your array is overwritten. Only if the problem is due to e.g. out-of-bounds access in another variable. Valgrind won't bark if the code follows the language rules.
Thanks for the help, I'll have a read and give that a go
This usually happens from writing past the size of the array. So if you have a array `n` with a length of 5 and you write to `n[-1]` or `n[5]` the memory location past the array will be overwritten. You can catch this by using `std::array`(for static sized arrays) and `std::vector`(for dynamic size arrays) and using the `at` function(this does bounds checking for you) instead of [] to access items.
std::array&lt;Type, Size&gt; works fine in many cases as well.
Can you post a code snippet? I agree with what has already been said. Use std::vector&lt;&gt; or std::array&lt;&gt;. That being said, if you post a code snippet, we can give you better help. Even if you decide not to use an array, it's worthwhile for you to learn what mistake you're currently making.
If you're just taking a block of memory and doing nothing with it, i.e.: char * my_string = new char[100]; The array will have in it whatever was in memory before that until you otherwise write over it. So an allocation in C/C++ does not write anything, it just gives you memory with whatever was in it last. This is good for performance, as let's say you allocate a block of memory you want to load a file into. Zeroing it out before that is just a waste of time. You can use something like memset to zero the memory out, which would give you more of what you are expecting. Or, as has been noted above, C++ containers will auto-initialize themselves, and won't have this problem in the first place.
Sure, but there is no point on bogging a beginner down with that for now. I would also say unless you need to semantically enforce the size of the array for some reason it's better to just use a `std::vector` in most cases by default. Don't forget that the vector has the massive advantage of supporting a very efficient move ctor/`op=`, where as `std::array` must do an element wise copy or move. Then once you've written your program and your profiler suggests your wasting to much time allocating for the vector then switch to the `std::array` as an optimisation in hindsight. 
If you really want an array, use std::array.
Read my other comment. I think the flexibility of `std::vector` more than pays for itself. I'd use `std::array` as an optimisation based on profiling the code, or when it's clearly a no brainer. Eitherway for a beginner it's more important that they have the the vectors interface burnt into the head ASAP,
Thanks for letting me know it was ambiguous. 
author posted it on /r/gamedev as well.
Even if it doesn't turn up anything, it only takes a few minutes and doesn't require recompiling. If you're developing on a platform where valgrind is available and aren't using it regularly, you're IMHO missing out. EDIT: Whoops, meant to post this in reply to grunzl
On polymorphism: There are a few non-standard hacks to making virtual calls in a tight loop more efficient. Just like the 'AI', 'Render', and 'Physics' components were put in to separate arrays, you could separate different Derived objects in to separate arrays of Base* at *insertion* and then use a [Bound function pointer](http://gcc.gnu.org/onlinedocs/gcc/Bound-member-functions.html) during access. Here's an example, not intended to be good design, just illustrative: #include &lt;vector&gt; #include &lt;memory&gt; #include &lt;iostream&gt; #include &lt;type_traits&gt; struct Child {}; struct Giant { virtual void on_smell (Child&amp;) = 0; }; struct Bloodbottler: Giant { virtual void on_smell (Child&amp;) { std::cout &lt;&lt; "Bloodbottler prepares his juicer." &lt;&lt; std::endl; }; }; struct Meatdripper: Giant { virtual void on_smell (Child&amp;) { std::cout &lt;&lt; "Meatdripper prepares his roasting spit." &lt;&lt; std::endl; }; }; struct World { std::vector&lt;std::vector&lt;std::shared_ptr&lt;Giant&gt;&gt;&gt; giants_; template &lt;typename GiantPtr&gt; void add (GiantPtr&amp;&amp; giant_ptr) { using giant_type = decltype(*giant_ptr); for (auto&amp; species: giants_) { if (typeid(*species.front()) == typeid(giant_type)) { std::cout &lt;&lt; "Existing species!" &lt;&lt; std::endl; species.emplace_back (std::forward&lt;GiantPtr&gt;(giant_ptr)); return; } } std::cout &lt;&lt; "New species added!" &lt;&lt; std::endl; giants_.emplace_back(); giants_.back().emplace_back (std::forward&lt;GiantPtr&gt;(giant_ptr)); } template &lt;typename T&gt; void endanger (T&amp;&amp; child) { auto const giant_smell_action = &amp;Giant::on_smell; using smell_function = void (*)(Giant&amp;, Child&amp;); for (auto&amp; species: giants_) { auto const species_smell_action = (smell_function)((*species.front()).*giant_smell_action); for (auto&amp; giant_ptr: species) { species_smell_action (*giant_ptr, child); } } } }; int main() { using std::make_shared; World w; w.add (make_shared&lt;Meatdripper&gt;()); w.add (make_shared&lt;Bloodbottler&gt;()); w.add (make_shared&lt;Meatdripper&gt;()); w.add (make_shared&lt;Bloodbottler&gt;()); w.endanger(Child()); } Needs to be compiled with -Wno-pmf-conversions under GCC.
&gt; unless you need to semantically enforce the size of the array for some reason Exactly. Or if you need stack storage, although I'm not sure that the standard actually enforces that. I'd argue that `std::array` is an optimization; if performance isn't a problem `std::vector` works just as well.
And here's the disassembly of the critical endanger loop: 40110d: sub $0x8,%rsp 401111: mov 0x8(%rdi),%r15 // Load ptr to the end of the giants vector 401115: mov (%rdi),%r14 // Load ptr to the beginning of the giants vector 401118: cmp %r15,%r14 // Outer (giants) loop starts here 40111b: je 40115b &lt;void World::endanger&lt;Child&gt;(Child&amp;&amp;) [clone .local.38.3422]+0x5b&gt; 40111d: nopl (%rax) 401120: mov (%r14),%rax // Access the next species vector (vector&lt;shared_ptr&lt;Giant&gt;&gt;) 401123: mov 0x8(%r14),%rbp 401127: mov (%rax),%rdi // Load *front() (Giant* inside shared_ptr&lt;Giant&gt;) 40112a: cmp %rbp,%rax 40112d: lea 0x10(%rax),%rbx // Load ptr to the end of the species vector 401131: mov (%rdi),%rdx // Grab the Meatdripper vtable ptr (for example) via the Giant* 401134: mov (%rdx),%r12 // Grab &amp;Meatdripper::on_smell from the vtable // Inner (species) loop starts here 401137: jne 401147 &lt;void World::endanger&lt;Child&gt;(Child&amp;&amp;) [clone .local.38.3422]+0x47&gt; 401139: jmp 401152 &lt;void World::endanger&lt;Child&gt;(Child&amp;&amp;) [clone .local.38.3422]+0x52&gt; 40113b: nopl 0x0(%rax,%rax,1) 401140: mov (%rbx),%rdi 401143: add $0x10,%rbx 401147: mov %r13,%rsi 40114a: callq *%r12 // Cheapish call via code pointer in the inner loop 40114d: cmp %rbx,%rbp 401150: jne 401140 &lt;void World::endanger&lt;Child&gt;(Child&amp;&amp;) [clone .local.38.3422]+0x40&gt; 401152: add $0x18,%r14 401156: cmp %r14,%r15 401159: jne 401120 &lt;void World::endanger&lt;Child&gt;(Child&amp;&amp;) [clone .local.38.3422]+0x20&gt; ... it's hard to tell if the above comments are 100%, the optimisation level is high, but hopefully it shows the advantage. The CPU should (hopefully) now be able to see the call to *%12 in the inner loop and speculatively execute the smell event code.
[Direct link to the post](http://www.reddit.com/r/gamedev/comments/1sgt2w/i_wrote_a_chapter_on_optimizing_games_for_data/), since it won't necessarily be at the top of that subreddit for especially long.
Exactly my point. People should default to `std::vector` and use `std::array` when your profile indicates `vectors` inner gubbins is a costly. 
If you need stack storage you are better of using a std::vector with a stack allocator. You can even group the arena of the stack allocator with the vector so that you can return them from functions. The main advantage is that you have to change no code at all: e.g. if you have code that uses push_back replacing vector with a std::array might be non-trivial whereas using a stack allocated vector requires no code changes and performs the same.
&gt; Configure your cmd to stay alive after the application terminates. For those who don't know: &gt;/k : Carries out the command specified by string and continues. [cmd.exe documentation](http://www.microsoft.com/resources/documentation/windows/xp/all/proddocs/en-us/cmd.mspx?mfr=true)
Not sure if the author's going to see this, but given the multiple mentions of run-time polymorphism through virtual methods, I'd have liked to see something about compile-time polymorphism through CRTP.
Why do people tag ugly C-style casts code as "C++" ? Casts are such a strong indicator of potential bugs.
now we're splitting hairs. I do agree that using std::array instead of std::vector should be done as an optimization, a "stage one" type optimization. Things like 2d or 3d vectors are very well represented by std::array. Funny enough the "stack allocated vector" could easily have its storage represented by a std::array.
Wow, suggesting std::list? I just checked our 850k+ code base of mostly scientific/engineering stuffs and found just a single std::list used in the entire code base apart from unit tests. And now that I look at that, I will replace it with a std::deque. I know std::list can be useful for *some* operations but the poor cache behavior and high memory overhead due to bookkeeping makes them sort of a last resort type data structure.
This looks a little scary to me, smacks of implicit type behavior. It would be nice to see a '0' in there somewhere.
Put the script in ~/bin and add #!/usr/bin/env cppsh to the top of your cpp file. Then make the cpp file executable and run it. 
If I may leave a suggestion: don't use `&gt;&gt;=` for bind. It has the wrong associativity, it has the wrong precedence.
Not likely to help you since you actually do not know the "real" base class. You are really using the virtual call here.
Its the new initialization syntax, you get used to it pretty fast.