N3690 is not the ISO standard. `optional` is not in any ISO C++ standard. It appeared in some drafts and was removed again. Consult N3936 to see what is actually in C++14. 
It makes sense though. While very high level languages have their place, it'd be quite incredible for productivity to be able to translate low level performance over to higher level languages for "free" so to speak. If Python was as fast and lightweight as C++ for more tasks, I'd probably use it a lot more.
Ok I took time off from my delivery tomorrow. Took one hour to table up those. HOPE YOU APPRECIATE THAT :) The test loops through sizes 1 up to 512 in powers of two. For each size, it forks a separate process and allocates a vector of 1M pointers. Then it starts by calling malloc() on all of them, then realloc() for a size 2x bigger and finally free(). I measure all these calls with a RDTSC, of course taking care of all the pitfalls following [Intel instructions](http://www.intel.com/content/dam/www/public/us/en/documents/white-papers/ia-32-ia-64-benchmark-code-execution-paper.pdf). Also I take steps to avoid out-of-order execution by both compiler and processor, discounting "dead time", ie time to actually execute the timing instructions (RDTSC, RDTSCP, CPUID). All results in clock cycles. For the first batch, I used a pretty old AMD Phenom 2 running Ubuntu 14.04.2 LTS kernel 3.13.0, glibc 2.19, gcc 4.8.4. First set, I allocate all vectors in a serial manner, ie with a loop ( j=0; j&lt;N; ++j ). Results: Pattern: SERIAL | Alloc | Realloc | Free | Size | Avg | Med | Avg | Med | Avg | Med | ------------------------------------------- 1 | 40 | 1 | 5 | 1 | 2 | 0 | 2 | 131 | 90 | 58 | 51 | 42 | 37 | 4 | 131 | 90 | 58 | 51 | 42 | 37 | 8 | 131 | 91 | 58 | 51 | 41 | 37 | 16 | 132 | 92 | 203 | 150 | 44 | 37 | 32 | 162 | 102 | 236 | 163 | 49 | 39 | 64 | 214 | 114 | 312 | 192 | 215 | 146 | 128 | 299 | 116 | 594 | 415 | 325 | 277 | 256 | 462 | 122 | 897 | 558 | 407 | 280 | 512 | 777 | 117 | 1450| 805 | 499 | 294 | On the second set, I allocated the vectors in random order to kill all possible cache read-ahead effects. Results: Pattern: SHUFFLE | Alloc | Realloc | Free | Size | Avg | Med | Avg | Med | Avg | Med | ------------------------------------------- 1 | 132 | 91 | 144 | 208 | 47 | 42 | 2 | 133 | 92 | 142 | 208 | 43 | 38 | 4 | 134 | 92 | 148 | 209 | 43 | 39 | 8 | 133 | 92 | 145 | 209 | 46 | 41 | 16 | 133 | 92 | 303 | 250 | 45 | 38 | 32 | 165 | 103 | 348 | 274 | 53 | 42 | 64 | 216 | 115 | 438 | 320 | 213 | 142 | 128 | 298 | 117 | 711 | 538 | 321 | 270 | 256 | 459 | 129 | 1027| 693 | 409 | 281 | 512 | 770 | 117 | 1586| 943 | 495 | 291 | What is interesting is that usually the average is higher than the median, which indicates normal spikes of high duration on the samples. However on this batch for realloc() with SZ&lt;16 the median is larger. Digging into the stats, I see a double mode pattern. For example for realloc/SZ=1: 32-64 cycles: 42.2% 64-128 cycles: 2.3% 128-256 cycles: 50.8% 256-512 cycles: 4.2% Ie the majority of the samples take 208 cycles but a distinct group - ~40% of them - take much less, I'd guess ~60 cycles. For the second batch, I used a newer Haswell i7-5820k (hyperthreading enabled) on Ubuntu 14.04.2 LTS kernel 3.16.0, glibc 2.19, gcc 4.8.4. Pattern: SERIAL | Alloc | Realloc | Free | Size | Avg | Med | Avg | Med | Avg | Med | ------------------------------------------- 1 | 94 | 54 | 1 | 1 | 1 | 1 | 2 | 84 | 58 | 44 | 43 | 30 | 30 | 4 | 85 | 58 | 41 | 40 | 20 | 20 | 8 | 76 | 52 | 40 | 39 | 28 | 28 | 16 | 76 | 52 | 118 | 91 | 28 | 28 | 32 | 88 | 52 | 134 | 93 | 31 | 28 | 64 | 111 | 52 | 174 | 95 | 79 | 47 | 128 | 155 | 51 | 243 | 145 | 316 | 279 | 256 | 248 | 51 | 349 | 162 | 348 | 275 | 512 | 430 | 51 | 655 | 249 | 408 | 280 | Pattern: SHUFFLE | Alloc | Realloc | Free | Size | Avg | Med | Avg | Med | Avg | Med | ------------------------------------------- 1 | 87 | 57 | 101 | 95 | 14 | 13 | 2 | 77 | 52 | 120 | 92 | 29 | 28 | 4 | 77 | 52 | 163 | 95 | 29 | 28 | 8 | 77 | 52 | 115 | 92 | 29 | 28 | 16 | 77 | 52 | 221 | 182 | 31 | 28 | 32 | 89 | 52 | 332 | 330 | 45 | 28 | 64 | 112 | 52 | 403 | 364 | 88 | 47 | 128 | 155 | 50 | 466 | 359 | 320 | 274 | 256 | 248 | 51 | 613 | 415 | 348 | 275 | 512 | 428 | 51 | 963 | 635 | 407 | 280 | As one can see, times in general improved quite substantially as expected. Struck me that on the newer Haswell the cache effects were much less noticeable. EDIT: I quickly ran the same tests with a memory pool - I think that was proposed on one of those C++ books, I think Exceptional C++ or Modern C++. For shuffle/512 I get alloc: 50 avg, 2 med realloc: 59 avg, 4 med and free: 9 avg, 1 med. (In this approach realloc is a free followed by an alloc). So glibc's alloc/realloc/free are really orders of magnitude more expensive than what you can do yourself implementing your own allocators. ANOTHER EDIT: Dang, I just realized the article's central point was for LARGE realloc's so I just ran another batch with the newer Haswell and in serial mode, now for blocks 1k up to 256M. Results: Pattern: SERIAL | Alloc | Realloc | Free | Size | Avg | Med | Avg | Med | Avg | Med | ------------------------------------------- 1024 | 800 | 57 | 1382| 672 | 536 | 292 | 2048 | 1520| 2922| 2526| 3008| 802 | 314 | 4096 | 3028| 2939| 5076| 6721| 1320| 339 | 8192 | 3094| 2972|10419|10432| 2327| 447 | 16384 | 3184| 3010|20833|20833| 3703| 435 | 32768 | 3263| 3062|40868|40868| 6229| 514 | 65536 | 3437| 3155|81491|81491|11704|11807| 131072| 4021| 3750| 4547| 7281| 3257| 3063| 262144| 4031| 3808| 4548| 7383| 3290| 3078| 524288| 4117| 3935| 5182| 8492| 3571| 3314| 1048576| 4261| 4243| 5171| 8878| 3987| 3727| 2097152| 5815| 4638| 6727|11743| 5887| 5387| 4194304| 5669| 4574| 6747|11885| 6031| 5565| 8388608| 4415| 4415| 5949|10851| 5306| 5306| 16777216| 4158| 4118| 5930|10859| 5481| 5481| 33554432| 4500| 4021| 6006|11031| 5655| 5655| 67108864| 4256| 4075| 6453|11952| 6023| 6023| 134217728| 4457| 4070| 7354|13723| 7428| 7428| 268435456| 5152| 4111| 9233|17378| 9175| 9175| I think the 128kb threshold is pretty evident in these tests. UPDATE: checked with the glibc folks, ends up you can tweak this parameter with something like #include &lt;malloc.h&gt; mallopt (M_MMAP_THRESHOLD, 8*1024); This brings the peak down a lot. Here are the new results: [imgur](http://imgur.com/AgOqn0s) Questions/comments?
Benchmark [posted](http://www.reddit.com/r/cpp/comments/3aqjr7/a_story_of_realloc_and_laziness/csfhqkp)
I use various combinations of both. Python with OpenCL. Or Python to do one thing in project such as to import/purify terrible source data but then the C++ to bash it hard during some sort of numeric analysis. Python is great for some interfaces while an interface that really needs to dance might need to be in C++. Oddly enough what I rarely do is to have the two languages talk to each other directly. I love having the two languages ready in my toolkit. Each has its strengths and weaknesses but with this pairing they compliment each other very well. 
This is incorrect. Consider the following struct { int i; short s; } This struct will require 4 byte alignment, but it has two bytes of slack space that can be used when when placed inside another struct. If we assume that most things stored in an optional have stricter than one byte alignment, as above, and are likely not sized as an integer multiple of that alignment, then it will generally be better to be ordered as T followed by bool, if we only consider space requirements. This is a good general rule of thumb; when ordering structs, sorting by largest to smallest will give a good baseline packing; maybe not 100%, but very good. Of course, there are other considerations such as having the bool at the leading edge might put it at the front of the cache line, which is desirable if the validity check is frequent, etc. Edit: My example is wrong because sizeof() needs to be a multiple of 4. Trying to come up with a better example, but it could be that I'm just wrong...
&gt; if sentinel values solve the problem then there's no reason to use optional Absolutely wrong. There are a *lot* of cases where you want something like `optional&lt;T *&gt;`, `optional&lt;fd_t&gt;`, etc. Integration with existing libraries is *hugely* essential to avoid frameworkization.
N3936 wasn't C++14 either. That was N4140/N4141.
Servers are so cheap these days as to be practically free. My Linode is $20/mo and I'm pretty sure it'd be more than enough to handle Boost's usage. (I used to pay $325/mo for a Rackspace dedicated server.)
Also, the expected execution path of your program probably shouldn't throw any exceptions, they should be, well, for *exceptional* situations. You pay just about zero performance cost for them as long as they aren't thrown, but once they are, performance will be butchered. Not that it really matters in small use cases, but still.
~~The returning type could have variable size~~ Different returning types can have different size, so having the bool before it gives both a constant starting point in memory, instead of having to hunt down the bool by first getting the size of the return type. Or something like that.
N3936 has the same text as C++14 (to my understanding) -- unless you are aware of any differences?
Most of the cost of replacing the server is not the rental, in fact Boost typically gets its servers for free as part of its university support and the Software Freedom Conservancy! Firstly, one off payments have a *much* simplified procedure over recurring payments, the latter have to go through US charity law validation procedures, and that's all compliance stuff undertaken by the SFC etc. In other words, it's a big ball to start rolling which takes a while to get there, and you try to avoid rolling it if you can. Secondly, those on the steering committee have exceptionally little free time as compared to back when Dave took up all the slack which he could as a consultant and could allocate his time as he saw fit between contracts. As someone would need to do the replumbing to swap that server, and volunteers for that type of role are very light on the ground or else are not trusted/liked by the committee, that means someone on the committee would have to do it and they all have higher priorities (after all, it's just an expired SSL cert, it doesn't really matter apart from appearance). BTW I've never understood why someone would pay so much for a VPS! You can get a fully dedicated Core i3-2130 with 8Gb of RAM for $21/month! You could run your own KVM and OpenVZ container cluster on that, I used to have my one running a personal private Jenkins! :) 
I mean... it could though. The pattern is used for outputting a struct with a variable-length array at the end. So for example: void func(std::optional&lt;Foo&gt;* ret) { if (...) *ret = std::nullopt; else { *ret = Foo(); SetData((*ret)-&gt;extra_data); } }
What is `(*ret)-&gt;extra_data`? If that is a "zero-sized array" then you're just writing into unallocated memory, since `Foo()` cannot have allocated any more memory than `sizeof(Foo)`. 
I was using the structs defined in my previous comment. So (\*ret)-&gt;extra_data is a char[] that converts to a char* which can be interpreted as a RandomData\*. It could be anything though; usually it's an array, ie. an array of chars to return a string without allocating. All it effectively does is save you the bytes of passing an additional pointer to the data/array, which is why you don't see it very often any more. While saving the allocation can be a big deal, saving the 4-8 bytes of a pointer usually isn't.
I'm not really sure if thread-sanitizer has any more stochastic timing interactions than helgrind does....usually the reason helgrind takes so long is because (in addition to the regular overhead) valgrind only runs a single thread at a time. However, the thread scheduling is controlled by the CPU still, so it shouldn't be any more or less random than thread-sanitizer. On the other hand, I understand why you would want to run thread-sanitizer if you're planning on running the tests in a loop.
&gt; David • a year ago &gt; Now I am looking forward to know wether std::vector in C++ uses realloc or resorts to the poor-man copy, anyone has dug there ? &gt; -- &gt;Xavier Roche Mod David • a year ago &gt; Haha. No. Not even in your dreams. The C++ committee seems to be more interested in allowing turing complete template metaprogramming and lambda functions. But you still can not reallocate an array of objects (even of base types) in 2014. (I'm sure I'm going to be flamed for that) &gt; Is this really true? Shouldn't the STL implementers make use of realloc? :(
I think the STL - as implemented by gcc and clang - does an amazing job within the constraints of the language, requirements (reentrancy, thread-safe, completeness) and the multiple platforms it has to support. I have to confess that given the needs of my industry (HFT/trading), I barely use std::vector from all STL. std::map and std::unordered_map only in reports or other non-critical applications. That said, there is plenty of room for improvement if you specialize on an algorithm and on platform or throw away some reentrancy or thread-safe requirements (which we do). But that would require a new "STL2" interface. I think it is as good as you get as it is right now. 
Because C++ has a policy of zero-cost abstractions, so those abstractions are inexpensive at run-time. Further, it allows you to address the machine directly - managing memory allocation, flow of execution and such like more directly.
I'm in total agreement. It is simultaneously very low level, very high level, and filled with so many complexities its dang frustrating.
It is true that this is very unlike to happen, realloc copies memory, doesn't call copy constructors, could possibly do this with POD but not a pretty thing to handle. If you want some useful stuff which hasn't made it into the C++ standard checkout * [N2045: Improved STL Allocators](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2045.html) * [N2271: EASTL -- Electronic Arts Standard Template Library](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html) While I havne't used EASTL based on what I've seen online from performance comments it definitely looks nice to use. (However licensing could screw you over)
$30/month for 24Gb dedicated is pretty good. Two of my three DNS servers are on $15/**year** 128Mb VPSs with Ramnode and BuyVM. Both are all SSD storage, and whippet fast. Anyone interested in reviews of such VPSs http://lowendbox.com/ is your friend.
It does matter in some cases, depending on your compiler: https://plus.google.com/111825405052388689490/posts/5knfu9psJR7
I like it too. Code should crash as quick as possible when something goes wrong.
I wouldn't say that C++ is either lower or higher level than Python (or any other language for that matter). That implies the "level" of a language is a fixed point on a scale. I would rather say that C++ has a much wider range than many other languages. It's at home whether you're coding down to the metal or doing some really high-level abstractions.
I did say "domain-specific knowledge". In the general case I'm perfectly OK with the existing implementation. However, why cannot I specialize std::optional with something like `std::optional&lt;double, my_invalid_state&gt;` where my_invalid_state is the empty-object &amp; validates state by asserting NaN? This lets me apply domain-specific optimizations at 0 cost to the API, runtime or complexity of the normal case. Having to specialize `std::optional` for optimizations is: 1. cumbersome since the API footprint is large 1. tricky since the implementation has pitfalls for novices 1. impossible to apply to built-in types like double
STL: any thoughts on why an additional template parameter defining the empty state would be a bad addition? I'm thinking of writing up a proposal but I'm sure I'm missing something. Something like `std::optional&lt;T, S&gt;` where `S` holds the empty state &amp; `sizeof(std::optional&lt;T, S&gt;)` == `sizeof(T)` iff `std::is_empty&lt;S&gt;`? `S` would be defined to have a member function like `is_valid` that takes a `const T*`. The nominal implementation of `std::optional` could just apply the empty base-class optimization &amp; inherit from `S` directly or store everything in a `std::tuple`.
Correct. It is typically disabled when compiling with NDEBUG (i.e. release). The behaviour of calling `*` on an uninitialized state is undefined.
I made a mistake. boost::optional::value *does* throw. Not sure why I thought it doesn't.
Copying from another answer: struct default_optional_state { template &lt;typename T&gt; inline bool is_initialized(const T*) const { return _initialized; } inline void set_initialized(bool initialized) { _initialized = initialized; } bool _initialized = false; }; template &lt;typename T, typename S = default_optional_state&gt; class optional { private: std::tuple&lt;S, storage_t&lt;T&gt;&gt; _data; }; So the semantics of optional&lt;T&gt; in the general case remain. However, it's now possible to: struct nan_optional { bool is_initialized(double *v) { return !std::isnan(*v); } void set_initialized(bool initialized) {} }; std::optional&lt;double, nan_optional&gt; foo; static_assert(sizeof(foo) == sizeof(double), "");
I did look at the boost optional design doc but I couldn't find anything about why there's no way to customize it this way.
I agree. I had to take a few breaks while watching his talk to keep focused, but I still found it very interesting to watch. It's good to know that people at the C++ Committee are thinking about adding cool TMP features into the standard.
That's pretty fragile, what if someone calls the function without a Container? You may as well accept Container as the argument type (or use a template parameter if you want different sorts of container).
hehe. hehe. hehe. you happen to ask the right person. did you see the new windows 10 hello world? First declare your main function. in any one of these App.xaml, App.xaml.h, App.xaml.cpp, MainPage.xaml, MainPage.xaml.h, MainPage.xaml.cpp, put namespace HelloWorld public ref class MainPage sealed { public: MainPage(); }; } MainPage::MainPage() { auto navigationHelper = ref new Common::NavigationHelper(this); navigationHelper-&gt;LoadState += ref new Common::LoadStateEventHandler(this, &amp;MainPage::LoadState); } To make your window resizable or for responsive design you have to add: &lt;VisualStateManager.VisualStateGroups&gt; &lt;VisualStateGroup&gt; &lt;VisualState x:Name="wideState"&gt; &lt;VisualState.StateTriggers&gt; &lt;AdaptiveTrigger MinWindowWidth="641" /&gt; &lt;/VisualState.StateTriggers&gt; &lt;/VisualState&gt; &lt;VisualState x:Name="narrowState"&gt; &lt;VisualState.StateTriggers&gt; &lt;AdaptiveTrigger MinWindowWidth="0" /&gt; &lt;/VisualState.StateTriggers&gt; &lt;VisualState.Setters&gt; &lt;Setter Target="contentPanel.Margin" Value="20,30,0,0"/&gt; &lt;Setter Target="inputPanel.Orientation" Value="Vertical"/&gt; &lt;Setter Target="inputButton.Margin" Value="0,4,0,0"/&gt; &lt;/VisualState.Setters&gt; &lt;/VisualState&gt; &lt;/VisualStateGroup&gt; &lt;/VisualStateManager.VisualStateGroups&gt; Dont forget your bitmaps Windows::UI::Xaml::Media::Imaging::BitmapImage^ bitmapImage = ref new Windows::UI::Xaml::Media::Imaging::BitmapImage(); bitmapImage-&gt;SetSource(fileStream); And finally add your XAML &lt;StackPanel Margin="120,30,0,0"&gt; &lt;TextBlock HorizontalAlignment="Left" Text="Hello World" FontSize="36"/&gt; &lt;TextBlock Text="What's your name?"/&gt; &lt;StackPanel Orientation="Horizontal" Margin="0,20,0,20"&gt; &lt;TextBox x:Name="nameInput" Width="300" HorizontalAlignment="Left"/&gt; &lt;Button Content="Say &amp;quot;Hello&amp;quot;"/&gt; &lt;/StackPanel&gt; &lt;TextBlock x:Name="greetingOutput"/&gt; &lt;/StackPanel&gt; Dont forget to translate any backslashes to html entities for XAML processing no more \", use &amp; quot; instead! gl :) [ from https://msdn.microsoft.com/en-us/library/windows/apps/dn996906.aspx ]
I do not negate that this would be efficient. However I will not name that a `optional` type. Imagine situation when you are using `std::vector`. But having some additional knowledge you know that it won't ever contains more than 12 values. So you want to introduce some sort of additional vector parameter which will allow `std::vector`to allocate memory on stack and get rid of overhead related to pointer chasing and dynamic allocation: typedef std::vector&lt;int, known_size&lt;12&gt;&gt; int_vector; // ... int_vector vector = { 0, 1 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}; But unknown to you your fellow programmer didn't knew about that and decided to modify this vector by sometimes adding and sometimes removing some values. At one time he tries to add 13th value: maybe assertion triggers, maybe nothing happens. Software has a bug, it starts crashing. After investigation someone find out that you have an static array disguised as a vector. Angry mob goes for `std` committee to hang them all on the nearest tree... I understand your concern about efficiency and will to avoid death by thousand cuts. But in reality projects more often fall because none can maintain them any longer. Creating API which is efficient, but does what 10% people expects it to do and surprises another 90%, will hit you back very soon. And I am pretty sure that any programmer exposed to functional programming (and not only them) would immediately assume that `std::optional` of `double` could contain any `double`: `1.0`, `2e-10`, `NaN`, `Inf`. Type with sentinels? Sure. Just, please, don't use `optional` name for it. It will cause confusion.
Because under your proposal std::optional has become something utterly different. When supplied with a sentry function it will no longer keep track if the stored data has been initializer or not. What this now implies is that the initialization of data no longer optional, but mandatory, making the class name and its purpose missleading. If the data is not initialized and the sentry function is called on uninitilized data you have undefined behaviour. Even with doubles. If you want a helper class that does value validation, you need a totally new class than std::optional. Shoehorning functionality where it does not belong will not end well. Case in point, the std::vector&lt;bool&gt; optimization, where its behaviour differs from other vector&lt;T&gt; types all for the sake of optimization (granted bigger than what you are proposing).
An alternative would be to switch to CMake (it generates makefiles compatible with both)
I've tried a few plans on lowendbox, but I keep coming back to Linode. Maybe it's just that I'm familiar with the dashboards, but it just feels better :P (Although, the customer support I've received is awe.some. for being on their second lowest tier.) Although I am curious now, who is the provider for your i3/8Gb plan? Edit: http://www.kimsufi.com/us/en/ is linked in the handbook ... tempting for running some Atlassian stuff that doesn't quite fit on my Linode server
&gt; it will no longer keep track if the stored data has been initializer or not Why do you say that? Please don't take my code-snippet as the end-all be-all of such a customization point. It was just meant to be illustrative of what a customization point might look like. I don't see that you've pointed out any fundamental unsolvable problem with having a customization point but I'm probably misunderstanding what you're saying. &gt; Case in point, the std::vector&lt;bool&gt; optimization, where its behaviour differs from other vector&lt;T&gt; types all for the sake of optimization The problem with vector&lt;bool&gt; is that they shoe-horned a bitset implementation under-the-covers, the API for vector doesn't lend itself to bitset &amp; you can't avoid it. Of the three, the middle one is the biggest problem (i.e. the API impedance mismatch). In this proposal, this is still an optional, the exposed API still makes perfect sense, &amp; it's an opt-in mechanism to apply domain-specific knowledge as an optimization. I'm not sure I understand why you're having such a visceral reaction.
shouldn't be much if any difference. just go for it.
Primer Plus is not a recommended book. Anyway, from where you're now, read Head First Design Patterns (its code is java but the patterns all apply), Effective Modern C++, watch tons of talks (just search this subreddit, it's full of similar questions), and at the same time work on a couple of hobby projects (whatever you like and fits your skills - a small game, an engine, algorithm stuff, whatever) and put them on Github. Whatever you do, use good, modern 3rd party libraries where appropriate (std::, Boost, Qt, SFML, ...).
Oh, I didn't know Primer Plus was bad. Is there a specific reason why it is bad? Anything that I was taught that was bad?
good summary: http://accu.org/index.php?module=bookreviews&amp;func=search&amp;rid=1744 (and these questions go to /r/cpp_questions (used to go /r/learncpp
The Fibonacci example is broken - not sure where the _2 stuff comes from, but it's not necessary
Find an open source project that you find interesting, and start submitting patches!
OOP
Dunno... Maybe sentinel?
You'll want to step forward the compiler you use as incrementally as possible, rather than in one leap, so that you can fix compatibility errors one step at a time. Maybe load up VMs of successive Debian releases or Ubuntu LTS releases, and walk through versions of g++ and glibc there. My experience working with a fairly old C++ code base (dating from ~1995, pre-standard) is that there have been very few cases where old code breaks in newer environments. Unless you're dealing with kernel module code, or the code uses some weird system calls from old FreeBSD that Linux has never implemented, the kernel is almost entirely irrelevant to this. After the compiler, you'll need to care about libraries (as noted by fritzroid) and build environment, as you noted yourself.
&gt; read Head First Design Patterns (its code is java but the patterns all apply) Ugh. *Ugh.*
make something! if you are in to games, try making something! here's a c++ game engine i just googled: http://oxygine.org/ put some shit on the screen and make it move around! then put that shit on a website! you are way more likely to get a job from demo-able work than even getting a degree. I've been getting paid to make games for almost 9 years now, it's crazy, fun, sometimes stressful, and always interesting. feel free to PM me if you have questions
Go through the Challenger Series at [Bloomberg CodeCon](http://codecon.bloomberg.com/) and see if you can do those problems.
Hmm, that's interesting. A few years ago I wanted to get into c++ for graphics programming, and I tried to get advice from a series of people and many of them said exactly the opposite. They said that Bjarne was obviously a knowledgeable guy, but his book was way too dry and long-winded to learn the language from. They suggested books like the C++ Primer as a better alternative. Maybe they completely ruined it by adding the Plus... I worked through the entire 5th edition and thought it was a great introduction to the language that moved at a rather good pace. My first attempt at learning c++ was with Bjarne's book and I was totally lost. Then again, I had a lot less experience back then.
&gt; it's not that hard the hardest part is the small irregular syntactic stuff, of having to do some things just a little bit different than other things. the stuff that Scott Meyers makes his living from. Things like `auto` and `{}`-init, the `decltype` vs `auto` subtleties, the absence of lambda and `goto` in `constexpr`, or that variables cannot be `inline` and live in headers, that futures can sometimes block. another hard part is that the expressiveness of the STL is lacking, no easy composition of algorithms, no lazy computations etc. Range-v3 is making good progress on that, but writing complex algorithmic stuff with iterators is harder than it should compared to range-like pipelining.
Hmm I honestly think (or thought) it gives a good introduction and overview of most patterns, like for a beginner. It was quite eye-opening to me, having never had a software engineering class. (of course you wouldn't just copy the code 1:1 to C++). So I kind of thought it's the "modern" version or rather an easier read than the GOF book. I'm eager to learn though and curious why you wouldn't recommend the book. And in case you know it, would you rather recommend [gameprogrammingpatterns.com](http://www.gameprogrammingpatterns.com)?
&gt;They said that Bjarne was obviously a knowledgeable guy, but his book was way too dry and long-winded to learn the language from. I bought *A Tour of C++* from him and and I totally have to agree. The language in it is so dry and it's more a reference type of thing than a tutorial "go through it and progressively learn". I was quite disappointed and would not recommend learning from it. The book is still a must-have, just as a reference though, not to learn from it. And Stroustroup is a genius and what is really awesome are his talks! I would recommend them over anything else.
I shall raise an issue around this and look into it immediately. With a brief test this seems better suited for the task ([^:.]*): *(.*)\s* https://regex101.com/r/bZ2fJ2/1 Will perform more testing before committing.
This talk is one of my favorite C++ talks. Really eye opening. I also found the book from Davide Di Gennaro helpfull to get started with template metaprogramming. But i am far away to be an expert on this topic. 
Good insight. It's true cpp has the worst resources (on average). OP watch his videos, they are very good.
I've found CMake to be very useful -- our use case is compatibility between Windows and Ubuntu 12/14.
looks like gcc 2.95.4 Thanks for the suggest about libbsd, that looks like it will help a lot
yeah, I totally agree that's what it will look like. Just was hoping for something like a magical "diff of changes to the languages" or something. So far it's going well, but small things (like scoping changes, Makefile syntax) are getting me.
You could also do this the other way around: make it build on a current FreeBSD 10.1 with clang 3.4 and then build on Linux after that. i.e. modernity then portability.
I've read GoF and haven't found design patterns to be useful at all. Game Programming Patterns contains nonsense like: &gt; Function pointers are stateless, functors are weird and still require defining a class, and the lambdas in C++11 are tricky to work with because of manual memory management. I wouldn't recommend that.
Several things: * smart pointers are kind of C++ invention, optional type isn't. So while C++ could dictate conventions on smart pointers with optional it had to use existing ones, * rule of zero overhead concerns only compiler, looking at library there are many features that performs suboptimal: * `std::function` is "too slow" for many people to use it, and so are lambdas which cannot be immediately inlined, * several build-constructs appear to be slower than needed (or at lest some people thinks so) - I once heard someone complaining that `std::vector` is slower than dynamic array from CLRS (though I admit that I didn't bother checking), any my lecturer complained that `std::queue` implements one of the oldest know queues th * many functions in standard library are implemented the way your program can be slow due to pointer chasing - I know companies where you are explicitly forbidden to use most of standard library and STL because their performance is unacceptable. * there already is some sort of rift in community: some people use concentrate on maximal performance - they often give standard library away and reimplement all they actually need to perform optimally on their platform - and some demand newest features even when those imposes some overhead - they want to quickly develop fast enough and very reliable code, and perform optimizations only after profiling. I would say that C++ committee for a long time addressed their efforts to the former group and at some point found out that many people assumed C++ to be bothering because of that. So they started to collect feedback from community concerning library, e.g. importing some concepts from `boost`. And boost was never performance-only library. While it's fast they seem to value stability above all, and if they concluded that the gain from avoiding byte or so overhead doesn't justify maintaining and debugging whole new template specialization, STL simply adapted their conclusion. I would also guess that they wanted to avoid effort on writing standard for something that not so many people will use. They have their hands full of work with making the C++ library more "modern": it's 2015 and you still cannot quickly implement program which would e.g. crawl over webpages, parse them, perform some JSON queries and store them in XML without installing a lot of third party libraries. C++ rivals already has most of those features in their standard libraries, and recent STL committee's efforts seem to be addressed towards closing that gap. With such amount of work something like adding support for sentinels might be of to little priority (especially when people like me would find it opposing state of the functional programming art).
Yes, absolutely. Actually, you just made me aware of this, so thank you. I intend to keep up with releases of gcc/clang/msvc and adapt the feature detection code and tests as they come out. By the way, do you, or someone here, know if there is a legitimate way to get *older* versions of MSVC without subscribing to MSDN? I may bite the bullet, but I want to be sure that I have to first :)
Gosh, I don't have an hour to listen to someone talk - I don't suppose there's a transcript?
Yea, I think the guy doesn't have a particular good idea about C++11 - he specifically mentions in his introduction though that he doesn't use smartpointers &amp; stuff to keep the examples simple - why not. It's about patterns after all and not syntax. The guy is one of the thriving forces behind the Dart programming language or something like that, don't remember exactly. Not that this means anything though. But I think he has a pretty good idea what he's talking about and we shouldn't hang him because of a couple of weird statements. Thanks for your comment on the matter, great to hear your opinion.
&gt;Currently, the checking of format specifiers is only done for a predefined set of CRT functions and is not available for user-defined functions that would also benefit from similar checks. :-( Most of my uses of these functions involve wrapping them, (and calling the vararg variant)
The "interesting" parts start at 28:00
Bravo!
Looks like they created a unix inside a browser: https://code.google.com/p/naclports/wiki/PortList
Spends the first 28 minutes describing how `shared_ptr&lt;T&gt;` and `weak_ptr&lt;T&gt;`. Then spends time describing how multi-threading is hard. Around minute 47, he finally gets around to saying "this makes passing `shared_ptr` by value slow", and showing numbers. Presentation tip: Lead with the problem, then provide explanation. I have no idea what parts of your explanation are important if I don't know why you're providing it. **TL;DR: Passing `shared_ptr&lt;T&gt;` by value is slow because you might use them in threads.** * Watch from the beginning if you want to know how `shared_ptr` works. * Watch from 28m if you want to know the problems with `shared_ptr` in multiple threads. (I highly recommend Herb Sutter's [atomic&lt;&gt; weapons talk](http://herbsutter.com/2013/02/11/atomic-weapons-the-c-memory-model-and-modern-hardware/) for how the C++ memory model works. * Watch from 47m for benchmarks (sans any charts, sadly). * Watch from 51m for problems with passing shared pointers by reference. * Watch from 54m for his own summary.
This is an interesting approach, the resulting data structure looks a lot like a [heap](https://en.wikipedia.org/wiki/Heap_%28data_structure%29) and thus probably allows similarly efficient tree traversal. But I only see a very narrow range of use cases for this. It's not sorted anymore and element insertion and deletion is probably rather expensive. A sorted array may have a slower binary search but also allows very efficient iteration in sorted order. A hash table probably allows even faster lookup for most types of keys and would additionally allow faster mutation. The only advantage I see is that it is slightly more memory efficient than a hash table. This seems to limit the reasonable use cases for this data structure to large read-only lookup tables in very memory constrained environments. I never really understood why tree based data structures are and have historically been so popular in C++ and why there hasn't been a decent hash table in the standard library for so long. While I haven't tried other implementations, the unordered_map in Visual Studio 2013 at least is still of questionable quality. Last time I checked a naive flat array based implementation (2^n sized) with open indexing turned out be about twice as fast for insertion and lookup with the same hash implementation.
Hash tables in C++ are typically implemented as a linked list of nodes with an array of pointers to those nodes. So they're not cache-friendly at all.
The guts of VC's unordered_map are very old, since they're shared with the non-Standard hash_map. I've deprecated hash_map in 2015, so I can remove it in the next major version, and then we can think about reimplementing unordered_map.
deque is not very friendly to caches, even with largeish blocks. vector (and array) is much better.
&gt; std::shared_ptr doesn't use synchronization but rather atomic variables to accomplish its magic Uh...using atomics is a form of synchronization. The cost is not negligible. Every CPU has to update its cache value for the variable for example.
Indeed, this is a major let-down. Gcc has had format(printf) for over a decade.
Why are all the methods prefixed with underscore? Is it to avoid collisions with the user's values? I'd think a nested type, while more typing, might set fewer people's teeth grinding: ENUM(Foo, int, A, B, C); size_t len = Foo::Type::size(); Foo val = Foo::Type::from_string ("C"); Just saw this link: http://aantron.github.io/better-enums/DesignDecisionsFAQ.html#ShouldBetterEnumsProvideEnum Is a nested type another possible solution aside from traits?
This is not really accurate, it would be more correct to say that std::unordered_map is generally implemented this way. Because of various guarantees on iterators and when they can and cannot be invalidated, and a desire to have robust performance across different types and degrading gracefully with the fill factor, the implementation you described is typical for std::unordered_map. However, usually when people implement their own unordered_map, they do it because they want very good performance for specific types. The most common choice is usually a flat, open address hash table which is fairly cache friendly.
I guess it's all relative, and it depends a lot which benchmarks you pick, but it seems to me that the difference between vector and deque is not that huge. Or, to be concrete: deque is much closer to vector than list. E.g. consider linear search benchmarks: http://baptiste-wicht.com/posts/2012/12/cpp-benchmark-vector-list-deque.html
I found that refcounted smart pointers are virtually **only** interesting in multithreaded scenarios. Without multithreading, handling object ownership through... well, ownership design, beats shared ptr any day of the week for me.
Please don't use shared_ptr most of the time. This is becoming the latest symptom of a *big-ball-of-mud*. First try to design your software so that there are clear ownership semantics. It creates a cleaner, simpler, faster design that is simpler to reason about. If creating clean, simple and fast software isn't your team's style then it should be. Only use shared_ptr when objects must have shared ownership for some reason. Also, don't pass any kind of smart pointer as an argument when you don't have to. If your function uses a T and doesn't deal with ownership then let it take a (const)T(&amp;). What makes you think I'm holding my T with your favoured smart pointer? End of rant.
Yes, looking at the specs for `std::unordered_map`, it's clear that they had separate chaining in mind. That explains why `std::unordered_map` will generally be implemented using separate chaining. But it does *not* explain why the interface was written with separate chaining in mind, given its cache-unfriendliness. True, as you noted, the performance of separate chaining degrades more gracefully than that of open addressing, as the load factor approaches one. That is why we put an upper limit on the load factor, and remake the hash table using a larger array when the limit is reached. Since `std::unordered_map` is going to do this regardless, I don't see that the performance degradation when the load factor nears one is an issue. And it isn't just C++. It appears that the standard hash tables for Perl and Ruby use separate chaining as well (I think). CPython uses open addressing (I'm sure on this one), but it might be the only major language to do so. I'm very unclear on why separate chaining is so much more popular.
Did the interview style improve? Listened to the first couple of episodes and it went on like:" Did you read that article?" "Yeah, I did. It had some interesting points." " Wow, that's interesting." And then they went on to the next topic and rinse and repeat. Very little substance and kinda annoying.
Why is everyone trying to turn c++ into haskell?
By default C++ does not involve the heap or a long slew of runtime checks for simple operations like 1 + 1.0 . 
Did you read the article? The whole point is that sorting is *not* as cache-friendly as you can get.
Yeah, I saw the similarities to a heap pretty quick too. I would call this a narrow use case though. It's certainly not *general*, but there are a *lot* of use-cases for constructing sets/maps once at setup and never modifying them.
ownership can be designed in with threading still. that's the bulk of the thread stuff I do.
&gt;First try to design your software so that there are clear ownership semantics. Sounds so easy i theory but in the real multi threaded world it's not. 
looks very interesting, but vimeo doesnt seems to work. would it be possible for you to post on youtube?
&gt; "Slow" is a relative term! It's slow relative to passing raw pointers around (assuming the `shared_ptr` has to be copied and cannot be moved). Whether that actually matters in your program is a different question. &gt; doesn't use synchronization but rather atomic variables I'd say that using atomic variables *are* a form of synchronization. I agree with you on the other points you raised. Personally, I almost never use `shared_ptr`. So far, I've used it once to write a copy-on-write wrapper à la template&lt;class T&gt; class cow { std::shared_ptr&lt;T&gt; ptr_; public: cow(); cow(T const&amp; x); cow(T &amp;&amp; x); T const&amp; operator*() const; T const* operator-&gt;() const; T const&amp; read() const; T&amp; write(); }; 
I'm still waiting for the port of NaCL and WebAssembly to NaCL and WebAssembly ;-)
Even though that is of course not true, for better or worse when C++ gets a feature it becomes non academic, since there are the compilers, tools, manual memory management and threading to back it up.
The world has woken up to the value of functional programming and C++ being inherently multi-paradigm is being adapted to it. That said, C++'s STL has always been somewhat functional.
That's great if it's a single threaded programming, but keeping track of everything in a non-deterministic multi-threaded environment can be very hard and is what I consider a wasteful micro-optimization; who is to say the thread holding the pointer won't idle for tens of thousands of cycles by the scheduler? Why keep track of that manually instead of just using a shared_ptr which, itself, takes only a negligible fraction of the total cycles in your program. I think many of the arguments on here stem from two camps of people, one who deals with multi-threaded environments, and one who deals with sequential where pointer safety is much simpler and easy to track.
Meta-programming allows to turn C++ into any other language.
Anyone got a C++ track playlist from NDC Oslo? The vimeo catalogue doesn't seem to be organised by track and I can't figure out how to search it by tag.
Sometimes it might be necessary to have multiple threads controlling the lifetime of an object. If that's the case then use shared_ptr. It's what it's there for. But usually that's not what you want. If you're just sharing an object between threads then let the parent thread control its lifetime.
If you have a `foo` which takes a `shared_ptr&lt;T&gt;` by value or const-ref and does not store the `shared_ptr` elsewhere to increase the lifetime of its pointee beyond the function call, then you probably should not have passed a `shared_ptr&lt;T&gt;` at all ... more like `T&amp;`. Anyhow, ownership transfer is a thing and we have `std::move` to support it. Taking a cheaply movable type by value if you want to have your *own* value is sometimes exactly what you want. For example: class Person { std::string name; public: explicit Person(std::string n): name(std::move(n)) {} }; That's as simple as it gets and it still avoids all unnecessary copies.
It doesn't seem to work when enum entries have the same values: ENUM(test_enum, a = 1, b, c, d = 1, e) test_enum v = d; std::cout &lt;&lt; v._to_string(); // prints "a" I realize this isn't a common case, but it is valid and we have at least one use of it in our codebase. Admittedly, I took the simplified version from your codeproject article, since I'm not at a computer with a c++ compiler and ideone wouldn't compile the real deal. Maybe you account for it there. Edit: got rid of switch example, because it doesn't work with regular enums, either
Seems like a stupid feud.
One cannot use const t&amp; in lieu of any form of a shared ptr because a shared ptr is nullable. const t\* should be used. Pointer is not a reference, however smart :-)
Great list. Thanks! Here is another one to the list: https://dbgr.cc/
You're right, that doesn't work. At this point, I don't think it can be made to work nicely – "a" and "d" have the same representation. I could switch to using indices (0 for a and 3 for d) for representation, instead of values. But then you would get a surprising result when interpreting memory as an enum or using fwrite on one, and it would take time to convert from test_enum::a to a test_enum, because there would have to be an index lookup. I have a todo item for writing a FAQ on the tradeoffs of using indices. I'd be happy to hear any more opinions on this whole issue. By the way, you can compile against the library online here: http://melpon.org/wandbox/permlink/wICNzu2LW2vEgqzh Likewise, the CodeProject simplified version is online here: http://melpon.org/wandbox/permlink/7cLP4VqGAORD3hKI Of course, they both don't do what you want :/ The behavior you found is documented here http://aantron.github.io/better-enums/ApiReference.html#_to_string
&gt; Supporting the C++11 standard required incompatible changes to libstdc++ ABI. Is there a short explanation of why this is the case?
FWIW we had an array of ~1000 shared_ptr with the same thinking (porting from Java). This is a numerical simulation &amp; finally getting rid of the shared_ptr sped-up the program by 20% even though we couldn't see shared_ptr in the sampling instrumentation. The main improvements are two-fold: contiguous memory was cache friendly &amp; we didn't have a bunch of unnecessary compiler &amp; CPU fences that prevented optimization. Additionally, the code is much clearer now since ownership is very clearly defined. We still use shared_ptr for caching of expensive cross-thread resources but we try hard to limit shared_ptr (&amp; even unique_ptr); using value types as much as possible really makes the code simpler to work with.
libstdc++ used copy-on-write `std::string`, which is no longer permitted in C++11.
Having a whole bunch of objects shared between threads is a great way to run into bugs even with `shared_ptr`. Sometimes it's exactly what you need, but in most cases it's only solving the simplest of your problems.
&gt; nstead of bumping the library soname (I still do not understand why that was not done…), the GCC developers decided to have a dual ABI Can someone explain why GCC made this decision? 
Probably because different libraries with common symbols can't be loaded at the same time. So if a gcc-5 program uses a gcc-4 library, it would be impossible to start it. Source: Comment on the blog page.
I'm particularly interested in knowing if there's an online MSVC compiler that shows assembly. I suppose it might be possible to open argv[0] and dump it as hex and disassemble locally ...
You're talking about an exception to the rule, where pointers make up a large part of your program; I am talking about the general case. Almost all tools in the STL are bad in specific cases where a much more optimal case exists.
You're right, I don't know of a good way to solve this and I think you made the right tradeoff. I just hadn't seen it in your documentation and wanted to know if you'd considered the possibility. The library looks very nice!
Coliru also has clang and some special libs (range-v3).
I'd not assume that it's "niche" programming. The cost of altering an atomic value can quickly cause some serious performance degradation in any program where that atomic value is shared across threads. It's worth developing a coding style that limits these effects.
In addition to that, libstdc++ uses a `std::list` without an size field embedded, making `std::list::size()` an `O(n)` operation. 
[C++ Shell](http://cpp.sh/)
I would agree there are tradeoffs with any abstraction &amp; you have to know which one to pick &amp; when you are unnecessarily paying for the wrong abstraction. Performance considerations aside, shared_ptr usually can be overkill &amp; demonstrates a larger complexity in the code than something like unique_ptr because the ownership is unclear when reading the code (e.g. does ownership imply you can mutate it? maybe, maybe not). I think the general advice still applies: use value types when possible, use unique_ptr when something needs to live on the heap and ownership is still clear, use shared_ptr when ownership is unclear or you need to share the lifetime between threads. Prefer to write your own move-only/copy-only/nocopy &amp; nomove value-types when multi-threading isn't a concern to express your needs clearly.
Hmm... I didn't come across one.
Yeah, that's already in the list.
I'll have to check out liveworkspace.org when I get home. Proxy says it's now a "Parked Domain." compilr.com was taken over by lynda.com, which is a video learning site. As far as I can tell, the online-compiler component of compilr.com did not make the transition. That's why it's not on the list. I have all the others. Thanks.
Yeah, actually, I have a link to that in my opening paragraph, saying that I used it as a starting point.
&gt; The last time G++ went through an ABI change, back in the 3.x period, we changed the soname of libstdc++, which was widely regarded as a mistake. Changing the soname caused a lot of pain but is not sufficient to deal with changes in symbol ABIs: if you load multiple shared objects that depend on different versions of the library, you can still get clashes between different versions of the same symbol. &gt; So the plan for this ABI change has been to leave the soname (and the existing binary interface) alone, and express the new ABI using different mangled names. [source](http://developerblog.redhat.com/2015/02/05/gcc5-and-the-c11-abi/)
&gt; Please don't use shared_ptr most of the time. Absolutely. With C++11 and move semantics, you rarely need it. It shouldn't be your "go to" memory management. &gt; What makes you think I'm holding my T with your favoured smart pointer? Well, as I said, "shared_ptr&lt;T&gt; by value (if the routine will keep a copy of the shared_ptr)". In that case, if you don't have T with the shared_pointer, you can't on principal use my routine! Given that you are forced into using a shared_ptr, the receiving method often needs to keep that shared_ptr. Given that you must use a shared_ptr, value semantics are cheap and easy. Of course, you should prefer passing a reference, and you should prefer overall designs that have clear ownership of your pointers.
If you're automating a playpen for your C++ library per commit, knowing which ones provide a push API is handy. Coliru and Wandbox do. Wandbox also lets you push a background file with your library, and lets the user play with a simple front example program. https://svn.boost.org/trac/boost/wiki/BestPracticeHandbook#a14.USERFRIENDLINESS:Considerlettingpotentialuserstryyourlibrarywithasinglemouseclick has some scripting for pushing playpens per CI commit if anyone is interested.
What? I always thought I could trust things like this from the STL. I guess that's why people don't like using the STL in performance critical code.
http://en.cppreference.com/w/cpp/container/list/size You can see here it was allowed to constant or linear until C++11.
smells of a screw up actually. I wonder how clang addresses this. 
Sauce?
http://coliru.stacked-crooked.com/a/6f72d5a72de2bf64
Sauce: have spent a lot of time working with GCC and LLVM teams. GCC team is generally a *lot* nicer and more likely to fix bugs, but they are still overcoming some of the political baggage of old times. LLVM team has Apple marketing behind them.
Yes, that was very helpful. Thanks! &gt; In python, everything is based around pointers, so the types stored in the hash table are always the same size. It seems that lots of design issues end up coming back to this. Recall the [discussion](https://www.reddit.com/r/cpp/comments/36sqtq/more_efficient_interface_for_algorithms_taking_a/) a month or so ago about specifying a custom sort order via a comparison function vs. a key function. Python is big on key functions, and, again, the fact that everything is referred to by pointer is critical in making this work well. Also, you said: &gt; In open addressing, .... You generally need a better hash, .... And: &gt; Python's hash function for integers is just the integer itself, .... Kinda ironic, no?
This always makes me laugh. I've used STL in tons of performance critical code; which usually means vector + algorithms.
I've just tested whether something I want is there and occasionally bugged the owner to update a part (you can thank me for Clang 3.6). The command window at the bottom is very general; you can put whatever you want within permissions.
LWS used to be my go-to over ideone, but yeah, then everything kind of died.
&gt; the compiler gave me errors when I tried to implement in in a .cpp (ignoring some complicated details) Templates need to be implemented in headers. That's because class templates and function templates *aren't* classes and functions - they simply have the ability to stamp out classes and functions. (The usual way I explain this is, cookie cutters aren't cookies. Cookie cutters are made of metal and you don't want to eat them.) You can't declare a template in a header and define it in a source file stuff.cpp, because if another source file other.cpp includes that header and instantiates the template for OtherType, the compiler needs the template's definition in order to generate a class or function that uses OtherType. (The obvious exception to "templates go in headers" is if you define a template in a source file, and then use it only in that source file. That's fine.) &gt; \#include "vector" Should be &lt;vector&gt;. Use angle brackets for installed headers (and Standard headers are the best example), use double quotes for your own headers. &gt; class common { Why do you have a class whose only purpose in life is to have static member function templates? This isn't Java. Non-member function templates are perfectly fine. (And if you want a namespace, use that.) &gt; template&lt;typename V&gt; &gt; static bool are_equal(int size, V v1[], V v2[]) { First, never declare functions as taking arrays by value. (There are few absolute guidelines in C++, but this one is a never-ever.) Doesn't matter if they're unknown bounds like you have here, or known bounds like V arr[3]. When the language/compiler sees an array passed by value, it *immediately* ignores what you wrote, and rewrites it to a pointer. This rule goes all the way back to C. You don't get any sort of bounds checking, and you can even pass pointers to individual objects to such a function. If you want to write a function taking pointers, declare it as taking pointers. Never arrays. In general (and now this is just a recommendation, not ironclad) modern code should use STL containers like vector and std::array, not builtin arrays, which so readily decay to raw pointers. If you use STL containers, you can compare them directly for equality with ==. Second, if you aren't using STL containers (or you have containers of different types), &lt;algorithm&gt; contains equal(). In C++14 it has a good signature, equal(first1, last1, first2, last2). Use this instead of writing your own. (In C++98 through 11, it has a dangerous signature equal(first1, last1, first2), where you're expected to check the lengths first.) &gt; static void push_iterable(const int length, V start[], std::vector&lt;V&gt;* vector) { Good work passing length by const value. However, you generally shouldn't use a raw pointer when a reference will do. Here, you're assuming the pointer is non-null, so you should just take a reference. &gt; for (int s = 0; s &lt; length; s++) { Conventionally, C++ uses preincrement except when postincrement is necessary. There are minor and mostly historical efficiency considerations (that apply to iterators of class type), but mostly it's for code clarity. Preincrement is the simpler one, so if you use it by default, you make the more complicated postincrements stand out due to being rare. Instead of a push_back loop, you can use a much more efficient range-insertion call. This looks like: v.insert(v.end(), first, last) where first and last are a range of stuff to insert. It's more efficient because the vector can do a capacity check and potential reallocation exactly once. To get a pointer to a vector's contiguous data, use v.data() in C++11. But if you're starting with a vector, it's pointlessly bad to drop down to the level of raw pointers, when you're going to keep working with them in your own code. You should stay at the higher level of iterators, unless you need to work with C APIs that expect pointers to contiguous data. `delete vertex_source;` indicates that you've got owning raw pointers. These are extremely bad and should be avoided like the plague until you're an expert (then they should be avoided like the common cold). Avoid dynamic memory allocations if you can, use unique_ptr/shared_ptr if you must. In this case, your optimized_verts should just be a local variable vector. Learning this is one of the **most important things** as a beginner - screwing it up is why people grow to hate C++, which is so sad, because it's such a very nice language. For example, you are leaking your optimized_verts. Using modern C++ properly, your program would be structurally immune to memory leaks. You're already so close, since you're getting vector to handle your element allocations. &gt; unique_vertices += 1; Preincrement was invented for a reason. Use it. (Again, this makes the more complicated += 2 and whatevers stand out.) &gt; common::GenOptimizedArrays&lt;GLfloat, GLint&gt;(2, &amp;source, optimized_verts, &amp;ebo); You shouldn't use explicit template arguments unless absolutely necessary. Let the compiler deduce them. The compiler is your friend. return 0; is unnecessary at the end of main() in C++ (it's a special rule, added implicitly even though main() must return int). I believe your algorithm could be simplified (it looks like you'd want an indirect sort-and-unique), but I'd have to think hard about that.
coliru misses libc++abi which quite unfortunate for libc++ use.
Scott Meyers covers this in item 4 of Effective STL. There was a choice between making size() constant-time or splice() constant-time with the other operation then being linear. Some implementers thought one operation or the other more important so implemented their preferred one as constant-time.
With some changes to the rest of your program, the optimize function could be simplified to something like this: template&lt;typename Vertices, typename Elements&gt; void gen_optimized_arrays (const Vertices&amp; in, Vertices&amp; out, Elements&amp; ebo) { for (auto iter = std::begin(in); iter != std::end(in); ++iter) { auto found = std::find(std::begin(out), std::end(out), *iter); ebo.push_back(std::distance(std::begin(out), found)); if (found == std::end(out)) out.push_back(*iter); } } full example here: http://ideone.com/cJjkwx
 template&lt;typename V, typename E&gt; static void GenOptimizedArrays(const int vertex_size, std::vector&lt;V&gt;* vertex_source, std::vector&lt;V&gt;* vertex_out, std::vector&lt;E&gt;* ebo_out, bool cleanup = false) C++ has come a long way in the last few years. C++11 really changed the way programmers think about the language and how we write code. Many advances in the language help us to write more fluid, almost prosaic code now. In my mind, the single facility in C++11 that helps us do that most is move semantics. In C++98 if you wanted to return two^1 vectors from a function like you are doing here, you had no choice but to pass them in as in/out parameters (either via non-const references or by pointers like you are doing). In C++11 we have move semantics, so let's use those. template&lt;typename V, typename E&gt; std::pair&lt;std::vector&lt;V&gt;, std::vector&lt;E&gt;&gt; GenOptimizedArrays(const int vertex_size, std::vector&lt;V&gt;* vertex_source, bool cleanup = false) { std::vector&lt;V&gt; vertex_out; std::vector&lt;E&gt; ebo_out; /* Do stuff */ return std::make_pair(std::move(vertex_out), std::move(ebo_out)); } Much better! Since we are refactoring, let's get rid of that ugly cleanup business. I want you to repeat after me "I will not use owning raw pointers in my code." Now say it 1000 times and give three hail Bjarnes. :p template&lt;typename V, typename E&gt; std::pair&lt;std::vector&lt;V&gt;, std::vector&lt;E&gt;&gt; GenOptimizedArrays(const int vertex_size, const std::vector&lt;V&gt;&amp; vertex_source) The only thing that is ugly now is the return type. If we move to C++14, we can write template&lt;typename V, typename E&gt; auto GenOptimizedArrays(const int vertex_size, const std::vector&lt;V&gt;&amp; vertex_source) Not even Robert Frost could write such elegant prose. Speaking of the return type, let's look at the code in `main` now. Normally when you are dealing with a `std::pair`, you access its members using `p.first` and `p.second`. That's ugly and doesn't allow for more of our beautiful prose. Fortunately, C++11 introduced `std::tie`. int main() { std::vector&lt;GLfloat&gt; source = { 1, 2, 3, 4, 5, 6, 5, 6, 1, 2, 7, 8 }; std::vector&lt;GLfloat&gt; optimized_verts; std::vector&lt;GLint&gt; ebo; std::tie(optimized_verts, ebo) = GenOptimizedArrays&lt;GLfloat, GLint&gt;(2, source); for (auto &amp;v : optimized_verts) { std::cout &lt;&lt; v &lt;&lt; " "; } std::cout &lt;&lt; "\n"; for (auto &amp;v : ebo) { std::cout &lt;&lt; v &lt;&lt; ' '; } } There are several things to notice here: 1. I got rid of the heap allocation of `optimized_verts` 2. Because we are no longer passing in the "return" vectors, we have to specify the template parameters for the function. You don't get template type deduction anymore, so we have to disregard /u/STL's advice about leaving off the template arguments. I think it's a small price to pay for a much cleaner function interface. 3. I converted your `for` loops to range-based `for` loops. I strongly recommend using them. I have heard tell that C++17 might be getting a feature where we can declare objects inside of `std::tie` so that we could write int main() { std::vector&lt;GLfloat&gt; source = { 1, 2, 3, 4, 5, 6, 5, 6, 1, 2, 7, 8 }; std::tie(auto optimized_verts, auto ebo) = GenOptimizedArrays&lt;GLfloat, GLint&gt;(2, source); /* stuff */ } Super cool! [1] Returning *one* vector could be done with [NRVO](https://en.wikipedia.org/wiki/Return_value_optimization) and you should still use that in C++11.
In addition to everything that STL already said: * C++11 also has a range-based for loop that looks like this: `for(auto&amp; x : c)` and works similarly to the `for x in c` syntax found in Python. * Try using `unsigned` or `size_t` as the indexes for your arrays, as `size()` returns an unsigned number, and comparing signed and unsigned numbers may sometimes lead to surprises. * Create a `vertex` class and store it directly in your vector rather than using size-and-offset indexing. It's less error-prone, and classes are cheap in C++. * Make sure to turn on warnings when compiling! For GCC or Clang, `-Wall -Wextra` is recommended. Sometimes, dangerous things are only a warning, not an error, and fixing your warnings can solve many problem.
 if (v1[i] != v2[i]) return false; Typically (in any language) you never want to compare floating point types directly like this - small inaccuracies will make it unreliable. You need to use some sort of comparison tolerance, the exact form of which depends on whether the values are all in the same approximate range or not. See e.g. http://stackoverflow.com/questions/17404513/floating-point-equality-and-tolerances There are some exceptions to this, like if you can be 100% sure that any duplicates are exact copies, but in general don't do it. Write an inline function which calls fabs() etc. and use that instead. In your toy example it's fine, but in the real world your verts may have come from an external tool, and/or have been through transform(s) etc. BTW once you change the vector to a reference instead of a pointer I think &amp;vertex[0] is perfectly fine, indeed arguably it's clearer than data(). Also the whole signed vs unsigned thing is debatable. Personally I prefer signed types as you can do this: `assert(length &gt;= 0);`. That way if you have a bug which miscalculates length you'll catch it more easily than if it's unsigned and wraps around (do litter your code with asserts for anything you think should be true at any given point, particularly if it has dependencies outside the local function). Another common bug using unsigned is if you write a loop going backwards from length to 0 (although legitimate compiler warnings might save you here). That STL uses unsigned size_t is an unfortunate design decision IMHO, but sometimes in C++ what seemed like a good idea 20-30 years ago sticks; however there are other ways to silence any spurious warnings if you choose to continue using signed types.
&gt; For example, is there a library to read a whole text file as a std::string with a single call? You don't really need a whole library for that... as you can see in [the first search result from stackoverflow](http://stackoverflow.com/questions/2602013/read-whole-ascii-file-into-c-stdstring), it's really simple with the standard library: #include &lt;string&gt; #include &lt;fstream&gt; #include &lt;streambuf&gt; std::ifstream t("file.txt"); std::string str((std::istreambuf_iterator&lt;char&gt;(t)), std::istreambuf_iterator&lt;char&gt;());
Yes, I did. I know both Perl and Python. I have ported a Python script to C++ and I have realized that things would be simpler with a library that lets you perform recurrent I/O operations and system calls succintly, and has defaults for the most common cases of STL usage (like using STL algorithms on whole containers). I would bet that somebody has thought about this already, and since I am not keen to reinvent the wheel, I am asking here. I do know that C++ is a language of choice for efficient programs, but I don't agree that C++ couldn't be used for simpler tasks, when suitable libraries were available.
I'm surprised you don't have http://gcc.godbolt.org/ in your list yet - imho it's one of the best ones, a lot of gcc/clang versions and even gives you errors while typing.
To be honest, I wouldn't use C++ for web development, and client-side web dev in c++, is definitively not the right tool for the job. Use a JS framework, or a similar language designed with web client in mind. 
&gt; Conventionally, C++ uses preincrement ...I agree, but I just have to point out the irony here.
does anyone know how did LLVM handled this change? or they didn't have this ABI problem (why?) ?
I don't know of any that are packaged that way. However it is relatively straightforward to write one using boost. For reading the whole file, I once wrote a library that used boost::mapped_file along with boost::string_ref to memory map the whole file and return a string_ref to it. For my code, I found that this was a major speedup rather than line by line reads which I was doing before. In terms of executing other programs, take a look at boost.process. It is not an official library, but is in the Incubator at http://rrsd.com/blincubator.com/bi_library/process/?gform_post_id=1427 If you would like to start a library like that on github, I am sure other people would contribute these kind of utilities.
OT: JUnit has also spread its pestilence into the Python standard library `unittest` module, which I find abhorrent. The idea of typing `foo.assertEqual(bar)` (vs. the much more sane `assert foo == bar` of other Python testing modules, and not having to inherit everything from some base class) feels so wrong. Why in the world has JUnit been copied so much? I guess it's supposed to feel familiar, but I don't want familiarity with Java. 
Very useful. And I didn't know about the Boost Incubator. Thank you.
I looked at Wt, but it seemed more like a framework that was different from everything else out there. I have done 2 projects recently using a C++ server. For the first one, I used a combination of AngularJS for the front-end and cpp-netlib for the back end. For the second, I used ReactJS for the front-end, and crow (https://github.com/ipkn/crow) for the backend. I really like ReactJS more than angular, and crow makes writing C++ REST services so painless. I plan on using this combination for other services.
If you are mainly wanting to test compilation, you can get the express editions which have the compiler and are free. 2005 http://go.microsoft.com/fwlink/?LinkId=51411&amp;clcid=0x409 2008 https://go.microsoft.com/?linkid=7729279 2010 http://go.microsoft.com/?linkid=9709949&amp;clcid=0x409&amp;wt.mc_id=o~msft~vscom~download-body~dn469506&amp;campaign=o~msft~vscom~download-body~dn469506 2012 https://www.microsoft.com/en-us/download/details.aspx?id=34673 For Visual studio 2013 and 2015 there are free community editions
Thanks! This will help to make my testing more thorough. I did already get VS2013 and VS2015, I just wasn't able to locate links for older editions. Kept getting MSDN pages saying old versions are no longer available without subscription, or redirects to VS2013/2015.
Are moveable streams considered an ABI change (I'm thinking yes)? What about the [proposed change](http://en.cppreference.com/w/cpp/iterator/istream_iterator) in C++17 to the iterators no longer inheriting from `std::iterator`? Will we be back here for another ABI breaking change in GCC 6?
&gt; but sometimes in C++ what seemed like a good idea 20-30 years ago sticks; Personally I can't fathom how could it ever look like a good idea given that usual arithmetic rules break down and that unsigned has higher rank than signed for the purpose of implicit conversions (for example, `x &lt; y &lt;=&gt; x-1 &lt; y-1` breaks down in unsigned arithmetic in the singular case of x being zero.. a nasty source of bugs). Do you have some historical account of why STL uses unsigned size type?
&gt; I guess that's why people don't like using the STL in performance critical code. Actually, this decision of C++11 to have `size` be O(1) is seen by many as a mistake in the case of `std::list`, because there's a trade-off: - O(1) `size` and O(N) `splice` OR - O(N) `size` and O(1) `splice` libstdc++ had picked the second alternative at a time where either was good, reasoning that the only good reason to use `std::list` was to have O(1) splice; the C++ committee decided to go the other way to be more newcomer friendly (too many people use `std::list` where other containers would be more appropriate). Personally, I preferred the former behavior...
Don't forget that the first internet clients were made using raw UNIX sockets (aka with C)
It's already on the list as "GCC Explorer." Although it looks very useful for what it does, it doesn't let you *run* the program. I downgraded it a bit for that.
&gt; is definitively not the right tool for the job. This is pretty debatable.
Qt has stuff for [parsing command line options](http://doc.qt.io/qt-5/qcommandlineparser.html) and [executing processes](http://doc.qt.io/qt-5/qprocess.html). Reading a text file : QFile myFile("da.txt"); auto val = myFile.readAll();
[This post](https://www.reddit.com/r/cpp/comments/3b2glr/why_clang_cant_use_the_new_gcc_5_cxx11_abi/csit6pz) shows the reasoning used by GCC guys (or rather, their clients). IMNSHO, they are wrong. Neither C nor C++ languages deal with an ABI. C easily has a de facto ABI for a given platform, but that is because C is **dead simple**. But for C++, this is **much** harder (name mangling, inlining, exceptions, templates, standard changes in this case...). I do not understand why gcc people bother trying to have an ABI, nor why clang people try to follow. Microsoft does it better: **no** ABI between compiler versions. Even an upgrade can break it (ok, I don't remember that happened since VC6 TBH). This seems so much saner to me. But then, Windows has had a **really** good cross-language ABI for a really long time, which might have played a part in forgetting one particular language. :-)
I don't know C++ very well but for example the lack of automatic garbage collection looks making program unnecessary complicated.
They concluded that the first number was entirely pointless since they didn't plan on ever incrementing it under the old versioning scheme, so they shifted everything over by one.
C++11 was mostly done when libc++ was created, so it just did things the C++11-compatible way to begin with.
C++ offers reference counting, which has its downsides, but so does garbage collection.
Is crow fully async? I've been toying with building a home automation daemon with cpp-netlib. 
&gt; I do not understand why gcc people bother trying to have an ABI, nor why clang people try to follow. There's no less reason to have a C++ ABI than a C ABI. IMO it's Microsoft that's been mistaken in not supporting a consistent C++ language ABI. That decision caused a lot of pain for a lot of their developers. They're now partially addressing that with their "Universal CRT", which moves the C and C++ libraries over to being part of the OS. This is now more similar to the way OS X and most Linux distributions work.
&gt; not having to inherit everything from some base class This hasn't been necessary since JUnit 4, which is nearly 10 years old and came out relatively shortly after Java added annotations. I don't think blaming JUnit for lousy ports is fair. I definitely agree that the notion of familiarity past a certain point is silly or actively harmful, but JUnit (especially with AssertJ) also provides some of the best testing tooling I've used.
From the [official tutorial](http://www.webtoolkit.eu/wt/doc/tutorial/wt.html): root()-&gt;addWidget(new Wt::WText("Your name, please ? ")); nameEdit_ = new Wt::WLineEdit(root()); Wt::WPushButton *button = new Wt::WPushButton("Greet me.", root()); root()-&gt;addWidget(new Wt::WBreak()); greeting_ = new Wt::WText(root()); button-&gt;clicked().connect(this, &amp;HelloApplication::greet); ***FIVE*** times `new`! In six lines! You really don't need to look further. This is the kind of library that was written by incompetent people without a clue about API-design in C++. On the contrast cppcms (I don't know what you dislike about their website: It works which is sadly not something that can be said about a lot of websites these days): class chat : public cppcms::application { public: chat(cppcms::service &amp;srv) : cppcms::application(srv) { dispatcher().assign("/post",&amp;chat::post,this); dispatcher().assign("/get/(\\d+)",&amp;chat::get,this,1); } ... }; (Again: randomly chosen from the [tutorial](http://cppcms.com/wikipp/en/page/cppcms_1x_chat)) This is more or less how a good API should look. * It does not require tons of `new` and naked pointers (IIRC there were some rare situations where you needed them, but not nearly on the same level) * It works nice with common idioms like iteratos * It follows the stdlibs naming-conventions * … Seriously: `new` is worse than `goto` and yes, I am completely serious when I say that. (This doesn't say that there is **never** a place for it, as is true for `goto`, just not in normal code.)
Not easy at all but working in a better design is more rewarding than debugging. 
eh? JUnit looks like this `Assert.assertEquals("foo is bar", foo, bar);` or if you have the static import `assertEquals("foo is bar", foo, bar);`. You don't extend JUnit classes using JUnit.
Bad tutorial is bad. * Nothing was explained. It was pretty much "After this line, add this line. After this line, add this line". * For no reason, he started by adding a global variable to a window pointer. Yup, good ole bad practices. * Few people want to watch someone code in real time. The video would have been much more effective (and shorter) if the code was prewritten.
I don't think it is so much availability as it is polish. I've yet to use CLion so I can't speak to it. But I have used a lot of other C++ ides and while they may have all the "Autocomplete, syntax highlighting, etc" checkboxes, many of them feel incomplete/buggy/less than useful. Java, on the other hand, has really spectacular tooling/IDEs. The autocomplete/syntax highlighting/code helps/etc on java IDEs is really good (Netbeans is the one I use for work, but I've heard good things about Intellij as well). But that is just what I've seen. This opinion may be way out of date because it has been a couple of years since I've done anything major with C++.
Hi! Thanks for your reply! I have a question or two for you. * What's the big deal with const references over (const) pointers? I've seen the "use const references for inputs" before, but I don't really understand why you would do this as opposed to just using a const pointer * Why would I pass a vector / list of things around by value? I thought that involved a lot of unnecessary overhead. Your iterator code looks a bit scary, so I didn't implement it in [my updated version](https://gist.github.com/pipsqueaker/aba18e4e8a42226b4bab). I'll definitely take a look and try to understand it though. Thanks for taking the time to respond!
Not exactly what you asked for, but pretty close: http://liblfds.org/ It includes a multi-producer multi-consumer lock free queue.
Thank you! I didnt [end up implementing your std::pair suggestion](https://gist.github.com/pipsqueaker/aba18e4e8a42226b4bab), since in working w/ OpenGL I'm using a bunch of old-style functions which work by the output-pointer method, and I thought it would be best to keep it consistent. However this is a pretty beautiful feature that I didn't know about before, and I'll definitely try to use it in other C++ projects! One question- why did you get rid of my declaring `optimized_verts` as `new std::vector&lt;GLfloat&gt;()`? I actually didn't think there was a difference in the two declarations. EDIT: I just tried adding `-Wall -Wextra` to my compiler options and it looks like my IDE (CLion) just prints out the warnings for a split second and then moves to another view with no option to reset to the warning output. Is there a way I can make the `-Wall -Wextra` generate legitimate errors so that I can read the messages? 
The problem with trying to achieve this kind of model is that mathematical concepts rarely map well, at least in my experience, to inheritance. Now you could of course allocate everything on the heap &amp; use unique_ptr/shared_ptr everywhere for the ownership. That is a quick way to kill your performance of course; the JIT in Java can devirtualize &amp; the VM smarter about allocations whereas smart pointers in C++ are not quite so smart. Of course you could do `(*a) * (*b) * (*c)`. You could also make sure that you have a `const Matrix&amp;` or `Matrix&amp;` where you actually try to use said objects. My suggestion is that you make good use of templates instead. SparseMatrix can be a standalone type &amp; operations are just templates that operate on the underlying types (e.g. multiplication in SparseMatrix is a templated operator overload). Also, I would recommend you start with an existing C++ math library (e.g. eigen) instead of trying to roll your own unless you're just doing it as a learning experience. If it's a learning experience, looking at how eigen &amp; other libraries tackled these problems will be informative anyway.
Thanks! I'll definitely use the `-Wall -Wextra` thing, hopefully it helps me learn. The reason I'm not encapsulating the vertices is that OpenGL expects vertex data to be uploaded in a single continuous array of vertex attributes, so I just decided to use that standard everywhere, although it is a bit painful 
&gt; One of the key points there is that I should code to an interface as opposed to using the objects outright. **should** Also, in C++ the interface can be defined by the code only, thanks to templates. For instance all the containers (list, vector, etc...) obey the same `begin` / `end` interface without any hint of inheritance. But here, your code sounds much more Java-like than C++-like.
For some crazy reason **pointers to pointers** are a different beast for many beginners. It also doesn't help they are introduced coupled with dynamic memory management, for pure sadistic purposes. :)
Altough one could very easily write zero-cost abstractions on top of this (and I suspect there are homegrown ones in a lot of codebases). 
Yea I just started looking into shared_ptrs after I posted this. I didn't know there'd be that big of a performance hit. Good to know. This might be mathematical for this example, but there might come a time where it's valid even if it's not mathematical. If I dereference the pointer as is, won't it become the parent class object and cause some kinda core since it's purely virtual and core since nothing is really implemented yet? Won't const Matrix&amp; also end up with the parent Matrix object as well where I won't be calling SparseMatrix's implementation of the call? edit: By using Matrix as the object itself, I'm not really using RTTI anymore. I might've picked a bad example to test this out, but all I wanted to do was code to an interface in C++ and I ended up with this snag. And I cannot think of a way out of it.
For vim: - [vim-plug](https://github.com/junegunn/vim-plug) is a nice plugin manager: it has on demand plugin loading (based on filetype) and parallel updates/installs - As you mentioned, [YouCompleteMe](https://github.com/Valloric/YouCompleteMe) is really good. It takes some time to set up (separately for each of your projects), but the clang-based autocomplete is really nice - [ctrlp](https://github.com/kien/ctrlp.vim) is very nice for quick in-project navigation - [vim-easytags](https://github.com/xolox/vim-easytags) for auto-generating tags and ctags based syntax highlighting - [syntastic](https://github.com/scrooloose/syntastic) for on-the-fly syntax checking - [vim-fugitive](https://github.com/tpope/vim-fugitive) for git As an alternative, I really like QtCreator. Good syntax highlighting, clang based autocomplete and (on Linux) valgrind integration. It also has good CMake integration. 
Thanks! Will try those and report back😊 
I'm saying that your function manipulating Matrix should manipulate a Matrix_T with the interface that you deem reasonable (if it's good enough for Matrix* it's good enough for Matrix_T). If the function can infer the template type from the parameters you're good to go and else, you could always have a `using ConcreteMatrixType = SparseMatrix` somewhere for your instantiations... Of course, the difference being that it's completely done at compile time (but are there really places in your code where it might be instantiated as WholeMatrix ? Do you have some kind of plug-in architecture ? Do you need to store both SparseMatrices and WholeMatrices and OtherKindOfMatrices in a single container ?)
`s/OOP/Java/`
If you try to write Java in C++, you're only going to get frustrated. Design patterns are language-specific: they are techniques to work around the deficiencies of a particular language, language family or paradigm. There's merit in coding to an interface, but just because in Java you would do that with subtype polymorphism does not mean that the same technique is correct for C++. The more natural technique would be to use parametric polymorphism: parametrize your algorithm on the matrix type. If you want to ensure restriction to the interface you can then do so with a minimal exemplar type. If you really want to use subtype polymorphism the handle idiom would be appropriate here. You would however have to solve double dispatch, which is not an issue with parametric polymorphism. 
Yup, the last 2 posters kind of convinced me of the errors of my ways. I think they're both hinting at parametric polymorphism as the approach I should be taking as well! Thanks! 
Certainly. I've dabbled with intellij IDEs before and they are pretty nice. I have a lot of faith in them to do a good IDE for C++ because they are generally good at that sort of stuff. OTOH. I've constantly heard that QTCreator is pretty awesome, yet when I went to use it I really wasn't all that impressed. It just wasn't a smooth ride (I feel like Visual studios does a better job at C++ handling than QT creator, other than their slow adoption of C++11). This is just my impression though. I'll have to take CLion for a spin to see how good it is.
[C/C++ Development Environment for Emacs](http://tuhdo.github.io/c-ide.html) is a pretty long and thorough guide. It may or may not cover everything you need, though.
&gt; The idea of typing `foo.assertEqual(bar)` vs. the much more sane `assert foo == bar` of other Python testing modules The bonus of that pattern, or `assert_eq(foo, bar)`, is that the error message can print out the values of `foo` and `bar` rather than just saying "they weren't the same".
I've been spending the last days (among other things) with redoing my vim-config basically from scratch. You can find it here: https://github.com/Florianjw/vimrc (if you use the install.sh, backup everything you want to preserve before and delete the old .vim and .vimrc) (C++-relevant) plugins are: * YouCompleteMe (note that this makes syntastic redundant) * Gundo * fugitive * fugitive-blame * airline * taglist One huge advantage that vim has over almost every other text-editor is that it permits a very unique workflow: open two or three terminals navigate to the project in question and open the files you want to edit; whenever you feel the need for it, close vim, do, whatever it is that you want to do on the console directly, and reopen it. Since it starts very fast this works great. (May not be for everyone but I am very happy with that approach.) 
What did you dislike about Clion? 
You don't need syntastic with YCM. and you can add ultisnips and tagbar to your list.
[Here's the `unittest` module documentation](https://docs.python.org/3/library/unittest.html). Why does every example implement a class that inherits from `unittest.TestCase`? Why can't I just write free functions? (Free functions don't exist in Java, so I'm not surprised this isn't an option.) And the point about `assertEquals` is not about its specific form, it's that it exists at all. I should be able to write a standard assert, not call some method. Why do I need all this garbage: assertEqual(a, b) assertNotEqual(a, b) assertTrue(x) assertFalse(x) assertIs(a, b) assertIsNot(a, b) assertIsNone(x) assertIsNotNone(x) assertIn(a, b) assertNotIn(a, b) assertIsInstance(a, b) assertNotIsInstance(a, b) And before you can say "so that the test can print the expected and actual values", please see my comment elsewhere in the thread showing that a standard assert statement under a different testing framework is perfectly capable of this. This is what I mean about JUnit spreading its pestilence.
I guess that applies more to languages (like Java) that can't do quite as much language manipulation. If you call `unitTestAssertMakeThisLongToMakeItObviousThatThisIsJava(foo == bar)`, all the function gets is `true` or `false`.
If you want to pass an array as an array, declare your function as taking a reference to an array, which looks like `int (&amp; arr)[3]` (in English: arr is a reference to an array of 3 ints). If you want to pass an array as a pointer (triggering decay), declare your function as taking a pointer, which looks like `int * ptr`. What I'm saying is, never declare a function as taking an array by value, because if you take `int meow[3]` or `int meow[]`, the compiler *immediately rewrites* that to `int * meow`, which is unnecessarily surprising. &gt; From what I've read a c-style array is just a pointer to its first element You have been misinformed (this is a common point of confusion). Arrays and pointers are different things, but arrays can be easily converted to pointers (to their first elements); this process is known as decay. &gt; You say that I'm passing length as a const pointer. No, I said "Good work passing length by const value." Taking `const int length` is good, because it prevents you from accidentally modifying `length` within the function. Taking `int length` makes no difference to whoever's calling your function, but within the function, `length` can be modified, which is usually undesirable. &gt; What's the difference between an "owning raw pointer" and a plain old pointer? A raw pointer is owning if you have to say `delete ptr`, `delete[] ptr`, `free(ptr)`, or something like that eventually. It's non-owning if the lifetime of what you're pointing to is controlled by somebody else. &gt; You say I'm leaking optimized_verts, but all I can see that I did was initialize it as a vector and append elements to it. What do you mean? As a silly analogy, imagine that whenever you say `new Something(args)`, you're borrowing money from the mob. When you say `delete ptr`, you're returning the money. With the mob, if you forget to return the money, they break your kneecaps. In C++, if you forget to delete allocated objects, you leak memory (i.e. permanently wasted, until the process terminates). Good lessons to learn from this are: don't borrow money from the mob unless you really have to, and then be really careful with it. In C++ that means avoid dynamically allocating memory (new/delete) unless you really have to, and then be really careful with it (i.e. get vector, shared_ptr, unique_ptr, etc. to manage it for you). The leak happens because main() says `std::vector&lt;GLfloat&gt; * optimized_verts = new std::vector&lt;GLfloat&gt;();` and never deletes it, or calls anything that deletes it. The only delete in your original code was `if (cleanup) { delete vertex_source;}`, but (1) cleanup defaults to false and you weren't passing true, and (2) that's deleting vertex_source, but you were passing optimized_verts as vertex_out. I'm afraid I'm not familiar with good beginner resources (I learned in the 2002-2004 era, in a really strange way). I hear C++ Primer, Fifth Edition (*not* C++ Primer Plus) is good, and I have a copy on my bookshelf, but I haven't read it. I've thought about writing my own, but it would be so time-consuming and I already have a day job.
So if I had declared optimized_verts as `std::vector&lt;GLfloat&gt; * optimized_verts;` the pointer would be deleted when it went out of scope, and the vector's memory freed? Also, don't all non-owning pointers have to become owning at some level of the program? If C++ doesn't have a garbage collector, then memory has to be managed explicitly by the coder eventually, right?
&gt; So if I had declared optimized_verts as std::vector&lt;GLfloat&gt; * optimized_verts; the pointer would be deleted when it went out of scope, and the vector's memory freed? There's a couple points of confusion here. First, local variables are destroyed when they go out of scope, but destroying a raw pointer doesn't delete what it points to (if anything). Second, if you have an uninitialized raw pointer as a local variable, it contains a garbage address (not guaranteed null), and it definitely doesn't point to a vector. &gt; Also, don't all non-owning pointers have to become owning at some level of the program? No. Consider: int x = 1729; int * p = &amp;x; // p is a non-owning raw pointer &gt; If C++ doesn't have a garbage collector, then memory has to be managed explicitly by the coder eventually, right? In modern C++, memory and other resources are managed *automatically*, with as little manual involvement as possible. This is what makes garbage collection unnecessary (and indeed harmful). For example, if you have a `vector&lt;int&gt; v = { 11, 22, 33 };` then `v` owns dynamically allocated memory. When `v` is destroyed, the memory it points to is destroyed - automatically.
I have an YCM fork specially targetted for C++: https://github.com/oblitum/YouCompleteMe My dotfiles: https://github.com/oblitum/dotfiles
&gt;optional&lt;T&amp;&gt; is specialized Didn'tknow that, thanks!
It was a selling point only in the 16-bit era, though I don't think STL is that old. For the difference between 31 and 32 bits for counting is relevant only if you're regularly dealing with vectors of chars -- with any other element type you'll be out of virtual memory space long before you reach the count of 2**31. 
Great implementation, I'm using this in production right now on a video transcoding platform. 
&gt;&gt;name mangling, inlining, exceptions, templates, standard changes in this case... &gt;There's no less reason to have a C++ ABI than a C ABI. How about the above? There are reasons why diversity is good. &gt;"Universal CRT", which moves the C and C++ libraries over to being part of the OS I think you need to be able to see past the marketing. This makes the CRT version shipped with VS part of the OS. Msvcrt.dll, the C runtime, has been part of the system since forever. Interestingly (or perhaps not), that's the version mingw uses. Universal CRT will merely dispose off the need to deploy VC merge modules (or the redistributable), uh oh big deal. The deal with the Universal CRT is more a clean(er) slate than anything else IMO. The pain Microsoft developers endured in the past was caused by incompetence morethan anything else. It is only noobs who do not understand how stuff is deployed. Well, tough for them. For those who know, many (all) version-related questions are a done deal. Having an ABI is by no means a better solution (as we see here) Having a "system" version of the runtime is a poor idea, because... why C and C++, and not all other languages?! Neither C nor C++ are special.
&gt; I'm using a bunch of old-style functions which work by the output-pointer method, and I thought it would be best to keep it consistent. That's understandable. When dealing with C libraries in C++, it's purely a design choice as to how you interact with them. I would still encourage you to consider using move semantics when writing your own routines, though. &gt;why did you get rid of my declaring optimized_verts as new std::vector&lt;GLfloat&gt;()? I actually didn't think there was a difference in the two declarations. The difference between the two declarations represents the two opposite ends of the C++ memory model. Let's say you have a simple class with a few simple data members. struct Foo { int i,j,k; float u,v,w; char name[10]; }; Then in `main` you write Foo f; Foo *f2 = new Foo(); The first line declares an instance of `Foo` on the *stack* and all of the member variables reside on the stack, as well (exactly how much space it requires is compiler- and system-dependent). The second line declares a *pointer* to a `Foo`. The pointer resides on the stack, but the thing to which it points resides on the heap (aka the free store). As you are well aware, the second form requires you to `delete` the pointer, but the first form will use RAII to clean itself up. So, how does this apply to a `std::vector`? A `std::vector` is what is called a resource handle. That is, it looks a bit like this template &lt;typename T&gt; class my_vector { size_t size, capacity; T *data_start, *data_end; }; The two pointers keep track of the data owned by the vector. That data is *always* located on the heap. When you declare an instance of `my_vector` on the stack like so my_vector&lt;int&gt; vi; only the four variables are located on the stack. When the object goes out of scope, RAII kicks in and `delete`s the data from the heap for you. When you declare a pointer to a `my_vector` like so my_vector&lt;int&gt; *vi = new my_vector&lt;int&gt;(); *all* of the variables inside the class are located on the heap and you get no RAII cleanup (the destructor is only called when you `delete` the pointer). &gt;Is there a way I can make the -Wall -Wextra generate legitimate errors so that I can read the messages? Adding the `-Werror` flag converts warnings into errors. In gcc, the `-Wfatal-errors` switch forces compilation to stop after the first error. Combining the two will force compilation to stop after the first warning. That should allow you to see the messages.
Will take a look, thank you!
&gt; Which to me translate to implementing towards a purely abstract class in C++, not sure how true that is It is true. &gt; As with your example, I'm not sure who makes sure begin or end is enforced for those std containers or if I want to create my own container. The users of these classes. You can write tests that respond to your interface however to validate them. There is also a C++ feature to allow for this, Concepts, but it's still on the works. &gt; If that is ever successful, I was going to start thinking about how to say produce a plug-in like architecture that takes advantage of me coding towards an interface using RTTI. It then would allow me to instantiate variations of Matrix implementations, pass that into the object using it and still produce the same result. It's a good use of interfaces then! &gt; If that is also successful, then I can say ooo this is what they mean by coding towards an interface, and I can say yup, I totally get how badass it can be. Just don't put it on top of your "how to implement my software idea in C++" list of stuff :p 
why raw malloc over new/delete? So you can realloc?
A smart guy once said: OOP in C++ means "object ownership protocols". Your protocol here is: caller of ::times is the owner of the result. These days, simplest C++ tool for that is unique\_ptr, and it looks like it would work in the "a times b times c" example. You also should apply the same to your calls to operator new, that is, always use unique ptr on the left. Without that, your code does not offer basic exception safety, e.g. a can be leaked if operator new or SparseMatrix fail when constructing b. Finally, to simplify such coding, you have make\_unique. So your code could in the end be: Auto a(make_unique&lt;SparesMatrix&gt;(); auto b(make_unique&lt;SparseMatrix&gt;(); // etc. auto d = a-&gt;times(*b-&gt;times(*c)); But the other aspect is what other people said: template-based polimorphism seems to be a better idea in your case.
This one looks pretty good thanks! I'll give it a go. 
Take a look at https://github.com/BartoszMilewski/Okasaki This is by Bartosz Milewski. He has some nice articles about functional programming in c++. Here is an article where he talks about a functional list http://bartoszmilewski.com/2013/11/13/functional-data-structures-in-c-lists/
Boost.Serialization if you have access to boost. (Which you should because in my opinion boost is de facto standard) 
This seems really awesome, but it also seems fairly windows/gnu centric from what I can tell by glancing at github and the source. I have to say though, there is a lot of good stuff there. He gets a thread id by taking the address of a thread local static. Why not use the hash of the C++11 thread_id? Anyone know?
This link from this same thread: https://github.com/cameron314/concurrentqueue says that both boost and Intel's concurrent queues require trivial copy constructors, and Intel's is not lock free. 
https://en.m.wikipedia.org/wiki/Persistent_data_structure
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Persistent data structure**](https://en.wikipedia.org/wiki/Persistent%20data%20structure): [](#sfw) --- &gt; &gt;In [computing](https://en.wikipedia.org/wiki/Computing), a __persistent data structure__ is a [data structure](https://en.wikipedia.org/wiki/Data_structure) that always preserves the previous version of itself when it is modified. Such data structures are effectively [immutable](https://en.wikipedia.org/wiki/Immutable_object), as their operations do not (visibly) update the structure in-place, but instead always yield a new updated structure. &gt;A data structure is partially persistent if all versions can be accessed but only the newest version can be modified. The data structure is fully persistent if every version can be both accessed and modified. If there is also a meld or merge operation that can create a new version from two previous versions, the data structure is called confluently persistent. Structures that are not persistent are called [ephemeral](https://en.wikipedia.org/wiki/Ephemeral_(disambiguation\)). &gt;These types of data structures are particularly common in [logical](https://en.wikipedia.org/wiki/Logic_programming) and [functional programming](https://en.wikipedia.org/wiki/Functional_programming), and in a [purely functional](https://en.wikipedia.org/wiki/Purely_functional) program all data is immutable, so all data structures are automatically fully persistent. Persistent data structures can also be created using in-place updating of data and these may, in general, use less time or storage space than their purely functional counterparts. &gt;==== &gt;[**Image**](https://i.imgur.com/5yZLKJh.png) [^(i)](https://commons.wikimedia.org/wiki/File:Purely_functional_tree_before.svg) --- ^Relevant: [^Hash ^tree ^\(persistent ^data ^structure)](https://en.wikipedia.org/wiki/Hash_tree_\(persistent_data_structure\)) ^| [^I/O ^request ^packet](https://en.wikipedia.org/wiki/I/O_request_packet) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cskfrai) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cskfrai)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](/r/autowikibot/wiki/index) ^| [^Mods](/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Call ^Me](/r/autowikibot/comments/1ux484/ask_wikibot/)
If you don't find what you are looking for, you might be able to make something by wrapping what you need around sqllite3.
Only one l in SQLite ;)
I can't see anything wrong with this program as you've written it, though I wonder why the head pointer is scoped to getHead rather than just being a private class member, which would make the pointer-reference-returning gymnastics you're performing here unnecessary. The only mildly dangerous part of this is the static_cast: as you've written it it's safe, but if you or anyone else came along later and created a list of something not a subtype of the list class, it would invoke undefined behavior (?) and then break.
His second link is an article about implementing a persistent data structure in an imperative language
&gt;As an aside, while the difference between struct and class doesn't amount to much, it is still needlessly cute to define a class in C++ using struct. Why? I always use `struct`.
+1. We are using a non-intrusive variant of this in production. Technically not lock-free, but it's simple, fast and doesn't require fancy memory management. 
The persistent data structures are in the functional programming sense not the in disk sense
For consistency's sake, I always use `struct` because I almost always want public inheritance and always want my public interface declared first. What does `class` bring to the table other than a keyword that people cling to for no _real/technical_ reason?
Just a small note: Wt is inspired by Qt, which also uses this new infested coding convention, so to speak. I find it repulsive BTW, but Qt at least has a historical excuse (compilers back then, etc etc).
I also used to mix them (with slightly different connotations) and changed for the sake of consistency (which one for incomplete types? which one for types that only exist for TMP?). I just picked `struct` instead :) If its for the sake of coworkers, maybe its for the best, but I think there are good reasons to prefer `struct`: the following cases are all simpler with `struct`: aggregates with all public members; the standard's style of listing all public members before all private members in a class; cases like `struct Foo : std::integral_constant&lt;bool, ...&gt; {};`, etc. There was a little discussion on this [here](https://www.reddit.com/r/cpp/comments/37v40y/what_is_a_good_rule_of_thumb_on_when_to_use_a/) too, with both sides represented.
Apparently I missed the bus on what was meant by persistent data structures. 
This is a well known algorithm and is likely used by many other games. It is also a valid algorithm if you also count rays that pass tangent to the polygon as either a zero crossings or two crossings.
I have probably walked into something I don't properly understand, but I think of the point as an entity which it might well stand for anyway (I don't properly understand C++ and games programming). Does this rule apply only to external walls or all walls? As if I have a square and then I also put a wall going from the north face of the square to the south face splitting the square in half and the point is placed in the right section, then surely the point crosses 2 walls but is still inside? Or have I got the wrong end of the stick with this whole algorithm?
CppCms has really shitty const-correctness. Query functions are non-const so that objects you'd like to be const, and should be const, cannot be.
Do you know what a polygon is? 
I can't imagine what restrictions you are referring to within Eclipse. Eclipse doesn't restrict you to any build system at all; it will heuristically resolve your includes for indexing purposes, and can be configured to launch any build command you want. It doesn't require any particular project layout either. I've done head to head testing of many of the IDE's and vim plugins mentioned, and Eclipse's indexing is the best: best combination of accuracy, performance, and minimal specification/setup required. CLion and QtCreator are both highly inaccurate; CLion in particular. Whenever someone cites CLion, I immediately question whether they have actually used it on complex code, its indexing is that bad. That said, it has the nicest interface and usability, and I suspect in a year or two, CLion will be the IDE to beat. Most clang based solutions have performance issues, as well as often requiring a complete and accurate compile_commands.json at all times to index. Vim and emacs have ok clang based solutions. YouCompleteMe does not touch Eclipse, or even QtCreator or CLion in terms of features, though it is more accurate than the later two. Emacs has rtags (clang based), which is probably the most sophisticated C++ IDE you can run in a terminal, period. If you aren't terminal restricted though, I still don't recommend it: it still lacks some features compared to Eclipse, far fewer man hours going into improving it and fixing bugs, much harder to setup. Since you mention syntax highlighting: Eclipse also has the most powerful syntax highlighting of anything I've ever used. It distinguishes read and write occurrences of variables, globals, macros, methods, data members, locals, function parameters, static methods, static variables, namespaces, types, template parameters, and more. It also has a very active community and constant releases. The latest version (Mars) came out a few days ago, and it continues to improve. Git support is excellent. Usability is excellent because Eclipse has the best Vim plugin around, better in some ways than Vim itself. It's not the best looking IDE, but if the point is getting things done and you're not restricted to a terminal, it's just unbeatable. I suggest actually pulling up multiple IDEs on the same or a subset of your codebase. See which ones static analyzers give you the most false positives. See which go to definition, or go to type fails the most often. See which ones give you accurate type hierarchies. I've already done this for myself on multiple codebases, and Eclipse is very dominant.
I've been wanting to fully move towards using Rule of Zero for some time now but as I primarily use Visual Studio for my development needs I haven't quite been able to do so until this week... Why? Because pre VS2015 move constructors and operators weren't being automatically created by the compiler... Edit: Also wrote a similar class that could handle polymorphism once... Was planning on using it in a project but after I finished I realised I could rewrite it in another way that removed its need... Code [here](http://pastebin.com/LE6HSeq5) if anyone is interested... It uses boost::any as the actual holder of the item but all access happens trough a cached pointer... Edit2: Just gotta add that after looking at my implementation of value_ptr again it isn't actually currently working. It's pretty easy to fix and it doesn't have some basic functionality that should have been there... Thats what you get for sharing something that you stopped working on when you realized you didn't actually need it... 
Thanks.
Got any book you could recommend me that would allow me to learn C++ from the beginning without getting bored out of my mind? I had a python book that allowed me to work through it and by the end I would have a working game. Was very informative and fun at the same time.
This is the typical low quality self-promoting fodder this submitter is known for - in short he's just trying to drive traffic to his site. As an example take a look at his previous spam related to command line arg parsing using boost: https://www.reddit.com/r/cpp/comments/37n5di/c_parsing_command_line_arguments_with_boost/crp8mj7
This is the typical low quality self-promoting fodder this submitter is known for - in short he's just trying to drive traffic to his site. As an example take a look at his previous spam related to command line arg parsing using boost: https://www.reddit.com/r/cpp/comments/37n5di/c_parsing_command_line_arguments_with_boost/crp8mj7 
perhaps it was to avoid the gymnastics of writing the definition of a static template class member variable =) It's a snippet gleaned straight from a lecture on TMP @ Digipen https://youtu.be/dyHWVQE3Oo4?t=18m20s. It's cool, but esoteric and prior to what /u/scatters said, I didn't know C++ made any guarantees about node construction like in the example.
VS 2013 didn't automatically generate moves, and didn't allow defaulted moves. VS 2015 does both, following the Standard.
Sorry, I missed the "pre" in the original post.
Just curious, why did you use a bare union instead of a boost variant?
It's a pretty broad convention. It's the google style guide convention, the llvm style is similar, the most common answer here: http://stackoverflow.com/questions/54585/when-should-you-use-a-class-vs-a-struct-in-c. 
There's one problem with applying "rule of zero" and letting the compiler generate all your special member functions: it (sometimes) doesn't give you strong exception safety. The strong exception safety guarantee says that an operation either succeeds or does nothing: if an exception is thrown, the objects involved are left in their original state. This isn't always possible or desirable, but providing it where you can makes reasoning about your code easier. Suppose you have two classes, Cat and Dog, each of which has nontrivial copy operations that might throw, but which provide the strong guarantee. Now you make a composite class that has one of each: class Zoo: public: // all special members auto-generated private: Cat c; Dog d; }; The problem here is the copy assignment operator. Zoo's auto-generated one will look like this: Zoo&amp; operator=(const Zoo&amp; z) { c = z.c; d = z.d; return *this; } If Cat's copy succeeds but Dog's throws, the Zoo object that was the target of the assignment is left in a partially updated state. Not necessarily an illegal state, but not one that matches either its state before the operation or its intended state after. The usual way to fix this is the copy-and-swap idiom, but the compiler won't do that for you; if you want a strongly exception safe copy assignment operator, you have to write it yourself. That means you also have to declare the move constructor and move assignment operator (although you can just =default those), since a user defined assignment operator suppresses both of those. (I have a vague memory they might be planning to change that rule in C++17, but I'm not sure about that.)
Doxygen is indispensable but I really wish they would test their html on mobile devices. I'm on Android/chrome ATM and I cant pinch zoom or scroll their site at all.
Memory. On a 64-bit architecture, the bare union with the rolled-in tagging mechanism uses 24 bytes, an equivalent Boost variant would use 32 bytes.
There are many reasons why you might want a pointer. The most common is polymorphism. Another is performance reasons. Another is to reclaim the memory from the object when it's not needed any more.
[Breathe](http://breathe.readthedocs.org/en/latest/) with [Bootstrap Theme](https://ryan-roemer.github.io/sphinx-bootstrap-theme/) is a nice mobile-friendly alternative to Doxygen's HTML output.
[My original response to @CPPOldie](https://www.reddit.com/r/cpp/comments/37n5di/c_parsing_command_line_arguments_with_boost/crobkih).
I still not sure I understand the desire to retrofit this on top of unique_ptr. It doesn't seem too complicated to just write your own: template &lt;typename T&gt; class copying_ptr { copying_ptr() = default; explicit copying_ptr(T* ptr) noexcept: _ptr{ptr} {} ~copying_ptr() { delete _ptr; } copying_ptr(const copying_ptr&amp; o) : _ptr{new T{*o._ptr}} {} copying_ptr(copying_ptr&amp;&amp; o) noexcept : _ptr{o._ptr} {o._ptr = nullptr; } copying_ptr&amp; operator=(const copying_ptr&amp;o) { copying_ptr tmp{o}; *this = std::move(tmp); return *this; } copying_ptr&amp; operator=(copying_ptr&amp;&amp; o) noexcept { std::swap(_ptr, o._ptr); return *this; } private: T* _ptr = nullptr; }; template &lt;typename T, typename ... Args&gt; auto make_copying_ptr(Args&amp;&amp; args) { return copying_ptr&lt;T&gt;(new T{std::forward&lt;Args&gt;(args)...}); } Sure the general guideline is to avoid new/delete in regular code. When you're writing a vocabulary type like this though, that kind of goes out the window.
Great! It shouldn't be necessary to write a swap at all, the default swap implementation will just call the move constructor and move assignment which are already defined elsewhere, so I don't see an issue. Am I missing something? I tend to avoid defining custom swap functions. 
Oh, I hadn't noticed std::swap() had been updated to use move instead of copy. Thanks.
I can't handle CLion's responsiveness (or lack thereof) after using either QtCreator or vim. But you're right, basing an IDE or editor on the LLVM tools would be really nice.
I assume you mean [Eclipse IDE for C/C++ Developers](http://www.eclipse.org/downloads/packages/eclipse-ide-cc-developers/marsr)? Any other plugins you use or is it just the default bundle? I really really liked Eclipse for Java development (university and small projects for myself and a company I interned for). Never had the chance to use it professionally because I got into C# and then C++ after university. I've tried Eclipse CDT maybe 2 times at work and it didn't really 'click' for me. I had a CMake project which compiled fine in VS and on my Debian build VM but I ran into problems with Eclipse CDT and MinGW; but I think those weren't Eclipse related. Some issue with MinGW (STL's distro), boost and our code base. I've primarily looking for an IDE for spare time projects and I resently switched to Ubuntu so I will definitely give Eclipse another try (downloading it right now).
The price tag. I'm looking into alternatives for personal projects; but those are silly and not open-source so I don't want to invest money into an IDE (for now).
See [my other comment:)](https://www.reddit.com/r/cpp/comments/3b8o8i/so_atom_10_just_got_released_what_are_your/cslp2yk)
The blog post has been updated, please let me know if there's something you don't like, or something inaccurate. Thanks again for your comment, I think it really helped improve the post. Maybe the "new" rule of zero will catch on!
IMHO it's a bit shameful that they're already charging for CLion, when it's quite clearly inferior to more than one existing IDE that are free. Now pycharm, I would gladly pay for if there weren't a community edition.
When it's illegal not to use it.
There are a couple of plugins I use. The main one is vrapper, which is a vim emulator. It's a really fantastic emulator: macros, bookmarks, block visual mode, integration with system clipboard, etc. The git plugin comes with and is nice. Bracketeer is very nice, it shows you what closing braces are actually closing for long blocks. That's basically all though. I know what you mean about it not clicking. When I first started at my job, Eclipse was the most common IDE. After a couple of months, I couldn't believe this was the best option. It felt slow and clunky to index, not very intuitive, etc. I tried many other IDEs, and they all fell even more short. So I invested more time in Eclipse, and it really pays off. We use a home rolled build system at my work, I simply set eclipse to run the same command that I run from the console to build. Eclipse pops up a console and builds. If there are build or unit test errors, I get clickable links in the console that take me to the source, and the problems get marked in the files. Eclipse has really been improving consistently. Whenever I open a project in Eclipse, because Eclipse's static analyzer (CODAN) tries to be quite rigorous, I see some supposed errors. If I know the code compiles, these are false positives. I've seen the number of false positives decrease with each iteration. With Mars, I see Eclipse index complicated source files thousands of lines long without a single false positive. But if you call a function with the wrong number or type of arguments, or a non-const method on a const reference, it will catch it as you're typing. The performance has improved too, on my project at work Eclipse uses 2 gigs of ram (even though I allow the JVM to use more), whereas QT creator uses 3. Just to dispel the myth that Eclipse is such a resource hog. 
This isn't the right sub for that. You should ask this on [r/cpp_questions](http://www.reddit.com/r/cpp_questions).
Actually, doing unnecesary file operations is generally slower than an extra buffer copy.
I doubt there's a timeline. Does `[NSThread threadDictionary]` provide something for what you're looking for? Also I think __thread works on OSX. You probably can also use the POSIX API via pthread_setspecific/pthread_getspecific
I'm using strictly standards-only C++ 11/14, so no NSThread. I'll try out __thread and if it works, isolate it so I can easily replace it when (better not be "if"!) thread_local gets support. *Edit: Well drat. `__thread` only supports trivial POD types and I need a thread-local `std::unordered_map`.*
 __thread std::unordered_map&lt;X, Y&gt; *m; if (m == nullptr) { m = new std::unordered_map&lt;X, Y&gt;(); }
Usually if you are writing polymorphic objects you think you'll be interested in copying, you add a clone method that returns a copy of the object (by value or by pointer). You would use this clone method in the functor that you would templatize copyer on. This is in fact exactly what boost::any itself does internally (use the clone method to make copies). The meat of boost::any is, well, the fact that you can store anything. Because boost::any fully erases the type, you can e.g. have an array of totally unrelated objects, stored in boost::any.
Burying a static in a function is a common trick because it avoids the static initialization order problem. It's talked about in one of Scott Meyers books. The first one, I think, Effective C++
I've kinda sworn off boost, after an initial torrid affair. :) I'm going to make a stub allocator that just aliases to std::allocator for the time-being so I'll be able to simply plug in mine once there's support from Apple for thread_local. The use-case is that I'm going to have a lot of threads constantly allocating and deallocating little fragments of memory darn near constantly (it's for a stochastic goal solver for autonomous AIs) where work units can get shifted from thread to thread, so I wanted to write a custom allocator that uses a static thread-local map of freelists stored in a base class (keyed by size in bytes). Without thread-local storage I'd have to wrap each access in a mutex and that would just be bad news.
I was hoping to be able to stick with standard-form allocators so I can pass those into the standard containers and make_shared(), and thread_local would make that extremely simple. I've learned the hard way that complexity is the enemy.
Ugh. Apple. Just... ugh.
Even then, an instantiation does not create a class, it is a term for creating an object as an instance of the class. Similarly, abstract classes are not instantiation - that does even make sense. Abstract classes are not instantiable. I cannot be bothered to read further as the first two relationships are clearly wrong. I strongly advise anyone attempting to learn OOP to look away.
So why not just use the Homebrew clang then? I understand that that’s a bit annoying as a requirement for other people to compile your code but in the end you’re simply requiring a conforming C++11 compiler (with hints of how to get one easily for Mac), which isn’t too much to ask nowadays.
&gt; I've kinda sworn off boost, after an initial torrid affair. :) Back up here. Using modern C++ without Boost is madness. You don’t have to use *all* the libraries (nobody does, almost certainly) but using *none* of them is almost certainly a mistake, especially when you have complete control over the project (as you seem to have). Boost simply offers some of the most high quality, general purpose libraries for C++.
You can have a __thread std::aligned_storage big enough for an std::unordered_map and use the [nifty counter technique](https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms/Nifty_Counter) with thread local counter to call placement new and the destructor respectively. That doesn't leak, ensures a well-defined initialization and destruction, and I have used it many times, e.g. in my temporary_allocator here: https://github.com/foonathan/memory/blob/master/src/temporary_allocator.cpp
Ah... Thought you meant adding requirements for the types that uses it... But yeah that does make sense and I guess the case where you can't add something like that would be very rare. &gt;The meat of boost::any is, well, the fact that you can store anything. Kinda what I was saying except I'd argue that it's storing and copying... Because if you only needed storing the implementation would basically be a void pointer with a type_info... Edit: Just gotta add that after looking at my implementation of value_ptr again it isn't actually currently working. It's pretty easy to fix and it doesn't have some basic functionality that should have been there... Thats what you get for sharing something that you stopped working on when you realized you didn't actually need it... That doesn't mean that the point I have been arguing is wrong though...
That can be difficult/impossible to actually do correctly/robustly. I only proposed it as a possible solution in case it's OK to leak (e.g. the number of threads never changes until the program dies). You can try using boost's TLS but unless you're using boost threads, you *may* be SOL. There's not a whole lot of guidance to what conditions it works under.
Have you explored the pthread API for this? __thread std::unordered_map&lt;X, Y&gt; *m; pthread_cleanup_push([](void *x) { delete reinterpret_cast&lt;std::unordered_map&lt;X, Y&gt; *&gt;(m); }, m);
This was around since C95, everyone knows about it.
I had a use case for a compact "cache-friendly" map with LRU characteristics, ie keep the least recently used ones in cache. I implemented a vector-based splay tree that worked wonders.
With boost::any, you also get any_cast which using dynamic_cast internally to perform a safe (run time checked) cast to the object in question. Much better than void pointer. If you put something in boost::any, you are always erasing the type, and you will basically always any_cast it to use it. You use boost::any when you want type erasure, you may also need to copy it, you may not, but you always want type erasure. Our solutions are also doing two very different things. Your solution solves polymorphic copy when a clone is not provided, but that's all it does. My example is about altering or even creating (in this case of unique_ptr) copying behavior. The only place they intersect is for polymorphic copying. In that case, I would use my solution when clone was available (on the grounds of simplicity, and avoiding a redundant pointer), and yours when it wasn't.
This is the solution I'm leaning towards, if it'll run with XCode. I'd rather not write a bunch of workaround code I'll just be deleting later when thread_local gets support again.
&gt; With boost::any, you also get any_cast which using dynamic_cast internally to perform a safe (run time checked) cast to the object in question. No it doesn't... It does a comparison check between the type_infos and then does a static_cast. Which is why I wrote void pointer **and** type_info. &gt; My example is about altering or even creating (in this case of unique_ptr) copying behavior. And the problem is that it isn't actually creating correct copying behaviour for any use of unique_ptr. Which is fine as long as you make it clear. And now that I read it again I do see you do make this clear when talking about DeepCopyPointer so that's good. Did I miss it the first time or did you add it afterwards? ^(Not meant in an aggressive way just want to know if I was blind or not)
I think the next thing I'm going to try is to recompile Clang. I'd very much like to stick with non-platform-specific C++ since I'll be wanting this thing I'm writing to eventually be compilable on both Linux and Windows as well as Mac.
I didn't know either. I feel while many people don't know about the complete standard library, many devs, especially beginners, ignores &lt;algorithm&gt; (exemple: [std::next_permutation](http://en.cppreference.com/w/cpp/algorithm/next_permutation) to create permutations). It's not as needed as &lt;vector&gt;, but it can help quite a lot when the time comes.
Correct you are, I could have sworn it was dynamic. Seems like there's a different boost container I was thinking of. void pointers and type_info are much worse for two reasons: first, you're much more likely to mess something up carrying around naked void pointers. Second, type_info is implementation defined, requires RTTI to be enabled, etc, generally a much worse mechanism than using templates. Anyhow, I think we've agreed as much as we're going to on boost::any. I think it's a great solution when you need type erasure, I would almost never use it otherwise. My solutions are templated on the contained type, which is preferable if you don't need type erasure. Correct copying behavior for a polymorphic class that a) you don't control and b) doesn't have clone, is a very interesting edge case I'll keep in mind, so thank you for that. I did not change those parts. I think it's clear in multiple places that the copying behavior is non polymorphic, and that the whole point of copyer is just to remove boilerplate and allow classes to easily redefine copying behavior of their members, not to provide a new pointer type with universally correct copying semantics.
&gt; a keyword that people cling to for no real/technical reason? I think it is unfair to discount convention; every project and team will build up their conventions as it helps teams communicate and get the work done more consistently and faster. As for technical reasons, I like to use class because the defaults are more restrictive. When I mess up somewhere, the compiler tells me a base class or method is inaccessible. The compiler won't tell me if I forgot to make a field private when using struct. I will use struct for POD types, containers of pure data, and (pre C++11) function objects (code is data!), or anywhere it is strictly required (usually headers designed to be fully compatible with C). Obviously, there are easy ways to make things public that shouldn't be, but I try to design my code so that mistakes are caught as early as possible, preferably by the compiler. Using class is an easy and low impact, though not foolproof, way to catch some issues early. 
Some people were born after that
That's what I assumed. Personally, I think using boost is an easier proposition than having to compile the compiler myself but that's just my preference. Something else to keep in mind is that I'm pretty sure you'll be unable to take this approach with iOS. Something else to keep in mind. In my experience, having written quite a bit of cross-platform code, aside from the most trivial of applications, platform-specific code is inevitable. Trying to avoid it at all costs instead of planning for it ahead of time can lead to some ridiculous contortions. My recommendation is abstract the pieces that are platform-specific behind sensible generic APIs. For example, I might provide generic_tls.cpp and darwin_tls.cpp. Then generic_tls.cpp gets compiled for all platforms but OSX/iOS. There's a single platform_tls.h header that defines the interface I want it to have. Of course, I'm using TLS as a place-holder. You typically want to do it at a slightly higher-level than this so you can make the optimal decision for this platform. For example, if the unordered_map is a cache of some kind, I might use libdispatch to synchronize a thread-safe cache on OSX/iOS &amp; mutexes for Linux. On Windows I might use a thread_local implementation if I felt that was the best performing mechanism on that platform. I would use CMake as the build system to make managing all of this easier.
I see what you're saying. I'm not claiming that copying is not an important part of any, just that it's not the most important part. The current implementation of boost::any is still cleaner and uses less space than what you're proposing, ignoring the copying issue. Sure, it is partial type erasure. When it comes to type erasure you want to erase as little of the type you need to, to keep as much of the type safety system as you can. I prefer partial type erasure to total type erasure.
Since you're using CMake, emacs + irony + cpputils-cmake is an awesome combination. Automagic clang-based code completion (with company-irony) and syntax/error checking (with flycheck-irony).
Thread locals are globals, and globals are a code obfuscation technique. :-)
I am simply questioning the usefulness of picking a random old library function for a reddit post. It's not like it's std::invoke or std::void_t. What next, "Hey, have you ever heard of strcspn?"
This particular project is a world-agnostic AI system I've been hammering away at since 2005 (started out in C99 of all places). After a decade my programming skills have finally matured to the point where I think I can finally pull it off. Since it's an AI framework, it doesn't have to deal with any system-specific pieces, not since threading was added as part of the C++ standard library. Except for this `thread_local` nonsense. (I'm not targeting iOS or any other mobile platform -- the CPU usage it will incur makes it useless for small battery-powered devices. I'm going full many-cores pc-master-race with this one. :) )
I think an ok article, a decent brief summary of some the issues surrounding c++'s evolution in the modern space. I think that anyone who is interested in this topic should view Herb Sutter's talk: https://channel9.msdn.com/posts/C-and-Beyond-2011-Herb-Sutter-Why-C. Herb gets into many more details, uses a lot of hard data.
The C++ 11 or 14 mandatory new Boost libraries pay far more attention to the problems you mention. They also are, to date anyway, completely standalone from Boost and only require the C++ 11/14 STL. That modularity may change in the future, but for now it's great to be able to just drop in a single header file and get to work.
Static thread locals are not globals.
Oops, missed the defaulted move assignment. Looks like I'm a little behind the curve on the utility of "unified assignment operator" since I last read about it, got some interesting hits with google. Well, luckily I never got around to actually using it myself. :)
I agree with "utf-8 everywhere" but I have found myself having to use wchar_t, wstring, etc for Windows GUI code that interfaces with my cross-platform (utf-8) code.
!! Holy heck. I'll check those out.
Really. Any time I see someone ask what a good language to learn is, most of the time I see either: a) C++ b) Java or c) Python. Sure, C++ isn't quite the "top dog", but I get tired of seeing entire articles written out to make it seem like C++ had disappeared. Seeing those articles makes me feel like, "oh, maybe I shouldn't be using it anymore" when really it is still perfectly fine. Why learn an entire new language (or 3) to do exactly what C++ was designed to do? C++ didn't go anywhere, people's dedication to making good programs did. 
Good question, I’d love to know this as well (I suspect the answer lies in Homebrew trying to be nice and not overriding Apple’s default install). That said, during the installation of Homebrew clang, it displays a message showing how to configure the paths properly. In principle it’s enough to put those as environment variables into your shell’s rc file.
http://en.cppreference.com/w/cpp/string/basic_string/getline or with the right packages `man std::getline`
When I last used it, there was a tremendous amount of interdependency between libraries for fundamental tools, so including one library pulled in a ridiculous number of other headers. And this was before SSDs were really widespread, so you can imagine the compile time increase that caused.
 I know it supports more of C++11/14 which is good.. Any performance improvements to the generated code? Better SSE/AVX intrinsics codegen or vectorization? 
There's been a whole bunch of compiler back-end work, as usual. I'd have to ask a BE dev for specifics, but I know they've been looking at autovectorization. For example, Eric Brumer contributed an improvement to std::allocator, where in 2015 we'll highly align large allocations to be AVX2 friendly. This can increase performance by 10-15% (IIRC), when BE devs usually drool over 0.5% improvements. I know they've also been fixing devirtualization bugs.
&gt;&gt; A lot more people hate pepperoni than anchovies; a lot more people hate vanilla than cinnamon-cardamom. Source?
ugh that example is horrible.
`std::getline`, like `operator &gt;&gt;`, returns a reference to the input stream, which when treated as a boolean, is truthy until there is an error. To copy one file to another by lines: void copy_lines(std::istream&amp; in, std::ostream&amp; out) { std::string line; while (std::getline(in, line)) out &lt;&lt; line &lt;&lt; '\n'; } (note that this is not how you *should* copy one stream to another, but it suffices as an example of `std::getline`)
For a while it fell out of favor in some circles. Clearly there are some circles where it never left. But the rapid iteration and deliverables of Boost, GCC and - whoda thunk it - the ISO WG in the past 3-4 years have made for a full-on language renaissance. It is fun to write C++ again! PS can't leave out /u/STL and the folks at Microsoft who have pushed C++ on Windows a long way in this time as well!
Ah, I see. Yeah, that's a pretty arbitrary argument. I think there is a good case to be made for either struct or class. I can see a case for calling OO style classes a `class` rather than a struct so as to use the keyword to document intent, but to dismiss any possible reason to use `struct` over `class` in that code like he does is just silly.
Not in my book. For example, in a single translation unit program with only main thread of execution, any object with static storage is both a global and a thread local. Obviously, the danger of globals is in how much sprinkled their use is, and being static or class-private helps limiting the damage.
Yes, the proper way of writing this in C++11 would be with &amp;&amp;'s and std::move, but I conciously decided not to use them in my example as I feel some readers not be that familiar with them and so miss the point of the article.
fixed, thanks.
I tested the RC and it was very good! I hope you fixed the two/three bugs I reported with the smile button! Two notes: - It could have been really interesting if we got intermediate updates after the RC, or an RC2 - I would really would like to read the follow up post on the Universal CRT story. You said that app-local would be added in time for RTM, it is still true?
Note that there's a huge difference between getline() and operator&gt;&gt;(). getline() consumes the separator (by default, a newline), while operator&gt;&gt;() leaves whitespace on the stream. This is a source of endless confusion to people who mix their usage. I strongly recommend using only non-member getline(), then processing the lines through another mechanism (e.g. regex).
I also believed that back in 2004. Since then I've believed the opposite. I presume you work exclusively on linux, is that right?
Frankly I think most people have switched to JSON by now. XML is a bit of a turd from the past in many respects. Also, both XML and JSON have good free libraries already available.
Been using VS2015 very extensively throughout beta. As a personal experience, for C++ 03 code VS2015 is very competitive with GCC if building for x64, but there is a very slight performance regression over VS2013 when programming with C++ 11/14 constructs. VS2015 remains about 15-25% slower than GCC 4.9 for my C++ 14 code. I've noticed a particular cause could be poor optimisation of acquire-release atomic semantics, plus VS2015's inliner gives up a lot sooner than GCC's or clang's. STL knows about some unfortunate legacy ABI requirements which forces VS2015 to be a lot slower/more verbose than GCC or clang and he'll fix them when he is allowed. Obviously these are personal experiences, your experience may vary.
If you have read the post, you will know it is a DOM and SAX parser and it is really easy to use; I dare say there is no XML parser as intuitive as mine.
As a starting point [this](https://github.com/marcodiiga/vectis) could be used
The &lt;algorithm&gt; header has a lot of really sweet stuff to make your life easier, like `std::transform`, `std::all_of`, `std::any_of`, `std:find_if` etc.
It disappeared completely for you if you live a bubble of webdev and JS frameworks.
No CMake files. There are makefile for GCC and Clang in the source code download. stdafx.h is not used in the makefiles. On Linux, please make use of the PreVS2012UnitTest makefile to build a unit test console executable.
That's DOM only. What about SAX?
This is completely other way which has it's advantages and disadvantages. Like you have to stick to such code generation tools, regenerate all declarations all the time, deal with 'expanded' generated versions when you explore your classes, etc. And whole approach is close to writing your own custom preprocessor, which is not so different from black magic. But still this is the possible optional way. I more like the way to convert all this into templates somehow, but this needs some template's syntax extensions in future standards.
Yeah I can understand that. A MinGW install is like 100MB. I remember circa 2003 Microsoft had the Visual C++ 2003 Toolkit which was what you are asking for. Just the compilers, headers and some related tools. Shame they don't offer something like that anymore. At least Visual Studio Community is free for the majority of people now though. Much better than the horrible Express version. 
How can i get the latest cl.exe without downloading whole Visual Studio?
There should not be any executable downloads. McAfee gives some more specific information (some links)?
That is unexpected. I tried several online checking tools and they don't show anything suspicious. I'll try to explore this, thanks for information. (ps. that's the reason to hate wordpress)
Nicely done. I did something similar a few years ago. Actually my final conclusion was that the only way to do serialization in C++ is using something like Protocol Buffer. So you have a generic format where you can write your struct and then you generate code from this. The reason for this is that It turns really ugly when you start using attributes you cann't expect others to take care of C++ naming limitations. I really hoped for the reflection proposal for C++17 but this doesnt really fix the error with naming.
Doh, I use C++11/14 heavily, why would it be slower in VS2015? 
My previous post in blog was related to Bartosz. :)
Do your own googling. This post is more than a quarter of a year old. Reddit is not your private research bureau.
The problem with using `const` member is that your class becomes non-regular. So if the user need to do something like this: event_data data; try { data = get_data(); } catch(...) { } This isn't possible(without requiring pointers and heap allocation). Futhermore, by making the class regular, it as simple as adding a visitor to do serialization: struct event_data { int id; string title; double rating; template&lt;class Self, class F&gt; static void visit(Self&amp;&amp; self, F&amp;&amp; f) { f("id", self.id); f("title", self.title); f("rating", self.rating); } }; However, if you don't like some of the repetition of the strings and members, you could use a few simple macros as well: #define CAT(a, ...) PRIMITIVE_CAT(a, __VA_ARGS__) #define PRIMITIVE_CAT(a, ...) a ## __VA_ARGS__ #define VISIT_EACH_1(x) f(#x, self.x) VISIT_EACH_2 #define VISIT_EACH_2(x) f(#x, self.x) VISIT_EACH_1 #define VISIT_EACH_1_END #define VISIT_EACH_2_END #define VISIT(seq) \ template&lt;class Self, class F&gt; \ static void visit(Self&amp;&amp; self, F&amp;&amp; f) \ { \ CAT(VISIT_EACH_1 seq, _END) \ } struct event_data { int id; string title; double rating; VISIT ( (id) (title) (rating) ) }; And then a simple form of serialization and deserialization for C++ streams could be implemented like this(using the Fit library): // Helper template&lt;class Self, class F&gt; auto visit(Self&amp;&amp; self, F&amp;&amp; f) FIT_RETURNS ( std::remove_cv_t&lt;std::remove_reference_t&lt;Self&gt;&gt;::visit(std::forward&lt;Self&gt;(self), std::forward&lt;F&gt;(f)) ) FIT_STATIC_LAMBDA_FUNCTION(serialize) = fit::fix(fit::conditional( [](auto self, auto&amp; os, const auto&amp; obj) -&gt; decltype(visit(x, fit::always), void()) { visit(x, [&amp;](const char* name, const auto&amp; x) { os &lt;&lt; name; self(os, x); }); }, [](auto self, auto&amp; os, const auto&amp; range) -&gt; decltype(*begin(range), void()) { for(const auto&amp; x: range) self(os, x); } [](auto self, auto&amp; os, const auto&amp; x) FIT_RETURNS(os &lt;&lt; x) )); FIT_STATIC_LAMBDA_FUNCTION(deserialize) = fit::fix(fit::conditional( [](auto self, auto&amp; is, auto&amp; obj) -&gt; decltype(visit(x, fit::always), void()) { visit(x, [&amp;](const char* name, auto&amp; x) { std::string n; is &gt;&gt; n; if (name == n) self(is, x); }); }, [](auto self, auto&amp; is, auto&amp; range) -&gt; decltype(begin(*range), void()) { for(auto&amp; x: range) self(is, x); }, [](auto self, auto&amp; is, const auto&amp; x) FIT_RETURNS(is &gt;&gt; x) )); Serialize `event_data` class to `std::cout`, just by doing this: event_data data; serialize(std:cout, data); Although, it doesn't serialize to JSON, it could be easily extended to support serialization to JSON or even XML, and it doesn't need macro magic to do it.
Umm... wow... No thanks.
Well how would you tell? If i build a library just how i want it it's bound to be the most intuitiv one to me.
&gt; there is a very slight performance regression over VS2013 when programming with C++ 11/14 constructs. Please give me a self-contained repro. &gt; I've noticed a particular cause could be poor optimisation of acquire-release atomic semantics Ditto for this one (I believe you, but I need a repro to report to the back-end team). &gt; STL knows about some unfortunate legacy ABI requirements which forces VS2015 to be a lot slower/more verbose than GCC or clang and he'll fix them when he is allowed. Remind me what this is? (I and my brain are on vacation.) In the STL, we don't *have* any ABI requirements. The compiler tries not to break ABI, which is why x86 is locked into code-based EH, but that's about the only limitation I can think of.
It's part of Concepts TS. http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4377.pdf http://en.cppreference.com/w/cpp/language/constraints#Abbreviated_templates
Yeah, there's a 2015 Community edition. (And the setup team has sworn that 2015 Community RC can be updated in-place to 2015 Community RTM.)
Cool, thanks!
&gt;&gt; I've noticed a particular cause could be poor optimisation of acquire-release atomic semantics &gt; &gt; Ditto for this one (I believe you, but I need a repro to report to the back-end team). I thought I sent you one based on concurrent_unordered_map? &gt; &gt; STL knows about some unfortunate legacy ABI requirements which forces VS2015 to be a lot slower/more verbose than GCC or clang and he'll fix them when he is allowed. &gt; &gt; Remind me what this is? (I and my brain are on vacation.) In the STL, we don't have any ABI requirements. The compiler tries not to break ABI, which is why x86 is locked into code-based EH, but that's about the only limitation I can think of. I hope you don't mind if I quote you directly: &gt; The error_category immortalizer is my workaround to make the Standard's "only one generic_category/etc." object compatible with our DLLs and _ITERATOR_DEBUG_LEVEL scheme. and &gt; We've got a circularity problem with shared_ptr, so that's why exception_ptr stuff is separately compiled. I've got a todo on my list to see if we can do anything about that. &gt; ... &gt; The one thing I'm aware of is that exception_ptr is copyable-only but should be movable. VS2015 *can* be very competitive, but it needs poking with __forceinline. You can see some benchmarks I literally posted today for lightweight future promise at https://plus.google.com/+nialldouglas/posts/GkvJgipzPjR where VS2015 is handily beating out clang and GCC on the same hardware. You'll also see that Dinkumware's future-promise is about half the performance of libstdc++'s. BTW STL, you can worry about this after vacation, but there is a standards conformance problem in your future&lt;T&gt;.get(). See Anthony Williams' comments at the bottom of the google plus post. As he says, it's probably a standards defect and your STL is not wrong, just different.
New language support in any compiler tends to get optimisation passes added later not sooner for it. As a very simple example, VS2015 now has proper rvalue semantics, so even in your C++ 03 code it'll now use move construction when it can instead of only when asked or it has no choice. If they had not fully tweaked optimisation for move construction yet (I assume they have, but this is an example) then all code might run slightly slower as a result of the improved language support changing how the optimiser works. Equally of course, move construction happening more often is likely a performance win too, so it's not open and shut either way. Some code might lose, other code might win. All I was claiming was that in my own code, I have seen a slight (~1-2%) performance degradation going from VS2013 to VS2015. Other code bases are likely different.
You could make it more intuitive if you used templates. Why do you need functions called "SetAttrInt32" or "SetAttrString" if you could have just one "SetAttr" that would deduce the XML type to use based on the parameter's type? Same for getters, you could have used defined conversions that can convert to the type you're trying to use without explicitly saying "I want an int". Of course you want an int, you're assigning the output of the function to an int.
Note that the RVO/NRVO doesn't care whether copy/move ctors have side effects - the Standard grants compilers extra permission beyond the usual As If Rule. &gt; In other words, if I write three functions calling one another and any of those could touch global memory state, MSVC appears to simply skip inlining completely That's incorrect. C:\Temp&gt;type meow.cpp void f1(int * p) { *p += 11; }; void f2(int * p) { *p *= 22; f1(p); } void f3(int * p) { *p += 33; f2(p); } C:\Temp&gt;cl /EHsc /nologo /W4 /O2 /c /FAs meow.cpp meow.cpp C:\Temp&gt;type meow.asm ; Listing generated by Microsoft (R) Optimizing Compiler Version 19.00.23030.0 [...] ?f3@@YAXPAH@Z PROC ; f3, COMDAT ; 11 : *p += 33; ; 12 : f2(p); mov ecx, DWORD PTR _p$[esp-4] imul eax, DWORD PTR [ecx], 22 add eax, 737 ; 000002e1H mov DWORD PTR [ecx], eax ; 13 : } ret 0 ?f3@@YAXPAH@Z ENDP ; f3 _TEXT ENDS [...] Here, `f3()` read/writes through an arbitrary pointer. It performs `*p = (*p + 33) * 22 + 11;` which is equivalent to `*p = *p * 22 + 737;`. Not only has the compiler inlined `f1()` into `f2()` into `f3()`, it's performed the math necessary to reduce the computation. And this is happening without LTCG, and without the `inline` keyword-hint.
did you just point out, to the guy that said "as an alternative to tuples", that you could use tuples instead
I did. I think it's useful to point out/emphasize just how small the difference in code size/convenience is, especially for people who aren't familiar with std::tie. I don't see anything wrong with my comment.
&gt; By list of functions I meant different constructors Ah yes, that is what I meant by regular types being better, since you only need a default constructor. Everything else you assign to it when deserializing. So then `from_json` could be written something like this: template&lt;class T&gt; T from_json(const std::string&amp; json) { T x; write_from_json(x, json); return x; } 
lol, sure :)
check out the latest version. We added the ability to add flags. :) http://webcompiler.cloudapp.net/
VC Dev Mgr Here. fyi, we just updated webcompiler to have the ability to set command line flags today. 
Yes, I am aware, the OP did a good job making that clear through his code and comments. I suppose that depends on your expectations, doesn't it? In c++, tie is constructing a tuple, tuple values are ordered strictly based on index, i.e. their order. So, personally, I would argue that TIE(y, x) just doing the "right" thing is what violates expectations. I'm not generally a fan of "do what I mean" programming, but naturally that's just my opinion. Just want to emphasize that my post is not intended to discourage the OP, who clearly has some good c++ chops, or to be a jerk. Just giving another perspective.
I thought it would be clear that was a joke...
It's neat. Is there a way to implement this without requiring c++14?
auto in function return value, you must not like your code readers :P
&gt; plus VS2015's inliner gives up a lot sooner than GCC's or clang's Are you using `#pragma inline_depth`? If not, why not?
Duck typing in cpp? IS NOTHING SACRED?
&gt;&gt; In other words, if I write three functions calling one another and any of those could touch global memory state, MSVC appears to simply skip inlining completely &gt; &gt; That's incorrect. I had a feeling you were going to say that :) Your above example works as you describe, and moreover I can provide examples which contradict what I just said earlier too. However, it doesn't make me wrong, just inaccurate through ignorance. I suspect there is something to do with exception handling in there too in that it might confuse the optimiser. Here's a bug I will be sending to Microsoft after your VS2015 RTM: many of the optimisation failures for lightweight future promise on VS2015 I can see a reason for e.g. we might touch an exception_ptr, however this one has no reason at all: https://ci.nedprod.com/view/Boost%20Thread-Expected-Permit/job/Boost.Spinlock%20Test%20Win8%20VS2014/lastCompletedBuild/testReport/%28root%29/constexprs/min_option_next_msvc/ Compare that to GCC: 0: 8d 14 76 lea (%rsi,%rsi,2),%edx 3: 48 89 f8 mov %rdi,%rax 6: c6 47 04 01 movb $0x1,0x4(%rdi) a: 89 17 mov %edx,(%rdi) c: c3 retq&lt;/pre&gt; The code is this: extern BOOST_SPINLOCK_NOINLINE option&lt;int&gt; test1(int n) { return option&lt;int&gt;(n).next([](option&lt;int&gt; m) { return m.get()*3; }); } .... which is called via test1(5), and it simply returns an option&lt;int&gt; containing 15. You can think of option&lt;T&gt; as an optional&lt;T&gt; for this example i.e. very lightweight. The 185 opcodes which spew, most of which the compiler knows for a fact can never be called (as GCC and clang figure out), are due to a failure to inline the .next() member function despite it being marked __forceinline, and instead it calls a stock .next() implementation which assumes an unknown global memory state. I tried turning on /Wall, and it simply warns it didn't inline the function, no explanation. This is the absolute smallest reduced example I can show your compiler team. If you can fix that, I suspect I have more optimisation fails which clang and GCC don't do for you, but this is easily the simplest of the lot. Anyway once I've verified this on RTM I'll send it into you. And stop talking to me on reddit! Go enjoy your vacation Stephan, we can deal with all this when you get back. I'll be unemployed yet again in a few weeks from now, so I'll have plenty more free time too. Right now it's prep for the Boost.AFIO review in a few weeks time!
Ah, this is news to me – do you know where this is documented, or at least noted by someone authoritative from MSFT in a blog/ML/somesuch? EDIT: This contradicts [the docs](https://msdn.microsoft.com/en-us/library/cx053bca%28v=vs.140%29.aspx), which state the default to be `254`, when unlimited (specified with `255`) is the maximum.
If you put them in a header and include it when you use it, it's as simple as how you use std::tuple, not complicated at all, isn't it? ;-) The implementation of tuple is much more complex than this under the hood, it's just that you don't even care how it is implemented because your compiler vendor already implemented it for you. Anyway, the complexity in implementation doesn't mean the complexity in usage. 
You do have a point in the expectation on TIE, I had also considered that but I couldn't think of a better name. Frankly, I don't have a need for TIE thus far, I only use LOCAL in practice, TIE is a byproduct when I wrote this, out of interest :)
I don't think so.
Ah, I didn't know it was 254. I just knew it didn't seem to have any limit I'd run into in recent years. What stops the inlining is not call depth, it's something else going on.
Ah, gotcha. Hopefully the resumption of this discussion is in a public forum, I'm very interested to see the outcome. And FWIW, 254 vs 255 is readily apparent when using complex grammars in Spirit v2, and complex MSM machines.
Unfortunately, with a macro there isn't really a good barrier between interface and implementation, because macros do not follow the rules of the rest of C++ which we commonly use. For instance, your code breaks if there are multiple exit points, even if they are precisely identical. So: auto f(int x, int y) { if (true) return LOCAL(x, y); else return LOCAL(x, y); } breaks. This is pretty unintuitive. Similarly, LOCAL(0, 0) will break. LOCAL(x, g(x)) will break. This construct basically doesn't obey any of the rules of regular C++. Here's something even worse that it does: renaming local variables inside your function has now become a breaking change, because you've sucked in the names of those variables as the fields of the struct. Not only does the LOCAL macro not have a clean separation between interface and implementation, but it actually actively destroys that separation in client code.
Its not current but there is the Microsoft Visual C++ Compiler for Python 2.7 which is the command line compiler from Visual Studio 2008. 84 MB. http://www.microsoft.com/en-au/download/details.aspx?id=44266
The problem you shown in the code is not inherent to macro, even if C++ would have built-in inline-struct support, I'd expect your example to break since you're trying to return 2 different types which is invalid for return-type-deduction anyway. LOCAL(0, 0) or LOCAL(x, g(x)) is invalid by design, as its name (i.e. LOCAL) implies, you have to provide some local variables instead of expressions like 0 or g(x). As for the renaming problem, similar problem applies to std::tuple as well - if you change the order of args you return (e.g. std::make_tuple(a, b) -&gt; std::make_tuple(b, a)), you also break the current code (even worse, silent bug if the type of a &amp; b are compatible, in which case you won't observe it as an compile error). Neither of them is better than the other in all cases, all depends on your need :)
Care to elaborate?
&gt; Frankly I think most people have switched to JSON by now. Dunno why you're getting downvoted, because it's absolutely true. I made significant cash in the 90s knowing about XML - that all vanished more than a decade ago as the browser became king.
Well, some comments would be useful in the code, especially if you want other ppl to read it, understand and comment on it.
That's just plain-old local struct not the imaginary inline struct I'm talking about, but I see that the name `LOCAL` may be the cause of your confusion. The intent of LOCAL is to provide an feature of inline struct which is not available in C++, so the imaginary code should expand to: auto f(int x, int y) { if (true) return struct { int x; int y; } {x, y}; else return struct { int x; int y; } {x, y}; } It's saying that you're making 2 different types, and that's what a c++ programmer would expect as writing []{} twice would give you different lambda types. Let me give the real case which I prefer LOCAL to std::tuple: I have a GUI library that is used like: w-&gt;on&lt;paint_event&gt;([](paint_event&amp; evt, widget&amp; self) { auto&amp; canvas = evt.canvas; auto&amp; res = self.init_once([&amp;] { auto background = canvas.make_bitmap(canvas.size(), [](canvas_ref canvas) { // draw background here }); auto gradient = canvas.make(radial_gradient_brush(...)); auto path = canvas.make(some_complex_geometry); return LOCAL(background, gradient, path); }); canvas.blit({}, res.background); canvas.fill(res.path, res.gradient); } Where `self.init_once` will imbue some data into the widget and the data is initialized once by the enclosed lambda, in this case, it's the drawing resources. The major benefit of LOCAL is that it provides mnemonic names instead of numeric indices. If I return std::make_tuple(background, gradient, path), I have to call std::get&lt;0&gt;(res), std::get&lt;1&gt;(res) and so on, which are more obscure in their meaning. You may argue that one could use enum for that, for example enum{background_tag, gradient_tag, ...}; and then use std::get&lt;background_tag&gt;(res), std::get&lt;gradient_tag&gt;(res), etc. But to be honest, do you really think you prefer writing code like that to simply using LOCAL here?
When you are doing policy-based templates (like specifying KeyComparator), you usually privately inherit from the policy instead of instantiating it as a member. You do this because c++ allows for the *empty base optimization*, which allows base classes with no data members to take up 0 memory in the layout of the child class. This contrasts with how you do it currently- member variables must have distinct locations in memory, which implies that they must have a non-zero size.
There was a proposal that await can be used for unwrapping any monad, like optional / expected. Is that still on the cards? Not able to watch the video atm, so not sure if it is covered in the video.
Expected directly mentioned in video, so likely optional supported too
Yet Another XML Library. What does yours do that others don't?
 ~priority_queue() { nodeHeapVector.clear(); nodeIndexMap.clear(); } Those calls to `clear()` are redundant. 
This was a very interesting video, but would appreciate a lower-level view of what's going on eg. stack growth, saving the execution context vs function call perf. However this is a compelling tool I would welcome in C++17, I would like to experiment in GCC / Clang first.
Select simply Run - Build
Well, the binary is produced each time you compile your program, it's just it's stored as a temporary file somewhere in your user files. You can modify the binary output path with a cmake flag like so: set(CMAKE_RUNTIME_OUTPUT_DIRECTORY "/home/me/cpp/binaries")
The difference between Debug and Release is not what you think. Both targets produce executables, however the Release target creates a binary which has been optimised by the compiler.
So, question. What's the deciding factor in speeding up builds? Is it CPU or Ram?
Related discussions: * https://www.reddit.com/r/cpp/comments/39fe55/named_multiple_return_values_with_anonymous_types/ * https://www.reddit.com/r/cpp/comments/30tqx0/simple_question/ I was quite pleasantly surprised that [this](https://www.reddit.com/r/cpp/comments/30tqx0/simple_question/cpwfxlo) actually works.
Sounds like he wants template specialization or overloading/tag dispatch...
Have you taken a look at https://github.com/corvusoft/restbed?
`_Key` etc. are reserved names. Drop the leading underscore. You do not actually use `_ValueHasher` in the type of `nodeIndexMap`. You have a lot of gratuitous copies. For instance, a single `push` call copies the value a whopping six times. Only two of those copies are actually required by your design; the remaining four are pointless extra work. A number of member functions should be `const` but are not (e.g., `empty()`).
Neither function pointers nor final classes are policies though, so I don't really see this being a problem.
&gt; here's (...) why Java is better than C++: One can readily build complicated and sophisticated programs in Java, thanks to the numerous libraries it has. (...) C++, on the other hand, allows coders access to the deepest labyrinth of the system, but requires coders to reinvent the wheel every time. Oh how I wish C++ had support for libraries! Greatest missing feature from the language. /sarcasm
I was watching a tutorial where the guy was using Eclipse, he selected 'release' and it built the binaries for him. or i may have misunderstood. either way, i rock, haters suck cock.
I agree - the author of the original article is not sufficiently knowledgeable on the topic. IMHO, the more important point is that a vast majority of these students learning C++ will graduate with a "C with classes" understanding of the language and limited exposure to many of the modern developments. 
I understand how the code works, and why it generates two different types. Your argument is now basically that this macro does not simulate a function, but rather a language feature that doesn't exist, and people should adjust their expectations accordingly. Inventing a new language feature using macros is, on its own, a very bad thing to do. It can be justified in some cases because the invented feature is so useful and lacking in the language, which is not the case here. To answer your question I would rather use a struct, a tuple, a tuple with enums, or std::tie (which you ignored in your answer), anything, over LOCAL. It's way too much complexity to introduce to a codebase, and too much non intuitive behavior for too little gain. Note that LOCAL basically acts as compile time reflection. Compile time reflection doesn't exist in C++ yet. When it does, and it becomes a standard technique that good developers are aware of, I will of course use it. I'm not going to use an attempt to hack it together use macros. Anyhow, I'm sure this isn't what you wanted to hear, as you wrote some very clever code. Clever code isn't always good code though, in fact it's often not. Out of the developers I know with years of top notch c++ experience, I'm fairly confident that every single one of them would not allow code like this to be merged into a production codebase.
Why shouldn't I be able to use class compare final : std::less&lt;mytype&gt; {}; or bool comp(const mytype&amp; l, const mytype&amp; r) { return l &lt; r; } as the key comparator?
OK, so we have disagreement in philosophy, arguing on that further won't be constructive, so I'll just explain why I ignored std::tie in my example - you may already noticed, that I used `auto` all around, and that's the point. To use std::tie, you have to specify the types of those resources explicitly beforehand, and that's what I want to avoid in the first place. If I were going to spell the types, I would rather use plain-old local struct and return it directly. BTW, do you use Boost or not? I hope you won't curse it to death ;-)
Could you provide an example where you need a specific type here? I mean, shouldn't you only store attributes holding either numbers or strings? If you don't want to use templates just use overloading. So have a SetAttr that takes an int, a SetAttr that takes a string, etc. The compiler will pick the most appropriate one depending on which type you use. If no type matches or there's an ambiguous match, the compiler will tell you.
I believe the author has no fucking clue regarding what she is talking about.
&gt; It's not really idiomatic C++. Idiomatic C++ changes every two years, good luck making a library today that will be "idiomatic" by the end of the decade. And the java model is, imho, better adapted to the building of applications, whereas the C++ model shines for library building. In the end you'll need a tree of objects. 
I meant it in a more general sense. I'm still in a stage where I'm not sure what the best route for coding is when it comes to readability/efficiency. I feel like overloading is only appropriate when the functions perform different tasks based on the type provided as otherwise you have code duplication. However, the types supported by the function are very clear as attempting to call them with anything that won't convert into the parameter types for that function will cause a compile-time error. Templates are great for when the parameters types don't make too much difference to the task carried out by the function, but they don't make it immediately clear what types the function may require; integers, strings, certain custom classes? ^ I was going to say all that, but I just realized it's sort of irrelevant. Thanks for replying. 
Expected, Optional, etc, will be supported, but, it requires a few tweaks to the design to make it efficient and safe. There will be a small proposal in the fall that extends coroutines to handle expected/optional/and others and matching implementation in VS update 1. Essentially the extension will allow to explain to the compiler that coroutine return type (such as optional) cannot represent the idea that value is not here yet and thus awaiting on a future will be a compile time error. Also, knowing that a coroutine can never be suspended, allows the compiler to generate better code. 
Great post! :) Btw, I wrote a library with an improved version of the serializer that inspired that post available at https://github.com/catedrasaes-umu/jsonip . It also includes the deserializer.
Indeed, your original blog post was very useful and provided most of the functionality I was looking for. Thanks again! I'll check out the deserializer, I was going to try and tackle that next! 
Thanks. I really prefer the Maybe monad to both exceptions and error codes. Await will make writing binds so much easier. A couple of questions: * How does your proposal differ from N4244? * I understand you can make lambda's resumable. So if I copy a suspended lambda, does the execution context gets copied? Or are resumable lambda's non-copyable?
In addition to that, if the address is taken, only a trampoline needs to be generated anyway, not a whole copy.
As far as I know you don't have the guarantee that it's different for conceptually-different but practically-identical functions. Any decent LTO will do the same thing and correctly IMO - you have two identical implementations, there's only overhead in keeping them separate and you may even reveal further mergeable functions.
... Seems to me like something that will prohibit LTO. If f() and g() are functionally indistinguishable, I would say let them compare equal.
I think the sample code is intended to reproduce the bug, I wouldn't read too much into it.
Tnx for the nice interview. Your code examples seem very convincing until I read N4453 that uses the proposed keyword `resumable` similar to how `constexpr` is tagged on an expression or function. Can you say something about the merits of that proposal? 
About time
Interestingly, [Boost.Function's rationale](http://www.boost.org/doc/libs/1_58_0/doc/html/function/faq.html#idp205088688) for not supporting op== is outdated; Expression SFINAE allows the existence of op== to be sensed. Such support could probably be added with no cost except codegen size (which is actually a concern for std::function).
There is no memory allocated for a lambda with nothing captured. It is equivalent to a function. `static` here is the same as it always is - it just modifies the linkage rules. Using `static` means that every compilation unit has a copy of the function whereas not having `static` means that all copies of the lambda *should* get merged. Keep in mind that adding static usually lets the compiler be more confident about inlining which may or may not be a good thing.
Some of these problems are bugs in the other libraries such as Boost though, not GCC. I've seen a similar issue with Boost.Variant with 1.58 and -std=c++14 (gcc and clang).
How else would you return a lambda without resorting to type erasure?
Interesting, would you mind directing me to more info on this? Edit: Is this what you're referring to, by chance? https://svn.boost.org/trac/boost/ticket/11285
&gt; There's no need to make `heapify_up` and `heapify_down` recursive. There's also no reason _not_ to; his implementation reads quite clearly to me.
&gt; which can be more valuable than learning the standard library Not if they ever want to actually _write anything_ in C++.
&gt; but part of it was that Java didn't provide anything particularly well suited to the task at hand in its library, and the minute you run into that, you start to realize that the Java language itself is much more limited, requiring a great deal more code to be written for many tasks. I'd gild you for this, but alas, I'm broke.
Please don't link to sites that require a login to see the content. It's not worth the effort and inevitable "newsletter" spam to read an article that is so vaguely titled here that I can barely imagine the content.
&gt; Go enjoy your vacation Stephan, we can deal with all this when you get back. If he's anything like me, he probably enjoys catching up on bleeding-edge language and toolset updates in his spare time. ;-]
GCC separates it, you don't get the string or list changes by only changing the language mode. You have to pass a separate ABI flag to get those and be fully standards compliant.
I use function pointers a lot, but don't find myself comparing them very often. How does that come up for you? Usually I have an array of them where the whole point is it's populated with distinct values and there's no reason to compare.
wtf
In my ideal world, the default would be `-std=c++14` not `-std=gnu++14`. You should have to ask for non-standard GNU language extensions, they should not be enabled by default. Every time I see someone using a VLA in C++ and claiming it as proof that arrays in C++ don't need compile-time constant sizes I want to cry, and then go back in time to 1994 or whatever and have a stern talk with whoever thought that was a good idea. 
And it's about to get a whole lot better when Eric's ranges are integrated. The first step (his current C++17 proposal) is a blessing, and then it gets more awesome after that.
In my case, I use function pointers as keys in the map to implement a type-based dictionary for type-erased objects.
Given your description I can see using function pointers as values in a map, but as keys??? That seems unusual.
Couldn't it just not perform the optimization under circumstances (such as this) one where it causes non-conforming behaviour? The way MSVC currently handles it sucks.
Since the program **must** be run (repeatedly) to play, it's a little inaccurate to call this whole system *"compile-time"*. It's still an interesting project. Compiling the code produces a binary. Running the binary produces updated code. 
Yeah, it's a bug, and it could be fixed. I actually forget if this is tracked by an active bug in our database, but the compiler/linker team is certainly aware of it.
Well, it's not unusual, in my case: obj.set&lt;Type, Tag&gt;(...); obj.get&lt;Type, Tag&gt;(); Internally it's an intrinsic map that uses the deleter function as the key, so calling `set`/`get` will lookup the key `deleter&lt;Type, Tag&gt;`. In some signal system, you can connect a function callback and disconnect it with the same function pointer.
Amazing approach and demo, but for real life projects, the code becomes a nightmare to maintain, especially in enterprise industry. Kudos!
There are/has been lots of other similar bugs when adding C++11/14. I had some problems with Boost.Asio, and the fix involved using -DBOOST_ASIO_DISABLE_STD_ATOMIC when I enable C++11. It may not have been a bug in Boost, but developers of libraries that depend on it can have a hard time tracking these bugs (e.g. long segv backtraces that end up inside the inner parts of Boost you're not familiar with). The first distributions moving to C++14 (Arch?) will probably have some rough weeks at the beginning, but even if we keep on waiting, the problem will remain the same.
We're happy to announce the release of Qt 5.5. For me the highlights of this release are support for Windows 10 and improved 3D functionality. Under Windows 10 Qt applications can be run as either traditional Win32 applications or as WinRT applications - just choose the appropriate platform plugin. This also means that you can upload your applications to the Windows Store, which requires WinRT. Note however that automatic styling is not yet supported in the WinRT port. Once Windows 10 is released we will add official support in the next Qt 5.5.x patch release. On the 3D side of things the Qt Canvas 3D module has moved from tech preview to fully supported status. Qt Canvas 3D exposes a WebGL-like API within Qt Quick. For a higher-level API we ship a port of three.js. Additionally Qt 3D is now available as a tech preview. The API has been completely revamped from the Qt4 times, courtesy of KDAB. On the commercial side we've simplified the product offering. We are of course also fully committed to the open source version. At the Qt Contributor's Summit that was held in Oslo last month we discussed with the community how to decrease the differences between the open source and commercial versions, and I'm hopeful that before long we will be able to open many of the currently commercial components. Thanks to the entire Qt community and to all of our loyal customers!
Yes, that's it. I don't see this as much more than an annoyance though--when a compiler implements new features or switches the default some minor breakage in libraries is expected. I ran into a similar issue with Boost and Qt two days back, but should be fixed with yesterday's release. When Boost 1.59 comes out, and the same for other library releases, it will all be solved. For now, I've just had to back down to C++11 to avoid breakage.
&gt; automatic styling is not yet supported in the WinRT port What do you mean by automatic styling? Also I'm currently learning QT and I would like to say it is an amazing piece of framework and everything right from community to IDE is perfect :).
Drawing controls using Windows' built-in theming system.
How can this be a bug in other libraries like boost when the libraries I mention have no dependencies? 
&gt; some minor breakage in libraries is expected We are talking about Internal Compiler Errors here. GCC 5.1 is not even able to emit diagnostics. https://travis-ci.org/gnzlbg/range-v3/jobs/66921303#L3293
Yaay, GStreamer 1.0 support! ｡◕‿◕｡
They are. It is one part of their many attempts to cause GPL supremacy. (No, seriously... various "vendor lock-in"s of GCC are regarded as a feature)
Great, I was missing more compiler dependent flags to keep track of.
6 years old, why post now?
Seems like an interesting parallel to Rust, that was just released. C++ could/should have gotten there first! ;)
&gt; But my understanding is that the point is to encourage developers to switch to C++1x, by making it somewhat easier to use (i.e., C++1x code will work "out of the box") They are switching from C++98 to C++14 in a way that breaks valid C++11 code that used to compile with old versions of gcc and they still cannot really compile C++14 code. They could have pushed C++11 first, and if they want to set C++14 as default they could work hard the next year to slay all ICEs and major bugs in C++11 and C++14 before making C++14 the default.
They aren't releasing it with the default set to C++14 tomorrow. They have another year of bugfixing before 6.1 is released.
Reminds me of a sales guy I once knew. He was recommending a friend of his for a programming position, so I asked if his friend knew C++. His response was: Oh yeah! He knows C, C+, C++... he's really good! Still makes me chuckle.
This would be great, but doubt it will ever get added to C++. I will be happy enough with a destructive move in C++ 17 in the meantime, but it seems that is not happening :(. 
1. Go to https://github.com/fffaraz/awesome-cpp 2. Find any project written in C++ that you find interesting 3. Get it to build 4. Contribute patches You will be doing something useful with your time, you will get your code reviewed by more experienced programmers and you even do something you can mention in your CV when applying as a C++ programmer. There is no better way to learn IMHO. Edit: point to a project on github about awesome C/C++ stuff:-) It lists my favorite (Qt Creator), so that must be good:-)
These examples are... Really really underwhelming. You're supposed to use unique ptrs as the exclusive owner of the object; passing a raw pointer (for instance, as required by an API) should not open you up to risk of that pointer being deleted. Even if there was no `.get()`, I can always do `&amp;*my_unique_ptr`. Or, for instance, that Foo object that deletes the Bar ptr. Obviously, it should itself be using a unique ptr rather than a raw ptr. If it absolutely must use a raw ptr, transferring a unique ptr to it should be done via .release, not .get. These features and usage patterns are well documented.
By the way, when do you plan to start shipping VS 2015 built binaries? We do two semester long game projects at my school and we're planning to integrate Qt for our editor. So far I've set it up and played around with prototyping interface stuff. But I'm planning to evaluate VS 2015 sometime in August so that we can get all the C++ features we want, but I wasn't sure how easy it would be to get the pre-built Qt binaries (or even just building it myself). (We only have one other dependency.) Also thanks for all the hard work you guys put in! Qt is pretty great!
Yep. If you just take Rust and replace all cases where you need to tag a reference with an explicit lifetime with "upgrades to GC", that's still a whole lot more than 5%, and a GC pointer is owning where a ref is not, so you lose semantics as well. 
I have a small (15 kloc) c++14 library that compiles under clang 3.5 through 3.7 tip of trunk, but also ICEs on gcc 5.1. I isolated (and submitted to gcc bugzilla!) half a dozen `constexpr` related bugs before giving up (there were several variable template related bugs as well). After 2 months, half of those bugs are fixed in gcc tip of trunk. The C++17 proposed Range-v3 and soon to be accepted Boost.Hana libraries fare no better. /u/gnzblg/ is completely on the money with his claim that gcc is not ready for prime time with c++14. 
&gt; impression of programming being a very hard exercise And that is a good thing. The sooner those kids realize Computer Science is or is not for them the better. If they don't have neither the will or the gift for coding better for them to look at something else and stop wasting time and money only to quit later. 
This is voodoo to me. And I LOVE IT. 
It's MSVC, but channel 9 has a good series on the STL from one of Microsoft's keepers of the implementation at the time: https://channel9.msdn.com/Tags/stephan-t-lavavej?page=3 I remember it being aimed more towards intermediate devs, though.
Thanks for the shoutout! :)
Honestly, for C++, you'll benefit more from a good book than any online resource. Check out the [recommended book list](https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) on Stack Overflow.
I agree. Websites tend to be a little superficial; books tend to be more rigorous. I'm halfway through *C++ Primer* (because I saw it listed on there) and I feel lucky that I found it. If you want to really get to know the language more than hobby-depth, I say start there. Not for the impatient, though. For example: the if statement isn't really introduced until around page 180. (It never really feels *slow* though). But for sure, the investment in a solid foundation will pay off not just for C++, but your whole programming experience. 
Or more importantly, why? What is the practical usage for doing this?
I greatly prefer C++, but I'm not sure I generally agree with what you're saying. Java just has many more libraries than C++, even if they're not amazingly designed they still let you accomplish something very quickly in practice. Java also has some significant advantages stemming from reflection. In general I think designing around reflection is usually not a great idea, but it's hard to deny it's usefulness when you want to e.g. serialize a class. I'm sure we could find dozens of tasks that would be easier in either language, to sum up.
&gt; &gt; Go enjoy your vacation Stephan, we can deal with all this when you get back. &gt; If he's anything like me, he probably enjoys catching up on bleeding-edge language and toolset updates in his spare time. ;-] Me, since May I have spent an average 23 hours per week earning money and an average 45 hours per week preparing a new Boost library for peer review later this month. I'm not into languages and toolsets personally, always been a libraries man for some reason, ever since the beginning. Weird what motivates us.
An approach that's worked well for me and which I heartily recommend is to pick up a comprehensive book and delve into a project you find interesting. Read the book in parallel with your project's development. If, in the course of coding, you run into a roadblock, look further in the book or online for a possible solution. Often times you will discover multiple ways of solving a problem, each with their own strengths and weaknesses. Eventually you will develop your own style, preferences, and an intuition regarding what components of the language might be suitable for a given task. Do you mind if I ask where in computing your interests lie?
An explanation of the Lenexa variant design.
I got that, but a programming language is a bit like a normal language: You need to use it to learn it. Get a good book on C++ and start to read code. Try to understand it (Google helps a lot here as it lets you look up stuff) and play with it. Try to improve it. Open source is a great way to learn IMHO: You get to work on a real project and not just the toy stuff found in tutorials and examples. Navigating a real project is a skill in and off itself and you can not pick that up with toy projects.
STL, a.k.a. ICEman.
I understand, and appreciate the response! Consider this my vote toward doing a build on that platform. (If it's not too much trouble!)
STL, I appreciate the efforts your team is putting into the library and compiler, however.... In the past you mentioned the compiler and library testing process utilizes plum-hall. Now if that were truly the case, then many of say Majnemer's if not a larger number of the total 750 bugs fixed would have been caught at internal testing time - as an example "crashes during class template instantiation with void template argument" really - in the year 2015? Makes one wonder what those "1300 non-connect bugs" were all about.
Hi Eric, IIUC the main argument against an empty state is that the empty state becomes a common case, and as a consequence users need to be ready for it everywhere, which is really bad. Still, the post says the following about the invalid variant: &gt; The operations related to inspecting the variant’s contents have a validity precondition. Note that the valid() method, which returns a boolean corresponding to whether or not the variant is valid, has no preconditions. If this precondition is checked, the empty variant can do the same to avoid the checks in user code. This makes empty variants more common than invalid ones, but it also makes empty variants fail loudly as opposed to e.g. default constructing an invalid variant to its first element, which might fail silently and behave differently depending on the order of the elements. In the mathematical discriminated union the order of the elements is irrelevant. If this precondition is not checked in the invalid variant due to run-time cost, then the advantage of the invalid variant becomes way more clear. However, if the standard encourages implementations to assert the preconditions as a QoI issue, the advantage becomes less clear since this can also be done for the empty variant. So I guess this means I'm still not sold. I would expect at first sight that a C++ variant follows "don't pay for what you don't use" and thus provide a zero-cost default constructor (i.e. default construct to empty). This will also allow default-constructing variants of non-default-constructible types. It seems to me that the empty variant can provide a strong debug mode, and a fast-unsafe release mode, with the advantages of the invalid variant proposal plus some perks. I'm not sure if it's worth it.
&gt; 1196276 郭轩 A possible found in Visual C/C++ Compiler [link](https://connect.microsoft.com/VisualStudio/feedback/details/1196276) Why did the team wait this long to fix the possible in the compiler? Still, thanks for listening to your users! Now please start sending stinkbombs to windiv via internal mail until they start listening too. I've come to believe they hate users, and not secretly, either.
That bug was reported on 3/22/2015 and resolved as fixed on 3/23/2015. How much faster do you want us to fix bugs? (And yeah, I know there are some Connect bugs that sit around for years. For example, many of the &lt;functional&gt; bugs I fixed in 2015 with a massive overhaul were reported years earlier. We continually have to triage bugs, prioritizing based on severity, difficulty, and how busy we are with other stuff. For &lt;functional&gt;, I had to wait for variadic templates before I could write a new implementation without my head exploding. We got those in 2013, and then it took me several months to do the overhaul for 2015.)
So many of the examples given here really come down to just not understanding the language. While rust can do a lot to ensure safety, imo it actually kind of gets in the way when designing more complex algorithms. Just test all the code you write! It never works the way you want it to on the first try. Also: regular C-style pointers are not obsolete! You can still use them! Honest!!
The problem is that the `empty` proposal sacrifices type safety. If the `variant` has a legitimate empty state, you cannot issue a compile-time guarantee about code with a “not empty” precondition. With the invalid state, you *can* issue this compile-time guarantee: the only way of violating the validity of the `variant` is if your code is *already* in an invalid state (failure to handle exception properly). Importantly, failure to handle exceptions properly *always* puts your program into an invalid state, regardless of which `variant` design you choose (and also when there’s no `variant` in the code at all). So with the “invalid” `variant` proposal, there’s no additional weakening of the type system beyond what’s already there. With the “empty” `variant` design, we introduce an additional weakness into the type system, and furthermore one that is going to be very common: failure to initialise the object properly. It’s generally agreed that compile-time safety is superior to runtime safety. By that maxim, the “empty” design is clearly inferior to the “invalid” design.
The article gives this definition of `unique_ptr`: &gt; It is a (smart) pointer that is the only reference to the object it’s pointing to. This is really wrong, and a glaring misunderstanding of the semantics of `unique_ptr`. In reality, `unique_ptr` dictates *ownership* semantics, it (deliberately) says nothing about the number of references. So, let’s correct the definition given above: &gt; `unique_ptr` is a (smart) pointer that is the only owner of the resource it’s pointing to. Only it, and nobody else, is allowed to manage the resource’s life time. With this realisation, some (but not all) of Bartsz’ objections simply go away. More importantly, there are other designs that restrict the number of references rather than owners of a resource. However, they are very restrictive in practice, which is the reason for `unique_ptr`’s design. Incidentally, this is a mistake that many made at the time (2009), and I don’t think Bartosz would make it now.
An ICE is *never* a library error. It is by definition a compiler bug.
&gt; I don’t think the missing default constructor is a problem Without a default constructor a variant is not a Regular (nor a SemiRegular) type. Note that the empty variant is always default constructible, while the invalid variant is only conditionally default constructible (if its first type is default constructible). &gt; Contrary to what you’ve said, this also doesn’t carry a performance penalty. A variant that on default construction default constructs its first element carries a performance penalty over a variant that does nothing on default construction. Doing nothing is less work than doing something, this is in the spirit of C++ "pay for what you use". &gt;&gt;the invalid variant still has, in practice, run-time checks &gt; &gt;Not during normal code execution, as far as I understand (that would be a major design flaw). During unwinding, sure. But performance isn’t relevant there. During unwinding the invariants of the variant must be checked "on every method call" (except for `valid()` and copy/move assignment); these checks are inside the variant methods. Calling these methods when no stack unwinding is taking place also performs these checks _unless_ a sufficiently smart compiler can infer at compile-time from the "type-safety" provided by the variant that these checks are not necessary. I doubt such a compiler exist nowadays but will happily be proved wrong here. &gt;&gt; Failing to logically initialize properly an invalid variant can result in silent run-time errors. &gt; &gt; Can you give an example of this? I’m not sure I understand what you mean here Sure: // T,U,V are default constructible using my_variant = variant&lt;T, U, V&gt;; // ... far away my_variant a; // ... far away a.visit(...); When calling `visit` with: - an empty variant: the variant is in an empty state, that is, `visit` will `assert`, `throw`, `std::terminate`, or in other words, fail loudly at run-time (at least in debug mode). - an invalid variant: `T`, it's first type, has been default constructed, so `T`will be visited. This might be a logic error since the user did not explicitly initialize the variant with `T`. That is, this might always work, some times work, always fail, or fail only in front of a client. In particular, changing the definition of my variant to: using my_variant = variant&lt;U, V, T&gt;; will result in different run-time behavior, that again might always work, some times work, always fail, or fail only in front of a client. In particular, default constructing the first element has nothing to do with the underlaying mathematical concept of a discriminated union. I can see why it is practical to do so, but at the same time it feels a bit arbitrary, so _I'd rather never default construct than default construct to the first element_. &gt; I certainly cannot remember the last time I’ve default-initialised an object or left it uninitialised If you have used the STL, then you probably have used code that does.
&gt; Without a default constructor a variant is not a Regular type. Quite right, but not a big problem. Sure, regular types have some nice properties but it simply doesn’t make sense to shoehorn a non-regular type into a regular type shell at the expense of correctness. &gt; Doing nothing is less work than doing something, this is in the spirit of C++ "pay for what you use". Which is why a `variant` simply shouldn’t default construct. It’s a nonsense operation. The current proposal allows this for convenience but I think this will prove to be a mistake in hindsight. At any rate, users don’t have to *use* this property — they can ensure that their objects are always properly initialised. Like I said, I haven’t needed default-initialised objects in my code for ages, so there’s no performance penalty in practice. &gt; these checks are inside the variant methods Is the code actually (going to be) implemented like that? This would be a glaring quality of implementation issue, and I don’t believe it barring evidence. The proposal only mentions that `index` handles this case.
&gt; Quite right, but not a big problem. Sure, regular types have some nice properties but it simply doesn’t make sense to shoehorn a non-regular type into a regular type shell at the expense of correctness. I'm undecided but since I lack practical experience using these variants (good that they go into a TS first!) I just by inertia would try to make it SemiRegular (which requires DefaultConstructible), and conditionally Regular. &gt; Like I said, I haven’t needed default-initialised objects in my code for ages, so there’s no performance penalty in practice. As I said, that you don't write them in your own code does not mean that you don't use code that uses them. The STL uses them for example. Variants are also a very common way of sending messages/events e.g. through a network or file I/O. You allocate a vector of "empty" variants, and use that as network buffer. Why would you initialize them to any value if you are just going to, right after, initialize them from data from the network. In particular, this is one of my most common uses of `boost::container::vector` since it has a constructor that allows you to do exactly this. &gt; Is the code actually (going to be) implemented like that? This would be a glaring quality of implementation issue, and I don’t believe it barring evidence. The proposal only mentions that index handles this case. I don't think it will be required, but implementations will hoepfully be encouraged by the standard to assert their preconditions. It is a one liner `assert(valid());`, and the precondition of which methods need a valid variant is in the standard text. I'm in general fine with undefined behavior as long as it delivers real value (e.g. performance) and is 100% preventable in debug mode.
Can I pray that, among those fixes, there is one for the traditionally dangerous [VC conditional operator](http://denisbider.blogspot.com/2015/06/c-ternary-operator-is-harmful.html)? The page I linked to shows VS exhibiting dangerous behavior: it compiles ambiguous code silently and against developer intent, and there's no way to get even a warning. GCC and Clang both emit *errors*.
I just tried in http://webcompiler.cloudapp.net/ But the compiler flag seems to be ignored. I get: Compiled with /OPT:REF,NOICF /EHsc /nologo /W4 cl : Command line warning D9002 : ignoring unknown option '/OP' cl : Command line warning D9002 : ignoring unknown option '/OT' cl : Command line warning D9002 : ignoring unknown option '/O:' cl : Command line warning D9002 : ignoring unknown option '/OR' cl : Command line warning D9002 : ignoring unknown option '/OE' cl : Command line warning D9002 : ignoring unknown option '/OF' cl : Command line warning D9002 : ignoring unknown option '/ON' cl : Command line warning D9002 : ignoring unknown option '/OO' cl : Command line warning D9002 : ignoring unknown option '/OI' cl : Command line warning D9002 : ignoring unknown option '/OC' cl : Command line warning D9002 : ignoring unknown option '/OF' main.cpp Compilation successful! Total compilation time: 218ms true Total execution time: 468ms Did I do something wrong?
I don't agree with the *need* to have a C++ book, so I'm just going to recommend this decent tutorial http://www.penguinprogrammer.co.uk/c-beginners-tutorial/ Even without a tutorial, build something very simple, like counting to 10, then change it to 100, then change it so it spits out Hello each 2nd number, going on an on until you've got this neat little number thing. Take it slow, but write something every day.
The other answers are correct, but: The STL was the name of a library from which components were taken to put into the Standard Library. There is nothing in C++ that **officially** is called the STL. But you will hear people talk about it a lot. It can sometimes be rather confusing to know if they mean the original version or the standardised version. Such is life, the unofficial name has stuck.
I think he/she was just joking about the omitted word in that bug's title.
I have a bit of a question, because I saw all these posts about variants and the committee... and has it occurred to anyone that they could maybe just add a policy parameter to the variant to allow for a person to choose what happens in these exceptional conditions? I know for the default argument case, I managed to basically create a policy called `union_policy` that makes it behave like regular union. And then there's an `optional_policy` that allows the variant to be constructed in the empty state... My implementation isn't complete, and I still need to figure out the additional places I could use the policy, but the `variant_base` (or what should probably be called `basic_variant` to make it like the `string` style of standardese-naming...) works pretty well in enforcing requirements so far: https://github.com/ThePhD/Furrovine.Heart/blob/master/include/Furrovine%2B%2B/variant.hpp#L77 -- there might be a bug or two since it's not as in-depth as boost::variant or even the everyday variant presented here.
Adding a policy variant splits all instances of a class in two and C++ doesn't have an elegant way of unifying such types. For example what if you have a function that doesn't care whether the variant can or can't be empty? You will need to write two overloads for it to handle the general case. virtual void f(const std::variant&lt;optional_policy, int, ...&gt;&amp;); virtual void f(const std::variant&lt;int, ...&gt;&amp;);
You have to put `/link /OPT:REF,NOICF` at the end of the command line - that's what I meant by passing it to the linker.
By default all threads share the same heap so you will need to synchronize those operations. Take a look at std::atomic to know how to make sure the compiler will generate the appropriate code. 
It's [metonymy](https://en.wikipedia.org/wiki/Metonymy). People mean either "the C++ Standard Library" or "the subset of the C++ Standard Library that was strongly influenced by the historical library". They're never talking about the historical library, except when it's obvious. It's like the White House. People mean the executive branch of the US government, except when they're obviously talking about the historic mansion.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Metonymy**](https://en.wikipedia.org/wiki/Metonymy): [](#sfw) --- &gt; &gt;__Metonymy__ (/mɨˈtɒnɨmi/ *mi-__TONN__-ə-mee*) is a [figure of speech](https://en.wikipedia.org/wiki/Figure_of_speech) in which a thing or concept is called not by its own name but rather by the name of something associated in [meaning](https://en.wikipedia.org/wiki/Meaning_(semiotics\)) with that thing or concept. The words "metonymy" and "metonym" come from the [Greek](https://en.wikipedia.org/wiki/Greek_language): μετωνυμία, *metōnymía*, "a change of name", from μετά, *metá*, "after, beyond" and -ωνυμία, *-ōnymía*, a suffix used to name figures of speech, from ὄνῠμα, *ónyma* or ὄνομα, *ónoma*, "name". &gt;For instance, "[Wall Street](https://en.wikipedia.org/wiki/Wall_Street)" is often used metonymously to describe the U.S. [financial and corporate sector](https://en.wikipedia.org/wiki/Financial_center), while "[Hollywood](https://en.wikipedia.org/wiki/Hollywood)" is used as a metonym for the [U.S. film industry](https://en.wikipedia.org/wiki/Cinema_of_the_United_States) because of the fame and cultural identity of Hollywood, a district of the city of [Los Angeles](https://en.wikipedia.org/wiki/Los_Angeles), [California](https://en.wikipedia.org/wiki/California), as the historical center of film studios and film stars. The national capital is often used to represent the government or monarchy of a country, such as "[Washington](https://en.wikipedia.org/wiki/Washington_D.C.)" for [United States government](https://en.wikipedia.org/wiki/Federal_government_of_the_United_States). &gt;Metonymy and related figures of speech are common in everyday talk and writing. [Synecdoche](https://en.wikipedia.org/wiki/Synecdoche) and [metalepsis](https://en.wikipedia.org/wiki/Metalepsis) are considered specific types of metonymy. [Polysemy](https://en.wikipedia.org/wiki/Polysemy), multiple meanings of a single word or phrase, sometimes results from relations of metonymy. Both metonymy and [metaphor](https://en.wikipedia.org/wiki/Metaphor) involve the substitution of one term for another. In metaphor, this substitution is based on some specific [analogy](https://en.wikipedia.org/wiki/Analogy) between two things, whereas in metonymy the substitution is based on some understood association or [contiguity](https://en.wikipedia.org/wiki/Contiguity#Psychology). &gt; --- ^Relevant: [^Metaphor ^and ^metonymy](https://en.wikipedia.org/wiki/Metaphor_and_metonymy) ^| [^Bench ^\(metonymy)](https://en.wikipedia.org/wiki/Bench_\(metonymy\)) ^| [^Condensation ^\(psychology)](https://en.wikipedia.org/wiki/Condensation_\(psychology\)) ^| [^Trope ^\(literature)](https://en.wikipedia.org/wiki/Trope_\(literature\)) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+csr80g0) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+csr80g0)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](/r/autowikibot/wiki/index) ^| [^Mods](/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Call ^Me](/r/autowikibot/comments/1ux484/ask_wikibot/)
Dude, just write one version of f that's a function template and use enable_if to make sure it only works for variants you want... I mean that code is easy, right? Don't you just want to write that code? I'm kidding, of course.
DevDiv#553676 "If you want a picture of the future, imagine a conditional operator stamping on a human face - forever." is still active.
RC has a link [here](http://rosettacode.org/wiki/Talk:I_before_E_except_after_C#On_modern_C.2B.2B_as_a_scripting_language)
Haha you do kid but of course I do write code exactly as you described, in fact that's why I made the functions virtual because you can't use `enable_if` on virtual functions. Oh the pain...
If you're referring to "6.096 Introduction to C++", it's worse than the web tutorials it lists instead of books. Is there a real course?
I'm having trouble finding that as a reference. Is 553676 an actual ID where this issue is tracked? Is that internal only, or available for public viewing?
As with any other language, my suggestion would be to pick a concrete project and start working on it. Personally I find that having a goal to keep me focused is the most important factor in keeping me motivated to learn new things. One of the difficult parts about C++ is that you can use many different styles: do you want to do object-oriented programming? Generic programming? Template metaprogramming? Functional-style? It is even more confusing to choose nowadays as the language has evolved considerably and what is considered idiomatic today probably does not even exist in many "classical" reference books. A possible course of action is to get yourself familiar with Boost in your toy projects. The libraries are high quality and just by reading the tutorials and the examples you will be exposed to proper and modern ways of doing things. Good luck!
Programming principels and practice is better for a beginner in my view. 
Trying to learn c/c++ as a first language was really hard for me. So much so that I gave up learning to program in any language for years. Decades later, I taught myself Python which made learning the universal programming concepts very easy to understand. With that, coming back to C/C++ was so much easier. Its still a challenge but one that I can usually overcome if I work at it enough. 
Whoosh.
I think you're in a somewhat similar boat than I was about 8 years ago. I already had lots of programming experience in other languages. But unlike you the languages I've been exposed to were primarily statically-typed. So, there's that. Anyhow, I thought to myself "why not learn directly from the inventor?" and ordered Stroustrup's latest edition of TC++PL (which was the "special edition" back then). I didn't regret this decision. The book worked for me quite well. I liked its information density and I learned a *lot* – a lot in a rather short amount of time which was probably a much better deal than relying on Google search and potentially misinforming C++ tutorials. After I finished it I ordered other books of which I would recommend Scott Meyers' "Effective C++". But Stroustrup's TC++PL book is not for everyone and it's possible that you're better served with another one. Just beware of the many crappy C++ books out there. Book reviews by C++ beginners don't tell you much about the technical quality. For example, when I visit amazon.de and search for C++ books, the first two search results are garbage that will only confuse you – or worse – make you *feel* like you learned valuable lessons but it's actually not worth your money. Put more trust in [this list](https://stackoverflow.com/questions/388242/) of recommendations instead. Of course, practice is the other ingredient. Lots of practice. But again, I felt like having read some C++ books saved me a lot of time I would have otherwise spent on "unlearning" misinformation and bad programming styles. Good luck!
See the [C++ FAQ](https://www.reddit.com/r/learnprogramming/wiki/faq_cpp) over at /r/learnprogramming.
Because of the blowing feet ! Seriously. Given a big enough codebase, errors will be made. Either because you are tired or because your coworker is a moron. Both will occur. The breakage may be hard/costly to track. Linus chose a minimalist (or, at least very understood) language to ease peer review. The rust guys came up with more compile-time guarantee. And, as crazy as it seems, it's easier to come up with a new, innovative language + its libraries than to hire and educate, top notch &amp; rigorous developers. And no. Producing high-quality code at scale is neither a small problem, nor a solved one. Look at the average enterprise code. On the other and, C++, notably clang; gets better and better at static analysis, and detecting some errors mentioned in the blog post seems quite doable. mostly, use-after-move errors can probably be tracked down nicely. 
C++ was my first language. It was fine. I don't think there's a "wrong" language to learn first.
If you want an extra state that is zero-cost to default construct to, with the Lenexa variant you just use `empty_t` (or `monostate` or whatever) as the first alternative. Giving *all* variants an empty state is paying for something that you don't need.
Just start programming. If you programmed in R/Python/Matlab/Javascript/Lua you could start by rewriting some of your simple programs. Also I would recommend looking at C++11 and up. C++11 is like new language, and I would not call it hardcore. Some current info about C++11 books is here: http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list Some C++11 examples: https://github.com/sftrabbit/CppSamples-Samples 
I would like the ability to have a single type that's used at the interface boundaries that everyone agrees is the best default. But I would also like, for other use cases, to be able to flex the design a little bit: I think that flexibility is worth it, given the amount of discussion around which one would be right in the first place. Having a "tough, this is the standard one" is great and all, but I'd still like a "and you can adapt for this other one if you like, too". E.g., having a `variant&lt;...&gt; = basic_variant&lt;union_policy, ...&gt;;` that the standard library `typedef`s/`using`s for us so that everyone who uses the regular "variant" vocabulary can get behind (or whatever style of variant people get with), while people who deal with the empty-default cases can enjoy their `optional_variant&lt;...&gt; = basic_variant&lt;optional_policy, ...&gt;` without having to explicitly wrap it up in an `optional&lt;&gt;` or some such.
I think ["A Tour of C++" by Stroustrup](http://www.informit.com/store/tour-of-c-plus-plus-9780321958310) is one of the best introduction books for someone that already knows how to to program. It's not exactly a reference book, it's more like a tutorial and it gives you an excellent overview of the C++11 language and its standard library. The language is very clear and accessible, it's not that "technical" and explains things as it goes, and it doesn't drag itself too much, it's about just 200 pages. It introduces you directly to idiomatic C++11 from the start, which is great. Other books go through the old way of doing things in C++98, or worse teach you going from C to C++ with classes and never get to modern C++. It is kinda important to learn about C++98 if you're dealing with legacy code, but otherwise you should only be doing C++11/14. After you're done with that I would recommend the rest of the "C++ In Depth" series and obviously ["The C++ Programming Language 4th Edition", also from Stroustrup](http://www.informit.com/store/c-plus-plus-programming-language-hardcover-9780321958327). TL;DR: I recommend "A Tour of C++" instead of "The C++ Programming Language", because it's much easier to read cover to cover and get a look at everything that's important in a reasonable time. 
&gt; these checks are inside the variant methods &gt;&gt; Is the code actually (going to be) implemented like that? This would be a glaring quality of implementation issue, and I don’t believe it barring evidence. The proposal only mentions that index handles this case. For the case of visit, you already need to inspect the index. For the case of get, you already need to inspect the index. There is no performance overhead of checking those invariants.
As Eric mentioned above, if you want this behavior you can supply your own empty_t or monostate as the first alternative of the variant. There is no performance penalty here. Most use cases of variant don't require this behavior so there's no benefit to push it on everyone.
This was discussed at Lenexa. The fact that "regular" types in C++ require a default constructor is an odd C++-ism. The idea here is that putting regular types in a variant shouldn't remove regularity. If you're going to choose an alternative to be the default, the first one is the most reasonable choice. I appreciate, though, the desire for explicitness which this proposal doesn't enforce, but does allow.
Been able to take a look at it (haven't been on pc that much). The sprintf_s function is not conditional. This is the change: // qtbase/src/3rdparty/angle/src/libANGLE/renderer/d3d/RendererD3D.cpp, line 591 snprintf(adapterLuidString, sizeof(adapterLuidString), "(adapter LUID: %08x%08x)", static_cast&lt;unsigned int&gt;(adapterLuid.HighPart), static_cast&lt;unsigned int&gt;(adapterLuid.LowPart)); Note the static_casts. Compilation drops a warning how adapterLuid.High/LowPart are LONG instead of unsigned int otherwise.
https://www.reddit.com/r/cpp/comments/3byjiu/a_variant_for_the_everyday_joe/csruni3
&gt; I rarely use empty, pre-sized vectors. Either I reserve the necessary size or I’m using an appropriate constructor to initialise the vector correctly from the get-go. Not using it yourself does not mean others do not use it. This overload of vector constructor has existed for a long time and must probably be used quite much. And it is a problem with the "invalid" flavor of variant. 
&gt; Not using it yourself does not mean others do not use it. There are tons of things people do that we don’t need to encourage. Now pre-allocating a vector’s space isn’t a problem per se — but with a type like `variant` it *is*. There’s no obligation at all for library implementors to support this pattern, since it is problematic and there are better alternatives. EDIT: And just to get misunderstandings out of the way, preallocating vectors of `variant` is of course not a huge problem either way. What I’m saying is that *not* supporting this operation is nowhere near as tragic as some of the debaters here seem to think. People would notice it not working, would shrug and find another (and, often, better) way of solving their problem.
- read books: Lippman et al primer, Stroustrup *The Language 4th ed*, Scott Meyers last 2 (*Modern Effective* and *Effective 3rd ed* - read code: seems like you're doing stats/prob/linear algebra/diff eq, that's a good limited domain to start in. Limited domain doesn't mean easy - set up dev environment: look at MSVC, or maybe qt creator or code Blocks unless you're wedded to vim or emacs. Start writing code, being mindful of correct IO and all the things that can go funny in C++-specific numeric computing, as well as all the generic IEEE 754 issues. read compiler and linker warnings/errors, valgrind, logging libs, unit/integration tests, git branches and commit messages, the whole toolchain. - 
Hi again :-) Took me a while (sorry about that, prepping for conference talks), but just wanted to let you know that I went over the curlpp codebase -- and it seems that it takes ownership in this case: - https://github.com/datacratic/curlpp/blob/master/src/curlpp/internal/OptionList.cpp#L50 - https://github.com/datacratic/curlpp/blob/f94747d0f0a93d0b75a797f77ba2846fddf1479b/src/curlpp/internal/OptionList.cpp#L58 Basically, followed this path along the way: - https://github.com/datacratic/curlpp/search?p=5&amp;q=setOpt&amp;utf8=%E2%9C%93 - https://github.com/datacratic/curlpp/blob/f94747d0f0a93d0b75a797f77ba2846fddf1479b/include/curlpp/Option.hpp - https://github.com/datacratic/curlpp/blob/f94747d0f0a93d0b75a797f77ba2846fddf1479b/src/curlpp/Options.cpp - https://github.com/datacratic/curlpp/blob/f94747d0f0a93d0b75a797f77ba2846fddf1479b/src/curlpp/internal/OptionList.cpp#L58 - https://github.com/datacratic/curlpp/tree/f94747d0f0a93d0b75a797f77ba2846fddf1479b/include/curlpp/internal - https://github.com/datacratic/curlpp/blob/f94747d0f0a93d0b75a797f77ba2846fddf1479b/include/curlpp/internal/OptionList.hpp So, perhaps we've been unnecessarily worrying ;-) Still, guess we indeed have similar feelings about raw pointers &amp; memory management, and for good reasons, overall :)
`clang -Weverything` will also catch unused variables, implicit conversions, mismatches between copy constructors and assignment operators, and much more. You can add explicit `-Wno-xxx` commandline options to disable benign warnings for issue `xxx`
File system support is hard because extremely platform dependent and you can't make a portable API that is satisfactory over different platforms. Windows paths can take the following formats: \\\server\share\file.ext \\\?\server\share\file.ext C:\directory\file.ext file://C:\directory\file.ext Unix paths all look like this: /dir/dir/dir/file Go ahead and design a portable API that can work with both. You'll end up with something that will disappoint.
Are you serious? Name them whatever you want, just be sensible like you would for any other class. 
`thing_guard` is a popular choice. `thing_handle` is also a good convention.
Depends on the situation: * If the RAII class doesn't own the resource, instead it just does some work on the resource at construct/destruct, I'll call it `xxx_guard`. * If the RAII class owns the resource and the resource is accessible via a pointer, it's typically defined as `using xxx_handle = std::unique_ptr&lt;XXX, XXX_deleter&gt;`; * If the resource is not accessible via a pointer and thus `std::unique_ptr` cannot be used, I'll write the RAII wrapper myself and name it `unique_xxx`. That's what I mostly used in my experience.
/r/dailyprogrammer should give you some interesting problems here and there. Also browse some open source projects, look at the open issues and start working on a solution and try to submit patches. Those are the first two things that jump to mind unless you think of a project that interests you (and is something you'd want to use for something) so that it keeps your interest. 
`AutoThing`. I have no idea why people like underscores for names. It's one of the least pleasant characters to type.
And clang's static-analyzer can take a CMake compilation data-base as input, so it is really easy to give that a try as well if your project is CMake based. In my experience, however, the static-analyzer finds 0 real problems with modern C++ projects. If you are using RAII and smart pointers it just doesnt find anything worth changing (if you are already compiling your project with `clang -Weverything`). It might be useful for C projects tho, but I don't know how many C projects use CMake.
&gt; it is childish to deviate from them. What are you thinking? Should we have all removed .h from our header file names for C++98 and added them back for C++11? The standard headers aren't meant as a style guide. Even if they were, who would buy style-by-committee?
&gt; It's one of the least pleasant characters to type Time for me to evangelize! I too used to find tying some characters unpleasant, but then I built my own [split-pcb semi-ortholinear](http://ergodox.org/) keyboard and re-mapped all the special character keys so they were easier to type. Plus I used special mechanical key switches that provide a satisfyingly chunky click when activated. Using it helped alleviate my wrist and back pain, it was great. If you're anything like me you will completely re-design the existing standard keyboard and create a custom mapping to better type those pesky underscore characters. And open &amp; close parenthesis, brackets, and braces.
void_t is really useful here. Upvote and more info: [how it works - stackoverflow](http://stackoverflow.com/questions/27687389/how-does-void-t-work) [docs - cppreference](http://en.cppreference.com/w/cpp/types/void_t) [template metaprogramming talk - walter brown](https://www.youtube.com/watch?v=Am2is2QCvxY) 
Put some effort into your post. What is your current skill level? What are you interested in? Posts like these should be deleted.
Why follow any naming-convention at all then? Make it php: force everyone to guess how the function is spelled, because everyone does whatever they want. Every major language that came later (php aside) managed to make people use consistent naming. Because it matters! In what way do naming conventions help with readability if every library uses a different one? Also what is the problem with style-by-committee? Picking a style is one of the things where it is important that there is a consistent way, not what it is, therefore it is one of the best examples for something where it is almost impossible for a committee to fuck up. Again: It doesn't matter which style they choose, it matters that they choose ONE and everyone uses that. Ans since almost everyone uses the standard-library, getting consistency with any other style is basically impossible, so you have to use that, whether you like it, or not!
&gt; PascalCase in C++ is as stupid It seems like template types (and examples of concepts) use PascalCase. Though if anything I think that supports your argument. If now PascalCase has a meaning, using it for other purposes can be counter productive.
Using c++ without oop and other defining features is like using a high intensity laser for lighting a cigarette. Why bother with the laser in the first place when a match would do?
Most recently it was this: https://www.massdrop.com/ext/ergodox/?referer=PJQRPT&amp;hash=b8251fb3744e4af73f58f99126b032ba But I added a Colemak layer recently and I'm mostly using that. My future plans are to remap the number 'row' to a symbol only row and add a 10-key numpad layer, but that's several months off while I struggle my way through Colemak.
I understand not going OOP (or going heavy OOP with deep class hierarchy) but not using RAII? A class with a destructor adds 0 overhead of what are you doing already (calling some init() and later a destroy(), close() or whatever)
The difference seems to come down to whether one uses exceptions or not. I can't think of any specific subreddits that discuss this, especially seeing as both sides tend to think they're "using C++ the way it should be used", but it's not a hard sentiment to notice.
Why not use a reference, though?
Better yet, do this: void func(Foo &amp; obj) or void func(Foo const&amp; obj) No need to play with raw pointers unless you are dealing with C code or require nullptr as a valid value.
having references is still quite nice ;) 
Macros aren't type safe or scoped. See Bjarne Stroustrup's page: [So, what's wrong with using macros?](http://www.stroustrup.com/bs_faq2.html#macro) With the changes in C++11/14/17 and STL functional, SFINAE / template work has become a lot simpler. 
I've heard one semi-valid argument against C++ RAII, and that is it's quite verbose; you have to type a lot (make wrapper classes) to get the effect.
You might have to write a few abstractions, but *using* them is the opposite of verbose because it's done automatically by the compiler. Also no chance to accidentally miss calling a close(), destroy() or whatever function.
It's more typing at declarations and less typing at use. I'm fine with that tradeoff.
Me too.
Thanks for the answer. However I disagree: a code like #if T=int something here looks very simple and natural in imperative language Honestly SFINAE are really ugly and very difficult to understand. Is there a reason for not choosing simple tests in an imperative language? BTW nobody writes code like fn(i++) as mentioned by Stroustrup.
In my experience it is always beneficial to use more than one tool for the job. Every tool has its strength and weaknesses, why not use those for our benefit? PVS-Studio's advantages are clearly the nice integration into the IDE and the possibility to suppress diagnostics on an instance by instance bases. I don't like -Wno-xxx as it may hide something important.
I can totally imagine that someone would like a straightforward language like C, which is simple to reason about. That said, there are many situations where some C++ feature would be really nice to have. If you go that route, you end up using C++, but mostly the C subset and sporadically using stuff like templates, overloading, exceptions and objects. Which is a totally reasonable thing to do - 'normal' code is simple to reason about, while the verbose and errorprone repetition from C can be avoided at will. As a bonus, the relation between such code and the generated assembly is pretty direct, which means that optimizing your code (counting cache line usage, memory alignment etc) becomes more straightforward. Now, this does mean that this particular style is geared towards smaller programs - objects, exceptions, templates and the like are useful in that they allow reasoning about code on a higher level and allow for better cooperation in teams.
Returning by value would defeat the purpose. It's an interesting example with breaking the temporary lifetime extension, I can't say I think that's a very wide pit to fall into. Returning by const &amp; in the wild is pretty common where efficiency is important. Your example works just as well to create a dangling reference with std::vector.
See this excellent answer on how to use `unique_ptr` even for resources not accessible by pointer http://stackoverflow.com/a/11002936/955273
site appears down, cache: http://webcache.googleusercontent.com/search?q=cache:UKdv0VLkEWgJ:vitiy.info/immutable-data-and-serialisation-in-cpp11/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us
Agreed, these kind of macro-based serialization schemes are too fragile w.r.t. forwards/backwards compatibility and cross-language use. And nowadays you can do better than Protocol Buffers: https://google.github.io/flatbuffers/
Thanks for sharing, I appreciate the digging :) Just curious, what kind of conference ?
I'll post the code here too for easier reading. Please let me know if this violates etiquette somehow! :) // // main.cpp // To do: // - Use better inputs, allow for inputting spaces. #include &lt;iostream&gt; #include &lt;string&gt; #include "cal.h" int main(int argc, char *argv[]) { // Instantiate calendar Calendar cal; // Menu loop while(true) { // Options std::cout &lt;&lt; "\n1 - Add event\n" &lt;&lt; "2 - Remove event\n" &lt;&lt; "3 - Show events\n" &lt;&lt; "4 - Quit\n\n"; int selection; std::cin &gt;&gt; selection; // Selection: add event if (selection == 1) { std::string name; int day, month, year, hour, minute; std::cout &lt;&lt; "\nEvent name: "; std::cin &gt;&gt; name; std::cout &lt;&lt; "Month: "; std::cin &gt;&gt; month; std::cout &lt;&lt; "Day: "; std::cin &gt;&gt; day; std::cout &lt;&lt; "Year: "; std::cin &gt;&gt; year; std::cout &lt;&lt; "Time (hour): "; std::cin &gt;&gt; hour; std::cout &lt;&lt; "Time (minute): "; std::cin &gt;&gt; minute; // Initialize new event to add to cal Event new_event(name,day,month,year,hour,minute); cal.add_event(new_event); cal.sort_events(); } // Selection: remove event else if (selection == 2) { std::string name; std::cout &lt;&lt; "\nEvent name: "; std::cin &gt;&gt; name; std::cout &lt;&lt; "\n"; cal.remove_event(name); } // Selectin: list num_to_show soonest events else if (selection == 3) { int num_to_show; std::cout &lt;&lt; "\nNumber of soonest events to show: "; std::cin &gt;&gt; num_to_show; std::cout &lt;&lt; "\n"; cal.print_soonest_events(num_to_show); } // Selection: quit else if (selection == 4) return 0; else std::cout &lt;&lt; "\n\nInvalid selection\n\n"; } }
 // cal.cpp #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;cassert&gt; #include "cal.h" std::ostream &amp; operator&lt;&lt; (std::ostream &amp; out, const Event &amp; event_out) { std::string months[12] = {"January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December"}; // Conditionals: don't want 3:05 to print as 3:5! if (event_out.minute &gt; 9) { out &lt;&lt; event_out.name &lt;&lt; " on " &lt;&lt; months[event_out.month - 1] &lt;&lt; " " &lt;&lt; event_out.day &lt;&lt; " at " &lt;&lt; event_out.hour &lt;&lt; ":" &lt;&lt; event_out.minute; } else { out &lt;&lt; event_out.name &lt;&lt; " on " &lt;&lt; months[event_out.month - 1] &lt;&lt; " " &lt;&lt; event_out.day &lt;&lt; " at " &lt;&lt; event_out.hour &lt;&lt; ":" &lt;&lt; "0" &lt;&lt; event_out.minute; } return out; } void Calendar::add_event(const Event &amp;new_event) { // Temporary event list for resizing Event *temp_event_list_ptr = 0; // Check to see if there are any events that actually // need to be copied over. if (num_events &gt; 0) { // Create temp event list temp_event_list_ptr = new Event[num_events]; // Copy contents of event list to the temporary event list for (int i = 0; i &lt; num_events; i++) { temp_event_list_ptr[i] = event_list_ptr[i]; } } // Increment the number of events num_events++; // Reallocate event_list_ptr for the new size delete[] event_list_ptr; event_list_ptr = new Event[num_events]; // Check to see if there were events copied if (temp_event_list_ptr) { // Copy contents of the temporary list to the new list for (int i = 0; i &lt; num_events; i++) { event_list_ptr[i] = temp_event_list_ptr[i]; } } // Add in the new event at the end event_list_ptr[num_events - 1] = new_event; // Deallocate the temporary list delete[] temp_event_list_ptr; } void Calendar::remove_event(const std::string &amp;rm_name) { if (num_events &lt; 1) { std::cout &lt;&lt; "No event to remove.\n"; return; } // Index of event to be removed in event_list_ptr int rm_index = -1; // Keep for loop index for check below int i = 0; for (; i &lt; num_events; i++) { // Compare returns 0 if equal if (event_list_ptr[i].name.compare(rm_name) == 0) { rm_index = i; break; } } // Return if event was not found if (i == num_events) { std::cerr &lt;&lt; "Error: requested event to remove was not found.\n"; return; } // Create temp event list Event *temp_event_list_ptr = new Event[num_events]; // Copy contents of event list to the temporary event list for (int i = 0; i &lt; num_events; i++) { temp_event_list_ptr[i] = event_list_ptr[i]; } // Decrement the number of events num_events--; // Reallocate memory for resized event list delete[] event_list_ptr; event_list_ptr = new Event[num_events]; // Sanity check assert(rm_index &gt;= 0); // Go through the whole array, copying over all but // the one to be removed for (int i = 0; i &lt; num_events+1; i++) { static int event_list_index = 0; if (i != rm_index) { event_list_ptr[event_list_index] = temp_event_list_ptr[i]; event_list_index++; } } delete[] temp_event_list_ptr; } void Calendar::print_soonest_events(int num_print) { if (num_events &lt; 1) { std::cout &lt;&lt; "No events.\n"; return; } // If user enters more events than there are, // cap it. if (num_print &gt; num_events) num_print = num_events; for (int i = 0; i &lt; num_print; i++) { std::cout &lt;&lt; i+1 &lt;&lt; ": " &lt;&lt; event_list_ptr[i] &lt;&lt; std::endl; } } void Calendar::sort_events() { for (int i = 1; i &lt; num_events; i++) { // if the event's time is less than the first one's, swap // it with the first one and set i = 1 again. if (event_list_ptr[i].year &lt;= event_list_ptr[0].year &amp;&amp; event_list_ptr[i].month &lt;= event_list_ptr[0].month &amp;&amp; event_list_ptr[i].day &lt;= event_list_ptr[0].day &amp;&amp; event_list_ptr[i].hour &lt;= event_list_ptr[0].hour &amp;&amp; event_list_ptr[i].minute &lt; event_list_ptr[0].minute) { Event temp_event_0 = event_list_ptr[0]; Event temp_event_i = event_list_ptr[i]; event_list_ptr[0] = temp_event_i; event_list_ptr[i] = temp_event_0; i = 1; } } }
For some wierd reason the 2 classes I cooked a few years back only have ThingRAI. It's never too late to refactor right? So far I've only used custom guards for things like progress bar advancing or for printing scoped timing information. I know, I know, multiple exit points are bad...
&gt; If you default-construct to an empty state, you must handle it in visitation because these variants will be common. Yes, thats exactly my point. We should be able to default construct a partially formed object, so we don't have to handle extra empty states everywhere. &gt; Also, it's not accurate to say that an invalid variant is partially formed. In the thinking of the proposal's author, you can copy/move invalid variants, and you can as them if they're valid(). It would still be partially formed, since you can't use fully use the object yet, even though there may be a few more operations besides the basic assignment and destruction that are valid for partially formed objects. 
The file system library is actually fairly long along the way to being part of the standard, as an optional feature (available if the file system is hierarchical).
The obvious question when I hear this sort of thing is: what's the advantage? OOP is contentious, the more so because it's often overused (Bjarne has called it the most overused aspect of C++). Not making your programming "oriented" around objects is fine I think, but if someone is not using objects at all or avoiding them when they are an obvious fit, that's not good. If people are advocating against RAII, I'd be very suspicious. I suppose if you really want to avoid objects badly, it would be hard to do RAII. But manual resource acquisition and release is incredibly bug prone, this really shouldn't be controversial. I'd say in the eyes of the vast majority of C++ developers, RAII is a huge strength of the language. It prevents bugs by ensuring resources are reclaimed, does so in a deterministic and usually (barring things like shared_ptr) in an easy to understand way. C++ is one of relatively few languages that has real destructors, in which you can put meaningful code. In C, you don't have destructors at all since you don't have objects. In Java, Python, etc, you don't know when the destructor (or finalizer) will be called because of the GC. In both languages, people at the highest level have recommended never putting "important" code in destructors. When I program in one of these languages after C++, this is what hurts the most.
VC allows unqualified name lookup to reach into dependent bases, which it should forbid. This rule is associated with two-phase name lookup (not yet implemented) but is technically separate. (VC will enforce the rule with the /Za compiler option, but you shouldn't use that - it's "enable extra conformance and extra compiler bugs because these codepaths are rarely tested".)
&gt;Knowing how the computer works from a "bare-metal" standpoint is often the difference between top-level programmers and programmers who can never quite master their art. This is how fistfights start. :P
I wish you came in plugin format for my favourite IDE /u/STL
It's no easier to read _ names. CamelCase is very easy to get used to.
Partially formed vectors do not exist, either the vector has some elements or it does not have any. Both states are fully formed. A variant is a different beast. In my opinion a variant is more like an `int` and there are a partially formed `int`s: int i; Here `i` is partially formed, it doesn't have any meaningful value. i = 3; int j = move(i); After moving from`i`, it doesn't have a meaningful value either: it is in a partially formed but destructible state. None of this is true for vector. Moving from a vector gives an empty vector, which is in a fully formed and destructible state.
The high-perf methodology you're probably asking about (I gather, since it's popular in the gamedev community) is called "data-oriented design" (DOD). Personally, I see absolutely _none_ (as in: _zero_) connection with RAII, though. This has been a pretty popular (often referenced) talk: - [Pitfalls_of_Object_Oriented_Programming_GCAP_09.pdf](http://harmful.cat-v.org/software/OO_programming/_pdf/Pitfalls_of_Object_Oriented_Programming_GCAP_09.pdf) More: - http://www.dice.se/wp-content/uploads/2014/12/Introduction_to_Data-Oriented_Design.pdf - http://gameprogrammingpatterns.com/data-locality.html - http://www.dataorienteddesign.com/dodmain/ Personally, I find many of the underlying principles to be solid (e.g., Mike Acton's ["where there's one, there's more than one"](http://macton.smugmug.com/gallery/8936708_T6zQX#!i=593422385&amp;k=5kqfJLP&amp;lb=1&amp;s=A)). The reason is that this is just good software systems' performance engineering, relying on the classical foundations, like the [trade-offs between AoS (Arrays of Structures) and SoA (Structures of Arrays) data layouts](https://software.intel.com/en-us/articles/a-case-study-comparing-aos-arrays-of-structures-and-soa-structures-of-arrays-data-layouts). "Don't forget how computers work," basically. Courses like Computer Organization &amp; Architecture are the right background for this. I mean, hey, Bjarne Stroustrup states just that (and, notably, he's definitely not an opponent of RAII): &gt; I use this example to illustrate some points, encourage thought about algorithms, data structures, and machine architecture, concluding: &gt; &gt; - don’t store data unnecessarily, &gt; - keep data compact, and &gt; - access memory in a predictable manner. &gt; &gt; I emphasize the importance of cache effects. In my experience, all but true experts tend to forget those when algorithms are discussed. https://isocpp.org/blog/2014/06/stroustrup-lists Side-note: At the same time, again, I (personally) also think that using DOD with RAII can be perfectly fine (OTOH, 1990s-style / possibly-strawman OOP, heavy with polymorphic class hierarchies &amp; run-time pointers chasing -- not so fine). I suspect (may be wrong) that folks who claim it ain't usually don't even bother to look at the generated assembly and/or use a profiler (and rely on "instincts" instead; well, that, and bad experiences with poorly optimizing compilers for consoles, may agree on that much). 
Awful. RAII is a tool used for a variety of different activities. It's also not something that comes trippingly off the tongue. `ScopedThing`, `ThingDeleter`, `ThingGuard`, `UniqueThing` - all fairly standard, understandable - and pronounceable.
The style of programming used in Handmade Hero is basically C, but compiled with C++ to use a very small subset of C++ features (like operator overloading).
&gt; Because camel-case is inconsistent with the standard-libraries naming-conventions Some people see that as an asset - to distinguish STL classes, functions and methods from everything else. (I'm really not sure if I'm in that category or not.) &gt; and it is childish to deviate from them. "They disagree with ME! They are no better than children!!"
I am new to C/C++, and I've never actually programmed anything using RAII. I'm hoping to understand the pros and cons of different approaches better. I don't think the arguments against RAII have to do with its verbosity. I've heard the argument that C++ itself is verbose and that OOP in C++ is verbose, but I have no heard that argument for RAII on it's own. The style I was first exposed to was allocating all the memory you are ever going to use up-front, and then writing components in such a way that they never exceed those bounds. Memory is divided into permanent and temporary blocks, where temporary memory gets cleared at the start of each frame. When an object gets free'd it gets moved onto a linked list. When a new object is needed it is pulled from the free list, and if the free list is empty its allocated into next spot in the memory block. This might not be possible with every type of program, but it seems to work well for video games. I see two downsides of RAII being worse performance due to multiple memory allocations and not knowing exactly how much memory your program is going to need. If you want to run on a Raspberry Pie or a cell phone where memory is limited, pretending you have unlimited memory seems dangerous. Jonathan Blow makes the argument that RAII only exists because the language supports exceptions, and that exceptions are entirely unnecessary in language design. (See: https://www.youtube.com/watch?v=TH9VCN6UkyQ&amp;t=38m15s)
That in itself is not an argument against RAII since you can overload the new and delete operators to specify how allocations and deallocations are done. I develop games as a hobby and I use pool allocators for almost all objects. With overloadable new/delete operators low-level resource management is still better done with RAII.
The memory allocator is what I was describing. There's two ways to deallocating memory. First, a block of memory is set aside for transient storage. The pointer gets set to the start of the memory block on each frame and its used for any processing that needs to happen while calculating a single frame. The second is that when an object is deallocated, it gets put into a linked list of freed memory of that type. When a new struct is allocated it first tries to pull from the free list, and if the list is empty it allocates a new one. It seems incredibly trivial to manage memory this way as long as your program is okay with never needing more memory. I'm not sure it would work with something like a word processor as you won't know how much memory the text buffer will need as it grows.
So am I reading this right in that this will both take care of the wall-of-line-noise error messages, and provide a terse syntax where you don't need the 'template &lt;typename T&gt;' part?
To be clear, Memory is only allocated once at the very start of the program. All the memory management is around splitting that single block into pieces that can be used by different parts of the program. I guess when I said allocate I didn't really mean allocate. I meant that I take a piece of memory from the already allocated block and use it, and then move a pointer to just beyond the part that was used. When I said deallocate, I didn't mean return the memory to the OS, I meant do a tiny bit of work to allow the program to re-use that piece of memory later without actually deallocating anything.
The critical piece of knowledge that you're missing is that when a class (e.g. Menu) is constructed, its data members (e.g. button) are constructed (in the order that they're declared) before the constructor's body (Menu::Menu()'s body, beginning at the open brace) begins running. When you say `button = stuff;` in the body, that's an *assignment*, not a construction. As /u/redditsoaddicting linked, the fix is to use a member initializer list (*mem-initializer-list* is the Standard's grammar term), which looks like `Menu::Menu() : button(11, 22, 33) { stuff; }` in C++03, or `Menu::Menu() : button{11, 22, 33} { stuff; }` in C++11. (The difference between parens and braces is another matter. Here, they'll be equivalent.)
You should be looking for performance problems with a profiler, which will work just as well with or without RAII. But honestly, I don't see your argument anyway - can you give a code example illustrating your point? For me, it makes it _clearer_ where performance issue might be, because of separation of concerns. A nice code sample would make your argument much clearer...
Thanks for the reply! I think I understand the arguments you make if the first section and I think right now my opinions are different than yours here (which is totally cool). Adding exceptions adds a lot of complexity to the language, so using multiple return values seems fine to me. I realize this is totally subjective and opinions will differ here. I'm not I really care if a caller checks my error messages or not. I'd like to think about it more, but I don't think I see any issues with saying "Here's how this function works, ignore the errors at your own risk." I don't think I understand the last point you made. Could you explain what you mean by setting an error value as a side-effect and maybe provide an example?
What you are describing *is* an allocator. *new* and *delete* (I will call them "conventional allocators") do essentially the same thing: given a large chunk of memory (from OS), they give you the requested piece of memory and take it back making available for later use. Most modern conventional allocators don't request memory from the OS or return memory to the OS on every allocation/deallocation (but normally only then deallocating big regions of memory). The real difference between what are you describing and conventional allocators is that the conventional one is equally suited for objects of every size. So what it must do, is first to find a gap in the allocated memory of the requested size. This is heavy operation, requiring some additional data structures to hold freed memory blocks. On delete, it marks that memory as free, merges it with adjacent free regions and inserts into the data structure of freed blocks. You allocator does the same thing, but because of knowledge of the object size and maximum allowed memory size, you can keep the data structure of freed memory extremely simple (linked list), and make the allocation and deallocation extremely fast operations. Again: it is the need to allocate the objects of arbitrary size that makes the conventional allocator so complex and slow. As of the allocator you are describing, it is a well-known and widely used technique, called "pool allocator" or ["Memory pool"](https://en.wikipedia.org/wiki/Memory_pool). It is perfectly compatible with RAII, OOP and whatever else. It is also implemented in boost as [boost.pool](http://www.boost.org/doc/libs/1_58_0/libs/pool/doc/html/index.html). By the way, modern high performance conventional allocators, like [jemalloc](http://www.canonware.com/jemalloc/) (used at Facebook, Mozilla) or [tcmalloc](http://goog-perftools.sourceforge.net/doc/tcmalloc.html) (Google) use similar techniques internally (they create a number of pools for objects of different sizes). (And another thing, that adds huge amount of complexity to conventional allocators, is thread safety and multithreading performance.)
&gt; You should be looking for performance problems with a profiler, which will work just as well with or without RAII. It's a lot simpler to write performant code when the costs are not hidden. &gt;But honestly, I don't see your argument anyway - can you give a code example illustrating your point? For me, it makes it clearer where performance issue might be, because of separation of concerns. You can no longer trivially read code and look at what it's doing. Hidden function calls in constructors/destructors/overloaded operators hinder this. The downvotes here are why I don't bother posting or reading /r/cpp. Established best practices when working on games are suddenly controversial because people don't understand what it takes to make a AAA game.
I agree. I too find the argument quite weak, but it's nevertheless the only argument I've heard, which I could make sense of.
This should be higher. You actually answered OPs question rather than speculate or get involved in a paradigm Holy War.
Allocating everything at startup is fine, but you can't always do that. RAII is also more than memory allocation - it can manage file handles, sockets, locks, etc. for you. I know Jonathan Blow's arguments, and frankly I think he's a bit misguided about C++. For example, a lot of his claims regarding exceptions are misleading at best, but that's a whole other discussion.
What costs? RAII guarantees cleanup regardless of which codepath you follow exiting the scope. What the compiler generates corresponds to what you would have done manually to get the same behaviour, i.e. inserting a (possibly inlined) cleanup function call at every exit. Are you thinking of stack unwinding?
you mean json?
Actually, I believe it's the opposite of what /u/tending describes. The default behaviour right now is to use standards-compliant implementation: https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_dual_abi.html There is a way to use the old implementation and usage of both implementations can typically co-exist for the most part.
Well the error messages would depend on the compiler, but it should theoretically shorten that wall, as template errors could be determined farther up the call stack assuming you make appropriate concepts. I believe that `foo(auto x)` is part of the proposal, so yes, you would be able to get rid of the `template&lt;typename T&gt;` part without even having to write a concept.
Nah, we need proper reflection support in C++, which would make serialisation tasks so much easier. But we won't get reflection in the standard for at least another 5 years from today.
When I see the expression "C/C++" I usually go elsewhere. It is similar to asking for "C/Z80-assembler".
I tend to code objects as read-only as possible (everything that *can* be const *must* be const), so this means nearly all of my classes are RAII by necessity. If you have an instance of an object, it's guaranteed to be 100% initialized and ready to use. When it goes out of scope (via local scope or shared_ptr), it is cleanly removed with no leaks of any kind. I don't understand this "RAII is more verbose!" mindset I'm seeing all over the place now. My objects are no more or less verbose than they used to be. The code just got shifted to constructors is all. Anyhow, this means the objects are simply named after what they represent or what they do.
&gt; just be sensible like you would for any other class Careful, man. We apparently downvote good common sense 'round these parts.
I am intrigued by his idea that programming should be fun and aesthetic. I am interested to see where he goes with his language. In any case, I do this there is good reasoning to look at how you might redesign programming languages that fit today better. C++ was written in 1979 and a lot has changed since then.
Unfortunately in some projects names longer than 2 words can be pretty common. One example is Unreal Engine 4: UPrimitiveComponent* Primitive = MyActor-&gt;GetComponentByClass(UPrimitiveComponent::StaticClass()); USphereComponent* SphereCollider = Cast&lt;USphereComponent&gt;(Primitive); if (SphereCollider != nullptr) { // ... } I honestly find that code to be really damn confusing, specially because the PascalCase is applied everywhere, from classes to variable names, whereas the Unity equivalent code (C#, but irrelevant) is much easier/faster to read: Collider collider = game_object.GetComponent&lt;Collider&gt;; SphereCollider sphere_collider = collider as SphereCollider; if (sphere_collider != null) { // ... } 
Why isn't it? Big companies write their own STL all the time.
I'm a big fan of underscores myself. I only use PascalCase in those rare instances where it actually is more readable, and then only for method names and constants.
I brought it up because I've had genuine confusion over it. In the last month, at least. For some reason, discussions here (my office) that mention the original STL are not as rare as you might think. There are a few Stepanov fans around, especially with his 2 books out over the last few years, and the interest in generic programming coming from the concepts work.
&gt; Stack variables are destroyed when going out of scope, which is common knowledge. To know if a constructor or destructor is expensive, you have to inspect every type on the stack to see if they have expensive constructors or destructors. This is much harder to do than to just look for function calls. &gt;If an uncaught exception is thrown and propagating up the stack, the stack is unwound, which causes a bunch of function calls. Pretty irrelevant here. Games don't use exceptions. &gt;Like the AAA game industry has a perfect track record of well-performing releases. Just look at the last year and a half AAA releases and tell me again with a straight face that the industry is competent at making well-performing software. You have no idea what you're talking about. The conditions programmers are required to meet for games are absurd. It's a minor miracle hitting 30 FPS on a game with a 2 year development cycle.
Concepts Lite. That is, without concept maps.
As I thought: for a samll amount of XML, method rarely matters; for a large amount, the non-standard syntax prevents any XML tools like validation or even correct syntax highlighting. So maybe for a large amount of small XML snippets to be maintained...
&gt;To know if a constructor or destructor is expensive, you have to inspect every type on the stack to see if they have expensive constructors or destructors. This is much harder to do than to just look for function calls. True, and for that reason should constructors and destructors be extremely lightweight. Besides, the work still needs to be done, so if you put init-calls all over the place you still need to inspect. &gt;Pretty irrelevant here. Games don't use exceptions. Some games don't. &gt;You have no idea what you're talking about. The conditions programmers are required to meet for games are absurd. It's a minor miracle hitting 30 FPS on a game with a 2 year development cycle. I know. It was just a snarky comment on the fact that the AAA industry's "best practices" don't seem very convincing lately with games like the PC version of Arkham Knight, Assassin's Creed Unity and a dozen of other infamous recent AAA titles.
Functional as in haskell? or do you mean imperative like C? Basically the new and delete operators can be overloaded on a per class basis so every object of that class that is allocated/deallocated using new/delete (or using smart pointers) uses the given allocation/deallocation function. Whenever you allocate an object using new it actually calls two functions, operator new, which is basically malloc, returns a pointer to a free block of memory, and then it calls the constructor. deleting an object first calls the destructor and then calls operator delete(free). A* a = new A; delete a; is the same as: A* a = (A*)::operator new(sizeof(A)); //allocates some memory new(a) A; //placement new(simply calls the constructor on a memory adress) a-&gt;~A(); //calls the destructor ::operator delete(a); //deallocates the memory Overloading the new and delete operators for a class replaces the calls to ::operator new and ::operator delete for all objects of that class. Here is a template pool allocator that I wrote myself and use for almost everyting: template&lt;unsigned BlockSize, unsigned ChunkSize, unsigned NumChunks = 64&gt; class ArenaAllocator { private: union Block { Block* next; char padding[BlockSize]; //T t; }; Block* _memory[NumChunks]; Block* _next; public: void* getAdress() { if(_next == nullptr) reserve(); Block* block = _next; _next = _next-&gt;next; return (void*)block; } void* getAdress(size_t size) { if(_next == nullptr) reserve(); Block* block = _next; _next = _next-&gt;next; return (void*)block; } void freeAdress(void* block) { ((Block*)block)-&gt;next = _next; _next = (Block*)block; } void reserve(uint8_t num_chunks = 1) { for(auto&amp; chunk: _memory) { if(chunk == nullptr) { chunk = new Block[ChunkSize]; for(unsigned m = 0; m &lt; ChunkSize - 1; ++m) chunk[m].next = &amp;chunk[m + 1]; chunk[ChunkSize - 1].next = _next; _next = chunk; break; } } if(num_chunks != 1) reserve(num_chunks - 1); } void deallocate() { _next = nullptr; for(auto&amp; chunk: _memory) { delete chunk; chunk = nullptr; } } ArenaAllocator() { _next = nullptr; for(auto&amp; c: _memory) c = nullptr; } ~ArenaAllocator() { this-&gt;deallocate(); } }; given that you can pool allocate all dynamically allocated objects of a certain class like this: class Foo; ArenaAllocator&lt;Foo, 256&gt; foo_pool; class Foo { //content public: void* operator new(size_t s) {return foo_pool.getAdress();} void operator delete(void* ptr) {foo_pool.freeAdress(ptr);} }; Foo* f = new Foo; //this object will be constructed into the pool
You can write your JSON in XML. https://www.reddit.com/r/programming/comments/h0chx/need_more_enterprise_introducing_jsonx_an_ibm/
I'd like to add: * When returning error codes the code becomes harder to read because you have to litter it with error-checking if-sentences everywhere. * Exceptions are theoretically slightly faster than checking return codes in the case of no exceptions, because throwing is a glorified goto, so you don't pay for all those if-sentences. There are a lot of myths regarding exceptions, even among professionals.
Exceptions really aren't that complex. I have a suspicion that you think they are because you are not familiar with them. I suggest you find a few talks about the subject on Youtube and get a good grasp on what they actually are.
A side effect is if a function changes the state of the application, such as setting a global variable, writes to a file, etc. Setting an error code as a global variable is a side effect. A pure function (i.e. a function without side effects), who only depends on it's arguments and only returns a return value without changing the application's state is much much easier to grasp and reason about. Side effects occasionally leads to some subtle bugs. It's harder to test functions with side effects, and functions with side effects can potentially behave differently when called again - even with the exact same arguments and return value. Because of these problems, some have taken the rather drastic route of completely avoiding all side effects. This is how functional programming arose.
http://www.vandenoever.info/blog/2015/07/05/literal-xml-in-c++.html#how-to-use-it shows looping over a set of inputs. This is done with a functor. sink &lt; div &lt; create_paragraphs{{mylist}} &gt; div; There is currently no way to write a loop inside of such a statement. Suggestions on how to do that are very welcome.
&gt;To know if a constructor or destructor is expensive, you have to inspect every type on the stack to see if they have expensive constructors or destructors. This is much harder to do than to just look for function calls. A function call will not tell you much about the cost of constructing an object unless you know what that function call does. You will not get around that abstraction by not using RAII.
This is pretty much the only cs-related subreddit I follow these days because there is a much greater focus on perf and low-level stuff (within reason) than on most others, even /r/gamedev. I think OP is thinking of a strictly low-level/high-perf sub, but this is the best one as far as I know. Having it burrowed in higher-level stuff is not a problem since the sub is slow enough as it is. And you can always learn good stuff about high-level programming as well. whynotboth.jpg
I agree with recommending TC++PL. It's both a tutorial, library reference, and a style guide. Stroustroup explains *why* he chose the design he did and gives guidelines on using language mechanisms. 
Hm... this is imho a common problem, but the suggested approach shadows the structure of the xml again - so the original goal fails here. Unfortunately I cannot make a better proposal 😉
That's an error, the exception is thrown only if the mutex was locked by this `unique_lock`, as it would cause a deadlock. The relevant section of the standard is 30.4.2.2.2 of [n4431](http://open-std.org/JTC1/SC22/WG21/docs/papers/2015/n4431.pdf): &gt; void lock(); &gt; &gt; 1 Effects: pm-&gt;lock() &gt; &gt; 2 Postcondition: owns == true &gt; &gt; 3 Throws: Any exception thrown by pm-&gt;lock(). system_error if an exception is required (30.2.2). &gt; system_error with an error condition of operation_not_permitted if pm is 0. system_error with &gt; an error condition of resource_deadlock_would_occur if on entry owns is true.
&gt; The ctor of unique_lock will lock the mutex; if you want to call unique_lock::lock explicitly, you must call unique_lock::unlock before that. This much is clear, but cppref' seems to imply that lock() will fail if the mutex is locked at all (e.g. by another thread), even when the calling thread does not hold the lock.
`lock()` throws if the `unique_lock` instance it's called on currently owns the mutex (&amp;sect;30.4.2.2.) That's not the same as the mutex being locked — it could be held by a different thread, but it must not be held by this instance — so that wording does need to be updated, yes. 
Msvc does have a pragma message.
&gt; if the RAII wrapper gets moved and out-lives the Device, DestroyResource will call on a dangling Device*. Ouch. I've learned that at some point, an application with enough object lifetimes to track converges on something resembling a GC to manage reliably. I can easily see a setup where things are flipped around, and a Device has a list/hash/map of `Resource` instances to destroy upon its own destruction. Maybe there's some smart-pointer types that can come in handy? Of course, there are innumerable permutations here, the essence of which is the fact that `Device` has a longer lifetime than `Resource`.
You're still bringing all the element and attribute names into the function, and there's more than just "p". There's things like a, b, i, s, id, name, rel, src, and so on and so forth; and you can add more in the future. The following might be a solution: namespace XmlLibrary { namespace h { // declare HTML tags here ... }} Then you could do this: void yadayada() { using namespace XmlLibrary; XmlWriter() &lt; h::html &lt; h::body &lt; ... } That would clean up the issue somewhat... But it still leaves the operator overloading. I mean, I tip my imaginary hat, this is nifty: &lt;img(src="http://example.com/hello.jpg",alt="Hello")&gt;img But... that's a new language. It took me a while to figure it out: template &lt;typename String_, const String_* Ns, const String_* Name&gt; struct XmlTag { ... template &lt;typename... Atts&gt; ElementStart&lt;Self, Atts...&gt; operator()(Atts... atts) const { return ElementStart&lt;Self,Atts...&gt;(atts...); } ... AttributeNode&lt;Self&gt; operator=(const String&amp; val) const { return AttributeNode&lt;Self&gt;(val); } }; ... using SrcTag = XmlTag&lt;QString,&amp;empty, &amp;srcTag&gt;; using AltTag = XmlTag&lt;QString,&amp;empty, &amp;altTag&gt;; ... xhtml11::SrcTag src; xhtml11::AltTag alt; That's ingenious and all, but... gosh, man. Code that uses too many of these constructs becomes write-only. It's cool if a pattern like this is easily recognized and frequently used, but that's a gamble. If few people adopt this, and familiarize themselves with it, this is going to be hard for someone down the road to comprehend and maintain...
That's an interesting alternative syntax. Thanks for the hint. XSMELL uses macros [1] to make the schema definition simpler. Compared to Blasien it has some limitations. It does not check nesting and cannot handle the use of arbitrary attributes because attributes are member functions. An alternative syntax in XSMELL that allows arbitrary attributes would be: &lt;img(src("chucknorris.png"),alt("sneezing eyes open"))&gt;_ &lt;!img&gt;_ or &lt;img(src="chucknorris.png", alt="sneezing eyes open")&gt;_ &lt;!img&gt;_ or &lt;img(src="chucknorris.png", alt="sneezing eyes open")&gt;!_ [1] https://bitbucket.org/edd/xsmell/src/3551ac07c4711a87f3f70dfa703a87eee3a7e292/xsmell.hpp
And in C++14 this can use auto in the lambda: &lt;for_each(items, [](auto sink, auto text){return sink 
Yes, still good discipline to use RAII. Anytime you find yourself having begin/end, create/destroy, etc kind of APIs, it's a very good candidate for using RAII as it ensures you never forget. Where it's of more questionable benefit is when your begin/end is across scope (i.e. you have a higher-level begin/end); even then I would say use it.
I'm not sure I'm understanding this. If you need the device to destroy the resource then why can you ever have a resource that outlives the device? Aren't you pretty much hosed at the point anyways, if there's nothing pointed to at the device *? It sounds like the lifetimes of these resources and devices are related so they probably need to be coupled in some way. Also, side note, why the hell are you worried about a single extra pointer for the device *? Unless you have tons (and I mean tons) of these resources that should be negligible in the grand scheme of your program's memory usage.
Sorry, but without context, I'm just reading garbage ಠ_ಠ
Beware that many if not most game developers are proponents of "C with classes" style of coding and would say things like "I wish it was feasible to code everything in assembly". It has to do not only with valid technical reasons, but also with culture. For example, see [this talk by Mike Acton](http://www.youtube.com/watch?v=rX0ItVEVjHc) (if you haven't seen it, I think it would be an interesting resource in the context of your question). When towards the end of the video he is asked why he is using C++ in the first place (instead of C), he doesn't really have an answer. Also, while there definitely are valid concerns about performance, a lot of this is cargo cult - I've seen quite a few people arguing for contorted style and basically for coding in C with just some syntactic sugar added to it from C++, ostensibly in the name of performance (and sometimes even readability), at the same time never bothering with profiling, not having any real grasp of assembly, writing everyting in this "highly performant" style instead of saving it for some critical parts of the code, etc. I would advise you to keep in mind that: * if you're interested in writing optimized code, you should have good understanding of what makes the code you write efficient and whether it's applicable in your case. I say this because I've seen lots of people, especially in gamedev, using built-in arrays instead of vectors, never using the standard library because it's "slow" and stuff like that - simply because they were told by somebody that "if you want perf, never use STL", "programmers who care about perf only use arrays" - that's just cargo cult; * realize that a lot of the time, performance doesn't matter. If you're writing a small game or a casual game, it doesn't matter 99% of the time. If you're working on an AAA game, it still matters only part of the time; * always make sure that you have some valid metrics of what you're optimizing. If it's not worth the time to have them, then it's not worth optimizing. I saw ugly "efficient" code that was written like that just because "it's obviously more efficient to do it that way". Benchmarks or it didn't happen; * don't buy into the idea that game developers care about performance all of the time and are superstars in this regard. Like, for example, the XCOM remake would visibly lag on a superfast machine if the number of saves is more than N, where N is about 50-100 (I'm not sure if it was fixed later, but the game has shipped like that) - that's obviously an inefficient algorithm (and they didn't even move the loading to a separate thread), and a very visible problem, and also it's definitely an AAA game; * in the context of OOP bashing, a lot of the time the OOP presented would be a strawman - crazy hierarchies with endless inheritance and every method virtual; * if you limit your learning of C++ to listening to only what game devs say, you will get a very specific (and limited) view of the language. Some of them would flat-out reject a lot of C++ killer features like templates with the arguments that, in the end, amount to "it's too hard" (it would be presented as "unmaintainable", "unreadable", "obscure" and stuff like that). My feeling is that quite a few of them are not so much programmers as they are domain experts (where their domain would be things like the workings of specific hardware and knowledge of algorithms related to rendering). Basically, I'd advise to focus on the important domain-specific things (like true performance concerns) and mostly ignore their choice of language tools to get there.
What kind of complexity are we talking about here? Is it syntactic/semantic complexity in the source code or complexity in the compiled binary?
Sounds to me that what you want is a managing class which takes care of your resources as well as keeps your device in check. Treat those resources as a vector would treat non copyable items.
This is great. Thanks for the post.
In type theory variant&lt;A,B&gt; is different from variant&lt;B,A&gt; (see: https://en.wikipedia.org/wiki/Tagged_union). We also need the difference in order to generate a proper ordering for operator&lt;. I'm not sure I understand the "default initialization cost" since one can always assign a variant explicitly if they so choose.
That depends on the data set and the hardware. But I would guess that your program has still lots of room for optimizations.
This is exactly why I came here, haha. I've only been following HMH for a couple of months, and it's my first jump into the C world coming from Java. I'lll still follow HMH for a while, but I was looking to expand my understanding with other points of view. :)
I've been programming for almost a decade now professionally, but almost all of that time has been using Java to do enterprise web stuff. A big chunk of that time was working for Amazon.com.
You've got quadratic complexity on your hands, friend. If you post your code here, we can probably help you get your algorithm cut down to something more reasonable.
Thanks for the reply. The arguments I have heard are to not worry about optimizing anything until you have to. They definitely talk about using performance timers when it's time to worry about performance, and the only time they jump into any assembly (as far as I have seen) is when they are trying to optimize math functions that are used quite a bit. Jonathan Blow made the point that Braid was like 80,000 of code and only about 6,000 of those lines had to be heavily optimized for performance. I think colleges and industry best practices have you doing a lot of premature optimization and in my experience I've seen a lot of overly complex code bases arise because of it. Casey's makes a point that the thing he optimizes the most is dev time. As an example, he doesn't like to use templates because it adds increased compile time and reduces the quality of error messaging. He makes some good points, but I do enjoy understanding other views, which is why this post exists. :) Of course the idea behind Handmade Hero is to write everything by hand, as an educational exercise. So some of what he does on the project isn't what he would do in his normal day job.
That makes a lot of sense. Are you assuming then (in your other comment) that the error message would be global? If you supported multiple return values from a function (error code and result) you could still maintain pure functions? edit: I realize the other comment was by a different person now, but I'll leave my post unedited.
Changing the order of the types in Haskell sum types has no observable behavior in a program (unless one lets the compiler generate code automatically by e.g. deriving `Ord`). That is, one can change the sum type `data T = A | B` to be `data T = B | A` without altering the program's behavior. C++'s Eggs.Variant goes pretty far into defining an ordering `lhs &lt; rhs` for every variant: - if both `lhs` and `rhs` have an active member of type T: `*lhs.target&lt;T&gt;() &lt; *rhs.target&lt;T&gt;()`, - else if `!rhs`: `false`, - else if `!lhs` : true, - otherwise: `lhs.which() &lt; rhs.which()`. Only the last step depends on the order of the types within the variant and it is there to give an arbitrary unique order. Note that this order is as arbitrary as `rhs.which() &lt; lhs.which()`. For instance it will give a non-meaningful order to `variant&lt;std::true_type, std::false_type&gt;`. There are alternatives, for example D's `std.variant` throws an exception if the comparison is not sensible (see [opCmp](http://dlang.org/phobos/std_variant.html)), and while Haskell let's you derive this order automatically, that is opt-in, the user can always derive the order manually. &gt; In type theory variant&lt;A,B&gt; is different from variant&lt;B,A&gt; (see: https://en.wikipedia.org/wiki/Tagged_union) Could you point to the part of the article where this is explained (or any other article)? &gt; I'm not sure I understand the "default initialization cost" since one can always assign a variant explicitly if they so choose. This only happens when one does not assign to a variant explicitly. As a consequence changing the order of the arguments might require to inspect all the places in a code base where the variant is default initialized without assigning it a value of a particular type explicitly. At this point we are better off without default initialization.
My Java is quite rusty, but if memory serves Java exceptions conceptually reasonably similar to C++ exceptions. Pondering about a language without exceptions is a good exercise, but in reality the programmer can't possibly anticipate everything (e.g. the user yanking out the usb stick you are reading from or the network connection resets), so there has to be some sort of error reporting mechanism. So what good alternatives are there to exceptions? Returning error codes, or setting error codes with a global variable have serious flaws and weaknesses too like /u/TomSwirly suggested. Even if our only concern was performance the choice of what to use isn't obvious.
No problem, I'll be happy to answer anyway. There are two ways of giving the caller an error code - returning it or as a side effect. Using a side effect can be done with a global variable, but doesn't have to. Sometimes you (as a user of the API) need to call a getter to access the stored valuable, but the principle is the same. You can return an error code, possibly together with other values (e.g. returning a struct, taking a pointer/reference to a struct as an argument, etc.), but you still get all the problems of his first bullet list. It would be a pure function though because of lack of side effects.
Not every algorithm runs in linear time (that is, scaling proportionally to the size of the input). There's a whole subfield of computer science known as 'algorithm analysis', where we figure out how the time taken by an algorithm scales up as you increase the size of the input, for various algorithms. It turns out that sorting, even with constant-time comparisons, inherently requires N\*log(N) time, so it will never scale linearly with the size of the input. However, a naive implementation might require N^2 time, which is way worse. The increase from 5s to 20s on a doubling of the input size sounds like an N^2 algorithm, which would suggest approximate running times of 2 minutes for 50000 lines and 27 minutes for 180000 lines. This matches what you're reporting pretty well. If we could see your code, we could probably tell whether or not it's an N^2 algorithm, and give you a faster one if it is.
Not sure if this shouldn't be in /r/cpp_questions
Ah, microcontrollers and the extreme hardware limitations. I understand why exceptions aren't well suited for your field. They can be beneficial in other fields though.
&gt; True, and for that reason should constructors and destructors be extremely lightweight. Then you aren't doing RAII. RAII says "if I have an object, it's valid" - meaning your expensive initialization and shutdown needs to be done in constructor/destructor. &gt;Besides, the work still needs to be done, so if you put init-calls all over the place you still need to inspect. Yes, but with a function call, it's immediately obvious at the calling site that work is being done. It is not immediately obvious that work is being done when creating an object on the stack, or when it goes out of scope. &gt;Some games don't. I would be very surprised if you found a AAA game that used exceptions, especially one on consoles.
&gt; RAII says "if I have an object, it's valid" - meaning your expensive initialization and shutdown needs to be done in constructor/destructor. Of course. I meant as efficient as possible. My point is the work has to be done no matter how it is expressed in the code. &gt; It is not immediately obvious that work is being done when creating an object on the stack, or when it goes out of scope. It is, when it's a part of your mindset. I literally see work when I see a stack object declaration or a closing bracket. &gt; I would be very surprised if you found a AAA game that used exceptions, especially one on consoles. I have gotten exceptions before, but I don't remember which game(s) it was. I know nothing about consoles, so I take your word for that.
&gt; A function call will not tell you much about the cost of constructing an object unless you know what that function call does. You will not get around that abstraction by not using RAII. That's not the point. The point is that you now obviously see a function call as something you may want to inspect. You don't get that obvious flag from constructor/destructor/overloaded operators.
Memory management is Java consists mostly of passing a flag to the JVM to increase the maximum heap space. And pointers exist, but not beyond dealing with a few "pass-by-value" edge case. Dealing with pointers to pointers makes sense to me, but it's not something that is intuitive or second nature to me yet. Things like data structures, run-time complexity, algorithms, are fairly second nature to me. C++ seems like a much broader world, and finding a place to jump in can be a slightly daunting task. I'm also trying to think about what pain points I've had with my past experience and what sort of a programmer I want to be going forward. I have lost count of how many times I've had to deal with someones factory factory that was only ever used to create a single object and I'm not sure how many hours I've spent writing getters and setters for objects with absolutely no benefits over just making the members public. These sorts of things make sense on paper, but in practice just seem to make it harder to get things done.
Indeed. I was surprised to see he is a bus driver and not a professional programmer. 
I used to work on a product with extensive plugin capabilities. Plugins that run in your process are a bad idea in the long run because they incur high compatibility and security costs. For example, if a plugin is running in the same process as your application then it can do anything your application can do and should be able to read and modify data elsewhere in your process. It is difficult to create a useful threat model in which your process may be attacking itself. Similarly you may run into other problems: What if someone writes their plugin in .Net 3 and another in .Net 2? Both plugins cannot be loaded at the same time because only one version of the .Net Framework can be loaded per process before 4. What if the plugin crashes a lot? Your product will take the blame. Etc. An alternative is to have a host process which loads a single plugin and which communicates with your main process. So many concerns are resolved with this architecture and there are several advantages. For example, you can now change the protocol between your application and the host at will and still maintain compatibility with older plugins. You may be able to detect problematic plugins and report issues to the appropriate ISV, etc.
In case anyone is curious, here's his self-promo with him driving his coach/bus? https://www.youtube.com/watch?v=3bIcbnDXSRg I'd like to meet this guy, he's very intriguing, and also a hint of robot.
That's a valid solution to the dangling problem, but more overhead. Safety or efficiency, we have to take our poison.
Interesting. It's not really related to the RVO, what I didn't think about was move constructing the return from the member variable. It does indeed work. Your argument can be applied just as easily to function inputs; why not pass by value? Notice btw how if Foo's constructor was by value, that would also avoid the issue. By the way, I don't know that I've fallen into that particular pit once, in years of programming. Returning something by value when you can return by const ref may be appropriate, but you are forcing the caller to pay a cost they may or may not want. They can easily make a copy themselves anyway. Adding interface for manipulating those guts is just bloating your object. I'd add last of all that by adding rvalue overloads that return by value consistently, it actually neatly solves the example you gave. So it seems like const &amp; string get() &amp; + string get() &amp;&amp; is better than return by value. Return by value is simpler, but I'd definitely look at the pair of overloads anytime I thought performance might be an issue in client code.
This is good to hear, I was worried that it would default construct the second type. Interestingly, that means that those that prefer a variant with no default constructor can trivially create one: class ethereal { ethereal() == delete; ethereal(const ethereal &amp;) == delete; ethereal(ethereal &amp;&amp;) == delete; } template&lt;class ... Types&gt; using my_variant = variant&lt;ethereal, Types...&gt;; Or something similar. Since ethereal can never be created, there's no risk of putting one in the variant, so it's not necessary to check it for the "invalid" type.
Prefer make_unique to new where possible. Or if you're deliberating coding 11 and not 14, make note of that fact and at least the existence of make_unique. 
At first I was like, "what..." and then I was like, "woah...". This dude is a beast. The MR Rodger's of hobbyist programming.
&gt;an element inserted into a container must be cleaned up by the same container Must is a big word. What about naked or shared pointers?
Please let us know how it works for you - it's the first release where we support it officially!
I don't know what the current plan is, but since both you and /u/kozukumi below have asked we might need to look into it. I have a hazy idea that the reason that these haven't been provided is some sort of issue with GDB, but don't quote me on that.
Well, sprintf_s is in no standard... Is there a reason why snprintf hasn't been used?
MSDN describes DevDiv/VS's CRT, msvcr120.dll in 2013. Windows' CRT, msvcrt.dll, was effectively forked long ago and is missing many features. (This has been resolved by 2015's Unified CRT, ucrtbase.dll or whatever the name is.) Third-party programs aren't supposed to use msvcrt.dll, but MinGW/MinGW-w64 does anyways. This is a dirty hack, due to the GNU project's lack of a Win32 CRT.
Uhm yeah, I guess I'll just bundle them with the application and release in different consecutive versions as new features. Thanks!
Won't do, I think they make concepts nicer to use but since the C++ ecosystem is already wired to work around this I don't know how much value can this bring in practice. I would be more excited to see how the Open Multi Methods proposal would/could interact with Concepts Lite: `foo(virtual Concept* a);`, where `a` is then a fat pointer with the vtable embedded in the pointer.
Bare in mind that you write code like this today: if (condition) return; to spare you some braces and zero seconds. When your future self comes to that same code tomorrow because a test fails, and wants to e.g. print something: if (condition) std::cout &lt;&lt; "exiting" &lt;&lt; std::endl; return; he is really going to hate you. Why? Because doing this: if (condition) { // std::cout &lt;&lt; "exiting" &lt;&lt; std::endl; // doesn't break your code return; } would have costed you nothing, but not doing it costed your future self seconds/minutes/hours of debugging time.
Does is really matter ? In order to install a malicious or non-endorsed plugin a "hacker" would have to * Have a preexisting access to the user computer, in which case you are doomed * Make the user download the plugin from a third party site, either voluntarily or by phishing. * Hack the store, if you provide one. The last case must be taken into account, there is little to nothing you can do for the other two. On windows, it may be possible to use some api to check a binary signature prior to installation ( and all your binaries should be signed anyway). But keep in mind that a hacker could very well install a modified version of your application that skip the check. and the average joe won't be concern if the certificate of the main application changes. Mac come to increasingly long lengths to prevent applications to augment themselves after the initial installation, specifically over security concerns. Your best bet is to educate your users. Plugins often make for a great architecture, don't be to much concerned over client-side security / piracy. 
If the Device is the actual heavyweight parent class (like say a wrapper on a D3DDevice or a CUDADevice) you might be better with weak_ptr as you don't want resources keeping the device alive after it should have been destroyed. Another option is for the device wrapper object not to be destroyed in the C++ sense, but you call some destroy() method which releases everything but keeps the wrapper object itself alive. The the resource calls device-&gt;exists() before accessing it (or if that's an efficiency concern and it shouldn't really happen anyway, then assert on it instead). In this case we're assuming that owned resources are cleaned up when the device is released, so the RAII class has no work to do anyway. Also if it's a more lightweight view/handle onto the main device that doesn't acutally manage its lifetime or own its resources, then shared_ptr is ok. BTW the manual "device-&gt;exists()" technique also means storing an 8-byte pointer (which you're already worrying is too big) whereas shared_ptr and weak_ptr are typically 16 bytes (but check on your compiler). Also have a look at std::make_shared() and std::enable_shared_from_this (http://en.cppreference.com/w/cpp/memory/enable_shared_from_this) to avoid extra overhead.
As some users already mentioned here, there is such a thing: `shared_ptr` and `weak_ptr`. A shared pointer keeps track of weak pointers pointing to it, and 'notifies' them on destruction. 
Take a look at cppcomponents https://github.com/jbandela/cppcomponents It allows you to write C++ classes that can be used by different compilers and standard libraries. It also makes writing plugins pretty easy. You can use std::string, std::vector, std::tuple and such in your interface as well as exceptions.
If you're concerned that someone is going to create many resources from a single device, then you can create an RAII object supporting that specific goal, i.e. an object that encapsulates a single device and allows for the creation and management of many resources. If they are creating many resources all from different devices, then in any case you need some way of storing and keeping track of all the devices that go with the resources, so it's not really a waste. Your c++ API can have several different RAII objects, which fit different use cases. The same way we use both unique_ptr and shared_ptr.
&lt;3
The host application would be the dummy executable and plugins would still be dynamic libraries. The plugins themselves don't need to perform any IPC. As for cross platform considerations, I don't know. I haven't made a cross platform plugin system.
I'm kind of glad he's not a professional programmer, I'd hate having to pick his stuff up after him! Absolute beast though, love his voice.
How do you run dynamic libraries without hosting them in some sort of "dummy" process`?
For GUI apps with Qt : http://doc.qt.io/qt-5/plugins-howto.html , from "The Low-Level API: Extending Qt Applications"
The host application is the dummy process.
He is actually the reason I decided to learn to program. I don't want to be a professional programmer but I still want to be good at it. Seeing this guy do all this crazy stuff just for fun gave me a massive boost. He made me realise there are amazing programmers who just do it for fun not for a career.
This looks impressive! Any examples of this library in use in the wild?
I have helped somebody else to use this as a plugin system, though I do not know what the final software was. If you are interested, I would be happy to help you and answer any questions you may have about this, Just PM me.
Concurrency problems are *really* unreliable to solve with the "it seems to work" approach.
The use case I have in mind is a 'universal' database access program that at runtime can load database specific dlls (plugins) (e.g. MySQL, SQLite, Postgress etc.) that are compiled and linked to their respective native APIs separately.
It was this video that made me realise I can be a programmer without having to have a job as one https://youtu.be/_vbMJ3-LuFk?t=5m54s I have included the time from the relevant comments made in the video but the whole video is an interesting watch!
cppcomponents would be perfect for this. If you write a regular c++ abstract base class for this it is pretty easy to convert that to cppcomponents that can work across dll boundaries
[Bo Qian's tutorials](https://www.youtube.com/user/BoQianTheProgrammer/playlists) he uses vim.
make_unique/make_shared can't leak, for both push_back and emplace_back. new T(args) won't compile for push_back (as T * isn't implicitly convertible to unique_ptr/shared_ptr). new T(args) will compile for emplace_back **and can leak**. If vector reallocation throws, the exception will be emitted before a smart pointer has been constructed from the raw pointer. This is why modern code should avoid saying new as much as possible, and why I wrote up make_unique for C++14.
So I was playing around with C++11 constant expressions today and got the c++ compiler to generate hashes (using MurmurHash 2) for constant strings. Was a pain because the only thing you can do in constant expression functions is direct computation off parameters (i know its constant for the inputs, but no temporary variables) and the only control flow you get is the conditional operator and recursion (no loops or if/else, switch, etc.) (EDIT: in C++11, C++14 relaxes these rules but MSVC is barely getting c++11 support) Output: Hash of "Does a set of all sets contain itself?" = -2163680713539448014 Snippet from generated assembly: .type _ZL11aStringHash, @object .size _ZL11aStringHash, 8 _ZL11aStringHash: .quad -2163680713539448014 Useful for when you have a bunch of strings known at compile time (names of parameters) and you need an efficient way / constant comparison time of using them in a map, etc. You can have the compiler generate the hashes so you don't have to do them at runtime.
Neat trick. Are you aware that C++14 introduced generalized constexpr which lifts the restriction on temporary variables, loops, if/else etc?
Thanks for the explanation - I hadn't quite thought the DLL-setup through. Looks like you need to configure the headers with --enable-secure-api, which is [off by default](http://sourceforge.net/p/mingw-w64/mingw-w64/ci/master/tree/mingw-w64-headers/configure.ac).
An advantage of OP's code is that it will work with VC 2015. (They've [announced](http://blogs.msdn.com/b/vcblog/archive/2015/06/02/constexpr-complete-for-vs-2015-rtm-c-11-compiler-c-17-stl.aspx) support for C++11 constexpr for RTM, but not C++14)
ah yeah.. i kinda meant how did you implement is_valid! :)
So nice. I really liked [llvm::SwitchString](http://llvm.org/docs/doxygen/html/classllvm_1_1StringSwitch.html) but your implementation definitely beats it with simplicity and efficiency.
This isn't a place for student programming questions. You need to use books, read tutorials, try out code, and ask questions of the staff and other students at your school. It sounds like you are not ready for C++ (I think schools teaching it as a first language is a sign the school has no idea what they are doing). If you can look into python I would recommend typing thing into a REPL while reading tutorials. Object Oriented programming isn't a big deal or difficult to get, it is just packaging data and code into one piece. Get something simple to work and move on to trying something else. Most of the time when questions like this come up the person just isn't actually putting in the work. You have to put in time and effort. No book or question asking will make up for this. This isn't something that you can read about for an hour 3 times a week and suddenly know. 
With people who are struggling to do something that has a wealth of information available, yet still asking for help there is really only one question that I need to sort things out: What have you tried so far?
No worries :-) userR! (on [R](https://en.wikipedia.org/wiki/R_%28programming_language%29)), pretty interesting stuff (kinda comparable with Python in the way I use it, but only on a superficial level overall, some similar trade-offs, but also some differences). // I assume you're familiar with either Python or R since you're into machine learning :-)
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**R (programming language)**](https://en.wikipedia.org/wiki/R%20%28programming%20language%29): [](#sfw) --- &gt; &gt;__R__ is a [programming language](https://en.wikipedia.org/wiki/Programming_language) and software environment for [statistical computing](https://en.wikipedia.org/wiki/Statistical_computing) and graphics. The R language is widely used among [statisticians](https://en.wikipedia.org/wiki/Statistician) and [data miners](https://en.wikipedia.org/wiki/Data_mining) for developing [statistical software](https://en.wikipedia.org/wiki/Statistical_software) and data analysis. Polls, [surveys of data miners](https://en.wikipedia.org/wiki/Rexer%27s_Annual_Data_Miner_Survey), and studies of scholarly literature databases show that R's popularity has increased substantially in recent years. &gt;R is an implementation of the [S programming language](https://en.wikipedia.org/wiki/S_(programming_language\)) combined with [lexical scoping](https://en.wikipedia.org/wiki/Lexical_scoping) semantics inspired by [Scheme](https://en.wikipedia.org/wiki/Scheme_(programming_language\)). [S](https://en.wikipedia.org/wiki/S_(programming_language\)) was created by [John Chambers](https://en.wikipedia.org/wiki/John_Chambers_(programmer\)) while at [Bell Labs](https://en.wikipedia.org/wiki/Bell_Laboratories). There are some important differences, but much of the code written for S runs unaltered. &gt;R was created by [Ross Ihaka](https://en.wikipedia.org/wiki/Ross_Ihaka) and [Robert Gentleman](https://en.wikipedia.org/wiki/Robert_Gentleman_(statistician\)) at the [University of Auckland](https://en.wikipedia.org/wiki/University_of_Auckland), New Zealand, and is currently developed by the *R Development Core Team*, of which Chambers is a member. R is named partly after the first names of the first two R authors and partly as a play on the name of [S](https://en.wikipedia.org/wiki/S_(programming_language\)). &gt;R is a [GNU project](https://en.wikipedia.org/wiki/GNU_project). The [source code](https://en.wikipedia.org/wiki/Source_code) for the R software environment is written primarily in [C](https://en.wikipedia.org/wiki/C_(programming_language\)), [Fortran](https://en.wikipedia.org/wiki/Fortran), and R. R is freely available under the [GNU General Public License](https://en.wikipedia.org/wiki/GNU_General_Public_License), and pre-compiled binary versions are provided for various [operating systems](https://en.wikipedia.org/wiki/Operating_system). R uses a [command line interface](https://en.wikipedia.org/wiki/Command_line_interface); there are also several [graphical front-ends](https://en.wikipedia.org/wiki/Graphical_user_interface) for it. &gt;==== &gt;[**Image**](https://i.imgur.com/nPxs84o.png) [^(i)](https://commons.wikimedia.org/wiki/File:R_logo.svg) --- ^Relevant: [^RKWard](https://en.wikipedia.org/wiki/RKWard) ^| [^Actor-Based ^Concurrent ^Language](https://en.wikipedia.org/wiki/Actor-Based_Concurrent_Language) ^| [^Journal ^of ^Statistical ^Software](https://en.wikipedia.org/wiki/Journal_of_Statistical_Software) ^| [^Knitr](https://en.wikipedia.org/wiki/Knitr) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+csw7k6s) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+csw7k6s)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](/r/autowikibot/wiki/index) ^| [^Mods](/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Call ^Me](/r/autowikibot/comments/1ux484/ask_wikibot/)
I really don't have a leg to stand on and I won't consume any more of your time, I know you're right, I completely agree with you. I'm sorry for wasting your time.But I appreciate your help mate so thank you for that - I was just drowning in the information that I can access, its a lot to digest and its a worrying feeling seeing so much stuff and understanding so little. I was just looking for the point in the right direction to a book that I could use to self teach myself that had exercises I could practise that best fits my ability instead of scaring myself with books books and books that I have trouble understanding. I see that now its near impossible to gauge my ability due to the sad description I have of my situation and that it is a stupid/overasked question. I was/am desperate and I am sorry for that. But also thankyou =]
You can use aliasing shared_ptrs when lifetimes are related - this might apply to some situations you are envisioning. 
Also maybe dial it back on the Adderall. 
Since you say "The plugins don't have to be necessarily written in C++", why not implement the plugins in a scripting language that runs in a sandbox in your main application. There are many such languages that you can easily plug in, like Lua, Python, Ruby, Javascript, and so on. That way you can control what the plugins can and cannot do much easier, and build in some form of piracy control into the delivery mechanism if you so desire. I can think of a few ways that you can achieve this, ranging from a simple bundled manifest that contains license information all the way up to a cryptographic signature that proves that the plugin was purchased for the same user as the application.
I get you're trying to be funny because its the internet, but no need to be rude ;/ Also you dropped this, https://img.4plebs.org/boards/pol/image/1385/75/1385757943224.jpg
This is great! Thanks a lot mate =] 
`auto` doesn't cover a huge number of use cases. auto index = ???; v[index] = 'a'; ... void some_function(???auto??? i, char v) { my_vector[i] = v; } ... struct MyIterator { private: auto my_index???; };
Is there any recourse if the hash of the input accidentally collides with the switched constant?
Oops. See [here](https://github.com/ldionne/hana/blob/e0b56a3d187447a870cd2a4d7246f07d7baa3e2f/include/boost/hana/type.hpp#L96)
My approach was writing a lot of code, then reading everything written by Meyers and "The C++ Coding Standards" by Sutter. Paying attention to the STL. Everything else seemed too long and misleading. But if you don't have time to write code, I don't know...
&gt;Technically you are right, you should use Container::size_type instead of size_t. But I do not know of any implementation where the two are different. The two are different on segmented memory architectures. So for example x86 processors provide segmented addresses using physical address extensions. This allows one to access up to 64 GB of RAM even on a 32 bit processor (Windows Server 2003). &gt;Is an index? unsigned unsigned defaults to `unsigned int` on many common platforms including Windows, meaning if you're on x86_64, you will be unable to index into a `vector&lt;char&gt;` beyond the first 4 GB.
By xml documentation, I mean this: http://i.imgur.com/bnjdgQo.png 
QBS? Oh noes, what is that? I thought they would make CMake their official build system...
What do you see under std::stringstream.str, anything useful that comes up? Perhaps I'm missing something, but I only see what I posted in the original post, which are the basic types and parameter names, no explanations.
if microsoft bothered to comment the STL it would appear, at least with Visual Assist, I don't use VS without it so not sure what stock VS does.
&gt;(the lack of two-phase name lookup and this associated rule are a known issue, and they're on the list of things to implement). If they had plans to implement them they'd have done it by now.
It seems too tool specific to do unless your IDE includes a built in compiler and standard library instead of relying on a third party implementation.
 class ShapeFactory { protected: ShapeFactory() { g_factories.push_back(this); } public: virtual unique_ptr&lt;Shape&gt; Create() = 0; virtual string getName() = 0; }; Just stay away from C++ please.
Checking for implicit type conversions (`-Wconversion`, `-Wsign-conversion`, and `-Werror`) also catches these errors.
I think this is one of the first things that would be done right if a redesign was possible, but due to backwards-compatibility, it isn't possible to change it.
I think that Rust could benefit from the least and fast types from &lt;cstdint&gt; as well.
ITYM `uint32_t` (a standard type). But that might suffer the same issues; if a size greater than 2^32 is wanted then it would be silently truncated. `size_t` should be used.
A mutex is an abstract data structure rather than a particular implementation. Spinlocks are a type of mutex that are implemented purely in user-space using atomic ints. The type of mutex you're describing would be implemented using OS based primitives. In fact, the advantage of a spinlock is it avoids the overhead that potentially comes from making an syscall and forcing a context switch if you only intend to lock a region for a very short number of cycles. The reason to avoid a spinlock is because in practice OS based mutexes perform a short spin of their own before suspending a thread which makes spinlocks only really relevant on platforms that don't have strong support for synchronization primitives.
Unfortunately, there is a real penalty to this on ARM. Arithmetic on the narrow width types is significantly slower than on the native word width. The C99 types int_fastNN_t are provided for exactly this case. There is also a good case for a separate {u}intptr_t, too - for the segmented machine category. size_t is wide enough for any single object, while intptr_t is large enough for any pointer. There is a real difference on the segmented memory machines. Finally, you also need an integer type which is a narrow as addressable memory. In C this type is 'char', and people often think it is equivalent to {u}int8_t. However, some conforming implementations do not provide int8_t at all - their narrowest addressable memory is a 16-bit integer!
Partially this is because Google's internal style guidelines very strongly discourage the use of the unsigned integer types.
Interesting, do you know why?
Just to chime in: I "used" eclipse for C++ at my last (embedded linux) job, probably because I guess I couldn't seriously learn vim/gdb fast enough or well enough. It sucked balls. The Visual Studio IDE (any version, as far back as 2005) beats eclipse or similar (traditionally java) IDEs _hands down_ at C++. If you want a full-featured C++ IDE and it's at all possible to use Visual Studio, use it.
&gt;Unfortunately, there is a real penalty to this on ARM. Arithmetic on the narrow width types is significantly slower than on the native word width. The C99 types int_fastNN_t are provided for exactly this case. I'd hope that the optimiser could handle that. While obviously that's a bit of a cop-out it should be the kind of thing a modern optimising compiler can do. As for the rest of your points... Well, yeah. It's difficult to balance making stuff easy-to-use for the common case with portability concerns. Oh, and Rust's usize/isize types are approximately equivalent to C's uintptr_t/intptr_t.
Most important feature - themes(since 3.4). http://i.imgur.com/Oj0O5uA.png
Can you vote for [this bug](https://bugreports.qt.io/browse/QTCREATORBUG-13791)? I really hate it. QtCreator can auto-complete smart pointers but don't do this because of this bug.
I think that the more general bug is that QtCreator doesn't really support variadic templates...
I'd recommend using codeblocks instead of Eclipse or that MS Visual Studio crap 
just use linux.
There's a reason this [site](http://www.ihateeclipse.com/) exists. I quickly developed strong feelings about it as well, as its own C++ syntax parser would fail on not-so-complicated stuff.
Actually, MS explicitly recommended using 'C' as a prefix for all classes. However, they also recommended using ~~Cthulhian~~ Hungarian notation, so they've improved massively.
I think this issue, together with countless other issues like this, the fragility of a C program. In the long run, the programming language C has done a lot of harm. I know what you will tell me, that is the programmer's fault and not the language's fault etc. Ok, it's the programmer's fault, shouldn't we provide the programmer with tools that save him from himself then? if programmers are easy to make mistakes that can potentially cost billions of dollars, then we should improve the tools and shield programmers from themselves to the max degree possible. 
Haha fair enough
I have many years java dev (now cpp hence reading this). Eclipse is also imho terrible for java.
Qt Creator would be a better choice. Code::Blocks might have all the right features, but it lacks the professional polish that Qt Creator has. Code::Blocks doesn't have a regular release cycle, still hosted on SF.net, still using SVN, no visible Codereview.
Another vote for QtCreator from me. A bonus of it is, it can use both a GNU toolchain as well as a VS toolchain, which I personally find really great.
Qt Creator is *not* based on Eclipse! [Cevelop](https://www.cevelop.com//) is based on Eclipse.
See [lambda functions](http://www.cprogramming.com/c++11/c++11-lambda-closures.html)
I'm not sure if you actually read the post.
thank you
QtCreator is not lightweight compared to Eclipse. This seems to be one of those "facts" that everybody knows but nobody has measured. On my Fedora box, QtCreator uses 3 gigs of memory, while Eclipse uses 2, even though my JVM settings allow it to use more.
Agreed. I personally decided to just drop it and continue to use Vim when I saw no will from Jetbrains to actually make the best usage of the existing tools like Clang, or compilation database. Yet another NIH syndrome IMO.
Every time an IDE convo comes up, I notice the same trends with regards to Eclipse. Then I realized Eclipse is very similar to c++: * From the internet, you'd get the idea it's terribly unpopular and disliked, but it has enormous real world usage * It's unintuitive and hard to learn compared to its competitors, but extremely powerful and featureful * Many people use old versions of it, and don't realize how much it has improved * Many of the people complaining about it have never learned to use it to its full potential By all accounts, Visual Studio is amazing, so I'd probably suggest using that on windows. On Linux, it's improved tremendously in the last couple of years and has been the best option for a while in any reasonably objective comparison. Maybe the newest CLion version will surpass it, at least for CMake projects.
I felt that way too at first, but I've seen that clang based parsing tools have a lot of issues of their own. Performance is one. Typically need some way to extract the exact compile command so they can't use heuristic resolution of includes, which means tons of time setting up your project instead of programming. (Straps on flame shield) I really recommend you try Eclipse with the Vrapper plugin. The vim emulation is phenomenal, and it doesn't tie you to any build ecosystem, and project setup is minimal.
I really think JetBrains are missing an opportunity by not having a community edition of CLion. With Qt Creator and Visual Studio Community (11 days until 2015 comes out) there isn't really anything CLion does that would make me want to switch from something else, especially not considering I would have to pay. They have community versions of PyCharm, IDEA, etc. so why not CLion?
Eitherway, using a variable like halfOfX seems a lot more readable than filling in x / 2 each time and less prone for accidental errors. It is in my vision much better to ask yourself "How can I make this code easier to read and maintain" than "will the compiler optimize this" (except in situations where speed is extremely important, but even in that case is trusting in the compiler often not the main may to improve speed)
I don't think I said it was clean code. :) I did say I found the second example to still be messy but cleaner than the first. So I already implied that the first example is the messiest of the three presented. I will say that the first example is probably about the cleanest you can get **in C** without resorting to proprietary extensions. But we are using C++ and thus we can do a lot better. That is why RAII is awesome.
Just tested with the CMake project I'm working on a Windows 7 64bit with lots of RAM: IDE | Private Bytes | Working Set -----|---------------|----------------------- Visual Studio 2013 | 251.716 K | 283.936 K Eclipse Luna 4.5 (CDT 8. 7) | 356.468 K | 245.664 K Qt Creator 3.5 beta1 | 226.008 K | 213.240 K Screen shot from Process Explorer [here](http://i.imgur.com/f6MUyHV.png). RAM usage is not everything, the responsiveness of the editor when you type and so on.
Does CLion play nice with the "auto" keyword yet? Last I checked, auto variables don't give you method/field suggestions like an explicitly typed variable would.
An asynchronous library would have been nice. [Shameless self promotion](https://github.com/daedric/httpp/blob/master/include/httpp/HttpClient.hpp). The problem with is that it is not really efficient though and do not offer too much control on the connection (cancelling an operation is quite hard).
I've seen plenty of people use these tools, so they could use for instance rtags. It generally means extra work and extra chance of something going wrong every time you do something that changes your compile commands, which means in particular every time you add a file. Almost all of the people who used these tools eventually got stuck. If you really want tight integration between IDE and build system, then maybe all this makes sense, but personally I don't see much advantage. Personally I wouldn't be so quick to assume that the people at Jetbrains are idiots. My guess is that they have solid technical reasons for writing their own parser. The team behind QtCreator has done all the work to use clang parsing on the backend; in fact you can use clang as the parser in QtCreator. But only for syntax checking and auto completion; it was judged to be too slow for code navigation. Unfortunately the ecosystem for c++ development in vim is light years behind. YouCompleteMe is probably the most advanced of the lot and it's missing ton of useful features that most IDEs (including Eclipse) offer. I can't think of a single reason I'd use pure Vim over any of Eclipse, QtCreator, or CLion with their respective vim emulators, other than remote work where I'm restricted to the command line.
Modern C++ compilers have gotten really good at optimization. Whether or not you pass in a temporary value (which should probably be const) depends on whether or not those parameters actually represent the same logical value. If they do and are thus likely to change to the same way in future updates then you assign them to a temporary value. If they just happen to be the same now but are not related and will change independently then stick to the current form.
It all comes up to the alias-analysis. The compiler must be able to prove that the value of `x` does not change inside each function call. If `x` is a local variable and you do not take its address, it is trivial, and I would expect it to be optimized.
I honestly don't see that as an issue. If I liked CLion better and thought it was better quality, I'd fork over $100 (or $200) tomorrow. Developers as lucky as it is that the tools of our trade are either cheap, or payed for by our employers.
IMHO, this is scary how smart they have become. One reason for using C/C++ was that you had total freedom over what the code was doing. It is not true anymore, the compiler may even change the intent of the code in order to optimize. Here is an example of that: https://lists.archlinux.org/pipermail/arch-general/2013-May/033531.html 
No they won't since that would produce incorrect results due to rounding. `-3 / 2` is supposed to equal -1, but using bit shifting you'll get -2. If you want performance over correctness, then you have to explicitly do the bit shifting.
I tend to agree with you. Whatever the benefits are of having a free edition, if they apply to IDEA, the apply to CLion. I've started a new project and decided to go with CodeBlocks. I may switch to CLion if it ends up looking like a no brainer, but inertia says I probably won't.
There's no way out of that. Even assembly is somewhat high-level these days. x64 supposedly has 16 GP registers, but real proccessors have hundreds and don't care about which specific one the machine code asks for - they allocate space from the pool as they please.
&gt; undefined behavior according to the ISO C standard
Works in my code. You can always click the variable and press Ctrl+Q to see what type it was resolved to. I did stumble upon some issues with `operator[]` though, so hopefully those will be resolved in this EAP build.
void func1(double y) { x += y; }
You are correct, I'm confusing Qt Creator with BBRY Momentics, which does a lot of what QtCreator does. 
Yup, and even then it's implementation defined behavior. As far as correctness goes, I've found that I've always wanted round towards negative infinity rather than round towards 0.
Probably the killer point of C++ nowadays (as opposed to C) is not so much to spit out some exact sequence of assembly, but simply to present the maximum amount of information possible at compile time so the compiler can be smart. Static polymorphism, tagged dispatch, etc, all work on this concept.
Can't you just specify the alternative compiler and options in the CMake file? 
&gt; I was actually looking around to a simple http server library Try my [shameless self promotion](https://github.com/BoostGSoC14/boost.http/blob/master/example/spawn.cpp). I'm going to add easier to use abstractions once I prove the core set of abstractions is correct. And by proving the core is correct, I mean passing on the [Boost review](http://www.boost.org/community/review_schedule.html). Easy to use features that I want to add after the review: - Request router. - Cookies &amp; sessions. - Easier POST support. Even if you're not interested in using the library, be sure to leave your opinion on the Boost mailing list when the review happen, then we can know what is good/bad about the library design.
Smart enough not to put in extra commas.
What is better, in your opinion?
Maybe love is too strong of a word, you're right. I don't hate it and it doesn't give me ulcers when attempting to use it cross-platform. That's better than any other build tool (for C / C++) I've used thus far. However, I'm open to alternatives, do you know anything better?
So are you saying there's kind of an "interpreter" or "program" running on the CPU that reads machine code, translates it somehow and then executes the instructions? So it can do something completely different from what the instructions in the assembly code say? It's not executing the machine instructions directly anymore?
Yeah. It can be actual code (microcode) or hardwired. Modern CPUs are enormously complex and do all kinds of things to improve performance. Like execute instructions in a different order than they appear in code or do calculations with missing data by guessing it and backtracking if it turns out the guess was wrong.
std::stringstream is only the way it is because move semantics didn't exist when it was designed. Look at the now [deprecated std::strstream class](http://en.cppreference.com/w/cpp/io/strstream) for some insight in to the original thinking here. The freeze() method ensures the char\* pointer returned by str() remains valid, even if you perform further stream operations, by disabling automatic memory management. As risky as that is in the face of exceptions, it's efficient. IMHO, a modern std::stringstream::str() function would still return by value, but it'd std::move its internal std::string buffer out, leaving the stream buffer empty and ready for reallocation. Exactly like std::future. This is how most people use stringstream most of the time anyway: calling str() once at the end of their business and then letting it die. The same is true of the constructor, it currently takes a copy via const&amp;, but it could, and should, take its initial contents by value and use std::move so that it can reuse the capacity() of the string passed to it. These two changes would allow alloc free operations in a reserve()'d std::string. &gt; I'd suggest you thoroughly read your own example: http://en.cppreference.com/w/cpp/thread/future/get. You have the option to return a reference Only for the future&lt;T&amp;&gt; specialisation, which doesn't manage any memory at all. This means you can pass references across asynchronous boundaries. If I'm not mistaken, future&lt;T&gt; returns by value so that the shared state allocated on the heap can be freed when you call get(), which is a very nice property if you have a whole bunch of futures. Returning a reference wouldn't allow this. 
premake5 although it's not fully released yet
That is it. You rock
I set a breakpoint on a std::vector&lt;int&gt; when debugging a unit test and QtCreator popped up a graph plotting the contents. It probably would have taken me 10 seconds to find the bug by reading the code, but looking at the plot reduced that time to nothing. [How Steam uses QtCreator on Linux](https://www.youtube.com/watch?v=xTmAknUbpB0)
`goto`s do have a (judicious) use, they are in the language after all. Remember the extreme hate of `goto` was borne from a time where it could go *anywhere*. for( ) { for( ) { for( ) { // I want early loop termination here // Break? Only exits one loop // Status flag? Expensive: check every iteration // Goto? } } }
Or you know, run gcc -S yourself.
Question: Does the library support https? Recommendation: I don't like the name boost.http if this is strictly for servers. Maybe boost.httpserver or boost.http.server. Then we could have boost.httpclient or boost.http.client in the future.
A modern std::stringstream would have both overloads: const &amp; std::string str() const &amp;, and std::string str() &amp;&amp;. Return by const ref still gives you things that the other doesn't. If you want to check conditions on the string in the middle of building the stringstream, for example. Const ref and move returns are not competing, they're for different things and complementary. I'm not really sure what your point is any more. If you're saying that the rvalue overloads should return by value then yes I agree, it's slightly safer and has no real downside compared to returning an rvalue ref. If you're saying that return by const ref shouldn't exist, then to be blunt I think you're just mistaken. Notice by the way that if you have both overloads, even your example about how const ref return is unsafe won't work. I don't see any major safety issue with const ref and it offers significant benefits.
Only for unsigned ints. For signed, it could be: `(x&lt;0?x+1:x)&gt;&gt;1`, but that usually isn't profitable.
i'm happy with gyp
I'd say it works 50% of the time in my code. Sometimes I have to reload the project because an auto variable gets "stuck" on an old type.
Aww why a wrapper around libcurl? If it was plain C++ (or boost etc), I would have switched from POCO. 
Pirate CLion?
I din't notice that you were an author! Ok, debugging a code and a code that you didn't write is very important in programming. Imagine that you have a Template which is used a lot for several types. However it seems that is a bug only for one known type. So you would like to debug it only for this type. By debugging I means adding some traces into the code. Currently you can't do that. However you really need to do it. This is why templates are sometimes complex to use. 
Finally a correct answer.
detail is really only for header files, especially for headers that use lots of templates. It's analogous to using the static keyword in .cpp files.
I use it for any helper functions or classes that aren't part of the public interface. In a cpp file I can use an anonymous namespace, but I don't have that luxury in .h files. So I use the namespace "detail". This is a thing that should hopefully go away with modules, I think.
Really? I think the Qt Creator cdb plugin beats the pants off of visual studio for debugging Qt types. Unless you are needing specific win32 debugging (like GDI) I feel like Creator is the superior experience to visual studio.
You're absolutely right, there are no library controls over how many threads are spawned. That's a good feature request! Maybe v1.1 (it's at like pre alpha v1.0 right now, just missing proxy support). Right now I just let the C++11 implementation handle thread pooling, since there is some internal pooling in std::async calls. Where do I force a copy of the async function? I think there's copy elision happening [here](https://github.com/whoshuu/cpr/blob/36397ffe6114f1e6a6d068ea0d0de8f3174cf7e5/include/api.h#L44), but correct me if I'm wrong.
I never said they were stupid :) YouCompleteMe does the job when it comes to completion. For refactoring, true that it misses stuff, I particularly miss the macro expansion feature. However, everything considered, I'm way more efficient when it comes to development. When I need to dig a very big code base, I sometimes fall-back on some IDE (was eclipse, but I'm considering CLion now), because the navigation and research is better (I miss an identifier database that you can look up by type, like `find all member function matching XXXX`. 
&gt;Oh god...I'm not familiar with POCO so that looks like gobbledygook to me :P. You and me both. The only part that matters is `params.set("track", "Greece");` which gets news about Greece and eventually trades greek stocks based on the news :P &gt; Edit: OAUTH support sounds swell, it's definitely in my plans A sane OAUTH implementation would be amazing! 
FYI the 1.1 EAP is available to evaluate without a license
Oh neat :) Is there a time limit? 
Just to add, for the benefit of the OP: you can of course use an anonymous namespace in a header file. The problem is that anything declared in an anonymous namespace is available in the surrounding namespace in the same translation unit (and not available anywhere else). Since header files directly become a part of client translation units, this would mean directly putting all these implementation details into the namespace. So it doesn't do what you intend at all. The detail namespace isn't a great solution, but it at least makes it clear that you shouldn't use these functions/classes directly.
I have accidentally dug down into system headers when debugging in CLion, but I can't say whether it was parsing correctly or not. It was all template voodoo to me. The biggest parsing problems I've seen are with Google Test macros. I've resigned myself to letting the red squigglies live in my test code.
If all you've known is autotools, everything looks attractive :)
You mean in the debugger? Or with go-to definition? Either way you can do both perfectly in Eclipse. The problem in practice that compilers (and their frontends) have different goals that IDE parsers. Eclipse indexes template heavy code very well; I'm sure it will quit if you do heavy template metaprogramming e.g. with boost mpl. But in those situations, doing auto completion is equivalent to running the whole program... so you kind of want your IDE to quit at a certain point. Eclipse (and probably CLion) index header files only once, instead of re-indexing in every translation unit. Again, this is a massive savings in work (think about a one line change in one header file), in well written code this strategy will almost always be fine, but it's not guaranteed to be... etc. So far the only products that are using clang entirely for indexing are ones that don't have the resources to write a good parser from scratch. I suspect it will stay that way until clang supports incremental compilation (which is a design goal).
It is profitable as it can be transformed in to (x+(x&gt;&gt;31))&gt;&gt;N, which is way cheaper than an idiv (and given super-scalar architectures, a negligible cost over the unsigned case). This is exactly what modern compilers will do. Try it: volatile int x = 5; foo(x/2); mov dword ptr [rsp + 4], 5 mov eax, dword ptr [rsp + 4] mov esi, eax shr esi, 31 add esi, eax sar esi 
I wonder if a `namespace private` extension would be a helpful feature. Maybe make it like an anonymous namespace, but restrict it so only certain other namespaces can use it, maybe with a syntax like `friend namespace foo;`.
Yeah I was talking about stepping through code and following it into headers. btw Clang also compiles headers once and does not recompile them unless they have changed. This gives it a massive speedup over the usual. You do have to enable C++1z modules tho :)
Great. Thank you.
&gt; I'd love to support multiple backends I wouldn't suggest you to go with this approach. You'd lose the ability to extract a lot from these frameworks if you have to support multiple backends. In Boost.Asio, you have a lot of control over the executors and you pretty much choose which tasks to handle in which threads and how many threads to use. Even communication among threads is possible. You handle **when** to start new tasks and you can postpone a lot of work if you detect your system is within a high load scenario. This kind of stuff is not something I think you'd support with a multiple backend library, because you'd basically hide all the libraries interfaces (and its strengths).
Sorry, doesn't this involve actually changing your source though? If that's the case, then this is a non-starter in a production environment. But yes, once this compile time propagation issue is solved, I expect it will give clang based parsers a massive boost. The thing is this isn't even in the 17 standard, so it's probably 5 years away from the language at least, and 6-7 away from production deployment.
Libraries have used the `detail` approach for a while, and I reckon it has spread because of usage in boost. One thing I've started to see (and use myself) is an `impl` namespace, possibly because it is fewer characters to type and might be a bit more obvious as to why it exists for newcomers to the language. But that's probably confirmation bias.
You don't have to live with red squiggles in your test code; Eclipse (and I think QtCreator) both parse that kind of code without difficulty. CLion's parser just isn't up to snuff yet.
I really want to get into Android development in the long term but when I looked at how things are done with their Java implementation I got PTSD. Are things any better with C++?
Very, very true. I was just wildly speculating: in reality this sort of feature is too specialized to put in to the language.
From what I've read, it's not recommended to C++ for ever day app development. I usually see the appeal of this feature with game engine developers, since it allows them to integrate their C++ code directly. From what I understand, much of the bindings for UI are only available to Java so you would have to use Java at some point unless you are working with something like OpenGL. This is my understanding of it from a few years ago. Times may have changed. edit: Did a little bit of reading and it seems like in order to get their "native" UI framework to work might take a little bit of [work](http://stackoverflow.com/questions/12822185/is-it-possible-to-create-ui-elements-with-the-ndk-lack-of-specs-in-android-d): &gt;Sure you can. Read up on calling Java from C(++), and call the respective Java functions - either construct UI elements (layouts, buttons, etc.) one by one, or load an XML layout. There's no C-specific interface for that, but the Java one is there to call.
Extra question: you installed 2015 Community RC, right? (VC should have been enabled by default in RC; the change to make it disabled by default was done for RTM, which is 10 days away from shipping. So we're a little confused as to how you got into this state.)
I ended up reinstalling it and it asked me something along the lines of which language I wanted to start off with and I was able to select from every language. Now when I go to start a project it allows me to go between all supported languages. Not sure why it didn't let me do this the first time. But thanks for the help.
&gt; &gt; &gt; From what I understand, much of the bindings for UI are only available to Java so you would have to use Java at some point unless you are working with something like OpenGL. Qt on Android works fine for the UI. And you can even reuse it for iOS / WP.
Unfortunately Qt produces very big executables, if I am not mistaken :(
To give reference, I have an app with about 70kloc which calls QtCore, GUI, Widgets, SVG, Network, Xml, PrintSupport; in release mode it's 2.4 mbytes. The combined Qt libs I require are less than 20 mbytes and if I wanted I could just build them all statically and add a dose of LTO to see if it makes it better (I guess it would).
Well, when I say build agnostic I don't mean build symmetric :-). Yes, there is a bit more of an attempt to support certain things than others (sadly one of these isn't CMake). But it's very easy to configure Eclipse to launch custom commands, or to have Eclipse call something (e.g. CMake) and then call make, etc. It just means you will need to edit your CMake file by hand, which I really don't think is a big deal. At work I use a different build system entirely, it isn't really integrated with Eclipse at all. But Eclipse can index and build my code, I get compile and unit test errors in the console which hyperlink back to my code, and that's all I really want. It takes less than 5 minutes of setup per project to get this running. Of course, all this is a bit of extra work and slightly redundant with your CMake setup if that's what you use, but it does give you a lot of extra flexibility. And, most importantly (as I originally noted): Eclipse doesn't (have to) depend solely on the build files to resolve includes like CLion does. This is really the factor that makes CLion unusable with non CMake projects. You can always make a dummy CMake file to build targets, this isn't hard and is roughly the same work as configuring targets or dependencies in Eclipse. But what sucks is having to get all the include directories right.
I am afraid it is not the language but the tools the responsibles of your PTSD. 
So your total binary size would be around 25MB, which is quite a lot, even nowadays. In fact I like Qt a lot for mobile development but binary size is a big big problem. I for example like to update/install apps over 3G sometimes and I have a 500MB data plan. Also, I have only 8GB space on my phone and no SD slot, so I unfortunately care about the size of an app.
Well, I mean that: adding up executable and all libs you have a nice bunch of fatty files around. I would like to create total downloads of 6, 7 or even 10 MBs (like the other native apps), but not 20MB or more. Also, if you want to build Qt in static mode you need a commercial license, but if you plan to release apps in Android or other mobile platforms I think you already have one due to Qt's licensing. All that is what I think it's the current state of Qt in this area, please correct me if I am wrong, I would like really to use this fantastic library.
What is the outcome when you run it as is?
Don't call main. If you need the main function to repeat, use a while loop or a goto (preferably the former).
How would I put the while loop into it? And does this solve the issue of some of the if/else if statements breaking? Edit: never mind I figured it out and it works! Thanks so much for the help!
well, the 'quit' case isn't handled properly I guess... and the invalid input case is also handled poorly... also I prefer using &lt;random&gt; instead of the old C library rand(). I reworked it a bit and put a revised version on pastebin: [here](http://pastebin.com/SYqdH7Rj)
Thanks for taking the time to clean it up so I have something to look at and learn from, I saved then code so I can break it down and reverse engineer it in a way. Like I said, I've just started trying to learn to program and have been getting by just using google to show me something. Then I try to use it similarly but different from the example (so not to just be copy and pasting everything basically). If you have any suggestion or resources to help me further my progress/understanding of c++ and clean up my coding I would greatly appreciate it! Thanks again for taking the time to help me!
The NDK is really only meant to be a supplement to the Java based SDK -- the idea is that you only use native code for things that require native performance (OpenGL, video encoding, etc), or for interfacing with existing C++ libraries. It is not well supported, making it extremely difficult to build, refactor, and debug. As much as I prefer C++ to Java, you *definitely* want to stick to Java as much as possible on Android, as things get very ugly very quickly using the NDK.
This is so sad. Java has no place on a phone. I was really hoping for a change of heart from the Android people. 
I chuckled :)
Try putting "int menu()" and "int decision()" above "int main()". Symbols need to be declared before they are used. As an alternative you could forward-declare those functions above main with: int menu(); int decision(); Also: cout &lt;&lt; "MMORPG\n\n\n\n"; is way more efficient than using endl.
As a C++ newbie some of the C code examples were almost completely unreadable. I remember seeing on LWN when GCC approved C++ use internally. I wonder what kind of progress has been made?
Yikes, I hope some ran some static analysis on this and realized that shouldn't be a pointer.
It's a lot nicer actually, but the transition between rewritten bits and original bits is often jarring.
How did you get that graph?
I'm not doing a feature comparison, just saying that CLion doesn't have enough features yet to strip features for a Community Edition.
LLVM also helped move GCC in the direction of C++. In fact I'm not sure GCC would be where it is today if it wasn't for LLVM/CLang. 
I don't mean to be mean, but could you maybe peruse the first few cpp reddit pages first, as there's been 2-3 questions on this topic in the last couple of weeks. There's a lot of good suggestions that people have already taken time to write up. Then, if you feel something is lacking, or help deciding between two things, you could ask a more specific question that people here will be happy to answer.
Check out [SFML](http://www.sfml-dev.org), I've used it for a university project and there have been coded a lot of cool games using it. I didn't use it to learn C++ but I started out with C# at the same time and I felt like it provides you with enough game-related stuff while not taking away the ability to have "full control" over things like your game-loop, the website also provides tutorials to get you started!
What? Ministro - Separate app with Qt libs. All other other apps **COULD** use it.
index should be ptrdiff_t or some other signed type. I always use p[-1] to refer to the "previous" element of current iterating position in an array, since p[x] is simply a syntactic sugar of *(p+x)
Just a small commentary on Java developers trying to pickup C++: with Java you're going to use "new" all over the place. In C++, pound it into your head that for every "new", there must be a corresponding "delete". Whether explicit or implicit, it holds. By default, there is no GC, so you better release your resources when you're done with them. shared_ptr and unique_ptr go along way towards making it simple. make_shared &amp; make_unique (C++14?) should even be preferred for such resources for any number of reasons. Another note: I often see developers coming from a Java/C# background inherently allocating resources on the heap (i.e. over use of "new"). The heap, or more generically, the free store, should be used as sparingly as possible. If I were to come across code that is either using "new" or "malloc" and storing the result into a raw pointer, I would inherently regard the code as suspect and needing further review.
&gt; **Qt** is perfectly capable of dropping product support. Qt? Qt is a god damn library. &gt; Qt is perfectly capable of dropping **product** support. They just recently dropped a type of **license** due to lack of interest if I recall. Really? &gt; If there is no business case for maintaining a product it is totally feasible it could be dropped, and if there is sustainable but low business for a product it could be put on life-support (poorly maintained). It consist from Official + Community support. And it's been initially made by guys from KDE. Not that much depends on Digia. &gt; In this case, it seems like they are saying that arbitrary executable data is being loaded into your app process. This opens up a kind of security vulnerability that mobile consumers are very unaccustomed to. Just pre-download and ship. &gt; The fact that you are not worried about these cases leads me to suspect you have never been burned by a third party software vendor before. You know... Qt can just disappear just like gcc, qtcreator, gdb and etc. &gt; Once again you are being pointlessly rude. Why post if you weren't interested in spreading your knowledge through discussion? You just tried to bring Digia problems to ministro... Do you even care?
KDE Frameworks to Qt are somewhat like Boost to C++.
Rewriting must give such a result regardless of the language change though :-)
tl;Dr : C++ is a better language than C, unless e.g. * you're a tool * you don't have a C++ compiler handy :-)
It works more like Java than like Python but you're conflating several things in your question. There's "how does the compiler compile" and "how does my code run". In the latter case, main is the entrypoint just as in Java. It's not necessarily the first instruction that gets executed - both Java &amp; C++ have static variables/code that can get initialized/run before main is invoked. Unlike Java, C++ functions need to be at least declared before first-use; the definition may or may not be visible (C++ is more complex so there's a lot more nuance here). C++ uses C's preprocessor. When you ask the compiler to compile your .cpp, #include directives tell it "paste this entire file at this point". Header files will typically have the just the interface of the function to make the compiler's life easier &amp; better delineate API boundaries. Obviously the C++ mechanism doesn't scale very well but there is work being done by the standards body to modernize this.
There are almost always exceptions in C++. I try not to mention all of them, in order to avoid exploding beginners' heads.
You're pretty much out of luck on Windows though. I think NuGet supports C++ packages now, but that's only relevant if you're using Visual Studio and the libraries you're using are available as packages there.
Cygwin and mingw both have package managers.
The [Meson build system](http://mesonbuild.com) has a dependency system called Wrap ([documentation here](https://github.com/mesonbuild/meson/wiki/Wrap%20dependency%20system%20manual), [web download service here](http://wrapdb.mesonbuild.com/)). It's quite new so the list of packages is still modest but it's growing. The main difference between other dependency systems is that Meson and Wrap are designed to work together with distro packages. This allows you to use distro packages whenever they are available and embed dependencies when that is not the case.
I've used CMake's ExternalProject_Add feature to some varying degrees of success.
Yes, distro's package manager: there are usually separate packages with libs for normal use and headers for development. CMake's find_package should find them if they are installed (in some cases it uses pkg-config internally).
Welcome to the big leagues, where there are approximately 74 different build systems and a patchwork framework of 28 various package managers, most of which only support a certain platform/environment and are useless outside of it. 
I think recommending pass by value for "sink" parameters without even mentioning the alternative is questionable. A common view (that I agree with) is that sink parameters should be expressed as rvalue references; after all, that's exactly what the standard library does: what is a move constructor if not a sink for its parameter? Scott Meyer talks about this, with others mentioning more interesting advantages of pass by rvalue reference:http://scottmeyers.blogspot.com/2014/07/should-move-only-types-ever-be-passed.html?m=1.
It's not actually a common view, it's a view that was put forth by Scott Meyers and Herb Sutter quickly chimed in to point out the flaws. Sink parameters are best passed by value, it avoids any ambiguity, it also behaves much better when it comes to function overloading, and Scott Meyers argument about performance is also incorrect. C++ compilers already perform copy and move elision so passing by value eliminates aliasing issues which enables further optimizations. There is a so-called "killer argument" that was referenced as to why pass by value should be preferred over pass by r-value-reference and it's along the lines of: void f1(std::unique_ptr&lt;int&gt;&amp;&amp; value); void f2(std::unique_ptr&lt;int&gt; value); auto x = std::make_unique&lt;int&gt;(5); f1(std::move(x)); auto y = std::make_unique&lt;int&gt;(10); f2(std::move(y)); `f1`'s function signature does not actually indicate or enforce any sort of sink parameter. After calling `f1` there is no guarantee that `x` was actually moved, but there likely is an expectation thereof. For example an exception may have be thrown that prevented x from being moved. However with `f2` there is an enforcement that the parameter is actually a sink parameter. There is no option but for `y` to be moved into `f2` regardless of whether an exception is thrown or not. The type system guarantees it.
Something else to consider. Ranges &amp; iterators typically require everything to be defined as a template which impacts compilation time. std::vector tends to be heavy-weight &amp; limits the generality of your code (&amp; has performance implications). Really I think the best approach is to use array_view whenever possible (&amp; whenever it gets standardized). I don't recall if array_view provides a mutable view but I believe it does.
You might want to read it again. Scott is saying that you should use `&amp;&amp;` for sink values of **move-only** types. std::vector is copyable &amp; moveable. Using by-value sink lets you get the speed without having to implement the function twice (or worse if you have multiple).
By behave better during function overloading, do you mean avoiding 2^N overloads? Except, btw, that Herb Sutter was convinced, and at his talk 2 months later at cppcon, he only recommends pass by value in very specific situations. See the link I posted below.
Except that you don't get the speed. Pass by value performs worse for lvalues then pass by const &amp;, ranging from slightly to considerably. It also performs worse than &amp;&amp; for rvalues. If you care about performance, then you should do const &amp; + &amp;&amp;. If you don't, you should just do const &amp;. IF you have multiple parameters, and IF you care about performance, and IF you are too lazy/too averse to introducing complexity to do perfect forwarding, then yeah, pass by value is a good call. Constructors are a good example of this; they're one of the few situations where Sutter recommends pass by value. Herb sutter talks about this in detail: https://www.youtube.com/watch?v=xnqTKD8uD64
Herb Sutter was not convinced. As the other posted said you're confusing two different things here. One has to do with sink parameters, the other has to do with general argument passing. Herb Sutter's talk at CppCon only says that one should continue to pass by const reference just like they did back in C++03. But he also says that one should pass by value for sink-parameters.
That's usually a small matter of making sure the .pc file is installed. CMake has all sorts of blatantly incorrect behavior, and when I filed bug reports (some with patches), they actively refused to fix them.
They know that a move has been performed from x/y, but a moved from object is just in some valid state, you don't know which. You still don't "know" anything about the object, you can't safely call any method with a pre-condition. If the data that was originally in x/y is left in there after calling move and the function at no extra cost, you're no worse off than you were in the first place. This is very, very far from a killer argument. Conditional copying, slicing, better performance are strong arguments. 2^N multiplicity of overloads is a strong argument. This is a very weak argument.
Sounds about right. Some projects have their own dependency management system. The rest assume that you have everything installed and configured just like on the main dev't computer. 
If Linux distributions commonly ship a package, I document the dependency in the README and require the user to install it. If Linux distributions don't commonly ship a package or when I require a newer version I include the package directly source tree in a directory named `external/` (as git submodule if possible) and build it along with the rest. On MacOS and Windows it's more chaotic, sometimes you can document a few Fink/Brew/MacPorts commands to ease the install, but it's generally much more fiddly then Linux.
Because of the what C++ can do and the lack of limitations it places on developers making a general purpose package manager has not yet worked. The closest to success has been Linux package managers and to a lesser extent app stores. Think about the fundamental problem of shipping an OS Kernel, the runtime for another language, systems initialization software or device drivers. Then add on the complexity of every other package and it should be obvious why this problem is so hard. Combine the politics of everyone wanting something different and it gets truly hairy. A package manager requires certain things to be useful like a system and network stack. Much C/C++ is the system and network stack. Imagine the circular dependency hell if you needed to download something to get your network driver working. To insure a base system is installed every OS provides different facilities for insuring packages are installed and dependencies are met (some provide none at all, I am glowering at you windows). This isn't an impossible problem to solve, just an improbable problem to solve.
I'v actually thought about making one but it would have to be extremely limited / specific. Essentially packages would reference a single header file as the point of usage and including that header would be all that's required in addition to only common compiler flags if they cause no side affects (like if something needed to be included). This would make a *HUGE* amount of existing libraries simply not viable for the package manager but I think, if enough people liked the idea, a community could come up around it and actually contribute packages that can be used. Trouble is I don't think if it would be *too* limited to be of utility.
Funny how competition works.
The first thing I noticed is that one of your functions is named `assert`. It's easy to break your code by including `&lt;cassert&gt;`, which defines an all-powerful `assert` *macro*.
This was basically my response as well. I don't really like having every language force me to learn a new set of tooling when I already have a perfectly useful package manager. On OS-X, I have brew and such, but it's still global even if it is 3rd party. I dunno why there's no equivalent of brew on Windows. Porting to Windows always seems to just involve a bunch of hard coded papths in my build config, and downloading a bunch of libraries by hand. But aside from Windows, the whole rest of the non-embedded world usually works just fine.
Can it break given that its in a separate namespace ? 
Yup, macros are all-powerful. They're text substitution that happens before regular compilation.
The server code isn't open source, you have to pay to have a private server on Biicode's hosting
Tbh if I had to do anything windows-based I would cross-build from Linux.
&gt; You use your distro's package manager Only support for one distro? Great for you, the pain of supporting multiple distro's and multiple versions of them is very real for me. It ends up being less work to manage all my dependencies myself and bundle them. Edit: Thanks for all the downvotes, please give hints how I can: * Have a single dependency tree for every Distro a customer might want, or a simple way to support every single Distro in existence. * Test my software against all versions and combinations of libpng,libzip,libdevill,libc,libtiff,Qt,OSG,tinyxml,boost, ffmpeg, cmake, etc. without going crazy. * Deal with customers complaining that their installations are isolated from the internet and installing hundreds of packages in a system wide fashion is just as prohibited. Since someone mentioned security: Not every software is internet facing or has root privileges, no need to deal with packaging here.
As someone who has had to build projects with bundled dependencies, I hate you.
Without looking too much at it: I must *strongly* oppose any internally-harnessed testsuites. Tests should *always* be harnessed by an external process.
Some projects include their own FindProject.cmake file (e.g. Boost.Hana, Eigen), this makes it a breeze to use. If you have the right version of the project installed, then that version is used. Otherwise the right version is fetched from github into your build directory and compiled with your project. It is worth noting that writing a FindPackage.cmake is a 5 liner and it works on all platforms.
Different priorities, we mostly provide binaries and headers. For an open source project this might differ. 
&gt; Qt is also known to have very well designed interfaces and APIs... /s
&gt; CMake has all sorts of blatantly incorrect behavior, and when I filed bug reports (some with patches), they actively refused to fix them. [Citation needed]
You swapped `f1` with `f2` and `x` with `y` in your comment, that's why people are confused.
Meson's wrapdb system is fully OSS, [the source code is here](https://github.com/mesonbuild/wrapweb). It has fewer packages available ATM, though.
It took this long for me to realise the hypocrisy of me laughing at the amount of javascript frameworks there are, when I work with C and C++ all the time.
Really? Why's that? Personally, I've found that bundled dependencies are much easier. I'm often running things on a system I don't have admin for, so every dependency requires me to build it myself (don't even have chroot permissions). Secondly it's a pain when the distro's version is incompatible with the program.
minor, minor point: insure-&gt;ensure.
It's [open source](https://github.com/biicode/bii-server/issues/1), though the web parts are not published yet.
chocolatey ?
&gt; there's no equivalent of brew on Windows there's chocolatey
As far as I'm aware, Chocolatey only has applications as packages – not libraries.
Something to keep in mind is that the average C++ project requires FAR LESS dependencies that the average Node / PHP / Ruby project. I don't see many projects linking to more than 10 different libs, or if it is the case, it's through a framework that makes it easy for you. But Qt, Boost, SDL covers most needs I think.
The MinGW package manager has a very limited selection of packages. I just checked and it only offers a handful of libraries.
There are some, like GLFW, OpenCV...
Ah, my bad. I meant unspecified state. But this still doesn't solve OP's problem. In this case the move will probably take the resources of the original vector and you will have to allocate memory again, defying the purpose of the function's signature (single alloc, multiple uses).
HA HA HA HA
I've thought about that topic before and as others said, there's already huge fragmentation. Ideally there would be something like [Cabal for Haskell](https://www.haskell.org/cabal/), but that would require a huge homogenization effort beforehand. Cabal is possible because there is a common repository for Haskell packages ([Hackage](https://hackage.haskell.org/)) and a common way to compile Haskell software. Unfortunately I don't see how this could happen for C++, because C++ is way more used and larger than Haskell and there was no generic way of building C++ packages from the beginning. Right now you'd have to convince hundreds of thousands, if not millions of people that your idea of a package management system is the right thing. And you'd still have some graybeards who wouldn't use it, just because. Imho, the only way to achieve this is a standardization effort through the C++ ISO committee. Not sure how that works, but it's probably worth to get Herb Sutter on your side first. :)
Why would it take the resources? It's using `convertBuf` as a temporary conversion buffer, not as a source for a move-constructor. Note also that when passing `convertBuf` by lvalue reference the called function *could* take resources if it wanted, even without calling `std::move` - `std::swap` being a prime example.
The move will just cast the lvalue ref to rvalue ref. But to take the resources, some move constructor must be called. It's not called inside the function.
There is also [msys2](https://msys2.github.io/), which handles both the installation of mingw and other tools, and has a bunch of 3rd party libraries available.
Cygwin has a higher performance penalty, and the license of the runtime itself requires you to release your code as GPLv2 (or higher).
and soon that thing integrated into powershell
&gt; As long as you share your code, you will enjoy all the functionality and benefits of biicode totally free. However, if you prefer to keep your code private and only accessible to you and your collaborators, you’ll have to upgrade to a premium account. Dunno which bots are upping the post about that builder. 
With msys2, if the library is in their repository (quite a few are) you just do a `pacman -S library` and you're done.
Unless you want to modify the vector or return it, you should also accept something like: void test(T const* data, size_t len); As that ensures that all vector-like types will work, not just the STL ones. That still won't work with lists, deque, etc., but depending on the use case that's not much of a problem (i.e. nobody stores pixels as lists) and easier to deal with then turning the whole library into a template when using iterators. 
oneget which is a set/subset/superset/none-of-the-above of chocolatey and nuget.
FreeBSD: ports/pkg Linux: package manager MacOS X: homebrew Windows: suffer and build everything by hand If you're only building on Windows, you might be able to embed all your third-party dependencies and build the entire lot inside Visual Studio. But this won't work if you want to build on Linux/BSD where such source embedding will fall foul of being suitable for inclusion in a distribution. And it's also a pain to maintain. What I do currently is use CMake, and for Windows I have an optional "superbuild" project which will download and build all the dependencies if not already available. This can also be used on older Linux systems with outdated dependencies if desired. This was a pain to set up, but without it supporting Windows would be incredibly more painful. BSD/Linux/MacOS are still vastly easier to support, but this at least makes Windows less of a burden.
Too damn true. 
Sure, that's understandable. If it's targeted at the beginners though, personally I would just not broach the subject of sink parameters. Yes, I saw Eric Niebler's advice in the video. I plan to ask him if he's changed his mind. Herb Sutter's talk goes into quite a bit more depth on the whole pass by value thing, and he comes out against it in the majority of cases. Herb Sutter's talk was end of 2014, so I'm not sure how that matches up time wise with Niebler's C++Now talk.
I feel there should be one. I hope/wish someone who does this a lot would make a dependency manager, or library manager. 
This article describes that at least for Android LGPL Qt is fine because it allows dynamic link libraries: http://wiki.qt.io/Licensing-talk-about-mobile-platforms. iOS doesn't allow it
I've been at CppCon and seen Herbs Keynote live, and also saw how controversial it was received. Both agree that the rules for C++03 are still mostly valid.
That might have been a libstdc++ bug (IIRC they screwed up a release on mingw). But again, it has nothing to do with the STL itself, rather with a particular implementation. It is a library mantainer (*any* library) responsibility to ensure ABI compatibility, or not (i.e. msvcrt). Pimpl is not the only way to do that (and I personally dislike the pimpl abuse on qt). This is not about the standard library, it is about *any* library, and it is not a good reason to not use the STL, just go and blame your standard library mantainers if they mess up. 
&gt; the license of the runtime itself requires you to release your code as GPLv2 (or higher). No it does not. The Cygwin license is the GPLv3+ with an exception clause that allows it to be linked with any OSI-approved license. As long as your project is open source, Cygwin imposes no licensing requirements whatsoever. (If you distribute cygwin1.dll you're still obligated to provide source for it, but unless you modified it that's not really an issue.) 
One of the greatest things about GNU/Linux systems. **The Package Manager** 
Hey! the code I have is the one in the description, that code was send to me from the statistics department of Mexico I need to extract information from a webpage, it says is API information. I tried to copy and paste the code on Dev- C++ 4.9.9.2 and click on run but it says file not compiled, after that I save the file and still is the same. The information is about energy consumption. THANKS! 
I guess that's a good point. Those frameworks pretty much provide you with 90% of what you need.
I've been calling this thing the Evil Extension for a decade. It is an **abomination** that has caused an incredible amount of suffering. When I go into work today, I'll ask the compiler devs (again) if they can remove it in the next major version.
&gt; `auto&amp; [...] -&gt; decltype(x &lt;&lt; a)` This is what I usually refer to as Outlook Code^TM (i.e. code typed into an E-mail program - or Reddit in this case - not a compiler). Trailing return types are introduced with `auto`, not `auto&amp;`.
Universal references are powered by the template argument deduction tweak, not just reference collapsing. This is a common misunderstanding.
Indeed, thank you for correction.
My experience with bug reports to CMake has been the opposite. Maintainers were responsive and polite. Brad King has even gone around to several large CMake-based projects (LLVM/Clang was one) and asked them how the CMake team could improve cmake to better support the projects.
Can you show an actual bad example? Because the above is not one. MSVC does not compile it. I've used MSVC for, well, 15+ years, and I don't remember a situation where I've been bitten by this. I've been bitten by the conditional operator accepting ambiguous code...
What would be a need common enough to be of use to... let's say 10% of all software and not present in either of those ?
So, all that drama about bringing static_if into C++, and it is solved by 20 lines of code?
Everything you have said makes no sense and I'm going to assume it's partially a language barrier thing. Copying XML &amp; trying to compile it directly with C++ seems to indicate you have a more fundamental problem of not understanding what XML &amp; C++ are. This sounds like something you are asked to do as part of your job, so you should ask your co-workers/manager what you are being asked to do. This looks like you were given an XML schema to which any data you got would conform.
If you are absolutely, positively, unconditionally convinced that you project will only ever run on one OS, go ahead and use whatever facilities that OS affords you. If, on the other hand, you're project is cross-platform, check in pre-compiled libraries in your source tree under /thirdparty/[name]/[version/[platform]. Trust me on that one. Managing multiple package managers is not worth it. It. Is. Not. Worth. It.
If you have a mutex held by a unique_lock and pass it by value to some function, you have no idea of when, if ever, it will be unlocked. I'm not sure what benefit you gain here compared to rvalue refs.
&gt;If you have a mutex held by a unique_lock and pass it by value to some function, you have no idea of when, if ever, it will be unlocked. Nor should you care, once you've handed over ownership you absolve yourself of the responsibility of managing that lock. That responsibility now belongs to the receiving function. &gt; I'm not sure what benefit you gain here compared to rvalue refs. The benefit is the guarantee that the unique_lock you passed to the function no longer owns the lock, a guarantee that does not exist if you pass by rvalue reference.
Yep, which is why I agree it would be a bad idea to introduce static_if to C++. The better solution is to introduce more principled features like polymorphic lambdas and concepts and then use those principled features to create your own variant of static_if.
I use ExternalProject_add and use PATCH_COMMAND to inject my own CMakeLists.txt. Writing a cmakelist for every dependency of every dependecy sucks but there is no real other way because other people are not reliable.
The way this is done in the [Meson project](http://mesonbuild.com) ([github project here](https://github.com/mesonbuild/meson))is that you first create a build system that sandbox other projects so they look like a native part of your build. Then you generate a [database](http://wrapdb.mesonbuild.com) where people can submit build definitions for upstream projects. There's also a cli tool to install them to your source tree. It also transparently uses system dependencies it they are available. Caveat: I'm the project lead for the Meson project.
I'm not saying that this is a reason not to use STL. Everyone should use STL as much as possible. It's really nice and solves a lot of problems. You just have to be aware of the consequences of exposing it in your library api.
I think it was this question [here](http://stackoverflow.com/questions/30189926/metaprograming-failure-of-function-definition-defines-a-separate-function/30515874#30515874). Basically, they wanted to define a `stringifiy` function that would use `to_string` if available otherwise it would use string stream. The simplest solution is to just to do this: FIT_STATIC_LAMBDA_FUNCTION(stringify) = fit::conditional( [](auto x) FIT_RETURNS(to_string(x)), [](auto x) FIT_RETURNS(static_cast&lt;ostringstream&amp;&gt;(ostringstream() &lt;&lt; x).str()) ); So you could apply the same thing for checking a member as well.
&gt; Nor should you care, once you've handed over ownership you absolve yourself of the responsibility of managing that lock. That responsibility now belongs to the receiving function. Why is this any different with passing an rvalue? Why should I care if the function never takes ownership? &gt; The benefit is the guarantee that the unique_lock you passed to the function no longer owns the lock, a guarantee that does not exist if you pass by rvalue reference. In practical terms, why does it matter, when I pass an rvalue to a function, I don't care about the value any more.
&gt; find out your distro of choice last updated the package during the cold war ( or earlier ) Or use arch as a dev reference.
&gt; is
&gt; In both Test1 and Test2, the lifetime of the mutex lock is now managed by the function, this could mean unlocking immediately, releasing so that it is never unlocked, moved again somewhere else, or even other possibilities. Why does it matter if Test2 also has the possibility of never acquiring the lock at all? In `Test1` ownership has been transferred, in `Test2` no ownership has been transferred, only an expectation that such ownership will be transferred by convention. My position is when possible use the type system to enforce statically verifiable properties rather than rely on convention. &gt;Moved from objects can provide very little in the way of preconditions. Sure, references (`T&amp;`) also provide very little in the way of preconditions compared to pointers (`T*`), but we still prefer using references over pointers for the few preconditions that they do provide.
static_if is a very simple solution. However some people prefer obscur and complex code nowadays. I am sad. What's wrong with static_if? I guess this is the imperative coding style that some people hate so much... (but without it C++ will be not use in the real world like Haskell and functionnal stuff)
&gt; In Test1 ownership has been transferred, in Test2 no ownership has been transferred, only an expectation that such ownership will be transferred by convention. My position is when possible use the type system to enforce statically verifiable properties rather than rely on convention. In both cases ownership has been transferred. Whether or not a move constructor has been called doesn't matter. Test1(std::move(x)); Test2(std::move(y)); both x and y are left in a state where the only operations we will likely be calling on them is assignment or destruction. &gt;Sure, references (T&amp;) also provide very little in the way of preconditions compared to pointers (T*), but we still prefer using references over pointers for the few preconditions that they do provide. References can not be null and provide a convenient syntax for function calls. This is greater than the mostly useless preconditions on moved from objects.
Not sure why you are getting downvoted. Its completely true especially with the commercial/old distros. Commercial linux/unix work is a pain in the ass since we can't just tell our clients to recompile their kernel or update.
&gt;In both cases ownership has been transferred. Whether or not a move constructor has been called doesn't matter. `std::move` does not transfer ownership and it's a common misconception which is why I prefer not to rely on convention when you can use the type system. `std::move` is basically syntactic sugar for a complicated type of cast that's somewhat similar to static_cast&lt;T&amp;&amp;&gt;(value). To better appreciate this consider unique_ptr: void f1(std::unique_ptr&lt;int&gt;&amp;&amp; value); void f2(std::unique_ptr&lt;int&gt; value); You can call `f1` and there is no requirement that any transfer of ownership take place. Yes I agree that you expect by convention that `f1` will own `value`, but that's just a convention that you and many other C++ developers expect. When you call `f2`, ownership is guaranteed to be transferred, plain and simple. This isn't a convention or merely an expectation. Your expectation is enforced by the compiler.
Fair enough, it's up to the developer then to decide if they want to leave this to convention or have it enforced by the compiler.
Amen. Some people are really eager to toss macros at things.
&gt; Using any C++ class across ABI boundaries with different compilers is very bad. I'm assuming when jp said "If you always compile from source, then it's ok" that implied compiling all the source with the same version of the same compiler. Though you can still go wrong by compiling some parts with debugging or instrumentation (such as memory leak checkers or profilers.) I used to work on a project that exposed C++ objects in DLLs (using whatever the magic MFC DLL linkage was in VS). Worked fine if all dlls + exe were debug or all were release. Probably could have mixed debug and release if you never did anything but pass an object around by reference in other modules code, but the code had bigger problems than that, including templates in the exported header files for some modules, which pretty well messed up even attempts to do independent versioning of modules.
I remember being faced a problem like this for a serialization framework several years ago. At the time, my project was specific to MS Visual Studio, so I used this compiler specific kludge in visual C++: __if_exists(foo) {} or __if_not_exists(foo) {} https://msdn.microsoft.com/en-us/library/x7wy9xh3.aspx It wasnt ideal, but it was concise and good enough at the time. I realize that this does not fulfill your C++11/C++14 requirement, but I thought it was practical and relevant enough that someone might find it useful. Edit: apparently __if_exists() is not recommended for new code. Here is an SO thread discussing how to do this using traits instead: http://stackoverflow.com/questions/3779466/is-there-an-equivalent-for-if-exists-in-gnu-c
&gt; that defines multiple macros that make errors hard to debug? How does it make it hard to debug? `FIT_RETURNS` is simply defined as this: #define FIT_RETURNS(...) -&gt; decltype(__VA_ARGS__) { return (__VA_ARGS__); } If you want to make it more explicit you could write it like this: FIT_STATIC_LAMBDA_FUNCTION(stringify) = fit::conditional( [](auto x) -&gt; decltype(to_string(x)) { return to_string(x); }, [](auto x) -&gt; decltype(static_cast&lt;ostringstream&amp;&gt;(ostringstream() &lt;&lt; x).str()) { return static_cast&lt;ostringstream&amp;&gt;(ostringstream() &lt;&lt; x).str(); } ); It makes more explicit that the expression will constrain the function for those who are unfamiliar with the `FIT_RETURNS` macro(of course a `RETURNS` like macro is quite common among many C++11/14 libraries). However, debugability is the same. Its one line of code, and the macro doesn't change that.
That's probably the other way round. An average C++ project has less dependencies (really?), _because_ there is no package manager. And that's not a good thing. That implies more monolithic code, more wheels reinvented, and less projects written in C++ that could have been written.
And then we see projects which work only on Ubuntu 12.04... And nothing else.
You are so far away from understanding what you need to do that it seems improbable anyone can help. To begin to see what you're looking at, search Wikipedia for XML and C++.
By the way, can you give a small example where additional optimizations resulting from eliminating aliasing are enabled? 
template metaprogramming: how to reinvent preprocessor macros with a lot more compiler involvement and a completely new level of fucked up. 
Yes, I agree. While most controversy was about Herbs views on almost always auto. Both view points regarding argument passing are valid, and I tend to weight the view of a library designer such as Eric is, a little more then Herb or Scotts views. Also, afaik the only difference is really about sink parameters. Which are except for setters/constructors rather rare.
I agree with everything you say. Especially about large projects. Different tools are required at that scale. For small projects I use https://github.com/keithalewis/fms/blob/master/include/ensure.h At some point a human being needs to be plopped into the debugger and have their nose put in the dog food. I should have been more responsive to dany74q's question and suggest he take a look at that to see if it solves his problem.
I use something similar to ensure, but not for unit testing, for defensive programming. I just put asserts throughout my code. 
… and as long as you aren't an upstream who is effectively forced by distribution vendors to support their patches because they don't label the versions as modified. We complained to Debian about their fucking up of our software and told them that unless they want to ship an unmodified version they have to support it. Their response was basically "but 9001 other vendors support our shitfest, you should too!".
__if_exists is an abomination, please **don't** use it. It's horrendously buggy, and supported only for back-compat with libraries that really should be fixed to use modern SFINAE.
Tag dispatch is what we use within the STL. It's simpler because it conceals the dispatch from the user, who sees only one public signature. It's easy to create multi-way switches - just add additional tags, and think a little about ensuring that the overload resolution is unambiguous. SFINAE is a more complicated way to achieve the same effect, since you have to make each overload appear exactly when it's needed. In particular, tag dispatch centralizes the mention of the properties you're interested in, while SFINAE will typically need to have each overload repeat them (is_array versus !is_array).
Everything STL said. To give an example when you'd use enable if: if you want a generic function to take primitive types by value, but user defined types by reference. In this situation, clearly tag dispatch cannot help you, because you have to change to signature of the function itself depending on the type. In almost all situations though I'd take tag dispatch over sfinae. 
It's not as though we didn't have static_if equivalents in C++98.
What kind of code are people writing that requires this. I feel like I'm working in a different language sometimes
Like what ?
Yes, it can. 
That's interesting. I saw this piece of example code *somewhere* as an explanation of why non-const ref to temporary is undesirable.
This is e.g. a pretty convoluted one for range-v3 since I just basically sed it with a different library name every time I need a new library and it has grown a bit over time (been doing this for 3-4 years): https://github.com/gnzlbg/htree/blob/master/cmake/Findrange-v3.cmake You can wrap this into a function that does: `fetch_pkg(range-v3 range-v3 https://github.com/ericniebler/range-v3.git GIT)` and I've done so in some projects. In that directory there is another one for cppformat. You will see that they are extremely similar. As you point out, the FindEigen3.cmake file provided by Eigen3 doesn't do this, but I just call that one first, and if Eigen is not found, I just fetch the master branch from source using a very similar file (EDIT: found the file, see below). The ones I'm using right now just completely ignore the FindXXX.cmake from Eigen, since over the years I've moved on to always use the master/develop/tip-of-trunk branch of the libraries I use. I'd rather have sporadic breakages as soon as someone screws up upstream, than fight against an upgrade 6 months or 1 year down the road when nobody remember which commit broke what and why. This breaks my builds some times, but ExternalProject_Add let's me easily fetch a particular commit or change the repository to a different one. That is, I can (and often do) fork the project, fix the error, send a pull request, and switch my projects to my fork until the pull-request is accepted. For releases I just fix a particular commit of the libraries in the files (typically the last one at the time I'm doing a release). EDIT: I just found mine from Eigen3: # Find the Eigen3 include directory # The following variables are set if Eigen3 is found. # Eigen3_FOUND - True when the Eigen3 include directory is found. # Eigen3_INCLUDE_DIR - The path to where the Eigen3 include files are. # If Eigen3 is not found, Eigen3_FOUND is set to false. find_package(PkgConfig) if(NOT EXISTS "${Eigen3_INCLUDE_DIR}") find_path(Eigen3_INCLUDE_DIR NAMES Eigen DOC "Eigen3 library header files" ) endif() if(EXISTS "${Eigen3_INCLUDE_DIR}") include(FindPackageHandleStandardArgs) mark_as_advanced(Eigen3_INCLUDE_DIR) else() include(ExternalProject) ExternalProject_Add(Eigen3 HG_REPOSITORY https://bitbucket.org/eigen/eigen/ TIMEOUT 5 CMAKE_ARGS -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_CXX_FLAGS=${CMAKE_CXX_FLAGS} PREFIX "${CMAKE_CURRENT_BINARY_DIR}" CONFIGURE_COMMAND "" # Disable configure step BUILD_COMMAND "" # Disable build step INSTALL_COMMAND "" # Disable install step UPDATE_COMMAND "" # Disable update step: clones the project only once ) # Specify include dir ExternalProject_Get_Property(Eigen3 source_dir) set(Eigen3_INCLUDE_DIR ${source_dir}) endif() if(EXISTS "${Eigen3_INCLUDE_DIR}") set(Eigen3_FOUND 1) else() set(Eigen3_FOUND 0) endif() This one tries a bit harder to find an installed version of Eigen3 even if Eigens own FindEigen3.cmake file fails (which should be called before). If it cannot find it, it just fetches the master branch from the mercurial repo.
Unlike preprocessor macros templates are Turing-complete 
How? AFAIK lambdas cannot be constexpr right? EDIT: I made this work by replacing the lambdas with constexpr function objects: http://coliru.stacked-crooked.com/a/63f154fc7456b83e But for binary conditions I just don't see the advantage of this over just tag dispatch on std::true_type and std::false_type: http://coliru.stacked-crooked.com/a/869f49003af2824b It is simpler, and cuts the lines of code by half.
The typical example of tag dispatching can be found in the standard library: `std::distance` based on the `iterator_category` (did you even wonder why they formed an inheritance hierarchy?): template &lt;typename It&gt; auto distance(It begin, It end) { typedef typename std::iterator_traits&lt;It&gt;::iterator_category Cat; Cat cat; return distance_impl(begin, end, cat); } And then one implements on `distance_impl` for each of the category for which its makes sense: - `forward_iterator_category`, the base implementation in O(N) - `bidirectional_iterator_category`, the implementation that works in both directions (still O(N)) - `random_iterator_category`, the efficient implementation in O(1) It's a pretty useful strategy, I remember using it for json encoding/decoding. `kind(T)` gives its tag (to be provided by the user, already provided for STL containers) and from then on you know whether it's to be treated as an object, list, string, ...
I don't use MSVC, but is the following possible? #include &lt;vector&gt; std::vector&lt;int&gt;&amp; f(std::vector&lt;int&gt;&amp; v = std::vector&lt;int&gt;()) { return v; } int main() { std::vector&lt;int&gt;&amp; v = f(); }
In your Example 1, I don't know that I love forcing clients of the function to deal with state, just because they want the speed boost. I would probably either make it a functor so that the state is encapsulated, or make the buffer a static variable, which will allow even "lazy" clients to get the speed benefits, at a minor cost in space (the buffer won't be freed until the end of execution). If you want to stick with this approach though, you could make the last argument a pointer that defaults to null, and check for null on the first line. I actually prefer this as its more explicit, and generally the difference between reference and pointer parameters is that pointer parameters are supposed to be optional/nullable. If you don't like that you could also use boost::optional. Your second example makes me a bit nervous. Your destructor non-trivially accesses a resource, what if it throws? Destructors should be for freeing resources, not for taking other non-trivial actions as scope exits. I'd probably just rather use one extra line of code to first dump everything into a stringstream, and then dump the stringstream into the console (which is basically what you are doing). Remember: syntactic sugar costs lives.
&gt; you could make the last argument a pointer that defaults to null, You are proposing solutions that involve typing more lines of code. I am aware that there are multiple ways to solve the problem by typing more lines of code. I have included one. I question the basic premise of being required to do so. It's inelegant, and against C++ principles - and indeed, principles of software development in general: which is to not type what you don't have to. &gt; Destructors should be for freeing resources You are beeing needlessly fearful. A destructor is a function. I use it, in this case, as a function. If it throws, it throws like any other function. The object whose destructor throws does not own resources, its parent does, and those resources are cleaned up. The one thing that might possibly go wrong is that operator&lt;&lt; might throw before the destructor is called, and then the destructor will try to output an incomplete string, or a string in an undefined state. The code needs to be modified to guard against this: ~WriteOnDestroy() { if (!std::uncaught_exception() &amp;&amp; !Empty()) Console::Write(D, *this); } Other than that, it is fine. Destructors can throw. It's normal. &gt; I'd probably just rather use one extra line of code to first dump everything into a stringstream, We can also type extra lines in C. The *whole point* of C++ is to avoid this. &gt; Remember: syntactic sugar costs lives. Unnecessary verbosity costs lives, also. We would all be using C if there wasn't a cost to verbosity.
HA Ha ha ^ha^^ha^^Please ^^^help
&gt; If a destructor throws when an exception is already being dealt with, the behavior is undefined. Which is what std::uncaught_exception() prevents. &gt; Allowing exceptions to escape destructors is usually very strongly frowned upon. In fact, it's a specific item of it's own in the widely respected book Effective C++. Who cares? I mean, seriously. Who cares what some "widely respected" person "frowns upon"? Effective C++ is good, but it's for beginners. I read that 18 years ago. An exception from a destructor; especially a destructor for a trivial class like this one; *is not a problem* unless an exception is already being thrown. And that's what std::uncaught_exception() is for. If you're not throwing exceptions from destructors, you *should* be. This: ~SomeClass() { if (!CloseHandle(someHandle) &amp;&amp; !std::uncaught_exception()) throw SomeException(GetLastError()); } is **much** better, more solid, more useful code than just this: ~SomeClass() { CloseHandle(someHandle); } The former will detect problems when closing the handle, the latter will just ignore them. The bugaboo about never throwing exceptions from destructors is harmful. Destructors are trickier to get right because they have to be *aware* of exceptions. That doesn't mean they can't *use* them. They *should*. &gt; It's definitely not worth having a throwing destructor to save one line. To save one line *every time it's used*. It's correct code with no danger or lack of safety that you're able to point out, except imaginary concerns from a guide for beginners.
I appreciate how you edited out the multiple fucks that the first version of your response had. Super classy. It's not just some widely respected person. It's a pretty widely held opinion. It doesn't mean you should never use std::uncaught_exception, but that shouldn't be the first tool you reach for. There's a cost to code complexity. To save that one line "every time its used" you've written non-standard c++, put main decision logic in the destructor, used an obscure function, and are potentially throwing from a destructor. Even if these things are "ok" under some set of circumstances, they're extremely rare, because most people don't think the costs justify the gains in most situations. Note that in your example, you can get the same effect by literally just changing the second &lt;&lt; to a +, since + has higher precedence, it will evaluate first, so you would get a single call to the stream anyway. If I really cared a lot about this problem, I'd probably use macros to solve this (like e.g. glog uses macros anyhow). And I hate macros. I still think it's the lesser of two evils. Anyhow, I'm not likely to convince you, code the way you want. 
&gt; I appreciate how you edited out the multiple fucks that the first version of your response had. Super classy. I am known for classy. Should I edit them back? &gt; It's a pretty widely held opinion. You keep coming up with these logical fallacies. Previously, it was [appeal to authority](http://www.nizkor.org/features/fallacies/appeal-to-authority.html). Now, it's [appeal to belief](http://www.nizkor.org/features/fallacies/appeal-to-belief.html). This is what makes me impatient with you, and causes me to want to use profanity in responses. On the one hand, you seem to be a clever person with some knowledge of things. On the other hand, you're pulling this crap that's beneath you. Please stop this. Either present arguments, or don't. What most people think, and what authorities think, is irrelevant. [41% of Americans believe](http://www.aol.com/article/2015/06/30/41-percent-of-americans-believe-that-humans-and-dinosaurs-coexis/21203204/) that humans and dinosaurs coexisted. If you're parroting other people's opinions, it means you lack thought of your own; or you can't express it; or you can't be bothered. Either way, it does not contribute. &gt; It doesn't mean you should never use std::uncaught_exception, but that shouldn't be the first tool you reach for. You should *always* be using std::uncaught_exception in destructors. It should not be considered obscure. You should be detecting failed resource cleanups. Failed resource cleanups are indicative of other major bugs. You can't safely throw in that circumstance without uncaught_exception. If you don't throw, you should outright abort.
I can't speak for the OP, but lambdas allow `auto` in the parameter list whereas regular functions do not (yet). It can be a convenient shorthand template. However, I'm pretty sure the OP's usage could cause ODR violations.
Wow, rewriting &lt;functional&gt; must have been a considerable undertaking. When you were rewriting this, did having the list of bugs in the back of your mind motivate any implementation decisions? Or, was the focus on writing standards compliant code with the fixes happening naturally as a result? And congrats on the upcoming release :)
I'm pleased to see concrt removed and winapi used instead for the threading impl but am definitely curious what issues this fixed exactly. 
It isn't customizable. The exact size isn't officially documented (it's right there in the header, but you have to understand some deep representation details, and it intentionally varies between 32-bit and 64-bit). As I mentioned in the post, in 2015 we're considering basic_string to be "small" for the SFO (and additionally you need a noexcept move ctor). We may change this in the future, although we have no current plans to mess with it again. The Standard guarantees that function pointers and reference_wrappers always trigger the SFO. Anything else is the implementer's discretion. We've tried to strike a good balance between avoiding dynamic memory allocations and making std::function unnecessarily big.
Ah, that's true, it saves a `template &lt;typename T&gt;`. I didn't notice the parameters. I'd personally still type out the function, but I can see the argument for OP's way. If you sort out the ODR stuff. Thanks!