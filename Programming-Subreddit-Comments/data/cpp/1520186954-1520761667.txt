Many people like their application code to look different from the library code, so it is easier to tell which is which. I'm not going to debug into vector, but I will go into Vector.
_lower is not reserved, but _Upper is (as is __doubleunderscore). Many avoid _lower because it often leads to an _Upper somehow. (like maybe abbreviations _XML or maybe _MEMBER_CONSTANT as a result of combining rules.)
&gt; It would have never passed the Boost peer review with a monadic API intact. It's unclear to me why you would think that's important to anyone else... &gt; Besides, the way forward is a monadic programming library which works with `ValueOrError` Concept matching types. Something general purpose. Now that I can get behind!
Be aware that UPPER_CASE for constants conflicts with preprocessor macros, which is quite problematic since it's important that macros stand out and can be identified at a glance.
Actually, I don't even think Google's C++ naming convention is the most popular one. I've rarely seen UpperCamelCase for function names, despite it being Google's default style. Nor do I frequently see a leading "k" for constants and enumerator names. (that might be more of a Windows programming style though) The one aspect of Google's that's still popular is UpperCamelCase for class names - but that convention has been around longer than google has.
That's not a suggestion of how these slides can be improved, nor even pointing out what issue you have with them. That's just, in many more words, restating that everything can be improved and the specifics are to be defined by a group that everyone should pay more attention to. If nothing else, please be aware that this is exactly why people dismiss people like you. It's not that we are against the idea of making STEM more suited for group X, it's that no one is providing any specifics for what's wrong and how it can be improved. They simply complain that it's not perfectly tailored for group X and that someone else should improve it; or donate to someone that wants to improve it. Frankly, I do not think anyone from your group could differentiate between a work saying it's tailored for group X, and a work that actually is. That the complaints and calls for donations is just a way to convince yourself that you are helping some cause, while providing nothing of value. This is not a unique idea. Please be the difference you want to see in the world, don't just ask everyone else to be it for you.
The C++ Standard also says nothing about exceptions with respect to marking a member function as `const`, but you'd be pretty surprised if that changed exception behavior. The "tangible effects" are, IMO, pretty clear according to the standard: You can safely call this from C using the same declaration. The Standard _does_ disallow altering exception-throwing when specifying linkage because it says nothing. In the same sense, if you wrote a compiler that made a function returning an `int` implicitly `noexcept`, I would tell you that it's non-conformant, despite the fact that the C++ Standard doesn't mention that you can't do that. What I'm saying is that just because MSVC has non-conformant behavior, that doesn't change what the C++ Standard states. That just makes MSVC non-conformant (under a flag that apparently is commonly set).
Many agree the Google C++ guide is not very good on many levels. Google probably has their reasons for their choices sure, but that doesn't mean they apply to 99% of the rest of the world. CamelCase for classes and snake_case for functions is pretty common in C++. And the C++ standard library uses snake_case for both of them. Though personally I prefer CamelCase for classes, particularly because I often find myself in a situation where naming like `MyClass my_class` makes sense.
Called? [It's described here](https://libcxx.llvm.org/docs/DesignDocs/DebugMode.html).
If the standard actually states anything I'd be curious to know where; it seems to me that it pointedly states next to nothing, likely to leave it to the implementation to determine what "C linkage" actually is on a given platform.
Anybody can bullshit or oversell on a resume, and it happens all the time. An even more difficult to detect resume problem is when people work somewhere where the standards are so low that they don't even realize how far behind they are. For example, it's a common problem I see in electronic trading for people to get stuck in a dev group doing trash-tier "hft", get mis-educated by working there, and come out 10 years later with no idea how to do well in the field.
I’d like to add optional to the list 
libfoo.so: struct Foo { ... }; extern "C" void register_factory(Factory* factory) { factory.registerType(typeid(Foo), [] { return new Foo; }); } my_app: using factory_function = void (*)(Factory* factory); int main() { Factory f; for(auto plugin : {dlopen("libfoo.so"), dlopen("libbar.so"), ... dlopen("whatever is in my plugins folder")}) auto reg = (factory_function*) dlsym(plugin, "register_factory"); // or use a framework such as Qt which does this correctly reg(&amp;f); } }
I agree that folds are a huge improvement over the existing methods, but one nitpick I have is that the use of recursive functions is probably not the idiomatic way to do that in C++11/14. I'd say that this fold: return (UINT32_C(0) ^ ... ^ std::forward&lt;Args&gt;(args)); is approximated in pre-C++17 by this: std::uint32_t result = 0; char dummy[] = { '\0', (static_cast&lt;void&gt;(result ^= std::forward&lt;Args&gt;(args)), '\0')... }; return result; Obviously the C++17 version is significantly nicer looking. Here is a [godbolt link](https://godbolt.org/g/kYqYzm) comparing the two (note that I added in perfect forwarding and a init value. The example from the article would fail if the C++17 version was called with no arguments)
"Language features". ;-]
More like this: std::tuple&lt;int, string&gt; foo() { return {1, "Hello"}; }
&gt; Called? Yeah, the name of the macro. Thanks for the link!
nitpick: thisIsCamelCase. ThisIsPascalCase. 
&gt; snakeForVariableAndFunction That's not snake case, btw. this_is_snake_case.
Universities should not be teaching specific languages just to teach them, they should instead focus on teaching in a way that the programming language of choice doesn't matter. 
Not only that, but people have different requirements and workflows that a single authoritative package manager won't work for everybody. This is even that case for python which has pip and conda. &gt; There should be a uniform "package" format and description, certainly. Totally agree. There should be authoritative package description and toolchain description.
I agree. Graphics are too subjective, ever changing, and implementation defined to be in the standard, IMO. The look and feel of an application is heavily platform specific, and way beyond the scope of the standard to address, and no one will use it for that reason anyway(Just look at Python's Tkinter, almost no one uses that for anything less than dead simple) Networking is an important, fundamental feature of many applications, and is much less platform specific, it will work the same way anywhere. It's much more useful than graphics, and will see a lot more use.
Right -- the actual meaning of "C linkage" is at the ABI level, which is platform-dependent. Specifics are in §10.5 "Linkage specifications," but they're quite light. There are some banned features with C linkage: Overloading a name, most of templates, user-defined literals, etc...they're all mentioned explicitly.
These typically offend seasoned developers. If you're having a hard time finding good talent then maybe you should consider improving your recruiting dept or hiring outside staff. No engineer brought in by referral would be subjected to this anyways. I pass on these. If I speak to them on the phone beforehand l let them know in no uncertain terms that this is unacceptable.
Or auto foo() { return std::tuple{1, "Hello"s}; }
So you mean Chromium... I wonder what's up with the original Opera (presto engine).
I hope it does get in. I recently converted over from Boost log to spdlog. My use case doesn't log enough to notice a performance difference, but the improvement in readability alone was more than enough to justify the switch.
&gt; To use Boost.Asio (installed on the system) one do: &gt; &gt; find_package(Boost 1.66 COMPONENTS system) &gt; target_include_directories(foo ${Boost_INCLUDE_DIR}) &gt; add_executable(foo foo.cpp) &gt; target_link_libraries(foo ${Boost_LIBRARIES}) &gt; &gt; This is insane ! But never mind. Using the same syntax, one could do &gt; &gt; find_cpp_dependency(BOOST_ASIO "boost/boost.asio" VERSION 1.66) &gt; add_executable(foo foo.cpp) &gt; target_link_library(foo BOOST_ASIO) Actually, with boost cmake you write: find_package(boost_asio) add_executable(foo foo.cpp) target_link_libraries(foo boost::asio) Or with pkgconfig you can write: pkg_check_modules(boost_asio IMPORTED_TARGET boost_asio) add_executable(foo foo.cpp) target_link_libraries(foo boost::asio) &gt; Upon running cmake that should: &gt; &gt; Look for a copy of Boost.Asio on the local machine’s cache. &gt; Look for that dependency on a remote server. The tool should have a list of mirrors baked in, and select the closest/fastest node to get the dependency from. Users, especially beginners should not have to care about where dependencies come from &gt; Look for/download dependencies transitively No, a build system should not be invoking the package manager. By keeping the relantionship one way, this will allow for a package manager and build system to be orthogonal, so you can use a different package manager or install everything manually. Of course, a build system could re-use the package meta data to get usage requirements in order to reduce duplication, but this does not requiring invoke a package manager. &gt; Then all dependencies are built. So maybe it calls bjam -with-system toolset=clang( bjam being the build tool used by boost). I think that is too much of a simplification. How would it know how to invoke bjam when its cross-compiling? Instead, you would create a custom user-config.jam file to describe the toolchain. This is bascially what cget does when you install with `cget install -X boost`. It translates the cmake toolchain to a user-config.jam file. Its not perfect, because there is no setting to tell it where your dependencies have been installed. Of course, if everything uses pkgconfig, then its easy as setting `PKG_CONFIG_PATH`, but thats not always the case. However, rather than always creating scripts to translate the build environment for every build tool, instead we can have a standard format to describe the build environment so then its a matter of invokeing the build tool with that. So then its just: `cmake --toolchain=my.toolchain`, `b2 --toolchain=my.toolchain` or `meson --toolchain=my.toolchain`, etc. &gt; Hopefully the build is successful and outputs a list of compile flags in a format that could look very much like pkgconfig Yea, hopefully. Its 2018, and boost still doesn't install pkgconfig or any usage requirements. Hopefully the move to cmake will help. &gt; In Python you can install a package using pip install foo. And then import modules in the code using import foo You could very much have a build tool do this. First, install the dependencies with the package manager, and then scan the project for header includes(or module imports in the future), and then call pkgconfig for that package. I have very much thought about creating a build system to do this. Of course, in the real-world I have found the building to be a bit more complicated, unfortunately.
&gt;CamelForClass That's PascalCase aka Proper ASE &gt;snakeForVariableAndFunction This is camelCase. The camel part is referencing the bump. &gt;such_as_this_though_I_dont_like This is snake_case.
Why is everyone in this thread calling PascalCase camelCase? :/
Because not everyone is as nerdy and pedantic as you and I. I just wish C++ supported kebab-case. 
&gt; We already have pkg-config pkg-config is for usage requirements, which is generated by the build script and not the package manager. &gt; Supports any build system that can be run via bash. Not every system has bash. Rather the build scripts should be the scripting language. Ultimately, there should be standard description of the build environment that can be used across all build systems. &gt; I assume that, like all of the other language-centric package managers out there, it won't try to inter-operate with any existing package manager, and instead will attempt to FORCE OS level package managers to do things it's way. From what I can tell, this has been fairly soundly rejected by OS level package managers, who do things the way they've always done and bundle the source code with manual compilation and installation scripts, instead of calling to the language-pm A C++ package manager should not take way the ability to install packages manually, which is important to allow for multiple implementations. In fact there is no reason to change the way we build packages manually at all, what we need is a uniform way to describe our dependencies and build environment.
AFAIR they used it in opera mini, because eg on OOM they didn't crash tab immediately but instead retrieved the memory and let the browser continue working on devices short on memory. But they didn't have the manpower to develop it actively, and there were no business incentives to release the engine as OSS (considering how weird some legal issues are eg concerning video codecs, they would have to spend tons of money on lawyers and code investigations before they would be able to release it for little benefit).
It's not perfect, but it is common, and in practice is does seem to have some value. But yes, I prefer namespaces. That's why I type out `std::` everywhere. As for other comments: yes, if you are writing a Container, you need to spell `begin` the same way as the standard. Boost is also not application code, so it's great that it follows the standard style. It would be nice if all 3rd party libraries were in that style. I work in a place that uses CamelCase, for whatever reason (legacy, whatever). If I'm writing something that is clearly 'library', not domain-specific, I write it to mimic the standard. But my domain-specific objects are CamelCase. Maybe I'm just making the best of a bad decision, but I've found value in it.
that's expected knowledge when reading about the factory pattern.
Should be easy to create a function chain abstraction yourself. A class with an `then` function that accepts a lambda and returns the same class.
But it's camelCase because of the bump! Tell me where the bump is in ThisStyle, huh?!
The code in the article is this: template&lt;class RType, class Type = RType&gt; struct type_factory { template&lt;class ...Args&gt; RType* operator()(Args&amp;&amp;... args){return new (std::forward&lt;Args&gt;(args)...);} }; ...
yes, and the point is to use it in factories. This is just an implementation detail (which replaces boost::factory which does sensibly the same thing in much more code).
&gt; This is just an implementation detail You mean *the subject of the entire post?*
Sorry, I don't understand your question. The ISO C++ standards are "free as in speech", meaning that anyone can join and work on the specifications. But, to actually download the final specifications you have to pay.
`CamelCase` is a correct term for it, but `PascalCase` is more precise. Similar to how squares are rectangles. If you see a square, it would be valid to call it a rectangle.
&gt; here's an idea floating around that they can be used for monadic error handling a) please do not use M word, it just complicates things... I assmume you mean you want to implement something like auto a = co_await func_that_returns_optional(); // early return if optional is empty b) co_await will look lovely in this context, so if possible please tell Guardians of the Keywords that we need a new one.
It's a camel with two bumps?
Yes that's my understanding as well. CamelCase covers both lowerCamelCase and UpperCamelCase, and PascalCase is another name for UpperCamelCase
_lower is reserved in the global namespace, which makes it fine for data members. I think people just avoid it because the rule is less clear-cut (scope-based).
Yes but I don't want to reinvent the wheel again. Surely someone has already figured out the many corner cases.
Outcome looks nice. I used [std::expected](https://github.com/viboes/std-make/blob/master/doc/proposal/expected/p0323r3.pdf) for a while, which looks rather similar. I'm saddened that it didn't make it into C++17 with std::optional.
^ this. I'll give another example. If I have a sqrt function and an unsupported negative number is inputted so like `sqrt(-5)`, how do I handle that? Do I just throw? But isn't that mixing unexpected behavior and proper errors (like out of memory errors)? Aren't those two different things? I'm not sure if these have proper names, and that is part of the problem. We don't (that I know of) have proper clear and concise language to talk about this. Right now it seems like the goto is 'error codes' and 'exceptions'. Though, that lingo is horrid. 'Error codes' is unexpected behavior and 'exceptions' are errors in the system. That's not really great. As long as this language barrier exists there will be problems, if not confusion alone.
I hate using auto in non local variables that aren't obvious
&gt; a standardised GUI as every other language [Citation needed]
That's fair... What I meant is a GUI from the get-go. I do GUI on C++ and there's a million paths to get there and they are all tortuous ones.
&gt; I feel that class and type names deserve special naming styles that differentiate them from other items Food for thought: * In Lua, functions and *classes* are first-class values like any other variable :) * In C++, what about functor/callable classes/objects? Named like a class, a function or a variable? In the end, I use different conventions for different projects, whatever the language. As long as everyone can easily understand the code, which convention you choose doesn't matter that much. And as others pointed out, consistence (inside a project) is important.
I was only giving my position on the subject 10 years ago. I'm against any GUI library being part of the standard, because there's no standard when it comes to GUI.
When I first heard Herb talking about the graphics porposal I got very excited, but now I just want it to die. What bothers me the most is that "games" is mentioned prominently in the proposal, but it's clear the authors have no idea or interest in games. I agree with the linked OP, the proposal is too broad and should be split up.
Wiedzy = of knowledge
&gt; I've yet to see a pkg-config file that wasn't hand-written. Most are only handwritten partially. It usually has variables to be filled during build/install(like [here](https://github.com/vadz/libtiff/blob/master/libtiff-4.pc.in)) Also, boost cmake modules generates them from the cmake target. &gt; I'd love to know more about this. While I don't think you're wrong, I have no evidence that you are right, and lots of evidence that you're wrong, so I'd like to know more about this. That is the way pkg-config is setup. It has things like CFlags and Libs, which are needed based on the way the package is built, but is not needed at all by a package manager. It also has no support for optional dependencies, and it would never need to because optional dependencies are decided during building and installation not during consummation. Finally, I know of no distro that uses pkgconfig for its metadata. Debian uses a control file. Rpm uses a spec file. Even portage has its own file format as well. &gt; Do you have a preference? Why is your preferred scripting language better? There should be no scripting language. The buildsystems provide the scripting. If a package's buildsystem doesn't work, it should be fixed upstream. Alternatively, a build script can be to replace the current one. This is similar to cget's `--cmake` flag which can add a cmake file to build a project the is lacking a cmake or the current cmake is broken. &gt; What build scripts are you referring to? There's make, ninja, msbuild, meson, cmake (which ultimately generates make or ninja). It should support all of them. Although some buildsystems may need some work. &gt; Are you proposing a new build script? No &gt; What do you mean a standard description of the build environment? I'm not sure what you're trying to convey here. Some kind of standardized syntax describing how to build a project? Or a standardized syntax describing what configuration options for the project? Or something else? Neither. I mean a file to describe the build environment, which means what system you are targeting, what compiler to use, what flags to use, whether to build static or shared, or debug or release, where the dependencies are installed, and where the package should be installed. Cmake provides a cmake toolchain file, bjam has a user-config.jam file, autotools/make uses env variables, and meson uses env variables or a cross-file. So rather then deal with all these formats, a package manager would use one standardized file format. In the short-term it would have to convert between the other formats, but hopefully in the long-term build tools will utilize this format directly. Also, a standardized format will help ensure that newer build tools are sufficient for a package manager. &gt; The existence of a language specific package manager generally means the developers using that language, and the developers of the language and the standard packaging system for that language, ignore to the point of active interference the entire concept of OS level package management. Yes, but a package manager for C++ should not be built that way. It should build on existing practice. Package managers like hunter and cget already do that. &gt; So long as whatever C++ ends up going with makes it trivially easy for my OS level package manager to build C++ packages "natively", without having to jump through a lot of hoops, I'm all for it. In fact, if a C++ package manager tries to change that, it will be a non-starter. Fundamental libraries like zlib or curl will not start using the new package manager+build and will stick to the traditional cmake/autotools. &gt; I'm not seeing a difference here besides the C++ language standard having the gall to claim one way of doing things is better than the others. Its about setting up a standard spec that can be used across platforms. There is no standard for that yet. Portage describes a package using bash, but debian uses a control file and rpm has a spec file. Ideally, we want a standard `package.spec` file that a developer can put at the top of the source directory and it can enable it to be installed by any C++ package manager. &gt; Now explain why all the existing programs out there aren't doing it this way? Doing it what way?
&gt; Who's gonna use this? This is going to be the next std::regex. Ummm... my company uses `std:regex`. We're _not_ using it to scan the Library of Congress's collection, or anything with performance implications. But we do use it. Is something wrong with it? (other than it having an annoying API) Regardless, I think that including a graphics library is a bad idea. Because it's going to take WG and compiler vendor time/people away from everything else, and I have doubts as to its use-cases. One of the responses in the first mailing thread had this line, defending the proposal: &gt; It's not more maintenance than, say, filesytem. I know very little about graphics libraries, but I'm pretty sure that statement is total bull. 
&gt; To press this point, if I was a new cpp developer and I went to cppreference to look up how std::vector works, would I be surprised when it suddenly throws an exception? Not if you actually read the page – every function has an 'Exceptions' section. ;-] &gt; imho exception information should be in the declaration Checked exceptions are great on toy projects but don't version well; if the language had them, I'd certainly avoid them in code I expected to use long-term.
I also have yet to read a statement of why Cairo was chosen and why some people think this is a good idea. An ugly, old C library with a horrible API. Who is ever going to use that in C++? I want a C++ graphics library, not a C one. Why not something like SFML instead? (And no please don't answer "Because nobody has written a proposal". The ISO WG's must have discussed this. Just because someone came forward with a Cairo proposal, and nobody came forward with a better proposal, we're all stuck with this, or what?
Regular expressions are useful, but I wouldn't trust any standard library's `std::regex` for correctness, much less performance, even now.
Reading the replies to the first linked thread is downright cringeworthy. &gt;cool ideas but where are your papers :))) we will ignore as many opinions as we can get away with because we're writing proposals to standardize a mistake in the making and you aren't writing any to stop us! haha! What even is it with the idea that unless someone gives a better "alternative" proposal this is the one everyone's stuck with now? How's not adding a GUI for an alternative? Does someone need to send a one page blank paper as a graphics proposal for that to be considered? Does this also mean someone could go forth and come up with the shittiest, most ridiculous proposal imaginable and if nobody offered a better alternative SG13 would go "welp that's the best we can do let's add it!". How about someone writes an `std::animoji` proposal with a webcam face tracking API with functions to map your face to 3D face models (in addition, based on the oldest 3D format one could find). Yeah, getting some Unicode support first would be a bit nicer but hey no ones submitted a proposal for that so animojis it is :))) 
re: a) "terse return" :P My point was just that if you talk about it even here at r/ cpp where a lot of people like Haskell compared to general C++ developers you should avoid the M world, same as you do not teach ADL when you explain hello world. re: b) thank you for fighting the good fight. :) also if you could convince people to go for std:: and std1:: instead of std2:: and std that would be great. I know it is just 1 char, but it is quite ugly to have version in a std namespace. :)
Yup, and I like the convention followed by the standard library and try to use the same in my projects.
This is just stupid.
What does that mean?
Yes, it is a good idea. Couple of things to be careful about. You do not want to make it too easy(no filtering, candidate thinks company hires idiots so he will be less interested), or too hard(no point in rejecting 70% of candidates esp, since they can cheat on it). But to tell you honestly I think your biggest problem is compensation/codebase. You can easily hire 10 C++ developers/month if you offer good compensation/ your project is not terrible. So either your HR is incompetent or your compensation package is too low. tl;dr yes, but I doubt this is your only problem
It means if I have to use `boost::regex` to get correctness and performance in 2018 then maybe `std::regex` isn't all that useful..? I don't really understand what you're asking.
&gt; doing trash-tier "hft" ELI5 how do they not loose money. Are quants so much more important than good code?
I initially downvoted because of the personal attack in the title, but undid the downvote because I share your complaints. Like others, I was excited at the announcement at first, but was disappointed with the obsolete approach.
I am shocked, SHOCKED, there would be differences in regex engines. And I guess technically the answer to your question is "yes", because we only use one: gcc's libstdc++, for both gcc and clang. :)
&gt; I am shocked, SHOCKED, there would be differences in regex engines. I get what you mean, but I can take the same patterns and run them against .NET's `Regex`, `boost::regex`, `boost::xpressive::regex`, and re2 and get the same results; so this isn't an insurmountable problem, but every `std::regex` implementation is flat-out unreliable at the moment. (And IME, libstdc++'s is by **far** the worst offender...) &gt; And I guess technically the answer to your question is "yes", because we only use one: gcc's libstdc++, for both gcc and clang. :) Right, that's the only practical way to use `std::regex` at the moment, and one I'm totally okay with – stick to a single implementation; however, kinda defeats the purpose of it being in the standard library, no? ;-]
This year is 2018 years, libc++,libstdc++ and Microsoft STL is planned to implement Network ? 
Cheers mate... we are all going through the same disappointment, seeing our expectations being shattered, not by the nay-sayers, but by hubris.
Which implementation? Run any regex test suite on any `std::regex` implementation and you'll come up with a different set of failures. And once you've vetted that the patterns you use give correct results on the platform you're interested in, then test those patterns with `boost::regex` and witness an order of magnitude speed increase. I have no problem with the specification, or regex being in the standard really, but if no one implements it properly it's pretty pointless.
ELI5 version: quants are more important always, speed doesn't make you money. I can tell you this from a losing experience. There's trading at every timescale, and it's a misconception that latency arbitrage (being fastest to respond to obvious signals) is even where most of the hft money based on how people define hft firms. Some markets aren't as latency sensitive as others, and some trades just aren't latency sensitive in the first place. As a result, a very poor "low-latency" system can do quite well because the trades it's executing are quite good. That's fine and good, but people will come out of a shop like this thinking they know what a good low-latency system looks like but really learned all sorts of anti-patterns.
&gt; While it isn't necessarily a job for the standards committee, it would be good if there were 'official' materials online for learning C++, I can only think of Standard C++ Foundation to be the suitable organization to host this effort. But whichever organization serves as the host, someone still has to do the real work.
Naming conventions are all about consistency above everything else. Yes, Python style is perfectly acceptable. Have a read of the core guidelines for naming and layout: http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#nl-naming-and-layout-rules
right, forgot about that part
&gt;Checked exceptions are great on toy projects but don't version well; if the language had them, I'd certainly avoid them in code I expected to use long-term. I don't know if std::expected or Outcome is checked exceptions, but I worked on a roughly 50 cpp file sized project not including libraries and what not using expected and it was fine. I don't think we're on the same page. In my past experience there was no problem with maintenance. 
At first I thought you were exaggerating. I figured there's no way they didn't just copy boost::regex or even PCRE under the hood. But I looked at libstdc++'s source, and it sure looks like they rolled their own. wow. I couldn't find any data of performance tests, other than this [horrible one](https://lists.gnu.org/archive/html/lmi/2016-07/msg00010.html), and although it appears informal it's still scary. I mean I don't expect re2 or hyperscan performance, but still... it looks like 1990's GNU regex performance level. (which was atrocious, back in the day)
What about Visual Studio? I doubt they'd remake an implementation since they already made one for .NET.
If you want real basics and "battle-tested", you'd go with the SDL. I don't see any metric were Cairo is really superior, so I guess some people have a vested interest in it.
What is the difference between this and `if constexpr`?
It's a shame that there aren't stronger semantics where the moved-from object doesn't need to be in a valid state (a.k.a it's immediately destroyed). For example, for a `std::vector` you could just copy a couple pointers and just clear the memory/pop the stack. I think some optimizers will do this, but having it in the standard would be neat.
&gt; The main difference between `if` and `if constexpr` is that the branch that is not selected is _discarded_ so it can contain statements that would actually be ill-formed.
Oh, no, like in the type signature. Like eg, returning an std::optional, so you know it can return null. An std::expected lets one return an expectation inside of the type, instead of throwing it. This way you can return an error code or the typical return type. It's like an explicit tuple for expectations so you don't have to throw.
I'm pretty sure a large part of the .NET framework uses native code for performance/calls native API, which is why I assumed they could have reused it. But it's interesting to see they didn't make it in-house.
So there's no reason to choose it over the newer C++17 version?
IMHO it's perfectly fine to include a C API in the standard, as long as it exposes all the necessary primitives and is implemented well on all platforms. Once we have such a basis, anyone can build a C++ interface on top of it, and it'll just work everywhere. This my main expectation from the standard; to expose low level primitives, that would be very hard to get right across a bazillion platforms. My hopes are shattered though, since that requires open discussion between people coming from very different backgrounds.
Oh, certainly not; the appeal is that it works with C++11 onwards.
GNU regex was originally released in 1985, but under GPL (well, something similar to GPL, since GPL didn't even come out until 1989). PCRE was released in 1997, under a permissive license that I believe even Microsoft could have used. 
Honestly this is a clear example of the insanity of "commitee-driven" development. There wouldn't be issues on this scale if C++ was developed in a more open-to-public-comments fashion, for instance like Rust.
&gt; . This my main expectation from the standard; to expose low level primitives, that would be very hard to get right across a bazillion platforms. So... why not just use existing libraries where man-decades have been spent in ensuring they work right across a bazillion platform ? The existing state of standard libraries implementations shows that even for simpler use case, one cannot expect std::foo to work the same in libc++, libstdc++ and msvc's lib, so expecting it for `&lt;graphics&gt;` is foolish
I pretty much use these rules with the addition that functions should use camelCase (first letter lowercase) and classes and other type definitions, like using declarations and strongly typed enums, should use PascalCase (first letter uppercase). This makes it reasonably easy to distinguish between different types of identifiers.
Skip to section 4.3 and below to get to the interesting information.
If you have any trouble (or success) don't hesitate to ping me!
&gt;But why isn't C++ programming a subject by itself? As the world's language of choice in quite a few fields, and given that so many people agree it is a difficult language, surely just learning C++ should provide sufficient material for a course? That way, one can at least start from the modern end. Where would such a class be taught? Not in a core CS class at university, I hope. Yet that's the only way it would supplant the teaching of C++ of a tool rather than as a subject unto itself. I'm skeptical of the effectiveness of such an approach.
&gt; Personally, I could care less whether the reference implementation for a proposal is written in C or C++ That's not really the point, but actually, I failed to mention some context to this point. Long story short, Herb asked SG13 to find a graphics library that was already out there and could be introduced as part of the standard, taking advantage of the body of work already open sourced by such a project. Cairo was an option. The other option was Skia. For some reason they went with Cairo. Now, Cairo is has a fairly outdated API and a lot of other issues. Being written in C is just another one. That thread is just asking why not Skia, and the fact Cairo is written in C is mentioned as a reason. The assertion was that a C library was easier to modernise to the latest C++ standard, than any C++ library. I have not see anything backing up this assertion though. So that was what that thread about C was all about.
For sure.
IMO, the most important part of this paper is something I see no other comments talking about. The call for cohesion and consistency in 4.2 is something C++ sorely needs. It has suffered greatly from a lack of consistent vision and design, which is no doubt due in part to the issues outlined in section 6. I look forward to C++ hopefully becoming a more consistent, focused language in the future.
That paper is so unnecessarily snarky and a missed opportunity to address the external criticisms in a constructive way.
I'm quite sure it's not a good idea to start a discussion with insults and emotions. I fairly convinced that most of the actual committee members who hang around here will just ignore it. Because of the naming... &gt; For starters, skia is the de-facto 2D graphics library for browsers (Chrome, Firefox, Opera, etc), definitely used in more than 1 billion devices around the globe. That doesn't say much - C++ target isn't only PC and Mac audience. I'm quite sure medical equipment is not supposed to run Chrome. So if you want to make a point, you better start with **data** and not **emotions**. P.S. I'm quite convinced that current proposal will not go past LEWG. Let alone WG21.
You might want to read [this](https://www.reddit.com/r/rust/comments/81qpvt/direction_for_iso_c/dv4f1pk/). Keep in mind that "committee-driven" development has to take in mind a lot of opinions of both big and small players. Something that Rust doesn't need to do... yet.
&gt; I'm quite sure it's not a good idea to start a discussion with insults and emotions. That's not about emotions... I just wanted to say something funny and provocative. &gt; So if you want to make a point, you better start with data and not emotions. You sound quite offended with this sentence... I even open the first sentence saying it is not ideal to insult. &gt; I fairly convinced that most of the actual committee members who hang around here will just ignore it r/cpp Is not a portal to reach out to Committee members, so my post is not concerned with that. I just thought other people would be interested to see that discussion on SG13. I can reach out to the members of the committee if I feel like. This is just a message board where we talk about C++, right?
Hmm. I think they're right in that if you need to wrap an API, it's easier to wrap or adapt a C API than a C++ API. C style APIs with plain functions and opaque pointers tend to be easier to deal with than a C++ API with templates and an existing class hierarchy that may not match the interface you're trying to create. But this is very, very low on the list for reasons to choose a reference library. 
Author of the first linked thread chiming in: This got a lot of attention! I think the feedback will all be useful, and it should be said that I think very highly of the standards committee/C++ in general. The graphics community has historically *not* been very enthused with C++ due to the lack of focus on performance/control. I would say only in the last few years has there been very significant adoption across the board, due to lots of efforts and improvements from C++11, 14, and on. Perhaps this is why I'm a little sensitive to this topic in particular. I'd like to keep the positive momentum! I read the original "C++ direction" document penned by Stroustroup and think there's some merit in helping practitioners "get up and running," but I think the idea that C++ is being marketed as anything other than a low-level systems/engine/server language is misguided. Students aren't looking at C++ to make a blogging site or GUI application unless they are already doing so with the express intent on learning. This is one of those cases where I think doubling down on your strengths (or at the very least, solidifying your strengths) is advantageous, compared to spreading yourself too thin. I chalk this up partially to the relative novelty of the new standards committee structure, where delegating of subdomains might mean "oh look at all these new toys we can have quickly." But as we all know... free lunches are poisonous or something.
Most people serious about gamedev don't care for a graphics library from what I've seen. They just want a couple more data structures in the standard library, like ring buffers, and fixes in other places. Then again just about all these same people replace the standard library with something custom made so I'm still a bit confused as to why they want additions if they won't use them. Maybe if someone else could shed more light on that second part I'd be interested. 
&gt; That's not about emotions... I just wanted to say something funny and provocative. Yet you bashing other's people work. &gt; You sound quite offended with this sentence... I'm not actually. I'm just unsure about your end goal. If you wanted to change something, I'm not sure it was the best way to do it. &gt; Is not a portal to reach out to Committee members, so my post is not concerned with that. I just thought other people would be interested to see that discussion on SG13. However, they are monitoring this sub from time to time, and even take notes. I agree that Reddit is not the best place for this sort of discussion, but it happens here from time to time. &gt; I can reach out to the members of the committee if I feel like. Opinions. Besides, participating in an actual discussion would lead somewhere...
&gt; What are you going on about here... I want examples of Skia being used outside of "mobile\desktop" market. With all imperfections, Cairo has them.
It was never mentioned as a requirement that it had to be used in multiple markets before being standardised. However, granted, that's a good question. A question that was never entertained in the thread a linked above.
Different game developers need different things. Simple example: std::hash gives different results on clang, gcc and visual c++. If you're making a game that is cross-platform and needs reproducible behaviour then you can't use std::hash. But if you're developing for a single platform then it's fine (assuming the implementation gives identical results *between* runs, which iirc also isn't required.)
I like the convention that given a user defined type, `UDT` declared as a `struct`, then `std::is_trivial_v&lt;UDT&gt;` should evaluate to true.
Yes, we are. If you looked at the referenced articles, you'd see an instantiation of the factory type is intended to be type erased and stuck in a container keyed by typeid or the name of the type or whatever. The author is not advocating using this instead of make_unique/make_shared/new when you have the concrete type available. // in some init code: std::unordered_map&lt;string, std::function&gt; factories; factories.insert("MyWidget", type_factory&lt;MyWidget&gt;{}); // repeated for each widget type // in some code run when creating some UI objects, the specific type of which are dependent on user input BaseWidget *widget_instance = factories[name_of_widget_type](widget_name, some_event_handler, model); The assumption is you'd have a standard set of constructor parameters. The other boost usage in the article seems to support providing default arguments for constructors.
Great !
https://github.com/SuperV1234/scelta https://github.com/TartanLlama/optional
I think what the answers that get criticised here meant to convey is that the proposal is at a point where just general, informal criticism on the design isn't useful. The need actionable input. That means a) A formal paper b) concrete examples and / or data that demonstrates the claimed problems are actually problems c) Concrete suggestions on how to improve. Formulated differently: You can open a bug report saying that the design of library X is fundamentally flawed because of reasons Y and Z, but even if the library author agrees with you that usually won't cause him/her to just drop everything and spend the next year's to write a new library from scratch. I don't see any of the hostility that others seem to read out of it. Just an attempt to explain what needs to be done, such that the opinion of someone has actual influence on what is happening in the standardization process.
I'm not fundamentally opposed to teaching programming languages in core CS classes. I know some people are, and one argument I've occasionally heard is that "astronomy is not about telescopes". That's true, but it's a poor astronomer who has never looked through one. Programming languages are the tool of the computer scientist. It makes sense to learn how to use them properly, especially considering that 99.9% of the students will eventually end up in positions that require at least some level of proficiency with programming. So why not spend some time learning about them as a goal onto itself? I first learned C++ in university, as part of a computer graphics course. The people teaching it had little interest in it, and less skill. Initially we were told to "learn C++, and for next week your assignment is to program a 3D visualisation tool" (this was in 1990, two years before OpenGL was released, and we were programming the whole thing in MS-DOS, using a custom library that allowed hardware-accelerated line drawing and nothing else). Not surprisingly, this drew protests from the students, who felt this was a bit much. In the end they spent three lessons teaching us C++, focused very strongly on a weird mix of low-level stuff (pointers, memory allocation), and high-level concepts ("objects are independent entities that communicate by sending each other messages"). This was a really lousy way to get started on C++: it took me another 5 years or so to become somewhat proficient, largely because I had started of in such a weird direction. Eventually I figured out that member functions are just normal functions with an additional implicit pointer, they are not "stored in the object" or something. And "sending messages", at least in C++, just meant "calling member functions" - there is no weird, asynchronous network of objects all talking to each other by throwing messages into the ether, cool as that may be. Anyway, I cannot complain about the lack of teaching materials in 1990, and considering the situation I suppose our professor didn't do too badly, but it's 2018 now and it would be good for the language as a whole if we manage to make better options available. 
I didn't see anyone get nocked down. They (I think it was actually just one guy) just told him the truth that general criticism in the form of an informal email without actionable items will have little influence on a formal proposal that has been in the making for years. And they told him what was necessary to make his opinion being heard on any official level. Unfortunately, that's just how c++ standardization works.
Nice under-quote. No, that was not (of course) what was meant. Here is the additional sentence you removed: &gt; Maybe if you decide to actually write a proposal (to not continue with the current one), you would set it up as an answer to P0669. My point was that there are arguments for a proposal designed this way and they are written in a paper. If you want to counter-argue that you need to send a paper with the counter arguments to what was argued. I respect the point of view and am still looking for strong arguments against the discussed paper but it's just practically not useful to anybody (committee included) to not have a paper to refer to in official discussions. Also note: I'm not part of the committee.
&gt; I didn't see anyone get nocked down. Clearly, a lot of people disagree with your assessment. You even admit that on your other comment.
What a waste of time, I can't believe that this is even being considered.
You can say goodbye to graphics then, because it won't ever be standardised, not like this. Or do you think that NVidia, Google, and others are saying Yay to this? You can argue all you want that we need to stop being peasants and start writing papers. We don't want to write a paper. We are just watching a car crash in slow motion and talking about it. Or am I just allowed to ever talk about it if I become a member of the committee?
I am astounded I had to come this far down the thread to see SDL. SDL is included with at least one compiler and is largely emulated for WebGL/WASM. It is a solid API that works in countless games and non-game applications.
&gt;&gt; It's not more maintenance than, say, filesytem. &gt;I know very little about graphics libraries, but I'm pretty sure that statement is total bull. I challenge that. You took that quote out of context, which makes it less obvious what was the original point. The point was that the implementors of a standard interface are allowed to use anything in the implementation, so using something like SFML (one of the many possible impl) as impl and just adding the thin layer is similar work to the one done with filesystem. Also, libs like SDL, SFML and Cinder also are relatively thin layers over the system/opengl in most drawing-related cases. Instead of begin baffled, could you give me counter arguments to these points?
It is not an under quote... you already set out the premise in which people have to play along, and you poisoned the well for anything out of those bounds... you next sentence only confirms this. I read that paper, and I even linked that paper over here, and it has really no rebuttal for the points made on that thread, even though you say so.
This is still BS though...
The OpenGL library is a horrifying example of how to get it wrong. There is no way to do RAII with OpenGL; before you can allocate, read, modify, or free anything you must ensure the right "context" is active. Some contexts are nested in others, and context switching is incredibly expensive... All of this makes it extremely hard to build a useful C++ wrapper for OpenGL. 
Defining a standard "interface" should be enough. Implementation does not matter so much, we just want to avoid rewitting everything if the backend has changed.
&gt; In C++ 17 std::unordered_map and std::map gained Howard's node based API which is a huge improvement in efficiency. I do not believe this matters in the big picture since biggest problem with unordered_map is buckets API. As for std::map - please do not use it in the sentence that contains word efficiency. :) &gt; Last I heard, the plan was to implement sparse and dense maps using a Range view, so you'd take a vector, adapt it into a map view, and bang you're done. AFAIK views are nonmodifying? "A view is a lightweight wrapper that presents a view of an underlying sequence of elements in some custom way without mutating or copying it. Views are cheap to create and copy, and have non-owning reference semantics. Below are some examples:" And either way I doubt you gain anything by forcing together vector and range view to make a new container. 
I'm not a native speaker, I always thought nocked down implies an unjustified hard rejection usually with unfriendly language and I don't see those aspects in the thread you linked to. I'm sorry if I misunderstood the meaning of the term. Also, I wonder how many of those "lots of" people (who ?) have actually read the thread and not just the quotes and "paraphrases" you and others posted. Also, I read very few rejections of the technical points but more like "it's what we have at the moment, we think it is good enough and we won't throw it out the window without having a concrete alternative". 
Thank you for this correction! I have never actually check for that rule myself, I just believed in what someone with large C++ expertise told me (and I think I saw this myth in several places on the web). I feel much better about using `_lowerCamelCase` for field variables.
Do you plan to add a floating point format using to_chars (P0067) ? Could it become the default format for float instead of the g "lose precision" format ?
&gt; Did you see how hard that bloke was knocked down by the people doing the work That is a hyperbole, as a figure of speech. &gt; more like "it's what we have at the moment, we think it is good enough and we won't throw it out the window" Which is a unwise course and definitely is going to be the downfall of this proposal or any other proposal in the future.
Unfortunately a lot of people say "camel case" when they mean "pascal case", so I wanted to be blunt with the distinction. Thank you anyway :)
Thanks for your positivity and for actually starting the conversation. It's already a good step forward. :)
Thanks for clarifying that better than I did.
I'm pretty sure there is no big player whatsoever asking for this, though.
&gt; I do not believe this matters in the big picture since biggest problem with unordered_map is buckets API. With the new node based API, if you never create nor destroy nodes, unordered_map now flies like the wind. The avoidable cost in there is the unavoidable malloc for the nodes. &gt; As for std::map - please do not use it in the sentence that contains word efficiency. :) Nothing wrong with RB trees for certain applications. Just avoid use in multiple threads, and they have a nice smooth scaling curve which is hard to maliciously perturb. &gt; AFAIK views are nonmodifying? Yes, you're right. Ok, whatever Ranges calls a modifying view. You know what I meant. &gt; And either way I doubt you gain anything by forcing together vector and range view to make a new container. Sparse map is trivially easy to make over a vector. Lacking Ranges in MSVC, I wrote my own view adapter implementing an open hash map at https://ned14.github.io/quickcpplib/classquickcpplib_1_1__xxx_1_1algorithm_1_1open__hash__index_1_1basic__open__hash__index.html. Performance is *superb*.
The points made in that thread are not in a paper, therefore, it cannot be discussed in the committee's (very limitted and benevolent) time except on the mailing list and if someone there request a discussion about it. However, they still need to refer to a paper, in the same way you need to refer to a ticket number for discussing an issue. This is not about you or emails, comments, reddits on the internet. We need a formal process to progress, that's all. What do you think a rant on reddit will change about the proposal? Probably nothing. However put that rant in a paper and you might have a real impact.
There are few libraries I would not prefer over OpenMP.
&gt; What do you think a rant on reddit will change about the proposal? Probably nothing. Exactly... This is reddit... r/cpp is just a place where people talk about C++. I don't know why you think I should be trying to effect a change with my post on reddit. Can someone just talk about something that have some interest about? Besides my post is going to have as much effect as this proposal. This proposal is never going to be approved, because the people involved keep sitting as high priests asking for other to write papers and waste more time in this pointless endeavour. I have said before. Do you think that NVidia, Google, IBM are saying Yay to this? I would make a wager this proposal is going nowhere, and this "Send Papers or we don't care" is just the nail in the coffin.
Give us utility features like unicode, crypto, interaction with clipboard, date time. But not damn graphics. We already have very good libraries for it. Make modules + packages happen instead. It's better to have a tool to pull good libraries than built-in thing with no users.
For me it's undisputable that `find_first_not_of` is much easier to read than `findFirstNotOf`. camelCase sucks for names with 1-2 letter words (`student_t_distribution`, `io_handler`)
As someone who has done a bunch of graphics this is a small slice of the problems I've had: 1. No way to easily/by default convert between SoA and AoS, which often means perf penalties just because the language makes it difficult to do correctly 2. Unicode support is terrible and makes rendering text and operating on text unnecessarily hard 3. RAII is an inadequate tool by itself for managing GPU based resources. EG if the context changes, you may need to reallocate a bunch of data, preserving the data across the context change by reading it back to the host. In an raii format, you have to tear everything down, and then rebuild everything back up again but this time with data. There isn't a c++ mechanism for handling this by default, I'm not sure if there could be, its equivalent to your heap becoming invalidated and having to move everything 'new' allocated over to a new heap 4. Managing lifetimes of graphics objects and graphics operations is hard to do correctly. Sometimes you want a piece of specially allocated memory (eg pcie accessible) that needs to persist only for the duration of an operation, and then be deleted after you've put it back to regular memory on a callback, or on an event happening For operations, at least in opencl, if you need to do operation -&gt; readback -&gt; readback dependent operation, its most efficient *not* to pipeline these but instead dynamically queue the next instruction in a callback after the previous has finished executing, while other work is happening. This results in a tonne of finickity multithreading async stuff where you have to be extremely careful with race conditions. The language provides poor support for multithreading safety which makes this unnecessarily hard Things which aren't hard: 1. Setting up a generic cross platform/vendor context and rendering 2d shapes to it SFML and SDL are both high quality libraries, SFML particularly is very easy to use, although it has limitations. It looks like Skia is used by the major browsers, so I'll have to add that to my list of things to investigate The problem is, it seems targeted at making games (lets assume that this is targeted at newer folks for 2d) but the vast majority of it has nothing to do with why making games is hard This leads me to believe that its fundamentally mistargeted - the people who would benefit from standardised low level graphics are fundamentally never going to use this (because it can never keep pace with a constantly developing library, and also because its bad), and people who need a friendly 2d graphics library are already cared for
How `(static_cast&lt;void&gt;(result ^= std::forward&lt;Args&gt;(args)), '\0')...` is not a fold expression? I though that before C++17 `...` always had to be adjacent to the `args`.
I would think that at least there are rather ordinary ways of dealing with this, e.g. `noexcept(false)` destructors that throw when they can’t do their job. In practice I would expect it to lead to `std::terminate` in short order, since you’d likely have several objects get destructed in a wrong context. Perhaps context swithching needs RAII too, but that seems like encouraging it, when we want precisely the opposite. 
&gt; I disagree with conflating fixing dependency management as fixing this, but maybe that's a parallel discussion to have Well, at least we have some common ground. &gt; Then... why do you rant? What is wrong with ranting. It is healthy to rant and vent frustration every now and then.
SFML (and many others) is based on SDL. So you could easily implement SFML-like library in C++ and allow customizing / using it at low SDL level.
`std::hash` is designed solely for use with the unordered containers. It is not intended for any of the other uses you might hash something for... Which is unfortunate but if you want repeatability you should be using a _specific hash function_, not just "hash".
Hey this looks very interesting!
Thanks :) I have forked linenoise-ng because no (C or C++) line editing library at the time allowed for custom syntax highlighting and I wanted that feature for REPL of [my programming language](https://huginn.org/). -A.
This looks super useful, i'm building (essentially) a c++ command line hacking game/mmo and I need syntax highlighting and autocomplete as well as an in-game code editor, so this is absolutely wonderful
Well, regex in general can take exponential time on length of input, and std regex does not provide APIs to detect/deal with those cases other than "let them run". So it is not suitable for consuming non-QA tested regex's. Which means you should onky use them with relatively fixed and/or constrained strings. At which point writing a manual parser starts looking tempting.
a) No promises - it's not my project, but I'll mention it next time I see the people involved. :) b) Thanks for the support and kind words. When it comes to std2::, I don't know yet how much of a fight that is going to be, but it's a huge issue for me and I'm going to fight it hard. I desperately want the benefits of the Ranges work, but introducing an std2 namespace is an unbelievably bad idea. *fingers crossed*
The proper solution would be an architecture that is free of context switching. OpenGL has been moving in this direction, but modern versions of OpenGL have a much smaller market share than the older versions, typically ruling those out for practical use. It would be helpful, I suppose, to have a framework that does the context switching automatically (so at least your software works), and that can warn if you do too much context switching (so you can optimize it as needed). I don't think such a framework exists though. 
&gt; A system package manager (apt for example), should be reserved for the installation of tools and applications, not something you use to manage the building blocks of a development project. And our dependency manager should not try to install things system wide. I disagree - I think this is where all the language-specific solutions fall down. Splitting dependency management between what you think of as the operating system and what you think of as your development environment is artificial. Put it this way: where does libc or libstdc++ sit? Is the compiler part of the operating system, or your development environment, or both? What if you want a more modern compiler than the one your OS ships with? Or the new libstdc++ that isn't binary-compatible? For non-C-like languages, what happens when e.g. your python library has a native dependency. Do you then have to go to the OS package manager to install it? Or do you depend on the operating system compiler and try to build it? What happens when a Haskell package wants to depend on a Python one, or vice versa. Should these different dependency managers interface with one another? These questions are hard because we have created a confused distinction between the operating system and development/user environment. I'm hoping that Nix or something like it can give me a tool that solves the one problem that is dependency management, rather than drawing a line in the sand and attempting to solve the problem on one side of it only. 
Why do you think that?
I just tend to overlook !. With the written 'not' the code is more verbose to me.
That's great, AND it's not header-only!
I don't like the Graphic Proposal either, but I think the insults in the title of this post + selective quoting were not needed. The point is that the standard commitee will not read threads on reddit or newgroups. Opinions need to be submitted as papers. If, as supposed, this proposal is dumb, then it should not be very difficult to put together a proposal to shot it down, or at least delay it out of C++20. If people actually believe that having a Graphic API is a good idea, then they should form a group together and submit proposals (and demo implementations).
&gt; I mean, it seems like it's obvious to a lot of people that alternatives have to be better, but I scan papers all the time and no geometry maths, nor color representation, nor serious graphic proposal where proposed (except if I missed one) in like 5-6 years. Because there has been zero demand for that.
Nope, the `...` just unwraps and applies the expression to the pack, even in C++11. Otherwise we'd never have been able to implement `std::make_unique` as `return std::unique_ptr&lt;T&gt;(std::forward&lt;Args&gt;(args) ...);` Notice the `...` is separated from the pack(s).
&gt; Just because someone came forward with a Cairo proposal, and nobody came forward with a better proposal, we're all stuck with this, or what? Of course. If there is only one proposal, then there is only one proposal. It may be struck down, but only if people against that proposal either submit written comments or an alternative proposal. If the commitee decides that having a crappy GFX library is better than having none, then we'll get a crappy one.
I would love to see your adoption! I am curious how other would implements their highlighters or other callbacks. -A.
Which is why networking is hgher in the priority list than graphics. Btw: &gt; Networking is an important, fundamental feature of many applications, and is much less platform specific, it will work the same way anywhere. It's much more useful than graphics, and will see a lot more use. From the direction paper: &gt; More specifically, don’t oppose a proposal just because: &gt; it is seen as competing with your favorite proposal for time/resources &gt; it is not perfect (according to your principles) &gt; [...] The core point of the document, regarding to graphics (and networking) is: &gt; C++ teaching is mostly stuck in a pre-graphics, pre-web world. This is a serious weakness, potentially fatal over the longer term. *Potentially fatal*. If they are right, is it such an issue if the graphic API that people would use for teaching is based on Cairo or anything else ?
That would surprise me a lot. Can you link a release notes page or something about this?
&gt; There was no selective quoting though I don't mean you misrepresented the specific comments, but by only quoting to semi-stupid comments out of the whole thread, you selectively quoted the thread. You then used a large brush to paint the whole SG13 as "basement dwellers". I don't grasp how you can even entertain the idea that you have any sort of moral high ground here. What the thread really said was "proposal, comments document, or GTFO". Quoting P0939r0: "A proposal for a radical change to a proposal already ``in flight’’ (i.e., in its second or later discussion) should not be allowed to delay the latter unless it comes with a paper with a detailed discussion of design, use, and implementation." Of course, I guess Dawes, Hinnant, Stroustrup, Vandevoorde and Wong are basement dwellers. 
&gt;&gt; why we didn't have a standardised GUI as ~~every other~~ most languages do I keep hearing this. Now, I'll admit I only know and use a half dozen languages. But I'm not aware of any mainstream languages that have a graphics API that anyone uses for anything serious, unless there is no alternative. Smalltalk/Squeak doesn't have a real alternative, and the results are awful. R has very good graphics, but is _very_ specialized. No one uses Java's standard graphics outside toys, similarly for Python. What "most" are people thinking of?
Good explanation. So the unpacking was already there. Fold expressions just allowed binary operators and arbitrary expressions.
I don't think it takes a genius to realize that this is bad for the language and a bad way to evolve a language... In today's age, the smallest step that the ISO/SG members could make is at least consider email threads (like the two linked by OP, which are very well founded) like a written submitted proposal. You know, these people are using their time to contribute on these official SG forums. But you're basically saying, whatever they write there, is pointless, because unless they submit it as a written proposal, nothing will come out of it.
Think of pre-C++17 pack expansions as fold expressions where the binary operator is the comma (but NOT operator comma). You could still nest the expressions fairly complexly, but now with C++17 you can, e.g. stick and AND in there instead.
Are there bug reports open for these things?
Random question: how about boost support? I really wanted to check out some Hana related assembly and it doesn't seem possible in godbolt which makes me really sad..
MS makes digging through the docs to find a good non-vague summary hard. [this video](https://www.youtube.com/watch?v=v0SjumbIips), even though it covers non-UI aspects, also applies to the UI parts of the new(est) API.
See [the previous discussion](https://www.reddit.com/r/cpp/comments/70hf7f/useful_gcc_warning_options_not_enabled_by_wall/).
[removed]
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/821b17/til_that_sg13_graphics_mostly_are_the_basement/dv7x9ye/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
A) **"A proposal for a radical change to a proposal already ``in flight’’ (i.e., in its second or later discussion) should not be allowed to delay the latter unless it comes with a paper with a detailed discussion of design, use, and implementation."** You didn't have anything to answer to that, of course. B) My point was about the people commenting on that thread Seriously. The freaking **title** of your post is **TIL that SG13 (Graphics, mostly) are the basement dwellers of the Standards Committee** The title of your little flamewar is saying that SG13 are basement dwellers (not some, all), and now you are trying to act offended. Cry me a river. I'm not arguing with yet another basement dweller. Don't care what the hell you do and what the hell you think, **but I won't argue with someone that resort to insults**, and this is why I will not respond to another message. Don't bother replying. Just continue to be the one that downvote the other like you did on all this thread, and just go away. 
&gt; selective quoting &gt; I don't grasp how you can even entertain the idea that you have any sort of moral high ground here. &gt; I know losers read it and cared about it strongly enough to try to suppress it. Right, you're not insulting anyone, because you insult with soft language. &gt; just go away. Who made you kind of the internet?
With graphics stuff, it can make sense to go more C-like at times since it represents interactions with hardware/firmware at times. This makes sense for something like Vulkan, ofc, but less so for this. I'd like to see an ImGui-like GUI system focusing on being stateless and dynamic, along with a similar feeling system for the rest of the graphics stuff.
wait really? I just fixed a bunch of odd bugs relating to this in my graphics engine, I don't want to fix more weird edge cases and behavioral quirks again ;~;
&gt; But you're basically saying, whatever they write there, is pointless, because unless they submit it as a written proposal, nothing will come out of it. Yes, this is what I am saying. Quoting [p0939r0](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0939r0.pdf): &gt; The aim of most members, new or “vintage” is to improve C++ by having their favorite proposal accepted. However, the sheer number of proposals (constantly on the order of a hundred) and the number of papers (running at more than one hundred for each meeting), not even every good proposal can be accepted. We encourage everyone to ask themselves As of today, the comittee members don't even have time to properly take into account the written proposal, so don't expect them to consider random email thread. Also. what is happeing here, is exatly what the Direction Group wants to avoid: &gt; Conversely, to improve the predictability of our processes and maximize the likelihood of delivering significant improvements, we discourage &gt; [...] &gt; “Change the World” papers for proposals already in flight And on the "they need to do a counter-proposal", it is even wrose: &gt; A proposal for a radical change to a proposal already ``in flight’’ (i.e., in its second or later discussion) should not be allowed to delay the latter unless it comes with a paper with a detailed discussion of design, use, and implementation. Ie: if someone wants to push for an alternative solution to graphics when the existing proposal is almost done, they should come with something much more complete than when arguing in the beginning. Also: &gt; Finally, after years of process, someone then stands up in full committee and raises issues that have been discussed for years stating “lack of comfort” with the proposal, suggesting alternative approaches, and demanding more time to consider or rejection. At this point, everybody unhappy with compromises made along the way chirps in with counter-points made over the years and the proposal is either withdrawn or defeated by a 20% minority, many of whom did not take part in previous discussions. We think that &gt; “lack of comfort” is not sufficient to block a proposal So, while there is around zero chances for the graphic proposal to pass in C++20, but there is pressure from the direction group to stop allowing people to step in years after the start of the work and stop proposal just because they are uneasy. Don't underestimate the will of the Direction Group to have graphics in C++: &gt; C++ teaching is mostly stuck in a pre-graphics, pre-web world. This is a serious weakness, potentially **fatal** over the longer term. Personally, I think the idea of shoehorning Cairo is quite a bad one. However, I do recognize that teaching C++ today is extremely difficult due to the lack of usefull things one can do out of the box. My kids use javascript for everything. I did teach them C++ and python, but they now end up firing Electron to build apps. There is indeed a risk for the future of C++, and *maybe* a bad Graphic Library is not such a big price to pay to keep relevance for newcomers. 
&gt; factories.insert("MyWidget", type_factory&lt;MyWidget&gt;{}); // repeated for each widget type The type is known here...
It only applies if you port to the new API (WinRT); win32/win64 will probably stick around forever for backwards compatibility. Of course, I once thought that about win16.
Windows support! You're my hero :D
Looks interesting! How viable would it be to port this to an embedded platform with no OS or heap allocator? Are the platform specific parts well isolated?
Fair deal.
There is no ambiguity. At any step either your program can continue with its assigned task, or it cannot. In the first situation it continues. In the second it aborts whatever it's doing and goes on to some other task (or terminates). How you handle an error is ultimately a matter of choice. Error codes and exceptions are not conceptually different; they both signal that the program has run into a situation it cannot resolve on the spot, and has begun the process of aborting and moving on to the next task. In the case of exceptions this is fully automated, and supported by the language. In the case of error codes you must write everything yourself, a bit akin to simulating virtual functions using collections of function pointers. Sure, you can do it, if you don't mind the inconvenience and additional work. As for C++, the mechanism of choice for signalling error conditions is exceptions, as defined by the language and by the standard library. And while a very vocal group of people want this to change, I'd argue that having a coherent, unified error signalling mechanism is both important and valuable. As such I'm not in favor of introducing all sorts of alternative error signalling strategies, or mechanisms for that, in the language or the library. 
std::cannibalize
https://github.com/SFML/SFML/issues/190 https://github.com/SFML/SFML/issues/551 Is this you?
Overall I think they are focusing on the right things, progress is just painfully slow. Things I care about most are modules and static reflection. But by the time these are in I may be retired. I don't want to use static reflection at runtime, I just want to be able to write tests for the code that analyze the code, e.g. how many objects do I have that inherit from X and could I write memory utilities that could mark and sweep to find dangling pointers and stranded memory according to the rules of my code?
Your comment has been automatically removed because it appears to contain profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/81xssx/using_pythonrustlike_naming_convention_in_c/dv85o53/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
It's worth mentioning here that there are real reasons. I end up writing a vector (a vector!) just because the existing vector doesn't support the small buffer optimization because this would violate some invariant of the data structure (iterator invalidation I believe). Also because everything is heap allocated (why not use the stack up to some size?). I don't have any "religious" aversion to the STL. I use it literally everywhere I can get away with it, but the defeat-ist attitude that I'm just going to write it all myself anyways is one of the contributing factors to not addressing the actual issues. Also, in the linked email, there are a number of countersuggestions about what can be worked on that aren't just data structures.
Yeah, that's very true unfortunately.
&gt; the moment I UB, I am already dead Hardly! I know we all like to joke about summoning demons being legal behavior for UB, but the more likely case is that the compiler would do whatever would have made the most sense if the UB condition weren't present, as C++ is not the sort of language that wants to spend runtime checking for UB conditions. So it is not at all unusual to have UB code that runs without error. Any sufficiently large code base that isn't meticulous probably has dozens of examples. Usually things like walking off the end of the array and managing not to stomp on anything important. On the same note, it is not only possible to have null references, it is easy. Typically something like dereferencing the return value of a function that has a case, maybe an error case, in which it returns nullptr. As to the value of checking for it, I am willing to concede that it makes little sense to check for it, and if you need to (interacting with messy legacy code?), don't use a reference. 
I thought this looked familiar... :P
Wow, this looks really promising because of: * Windows support * CMake support * A really clean public interface But I agree with the other comments that the code isn't idiomatic C++ and the internal code looks sometimes C'ish. Maybe the internal platform dependent code could be modularized in order to support more use cases. In the public interface you should prefer `std::string` over `std::string const&amp;` (see Scott Meyers book). Additionally returning a temporary `char const*` could be improved as well. 
Thank you for your comments. Yes, internal code does not look too pretty, at least part of it will be rewritten. I agree with removal of `const&amp;` in std::string passing, but char const* is rather difficult to handle, I want this library to be C++11 compatible so I cannot use std::optional&lt;T&gt;, and the next best thing is std::pair&lt;std::string,bool&gt; which does not look so clean either. For now char const* will probably have to stay. Unless different interface can be proposed. -A.
Now that we have move semantics, you could have Textures as values, but avoid the copies. If done right.
Indeed, that's the convention I also follow. I've worked in and written snake_case and camelCase codebases, and don't really mind either. What I do mind is fricking upper-case function names. WTF, Google. I'll never, ever get used to that.
SFML is older than C++11, and even then I'm not sure I would want to depend on move semantics vs just being explicit that it's a handle to a gpu texture.
Um, yes? That's not the part where type erasure is essential.
How does this library compare to the soon-to-be-standardized 
https://nuwen.net/mingw.html This is maintained by Stephan T. Lavavej, last I heard he was head maintainer of the STL at micrsoft and has/had a video series called STL the STL. This is a repackaging of mingw.
You do realize whatever you think about SFML have nothing to do with whatever implementation is chosen for a graphic API, right?
&gt; In the public interface you should prefer `std::string` over `std::string const&amp;` (see Scott Meyers book). **Only** if you need a copy of the data anyway; taking objects that you only observe by value is about as wrong as it gets, and Meyers also tells you that. ;-]
I had a quick look at the docs. Here are some of my thoughts: * Run a spellchecker over the documentation, and proofread for typos (e.g. `Stringiy` instead of `Stringify` * Comparisons to existing formatting solutions would be helpful. How does this stack up to fmt, Boost.Format, iostreams, etc. * Personal opinion: I'm not a huge fan of "gratuitous" operator overloading, especially of assignment operators. I tend to prefer regular old function calls, or overloads that are already in common use (e.g. `&lt;&lt;`) * Good documentation
Ahh mingw! Thanks. While we're on STL facts, he's the only programmer I've seen who wears an eye patch! He was born to be a STL hacker haha He's also a mod of the very sub if ya didn't know! He gets around!
&gt; Because there has been zero demand for that. Oh ho ho so wrong, you've not followed the whole story. Just google the discussions about that around the creation of SG13 and SG14, in several places, you'll be surprised. Even discussions about that spawn every 2-3 years in Boost mailing lists, if not in more common places, like reddit/cpp. &gt; Standardized algebra types might be a good start, and even more useful and worthwhile, but a whole 2d graphics library? No. There is I, at least some people in the committee (who encouraged the discussed proposal instead of shutting it down) and at least educators and some people (a minority) in gamedev who do want a simple graphics API (not necessarilly the one proposed). So, "Yes". Your affirmation is incorrect. Double negation card. You don't have to decide for us what we want. ;) You also probably don't understand the contexts we want to use such API for (from what I have read so far).
There are some advantages: ​* you can extend it to write into your own output types ( like if you use some string type other than std::string) * compilation error instead of runtime errors: fmt throws an exception if there is something wrong in the format string. Since stringify use format functions, you get compilation errors instead. * In oder to customize numeric punctuation, fmt forces you to change the current locate. This means modifying a global state, which can be bad especially in multi-thread. Also, I presume that fmt delegate the job to sprintf in this case, which I suspect must reduce the performance. * In case you use some translations tool ( like gettext ), the message to be translated does not contain formatting. Hence there is less chances that the translator team ( which is usually not composed by programmers ) make some mistake. This also enables you to change the formatting without requesting the message to be updated. For example: namespace strf = boost::stringify::v0; auto str = strf::make_string [ gettext("your login is: {0}\n your access code is: {1}") ] &amp;= { strf::right(login, 40) , strf::hex(code) &gt; 40 }; 
If only they've spent this time wasted on 2d graphics on standardizing any remotely useful package manager. Really, the main problem with existing package managers is low acceptance, and with it standardized a lot of popular libraries will use it soon (even if it's not very good). That way they'll get 2d graphics, gui, and everything else for free.
There's a reason they chose the SDL after all. They keep it as simple as possible but you can still mess around with the OpenGL internals if you feel like it.
No. ;)
Sorry, I just didn't feel the context made any difference. Here's the relevant context: &gt; &gt;will be a constant thorn in the side of the standards committee, and will need to co-evolve with other existing open standards (OpenGL, Vulkan) as hardware changes are made. &gt; What is the problem here? &gt; A standard can be implementd whatever they want. They can just put a graphic engine already existing (even the OS API) behind the standard interface. &gt; It's not more maintenance than, say, filesytem. I'm not sure I believe that compiler vendors can just: "put a graphic engine already existing behind the standard interface". If it's going in the C++ standard library, it's something they'll have to support for _decades_ in the future. And it means they get bug tickets for it; they fundamentally have to SUPPORT it. So even _if_ they could just slap onto an existing library, they're really taking on that library, in the fullness of time. Regardless, the reason I said I didn't think the context mattered, was because I think it's either naïve or disingenuous to claim that something as large as this proposed graphics work is "no more maintenance" than the filesystem TS. Just in WG time/resources alone, it will be more work. Add in compilers, and it's a LOT more work. A more apt comparison for graphics, I think, would have been the **networking** TS. But at least the networking one is based on ASIO, which has been in Boost for a while, and whose API has some actual experience in use. Don't take this as being against graphics - I actually _believe_ in having a C++-accessible GUI as both a teaching tool and even for simple every-day use. But putting in the standard library isn't the right solution. The **right** solution, imo, is to spend the time instead on addressing what made a GUI proposal come up to begin with: our C++ packaging/build model sucks. I have no idea how to fix that - it's not my domain of expertise. But if we _can_ fix it, or even make the current situation better, we'll enable people to easily have **far more** than one 2d graphics library.
&gt; std::unique_ptr has two overloaded constructors There are [more than two](http://en.cppreference.com/w/cpp/memory/unique_ptr/unique_ptr). The two lines shown are not constructors. &gt; In case of array of objects, you need to provide a custom deleter. No you don't. 
Bastardizing operator overloading like that is not a very good thing.
This might be better for /r/programming or /r/codereview or something. It's not immediately obvious how much of this is specific to C++ rather than just being a general VM post. It's also super unclear from your write-up which behavior you're referencing is old code and which is new code. You at one point mention adding hash tables for variable lookup (eww) and then later say you're not doing that anymore. Which is it? &gt; TL;DR : creating a VM for a programming language is not really useful IMO nowadays Well there I disagree. A VM for a whole Turing-complete language, maybe not, but a parser/VM for a micro-DSL is still very useful. I just wrote a new one a few months ago to optimize both build and runtime on a small DSL for input/output controls specified by game designers (most common usage is expressions very similar to `movement[x] = key[right] - key[left]`. The old system using Boost.Spirit (shudder) to parse the DSL into an expression tree, and then evaluated that tree via recursive function calls whenever evaluated. Slow to compile, slow to run, and inscrutably complex to anyone without a PhD in template meta-programming. Ripped the whole thing down and rebuilt it in ~500 lines with a hand-written lexer and recursive-descent parser (directly generating bytecode, no intermediate tree) and then a very simple stack-based bytecode interpreter. The result was a massive reduction in compile times (thousands of template instantiations replaced with a few dozen simple functions), the runtime cost disappeared off our telemetry entirely, and the code is understandable by pretty much every engineer on our team (... even despite me being a lazy bum and not annotating/commenting the code particularly thoroughly). That's *exactly* the kind of stuff meant by that gameprogrammingpatterns article you mentioned: micro VMs for small game-specific DSLs. We likewise have some special VM stuff for the particle engine, in no small part because the custom IR allows us to lower the code into HLSL where applicable. Our particle system runs in mixed-mode on host CPU and the GPU, depending on the particular effect's requirements and the hardware in use, but without any need to hand write the particle effects for each run-time environment. Any node-based effect graph can be compiled down into a bytecode representation that may be (efficiently) interpreted by a CPU VM or lowered into GPU code. See also these lovely articles about a micro-VM for the (sadly now-defunct) BitSquid engine: http://bitsquid.blogspot.com/2012/10/a-data-oriented-data-driven-system-for.html It's *hard* to justify writing a whole new "programming language" per se, but these little one-off cases are good candidates. And writing a little toy programming language is a great way to learn all the concepts that will later server you well... though personally, I'd recommend writing a toy JavaScript (ES5) environment rather than inventing your own language (if for no other reason than making sure you've got a useful target with ample existing test suites!).
&gt; The proper solution would be an architecture that is free of context switching. Isn't that one of the prime motivations for Vulkan?
&gt; argue all you want that we need to stop being peasants and start writing papers. We don't want to write a paper. We are just watching a car crash in slow motion and talking about it. Or am I just allowed to ever talk about it if I become a member of the committee? I'm not saying you need to write a paper - I'm saying you should not be suprised if people tell you that an informal e-mail will not stop a proposal that has been in the making for multiple years. /u/F54280 explained this very well based on the "Direction for ISO C++" paper. Would you have preferred, if the guys on the mailing list would just have said "Yes, what you say is correct, this is going to change" knowing full well that nothing is going to change without a formal proposal? 
Yes, and so unordered_map, for example, will give a different "unorder" on different platforms, though this also happens if you use a specific hash function due to implementation differences. My reply to the parent was to point out why gamedevs might use some parts and not others, depending on their requirements.
I use C++ with AVR. I have to heavily use casting *all the time* to make sure that the compiler performs the requested operations in a minimum of byte-width, as AVR is 8-bit. I don't even bother with static_cast as in that context it becomes *far* too verbose and practically unreadable.
I think we agree on many of these things. In fact I agree with many/most of the things in the "Directions" document :-) However with respect to Cairo it's really going horribly wrong. And yea, I totally agree with your last point about C++ stuck in console world and the kids thing... But you also definitely do not want the kid to have to deal with Cairo... it will be as lost as they would be now. What you want your kid to have is something like SFML (in C++). 
This is hitting the standard? I had not read that
&gt; but I think the idea that C++ is being marketed as anything other than a low-level systems/engine/server language is misguided. I mostly agree with what you write in the linked thread and here, but when it comes to the standard library I think people loose sight of what it can and can not do and what the actual requirements of the users are. Just because I'm using c++ doesn't mean all aspects of my code have to be highly optimized and tunable. In fact most of the time I'm happy with something that just works and I can use easily. That's what the STL is for. And then there are the places, where I need the full power and performance that c++ can offer and most likely, I can come up with a much better solution for that than the STL, because I don't have to generalize as much as the STL (I can optimize for my particular use case), I can innovate much faster than the STL and I might even be more of an expert in that particular domain than the STL implementers and whoever voted the feature into the standard. A lot of arguments around a standardized GUI library are made in the context of the latter (where the GUI is the focus of the program) whereas the target of the current proposal is imho more the former (I need something easy to use, which need not be perfect).
Yea I'm sensitive to that. Which is why this proposal is all the more baffling though. Like I said in my original email, the things that are difficult that you'd like to "make work" are things like handling window creation and input. I highly doubt a person that just wants to make an app is going to bother learning about color spaces and issuing rasterizing commands. This proposal occupies a very strange uncanny valley. Personally, even as a graphics guy, if I wanted to whip up a quick GUI, I would prefer something declarative. Look at Windows, Cocoa on Mac, HTML/CSS, iOS, Android development. Everyone else gives a data-driven GUI specification, and even if this proposal was finished, I'd recommend that a newcomer look to one of those options as that's the way you'll see GUIs being developed in the wild.
Thanks for the explanation and I'll definitely watch the talk later. Meta-note, I guess this is why historically, graphics/game engines and C++ didn't get along super well... It's all a lot to take in compared to how you would do things in C-land.
&gt; if you never create nor destroy nodes If your map is always empty std::list&lt;std::pair&gt; is a fast. :) Anyway if you have links to some perf please do share. Last time I checked unordered_map is pathetic when it comes to proper hash map implementation and map is in a different league... slowdowns measured in x, not in % :) &gt;&gt; Sparse map is trivially easy to make over a vector. I know you are smart and as contractor you need to make that clear on the internets, but what is trivial for you is not trivial. Also from what I see it is not handling resize. In other words AFAIK caller needs to make sure not to insert more than .size elements. In any case you are not wrong that it can be done... but it is not what I consider trivial, so I think it is best we leave it at that, since it seems kind of useless to argue over definition of trivial. :D 
If it could be on the heap, how about std::unique_ptr&lt;std::string&gt;? Lifetime/ownership would be clear from the function prototype and much nicer to use than std::pair&lt;std::string.bool&gt;.
Great. While I reserve right ;) to maybe in the future disagree with your opinions I must say that I appreciate your contributions to C++ for one reason. I often say that C++ is language without a PM, and you seem pretty aware of usability issues with new features. In other words if we had more people like you working on C++ for the past 30 years we would have had erase remove idiom in &lt;algorithm&gt; and map.contains in C++03 :) P.S. I am 99+% sure you have this covered already but please make sure that GTest needs are met with all the reflection/meta proposals so we can stop using macros. :)
On one hand I am happy since this reduces the weight that MSFT opinion has when it comes to blocking hard to implement compiler features in the language(you NEED US for WINDOWS!!!) and has a chance to cause a bit of a panic in MSFT so they allocate more $ to VC++, on the other hand I am worried that Chrome will settle into this land where it is abusing many clang bugs so it will be hard for them to switch to other compilers in the future... I wish they maintained clang/GCC builds at least for Linux.
&gt; On one hand I am happy since this reduces the weight that MSFT opinion has when it comes to blocking hard to implement compiler features in the language This seems much worse than &gt;on the other hand I am worried that Chrome will settle into this land where it is abusing many clang bugs so it will be hard for them to switch to other compilers in the future. this Google has been the leader in creating a lot of contemporary engineering best practices, including testing and static analysis. They also have a ton of money. If this was a non-issue for any company, it would be Google.
I strongly encourage people to disagree with me, when they can explain why they do. :) Re: macros: See the last page of wg21.link/p0922 ? :)
&gt; They also have a ton of money MSFT has a ton of money.... And try compiling range v3 with MSVC. :P My point is that this is a hubris we often see from big companies, and then in 10 years it turns out that they are stuck with clang and switching to gcc is infeasible because of costs... And trust me... every company cares about costs, regardless of how many billions they have in the bank. :) 
At that point, Google is not so different from Microsoft. They don't do open source out of the goodness of their hearts, they just enjoy the positive image and getting free contributions.
libfmt has already said they have compile-time format checking working. 
But for the standard you have different companies representing different interests so it can't be one-sided. The problem when one company has 95% of the pull in an open source project is it's not really free, you need to follow what the higher ups there say and unless there is gross mismanagement like with OpenOffice, forks usually don't work out. Though to be fair, dictators over Open Source projects are common, the Linux kernel is lead by one.
Well the point is that they invested a lot of money into it, and their reputation is on the line. So yeah they can make stupid mistakes... but generally it is not a good business to piss off bunch of nerds with keyboards and internet connection. :P Obviously they will do it for $ large enough, but in general corporations do not want to piss off developers. Google hires a lot, imagine fun of being recruiter at MSFT when that errno lawsuit sh*t came out. :P 
&gt; but the committee is definitely using the term "monadic error handling." I'd aim for conditionally returned value propagation, or CRVP, because this is C++ and hot dog do we love our impenetrable acronyms. :p
&gt; I strongly encourage people to disagree with me, when they can explain why they do. :) https://www.reddit.com/r/cpp/comments/80ow2e/abseil_what_should_go_into_the_c_standard_library/dv6pa2p/ :) Note that I am much more free to say bad things about standardization since I do not know personally people involved with it. :) &gt; See the last page of wg21.link/p0922 Very nice paper. Except call for more string_view usage, I consider it a sad product of C legacy and fact that "s was 10 years too late. I would personally push for language/compilers implementing auto bla = "lol"s; as efficiently as when there is no s after ". Meaning that compiler can preconstruct that string at compile time, know it's size... I imagine now that being super hard since string ctor allocates in general case, but with language changes it may become possible. Note that I know that in some cases due to perf reasons string_view is the only option beside char*, I am talking about usage where perf is not critical but it is used as catch all parameter. Another example I can think for MACROs is abusing magic statics to implement lazy run once function call. Not sure how often used this is but macro expands to something like this. void func(){ static const char dummy = function_to_be_called_once_lazily(), '?';
Not cool to hijack unrelated threads to promote your project 
It's the only build system I'm aware of that acknowledges that Clang on Windows is even a thing. I find it highly relevant, personally.
Nice to see movement towards open-source projects.
Doesn’t Clang support G++ flags? I thought you could just replace \$CC or whatever your build system’s equivalent is and it would work fine. Or am I missing something? 
Christ. This kind of crap is why Rust seems attractive to people...Cargo is just dead simple. I think C++ will simplify its build process before Rust takes over though. 
I was sure the latest CMake was supporting Clang on windows using MSVC style arguments, I made an experiment and I successfully made my projects working by selecting the llvm toolset. In visual studio.
A) Doesn't work with VS2017. B) The clang-cl driver sucks if you're pedantic about codegen (like I am).
To be fair, Clang is probably the most standard compliant compiler out of the popular ones (GCC, Visual C++). It intentionally doesn't compile certain commonly abused but non-standard features and try to avoid doing anything custom. Obviously it still has bugs, but it's a better starting point than the other options IMO.
&gt; My point is that this is a hubris we often see from big companies, and then in 10 years it turns out that they are stuck with clang and switching to gcc is infeasible because of costs... Except when you have people who care about cross-platform compatibility. I've worked on multiple teams who care about this, and I've never worked for a company as prestigious as Google. If your point is that Google will find itself stuck in a corner because of compiler-specific behavior... well... a lot of other companies with **worse** testing and **worse** engineering practices have found their way out. I'm sure Google will figure something out. This seems like a massive non-issue to me, considering Google's collective experience. 
To add to /u/dodheim's explanation, you essentially need to use a compiler with GCC-like command line interface but then continue using VC's toolchain (`link.exe`, `lib.exe`, etc.) and runtime. Also the header dependency extraction interface if quite different (`-M*` vs `/showIncludes`). While it wasn't particularly difficult to support in `build2`, it was designed to handle such things so this may not translate to other build systems.
&gt; There is no way to do this with gcc. I build with all possible warnings enabled for both clang and gcc. I do the same thing as you on clang, and then I manually list all of the warning options for gcc. In the past I've had to grep the gcc man page for new warnings every time I upgrade my compiler, but after reading your comment I just discovered that `g++ --help=warnings` prints out all possible warnings for that version of the compiler! Does anyone know how long has that feature been there? 
Maybe in the next revision of the paper =). I made the error handling configurable in the implementation so that errors could be either reported at compile time or via exceptions, but haven't described the error handling API in the paper. Regarding allocators, with the iterator-based API (`format_to`) you can write anywhere you want and use an appropriate allocator.
Not yet, I plan to add this info to changelog later. The main changes were a switch from Google Style to the naming conventions used in the standard and the new extension API to accommodate constexpr format string processing.
No problem, I'm all for breaking stuff to make the overall thing better !
Don't 32bit versions of windows *still* support 16bit applications?
&lt;https://upload.wikimedia.org/wikipedia/commons/e/ef/CamelCase.svg&gt;
Mh ? I had no problems building my software with clang-cl using CMake
 .. No OS and heap allocator but a keyboard and a screen ? That's fairly weird. 
Does gcc support cl command line options? Does it follow the msvc abi? Is there a toolset file for visual studio? Does it define _MSC_VER and other macros? If it answers yes to all of these then yeah, sure.
I'm always hoping these events would cause MSVC to be developed in the open too.
It's not. A proposal has been submitted which is a good start, we're still far away from standardising it
Not at all. You might be thinking from an opposite perspective. It has a serial port...
What is RIAA?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/82d4ja/why_this_function_printing_abnormal/dv992n8/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Yeah I don't know what my reasoning was. A straight line from the top of the letter there's only a bump with lowercase.
Not sure if anyone would want to work on that codebase for free (I'm trolling of course, I have no Idea what it looks like)
I wish -Wshadow was part of -Wextra
To what compiler features are you b referring?
When following the discussions around modules, I have to say I'm very happy that Google/clang hasn't yet taken over the (c++) world.
&gt; Why would they want to change compilers? They pretty much own clang these days. GCC implements something fancy in optimizer and now Chrome is 5% faster compiled with GCC... :P And it will take Clang 9 months to implement something similar...
Nothing in particular. It is just that every compiler has bugs/interpretations of Holy Standard. And if you compile huge codebase on just 1 compiler for 5 years it will not be easy to switch to some other compiler. 
Fair enough
&gt; SFML (and many others) is based on SDL. I'm pretty sure you're confusing SDL with OpenGL here?
Yes, I'm a week late, sorry. Of course incremental builds still exist when you use unity builds. It's a very common misconception that unity builds mean compiling a single file per application, while everyone that uses unity builds in larger projects is building one cpp per module/project/package (however you name them). Also, the fear of slow incremental builds in a single project is quite overrated. Especially because many people expect the compiler to take 5x the time compiling 5 equally sized of your files together, which is also not true. Most time is wasted in parsing includes anyway, especially when not using PCH, or when huge headers like STL or Windows headers are not included there (sometimes for good reasons). Additional time is spent in compiler ramp-up and down. I'd suggest this: Try unity builds. They're easy to implement, and you can measure the savings yourself. You'll also see the problems that come with the approach. But do you really want to wait at least another 2 years (or more) and potentially waste tons of time waiting for the build? Another thing: If you're using C++ and turn an idea down out of the fear that it might be abused, then I fear you probably cannot use much of the language at all ;-) Plus, unity builds as an idea have been around for many years now, the idea isn't exactly new. Unity builds aren't a silver bullet, but try them before turning them down. Of course if you want to try PCH first, by all means do that, PCH have been around way longer than unity builds. That said, nobody's stopping you if you just use both ;-)
Ah I see your point, let me clarify a few things. First, when writing this I was thinking about, starting with an already ready Impl, but changing or rewriting the code for long term purpose. I do believe slapping something already existing would be a short term solution in the same way some standard library Impl started (say filesystem in VS for example). Second, filesystem, thread, networking/asio, and some other libraries are actually thin (in call layers at least) layers over OS APIs (except maybe on some Unix variants). The hard part seems to be giving the standard interface guarantees while relying on the probably legacy OS scaffoldings. I'm not saying this have no cost. I'm saying graphics doesn't seem to have more cost than that. It appear like a fixed additional cost, not a multiplicative of cost. Microsoft for example implemented chrono first in poor performance but still as confirming as possible. It took them several versions, if my memory is correct, to fix the performance cost and the precision. I imagine a quick Impl of the current graphics proposal (from having read the actual proposed interface, not assuming that "it's just Cairo"...) to just be usage basic windows surface drawing or even just another thing library over that (because on windows the API might be hairy). You don't even need DX or GL or Vulkan. I do not believe that it is a good Impl for long term or for performance. But that would work for its purpose (aka not high perf graphics). But I'm not a standard library implementor so even if I watch in details what is happening there, there might be something I don't get yet. On the dependency management issue, I believe it helps adding or removing dependencies, it does not provide a default cross platform always available API for drawing.
First, that's doubtful. Second, it's probably not worth the effort even if it did happen. And really, they could just optimize the code path by hand if they absolutely had to.
Actually it's not healthy if you rely on the researches about that. But more than that, a clear discussion started with clear points would have had more sense, more positive output (like maybe having actual good reasons to turn the proposal down) and clearly it would have been useful to somebody.
Not really. Afaik msvc is still supported - although their long-term goal might be to switch to clang exclusively.
!remove
OP, A human moderator (u/blelbach) has marked your post for deletion because it is not appropriate for r/cpp. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/826ln9/feedback_on_creating_a_vm_for_a_programming/dv9c9nk/,%20was%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
That's a fair point, but Chrome still has a good amount of code to circumvent MSVC's behaviour, and it used to be way worse. You still can see these hacks on Absail.
It's worth noting that this is a proposed document, not something the committee has a whole has seen and committed to.
For the love of god, can you guys be more boring...
I really want to use clang on Windows, but every time I look into it, you still have to use VS for linking and it doesn't work with MinGW and there's no pre-built binaries. Did this change by now?
No. SFML uses OpenGL for rendering, but it has SDL for input devices.
&gt; Second, it's probably not worth the effort even if it did happen. Seriously ? If a compiler optimization that would give 5% improvement on Chrome would be not worth the effort ? Do you have any idea how much C++ code google run in production, and how much value they get out of any compiler optimisation ?
LLD works fine now, and allows you to use LTO with Clang; it even emits mostly-useful `.pdb`s. Prebuilt binaries have always been available; relevant links: [5.0.1](http://releases.llvm.org/5.0.1/LLVM-5.0.1-win64.exe), [7.0 trunk snapshot](http://prereleases.llvm.org/win-snapshots/LLVM-7.0.0-r325576-win64.exe). MinGW compat is still nonexistent.
That's simply not true. You're certainly confusing something.
I have previously used mingw (gcc built for windows, as opposed to cygwin) via Visual Studio. If you must have GCC for some reason, it's worth looking in to.
Nothing you say contradicts my point. Obviously they are working towards standard compliance. My point was that just because they are big corporation does not mean that every project will get 100 developers working on it. And AFAIK they are still not C++11 compliant, and that is kind of amazing considering 11 comes from 2011 and we are in 2018. Also their range fork is not really that great. https://youtu.be/LNXkPh3Z418?t=7m9s
&gt; Anyway if you have links to some perf please do share. Last time I checked unordered_map is pathetic when it comes to proper hash map implementation and map is in a different league... slowdowns measured in x, not in % :) For maps with a lot of inserts, yes you are right, they're slow. For maps mostly doing lookups, unordered_map and map are fairly competitive. Typically within half the performance of alternatives. &gt; I know you are smart and as contractor you need to make that clear on the internets, but what is trivial for you is not trivial. I hear that a lot from Reddit in particular :) But some stuff really is hard. As in, hard hard, so hard that nobody is sure of a good answer. Whereas other stuff is just a matter of learning it, then it becomes trivially easy. Sparse maps over any ContiguousContainer are trivially easy. Honestly. &gt; Also from what I see it is not handling resize. In other words AFAIK caller needs to make sure not to insert more than .size elements. Correct. My great hope for the STL2 containers is that we finally eliminate implicit expansion as the design mistake that it is. Removing implicit expansion means the containers no longer throw exceptions, and thus nobody needs write exception safe code around the STL any more. One can also purge allocators from the container's definition, and hugely simplify implementation which then turns into much better codegen. The gains are enormous. Explicit expansion need not be tedious however. For example, in sparse maps there is no reason why an item can't exist concurrently in more than one map. So one can do a live expansion of a map whilst it is in use, even under multiple threads. You even get two choices of tradeoff, either one employs atomic versioning where all reads use the existing map until the new map is atomically swapped in place and thus all writes block until the new map is ready. Or if that is unacceptable, for a short period of time some lookups may take twice as long whilst the new expanded map is built from the old. What I'd love to see in STL2 algorithms is a suite of explicit expansion only containers with a choice of explicit expansion implementation algorithms. STL1 containers would of course remain for those wanting implicit expanding containers. But that's just my personal vision for the future of the C++ standard library, one opinion amongst many others, most of whom disagree with me profoundly :)
It's not going to happen so it's really not worth the thought. The fact that I didn't put as much thought as you into your improbably hypothetical really isn't that interesting to me.
Yeah, it's a touch old. They are preferring to implement new C++ language/library features with the aim of being compatible with the master range-v3 rather than putting a lot of effort into re-porting it.
It still needs a standard library and CRT. I haven't tried building libc++ on Windows, so I don't know if doing so would obviate the need for MSVC, but the usual approach definitely relies on having MSVC installed.
Thanks for clarifying. As somewhat expected it's still not fully independent and MSVC build tools are still required.
mingw has a different ABI than MSVC, which means that I can't use it with other existing Python things. So all those Windows Python wheels on PyPI are worthless to me :( I've used mingw before, and I know its an option. But I want to compile Windows native Python with clang. Compatibility is key.
When you say `clang-cl` I think you mean `Clang/C2`, which is the Microsoft experiment.
Both Foreign.Storable and Data.Storable I/O operations are in the I/O monad, right? at least that's according to the official documentation. Therefore they are not part of safe Haskell.
No, he doesn't. `clang-cl` is a compiler driver that comes with Clang for Windows that attempts to mimic MSVC's commandline args, as opposed to the clang++ driver which mimics g++.
Hey, I did write a HTTP client based on boost::asio and curl multi. You can find the code here: * https://github.com/daedric/httpp/blob/master/include/httpp/HttpClient.hpp * https://github.com/daedric/httpp/blob/master/src/httpp/HttpClient.cpp * https://github.com/daedric/httpp/tree/master/src/httpp/http/client It does not have many embedded feature, only the minimal. Integrating Curl has not been without problems. &gt; (it enable event-based handling and scaling transfers up to and beyond thousands of parallel connections) Not in my experience, but Curl might probably be tunable to get some more qps then what I saw (don't remember the numbers). However, it was not derterministic nor tracable enough for my use-cases at the time. If you want to design RESTinio for speed, then I would not use Curl, however if you want something full featured HTTP-wide then it is a good solution. To answer the questions: * I like a simple base, and then optional features (do not, by default, handle cookie for instance); * No idea, not a user of RESTinio for obvious reasons :) * If there are high level features I need why not depending on my use-case. If we talk about the client, if based on curl I would probably use mine even if less featured as I spent enough time to know what I can get from it and I don't want to go through this pain again :) Good luck ! Cheers, 
Thanks for your feedback, &gt; it enable event-based handling and scaling transfers up to and beyond thousands of parallel connections This is stated by curl docs ;) Curl was taken for a sample application as it appears to be very popular for doing client request. We have no plans to build client-side restinio upon it.
Well, logic and purely functional are subsets of declarative - they are equivalent (as are all TC languages), and maybe even isomorphic, but I would have an issue calling language *functional*, where the language itself does not define a concept of function - at best, one can use predicate and relationship to emulate a very finite function, but if we include emulation, we might as well include C++. After all Prolog in not free of side-effects. Yet, no one would call Prolog an imperative language.
Got it, indeed reading again your post that is stated. However that would be a nice addition, it is common that one wants to query and serve HTTP request/response at the same same. 
If you mean CMake supports it by way of the llvm-vs2014 MSBuild toolset, see [here](https://www.reddit.com/r/cpp/comments/82a0yo/clang_is_now_used_to_build_chrome_for_windows/dv91989/) – clang++ is the only driver I consider using.
The signal solution only seems more complicated and very much prone to mistakes. I can't imagine managing all those connections in a larger project. If you really want to decouple those classes, have logger/debugger/profiler interfaces and pass those around. It has the same benefits in terms of "code readability, compilation time, writing tests" as described by the article, without having to resort to template fuckery. It probably performs better as well. TL;DR: KISS and avoid Golden Hammers.
{fmt} has first three features too. Here's an example of compile-time format string checks: https://godbolt.org/g/8hPJ5o
 Perhaps a good solution is the library to provide more than one syntax: The "long syntax" based in a chain of function calls, and the "abreviated syntax" - a syntatic sugar basically - which would be less capable, but would be fine for most uses. &gt; As for joins making it impossible to use variadic templates, can't you make it `strf::join_right(15)("abc", "def", 123)`, which would return some `strf::JoinRight` struct that the formatting function knows how to handle? Maybe. The complication is that such struct would need to contain the arguments and their types ( like std::tuple ), some of them possibly also being a "special" input type. But I will think about that. Btw, It seems that "Fixed sized parameter packs" ( [n4072](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4072.html) ) would solve the problem easily and nicely. We can see here how it can achieve things impossible to variadic templates. It's unfortunate that it's (apparently) discontinued. &gt; (...); you have a lot of competition. If your library is hard to learn, you really have to sell the benefits to me. I see. My hope is that people will get interest because it can do things that others can't. However this strategy may turn it overelaborated. Another appeal is that, as far as can see yet, it has no pitfall, while all the others seem to have one or other. Though this is not something that can be easily asserted. 
sorry, RAII, I went back and edited the post.
Yes, but most machines come with preinstalled 64-bit Windows.
I'm curious: is there any language which makes it easy to convert between SoA and AoS? Has anyone checked if the reflection/metaclass proposals will make a library solution viable?
You should take a look at Gamma(https://mygamma.io/) then. It is quite new, but has a reputation of working with bigger companies and they have just received a funding round as well. The difference between other tools and Gamma is, the analysis and results that Gamma provides are faster and clearer to see, than with other tools. The method behind it is quite simple: it analyses, diagnoses and verifies raw metrics and data, to then be displayed on your dashboard. This way you see clearly an analysis of your design, metrics, duplications and code issues. The results are thorough, they are displayed in a simple, easy to understand manner. For developers, this means clearly seeing where the issues in the code are, so that fixing becomes easier. For managers and other decision-makers, the visual results allow them to make informed and time-saving decisions without having to be of a technical background! It’s a win-win for everyone really because Gamma makes your development time-efficient and reduces further maintenance costs by helping you clean your code from the root.
IMHO, this is a pretty problematic blog post. A lot of important distinctions are glossed over, and it doesn't make a strong technical case for any of the conclusions. &gt; But in my experience you never have just one system as a singleton. You have multiple occurrences of them and at some point they will depend on each other. So you will have no way of controlling the initialization order unless you do some obscure compiler tricks. And of course you will have no way of controlling the destruction order either. You obviously need to think about these issues carefully, but when you have an explicit dependency between two globals, it's very easy to control their initialization order. // Global.h #include "OtherGlobal.h" // Looks like Global.h auto&amp; makeGlobal() { static MyGlobal g; return g; } static auto&amp; global = makeGlobal(); If `OtherGlobal.h` looks like `Global.h`, this guarantees that `other_global` is initialized first. This isn't obscure compiler tricks either. And the standard guarantees that destruction order is reverse of construction order. In C++17 this becomes even less obscure: you simply define a global in the header file using keyword `inline`. You can still get complex issues if you use interdependent globals excessively, but if you restrict yourself to a handful of globals and minimize dependencies, you can easily get more benefit than harm out of it. &gt; Or even worse… singleton classes are impossible to unit test since they should be available for the duration of the application. At this point, the article should make a distinction between *globals* and *singletons*. Singletons are almost never correct; there's no fundamental reason why you can't have two Loggers in one application, logging to different files, and there are even situations where this is helpful. However, you can just have Logger be a normal class, and have a global instance of Logger for convenience. This is fully compatible with unit testing, both of Logger and classes that use it. &gt; Now you can rewrite that so you no longer have singletons but member variables, so you control the lifetime, the order of creation and destruction and reason easier about what objects might be affected by a method call. Again, it's easy to control lifetimes even if you are using globals properly. Having member references is: a) a member of a class that isn't part of its invariants, which is bad, and b) the class doesn't control the lifetime of this object anyway. Member references may seem nicer, but they don't really offer any advantages except for the fact that they can all be different. But if in your actual use case, 99.9% of classes are just going to be logging to the same logger, all that member references do is add lots of cruft with no benefit. This also doesn't address free functions at all. With classes, passing in a logger seems less painful because you typically construct once and then call member functions many times. What about functions? Are you going to take a logger parameter to every free function in advance, just in case it needs to log? Sounds horrible. Or you try to only take loggers when you need them, in which case when the function grows bigger and needs logging one day, you'll need to add this parameter to every single call of the function. This is just a very significant chunk of work for very little benefit, especially since loggers *should not affect the behavior of the system*. &gt; What this will do is make the systems decoupled. Decoupling is great, if you actually need it. Otherwise, you're adding complexity and reducing performance to no benefit. Personally in my domain, I cannot imagine any purpose for this generic signal-slot mechanism, i.e. I can't imagine registering anything else for emit other than the logger. Sometimes a message might go to more than one place, but not always, so in any case I still need to code out specifically whether I want a message to go just to the logger, or also somewhere (like an alerting system). A logger might record a message more than one way (e.g. to a file and stdout), but generally the logger itself will allow registration of multiple handlers so signal/slots isn't necessary for this. I honestly wonder how many people would really benefit from this signal/slot approach. Doing more sophisticated logging well in a language like C++ well is not easy, but I highly recommend checking out a hierarchical logging implementation like Python's (which, IIRC, is mostly copied from Java). I'm not exaggerating when I say that it gives all the convenience benefits of globals, and perhaps 95% (in practical terms) of the potential flexibility of using member references per class. Maybe when C++ has modules we'll have a really nice hierarchical logging implementation. That said, in C++, with a little knowledge about globals, you can get by with a relatively simple logger that uses a global (but not a singleton!) and IMHO it will work much better than the approach suggested here. This also applies to things like intrusive performance profiling. To anyone interested in trying to gain a better understanding of some of the issues with globals, I'd suggest my cppcon talk (sorry for the self plug, but resources on this topic aren't too common, which is why I gave it in the first place): https://www.youtube.com/watch?v=xVT1y0xWgww&amp;t=1469s.
The fact you didn't even noticed I wasn't the original poster shows everyone how little thoughts you put into your posts.
I used the ninja generator, with the clang-cl driver.
So, no LTO then. Meh. ;-]
I think this topic is especially hard to discuss because people involved with package management have their own niches and it's hard to see past that. &gt; We already have pkg-config Yes, and when it works it's great, but when you have to troubleshoot it it's terrible. It does not really work on windows (anyone who claims otherwise didn't have to use it non-trivial cases). &gt; portage Just because portage was designed to be platform-independent it doesn't mean it instantly works everywhere. portage is very dependent on unix tooling. Yes, there is cygwin and WSL, but they are pretty bad to work with. Anyone who claims otherwise didn't have to use them in non-trivial cases. For context, my experience is building close to 80 libraries for 4 platforms (Windows, Linux, macOS, FreeBSD) with 16 different toolchains. We use conan to do all this and it handles everything we throw at it like a champ. I don't see any other old or new package manager currently that even comes close to doing the same. Yes, all of them work in the constrained niches with very strong assumptions.
Yes I know what `clang-cl` is, but unless I am very mistaken, `clang-cl` is not deprecated, while `Clang/C2` is.
Thanks for that laugh.
Just came here to say that this project is lovely. I have been looking for a nice REST framework in C++ for quite some time with the following characteristics: use the standard code-style, based on asio/boost asio/networking TS, doesn't reinvent the wheel where not necessary. By quickly looking at your code, this looks promising! I tried few others. crow was easy to use but the quality wasn't as good as expected, especially the choice of creating a http request and json parsers from scratch. Cpprestsdk looks good but kinda dead. Pistache has weird code style... 
I didn't know that the user can add new output types in {fmt}, nor that he/she can use numeric punctuation without modifying the global locale. Can you provide some references ? I just saw the [compile-time format checking](http://zverovich.net/2017/11/05/compile-time-format-strings.html) that's under development in {fmt} right now. I must say it's an admirable work, and I praise their progress. Still, the format string can't be checked at compilation time if it is obtained at run time, like when it is returned from gettext. 
I'm glad I could give some things to think about. Good luck! I'd love for this library to become one of the top contenders for string formatting someday.
Oh, I should have read more thoroughly; you're quite correct!
A) I made it work with visual studio 2017. I'm thinking about making a tutorial for it. B) I'm sure clang-cl is generating good code, unless I'm mistaken. Were you referring to clang/C2? Clang-cl is just the driver that mimic MSVC style arguments AFAIK. 
A) I know it can be made to, but it doesn't OOTB and it still uses clang-cl, which is a problem in general because: B) clang-cl is indeed what I mean, and it offers very little control over codegen options, doesn't support LLD (and thus doesn't support LTO), and hardcodes some options that are undesireable. IMO clang-cl is a hack and I prefer the control that clang++ offers.
If you need the false branch to be discarded, the alternatives to `if constexpr` are ugly.
&gt; Not sure if anyone would want to work on that codebase for free. You would be surprised. Some people would submit a PR just to scratch a particular itch... And then, perhaps, Microsoft would hire the active committers?...
So, what about Microsoft's Clang/C2 effort? @AndrewPardoe, could you shed some light on that please?
[It's dead](https://twitter.com/stephantlavavej/status/871861920315211776?lang=en). Also, use `/u/` rather than `@` to address a user on Reddit.
&gt; But I think the level of vitriol in this thread towards the people working on it is entirely unfair and undeserved The only thing said slightly inappropriate was the expression "basement dwelling". Get off your high horse.
Can it use re2 instead of boost regex?
Stupid question: Pythons API is C only isn't it? mingw and MSVC should be compatible when it comes to C ABI
Right now RESTinio supports std::regex, pcre, pcre2 and Boost.Regex as [regex engines](https://stiffstream.com/en/docs/restinio/0.4/expressrouter.html#regex-engines). But you can add an issue ([here](https://bitbucket.org/sobjectizerteam/restinio-0.4/issues) or [here](https://github.com/Stiffstream/restinio/issues0)) and if there will be votes for your issue we will try to add a support for RE2 engine.
Not as far as I know. The prime motivation for Vulkan was really that OpenGL has become too byzantine for anyone who is not a total expert to understand. For each task OpenGL has numerous ways to achieve it, with good performance only on some of the paths. There are also significant differences between various OpenGL implementations, both in core functionality and in supported extensions. Vulkan vastly cuts down on the number of paths, adds conformance testing for drivers, and also makes for a better match with modern hardware. If C++ implementability was also a concern, I haven't heard about it. 
[Jai](https://github.com/BSVino/JaiPrimer/blob/master/JaiPrimer.md)
I only use specifically-sized types, so `[u]int8/16/24/32/64_t`. Generally `unsigned` as it gives me more control on AVR. When performing operations, I tend to use a heavy combination of casting to make sure the two operands are the *exact* type I want them to be so it doesn't implicitly promote to `int` (especially when 99.9% of the time I would rather be operating on `uint16_t` anyways). I've run into issues, especially when using `auto`, where implicit promotion has bit me hard and I've ended up with `int`s and the resulting slowdowns where I did not expect them - mainly due to getting bit by something like `uint8_t + 'integer literal without type suffix'`, which got promoted to `int`. I also heavily use macros like `__assume` (`#define __assume(c) { if ((c)) __builtin_unreachable(); }`) in order to help guide the compiler to know that the values of a variable are constrained so it can emit less code - say, I can explicitly tell it that a uint64 will only ever have the lower 40 bits be relevant, so I can tell it `__assume((var_64 &amp; FFFFFF0000000000_u64) == 0)` (I really should make a macro like `__assume_size` that automatically generates those masks) and the compiler generally will not emit code to maintain the upper 24 bits, as that's another 3 bytes. I often do this because while g++ for AVR defines `uint24_t`, it does not define a 40-bit, 48-bit, or 56-bit type. I plan on writing thin wrapper classes for those that automatically emit the proper `__assume`'s and are the proper size. There *is* a compiler flag to specify that you want `int` to be 8-bit instead of 16-bit. It causes g++ to generate *awful* code, as the g++ optimizer is designer around the premise that a pointer and a word are at least the same size, and AVR has 16-bit pointers (technically 24-bit for universal pointers, but g++ doesn't support program-memory or universal pointers, unlike gcc).
You also have the problem that they use different C runtimes, which makes all sorts of things break if you aren't very careful.
A nightmarish code base makes it hard to build major new features, but for drive-by PRs it's relatively unimportant compared to how hard it is to build the thing.
Awesome, thanks for the suggestion.
I'm pretty sure I have seen your pretty much exact comment on some previous thread. You know, just because you took issue with a library many years ago and your voice wasn't immediately heard and bowed to, doesn't mean you need to constantly defame for all eternity. If I spent the time, I'm sure I'll find a discussion somewhere that was more emotional driven than rational and more likely without will to actually step up and propose a change in form of actual code. SFML isn't driven by people that take issue about something, complain loudly and then leave while talking badly about the library. We're not saints, we're not always right, but the same applies to random people telling everyone how their library should be written. Make a rational case, provide use-cases, provide examples, keep it a discussion without involving emotion and make a proposal to change something. Texture copying is now performed on the GPU. The white square issue is more often because people let the texture get out of scope and then wonder why the sprite has no reference anymore. Most people that run into this issue, have a very basic knowledge of C++, yet we try to help them as best as we can. Now please stop defaming something you have not followed in years and have very little knowledge about it, just because you had a bad experience with it that one time.
It's abandoned. Most likely because new clang works perfectly fine with VS. Very easy to setup if you already using a cmake.
&gt; segmented_vector Doesn't `deque` do that in most implementations? It's mostly implemented as a sequence of flat buffers chained together. But then again, this kind of implementation is not guarantueed, so its kinda useless in that regard
[Similar topic](https://www.reddit.com/r/cpp/comments/7y0o6r/is_it_a_good_practice_to_use_unsigned_values) from a few weeks ago.
SFML dev here, uhh no. :D
&gt; In the category of design smells, I find it easier to justify a goto or a global variable than a singleton. ... but global variables literally are singletons ? 
Should be already in [trunk](https://reviews.llvm.org/D30240).
&gt; But in my experience you never have just one system as a singleton. well, no. I never had the case where I would have had two IOC containers or two root windows for instance 
A) ? I encountered 0 problems. Built LLVM that way. Just used `cmake -G"Visual Studio 15 2017 Win64" -T"LLVM-vs2014"`
What about the situation where `LLVM/clang implements something fancy in optimizer and now Chrome is 5% faster compiled with LLVM/clang`? Why don't they use ICC then? Surely, it'd be able to squeeze a few extra %. Also, now they have a compiler that works for 95% of ALL platforms (including mobile). GCC folk doesn't seem to care much about being crossplatform as long as it compiles the kernel.
You should post this to [r/cpp_questions](https://www.reddit.com/r/cpp_questions/). Please read the rules before posting ore carefully.
The templated compare solution is quite nice - I had to do a similar solution myself not too long ago (though practically I just asserted on the 'goofy' signed &lt; unsigned case).
Small mistake in the article: &gt;When applying this generic rule to comparisons, it means that if we’re comparing a negative signed integer x with an unsigned one y, then, first of all, the signed integer will be converted into unsigned one. At this point, as our signed integer x is negative, and assuming universal-in-practice “two’s complement” representation, it will become a very-large unsigned value (to be exact – 2^N+x, where N is number-of-bits-in-our-int-type). Actually that resulting value (with N being the number of value bits in the unsigned type) is guaranteed even if the negative number didn't use 2's complement representation. On non-2's complement systems the bits of the value are changed by this conversion. 
I haven't run the code, but it appears that it will crash when entering values &gt; 110. For the rest it will increment the input/10 th element.
I encountered this issue yesterday actually . Compiling the function [checkUpperLimit - line 411](https://github.com/pocoproject/poco/blob/poco-1.8.1/Foundation/include/Poco/Dynamic/VarHolder.h) , g++ complained that `from &gt; static_cast&lt;F&gt;(std::numeric_limits&lt;T&gt;::max())` was a signed-unsigned comparison. The authors of the code only use MSVC so far as I know, which presumably doesn't warn otherwise they would have noticed and fixed the code already. It turns out that the function is only called from other functions in which prechecks have been made on the types and values involved, so that the comparison is always correct. But the compiler doesn't realize this. I have my doubts about that entire section of the code TBH, but I don't use that library component in my code so I just used `#pragma` to disable the warning for the function and made a note to consider raising a ticket about it later.
 class S { public: static S&amp; GetInstance() { static S instance; return instance; } private: S() {} }; &gt; So one approach you can try to use is to create the singletons “on demand”. Wtf, that is precisely what the state of the art GetInstance code is doing.
No. A singleton is a *class* of which you can have at most one instance. A global is a *variable* accessible at global scope. Most globals are not singletons; there are tons of globals of integer or const char* etc type and these have absolutely nothing to do with singletons. Almost all singletons offer some form of global access but it's not technically required; you could have a class that has a private, static bool that's set to true in constructor and false in destructor; if it's already true when constructor enters it throws.
&gt; Texture copying is now performed on the GPU. It shouldn't be copying textures in the GPU because of C++ language semantics. **That's the point**. That design is horrible. And you didn't even put an explicit identifier on the copy constructor because you have to support pre-C++11, right? Which means that the compiler can be emitting code to copy textures in the GPU without it being obvious in the code, causing hidden performance problems. All you've done is made it not quite as bad, but you haven't fixed the design flaws, even after all this time. &gt; The white square issue is more often because people let the texture get out of scope and then wonder why the sprite has no reference anymore. Because you chose to give textures value semantics instead of reference semantics. In other words, my criticisms are still relevant, and you guys are still defending indefensible design decisions. And you do so by coming in here and claiming I'm being overly emotional, as if that somehow makes your terrible decision decisions acceptable. And the worst part about it is that you've essentially admitted that even after all these years you've been too stubborn to try and fix the issue. By copying in the GPU instead of going through main memory in the copy constructor what you've done is **continued doing the wrong thing, but faster**. As if it was the roundtrip through main memory that was the core of the issue. Why didn't you just give the texture objects reference semantics? Wait, let me guess... RAII? &gt; Most people that run into this issue, have a very basic knowledge of C++, yet we try to help them as best as we can. Most of the people who run into this issue have a very basic knowledge of **SFML** and are surprised by the design decision. I discovered it very early in SFML 2.0's lifetime and at that point I had been using C++ for a good 15 years. Not only that, I took the time to download the sources to see if I could understand the technical reason for it. What I discovered was that SFML already had a system for tracking and sharing texture handles, but that the overlaying texture object was explicitly given value semantics. I then asked for an explanation and was told the reason for it was because RAII was proper C++. And when I disagreed with that I got treated to the alphanerd bullshit that you see so often, most especially by one of the maintainers specifically. At which point I moved on. And I would recommend pretty much anything over SFML. Not because you made a design mistake (and I don't think you'll find very many on this subreddit that would disagree that it was a mistake), but because you then tried to argue that it wasn't a design mistake by citing RAII. I would recommend various C libraries/frameworks over SFML **for no other reason than the mindset problem* No design is perfect and no API is without it's flaws, but your defense of the decision was outlandish, and yes, it did affect your other API's as well. IIRC you clock api's were awkward as shit to use, and some of the transformation API's were kind of ass backwards. There is only 1 valid reason why you haven't fix that yet, and that's because once you officially released that API you couldn't break it. Which is fine, but that doesn't stop you from creating a "TextureHandle" class that does the right thing.
I just said I didn't put much effort into addressing this unlikely hypothetical.. so calling me out on it doesn't really do much.
Yes, it's dead. The MSVC compiler can compile most code--we're very near to conforming now. In cases where you need Clang specifically, use LLVM-Windows.
It reads line representing scores and counts them in "buckets." The vector counts the number of scores below 10 in index 0, between 10 and 20 in 1, etc. It seems index 10 is reserved for scores of exactly 100.
&gt; The ISO organization requires that the final standard not be freely available What, what. Is there some good reason for this?
Which build system do you recommend instead?
Teaching someone means, apart from pure acceptance of the taught/teacher, to put him in consciousness, to be able to explicate in detail what is known, ideally down to the smallest detail. From my perspective, it doesn't matter at all what degree of abstraction you base your work on. Asm, C, C++, C#, Java, Python.... In the end, everything leads to the goal, because you have to deal with it in one way or another, how components of computers tick and what it is all about. In today's teaching, the top-down approach makes sense in that at a high level of abstraction (C#, Java, Python) it is possible to aggregate quite a bit of cognitive comprehension. And if necessary you climb down the abstraction ladder (C++, C, Asm) and have a look at what it looks like. Then people learn what they want/should/have to learn. In any case, I would start at the highest possible level of abstraction and then climb down a few steps as needed. The concrete language isn't the matter.
I honestly don't know. Funding perhaps?
Actually, msvc is usually much more aggressive about those kinds of warnings. What respective warning levels did you use.
I haven't used connections or signals before, but if all input/output to/from systems is managed by these signals, it would make unit testing a bit easier. Instead of having to mock the sources and sinks each time, you just create a single test signal for inputs and another for outputs and use that for all your testing.
in g++ I used `-Wall -std=c++14`. 
Somehow this feels really over engineered, but I don't know a more elegant solution.
? 0u could just as well be converted to a normal int. One direction isn't really more logical than the other. In both cases you get bogus results for some value combinations. If you want to about compilation, you can just test warnings as errors, but that doesn't solve the fundamental problem.
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/82i4v2/deferencing_and_incrementing_iterators/dvafiiv/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
The only possible thing? I beg to differ: the standard could just as easily have specified that such conversions must be performed mathematically correctly, which (in this case) means that negative numbers always compare smaller, and non-negative numbers can be treated as if they were unsigned to begin with. None of that requires extension to a greater type, but of course it wouldn't compile to a single assembly instruction anymore... 
It created a histogram. Next time you post your homework, please do so in r/cpp_questions, properly format the code and remove unnecessary parts.
Yeah, exactly that. How often do you construct a would-be singleton multiple times by accident? How often do you get the number of any object in your application wrong, for that matter? If I need exactly two of something, I'm not going to implement some kind of weirdo "gemini pattern", I just construct two and never worry that I might carelessly construct a third one somewhere. I can't help but feel that while the singleton _pattern_ has its place (of some things one is enough, and you need it for pretty much the entire time your program runs, so yeah, that's a singleton), actually translating that design into code is a highly overrated activity. That doesn't stop people, I suspect largely because it lets them feel clever, but it's questionable if it adds any value. Also, aggregating global variables in a single global class or struct does not make them any less global. Pretending that it is is intellectually dishonest. 
And that's also basically the standard "safe way" to make singletons.
Well, loggers will typically have multiple handlers: to a file, to stdout, to stderr, a null logger, and handler that just keep things in some kind of simple buffer e.g. `vector&lt;string&gt;`. Typically for unit testing you would use a null logger (if you weren't also testing the results of logging) or a buffering handler (if you were). You just add/remove the handlers you need in the unit test, so there is definitely no need to mock repeatedly (if I understand you correctly at least). If they are separate translation units, yes that's true, but the whole point is that they aren't separate translation units, because you included it from the .cpp file. If you have e.g. Foo.{h,cpp}, and Foo.h *defines* (not declares) a global, and Bar.h defines another global, if Bar.h uses the foo global, it must include Foo.h. Whether the Bar.cpp or Foo.cpp TU gets loaded first is not defined, but in either case, the foo global is initialized before the bar global, which is what you want since the bar global uses the foo global.
I think that initialization problems shouldn't be discussed when talking about singletons. Those are bad implementations and only tangentially relevant. I would have liked this article to stay focused on what singletons do to your code design and what sort of design lock-in they create. For example, substantial use of singletons (as well as global mutable variables) creates a maintenance nightmare where there's way too much mutable state. This makes it extremely difficult to reason about what code is doing because every single function is implicitly taking all that other mutable state as inputs. It then becomes hard to untangle the logic if you ever want to parallelize it. In addition, threading in general is made a lot more complex and error prone with shared mutable state. 
Note that if you do anything fancy and edge-casey, like linker scripts, it may not work. I was doing some hobby osdev recently and tried to use lld, it kept failing on my poor linking :( Ended up using the WSL and normal gcc linker. I'm sure it works fine for the common cases though.
You can make the function a bit simpler with`std::common_type`: https://godbolt.org/g/RnxvGm
...then why did you go around saying they were blocking any if you can't even name one example? What warranted the bashing?
Although there is some interesting info here, using the Google style guideline smells of click bait. The Google style guide sounds authoritative, because that company has been very successful, but Google's C++ style guidelines are at very best considered to be controversial in the C++ community (many respected figures in the C++ community are on record saying they would not work for Google due to this very document). Readers of this article should at least read why these features are banned and make their own judgement.
I've found CMakes clang on windows support to be extremely iffy. And Clangs, for that matter. They still don't have a VS2017 MSBuild toolset, though there are community ones on google. CMake, for it's part, requires you to use the windows driver and MS linker, but I want to use gcc style for cross compiling and stuff sometimes. Not the most common case, but it shouldn't be so damn hard :(
I'm guessing you also have the MSVC 2015 toolset installed and it used _that_ – the 'vs2014' msbuild target uses the v19.00.xxxx compiler and standard library.
Is there anything other than macros and SFINAE?
So you have your own implementation of hardware input devices? I might mistake it with other library
`deque` uses the same segment size for each segment, and `std::deque` offers no control over that size whatsoever; in contrast, `segmented_vector` typically grows each successive segment by a factor of 1.5, ~1.62, or 2.
Perhaps something like this as well: if constexpr(!(aSigned ^ bSigned)) return a &lt; b; else { ... } 
It gets even worse because virtual final functions, called from a pointer that defined the function may skip the vtable. 
Yes, we have our own code. Only non-system dependencies are for audio (vorbis, ogg, flac and soon opus) and font rendering (freetype). Feel free to check the [source code](https://github.com/SFML/SFML). :)
Why don't we have `std::sane_int` in the standard library already?
Thank you! "Refs can't be null" seems to pop up periodically on this sub or in /r/programming when cpp rears its head. I got sick of arguing this point years ago and you stated your argument much better than I did. This should be the copy-pasta response anytime anyone starts another one of these threads.
no, not if you're unlucky, and/or if your pointer was allocated via a placement new in some memory pool elsewhere in your application. In that case, pointer addresses can get reused. Yes, I've experienced this pain before.
Pedantically this is true, but it's not useful. I'm sure that the guy debugging a crash would be relieved to know that the source of his problems was that it was because it UB'd 2 days ago and has been in a questionable state since :P. Handwaving away the UB effects doesn't make UB not happen, and not something you need to deal with during debugging. Technically, overflowing a signed int is UB. That's generally not fatal, but can sometimes be a source of logical bugs.
&gt; People are wrong on the internet, and somebody ought to try to correct... hehe good one. :) &gt; But it's worth pointing out that the people who are working on it are not taking time away from other highly-desired things like modules. That's not really true, in practice. Or rather, I believe that's not a good way of looking at it. In practice, committee members outside of this SG _do_ spend _some_ time looking at things in this SG, right? I mean I'm not in the WG, but even as an outsider I see other WG members discussing it on cpp-slack, for example. The bigger issue, though, is once this tries to get _out_ of the SG, then it will need to be looked at by the others... and not only will that then take their time, but even worse they could say "this is not good" which means even the SG's time was wasted. Right? That would be really a waste. I would think even the SG members would want some sort of preliminary feedback, just to avoid wasting _their_ time. No? That's how I view these reddit/slack/mailing-list communications - as sort of a litmus test of "do people want this?" type thing. (I'm ignoring the poor taste of some of the feedback) &gt; we're getting an io_service in the Networking TS -- wouldn't it be good if this proposal could use that somehow? I had (perhaps naively) assumed `io_service` was going to be the new event pump for everything that needed one, including graphics. Is that a bad assumption? (could be bad - the WG's view is rather opaque to us outsiders) &gt; But I think the level of vitriol in this thread towards the people working on it is entirely unfair and undeserved, and frankly I just don't understand it. I _know_, from personal experience, how much time, effort, and money is involved in creating standards. (not isocpp ones, but really there's not much difference from other SDOs, afaict) So yes I also thought the "basement dwellers" stuff from the OP was way out-of-line, and set a bad tone for any further discussion. Having said that, I found the email responses in the OP's posted SG email thread to be very insular. I _think_ it's just a case of the ISO/WG21 standards process being extremely document-driven. So from the outside it looks like the responses in that thread were bordering on religious dogmatism, but in reality they may have just been quite normal? &gt; Let's say the "worst" happens and this gets approved for C++20: if it's a disaster, then MSVC/libc++/libstdc++ simply won't implement it. That's not the worst case, actually. The worst case is it gets approved, and the compilers _do_ implement it, but no one _uses_ it. Because then it just wasted compiler vendor time - and _that_ is a precious resource we must not waste. There are proposals in the WG that cannot be implemented easily or at all without compiler magic. For example reflection, ranges, concepts, more constexpr enhancements, etc. Wasting compiler vendor time on things people don't use has an enormous opportunity cost for the rest of us. Another worst case is only one or a couple compilers implement it, but not the other big ones, and some users _do_ use it... then C++ get's another black eye for things only being possible in some/few compilers but not all. (ie, a "standard" only by name)
RESTinio looks really cool. While taking a look at the examples I've recognized that you are using plain callbacks mostly. Recently I've developed [continuable](https://github.com/Naios/continuable), an abstraction library for callbacks which could really integrate well into RESTinio. This could make it possible to support longer continuation chains, logical connections and even experimental coroutines straight out of the box. Let me know if I can provide you any further help on this.
Tag dispatch: if constexpr (EXPR) { // A } else { // B } becomes void impl(std::true_type) { /*A*/ } void impl(std::false_type) { /*B*/ } // ... impl(std::bool_constant&lt;EXPR&gt;{});
Yes, but I don't _want_ to use a two year old stdlib... The fact that it works, but only under some configuration I don't want to ever use (clang-cl + VS2015), doesn't really have any practical value to me.
A goto can almost always be replaced by a `return`. Usually it's to escape a deeply nested loop, but you might as well make the loop a function (or lambda).
The default warning level in VS is `/W3` but this is probably a level-4 warning. I hate bad defaults. :-[
If only they didn't mess up `size_t`...
Sadly, no. Microsoft didn't have a stable C ABI until recently, and furthermore, not all extensions are written in C.
Thanks! I really appreciate all the feedbacks you gave. 
I haven’t heard of this, is this widely used in C++?
Cute! Did you know that unsigned ints tend to bench slower than signed ints? Yep, it's true! So unless you're pressed for space, try to default to a signed it. You can argue, "Oh, but bunny, it's for self-documen..." stfu and don't write unsigned ints please. Thank you! \*wiggles nose\* :3
No worries, in the end it's more or less SFINAE.
It's like moving a file to another directory (within the same disk partition). The file contents doesn't really move.
It's just as much verbosity, if not more, I agree; but, it's significant that there's no SFINAE here because overloading is far lighter on compile-times than SFINAE given a large number of instantiations. (IME using tag dispatch over SFINAE post-C++11 is usually done for the sake of build times.)
How is the ToLoF not an AST?
After three years I was okay to do stuff without shooting myself in the for too much. I still have much, much more to learn, avec after 7 years of programming C++. The more I know, the more I know that I don't know.
Could you elaborate which guidelines are considered controversial. I've not been around here (or in C++ community) enough to have heard anything about it.
Unless you’re a super competent functional programmer, static typing is going to harm the rapid development that you need in a scripting language IMO. 
Isn't AST an intermediate form? In my case ToLoF is final form, there is nothing after that, it is executed directly.
AFAIK the AST only needs to be transformed if the language is compiled, but it’s still an AST otherwise. You definitely know more about this than I do though
&gt; AFAIK the AST only needs to be transformed if the language is compiled, but it’s still an AST otherwise. I could agree if we would drop "A" from "AST" ;)
I want to read this guy's posts, but all the conversationalism and chat speak just makes it too much effort.
Any chance of getting the std:: branch in there, too?
How is it messed up? 
By making it unsigned, it can cause a lot of bad behaviour if you try to compare it with signed values (as seen in the article).
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/82lf10/how_to_get_gud/dvb495g/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Well... I hear you, but people tend to want to reason about what happened at the place where their UB had visible consequences, which can be **very** far away from where the bug happened. I wrote what I wrote for this reason; upon an UB, usual logic does not apply; optimizer plays tricks; seemingly random memory overwrites destroy evidence; system reaction is misleading (e.g. "invalid instruction", SIGILL) and so on. See that overflowing a signed int? Say if it overflows to a small negative value once, reads valid (from the system standpoint) memory and starts making wrong conditional logic and data modification based on that data. It **really** is chaos. So... me wanting to investigate this data corruption? I am in a world of pain. Now, I know that I in fact need to look out for an UB **in an unknown place**, which will wildly influence my choice of troubleshooting strategy and tooling. The guy who said "technically overflowing a signed int isn't UB"? I would seriously mistrust the logic and tools they will use.
Why do all of the *completion_t prototypes take a void* argument instead of expecting callback data to be bound to the std::function in the usual type-safe manner? If you have a specific use case for this, it would be nice for all of the set_*_callback function declarations to at least default userData=nullptr for the more common usage.
Mathematically, operators only work on operands from the same set of values. If you take 'unsigned' to refer to Naturals and 'signed' to refer to Integers, the comparison operation for one is technically distinct from the comparison operation for the other. Saying that the Natural less than operation should treat all negative Integer values as less than all Naturals is not 'mathematically correct' in any rigorous sense, it's just another ad-hoc rule that seems to make sense to you. The rules that actually exist in C and C++ seemed to make sense to their creators. Ad-hoc rules are convenient until they bite you, and all of them have the potential to at some point or another.
&gt; In reality the representation of negative numbers has nothing at all to do with the actual issue of signed-unsigned comparisons. Having to fight nitpicking with nitpicking, I have to note that for the article to be correct, it doesn't need to answer this question. The article says that the problem exists for 2's complement, for 1's complement, and that the author doesn't care about signed+magnitude. I don't see you arguing with any of these statements, and the rest is simply beyond the scope. I added "at least" before "2's complement" to emphasize that I don't really care about the rest (actually - nobody in C++ reality does for a simple reason that C++ compilers for non-2's-complement systems don't exist and are extremely unlikely to appear, ever). 
Even worse, they don't enable a few of very useful warnings even at /W4
/r/iamverysmart
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/82m5ho/looking_for_good_c_tutorials/dvb7273/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I think we're in agreement here. The main thing I'm trying to get across is that nothing's magic. If you've been coding in C++ for a while, you start to get a sense of the possible UB causes when you encounter a bizarre bug. Knowing that they exist is half the battle. 
I like the idea, but: (a) perfect wrapper is fundamentally impossible in C++ (_at_least_ because of famous 1 standard+1 user-defined conversion rule). (b) I have my doubts about wrappers being really zero-cost (I will formally benchmark my own supposedly-zero-cost wrappers a bit later, but my very preliminary results indicate that while under Clang it can be more-or-less zero-cost, under both MSVC and GCC we can have huuuuge performance degradations even when using doing-nothing wrappers :-(( ). 
Afaik CMake does support cross compiling with clang from Windows, you just need to use the clang++ frontend instead of the clang-cl frontend. And for the VS toolsets, I personally don't care, since I use vim to write my code anyway, but you could poke people on IRC about a VS2017 toolset and see if you can get anything upstreamed.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
The whole thing has nothing to do with 2s complement. You might as well say the problem exists on Windows and Solaris but you don't know about Linux.
Ok then, let's say we have imperative, purely functional and logic.
Unsafe code is not unsafe by itself. The programmer must involuntarily introduce unsafe actions due to logic mistakes. So, any part of a programming language that allows the programmer to introduce logic mistakes **that can be mechanically avoided** is to be considered unsafe. 
C++ people have waaaaay too much of their own specialist jargon and technicalities to get sensitive about people using math jargon and technicalities. How come you think it's okay to be really loosey goosey about what "mathematically correctly" means when complaining about how the language specification works but feel it's somehow "showing off" to use math terminology from high school math classes? Oh well, it's a tough crowd, and strangely over-sensitive. :P
&gt; The whole thing has nothing to do with 2s complement. Care to give a reference to the specific place in the standard? &gt; You might as well say the problem exists on Windows and Solaris but you don't know about Linux. And would still be formally correct :-). However, given that nothing-but-2-complement exists in reality, it is more like "the problem exists for all the currently-existing computers, but I don't know about ENIAC". 
&gt; The C and C++ specifications actually do specify mathematically how to do conversions; those rules are just as correct as the ones I was replying to. Formal correctness and usability are two different things. Formally - there exists definition under which https://en.wikipedia.org/wiki/Brainfuck is equivalent to C++ (both languages are Turing-complete). OTOH, it is possible to demonstrate (given any required-degree-of-being-convincing) that brainfuck is unusable. 
Because you avoided /u/johannes1971's entire point in the most flowery way possible. His point (stated in math terms) was that all C++ integer types are merely subsets of ℤ and, as such, there is one total ordering. Just because both arguments to the comparison operator are restricted to (potentially different) subsets doesn't mean ... anything. There is nothing ad-hoc about making the comparison operator always do the "intuitive" (as defined in this article) thing.
What are you on about? ℕ ⊆ ℤ; are you saying you cannot compare elements of ℤ to each other? Oh, and if you want to talk 'rigorous mathematics'... The sets ℕ, ℤ, and ℝ have precise definitions. `unsigned`, `int`, and `double` are not at all the same thing, and many of the mathematical properties of those sets do not apply to their C++ counterparts. For one thing, `unsigned` ⊆ `int` is not true - precisely the problem we are discussing here. 
Great catch! Thanks!
To be honest I just want to avoid forcing user to call `*free( input )` in C style interface, so `replxx_input( Replxx*, char const* )` returns a pointer to internally managed memory. Maybe I could have to versions of `ReplxxImpl::input()`, one user in C interface that would have current semantics, and one used in C++ interface that would return `std::unique_ptr&lt;std::string&gt;` as you proposed. It is definitely worth considering. Thanks!
What would that be? Genuinely curious
What is the famous 1 standard+1 user-defined conversion rule?
For me I solved most of my issues by using signed arithmetic exclusively. Had to add a size() function which does a static_cast&lt;int&gt;(T::size_type) and debug only out-of-bounds check to get rid of most sources of unsigned numbers in my code.
Excerpt from [conv]: &gt; In general, an implicit conversion sequence consists of a standard conversion sequence followed by a user-defined conversion followed by another standard conversion sequence. And from [class.conv]: &gt; At most one user-defined conversion (constructor or conversion function) is implicitly applied to a single value. Standard conversion sequences are listed in [conv]/1.
My $0.02: as-large-as-necessary integer able to represent any integer-in-math-sense (whether 1, or 2^(2^(2^1024))). Would be really nice, self-consistent, intuitive, and inherently overflow-free - IF we could afford to stop thinking about potential allocations... 
The only thing I've noticed that doesn't work is column information for lines containing multiple expressions (which does work for DWARF). I don't spend much time in the debugger, but I wouldn't consider the experience overly 'diminished' unless you rely on E&amp;C.
I'd imagine it's much better since the last time I tried hence me asking. I'll probably give it another go soon, thanks. I never use E&amp;C as I find that pretty much useless (I use DLL hot reloading instead when I need that kind of instant feedback).
I see. Wouldn't you want to disable implicit conversations on your own types anyway? I mean we're supposed to mark all our single argument constructors as explicit? 
OTOH, were it to exist, Accio would be a great name for such a dependency manager.
I think this library seems great and I intend to use it a lot in the future
&gt; I mean we're supposed to mark all our single argument constructors as explicit? It all depends on the context - and for wrappers-of-integers, I'd argue for making conversions implicit. 
My original point was intended as an interesting aside, not an attack. I take it as obvious that safety doesn't need to be absolute to be useful, even withing the scope of what could theoretically be controlled. But since we're counter-attacking each other (I think resulting in another interesting aside, but I understand if you disagree)... There's always a narrower version of "safe" that makes some other class of logic errors impossible, but doing that without care tends to outlaw too much useful expressiveness. There's trade-offs to make, and we don't even know all the options we have to choose from. There's no one definitive meaning of "safe". If Haskell had a single formally defined safe subset (as opposed to various unsafe features - which incidentally, could also be said of C) then fine, but AFAIK it doesn't. The mechanical enforcement is about purity, not safety in general, and indeed unsafety can be used (among other things) to subvert purity. Even without using impure or explicitly unsafe code, though, you can certainly make mechanically avoidable logic errors in Haskell. The pure functional subset of Haskell allows one to write `let a=a in a`, also known as `undefined`. Try to inspect the result and you obviously get divergence. You can write that anywhere in pure functional code, you can try to inspect the result anywhere in pure functional code. The mechanical way to avoid that would be to only allow a non-recursive variant of `let`, though Haskell doesn't even provide a non-recursive `let`. In fact, all top-level definitions are effectively already in a kind of implicit recursive let. Potential paradox by direct or indirect self-reference is a basic fact of Haskell, and one that most are proud of (because of the "tying the knot" power and expressiveness it provides) rather than ashamed of (because of the risk of divergence). Obviously you can't mechanically avoid all divergence, but this is certainly a potential logic mistake that can be mechanically avoided in principle, yet affects all Haskell code by AFAICT deliberate (and IMO very well-made) choice. So all of Haskell is in the unsafe subset? Actually, cancel that "can't mechanically avoid all divergence". Just ban all forms of recursion, including recursive function calls. In the absence of `goto` that's a massive loss of power and expressiveness, and probably in conflict with having higher order functions, but it's also safer, at least for the few functions that can still be written. 
&gt;I was referring to a notion of "mathematically correct" that doesn't really exist in mathematics To be honest, that was already clear ;-) &gt;you can think of Naturals as a subset of Integers That's wrong, it's the other way around. The proper mathematical phrase for `int` is (probably, it's been 30 years so forgive me for not remembering exactly) 'finite abelian group'. This is also why people who want to use proper mathematical terms and rules in programming are generally known as "fags". 
Yes, I might have confused the two. Thanks for the note and I've added a correction.
For embedded programming, yes. The hardware specs tell you which memory address represents which register for some bit of hardware.
That is the way to go. Parallel computing is the future of programming and the concept of automatic parallel computing is just the icing of the cake. At the end of the day, we want things to be done fast. If a task can be done at the end of the week, we end up actually wanting it to be done tomorrow. If a specific task can be completed tomorrow, we would really like it ready by today. The world we live in today, we don’t like to wait. If anyone in this thread does not agree, just take a moment to think about the last time you stood in a line at a fast food restaurant and had to wait for more than a couple of minutes for you order to arrive. This same idea extends to other things like the weather. We usually routinely check the hourly forecast to see what the weather will be like on our commute to and from school. We at time expect that there is a computer working behind the scenes to provide this information. One computer may not be up to task and what you guys are doing, availing resources of automatic parallel computing become very relevant. Check out Holbertron programming (https://www.holbertonschool.com/) school and learn what automatic parallelism is and how it can be applied in future software development. 
According to Bar Code Group, C Coding standards is a set of rules for source code that is adopted by a team of programmers working together on a project, such as the design of an embedded system. Programming teams and companies write down their C coding standards for a variety of reasons but often bicker internally about which rules to follow. I just felt like it was worthwhile for me to mention this for those who may have no idea what c coding standards. Moving on my favorite c coding standard is Embedded C coding standard. This standard was developed with a goal of minimizing bugs in firmware by focusing on practical rules that keep bugs out--while also improving the maintainability and portability of embedded software. What I like the most about this coding standard, it details a set of guiding principles as well as specific naming conventions and other rules for the use of data types, functions, preprocessor macros, variables and much more. Individual rules that have been demonstrated to reduce or eliminate certain types of bugs are highlighted. Go to a good programming school like Holbertron school (https://www.holbertonschool.com/) and learn the popular c coding standards and make one your favorite. Good luck.
I don't have a good reference, but I've found the most important thing is to keep a clear head about where types belong and where values belong. Once you start keeping those things straight, then everything starts making a lot of sense, but its one of those things that takes a while to really "click". Much of TMP is playing "tricks" with the type system that seem nonsensical at first until you start seeing it for what it is.
I really liked Sasha Goldshtein's introduction. https://youtu.be/lrziylOWBT4 I haven't done much TMP but this helped me understand more of how to use the STD TMP library.
Thanks, I'll give this a watch!
You have to start seeing types as variables, yet still of a different "class" than runtime-value variables. And things like "I need 1 type but it's composed of 3 types": template&lt;typename&gt; struct S; template&lt;typename R, typename C, typename... Ts&gt; struct S&lt;R(C::*)(Ts...)&gt; {}; ^^^^^^^^^^^^^^ All that is just one type (pointer to member function) that matches up with the original template definition of S which says that template S requires 1 type. 
I can suggest to grab yourself a copy of [C++ Templates: The Complete Guide](https://www.amazon.com/C-Templates-Complete-Guide-2nd/dp/0321714121). It's a great book.
&gt; Template syntax is so horrendously confusing to me that I don't know where to start. not that much if you consider it as a LISP-like language on types. Proper indentation works wonder eg. template &lt;typename T, std::enable_if_t&lt;!(std::is_arithmetic&lt;T&gt;::value &amp;&amp; std::is_same&lt;T, QStringList&gt;::value)&gt;* = nullptr&gt; QDataStream&amp; operator&gt;&gt;(QDataStream&amp; stream, T&amp; obj); =&gt; template &lt; typename T , std::enable_if_t&lt; std::negation_v&lt; std::conjunction_v&lt; std::is_arithmetic_v&lt;T&gt; , std::is_same_v&lt;T, QStringList&gt; &gt; &gt; &gt;* = nullptr&gt; QDataStream&amp; operator&gt;&gt;(QDataStream&amp; stream, T&amp; obj); =&gt; (enable_if (not (and (is_arithmetic T) (is_same T QStringList) ) ) ) where the value yield by this LISP expression, is a C++ type. Then, the main "rule" when doing template metaprogramming is, "if the value yield by such an expression is non-sensical, this function / class / etc... is skipped". 
Run away! Save yourself! It's to late for us!
Too pricey for such an awful cover. Jokes aside, I'll see if I can find a used copy. Thank you! Just the kind've thing I was looking for for a deeper dive into it. 
Pre-C++11 is _not_ outdated if you need to learn the concepts. C++11+ buys you succinctness, not magic. ;-]
The basic question to ask yourself is: Can this be done at compile time instead of at runtime? Just by chasing down the answer to that question enough times you'll inevitably learn about templates and their various uses.
It’s worth the money... and be sure to buy the most recent release... the second edition (2017) is a couple is a couple pages longer than the first, and is updated for c++17. 
=P
Interesting! In our code we hardly ever deal with signed integral types. Therefore we really get annoyed when f.e. we get a signed integer as a result type from e.g. Qt functions where the positive value domain covers true function results and negative numbers indicate some kind of failure. Two different kind of outcomes conflated into the arguably *least specific* type that exists in C++
It depends what knowledge one has and what one lacks. For just syntax, sure, and the Vandevoorde recommended already is great; but if one still needs to wrap their head around the _whys_ and not just the _hows_ then the standouts in my mind are all from the early 2000s.
TMP is not meant to be used by normal application developers, despite what some "experts" say. So if you want to learn C++ without me knowing exactly what you work on most of the time I assume you are better to learn about testing, smart pointers, &lt;algorithm&gt;, boost, lambdas... If you are really interested in learning TMP you can do it by reading a short [free book](http://www.oreilly.com/programming/free/practical-c-plus-plus-metaprogramming.csp) by really smart French people... but again TMP is not usually needed for most of the code. Other than that if you have specific problem you want solved by TMP you can ask on SO.
heh, that's what I get for typing code in a reddit comment without checking :p 
&gt; I don't really PLAN on writing TMP stuff, more just want to understand how it works when I read through code. Ah OK. :/ Then again a bit more specific questions would probably be easier to answer, but here is a starting point for you: C++ uses template overload resolution as a stupid ugly way to do if statement. For example see [here](https://en.wikibooks.org/wiki/More_C%2B%2B_Idioms/Tag_Dispatching) This code does if on the kind of type you provide to it. Notice the ugly trailing return type where they do decltype of something, void. Well that something is the condition of our ugly if. Compiler will try to instantiate that function and try to see if that something compiles. If it does it will pick that overload, if not it will proceed to go to the other one. This is known under the lovely name SFINAE, meaning that the fact that compiler tried to create this function and failed is not a hard error. Reason for this is that functions that do not match are not instantiated for this type. So you do not get into problems of trying to call .remove_if on type that does not have that member function. If you had just 1 function and did the if inside that function you would run into the problem of trying to call .remove_if on a type that does not have that member function. When you use overloads like this only template that is instantiated is the one that does not use .remove_if member function so it compiles. 
So I have a fair understanding of template syntax and I know what enable_if does - however I've always found it impossible to read this sort of thing in a single line. Splitting it out like that and reading it as a LISP-expression has really opened my eyes. Thanks!
Last I stumbled across gcc/clang perf test, gcc was generating faster code (and faster). I think that was here or on proggit. Are you a tad biased against gcc perhaps? Or have memories of gcc when it wasn't as good with C++ standard support as clang was?
I could've agreed with you if you had said **heavy template metaprogramming**. Moderate use of templates is absolutely fine, even for if you're not an expert.
Are you telling me i accidentally learned LISP trying to understand templates?!
Note that there be dragons with dependant types; you can easily make an ill formed program that the compiler fails to diagnose that "works" in your current compiler.
I learned TMP by accident. I started off with using tuples, then figuring out type deduction and variadic templates. Now, most of my use cases for TMP have been superseded by constexpr if, and the relaxed rules for constexpr functions in C++14 and 17. Some understanding of SFINAE is still needed, as constexpr if doesn't handle all cases, which is what you seem to be calling "action on failure". Think of "action on failure" simply as taking the else branch on an if statement, or jumping to a case label in a switch statement. You're basically just writing conditional logic. But instead of the explicit style of ifs and switches, you're doing so with implicit pattern matching. You provide overloaded definitions (partial and full specializations) that represent the "branch" you want to take. The compiler takes the definition branch that most matches what you've provided at the actual call site. If that branch doesn't exist you get a compile error. If that branch does exist, it's up to you how to handle that condition. Sometimes you want to take the branch that results in a much nicer compile error through static_assert. Sometimes you want to take a branch that is a no-op. Sometimes you want to take the branch that chooses a better algorithm based on compile time information.
&gt; you can easily make an ill formed program that the compiler fails to diagnose that "works" in your current compiler. Explain?
*if we could stop thinking about reality
If you've done recursive variadic templates, that's pretty much the car and cdr of the LISPs. I think it's actually better than LISP because it's a compile-time only language, whereas the LISPs with macros you can't be sure when they're evaluated.
&gt; Are you telling me i accidentally learned LISP trying to understand templates?! https://www.youtube.com/watch?v=_uJMKxmoo68
And potentially expensive because static construction must be thread-safe. Every call to GetInstance will add guard code which will increase the i-cache pressure considerably: https://godbolt.org/g/TBrfmK
&gt; Moderate use of templates is absolutely fine, even if you're not an expert I disagree, but give me an example so we know we are talking about same things.
 template &lt;template&lt;class&gt; class T, class U&gt; How is this not obvious?
There are many programs, and many parts of programs, in which integer allocation is so far from being a performance bottleneck that it doesn't matter if they are 100x slower than native integers as long as the resulting use by the programmer is more efficient (easier to understand, less prone to bugs). There are of course also many programs where numbers need to be as efficient as possible because they're on the hot path of a performance-critical piece of code. Speaking as someone who uses C++ professionally, I am often drawn to other languages that put less burden on me for the average task. In my opinion, C++ over-optimizes for the zero runtime overhead goal to the detriment of programmer experience in all the cases where it doesn't matter.
People seem to forget that you can break large template specs into pieces just as you ordinarily use functions. When it starts to look like line noise, make some new definitions that capture commonly used patterns. template &lt;typename T&gt; struct something_simpler { using type = typename something_more_complicated&lt;nested_nested&lt;T&gt;::type&gt;::type; }; template &lt;typename T&gt; typename something_simpler&lt;T&gt; my_func() { ... } If you use really clear naming, it can actually become somewhat readable.
And how does it work with shared-libraries?
I'm not /u/hyperactiveinstinct, but I work in HPC with heavy C++ and CUDA code, and we couldn't achieve the performance that we do without either using templates heavily or doing a lot of copy-pasting. We need to be able to select, at compile time, which runtime parameters get passed to the specific instance of function templates, which variables should exist during the function run time, as well as which specific variant (based off a combination of its template parameters) of functions need to be called. I'd _gladly_ do without template metaprogramming for all that, but I honestly haven't found a way to achieve this without massive usage of `enable_if`, `conditional` &amp; co.
&gt; I work in HPC with heavy C++ and CUDA code Good for you, but I doubt your job is representative of average C++ job. Most C++ codebases would probably do what you do with bools or OOP. :) tl;dr In your case you are right, but I doubt it is a common case. 
While I agree that my job isn't the typical C++ job, I would argue that having an understanding of how these things work can be very beneficial to produce better code and even reduce development time. I mean, if performance isn't one of the objectives, why even use C++ instead of, say, Python; or even JS (there's a reason why Electron is a thing, after all)? 
That does seem very weakly typed, merging the meaning like that. I'm very happy after the switch to signed integers for all ints representing quantities or number, i.e., anything you can do arithmetic on. Occasionally I use size_t if I index into a container in a loop where only increment and nothing else.
I added an item to https://github.com/fmtlib/fmt/issues/518#issue-234239830, thanks.
But you're also "subscribing" for the MSYS2 runtime library.
&gt; I mean, if performance isn't one of the objectives It is not binary. I mean there are projects that beside legacy reasons should be done in a lame slow C++ kind of way because that way they are still faster than Java or Py version of the same project, but you do not end up calling Eric Niebler in 3 years to ask him what your code does. :P And there are projects like quasardb where (according to author) perf is pushed to the limits(inline asm and huge amount of templates and boost).
I thought the std:: branch had compile-time format string checking... https://godbolt.org/g/Rw3DdC
&gt; For me I solved most of my issues by using signed arithmetic exclusively. FWIW: do you know that signed integer overflow is UB, which in turn allows a perfectly-compliant compiler to generate code which formats your hard drive? 
Check this video from cppcon 2014 by Dr. Walter E. Brown https://www.youtube.com/watch?v=Am2is2QCvxY And here is my repository, I used it for learning tmp, maybe it will help you: https://github.com/elvisoric/cpp-tmp
Can we use `break` and/or `continue` as keywords here? ie we break the function in half at this point, or we return here to continue later? Even if we had to combine them with `return`. Like `return continue std::async(...);` 
Last time I checked (which was fairly recently), it still was /W3. 
Yes
Absolutely! Overflow is a serious logical error and should never happen. And with signed arithmetic it's a lot less likely to happen by accident.
If there are no static objects involved at all, but a class is still designed to be instantiated only once, does it still count as a singleton? In Qt for example, you need exactly one QCoreApplication object. You can't have two. It's accessed either through a global variable (::qApp), or through a static member function (QCoreApplication::instance()), but the object itself is not static. You need to create one yourself at program startup. It it a singleton?
Any idea if there's something on the table for '20 to fix that? 
&gt; You're also welcome to write anything else that produces a null pointer, such as [...] `HMUMBLE h5 = 3 - 3;` False. Only literal `0` is allowed. Any other expression is invalid. See [CWG #903](http://open-std.org/JTC1/SC22/WG21/docs/cwg_defects.html#903).
No need for sfinae, you can just use tag-dispatching.
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0424r1.pdf would allow a nicer literal-based API instead of a macro, e.g. fmt::format("{}"_fmt, 42);
Oh, there's a clang/gcc interface for doing this already? &gt; &gt; Today, we must rely on a non-standard extension provided by &gt; Clang and GCC, which allows user-defined literal operators of the following form to be considered &gt; for string literals: &gt; template &lt;typename CharT, CharT ...s&gt; &gt; constexpr auto operator"" _udl(); &gt; "foo"_udl // calls operator""_udl&lt;char, ’f’, ’o’, ’o’&gt;() I don't suppose there's a #define to turn that on in fmtlib, is there? :)
Boost.Regex is great until you find that building your code with clang in 'release' mode causes a linker error.
At least do some small string type optimization and avoid wasting half the memory. 
It's important to note that while this is fine and dandy for new code, blindly refactoring NULL with nullptr for existing codebases is a pretty bad idea because: a) It doesn't really improve anything. b) since NULL is technically an `int` and nullptr is a `std::nullptr_t`, overload resolution might actually differ and lead you down different codepaths,
According to the link, it was never standartized to only allow the 0 literal, and not any other 0-evaluated value. Found here: &gt; Additional note (January, 2013): &gt; &gt; Concerns were raised at the Portland (October, 2012) meeting that the value false has been used in existing code as a null pointer constant, and such code would be broken by this change. This issue has been returned to "review" status to allow discussion of whether to accommodate such code or not.
The bug may be caused by something trashing the heap, a call stack won't help you then.
That's absurd. "Hey, TreeNode, what's on your left?" "false" What?
This observer list, for instance: https://cs.chromium.org/chromium/src/base/observer_list.h?type=cs&amp;q=base/obser&amp;sq=package:chromium&amp;l=1 It is not that sophisticated and it is fine for the intended purpose.
&gt; b) since `NULL` is technically an `int` and `nullptr` is a `std::nullptr_t`, overload resolution might actually differ and lead you down different codepaths. I wonder if [clang-tidy](https://clang.llvm.org/extra/clang-tidy/checks/modernize-use-nullptr.html) checks for this situation. Even better -- I'd like to know when this happens in my code, because it's likely a bug I need to investigate.
Prepare yourself that you're not gonna catch up all the details from the beginning so don't be too harsh to yourself and most importantly have patience. Templates (and TMP) will give you a completely new perspective on the way how you can approach solving problems in C++. This perspective, or paradigm how people like to name it, is not natural to most people coming with a background of procedural programming languages (which makes most of us) and which is IMHO why most people cannot easily grasp the concepts of it. But once you get a good understanding of it, your way of thinking will change and the way you have approached the problems before will start to look unnatural (at least that happened to me). Once you get into it, you'll enter a completely different world of C++ and there is no coming back from there :D
I recently learned a lot from watching some CPPcon talks about it by [Walter Brown](https://www.youtube.com/watch?v=Am2is2QCvxY) and [Arthur O'Dwyer](https://www.youtube.com/watch?v=vwrXHznaYLA). Should be enough to get you going. They were made before the current standard, but the stuff they talk about ended up making it into the standard, so it's still very usable.
&gt; I get variadic template functions and what not, and the absolute basics, but I've been stuck a bunch of times lately just knowing issues I'm coming across could be solved with some compile time magic. One thing is true: You will not learn *perfect forwarding* by trial and error. This really needs a guide. Generally, you do not want to learn templates by trial and error as you will end up only with more questions and frustrations. &gt; what features are you guys most excited about in upcoming standards? Concepts. Why? Because they further enhance the Turing-complete template language. I'm a sort of wizard that very likes this arcane stuff. &gt; Can anyone point me in the right direction for learning more about template syntax and what not? I mostly just don't want to be totally lost when reading other's code. Initially I wanted to contribute to learncpp.com but the author responsed that currently does not accept external writers. Currently learncpp.com (excluding stuff on YouTube) is regarded as the best free online tutorial resource. It's template section stops on specializations for functions and classes - that's &lt;= 10% of the template features. This did not stop my plans, only changed them. I have a WIP repository (in markdown to read online) that is intended to fully explain templates from the basics up to the highest-level black magic. There is no ETA now, nothing is yet public but I predict there will be a huge speed up in the work once I finish my semester on studies. I will have finally free weekends to dive deep into the tutorial.
Very cool :)
&gt; since NULL is technically an int and nullptr is a std::nullptr_t, overload resolution might actually differ and lead you down different codepaths. Alternatively - from experience - said change finds/fixes some long-standing bugs that already existed because of incorrect overload resolution. :)
How convenient for you.
Tee or coffe? Yes.
IRC, gcc and clang have warning when NULL is interpreted as `int`.
But that's the whole purpose of using signed arithmetic, to make out-of-bounds arithmetic less likely. Unsigned int overflow even though it's well-defined can result in just as bad logical errors.
Template meta programming is just so much easier if you have a newer C++ compiler. Variadic templates, constexpr and if constexpr just to name a few. A lot of the techniques you used is outdated now.
Yes. Walters talks are most enjoyable.
That is not the "hard" part. That's just cumbersome part. The real frustration comes from overload resolution, SFINAE, ADL and other fun acronyms.
&gt; According to the link, it was never standartized to only allow the 0 literal It got standardized. The wording in the standard today is "A _null pointer constant_ is an integer literal with value zero [...]"
Other ideas: * in a header, do not #include a definition of a type if a declaration would do; forward-declare the type instead; only include the type header in a .cpp file * typedef smart pointers to your types in a separate file; when possible, include that in your header; only include the type header in a .cpp file * use .inl files to take stuff out-of-line in `_DEBUG`builds * use precompiled headers; do not put your own headers in them (do put in your own headers of stable libraries though)
Yes! Absolutely right. 
A bunch of reasons. First, as I've recently written elsewhere, if you want global access, then you can just write `Engine` as a normal class, not a singleton, and have a global instance of `Engine`. This makes it much easier to unit test Engine itself and has no practical downside. Programmers accidentally constructing multiple Engines when you only need one is just not something I've ever seen people do realistically. Second, with a global/singleton, any function/class could now be accessing state from Engine, which could be different at different points, which means that testing gives you much poorer assurances as to testing. Basically, every global is essentially an input to every single function. Globals that never change aren't so bad because they will be the same in your tests and in every point of your program execution, so they don't really change reliability, but globals that change during program execution are pretty bad. Loggers often get a pass on this because usually the state of your logger should never, ever impact the return of a function or the state of a class. A few other things fall into the same category (intrusive performance profiling), or things that are initialized once at program initialization but never change afterwards (factories). Globals can reduce boilerplate, and I'm not going to say to never use a global, when it's a careful part of the overall design. But in many cases, the reduction in boilerplate is largely caused by the fact that things aren't well designed to begin with. Or rather, they probably used to be well designed, but as the codebase evolved, it no longer is. So you have to shuttle pieces of state "long distances", which the global saves you. I'm a firm believer that getters and setters are also a big consequences of this (and they suck too, but not as much as globals, I notice your code examples are packed to the gills with getters, this is terrible class design). Basically, often, if globals are really saving you so much boilerplate, it's a sign that your code may need some refactoring. That said, refactoring takes time, and business concerns drive technical concerns and not vice versa, etc. Tech debt is like any other debt: it's ok to take it on with eyes open, sometimes it's not just ok but necessary. It's just important to understand that it *is* a form of debt to throw something in a global, because you'd have to pass it really far down and it's a pain, instead of maybe taking a good long look at why it has to be passed so far down in the first place. I think people rail against mostly because some people still don't fully agree that these things are bad. Hopefully most people understand that real codebases are full of compromises and you don't always have time to do a big refactor, and a global might be the lesser of two evils.
Why use a singleton over a global? `GEngine.getWindow().getSize()`
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/82rduj/is_cmake_worth_learning_for_a_beginner_to_the/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This is a small problem I had too. For GUI controls, I had them get their and their children's Scene from the parent control, so then I only had to give the root control the Scene pointer. To shorten the path to deep data, add some member functions so that you can write `this-&gt;getGuiManager().getEngineWindowSize()` as a shortcut. And for GUI layout, which is probably what this is about, you could instead pass the relevant info to the layout function so that controls don't need to look into the GUI manager. This generalises to other stuff, where I prefer passing managers and other such stuff by function arguments when needed, rather than storing it. Furthermore, if you have lots of stuff to pass around, put it all in a `struct UpdateCtx`, which allows you to change the "arguments" without touching all member function overrides.
I like to include all definitions of types that get returned by my interface. It is really annoying when #include &lt;foo&gt; auto f = Foo(); Gives an error.
&gt;so why the hell I would avoid using a singleton ? Well presumably you're not a bad engineer so you want to actually test your code... ...and there's your reason!
You're right, can be found in C++17 standard from March 2017, section 7.11, point 1
May I make a suggestion? Drop the word 'get'. `Engine::Instance().Window().Size();` is just as readable, and less typing. And for the rest... If you have precisely one, and it lives for the duration of your program, feel free to make it global - that's what that scope is for. The most significant pitfall that you will encounter is that initialisation order can get tricky. Be prepared for that. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/82ruu4/help_help_estimating_calculations/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; in a header, do not #include a definition of a type if a declaration would do; forward-declare the type instead; only include the type header in a .cpp file There are two problems with this. First, if you're not the authoritative party to determine the correct forward declaration then you can get it wrong, or the library can be updated in a way that invalidates your forward declaration. One example is if you try to forward declare things from the standard library. It's undefined behavior to do so, and if you want to do it anyway using implementation specific knowledge, different implementations require different forward declarations. One you write for libstdc++ won't work for libc++, for example. Second, forward declaring entities from other logical 'modules' will break when C++ modules are implemented. Clang's early work on modules showed that it can actually be quite easy to adopt modules in 'well behaved' legacy code. For example libc++ and Mac OS X's system libraries were modularized and it worked quite well. But forward declarations and duplicated definitions are exactly one of those 'non-modular' behaviors that has to be fixed to adopt modules. The best way for forward declarations to work is for a library to provide forward declarations for its own types in its own header, similar to the \&lt;iosfwd\&gt; header in the standard library. This means the authoritative party provides the correct declarations, and it can be done in a way that won't break modules.
For the [CertOpenStore function](https://msdn.microsoft.com/en-us/library/windows/desktop/aa376559(v=vs.85).aspx) it advises to pass `NULL` for a parameter of type 64-bit unsigned integer. Currently this elicits a warning from g++, but passing `nullptr` would cause a compilation error. `warning: passing NULL to non-pointer argument 3 of 'void* CertOpenStore(LPCSTR, DWORD, HCRYPTPROV_LEGACY, DWORD, const void*)' [-Wconversion-null]` Seems like bad API design to me; the documentation should say to pass `0` rather than `NULL`.
&gt;since NULL is technically an int and nullptr is a std::nullptr_t The Standard permits `NULL` to be a macro for `nullptr`. If there is a potential problem with overload resolution of NULL in the code then it is arguably better to deal with it now than to leave it and hope for the best. 
isn't that what unordered means? Not sure what your point is.
&gt; It's just important to understand that it is a form of debt to throw something in a global, because you'd have to pass it really far down and it's a pain, instead of maybe taking a good long look at why it has to be passed so far down in the first place Your whole post is beautiful but this just deserved to be emphasized. Introducing a global may well be an improvement on the current state of some code, but it's important to remain aware of when it's a crutch propping up poor design. 
For the love of god, this. All headers should be independent. I enforce this in my projects by making sure that the first thing included by any unit test or implementation file for a header is the header. If I forgot to forward-declare something or include something in the header, the unit test and implementation file will have to compile. To give a concrete example, if I have a Foo.h defining class Foo, with the implementation in Foo.cpp, the first non-comment line in Foo.cpp is #include "Foo.h". This ensures that Foo.cpp will fail to compile if Foo.h doesn't have the right declarations and definitions in scope Foo.cpp will fail to compile, forcing me to fix it.
But the ::getInstance() is the global instance. It really does not change much. And that Engine is essentially global anyway. Everyone that wants to change it will have access through the guiManager. Very often singletons is not the best solution, but when it is the best solution you should not avoid it because some rule say you should.
I blatant disregard for the title, here's an include trick for named enums I saw in tcc -------- keywords.h DEF(TOK_INT, "int") DEF(TOK_VOID, "void") ... main.c enum keywords { #define DEF(id, str) id, #include "keywords.h" #undef DEF TOK_MAX }; const char* keyword_str[] = { #define DEF(id, str) str, #include "keywords.h" #undef DEF "" };
Singletons are a "code smell". ie they aren't always wrong, but they hint that something might be wrong. Have you heard globals are bad? (Not always, just usually.) Do you agree? Singletons are just fancy globals. Know what else is a code smell? `getThis()-&gt;getThat().more().digging().into().classes().` (even the smaller version, via singletons) That is a sign of lack of encapsulation and abstraction. Do you agree with encapsulation? Fundamentally, the problem is that our minds are small, and can't hold too many details at once. We thus try to separate our code into small pieces, with each piece as independent and separate from the others as possible. We should be able to look at a single piece at a time, and understand it without needing to understand all the other pieces at the same time. As a bonus, the piece becomes testable independently. Now that's not always possible - some problems are complex by nature. But we should strive for it. For a GUI component, if it needs to know the window size, make sure it knows the window size. It probably doesn't need to know _everything_ about the Engine. Just window size. Write that component as if it wasn't attached to the particular app it is in. On its own, it would 'think' "I need to know window size, so either my functions will take a window size, or I will get one on construction, or I will have a `setWindowSize()` function - that, hmmm, can maybe be naturally connected as a 'slot' to some kind of `windowSizeChanged` signal." Make the component only care about the things it needs to care about. Let it be very focused. (P.S. each component should only do one thing - "Single Responsibility Principle".) Singletons work against separation. As does get-&gt;get-&gt;get. Avoid them. They make understanding harder. Make independent pieces. P.S. this also applies to _functions_. Functions should be small and independent. And do one thing. for the ground-breaking research in this area, see http://www.laputan.org/pub/papers/wheeler.pdf (Stroustrup's thesis advisor, by the way). eg "self-contained part of a programme" which "allows the coder to concentrate on one section of a programme at a time without the overall detailed programme continually intruding".
Singleton properly means there really can be only one, and it usually turns out that's not strictly true. Using an accessor to get a well-known instance helps with lifetime issues. In particular it can help with order of initialization problems, and code running before main starts. You still have the problems of global variables, like hidden coupling, and spooky changes in behavior of functions over the runtime life when the 'singleton' changes state. It may still be preferable to passing Engine* everywhere, especially if there are a few things like that.
I do this even if it's the only line in "Foo.cpp". Makes misformed templates, and so much else, easier to diagnose. 
When we (ie the Product Manager really) take on tech debt, as programmers, we should set up the repayment plan _then_ - when the debt is being taken. Next time you tell your PM, "yeah, we can get that done this sprint, but we will need to cut corners", also say "and our repayment terms will be one dev every other Friday, for the next 6 months. If that's acceptable, just sign the loan agreement here." When the PM later "defaults" on some loans, eventually stop offering tech debt, and tell them they are a "bad credit risk".
P.S. `get-&gt;get-&gt;get` really is bad. I'm dealing with it in our current codebase. The concrete result is that _nothing_ can be changed without breaking something. Everything is connected. Don't go there. And singletons are just another form of the same "there". The thing you need to try to avoid is interdependence. Your future self will thank you for the extra effort that current self put in to maintain independent code. It is more effort, but with practice it becomes easier.
Heh, QStringList, that brings back memories. Did you know they picked the name Qt because the main guy liked how the Q looked in his favorite programming font?
The most important reason to eschew singletons is that the make your code become spaghetti. This isn't obvious or a particularly huge problem working on a small hobby or indie project, and if that's what you're working on then they're probably just fine. I've used them for many many years in small projects with no regrets. I'd also been a proponent of using them in a Big Game for convenience' sake and that was easily the worst mistake I've made in the 5 years of working on that engine. When your game (or library/application/etc.) is a few million lines of code and you've got dozens of engineers supporting hundreds of content creators... that code spaghetti becomes a serious liability. Being able to understand complex code you didn't write is the *hardest* part about your job. With singletons, `int foo(int x)` could call into the Audio system. You can't even tell that without looking at the implementation of `foo`. And looking at it again and again, because you'll have no idea if someone in another team *added* a dependency in some other branch 3 months after you first looked at it, so all your knowledge about `int foo(int x)` becomes invalidated every time you look away for a minute. I would very much classify an `Engine` singleton as *the worst possible fricken idea*. Every system lives on Engine. Making Engine a singleton is effectively identical to making *everything* a singleton. That's the path to madness. Do not do that. Do not. Just don't. In your example, what code *actually needs* the window size? That should be exceedingly little code, and it should be fairly localized. UI code needs it for calculating mouse coordinates in absolute mode, or for calculating the size of the UI canvas (and all UI widgets and layout code should be using the *canvas* size from then on, so no further dependency on the Window is needed). The renderer needs the window to allocate swap chains and back buffers and set various rendering options. All the actual rendering code should then use *those* sizes and not the window's native size, though. No need for window to be a global just so two functions can use it. Most of the "but I need X so often" cases I see come up are bogus. The most common one I see is "but I need to be able to load resources wherever!" No, no you do not, and even trying that causes all kinds of problems. Resource IO should not be randomly performed by any ol' code. Game IO is done in well-controlled locations (loading a scene, saving the game, etc.) or by insulated systems (world/texture streamer). I could go on at very great length of the resource loading topic (there's a lot of complex cases in more advanced engines; trust me, I am very cognizant of that... but no, not one of them is made *easier* via singletons, I also can promise you that). This is one of the reasons that the Entity Component System architecture got so popular. I have a lot of qualms with that architecture, but it *does* solve this problem very very well: because all code lives in a System object of some kind, you can easily just pass references to your sub-engines (Audio, Physics, etc.) to the specific Systems that need them. You don't ever have rando code living out in some Component that needs access to sixteen arbitrary modules of the engine, so there's never any need to expose those modules via a singleton. Your dependencies are clear, and being so clear and localized, just passing them explicitly when constructing the Systems is convenient. In a non-ECS architecture, there's still a lot of easy solutions. For one, don't have code that's doing too many different things. If you ever find yourself writing a component or object that needs access to Audio, Physics, Windowing, Renderer, and Input, immediately stop and rethink that code. That's a gross violation of the Single Responsibility Principle if nothing else. e.g., we have a component called an Action Choreographer that handles sequencing a events from a stimulus. Instead of having the Choreographer depends on all the things it could do, the individual Actions have those dependencies. Those dependencies are passed in very factories registered in Engine intialization code. Clear explicit dependencies, no singletons, and yet there's still a complex system that seemingly can interact with any part of the entire engine. The code is very maintainable, clear, and there's little extraneous complexity. Adding singletons wouldn't even noticeably make the code more convenient to write. When it comes to *good* singletons/globals, there's a particular type of thing that tends to work really well: debug-related code (logging, profiling, memory tagging, telemetry, etc.). Why debug code? Because that's exactly the kind of thing you might want to drop into rando code. It's handy to be able to drop a profiler marker, or log statement, or memory region, or so on *anywhere*. Even inside `int foo(int x)`. Code that you might actually need *anywhere* is the code that should be globally available. That may mean having some singletons for supporting system, though in most of those cases in my experience the actual public interface will be something else (like free functions, macros, or RAII scope guard objects).
class Engine { public: static Engine&amp; Instance() { static Engine instance; return instance; } private: Engine() = default; } It's guarantied by STD, that 'static Engine instance' is (thread safe) instantiated on the first call of 'Instance()'. 'Engine GEngine' would be instantiated at the point of it's first occurrence in the #include-hierarchy. The singleton-approach is safe, the latter not. It relieves you from matters of #include-order. (AFAICS)
But... Light blue font on dark blue background. :(
If Engine is a singleton, that usually means that its constructor is private, and you can't construct it all yourself, and typically also means it will never destruct until the program ends. If Engine is a normal class, you can construct and destruct it as many times as you want. This is necessary for unit tests; your unit tests can't really be independent if they are all running on the same Engine instance. So just make Engine a normal class (it can be uncopyable, but it should have a public constructor and destructor), and have a `Engine g_engine` global variable. And just replace `Engine::getInstance()` with `g_engine`. So part of my point is, that even if you do want global access to something, just make it a global. Not a singleton. There's almost no reason to ever use singletons. Globals still aren't great but yes, sometimes all things considered they might be the best solution.
This looks really useful! Nice work! One thing I wonder is whether it would be nice to avoid having to call CMRC_INIT(n) and have an option to pass 'n' as a parameter to the resource access functions. Anyway, I'll give it a whirl and see how it goes. Thanks! 
Read Alexandrescu's "Modern C++ Design". That is old school TMP, a lot has become easier in recent updates of the standard. It is well written in a pioneering spirit. Very accessible. Never forget that TMP was not intended but discovered, which explains why many things are awkward and complicated. Things are getting better though. Also, check out Boost. Mp11 and Hana are about modern TMP, and they have free tutorials.
It is with Chromium though.
Yes, it's okay to replace NULL with nullptr whenever working with on perfect code.
Unordered just means "not sorted". If you use boost::unordered_map then you'll get the same order of elements across platforms. The entire point of my comment was that if a game developer (or anyone developing portable software) asks for a feature in the STL, like a hash_map or unordered_map, but it's so loosely specified that it behaves differently across platforms, then it may be unusable by them. It's not a critique of the STL, but an answer to the parent's question.
Cool, I always wondered how that works.
Cpp-dependencies has an option --include-size that tells you the full LoC impact a given header has with how often it's transitively included. That will show you these cases quickly.
I have a build step that tries to compile all header files as C++ code.
What are you referring to as "initialization"? Instantiation implicitly represents initialization. And that's actually the point, that instantiation of the static instance is done thread-safe by STD at the first call of the function Instance() in code. There is nothing more to consider in this respect. And as for any overhead... It should probably go towards zero, because after all, only a reference (compile time) is returned. (We do have optimizing compilers, nay...? *g)
This trick is so useful, or at least widespread, that it even has a name: [X-macros](https://en.wikipedia.org/wiki/X_Macro)
c) Accidentally break API: https://bugzilla.mozilla.org/show_bug.cgi?id=784739#c281
What type is the variable `broken` in any possible situation?
Get a good dependency injection framework, and many of these problems goes away without the need for globals. Of course there are use cases for globals, but it happened many times there were things I thought to be a good candidate for a global, but it turned out I needed many instances.
Never met a PM with good credit... 
True. Though I reckon there just less contributors that have an incentive to get involved with such complex project at a more than a surface level. 
Lisp macros are always expanded in the macroexpansion phase which is part of the compilation phase. Even if you have reader macros like in Common Lisp, they're still expanded as part of compilation, not runtime.
The error message are much easier with Lisp macros as well :D
Though, we don't need any include tricks for that. Even the wiki uses just ordinary defines. #define KEYWORDS \ DEF(TOK_INT, "int") \ DEF(TOK_VOID, "void") enum keywords { #define DEF(id, str) id, KEYWORDS #undef DEF }; const char* keyword_str[] = { #define DEF(id, str) str, KEYWORDS #undef DEF }; CC /u/dioafpire
In kalmoc's example, foo may very well may be an independent header. The full definition of the return value is only needed for the function definition and at the call site. If the return value is properly forward-declared, your first-line include will work just fine, but `auto f = foo();` may still be a compile error.
Would like to add that variadic templates and parameter pack expansion are a lot like Scheme macros.
It is a lambda? This isn't metaprogramming 101, it is C++11 101.
It's story time. A couple years back I needed to interoperate with some code a coworker had written. The header files involved were full of template metaprogramming. After several hours of frustration trying to figure out the interface, I went to the author's office to ask how to do what I needed to do; I did not hide my annoyance well. He opened the header files in question and began pouring over them. After serveral minutes of scrunching his face at his monitor, he reached for a book on template metaprogramming patterns and began searching for a section. I left him to it. Out of curiosity, I checked the commit logs which showed he had written the code not 6 weeks prior. Knowing that he is generally a better programmer than me, I made a mental note that 6 weeks was the upper bound on the time after which I would no longer be able to maintain any similar code I may write. tldr: I ran.
At least they are better now that what they used to. But there are still improvements, like making it easier to find where your instantiation was wrong instead of linking to the insides of the STL. I'm like "yes VS, I know I messed up my `std::unique_ptr`, but can you bring me to my code instead of yours?"
I've heard that commenting your code helps.
&gt;CS programs are not in the business of teaching how a computer works. I think that kind of sucks though. Perhaps it is not the core concern of a CS program, but most CS majors will have to do work on a computer at some point and not know much about how one works is not great. 
The example you shown just means that your code is poorly designed. There's a lot of reason to not use Singletons (they destroy encapsulation, prevent proper lifetime management, encourage god classes etc), but one of the best reasons is that they prevent lazy coders to get in your situation :) Each class/function should only be passed the _most specific_ object it needs to do its job. This becomes a very useful hint to decide where a piece of code should go: it goes where the other components it needs to work are already. In your example, why don't you have a Size on your own component? Why don't you have at least your Window? Why does the Engine know about the Window? Why are engine and manager different things? Overall it looks like the Singleton let you plow ahead without answering any of these "how do I decouple this mess" questions, and so it's extremely hard now to get rid of it. But code designed without any singleton in mind rarely does more than 2 or 3 `get`s in a row, possibly none.
The point was it is possible to have it not-so-expensive; if you can do it better - it's even better :-). 
There are two considerations involved here: being "less likely" is one thing, and "having the whole thing crash as a result" is a completely different story. Unfortunately, C++ as such has these two things in different directions (first one pushes us towards signed, second one - towards unsigned, that is, unless we have compiler-rovided extra guarantees such as -fwrapv). 
I'm surprised that you can hold a lambda which is essentially a template. I thought it would need to be converted to a specific implementation before it had a type.. sort of like a templated class.
everyone already gave their reasons which I agree with. But to give you an example, at my previous job, I inherited a codebase where literally every single object was a singleton and those objects where used quite frequently across dozens of source files. To make matters more interesting, this was a multithreaded environment. When tracing through a codebase where pretty much every class has direct access to pretty much every other class defined in the codebase, how would you know the current state of a particular object? How would you know who last modified a particular object? It makes things vastly more complicated in understanding the flow of everything.
Thanks! Now I can be sure about it, so I changed the wording accordingly. As a side note - this kind of wording in the standard makes appearance of non-2-complement's representation even less likely. 
i down voted,since it still gives me chill when i remember when i had to use eclipse and msys for c++ development in windows.it will be a great service to poor third world developers if eclipse ide stops supporting c++. the bean counters here think eclipse ide is a free visual studio.
A generic lambda isn't a template, it's a type with a templated call operator.
ah, that makes sense. Thank you.
It's all about how you read it, I suppose. To me `if ( ptr )` is saying "if ptr is good". Whereas `ptr = false;` just doesn't make a lot of sense to me. You certainly wouldn't want to do `ptr = true;`
Your component shouldn't be asking the engine what the window size is. Whatever is creating the component should size it correctly. Planning your program's architecture is critical. Draw inheritance/dependency/coupling diagrams. If everything is controlled in a neat flow it will be apparent, but if every little component is grabbing and changing global state then your diagram will look like spaghetti. 
I agree with you, I don't even like literal 0 being assignable to a pointer to set it to null. "I mean" was a sarcastic way of saying this is devil's advocate. My issue with 0 being NULL, is it can confuse people into thinking NULL being 0. This is not a good thing, but I've seen it in code and compilers let people get away with it.
Having gone through several interviews in that area/industry recently, as long as you have a decent grasp of big O (n : iterating through items, log n : bisecting your way through sorted items or similar, and so k ) and relevant (_basic_) data structures then you should be able to get through a couple of interview stages with no problem. Read about what tools are already provided in &lt;algorithms&gt;. It was only in a handful of final round interviews that things got kind of C++ nitty gritty but even that was basic stuff picked up from having used and debugged libraries that employ templates. So my advice in a nutshell is if you've got the algorithmic basics down, go get down and dirty with some modern C++ libraries. 
I owned the v1 of this book. It didn't help me because it wasn't as fun and compartmentally useful as something like Effective Modern C++. It seemed comprehensive though and I just bought the v2 a few days ago. I keep having some kind of hope that one of these days things will just start clicking. But building a skills toolset that is horizontally useful within the template meta-programming world is going to be very difficult. Its certainly one thing to see examples and understand them, but getting to the point where you can just pull template meta-programming out when you feel like it is a mountain. I think the C++ world has recognized this and is working to provide language mechanisms which work at compile time that don't feel like tricks like meta-programming always does. 
I learned what amounts to the bare bones basics of cpp and I have no clue what the fuck any of y’all are talking about.
Yes! If a type is "going out" of a header, then yes, need to include type definition. I was thinking of a type "going in", e.g. Hdr.hpp class external_type; void foo(type&amp;);
I agree that this post doesn't do a great job of explaining why singletons are generally a bad idea. Thankfully I think people have gotten better at that over the past few years. I think Apple really did the programming world a disservice with the first few versions of the iPhoneOS/iOS SDK having so many singletons in them. Granted the way they were using them made sense (an iPhone at the time could only have one screen, one audio session, one application context, etc...) but it really led to a lot of people cargo-culting that design pattern for no reason other than convenience and the idea that it must be right because Apple does it so much.
I indent them like this as well as sometimes make a struct that extends from enable_if. It's basically a "well-named-function" but in the context of sfinae structs.
Boost 1.58 came out in April of 2015. Just saying...
You went from "if I don't use singleton, I **have** to have [insert long call chain]", but you don't 't **need to**. So... false dichotomy, really. Singletons and globals[1] are bad because they obscure your dependencies. That makes it harder to reason about what changes where in the program state (not in your example, you're normally just reading stuff) and makes it harder to unit-test (your test code now **has** to have that window prepared separately). So to improve on that, you give references to dependencies to your object. Now that becomes somewhat tricky when there's a lot of them in various places. So to alleviate that, you use an IoCC. Having said that... it really is more about being moderate. I will survive with a handful of singletons who can't be used to change much of the program state. The real trouble is when this goes overboard, which tends to happen as the codebase grows. [1] I see people here going "no need for a singleton, just do a global". Nah... singleton is a poorly disguised global...
&gt; I'm a firm believer that getters and setters are also a big consequences of this (and they suck too, but not as much as globals, I notice your code examples are packed to the gills with getters, this is terrible class design). There's quite a few good arguments about the pros and cons of getters and setters. My personal opinions aside, what do you think are the problems with getters and setters?
I have found that TMP has expanded my way of thinking for good and bad. Good because I see more dimensions in the solution space when tackling something. Bad because I have too much choice to choose from and my brain wants to evaluate them all which sometimes leads to slow decision making. That said, TMP can be very difficult to debug as the compiler doesn't provide a lot of assistance. There's a huge temptation to copy esoteric looking TMP code. The danger there is as you described - and upper bound of maintainable time. The ideal way to do it is to really understand how it fundamentally works so that you no longer think any part is magic. The code is still not easy to read, but at least you can work through it without hitting brick walls. 
In theroy, you are entirely correct. However, in the real world, there are a lot of codebases that happen to unknowingly rely on `NULL` being 0 in all the platforms they happen to be tested on.
That's only the case if using the NULL defined in `stddef.h`. If, as I have seen in some codebases, you rely on something like this to be more consistent accross platforms:: #ifndef NULL #define NULL 0 #endif Then you will be out of luck.
I did this for fun and just to do it, rather than use something that's already made but the feedback is still helpful :) I didn't know about transform.
I don't think you are off base. Programming interviews are hard to do and give. Cpp is large and incredibly complex. I'd just be honest of what parts you are comfortable with. If they push something outside your "zone of knowledge", simply say so and ask how often they tackle those problems in the job. If the answer is alot. Probably not a great place for you at this time. If they say "not often". Leave it at that and go to the next question. If they can't adjust the interview to deal with this type of question. I think it says alot about the company. I'd probably avoid it. Lastly, this is probably not the best advice. I've just been in enough bad interviews ( on both sides ) to not have the patience for the BS that can happen. Good luck! PS I'm kinda interested of what kind of problems HFT run into. Can you share a common one?
This helped a lot, actually. And shit yeah I don't know how I forgot to allow access to the data... Guess I was too caught up in the map function... Anyways, thanks for the extensive review :)
A bit off-topic from the discussion of singletons, but can you elaborate on what you don't like about ECS? Also, what kind of ECS are you're talking about? ECS definitions appears to vary depending on who's you're talking to.
If you have time for that - read the most recent version of "Effective Modern C++" by Scott Meyers. Easy way to get a deeper understanding of the language, without reading the language spec itself. 
I'm saying that in the real world it would be better to identify and fix those bugs, instead of leaving it and having it spring up at some undesirable time in future when the next version of the compiler defines `NULL` as `nullptr`.
I have written down a series of notes for things I should know and remember while I was looking for a job and doing interviews. The document has links about C++ and graphics and I try to keep it relevant and updated: https://encelo.github.io/notes.html
I won't really reply to each point you made except to say that you've grossly mischaracterized the discussion and I encourage you to read beyond the text in the OP's post. The only point I will address is: &gt; [SDL is] nowhere near as rich (or as performant) as a "proper" drawing library would be. You can get a vulkan/opengl/direct3d context. What more do you want. I think a plethora of different libraries for 2d/3d graphics are a hop skip and jump away. SDL would be orders of magnitude more useful with absolutely no changes made.
Yes but it is the shipped version with a Ubuntu LTS version. 
That’s an excellent document! Thank you for sharing. 
Just go with the flow of [this!](https://www.geeksforgeeks.org/c-plus-plus/) crazy website which prepares you specially for interviews.
Some things I think are worth doing: * Work through some dynamic programming problems in C++ e.g. something like this: http://p-nand-q.com/python/algorithms/searching/max-sliding-window.html but do it using C++11 * Work through building some kind of utility class in like a timer or a base64 encoder in C++ * Think about how you like to test your code. What are the best practices for unit testing, system testing, etc * Think about the best piece of work you did at a previous job or on a personal project and be prepared to explain it in depth. Mostly, interviews are there to try and find out how you think as well as what you know. At the end of the day the interviewer is trying to answer the question, "would I like to work with this person?" 
Why not just use a global variable?
Study the STL algortihms. That's how "it is done" in C++. Then invent your own algortihms. Don't try to imitate other languages.
&gt; setWindowSize() I agree with most of what you say, I don't know if the component in your example would be storing the window size, if so I'm not a fan of the `setWindowSize` approach, liking `get-&gt;get-&gt;get` even better. What I like best is to take window size as a function argument. With some luck the class can be immutable.
&gt; Those dependencies are provided to the Actions via their factories registered in Engine intialization code. The one thing I've never understood about this, is why no one bothered by the fact, that now Engine initialization code depends on everything and needs to be changed every time some new Action wants to call OpenLevel.
I wouldn't treat C++ interview preparation any different than another tech stack. Be prepared to solve general programming problems comfortably in C++ on a whiteboard without using a reference. You should be knowledgable enough with the standard library to know all of the containers you'll need and how to use them with the algorithms to solve CS problems. I wouldn't get hung up on having reference like knowledge of the newer c++17 features. You should know them, but I wouldn't mark anybody off for messing up the syntax of a complex nested variadic template. 
You may want to look at [served](https://github.com/datasift/served/), which has a nice way of registering URIs, and also accessing headers and variables. Maybe this is useful to you.
Especially the last remark is important. Interviewing is about finding people that fit in the team. Problem solving skills etc. are(/should be) to show your level is enough for their standard (being their other employees). But being able to work together is the most important part of the interview. This does not mean there are none that are searching for some measurable best candidate. But, unless they want a C++ genius to do everything the rest doesn't get, they have selected all their employees like that. And if you don't match it is questionable you'll fit in the team anyway.
tldr
What is wrong with the getters and setters ? and what are the alternatives, public access to my variables like structs ? Setters and getters are extremely useful because I can prevent bad things happening, and moreover it give me the ability to have control and knowledge of whats happenning to my object. Let's say one day I want to do something each time I change an attribute of one of my objects, if I already have setter for that attribute its easy, just put "handleSet(..)" inside my setter and done. Otherwise I would have to add lines of code everywhere on my project where I change the attribute. This was just one example. How can using setters and getters be so bad ?
What do you think about globally accessible rng object? It's kinda like logger - used everywhere and for various purposes.
&gt; I don't understand the hate towards singletons in c++ community. There is not hate (that I've seen). Singleton is an anti-pattern: when you apply it, it looks like you are improving your design, but the design of the solution is bad: it adds a hidden dependency on state that is out of your control (when you interact with your module through it's API). &gt; They are extremely useful and improves the clarity of the code in many cases. They do improve code clarity; Using dependency injection instead of singletons, improves the clarity of the code even more, and adds configurability to your API. &gt; I want to get information about the size of the window somewhere deep in the code. void YourFunction(std::size_t windowSize); class YourClass { public: YourClass(std::size_t windowSize); should both work. &gt; I have a windowed app, I want to get information about the size of the window somewhere deep in the code. Inject it from the outermost API (don't inject _the Engine_, just the size, if this is what you need). &gt; `this-&gt;getGuiManager().getState().getEngine().getWindow().getSize()` and this can go even longer in some cases, if you are very deep in your code structure.... This is bad design: With this implementation, your client code (the code that needs to know the window size) also needs to know (and include) the API/header of GuiManager, GuiManager's state, the state's engine, and the engine's window (when all it needed was a size to work with). When you have code like this it makes your code inflexible to change (how much code will you have to update whenever you change a GuiManager's interface? (or the state's engine API and so on)). &gt; You may say you could have passed the Engine directly to GuiManager, or even pass the Engine reference/ptr each component ! No, this would contradict the [LoD](https://en.wikipedia.org/wiki/Law_of_Demeter) design principle. If you need an engine, then inject an engine; if you need a gui manager, inject a gui manager; and if you need a size, inject a size. &gt; I want to have easily default initializable constructors without any references, I want to have a clear code... If you inject the dependency in construction: - it is explicit ("clear code") - it is easy to configure (you can provide whatever value you want) - it is limited to the value you pass (your class no longer needs to know about an engine, state, gui manager, and everything else). - it is loosely coupled to the rest of your code (if you inject a size object, you can pass in the result of getSize() in client code, but you can also define a local size object and pass that instead). - it is reusable (with your call chain - `this-&gt;getGuiManager().getState().getEngine().getWindow().getSize()` - you will need to make sure this chain makes sense in another project in order to reuse your code). If you use call chains: - it is implicit (there is nothing in the API of the class that tells you "this depends on a GuiManager, a State, an Engine and a Window, all because it needs to work with a Size). - it is difficult to configure (you probably _can_ make it work differently, by changing the size of your window; depending on your application requirements, you may not be able to change window size freely). - it is tightly coupled to the rest of your code - it is not reusable - it is not testable (well, not without defining a mock GuiManager, State, Engine and Window classes). &gt; so why the hell I would avoid using a singleton ? Because it doesn't make your code _clearer_. It makes it clearer in your implementation _where the size comes from_, but that is the useless part of "clearer code". The part it would be useful to be clearer is your public API (and with singletons, that hides things it shouldn't). It's not like I am gonna have multiple instances of my Engine, running on multiple threads
For some background, the example I've given was an issue I had a long time ago. Now my Gui system is much more improved and different. (I can init a Component without anything and add it to a Canvas later) But I still have the same sort of problem in a few other parts of my code in a project, for example in my rendering engine my Camera needs the window size for calculating its Frustum. I just hate having to pass stuff in my Camera constructor parameters just for that. Regarding resource management, I just need a global resource access I can't do without. My Material class has a Shader which by default initializes to a particular default Shader loaded during the initialization of my Engine. I want my Material constructor to be parameter free and I also like having its Shader loaded to a default because its the most used Shader on my engine. So for now I have a global access to some resources like Shaders, Meshes, Textures. Another example: I have a simple unit rectangle mesh loaded from my Engine, I use it all over my Gui, because each component is rectangular so I just use the same mesh and scale it, thanks to global access to engine resources.
I just check if the signed int is negative before performing the comparison; if it is not, safely cast it to unsigned, otherwise, the result of the comparison is known at compile time. One could also check the MSB of the unsigned int.
Wow, that's really great
I am surprised no-one mentioned the law of demeter. Code like this getGuiManager().getState().getEngine().getWindow().getSize() violates this rule so aggressively!
I don't think much differences between served's: mux.handle("/users/{id}") .get([](served::response &amp; res, const served::request &amp; req) {...}); and RESTinio's: router-&gt;http_get(R"(/users/:id)", []( auto req, auto params ){...}); More information about RESTinio's abilities in this particular area can be found [here](https://stiffstream.com/en/docs/restinio/0.4/expressrouter.html).
unordered means without order it doesn't mean unsorted. This means even iterating over it twice in a row can produce the different results. You saying a unordered container should have consistent ordering makes no sense.
A tiny bit off topic. When I interview people for C++ positions, I am more interested in the flow of how they program. I want to know how they see going from problem to solution that fits with a larger architecture. I couldn't care less if a programmer could literally do a mental optimized assembly of any C++ code if they had something against unit testing. Or if they didn't understand that the final product still needed to have full traceability to the original requirements. And that requirements themselves are changeable as long as you get everyone to buy into the changes. How code is structured. Is the person really planning on just using C, or does the person using some of the most advanced C++ that they use a lambda-regular-expression-pointer-magic-template-nightmare that nobody will understand or be able to maintain? For example. I fired a guy a few years back who templated everything, and I mean everything. We had a user_id that was pretty much set in stone as a uint32_t, yet he templated functions such as GetUsernameFromID(uint32_t). Why? Why? Why? All it did was add clutter and made code far harder to test, type, and understand. Then there are certain structures and anti-patterns that can buy you a program that won't crash so easily. For instance, there are two exactly opposite "rule" that should be followed for very solid programming. The first is to minimize scope where possible. This makes sense and makes code less confusing when rigorously applied. This way you don't have to keep so many variables in your head when looking at any given bit of code. Yet the other way to make your code solid is to preallocate as much memory as you can. This one is much harder but is used in mission-critical systems. But an understanding of where you use one or the other is often a subtle situation where you must have a greater understanding of the ebb and flow of the program running over time. So, while I can appreciate having a larger mastery of C++, the reality is that I can take the best programmers I know and probably cobble together a test that they would all fail. For instance, do you know the C++ keyword that can be used in place of a ~ when denoting a destructor? Basically, I have little interest in the skillset that is most applicable to hacking contests.
Let me try to address your examples. I don't have much experience with engine code, so some of my assumptions may be wrong, but maybe I can still be helpful: ##Camera How many Cameras are there? I'd guess from your description, that there is only one Camera. So for the convenience of one constructor call you want to make the window + its size public? I don't think, that is a good tradeoff. Also why is the camera married to that particular window? That prevents you from reusing the Camera in any other context. You may want to reuse the same camera in a scene editor, where the render surface is just one part of a bigger window, you could use it to implement split screen or to implement mirror rendering, all of which you are preventing by marrying it to the global instance of your window. I would suggest just passing the plane you want to render to to the Camera constructor. ##Resource Management I have to admit, that I also usually use a global ResourceLoader, which returns refcounted handles to the same resources, so that I only have to load every resource once. I didn't implement that as a Singleton though. I have some initialization parameters for the Loader, so it is a global variable, that gets initialized pretty early in the program startup sequence. It is zero initialized before then, so I can log all resource loads, that happen to early and fix them. Resources are already part of the global state, as you are loading them from the file system, so I see no harm in loading them through a global interface, that I can control. ## Shaders I don't understand, why your Material should care, which Shader it has to load. It is either associated to a specific shader or it isn't. So you can implement your Shader class to initialize to the default shader, if it is default constructed. But then again, you probably don't want to compile one shader for every material, you just want to compile each different shader once. For that, I would suggest loading every shader only in your renderer, which will have a list of all current shaders. Then you only need to save a ShaderHandle in each material, which can be as simple as a class wrapping a string or enum. The handle will default construct to the default shader, no need to call the Singleton. ## Rectangle Do you actually need to load a mesh for a simple rectangle? You can just have a free function, that returns a mesh initialized from a hardcoded rectangle mesh. You can also supply that function all the scaling parameters you need. This also doesn't need a Singleton. You could even implement that without the ResourceLoader.
There can be many Cameras, as you are suggesting I think I'll pass the window width &amp; height to constructor. For the Shaders, no I did not say Material own any Shader, they just have a pointer to a Shader and I set to a default Shader loaded from the engine, during its (Material) initialization. I can do without it and set it externally, but since its the most used Shader I like the way thats its being set to a default during init. Regarding the rectangle I could do well as you said but why use duplicate mesh for every single component while they're they same ? Yes I know it's no big matter
I've read it (and his other books) multiple times -- he's great. Same with Josuttis' new Template book -- also outstanding. 
Even though this is not directly C++, I'm posting this here because I find it to be relevant to the various requested metaprogrammation facilities in C++: reflection, code generation, user defined attributes, metaclasses, etc... Seeing how it's done in other languages can always be useful for C++ design I would say.
[for the lazy](https://isocpp.org/files/papers/CppDevSurvey-2018-02-summary.pdf)
I must acknowledge that stringify has less advantages over {fmt} than I though, while it also has disadvantages. Anyway, your link clearly explains how the user can add a new input types, but I was talking about adding new output type. Though I can see, after a more careful examination, that this is possible by subclassing BasicWriter. Overriding the implementation of a build-in input types just to get punctuation doesn't seem very practicable to me, but I recognize it's a possibility I didn't realize. The index in positional arguments is indeed not compile-checked in stringify, but I think this is little error prone, so it doesn't seem very relevant. Though only user experience can confirm that.
Did you have to be pre-filtered by HackerRank-like sites before these interviews? I'm not as worried about the interviews themselves, as much as getting past the initial &lt;unknown&gt; filtering.
Some did an algorithm problem set and some did a small industry relevant program as the prefilter. I rarely _aced_ either, but it was always solid code I could explain well later.
I learned about all those things in a sophomore-level class, but I don’t think that I would be super comfortable using them idiomatically in practice. Do you ask about design patterns? I feel like that would be truer test of senior-level competence.
**Company:** [Kitware](https://jobs.kitware.com) **Type:** Full Time **Description** Kitware's mission is to advance the frontiers of understanding by developing innovative open-source software platforms and integrating them into research, processes, and products. We currently have Cleraed Cpp/Python Dev position that requires TS/SCI clearance...[Cleared CPP/Python Developer](https://hire.withgoogle.com/public/jobs/kitwarecom/view/P_AAAAAADAAADHydgCg7f2Fu), **Location:** Arlington, Virginia **Remote:** No **Visa Sponsorship:** Not for this position. **Contact:** Apply via [website](http://jobs.kitware.com) 
Scala has brackets, we approve.
&gt; This release is the result of the community's work over the past six months, including: retpoline Spectre variant 2 mitigation, significantly improved CodeView debug info for Windows, GlobalISel by default for AArch64 at -O0, improved scheduling on several x86 micro-architectures, Clang defaults to -std=gnu++14 instead of -std=gnu++98, support for some upcoming C++2a features, improved optimizations, new compiler warnings, many bug fixes, and more. &gt; For more details, see the release notes: &gt;- https://llvm.org/releases/6.0.0/docs/ReleaseNotes.html - https://llvm.org/releases/6.0.0/tools/clang/docs/ReleaseNotes.html - https://llvm.org/releases/6.0.0/tools/clang/tools/extra/docs/ReleaseNotes.html - https://llvm.org/releases/6.0.0/tools/lld/docs/ReleaseNotes.html 
Of course it would be C++. Which would then allow me to create all other languages ;-). 
Nice to see the results! Linux's (slight) lead is somewhat surprising, especially since 55% of developers use Visual Studio. But I would really like to see more analysis of the results, beyond mere graphs and words clouds. Does anyone know if it's coming any time?
See my response above. What you're writing is framing things entirely in terms of public vs setter. The real main goal is to avoid *both* public and setter in the majority of our real classes. Public is only used for trivial groupings of state (e.g. `struct Point { double x; double y; };`). Avoid both, and truly encapsulate. Even the scenario you are suggesting, in my experience is very rare. People who use setters everywhere, almost never end up adding semantics to the setting call other than perhaps logging, or maybe use it for setting breakpoints. Once you have a setter, it's public, it's called all over the place, and often adding significant semantics can be a breaking change anyhow.
I believe there is too much hate around singletons. The best argument today is that they are hard to unit test, which is fair. I have worked on many systems though where it makes a lot of sense to have one and only one instance of a class, and to have that class perform a well defined service. I tend to think of singletons as microservices within my code. You have to be careful that your dependencies do not get entangled. The teams I have worked with in the past, I have not found this difficult, but it seems to be an issue in many places- I have not worked on any "mega apps" like an Office or creative suite, but have worked on fairly large projects. That said, if you find yourself with more than a handful of singleton classes, you are probably doing something wrong. 
I’m so ready to ditch MSVC as the Windows compiler for our stuff and build using Clang for all targets. Thank you everyone for all the hard work that goes into this beast. 
I work in the same field as a tech manager and have some advice for you (a little off topic): - You have a okay understanding of the problem domain. You're probably not positioning yourself correctly if you need to take online skill tests. Have you tried working your personal network or used a recruiter? Chicago is dev poor at the moment. * Once you can talk to a human drive home how you would triage the above issues. * A lot of the well meaning and technically correct advice in this thread doesn't apply to trading. * Fair number of shops on C++11. Some on 14. Few on 17. Expect that, ideally, they will want you to solve problems with whatever revision they're currently using. * Some part of interviewing is random chance. Trying to chase the target is going to be tough - especially with how tribal and pedantic the gatekeepers at the code test level tend to be. 
rust spreads quickly
&gt; You're probably not positioning yourself correctly You may be right. I've done virtually the entire trading stack, from market connectivity to core infra to trade logic to GUIs to post-trade analytics and tools. I think I could find places easier if I went for exchange connectivity or core infra jobs, but at my last job I've worked almost exclusively as a trade dev, and loved working directly with traders and quants, and I have a pretty good understanding of certain types of market microstructure and trades -- I'll keep looking for those kinds of jobs. &gt; Have you tried working your personal network For years I got jobs via my personal network, but over the past few years a lot of my network has left the industry. I had something very promising set up with a friend, but it fell thru, and that knocked me off my stride. Now that my non-compete has expired, I've started preparing again. &gt; or used a recruiter? Chicago is dev poor at the moment I have a pretty strong background and experience, so I have recruiters reaching out to me all the time. It's the recruiters themselves that talk about the first step being HackerRank/Codility/etc. I've spoken with a friend (similar background) who recently got a job out of the industry, and he confirmed that even he had to go thru all that stuff, and finally said screw it. Also, my most recent experience not being in C++ seems to be a stopping block. I had a phone screen where we talked about a ton of stuff that they're trying to do, and how I can help them, but I felt that they kept getting hung up on the recency of C++, and we ended without them asking me a single technical question. &gt; A lot of the well meaning and technically correct advice in this thread doesn't apply to trading. I agree &gt; ideally, they will want you to solve problems with whatever revision they're currently using. I agree, and I've successfully worked with not just different versions of a language, but changing languages for jobs - it's only an issue during the interview, it's never been an issue once you come onboard. There is always going to be a set of problems that you don't know how to do at the outset -- but there have been no problems that I couldn't do "eventually" Thank you for your thoughts!!!
So what you are suggesting is, let's say in the example of a GUI instead of having a Button with setters for position, action, animation etc. You would keep all that protected without any set/gets, and create a sub class of Button for each button of your GUI ? Like PlayButton, OptionsButton, QuitButton ? That doesn't seem so bad, but if you have dozens and dozens of buttons, radio buttons etc.. I'd rather have setters in that case. I mean at least the setter for the position, having to create a class just for changing a position would be painful... 
You hiring? ;)
Absolutely, I can't deal with the regressions that MSVC constantly introduces with every release, it creates too much uncertainty for our business and results in an overall lack of trust in the product. MSVC 2017 introduced a regression that prevents static builds of Qt from functioning properly in debug mode. So now our developers have to debug strictly in Linux. MSVC 2017 15.6 which was released two days ago results in the compiler being unable to match template function definitions with their declarations in many cases, resulting in incorrect compiler errors for what is perfectly valid C++ code. I can't remember a single time when a new version of MSVC 2017 was released where there wasn't a regression that forced our Windows developers to have to spend a couple of days working around the compiler and to the best of my knowledge there's no way to downgrade MSVC 2017 or install a particular version of it.
Does this include `-fsanitize=type`? That's probably my most anticipated compiler feature in years.
What is that "Party Library" and why nobody has invited me? ( /s )
Why do you update for every single release? It would be much more prudent to only update for major version releases (i.e. new VS version). 
What does it do? I googled but couldn't find anything.
IMO that's not the way to go, consider the following code (using % for clarity) void deterministic_something() { thread_local_rng.seed(someCachedSeed()); int i1 = thread_local_rng() % 12 some_other_function(); int i2 = thread_local_rng() % 54; } Here it becomes pretty clear what the issue is. If some_other_function pokes the rng, you end up with the value of i2 changing, which can be unintuitive In my opinion, the better solution is what the standard went with, of void determinstic_something() { std::some_gen gen(someCachedSeed()); int i1 = gen() % 12 some_other_function(); int i2 = gen() % 54; } Now your RNG code is independent of what happens during some_other_function, and scopes and behaves exactly like you'd expect in all circumstances Any globalifying of it at all seems to just make it harder to work with in the long term
Checks at runtime whether you violate strict aliasing. I haven't seen much written about it except the patches that introduce it (https://reviews.llvm.org/D32199 and friends).
I also made the mistake of using singletons. At first I was happy... later problems came. Lessons learned are exactly as what you say.
You can install 'inbetween' versions, if you keep offline versions. see: http://www.binaryintellect.net/articles/7b3d485f-0d2d-4721-a298-9e28adabacd0.aspx
&gt; Clang defaults to -std=gnu++14 I'm wondering, why not `-std=c++14`? Would be the better choice, right? Why would anyone want GNU rules/extensions, particularly in nowadays world of "modern" cross-platform C++11/14/17?
Not really actually. Incremental updates are better. You catch problems early, and one at a time. If you only update once every 2-3 years, you've got a very big update and will be in for lots of surprises. The upgrade will be very costly at that point, in terms of hours, costs, and technical risk/changes.
Have you contacted someone at MS? They're listening to customers quite a lot these days and sometimes even fix such issues, particularly if they concern large customers, pretty quickly.
Ditch the compiler maybe yes, but the debugger and IDE is still unmatched to date, nothing even comes close.
Don't do that. RNG is mutable observable state. It's one of the most classic examples of things *not* to ever make global. Using a global RNG like that defeats all kinds of valuable features like replays which are very important for things like automated perf regression testing, bug reporting and diagnosis, and so on. You can get "randomness" (from a player's perspective) without a global RNG. See https://blogs.unity3d.com/2015/01/07/a-primer-on-repeatable-random-numbers/ (There was a great GDC talk a year or two ago on the topic that I thought was very approachable, but I'm having trouble finding a link, unfortunately.)
&gt; Clang defaults to -std=gnu++14 instead of -std=gnu++98 This warms my heart.
throw std::party();
Probably in Xcode 10 or Xcode 11. Current Xcode 9 is based on Clang/LLVM 4.
Xcode has quite a small share, given it's the only (reasonable/sane) way to create iOS (and even proper mac) apps. I guess its popularity is (rightly so) quite low and people avoid it, whenever possible and as long as possible. :-)
I guess it's for compatibility with gcc's defaults... which again I think is ludicrous. I agree that the default should always be the ISO standard with pedantic. The extentions should be explicitly opt-in.
It's quite ridiculous. :-(
I have sometimes reported bugs yes, but not always. The Qt regression was reported when MSVC2017 first came out but still hasn't been fixed. This template deduction regression hasn't been reported by me yet but if you go on Stack Overflow you find tons of people complaining about it. Apparently this is a bug that comes and goes periodically with MSVC releases.
Thanks for that advice. Can't say I'm too thrilled to jump through hoops to do that but it's better than us constantly working around these issues.
&gt; for example in my rendering engine my Camera needs the window size for calculating its Frustum. Not really. The Camera needs to know about its Viewport. And you don't really render from a camera, you render *with* a camera. The render state/pipeline/whatever hence is fully capable of calculating a view frustrum from its active camera+viewport whenever it starts (e.g. once per frame). &gt; Regarding resource management, I need a global resource access I can't do without. My Material class has a Shader pointer which by default initializes to a particular default Shader loaded during the initialization of my Engine. None of which requires a global. MaterialResourceFactory, when initializing a Material, can set its initial Shader to the defaultShader bound in the loader (which itself was initialized by the graphic subsystem). &gt; I want my Material constructor to be parameter free Arbitrary requirement. I can toss in all kinds of useless requirements that force my hand into using globals. :p &gt; Another example: I have a simple unit rectangle mesh loaded from my Engine, I use it all over my Gui So the Gui needs a reference to it. Doesn't need to be global; just needs to be provided to the Gui. Or the Gui - which probably depends on graphics - can just create its own unit cube mesh. You're not going to be in trouble if a few different systems create their own identical copies of some basic resources like that. Using up a few extra bytes to avoid massively technical debt and deep architectural problems is worth it. &gt; because each component is rectangular so I just use the same mesh and scale it, This makes it sound like your components or Gui are free-standing objects. Also don't do that. It's not an efficient or manageable approach. A gui system should work its tree of widgets and build a draw list for rendering. The code will be smaller, easier to maintain, faster, and simpler to write. Which means the only thing that ever needs a shared default mesh in such a case is the gui system itself, not any components or individual objects. &gt; Same for text Fonts. Same situation as with the gui mesh. You don't need more than a handful of places to reference a font, because there shouldn't be code spread all over *using* a font. There should be *data* spread all over that describes text to be rendered. A system of some kind collects that data and uses a font to generate draw lists. Hence only that system itself needs to hold a handle to the font resource. Where more complex layout needs are in play (e.g., calculating the size of a box based on text) consider using a layout pass and a gui context. The context can hold a reference to the resource and is passed into the `layout` function recursively for gui objects. A more complicated version of this is used for highly efficient and accurate layout in things like browsers or production-grade desktop GUI toolkits, and works just as well for soft real-time apps like games. :) I'll repeat what I said: the "but I need X" singleton arguments are bogus. You're convincing yourself you need them because you chose to build an architecture that relies on them. Nothing you're trying to accomplish requires them, and there are games that manage to do anything and everything you're doing - and then some - without them. I 100% beyond any shadow of a doubt guarantee you that you can build any game of any complexity you can imagine without singletons or globals for engine systems, and I promise you that the end result for any game engine of large scale is going to be *simpler* and *easier* to work in without those globals.
With fear
It is unfortunately, but I hope their negligence of C++ will haunt them soon. C++ is _the_ one language for cross-platform code and app development and really can't be ignored.
So even MSVC is doing better in that regard right now ;-) They introduced `/permissive-` and announced that it will become the default in a future release.
&gt; I have sometimes reported bugs yes, but not always. The Qt regression was reported when MSVC2017 first came out but still hasn't been fixed. AFAIK, it is fixed in 15.7 with a targeted release in May. The issue was complex and required a big overhaul: https://developercommunity.visualstudio.com/content/problem/76198/vs-2017-compiler-creates-broken-debug-build-using.html &gt;This template deduction regression hasn't been reported by me yet but if you go on Stack Overflow you find tons of people complaining about it. Apparently this is a bug that comes and goes periodically with MSVC releases. Certainly, that's not the ideal stance to take. See if the bug already exists and if it doesn't report it here: https://developercommunity.visualstudio.com/spaces/8/index.html In my experience VS team has been very good at getting back to me regarding the issues I've reported even though I'm just a regular C++ dev without any big important project or company behind me.
&gt; For instance, do you know the C++ keyword that can be used in place of a ~ when denoting a destructor? Browsing the [list](http://en.cppreference.com/w/cpp/keyword), I didn't want to believe it but then I tried it and... omg.
There are dozens of us! _Dozens!_
I dream of a day this can be done without macros. Compile time introspection maybe.
Yes, `setWindowSize` might imply caching, which can lead to things getting out of sync. But signals/slots tends to prevent that.
I've always referred to kebab-case as arrow-case. Granted, its usually limited to command line arguments.
Thanks for advices. Regarding the rendering of my gui, each Component owns a SceneNode. If I want to make the Component renderable I just create &amp; attach a Model (Renderable) to its SceneNode. The SceneNodes of the Components can be the children of the SceneNode of the Canvas (which is also a Component) they may belong in. Idk if I explained well but to make short components are in a scene graph. My renderer renders the graph top to bottom &amp; left to right so I can manage the order from GuiManager for example if I have multiple Window(gui) components etc. 
Hey, BlackBerry10 OS used C++ as its first-class language. And it had the best APIs you will never use. :-(
&gt; If I want to make the Component renderable I just create &amp; attach a Model (Renderable) to its SceneNode. The SceneNodes of the Components can be the children of the SceneNode of the Canvas (which is also a Component) they may belong in Yeah, that's not uncommon. To explain more clearly what I meant: none of those things need references to global resources because they don't themselves directly *use* the resources; the system that walks the scene graph uses the global resources. The scene nodes and related components might have custom resources, but those are bound and loaded at load time, in which case a loader context object of some kind can be passed in to the load functions for each, which in turn can create dependent resources. Although it's maybe worth noting that that's a perfectly fine way to handle shared default resources if you did want your individual nodes to reference them: the resource load context can offer a default or fallback option. We did that in some engine code some years back. It worked alright. My complaint is that it made things a bit harder to debug vs explicit states. The upside is that it unifies some the code and is less branch-y. Pros and cons, as always. :) There's a whole separate debate on the merits of a unified resource loader/manager system vs individual loaders/managers for each resource type, and my opinions waver between the two. :)
I would guess most people writing code for iOS would use Objective-C and Swift, not C++, and therefore would not be included in this survey. On the other hand, Xcode place 1st in the recent survey of the most hated IDEs, so there is that.
You should avoid them because: * Of the various was they can go off the rails when you use them in a multithreaded environment. And every language has its own special gotchas for singletons. * They are commonly used for nothing more than access to a global variable (And are therefore just as bad.) * Even if you can actually justify having one of something today, you'll want two of them tomorrow. The example I heard as a good justification for a singleton was an audio device. That was back in the day when it was common to have just one on your system. Well if you want to run a separate headset/camera for videoconferencing and you designed your audio devices as a singleton, now you have a problem. As for your example, if you're a component inside a GUI, why don't you just say this-&gt;size()? That's exactly the sort of thing I'd expect to have access to in a component in a GUI. I'd also kind of expect the Component interface to provide a resize callback the GUI manager could use to resize the component when the window size changes. If you're passing around too many related parameters, you're probably missing an object that you can use to group those related parameters together. If you're passing around too many parameters, you probably need to make some more objects to aggregate functionality into.
I disagree, keeping a developers environment in a good state long term should be the goal. Comparing having a few days downtime every couple of months vs maybe a week every 2/3 years, I would pick every few years. Especially so when you're talking about a compiler, even if upgrading was seamless from a development environment perspective it would require some decent testing (especially on legacy code bases that might take advantage of UB) before I would be confident about deploying to production.
&gt; Give me a programmer who can answer these questions and I don't care if they can't program a line of C++, they can learn C++ but most programmers can't really use math in their code elegantly. One of the best teammates I had started in our team thinking that he could `dynamic_cast` from `void*` because that's how he'd do it in Java. In less than a year, he'd ramped up to the point where we could trust him to hold his own, and well. C++ is hard, but it's not impossible to pick up, and the concepts are mostly similar to a lot of other languages (the devil is in the details, of course). Pick a good programmer, and they'll do well in C++. --- On a personal note, I'm always surprised about companies who seem to recruit "similar people". I've always found diversity (of background, knowledge, interest, ...) to foster productivity. If I had to pick a team, I'd try and cover as much ground as possible: - tech stack: hardware, OS, run-time, framework, etc... - theory: algorithms, language, architectures, etc... - functionality: experience in the domain, knowledge of terms of arts, etc... which means picking people with as different a skillset as possible.
It depends how good your automated regression test coverage is. If it's good, you should be able to swap out compilers and frameworks and be reasonably confident that nothing broke if your tests pass. If there are gaps in your automated test coverage, somebody has to do some manual regression testing. In this case, in can make sense to economise on tester time by having them retest a feature once every 2-3 years when you make a big version jump, instead of having them retest the feature every month for each 'incremental' version jump. 
Well last time I failed with setting up intellisense for it. What are you using for code completions, call hierarchies, etc.?
What are you saying here? That the unpredictability of 'i2' is bad even though it's supposed to be random?
They don't need nor want cross-platform. They'd rather all devs use their own proprietary language for their proprietary OS and their proprietary APIs.
&gt; Engine is everything. It's what owns all the other modules. That's like complaining that your main function depends on everything in your application code. :p Well, if you mean semantic dependency (observable consequences of statements in main depend on everything), then sure, its unavoidable. But there is no reason to, for example, include all your headers in main. I understand that it is not what you suggesting, but can you explain how Action factories would get access to Engine subsystems without all of them being initialized inside single gigantic Engine::initialize function?
I use the C/C++ plugin made by microsoft (https://github.com/Microsoft/vscode-cpptools), it is suggested for any C++ project. Works like a charm for me!
Is it really, though? What about C# and Java?
That doesn't prepare you at all for any "algorithm" questions though, which it seems OP (rightly so) most fears.
&gt; but can you explain how Action factories would get access to Engine subsystems without all of them being initialized inside single gigantic Engine::initialize function? The subsystems tied to those actions can register them on the action system. Put simple, there's a coupling present, and that's unavoidable. If you have a system that can play sounds, that system and sounds are joined. Now, sounds don't depend on the action system naturally, so it makes sense for the action system to be responsible. So you can have something like `initializeActionFactories(SoundSytem&amp;, RenderSystem&amp;, ...etc...)`. That certainly works. You'll have a huge list of things to pass in, certainly; you could refine that a bit to take an `ActionInitContext const&amp;` that has a bunch of pointers. Or you can split it up: `initializeAudioActionFactories(SoundSystem&amp;)`, `initializeEffectsActionFactories(RenderSystem&amp;)`, etc. These might be spread across different files, or even live in different modules. Even if you make these part of their respective systems, e.g. `RenderSystem::registerActions(ActionSystem&amp;)`, making them separate functions is at least nice as you can opt out of them (e.g., I might initialize the render system in the asset pipeline for running GPU programs, but I don't need to register any action factories since I won't be simulating the game or executing choreographed actions). Someone will have to own that code, though. It doesn't have to be a member of any particular system nor deeply intertwined with a system - free functions are a thing, after all. But it has to live somewhere. Again, it's a coupling, and in this case, it's an explicit coupling, so you just have to put it somewhere. One could also go for a *loose* coupling approach. Heavily message-based architectures do this. In that case, you "just" have a simple dependency of the action system on the message system. Your `PlaySound` action then might just send a message with the name of the sound. There may not even be a specific sound action; there might just be a generate `SendMessage` action. I don't see that as a huge improvement, though. The conceptual dependency isn't gone. The action system is still dependent on audio; it's just changed from a clear pointer to a compile-time-checked interface to a vague message descriptor that's at least partially runtime-checked. Still coupled, only now it's not obvious by looking at the code, *and* a bunch of easy mistakes won't be caught by the compiler and can only be found via extensive integration tests or gobs of analysis tools. If the idea of having to put a `initializeActionFactories` function (or family of functions) *somewhere* is a problem, though, loose coupling comes to the rescue. :) It might be worth noting that things like an action choreographer or a script system are kinda special cases. They by their very nature just reach into everything. They're "glue" for gameplay systems. Most systems don't really run into these problems and are a lot more clear cut. Another way that I like to think of things to help all this is to consider layering. Different systems live in different layers and have a fairly easy set of dependencies to track. The "core" layer of systems probably includes rendering, physics, networking, telemetry and debug, core objects, resources, etc. The "game system" layer is going to contain things like script, action choreographers, path finding, etc. The "gameplay" layer has all the title-specific stuff or title-customized stuff: character customization, high-level AI, and so on. Looking at it that way, it can be a little clearer that something like action choreographer might even multiple whole stages responsible for its complete initialization of all factories. The `initializeGameSystems` entry point might be responsible for registering action factories for lower-level systems like audio, but it doesn't even know anything about higher-level gameplay systems; it falls on the `initializeGameplay` entry point to handle those cases. Or a specialized tool can just skip calling the big `initialieFoo` functions and do all the stuff manually. Which is useful. Our current engine runs into the problem where our resource pipeline has to initialize the *whole* engine because it's not cleanly separable (... because singletons!!) so just trying to repack a texture spits out all kinds of crap about audio system initialization and scanning global gameplay configuration files and all that crap. It's not good. Back to the layering thing, though, that even opens up another possibility: using singletons safely in constrained code. That is, the "core" module and its systems might have no singletons. The "game systems" module likewise, no singletons. The "gameplay" module could be a wild west wonderland of wacky ... I can't think of a w-word for singleton, but you get the idea. Gameplay is messy by its very nature and tends to be iterated on the most, so it might even make sense for a team of gameplay programmers to use singletons. And with the layering (and enforcement thereof through source structure, the build system, and DLL boundaries) you can provide hard assurances that low-level engine code stays singleton free while high-level gameplay code can do whatever it darn well pleases. :) I mean, I still *wouldn't* use singletons there, but you can leave that option open for the team responsible for gameplay code while keeping your engine code clean of spaghetti, efficiently re-entrant and race-free, and maintainable in general. *Especially* important for a larger company where the "engine" code might be shared tech across many titles while the gameplay code is naturally title-specific. :) Also useful even for a single-dev hobby/indie project if the developer plans to reuse that engine tech on multiple prototypes or games.
It's always interesting to see and work with your own code from a few years ago, and very interesting to read about other people's experience with that. Unfortunately I didn't take too much home other than "things could have been named better". I think what I was mainly missing and would like to have read a bit more about is how you designed the tree with `boost::variant` - from your text description, I have no clue (maybe that's just my inexperience). Some code (or pseudo code) and/or a diagram might really help and set more context. * In most of your sentences, there shouldn't be a comma before "that" or "what" * "it self" =&gt; "itself" 
I don't think it's unreasonable to expect microsoft to occasionally have someone look at popular communities, like stack overflow, for bugs in their compiler. Requiring anyone who runs into a problem to report it directly to microsoft, who used to have a reputation of utterly ignoring user complaints (at least, in my circles, perhaps different groups have a different perspective), means a lot of legitimate issues are going to go unreported.
&gt; Xcode has quite a small share, given it's the only (reasonable/sane) way to create iOS (and even proper mac) apps. you only need to have xcode installed, not actually run it. I ship mac versions of my software and never open Xcode, everything is done through QtCreator.
Mobile apps are often performance-critical (think gaming, AR/VR, graphics, ...), and C++ is one of the only languages that are both fairly "high-level" (i.e. convenient to code in - particularly C++11/14/17), and at the same time give you complete control of the hardware and performance. There's a reason many companies program the core of their apps in C++ (often as a library/service), and then only the GUI in the platform-native language (Java/obj-c/Swift). A good example is Dropbox, there's a great blog post or video about that from them. If you look at these domains, hardly anybody uses Java or obj-c/Swift - all libraries are coded in C++ and people are not interested at all in Java or obj-c/Swift. They are just a hassle you have to get through for the GUI part of an app (or if the company is big enough, separate people would do the GUI part in that other language). You write the core of your software once in C++, and it runs everywhere. The same is not true for Java or C#. It won't run (or won't run well) on all of Windows, macOS, Linux, iOS, Android, and Windows Mobile. Maybe for a toy-project yes, but not for anything serious.
Maybe ;-) I guess that boils down to personal preferences. The tools "accompanying" the debugger are great as well. "Edit &amp; Continue" is fantastic. The "Diagnostic Tools" are fantastic. For auto-complete &amp; stuff, try Visual Assist X. I know it's a separate tool and costs separately - but it's blazingly fast, faster than any other IDE or plugin I've tested.
I was just suggestion that the blog post would be more self-contained if it had a couple of lines of code or diagram summarising the variant-approach. :-) Yes, of course I can go and read the old blog post. (Which I started - but it seemed quite complicated to me.)
That's actually what happened. First iteration was Obj-c, then I got hired to build v2 in C++ so we could reuse it on all platforms. I don't mind the JNI or Obj-c++ wrappers as much as I use to. It's still "better code" than most of the application code I have to write on those platforms.
Thanks for your feedback, added a code example of the tree, so that you can see what the actual tree implementation is based on.
Cool! I think the example fits really well there. The fact that I didn't really grasp the implementation in the old post is more like because I am not too advanced and I probably read it too fast. I am sure it becomes clear if one really digs into it :-)
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/831kn9/i_need_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; I don't think it's unreasonable to expect microsoft to occasionally have someone look at popular communities, like stack overflow, for bugs in their compiler. It's also unreasonable to expect your bugs to be fixed if you are not even willing to report them thinking that someone else would. &gt;Requiring anyone who runs into a problem to report it directly to microsoft, who used to have a reputation of utterly ignoring user complaints (at least, in my circles, perhaps different groups have a different perspective), means a lot of legitimate issues are going to go unreported. Requiring? Nobody requires you to report anything. As well as nobody requires devs to fix unreported bugs. It's just as easy as that: you want some bug to be fixed, you report it. That's just as true (if not even "truer") for GCC and clang.
Random =/= non deterministic. Here, some_other_function could reset the rng state, or call the rng in a fashion that's non deterministic which would mess up your desire for deterministic random numbers here This is an example taken (very roughly) from a game I'm building - I simply save an rng seed to the db, and then on load rebuild the puzzle using deterministic random numbers from that seed so as to get the same puzzle every time. If other processes or threads could invisibly mess with the rng state, it would break this
how does c++ run in the browser tho
c++ -&gt; webassembly via emscriptem
Yeah, that's the way to prepare food initial screening rounds. Practice on hackerrank or leetcode. 
wasm.
&gt; The HTML output isn’t limited just to just displaying text. You can also use the SDL API to show a colored cube dear lord we have gone too far 
Hi tvaneerd. Said, we are confronted with following situation: We have an application, that communicates with some device. This specific device can always only communicate with a single client and also always can only process one request for data at once. In this case I would suggest to either use a singleton class that coordinates the access to that device inside the application, or a class that relies on another class, that coordinates access to that device (what imo also would have to be a singleton-class). What pattern would you propose?
Cool... *g Great suggestion. Can you suggest some...?
Well, the two first on google are [`boost-DI`](https://github.com/boost-experimental/di) and [`google fruit`](https://github.com/google/fruit). Of course I would also suggest my dependency injection library, [`kangaru`](https://github.com/gracicot/kangaru). With all that said, Using a DI framework may help a lot reducing the amount of singletons and code like `that-&gt;getThis()-&gt;getThat()-&gt;thenGetThat()` but require a lot of refactoring, especially in large existing codebases.
Iterating twice in a row without modifying the map gives different orders? That makes no sense, as it would imply that the order of iteration could change half-way through an iteration. A container doesn't know it's being iterated over, and therefore can't "lock down" its order during an iteration only to reorder itself once the iteration is done. 
Move construction should be delegated Now it will work with const &amp; or &amp;&amp; construction which is delegated to std::vector's construction. Data(std::vector&lt;int&gt; data) : m_data(std::move(data)) {} 
Currently the installer allows you to pick two older compiler toolsets: 15.4 with VC v14.11 and 15.5 v14.12, besides the current 15.6 v14.13 ... 
Create one instance of the class that represents that device. Pass that instance around. Maybe turn it into a pure interface, so that you can have a real implementation, and a test/mock implementation. You can then test pieces of code that use that device. Since you don't want multiple things talking to it at once, consider passing it as a unique_ptr. Or hold it in your main app class, and pass it down as a reference to whomever needs it, and hope they don't keep the reference beyond the function call.
 Q16 Do you have any additional feedback for C++ standardization? https://i.imgur.com/l7o4XOo.png
Do you have a reference for how to do that? I am checking the installer and don't see that option anywhere but would appreciate help in that area.
IDK VS isn't as bad as I used to think now that I've gotten used to some of it's "quirks", but I still prefer Xcode.
we stray farther from gods light with each passing day.
This book is great. https://www.amazon.com/Cracking-Coding-Interview-Programming-Questions/dp/0984782850/ref=sr_1_1/134-7106793-0559652?ie=UTF8&amp;qid=1520555954&amp;sr=8-1&amp;keywords=cracking+the+coding+interviews
What platform are you running the plugin on? I found on macOS the C/C++ plugin would mysteriously quit working after a few days, and I'd have to completely nuke my VS Code install and .code directories. I got frustrated and went back to Xcode. :(
Thanks for replying, /u/spongo2. I appreciate the insights, and I especially appreciate the direction your company has been going in for the last several years. You've managed to surprise me by replying directly to me, which is a good sign that at least the crowd that I'm a part of isn't completely right about Microsoft's stance on community feedback. I'd like to point out that I'm very reluctant to make yet another account on yet another service. Surely there's some way to allow logging in via Github, or Google, or other wide-spread authentication service? I've also had extremely poor results using the search features on https://developercommunity.visualstudio.com/spaces/8/index.html. Copy-pasting the error that the cl.exe process spits out at me almost always takes me to an "Internal error, we can't complete your search" page. Also, just so you're aware, copying text out of powershell into the bug report form strips all new lines. Makes formatting bug reports next to impossible. 
This seems only immediately useful for function templates which have no dependent parameters (otherwise how do you pass them in?) and also only for copyable parameters (you can't pass a `unique_ptr` to multiple invocations of a function). That places extreme limits on the applicability of the feature even were it implemented. Even with those limitations accepted, the problem space needs to be far more clearly defined. You want to re-invoke every previously-invoked instantiated function template or to invoke any instantiated function template? What about member function templates or member functions on class templates? Only explicitly instantiated function templates? Just the templates that were instantiated in the enclosing scope, the templates instantiated in the entire TU, or across the entire program? How do you want specializations handled? I mean, it's quite possible to implement at a compiler level, depending on the compiler in question (the specifics will vary for the compiler in question and details would require input from a dev experienced with said compiler). Some tricks on that stackoverflow link show how it can be faked without compiler modification. The most important question though is... why? Assuming there's some actual real goal to accomplish here, just ask about that; there may be a far better solution than trying to hack a compiler to do this thing.
I'd love to sign up as a remote tutor, not for making money but I feel that would help me as well. I'll be following this thread for any updates.
Id get all the help I can get Will skype work ? 
Linux. Write to them, they are very responsive!
&gt; Sure, that's a true statement. It is unreasonable to expect that bugs that are unreported will be fixed. But it's also not unreasonable to expect a product that involves money changing hands to involve someone proactively finding problems. So they do (as demonstrated by this comment thread). But there is no guarantee that it will be your vague comment about something not working that'd they decided to look into or that it'd wouldn't take 10x more time to fix the bug based on some complaint on SO instead of a proper report with a min repro case in the appropriate place. And you won't know if there is a workaround or when it's fixed until you manually check every new release. &gt;Reporting bugs on https://developercommunity.visualstudio.com/spaces/8/index.html requires that I make Yet Another Account, which is unreasonable. I'm not going to do that for my own personal projects shrug, and only have an account through work. I'm pretty sure you can just use your MS account that you'd use to login into Windows (if it's not local) or into VS itself (as well as other MS tools and even Skype). Also, current VS has the neat bug-reporting mechanism built-in. Just use "Send Feedback" in the upper right corner.
I am willing to help if it's needed, as I want to be able to teach C++ to others. I love to answer on stackoverflow, but I didn't had the opportunity to teach someone directly yet.
I can definitely use some help. I’m in a class where we are learning to code using c++ and I’m not familiar with shy of the concept and it’s my first time programming with c++
Gentlemen, behold https://tbfleming.github.io/cib/ ! The C++ compiler running in the browser compiling C++ into code that runs in the browser! Each year brings us closer to the [Death of JavaScript](https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript).
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/832og2/i_am_looking_for_a_tutor_or_an_instructor_to/dvepm5t/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; So they do (as demonstrated by this comment thread). Yep, I was surprised, but this is apparently true. &gt; But there is no guarantee that it will be your vague comment about something not working that'd they decided to look into or that it'd wouldn't take 10x more time to fix the bug based on some complaint on SO instead of a proper report with a min repro case in the appropriate place. Sure that's all true. But, on the other hand, I've seen lots of noise about internal compiler errors on stack overflow, and not seen anyone claiming to work on the VS team asking for help reproducing. &gt; And you won't know if there is a workaround or when it's fixed until you manually check every new release. Not really relevant to me, personally. Either I've been able to find a work around, or I don't bother trying to do something. I can't wait potentially months for Microsoft (or LLVM community, or GNU) to patch their compiler, I need to get things done. Once I've found a way to do what I needed, that work-around stays in place until I install a major upgrade and give it another try. Until VS2017, I was under the impression that those major upgrades happened rather sparsely. &gt; I'm pretty sure you can just use your MS account that you'd use to login into Windows (if it's not local) or into VS itself (as well as other MS tools and even Skype). I have neither a personal Microsoft account, nor do I use the Windows account "feature" (why would anyone...?). I don't use Windows, or Microsoft products, generally. &gt; Also, current VS has the neat bug-reporting mechanism built-in. Just use "Send Feedback" in the upper right corner. My use of visual studio is exclusively the cl.exe process, and associated command line tools. I don't use the IDE at all, and wouldn't be able to create a meaningful bug report with it, as my team doesn't use the visual studio project configuration or build system. Most of my interaction with visual studio is via the build system for my team at work, I rarely interact with it directly, and we use gcc and clang at the same time on the same code. 
I hope that they will improve codegen for the patterns used by `std::variant`. int f(std::variant&lt;int,int&gt; v) noexcept { if (v.index() == 0) return std::get&lt;0&gt;(v); if (v.index() == 1) return std::get&lt;1&gt;(v); return 0; } Currently the generated assembly looks quite awful....
Well, then the problem is understandable. But you'd also have to create an account for gcc or llvm bug tracker (and they often go into "no self-registration mode"). Though you could probably "bug" someone to create a bug for you on the mailing lists or other platform. &gt;"feature" (why would anyone...?) Meh, somewhat convenient being able to log in into all MS services via single account and share stuff over multiple machines. Kinda like google account or apple id and etc. Nothing special. If you don't really use or interact with MS products you wouldn't really need one. 
YES!!! Doing something drastic enough to actually be helpful would probably require incorporating breaking changes into the language... but look at the success python is having after it introduced breaking changes in python3!
Just using that list I can come up with a test that I will fail. synchronized(looks cool), const_cast, thread_local, alignof, alignas, #line. So you could give me a test saying, "Use the following keywords in a short program." and with many, I would just sit there going. "Um, no" 
[Come to C++now](http://cppnow.org/announcements/2018/02/2018-call-for-student-volunteers/)
There were also enormous bugs related to the executables generated with optimizations. Turning optimizations on would cause binaries to crash. 
I've seen them reply to people asking for examples of bugs, but when given, they don't respond any more.
Java people have some interesting tools they like to use. I know a guy who wanted to learn C++ and he hyper-focused on pure virtual functions, got stuck (surprise surprise) and gave up on C++ in frustration. I tried telling him that you can go a long way without using that but he spun his wheels anyway. His goal was to use C++ exactly like he used Java and I tried to tell him that while the syntax is very close, the languages are actually far apart. I have had programs that I have needed to port to or from Java/C++ and it was hard. Whereas I have had programs that I needed to port to/from C++/Python and amazingly in many cases I was able to copy paste the code and then quickly modify it into the correct language structures etc. Strangely fast. 
VS getting slower and intellisense showing errors everywhere after a clean compile is the VS experience. The debugger and the auto completion is what keeps me coming back for pain.
Swift is not a proprietary language, it is licensed under the Apache License 2.0. Their OS is also no longer proprietary, although it used to be. Their OS is now licensed under the Apple Public Source License, which has been approved by the Open Source Initiative and the much more strict Free Software Foundation. As for APIs, currently APIs are not proprietary and have no legal protections other than trade secrets or NDAs, but as the APIs are publicly available and disclosed, Apple has no mechanism to protect such intellectual property so I'm not sure how that statement is justified. It's ironic that /u/sumo952 claims that Apple has neglected C++ since Apple is the main contributor to clang, for whom this very submission is the subject of.
&gt; Dang, I'm a small minority. That's great! We need more minorities in the C++ community. And don't worry about your diminutive size - there are work places specially catered to your shape, such as [google's work pods](https://pbs.twimg.com/media/DXeJ1P4VoAAFmUA.jpg).
I'm not using the VS IDE anyway...
Go to 'individual components'; they're in the 'compilers, build tools, and runtimes' section.
Maybe they should test it on big opensource code bases. That Qt thing is unconscionable. It's not exactly a toy code base. They should have it as a part of their extended test suite for the compiler. Qt, just like any big project, has a test suite - any regressions on compiler changes should be investigated, categorized and acted upon...
Yeah, LTO + static binaries is still a mess. Unusable. Sigh.
Swift barely works on anything but Apple platforms and barely has any use outside of them. You can use Objective-C outside of Apple platforms too, you know. Yeah, it's true that some of their projects are released under some open source license, but it's not that much different than looking at the source code of windows (that was too released and then leaked). Also, obviously when was I talking about API being proprietary I didn't mean it in the literal sense since you can't patent an API (though companies tried to do so numerous times and will undoubtedly try again). I used the word in the more general sense of "specific to one device or, more likely to a number of devices within a particular manufacturer's product range." usually to enable vendor lock-in. Apple consciously tries to foster vendor lock-in by the means of the reinventing the square wheel and ignoring open standards (what was the latest version of OpenGL supported by their OS? What prompted them to create Metal instead of adopting Vulkan?). And that sort of behaviour is exactly what I'm talking about. Some of their software may be de-jure open but de-facto they are not much different from the Microsoft. Though Microsoft doesn't restrict you from choosing your hardware. There is no such option with Apple. Though this doesn't negate the fact that they've made (and continue to make) some great contributions to the open source community. Though nowadays this can be said to some extent about almost any big software company.
On iOS, you can go through Obj-C++, but that's not necessary. All of Obj-C is available via C-only APIs that can be wrapped with generated C++ classes. My high school classmate has a small app development company and they develop for both OS X and iOS purely in C++, without any Objective-C/C++ code at all. They adopted an approach similar to C++/WinRT and machine-generate the adaptation layer. But even the adaptation layer doesn't use Obj-C. The generated code uses the low-level ObjC runtime APIs - precisely the same ones that are called by code generated by an ObjC compiler.
? But it will let you generate Ninja files for Clang on Windows. No IDE required. It's right in the [user manual](https://clang.llvm.org/docs/UsersManual.html#clang-cl): ``` cmake -GNinja -DCMAKE_C_COMPILER="c:/Program Files (x86)/LLVM/bin/clang-cl.exe" -DCMAKE_CXX_COMPILER="c:/Program Files (x86)/LLVM/bin/clang-cl.exe" .. ```
No it’s not. Clang 5.0 was like five months ago. The LLVM project switched to a must faster major version upgrade schedule. Clang 4 was on master when Xcode 9 was released. Hell, half of the biggest contributors to LLVM are Apple employees. 
Swift uses clang and llvm. 
You don't seem to understand some people don't want to use clang-cl.
I believe the radical shift we need is a next-generation, native build system that is well-integrated with the project/package dependency management -- the experience of Rust and Go shows that this is the way to go. We need this to change the way we are building C++ in the same way git changed the way we changing our code.
You have many good points that I agree with, but some stuff I would like to dispute: &gt;Swift barely works on anything but Apple platforms and barely has any use outside of them. Swift doesn't work on Windows no but not due to it being proprietary or because of vendor lock-in. Rather there's just not much demand for using Swift to develop Windows applications. Windows has its own ecosystem with C#/.NET that is very well suited for it. Honestly even if Swift was available on Windows I don't think many people would use it, including myself. However... Swift works perfectly fine on Linux and in fact Apple provides a great deal of support for writing server side applications in Swift using Linux as no one in their right mind will use a Mac to run server applications. You can refer to this to see the list of contributors to Swift for server side development, the Swift Steering Committee includes participants from IBM and other (mostly smaller) companies: https://swift.org/server-apis/ &gt;(what was the latest version of OpenGL supported by their OS? What prompted them to create Metal instead of adopting Vulkan?). The latest version of OpenGL supported by macOS is OpenGL 4.1 which is older but it comes included with the operating system, no additional download or update is needed. Do you know what version of OpenGL comes with Windows 10? OpenGL 1.1. If you want the latest OpenGL for Windows you get it not from Microsoft but from your video card's vendor. This isn't all that unreasonable to be honest, but it is rather unusual to say that Apple doesn't support OpenGL in their OS when in fact the OS comes with native drivers for the latest version of OpenGL and Windows comes with a software based emulator that works with a version of OpenGL 1.1 that's 21 years old. At any rate, my opinion and frankly the opinion of many game developers and graphics developers is that OpenGL is simply garbage. Microsoft won that battle with DirectX, which is as proprietary as it gets but in spite of that DirectX is a very ideal API that strikes an almost perfect balance between low-level access to hardware and high level expressiveness. I'm not qualified enough to know about Metal compared to Vulkan, never used either of them, but my suspicion is that they will both be poor competitors to DirectX. At any rate, your other points are things I somewhat agree with. I think you painted a very absolutist picture about Apple being proprietary and locking developers down with your original comment. Their hardware is proprietary and closed in an absolute sense, yes. But their software is fairly open, maybe a little less so than Google, but leaps and bounds ahead of Microsoft. And as I mentioned originally, clang, which is probably the most standard compliance C++ compiler is originally an Apple product and Apple continues to be the main contributor to it.
Yes, "stop" "moving forward" is an unfortunate and amusing combination.
You're right, since Obj-C is already just C with some fancy pre-processing, but going without Xcode for an UI app means writing all of UI code and layout by hand, which is not very fun (though I know some people who say that WYSWIG UI editors are a curse on humanity, I still think it's good to have one). You can build your own UI editor, of course, but it's usually out of scope for a small company (we, for example, have UI viewer - which allows to quickly preview changes in UI layout files for our UI library - but you have to edit files by hand).
Obj-C is better in that respect. Java/JNI... Well, let's say that even with our wrapper, which I consider to be good, it's still pain. I thought about rewriting out Store code in C++ with JNI calls to API, without Java on our side, but it's not convenient at all. I'd have to spend much more time on the wrapper to make it more-or-less automatically wrap Java objects, and it the end we'll still have to have some Java because onActivityResult has to be intercepted on its level (we can't easily use NativeActivity, because we need to integrate 3rd-party Java libraries which often need even more things on Java side).
&gt; I don't like the last one because it's harder to indent when breaking it into multiple lines, and it's less readable when there are many arguments. I can tell this from my experience when writing the unit tests and examples. The current syntax is the one which I find more readable, though I agree it's weird at first sight. I think you'll find that vanishingly few people agree with you here. Using existing idioms is extremely important. Violating expectations should not be done lightly, and should only be done if it offers a dramatic advantage over the more conformational alternative. 
&gt; As for APIs, currently APIs are not proprietary and have no legal protections once they're made public I guess we'll have to wait until somebody makes an equivalent of Wine but for Apple's APIs.
Here is my code so far. Sorry if it's bad or messy. Still trying to get the hang of coding in general
#include &lt;iostream&gt; using namespace std; int main() { const int MIN_NUMBER = 1, MAX_NUMBER = 25; int student; cout &lt;&lt; "Hello! Please enter the number of students in class." &lt;&lt; endl; cin &gt;&gt; student; for (int i = 0; i = student; i++) { if(student &lt; 1 || student &gt; 25) { cout &lt;&lt; "Invalid number of students. Please enter the number of students again (1-25)." &lt;&lt; endl; } else { cout &lt;&lt; "Here is the list of the students in order of their first name." &lt;&lt; endl; } } return 0; } 
Not really comparable at all. Maybe 15 years ago but GCC has had excellent standards compliance for a a long time and it has had flags to turn on strict compliance, something VC only got in the last year.
What? That doesn't make sense on any level. Toolchain developers don't do marketing and marketers don't understand upstream merges. master Swift presents a dependency on master clang. No idiot is going to permit ridiculous marketing influenced dependencies in projects as complex as llvm/clang/swift. 
Short of having massive amounts of technical debts, MSVC is generally doing the right thing ¯\\\_(ツ)\_/¯
thanks, I agree that we still have a lot of work to do to make developercommunity better. I've passed your feedback on to the leaders of the team that develop that site (and fwiw, I agree). in the meantime, just to clarify, there are actually multiple ways to report bugs and one of them is "send us an email". the official docs on how to report issues were recently refreshed by us and are stored here: https://docs.microsoft.com/en-us/cpp/how-to-report-a-problem-with-the-visual-cpp-toolset#ways-to-send-your-report . We also have recently started trying to monitor stackoverflow more systematically, but it's not as well covered as the other three ways in that post.
Whats wrong with Xcode? I think it is excellent for C and C++. The built in debugger is powerful and useful, and the linting is very good if a little slow. Hell I even use it for MPI and openMP. It is quick to set up a project and easy to use.
I also appreciate the general responsiveness of your team. Adding to what jonesmz said, I found the experience with using the official bug tracker pretty bad. First of all: Why does Microsoft display my name on a public page, when I send a bug to MS? Second, formatting support was also pretty bad (maybe it improved by now) IIRC standard markdown didn't work and I think, there was no way to preview the submission. Honestly, I'd suggest just just license the engine from SO. That seems to be what you try to emulate anyway. Third, the is no help anonymising my data (e.g. remove user name from folder paths in the compiler log). Fourth: There is no help in composing the necessary information: If I get an ICE and I want to report it from VS, I should not be required to manually write things like VS and/or SDK version. It would also e.g. be a nice feature if VS would automatically extract all necessary files and compiler commands to reproduce it (of course giving me the chance to edit them before submission so I can bring it down to a more minimal example). Sorry if some of those points are outdated by now. I haven't used the bug tracker for some time now.
I feel like VS2017 is quicker than VS2015
&gt; the experience of Rust and Go shows that this is the way to go. The experience of Go at least is pretty terrible. Everything is statically linked because different projects require different versions of the same library, so they each need their own copy. The problem is at least partially cultural though, with the "lots of small libraries" development style leading to a proliferation of dependencies.
They are responsive, but the problem now is rolling breakage. On average, it seems to take two point versions for a codegen bug to be fixed. For the codebase I'm working on, had to work around a codegen bug introduced in 15.3, which was fixed in 15.5 but that version then introduced another codegen issue, which is scheduled to be fixed in 15.7. On top of that the debugger has been throwing exception errors randomly since about 15.5. I have the release build machine parked on 15.4 because I simply don't trust the stability of the current releases right now. 
AppleClang doesn't even have a working `&lt;optional&gt;` yet... :( (There is "something" under `&lt;experimental/optional&gt;` but it's non standard-conformant, has different member function names, and the functions are not exported into the library).
I compiled my MIPS virtual machine with Emscripten and executed binaries... so you could also run that browser in a VM in your browser!
Correct me if I'm wrong but the only people who can decide what to do with the results are the C++ Direction committee, right? My point is that I don't see any of the results or word-cloud keywords affecting the members of the working groups.
The main difference is that you could bring g++ into a pretty conforming mode for years. With msvc prior to VS2015 this was pretty impossible and even now, compiling standard conformant template code can be problematic.
&gt; Their OS is also no longer proprietary [...] Feel free to download the OS and build it yourself I am not an expert on licenses but something is off here. It is not even legally possible and allowed to run macOS on anything but a Mac. Not even in a VM. You tell me this is not proprietary or even open source? Apple employees contributing to LLVM is different (and probably a whole different department) than the people making decisions in Xcode regarding C++. What I mean with "Apple is neglecting C++" is not that Apple is not contributing to LLVM. It is that Apple is neglecting C++ devs on its own platform, and C++ and keeping AppleClang updated is, as can be seen by the current version, a non-priority for them, which is neglecting every C++ dev that is stuck on having to have their code compile with XCode 9. Btw this is guessing without researching, but I guess that they use LLVM for Swift (and potentially obj-c?) so their interest in LLVM is maybe much larger than "just" C++.
Go might have made some questionable implementation choices (and is about to make [some more](https://research.swtch.com/vgo)), but the idea of a single build toolchain (the `go` command) is good one. In fact, I don't even advocate for a single build/project/package management tool like `go` or `cargo`. I think directly using the build system for building, package dependency manager for consuming packages and project dependency manager for developing packages is perfectly reasonable (just like we use a VCS to manage changes).
I would actually write/default the copy constructor, so that you don't have to write IpType res_ip = { {0}, ip.bitmask }; all the time. Then I would also add an value type for ip structs: struct v4 { static constexpr size_t size = 8; using value_t = uint8_t; using data_t = std::array&lt;value_t, size&gt;; Then you could simplify all the bit operations template&lt;typename IpType&gt; IpType operator~(const IpType&amp; ip) { IpType res_ip(ip); std::transform(begin(ip.data), end(ip.data), begin(res_ip.data), std::bit_not&lt;IpType::value_t&gt;{}); return res_ip; } Ahh yeah and just write a static assert instead of the comment for template&lt;typename IpType&gt; struct ip&lt;IpType, false&gt; { static_assert(false, "Only IPv4 and IPv6 supported!"); }; 
Does visitation look better (I don't expect it to, just curious)
Indeed, I was missing this capability :-)
Just saying: open source and "licensed under..." is certainly not the same as non-proprietary (e.g. standardized).
&gt; Feel free to download the OS and build it yourself by following these instructions: Incorrect. No, this is not an OS. This is just a kernel. None of the userspace is open source. As others mentioned, you are also not allowed to run it on anything other than Apple hardware. &gt; WebKit, their browser engine which is also used by Google Chrome is also open source Technically partially incorrect. Chrome uses Blink, which forked off Webkit 4 years ago, and since then developed separately. But yes, Webkit it is open source. &gt; It's ironic that /u/sumo952 claims that Apple has neglected C++ since Apple is the main contributor to clang for This is also not correct. While this was true for most of the clang's history, as others correctly mentioned, Apple reallocated their resources to Swift lately an pay much less attention to Clang. If you look at [contributors](https://github.com/llvm-mirror/clang/graphs/contributors) on Github, top three contributors were indeed from Apple. But they all ceased their activity on Clang 2-3 years ago. Of active contributors, the top one Richard Smith, from Google. If you look on [last month's activity](https://github.com/llvm-mirror/clang/pulse/monthly), from top contributors who I could identify, most are from Google, and only one (in second place currently) is from Apple. So, facts are actually on the side of /u/sumo952 : apple indeed slowed down activity on C++ front last couple of years. &gt; Basically... absolutely nothing you've said is true. One could say that about your post.
It is nice to see that you can compile c++ to run in a Browser. That doesn't make c++ a competitive language for must kinds of web applications.
&gt; whenever working with on perfect code "whenever working with on perfect code" - so, in other words, never
From ~ 1991-2005 I developed on the MS stack, much of it C++. And it was rock solid. Since then I've been *nix / gcc and its got lots of problems, but it pretty much works. I'm kind of stunned at the comments in this thread along the lines of 'every VC release breaks something'. If that's BS, then fine. But if you believe it's true there's something seriously wrong. 'Move fast and break things' is fine for stuff up at the top of the stack where there's little in the way of dependencies. But if you're at the bottom of the stack - and the compiler comes pretty damn close - that attitude is just death. As a somewhat unrelated aside, I think SatyaN is a huge breath of fresh air and VSCode is really magnificent (although I can't figure out the business purpose, but whatever.)
Yeah, std::variant being a library type is imho pretty unfortunate (just like a few other vocabulary types). But imho, the compiler should - in principle - be able to optimize through a constexpr array of function pointers (not just in this context) and generate the equivalent of a switch block on the fly.
LLVM uses something similar in their code base. You can Google for their development guide which explains it. Not sure how easy it would be to leverage though.
Oh yes please
Some_other_function could very easily reseed the rng, which would break everything
The order of iteration cannot change unless the container is modified, in theory or practise. For the reason I mentioned above. It's not an implementation detail, it's how iterators work.
Assuming this post is accurate (thanks btw, this was the best explanation I have read so far, not that I looked for other ones though:) wouldn't it be more consistent to name lvalues as plvalues (pure lvalues, equivalent to prvalues) and call the whole identity column lvalues (instead of glvalues)?
Well, someone will always use something different. Here is the Qt run on wasm: https://msorvig.github.io/qt-webassembly-examples/ So the answer to the question "how does c++ run in the browser tho": pretty well (given the infancy stage).
We need to go deeper!
Relevant Stack Overflow [post](https://stackoverflow.com/questions/3601602/what-are-rvalues-lvalues-xvalues-glvalues-and-prvalues).
&gt;I would actually write/default the copy constructor, so that you don't have to write &gt; &gt; IpType res_ip = { {0}, ip.bitmask }; &gt;all the time. &gt; &gt; &gt;Then I would also add an value type for ip structs: &gt; &gt; struct v4 { &gt; static constexpr size_t size = 8; &gt; using value_t = uint8_t; &gt; using data_t = std::array&lt;value_t, size&gt;; &gt; &gt;Then you could simplify all the bit operations &gt; &gt; template&lt;typename IpType&gt; &gt; IpType operator~(const IpType&amp; ip) { &gt; IpType res_ip(ip); &gt; std::transform(begin(ip.data), end(ip.data), begin(res_ip.data), std::bit_not&lt;IpType::value_t&gt;{}); &gt; return res_ip; &gt; } &gt;Or do it even more fancy :-) &gt; &gt; template&lt;typename IpType, template &lt;typename&gt; class BitFunc&gt; &gt; IpType applyBitFunc(const IpType&amp; lhs, const IpType&amp; rhs) &gt; { &gt; IpType res_ip(lhs); &gt; std::transform(begin(lhs.data), end(lhs.data), begin(rhs.data), begin(res_ip.data), BitFunc&lt;IpType::value_t&gt;{}); &gt; return res_ip; &gt; } Ahh perfect, I'll incorporate this. Thanks for the feedback! 
Sure if you use WinRT. But nobody does unless forced to.
Yes, it would. My understanding is that they did the naming "asymmetrically" like that in order to keep *lvalue* and *rvalue* as close as possible to their original (pre-C++11) meanings, which makes sense. But IMO that little inconsistency is the cause of most of the pain in learning value categories. It would be much easier if we had plvalue/lvalue/xvalue/rvalue/prvalue, or lvalue/glvalue/xvalue/grvalue/rvalue, rather than lvalue/glvalue/xvalue/rvalue/prvalue.
&gt;What prompted them to create Metal instead of adopting Vulkan? The remarkable scarcity of time machines.
Yeah... You might be right about that.
The issues you have here are (1) you should validate input before entering the loop; (2) you want to print 1, 2, 3, ..., student, so you want to start your loop at 1 and progress it each time until i is student; (3) your comparison in the loop was wrong (you were accidentally doing an assignment (like x=2), instead of a comparison (equals would be ==, but in this case you wanted &lt;=, since you wanted #students iterations, and you were starting at 1)). A lot of times when you're dealing with output for humans, you'll find yourself writing loops that start at i and progress until they're &lt;= to something, since humans don't like zeroes. But for most for loops (e.g. over arrays, when you get to them), you'll start at 0 and progress until you're &lt; target value. Both of those forms: | for(int i = 0; i &lt; target; ++i) and | for(int i = 1; i &lt;= target; ++i) Result in #target iterations, but one way will start at zero and the other will start at one. Something that works for me is to write comments for each thing I need to do in a procedure, then fill in the code: | // Declare constants - input bounds | // Get user input for number of students | // Validate that input is within our bounds | // If the input is out of bounds, exit the program with an error | // Loop from 1 to # students and print out the number each time As such, you code looks something like this: | include &lt;iostream&gt; | | using namespace std; | | int main() { | | // Declare constants - input bounds | const int MIN_NUMBER = 1, MAX_NUMBER = 25; | | // Get user input for number of students | int student; | cout &lt;&lt; "Hello! Please enter the number of students in class." &lt;&lt; endl; | cin &gt;&gt; student; | | // Validate that input is within our bounds | | if(student &gt;= 1 || student &lt;= 25) | { | cout &lt;&lt; "Here is the list of the students in order of their first name.." &lt;&lt; endl; | } | else | { | // If the input is out of bounds, exit the program with an error | cout &lt;&lt; "Invalid number of students. Please enter the number of students again (1-25)." &lt;&lt; endl; | return 1 | } | | // Loop from 1 to # students and print out each number | for (int i = 1; i &lt;= student; i++) | { | cout &lt;&lt; i &lt;&lt; " "; | } | return 0; | }
This is an embedded device. You connect it to your PC through a serial post, and then use a serial terminal program like PuTTY, minicom, etc. to communicate to your device. 
ಠ_ಠ
Yes but you have full control over what that function does, if it needs a random number then pass one to it or the generator itself. Your requirments are questionable, not the idea of thread local rng's
That is a long discussion. What exactly are you upset about?
If you write a POD object into a memory location, that should be defined behavior as long as no non-POD object resided at the same (or overlapping) memory location before the write.
&gt;Windows has its own ecosystem with C#/.NET that is very well suited for it Btw, some good comparisons can be made with open source .NET Core and Mono. &gt;However... Swift works perfectly fine on Linux and in fact Apple provides a great deal of support for writing server side applications in Swift using Linux as no one in their right mind will use a Mac to run server applications. We'll see but it doesn't look like anything more than "racks of mac minis running mac os are a horrible abomination so let's let apple devs program for linux or otherwise they'll switch" kinda deal. The language that doesn't offer any significant advantage over existing solutions and which likes to break your code with each new release doesn't seem like a good fit for a serious server-side programming. &gt; The latest version of OpenGL supported by macOS is OpenGL 4.1 which is older but it comes included with the operating system, no additional download or update is needed. &gt; &gt; Do you know what version of OpenGL comes with Windows 10? OpenGL 1.1. If you want the latest OpenGL for Windows you get it not from Microsoft but from your video card's vendor. This isn't all that unreasonable to be honest, but it is rather unusual to say that Apple doesn't support OpenGL in their OS when in fact the OS comes with native drivers for the latest version of OpenGL and Windows comes with a software based emulator that works with a version of OpenGL 1.1 that's 21 years old. &gt; &gt; At any rate, my opinion and frankly the opinion of many game developers and graphics developers is that OpenGL is simply garbage. Microsoft won that battle with DirectX, which is as proprietary as it gets but in spite of that DirectX is a very ideal API that strikes an almost perfect balance between low-level access to hardware and high level expressiveness. &gt; &gt; I'm not qualified enough to know about Metal compared to Vulkan, never used either of them, but my suspicion is that they will both be poor competitors to DirectX. &gt; &gt; At any rate, your other points are things I somewhat agree with. I think you painted a very absolutist picture about Apple being proprietary and locking developers down with your original comment. Their hardware is proprietary and closed in an absolute sense, yes. But their software is fairly open, maybe a little less so than Google, but leaps and bounds ahead of Microsoft. And as I mentioned originally, clang, which is probably the most standard compliance C++ compiler is originally an Apple product and Apple continues to be the main contributor to it. &gt;I'm not qualified enough to know about Metal compared to Vulkan, never used either of them, but my suspicion is that they will both be poor competitors to DirectX. &gt;The latest version of OpenGL supported by macOS is OpenGL 4.1 which is older but it comes included with the operating system, no additional download or update is needed. &gt;Do you know what version of OpenGL comes with Windows 10? OpenGL 1.1. If you want the latest OpenGL for Windows you get it not from Microsoft but from your video card's vendor. This isn't all that unreasonable to be honest, but it is rather unusual to say that Apple doesn't support OpenGL in their OS when in fact the OS comes with native drivers for the latest version of OpenGL and Windows comes with a software based emulator that works with a version of OpenGL 1.1 that's 21 years old. That's not entirely correct. You install windows, and you'll automatically get your graphics drivers from windows update. They might be not the most up-to-date ones but they'll still have a better API support than on an Apple system (provided the up-to-date hw). So here is the situation: on Apple you are stuck with 8 years old API or proprietary Apple one. Even though the same hardware on windows or linux supports the latest API just fine. You can't do anything about it. You have no choice to install some newer drivers. You've basically have what've been bundled with the OS and that's ALL. And they can do it because the HW on which macOS runs is very restricted. So it's not about "what comes with it". It's about "what works" with it. &gt;At any rate, my opinion and frankly the opinion of many game developers and graphics developers is that OpenGL is simply garbage. Microsoft won that battle with DirectX, which is as proprietary as it gets but in spite of that DirectX is a very ideal API that strikes an almost perfect balance between low-level access to hardware and high level expressiveness. OpenGL is not great. So is DX (especially pre 11). But until Vulkan it was the only choice if you want to deliever cross-platform game. Not to mention there is no DX on mobile (ignoring almost non-existent winphones). Vulkan has all the potential to become One-API-to-rule-them-all and it almost did. It's supported on any platform (mobile included) besides Apple ones currently because they've decided to go with their own which offers no real advantage other the competition. &gt;I'm not qualified enough to know about Metal compared to Vulkan, never used either of them, but my suspicion is that they will both be poor competitors to DirectX. In fact it's the opposite. Almost no one uses DX12 (DX answer to Vulkan). Vulkan is actively spreading on the other hand (every somewhat major engine has support for it). The only reason why the Metal is used is because there is no alternative. You either use outdated openGL or their custom API that only works on their devices. Thank god that something like [this](http://store.steampowered.com/news/37575/) exists now.
&gt; if iterate touches only local data and scratch, under C++ the compiler knows count cannot change, and it can cache the value. Under your rule, it has to either prefix the code with a pile of aliasing checks, or reload everything from memory. &gt; That sucks. That code sucks. You should copy count into a local variable before the loop. Furthermore, your criticism also applies to C. Do you think C sucks? &gt; As for "memcpy is expensive", run this through any modern compiler: Do that in the middle of other complex code.
And loathing
I checked the experimental compiler on godbolt and it seems to be failing when using "Runs Herb's examples": https://cppx.godbolt.org/ "Latest trunk" outputs the generated code with no "virtual int function() = 0;" present.
This always makes me giggle. It's so absurd :D
I have to say, the example on page 2 is pretty distressing: This is UB: switch (*reinterpret_cast&lt;uint16_t const*&gt;(buf)) { case MsgA::value: handle(*reinterpret_cast&lt;MsgA const*&gt;(buf); break; case MsgB::value: handle(*reinterpret_cast&lt;MsgB const*&gt;(buf); break; // ... } This is not: uint16_t msgType; memcpy(&amp;msgType, buf, sizeof(msgType)); switch (msgType) { case MsgA::value: { MsgA msg; memcpy(&amp;msg, buf, sizeof(msg)); handle(msg); break; } case MsgB::value: { MsgB msg; memcpy(&amp;msg, buf, sizeof(msg)); handle(msg); break; } Basically, this is saying that the 100% standard way in which everyone writes code that reads binary data off the wire is UB, and the only way to make it not UB is to introduce `memcpy`s that you have to pray are optimized away. This seems like a pretty ridiculous state of affairs (especially if it is really undefined and not unspecified).
This one at least I can just downvote and move on, unlike the previous one where I was torn between downvoting for the title and upvoting for the content that I just wish was better presented.
Singletons are extremely useful when wrapping communication with external libraries that are not thread safe and themselves are limited to being used as a singleton. I challenge you to find a better solution, we could use it :D
Hint: it doesn't always compile to zero instructions. https://godbolt.org/g/EJDj2v. Unless you can tell me what's wrong with this example (or maybe clang 5.0 isn't "modern"). I mean, seriously, what are you doing? You're defending having to write *more*, potentially *slower* code to satisfy UB demons, by saying that it will optimize away, in this one case. Nobody who writes high performance networking code is going to do it this way, and my example above shows exactly why.
Thanks for the info!
in Las Vegas
Why do you want to do that? As is your feature wouldn't be nice, as in some cases, it is left to the implementation whether a template is instantiated implicitly (e.g. overload resolution). That would mean that your feature would be implementation defined without any further change to the Standard. Without a very compelling use-case, I doubt the committee would accept such a major overhaul of implicit template instantiation rules.
Does there need to be a rule about it? The community has downvoted this one to oblivion on its own. While I agree the other one was needlessly antagonistic, it created an informative discussion so I'd hate for it to have been removed outright for the title.
Perspective of someone who interviews and hires C/C++ developers, mostly for embedded systems: I usually first ask candidates to rate their own proficiency so I can scale the questions accordingly. If they reply 8/10, for example, I'd start with tough questions on dangerous pitfalls and misconceptions, and then adjust the level according to the quality of the answers. If they modestly reply 4/10, I'd start with common language concepts instead, then adjust as well. This results in a process that feels natural to both parties. Moreover, it says a lot about the personality in general (do they overestimate their abilities, do they know exactly where they stand, or do they approach situations too humbly?). One thing I really like to do in interviews is code reviews. It doesn't build up the pressure of programming under observation and tight time limits, but gives a very good impression of how a candidate thinks about code. It's not only about the question whether they spot the terrible error (e.g., a race condition, a deadlock waiting to happen, or a potential buffer overflow), or get lost in meaningless style discussions, or even diagnose bugs that really aren't bugs simply because they know they're supposed to find something. It also reveals a lot about the general intellectual approach to problem-solving (e.g., do they approach the code snippet in a top-down or a bottom-up fashion, do they respect the connection between code and requirement, do they think about portability or efficiency, etc.).
&gt; and themselves are limited to being used as a singleton. I have actually some wrappers for things *kinda like* that. Technically not a singleton but just global IO code that's extra finicky for Reasons(tm). We have a wrapper "singleton" (as in, there's only one) but it's _not globally reachable_. An explicit handle is passed to the modules that need it. The wrapper is not constructible outside the initialization code that creates it so we know there's only ever one instance. The wrapper then handles all the various error-handling and IO locking required to do the IO operations *correctly*, as opposed to using the raw core IO routines that require gobs of error checking and recovery code for our uses. That said, if you have a low-level library that ties your hands... well, good luck. You can't build a strong castle on foundation of sand. :p (remember, when we're complaining about singletons, we're really complaining about *global mutable state*. the general CS concept of a singleton object - an object of which only one instance can exist - isn't problematic. it's the design pattern that enforces singleton-ness via global state and then exposes all that state and the singleton itself to application code that's the evil part.)
**Company:** [Zühlke Engineering](http://www.zuehlke.com/) **Type:** Full time / Internship **Description:** We develop products for all sorts of markets, e.g., medical devices, IoT solutions, industrial applications, VR/AR solutions for servicing, and many more. Since we combine business and technology expertise (across mechanical, electronic, and software engineering), we have exciting projects -- very often, these are highly innovative and strategically relevant projects (as opposed to middle-of-the-road development). **Location:** Frankfurt, Germany (among others) **Remote:** Sophisticated projects require aligned teams and a lot of communication, so we usually prefer to have highly interactive co-located teams, but we also do distributed development across different sites (following a set of best practices learned from past projects, continuously improved). It's okay for people to work from home a day a week, too. **Visa Sponsorship:** No. **Technologies:** We're mostly interested in C++ developers for embedded systems and backend development. The specific technologies depend on the project, the domain, and the client's constraints. There's usually a lot of freedom for the team to choose the technologies that help build the right product the right way. **Contact:** Please check [https://www.zuehlke.com/de/de/ueber-uns/karriere/jobs/](https://www.zuehlke.com/de/de/ueber-uns/karriere/jobs/)
From my experience with similarly sized projects, I'd expect that 16 configurations of any big library are relevant to testing: debug/release, with/without LTO, static/dynamic linking of the library itself, static/dynamic linking of the C++ runtime. I've had any one of them fail by itself: I have a project where we test our code with two major libraries, and that's 8*4=32 different builds to test. Failure on any of them is a release blocker: shit's supposed to work, and when it doesn't - it usually means that unrelated bugs are possibly shipping undetected.
Here's an illustration: https://godbolt.org/g/sBqXsZ Uncommenting /*constexpr*/ fixes the compile.
Apple is part of Khronos. And so far Vulkan seems to be ahead of Metal. Also, it's silly argument to make. OpenGL wasn't "behind". It kept pretty well. It was just archaic at it's core and it wasn't easy for manufactures to fully support in their drivers. Vulkan on the other hand is designed to be as lightweight and as lean as possible. And you you can see that it works by just how quickly it gained full support by all HW manufacturers (mobile ones are lagging behind but the fact that it's even there is amazing in and of itself). Not to mention that it's actively developed by the GPU manufactures themselves. At this rate it's the Metal that will be trying to keep up. And that's hardly surprising considering Apple's track report. They have little incentive to keep Metal up-to-date as long as it fulfills their goals. Just as they've kept their oGL outdated even though their HW was capable of much more on other platforms. They certainly want the control. The more control and ties to their platform the better. Doesn't justify their stance though.
We think alike. Here's what seems to work for me when I'm the interviewer for a dev job: 1. I ask them what they know really well and what they know poorly. That tends to relax them, and we can discuss why they know stuff well, and what they think it'll take to improve what they don't know. The latter part is crucial, since if they know "I don't know metaprogramming, but if I did XYZ then I would get to know it" then I'll know that they at least looked into it. 2. We sit down in front of a computer (with a VM for Linux or Windows, depending on my host), and we take a few minutes to set up the environment how they like it. This gives me a huge insight into how comfortable they are. Vast majority say "I'll use whatever", which is fine, but sometimes you get a "I am much more productive in VIM and GDB", which is fine also. Then I have them tell me what kind of a program we should write together that can be written in 45 minutes. I tell them that StackOverflow and Googling is not only allowed, but encouraged -- I'm looking for HOW they code, not how good their memory or muscle memory is. This also relaxes them. Then we build what they know to build, and then we try to add some variations that stretch them -- if they don't know regex, then let's parse a simple string (I'm happy if they hit SO, copypasta the example, etc, since that's what I do) So, I'm basically looking if the person is a BS'er or a doer, if they knows some basic stuff, if they can write simple code at a computer, if they can debug what they wrote, what questions do they ask about the problem, what they do when they hit a wall, how they think, etc -- and since they're "in control", they're much more relaxed and open and "discussion'y" Of course, when "I" go to interviews, I get raked over obscure language features like "compl, and, or, etc", or algorithms that I never thought off (not in my domain), data structures outside of what I use (and normally can't use in real prod code), etc.
I believe the point the speaker was making in that talk is that metaclasses struck something very fundamental in the language. "Metaclassing everything" proves how powerful and flexible that new mechanism can be, considering that all of those core language features could have been implemented using metaclasses if that had been an option back then.
&gt; Of course, they were also discussing to some extent modularising C++, Thats not what modules are about.
Not really; the terms lvalue and rvalue still have roughly the same meaning as they did in C++03, but extra rvalues were added . Most of the cases where an lvalue was required still require an lvalue, not a glvalue. 
&gt; I am Church of Google member(std::bad_alloc == std::terminate) so I do not care about OOM exceptions with containers &gt; &gt; I do not think the removal of allocators will help with perf. I know arena alocators help but that is not what you are saying. You are saying perf suffers because fact that allocator is part of the type of a container. Sounds weird. If STL containers never throw, then the compiler no longer need generate code to handle them throwing. Fewer codegen inc tables usually equals more performance. &gt; Especially since AFAIK there is not some Ubisoft or FB or Google or EA vector/hash_map that has allocator removed from type. It's a minority opinion. Me, John Lakos and most of the Bloomberg crew are mainly the strong believers. All of us, uncoincidentally, have spent many years of our careers writing memory allocators of various kinds. I'm also mindful that allocators are reasonable fit for a flat memory space of equal memory. Computers stopped being that some time ago. Now we've got heterogeneous types of memory, so for example the current 64 byte cache line may have very different characteristics to some other 64 byte cache line. Same for 4Kb pages and so on. AFIO at least will solve those issues, if it's accepted at Rapperswil. But it'll get even more complicated again soon, GPU memory, RDMA, PMEM are all just around the corner for standardisation. It is my opinion, and that of a few others, that a one-size-fits-all STL allocator just doesn't cut it. I'll be proposing a paper on span colouring at Rapperswil probably, but if nobody likes that, somebody else will propose something better soon. And we might even get it into C++ 26!
It makes it impossible to consistently test stuff like unit behavior or map generation in isolation. Which isn't necessarily the absolute worst thing in the universe. But I think think that local RNG classes with well defined scope + responsibilities is a lot easier to understand than a C style global rand() with global seed (which is generally equivalent to a global RNG object.) It's also a little easier to sync significant RNG's in multiplayer. If it's a single global RNG and I have my graphics detail cranked up high, the RNG will get triggered more times to play the extra leaves on the trees or whatever, compared to my friend who has the detail lowered. Then when it comes time to spawn the mutant Death Koala, our RNG's will be out of sync because they have been accessed different amounts. If you have one RNG object for creature spawning, that a critical thing that you can keep in sync. But the RNG for leaf placement and glowy shimmer particles is just a graphical detail, so you don't necessarily care if it has slightly different results for different players.
Why would you post "it doesn't get optimized away" and as proof link code **that doesn't have the code I claimed would be optimized away**? 
2020
Qt is based on C++; and while it is mostly similar, it's not really C++ anymore. It's what I would call a fork. It can't update with C++; it has to update from Qt. Basically. I don't even know why you brought it up. When I said industries, I meant thing like electrical engineers who use C++, or physicists, etc... I'm talking about C++ 17, 20
The much higher percentage of people developing for Windows desktop than for server/cloud surprises me, given that development tooling (sanitizers, fuzzers, linters, etc etc) on Windows is still pretty bad compared to Linux.
I have no idea what you are talking about. When I pointed out I had no idea what you where talking about because you where unclear, you remained unclear. Occam now tells me to assume you don't know what you are talking about. As for Qt, with metaclasses you should be able to eliminate the MOC and make everything clean and standard C++ by replacing the Q_OBJECT style macros with a QClass metaclass. Metaclasses can turn a language extension (MOC compiler) into a library feature. 
I run CppCon, so I've seen the talk :p. We have no plans to modularize the language, or modularize distribution.
Nope, it definitely won't be in the IS for 2020.
I didn-t think it was a bad idea myself. I'm quite familiar with "no plans" and "discussion idea" being separate things. So while you may not have plans, it has been talked about, and it is something Bjarne would like to do. Maybe it will happen; maybe it won't. Personally, my thought was roughly hinted at above. To distinguish between industries, and have either a industry managed library for each industry, or to adopt the modular distribution system. Instead of focusing on Basic, Intermediate, and Advanced/Expert, (Distribution + add on + add on), however; It would instead be the basic distribution, then different add ons, (avoiding calling them modules), for each industry, as well as Intermediate and Advanced/Expert Add on. Call Basic what you would need for intro to C++ in the education system, and your Intermediate add on would be for professional or internship use, or for advanced education in C++ training. Basically, pull an Autodesk with C++ and move it to an industry standard for a large variety of programming applications. Education systems are already starting people off with it, it's used in everything from game programming to aeronautics and robotics programming. Why not? Break it down, provide industry distribution packs, better distributions and documentation for education, etc... That's what I think. 
&gt; Qt is based on C++; and while it is mostly similar, it's not really C++ anymore But it is. MOC just generates boilerplate C++ code for programmer. It's all compiled to the perfectly conforming standard C++. You can even get rid of MOC today at the expense of the less convenient macro, i.e. see Verdigris. metaclasses would allow to implement the boilerplate generation and reflection support via standard built-in methods
Hi. Okay, boost appears to me like a monster... :) I avoid it. (Just like I avoid anything, that attempts to taint my code base with an overwhelming flood of macros.) Fruit looks interesting so far, kangaru also. Do you know cinject? How would you compare kangaru and cinject? What pros/cons would you claim? And sure you're right, insofar using a DI-containers singleton facility makes far more sense, then bare metal c++ singletons.
You're still programming in Qt though, and using different standardization specific to Qt. And there are aspects of Qt that are very distinct and unable to be brought forward to modern C++ be a use they would break anything written with it. That to me is a fork. You can't update it to modern standards; the developers of Qt have to integrate modern C++ into Qt where they can, and you get the update from them. So not the same thing. It's still C++; it's just using some outdated stuff and has it's own distinct libraries and classes. Don't get me wrong. I seriously considered Qt; I'd just prefer to use C++ until I can reliably define the distinction between something like that and pure C++, outside of the obvious differences. I am still learning. What tends to throw me off the most at the moment is unconventional usage and usage specific to things like Qt. I read over here, (or watch a video), that it is best done this way, or using thus syntax, etc.. . and then somewhere else I see something different, using different syntax, or libraries which are inconsistent with C++ standards, or just doing weird things like using Syntax I identify as C# mixed with Syntax I identify as C++, and it gets written off because otherwise it contradicts what i'm learning and that creates confusion. 
Which ones do you suggest? I want to start using it at work, but we're stuck on C++14 for a little bit. :(
&gt; wouldn't it be more consistent to name lvalues as plvalues (pure lvalues, equivalent to prvalues) and call the whole identity column lvalues (instead of glvalues)? So some values can be lvalue and rvalue at the same time, and some non-bitfield lvalues cannot bind to an lvalue reference? I don't think it would be better than the status quo.
To answer both you and /u/ared38 - I'm not convinced that "down-voting as a filter" is thing. I think it works to show that you agree or disagree with someone opinion. It's not there to prevent rules breaking. To be more precise: &gt; Programs in ABC language contain a lot of bugs This is opinion. Overgeneralized, but still it's well within bounds. &gt; Programs in ABC language are written by idiots. And this is insult. Uncalled and unjustified. The first thing is about agreeing\disagreeing. The second one is attacking people directly.
Debian 8 is still on 1.55. :(
Still the same as dereferencing bull: you're in UB land where anything can happen. 
It then becomes harder to tell which code is using the device. Does `int foo(Bar b)` communicate with the device? And if not today, maybe tomorrow after someone makes a "quick fix"? And maybe it's fine that `foo` talks to the device, but multiply that by 10 things that all want to be singletons. The code becomes unmaintainable. Change one thing and you have no idea what code is effected. This is literally the code I'm currently staring at. I deal with physical cameras, physical projectors, and a _single_ screen model (for projection mapping - stitching multiple projected images into a single coherent image on a surface). None of these things can be copied (like an int or a struct) - the represent physical things. So it is easy to turn them into Objects that people access, instead of values that you pass around. And there are only so many of them in the system, for example only one screen - a singleton. Whoops, except now people want to project onto multiple objects within a scene (like two cars parked beside each other). And the cameras all live in the CameraManager (singleton), and the Projectors live in the ProjectorManager. No wait, the ChannelManager ("channels" represent the section of the content being projected ie the to-be-stitched pieces). So the ChannelManager has channels that also have projectors. Oh wait, actually Channels and Projectors should be separated, because you could have two Projectors projecting the same section (to make it twice as bright). What code needs to change to fix that? _ALL OF IT_ because anyone who needed anything at all about a channel or a projector (you need section width/height in this code, whereas you need to know power on/off in this other code?, just ask the same ChannelManager, its all in there somewhere). So much code is written because we know what the answer is, the problem is we don't know the question. I know the answer is "getFoo()-&gt;getBar()-&gt;getX()", but that's just for the specific problem _right now_. Code doesn't stand still. What is the real question that piece of code (function or class) is trying to solve? Is it finding where this projector pixel will land on screen? Because that's a simple bit of geometry - when you have a flat screen at (0,0,0) parallel to the XY plane. But then one day someone asks for it to work on domes (like at science centers). Oh, and your projector now has an anamorphic lens, so light doesn't all exit the same way? Suddenly all that code that just grabbed Engine-&gt;screen-&gt;width and channelmanager-&gt;channel(i)-&gt;position and did simple some simple math, is no longer simple. (This is only a slight exaggeration, our code was never quite that naive.) Often abstraction goes along with separation. Knowing _what does this function really need_ (from the _function's perspective_) instead of _what do I have at hand that happens to hold the info_ will lead to abstraction and separation. Don't pass in a Foo, when the function just needs Foo.x and Foo.y. Pass in a Point. (And somehow, I'm telling you now, know - preferably at compile time - what coordinate space the Point is in. If you have one coordinate space, you probably have many, and you will eventually mix them up. Even in a 2D windowing system - there's the absolute screen space, the window space, the _client_ space, the document space (the doc could be scrolled, zoomed). Imagine all that code that grabbed x and y, and then one day you add zooming. So just add `* scale` everywhere. Except wherever it has already been applied... Or better, for each _small_ piece of code, know what _its_ world looks like, what x/y means for it, is this function in doc-space? Or you can't tell because today doc space and window space are the same? Because you just grabbed that singleton... (It can happen without singletons as well of course. They just tend to make it worse.)) Maybe I just work with bad code. No, actually the code is amazing. It does amazing things. https://youtu.be/G86thpiR_AQ?t=58 *ALL* code I've seen (over 30 years, companies big/small, Adobe, BlackBerry, Android, Christie, etc, etc, etc) eventually becomes a mess. You either pay the price to refactor it later, rewrite it, OR make an effort to catch it early and don't let it get that way. All my experience tells me that the main cause of that mess is that each piece of code is not kept independent. I don't care about OOP, language, where the heck you put your brackets, whatever. Just keeps your pieces of code isolated. And name things well. 
What I'm saying is that Qt is a framework for developing C++ applications. It has it's own compiler, and while you can use a metaclass to make that compiler a library feature as you suggested, (supported in the proposal documentation), it will only compile to the C++ Standards it is designed to compile to. i.e. it does not make use of everything available in C++ 17, but compiles to C++ 11 standards with some C++14, and possibly C++17 thrown in. So it will not be as efficient or as optimized in compiling as directly coding in and compiling C++ 17, something new. It will still be efficient and optimized for what it is used for, and it will work great for that. I'm not arguing that. I'm just arguing that it is not complete. Take that as you will. If they make a Metaclass compiler for Qt, chances are it will remain a compiler for Qt, and take into consideration all the design requirements for Qt. i.e. unless they change Qt, it is still going to compile the same way it does now, and output more or less the same thing, with any revisions to Qt taken into account. 
What's so terrible about f PROC sub rsp, 24 mov QWORD PTR $T1[rsp], -2 movzx eax, BYTE PTR [rcx+4] test al, al jne SHORT $LN2@f $LN49@f: mov eax, DWORD PTR [rcx] jmp SHORT $LN1@f $LN2@f: cmp al, 1 je SHORT $LN49@f xor eax, eax $LN1@f: add rsp, 24 ret 0 f ENDP
&gt; I have not watched the video above. Is this metaclass video strictly talking about Qt? Why even bring it up? A lot of people use it. It's a great tool. I don't really care about it in the context of this discussion. Because you were making claims such as this &gt;My issue was more with the apparent suggestion that they make a C++ Metaclass in the ISO Standard library that includes a whole lot of code that is used internally by various developers and engineers. &gt;So basically, gathering hundreds of different sections of code that are used for various things in different industries and making them part of the ISO Standard. Which indicates that you didn't understand the concept behind metaclasses. The people tried to explain it to your by using commonly brought up example with Qt (since it's one of the biggest C++ libs out there that will benefit from the proposal). In response you continued to make some weird claims based on second-hand knowledge. It turns out that you didn't know what you were talking about so the confusion is understandable. You can watch the video or read about them and I'm sure it'll become clearer to you. The problem they solve is orthogonal to someones opinion regarding whether some codebase is "true"/"modern" C++ or "fork".
Someone correct me if I'm wrong, but it seems like a good way to think of an rvalue is a temporary in the register of the cpu (Unless it can't fit or something.), where an lvalue is on the stack. Or at least in a perfect world it would be.. An xvalue is an rvalue that's being returned from a function into an lvalue, so it's an rvalue moved onto the stack. And a glvalue has no apparent value. Maybe the compiler throws error codes with 'glvalue' in them but I don't recall.
Storing each function pointer in a `set` or some other container _would_ work for your small example, but not sure how useful this would ever be. #include &lt;set&gt; std::set&lt;void(*)()&gt; foos; template&lt;typename T&gt; void foo() { static const auto _ = foos.emplace(&amp;foo&lt;T&gt;); /* Other stuff */ } void all_foos() { for (auto* f : foos) f(); }
Are you messing with me? What is it?
[`compl`](http://en.cppreference.com/w/cpp/language/operator_alternative)
The way to deal with io is to wrap it up in a function and never look at it again. So you know you need some io? That means you have an idea of what you need. Do top-down programming. Write some code calling the functions you wish you had. Then write those functions. Then never look at them again. Make sure they just return some classes. Don't put IO into your classes. (Otherwise you will end up looking at IO again.) Keep it disentangled. Your classes should be constructable. Have the IO call the normal constructors. When you change from XML to JSON, your classes shouldn't change. Speaking of XML/JSON. Skip XML. Use JSON. So find a JSON library. Use that. You are then already one level removed from io. Great! 
Go watch the CppCon Metaclass presentation. It's about 1.5 hours longer than this video summary. If you can get through it, you'll understand what I was talking about. Maybe, if you ignore your one Qt benefit example, and actually listen to him telling people about all the industry specific uses, and how he wants more ideas and suggesting people provide him code that they use that can be replaced with metaclasses. Yes, I understand they are powerful, and I at least somewhat understand usage, (and yes, I watched the video; my limit of understanding is the span of my knowledge of C++, not the encapsulation of an idea like a metaclass). I think maybe you're a little stuck on that ability to turn a compiler into a metaclass. Or make a compiler a metaclass. However you want to say it. That's not really relevant to the hundreds, or even thousands of possible uses for it that are being presented, or the fact that in that presentation, it seemed very much like that guy wanted to include hundreds of metaclasses in the standard library, not simply introduce the ability for people to make their own metaclasses. If anything, blame the guy in that presentation for rambling on, and wandering around in the discussion in an unclear fashion that made it hard to see exactly what he intended for it. Maybe to an expert programmer he might make sense, but in Layman's terms, he was about as clear as mud. And for someone new to programming and C++, only slightly more clear. Like muddy water. So, if I don't know what goes on in the background, that makes a programming language like C++ work, (and I mean the actual code behind the code), and if I don't know everything that is included with C++ language in terms of libraries, and what they all contain, or even how they are all used, maybe I might not be entirely sure whether someone might actually try to add every possible usage case of something like a metaclass to it, or at least all the ones they could get away with, which a lot of people use. That's my concern. Let people build their own metclasses if they need them. I'm not sure if he intended to include all those possible metaclasses in the C++ Standard, but the way he was speaking, it sure seemed like that was what he was getting at. And here's the thing, while my experience with programming is limited, my experience with people isn't, and that is exactly the sort of thing I would expect someone like him to try to do. Or as Bjarne put it in one of his presentations, roughly quoting, " or you could have the someone else defining your language, and doing something you really would not like"
I know that boost aim to be zero overhead, as opposed to other libraries. Also, boost, especially boost DI, is not as bad as you claim as far as I can see. There is no macro involved in it's usage, and seem to adhere to modern practices and quite easy to use. Between kangaru, cinject and boost, I find boost to be the most easy to use. I really suggest you look into each library if you want an extended comparison. I don't know your needs, nor what you want to achieve with those. It's the first time I heard about cinject from a quick look I see some pros: - Resolve dependencies automatically, without any config - Quick binding of interface to implementation - You decide at runtime if an instance is singleton cons: - Forces shared_ptr everywere :( - Configuration of the container at runtime - Documentation and tests incompletes. No clear compiler support Kangaru is zero overhead if no single services are involved, but searches in an unordered map when requesting a single service. From what I see also is that the cinject library is quite new, and I suppose will do much better in the future. In my opinion, it's still missing some stuff right now. For kangaru, here's some pros: - injection in function parameter - Allows fork and merge of containers - allocation strategy is configurable per service type and some cons: - needs a separated configuration for each service type - cannot change internal container (we are using an unordered map and a vector of unique ptr) - Not zero overhead Again, these pros and cons are arbitrarly choosen. Try to see what kind of problem they can solve for you, and select the one that fits your need the most.
I was busy today helping with implementing `&lt;filesystem&gt;`; I'm not *constantly* on reddit... I agree with what cleroth said, and thank you for bringing this to our attention. It's a worrisome trend that I don't want to see any more of.
Okay. That's not something that Bjarne has ever pitched.
That isn't a good mental model. `"me"s + "ow"s` is a prvalue of type `std::string` which probably (definitely) doesn't fit in a register. Given `vector&lt;int&gt; v`, `v[idx]` is an lvalue of type `int`, which lives on the heap. Remember that value categories are a property of expressions, **not** of objects. For example, `print(const string&amp; str)` can be called as `print("me"s + "ow"s)`. There, the temporary `std::string` containing `"meow"` is produced by the expression `"me"s + "ow"s` which is a prvalue. Within `print()`, `str` is an lvalue referring to that `std::string` (which is *ultimately* a temporary, but exists for the duration of the `print()` call).
File I/O itself can be wildly different depending on the platform if you want to "do it right." APIs exposed by the standard library (fstream) don't do asynchronous reads/writes and there's a lot more functionality hidden away that requires a more platform specific API. To get more help, it's probably more useful to understand what you mean when you say "file io." Also, it's worth taking a look at r/cpp_questions
https://youtu.be/fX2W3nNjJIo?t=41m9s Exact time; there you go.
References are better than tests. Some people don’t test nor interview well, but if they can provide reputable references then that’s all that’s needed
Makes sense, but if an rvalue can fit in a register will it? Will it live in the heap? I like your username btw. \^_^
Expressions, more or less, relate to an identity (or address). glvalue expressions are any expressions denoting an identity. prvalue expressions are expressions without identity. So in this case, prvalue expressions are going to be your register-friendly ones.
In the end, a file is just a big block of bytes. But, in the middle there are as many ways to deal with a block of bytes as there are programmers. So, what are you looking for? Do you want to parse some JSON? Stream a log? Write to a database? Load a 3D model? Scan a directory hierarchy? Write to file-mapped hardware? Page memory beyond the 48-bit address range? You are going to have to state some goals if you want meaningful directions :)
"-std=gnu++14" is required for POSIX facility compatibility also, otherwise most POSIX or GNU tools cannot be compiled using default configuration.
Qt is straight up pure C++. Qt Moc is basically just a fancy, more powerful, macro. The end result, after it's processed, is still C++. It's even possible(and has been done) to do in pure macros, with a slightly more convoluted API. You could, if you were a masochist, write all the boilerplate yourself and completely avoid moc.
&gt; It has it's own compiler, No it doesn't. It's a preprocessor, at most. Like macros. It still generates plain C++ code, which your normal compiler then, well, compiles. Your buildsystem, such as CMake, should handle this automatically. With things like [Verdigris](https://woboq.com/blog/verdigris-qt-without-moc.html) you can even remove moc, using pure macros and a slightly less convienent API.
This Python/Rust-like convention you describe is my preferred convention. Underscores are cool.
You just need [the right toolchain](https://github.com/deplinenoise/c-amplify) \^_^
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/83c8t7/good_resources_for_understanding_and_using_c_file/dvh1oll/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; I've never used VS so maybe it is better Yo it is a NIGHT and DAY difference. Do yourself a favor and do some C++ dev on Windows. MSVC is traditionally not even on the cutting edge of C++ features, and I don't care that much about that either. The Visual Studio debugger is just far and away better than anything XCode (and probably anything else, really). Its features aren't even that fancy, you can just use it quickly and it's relatively reliable. I can't say the same for Xcode (adding watch expressions in Xcode is agony). Xcode could do a lot of things and start to approach parity with VS, but for whatever reason they just don't. It's insane how obviously bad its watch window is. There is a single thing Xcode does better than VS: draggable breakpoints. That's about it. &lt;/rant&gt; P.S. Emacs 4 life, better than Xcode
You seem to have a weird definition of C++. C++ == a syntax and a semantic, not a set of idioms. Qt is just a library which respects this. There are no new keywords in Qt if that's what you are referring about: signals, slots, etc are just macros.
You can entirely code qt outside of qtcreator (their IDE). The more important quesyion is, why would you ever use another IDE than qtc when you've tried it, even for non-Qt code :p 
This strategy (although very sound) doesn't project you from what I described. 
Not even a part of it?
Are you talking about industry specific modules inside the standard library? And tool vendors by default only shipping subsets of the standard library by default? Considering how small the c++ standard library is and will remain I see neither the need, nor do I expect it to happen.
You got obviously confused, which is not uncommon in c. The fundamental thing you have to accept in c++ is that there are a lot of different library out there following different styles, conventions, using different API designs, following different goal and making different trade-offs and most importantly where invented at different times. That doesn't make those libraries a fork out c++. Now, qt (which predates the c++98 standard btw) goes two steps further than a classic library: It has moc, which is essentially an additional preprocessor, generating a lot of boilerplate code for you to enable nice syntax for defining things like signals and slots. The generated code however is normal c++ and is in fact compiled with different c++ compilers and different language standards. Second, Qt provides a lot of tools (e.g. for GUI design) that help you generate c++ code. But again, it's just c++ - not a for of it.
One of the best explanations I saw on the subject.
You got obviously confused, which is not uncommon in c++. The fundamental thing you have to accept in c++ is that there are a lot of different library out there following different styles, conventions, using different API designs, following different goal and making different trade-offs and most importantly where invented at different times. That doesn't make those libraries a fork out c++. Now, Qt (which predates the c++98 standard btw) admittedly goes two steps further than a classic library: It has moc, which is essentially an additional preprocessor, generating a lot of boilerplate code for you to enable nice syntax for defining things like signals and slots. The generated code however is normal c++ and can in fact be compiled with different c++ compilers and different language standards. Second, Qt provides a lot of tools (e.g. for GUI design) that help you generate c++ code. But again, it's just c++ - not a for of it.
Friends don't let friends write node based data structures without using smart pointers.
You got obviously confused, which is not uncommon in c++. The fundamental thing you have to accept in c++ is that there are a lot of different library out there following different styles, conventions, using different API designs, following different goal and making different trade-offs and most importantly where invented at different times. That doesn't make those libraries a fork out c++. Now, Qt (which predates the c++98 standard btw) admittedly goes two steps further than a classic library: It has moc, which is essentially an additional preprocessor, generating a lot of boilerplate code for you to enable nice syntax for defining things like signals and slots. The generated code however is normal c++ and can in fact be compiled with different c++ compilers and different language standards. Second, Qt provides a lot of tools (e.g. for GUI design) that help you generate c++ code. But again, it's just c++ - not a for of it.
Most of the libraries and executable or there don't use c++17 you know that right? Are all of them not c++ for you?
I'm well aware of that. There are early adopters though, so when I say maybe some, I mean maybe some, and I'm not necessarily speaking present tense. Seriously though, your taking offense is actually offensive. Is it something that programmers do; taking every little thing and getting worked up over it and trashing people on the internet because you don't agree with them. Where's that meme: Something's wrong on the internet? Seems appropriate here.
Does it not? I ran the windows installer, offered me to uninstall version 5, and now the LLVM-vs2014 toolset reports to be clang 6 
&gt; LLVM-vs2014 This uses the VS2015 stdlib; still doesn't work OOTB for the _VS2017_ stdlib.
Oh interesting! Wasn't aware of that I wonder if this actually works with the new one: https://github.com/arves100/llvm-vs2017-integration (Would have to be adapted for clang 6)
Yea that should use the right stdlib, but as you said, it hardcodes Clang 5, and it hardcodes `-fmsc-version=1910` which is wrong for VS2017.3+. Minor cleanup should make it workable if you're okay with using clang-cl.
I don't see that as a problem. If a GNU tool needs GNU extensions or POSIX facilities, it should rightly signal it so, by adding `-std=gnu++14`.
So? No one is suggesting to standardize a QtMetaClass. What is your point. In almost everything you write about Qt, you could replace Qt by LibraryX and it would still be true. Personally I wouldn't go so far as to call Qt code ISO c++ due to the need for moc, but Qt does neither need it's own compiler, and also doesn't have to "allow" you to use c++17. Like every other library out there (and even the standard library btw.) It doesn't immediately make use of all the features of the most recent standard but that still doesn't make it non-c++. Essentially, you are not writing IN Qt but you are USING Qt.
A compiler converts Human Readable code to Computer Readable code as I understand it. i.e. C++ to binary. Now from what I understand about translations, it's basically taking one thing in one form, and converting it to another form. It's still that thing, it just looks like ones and zeros, and were you to reverse the compile it would come out as the same code it went in as. So, it takes Qt and turns it into binary, but it's still Qt. It doesn't magically turn it into something else in translation. Though, if you put enough code behind that compile process it could actually change what was written there. Obviously. That is from what I understand, something like what Reflection does. But typically speaking, to present at least, as far as I know, that isn't something that is done. Ironically, when I do a search on Qt compiler, I get a lot of forum posts about people having trouble adding compilers in Qt Creator, or not having them work, and various other posts about compilers of x.version number that will/should work. Seems like that supports my hypothesis I arrived at after watching that Qt Dev speak on the Cpp Con video. As for it having a compiler, well, someone else here said MOC was a compiler, and the internet documentation seems to support that, as does the metaclass proposal documentation. But actually it apparently generates boilerplate code that can be read and compiled by a regular C++ compiler...which further supports my thoughts on Qt. Maybe I'm completely missing it, but the internet seems to be largely in support of what I think about it, except for the people responding here. So, to rehash, MOC reads Qt code, and converts it into code readable by a C++ compiler because a C++ compiler can't. I assume Verdigris does the same. Either way, completely irrelevant to me outside of this endless argument I didn't once even consider having a discussion about before some started arguing with me about it today. Even though I didn't mention it. the only relevant part of all that is that a metaclass, as proposed, can be used to do the same thing, according to the Proposal documentation.
This conversation is over. I haven't found a single useful or informative discussion in this sub since I joined it last week. You're basically trolling me.
Then all previous releases will break without an upgrade with the new build flag.
There's no impact if you don't use the library at all, no. That would be ludicrous. 
There's a difference between "trashing people" and what's happened in this thread, which is multiple people patiently trying to explain to you that nothing you've said makes sense and that you're arguing from a position of total misunderstanding. 
Isn't that the point of SEMVER and increments of the major number that they may require breaking changes... (and in this case we're talking about a simple flag change downstream)
If your change breaks building of majority packages it will prevent its adoption. Also, gnu++14 is just super set of c++14 with support for POSIX and GNU. There is no point to disable the latter just for hygiene purpose.
With some hacking (look inside the installer, it's fairly simple to fix) it works perfectly fine (with the same limitations as LLVM-vs2014).
The installer *will* "work", if you have an "upgraded" install of VS2017 (the relevant files are installed in directories from the previous install). If you do a clean install of VS2017 (clean up all the remnants), then the Clang installer will report an error (and integration has failed).
&gt; If STL containers never throw, then the compiler no longer need generate code to handle them throwing. Fewer codegen inc tables usually equals more performance. True, but the question is how much real difference this makes. Branches should be predicted and compiler should be smart enough to move unlikely asm paths from hot paths so they do not waste I-cache. Obviously since I say should this means I have no perf numbers and I am mostly relying on what some people said on the internet. &gt; It's a minority opinion. Me, John Lakos and most of the Bloomberg crew are mainly the strong believers. All of us, uncoincidentally, have spent many years of our careers writing memory allocators of various kinds. My rule of thumb for standardization: if it does not exist it means that it is not useful OR nobody bothered to ISO it. My rule of thumb for industry: if it does not exist it means it is not useful. I am sure you and Bloomberg people are smart, but again it is fishy to me that neither FB or Google never did something like this. And I mean they have so many machines that 1% speedup is millions of dollars of energy cost(datacenters in the US consume 2% of total electricity consumption). &gt; Now we've got heterogeneous types of memory, so for example the current 64 byte cache line may have very different characteristics to some other 64 byte cache line. Same for 4Kb pages and so on. AFIO at least will solve those issues, if it's accepted at Rapperswil. Again I would need numbers. Yes Ryzen is not same as Intel CPUs, but it is **pretty** similar. As for your proposal, I wish AFIO first got into boost... I am a big fan of standardizing stuff that is not used. I know you are smart and all that but it is hard to think of everything and having 1000-2000 developers use your library for real projects for a year or two helps. &gt; I'll be proposing a paper on span colouring at Rapperswil probably, but if nobody likes that, somebody else will propose something better soon. And we might even get it into C++ 26! IDK what is span colouring, but like you say with ISO standardization speed not urgency for me to learn about it. :P 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/83fay5/now_that_we_have_concepts_should_stl_containers/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
&gt; would it not be beneficial to not have a lot of stuff you don't need in it? Why? If you don't use it, it doesn't have a cost.
Unlikely.
It would be nice to be able to write std::array&lt;int, 3&gt; or std::array&lt;3, int&gt; (although someone pointed out the other day, deduction guidelines will simply infer this), but I don't know if this would create more confusion than its worth
I know where this is coming from, but I don't think it works out that well. I think that we really need is named parameters. Something like `std::unordered_map&lt;int, std::string, allocator: MyAllicator&gt;`
I am working on a very simple entity-component-system system where this seems to be useful. Currently, i am using the solution that a nice StackOverflow member provided to my question that I linked in my original post. If you're interested: https://github.com/tsoj/ecs_prototype Where I would need this is when I want to work through all event types that the user of this entity-component-system system used.
This. Moreover, we need it before we release stl2, so we can build that without dozens of slightly different constructors that may even conflict in specific situations. I want to write this: std::vector&lt;int&gt; v (.list={1,2,3}); std::vector&lt;int&gt; v (.size=10, .value=5); std::vector&lt;int&gt; v (.reserve=20); 
I think `std::equal_range` is from the same group of algorithms.
I somewhat agree with you. But the main problem is that people might use (I guess beginners/intermediate programmers) these features (maybe by accident) and then only later once they or someone else tries to compile the code on e.g. Windows, they realize they've used non-standard stuff - even though the compiler, on its **default** options, never complained or warned.
looking for contributors / enthusiasts. the code isn't perfect, so if you find something wrong feel free to push some changes, all help is welcome
What use cases is this library targeting? How does it compare to existing SP libraries like Intel IPP and KFR?
What if both template parameters fulfills both concepts?
sadness. :P But I think for maps it is possible to write Concepts that detect comparators, hashers and allocators.
Solve some medium/easy problems on HackerRank. In my experience usually those screening tests are easy, but only problems is the lack of time, so be aware of time and do not get stuck on hard problems for too long.
this started some months ago, i needed "ready to use" audio modules for a STM32 project i was working on, then i realised this could easily become an open source lib. so the idea is to create a c++ library that resembles the concept Native Instruments' Reaktor Core, useful modules, easily tweakable and quality output. it doesn't compare at the moment since it is still so young, but i'm curious of what it will become with the help of better developers compared to me.
no real reason for .hh and .cc. makefile over cmake: just because i have no experience with the latter, but feel free to propose a new build method, i'm relatively junior developer, have no degree nor experience except for the time i spend coding for fun / personal interest. didn't think of contribution guidelines yet, will add them soon.
No, aside from one, it's multiple people pumping their own egos demonstrating their knowledge about things which are not on topic, to the person they see as the noob with no skills or knowledge, who they are also quite willing to continuously browbeat over that. And multiple people being in a permanent state of denial as well, because not one of you admits when you're wrong, or has once actually acknowledged that you are off topic and talking about things I have repeatedly told you I am not interested in.
Of course nobody has admitted that they're wrong - they aren't. You come across as ignorant, narcissistic and paranoid. Please go away. 
What do you mean with 2D `std::array`? Isn't that 1D? 2D would be something like `std::array&lt;std::array&lt;int, 3&gt;, 3&gt;`?
It still takes up storage. tbh, I don't know how much storage space it requires, but my install of VS 2017 includes a significant number of libraries, and takes up 94 GB Now, VS itself isn't that big, but when you tick off all those boxes to include all that stuff, it kind of inflates. Everything has a cost, even if it's just in memory handling when doing builds or refreshing during programming. Again, I am aware of that. You don't actually read the posts you're replying to or you would know that. Half the stuff you correct me on is quite literally the exact opposite of what I said.
More excellent contributions from the peanut gallery.
My post contains more correct information than the sum of your posts in this thread. And it's not even close. 
Look. I've spent over 20 hours getting spammed with messages from this thread about how Qt is C++, and how awesome it is. The subject of this thread is the Metaclass proposal. Qt is only vaguely even close to related by it being mentioned once in the metaclass proposal through MOC, along with 3-4 other things. Barely any of the responses I've had have had anything at all to do with metaclasses, or what they do. Qt is not C++ Standard. Watch this video: https://youtu.be/YWiAUUblD34 This is one of the Devs who has worked on Qt for years describing the problems with Qt, and what they have done with it. Pretty simple stuff. Not hard to grasp, and the guy is a good speaker. He's definitely selling the product, but he doesn't gloss over its failures; he simply provides reasons why he thinks they are not all that significant. Pretty much everything I have said about Qt here has been based on that, aside from one statement based on there technical documentation which I looked up. Most everything else here has been a silly argument about what is or isn't C++ led by people like yourself, and completely ignoring the fact that the discussion here is related to ISO Standard C++, as well as details like those brought up in that video, which very clearly defines what Qt is, and what it isn't. Enjoy.
I think he's referring to `int arr[M][N]`'s equivalent being `std::array&lt;int, std::array&lt;int, N&gt;, M&gt;`.
Either build something substantial or help some existing projects. The former will likely help your development better, but the latter might appear better to companies. a bit of both would be perfect
Can you give some examples of both? Where can I find semi-developed open source projects I can help with my current knowledge?
int[2][3] has 3 and 2 swapped when you want to have std::array of std::array
Make a great repository of your solutions to the challenges of http://adventofcode.com
No. That's explanation for relatively long time it took to fix it.[
There are also problems with that all concepts have to be structurally different (e.g. no other function object taking one argument and returning size_t or else it would conflict with Hash), compile times would increase, and making libraries to mimic the standard library becomes harder.
No. The guy who is right is the one in that video. It's over an hour long, so it's a safe bet you havn't watched it. You just called me a paranoid narcissist. An ignorant one. I'm pretty sure I know what side you're on. 
Your response time. Apparently programming logic doesn't really require you to be logical. 
Apparently you do. That wasn't indirect. Although I think it's more likely you never watched it, or them at all. 
oooh boy - that's tough, I mean you want to work on something that interests you and is progressive I'd imagine? This is what I'd suggest, as I have *some* experience with it https://github.com/STEllAR-GROUP/hpx Only you can know your current knowledge, and you might have to develop that in order to work on something more interesting
Okay, I think I see what you're aiming at. My current project is probably less demanding than yours. I am involved in operating software for screwdriving systems, which is mainly used for configuring the systems on the one hand, and for diagnostic purposes (recorded bolting data - angles, forces, torques, etc.) on the other. Originally, the software was implemented under MFC in the late nineties. Up to now I've pulled the project over to MSVC++ 14.0 and am now aiming for further modernization. I think you score well against Singletons and DI names the only sensible alternative for me. If I had found a DI-Cotainer for C++, that works for me, I would certainly use it. But up to now I don't see anything really usable, and maybe I'll actually end up trying to tame the monster boost... *g In the case of what you are describing, I would immediately think of a pipeline into which a vertex with coordinates and color information is fed, which is then automatically routed through various - per pipeline - processing steps to the projector. Any conversions would only play a role within the pipeline and would not be of interest to anyone or anything outside the pipeline. What would remain would be a pipeline manager which manages all pipelines that receive the existing data and directs them selectively into appropriate channels. Hmm... I think that could well be a Singleton, no matter if bare metal C++ or via DI.
That there is a solution doesn't imply that that solution is ideal or ergonomic or even suitable. We *could* write everything in assembly if we wanted. You're correct that the strong typedef solution helps avoid errors, but I still think named parameters are better because they're just as good at that and also more ergonomic.
Definitely, couldn't agree more with that :-)
Ah I see! Thx!
What kindof company? What do they do? Think of something helpfull for them.
Hmm... For me "zero overhead" sounds mainly academic. Any benefit comes for some costs. I am momentarily mostly focused on clarity and maintainability. And as I'm currently mainly concerned with UI, any possible overhead in ns-range is pretty unimportant for me. I think, runtime-configurability would have to move to the pros, since this way dynamic plugin-concepts become implementable. I would love to have both - compiletime and runtime wiring - side by side, the way, that there would be a basic (compiletime) working wiring, what would be extendable with dynamic (runtime) plugins/addons... you name it... What's the problem with std::shared_ptr?
&gt; &gt; If STL containers never throw, then the compiler no longer need generate code to handle them throwing. Fewer codegen inc tables usually equals more performance. &gt; &gt; True, but the question is how much real difference this makes. Branches should be predicted and compiler should be smart enough to move unlikely asm paths from hot paths so they do not waste I-cache. Sure, but branch predictors have finite history. If we chop 30% off of the code and table generated, we effectively increase the amount of branch predictor history retainable by 30%. Similarly, cache is limited, if we generate 30% less stuff, we effectively increase the L1/L2 caches by 30%. And so on. &gt; Obviously since I say should this means I have no perf numbers and I am mostly relying on what some people said on the internet. You're right that if your existing hot path fits easily into L1 cache, then none of this will make a difference. It's for those cases where it doesn't fit into L1 cache, or the L2 cache, and so on. &gt; &gt; It's a minority opinion. Me, John Lakos and most of the Bloomberg crew are mainly the strong believers. All of us, uncoincidentally, have spent many years of our careers writing memory allocators of various kinds. &gt; &gt; My rule of thumb for standardization: if it does not exist it means that it is not useful OR nobody bothered to ISO it. &gt; &gt; My rule of thumb for industry: if it does not exist it means it is not useful. &gt; &gt; I am sure you and Bloomberg people are smart, but again it is fishy to me that neither FB or Google never did something like this. And I mean they have so many machines that 1% speedup is millions of dollars of energy cost(datacenters in the US consume 2% of total electricity consumption). Did you not see me mention that me and said supporters have spent many years of our careers writing memory allocators of various kinds? Industry has been doing this for decades now. It's extremely useful. I remember a client with a large DoD contract which was going to fail unless the memory allocation pattern problem got fixed. I worked my ass off for two months, and we came in 20% under the CPU budget eventually. I got paid a silly amount of money, and the client saved themselves hundreds of millions of dollars and a ton load of pain. Bloomberg's terminals similarly would not work as well without attention paid to this kind of stuff. The problem is in fact how best to standardise it. To do it properly is very hard, I remember Hans Boehm telling me a long time ago he wasn't sure if doing it properly is achievable as he thought it a NP hard problem. And nobody likes to standardise an obviously inferior solution, so the can gets kicked down the road. &gt; &gt; Now we've got heterogeneous types of memory, so for example the current 64 byte cache line may have very different characteristics to some other 64 byte cache line. Same for 4Kb pages and so on. AFIO at least will solve those issues, if it's accepted at Rapperswil. &gt; &gt; Again I would need numbers. Yes Ryzen is not same as Intel CPUs, but it is pretty similar. Differences between difference cache lines and 4Kb pages go right back to the 486. Think disc swapping. &gt; As for your proposal, I wish AFIO first got into boost... I am not a big fan of standardizing stuff that is not used. I know you are smart and all that but it is hard to think of everything and having 1000-2000 developers use your library for real projects for a year or two helps. It is a post-Boost-peer-review design though. Which is better than some libraries submitted for standardisation. I actually agree strongly with you on this, indeed I have lobbied, and will continue to do so, for LEWG to hard prioritise submissions from Boost or an equivalent. As in, if LEWG can process X papers per meeting, the papers which will be dealt with will be strictly prioritised based on having userbase experience, passed a peer review somewhere, come from a study group in that decreasing order. I would also say that most of AFIO is merely thin wrappers around the syscalls. It's no Ranges nor even Filesystem as a result. It's much less substantial. &gt; &gt; I'll be proposing a paper on span colouring at Rapperswil probably, but if nobody likes that, somebody else will propose something better soon. And we might even get it into C++ 26! &gt; &gt; IDK what is span colouring, but like you say with ISO standardization speed no urgency for me to learn about it. :P https://wg21.link/P0546 proposes a `span&lt;T&gt;` attribute mechanism. I implement that customisation point with span colouring, so for example you can colour a span to say it non-volatile RAM, and thus if you execute a CLWB instruction on the span, that's equivalent to `fsync()` for that file. Which may save on actually calling `fsync()`. Another useful colouring is alignment, so you can say that a span may be assumed to always be aligned to some byte multiple, and always be some byte multiple long. The compiler may then use SIMD. I've already got a toy implementation for this stuff, just need to write it up. 
They're actually a gaming company, but my time is very limited so I just want to show that I know **something**. I don't have time to learn any game engines and code a game until the deadlines.
When I say zero overhead I mean that the abstraction completely goes away when compiled, and the resulting binary is the same and everything can be inlined. Changing the creation of an object from a simple construction to a new is not zero overhead. Calling a virtual member function is not either. Relying on dynamic allocation is not. Almost anything that cannot be constexpr are indeed costly abstractions. Also, they are many many problems with shared pointers, especially when you use it when you don't really need it. They are overused and they promote a bad design of lifetime management of objects. They are thread safe, meaning they must do atomic operations, and they are bad for the cache. Just search why shared pointers are bad, there is enough talk and articles about that. Also, when shared_ptr/make_shared is used, you cannot use custom allocation strategy. In cinject, you cannot use a pool allocator for example. You cannot pre-allocate a buffer where you're constructing many objects in it. In boost-Di and kangaru, it's possible.
github
[Here](http://www.stroustrup.com/terminology.pdf) is basically the same explanation from Bjarne Stroustrup (using a "W" instead of a square.) It completely cleared things up for me.
Well sure for them it will be hard to do something amazing. Was hopping for a less programming focused company, where you could write a short helpful program calculating something. 
My point is that you don't get to break something and then be like "oh, sorry, but that's going to take a long time to fix". 
&gt; so the idea is to create a c++ library that resembles the concept Native Instruments' Reaktor Core, useful modules, easily tweakable and quality output you should maybe look into Lance Putnam's [Gamma](https://github.com/LancePutnam/Gamma) library, it's really about this and extremely efficient.
Maybe I'm missing something here, but I feel like this is something we could have done on a lot of STL functions as well, but haven't. e.g. we have explicit vector( size_type count, const Allocator&amp; alloc ); but not explicit vector( const Allocator&amp; alloc, size_type count ); Why should template arguments be any different from function arguments here?
I haven't seen this presented in a way that's viable beyond small toy examples. It doesn't allow you to specify the parameters out of order (see this very post for an example of someone wanting this functionality), unless you implement a function for each possible parameter ordering. Additionally, declaring them as types ends up polluting the namespace with types for every named parameter that is used. This is already obviously bad, but it also leads to the lesser problem of having to specify the namespace those types reside in. So you won't have anything as clean as your example `std::vector&lt;int&gt; v(reserve(20))`, because the typedef wouldn't reside in the global namespace.
&gt; Or are you just plain angry? Way to get personal about it. blocked.
Sorry for that - that wasn't my intention. Maybe we just don't understand, what the other is concerned about. Have a nice remaining weekend anyway. 
Sorry to hear that, but I guess it was to be expected. Thats actually one of the reasons I'm not all that excited about the Metaclasses proposal in the first place: It is so far out in the future, I'm not sure if I'll even be using c++ by then.
Thanks for clarifying that! It is very hard to find a good answer to that question online and I see it used interchangeably so frequently.
Thank you very much. Appreciate you monitoring such threads and responding on comments so quickly. 
You can't prevent updates from introducing bugs, that is true, but if you switch to a roling release model and don't give the user an easy way to roll back an update you have to be accountable to a higher standard. Thats btw. also my problem with Win10 updates. I don't necessarily have a problem with "forced" updates, but if MS wants to force the updates on the user it is their responsibility to not break the user's machine when doing so. 
It looks like you have declarations in your .cc files and the actual code in the .hh files. That seems backward. Can you explain your reasoning?
Those are [explicit instantiations](http://en.cppreference.com/w/cpp/language/class_template#Explicit_instantiation) in the .cc files, not declarations.
Is this supposed to be ironic?
&gt; You can't prevent updates from introducing bugs, that is true, but if you switch to a roling release model and don't give the user an easy way to roll back an update you have to be accountable to a higher standard. But there IS an easy way to roll back. Or more precisely: you can install old toolsets in parallel now using Visual Studio Installer (AFAIK right now it's only VS2015.3, 15.4 v14.11 and 15.5 v14.12, so it looks like the trend will continue going forward).
IIRC VS2017.1 and .2 had no C++ changes, so the options are essentially everything except VS2017 RTM. Odd that it was left out; I wonder if it was too buggy to be considered worthwhile?
with proper IPv6 compression as well, this is so cool!
That compression took a lot longer than expected but I’m pleased with the way it turned out. Btw, you can simplify your initialization to “all ones” by simply stating ~0 instead of the repeated calls to max(). You may need to perform a static_cast to make a compiler warning/error go away. 
Your `operator&lt;&lt;`s can be a single template: template&lt;typename IpType&gt; std::ostream&amp; operator&lt;&lt;(std::ostream&amp; ostr, const ip&lt;IpType&gt;&amp; ip) { return ostr &lt;&lt; ip&lt;IpType&gt;::format(ip); } Indeed, they should probably be a template anyway (i.e. even if your data structure wasn't a template) because as-is your operator only works for narrow streams, which is arbitrary: template&lt;typename CharType, typename TraitsType, typename IpType&gt; std::basic_ostream&lt;CharType, TraitsType&gt;&amp; operator&lt;&lt;(std::basic_ostream&lt;CharType, TraitsType&gt;&amp; ostr, const ip&lt;IpType&gt;&amp; ip) { return ostr &lt;&lt; ip&lt;IpType&gt;::format(ip).c_str(); } N.b. `c_str()` is added because all streams can write `char const*` but not all streams can write `std::string`.
I would've never thought of wide streams. for what it's worth, operator&lt;&lt; was a late afterthought haha, thanks!
Just made a pull request with a basic cmake config, implementing his unit tests with ctest. Should get things started.
Modules and reflection are far more important.
This has been proposed to the committee before but I don't know what happened with it.
Thanks! It`s nice. 
&gt; Maybe I'm missing something here, but I feel like this is something we could have done on a lot of STL functions as well, but haven't. Because it is easy to mix things up. For example vector&lt;int&gt; (10, 20) can mean 10 elements with value 20 or 20 elements with value 10 if you allow permutations. For template parameters it is easier since they are usually complex types you can distinguish with Concepts.
Hi, I wonder, what would be the best practice to use instance of a logger? I suppose this would be one of those rare cases when singleton is inevitable... Or? (let's say DI framework is out of scope)
&gt; we effectively increase the amount of branch predictor history retainable by 30%. Similarly, cache is limited, if we generate 30% less stuff, we effectively increase the L1/L2 caches by 30%. And so on. Yes, key word being "if". :) Also note that 30% increase in cache branch prediction cache is not equivalent of 30% perf increase. So again without any numbers all I can say it probably helps, but hard to know how much. &gt; Did you not see me mention that me and said supporters have spent many years of our careers writing memory allocators of various kinds? &gt; OK, to be clear what we disagree and agree on since it is a long reply chain. We agree on: [arena allocators](https://developers.google.com/protocol-buffers/docs/reference/arenas) are huge perf win. What we disagree(I would need data to be converted) is this: "One can also purge allocators from the container's definition, and hugely simplify implementation which then turns into much better codegen. The gains are enormous." In other words I believe making A in vector&lt;T, A&gt; something non default can be amazing, but IDK if removing A from vector(so we have vector&lt;T&gt;) is that great. &gt; I actually agree strongly with you on this, indeed I have lobbied, and will continue to do so, for LEWG to hard prioritise submissions from Boost or an equivalent. I think this is great, assuming Boost review process is good. I am not trying to get you triggered, all I am saying that my only worry is some legit C++ library being rejected because it does not follow the spirit of the boost or something... &gt; https://wg21.link/P0546 proposes a span&lt;T&gt; attribute mechanism. I implement that customisation point with span colouring, so for example you can colour a span to say it non-volatile RAM, and thus if you execute a CLWB instruction on the span, that's equivalent to fsync() for that file. Which may save on actually calling fsync(). Another useful colouring is alignment, so you can say that a span may be assumed to always be aligned to some byte multiple, and always be some byte multiple long. The compiler may then use SIMD. I've already got a toy implementation for this stuff, just need to write it up. Ah, like I guess it will be like add_const metafunction... It will take span and produce some new type that then means you can apply certain optimizations to it. Cool(assuming perf is worth the hassle).
will definitely give it a try!
RealNC are you saying that auto doesn't work with East const? Clearly this doesn't work because you didn't give it an identifier. This works fine: auto const i(func());
That could work. My suggestion is really a generalisation of something that is already planned anyway: C-style named structure element assignment, which uses the same syntax and is apparently coming to C++ as well. 
Thanks! the idea is pretty simple, all top-level components should have a "tick()" method that processes the output. No big complications. Also, the majority of components require some parameter to be set (eg oscillator frequency, phase etc), the syntax for parameter setting should be "void setParam(type param)". The only public member the components need (IMO) is "sampleRate", all the others should be private, accessible via the specific method. I still have to choose if it's better for the tick() function to be of type void and have an "fp_t out*" argument (fp_t being the typename for a floating point capable template) and pass the output via referenced argument: template &lt;class fp_t&gt; class MyComponent { ... void tick(fp_t* inputSignal, fp_t* outputSignal) { ... } ... }; or just return it normally (eg. fp_t tick()) template &lt;class fp_t&gt; class MyComponent { ... fp_t tick(fp_t* inputSignal) { ... return outputSignal; } ... }; Any suggestion?
Honestly, we're usually just fucking around.
Unfortunately, the C++ element assignment is as nice as in C because specifying members out of order is a compiler error.
If you want other alternatives, Meson is a modern build system that is even simpler to use and cross-platform friendly. 