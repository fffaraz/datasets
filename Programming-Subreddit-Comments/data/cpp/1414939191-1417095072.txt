This is a really good talk (even without the video). 
Hi! Since you're starting, you'd better start getting acquainted with more modern tools: #include &lt;algorithm&gt; #include &lt;iostream&gt; #include &lt;iterator&gt; #include &lt;numeric&gt; #include &lt;vector&gt; int main() { auto numbers = std::vector&lt;int&gt;{1, 2, 3, 7, 9}; std::copy(numbers.begin(), numbers.end() - 1, std::ostream_iterator&lt;int&gt;(std::cout, " + ")); std::cout &lt;&lt; numbers.back() &lt;&lt; " = " &lt;&lt; std::accumulate(numbers.begin(), numbers.end(), 0) &lt;&lt; std::endl; return 0; } References: * [ostream_iterator](http://en.cppreference.com/w/cpp/iterator/ostream_iterator) * [accumulate] (http://en.cppreference.com/w/cpp/algorithm/accumulate) * [copy] (http://en.cppreference.com/w/cpp/algorithm/copy) * [use of auto] (http://herbsutter.com/2013/08/12/gotw-94-solution-aaa-style-almost-always-auto/)
IIRC I even expected `reinterpret_cast` to do what you propose when I learned C++ 7 years ago. And now, where I started learning Rust this reminds me of `mem::transmute` which does what you want in this case. :)
Note that memcpy should only be used on simple types, i.e. int, float, etc.
I wonder why you have to move them at all. Using some indirection, if you find you are moving blocks of memory often, you can leave them in place and hold a smart pointer to the individual vectors. You will pay a small price for the first level of indirection, but that should be far cheaper than copying each element one-by-one. Depends on your requirements, I suppose.
Formally, it should only be used on [Plain Old Data](http://en.cppreference.com/w/cpp/concept/PODType) types. This includes built-in data types and structs/classes that only contain POD types and don't do anything funky on copy or destruction.
You should get used to thinking in zero-based indexing, so the first N elements are 0:(N-1), not 1:N. If you want to reference your 1-D vector using 2-D indexes, you just need something like this: ii = icol * 8 + irow; where icol is the column index, irow is the row index, and ii is the index into the 1-D array, which stores the 2-D values in column order (i.e., elements in each column are contiguous, and the N-element column chunks appear one after another). This is a fairly C-based way of approaching the problem; others have suggested purer C++ solutions.
Yes. In most numerical software, N dimensional arrays are just abstractions of a linear block of memory.
That part isn't a problem - I was a high school math teacher in my first career and work in R, Netlogo, and a number of other platforms with different indexing. Here's a simple thing that I simply don't know how to do in C++ yet - how do I copy in just the 0th to 10th element, and then do it again with the 11th to 20th element? This is an area where R has C++ beat - one can simply call a matrix in any subset of it's elements by calling the rows and columns inside the brackets--&gt; matrix [1:3, 8] &lt;- would update the 1st to 3rd rows, 8th column. 
I believe that the standard *does* require `memset`-ing a pointer to zero to produce `NULL`.
This is why I think Rust's macros are such a bad idea. They operate on tokens, not the AST. 
Holy shit you're nuts. I forgot how crazy macros got. 
Ah - so in R one can simply make matrix [,1] &lt;- vector[], moving all the values at once. If I have a vector with N values and I want to place them in the first column of a matrix with N x Q values, is a for loop simply the fastest way? I was sure I could simply move all the values at once from vector to matrix. 
In this context, it's probably wiser to use a unique_ptr, which is 0 overhead.
I don't see the point, there are so many todos that I'll be completely different after its been reviewed and I'll have to be done again. Someone correct me if I'm wrong.
1. use boost::filesystem instead of direct winapi calls 2. make good names. It is completly unclear what game function do. And the comment will not replace some nice name. The same for aair. 3. a lot of constants in code. move them somewhere and make a nice names for them 4. global variables - pathcontainer. and indexes for operations on pathes? Copy(6, 12); Copy(11, 13); Copy(10, 16); Copy(2, 3); Copy(4, 5); This looks like a complete mess. Try to read this book and then rewrite this code if necessary http://www.amazon.com/Code-Complete-Practical-Handbook-Construction/dp/0735619670 this one.
Actually stopping by the library just now.
 * Your main() method is too big. It should be composed of several smaller methods with meaningful names. * instead of &amp;vec[0], use vec.data(), it is specifically designed for this. * URLDownloadToFileW -&gt; no success check is done. **Basically, no error checking**, as I see * can you say at one glance what this line does: pathcontainer[19] &lt;&lt; (std::wstring(&amp;cwd0[0]).substr(0, std::wstring(&amp;cwd0[0]).find_last_of(L"\\/")) + L"\\"); or this: if ((cpuInfo[2] &amp; (1 &lt;&lt; 27) || false) &amp;&amp; (cpuInfo[2] &amp; (1 &lt;&lt; 28) || false) &amp;&amp; ((_xgetbv(_XCR_XFEATURE_ENABLED_MASK) &amp; 0x6) || false)) * use enum instead of int (void Copy(int from, int to) ), use std::map&lt;Path, std::wstring&gt; * yeah ... there are some more, but for now it's enough
I mean sure its great for code reviews, but practically speaking the end users shouldn't really care how things are formated. But it's not about formatting, just wanted some sort of template that i could go from through this review.
Good point, or better yet, a std::vector&lt;int&gt;.
End users shouldn't care, but YOU should. You spend minutes writing code, but weeks reading it. Optimize your formatting to be easily read.
God damn there are some awful suggestions in this thread. You nearly touched on the best way yourself. Use a Numerical Linear algebra library like Eigen, NT2 or MT4 for quality, of Boost.uBlas for ubiquity. Then simply take a vector slice of the matrix type and assign the vector to it. Don't be fucking around with vectors of vectors, or smart pointers. And if you want to make it fast make sure it's linked against a decent version of BLAS and LAPACK if you need it. This example uses uBlas, but all libs should provide a mechanism to do this. #include &lt;boost/numeric/ublas/matrix.hpp&gt; #include &lt;boost/numeric/ublas/matrix_proxy.hpp&gt; #include &lt;boost/numeric/ublas/io.hpp&gt; int main () { namespace ublas=boost::numeric::ublas; ublas::matrix&lt;double&gt; m (3, 3); ublas::vector&lt;double&gt; v (3); v(0)=1.0; v(1)=2.0; v(2)=3.0; //get a vector slice of an array ublas::matrix_column&lt;ublas::matrix&lt;double&gt; &gt; mc (m, 2); //assign a vector to the slice mc=v; std::cout &lt;&lt; m &lt;&lt; std::endl; } If linked correctly, this should just call into the FORTRAN sub DCOPY or similar which will be extremely well optimised.
Hi vlovich. Thanks for the explanation, but I am sorry, still don't get it. The #includes you say are not present in the example code. Maybe you can provide links to the code, I think there may be a misunderstanding here. I have run myself the example in the blog, the result can be found here: http://www.biicode.com/diego/diego/clientserver/master The person.pb.h: http://www.biicode.com/diego/diego/clientserver/master/0/person.pb.h The person.pb.cc: http://www.biicode.com/diego/diego/clientserver/master/0/person.pb.cc Maybe you are talking in a figurative way, and those #includes are just examples. Even in that case, I think I dont understand the problem. If you use "person.h", yes it pulls "person.cpp", because it is indeed needed. If "person.cpp" requires in turn some logging framework, yes, it will also pull it. It is relevant, your "person" code needs it to build and run. There are no duplications, retrieved dependencies are stored in the "deps" folder (read-only) to be built and linked with your project, but are not intended for collaboration or modification. For managing divergent versions of code, we obviously recommend forking on a VCS (github), and publishing it to biicode from there, can be easily automated with travis-ci. 
Initial comparison tables where added, comparing multi/single threaded performance vs boost under Ubuntu. 
Thank you very much! I just want an easy way to set/retrieve values on some tree nodes. In the above case I can't infer that the value '["a", "b"]' is connected with a previous parsed/reduced '["a", "b"]'.
I'd be happy to see that. I'm currently using [pantheios](http://www.pantheios.org/performance.html) for a project and would be interested to see how this fairs against it. 
Do we really need to be concerned about logging performance? does it matter
As arrays can contain other arrays, then I would say you need have a vector of variant. The variant should be capable of storing another vector of variant. You might be able to use boost for this, or you could write your own.
I don't have an issue with C++ itself, I can handle that. The issue is that the order of reductions doesn't follow a tree like walk. Imagine that I have '[1, ["a", "b"], 2]': i) In the ["a", "b"] reduction I can store "a" and "b" in a list (in this case "a" and "b" are element value rules that are added to a list that is initialized empty). ii) Then, "much" later the ["a", "b"] appear as a value, so here I need to retrieve the list that I filled in (i) but there is not way to know (or I don't know how with parsertl) connect this ["a", "b"] with the previous list. iii) I don't think this can work following your example on parsing math expressions using stacks. For example, in ANTLR or in YACC/Bison you can return values in the rules (in this case the list) and use this value when the rule appears in another context. I don't know how to achieve this with parsertl. Thanks!
Some of us do.
How about a try_push in the blocking_queue instead of timeout. Maybe you should just template out the protection mechanism from that queue so the user can decide the strategy at instantiation time. How does it compare against other loggers if you don't use your custom "fast_itostr" function? Cause frankly I don't trust it. It wasn't clear from a first glance if you were doing your formatting before pushing on the async logger queue or after, but be sure it's after.
fast_itostr is only used internally by the formatter to format dates, and so far it works great. When the user does logger&lt;&lt;some_int, the regular std::ostream number formatting is used.. Why format after the push? I actually format before the push so the formatted timestamp reflects the time the user issued the log message, not when it actually got to its destination.. 
&gt; Why format after the push? You might what to log something that is expensive to format.
If I wasn't concerned about performance, I wouldn't be using C++ to begin with.
I'm not totally clear on what you're doing. This might help. http://gallery.rcpp.org/ Note, c++ has changed a ton since then. Here's a start http://www.stroustrup.com/C++11FAQ.html# 
What is boost.log doing that's slow?
That's fine, but most people use C++ because they DO care about performance, and C++ is used in domains where performance is one of the top concerns. Sure, some people might use C++ and not care about whether it performs well, but that's not the majority and it's certainly not the manner in which C++ was designed or continues to evolve as per Bjarne's own reflection of the history of language in C++ Design and Evolution.
What I'm saying is that since C++ is good enough most of the time, I don't need to worry about whether it performs well since it does. I don't wake up and think "performance", because I don't need to. We're both saying the same thing, I just have a different perspective on it.
Right. There is no intention to compete with boost feature wise. The idea is to have a high performance, convenient library with just enough features to make it easy to install and use. &gt;Plans for forum to discuss it? Issues is great place to discuss I think.. Saw your mingw issue. Thanks
Why don't you try to solve the question, and we can give you help if you are stuck?
Not at all. You often hear c++ is only useful if you're overly concerned with performance and so the impression others might get is you spend all day fiddling with bits and object layout. In fact, the design of c++ makes it so that the defaults are usually good enough. The point elsewhere about formatting after pushing on the queue is an obvious optimisation though.
Actually... yea it does. Not always, and only when you're into the 'where can I get one more hundredth of a percent' stages of optimization but when you realize that your logging is actually taking up measurable percentages of your resources then it does matter.
Pantheios is literally horse shit. The day I deleted all traces of it from my code base in favor of a logger I implemented in a couple of hours was a very good day.
&gt; if you have any idea about how this compares to g2log in terms of speed. I have no idea but I will bench soon. From my understanding g2log is all about async logging, where in spdlog it is just an option (and not even the fastest when to queue gets full and back pressure is being applied) One thing that always bothered me in g2log is that the queue size is unlimited and no back pressure is applied, so the process would just crash if it constantly logs faster than the disk is able to write. Also , there is no support for changing log levels at runtime (one of the most important features that a logger should have IMHO )
How would that be any different to just putting the data member in the base class?
Yes, it was a figurative example. The point I was trying to get at is that a poorly designed library (&amp; even a well-designed one) can pull in a lot of transitive dependencies. Boost has a tool that lets you extract just the pieces you want, &amp; it has this problem as well (extracting just 1 piece pulls in a giant portion of the codebase anyway). Versioning and proper explicit dependency management via compiled libraries is actually a good thing. It puts the developer in control of which version of which library they want. It would be a shame if my project stopped building just because some third party published an API-incompatible version. Don't get me wrong. This is awesome for smaller-scale projects. For larger multi-component projects, I don't think it scales as well. What happens if two projects depend on sqlite? Each builds &amp; statically links against the same codebase? That seems like a giant waste of RAM &amp; compilation time.
Just define pure virtual accessors.
Right. Originally you said *pointer* to the char array as opposed to the array itself. If you actually need to retrieve a pointer to the first element of the array via the base class, you can use a pure virtual function as somebody else suggested.
Both bench using synchronous sinks that employ file rotating after 10MB. 
Is it possible to plug in my own logging provider? I have an existing system I need to log to at work, but I like to write my code that is logging sink agnostic since depending on the context the code is run in (unit testing, production, etc.), I want the logging to go to a different destination. EDIT: I like the API, btw, good work!
&gt;Is it possible to plug in my own logging provider? Sure. All you need is to implement the sink interface (sinks/sink.h) Moreover if you want the lib take care of thread locking for you, you can inherit from base_sink.h instead and implement the protected _sink_it function (see null_sink.h or file_sinks for example)
Take a look at this submission's score. Noticed the distinct LACK of upvotes? It's almost like we don't enjoy doing your homework for you.
insert: if(data &lt;= root.data) search: if(root.data == data) return true; else if(data &lt;= root.data) No. Yes, it's a modernized reflection of your original...which is broken.
By the time a student got to learning this type he would already have needed pointers. RAII should have been taught then. If they're fucking with pointers I'd hope they've learned more basic constructs like lambda. Templates? Meh. I'd probably teach them after pointers...maybe...but before the binary tree. I'm more disturbed by the fact that he's teaching the actual ADT incorrectly. His binary tree accepts multiple instances of the same value but doesn't allow you to search them. It also pointlessly uses `&lt;=` in an if/else after `==`...which isn't going to have any observable effect but it's still pretty disturbing.
And the obligatory source: http://isocpp.org/blog/2014/09/trip-report-cppcon-2014
If you can't move without creating zombies you probably shouldn't implement move at all, and maybe not even copy if the object is really complex. This is the time where you begin passing pointers around instead.
Awesome, thank you!
Rather than doing your homework for you, I would rather you just fail so you dont end up scamming your way into a job and causing your co-workers hell. 
 Foo *x = new Foo(); some_consuming_function(std::move(*x)); // invokes dmove, *x is not destructible after this operator delete(x); // deallocates memory without calling destructor While a function can std::move a reference, potentially creating a zombie object I'd call that terrible API design. The solution to the above problem is this: { auto x = std::make_shared&lt;Foo&gt;(); some_consuming_function(x); } some_consuming_function() can store the object away or not, it doesn't matter: { auto f = std::make_shared&lt;Foo&gt;(); if (rand() % 2) { some_consuming_function(f); } else { some_copying_function(f); } } If you really really want high performance then just pass a reference to raw pointer around. Set it to zero if your function decide to take ownership of the object. Deleting a nullptr is OK.
Very nice. Google Mock configures mocks using this paradigm. I've been using it for years and can't think of an easier way to "configure" things which require a lot of parameters: EXPECT_CALL(turtle, GetX()) .Times(5) .WillOnce(Return(100)) .WillOnce(Return(150)) .WillRepeatedly(Return(200)); Of course there's some macro magic here but conceptually it's the same. Now combine it with either of recent [Herb's](http://isocpp.org/files/papers/N4165.pdf) or [Bjarne's](http://isocpp.org/files/papers/N4174.pdf) proposals and you've got a pretty powerful tool in your hands!
If f() can conditionally turn y into an unusable object this needs to be documented. f() should probably return a value to indicate this or be refactored to not take ownership over objects that are passed by reference because that's terrible. Who would make an API like that? Even passing raw pointers around is better design that that mess. 
Okay sure, f documents that it conditionally turns y in an unusable object... so what? The compiler doesn't know this, and as such the compiler still has no statically verifiable way of checking whether a destructor is safe to call.
The moving is not built into the API so it has nothing to do with the API design. Rvalue references were carefully designed so that moves would occur implicitly only where it was clearly safe, and otherwise it would require the client, not the API, to be very clear and explicit about their intent to move, requiring them to type in `std::move()`. Using smart pointers and shared ownership is not a good substitute for move semantics, nor do I think that passing around pointers and having changes of ownership indicated by setting pointers to null is a good design. An API may be better and clearer when it is simply: void some_consuming_function(Foo f); as is implied in my original example. I don't see that using shared pointers or references to pointers improve this API at all. On the other hand, I wouldn't blame you for complaining about the usage of this API I in my example. That was not intended to be an example of good style. It is merely a demonstration of a problem with the non-proposed `dmove` operation.
My interpretation was different. Each module is pre-processed into an implementation-defined AST. Importing module simply loads the AST (at compile-time). There's no link-time requirements in modules. Modules will specify which types/constants etc (i.e. symbols) they export. Modules by default will not export anything. Circular dependencies shouldn't be a problem normally: I don't believe the AST requires symbols to be resolved.
Please fix the spelling mistake (Behavior -&gt; Behaviour). it's kinda painful to look at (as a Canadian) :P
I've enjoyed looking through your teams code - very nice. The commenting and example usages are great. I've been looking to replace boost posix/gregorian time in some of my code, and will definitely be looking even closer at yours to see how well it will work for me. Thank you!
That's...surprisingly convenient for me. There was a bug in boost.serialization that eventually got patched and I was going to try and hunt that down and cherry pick it...but now I don't have to! Other than that, this seems mostly like a bug-fix release with little features added here and there to you favorite libraries. Great job boost folks! Also, &gt; \#6787 boost::thread::sleep() hangs if system time is rolled back made me giggle a little bit. I'm not sure why.
Could be based on [this](https://github.com/klmr/named-operator/).
You have three cases: 1. Your hard-drive can keep up with your data stream. 2. Your hard-drive can usually keep up with your data stream (spikes due to system load) 3. Your hard-drive cannot keep up In the first one, you'll just serialize the data as you get it without buffering. You can move the data to a secondary thread dedicated for writing. The second scenario is basically this although you allow for a memory buffer to grow as data comes in. In the third scenario, you have to re-evaluate your algorithm/requirements (log fewer samples, improve the runtime of your algorithm etc). I would stay away from iostreams (boost or otherwise) &amp; stick to writev/WriteFileGather if performance matters. I wouldn't bother with memory-mapped files. It turns out in practice they're indistinguishable if you make sure that you avoid lots of small reads &amp; you're not reading in data that can just be read directly once memory-mapped (i.e. there's a deserialization step). For sequential performance, you may consider using buffer pools instead of 1 contiguous array. This will limit your memory usage to your current peak working set instead of peak working set for execution. For example, have buffers of 16k. If it fills, allocate another 16k. Use writev/WriteFileGather to dump any full buffers to disk. That gives you the nice benefit of amortizing the CPU prefetch miss while limiting your memory usage. Unlike vector, this also guarantees that your iterators are stable since your buffers are write-only or immutable once they're full. Additionally, you can free chunks of data without invalidating iterators &amp;, more importantly, freeing the chunks is O(1) which it isn't for vector unless you're freeing the entire array (erasing from front is expensive). Overall, here's a good starting architecture I would recommend: * 1 thread dedicated to reading the input data. Move the input data into a thread-safe shared FIFO queue* * 1+ thread(s) dedicated to running your compute algorithms (depending on how parallelizable they are). Pop items from the shared FIFO queue. If you're falling behind, drop events on the floor as appropriate. Move the data you want to log into a thread-safe FIFO queue/throw it away if the logging thread isn't dumping it fast enough. * 1 thread dedicated to logging the data you want. You can look at implementing your FIFO queue using shared memory instead of something where you have to shuttle data around. A circular memory region could even do the throw-away of data for you as you fall behind. \* on OS X you'll want to *really* avoid std::mutex. Use dispatch queues to implement your FIFO queue. On Linux std::mutex should be fine. On Windows, it looks like CriticalSection is the better primitive than std::mutex.
Does it work with VS 2013 yet? 
Your "modernized" version is actually much worse, it cant handle the empty set and as /u/Crazy__Eddie pointed out, its comparisons are broken. Also, you should wrap your node into some container interface instead of exposing node structs. Here is a much nicer implementation of a BST: http://ideone.com/cZPwj6 It has the properties that it cant leak, is more abstract (no exposed node struct), insert and exists run in constant space and the code is as simple as possible.
I would prefer a benchmark comparing the fastest time (read, the async versions) if I care about the performance. If I don't, I might as well go for Boost.Log anyway.
Your review is the best one yet, will use it is a guideline when I edit the code. EDIT: so far i've "upgraded" the code with a few things mentioned in your review. Did not know about compilers might not do return value optimizations, will implement this asap. About inclusion guards i've read about them but never used them, thanks for refreshing my memory.
`unique_ptr` is as a drop in replacement for owning pointers, and for that it does it's job very well. However, I would suggest that instead of going to `unique_ptr` first, developers first see if either `boost::optional` (if you need nullability) or `value_ptr`/`clone_ptr` (e.g [mr-edd's value_ptr](http://www.mr-edd.co.uk/code/value_ptr)) (if you need heap allocation) would be more appropriate. Both would solve your issue of unsafe dereferencing because `boost::optional` throws, and `value_ptr` can never be null. You could always write your own `safe_ptr` that operates like a `unique_ptr`, except that it throws an exception when you dereference a null pointer. Or maybe you write `safe_ptr` without dereference operators and just have the following functions. template &lt;typename Function&gt; void safe_ptr&lt;T&gt;::alter(Function f) { if(this-&gt;p) { return f(*(this-&gt;p)); } } template &lt;typename Function&gt; void safe_ptr&lt;T&gt;::apply(Function f) const { if(this-&gt;p) { return f(*(this-&gt;p)); } } template &lt;typename Function, typename Return&gt; Return safe_ptr&lt;T&gt;::apply(Function f, const Return&amp; value_if_null) const { return (this-&gt;p) ? f(*(this-&gt;p)) : value_if_null; } // Example safe_ptr&lt;int&gt; i = nullptr; int next = i.apply([](int x){ return x + 1; }, -1); // next is now -1 i = new int(4); int prev = i.apply([](int x){ return x - 1; }, // prev is now 3 i.alter([](int&amp; x){ x *= 2; }); // i is now 8 i.apply([](int x){ std::cout &lt;&lt; x &lt;&lt; std::endl; }); // prints 8 to cout; EDIT: whoops, forgot `&lt;T&gt;` on member function definitions
biicode sounds interesting, don't get me wrong. The architecture I designed a few years back was more influenced by bitbake &amp; OE. Each component had a recipe &amp; you could build any version of a component (recipe's could have version-specific information as needed). A project was a listing of top-level component + version that needed to be built. Each component could also depend on other components. So no, you couldn't include just 1 header &amp; get just some small subset of an external project implicitly included. Yes, it was more maintenance since you actually had to specify the build recipes for each component (one-time setup). However, it did force you to organize your projects. It was also in a sense more flexible to individual projects (could be auto-conf, cmake, something else) &amp; let you specify whatever features you needed from a project. That being said, I imagine you'll probably end up adding such features if you start targetting larger-scale projects. I think such an approach also let's small-scale projects scale nicely as they're encouraged to manage their dependencies properly from the get-go.
No I didnt get you wrong! Thanks for all your input! Really appreciate your feedback. :) We know that, many pro-developers and companies end building their own internal dep&amp;build manager to automate tasks, and they indeed define an engineering process which can be very flexible and powerful according to their needs, and they force that extra (but positive) effort of organizing projects properly. The challenge is obviously to build something as wide as possible, and as simple-automated as other existing (other languages) deps managers, for many people without the resources, experience or time to roll their own manager. Of course we tend to add those features, it is just a matter of time and resources. We are small and have tons of tasks, demanded by our current active users (for small-medium size projects). And as you said, we plan to grow with their projects. What we need is the feedback of devs like you that have experience in this problem, that try it out, and help us to prioritize and to drive our roadmap to something really worth it. Thanks very much again! Best. 
Just some comments: * new won't return nullptr when out of memory, it will throw std::bad_alloc. * using std::function when stored value is fixed, local and known at all times is not what it was designed for. You should really just use auto there and resort to std::function only when you need to refer to a function-like entity and it can be of different types unknown locally, as in function parameters. * you really should be using *std::unique_ptr* for *left, right and root_* as your pointers imply ownership. * I'm not sold on your use of lambdas all over the place. I feel as if lambdas were used just for the sake of it in some functions where it would be perfectly valid to just put the code inside the function itself. * You should either implement copy constructor/assignment or disable copy as default copy constructor/assignment won't do the right thing for you here.
 1. I have not modelled a tree. I have only modelled a node of a binary search tree and operations you can do given a node. You can easily wrap a simple struct around a root node to call it a tree. This gives the freedom to the user to implement more actions eg. delete, replace etc., 2. I have only reimplemented whatever algorithm was there previously, so didn't care about the algo specific details. Just to discuss whether it looks better with modern c++ Your implementation works but it is not a good way to implement. Why use raw new and delete when you have unique_ptr? 
I'm on a sister team from Lakos' BDE team. I don't want to take any credit for code I didn't write :) The "we" I like to use is Bloomberg R&amp;D. One of the most useful, higher-level packages is a full IANA timezone implementation that sits on top of all of the bdlt vocabulary types. I hope it won't be long before that is released, as it ties everything together very nicely and with bdlt essentially makes C++ datetimes a solved problem if you adopt the libraries.
Keep in mind that at 10kHz, every double of output is ~80kb/s. Unless you're on a really constrained system, you should be able to log all data without saturating your link. Thus, the only thing to watch for is if latency is important for your computation: if it is, then move the writing to a different thread.
I can finally compile boost with msvc12 for HPX and not have to pull my hair out! Today is a good day
&gt; Keep in mind that at 10kHz, every double of output is ~80kb/s. Unless you're on a really constrained system, you should be able to log all data without saturating your link. There could be as many as 900 floating point values to log at each sample point, is the thing.
Thank you for writing this! I've tried to get into SIMD a couple of times, but always hit the stumbling block you describe in your first post - namely that most of what's out there doesn't actually teach you how to use the instructions in real code. Are you going to write any more articles like this? I'd be particularly interested in designing custom allocators, SIMD-izing more maths functions (as you hint in the last post), and examples of using your wrappers in real-world scenarios.
Passing shared_ptr&lt;T&gt; by value implies ownership to the reader, and it tells the compiler to increment and decrement a reference count, destroying any hope of cache locality. And if you have a circular reference it tells the compiler that this instance should never be destroyed. Oops. Anyway, getting into the weeds of parameter passing in C++ was not my goal. The main point is that shared_ptr is not perfect, and should not be used everywhere. Passing by value, reference, and, yes, even raw pointer is preferable when writing code that does not need to free or delete memory (which should be *most of your code*).
Quite interesting. Keep on with the project, will follow it ;)
Curious about how well auto vectorization would work on whatever project resulted in this approach...
Why?
Auto works well until you use mat functions like pow or sqrt - last I remember those are not vectorized with gnu math library. I think I remember intel's were though... Long story short buy an nvidia gpu and use cuda... It can save time and money
[Boost.Compute](https://github.com/kylelutz/compute) provides a high-level, STL-like API for GPU/parallel-computing and is cross-platform (built on OpenCL).
herb would also add that there is no break; so it is more readable...
More complex techniques can be employed, including implementation of memory pools through those structures. Suggesting so would have been a little too much in response to the assumed C++ experience of OP. 
WTF do memory pools have to do with 'don't use shared_ptr unless you need it'?
Thanks! I fixed it, here is the new version :) I just need to make it uncopyable. https://gist.github.com/zxmarcos/ba0fbd048c3c8bd61278
&gt; There is the opposite side too. To some, C++ is the One True Programming Language, which is obviously an exaggeration. To be honest, I don't think it is an exaggeration. I couldn't count C++ weaknesses over the course of a decade, but I've also yet to see anything that can replace it, nor anything it cannot replace. There are a lot of strange claims about, like it doesn't do well in implementing web systems, but so far I have found them all false--there's nothing convincingly better about the languages people DO use a lot for web services that has me wanting to go there. Except for the fact that there are less job opportunities (though still many) in C++ I would label it at *the* language everyone should learn. 
1us for a log line on average is pretty good, but you can definitely do better. From experience, you should be able to get below 500ns generally, and on a good computer, &lt;100ns fairly consistently. You should also accept format strings since passing everything through the stream operator is not fun. Something like console-&gt;info("%u", 32), etc. Having a set_pattern seems redundant to me.
You also need to link to it, by going into linker settings and adding the headers you want to use. This might help: http://www.gamedev.net/topic/537599-how-to-link-libraries-with-codeblocks/ I also want to suggest looking into Linux. Since Linux distros use package managers, they handle this installation for you. Even installing Linux on a Virtual Machine would make your life much easier. 
you're talking about Nt² ? I think it has not been integrated in Boost yet. Anyway, I mention it in the introduction, it works well and has a really comprehensive set of mathematical functions, but is quite hard to extend (in my case I had to implement numerical types for tropical algebra), and really increases compilation time (at least last time I used it)
Not sure what a header is - what format are they in?
I'm glad if it helped! And yes, I am currently working on an howto article about aligned memory allocators, and plan to write other articles about vectorization
Boost.SIMD is a part of Nt².
Out of interest, why did you choose to represent Datetime as a tuple (year,month,day,hour,minute,second,millisecond), rather than something analogous to a high-precision time_t? To me, this looks like a representation-of-a-time (requiring context to correctly interpret), rather than an unambiguous point in time. This implementation sounds like it requires the user to have a particular timezone (hopefully UTC) in mind, and makes comparing two Datetimes hazardous if they're thought of in two different timezones - e.g. auto now1 = CurrentTime::local(); auto now2 = CurrentTime::utc(); now1 and now2 represent the same point-in-time (ignoring the fact that the calls don't take zero time), but (probably) in a different way, and aren't safely comparable. I'd argue that there's only one correct answer for "what's the current time", and should only be one function for getting it. Choosing to represent that time in a particular timezone is something the end-user should do when displaying it to a user. For comparison, Python's native datetime library does pretty much what you do (year, month, ... with optional timezone), while numpy's datetime64 gives you the equivalent of a high-precision time_t (number of seconds since a fixed point in time).
The hypothesis talks about developers from 1990 and early 2000s. I don't think they're the one who despise C++, they're mostly mature developers who've a better understandings of the system innards. They just love having more control with their code, while appreciating the simplicity of new languages, like Lua. It's the younger programmers who've started programming with 'easier' languages when have to switch to C++, they just don't understand the complexity, and they find it pointless. I've met young developers who just don't understand why C uses strcmp(string1, string2) and not simply 'string1 == string2'. It's really hard to explain them. While a C++ programmer can easily switch to using strcmp(), although it's still a step backwards. For example, say a python programmer has to implement his logic in C++ but he soon discovers that it's not that easy. Say for his calculations he need a storage for huge integer types, which isn't directly provided by C++, so they get frustrated and start nagging about how easy it was with python. OP please post this to /r/programming to get a better discussion. Here you'll only find developers who think that C++ is in fact the One True Programming Language, including me.
The only I problem I have with this code is a big mistake in regards to some of your function parameters. Example: inline float hadd(const vector4f&amp; rhs) { #if SSE_INSTR_SET &gt;= 3 // SSE3 __m128 tmp0 = _mm_hadd_ps(rhs,rhs); __m128 tmp1 = _mm_hadd_ps(tmp0,tmp0); #else __m128 tmp0 = _mm_add_ps(rhs,_mm_movehl_ps(rhs,rhs)); __m128 tmp1 = _mm_add_ss(tmp0,_mm_shuffle_ps(tmp0,tmp0,1)); #endif return _mm_cvtss_f32(tmp1); } You never want to pass __m128 or vector4 values by const reference into intrinsics, ALWAYS pass by value when you can. The indirection through reference is not necessary because the simd registers are already natively 128bit - 512bit wide depending on the instruction set you are targeting. A copy is essentially free as it immediately gets stored into a register. If you do an asm view of your code you will see what I mean.
I think this is a case of the loud minority. Any programmer worth their salt knows every language has its place.
Well even a recent and used programming language like Java doesn't support == for string comparison actually.
Very nice. Last time i tried vectorize some code was by using ispc (semi automatic spmd approach). Worked very well but it is alot harder to integrate into a project than a nice template library. 
Header files are the files with .h extension. It has been some time since I've done anything on C, but if I remember right if you have a "foo.h", you need to add "foo" to linked libraries or -lfoo to other linker options. 
I like C++, but no other language these days (with the exception of C), has such a terrible story with third-party libraries. It seems like C++ is the only language without a package manager for developers (also distributing binaries is a giant PITA even if we did have a package manager).
I think one of biggest C++'s complexity or annoyance is the lack of a huge standard library like python, java and such, and the other one the sometimes too hard integration of a library in your project (SOs, compilers, compiler versions, etc). I mean, other languages already have a standard, multiplatform package manager which C++ can only dream of.
Yeah, the tooling support is shit. That's fairly indisputable...or at least I can't fathom an argument that would be for the, "It's all we need," side. I do think it's improving though and like the clang libraries have created a sort of explosion in tooling support...that still has much catching up to do.
&gt;But just to write your average program is C++ actually all that more complex than anything else? For a new programmer yes, for a newish programmer with some experience with a more managed or weakly typed language doubly so. More popular languages such as javascript or php will bend over backward to try and run your early buggy programs without so much as a peep (unless you actively go looking for warnings). C++ on the other hand will vomit pages of template errors at you for the slightest typo, or simply smirk and not say anything as you blunder into the land of undefined behavior. Learning these and other intricacies such as the ODR or vexing parses might not be hard to understand separately, but it takes far more time and patience then `echo "Hello world";`.
hehehe - I have the opposite perspective on php and especially javascript. I was writing javascript back when it was just a scripting language to fluff up a website. In the first quarter of this year though I had to use it to write TestComplete tests and holy fuck did I find it horrible!!! There were like three different, completely independent versions of `String` for example. All have their own versions of lower casing. The compiler sure didn't tell me when I used the wrong version. I had to run the test up to the point of failure and exit into the debugger to analyze the type. MAJOR nightmare! It's probably not JavaScript's fault per-se but breaking into the debugger took somewhere on the order of 5-20 minutes. No, not a massively underpowered system...a fairly intense one actually. In part though I think it really *was* JavaScript's fault because shoving that much stuff that should be detected at compile time into run time means that much more crap that the interpreter, in this case a complex testing platform, has to do. I actually really, really hate "dynamic" languages. [Dynamic languages are static](http://existentialtype.wordpress.com/2011/03/19/dynamic-languages-are-static-languages/) BTW.
Because when it comes to C++, many people still imagine "C with classes", instead of modern C++11. Its not always their fault, since many online tutorials still teach "C with classes" instead of modern C++11 approach, and people who come from other languages are accustomed to online tutorials being good, instead of having to learn from books, so they think that is how modern C++ looks like. If your online tutorial covers C arrays and new and delete, but fails to cover std::vector or smart pointers (and accent the importance they have in modern C++ style), you are doing it wrong.
I really hope so. Also I hope modules will help to ease somewhat the tooling and library integration (along with standard ABI stuff)
It's absolutely worth getting boost working. I guess my first question is do you have you use Windows? On Linux it's like a single call to a packageman apt-get isntall boost or pacman -S boost Failing that, just google for the pre built windows binaries don't bother messing around with trying to compile them yourself. Also don't forget that boost has a very active IRC channel and mailing list. Finally boost, was only one of my suggestions, any one of those libraries I mentioned would be capable of the sort of code I presented.
Well ... Qt + Boost seems to cover most of the "standard needs", no ? :p
Does that mean that __m128/vector4 are always passed to functions via registers, not e.g. on the stack ? Is there an ABI for that for the relevant platforms ?
http://gameprogrammingpatterns.com/game-loop.html Do modern games still work like this? I know fuck all about that industry but I would anticipate that they're a bit more concurrency happy. Even modern concoles have multiple cores, no? I would gather there is still an *input loop* of some sort if the system isn't interrupt driven, but wouldn't it just set some shared values or something that alter concurrently running redering tasks and such?
Because you never forget your first ...
Lots of the details differ but it's broadly still how most game engines work. Fully concurrent engines are rare, a more common model is a 'main' thread and lots of subthreads where work is farmed out or dedicated to specific tasks - these are still usually syncronised in some way to the main game loop on the main thread.
I'm thinking trap shift of '[' and create a new vector ptr and push that on a stack as a variant. The idea is that parsertl *only* deals with the parsing, and the processing of that data is up to you. When parsing JSON, the problem you have (as you mentioned) is maintaining a tree structure for your data. You can absolutely do that with a stack if you have a variant that can handle all the data types you need. That way, when parsing is complete the stack will have one item on the stack which will be the root of your tree. Of course the top of the stack is the current context you are working on. As well as handling the JSON data types such as string and number etc. your variant will need to handle vector (for your arrays) and map (for your name value pairs).
Thanks. I guess GUI libraries work similarly to that, with a main drawing thread that absolutely cannot farm its work out. Object of other threads is then to render data into a format that's drawer friendly...making an image that can just be blit whatever onto the window (forget the lingo--been systems programming too long :P). Any attempt to break out of that paradigm breaks the hardware optimization so the fancy new shit no worky anymore. No more XOR rubber banding and such...I learned that the hard way. Gaming is one thing I rather wish I'd gotten into. I gather it's not the awesome job people think it would be--lot more fun playing them than making them--but I might have been good at it and had a good time. But that's not where the job line took me. Oh well :p Still fun to think about.
What was the bug in boost.serialization, if you don't mind me asking? 
I don't remember the exact details...it was something simple and silly. I think it was the serialization function for boost::shared_ptr was missing a bunch of #includes or something. Nothing subtle...it just made my build fail spectacularly when I upgraded. EDIT: Found it, https://svn.boost.org/trac/boost/ticket/10348
&gt; but no other language these days (with the exception of C), has such a terrible story with third-party libraries. It's because in C++, this is a much harder problem than is the case for other languages. Not that it's wrong to lament this deficiency, but we should not forget just how big a task it would be.
I thought that surveys were still showing that C/C++ were the most used programming languages?
Thanks!
I've never understood this common "tool for the job" refrain. General purpose programming languages are not analogous to the different tools in a workshop. The language is the workshop. If you want to claim SQL, EBNF syntax, and regex are "languages" OK, but that's not what's typically meant. Ignoring employability concerns, I can't see the point of knowing more than three or four general purpose languages well. Know a fast one like C++ and know a whip-it-up-quick one like perl.
boost is huge and sprawling, but it does serve that purpose. I can completely understand if people don't want to use it because of its size, but it really does hit all the spots of a "standard library".
I think the hate for C++ stems from it being used when another tool would have been a better fit. Well..., that is an oversimplification. The hate for C++ stems from though being the right tool, the devs didn't stick to a sane subset of C++. Well,... what is the "sane subset" for a given task? STL (custom allocators LOL) yes, no? Exceptions yes, no? RTTI yes, no? Templates (a language of it's own with really shitty error message, horrible syntax and unbearable bad runtime performance, really) yes, no? If templates, because it's very very useful indeed, how much of it, where to draw a line? You see, it's complicated, C++ is complicated. However, there is nothing better right now. My current rules of thumb: If you can get away with plain C, stick with C! If you reinvent std::vector&lt;T&gt; for even a small number of Ts and hunt down memory leaks (RAII ftw, C++'s best feature IMHO) all day, it's time for C++. I hope for a GCless, stable language to come around with an C compatible ABI that replaces C++ (Rust and maybe a future version of D). Maybe this language will be a C++XY, not even that unlikely.
Take a look at the docs for MSVC's [__vectorcall](http://msdn.microsoft.com/en-us/library/dn375768.aspx) and the [DXMath docs](http://msdn.microsoft.com/en-us/library/windows/desktop/ee418728.aspx), should be of use (and yes I know mainly MSVC stuff, but apart from __vectorcall its pretty much the same with the Sys-V ABI as well).
If you are planning to use this in scientific apps, you might wanna give Agner Fog's [C++ SIMD](http://www.agner.org/optimize/#vectorclass) library a look-through, its highly optimized, covers all SIMD instruction sets (bar 3DMax!) and is [very well documented](http://www.agner.org/optimize/vectorclass.pdf). If you are just doing this for a learning experience, read through his code anyways :P Only thing its missing are SIMD variants of functions complex functions like log2 (which most libraries tend to neglect, unfortunately, still waiting for the day there is a SIMD'ified CRT lib...), though it does have quaternions. My only problem with these kind of SIMD wrapper classes is the fact that sometimes you actually lose performance by blindly using "the most up to date" SIMD, I'm not sure if this is the case, but last when I made a ray-tracer, using SSE3 hadd_ps was worse that the SSE2 method for 4x4 matrix muls cause it caused too much stalling (due to the higher latancy).
So I have been struggling with boost, and on a hunch I removed #include &lt;boost&gt; - I kept the #include &lt;boost/number/ublas/matrix.hpp&gt; and it started working fine... So I guess i've had it working for an unspecified amount of time and I didn't realize it? 
So I have been struggling with boost, and on a hunch I removed #include &lt;boost&gt; - I kept the #include &lt;boost/number/ublas/matrix.hpp&gt; and it started working fine... So I guess i've had it working for an unspecified amount of time and I didn't realize it?
That's a really great question. I only recently found out what it is that std::endl *actually* is under the hood, because I needed to write an output stream splitter (i.e., to allow something like: Splitter splitter(std::cout, std::cerr); splitter &lt;&lt; "Hello world" &lt;&lt; std::endl; And it taught me a fair amount. But even not knowing that, there's a lot you could talk about as you say!
C++14 will be fully supported by (some) compilers very soon too.
The benefit I've had is working with other peoples code more easily. In the last year I've done C, C++, C#, F#, and at least worked near Lua, Lisp, Python, and a bunch of others.
template runtime performance problems? Compile times sure, but there shouldn't be runtime overheads really (unless you are making use of its turing completeness and the compiler gets to the max recursion depth level and switches to runtime)
A consequence of following C's tradition of having a small library. When C++98 eventually became properly supported across major compilers, there was already C++ libraries everywhere like Tolls.h++ and similar. Thankfully ANSI is now working on having a few more batteries in the standard and partially fixing the ABI story. 
&gt; #include &lt;boost&gt; ermm what, yeah you don't need that! Just include the headers you want; boost as a whole is not a header.
I'm gamedev. It's cool and it has its perks, but it's a lot more fun to play than to make, that's for sure.
Actually, Herb Sutter is pushing toward standardizing ABIs to allow just that. His idea is that much like C, an OS should specify what the Standard ABI for C++ should be on its platform, as well as bless one Standard Library. Then conforming compilers would use both those Standard things, and naturally produce interoperable libraries, like they do for C. Whether this gains traction is another thing though...
The short answer is that yes you can run into "register spillage" when using an intrinsic type such as __m128, resulting in values being stored on the stack, but this is NOT preferred. Let's say that you are targeting a specific CPU that you know has access to 8-16 YMM registers for SIMD usage dependant on whether or not you are compiling for x86 or x64. As a programmer you want to make sure that you do not go overboard within a particular function when using SIMD because the penalty for having temporary __m128 on the stack is quite high. You want to keep these values in registers as long as possible.
Yeah I would say more than half don't know what endl actually is, and the majority of those people can't figure out even after prodding with statements like "well we can put endl in the middle of a stream, it kind of acts like a stream operator, doesn't it?". And I only ask this to people looking for senior roles. Its one of those questions that helps differentiate without being too trivia-like. 
Nice, I'll be following along :-)
Aside from bii, all of the ones you listed are platform-specific package managers for distributions and not focused on C++.
&gt; Templates (a language of it's own ... unbearable bad runtime performance The runtime of the language called C++ templates is when the C++ compiler runs. You could say it's an interpreted language.
&gt; General purpose programming languages are not analogous to the different tools in a workshop. They are different workshops. If you have enough time, you may produce at carpentry workshop every tool and detail you need to repair a car. But it will be rather shitty and paintful repair.
&gt; Yes, because you need to know the contents of a basic systems organization course to understand what some of the most basic language features (integer arithmetic, floating point arithmetic (!), allocation, etc.) are doing. You need to know little about computers to do nontrivial stuff in Python. So, you are claiming that a python developer doesn't need to know how floating points work and when they don't work? .1 == 1/10, always? I don't know Python well enough to say but I would be quite impressed if that's the case. Either that or quite disturbed and curious what the performance impact of ensuring that relation must be.
The `Datetime` vocabulary type isn't supposed to refer to an unambiguous point in time. It doesn't pre-suppose that every possible use case must carry along an explicit offset or IANA timezone with every value. Imagine an application was written to implicitly use UTC everywhere and by omitting the offset, memory is saved if many values exist in memory at once. (You're right -- it is equivalent to a Python "naive" datetime.) We've found in many cases the "context" as you describe it is useful for optimization when being explicit is not necessary. The unambiguous vocabulary type is `DatetimeTz`, which includes the offset and can easily provide either the local or UTC `Datetime` object as accessors. Provided in the higher-level package is the missing third vocabulary type that is a `Datetime` + IANA timezone string. Maybe you want an in-core value semantic type to hold the timestamp from an SMTP header. Since those header values are sent as datetimes with an offset, the `DatetimeTz` can represent exactly what was contained in the header and the rest of the library allows computation/conversion from the source values. The higher-level `Datetime` + IANA string can be used if other `Datetime` values need to be computed in the same timezone (potential DST shifts) from a user input value. The `DatetimeInterval` is for general high-level calendar like computations (millisecond precision) between two `Datetime` objects and the `bsls::TimeInterval` is the vocabulary type for nanosecond resolution differences usually associated with performance timing and other non-calendar computations. For example, `DatetimeInterval` is used to convert a `Datetime` into the number of milliseconds since epoch (needed to create a `Date` object in a Javascript engine): (CurrentTime::utc() - EpochUtil::epoch()).totalMilliseconds(); I hope I'm explaining things in a way that makes sense. We've been using these core vocabulary types for over a decade in all of our C++ and the open-source version is the culmination of that decade of refinement. They've worked very nicely for us internally, so our hope is that they work well for others as well. (I personally won't consider it a complete package, though, until the IANA higher-level bits are available as well!)
When you are one among a thousand, "most used" doesn't necessarily mean much. C++ jobs aren't going away, but it does seem easier to get hired to do something like Java or C# these days.
&gt; But in C++ what concepts do you need to know to truly understand assignment in all its forms? Well, yeah...over complicating things is indeed a problem in the C++ arena. That's not a problem with the language though, but the people who use it. You don't need all that crap you listed to know what `a=b` means in C++. You turned a simple operation into a nightmare for no reason. Only thing you need is to know your coworkers are not total idiots and haven't made `=` mean something absurd. If not though, again...not a problem with the language.
Your second paragraph undermines the first. As for programming languages they are very much like tools in a work shop. I for example have dozens of hammers in my tool box and everyone of them can whack something but only a couple excel at driving nails. So be it with programming languages, some simply are better tools for specific jobs. Knowing which tool to grab for a specific job can do wonders for your productivity and code quality. 
No, floats work in Python the same way they do in C++. The list wasn't meant to be exclusive to C++, though Python integers have arbitrary range and allocation isn't managed explicitly. I emphasized that item since floating point arithmetic and stability are much more subtle than the other items.
Unless you want to specialize, the common thing in consulting is that each new project brings some sort of new technology stack.
Why start from scratch and why not refactor the best open source C++ program [Stockfish](https://github.com/mcostalba/Stockfish)?
Or to put it another way, a 'frame' is usually defined by a few logical event completions (input process is done, 'game state' updating is done, rendering is done). These may be pipelined across threads but the logical events are important. You want games to be as responsive to player input as possible so you don't want to miss an opportunity to apply it. You also don't want too many frames buffered at the rendering level or the game will start feeling 'floaty' and unresponsive (visually lagging behind the input). As a result, those generally need to be synced at some point to insure they stay together. Similarly, you want the motion of objects moving around in the world to render in a smooth way; you don't want to end up rendering a 33 ms interval with no animation update one frame and then 66 worth of motion the next frame. Thats where the 'game state' stage comes in to play. Now, its entirely possible that the loop described is really just serialization points for each of these systems running in separate threads. Or perhaps pipelining of these stages is applied so that one thread is running the state update, another thread is running the previous frames visibility gather/draw list generation, another thread is pushing the draw calls to the card for the frame before that, etc. The update loop is really just the conceptual starting point for all of this.
 &gt;I think the hate for C++ stems from it being used when another tool would have been a better fit. I'd alter this a bit, the problem often is a question of programmers choosing C++ when they don't grasp how to properly solve a problem in C++. Not to be unkind but there are a lot of programmers out there that think they understand the art and science of programming but frankly are a bit short in gray matter. These people couldn't get C++ to work properly for them even if they tried. Having the intelligence of a head of cauliflower will not lead to using C++ well. The same people that can't use C++ effectively write really bad code in Python. A good programmer should choose the best tool for the job, I don't dispute that. However a programmer that can't use C++ OFTEN isn't what would pass as a good programmer. I say often with care here because there are those that could be called good programmers that never touch C++. What I'm trying to say here is that those that criticize C++ the loudest often do so because they can't or won't (can't be troubled mentality) put time into developing programming skills in general. &gt;Well..., that is an oversimplification. The hate for C++ stems from though being the right tool, the devs didn't stick to a sane subset of C++. Or the developer simply doesn't understand the subsets they choose. There isn't a lot about C++ that is truly insane, there is much though that you shouldn't use if you don't grasp the technology. It is sort of like a run of the mill driver taking a high performance car for a drive and crashing, then blaming the car for his not being able to handle the power it offers the driver. A car doesn't crash on its own and sometimes a winter beater is a better solution for the conditions, knowing which to jump into and when is part of getting through life with a minimal of crashes. &gt;Well,... what is the "sane subset" for a given task? STL (custom allocators LOL) yes, no? Exceptions yes, no? RTTI yes, no? Templates (a language of it's own with really shitty error message, horrible syntax and unbearable bad runtime performance, really) yes, no? If templates, because it's very very useful indeed, how much of it, where to draw a line? On the flip side how many Python developers out there right at this very moment have no idea what is going on in their code? I'd think you would be surprised at the number that can barely comprehend what Python is doing under the hood. If a developer can't take the time to understand Python he certainly won't take the time to learn C++. Using a language well takes an effort upon the part of the developer to understand the language and what is going on with that language. The Python developers out there that write great Python code routinely demonstrate a deeper understanding of the language than those that don't - so why do we expect anything different from C++ developers? Yes there is a lot to learn in C++ and in some cases requires a specialized interest but that doesn't keep anyone from becoming proficient in a subset of the language they need. You put in the time and you can have a real payoff in usable skills developed. &gt;My current rules of thumb: If you can get away with plain C, stick with C! If you reinvent std::vector&lt;T&gt; for even a small number of Ts and hunt down memory leaks (RAII ftw, C++'s best feature IMHO) all day, it's time for C++. This boggles the mind really. 
I tend to notice people down-play the amount of computation knowledge required to work in *any* programming language well and overemphasize the complications of the one they particularly don't like or whatever...or as in this case imply there's a difference where there isn't one. It seems to me especially the case with anti-C++ sentiment but I could be biased.
&gt; His idea is that much like C, an OS should specify what the Standard ABI for C++ should be on its platform, as well as bless one Standard Library. Funnily enough that's pretty much what OSes other than Windows' already do. Third party tools have to and already do target the ABI of the OS's default C++ toolchain for compatibility, such as Intel's compilers matching the C++ ABI used on OS X, etc. Otherwise third party toolchains can't even link to the OS's C++ binaries. What Herb Sutter is proposing is that tool chains be required support two ABIs so that one of them can be modified the way the Visual C++ team likes to do, and the other can remain independent and stable, but inter-operate with code that uses the unstable ABI. It seems to me that it's a major problem with the proposal that it makes the current ABI, the one that everyone else relies on for stability, into the unstable one, and proposes that the new addition, the one that nobody else uses or needs stability from, be the stable ABI. This works out fine for VC++ where their existing ABI is already unstable and they just add a new ABI that everyone can finally start targeting for stability (of course everyone already targets each specific releas of MSVC for stability), but it doesn't address the problems faced by platforms that already use their existing ABI as a stable ABI. Basically it would force an ABI breaking change on other platforms in order to move from `std::` objects in their stable interfaces to `std::abi::`
&gt; because there are those that could be called good programmers that never touch C++. ... &gt; Or the developer simply doesn't understand the subsets they choose ... &gt; how many Python developers out there right at this very moment have no idea what is going on in their code? &gt; If a developer can't take the time to understand Python he certainly won't take the time to learn C++ Some claims of mine: What separates a good from the not so good programmers is how they deal with problems, may it be bugs or performance issues. Good programmers will eventually seek to master the tools they use. Those who went through this exercise are unlikely to use a tool they don't think they'll be able (or have enough time to invest) to master. Even if my reasoning isn't entirely science proof here, but I full heartedly believe, that C++ is avoided by a large amout of good programmer because C is just good enough for the problems at hand. The complexity added just isn't worth it. &gt; &gt; My current rules of thumb: If you can get away with plain C, stick with C! If you reinvent std::vector&lt;T&gt; for even a small number of Ts and hunt down memory leaks (RAII ftw, C++'s best feature IMHO) all day, it's time for C++. &gt; This boggles the mind really. Yeah, it's actually not entirely true. I do know enough C++ and more importantly best practices that I can confidently write code that just won't leak and is decently fast. But once things work I think really hard about how long it will take me to rewrite it in C, optimize the code so it can compete with the STL containers, make sure it doesn't leak. Why? Because I'll be done for eternity once it's written in C. I can use it in Python, Ruby, Matlab, Java... without (or even worse others who use my stuff) having to deal with i.e. conflicting C++ runtime libraries (spend a few days figuring out that Matlab crashed in the std::string ctor because of that). 
Thank you for your remarks, but I must say I disagree on some points. 1) What do you do when you want to use it in an existing code ? You replace every arithmetic operator with a stateless pure function ? Beside the fact it requires a lot more changes, I really prefer to read e = a*b + c*d than e = mul(add(a,b),add(c,d)). Moreover, if you want your code to work with both wrapper and scalar types, you have to define overloads of your functions for scalar types too. And finally, not wrapping the intrinsic type __mXXX prevents you from defining operator+=, operator-= and so on. So in my opinion, yes, there's a need to build an abstraction around intrinsics types. 2) I don't know, and I agree with you on that point: we must compare both implementations; I'll do it as soon as I have some time and post the results. 3) This was a temporary example; if you read further, ev.store_a(&amp;e[i]) is replaced with store_a(&amp;e[i],ev), which is a generic function that works with any instruction set. So if I want to compile my code on a machine that doesn't support the same instruction set or doesn't support SIMD at all, I don't have to make any change in my code. This indirection (which maybe introduce a performance hit, but not sure, I will do an asm view) gives me genericity. 4) OK for the constexpr instead of the static, I didn't adapt my code to C++11. But I need the template specialization to get the size of the intrinsics type. As I said, I want my code to be generic enough so I don't have to make any change when I compile it on machines that don't support the same instruction sets.
I actually rarely use Python, and do most of my computation using C++. I just wanted to refute the following point: &gt; But just to write your average program is C++ actually all that more complex than anything else? While I believe that you need to know more background material to write your "average" C++ program than you do to write your "average" Python program, you don't need to know a whole lot. The problem is that many of the best C++ libraries are written more so that the authors can showcase the "elegance" of their user interface than to be easy for beginners to pick up. There's an air of circlejerkiness in the C++ community (much like in many other communities -- especially unapplied academic ones) because people who spent the time going through the standardese and other arcana needed to efficiently solve the most generic formulation of their problem possible want validation for their effort. Just compare the tone of some of the "good" online C++ resources (e.g. the C++ FAQ) to the official Python FAQ. There's a lot of condescension in the C++ sources that I've read, where the author tries to convince the reader that X is morally the "best" way to do something. And "best" changes every few years based on standardization. Even something as trivial as passing arguments to functions is hotly debated among leading C++ gurus (recall the discussion between Meyers and Sutter regarding universal references vs pass by value). And does this even influence codegen in the latest version of Clang/GCC? Say that my "average" C++ program consists of downloading a file from a URL. How can I do this using C++? Googling "C++ download file from URL" brings up [the following](https://xdev.me/article/C%2B%2B_download_URL_to_a_file_with_libcurl) ~30 line listing using cURL. After you go through the process of setting up cURL (whatever that happens to be for your OS), you can presumably try to compile this. What if I want to use the venerable Boost.ASIO library to do this? [This](http://stackoverflow.com/questions/21422094/boostasio-download-image-file-from-server) is the best answer I found, and it's ridiculous. Presumably I'd have to read through a fair amount of the detailed documentation to (1) get a general understanding of how the different parts of the library fit together and (2) find out which facilities to use to download the damn file. Here's the [Python solution](http://stackoverflow.com/questions/22676/how-do-i-download-a-file-over-http-using-python): import urllib urllib.urlretrieve("http://www.example.com/songs/mp3.mp3", "mp3.mp3") Of course, there are other tasks that may be easier to do in C++ than in Python, but this example illustrates what I argued earlier. In contrast to most of the Boost documentation, Python documentation is much more practical. If I Google a given Python library, one of the first things I'm likely to see as I scroll down is "Usage" followed by the most common examples. Python's widespread adoption by scientific communities is something that will never be achieved by C++ (at least, not in the near future).
&gt; Because when it comes to C++, many people still imagine "C with classes", instead of modern C++11. There was a point where Rust had inbuilt sigils for unique ptr etc; and the compiler knows about move-semantics. `fn foo()-&gt;~T` .. 'a function returning an owned pointer' `let x=~Foo{..}`, instead of `make_unique(...)` that sort of thing. So elegant. But "explicitists" infest that community and they changed it. "its too easy to allocate", "you can't google for "~"". aaarrrgh. Jonathan Blow's embryonic language gets it right. `T*` .. just change it to `T*!` to make it 'owned'. After having experienced Rust, we have ammo: we can see modern C++ is still a mess , because its' shoe-horned into C. C's syntax is optimised for low level pointer use. There will always be a draw back to the older style. The language should have a pretty syntax for the techniques you're supposed to use.
msvc-12 = VS2013 Boost 1.56 is also supported by VS2013. 
I use Xcode. It's OK ... not great, but OK. But then again there aren't really "great" C++ IDEs out there. If I was on Windows/Linux I'd probably would give CLion an extended try. 
Qt Creator, at least in my experience, is a *great* C++ IDE. What's your definition of great?
In my experience, Microsoft Visual Studio is still the best IDE for C++. BTW, there's no such thing as “C/C++”. Pick one language and learn it well.
I've been using KDevelop lately and it's pretty nice, at least until CLion is done.
I use Visual Studio in Windows and Eclipse in Linux.
[Code Blocks](http://www.codeblocks.org/) is good. The UI is a bit un-intuitive but ok. It is cross platform and relatively snappy compared to the Java based IDE's
&gt; There's an air of circlejerkiness in the C++ community Exactly. Endless discussion about esoteric features. Quite frankly I would be happy with C++03 if I had standard ABI and useful standard libraries. Useful meaning able to solve modern problems, web services, GUI, sql, xml, http, smtp, encryption etc. Sure you can do all this stuff in C++ but boy what a pain. It is a shame that even c++17 is unlikely to have such libraries in the standard.
Sure. Why not write your own blog on that. Entering into an existing project and refactoring is a pretty important skill to have. It appears to lack any automated test suite at all, much less unit tests. Would be a worthwhile endeavor to instruct people on what would be required to do so. I would also bet there's plenty of legacy cruft to work with too, without having something too crazy to handle in a blog. I'm only one person though, and kind of a lazy one at that. I doubt I'll get to it. So go for it! I'd be willing to leverage my own blog to help you popularize it.
You probably meant to reply this to leftofzen, not as a global comment.
&gt; on a good computer, &lt;100ns fairly consistently Would be glad to get my hands on such logging library and learn its tricks.. any reference ? &gt; passing everything through the stream operator is not fun The library offers also variadic template interface which is much safer and nicer (and probably faster) than sprintf: *logger-&gt;info("Variadic call", some_int, some_uint, var1, var2,..)*
We use it internally at our company so I can't give you specifics, sorry :( It comes down to basic things like not copying when you don't need to, evaluating as much as you can at compile time, having a dedicated (lockless of course) logging thread to do deferred logging, etc etc. Variadic templates with your format string are definitely the way to go as you mention, I must have missed the implementation.
thanks
&gt; logging thread to do deferred logging How does it deal with overload? i.e. logging requests rate is higher than what the logging thread can handle ? This crucial imho..
Just a queue of messages to process, though if you are overloading it you are probably logging way too much :p
Can someone expand on why the use of lambdas to wrap the recursion is more clear than recursing directly? I would understand if it factored out a large amount of code but that really isn't the case here. It also hides passing data but that doesn't seem like a big win either. Don't get me wrong - I'm not anti-lambda - but I'm not sure the use here makes the algorithm itself more readable.
Yes, but what happens when the queue gets full? 
I have no idea. Our queue never gets full, it's always a reasonably large preallocated size and there is always disk space, so we never have that issue. If I had to guess, I'd assume that the queue would resize (which is rather costly) to contain them all, until we ran out of RAM, at which point bad things would happen.
Qt Creator
So that's how it got to 100ns rate, just fill the ram like there's no tomorrow ;) In spdlog, when using async sink, the lib limits the queue size(configurable) and apply back pressure by blocking the call when logging into a full queue.
&gt; So that's how it got to 100ns rate, just fill the ram like there's no tomorrow ;) Certainly not, RAM access is on the order of 100ns alone. You want to keep your data in cache all the way till it's logged. Get your alignment right and don't thrash the cache, that's how you get 100ns. If you are EVER resizing your queue, something is going wrong, either your queue size is too small or you are not processing fast enough.
Thanks for the explanation. &gt; It doesn't pre-suppose that every possible use case must carry along an explicit offset or IANA timezone with every value It wouldn't need to. In the alternate setup, Datetime is just a more precise time_t - there's no need to hold a timezone string or offset. In fact it would make no sense to do so. It's equivalent to saying "Datetime is always in UTC", rather than the current "you need to work out what timezone this is in order to use it safely". I've never had a use case where I needed to store a Datetime-with-a-particular-timezone. The timezone bit is redundant if your Datetime is an unambiguous point in time. In practice it's always number of nanoseconds since a particular point in time. Another problem with datetime-with-timezone (your DatetimeTz) is that it can represent two different "real" times (due to DST transitions), so is probably something best avoided IMHO. That said, this means I can't store what's in an SMTP header - I'd have to store the timezone offset of the sender if I wanted to keep that. I can see that it's sometimes vital to store the "+0600" or you're throwing away information, and my suggestion isn't helpful here. &gt; We've been using these core vocabulary types for over a decade in all of our C++ and the open-source version is the culmination of that decade of refinement. I respect that, and that speaks highly of the library. I don't doubt that it can work very well. But don't you have problems where you end up with multiple Datetimes and it's hard to be sure you can safely compare them? Or DatetimeTzs that can refer to more than one point in time? Surely the most important thing a datetime class can do is provide reliable, unambiguous ordering to events?
Other platforms can always just keep both ABIs stable and not break anything that isn't broken right now. And frankly, more ABI breakage is needed, because the current story with GCC and libstdc++ is horrible. "Oh that bug? Yeah, it has been present for the last 10 years and is trivial to fix, but it would ruin ABI compatibility for &lt;obscure OS&gt;'s specific version of library."
I've been trying to learn Emacs with ECB, but I'm weak and I keep going back to Vim...
KDevelop has been a favourite of mine for a long time. It's autocomplete has always been great and it also allows me to work effectively in Python which is the other language I use extensively.
Sublime Text + SublimeClang + SublimeGDB
Does anyone has a reference to a strong scaling supporting their claims (i.e. strong scaling of unstructured code using e.g. block AMR or octree-like AMR)? I went through the publications but couldn't find anything. It would also be helpful to know which scalings use an MPI backend and which use the HPX backend. HPX is really nice. However, I distrust it since it is based on a PGAS, and while MPI scales to 1.5 Million cores, the largest HPX scalings I've seen go to about 10k cores "only". I don't really know, in general, if PGAS approaches scale at all. Without strong data backing them up, it is hard to argue for HPX and LibGeoDecomp right now even in new projects, which is a shame.
Any feedback about CLion?
Doesn't clang already have implementation of c++14?
I've heard that claim, but when I tested their similar claim about C++11 I found it buggy enough to not compile code that was valid and working in the supposedly not complete gcc 4.8 (4.8.1? I don't remember). I'm sceptical for now, but that doesn't mean I'm right :)
&gt;There’s always a person who detests C++ so much that he takes the time to write a long hateful comment. There’s always a person who doesn't know C, and because of that, it can't grok C++. FTFY :-)
&gt;unbearable bad runtime performance Eh, nope, not really. Or rather, [[citation needed]]
Really, you want me to cite someone who says that the use of templates causes longer compile times? Comon.
I'll be that guy: Vim + YouCompleteMe + Tagbar + NerdTree + NerdCommenter + Surround.vim + maybe one or two more I've forgotten. EDIT: How could I have forgotten CtrlP?
Qt Creator is a great C++ IDE if you drink the kool aid. My only problem is that it's not Emacs.
So, CMake and bam have already been mentioned. I'm going to go ahead and plug [SCons](http://www.scons.org) as well. It's a build tool written in Python where your build scripts are also written in Python, so it's very powerful and very extensible. It's been great for developing cross-platform builds.
As far as I can see from a first look at it, you don't even need something like a CMakeFile.. Only the file with the hints is needed, and there could be (is it?) delivered a standard hint file with lots of predefined hints. I didn't try it yet, but I really like the idea!
Don't you also have to include all files manually in CMake? This tool automatically adds and builds all source files.
I develop with QtCreator. Actually I'm working on a big C++ (non-qt =&gt; pure c++) project. Besides, I'm using it on different platforms (osx, ubuntu and windows) because that project is multi platform. I love it because it's pretty fast, easy-to-use and the integration with CMake works like a charm. 
I use SCons too - mostly for its ability to do automatic dependency calculation.
Technically you can use globbing to get files in CMake, but it's not recommended, since then you have to manually re-run cmake when you or another developer adds or removes a file...so you're pretty much on the money
I am a giddy member of the autotools stockholm syndrome cabal too. I've always wondered why all these new magical languages that are the next coming of our language savior can't seem to solve the build tools issue. Either it's a strangely untractable problem that defies simple expression or the domain really is that tricky. I guess part of the problem is that the build tools for every language have to take into account a foreign function interface and allow (somehow) building and linking with C programs and libraries. As soon as you're building and linking with C there's the whole header file / library link mess and it devolves back down into "does the target system have clock_gettime()? how do I check for that?".
I prefer [waf](https://code.google.com/p/waf/) over SCons, it's easier if you need to build something else than code (like game assets).
I don't think I've worried about makefiles since first year undergrad. Anything I make from scratch is in visual studio though, so I'm a monster.
Do you use facebook? They have services written in Haskel.l [Here is a blog post about it](https://code.facebook.com/posts/302060973291128/open-sourcing-haxl-a-library-for-haskell/)
[PDF] (Sample) Chapter 2: The First Algorithm: http://www.informit.com/content/images/9780321942043/samplepages/9780321942043.pdf 
I have a little bit of [emacs magic](http://ix.io/f4H) + [a script](http://ix.io/f4F) that I use to maintain my file list automagically. Also, the way Ninja files are generated, cmake is rerun automatically when any of these glob.cmake files are touched. It all works VERY smoothly and I never need to manually run cmake for new files.
I'd like to hear opinions on why kingofthefaffacakes views aren't valid. I'm on platforms where specifying thread affinity is virtually required for code to run in a performant manner. I understand why this is often left out of standard, cross platform concurrency implementations but it effectively eliminates those implementations as options for us. From my perspective, there absolutely platform/OS differences which make a unified implementation challenging.
QT Creator, indeed. 
You went from "runtime" to "compile time" here.
I've been using both [CMake](http://www.cmake.org) and [GYP](https://code.google.com/p/gyp/) recently. I start to like GYP much more due to its flexibility and declarative syntax, which is IMHO much cleaner.
&gt;Another problem with datetime-with-timezone (your DatetimeTz) is that it can represent two different "real" times (due to DST transitions), so is probably something best avoided IMHO. I don't think that's true, one may construct a DatetimeTz that is nonsensical for a given time zone (e.g., 12:00+8:00 for a time in New York), but every DatetimeTz object represents a single, unambiguous, point in time. &gt; I don't doubt that it can work very well. But don't you have problems where you end up with multiple Datetimes and it's hard to be sure you can safely compare them? Or DatetimeTzs that can refer to more than one point in time? We generally encourage the use of `Datetime` (or sometimes `TimeInterval`) values in UTC within the context of a application, and covert only to a local time representations for presenting date &amp; times to a user. We're still working on incorporating the IANA timezone library into BDE (to make converting UTC values to a local time in any time zone easy). As I mentioned, DatetimeTz values are unambiguous. I think there should be method on `CurrentTime` to obtain the current time as a `DatetimeTz`. 
nope, I wrote about the runtime of the compiler, which is when the C++ templates are evaluated.
Have you used SCons? How do the two differ? Both of them are written in and make use of Python, but it seems like SCons gives you a better framework. You don't have to define functions in SCons unless you need to do something advanced. If one is already writing functions and the like to build stuff not natively supported, then adding that support to the SCons environment is a pretty simple matter.
I dislike waf only becuase I dont like bundling the build system with my code. If there's a fix in waf itself, I dont want to update every single copy of waf in all my codebases to get the fix.
Ordered! :-)
..g++ can build the dependency tree for you anyway, which pretty much solves most things. my 'standard' makefile goes with a little script that will make sure every .cpp in the src directory in the same folder will be built to its own .o in an intermediate directory
Ah, yes, I've read that article before, actually. I was looking into choosing between the two. Ultimately, for my cross-plat needs and especially my needs with working with a lot of different toolchains, SCons fit the bill better. That said, as far as your prime example goes in that article, I solved it by attaching the SCons built Node to a global Environment object. Something like env['SOME_FUNKY_DLL'] = env.SharedLibrary(...) and then in the project that depends on it, reference it so that it is linked against or just depends on it period. It'll be available throughout the SCons build process as long as there's a Export('env') somewhere in any of your scripts.
I've been working as a programmer for over three years, I've yet to use make on the job. Visual studio, however, pretty much every day.
Yeah, that's a cmake feature, not a Ninja feature...it works the same way with make or nmake...if you change a cmake file, then cmake is rerun next time you build. And what you're doing is slightly different, you're still maintaining a list of files to use in your build, as is recommended, you're just having a tool generate that list for you. Which is cool, no problem there.
Wow, I can see GYP getting out of hand for projects with a high amount of source files. That looks even worse than just using CMake. But if you can get that to work for you, then great! SCons also has a declarative syntax, in addition to the power Python offers you.
The problem with SCons is that the dependencies depend on order of evaluation of the scripts and so everything can be really brittle. Even if you had env.Program('whatever.cpp',LIBS=env['SOME_FUNKY_DLL']) That's not enough, you need: env.Program('whatever.cpp',LIBS=env['SOME_FUNKY_DLL'], LIBPATH='/path/to/build/directory/funky/dll', CPPPATH='/path/to/include/directory/funky/dll', CPPDEFINES='-DDEFINES_FOR_FUNKY_DLL') And this is just one DLL. With multiple DLLs, it explodes, especially when the requirements are transitive.
I thought it might be but I wasn't sure so I just wanted to speak to what I knew. You are correct that I am maintaining a list manually, but it really is hands-off. I get the benefits of globbing and cmake. Also, I added one little helpful thing to my script for my own purpose. Anything in the directory mac+linux would be built only for mac or linux. Similarly for mac+windows or linux+windows, etc. It turned out make a lot of things easier.
(Disclaimer: I'm the developer of the [Meson build system](https://github.com/jpakkane/meson) so feel free to take the following with as many grains of doubtful salt as you prefer.) This seems like an interesting approach, but there are a lot of questions the documentation page does not answer. Such as: * What is the license (presumably closed source as there is no link to get the source)? * Does it scan the files itself or use gcc's dependency printer? * If the former, how does it handle include directives in #ifdefs? * How would you create a shared or static library, the docs speak only of executables and "object files"? * How does it scale? 100 files? 1000? 10000? * Does it have standard Unix install targets? Autoconf-like functionality? Pkg-config without manually copypasting the output? 
Yeah, clang-format is very handy, i use it here. About ClangComplete, last time tried it, on one of the latest build of Sublime (don't remember exactly which one), it didn't work. I'll try it again, and see if i can get it to work.
I find that the automatic stuff autotools includes is pretty good, specially when you don't need lots of custom behavior. Things only get ugly when you need to dive into M4 and write your own macros. Otherwise it is probably the fastest way to get something that works on most UNIXes, does most things 'right' regarding libraries and compiler options, and makes packaging relatively easy.
KDevelop++. It has a VIM mode and natively supports CMake, so I'm not bound to it if I don't feel like using it for a while. Plus semantic highlighting, lovely. And it doesn't look like crap on Linux, which most IDEs tend to do with their toolkits.
like SCons... unless installing it in site_packages is any different, and when you update it, you break all your projects that aren't compatible...
yes, I used SCons before waf, and it was a pain to create custom tools (to build assets). I discovered waf after reading a paper from Avalanche Studios and how they used it in their asset pipeline for Just Cause 2. If you only need to build code, SCons is fine. But if you need to do something else, I'd recommend waf.
Could someone give me a tl;dr on make files? I've been working in c++ on and off for about 6 months now and even with some basic games I've not had reason to use one, is it just something the IDE does for me? Is it different if you are working outside of an IDE?
You got ; right after while(...). With that is just reading whole file without doing anything with it. Then you got { cout &lt;&lt; ... }, which will print last 2 reads.
Didn't know that about scons. I will add it to my ignore-list too :)
Similar story: it would break existing clients. Instead of aliases though, you could use proxies that just delegate the work to the "other" side. It would be slightly more work though.
Typing this quickly between builds so I may be missing something, but it seems like it would be simpler to express like this: void insert(Node&amp; root, int data) { auto&amp; nodeptr = (data &lt;= root.data) ? root.left : root.right; if(nodeptr) insert(*nodeptr, data); else nodeptr = std::make_unique&lt;Node&gt;(data); } 
Yes, but only after everyone has made the abi breaking changes to move over to `std::abi`. I don't think there's any solution that doesn't require breaking ABIs, but my point isn't that it therefore should not be done. I just think more consideration of existing practices is needed.
I think the comments demonstrate why this is redundant. Nice tool though, good for you.
Without any information on what set up you're using, I would tenatively say "yes", only because you would probably know about them if it wasn't doing it for you. At their simplest, makefiles are a way to execute a tree of arbitrary commands. Something like, * Make thing A * Make thing B * Make thing C, which relies on A and B. So the make file runs the commands for A and B (possibly in parallel, depending on your settings), and then when A and B are both done, does C. This is typically done for building c++ code so that you don't have to recompile your entire project when you change a single file. However, because "make" is very general, people tend to use other tools so they don't have to spend too much time writing the makefiles themselves. Additionally, sometimes you need other things in your build system, such as checking that you have the correct compiler version or other things like that. To do this, people tend to use other tools like autotools or CMake, which generate a makefile for you.
And if you want to know where it starts getting tricky and complicated, google "recursive make considered harmful"
I think we're kind of missing the point. Everyone's pitching their favorite build system here, but can you imagine a world without build systems? That's the point.
Actually, now that you mention it, I think I did modify ClangComplete slightly to get what I wanted. FWIW, [here's](http://pastebin.com/N9fxAvRm) my copy. It's just really unfortunate that it's much more convenient for me to use Windows, so I don't get much of a chance to use either of these great plugins.
[Turn up your warnings.](http://coliru.stacked-crooked.com/a/dfe887e721dc960e)
HPX is not really traditional PGAS, there are quite significant differences. WRT scaling to more that 10k cores: We are working on it ... so far however, we don't see any strong evidence why it shouldn't scale beyond that number. Even traditional PGAS languages or libraries are able to scale to some degree. For new projects, true, it might seem like a high risk, but sometimes it might be worth it, especially when the projects requires HPX like concepts. For LibGeoDecomp: It is a very nice library and serves an excellent purpose. So let me ask you: What risk is higher, re-inventing the wheel or using an existing that has proven itself in one way or another?
Unix: vim+ctags+screen+cgdb (I really hope something better than ctags appears soon - rumors are Google is going to open-source their C++ indexing engine) Windows: MS Visual Studio + VsVim 
Plato's Allegory of the Cave: https://www.youtube.com/watch?v=69F7GhASOdM
As far as I understand there's a lot of nice "magic" out there with parsing `#include` directives. But parsing C++ is hard. For example, how do you handle the following case: #ifdef CPP11_AVAILABLE #include &lt;memory&gt; #define MySharedPtrType std::shared_ptr #else #include &lt;boost/shared_ptr.hpp&gt; #define MySharedPtrType boost::shared_ptr #endif What about setting the other flags? Can I specify, say, optimization level? I.e., is it a full fledged build system? I'm a Linux user but I must also ask if you plan to support other platforms than Mac and Linux? These are pretty basic features and there are also more complicated ones (like generating code, exporting buildsystem to IDE-specific projects (VS, Eclipse, ...), allowing users custom build targets and so on). The competition is tough. ;)
Being a Windows developer by trade, projects which use the autotools exclusively are a bit of a nuisance as you have to use msys just to run the build scripts. I'm a fan of CMake as it can generate projects in a bunch of different formats.
Post this to /r/cpp_questions, you're likely to get more help. You're also likely to get more help if you post all of your code, properly formatted. I'm guessing `number` (the left operation) is a float variable (but I can't tell because you haven't posted all the relevant code), and you're trying to do a modulo on it, which is an integer operation (at least with this operator). Use a [static_cast](http://www.cplusplus.com/doc/tutorial/typecasting/) to convert your float value to an integer. You should also read up on the effects this will have to the value with respect to rounding.
Thanks, i'll try it later. I'm on Windows too btw.
Hey gnzlbg, thanks for your input! I'm the project lead on LibGeoDecomp, so my view is biased, but I hope I can supply convincing data. - Here are the slides for a talk I gave at the EuroMPI/Asia conference a couple of weeks ago. It contains some measurements done on Titan (Cray XK7) and JUQUEEN (IBM BG/Q). Key result: 9.44 PFLOPS with a short-ranged force-based n-body code on 16384 nodes of Titan. http://www.libgeodecomp.org/archive/eurompi_2014_talk.pdf - Our project on JUQUEEN just ended and I'm still wading through the results. Here are some new, preliminary, unpublished plots of the same n-body code's performance on JUQUEEN (1 to 28672 nodes) http://gentryx.de/~gentryx/weak_scaling_big2.png http://gentryx.de/~gentryx/strong_scaling_pro.png - Strong scaling may look disappointing at first sight, but the performance actually corresponds to &gt;2 PFLOPS for the full system run, so this is a good result (scalability != efficiency). - All measurements above used the MPI backend. The HPX backend is our joker for the next months, as we hope it'll ease balancing loads. Many of our users have expressed interest in unstructured/inhomogeneous models. - Data for strong scaling of AMR+LibGeoDecomp+HPX on 10k nodes? Not yet available, and I wouldn't claim that this would work efficiently out of the box at the moment. All we did with AMR+LibGeoDecomp right now is proof of concept, nothing more. - We have production code utilizing the following models: stencil codes, particle in cell codes, n-body codes. If interested, I can point you to the corresponding papers. Rigth now, none of our users are running their codes on more than 1000 cores for production runs. We did the benchmarks to show that this is quite feasible though.
Thanks for the links, i'll go through them tomorrow. Awesome work you guys are doing btw, keep it up!
The pure math looks like LISP, and then the programmer comes along and fucks it all up with curly brackets, and semi-colons.
Congratulations on your first submission, /u/mona420.
CMake is fairly simple and if you use QT, then QMake. There are already tools that allow a dev to forget about the details of makefiles
make rebuild_cache
some advice: most people dont like : // This code be like crap, but I like to busy to like fix... use proper naming, partial knapsack might be literal translation from your language, but at least bother to find a proper translation... other than that nice and I hope STL will see this and comment, I would like to comment on the code, but I first need to learn some c++ to understand what the cool kids are doing this days. :( :P
Is there any online tutorial you know of and can recommend?
Before Qt Creator, I used VS a lot and now I still think VS is one of the best IDE. The most advantage of Qt Creator over VS is it's cross platform. Most time I develop on Windows, sometimes I need to develop on a Mac Book Pro when I'm in a trip, and I need to compile my project on Ubuntu box to run on Linux server. All I need to do on those platforms is just load my project in Qt Creator and build it. Can't be simpler. Qt Creator has some very useful features to help productivity, such as, but not limited to, F4 to switch between header/source, refactor to rename a symbol (I refactor a lot), refactor to add definition of a function in the source file, find usages, etc. And the auto complete is very good. About the interface, I found it quite simple and intuitive. I rarely use the menu, but the left bar is really useful. I can switch views (edit/debug, etc) quickly, switch projects and compile modes (debug/release) easily, etc. Several years I tried C::B and gave it up quickly because it was buggy and slow, not sure how it is now. Any way, we don't need to try every IDE, just stick to the one that suits us best. :-) 
Sorry if this comes of as a stupid question, but what is a module? http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4047.pdf seems to be answering that question but i cant even understand the introduction, for example what on earth is "componentization of C++ libraries and programs"? (English is my first language BTW) 
YES! So simple, so fast, and so clean! I sometimes have to use VS2013, and, in comparison to C::B, it's slow, bloated, unintuitive, and there's no god damned multi-cursor support!
Couldn't this be done via template magic? unique_ptr doesn't allocate space for a custom destructor unless it needs to. Couldn't this do something similar whereby UTC types don't store an offset but non-UTC types do? Then you could also protect against precision loss if one time basis can't represent another.
How on bloody earth did you get SublimeClang working then? Pretty sure I attempted it with ST2, though I prefer ST3.
Our internal logging implementation offloads as much as possible off the critical path. The only thing we do on the critical path is copying arguments. We have a union which we store arguments in. union ArgT { const double d; const uint64_t u; const int64_t i; const void* p; }; We use `printf` style formatting, and a variadic function template which captures the args. Fundamental types are just copied straight into their respective union member. String arguments are copied (we walk the format string to work out the length of data we need to copy, create a buffer on the heap, and copy the string contents across. We have a *static string* optimisation (via a special format specifier) which means we shallow copy the string. We use `__attribute__((format(__printf__, ...)));` to catch bogus format strings. This does mean we can't pass `std::string` types. However, we have a macro for passing `std::string` arguments which expands to `str.c_str()` in debug mode (allowing us to use the format string checking) and to `std::string` in release mode (when format string checking is also turned off) with argument storage function overloads which can use `str.size()` to prevent having to call `strlen` It is quite rare that we are logging non-static strings (element ids are logged as static strings (so we just copy the pointer), and the main data is typically `doubles` and `ints`), so time spent creating the buffer of log args is minimal. In the logging thread we use `boost::format` along with the format string (again, a static string so just a captured pointer) and do the actual log message generation in this way. This is slow, but is off the critical path so we don't really care. We walk the format string to work out which strings were deep copied in order to free the associated memory.
You know that you can run CLion on OSX too, right?
What about emacs? I know it's not pure IDE but it can become something which is pretty close to IDE at some point.
Never tried SCons, but might have a look... Unfortunately it seems that SCons doesn't support Xcode project generation? (only Visual Studio is listed on the front page), which is quite an important feature for me.
Sure, it works with any compiler. I'm cross-compiling microprocessor code in QtCreator. However, if you use third party libraries (e.g. Qt) make sure that that library is built using the same compiler. But that has nothing to do with the IDE.
Yes, but I'd prefer a native IDE over a Java-based any day. 
I had the honor of reviewing the draft version, it’s a wonderful book! Strongly recommended. 
&gt; you have to manually re-run cmake when you or another developer adds or removes a file Don't you have to do that anyway?
There is no such thing as a "C++ package manager".
`unique_ptr` in a tree or linked list structure will easily lead to stack overflow when you destroy a structure that is large enough (which doesn't really require unreasonable sizes), because the destructor of a node gets called from the the destructor of the parent. I personally think `unique_ptr` provides the wrong ownership semantics here: the nodes belong to the tree, not to their parents. Consider what removing a node would look like. You would be effectively *fighting against* the ownership semantics of `unique_ptr` to avoid destroying a whole subtree when you remove a single node.
Same here, some awesome piece of Free and free software.
Not open source? :/
QtCreator for big projects, Geany for small snippets / unrelated tests.
What code was that? Did you file a bug?
If you are starting, the Codelite is good, because is simple (I hate that mess that is Visual Studio), multi platform and have a really wonderful auto completion as it can even use clang as source. I only miss some plugins. The Code::blocks is also good, it is very flexible and customizable, it has many wizards for common tasks, it simple-ish, however I dislike their release model and I have many troubles with its auto completion. 
&gt; Contrast to my implementation where if you did : LOG_DEBUG("the thing=", complexCalc()) &gt; Then complexCalc() is NOT evaluated if the log is in level ERROR. Can you elaborate more on your implementation? Any source code by chance? 
http://www.codergears.com/Blog/wp-content/uploads/pattern3.png This isn't just poorly implemented, it isn't implementing strategy at all. A more common picture that I've seen is this: http://www.netobjectivestest.com/PatternRepository/images/9/98/Strategy_1.jpg The Context should not be both creating and using the Strategy. Both of these pictures are just implementations of the Strategy and not the pattern itself. From the net objectives website, the pattern is &gt; A single behavior with varying implementation exists, and we want to decouple consumers of this behavior from any particular implementation. We may also want to decouple them from the fact that the implementation is varying at all.
Sorry if going too deep, but from your question I understand you aren't aware of these concepts. C++ compiler toolchain is based on the C toolchain. It was a design decision to be able to easily integrate into existing developer tooling. C's compilation model is very basic. A translantion unit (e.g. source file) gets compiled into an object file. Afterwards a linker is required to bring all the required object files into an executable or library. There is no type checking between object files and the headers are plain text inclusions that need to be parsed multiple times, while the programmer is thrust to have written the right type declarations. Modules go back to the CLU and Mesa languages in the mid-70's. You also have separate compilation, but now the information regarding exported types is either stored inside the module, or dynamically generated at compilation time. The compiler just reads the type information, which is way faster than parsing header files multiple times. In the Mesa family of languages (Modula-2, Oberon, Ada...) the compiler enforces strict type checking across modules. In C++'s case what modules bring to the table is faster compilation times by not requiring endless parsing of headers files, optimized storage information for templates and things like Pimpl idiom aren't required any longer.
Python has one (easy_install/pip), Rust has one (cargo), C# has one by virtue of it really only being used on Windows (hence NuGet works for it), Java has several (maven, gradle, etc). Until someone builds it, no there's no C++ package manager. That doesn't mean one couldn't exist: being able to do something like cpp_package install &lt;foo&gt; &amp; have it pull in all dependencies would be really useful.
Qt Creator can load CMake projects natively and work with them
Yup the IDE does but the Qt (the framework) uses QMake. 
Kdevelop is looking promising so far!
&gt; Couldn't this be done via template magic? unique_ptr doesn't allocate space for a custom destructor unless it needs to. Couldn't this do something similar whereby UTC types don't store an offset but non-UTC types do? &gt; &gt; &gt; &gt; Then you could also protect against precision loss if one time basis can't represent another. But then they would be different types (just as `Datetime` and `DatetimeTz`, or `unique_ptr&lt;A&gt;` and `unique_ptr&lt;B&gt;`, are different types), they would just be implemented through a common template. 
Sorry, my fault ^_^U
My knee-jerk reaction to the idea of two std libraries is not a positive one. A certain xkcd comic about multiple standards comes to mind.
No fault at all. CMake is supported as non QT projects within the IDE. Can also import from repo's as well. It's a great IDE.
The alternative of never fixing problems or making improvements is far worse.
Yep, it's either two standard libraries or never fixing problems and never making improvements. There is absolutely no other option available.
Was any thought ever given to adding a `slice` function? It was in the old range proposal and I've (personally) gotten a lot of mileage out of it, especially when having to delegate sub-ranges to tasks. I'm sure it could be done with the adaptors, but its more of having the same semantics as, say, python's slicing capability. Also, I'm very glad that "The Great Range Debate" is finally coming to a close. Since you've been fighting for this proposal does this technically make you a... ranger? (Nothing but high quality puns here, I assure you)
I don't think I see the problem though. std::chrono::seconds is a different type from std::chrono::minutes. I can still do std::chrono::seconds one_minute = 1min. It's actually a good thing that there's type-safety. Imagine you allowed for a type without a timezone. It would prevent you at compile-time from assigning it to a UTC timestamp or a local timezone that encodes offset without explicitly assigning a timezone first: EpochUtil::add_timezone(NaiiveTimestamp&lt;&gt;, Tz::EDT); or EpochUtil::add_timezone(NaiiveTimestamp&lt;&gt;, Tz::offset(-9));
The Qt integration in the latest CMake is pretty good, with http://www.cmake.org/cmake/help/v3.0/prop_tgt/AUTOMOC.html and find_package(Qt5Widgets) &amp; the likes...
Some problems can't be fixed without breaking code. If you ever want to move the state of the art forward, at some point you have to make a clean break.
They are mutually exclusive?
Of course not, and the committee has been steadily improving `std::` since 1998. That's 16 years of stability. At this point, we are *well aware* of the problems with the current STL, and the Concepts Lite feature is specifically aimed at addressing them. There is no easy way to integrate Concepts Lite into the STL without breaking some users. We've had a stable standard library for an age and a half. We now have a chance to dramatically improve things, and I think we should. *Edited to remove inadvertent negative cultural reference. Yeesh, sorry.*
Funny, another Chandler has argued for a Python-like `slice` function. He also has a propensity for terrible puns. :-) Yes, there is a `slice_view`. Unlike Python's `slice`, it is a distinct utility from `stride_view`. Both are lazy, non-owning views of data. There is also a need for an eagerly-evaluated container-based `slice` algorithm. Container algorithms are separate beasts, and I've only started implementing them recently. I'll give it some thought. Unless there is a very strong reason not to, it will have the same interface as the lazy, non-owning variant.
What kind of ranger would he be? Would that be the D&amp;D class or anla'shock?
Yeah, a lot of these abstract arguments sounds good on paper, but in practice the social effect that having a fragmented ecosystem ends up causing a great deal of harm, sometimes irreparable. Python and D are both actual use cases of good intentions and arguments about making a clean break to move forward ultimately resulting in literally years and years of conflict, issues, and just overall headaches for people. I know, I know, this time it will all be different... but understand that for the overwhelming majority of C++ developers in actual industry, most of us just stick to some really basic and non-fancy C++ and actually like that C++ evolves in a gradual and stable manner. Fragmenting the C++ ecosystem by having people decide between the new standard or the old standard when developing an open source library, or awkwardly mixing the two libraries God knows how is inviting disaster. Remember that the overwhelming majority of C++ users stick to some pretty basic stuff, so when considering whether a new library should be added as a standard (rather than a part of boost or some other third party library) it's worth considering whether this will actually, in practice, improve and help those developers write code, or whether this library mostly just satisfies the curiosity of the few C++ developers who enjoy working with bleeding edge template meta-programming and other fancy stuff.
D'oh! Bad choice of words...
This is 2014. Should we really use raw pointers?
This is FUD. All existing code will continue to work. Please see my comment above about why the committee is open to this. It's not for some esoteric metaprogramming facilities, and it's not for their jollies. It's to make the core library's interfaces more rigorously type-checked. The result will be fewer bugs and better template error messages for those who choose to use the new facilities. Mixing the two, even in the same source file, would be fine. That would be a hugely important use case. The committee takes it responsibility of backwards compatibility seriously. Most code the the 80's still compiles, and it will continue to compile. Seriously people, chill out.
Your reply to having a discussion over a legitimate concern about how having TWO standard libraries in one of the most widely used programming languages is to dismiss it as FUD and tell people to chill out? Fair enough, don't know what more to say but it's rather disconcerting that this is the attitude taken. I guess anyone with a dissenting opinion should just remain silent.
1. C++ ABIs are actually quite stable, so assuming you had both runtimes it should just work (GLIBC is actually your problem). 2. Your libraries would probably be compiled on your machine. That's how pip works too BTW. Distributing binaries is a much harder proposition. You could do it by allowing pre-compiling them on an old version of the OS &amp; then distributing that: ABIs tend to be backwards compatible, not forwards. Anyway, I don't see why you would bother.
Ahh, ok. I think I was thinking of the eager `slice`, but it's good to know there is a lazy version.
&gt; I can think of one disadvantage: People starting to use features from std::experimental for their projects and the same features never appearing in std. It's certainly a risk. Remember TR1, in the `std::tr1` namespace? Most of that stuff ended up in `std::`, but not the special math functions. And some things changed when they went into `std::`. The world didn't end. Boost regularly breaks code, and some people scream, but sometimes it really can't be avoided. &gt; having a community that actively experiments with C++ would be a godsend. Completely agree.
Can you give an example of such a breakage? Just trying to understand the nature of the problem...
No! We do not need to use owning raw pointers. 
One example: some algorithms take an iterator and a count. The type of the count argument is deduced today. In the future, it will be pinned to the iterators difference type. That's a signed integer. It might catch a few users out. A far more subtle change is to tighten up the type checking of heterogeneous comparisons; e.g., searching a `vector&lt;string&gt;` for a `const char*`. That works today. It's important to make heterogeneous comparisons work, but it's also important to make it meaningful. The new rule will be that a heterogeneous comparison will be allowed if the two types have a type in common (as determined by `std::common_type`) to which they both convert, and which is comparable. (The algorithm doesn't need to actually do the conversion first. That could be expensive.) So, comparing `std::string` and a `const char*` will still work, but only because it is a principled, meaningful comparison. This is a subtle change, and most users won't notice it. It *will* break some code though. In those cases, it may be necessary to specialize `std::common_type`.
Let me guess: you haven't read the proposal? Ranges are layered on top of iterators. Anything with a begin and an end is a range, not just pairs of iterators. Ranges are also Generic and have concepts that are defined in terms of the iterator concepts. One of the coauthors of the paper is the former boss of Alex Stepanov, the inventor of the STL. He's not ignorant of its strengths.
Having read Stepanov's "Elements of Programming", I have to say that I'm skeptical about the usefulness of this book. First, there's much more to programming than what arises from algebraic structures (groups, rings, etc). Second, judging from the ToC, there's a big overlap with TAOCP. Knuth's derivations of algorithms are particularly insightful. I want to criticize Stepanov's writings from another angle too: he's always talking about programming in the small, exemplifying his techniques on problems which have already been beaten to death and beyond (GCD, RSA). How about extending these techniques to "programming in the large"? How can mathematical structures help in program design? Take a case-study from the OOAD book and apply generic programming instead of OO. Show us the reasoning process and the end result.
Compiler devs are the forces of natural selection.
A count that is signed? This signed vs. unsigned thing is turning into a real problem. In any case, this sounds more like a new namespace within std rather than a new library entirely. Perhaps that's what you were suggesting in the first place...
You guessed correctly - I haven't read it. It may be pretty ignorant from my side, but to my defence: I'm not in the scope of the intended audience; the details are intimidating to me. The introduction reaches my limits of comprehension (and the attention span) but may be enough of a read for a programmer that just wants to use the ranges (or doesn't). I assume that it boils down to: &gt; * It eliminates the possibility of mismatched iterators. &gt; * It opens the door to range adaptors which lazily transform or filter their underlying sequence in interesting ways. The first is not very sound. If you can't manage your iterators, then fine, use ranges, but how about leaving this outside the standard library? At the end, if you value terseness, I guess you can do something like: sort(unpack_magic(my_range)). The second consists of *opens the door*, *interesting ways* - this looks kind of iffy. How is implementing som goofy *range adaptors* easier than implementing some goofy iterator adaptors? I am actually really curious and have a lot of respect for Sean Parent. I'm just deeply unconvinced. (I feel the same giref about the range based for loop - that it doesn't support an iterator pair easily)
&gt; Your libraries would probably be compiled on your machine So if I want to use Qt with webkit in my app, I download 200 megabytes of sources which takes half an hour to build ? Edit : I was not sure of the thing with the commonly-breaking abi but yes, it would more be glibc than libstdc++. And I don't even begin to imagine the mess with libc++ and libc++abi...
The signed/unsigned thing *is* a real problem, and has been for time immemorial. The committee members I've asked generally feel that putting unsigned integers *anywhere* in the STL interface (even `vector::size()`) was a bad idea. Negative numbers wrap to huge numbers when passed to a function that takes an unsigned integer, and the function can't easily check that precondition violation. Mixing signed/unsigned is one of those mistakes I hope we can finally correct.
Well, I mostly use unsigned integers and cannot complain about problems there. On the contrary, the idea of using signed integers for things where negative values are impossible sounds terrifying to me, since this just opens up another opportunity to mistakes. To me this sounds more like a problem of implicit signed→unsigned-conversions. 
 auto GetR1(void) const -&gt; double Seriously, why write you definitions like this? 
For consistency (functions with *decltype* as return type must use this style; in C++14 we [can](https://solarianprogrammer.com/2014/08/21/cpp-14-auto-tutorial/) also write only *auto*, if the type can be deduced) and readability (we have all function names in the same column). It's not my blog, in fact.
Going by past C++ standards - how many of all proposals are generally accepted?
&gt; 1. delete heap memory Cringe. Don't manually manage heap memory, use RAII smart pointers. &gt; 5. char const* const buffer Yeah, or just use a vector, which unlike pointers, will abide by the same const and passing semantics as other object. &gt; 8. temporary objects can only bind to const references Not really important as the compiler will enforce this. &gt; 9. the parentheses in new A() matter more than you think they do Or how about stop newing shit yourself; call make_shared, make_unqiue.
Okay, I honestly didn't have the patience or interest to read the whole article. Could I get a brief summary of your idea? Also, it looks like people are downvoting this submission, probably because they read the first page or two and didn't find much of interest there. I can't do much about that, but it's probably a lesson to learn.
Very simple: #define LOG_ERROR(...) do { if (Logger::currentLevel() &gt;= LEVEL_ERROR) Logger::log(__VA_ARGS__) } while(false)
It kind of sucks that this is the case but the bright side is that clang is forcing a lot of the compiler devs to catch up or die out.
OK. You do that once. The same thing happens when you install pyqt.
&gt; And be inconstant with every other piece of software ever written? Well, consistency with every other C++-code is impossible anyways. Way to many people don't even follow the stdlibs naming conventions and write classes with different styles then `all_lower_snake_case`. 
 class Ellipse { double r1_, r2_; public: Ellipse(double r1, double r2) : r1_(r1), r2_(r2) { assert(r1 &gt;= 0.0 &amp;&amp; r2 &gt;= 0.0); } .... } Are you supposed to use asserts like that?
Windows only: Visual Studio, cross platform: Qt Creator
also, f(void) is C, not C++. Stroustrup has gone so far as to call it an abomination
I read all of it and it ends up just being yet another unintentional demonstration of the fact that trying to model hierarchies of things with hierarchies of classes usually doesn't work. His solution to it often being very difficult to actually do anything interesting when inheriting from a non-abstract base class without violating the LSP is an exponential explosion of interfaces.
If this is your code exactly, you are missing the # sign in front of include &lt;iostream&gt;. 
No. Asserts are for invariants, never input validation.
Just a result of Markdown interpreting the \# as a HR, OP should format the code with 4 spaces to alleviate this.
**bold**Thanks for the help guys. I managed to fix it by copying and pasting a while loop from google. 
No I disagree with that; and it certainly is a matter of opinion. Asserts are for preconditions, including invariants. If I have a function `f`, which takes an `int` between 0-65 and you pass in 67 your program is broken, end of. It's not the job of `f` to validate your input; the best thing it can do is assert and die early so you can attach a debugger at the point of failure and inspect the invalid inputs and context from within which it occurred. Normally I'd have my own assert which is either disabled on release or through so it can at least fail cleanly. Then I typically use exceptions to make post conditions, ie your input wan't wrong, but I couldn't complete the process. This in effect is programming by contract. 
Macros are [problematic]( http://www.parashift.com/c++-faq/inline-vs-macros.html) on their own, but here, expanding what looks like a function call into a conditional is just asking for trouble: presented with the unexpanded statement, I would expect the arguments to always be evaluated, regardless of logging level. Regarding speed, pantheios skips string formatting along with any allocations if logging is not active, which is where most performance is lost in most cases.
Im saying that the guy who created C++ calls it an abomination. Those are not my words. So probably not overkill?
aw man... you must be a real pleasure to work with plus, if you need hints to remind you that you forgot to add a parameter, perhaps you didnt need that parameter in the first place. I dont think Ive ever been caught thinking 'did I mean to leave this parameter list empty?'
Developing apps that use Qt-the-framework doesn't *require* qmake. It's quite possible to developer Qt apps using makefiles, cmake or any other build system you like. Qmake is quite a nice meta-build system for C++, and (obviously) comes with both built-in and preconfigured rules that make it work particularly well with Qt apps.
Nice. For member functions depending on the class type parameter, the trick on STL's CppCon talk seems to make it somewhat easier: template&lt;typename T&gt; struct foo { template&lt;typename U = T, REQUIRES(std::is_integral&lt;U&gt;())&gt; void bar() { puts("integral"); } template&lt;typename U = T, REQUIRES(std::is_floating_point&lt;U&gt;())&gt; void bar() { puts("float"); } }; 
I actually quite like the 'REQUIRES' syntax, I first saw it in Alexander Stepanov's book Elements of Programming. Although there it was just MACRO leading to a NO-OP as a form of documenting syntax. I am wondering whether the syntax though messes anything else up, like casting functions (to provide a specific overload for a callback) or when called from variadics.
The catch is that `f()` and `f(void)` are two completely different things in C, and that C++'s `f()` is C's `f(void)`. If you're writing `f(void)`, you're simply not writing C++ but C. I don't know why Stroustrup considers it an abomination but if it has anything to do with the lack of compile-time verification I would be inclined to agree (however, C obviously couldn't possibly change this for compatibility reasons).
What is the difference between eager and lazy slicing?
A lazy slice holds a reference to the underlying sequence, and returns an iterator that starts at the requested offset and counts until it has reached the end of the slice. In contrast, an eager slice takes a vector and returns a new vector with just the requested elements. Replace vector with *container-like-thing* and you get the picture. Both have their uses.
There is no need to do this if you use the requires macro defined in post: template&lt;typename T&gt; struct foo { template&lt;REQUIRES(std::is_integral&lt;T&gt;())&gt; void bar() { std::cout &lt;&lt; "integral" &lt;&lt; std::endl; } template&lt;REQUIRES(std::is_floating_point&lt;T&gt;())&gt; void bar() { std::cout &lt;&lt; "float" &lt;&lt; std::endl; } }; Plus, this will work for free functions as well, whereas STL's trick won't work: template&lt;REQUIRES(sizeof(int) == 4)&gt; void serialize(int n) { std::cout &lt;&lt; "Size 4" &lt;&lt; std::endl; } template&lt;REQUIRES(sizeof(int) == 8)&gt; void serialize(int n) { std::cout &lt;&lt; "Size 8" &lt;&lt; std::endl; } 
So we are two. I see some of the arguments that those other people use, but when I think about how this behavior would be regarded in Java or Python, two languages that are in my opinion clearly inferior to C++, I get really jealous and sad.
Is there any progress regarding compile time reflection in c++? That way Qt can avoid the moc pre-processor. Any chance it will be in C++17?
Looks a lot like the `REQUIRES` macro in Range v3. Hrm.
Python and C++ are such different languages with such different goals that I don't really think it's valid to make such general comparisons between the two, especially something as broad as 'clearly inferior'. I'm working on a C++ game engine right now and Python would be a terrible choice, for performance reasons and because dynamic typing would make it incredibly difficult keep track of everything. But on a smaller codebase where performance isn't critical/CPU bound, python is very nice and expressive. It's also a godsend for data analysis tasks, which call out to pandas/scipy/numpy for performance yet can remain quite expressive.
What I'm doing with 42 is what you're doing with PrivateBool. It's just some way to make the REQUIRES expression dependent.
&gt; [Overloads are] not exactly the same thing. Well, you're right of course but that doesn't really say anything. Overloads are a better, simpler answer and I was asking why you'd do this complicated thing instead. &gt; ... compile time doesn't seem to be impacted that much by making it a template. Then your profile test must be pretty limited. Turning free functions into templates just to do this should certainly impact build times for any moderately sized project. And I'm still not getting the point of why you would even want to do this. Sticking what is basically concepts on non-templated functions seems utterly useless. Concepts are for generic programming but non-templated functions are not generic.
There is some work done on reflection, look at the previous part, where the 2 papers for reflection were handled. One of them is doing the default comparison operators over reflection.
This was not meant as comparison of the core languages, but as comparison of the communities, where the other two managed to prescribe coding-standards that almost everyone agrees on. In C++ we have a huge mess and lot's of people who are knowingly and willingly increasing it. Also: I wrote “in my opinion”, which in case of python is mostly backed by python throwing away static typing for nothing.
I think that sizeof(int) is trivial enough but if you do more complex template foo I can see where this would be usefull over overloads (especially in combination with a templated function. template&lt;typename T , REQUIRES(std::is_default_constructible&lt;T&gt;:value)&gt; &gt; T deserialize(){...} 
IIRC, there are dark corners in how C++ chooses the correct overload for some expressions. Although I can't think of a specific example off the top of my head; I recall having overload resolution fail unexpectedly at times. I suppose a saavy programmer would account for that though, and avoid flat overloading of functions/methods like this unless it's really helpful. The provided template/macro is kind of nice since it's much more explicit, and doesn't require the developer to have deep knowledge of the exact behavior of overload resolution. IMO, relying on expert knowledge of the C++ spec on behalf of the would-be maintainer is usually asking for trouble.
I stick with Visual Studio for larger projects and do my simple editing in Sublime Text 3
I tried it out... seemed pretty cool... but since I work on a cross platform codebase (one that is compiled with Visual Studio on Windows and GCC or ICC on Linux) I really want a portable IDE and right now CLion only supports mingw gcc on Windows... So I'm sticking with my emacs config for the time being...
OK, I see now. Either way requires "bootstrapping" this ABI practice moving forward. That bootstrap step could be an ugly transitional period if not considered properly.
If you really posted a question on stackoverflow asking for a story, you don't understand that site at all.
That's a function template. It makes sense to use concepts there. I'm not talking about function templates but about functions that have no debpendent names at all (not templates or members of a template in other words). This is what a good half of the OP's blog is about. I do tend to prefer tag dispatching in a lot of these cases though. For example your example, if you have a second function for non-default constructible types I'd prefer tag dispatching to defining the second as `REQUIRES(!std::is_default_constructible&lt;T&gt;::value)`. In cases when there's more complex rules I *definitely* prefer tag dispatching. For cases though when there's no competing 'overload' though `REQUIRES` looks like a nice solution. It could also be used to further secure the dispatch target functions just in case someone got clever and called them directly or confused the tag system.
Not sure what resolution trouble you had. Overloading isn't tough. When you mix templates in then things do become confusing and a little unintuitive, but other than that I'm not sure what's hard about them. An example of templates screwing up resolution would be this simple example: void foo(std::string); foo("hello"); // works. Then you add this: template &lt; typename T &gt; void foo(T); And now your call does not work. Same thing happens when you're passing around derived classes into a function with base parameter and you add a template "overload". Template gets chosen instead. &gt; The provided template/macro is kind of nice since it's much more explicit, and doesn't require the developer to have deep knowledge of the exact behavior of overload resolution. IMO, relying on expert knowledge of the C++ spec on behalf of the would-be maintainer is usually asking for trouble. In my experience it is trying to out-think the compiler that causes maintenance issues. This REQUIRES solution actually requires the developer know a lot more about name resolution than the simple name overload version because function templates make the issue more complex and subtle. That and he's actually using some not entirely obvious tricks to make free functions without dependent names check the concept. Someone that doesn't know what REQUIRES does will have to look at its definition and that's going to result in a few questions unless the maintainer is indeed pretty advanced...and even then, "Why did you force me to dig through this??" still seems to me like a question I'd be begging to know.
I think where I ran into trouble was with long, ulong, int, and uint. There, my compiler had a hard time due to implicit casting interfering with overload resolution. Again, I might be wrong here since it was some time ago. &gt; In my experience it is trying to out-think the compiler that causes maintenance issues. This is an excellent point. I'll be sure to remember that in the future - usually the compiler does try to do the right thing. 
I can imagine a couple ways in which you may have run into trouble there. First you might have expected the `long` version to be called when you did `foo(42)`--in this case `int` is the closer match. If you called your function with a short also it would probably cause an ambiguity error because it can't decide whether it should convert to `int` or `long`. The first is kind of an, "Oh, duh!" issue. I've made the mistake many times but it's a rather silly one to make. The second is annoying. Implicit casting and conversions cause confusion in a lot of places. That's one reason why people tend to recommend you avoid allowing them (make your "conversion" constructors explicit). So I'd do one of two things here: 1. Use a more interesting type--perhaps a simple strong typedef. Force the caller to disambiguate. 2. Implement your function for all basic types and do the casting you want yourself. This is sort of a rare problem if you stay away from implicit casting most of the time. When it comes up the compilers I've seen make it clear that the problem is it can't decide between two versions after its already resolved the name. The rules here are pretty simple though: the compiler will chose the closest match and there'd better eventually only be one. I don't think `REQUIRES` would solve the problem and if it did it wouldn't solve it any better. You could make a templated function so that `int` wasn't your parameter anymore but instead `T` is and you analyze `T`...perhaps `REQUIRES(sizeof(T) &gt;= 8)`. However, `void foo(int)` would still be taking an int if you add `REQUIRES` as the blogger is...you'd not be able to assert anything like, "Use this version if T is a short," because there's no T. You also still have to disambiguate except now you need to do it in the REQUIRES bit with `REQUIRES(sizeof(T) &lt; 8)` for the other one. And you're using SFINAE rather that type conversion rules. So yeah, I see what you're getting at now with overloads not working as you expect sometimes. I think though that the message is pretty clear and the rules simple enough that you know what the problem is when it comes up. I don't see how `REQUIRES` simplifies the issue either and I struggle to imagine a way in which it actually even addresses it.
He understands what people will do for points.
&gt; For example your example, if you have a second function for non-default constructible types I'd prefer tag dispatching to defining the second as REQUIRES(!std::is_default_constructible&lt;T&gt;::value). However, the `REQUIRES` macro produces much nicer error messages than tag-dispatching.
Since I explicitly stated they can be used together this response seems ... lacking. One can also use `static_assert` to clarify errors. I would expect anyone that's messing with this level of TMP already knows this so I'm a bit unplused that you'd exclude that middle when being fully aware of it.
&gt; Since I explicitly stated they can be used together this response seems Sorry, missed, that. But that seems like a lot more work. &gt; One can also use static_assert to clarify errors. Which is not quite as clear of errors, since the error will be in the function rather than the call site, but still better than none. 
OK, well since you say so...I guess that's all the justification I get so...sure, why not. From my POV the discussion is rather moot since you've not explained why anyone should do this to begin with. It's not like you've not had the opportunity since you're replying here.
&gt; From my POV the discussion is rather moot since you've not explained why anyone should do this to begin with. It's not like you've not had the opportunity since you're replying here. I was just presenting it as an alternative.
how do you deduce the return type from a generic lambda? the reason i switched to explicit return type in [my own](https://bitbucket.org/jehelset/abstract/src) take on this was because i couldn't figure out how to do that if i wanted to pass a generic lambda. edit: i peeped your code, really sweet. i didn't know common_type existed.
I benchmarked Boost.Log v1 against Log4cxx in 2009(!). At the time it was Boost DateTime formatting causing a slow down (and apparently MS STL vs STLPort). Not sure nowadays. See http://sourceforge.net/p/boost-log/discussion/710021/thread/47dd83b3/. 
Thanks for posting this example. That code is very inspirational, and it is surprisingly easy to follow, even for someone (like myself) that just learned about rvalue references, and rudiment use of auto and lambdas.
You mean that one IDE that ships with the most outdated latest compiler out there?
Very interesting code, I understand each section of the code (lambdas, RValues etc.) but what is a State Monad?
I think this would have been a better fit for /r/cpp_questions or even /r/learnprogramming. Many parts of formatting are a matter of taste. When looking at a codebase, I don't care if the braces are on new lines or the same line, whether the lines are 80, 120 or unlimited wide. The most important thing in formatting is a proper indentation that makes the control flow more obvious. And again, I don't care if it's tabs, 3 spaces or 6 spaces (although anything less than 3 is borderline). It's just like with natural text. As long as the font is readable, line-spacing is ok and the author has broken the text up in sensible paragraphs, it's the content that counts, not how it looks. If you haven't already, look at automatic code formatters, like [AStyle](http://astyle.sourceforge.net/). They can make formatting more consistent across your project, which is important (but not critical in my eyes). And now, to add to your confusion, I personally like this formatting of function signatures: void MyClass::functionName( int arg1, Unreadable&lt;Nested&lt;Template, Involving::Some::Namespace&gt;&gt; arg2, float arg3 ) const override { // Body } The main advantages are: * Return type is visually distinct from the function name, which is especially useful if it's a complicated or long type name involving templates. Even more useful if you need to qualify the function name with a namespace, maybe even a template parameter or two. * You can tell the number of arguments at a glance. I also find it easier to distinguish type / argument name like this. It takes more vertical space, but saves horizontal space, which is nice when you want to edit two files side-by-side on a single monitor. Unfortunately, I haven't found a formatter yet that allows me to automatically apply / enforce this style. Oh, well.
You can look at clang-format. You can specify a very robust set of options on how you want it formatted. That being said, don't worry too much about it. If your biggest concern is consistent code-formatting, you're doing well.
Are there any good examples of a practical application of this pattern?
We have looked at two proposals (N4111 and N4113) last week and liked the genaral direction. So the work has started in earnest, but a for comprehensive proposal there is still a lot of work. Bits and pieces might end up in 17, but the full thing will most likely take longer to bake.
You should look into clang-format. It'll let you change the formatting according to whatever rules you prefer automatically. 
Any chance you do the same test against spdlog ? Log4cxx vs spdlog would be great!
Consistence is the most important thing you should care, formatting is less.
Wooo But oreilly.com still lists the "undedited" version: http://shop.oreilly.com/product/0636920033707.do 
as far as I know that is common, use clang-format as someone else suggested, and stop worrying. Depending on the code type and target those rules vary, linux for example has a really good reason for tabs + really wide indentations, maybe you don't
I would love to hear that reason :)
Nice. Been looking forward to this for a while. 
Focus on consistency. Choose a set of formatting rules and be sure they are applied consistently. There are tools to help you with this, as others have mentioned, but don't get lost trying out various tools and tweaking the knobs. If your codebase already has a consistent style, just go with it.
CAF does have strongly typed actors for that purpose. See the [manual](http://www.actor-framework.org/manual/) for more details.
* Per default it does have its own IO loop. However, the backend can be replaced and you might see an ASIO configure option in the future. * An exception will cause the actor to terminate with exit reason `unhandled_exception` * There's a [fractal demo](https://github.com/actor-framework/fractal-demo) application to showcase some of CAF's features in a distributed setup. The code does need some cleanup though and is going to be overhauled in the near future. In case you want to have a look at a real world application based on CAF: [VAST](https://github.com/mavam/vast) is an excellent Open Source showcase.
I would like to add that everyone has different views on the "best" format. But by using clang-format, they can just take your code and change it to "their" style with a simple command.
Instead of manipulating the state directly the operations on the state are chained together.
Hey guys, thanks a lot for the replies! Sorry it took me so long to reply as well. I removed the semicolon but it didnt fix the problem. I also installed visual studio and ran the code with the same results. Ultimately I deleted the input file and made a new one and it suddenly worked. No idea why. 
One of the Qt developers gave an example of how you could avoid the moc pre-processor using several of reflection proposals. If you are referring to this, I have some bad news. As the developer mentioned, to make it work he needed reflection of generalized attributes, and not only that, but also custom generalized attributes. Given my impression of the how the standard makers view generalized attributes in general (they don't like them), I would guess that any proposal which introduces library-provided generalized attributes, aka custom generalized attributes, would have a hell of time getting into the standard. Even reflection of generalized attributes I'm not so sure would get into the standard, but I haven't yet read the current proposals for reflection. So either someone has to find a quite different way to implement moc insides C++, than what the moc maintainer blog about. Or we are still stuck with it, sadly. Btw, I could certainly understand why the standard would avoid custom gen-attributes. It would open up for a lot of questionable coding practices with probably the only reward being that Qt could drop moc. But then again, that could be worth it.
I bougth the Early Release version in July, and today I got the final release version (dated Nov 10). It looks great and the content is immaculate.
Any idea when/if this will show up on Safari Books Online/Proquest?
Yes I see this on safari. Also I have to spend tokens to individual chapters. I wonder when the final edit will come to safari...
When writing a parser combinator library, it can be useful to thread state into the functions behind the scenes, to not clutter up the interface. Using something like the state monad pattern, one can write code like this (psuedocode) myParser = char '(' &gt;&gt; oneOrMore letter &gt;&gt; char ')' to match an opening brace, followed by one or more alphanumeric letters, followed by a closing brace. Obviously this is a really tiny example, but all of the parser's state (the memoization table, the remaining input stream to read from, and the partial data structure being constructed) are passed to the functions `char`, `oneOrMore`, `letter`, etc behind the scenes automatically, leaving the actual interface simple and clean to use.
It can be used in any case where functional purity is wanted for a changed input that is paired with some other output of a different value/type, and where the syntactic overhead of doing so is not wanted, e.g: template&lt;typename S, typename Result&gt; std::pair&lt;S,Result&gt; f(S&amp; state, const int&amp; arg1, const string&amp; arg2) { .. } .. plus other messy functions to compose f with functions of type g&lt;S, ResultOrOtherType &gt; (S&amp; state, const double&amp;... etc); /* g may also be functionally dependent on the value of f's Result */ Unlike the above functions, state monad functions can be easily composed (chaining the state output of one function to the state input of another similar function). Use-cases of this occur in parsers, and random value/object generators. And I don't know if it's truly possible to capitalize on all the properties of the State Monad in C++. For some very powerful demonstrations of Monads + State Monad, see Haskell.
The heavy lifting comes from using a SFINAE capable result_of (which I had to implement myself as well). The easiest way to see if something is callable is by writing type traits for the *INVOKE* pseudo expression. There was a proposal to add a `std::invoke` which would perform the heavy lifting for a user (and if this were added you could use this with the `void_t`trick that Walter E. Brown showed off at CppCon). As it stands because I implement an `invoke` function in MNMLSTC Core, I have to do this heavy lifting myself (though I recently found a way to use `void_t`to check if something follows the *INVOKE* rules, and then implement the *INVOKE* rules elsewhere). common_type is pretty great for insuring that all return types for a given expression would work out well, and I think this can be used in cases where you have generic code that returns potentially different types (I believe this is also why common_type in C++14 performs a `decay_t&lt;T&gt;` on a given type, to remove qualifiers. A `T` can be converted to a `T const`, but not the other way around)
An alternative maybe - [CppCon 2014: Thomas Rodgers "Implementing Wire Protocols with Boost Fusion"](http://youtu.be/wbZdZKpUVeg)
Pick one and stick with it. Roll the dice if you can't decide. Only **idiots** will complain. Only consistency is important.
N4134 is purely a language extension. There is no library types (yet) to go with it apart from resumable_handle / resumable_traits. Library imbues await with higher-level semantics. If you want, you can use await to unpack monadic types like optional / expected. There is no asynchrony / coroutine in such usage at all. I expected that after coroutines are available in the language, robust async libraries will appear that tackle the concerns you raised. (Think templates language feature and Stepanov's STL that came later)
It will be a classic for sure.
&gt; That way Qt can avoid the moc pre-processor. For what do they actually need it? Signals and slots can be implemented in ISO-C++ directly since C++98 (check out gtkmm), including checks at compile-time.
The interesting this about the State monad is that you can define transforming operations without referring the the state itself. So, for the state of a game, I could write: auto game_loop = loop(update, // Update the positions of the actors do_collisions, render); game_loop(initial_state()) 
&gt; Ebook: $42.99 &gt; &gt; This item is not available. How can an ebook not be available? Anyway, can someone tell me what changed from the prerelease to the released version? Did any new chapters get added? Example?
If you have an IDE that can clang-format one way but clang-format it a different way when committing, by all means. I think the tooling is at it's infancy at this point, so beware that changing that is going to screw up the history (one person is going to be blamed for all the lines) &amp; play havock with merges.
I would love to support him by buying a copy, but 42.99 for an ebook? i don't think so..
I just decided to bite the bullet and use Boost Serialization and Boost Archive. Turned out to be supprisingly painless.
If you already know the basics of programming, then the [C++ Primer](http://www.amazon.com/Primer-5th-Edition-Stanley-Lippman/dp/0321714113) is also an excellent introduction. The 5th edition is updated to include C++11.
Qt's stream/shift (I'm not sure what's the formal name) operators overloading (e.g. for adding elements to containers) is one of the best interface decisions I've seen in my life. I used it few times too :) Do you have the code of your class available somewhere?
The official name would be the (left and right) shift operators. Of course that makes much less sense than just saying input/output operator when it's used for that purpose, though, hence the common referral.
Are you referring to [this](https://www.youtube.com/watch?v=ltCgzYcpFUI) talk relating c++ to the Vasa (a ship that sunk due to too much shit on it)? https://www.youtube.com/watch?v=ltCgzYcpFUI
yup. its a story.
while it may not be ideal (since that site prefers specific programming questions), there are countless questions on "tell me the differences between c and c++". the story I'm trying to find belongs in one of those answers!
I'm pretty sure he's said that pretty much all of Effective C++ still stands. Not sure on the other ones though.
Would you guys suggest this to a beginner?
No, I have not uploaded the code to somewhere but I can do it. Give me some days and I will put it in github ;)
Just start with this one. The mistakes programmers made with C++98 and STL aren't the same mistakes programmers make now. Those things were new back then, and the community as a whole has figured out how to teach them.
Books like this are aimed at intermediate programmers and above. You won't get much value until you've achieved basic competence with your language and core libraries.
I doubt it had much impact on build times. Serialization is a bloated mess, but that only shows up in the bad performance and large size of serialized data.
This appears vulnerable to exploits delivered by malicious malformed data. Why would you teach the next generation of programmers how to write vulnerable code?
Indeed you can break things if you try to read a malformed file, but how do you avoid that at all? Or you mean the example above?
your implementation is really elegant! well done. it's also possible to generate n-nary visitations in a similar manner you generate unary ones, maybe not useful enough to bother? i believe that approach might be preferrable to implementing a hardcoded binary vistation re:jason9000's source. the computation is only slightly more involved, seems to generate marginally faster (binary) dispatch by my own caveman measurements, and is the agnostic wrt to the arity of the visitation. a side note: wouldn't it be super-nifty wrt variant-implementation if you could expand template parameter packs out from the case-expressions of a switch, and/or array subscript operators? boost::variant (i think) uses preprocessing to generate a switch case, which seems to produce faster dispatch than any other implementation i've seen (allthough the margins are pretty small). it would also simplify the implementation quite a bit.
lol, glut
I like Matt Hermann's cake. https://github.com/Zomojo/Cake I really like it. $ cake exe/my_prog.cpp that then goes and finds everything included in that cpp, compiles it, links it, distributes the work over all my cores and I really don't spend time hacking the build system or even thinking about it, save when these posts come up. I like the way Matt Hermann has gone about it. Caveat - it's for greenfields projects only. It assumes foo.cpp relates to foo.hpp and treats it accordingly. 
As said by lots of people here: just focus on being consistent. Anyway, just my two cent here: I always liked [KDE/Qt formatting style](https://techbase.kde.org/Policies/Kdelibs_Coding_Style): if that happens to be also your ideal of consistency and aesthetic, in the previous link they have a [section](https://techbase.kde.org/Policies/Kdelibs_Coding_Style#Artistic_Style_.28astyle.29_automatic_code_formatting) about how to setup the program [astyle](http://astyle.sourceforge.net/) to automatically format all your sourcecode in one go, plus code formatting scripts for Vim or Emacs.
All I can say is wow. I know the NDK is still a second class citizen, but this is really encouraging.
What version of Qt because so far I have only used 3.14
Well, what exactly do you want to integrate? I guess in general the answer is pretty much "no, there is no manual yet", as OpenCV 3 is very new, and certainly not a lot of people use the combination you mention. It might help though if you were more specific. 
I guess it's more that most of Effective C++ is nowadays considered common-sense. (Most, not everything.)
It's amazing that with 50K employees, and after many years, they still can't get their compiler front-end caught up with modern C++ features.
&gt; If it tells you that you have size_t(0)-1 structs, you'd better check that the stream has enough data before you allocate that much memory. Alternatively, just try to allocate, let `bad_alloc` unwind the stack... ... though my personal preference is just to `push_back` the data as soon as I read it and let the amortized constant cost take care of re-allocating as few times as possible.
Did I miss them releasing VS2014? I just find it funny that there's a preview of 2015 out before a full release for 2014.
Then some type of format description should be performed first (something like xsd for xml, so to speak). That ByteStream class is just glorified fwrite/fread which advances the writer/reader head in function of the provided type.
Microsoft isn't required to release a version of VS every year. There wasn't a Visual Studio 2011 either 
I get that, but they've been releasing previews of VS2014 for a while now. To me it had seemed like they were getting close to full release. Does anyone know if the new preview has the VS2014 features integrated as well?
IMO the highlight is tucked in at the bottom: &gt; we have also done work on improving clean build times where typically majority of the time is spent in the compiler frontend. As a result of this work template heavy C++ code should now compile faster. As an example, the Unreal game engine which is template heavy compiles ~30% faster with VS2015 Preview.
Herb Sutter posted a video here: http://channel9.msdn.com/Events/Visual-Studio/Connect-event-2014/311 At around the 1:13 mark there is a chart titled "C++ conformance update". It looks like two-phase lookup is not happening any time soon.
Still no support for C99. It's only been 16 years.
&gt; I don't know what power do you expect from MS. For a company whose former CEO stood on a stage yelling DEVELOPERS DEVELOPERS DEVELOPERS, a company that -- despite layoffs -- is sitting on more cash than god, I would *expect* that such a company could hire a decent staff of full time engineers, testers, and technical writers to actually walk the walk instead of talking the talk. That's what I would *expect*. What I actually get is constantly paring down to the bone, fewer people doing more work as the new normal, middle management marketing dweebs promising more more more while overall quality/robustness spirals ever downward. And finally, Microsoft throws up its hands and says we won't pay for this at all, if you want it you need to do it yourself. On your own time. For free. THAT is the reality of corporate amerikkka. I'm glad for the cross-platform possibilities here. I have no delusions at all about why this decision was made. I guarantee you it was not a gesture of goodwill. It is Microsoft being too cheap to hire help and pay them. 
That was Visual Studio "14", which I believe was a codename for 2015
Great news!
The Incremental LTCG is particularly impressive. Microsoft is the first to offer such a feature, right? The incremental static library linking is also impressive, although CMake's object library target seems like a better approach. Avoids generation of a static library in the first place which is perfect for internal targets.
Thanks! I try to make my code small and simple (and easy to follow). It should be possible to do, I was trying to reach an almost 1:1 interface with Boost.Variant so that you could drop `core::variant` in and have very few changes (but definitely have some compile-time performance increases. `core::variant`includes only a few files internally while Boost.Variant includes many files; 374 IIRC) Actually for Core 2.0, which will be the version I start on *after* 1.2, I do plan to make a constexpr capable variant, the hard part of it is delegating construction to its underlying union, without running into a few issues. I did learn a lot about C++11 (and later) while writing Core though, so I think it's definitely possible to do. I also plan to break the interface a bit with it, to allow for nullable variants and also to change how the visitation stuff works to allow for better binary visitation. I've been meaning to revisit the visitation method in Core, to see if I could possibly do that, or at least fake something like it. I think it would be a lot simpler in its implementation if I didn't have to do the workaround regarding unpacking lambdas when using GCC. It's the one thing that I wish would work, but I don't know enough about GCC's internals to attempt to fix it myself. :/
it didn't - but I was already using templates elsewhere in the project and it's still a very small project.
VS2015 == VS "14" :) 14 is the version number. Currently we are on VS12, they skipped 13 for superstitious reasons.
Well now I feel like a dumbass. That makes much more sense.
That makes so much more sense. Thanks!
&gt; Note (11/12/2014 1:00pm EST]: This proposed feature was approved by the Evolution and Core Working Groups in June 2014, and it was implemented in VS 2015 Preview and Clang 3.5, but the full Standardization Committee rejected this feature on Nov. 7, so it will be removed from VS 2015 RTM. New syntax will be proposed at the next Committee meeting in May 2015. I'm actually glad to hear that. I didn't like that syntax because it's inconsistent with every other declaration in the language, except one place in which it was introduced by accident, partly because that one place isn't supposed to be thought of as containing declarations at all (lambda capture lists). The terse syntax just doesn't seem that valuable, because the only benefit is that it encourages a particular default (`auto &amp;&amp;`) where it is perfectly fine for developers to select `auto`, `auto &amp;`, or `auto &amp;&amp;` based on what they're actually doing, nor does there seem to be any real problem in asking developers to be explicit. The proposal gave some reasonable examples that show `auto &amp;&amp;` is usually a good choice but doesn't really give a good reason to hide `auto &amp;&amp;`. Additionally, code can be written such that `auto &amp;&amp;` is the wrong choice, and hiding the declaration might end up confusing people when they forget the details of what the terse syntax does. So I just don't see that the terse syntax is better than simply teaching people, "This is how to loop over a range most of the time: `for (auto &amp;&amp;x : v) {`".
as long as the command line compiler remains that I can use with our build stuffs. I do all my heavy lifting on linux and run verification on windows.
Hold on... did you just say that it's not really amazing or unexpected that one of the world's largest software companies is unable to implement a basic functioning C and C++ compiler? It's not like C and C++ are obscure languages, Windows is built using them and its API is defined in terms of both C and C++.
No. The C99 features they support (aside from C99 features already in C++) are designated initializers and compound literals.
So can I use this to code in C?? I really want to code in C.
The future of Visual Studio looks very exciting, [here is a bit from their blog](http://blogs.msdn.com/b/somasegar/archive/2014/11/12/opening-up-visual-studio-and-net-to-every-developer-any-application-net-server-core-open-source-and-cross-platform-visual-studio-community-2013-and-preview-of-visual-studio-2015-and-net-2015.aspx): &gt; With Visual Studio 2015, we are delivering a complete tool chain for cross-platform mobile development with C++. This includes integrated support for the Clang complier and LLVM optimizer for targeting Android now and iOS soon. You can edit and debug a single set of C++ source code, and build it for iOS, Android and Windows. This is awesome.
Visual Studio does come with a C compiler but it is seriously out of date. Like C90 out of date! It has some C99 bits implemented but it is far from a real C99 compiler. If you want to do C and are you Windows I highly recommend the free IDE/Compiler Pelles C, you can grab it at http://www.smorgasbordet.com/pellesc/ GCC is also an option should you want to just hack away at code in a nice text editor. 
I know! So fucking awesome. I wonder if they will include Clang or require it to be user installed separately? 
lol, Microsoft.
2004 called. They want their comment back.
Ah thanks for the info, I couldn't find anything definitive.
It wasn't clear if there's a price for the combined print/ebook. Did I miss something?
Great news, long live Microsoft!
Thanks! I use python with NotePad++ and windows powershell.
It will almost assuredly be user-supplied.
&gt;Qt Creator with MinGW Which means you were using a better compiler/standard library than what you'll get with VS, unfortunately.
&gt; Alternatively, just try to allocate, let bad_alloc unwind the stack That requires you to catch the exception (which you should do anyhow), and runs the risk that you won't *quite* run out of memory, and doing so can cause problems for another more critical thread. It's also expensive to allocate that much memory, and that's a great DOS attack vector right there. &gt; though my personal preference is just to push_back the data as soon as I read it and let the amortized constant cost take care of re-allocating as few times as possible. I hope that was a joke.
That's a valid answer, but please say so when talking to beginners. Otherwise they'll have no idea that there are other steps they need to do. Separate validation and loading steps aren't my preferred method, but it is valid.
In what way is libstdc++ better than msvc's standard library? It's lagging significantly behind in features and correctness, and I haven't seen any benchmarks that suggest it performs better.
2013 has nearly all of C99. IIRC all that it's missing is &lt;tgmath.h&gt;, &lt;uchar.h&gt; and `snprintf` (which is implemented in all of the 14 previews). The initial release had a bunch of C99 language feature related bugs, but those were mostly fixed in the first two updates. [e] It's also missing VLAs, but those were made "optional" in C11.
That's exactly my point
That would be extremely weird. Why would they ship an Android development environment without a compiler?
&gt; I don't know what power do you expect from MS. I expect them to spend some of their $$$ to hire one or two more people and catch up to C++ standards that are 3 years old. Or even fix features from an 11 year old standard. Of course, if they hire some good people, they won't be able to spend $400M on Surface 3 advertisement... 
Implementing less of the standard library and still not implementing `std::string` correctly makes libstdc++ better? That's a rather unusual position to take.
You have it backwards. libstdc++ has MORE of the standard library implemented than MSVC's library. I'm not sure on the std::string you're talking about 
As of gcc 4.9 and VS 2013, libstdc++ implements nothing that vc++ doesn't, and lacks &lt;codecvt&gt;. 4.8 vs. 2012 was even more in vc++'s favor, as 4.8 lacked &lt;regex&gt; and a whole bunch of assorted important things like `emplace()` on `map`/`set`, move constructors for iostreams, and a bunch of things in &lt;thread&gt; (the one I remember offhand is `std::this_thread::sleep()`). While vc++'s compiler is significantly lagging behind g++ (and even more behind clang), the standard library has been consistently ahead of libstdc++ for the last few years. The `std::string` issue is that libstdc++ still uses copy-on-write strings, which is explicitly forbidden by C++11 (they haven't changed because the ABI break would be very painful on Linux, but that isn't really relevant to comparisons on Windows).
No dumbassness at all, the name change without explanation is a bit irritating. I had downloaded and been playing with Visual Studio 2014 CTP 3 (Customer Technology Preview) since last month. Today's press release does not at all state clearly that they just decided to rename it at the last minute, you kind of have to read between the lines to figure that out. Kind of Orwellian: "The next release has always been called Visual Studio 2015." Or may it's Oz-like: "Pay no attention to those Visual Studio 2014 CTP releases we've been issuing." So as far as I can tell they just decided to call it "Visual Studio 2015 Preview" instead of "Visual Studio 2014 CTP 4". That's fine, but 1 or 2 sentences in the press release clarifying that would have been nice. EDIT: Here's a funny clue. The web page includes a link to [C++ in Visual Studio "14" (Thu, 17:00)](http://channel9.msdn.com/Events/Visual-Studio/Connect-event-2014/029). The double-quotes are a bit of a giveaway of names in transition, but when you click on the link, the event is actually titled "C++ in Visual Studio 2015".
&gt; Their C++ compiler doesn't support the C++03 standard which is now 11 years old and two revisions behind. Your definition of "supports" is "supports 100% of the standard and has 0 bugs". Good luck with that. You're nit-picking beyond reason. &gt;People who develop software using that platform API do care about C++11. They can use C++11/14 features that are in MSVC compiler, or they can use another compiler that does have the "complete" C++11/14. &gt;You can't be serious that C++/CLI, which is used to wrap C++ code for use with .NET's managed environment, is more important to C++ developers I did not say that. I said that it is more important to people who write for MS platform. Honestly... you **can't, at all**, take e.g. GCC and write for .NET, and you hardly can write for WinRT with GCC. Oh, and: you mention C. C is dead on MS platform. You don't need a C compiler **at all** to write for it.
&gt; 14 is the version number. Currently we are on VS12, they skipped 13 for superstitious reasons. My understanding was that they skipped 13 to reduce confusion, to finally get the internal numbers nicely aligned with the marketing product names. Then the schedule slipped, and now we're back where we were before. Hadn't heard the "unlucky 13" thing, that seems even more ridiculous for a supposed tech company.
They are getting there slowly. Not that I think they're doing it out of kindness or anything, but business-wise they're realizing that Microsoft doesn't rule the world any more so now they need standards compliance to stay relevant. I've been playing with "Visual Studio 2014 CTP 3" (the name of the previous release prior to this one) and the biggest problems I've encountered when building old C/C++ code is that the compiler and standard libraries now support standard C/C++ features like stdint.h, stdbool.h, vnsprintf, etc. that weren't supported before. Lots of old code has #ifdef workarounds for previous versions of Visual Studio, and those workarounds now clash with the new standards-compliant implementations. So you need to change lots of "#ifdef _MSC_VER" non-standards-compliance workarounds to "#if defined( _MSC_VER ) &amp;&amp; (_MSC_VER &lt; 1900)" 
LLVM isn't Free Software. There are no licensing complications involved in shipping it in binary form without source. One of the major things they announced today was an Android emulator that's fully integrated into VS along with debugging support, and between the various announcements they covered everything an Android development environment would need to have.
&gt;Your definition of "supports" is "supports 100% of the standard and has 0 bugs". Good luck with that. You're nit-picking beyond reason. This is untrue. &gt;They can use C++11/14 features that are in MSVC compiler, or they can use another compiler that does have the "complete" C++11/14. Yes but then they can't use the functionality available in the native Win32 API since the Win32 API is defined in terms of non-standard and undocumented extensions to their C compiler. MingW, for example, has to ship a duplicate of the Windows header files to emulate most of the functionality available in Win32, but the maintainers have been unable to figure out many aspects of it, considering that much of how the functionality is exposed in the native header files are based on undocumented C compiler extensions. &gt;Oh, and: you mention C. C is dead on MS platform. Except for the fact that the Win32 API is defined in terms of C. But sure, apart from their OS exposing its core functionality using C, yeah, C is dead on MS platform.
With the advent of lambdas and std::function in c++11, using callbacks for this sort of thing starts to look a lot more attractive. Instead of having to loop over your stream using &gt;&gt; until it's done (or indefinitely if it's that kind of stream), you just register the callbacks you need and start streaming.
I don't know what something like Photoshop does when loading a png file: do it read some bytes and then for each step validate it? Anyway you first need to load some data and then check if it is valid or not(magic numbers, hashes, etc), if it is possible at all due to file format. The loading part can be done by ByteStream, the check step is up to its user.
14 was always a version, never a year. When 14 CTP1 was released, DevDiv's Corp VP [announced](http://blogs.msdn.com/b/somasegar/archive/2014/06/03/first-preview-of-visual-studio-quot-14-quot-available-now.aspx) that RTM would be in 2015. I've been watching the confusion between versions and years, and groaning every time. Even a few employees have been confused; e.g. command prompts were titled "2014" which was incorrect and had to be fixed.
ridiculous yes but they did the same thing for Office recently ;)
btw Stephan, your tiny but awesome Ranges TNG proposal is still listed as a feature, yet there was a tweet by Jonathan Caves that it was voted out of C++17. What gives? (FWIW, Clang also still lists it as a feature for 3.5 and onwards).
FYI, you can just use `#if _MSC_VER &lt; 1900` because when `_MSC_VER` isn't defined it's replaced by `0`.
As a dev, I couldn't care less if some C++17 feature is implemented while C++11 is STILL not fully implemented. "Oh we'll add terse for-loops but fuck people who want to use actually useful things like constexpr". Get your priorities right please Microsoft.
Finally! (And one less reason to use Go. You *can* implement coroutines &amp; channels even in C++11, as a library, with ugly platform-dependent code hidden.)
Lol, watching GCC and MSVC fans argue is like watching the special olympics :) libc++ for ever!
Yeah, just configure your project to use GCC or clang. The IDE is fine - the MS compiler on the other hand is hopelessly outdated for C.
The dudes behind STL are really switched on at MS. They always seem to be pushing ahead in trying to improve the library standards by experimenting with new things. 
Especially /u/STL.... Great guy!
* full constexpr == hard * terse for loop == five minutes of one dev's time while he is eating a sandwich Also no, while it would be better to have full C++11 and piece of 17, it doesn't follow that having full C++11 support is better than most of it + pieces of new standards. ---edit--- Also two phase lookup.
Do we have any idea on when VS 2015 is expected to be released?
`libc++` is actually not `gcc`, it's the C++ standard library implementation that is being done under LLVM, and ships by default with `clang++` (though it can freely use `libc++` as well as `libstdc++`).
If you want to code in C and don't want to deal with microsoft's compiler, but still use the IDE, the easiest way is download and run the Windows installer from http://llvm.org/builds/ Then you can select the LLVM toolchain in the project options. The LLVM toolchain works pretty well exceptions are still a work in progress. Given that you do not need them in C, you should be fine. You will then be able to use the IDE for building your coding, debugging, and building just as you would normally, but the compiler will be clang.
That's awesome. It looks like a great piece of technology. Would definitely help untangle the callback-hell mess with libdispatch.
&gt; have rewritten it from scratch about 200 times whaaaaaat
Well not really 200 times, just a bunch of times.
None, enjoy your opportunity to write bit-bashing code :) If you get to define the file format yourself, you can use something like protobuf, but only if you're comfortable saying that your file format is "whatever protobuf decides" instead of defining a file format spec yourself.
hey man if at first you don't succeed the way to get to Carnegie Hall is practice!
&gt; So I just don't see that the terse syntax is better than simply teaching people, "This is how to loop over a range most of the time: for (auto &amp;&amp;x : v) {". FWIW, to me it's that defaults matter. In general, defaults should be correct and efficient; using plain 'auto' in range-for seems to be a recurring (if occasional) performance pitfall even when we know better. Also, defaults reduce concept count for people learning a language or just using it day by day; yes, we could teach "usually write auto&amp;&amp;" here, but it would probably be the only place where we would have to teach the &amp;&amp; concept in the first 50 pages of a book.
Had a quick look. * You're using global variables for no reason * WinMain() is a 300+ line function. WTF? * Why is this function that deletes a file called "unblockFile"? * Some C library calls like memset, most of them unnecessary. File access entirely C, not C++ * Generally hard to read, ex.: if (!URLDownloadToFile(...) == S_OK). Why not use !=? * Not a single comment to be found, even in the part where you're downloading and silently installing some Adobe crap and whatnot Edit: I think that this is not something that should be done in C++. It's ok for learning purposes, but C++ doesn't seem to be the right tool for the job. Could be done in some script language in just a few lines of code, instead of 500 buggy lines of C++.
&gt; In previous versions of Visual Studio it worked fine, but starting with 1900 I got error messages about redefinitions of standard types. My psychic debugging powers suggest that some VC header started dragging in VC's stdint.h, leading to the conflict. /showIncludes will reveal what's happening (if not, /P).
And `auto elem` is a correctness trap, not just a performance pitfall.
That's basically right. The range-for proposal took literally less than an hour to implement, whereas constexpr is probably *the* hardest feature in C++11 to implement.
`if (!URLDownloadToFile(nullptr, url.c_str(), file.c_str(), 0, nullptr) == S_OK)` **BUG:** This isn't doing what you think it's doing. In C and C++, negation binds very tightly, much more so than equality. (I have precedence charts taped to my home and work monitors.) So when you write `!x == y`, it's parsed as `(!x) == y`. You almost certainly intended `!(x == y)`, which is equivalent to `x != y`.
It is unclear to me exactly how stackless this is; most examples do not contain any further function call, except the one calling `sleep`. Could you explain in broad strokes what are the limits of stackless coroutines? *Note: stackful coroutines seem incredibly difficult to get right, the Go green-thread strategy, for example, rely on its GC implementation for correct performance because the sheer number of concurrent coroutines you could want for is not compatible with large stacks as we use for regular OS threads.*
Yeah for *fold-expressions*! However, regarding N4268 (more `constexpr`), would it be time to lift the restrictions on non-type template parameters so they encompass any value that may be generated as `constexpr`... and thus include values of arbitrary types!
I agree that defaults matter and that if there's going to be a default then `auto &amp;&amp;` is the right one in a `for`-loop. But is a declaration syntax that leaves out the declaration bit a good way to indicate that you want to create a variable with a default type? And if so are there other places that should use it? Should they each get the same `auto &amp;&amp;` behavior, or do we need a different default in each case? Lambda capture lists, the place this declaration-less declaration syntax was previously introduced by accident, already behave differently from the proposed terse `for`-loop. On the issue of occasional unnecessary copies, I think that this core language change is not the best way to address it. Implementing this proposal does not prevent unnecessary copies, it just makes them perhaps a bit less common at the cost of creating other problems. I think a superior solution is C++ tooling such as a linter or compiler warning that looks for this problem. Tooling can both cast a wider net to catch more problems and more precisely target actual problem cases, all without the problematic side-effects of a core language change. As for concept count, in your first 50 pages `auto &amp;&amp;` doesn't need to be taught as a concept any more than the terse syntax does. In both cases the first 50 pages should simply teach it as the magic syntax for looping over ranges most of the time. If you were to teach the terse syntax as a concept you'd be introducing what `auto &amp;&amp;` does even if you don't use `&amp;&amp;` in your description. I don't see that the terse syntax saves anything in terms of concept count for the first 50 pages, and it increases the concept count of the whole book by one. --- For me the answer is that this is not the right syntax. No good syntax occurs to me, but I'm still open to the idea and I'll await an updated version of the proposal to see if STL comes up with something. I'm also looking forward to seeing the ISO C++ meeting minutes to see what exactly the committee's issue with the proposal was.
Wouldn't that essentially be the same thing. If !x == y and if x!=y are the same aren't they? 
No. As STL said, `!x == y` is the same as `(!x) == y`, not `!(x == y)`. Consider this example: int x = 2; int y = 1; std::cout &lt;&lt; (!x == y) &lt;&lt; '\n'; std::cout &lt;&lt; (x != y) &lt;&lt; '\n'; `x` and `y` are not equal, so `x != y` is true, as is `!(x == y)`, but `(!x) == y` is false. And here are the handy compiler warnings pointing this out when you try it: main.cpp:6:19: warning: logical not is only applied to the left hand side of this comparison [-Wlogical-not-parentheses] std::cout &lt;&lt; (!x == y) &lt;&lt; '\n'; ^ ~~ main.cpp:6:19: note: add parentheses after the '!' to evaluate the comparison first std::cout &lt;&lt; (!x == y) &lt;&lt; '\n'; ^ ( ) main.cpp:6:19: note: add parentheses around left hand side expression to silence this warning std::cout &lt;&lt; (!x == y) &lt;&lt; '\n'; ^ ( )
He's correct. ! has precedence over ==. Did not even notice that, heh. Kind of proves my point regarding the line.
Ahh gotcha. Was a bit confused there haha. Thanks for clearing that up. 
Stackful coroutines are cooperatively scheduled threads with a coroutine interface on top. A stackless coroutine is a function that can suspend and resume. Prior to language supported coroutines, the only way to implement a coroutine was to give every coroutine its own thread (fiber). Resuming a stackful coroutine is a context switch. Resuming a stackless coroutine is a normal function invocation with a funny prolog that allows to access variables with automatic storage duration that are stored separately from activation frame of the coroutine. Stackless coroutines are not general purpose thread / fiber replacements. They are callback / state machine replacements. It would be awkward to imitate threads using stackless coroutines, though sometimes it may be beneficial from performance perspective if higher overhead of a coroutine frame creation is compensated by cheaper suspend/resume and no limits on what you can call from a coroutine. 
I doubt yall can do better, if you can, prove it. Edit: Lesson learnt, commas are very important in structuring a sentence.
Seems like everyone says this. Just because something is hard why does that mean we can't do it. It a matter of priorities, not dev time, and we should not be advocating shortcuts and easy, unnecessary things over necessary but hard things. It sucks for when I (and others) have to write to msvc standards rather than Iso c++ standards, it makes writing cross platform software hard. It is always "this works in every compiler except msvc". You'd think for a big company with so many employees they'd be at least on the curve, not years and decades behind.
These are bugs: std::wifstream(L"lol.exe").good() &amp; std::wifstream(L"lol.launcher.exe").fail() std::wifstream(L"lol.launcher.exe").good() &amp; std::wifstream(L"lol.exe").fail() `good()` and `fail()` return type `bool`, so it doesn't make sense to use a bitwise and here. You should use the logical and, `&amp;&amp;`.
thanks, not a critical feature though.
reddit has the answer to everything.
Dude, really to a beginner these things are nearly impossible to understand straight from the start.
Its usefulness really becomes apparent when you're working with a big, mutli-threadded program, where multiple threads all need data from one stream object. If your design requires you to extract data from the stream (using &gt;&gt;, for instance), then your threads need to all be aware of each other and have to make sure that they aren't taking data meant for someone else, or put the stream in a state that might break another thread.
I make it clear enough on my website.
aa a f
Hah! I am actually writing a type not too far from what he suggested in his post as of yesterday, and I even read the same paper. *Get out of my head!*
I've written quite a few parsers over the years, and allocations are always the bottleneck unless you're doing something like parsing via XPath. Preallocating when you know the required size is a very good optimization, and quite readable.
I think metaprogramming is going to change dramatically in c++14 and beyond. I find Louis Dionne's *Hana* library particularly compelling. Lifting types to values and metafunctions to functions seems to be a powerful foundation.
I think Hana is a very promising direction, and looks to be a good post-modern replacement for Boost.Fusion. I'm less convinced about its usefulness for pure compile-time type manipulation. From the docs: auto ts = tuple(type&lt;int*&gt;, type&lt;void&gt;, type&lt;char const&gt;); for_each(ts, [](auto t) { using T = typename decltype(t)::type; std::cout &lt;&lt; typeid(T).name(); }); I don't like having to wrap types in `type&lt;&gt;`, and I don't like the idea of sprinkling my code with `typename decltype(t)::type`. It's rather awkward. It's great that Hana can do this, but I don't think it's a substitute for typelist algorithms.
There is some awkwardness, but I think it's perhaps less awkward than the typical c++ template syntax. I find this example from his cppcon talk quite elegant: template &lt;typename ...T&gt; using smallest = decltype( minimum_by(ordering(sizeof_), tuple(type&lt;T&gt;...)) ); template &lt;int i&gt; struct storage { char s[i]; }; static_assert(std::is_same&lt; smallest&lt;storage&lt;3&gt;, storage&lt;1&gt;, storage&lt;2&gt;&gt;::type, storage&lt;1&gt; &gt;::value, ""); Here smallest&lt;...&gt; is a pure compile-time type manipulation and I would argue the wrapping in type&lt;T&gt; and unwrapping by decltype() is not obtrusive. And that expression, "minimum\_by(ordering(sizeof_), tuple(type&lt;T&gt;...))" reads so well I think I'd happily make the trade. 
Agreed. I point it out since I believe elements of its core may be worth considering to help inform additions to the standard library. As you say, it seems a promising direction.
That is actually a good book to get the conceptual pieces of audio programming. Its age does not matter much since the basis hasnt changed. Even older books can also proof very useful such as "computer music tutorial" for example. For practical stuff like audio file io and communicating with a sound card or making plug ins you will need to look in to libraries and frameworks. A big one used in the audio programming industry is JUCE. Also portaudio, libsndfile, jackaudo, iplug, rtaudo, are some more open source stuff to look into. Be aware that most of these are actually c, but Juce is very m odern C++.
I had a similar problem I wanted to solve and wrote something I think is rather similar. The difference is I didn't have a particular struct called e.g. typelist; instead I thought that _any_ variadic template should qualify as a container of types. E.g. you can do this: using T1 = std::tuple&lt;int, double&gt;; using T2 = std::tuple&lt;char&gt;; using J = Join&lt;T1, T2&gt;; // = std::tuple&lt;int, double, char&gt; Code here: https://github.com/cdyson37/rebind
I can second the other comment's recommendation of [JUCE](http://www.juce.com/), I produce [a synthesizer](http://sound-guru.com/software/mangle/) using it, and it really makes the basics of opening audio files, playing audio etc. very easy. And the C++ is really really nice. It's free as long as you're not selling a product (you can buy a license for that, which IMHO is reasonably priced). Of course, you still have to write your own code to manipulate / generate your audio, which is a massive discipline of its own, obviously it's fairly mathematical. I recommend [this blog](http://www.earlevel.com/), which contains lots of really good articles on many of the basic components that get used - filters, envelopes, oscillators and all that good stuff.
Great thing! But why students only? Why not the whole academics? That way, teachers can have it too to show it to their students!
Just a small addendum, juce is free as long as you do not release anything closed source. A free closed source product would also not be allowed.
Memory mapping and then access your entire file with pointer arithmetic. If you want more higher level access write a wrapper class for it. Don't use C++ streams, don't use fread() like functions, use memory mapping and be done with it. 
Bit of a long shot but does anybody know if this Community version will include the code coverage tool? This is currently only available with Premium and Ultimate editions and *not* Professional.
Stack Overflow is for *technical*, *on site* answers. Your question simply does not fit that mould, and it’s fundamentally different from other “differences between A and B” questions in this regard.^1 This doesn’t mean that it’s a bad question, and the reflexive downvoting is a pity. But I would have closed this question. --- ^1 It’s worth noting that these questions are also no longer welcome on Stack Overflow since they usually engender lists of (equally valid) answer rather than “one true” acceptable answer. This, in my opinion, is a patently stupid rule. But there you are.
Also better: X * 1.0/Y;
What was the reason for the rejection?
Some people were concerned that the syntax looked even less like a variable definition than classic range-for, and that this would lead to users attempting to access previously declared variables with it.
All academics will also be granted a license. They need to provide an alternative document to confirm.
Note that the analyzer is not only for C++. Tool must print a generalized messages. For example, this is C file (color.c).
Hmmm.... too bad. I really, really liked the syntax.
I am sorry if I annoy you (in which case I urge you to just ignore me), but I fail to understand: - whether a stackless coroutine can invoke arbitrary functions (which will use a stack) ? - whether a stackless coroutine can invoke arbitrary functions *which will yield at some unknown depth* ?
Just finished it last night. If you enjoyed Elements of Programming you'll probably enjoy this one too (and learn some number theory along the way).
&gt; the best C++ IDE for Windows Best IDE anywhere. I spend a *lot* of time cursing the whole Linux dev toolchain. It boggles my mind how far the open source community has come without a productive dev environment. And don't even get me started on gdb.
Can't install it on the current Windows 10 build.
Just because it's unproductive for you, doesn't mean it's unproductive for everyone. I do most my programming in VIM. The only exception is KDevelop when the project gets very big, and only because KDevelop has a VIM mode, and even then I only use it as a glorified CMake frontend. IDEs always impose some usage style on you and if you try to go against that, it will make your life hell. I did try the IDE way, but before I tried KDevelop, 90% of the time was spent fighting bullshit defaults, looking for *fundamental* settings like linker and compiler options hidden 5 layers deep, and when it all finally worked like it should, I was 100% constrained to that IDE with that exact setup, and copying it to different devices was a catastrophe.
QtCreator on anywhere Qt runs is FANTASTIC. Way lighter on resources than VS, the code editor is top notch, fake vim support, excellent session/project management, and gets updated like crazy. Even for non-Qt projects.
I use Qt Creator professionally in preference to Visual Studio. It's just embarrassing how poor intellisense is in comparison to Qt Creator's code navigation and completion.
I'll give you gdb. But Visual Studio (Windows in general) is horrible for large C++ projects. I switched years ago and my productivity greatly increased. I have a former MS Engineer, who used nothing but studio for years, transitioning to emacs as we speak because Studio is such a POS.
To be fair, when you take the time to learn it the linux dev toolchain is that you run one command and it builds everything for you. I haven't used visual studio extensively, but gdb itself is one of the best debuggers out there. It just doesn't have a GUI, though you can get one easily. For instance, I use gdb with emacs and in that mode I can create breakpoints by clicking on lines, have watches in a separate frame, etc.
It depends on how far you want to extend the term "toolchain". That autotools is still around (and in widespread use) does indeed boggle the mind. But I've found both Emacs and VIM far more capable code editors than any IDE.
Are these kinds of discussions really that useful? Sure some people like having an all-in-one graphical IDE and good for them. Some other people like working with smaller lightweight tools that they can compose together and customize, good for them. It's really not that mind boggling that a diverse group of developers will prefer different ways of working.
They are licensing the Standard Library from Dinkumware, so STL is really not the only one working on it.
&amp;lt;boggle&amp;gt;
I have the book in question and find it a great first resource. It does have enough information, examples and theory to be able to "get going". It does lack a little when it comes to the finer points of signal processing - which is ok - the book wasn't intended to be DSP for programmers. So consider supplementing it (or something like it) a little later with deeper material concerning signal processing for things like filters and frequency domain processing. My last recommendation would be to look into tools like MaxMSP, PureData, SuperCollider etc as platforms on which to experiment and get a practical understanding of what individual pieces of signal processing are doing. It took me quite some time trying to understand the "time" nature of phase modification in a filter - but once I'd built a test rig to show what was happening it clicked. Do not underestimate the mathematics behind audio programming .-) 
I used to use VS for all C++ dev on windows, as of about 5 months ago I switched to Emacs. I'm never going back, VS is just so restrictive and doesn't have particularly good C++ support compared to any of the modern clang based systems.
The only thing VS is still king of is C# dev, and even then that's only if you have ReSharper installed to beat the NRefactory based plugins for real editors. VS is up there with IntelliJ at having a good out of the box default configuration, but it's severely limited once you move beyond basic code navigation and completion.
what he said. programming tools must be programmable. studio fails in that area.
1. Yes. It has no restrictions on what you can call. Stackless coroutine is a normal function that does not fiddle with the stack in any funny way. It just does not keep the state that must persist across suspends on the stack. 2. No and Yes. No, because you are not asking to suspend a coroutine, you are asking to suspend entire thread. Not just a function which is at an arbitrary call depth. To do that you have to have a call stack associated with a coroutine, ie. running on its own fiber (or other lighter weight user-mode thread). Yes, because you can call other coroutines and await or yield on them. (That is what I was referring in my previous reply as an awkward imitations of a thread) auto flatten(node* n) -&gt; generator&lt;decltype(n-&gt;value)&gt; { if (n == nullptr) return; yield flatten(n-&gt;left); yield n-&gt;value; yield flatten(n-&gt;right); } bool same_fringe(node* tree1, node* tree2) { auto seq1 = flatten(tree1); auto seq2 = flatten(tree2); return equal(begin(seq1), end(seq1), begin(seq2), end(seq2)); } Did I answer your question? 
You can say what you want, but our compilers actually support current standards :)
The way that most of these work is by writing a stub decompressor that gets concatenated with a .zip or .rar or whatever archive. The archive has a header at the end, whereas the executable has its header/directory at the beginning, and the operating system doesn't care about extra data past where the header says that the file ends. So the stub just opens itself, seeks to the end, reads the archive header (which contains relative offsets to the compressed data), and then proceeds from there. 
My new syntax is shorter and better (I prefer it to the original, although it is more radical; the original tried to be a conservative transformation).
aa a f
I look forward to seeing it. (Any possibility of a preview?)
`for ELEM(RANGE) {` where ELEM is an identifier and RANGE is the usual range expression. Also `for const ELEM(RANGE) {`. It looks like a variable definition whose type is `for`, compare it to `int meow(value);`. I have to write up coherent arguments explaining why this is desirable and answering questions about potential downsides, plus Standardese, but that's the basic idea.
Too true! But I'm not using the msvc compiler with Visual Studio. I use clang under mingw. Visual Studio is perfectly happy calling out to gnu make or cmake to actually do the build.
I've been using both for small to medium projects. I love eclipse but for some reason it breaks every couple of months... Creator is less powerful but it suits my needs. 
&gt; For instance, I use gdb with emacs and in that mode I can create breakpoints by clicking on lines, have watches in a separate frame, etc. Can those GUIs easily traverse pointer-based data structures or contents of STL classes? E.g., it displays classes as a tree, and if I click on a pointer, it will expand the tree and display the thing pointed to. Each time I write `print *this` into GDB's command-line and the object is slightly complex (e.g., contains an std::vector), the output is unreadable junk. Setting breakpoints on template functions is painful, even with autocompletion. Etc.
Which is nice (I do the same), however there are limitations in the editor with regards to some C++11 and C++14 constructs (but QtCreator which was my choice until now due to its abilities vs license has the same limitations in this area) that your compiler choice might support. Do you use any form of plugins to make VS play nice with clang/mingw and cmake?
Qt Creator is more responsive, leaves more screen space for the code and looks better (at least to me). It plays nice with the command line, so you can use the normal tools on build servers, test machines or run your own scripts. Eclipse has better integration into a kinds of bug trackers, etc. Ubuntu ships with some rather substandard plugins not in the default package, so avoid the Ubuntu package (or disable those plugins). Disclaimer: I work on Qt Creator, so I am probably a but biased:-)
I find qtcreator slows me down less often. Eclipse gui is a lot more customisable. Both support multiple windows for lots of monitors which is important for me. qtcreator works seamlessly with cmake, whereas I could not seem to get it to work well with Eclipse.
Why not KDevelop? Last time I checked, it was quite powerful C++ IDE for Linux.
Well, that's your opinion, but I really like KDevelop, although at the moment I'm using vim with a bunch of plugins.
&gt; leaves more screen space for the code Except when debugging. Which is actually one of my main complains about Qt Creator. It would be great to be able to move some of the debug windows to a second screen. 
Ive been using qtcreator for the last two months and its been incredible, specially the seamless cmake integration. I didnt know you could add and remove plugins, Ima take alook at it. Thanks for your work.
+1 to KDevelop. This is a good application--especially with the gdb integration.
What can do Eclipse which Qt Creator cannot do? I only used the former up until now, I am interested in the features of Eclipse
I did think this, but I'd like some compression. Possibly encryption options too. 
I solved this with NSIS some time ago: http://fd-imaging.com/self-extracting-lzma-compressed-binary-with-nsis/ It should be possible to add this as post build step.
Good idea. Go for it.
This way you can do compression, you'll just have to think of something that reduces the length of the bytearray/base64 string without losing information. You'll probably have to implement it yourself but I can't think of a reason why compression wouldn't be possible. Edit: the same probably holds for encryption 
You answered it perfectly thanks! I had not thought about `yield` not "traversing" layers but indeed it makes sense for a coroutine to be able to call a coroutine.
You should probably also try [JetBrains CLion](https://www.jetbrains.com/clion/) it supports CMake and I use it for my Qt projects. it offers already in early stage many features that QtCreator does not.
You can do this. Right click ⟶ [ ] Locked. ([docs](http://doc.qt.digia.com/qtcreator-2.3/creator-debug-mode.html)) edit while writing: at least you could. I can't do this anymore on my Qt Creator 3.2 :(
&gt; frame.__init &gt; char * _GET (char *param) These identifiers are ... oh fuck it ... I don't understand why people find these sooooo appealing to (mis)use.
what do you mean by this ?
read the source code for Csound, SuperCollider, and PD would be a good start. 
which features does it have that QtCreator doesn't? I can think of a ton of features that QtCreator has that it doesn't, though. also, not open source. not sure if it matters, but both the IDEs op mentioned are, so. 
I always have the idea that I am using intellisense wrong. It is so incredibly slow compared to Qt Creator when it comes to navigating code. Sure, Qt Creator is not always complete, especially in heavily templated code. But in most circumstances it blows intellisense out of the water. 
gdb latest versions include python support and you can get a script that hooks up on `print` commands to customize the display of some types (which you have to identify). Of course, it comes pre-bundled in Visual Studio...
Love Qt Creator for my multiplatform needs! I have a few gripes with the UIs look but its highly functional which is what matters. I've used eclipse many times over the years but anyways found a reason to be angry at it.
It is a rather slow IDE when used for large projects. Also, fails to do any auto-complete stuff when encounters template magic.
Eclipse is more mature (so, is more stable and has much more config options), and will give you much better integration with build systems. You are not missing anything, QtCreator is solid and handles large projects like a champ.
From the subreddit description: *For C++ questions, answers, help and advice see r/cpp_questions or StackOverflow.*
We consider having *less* options than eclipse a feature of Qatar Creator:-) There is no one tool to fit everybody, give both a try and pick your favorite. And take the time to read the manuals, they do explain many things that you will need to stumble over otherwise.
Oh, yes, templates are still a problem for Creator. It has a clang-based parser plugin which fixes that, but it is so much slower than Creator's custom parser (mostly since clang does handle templates and some less obvious other things which the custom parser does not) that it is not possible to switch to that yet.
&gt; It is not even beta now, so not recommended for use. It's EAP (Early Access Program), in Jetbrains terms this is like an RC release and offers more feature than Beta release. Like I mentioned, so far it works great for my specific needs, that's some basic Qt5 desktop application development. 
having used Eclipse, "stable" is not the first word that comes to mind... it spews uncaught exceptions and doesn't seem to have received much polish at all. 
Combined price is $54.99 at http://shop.oreilly.com/product/0636920033707.do.
Classical example from Qt: http://blog.debao.me/2013/08/how-to-use-qthread-in-the-right-way-part-1/ http://blog.debao.me/2013/08/how-to-use-qthread-in-the-right-way-part-2/ Also the links from references at the bottom of this articles.
This is overkill. Just because you can do something in a new way, does not automatically make it better. E.g., if you just have 5 million records of a fixed type struct, you are better off just having a simple C struct and casting to it. The problem with these types of solutions is that they are over engineered, and when they break down, no one wants to try to look through the technical wizardry, and the original developer ends up being the only one who ends up maintaining the code. Also see: http://www.reddit.com/r/programming/comments/20ltfi/the_evolution_of_a_software_engineer/
Fine whatever, I was just sharing some information.
You can always use plugins like Visual Assist which are arguably at least as good as what Qt Creator provides but then you've already spent money on VS and then you have to pay out even more for this plugin. You're looking at paying out thousands of dollars to just get what Qt Creator already gives you, for free.
Thanks for the tip, but for me, it's the opposite :P As you can see I didn't find this intuitive. And it's slower.
With Creator all those navigation features are Ctrl-K. That opens the locator where you can search for everything. Just type to find any file in your projects, Prefix classes with "c ", functions with "m ", symbols in the current file with ". ", etc. You can do way more in the locator (search the help, search the web, even run some git commands). PS: Note the space in all those prefixes.
I find a bit disappointing links to pages that announce that X has been released and that do not explain what X is. I even loaded the homepage but there was no description of what dlib is and why someone should be interested in it. 
Because everyone has one, students and ... alumni. 
I cant understand any of this though I program in C++ professionally... anybody has some nice tutorials that explain syntax used here? 
well I agree, but good luck with VS if you need full ISO conformance in this millennium :P IDK if they limit clang to the pathetic msvc feature set, my guess is yes since all that cross platform stuff would not work nicely, not to mention intellisense would need to be forked to support 2 diff compilers
For those not wanting to dig around, from the [SF page](http://sourceforge.net/projects/dclib/): &gt;Dlib is a C++ toolkit containing machine learning algorithms and tools for creating complex software in C++ to solve real world problems.
Await is a very useful keyword, but syntactically very confusing. Syntactically the return types of the declaration and definition wont match any more. (int vs future&lt;int&gt;) I wonder how many static analysis tools this feature will break. And how hard this return type missmatch will be to teach to new programmers. 
Well, for that you'll have to visit dlib.net (and yes, they should have linked to that) *Dlib is a general purpose cross-platform C++ library designed using contract programming and modern C++ techniques. It is open source software and licensed under the Boost Software License. The introduction contains everything you need to know to get started using the library. However, if you have any questions, comments, or complaints feel free to email me or post in the sourceforge Forums.*
Well, with an issue database that supports attachments mylyn is pretty cool. Eclipse seems to support a workflow that I've not seen from any other IDE, tying what you see in the project, changesets, etc... all into the integrated task list that can be tied to a multitude of different issue databases.
What's to work with cmake? It opens CMakeLists.txt files just fine from what I can tell.
Perhaps [GtkDrawingArea](https://developer.gnome.org/gtk3/unstable/GtkDrawingArea.html) from GTK+ or Canvas from [Qt](http://qt-project.org/doc/qt-5/qml-qtquick-canvas.html) might be a good idea?
With how simple this request is, I'd lean towards SFML. SDL seems to have a slightly higher learning curve, if I remember correctly.
Cinder is the fashionable graphics library in C++ right now. Its main advantage is that its modern C++ as opposed to all those old C-style API's. http://libcinder.org/ Edit: I used SDL, Allegro, DirectDraw, Direct3D/OpenGL directly, imagemagick, etc. But would choose Cinder next time.
Sorry for reposting my old comment, but I feel it's necessary until the next stable version of SFML is released: SFML may be a bit easier to use than SDL2, but you're much more likely to stumble upon unexpected bugs with it. It still has a lot of rough edges, especially the stable 2.1 version (which is over a year old). Some that I've noticed when working with it: - [`PollEvent` function is really slow](http://en.sfml-dev.org/forums/index.php?topic=6079.0) because of slow joystick polling. I recompiled SFML from source just to disable this. I'm not sure if this has been fixed. - [You can't focus the window by clicking inside it](https://github.com/LaurentGomila/SFML/issues/437). Fixed in upstream. - [Alt-tabbing in fullscreen mode is buggy](https://github.com/LaurentGomila/SFML/issues/306). I think there was also something with window/fullscreen/borderless switching but I can't find that now.
SFML.
Static analysis tools had to learn to deal with lambdas and auto. In C++17 they will have to learn to deal with modules, concepts and await. Similar syntax was in C# since 2012 and seemed to be loved by developers. Google's DART adopted that syntax this year. This pattern has root in Haskell do-notation that was available since 1998. Generalized form of await in N4134 has this form: M&lt;T&gt; f() { auto x = await f1(); auto y = await f2(); return g(x,y); } Where f1: () -&gt; M'&lt;X&gt; f2: () -&gt; M''&lt;Y&gt; g: (X,Y) -&gt; T await: M*&lt;T&gt; -&gt; T return: T -&gt; M&lt;T&gt; In English, await and return simplify working on containers of values such as expected&lt;T&gt;, optional&lt;T&gt;, future&lt;T&gt; and others. await unwraps the value from the container and allows to operate on plain values. return puts it back into the container. Failure to unwrap from the container is directly propagated into the return value. Consider the following two functions (one async another is sync) future&lt;int&gt; tcp_reader(int total) { char buf[64 * 1024]; auto conn = await Tcp::Connect("127.0.0.1", 1337); for (;;) { auto bytesRead = await conn.read(buf, sizeof(buf)); total -= bytesRead; if (total &lt;= 0 || bytesRead == 0) return total; } } Now replace future&lt;T&gt; with expected&lt;T&gt; and call sync APIs. expected&lt;int&gt; tcp_reader(int total) { char buf[64 * 1024]; auto conn = await Tcp::Connect("127.0.0.1", 1337, block); for (;;) { auto bytesRead = await conn.read(buf, sizeof(buf), block); total -= bytesRead; if (total &lt;= 0 || bytesRead == 0) return total; } } Await allows to unify synchronous and asynchronous programming patterns and provide a lightweight error propagation mechanism (if desired) that does not have to rely on exceptions
C++ will already warn about C casts if you enable -Wall -Werror
I guess this is because it's less mature and less actively maintained. I wouldn't say it's a reason not to choose SFML but one should just keep these things in mind.
I'd vote for SFML as well, just use the [latest source/master branch from GitHub](https://github.com/LaurentGomila/SFML/). Showing a window and drawing a rectangle and circle is rather trivial to do and easy to understand: #include &lt;SFML/Graphics.hpp&gt; int main(int argc, char **argv) { sf::RenderWindow window(sf::VideoMode(640, 480), "Simple Shapes"); sf::RectangleShape rectangle(sf::Vector2f(300, 200)); rectangle.setFillColor(sf::Color::Red); rectangle.setPosition(50, 50); sf::CircleShape circle(100); circle.setFillColor(sf::Color::Green); circle.setPosition(300, 200); while (window.isOpen()) { sf::Event event; while (window.pollEvent(event)) { switch (event.type) { case sf::Event::Closed: window.close(); break; } } window.clear(); window.draw(rectangle); window.draw(circle); window.display(); } return 0; } [Here's the result on my Windows 8.1 Desktop](http://i.imgur.com/9uJ2ldP.png) (although it will compile for MacOS X, Unixes, Android, and iOS as well).
For getting started drawing simple 2d objects I would strongly recommend ImageMagick++. Here is a pdf link to some great documentation. http://www.imagemagick.org/Magick++/tutorial/Magick++_tutorial.pdf The part you are most interested in is section 4 "Drawable Objects".
Do you know if they plan on doing a Linux release?
You could take a look at cimg. http://cimg.sourceforge.net/reference/group__cimg__tutorial.html
Neither Clang nor GCC do that. If you pass `-Wold-style-cast` they will warn in some cases, but sadly not all: `std::size_t("foo")` is a C-style-cast too, but compiles clean.
Edit: AntiProtonBoy corrected me, sorry about that.
but that dark ages book, right? I mean pre C++11/14? more specifically no variadic templates... I know to read normal TMP code, and even some basic SFINAE...(or how i call it :compile time if :) )
+1, very nice template library, been using it in small projects for years
Yeah, that's true. I don't know a good reference for variadic templates.
It doesn't exist.
I suppose. I was thinking -Werror=old-style-cast.
You should remember that if it boggles your mind, then you don't understand it. And if you don't understand it, then the problem is you (and your understanding of the world).
debugger?
**bgfx**: https://github.com/bkaradzic/bgfx#what-is-it Not sure what exactly you need, but there are bunch of examples and you could pick one and modify it to make what you need. For example this one could be what you need: https://github.com/bkaradzic/bgfx#23-vectordisplay
cairomm already provides a C++ api. No need to use sketchy proposal stuff. http://cairographics.org/cairomm/
I see the error of my ways.
Is there any information on how this is implemented? The reason I ask if that I have no mental model for how this works so I can't judge how efficient it is, or more accurately what the cost of using this feature is. Does it require run time memory allocation? Or is it syntactic sugar over a simple bit of efficient code?
SFML code is beautiful. And in c++... EDIT: and its documentation is top notch. Actually, after having read the tutorials, documentation and seen the examples, I think SFML wins the prize for the most nicely coded library ever. 
Also showing your own buffers is pretty easy: std::vector&lt;Uint8&gt; myPixels(640*480*4); std::fill(myPixels.begin(), myPixels.end(), 255); // Total white sf::Texture texture; texture.create(640, 480); texture.update(&amp;myPixels[0]); sf::Sprite sprite; sprite.setTexture(texture); someRenderTarget.draw(sprite);
Me too. :)
Thank you! Perhaps one of the best replies and suggestions I've received re this book and audio programming. Any suggestions on books, tutorials, articles, exercises to learn the basics of DSP and general signal processing in a way that I can understand how to relate my programs to it?
Thanks! Will look into those, and definitely think I'll be picking up the book soon :) and the DVD as well now.
Thanks! Will look into Juce and your synthesizer
thanks! :) Definitely think the book will be a good investment, and yours (and the replies of everyone else) have been invaluable to me on deciding to pick up this book, many thanks!
Proposal [N4134](http://open-std.org/JTC1/SC22/WG21/docs/papers/2014/n4134.pdf), page 18 shows one possible implementation. If no optimization are done, for every coroutine instantiation of a coroutine there will be a call to a library supplied allocator to get memory for coroutine frame. Page 9, "Allocation and parameter copy optimization" describes allowed optimization that can violate "as if" rule to allow allocation and parameter copy elision. Implementation we shipped in Preview, does not have any coroutine specific optimizations. We are working to add them for RTM, so that for most common scenarios there will be no allocations. 
http://www.dspguide.com http://diydsp.com/livesite/pages/home 
The bullet points under the Major Features heading is a fairly comprehensive summary, thought. Unless you're looking at something else? http://dlib.net/
How stable is this preview? Would it be advisable to use it in place of the new VS2013 Community Edition for non-critical projects?
The [download page](http://www.microsoft.com/en-us/download/details.aspx?id=44934) says: &gt; This release is not intended for use on production computers, or to create production code. But as far as stability goes, 2015 Preview contains a [whole bunch of STL bugfixes](http://blogs.msdn.com/b/vcblog/archive/2014/06/06/c-14-stl-features-fixes-and-breaking-changes-in-visual-studio-14-ctp1.aspx) (plus more since CTP1 that I haven't written up yet), plus compiler bugfixes. I haven't observed any significant regressions.
 If you are using Qt,then this[1] project may be useful An example of the library that runs a lengthy task without blocking the UI is here[2].Task::await() will suspend the processing of the current event at the point where it was called,and then will create a new thread and then run the passed in lambda in the new thread and then finally unsuspend the event when the lambda finishes. The above gives you synchronous looking code that does not block the UI. [1] https://github.com/mhogomchungu/tasks [2] https://github.com/mhogomchungu/zuluCrypt/blob/b4860690e1cf67168ba1ae4f17494c8bfd45ee71/zuluCrypt-gui/createkeyfile.cpp#L166
Still not C++11 compliant :p You guys got all those really smart people working on it. You gonna let gcc and clang beat you like that?
They've stated that, given their limited resources, they'd rather implement important c++14 features (and potentially all-but-confirmed c++17 features) before lesser-used c++11 features. That said, I think it's about damn time get compliant. ^You ^guys ^are ^awesome ^thanks ^for ^the ^hard ^work ^though
&gt; whole bunch of STL bugfixes Does that mean you fixed them or you caused them? ;-)
It's not really about money, it's about how many people are working on it. I'm fairly certain that they have less people working on it than gcc or clang, since those are open source projects that anyone (anyone that is verified/approved) can contribute to.
I see. But MS still have a lot if money and a lot of man power working on this. I just find it weird they arent aiming for a solid product. 
You're right! That's totally my fault; I went straight to the introduction without even seeing that features list. 
MS is also a big company and I'm sure, even if they are as savy as they let on, they've still got their fair share of PHBs.
Yes
VC++ is partly a means to an end. It's what they use to compile Windows itself. That puts strong constraints on their priorities, and also means nothing can ever ever break, which slows down what they can do.
both ? :-)
It's plenty stable for learning or tinkering. I'm currently evaluating some larger applications and so far so good. I would recommend sticking with the new 2013 CE though for "real" work.
&gt; That puts strong constraints on their priorities, and also means nothing can ever ever break, which slows down what they can do. Except that things do break with new releases, and break quite often. New bugs get introduced in previously functioning features, behavior and semantics of existing code changes, and a host of issues come up with every new release of MSVC. What's even worse is that strict bug fixes are often not back ported to previous versions of MSVC, meaning that you often have to trade one set of bugs for another set of bugs.
Is it possible to create a circle that isn't so pixelated?
Still no SFINAE for expressions.
I picked up the Will Pirkle book and it seems to be a pretty good resource. I've skimmed through the Audio Programming Book and found that it's mostly C based, which is fine, but C++ is more my style. Some other things that haven't been mentioned yet: https://audioprograming.wordpress.com/ (this blog hasn't been updated much recently, but there's some interesting stuff if you're doing mobile). http://chuck.cs.princeton.edu/ http://wavepot.com/ (live in-browser audio programming, with cool examples. not c++ though, it uses javascript) You can also mess around with some libraries/tools out there, like portaudio, SoX, STK, etc. As has been mentioned, I'd probably recommend looking into JUCE. I haven't used it yet myself, but it seems like a pretty sweet framework for audio coding.
The compiler team is working on improving the codebase to the point where it's capable of Expression SFINAE, but it's not there yet. Expression SFINAE is basically asking a compiler to be able to speculatively compile and cleanly backtrack out of arbitrarily erroneous expressions, which C1XX wasn't ever meant to do. (This was considered impossibly hard back in the 90s, which is why C++98/03 had limited SFINAE). The compiler team is very much aware that this is an important feature, partially because I keep asking for it. (Two STL features, result_of SFINAE and std::function ctor SFINAE, are blocked on it.)
"Emacs"
That is why they have the best C++11/14 support among commercial C++ compilers. Other commercial vendors are still worse.
&gt; lesser used c++11 features You clearly haven't used constexpr before. Partial support in 2015, it's a joke.
Sure, it has issues. But I was talking about the beauty of its api: small, elegant, beautiful.
It is less a matter of money or manpower than priorities. The VC compiler exists to support the platform - Microsoft makes its money on licenses of Office and Windows, and apps and market share drive those businesses. Visual Studio (aside from the ALM stuff) will never be a real profit center. Microsoft spends money on developer tools primarily to encourage developers to make apps for their platform. Part of that, it is true, is in having a compiler that is conformant enough to compile and port code from other platforms/compilers, but remember that one of windows' biggest competitors is older versions of windows. So compliance with and ability to build those applications (not to mention office and windows itself) is a very important goal of that compiler. Sometimes that goal is directly at odds with the goal of standards conformance. And you can't just throw more developers at a codebase and expect to achieve additional results correlating with that extra spend. Implementing big features in a mature codebase is like playing jenga with oven mitts on. With twelve other guys trying to do the same thing. Adding extra guys doesn't necessarily help, regardless of how much money you have.
That's exactly the point. I suspect that until recently MS actually didn't care much about the standard, but just wanted to support their internal development and products. This is however not acceptable any more, and is also the reason why it's so difficult for them to catch up now.
&gt; a lot of man power working on this I think that the Visual Studio team is mostly focused on C#, C++ doesn't get that much attention. 
Clang is backed by Apple. So I'm not sure.
Not even C++03 compliant actually
&gt; The compiler team is very much aware that this is an important feature, partially because I keep asking for it. Thats good. Plus, its a really nice feature to achieve concept traits in C++. &gt; result_of SFINAE You can detect function object callability in C++98, using a lot of [magic](http://www.boost.org/doc/libs/1_56_0/doc/html/proto/appendices.html#boost_proto.appendices.implementation.function_arity) from Eric Niebler. This works quite well on MSVC. I have initially used it to implement SFINAE-friendly result of, but then had to abandon it and switch to the result of protocol due to type deduction being broken on MSVC. Hopefully, switching to an AST will fix a lot of those problems. 
The integrated NanoVG along with bgfx's cross platform nature would be a decent quick starting point with room to grow into learning more.
&gt; Classical example from Qt: That's exactly the problem, although Qt is 'the best of a bad bunch' when it comes to UI programming, it's hardly what I'd call text book modern C++ that should be used for the purposes of teaching.
Isn't Intel's C++ compiler a bit ahead?
I would say that they've been serious about it since VS2010 or so (that release contained lambas, r-value refs, auto, and TR1 libs, I believe). Actually, even before then, the 7.1 release (Visual Studio.NET 2003) contained some key template parsing fixes. But VS2005 and VS2012 showed a company-specific focus with C++/CLI and C++CX respectively. In the end, the people holding the purse strings really set the priorities.
There's a reason why I keep listing Expression SFINAE as No - some cases might appear to work, but other cases are broken. For callable object callability, I know for a fact that it's broken - while reimplementing &lt;functional&gt;, I accidentally used Expression SFINAE despite attempting to avoid it, and it broke for PMDs. (I then reworked my overhaul to absolutely avoid any trace of Expression SFINAE.)
File a bug. Otherwise, it's less likely that we'll find and fix the exact problem you encountered.
&gt; There's a reason why I keep listing Expression SFINAE as No - some cases might appear to work, but other cases are broken. Eric's Niebler's technique for detecting function object callability is not SFINAE at all. That's why it works on MSVC(and even older compilers such as gcc 4.2). &gt; I know for a fact that it's broken - while reimplementing &lt;functional&gt;, I accidentally used Expression SFINAE despite attempting to avoid it, and it broke for PMDs. Are you suggesting that type deduction in result of is broken because you accidentally used Expression SFINAE? I actually tried several iterations of getting `result_of` to work and finally gave up and used manual type deduction using the result of protocol(ie using a nested `result` metafunction). I actually used a hybrid form of `result_of` so if `result` is not found it would try to deduce the type. However, on MSVC I never used `std::result_of`, I seemed to get better results implementing it myself(perhaps that was due to Expression SFINAE issues). You can see how I implemented it [here](https://github.com/pfultz2/Linq/blob/master/linq/extensions/detail/result_of.h). Now translating the Boost.PP to varidiac templates, the `auto_result_of` would look like this: template&lt;class F&gt; struct auto_result_of; template&lt;class X, class... Ts&gt; struct auto_result_of&lt;X(Ts...)&gt; { typedef decltype(std::declval&lt;X&gt;()(std::declval&lt;Ts&gt;()...) type; }; And this doesn't rely on Expression SFINAE, however, the type deduction still fails. And what I mean by type deduction fails, is that the compiler deduces the type as an int. Of course, I have not tried this on the latest MSVC preview.
I guess my point was that VC++ is not the product. Windows is the product. Office is the product. Internet Explorer is the product. VC++ exists to support other entities, and it's those that drive the priorities.
Congratulations to ROLI and Storer. With the acquisition, is there any chance of making the JUCE license more liberal (ie not GPL)
I have done that. https://connect.microsoft.com/VisualStudio/feedback/details/891744/variadic-templates-compiler-crash Apparently it cannot be reproduced. Relevant functions: http://pastebin.com/7Lbgezc4 Defined there: https://github.com/Ezodev/ECS/blob/master/src/core/componentContainer.h But it was some time ago so maybe I have changed something from that time. Sure, there are dependiences for this project, but exact place where crash occurs has not. Only dependience for this file is boost's lexical_cast(in logger), and this is not relevant.
bgfx is amazing!
I understand the sentiment; however, in my opinion, needless trailing return types muddy the code. It starts to look eerily like VB.NET, only worse because of noisier syntax. I only use trailing return types when I don't immediately remember or know the fully qualified type I am returning (template magic, or wrapping a vector in a collection class and exposing begin() and end() to use range-for... I don't remember iterator types and never will). Obviously trailing return types have their place, but I definitely don't think they should replace the traditional way for "simple" types. The traditional way (for "simple" types) is objectively easier to read at a glance, biases aside, because it contains fewer characters. Just my two cents.
I have spent maybe 600 hours in QtCreator. It's nifty, but it isn't great. I like what it stands for, but damn it can be a pita. Code completion doesn't always work for auto types (I understand why, but still frustrating). Code completion in general is spotty (sometimes it just quits working), which is the #1 reason I use an IDE. When I lose that, I'd rather be in a simple text editor. Crashes far more than is acceptable. Weird bugs can occur when debugging. Debugging is a tedious process. It can take 6+ seconds for a value tooltip to appear, even on a very power machine. Puts red squigglies under some c++11 metaprogramming code (last time I checked). Multiple project "solutions", or whatever they are called, are buggy to use. Unusable in my experience, for very simple test apps. Designer is quite limited (understandable, not a big deal) 
&gt; You clearly haven't used constexpr before Doesn't that support his point?
Huh. I have not had this experience at all. It might be that I don't know a good IDE, but it worked great when I used it for my own C++ applications.
&gt; Are you suggesting that type deduction in result of is broken because you accidentally used Expression SFINAE? No, I was referring to my &lt;functional&gt; overhaul-in-progress, which hasn't even been checked into 2015 yet. My new result_of conforms to C++11 perfectly, always getting the right answer via decltype. (It's actually beyond perfect; I discovered compiler bugs with decltype, PMDs, and xvalues, which I have a library workaround for; when the compiler bugs are fixed I'll be able to remove the workaround. I checked, and even clang got this wrong.) The only thing that my new result_of won't do is C++14's SFINAE behavior.
Please report your clang bug, http://llvm.org/bugs/enter_bug.cgi?product=clang Bugs can't be fixed if they aren't reported :)
C++ is getting weird
Perhaps overload `&gt;&gt;` for when the result is to be ignored? Though this could be done with a `then` that uses SFINAE to call with the appropriate number of arguments. auto then(F f) -&gt; decltype(f(std::declval&lt;???&gt;())) { ... } auto then(F f) -&gt; decltype(f()) { ... } I'm not sure what should go in place of the `???`, though having it only enable when `decltype(f())` is not well-formed may be sufficient.
Problems starts when someone try in your code base reverse for loop or compare incoming buffer minus some data if (curSize &gt;= bufSize - sizeof(HEADER)) error();
Not sure if this is the right place... or if I should go over to /r/learnprogramming. Can someone give me a breif description of what continuation passing is and what its used for? Maybe a short example?
When it says that r-value reference support is _partial_ they mean it's mostly feature complete, but with just the latest wrinkle missing, like what 3.0 fixes, here: http://msdn.microsoft.com/en-us/library/hh567368.aspx - right? Anyone know how usable the VS 2013 version of r-value references is? How compatible with other compilers? edit: there's a section in my link that explains what 'v3.0' adds: automatically adding them in certain cases. 
EDIT: Okay, so I failed at "brief". But it hopefully isn't too hard to understand? A continuation is a basically the "state" of the program. A language with first-class continuations (which as far as I know c++ is not) can use it to do some really wonky things, and basically look like a time lord. This is probably best described by this [wikipedia summary](http://en.wikipedia.org/wiki/Continuation): &gt; Say you're in the kitchen in front of the refrigerator, thinking about a sandwich. You take a continuation right there and stick it in your pocket. Then you get some turkey and bread out of the refrigerator and make yourself a sandwich, which is now sitting on the counter. You invoke the continuation in your pocket, and you find yourself standing in front of the refrigerator again, thinking about a sandwich. But fortunately, there's a sandwich on the counter, and all the materials used to make it are gone. So you eat it. :-) In c++, we can't just warp around like that, however we can use lambdas to approximate continuations to preserve tail-recursion, so I'm going to explain that first. Every time you call a function, you have to allocate some stack space for the function's parameters, return value, and return address (where we go when the function is done). If you use recursion (calling a function from itself), each call will add more items to the stack. This can cause a lot of memory usage and possibly stack-blowout when you have a lot of recursive calls. Tail recursion is a way of optimizing away that memory usage, and can only be done when the recursive call is the very last thing done before returning. Lets take the following code: bool is_in_list(Element e, List l) { if(l.empty()) return false; elseif(l.head() == e) return true; else return is_in_list(e, l.tail()); } Note that after the recursive call is over, we simply return. And return, and return, and return. So, instead of allocating new stack space for the return value, parameters, and return location, we can simply reuse the space for the return value, write over the old parameters with new parameters, and keep the same return location, so that the final recursive call returns directly to the caller. In this way we can optimize away the memory space. This ONLY works when the recursive call is the last thing done. For example, take this factorial code. unsigned factorial(unsigned n) { if(n == 1 || n == 0) return 1; else return n * factorial(n-1); } Note that, after the recursive call to `factorial` we then have to multiply it with `n`. So, we can't overwrite the parameters, or return directly to the top level. Continuation passing style is a hack to get around all this. It pretty much destroys all code readability, but you sometimes need that performant code in some places and sacrifices must be made. What we want to do is basically pocket our current state of execution before the recursive call, and let the recursive call activate it. We approximate this by grabbing everything that's done when the continuation is activated, and stuff it in a lambda, which is then passed into the function: int factorial_helper(int n, Continuation k) { if(n == 0 || n == 1) return k(1); else return factorial_helper(n-1, [n, k]( int factorial_result ) -&gt; int { return k(n * factorial_result); } ); } int factorial(int n) { return factorial_helper(n, [](int factorial_result) -&gt; int { return factorial_result; } ); } Boy that looks ugly, doesn't it? The important part though, is to notice that recursive call is the last thing done before the return statement, allowing us to do tail recursion. So what else is happening here? So someone calls `factorial` which is basically our clean interface to hide the messiness that is continuation passing. Since `factorial` just needs to return the result of `factorial_helper` we don't really have a state that we need to manage when the continuation is activated, so we just construct an identity function and move on with our lives. Now lets look at the recursive case of `factorial_helper`. After the factorial is done we want to multiply it by `n`. So we construct a function that multiplies our result by `n`. This function gets passed into the next recursive call. Eventually we hit the base case, which is a return value of 1. This is our sandwich. Now that we've built our sandwich we want to activate the continuation and go back in time to when we still wanted it. So instead of returning `1`, we return `k(1)`. Now we're inside one of those lambdas we passed into the function, we're back in front of the fridge, and our ~~sandwich~~ `factorial_result` is on the table. We can multiply it by `n`, and activate the next continuation, and continue upwards. While this is probably the easiest way to use continuations, they're really much more powerful. First class continuations allow you to implement loops in languages without loops, create loopless state machines that simply flick back and forth between states, or resumeable co-routines to allow asynchronous operation between multiple code paths on a single thread.
I'm split about this sort of thing. It makes perfect sense if you understand C++, and yet when I think about explaining it to friends who program in other languages, I realize that the necessity of such abstruse constructs is one of the downsides of C++11/14.
Would std::decay be preferred to std::ref when passing to threads?
That's awesome, thx man.
Consider what you're doing when you're implementing a generic pair type: You're not creating a type that holds two objects: In effect you're writing a program that knows how to _design_ such types. That design knowledge must get encoded in there somehow. You just have to compare that complexity to the trade offs made by other languages. - In C we can't represent the abstraction at all and instead just write each kind of pair manually, which produces efficient results. - In Java we can have the abstraction, but the pair types it produces won't be efficient. And finally it's important to note that writing this kind of C++ isn't required. It's available if and when you need it, but it's perfectly reasonable to write C++ without getting into this complexity. New C++ programmers can be productive writing C++ for years without learning this stuff. So I think C++ makes a fairly good compromise: simple, efficient, good abstractions; pick any two. Languages like C and Java, on the other hand, have already picked for you.
As explained in further detail [here](http://blog.biicode.com/biicode-going-open-source/), if we reach 10000 users we will open source biicode's client. Please give us a hand, we believe we are providing a useful tool for the C++ community. If you give us a hand in this mission you can win a cool Darth Vader++ t-shirt and stickers. It's easy just follow the three steps described in the section on the right. Thanks in advance. Any feedback on the tool is also very welcome.
Next time use: /r/cpp_questions You need to write something like: if ( 100 &gt;= x &amp;&amp; x &lt;= 0 )
Well ideally, you would have then return a special functor that performs the actual work, since this is what knows what type will be passed in to the callable `f`. What you can do is use some more template magic to see if `f` takes any parameters and handle that case (there would be a lot of wonky workarounds to get this to work, but its doable in Core's current state).
My feedback would be that your arbitrary user requirement to open the source doesn't make sense, especially on a free piece of software. Either you're looking to monetize it in the future or have something in the source you don't want your users to see. And if neither of those are the case then why not just release the source? Personally, I'll just wait until you have 10,000 users.
That doesn't really make sense either... replace your operator with || 
&gt; if (x &gt;=100 &amp;&amp; x &lt;= 0) Error: no operator "&gt;=" matches these operands operand types are: std::string &lt;= int Is the error I'm getting from c++, remember this is in a class. 
Well of course, you can't compare a string to an int, that makes no sense. Why accept a string if you want to assign it to an int? This has nothing to do with being in a class.
According to the blog post it's a stipulation from their investors.
if it doesn't need to be displayed you can use agglite. It's good for software rendering into a buffer. I would probably mess with SDL2 myself since it's the most platform agnostic of the rendering libraries. Handhelds, embeddeds, etc...
In Java a generic pair will store pointers to objects allocated elsewhere instead of the objects themselves.
Thank you.
What's frustrating is that neither answer actually says what it does, they just provide examples of use.
I finally did some tests and wrote the conclusions in this [article](http://jmabille.github.io/blog/2014/11/20/performance-considerations-about-simd-wrappers/). Any feedback is welcome.
And this is why Java needs Value Types. Got I hope they Make it into JDKX
The "possible implementation" given here is a pretty good description of what `std::decay&lt;T&gt;` actually does, once you parse all those nested `std::conditionals`: http://en.cppreference.com/w/cpp/types/decay Basically, it's this, in pseudo-code: 1. Let `U = std::remove_reference&lt;T&gt;::type` 2. Choose one of the following: * If U is an array, then `std::decay&lt;T&gt; = std::remove_extent&lt;U&gt;::type*` * If U is a function, then `std::decay&lt;T&gt; = std::add_pointer&lt;U&gt;::type` * Otherwise, `std::decay&lt;T&gt; = std::remove_cv&lt;U&gt;::type` At a high level, `std::decay&lt;T&gt;` does the same implicit type conversions that are applied when you pass something to a function by value, and you can see that in the rules above: references and const/volatile qualifiers are removed, and arrays and functions become pointers.
I'm more curious about why the answers refer to rvalue references as references. Is normal? I always call T&amp;&amp; an rvalue reference, and T&amp; a reference. Am I mistaken?
They're both references. T&amp; is an lvalue reference, and T&amp;&amp; is an rvalue reference.
Yep. N4140 8.3.2 [dcl.ref]/2: "A reference type that is declared using `&amp;` is called an *lvalue reference*, and a reference type that is declared using `&amp;&amp;` is called an *rvalue reference*. Lvalue references and rvalue references are distinct types. Except where explicitly noted, they are semantically equivalent and commonly referred to as references."
And in why is that less efficient?
One more indirection before accessing the object, the pointer isn't free.
Look at it this way, if you need it it's there, if you don't then no need to worry about it. Any language has that sort of feature.
I don't think this can catch on, and here is why I think that. No support for boost because it's too hard? Really? How was that not your first target/example? GTest (your actual first example) is so trivial, particularly for a CMake-based system. From your forums: &gt; diego23 Aug &gt;Wow! &gt; Thanks for such comprenhensive feedback. &gt;Issue 1: &gt;You are totally right. Dealing with a preprocessor is really, really difficult I really hope you are joking/humoring this person here. Your system attempts to be in control of everything, and is also using CMake! You can know the relevant command line flags that the compiler will see for any given object. You can also have a conversation with the preprocessor directly if you'd like (at least with gcc and clang, I haven't played the Windows game for a few years, but I'd expect similar functionality to exist there too). I've seen a few posts here lately about "package/dependency" managers for C++. Most of the time, I don't have a problem with the current state of affairs. If I want to use some software product (and perhaps apply a few patches), such is relatively straightforward to do with existing build tools. One notable thing that isn't required is conformance to some external spec (how many config files do you guys use?). All of that said, good luck amigos :)
In addition to the indirection overhead, they are not contiguous in memory. The objects can be splayed out across the heap randomly. Data locality is very important for high performance systems.
Whether it's efficient or not really depends on the specific use, but commonly we don't want the extra pointer indirection (due to poor memory locality, mostly) or memory footprint.
Not really. I don't know any other language that gets quite as obscure as C++ with the type system hackery. Most languages either follow the "don't care if it's slow" approach or don't bother with an elaborate type system in the first place. C++ is pretty much the only language I know that wants to give you a high level type system and still give you control over how things are packed into memory. Another big issue is that all the type magic in C++ happens at compile time. If I encounter something weird in Python or Lisp, I can just drop to the REPL and inspect stuff, print it and figure out what is going on. In C++ I get an unreadable compiler error at best and at worst things will just go silently wrong without me even noticing. Something like a `cdecl` on steroids for the C++ type system would be nice to have.
Visual Studio one of several Microsoft billion dollar products http://www.zdnet.com/microsofts-16-billion-dollar-businesses-an-updated-list-7000019346/
I know. I'm just expressing annoyance at SO culture. First, the answer is blatantly easy to find if you use google. Unfortunately, SO noise now takes that over a bit (google it, all SO links to closed questions--ARG!!!) but this one still turns up a reputable reference quite readily. Second, nobody answered the question asked and yet the accepted "answer" has 40 votes. A copy-pasted example and link to the pre-standard submission text.... :\ Like I said, frustrating.
&gt; [Please give us a hand, we believe we are providing a useful tool for the C++ community.](http://img2.wikia.nocookie.net/__cb20130805190214/animaljam/images/4/46/Clapping.gif) 
Parsing of the CMake project ? (Actually I think that in Qt Creator it is done by calling CMake with the code::blocks / ninja generator, and parsing the later)
The type system protects you from errors that have to be debugged at runtime. ~~I'm not sure what REPL is~~You can of course do runtime debugging, including evaluating expressions, in C++. MSVC and other commercial IDEs are very good for this ; IDK about the status of free IDEs though. (maybe someone who uses gdb as their main debugger can chip in here) Of course if you bypass the type system and/or ignore the rules of the language then you're in quicksand. You're right that compiler error messages could be better. Join up with the g++ development team to help improve that &lt;3 
This is awesome. Just out of curiosity, would anyone know where I learn/practice C++? 
Making things work exactly in the same way in five different platforms is not that trivial. Take Boost as an example. We offer a dependency manager for C and C++, but the boost libraries are a monster with lots of inter dependencies (even dependency loops) very hard to deal with. The fact is that is such difficult that even the boost team developed a dependency management tool only to handle it. And thats exactly the tool we were using when working on Boost. Even with boost bcp, the libraries are so hard to deploy: There are hundreds of dependencies, boost is not cmake-ready (There are a couple of projects trying to so so, like https://github.com/boost-cmake/boost-cmake), and playing with it was taking a large amount of our time. So we decided to stop working with boost until we have a better tool to deal with huge libraries. That tool is the hooks system we are working on. The hook installs boost, Qt, OpenCV, whatever in your system and then finds it via cmake's find_package(), FindBoost(), etc. As I said, is not that easy. Every block we deploy, from the "simple" gtest hello world, the so complex wxWidgets, to the very system dependent graphics libraries such as glfw or SFML have to work in a fully portable and multi-platform way. And thats what takes time: Toggling things to make it work on Windows, Mac, Ubuntu, Archlinux, Fedora, Raspberry Pi, etc in exactly the same way. We hope biicode will help the C++ community to deal with dependencies. In my case, I really like the workflow it provides: Just include what you need, do bii cpp:configure, and you have a working Visual Studio solution thanks to biicode and cmake. That's far better than downloading all the libraries and setting up the project. You work on linux? Don't worry. Change the cmake generator and the thing still works perfectly, without touching any source line of your codebase.
aa a f
suppose that I want to do something like this: TYPE getClassFromNumber(int class_number) { switch(class_number) { case 0: return Class1; break; case 1: return Class2; break; default: return null; } } int main() { Class1* c1; c1=new getClassFromNumber(0); return 0; } I read that the *new* operator uses *size_t* but I can't do something like this: Class1* c1; size_t s; s=sizeof(Class1); c1=new s;
I thought that my question was obvious enough... Didn't know about the sub, thank you!
If "class_number" is known at compile time, this is easy: template&lt; int class_number &gt; struct getClassFromNumber; template&lt;&gt; struct getClassFromNumber&lt;0&gt; { typedef Class1 type; } template&lt;&gt; struct getClassFromNumber&lt;1&gt; { typedef Class2 type; } template&lt; int class_number &gt; //c++11 only using getClassFromNumber_t = typename getClassFromNumber&lt;class_number&gt;::type int main() { typename getClassFromNumber&lt;0&gt;::type * c1 = new typename getClassFromNumber&lt;0&gt;::type(); auto c2 = new getClassFromNumber_t&lt;0&gt;{}; //c++11 only. } If you don't know class_number at compile-time, I question how you know what type in main you're going to declare to receive it. Type information in c++ MUST be known at compile-time.
&gt;using namespace std; My eyes, they burn.
It would be fun to make one of these; for now I guess could use [ideone api](http://ideone.com/sphere-engine) or similar. Here is some quick PHP that does it (I know this is not C++) for if you are interested! This works but doesn't handle multiple users, really long compiles, and so forth: $myFile = "code.cpp"; $fh = fopen($myFile, 'w') or die("Can't open file"); fwrite($fh, $codetext); fclose($fh); exec("g++ code.cpp &gt;&amp; code_compileresults.txt", $output, $return_var); $compileFile = "code_compileresults.txt"; $compilefh = fopen($compileFile, 'r') or die("Can't open file"); $compiledata = fread($compilefh, filesize($compileFile));
Yes, you need to turn up the multisampling in your OpenGL context. sf::ContextSettings settings; settings.depthBits = 24; settings.stencilBits = 8; settings.antialiasingLevel = 4; settings.majorVersion = 3; settings.minorVersion = 0; sf::Window window(sf::VideoMode(800, 600), "OpenGL", sf::Style::Default, settings);` (http://sfml-dev.org/tutorials/2.0/window-opengl.php)
Can we agree on that the C++ compiler is the worst part of Visual Studio? I love the IDE! But wow, I have really struggled with the compiler the last few years in regards to their C++11 support when working with people who use clang or gcc. Also sometimes it just lets me omit includes so when my group members try to compile with clang I get stupid looks :(
Wow, thanks for the detailed answer. I just wanted to know if it was possible. Unfortunately I have no idea what any of this means. I just started with c++ and we've only gone over writing simple win32 console programs so I know stuff like file streams, functions, arrays, for &amp; while loops, switch-case etc. It looks like I have a lot more to learn!
Visual Studio 2015 will officially support using Clang as a compiler.
You just have to know a little bit about graphics and how they work on the hardware. I recommend (http://www.arcsynthesis.org/gltut/) if your interested!
&gt; Also sometimes it just lets me omit includes The compiler automatically defines a very small number of types which it technically shouldn't be doing, like `size_t`. In practice, this isn't an issue because everyone and their pet cat drags in `size_t`. What you're probably seeing is CRT/STL headers including each other in different patterns for VC and libstdc++/libc++, but that's not a bug. Standard Library headers are permitted to include each other in unspecified ways (a few inclusions are mandatory, e.g. &lt;iostream&gt; must include &lt;ostream&gt; in C++11).
Using-directives are fine when used in small test cases by people who know what they're doing. I write single-page test programs all day, and I routinely use using-directives. That doesn't mean that I go crazy and put them in headers where they don't belong.
thanks you. I will take a look. I appreciate it. 
Thanks! Really appreciate the lit. I've been tryingto wrap my head around i guess more of syntax kind of thing and when it'd be better to use templates than actually declared functions. 
&gt; What you're probably seeing is CRT/STL headers including each other in different patterns for VC and libstdc++/libc++, but that's not a bug. Standard Library headers are permitted to include each other in unspecified ways (a few inclusions are mandatory, e.g. &lt;iostream&gt; must include &lt;ostream&gt; in C++11). Aha, I see.Maybe I have been too fast to point fingers. Thanks for clarifying. 
The compiler takes slightly longer, but that's only while you're compiling. At run time, it's as if you'd written all those nearly-identical functions yourself. You can almost think of the template arguments as part of the name of the function you're calling. With generics in some other languages, as I said, although the basic purpose is the same the implementation (at least in theory) is different. In that case you actually do pass types into the function at run-time - or more precisely you pass pointers to all the operations you need for that type. That has a run-time overhead which templates don't have. It's really a trade-off. Although calling a template function is the same as calling one of the non-template special cases, it also means you need all those special case functions. The compiler generates them all for you but they're still there in the final executable code. This can (mostly in theory) lead to bloat. It can also cause code to run slower precisely because there's more code (memory bandwidth and cache friendliness). However, those implementations are mostly theoretical. A C++ compiler can generate fewer implementations of template functions than it appears to need. Languages that support generics can "inline" some or all of the type-specific operations and effectively end up with a template anyway. For both approaches, the whole function might be inlined into every call site - implementing the function call by cutting and pasting the function into the call site, basically. From one POV templates are more bloat-prone than generics, and inline is more bloat-prone than either without it. The problem is the same both ways - code is in principle copied rather than having one copy that gets called. That said, a copy can be specialized for the particular case - irrelevant complications can be eliminated etc. This is part of why compilers inline function calls - partly to eliminate call overheads, partly to specialize the code. And sometimes the body of the function is smaller than code to call that function anyway. [**EDIT** The thing is that it turns out, in practice, that bloat is rarely if ever a problem, and that the benefits from specializing the implementation for particular cases often lead to significant performance improvements - certainly for small simple functions.] Some quite complex things happen in real world compilers, but the early take-away lesson is really that you shouldn't worry about it. For simple use you probably won't notice the difference. The theoretical implementation is still relevant, but mostly as you get into template metaprogramming, where the theoretical implementation defines some of the limitations on what you can do. 
The advantages to templates are not speed or memory, in either case the code will compile down to essentially the same assembly language. 
Another [good book](http://www.amazon.com/C-Templates-The-Complete-Guide/dp/0201734842), starts a little bit easier on the newbie than Alexandrescu. Between the two of them you should be a template wizard in no time... :)
That's an improvement. I recently switched to Clang for projects I do outside of work and one beyond better standards support, the compiler errors are infinitely better. It makes writing and using templates actually enjoyable.
I highly recommend this book, written by some C++ gurus and is clear, concise, and a joy to read.
&gt; I'm not sure what REPL is http://en.wikipedia.org/wiki/REPL
This was a talk as CppCon and there is also a video available at https://www.youtube.com/watch?v=PVYdHDm0q6Y I'm considering implementing this pattern in one of my projects and was wondering is other people have any experience with it and perhaps know of any pitfalls.
Yeah. No Windows support despite the great work of the clang on windows team. And one wonders why Microsoft just doesn't supports clang as a second compiler option. Since they seem to have the clang message/error API integrated for the support of Android development. Maybe IP/Contracts with Intel or other compiler studios prevent them from doing so? (I'm just writing about c++ here... Where the Microsoft Compiler is always lagging behind in comparison to gcc &amp; clang. And c++ support is being added through clang for android development)
&gt;Rewriting the STL to avoid new and delete is a challenge. This premise sounds plain wrong to me - why would anyone want to avoid new/delete, especially in embedded world? Where else would you plug in vital diagnostic tools in standalone app, close to bare metal? &gt;This means we must change the way we think about the containers. Why? [Placement 'new'](http://en.wikipedia.org/wiki/Placement_syntax) is available for quite a while. And when it is not (~~then think about upgrading your C++ compiler/toolset~~), you could overload new/delete. Allocators (and deallocators where necessary) could be specified for most (all?) of STL container classes. Plugging placement new into STL containers does the trick for me. 
I'd think the biggest pitfall would be having to write all of your interfaces twice.
The other comments are good, but I thought I'd just give my own super quick explanation of templates. First off, you have [class templates](http://en.cppreference.com/w/cpp/language/class_template) and [function templates](http://en.cppreference.com/w/cpp/language/function_template). There is no real difference between them, just that one applies to classes, and one to functions. I'll just give an overview of function templates, and everything I write will apply/have an analogue for class templates so I won't write it twice. A function lets users pass in variables of a set data type. A function void Foo(uint32_t u) {} lets a user pass in any valid uint32_t type. This is great...but what if you want to let the user pass in the type itself? This is the idea for generic programming, or as it is known in C++, (meta) template programming. In C++, a template is literally a template for the compiler to produce some code with a given type. For example, if we want our Foo method to accept any type, we can write template &lt;typename T&gt; void Foo(T t) {} Now a user can write: Foo&lt;int&gt;(12); Foo&lt;std::string&gt;("hello"); Foo&lt;MyOwnClass&gt;(mClass); To give the simplest example of a use case for this, consider a function to print things to stdout. A user wants to print numbers, strings, booleans, and so on. How can we do this? template &lt;typename T&gt; void Print(T toPrint) { std::cout &lt;&lt; toPrint &lt;&lt; std::endl; } And there we have it, the simplest of templated print functions. Of course this is very limited in use since you can only pass a single value to print, but it is just to demonstrate why allowing the user to pass their own type in is useful. Another useful thing is that the compiler can do [template argument deduction](http://en.cppreference.com/w/cpp/language/template_argument_deduction), which means that you don't have to explicitly tell it the type: While Print&lt;std::string&gt;("Hello World"); works, we can omit the type since the compiler can figure it out for us: Print("Hello World"); Print(3481); Print(true); For a quick example of class templates, the idea is exactly the same and I'll use the class as a wrapper for printing an object: template &lt;typename T&gt; class Printer { public: Printer(T t) : myObject(t) {} void Print() { std::cout &lt;&lt; myObject &lt;&lt; std::endl; } void SetString(std::string input) { myObject = input; } protected: T myObject; }; and then you can use it like Printer&lt;std::string&gt; stringPrinter("Hello World"); stringPrinter.Print(); stringPrinter.SetString("Goodbye"); stringPrinter.Print(); Which of course prints Hello World Goodbye Clearly the function template version of Print is much more concise than the class template version, but this is just a demonstration. I'll leave as an exercise for the reader to try and extend these to accept arbitrary numbers of arguments, do formatted strings, etc. There is a whole field for template metaprogramming and I could talk for hours, but this is a brief intro so I'll leave it there. Hope it helped!
Well, there's really a lot. Some of my blogs might even help if you're desperate: http://crazycpp.wordpress.com I think you might want to ask yourself first though what you intend to get out of it. *Why* do you want to learn template programming? In fact, now that I think of it...do you mean template metaprogramming or just general template use? I'm assuming the former but I was about to argue that for most of your software development needs in C++ you really only need the latter. Uses of the former are generally limited to basic list processing such as, "Take this list of types and build me a factory that can generate them based on their index in the list." There's the very occasional legitimate use for TMP. You can do a lot more though with templates in general that IMO you should be pretty good at first. It's a more useful skill. TMP is fun and fascinating but it really does tend to convolute things and often times unnecessarily.
Judging by you comments elsewhere, you are not ready for 'template **meta**programming'. You just need to practice templates first. 
Not bad. I am curious about other containers you use. Here are some comments I have: * Is placement new not available on your compilers? You're severly restricting yourself by not allowing non-default-constructable types in your vector. Also, RAII won't quite work properly with your vector because elements are not destructed when 'removed' from the container. (As others have mentioned, placement new has been around for a very long time. If it is available, you should use it.) * It seems you have a single compiler you want to use this on. There's no enabling of certain features (r-value references, move construction) based on preprocessor definitions. In my embedded container library, there's a lot of '#ifdef COMPILER\_SUPPORTS\_*feature*' blocks. It's ugly, but it allows proper use of the container for newer compilers. * You've gone through the trouble of implementing C++11 functions such as cbegin() and cend(), but erase() is not C++11-like. It takes non-const iterators as arguments. But the standard containers' erase() function takes const iterators. * I don't understand the non-copyable feature. Copying doesn't require new/delete. I understand that copying large vectors may be inefficient, but copying small vectors may be appropriate. * ADDED WITH AN EDIT: I don't see any testing in the repo. (I assume you do have some at your company, they just didn't make it into the repo.) I'd be nice to have unit tests that others could run too. Then if anyone finds a bug or wants to add a feature, they could write a test for you. It would also show a comittement to quality. In general, it looks like requirements for your company's specific use are leaking into the implementation of the containers. That's OK. But for more general, wider spread use many of these things could be fixed. (I'd especially look into the first bullet point about placement new. Someone might expect RAII to work properly and be surprised it does not in your container.) P.S. Good job getting this open sourced. I'd love to get my embedded containers open sourced too (and would look forward to criticism, feedback, and if others were willing even cooperation). But sadly, upper management in my company doesn't understand the value of open sourcing yet. :(
(Original article author here, and co-author of the library). Thanks for your comments. We do have many other containers: intrusive list, array, map, queue, deque, stack, etc... They're just not ready for public consumption yet. We're working on it though. We can use placement new. And we do that in a lot of situations, but not in our ESTL. But, that's an interesting idea and I'll have to think about that and see if it would make sense for what we are doing. What kind of use case are you thinking of for putting RAII style objects into a vector? I'd be interested in hearing about that. Our embedded applications are really restricted. We don't have gigs of ram. Our memory usage is typically measured in 100s of kbs or a few meg if we're lucky. That makes things a bit harder. We also have severe restrictions on performance and response time and unfortunately that does have an impact on the API. For example, the uncopyable part is really to help prevent other people who are using this library from doing something stupid (forgetting to pass the vector by reference or const-reference). Our target compilers that we're required to use only support C++98. That's frustrating! There are so many more things we would love to use but just can't right now. Your idea of #ifdef'ing parts of the API are also on our roadmap for this. We added a few C++11 APIs when we could. But first things first, we needed to support what we were doing. Good catch on the erase function. That was an oversight on our part. We do have a full test suite for our ESTL. Unfortunately, it was a bit more work to untangle the vector tests and get everything in place. I'll see what I can do about adding our tests. 
When I first started working at ESR Labs I asked the exact same question: Why not just use new and delete. It just seemed strange to me. Having spent many years writing C++ libraries (at Rogue Wave) I was just really confused. But the more I started to understand the limitations of the embedded environment it became clear to me that dynamic memory really wasn't an option in most situations. Having a car OS crash while you're speeding down the AutoBahn because you ran out of memory isn't a very nice thing to do. Debugging that kind of problem is extremely difficult and flagging the bug report as "can't reproduce" isn't acceptable. We work in very limited environments. We just don't have a lot of memory that we can use (and sometimes a very limited amount of stack space for each "thread"). We've looked at using custom allocators. That would be ideal (we really didn't want to re-create our own container library). But allocators still have the same problem as the heap: what happens if you need to allocate a block of memory but the memory is so fragmented that you don't have enough contiguous space? Unpredictability is not acceptable in our environment. We do use placement new. We use it a lot in fact. It's a great technique for delaying object creation. We could have done that for our vector class but it just didn't seem necessary. But there are valid reasons for using it and I'll take a look and see if that does make sense. But there's another issue. Some of the APIs on the STL aren't acceptable in an embedded environment. Resizing a vector for example is probably not something that should be done. Copying vectors is also probably not something you want to do. Instead of leaving those methods in the API we decided to remove them from the API to make it a bit easier to write safe embedded applications. C++ programmers already have enough tools to shoot themselves in the foot. Maybe our library can help embedded programmers write safer C++ code. 
I made my own lib (quite imperfect) to learn; some points were quite hard but I let comments linking to the blog posts, papers, and the things that had me understand how it all worked. https://github.com/jcelerier/libaudiotool/tree/0e2cf3becb11c796d0107593880896fca7cf6f84 It was used to implement watermarking algorithms, noise reduction algorithms, a 8-track mixer with volume &amp; pan, etc... (the latest commits might not work fine, I was in the middle of a thought process and was disturbed by my job :p I should put them into a branch)
I start to think a bit more everyday that for UI's in C++ you should do your business logic in "pure" STL C++ or whatever framework / library you need, and UI's in pure QML.
@Acritas - I am working for an automotive company writing embedded software, where comfomance guidelines simply do not allow us to use new/delete. The goal here is safety. We also are not allowed to throw exceptions. Why? Well new/delete/exceptions lead to a non deterministic behaviour. Will my new allocate? Will it throw? WIll the exception be caught? etc. Regarding placement new. Yes, this could theoretically be used, along with a custom .heap section in the memory layout. However, then we would also have to introduce additional checks ( i.e. can I allocate? or should I assert? ). If a size of a container , or at least it's max size is not known before hand ( compile time ) then a rough estimation of maximum ROM resources cannot be done. We do not have this luxury in my project. Our programs need to have a predetermined memory footprint. In addition, new/delete/copies may lead ( if misused ) to unecessary CPU usage. There are cases in Real Time Operating Systems where the execution times are really crucial. I hope this clarifies some of your concerns. I would personally welcome such a library in my project :) but alas I have none.. 
If you are able to use C++11, take a look at cppcomponents. https://github.com/jbandela/cppcomponents C++Now Presentation:https://github.com/boostcon/cppnow_presentations_2014/blob/master/files/cppnow2014_bandela_presentation.pdf?raw=true Basically, it is a header-only library for Windows and Linux that uses metaprogramming magic to have the compiler create the hourglass interface automatically. It allows you to use std::string, std::vector, std::tuple, and function objects as parameters and return types - automatically converting to and from an ABI compatible type. You can also throw exceptions (which will be converted to error codes at the boundary then back to exceptions on the other side. It also has an implementation of future so you can pass and return futures across ABI boundaries for asynchronous computation. It supports creating the components as shared libraries/dll and handles loading the required library automatically. It is tested on Windows with MSVC and GCC and on Linux with GCC and Clang/libc++, creating components with the 1 compiler and using those components with the other compiler. 
Interesting. Starred and will look at this a bit more when I have time. I'm not too up on the various Windows component models, but would this be one way to make C++ APIs callable from .NET?
&gt; IDL No do not. I am fucking sick of working on large code bases with it's own in house intermediary languages that are typcially rushed out don't keep up with the changing languege that is C++; &amp;oh you want variadics? Oh we'll you'll have to wait for Mike down in dev ops to add that to the generator*. A better idea would be to implement the PIMPL and flyweight patterns universally in the public API of your library with the front layer being implement header only in the top of the hour glass and the rest sitting behind the ABI.
Why adopt all the power of C++, only to be forced to use an inexpressive interface?
I've done this before. It's somewhat time consuming, but pretty straightforward work. I used it in a situation where we have a frequently used, but fairly complex (in terms of dependency and code size) library that actually has a very simple interface - it was the perfect case. The benefits for the client are great. Things that worked nicely for me: * With [JNA](https://github.com/twall/jna) (NOT JN**I**.) I was calling the library in JAVA with zero hassle. * I managed to decouple two fairly huge C++ projects. They can now use different versions of VS + boost and everything else - this is a great benefit. Without this neither project would ever be upgraded to newer tooling because it becomes a much larger job. * ABI compatibility helped in chaotic deployment scenarios. Basically I could roll back if I needed and be pretty confident that if I forgot the dlls things would be OK. And I knew my java wrapper would keep working. Or I could roll back just the dll if that was the problem. I'd love some tools for assisting with this pattern (without reinventing COM!) I'll be looking into cppcomponents.
Because C++ interface dynamic libraries are a minefield. Every C++ dll the client uses to be compiled in the same compiler with pretty much the same settings. Throw boost or something similar into the mix and you're going to have a hell of the time upgrading the tooling for that project. Don't forget the whole point of the hourglass pattern is to rewrap the inexpressive interface back in C++ (in the headers) to undo the damage (at the cost of some fairly simple work.) Something that's reused everywhere (to the point you may want other language bindings) and is well designed enough to have a simple interface can be "hourglassed" fairly easily. Client applications have a much easier time. Everything is nicely decoupled. You could use it from weird compilers or other languages entirely. Your library can use fancy modern C++17 compilers whist your clients don't need to (and vice versa). I've found it to be worth the effort in some cases. Other possibilities are making the library simple to compile (a few .h and cpp fileto be added to project, or a CMake/visual studio sub project). Sometimes these are appropriate. A popular library that uses the hourglass pattern is ZMQ (with the zmq.hpp header). I always breath a sigh of relief when a library has a C interface or even better then fully hourglassed it. Bit of a brain dump there, hopefully it helps you understands.
That looks very interesting, thank you. One of our requirements is being able to call the code from C#, Python etc. I can see how this could provide a stable ABI but how is the 'C style' API defined? Or do I just call the DLL directly?
The real solution would be to extend [SWIG](http://swig.org/) to do it automatically. It already does half of the job by being able to generate C wrappers for C++ code (although only in a separate, not yet merged into master, branch). Now someone just needs to automate generation of C++ client interface too. This won't be trivial, but it still seems like an obviously better solution than everybody doing this by hand.
The first time I saw this approach used was in TIBCO Rendezvous sometime in 2001. This approach worked really well for managing a C++ API without binary compatibility issues and without leaking dependencies through the header files.
Exactly. The first thing I look at when considering a library is its interface. If it forces me to write terrible C++ code then I’ll keep looking. I’m the client, I don’t want to jump through hoops just because the library also wants to support C, and is too lazy to offer proper C and C++ bindings. The whole point of a library is to free the client from writing redundant or error-prone code. Having to force C++ into a C interface *is* exactly that.
Well the point of the hourglass is that it has a lovely C++ interface on top if the C bit.
Right, scratch my comment. Brainfart. /u/TomSwirly’s comment stands, though: the idea still forces you through a C interface bottleneck, and I really think that’s a bad idea in most cases. Of course it also incurs a runtime overhead due to the necessary conversion to and from C++ objects to C objects.
For a simple introduction to generic programming I always liked this site. http://www.generic-programming.org/ 
What do you mean conversion to and from C++/C objects? If you're dealing with a DLL, you're generally just dealing with pointers, and the C++ interface just wraps/abstracts these pointers away. A properly written client side C++ interface won't introduce any overhead that wouldn't otherwise occur with the use of a DLL. Besides, as discussed elsewhere, it seems like many would consider the real world cost of maintaining a C++ DLL to be greater than that of at most minor overhead.
&gt; Using-directives are fine when used in small test cases by people who know what they're doing. ... and then, junior team members are going to say: look STL wrote that, it must be the way to go...
Honest question, because I never used an IDL, but like the idea: What about swig?
"do not allocate on heap" - yes, I could understand that restriction in RTOS. But it has nothing to do with new/delete usage per se. Yes, std::new and std::delete allocate on heap (in most implementations, BTW). But that's the beauty of C++ - you could overload these ops to do a fixed allocations instead. Placement syntax for 'new' is a shortcut to fixed allocations too. So, to me the problem was addressed from wrong end: instead of rewriting STL containers, much easier and faster (and I suspect - safer too, since STL code scrutinized by a lot of tests) would be to implement proper overloads for new/delete with fixed allocations. And if there's concerns of runtime overhead - any decent compiler and pre-processor would allow you to define them to be optimized away (e.g. compile-time code gen in-place) in production builds.
Lots of good points here! I have to say that it being 2014, I don't have any good use for dynamic linked libraries in new code any more... for this reason and many others. If I can get it, I want a header-only library, or else a static library I can link right into my executable so I _know_ what code is being called.
&gt; Well new/delete/exceptions lead to a non deterministic behaviour How? I mean really, how are any of them non deterministic? The worst I heard was that they where harder to reason about than the alternatives.
heap allocation != new/delete . Yes, standard implementation allocates on heap. Just overload it with fixed-placement implementation.
&gt; Because C++ interface dynamic libraries are a minefield. Every C++ dll the client uses to be compiled in the same compiler with pretty much the same settings. The amount of problems I had with that was never worth the effort. &gt; Throw boost or something similar into the mix and you're going to have a hell of the time upgrading the tooling for that project. We don't use any of boosts fancy features, so I might have been just lucky with that. 
If that's the case, I would use a custom allocator that is more domain-specific or use std::array/boost::static_vector. I would also only do this after profiling to make sure that it is indeed where my CPU time is being spent. Even if that is where it was being spent, I would first try to optimize by reducing the need for dynamic allocations in the first place by reserving the correct amount of space up-front, by using more efficient data structures on the stack (if I can), or by trying to optimize moves. If all of that failed would I then start to look at more obscure data structures.
Good to see that no one looks good when staring into the soulless gaze of a webcam. Thought I was just ugly.
Interesting response. 
I usually just fill the grid randomly.
This is from a few months ago now. You can form your own opinion, but for a two hour watch it doesn't deliver much. This is by design, as it's a "Hangout" session. If you've been paying any attention at all to the development of C++11/14/17, you probably know about everything shared in this video.
Ah okay, thank you.
I agree with you. :) On the project I work on, we frequently use std::vector and reserve space. We profile. We have found that some new containers are appropriate (see the linked list I described elsewhere in these comments). Custom allocators with the standard library are OK. I don't like how the allocators can't be associated with a particular object. In other words, each container can't have its own object pool with custom allocators.
&gt; Are those guidelines came directly from God and therefore cannot be challenged? They might as well have come from God. See [my other post](https://www.reddit.com/r/cpp/comments/2mw6xk/c_stl_for_embedded_developers/cm9gt6k). The rules cannot be challenged for the automotive industry. &gt; Placement new (or overloaded new) allows to have predetermined memory footprint. No contradiction there. The OP said he uses placement new elsewhere. It really would help this library to use it. EDIT: Clarified that the rules can't be challenged *in the automotive industry*.
Doesn't Qt have a stable C++ ABI across versions? How do they do it? 
&gt; What kind of use case are you thinking of for putting RAII style objects into a vector? I'd be interested in hearing about that. I forgot what the use case specifically was. But let's explore. One could have a vector of std::unique_ptr with custom deleter (that's rather broad I understand, but is a potential use case); vector of signal slots that automatically de-register themselves; vector of slots for that matter; vector of memory mapped resource handles. There are lots of other possibilities. I just recall encountering the same design for an embedded vector in our product and being surprised when destructors were not being called when objects were removed. That's when I fixed the problem and rewrote that container. &gt; Our target compilers that we're required to use only support C++98. That's frustrating! Indeed!!! By the way, I recently talked to Green Hills Software (whom I am not associated with at all; just scoping out their compiler) and their latest compiler is nearly C++11 compliant and supports many C++14 features such as binary literals and relaxed aggregate member initialization. You might want to check them out next time there is a possibility of upgrading your compiler. &gt; For example, the uncopyable part is really to help prevent other people who are using this library from doing something stupid (forgetting to pass the vector by reference or const-reference). Yeah, that could be an library option. Something that is included when ERSSTL_NO_CONTAINER_COPYING is #defined.
By not changing things which would break the ABI.
I'm not sure I understand your custom allocator point. Are you saying you want to tie ClassA to always have a certain kind of allocator? If that's the case, you could try traits &amp; container aliasing: template &lt;typename T&gt; struct allocator_traits { using allocator_t = std::allocator&lt;T&gt;; }; template &lt;&gt; struct allocator_traits &lt;MyType&gt; { using allocator = ...; } template &lt;typename T&gt; using default_allocator_t = typename allocator_traits&lt;T&gt;::allocator; template &lt;typename T&gt; using vector = std::vector&lt;T, default_allocator_t &lt;T&gt;&gt; template &lt;typename T&gt; using list = std::vector&lt;T, default_allocator_t &lt;T&gt;&gt; Etc. It would be nice if the default containers let you do that.
These are exactly the 2 books I was going to recommend, with "The Complete Guide" being first. Vandevoorde's book explains templates inside &amp; out, and almost always, when I have a question, that is the one &amp; only book I need to consult. Modern C++ Design, OTOH, assumes a decent grasp of templates, and then illustrates some really fantastic, clever, useful and creative /uses/ of templates. Great stuff.
Why is reading a book is best way of learning C++? Just out of curiosity.
Hey again :) 1) We'll have to agree to disagree about "Hello, world!" being useful as anything other than a programming 101 exercise. 2) I'll have to take your word for it. What platform is gtest hard to build on? I'm not sure what you mean about setup time on github. Are you saying that it takes most people one hour to get their repo set up on github? 3) Being able to compile OpenCV is nice. I spent more than half a decade in rad-onc. I'm still confused about what you purport to provide over stuff that already compiles/links. 4) so students can experience easier versions of hello world (after learning YAML, is that it)? 5) Perhaps it was rude of me too pick on this subject. 
Nope, the biggest pitfall is largely losing C++'s value semantics.
None of this 'no dynamic memory' hogwash I've been seeing lately makes any sense. The issue is, it seems, that there's confusion about what dynamic memory is. If you are reusing memory in any way, you are using dynamic memory. If you have an array that you're using as a pool, that's dynamic memory. Dynamic memory is anytime your entire state doesn't fit in memory. Indeed, the only reason to use dynamic memory is to reuse memory during the lifetime of your application. I find it ironic that this comes up with regards to embedded, because embedded is precisely the place where the state doesn't all fit and memory needs to be used dynamically. Now, it's true you probably don't want to heap allocate every little thing, but that is not 'no dynamic memory', that's simply an optimization of your dynamic usage. 
&gt; I am not arguing I didn't mean *you* specifically, I meant 'you' generally. I probably should have said 'one' instead of 'you'. In any case, I have argued against many of the MISRA-C++ policies where I work (because I do disagree with some of the rationale). Luckily, I don't work in the automotive industry, so I can successfully argue such points. As for exceptions.... you're right MISRA-C++ does allow exceptions. There may be other constraints though. It may be his C++98 compiler doesn't deal with them well; it could be a rule from management; I don't know. It would certainly be something *I'd* question though.
Lots and lots of the pimpl/d-pointer pattern.
I've implemented this approach for proprietary SDKs and it is a good one. The only thing I wish I had done better was not requiring dynamic allocation. That is, perhaps allowed an interface like this (pseudo-code): hairpoll_t construct_hairpoll(unsigned char buffer[sizeof_hairpoll],args) { ... return appropriate_cast&lt;hairpoll_t&gt;(buffer); } So that I could construct in-place. Otherwise, where it looks like you're using stack allocation, you're using dynamic allocation which can be surprising. I'm not sure if the above is the best way to do it or not, but I'd like to hear ideas.
Sorry for the confusion. As an example, I want each instance of a linked list to have its own pool of elements so that all nodes of a linked list are located close to each other in memory. For example: estl::list&lt;Foo, 50&gt; list1; // Pool of 50 nodes located together estl::list&lt;Foo, 50&gt; list2; // Pool of 50 nodes located together, but separate from list1's pool of nodes 
Is it just me? I'm not really seeing anything exciting on the horizon for C++17, especially now that ranges were punted to a post C++17 TS. There's some interesting features that improve things here &amp; there, but there's nothing truly transformative like there was with C++11 (except maybe coroutines). C++14 seems like a bigger release for basic usability &amp; that was just polishing off C++11.
I am hoping for big three: concepts, modules, coroutines.
Not an article, but there's [Advanced C++ Template Metaprogramming](http://www.amazon.com/Advanced-Metaprogramming-Davide-Di-Gennaro/dp/1460966163).
&gt; Except for the fact that the Win32 API is defined in terms of C. But sure, apart from their OS exposing its core functionality using C, yeah, C is dead on MS platform. You realize that was done back when C++ barely existed? You can't just change it now. Also, having it exposed as C APIs lets you use it from variety of different languages, including but not limited to C++, C#, VB, Python, Delphi and others.
If I had to guess, it would be at //BUILD/ 2015, which is scheduled April 29, 2015.
Don't you consider Concepts and Modules to be huge steps forward? My own deception is that the number of undefined/unspecified/implementation-defined behaviors does not diminish; and that is ultimately why today I am looking at Rust rather than C++17... even though I really miss non-type template parameters.
But the article doesn't mention Modules anywhere unfortunately :/
I'll mention it then. Module proposal http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4214.pdf was reviewed by Evolution group and the vote was unanimous to approve the direction. (Keep working, we like it). 
Concepts + modules + static reflection + coroutines. Well, if that does not transform things... Let's see what's in finally. Remember that this was the first "c++17-only" meeting. Be patient.
Me too. But coroutines, please, not type erased in any way :p
That's good news. So it's on track for C++17 ?
What's the point you're trying to dispute? Be specific.
Win32 API being defined in terms of C doesn't mean that C itself isn't dead for Microsoft. There are other reasons for why the API is as it is.
What about operator dot and its sister proposal, both by Bjarne? Those seem to enable some pretty slick code.
Boost has allocators for exactly that. You should look at it. Of course there are limits (at some point contiguity must be broken unless you violate the bigO of list).
Ranges weren't exactly punted from C++17, but they were decoupled from that effort. It's entirely possibly that I can have a minimal proposal ready in time for the next meeting. If you figure at least one meeting for revisions, it's conceivable (albeit unlikely) that a ranges TS could be ready by as early as next year. In other words, your disappointment about the ranges schedule may be premature.
operator dot: Reviewed, further work encouraged x.f(y) == f(x,y): reviewed, more work needed. 19 vs 6 to allow x.f(y) to call f(x,y) 15 vs 11 to allow both ways (no consensus) 
We will see next year, when we have an experimental implementation of N4214. 
This article is best read with one hand down the pants.
Sorry, I didn't mean to imply I was down on ranges or the schedule. I think it's one of the proposals I'm really excited for &amp; I appreciate the work &amp; care you're putting into it. I also liked reading the various articles that gave insight on what your thought process was. With regard to TSes, I'm not too keen with TS'es as they're not versioned &amp; the standards support is hit-or-miss (i.e. gcc implements string_view but clang implements optional). As an end-user, I don't really have any protection that the API is changed in an incompatible way, so that upgrading my compiler toolchain either results in a broken codebase or, even worse, a subtly broken runtime. It seems like TSes are more for the standards body to gain experience by implementing it in a compiler &amp; testing it out rather than for the community to get the feature early. I think TSes are a good start, but the standards body could do a lot of good by flushing out the guidance on how to use them &amp; how they should be included in the standards libraries. Even something as simple as having STL authors provide a switch like -enable-ts=N3690 would allow for the standard library to pick the appropriate implementation (presumably any API incompatible change would be delivered in a different proposal). It would also let you just put things in the std:: namespace instead of the unversioned ::experimental mess that exists now. Of course, that has it's own problems (which is why this isn't done) of making an intermediary specification something people can rely on, but I think that's a better situation than where we're at now.
I had a lot of hope for modules. However, reading each proposal, it feels more watered down as it progresses that I have questions about how much real benefit it will provide. Of course, the risk with a more ambitious proposal is that it's never adopted. Aside from the preprocessing of the AST, I was hoping for a solution to speeding up template instantiations (why does every compilation unit still need to do it), avoiding recompilation to things that didn't meaningfully change the AST (i.e. comments &amp; private functions), &amp; speeding up compile times by including only the parts of a module that are necessary (like D does). Finally, although this kind of approach would never get adopted, I was hoping for some kind of unification between modules &amp; namespace to reduce the mental burden required to use something.
Im very excited about C++17. If I understand correctly that's probably where the "Parallelism TS" and "Transactional Memory TS" will land. Both important, maybe even revolutionary, when it comes to writing scalable programs. And there will more. C++17 looks like a large update. (C++11 was almost 15 years in the making .... I'd rather not wait that long.) Check out this for more info on what might land in C++17: https://www.youtube.com/watch?v=Vo-WpGkb2JM
I appreciate that. 2017 is certainly a ways away so lots of work is still going to be done. I'm not a huge fan of concepts. Not that it doesn't solve an actual problem. It does. More that it's going further down the template rabbit hole instead of revisiting other non-pattern-based approaches might be out there (e.g. constexpr solves a large class of problems far more efficiently &amp; simply than TMP). The way I see it, templates are very difficult to write unless you're an expert (and even then...). They are even more difficult to read. Templates are frequently more of a write-once kind of thing. I do not see concepts as addressing this. I also think that members of the community are pushing concepts with a little bit of tunnel vision &amp; aren't being fair to alternatives (the fight over static_if felt nasty &amp; didn't present meaningful counterpoints). Modules I discuss above. The concern I have is that if it does land in C++17, it will be really watered down. Of course, that's likely just an initial building block, but my enthusiasm is kind of tempered given how long the road to date has been &amp; the end is still nowhere in sight. Static reflection is interesting but I haven't read any papers yet about it (any links?). The only one so far has been with respect to the default operators which is really nice (although it misses the giant hole of hash&lt;&gt;). I agree with respect to coroutines having a very strong potential to be transformative. I think /u/GorNishanov is doing a great job on driving it through the standards body.
Modes are nightmarish. If you give users an option, they will immediately attempt to link object files, static libraries, and dynamic libraries with mismatched modes.
In case my complaint came of as non-constructive, here's my list of what I believe are real-world deficiencies in C++. **Compilation times** * Deprecation of PIMPL. Provide a mechanism whereby modifying the private member variables of a type doesn't necessitate recompiling it. * Out-of-band private functions extensions declarations/definitions. Changing/adding/removing a private function should not trigger a recompile of all the things that depend on that header/module. * Template instantiations. Provide a concrete mechanism whereby templates are instantiated once per type in a project. Having each compilation unit instantiate std::vector&lt;int&gt; is ridiculous &amp; expensive. Existing mechanisms to accomplish this are extremely kludgy. **Preprocessor** * Robust compile-time reflection that obviates Qt's MOC. Anything sufficiently powerful enough to do that would get rid of large swaths of CPP &amp; code generation. * N3972 **Template complexity** * Pattern-based templates are really difficult to write &amp; reason about. Also, templates suffer from easily having bugs if they're never instantiated. Figure out an approach like static_if or something similar that lets you write traditional conditionals you can reason about &amp; read easily instead of leaving it as compiler-internals. * Really get a good handle on constexpr. Right now, constexpr is simultaneously too limiting (math intrinsics aren't) while risking becoming vendor-specific &amp; non-portable (i.e. some math intrinsics or compiler builtins are). **ABI** * Define an ABI interface for C++. The hourglass pattern is a kludge to get around there being no stable ABI for C++. It also means compiler vendor hell as porting a compiler means porting not just the size of integers, but the calling conventions &amp; name mangling. And even then, you're SOL since it's highly unlikely for 1 standard library to talk to another. * Define an FFI for C++ so that Java, Python, etc can provide first-class integration (i.e. not via a C interface) **Memory allocators** * Maybe make a few different ones part of the standard (boost has a few good ones) * Containers having the allocator as part of the type signature sucks for APIs. It would be nice if this could be addressed. **Smart pointers** * N3840 - I know it's controversial, but there needs to be something to help transition legacy codebases. Newer codebases can largely get away with defining raw pointers as non-owning observers (although it can still sometimes be confusing). * non-atomic shared_ptr. atomics introduce expensive CPU &amp; compiler barriers. * version of shared_ptr without weak_ptr (both with &amp; without atomic). particularly with the atomic version, the weak_ptr forces some really performance-obstructing code. **Threads** * Thread-pool-based work queues, ala libdispatch, seem like a glaring omission (of course the standard may choose to go a different way). With coroutines, this kind of code could start to become really simple to write. **Collections** * std::map/std::set suck. std::unordered_map/std::unordered_set suck less, but still aren't great. std::map should be deprecreated in favour of a drop-in replacement like boost::flat_map. std::unordered_map should have a cache-friendly implementation. * std::list/std::slist should use cache-friendly allocators by default in the scenario that people mistakenly use them instead of vector. * std::vector but stores only the pointers to the actual memory (i.e. QList). the interface is still value-types. **Runtime-reflection/exceptions** * Allow for an opt-in version of RTTI. That decouples it to being an explicit cost for types you want it for rather than an implicit cost just because you use inheritance. This also would make it easier for Google, clang &amp; others to come back into the fold of the standard. * A faster version of dynamic_cast. There should be a standard way to accomplish what clang &amp; others do to get cheap runtime polymorphism. * Checked exceptions. Unchecked exceptions can too easily result in a crash due to being unhandled. * Enforce that return values are checked. GCC (&amp; clang?) have this as extensions but having it standardized would be great.
Oh I don't disagree, but do the same issue not apply with -std=c++14/-std=c++11? My point is that as an end user, how do I use std::experimental? If that API stays stable, that kind of defeats the purpose of it being experimental. If it changes, then users tie themselves to a specific compiler version with not really any kind of migration path available.
&gt; do the same issue not apply with -std=c++14/-std=c++11? I also consider 03/11/14 modes to be evil. VC's behavior of always providing the latest conformance is ultimately superior, even if it's more work to upgrade toolsets. &gt; If it changes, then users tie themselves to a specific compiler version with not really any kind of migration path available. The migration path is "update your code when you update your toolset".
&gt; I also consider 03/11/14 modes to be evil. VC's behavior of always providing the latest conformance is ultimately superior, even if it's more work to upgrade toolsets. I think the default if not specified should indeed be the latest. However, being able to specify a specific version of the standard is still extremely useful. &gt; The migration path is "update your code when you update your toolset". That results in multiple moving pieces. I guess often that can be OK. At least one counterpoint is I think statistical modelling. We run simulations on captured data to make sure that any change we introduce is expected &amp; within the bounds of the change (i.e. catch unexpected regressions or improvements). The recommendation to change both compiler &amp; code at the same time is not a practical one. If there are changes, we don't know what is responsible. Is it the new compiler, standard library changes, or the changes we made to obtain the latest standard. Another counterpoint I would give is that I used to work in a largely MS shop about 6 years ago (so this experience may be dated). They had a very large codebase. Upgrading to a new Visual Studio version was a giant ordeal that required giant amounts of synchronization. First, they had to prepare all the changes ahead of time. Then they had to continuously update it to the latest master. Then they switched it over &amp; had to make sure all developers &amp; build systems switched over at the same time. I have never seen this amount of effort applied on any other non-Visual Studio project. Xcode is largely backwards &amp; forwards compatible. autoconf is backwards &amp; forwards compatible. CMake is largely backwards &amp; forwards compatible. The point I'm trying to make is that the longer you make the migration path, the less synchronization you need between a lot of components which actually makes it easier to migrate as you can do it piecemeal as appropriate. EDIT: Here's another reason why this migration path is undesirable. Let's say I have multiple projects that all use the same toolchain &amp; standard library (for example OS development but could be other complex projects). Upgrading the toolchain is blocked on upgrading multiple projects. Upgrading any particular project is blocked on having the new toolchain. That means you have to upgrade multiple projects &amp; the compiler all at once. The amount of coordination required to pull that off is insane &amp; extremely undesirable, at least IMHO.
I did some benchmarks on g2log. see https://github.com/gabime/spdlog#benchmarks 
I could be misunderstanding allocators (I've never really used them, just read about them). The constructor for the containers takes in an instance of the allocator defaulted to a default constructed instance. So each instance of your allocator is already unique to each container. It's if you want to share memory between containers or do more customization that you need to do anything special.
Well, concepts will make code easier to write, IMHO, even if they add more on top of templates. About constexpr vs templates, yes, constexpr solves problems better than TMP in *some* cases, but not all of them. There are many things that cannot be done with constexpr only, one being computing types from compile-time strings, which is a place where templates are very useful. Modules: we cannot have a super module system immediately on top of a language that must keep backwards-compatibility. So it is better to have a better solution than headers that can be extended. So I would look at C++ lang evolution like this: everything that is an improvement should be welcome, as long as it doesn't preclude future extension. We need modules for improving compile times, if we have that, we already won something. Later more things can be added. What wouldn't be wise, IMHO, is to make modules out completely, unless there is a big, justified concern. Static reflection. Several proposals, of which the most promising for future work was http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4113.pdf I think. Coroutines: In my opinion, resumable lambdas are potentially a simpler solution that has better properties http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4244.pdf. I don't mean Gor Nishanov is not doing a fantastic work, he is, and I think we will end up having a mixture of the best things from all proposals. The advantage of resumable lambdas is that it is, IMHO, easier to reason about them, since they are just function objects. It's not perfect, but it is simpler, that is why I favor an approach like that. See discussion on n4244 vs n4133 merits here: https://groups.google.com/a/isocpp.org/forum/#!topic/std-proposals/_ssbHm4C2t8
&gt; one being computing types from compile-time strings, which is a place where templates are very useful. That's interesting. How does one do this even with templates? I thought the only parameters to a template could be constant integrals. The broader point I was trying to make was not that constexpr is the answer to everything. It's that there are alternatives that can solve large swathes of problems that templates are (ab)used for right now. Templates still have a place, but the goal should be that we reach for other things that are more understandable first before we resort to templates. For example, I find static_if code snippets in D that select code based on types far more elegant to read than the equivalent template code in C++ (it's also faster for the compiler to evaluate). &gt; Modules: we cannot have a super module system on top of a language that must keep backwards-compatibility I'm not disagreeing. There's very good reasons why the module system is being designed the way it is. My only point was that it's a little hard to get particularly excited when each next proposal is only more watered down. The static reflection looks powerful &amp; neat. It will be interesting to see where it goes. With respect to resumable lambdas, it feels like a complementary rather than opposing proposal. It seems like resumable lambdas would be built on top of the original stackless routine mechanism.
"Containers having the allocator as part of the type signature sucks for APIs. It would be nice if this could be addressed." There is the proposal from Bloomberg about polymorphic memory resources. This would solve the problem if it goes into the standard at some point. All the other points are valid, though they are working on some of them, such as coroutines. 
I was aware of the Bloomberg proposal, although I don't know what the reception is in the standards body. Is it on track for C++17 or any standard? My point with respect to coroutines was more that they make asynchronous queue-based approaches very readable.
Again, I don't disagree that it could be an improvement. I'm just saying it's hard to get excited when the scope keeps shrinking with each proposal (incremental compile times are just as important as clean compiles). Also the O(n*m) -&gt; O(n+m) transition isn't free. There's a lot of code re-writes on the horizon if you want to take advantage of modules. Additionally, I haven't really heard what the pre-compilation story is. AFAIK, clang doesn't have one. What that means is that the initial compile time is slower as you have to build up all the modules for the first time (i.e. STL). It is of course amortized over time as you do more compilations. I'm not sure I understand what your point with respect to backwards compatibility is though.
If you have the time, could you state your concerns? I've briefly looked over the clang proposal, but I'm interested in what you think is "wrong" with clang's proposal and why it's only a half-solution.
"For C++ questions, answers, help and advice see r/cpp_questions or StackOverflow." -- The sidebar
I was certain [the last proposal I read](https://isocpp.org/files/papers/n4214.pdf) contained a section that, grossly paraphrased, said something to the effect of, "improving compilation times is very nice, but is a less important bonus gain and not a specific goal." I can find nothing like that now so I wonder if I misread something and formed my opinion on that, which would be a little embarrassing. All the same, I didn't think anything was specifically wrong with the proposal and I didn't use "half-solution" to suggest that, but rather to say that it didn't solve *enough* problems.
http://www.gotw.ca/gotw/
Pre-C++11, stateful allocators had problems. ([ref1](https://en.wikipedia.org/wiki/Allocator_%28C%2B%2B%29#Background), [ref2](http://stackoverflow.com/a/12555064/2913902)). Even with C++11, [GCC is non-compliant](https://stackoverflow.com/questions/24278803/how-can-i-write-a-stateful-allocator-in-c11-given-requirements-on-copy-constr) with regards to allocators (and some other features such as COW strings) due to binary compatibility. In the end, even with today's compilers, it is best to avoid stateful allocators. According to the standard, something like what I want may be possible, but the real-world often gets in the way. :( The one advantage to a custom container is that the memory for the container data and its nodes can all be allocated as a group. This is much more difficult with custom allocators.
Yes, we've tested execution times. We rarely traverse the whole list, usually only peeking in one or two elements with the option of inserting in the middle one or two places deep, or swapping out all values after that spot with new elements. The insertion bit is the troublesome part. The nice thing about having a linked-list whose nodes are in contiguous memory locations is that we benefit from cache locality. (I'm assuming this is the case; the performance seems to back this up, but I don't have the tools necessary to interrogate the embedded processor we're using for verification.)
Another good resource. These all seem to be 2008 and before though, so probably not the exact subject matter I'm looking for. Also a good pointer to comp.lang.c++.moderated. I haven't followed that in quite a while; might be worth looing into that again. They used to have great discussions there.
He still updates it: http://herbsutter.com/gotw/
Why do you need C++ "skills"? I presume in order to create programs? So create something.
&gt; Preprocessor &gt; Robust compile-time reflection that obviates Qt's MOC. Anything sufficiently powerful enough to do that would get rid of large swaths of CPP &amp; code generation. &gt; N3972 &gt; &gt; Template complexity &gt; &gt; Pattern-based templates are really difficult to write &amp; reason about. Also, templates suffer from easily having bugs if they're never instantiated. Figure out an approach like static_if or something similar that lets you write traditional conditionals you can reason about &amp; read easily instead of leaving it as compiler-internals. &gt; &gt; Really get a good handle on constexpr. Right now, constexpr is simultaneously too limiting (math intrinsics aren't) while risking becoming vendor-specific &amp; non-portable (i.e. some math intrinsics or compiler builtins are). The proper solution would be add support for AST macros, generalizing/extending constexpr maybe a good base to start from. It could go a lot further: * In Nemerle you can make user-defined .NET attributes using there macro system, the same could be done for C++ attributes. * A standarized AST/Compiler internal library could double up for both compile-time and run-time introspection/reflection. * Add support for syntax extensions later on. I've been suggesting this recently so if you're interested make some noise: https://groups.google.com/a/isocpp.org/forum/?fromgroups#!topic/std-proposals/MblNbx7xc94
Disclaimer: I wrote this. Happy to answer any questions or discuss bugs/issues.
[Get the PDF and code on github.](https://github.com/CppCon/CppCon2014/tree/master/Presentations/Hourglass%20Interfaces%20for%20C%2B%2B%20APIs)
If I was going to make a networked game. Id probably make a struct of the game state (position+velocity+acceleration+timestamp, of all dynamic objects etc) and the use json as the serialized object representation. Id use the cpprest library to stream updates from the server. (ccprest has built in json serialization/de-serialization so no need to reinvent the wheel) https://casablanca.codeplex.com/ For storing historical states I would just push them them in a vector. And use overloaded operator== to see if they changed. 
Also looks interesting.
&gt; Avoiding new and delete in embedded projects is often due to CPU time, not running out of memory per se; heap allocation and deallocation can be expensive in terms of CPU cycles. (Though for some projects the concern of running out of memory is real.) And for RTOS, you need deterministic behavior too.
There is no way to avoid (generically) template instantiation for each compilation unit, what you CAN do however is caching the AST of the template to avoid re-parsing it in each compilation unit. You can, however, already avoid it with code using the `extern` declarations to declare that your library will provide the instantiated form of a given template. This what libc++ does for frequent combinations, though it's a trade-off since it has to guess at those...
The infamous UFCS...
indeed
what about `touch::` and `view::`?
That's really interesting. One of the other points I had that I forgot to add was a mechanism by which I could add lazy evaluation transparently (i.e. logging). It sounds like this could do it. My concern with that group is I'm not sure how active committee members actually are.
&gt; With respect to container data &amp; nodes being allocated as a group, I would be very surprised to find out that that doesn't already happen for all the containers in the STL (at least in any of the 3 main STL implementations). Nope, they are allocated separately. Think about vector. How do you allocate a resizable-array on the stack (that doesn't have a defined maximum size) and keep that data array near the memory of the vector data members (i.e. on the stack)? As a test, try this: #include &lt;iostream&gt; #include &lt;vector&gt; using namespace std; int main() { vector&lt;int&gt; vi; for (int i=0; i&lt;10000; ++i) vi.push_back(i); cout &lt;&lt; sizeof(vi) &lt;&lt; '\n'; } I guarantee you that the program will print out less than 40000.
Is this information for every paper posted somewhere? I haven't seen it pop up from what I can remember.
&gt; That's interesting. How does one do this even with templates? I thought the only parameters to a template could be constant integrals. From what I've seen, as of C++11, `using AbcString = String&lt;SOME_EXPAND("abc")&gt;;`, where `SOME_EXPAND` repeatedly indexes the literal to produce a comma-separated list of character literals. 
If you really have to make it in C++, Qt is probably the only option which supports (at least partially) Android, iOS, Windows RT, and most desktops.
Very cool; thanks! I have another question about the use of spdlog. Does the library provide a way to obtain "global" access to a logger? g2log for example, provides the LOG() macros that will provide access globally to the logger thread. If not, I imagine something like this may be easy enough to implement on ones own, but I just wanted to see if this functionality existed before I went about trying to replicate it.
I've heard of people doing the whole UI in OpenGL rather than Qt or the native toolkit. Dunno what OpenGL widget set they use.
&gt; but C++'s current semantics don't support that. But C++17 might. I'm a fan of the pipe syntax given what's possible in C++14, but if one of the `f(x,y) == x.f(y)` proposals gets adopted I think I'd be opposed to it, even if it's still occasionally better (e.g. `bigvec |= cont::sort | cont::unique` doesn't have quite as nice of a dot-notation equivalent).
I think the meeting minutes are private until the chair writes a report and submit it as an N-paper. November mailing will be out soon, there may be a report there from Evolution group that was looking at those papers
Ah, thank you. I'm still ever learning how these meetings work. Wish it was possible for me to attend one, but I really can't .
What I meant higher up is that the container 'shell' and the the nodes/elements are contiguous to each other. For example, a typical linked list is as follows: template &lt;class T&gt; class list { list_node&lt;T&gt;* first; // points to memory elsewhere list_node&lt;T&gt;* last; // NOTE: nodes are usually not in contiguous memory. unsigned size; // to prevent having to calculate the size by traversing the list. }; Whereas the following is very useful in an embedded environment: template &lt;class T, unsigned N&gt; class list { list_node&lt;T&gt;* first; // points to something in data[]. list_node&lt;T&gt;* last; // all nodes are in contiguous memory as could even be in stack memory. unsigned size; list_node&lt;T&gt; data[N]; public: static const unsigned Capacity = N; }; This way, when you are referencing the any member of the list, you don't have to make a single jump to something far away in memory. Everything is close by. Does this make sense?
It does to some level. However, this kind of data structure only works for smaller values of N (otherwise you can overflow &amp; corrupt the stack). In that scenario, it's often faster to just avoid the list altogether &amp; use a vector/array. It's also rare in my experience to have data-patterns better suited to a list than a vector. Another thing you might want to look into is an intrusive list. It's a really neat data-structure that lets you access your data as a linked list even though it's stored in a vector/array.
Excellent! Thanks so much for the benchmark and the library. I look forward to giving it a whirl soon :).
Protobuf, cap'n'proto, thrift, swig, messagpack, etc, etc. Lots of industry-standard IDLs to use.
&gt; It does to some level. However, this kind of data structure only works for smaller values of N (otherwise you can overflow &amp; corrupt the stack). If you are using it in a stack. I mentioned that this was possible, but it's not the only use case. My first use of this data structure was for a moderately-sized (~500 elements) list that was a member of a larger structure that was dynamically allocated at the beginning of program. The part of the program that needed to access the data structure did so periodically (well, the whole runtime was periodic) but all within a short time frame. Having everything next to eachother in memory here was nice. &gt; It's also rare in my experience to have data-patterns better suited to a list than a vector. Agreed! &gt; Another thing you might want to look into is an intrusive list. It's a really neat data-structure that lets you access your data as a linked list even though it's stored in a vector/array. That's sort of what I implemented -- accessing data as a linked list even though its stored in an array. Although, I don't expose the array portion, which certainly could be useful if you want to iterate over the elements, but out of order with the possibility of coming across null nodes.
With Qt you have a QML, which is designed to do that tiles and animation stuff easily. The problem is that (if I am not mistaken) you need a commercial license to publish a Qt app in a mobile app store. Also technically Qt apps are perhaps too big :(
Oh yeah. That's the other challenge with this kind of approach. Inserting &amp; removing elements will be a giant PITA as you have no idea which are empty. If you're only ever inserting, it's not a problem. I imagine there's some kind of reclamation phase where you compact all the elements (i.e. if you hit N &amp; have removed elements).
It's not that much of a pain. You internally keep two linked lists -- one that is "free" and one that has data. When you add an element, take an element from the free list. When you remove an element, add it to the free list.
It's perfectly reasonable to use C++ across all the mobile platforms to share the vast majority of the program across platforms. But: &gt; that uses the Same GUI across all targeted platforms Unless this is some boring, line-of-business type program that won't be seen publicly you really should do native UI's. UI's that don't follow each platforms' standards will be awful, unless for some reason none of the platform standard behaviors apply. Here's a pretty good talk on building cross-platform apps using C++ from the recent CppCon: https://www.youtube.com/watch?v=5AZMEm3rZ2Y
That's still a non-negligble amount of book-keeping though. It's questionable if you are in fact saving anything as opposed to taking a bit of an extra indirection. Note that freeing memory now involves dirtying "cold" memory. You'll fault items into the cache that are not actually relevant anymore, thereby hurting temporal locality. That's why memory allocators stopped using this approach in favour of dedicated tables to track allocations. It may have more overhead, but you gain significantly by letting cold memory stay cold &amp; keeping all the memory management in a single hot region. Keep in mind that what's realistically going to happen with a traditional vector is that your member variables array &amp; the book-keeping part of the inline vector members will both be hot in the cache. You might think that you're wasting the remaining part of a cache line with the size/capacity/pointer, but the principle of data locality tells you that it's highly likely it's near other hot data so you're not actually losing much. Worst case, you're losing 1 cache line (on an Intel you'd only be wasting 60% of a single cache line). It could be there's some domain-specific reason you're doing this aside from cache coherence unless you were on exotic/ultra-embedded CPUs. Even then, it would be surprising if it had drastically different properties.
Platform standards rarely applies for some types of applications like games or some types of music software (eg soft synths) and probably some other types as well. Especially in games if you use native GUI components the result will look really cheap. Without knowing more about what type of app OP is planning to do it is impossible to say if using something that results in a native GUI or not is the best way to go.
For one it requires a reference and an object it can point to. If you need a pair of byte you end up with a pair of regerences to java.lang.Byte - using about ten times more memory.
I'm still considering what to do about auto_ptr/etc. in VS 2015. At the moment, I'm leaning towards nuking the binders and mem_fun family outright, which should be easy to do and easy to adapt to, while marking the other stuff as deprecated, for removal in the version afterwards.
When the queue seems empty, I just wait for a fixed period of time (0.1s). The writer thread looks like this: for (;;) { auto size = queue-&gt;get_size_approx() ; if (size == 0 ) { std::thread::sleep_for(100ms); } else { queue-&gt;debulk(size); } } 
I'm in favor of overloading here. It does introduce more rules but I find it much easier on the eyes and slightly easier to parse. That said, the old way is perfectly fine too.
N4230 seems pretty convenient (namespace A::B::C{} = namespace A{namespace B{namespace C{}}})
We will be stuck with C++98 for a while due to being stuck with msvc9 as one of our compilers. We target multiple versions of a proprietary platform with msvc and have to wait until a version has the msvc10+ runtime and then wait for us to stop supporting all the older versions. This is especially bothersome when we use more modern gcc's for Linux and msvc for Windows and can't use any of the cool features. We are also pretty much stuck with our fork of stlport because the devs didn't know better 10 years ago and built it into the binary interface (which we pretty much never break). We've been tempted to play some namespace trickery to allow compiler vendor stl and stlport to live side-by-side but it will be messy and no one has taken the time to do it. Yes, this all sounds bad, but these are all by products of decisions over 10 years ago when not everyone knew better. We've learned our lessons and the green field projects are following modern industry best practices. It helps that they don't have to support the proprietary platform since its being deprecated.
Removing things entirely before there's actually a published standard which has them removed seems a bit over-eager to me.
If I remember right, msvc doesn't yet support the attributes necessary for [[deprecated]].
You can do c++ on iOS, Mac, and Windows (classic style apps) **very easily**. On Mac and iOS, all the "native" APIs are Objective-C and you can mix C++ and Objective-C in the same file by naming the file with a .mm extension. On Windows the primary native APIs are in C so you're good there as well. .cc and you can mix them freely. Everything else is a bit trickier because you typically have to "bridge" or you have to select whether you're making a gui-based app or a game. Android APIs are primarily Java, and you can do what's called JNI bridging to go from C++ to Java and vice versa. But this is not very straightforward. Windows Phones used to be C\# only but since Windows Phone 8 allow you to use C++ ; however, here's the rub: C++ projects can typically only be "games" (with no native gui), and although you can bridge between c++ and c# for gui apps it's nearly impossible to do in practice. Also, there's no support for OpenGL, it's DirectX only. All of this is the same for "Windows 8" style (tile based) apps. If you're looking to make games, SDL is probably your best bet for most platforms. Directly using OpenGL is probably a bit better though. If you're looking to make gui-based apps, GTK will work on desktop platforms, but honestly I suggest sticking with native gui and "bridging" keep your app logic in c++. Whatever you do (games, apps, etc), follow "model view controller" principles and keep your "models" in c++ and your views in whatever native api / system the vendors suggest. For example Mac / iOS keep your UIs as XIB files with Objective-C based classes, for classic Windows keep your UIs as .rsrc files or build programmatically. None of this is necessarily easy, and 99% of the time you'll be writing more code this way than just "going with" what Apple / Microsoft / Google want you to when building apps, but you can make cross-platform apps and games in c++. It's just not as easy as drinking the kool-aid they give you.
Yeah, I was surprised when I first started writing serious C++ that the syntax wasn't already supported.
Looks pretty clean; any reason why you put it on sourceforge though? Their interface makes reading the source code via a web browser a poor experience.
I wrote it for my old project which lives on SF.net for very long time. So for my SF and Svn just works.
It's had ` __declspec(deprecated)` forever. Even if it can't do `[[deprecated]]` for whatever reason, standard library headers for a specific compiler are pretty much the most acceptable place for compiler-specific functionality possible.
Qt released a new license option for mobile devs to address exactly this issue just 1 or 2 weeks ago. I can't remember the details but they can easily be found. 
Android has the NDK, there's no need for bridging/JNI.
Plugging emacs. Evil mode is the best thing ever created, coming from Vim. 
I have updated all files to be individually licensed as the 3 clause BSD except the Dmitry Vjukov ones.
I think it's due to the floating point comparison. Try running the test with a double.
That makes no difference in this case; I updated the example though. This is one of the rare times when exact floating point comparison is appropriate.
Oh My... me thinks you need to read up on floating point values. http://ideone.com/8mwKak
According to this [answer](http://stackoverflow.com/questions/25668600/is-1-0-a-valid-output-from-stdgenerate-canonical) on SO, it is a bug *in the language*. Basically the standard describes the algorithm that an implementation should use in `generate_canonical` in order to obtain a random real number in the [0,1) range, but such algorithm might always output exactly 1.0 if your current round mode is not [round_toward_neg_infinity](http://en.cppreference.com/w/cpp/types/numeric_limits/float_round_style). Your bug is probably the same since every implementation uses `generate_canonical` to implement `uniform_real_distribution`.
Oh thanks, somehow I didn't find this SO post. This looks like the answer though.
Great find. I didn't find it as I searched for `uniform_real_distribution` but that question doesn't mention it. 
Ah the irony :p
Interesting. Is boost random affected? We've been having randomness issues with libc++ random &amp; I'm wondering if this was the cause.
&gt; Another consequence of the exact specification is that it's not true that every bit pattern that represents a value of the specified type in the specified range can be produced. Due to rounding, some values will never be produced and other values will be produced with more frequency than they should be. I agree with your first comment, but in my reading the standard does address the second point. In the description of generate_canonical, it says: "distributed as uniformly as possible." ~~When converting from some other type to the float range [0,1), you can't even theoretically generate a perfectly uniform distribution depending on the size of the types involved. This is true even ignoring rounding. "as uniform as possible" is the best we can hope for.~~ Oh I was really wrong.
Why are they removing random_shuffle?
If I remember correctly, floating point numbers are not uniformly distributed so there are pitfalls here. Not that the implementation wouldn't account for this, but I don't think the previous poster is entirely wrong.
Nice work. From the README: No ostreams (a very ugly part of C++ for my liking). Preach on! I couldn't agree more, especially for logging. See also my pul request with compile fixes for g++ 4.9.1.
It's explained in n4190: The two-argument overload because it is allowed to use std::rand, which is allowed to be crap, three-argument overload because it's useless due to very strange requirements for the RNG. std::shuffle has been around since C++11 and it makes a lot more sense.
You may be interested in the soon-to-be-proposed [Boost.BindLib](https://github.com/ned14/Boost.BindLib).
BTW, the queue you posted isn't suitable for a logger, as the author says it's not linearizable, this means that the data ordering is not guaranteed between all threads. This can be catastrophic when used with an asynchronous data logger (very fast producers, utterly slow consumer). Let's say you insert sequentially 10000 entries from two threads, the first thread inserts 10000 entries and then the second inserts 10000 entries more just after. Let's say that at the point that all the job is enqueued the writer could just write 900 entries to disk. This is a very realistic scenario. As cameron134/concurrentqueue is based in N parallel SPSC queues, one of the queues can still have 9100 pending entries to process and the other one 10000. The consumer/worker will try to pop N entries from each queue each time before switching to another queue (multiplexing queues). This would show very weird ordering in the log file and timestamps traveling back and forth in time.
That *is* the issue according to the SO post. The PRNG is simply generating a value so close to the maximum that it gets rounded to 1 when cast to float. It's not the 1 that can't be exactly represented, it's the random value generated (4294967257/4294967295) which gets compared to it. I'm not disputing that it's an error, mind you. It does say the value generated should be strictly less than the upper limit, so that guarantee ought to hold for all types.
Yeah there is some type of "indie" license but it is not free (although it is cheap if I am not mistaken)
[Infinite loop == undefined behavior](http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1528.htm).
While this is very interesting, it is not what is happening.
If I understand correctly, OP wrote a code that is equivalent to int main() { while (something_standard_says_is_always_true()) ; std::cout &lt;&lt; "Terminated."; } This is UB, and now, the compiler has the liberty to do whatever it wants, including writing "Terminated.", or "foo". I agree that OP is most probably right in his assumption that there is a bug, but saying that "Terminated." should not be written is wrong.
Cool, I really like this tool
Buy a Mac!!!! There you can run either CLang or GCC without a problem. Windows is really legacy hardware/software. 
Yes I would love that syntax. Doing namespace A{namespace B{namespace C{}}} Makes you wonder if you should indent each NS, and if you don't, then how do you close those NS's Something like }}} is kind of ugly.
Or just install Linux on your existing hardware and have a truly free choice of what to use?
Regarding building CEF, you need to first build Chrome, and then statically link that into your build of CEF. Both use ninja to build. You are right about the high resource requirements, though; IIRC you need 16GB of memory to build Chrome.
I didn't know it was still being developed. this is awesome!
IMO osx ofer the most pleasant way to write multiplatform code, the best of the two worlds, a little bit expensive but totally worth it.
I don't really agree. OSX is a pain to develop on in general (I write C++ on OSX for work). In fact any OS without a first class package manager is a pain to work on. That major plus of OSX is that it has *Nix under the surface and comes with a terminal emulator. But that shit is taken for granted on Linux. The downside of OSX is it's expense and the fact that it's UI generally sucks for developing (no built in tiling?). I just do most of my work in the terminal. 
I have just added a quick section in the readme on `ez::direct_iterator` vs `boost::counting_iterator`. They should be functionally identical, the only differences are that `counting_iterator` will work in C++98 but requires you to specialise a small template to work with custom types. If you're already using boost then I wouldn't change to this. It's a small case where you would need to use `counting_iterator` on a custom type and boost is likely tested more thoroughly. EZInterval is a bit of an experiment with syntax. I'd not seen anyone overload `operator()` and `operator[]` to mimic open/close notation before and wanted to see what could be done with it.
Many thanks - very informative!
You mean tmux style tiling?
Well anything like TMUX, DWM, i3, awesome, vim's windows, *even Windows* has snap to window, 50% fill.
Run it on a DEC Alpha... Super weak memory model, if it still works there you probably did it right... :) Possibly impractical advice....
VS2013 support only one feature of C++14. Take a look [here](http://blogs.msdn.com/b/vcblog/archive/2014/11/17/c-11-14-17-features-in-vs-2015-preview.aspx).
&gt; programming tools must be programmable Must the tools to program programming tools be programmable too?
You are correct. The SO post demonstrates this issue without a loop (and I could've done likewise by counting iterations and advancing the PRNG).
&gt; Support for MacOSX 10.8 and 10.9 is significantly improved relative to the 3.9.0 release.
That's the Core Language. VS 2013 supports several C++14 Standard Library features, including the `less&lt;&gt;` family of transparent operator functors, `make_unique&lt;T&gt;()`, and the `decay_t` family of type traits alias templates.
Yes. That seems to be a very involved process. I'm not sure if it's really 16GB (the official site mentions 4GB as the absolute minimum), but I definitely don't have that much memory.
My opinion is that sticking with the "main" compiler on a platform is not wrong. Where I work, we build for windows with MSVC, Linux with GCC and AIX with xlC. This is mostly for support reasons, not day-to-day work practical ones (IMO). E.g. I guess we could drop AIX without a hitch. Dropping MSVC for windows-specific stuff, much less so though. Overall, there's obviously a big split between the Windows and Unix lands. Unix land takes more care about being standard-compliant, but to be honest, I never felt that being a major issue with MSVC (that is, it has to be, but can be, worked around). You need to actively compile and test for all platforms you want to support, otherwise silly non-portable mistakes creep in. Don't think that using e.g. gcc will give you total portability - there's a lot of gcc-isms out there that aren't standard and might not be supported on other compilers. Last I looked, even high profile stuff like Linux kernel needed gcc-specific extensions to build (but then again, in Unix land compilers tend to follow gcc, so that's not a big issue). I don't get what you mean by "I ran into some issues with x64 and certain functions (std::stoi, std::to_string) as well as support for certain exception models." (curious for detail).
I hope you're exaggerating but yeah, can't wait to try it!
&gt; I don't get what you mean by "I ran into some issues with x64 and certain functions (std::stoi, std::to_string) as well as support for certain exception models." (curious for detail). I can't remember exactly what it was about x64, but the problems with the string functions seem to be related to how string is implemented in mingw. Those particular functions just don't exist, despite beeing part of the STL. mingw-w64 doesn't have that problem. Some people say newer versions of mingw's gcc fix that but I don't think that is true. The exception models aren't a problem per se, just that support and implementation seem to vary, especially between mingw and mingw-w64. SEH seems to be the only zero-overhead model, while DW2 doesn't seem to exist on x64. While I don't really care about the specifics it is my understanding that the models have to match between linked code, which makes creating/using precompiled binaries for libraries even harder. For example SFML provides binaries for several versions of VS, mingw and gcc-tdm. I stil have no idea how gcc-tdm is related to mingw and whether or not it is mingw or mingw-w64, or how it is compatible to anything. But their x64 builds are limited to SJLJ. So compiling them myself was the only choice in the end.
I imagine once you know what you are doing with the ninja build system, its not so bad.
Doesn't look very secure. Wouldn't trust that code with anything sensitive.
Fuuuuuuuu.... The same day that I update to Mac OS X 10.10. Awesome timing by me.
Aww thats so sad I work with this all the time
&gt;models have to match between linked code The state of both C and C++ has been that there's no support for mix-and match between implementations. Neither C nor C++ languages know anything about binary compatibility and the author is obliged to provide it. That normally means resorting to a C interface (ABI is doable with C because of the lack of options 😉) or providing an implementation-specific build of a library (which is what you have seen). To my mind, this is the normal state of affairs. People who want an ABI need to reach for aim integration tech (e.g. COM under Windows), or wait for the standardization to take place (I personally think, while it could be useful , there's no hurry 😉). (People asking for ABI with C or C++ are a pet peeve of mine 😉).
The "funniest" part is when two **versions** of the same compiler are not compatible because they generate different padding in structs. People want ABI compatibility, because building a c++ lib require quite much infrastructure and building large code base is extremely slow. 
Does this support Yosemite? Seems not very likely since only minor version is incremented.
Botan is the go to library for cryptography for me. Easily extendable and well documented. I stopped using cryptopp because the code is hard to read, it throws a lot of compile time warnings, and the license is a mess.
Note that both g++ and clang++ are happy if you name the argument (`auto&amp;&amp;...unused`). You probably want to use this as a workaround. I fully agree that this is a bug in gcc and clang; I can't see anything in the bug trackers so you might want to file new bugs; because of the workaround it might not be a particularly high priority.
This is a grammar issue rather than an actual bug. It's a small gotcha that has to do with `va_args` rather than template parameter packs. So that being said: void f(int...); // equivalent to void f(int, ...); Likewise.. [](auto&amp;&amp;...) { return 123; }; // equivalent to [](auto&amp;&amp;, ...) { return 123; }; This is what allows the funny quirk of 6 periods: template&lt;typename... Args&gt; void f(Args&amp;&amp;......) { } // equivalent to template&lt;typename... Args&gt; void f(Args&amp;&amp;..., ...) { } Here's an [old blog post on the six dots thing](http://lbrandy.com/blog/2013/02/c11s-six-dots/) that might be relevant.
You're right; the relevant language is in §8.3.5/4 of the standard: &gt; Where syntactically correct and where “ ... ” is not part of an abstract-declarator, “ , ... ” is synonymous with “ ... ”. In the case (say) `auto f = [](int...) {}` I think you're right, since the `...` are not part of the abstract-declarator `int`. However, in generic lambdas `auto` has a special meaning, specified in §5.1.2/5, which states that `auto...` translates into a parameter pack, and is therefore an abstract-declarator. [scatters](https://www.reddit.com/r/cpp/comments/2nkcvi/generic_lambda_inconsistency/cmed8zw)'s observation makes sense here--naming the parameter disambiguates the declaration.
This (and all other mailings from this year) sorted after subgroups: http://meetingcpp.com/index.php/cpp-proposals-by-mailing-and-subgroup-for-2014.html#mailing2014-11
Is there a longer term solution here? Perhaps a warning should be given, advising the developer to give the variable a name (if they want a modern 'pack' parameter), or insert a comma just before the `...` (if they want old school va-args). Does this cover everything, giving us a straightforward way to disambiguate everything? (Darn, I remember now that I was struggling with empty parameters packs a couple of years ago. I think I know know what was wrong!) The compiler can "rewrite" `,...` as `...` on occasion, but it is not allowed to do the reverse? Perhaps my real question is whether the compiler is allowed to interpret this: template&lt;typename... Args&gt; void f(Args&amp;&amp; , ...) { } // obviously "intended" as an old va_arg (with a single (non-pack) arg in the first position as template&lt;typename... Args&gt; void f(Args&amp;&amp; ...) { } // now (mis) interpreted as a parameter pack In short, can we say that a `...` which is *not* preceded by a comma and which is *not* succedded a parameter name is (potentially) subject to unintuitive interpretation? And that we can easily disambiguate by adding a comma or parameter name? (But I assume a comma *and* a parameter name will not be valid?)
I think my main problem is that I don't like saying that `,...` and `...` are synonymous. The 'direction' is ambiguous. I would prefer to say that (under certain circumstances) `...` can be (or *must* be) rewritten as `,...` , and that rewriting in the other direction is not allowed - a comma before a `...` means that it is va_arg and that will always be respected. &gt; I still believe that gcc and clang have a parsing bug, and they should accept auto... as a parameter pack. Aha. So there are situations where gcc and clang (incorrectly) rewrite `auto...` as `auto,...`? Maybe I could ask some further high-level clarifications. I feel a bit repetitive, but I'm just trying to straighten out my thoughts here: 1. A `...` which is preceded by a comma, i.e. `,...` is treated as a va_arg in the standard. 2. All compilers correctly implement (1.) 3. A `...` which is *not* preceded by a comma, and which is succeeded by a parameter name, is a pack according to the standard 4. All compilers correctly implement (3.) 5. A `...` which has neither a comma before nor a parameter name after is complex. The standard requires packs in some cases, and va_args in others. 6. MSVC seems to do (5.) correctly 7. gcc/clang do (5.) incorrectly Are these correct?
That list looks accurate, yes. I'd like a language lawyer to provide some confirmation on 5. though.