&gt; Unless it is built into the VM you need to go through JNI. You're missing VM bypass. &gt;And if it is built into the VM and just pretending to be exactly like Java's TCP/IP sockets then you can't get the highest performance from it. RDMA, and zero-copy I/O in general, doesn't work this way. TCP/IP are just protocols that control the exchange of messages between two end points. RDMA is completely independent of that. It's simply a way to go from application --&gt; NIC directly, without needing to copy the buffer into kernel space, and then into the NIC. &gt;I think the point some of us are trying to make is that the JVM for all its advantages does not make it easy to hook up to an unknown C API without performance hits. It is just easier to do in C++. That is one of the trade-offs - you get more flexibility in C++ especially with calling into C APIs but also suffer from most(all?) of C's issues. This isn't true, either. Hardware is accessed via system calls. The JVM can make system calls on the host machine, and the Java applications can make calls on the JVM. Using JVM Bypass, the application can make the system calls on the host machine directly. Honestly, the rest of your post isn't really worth reading. Don't take that as an attack on you, but you don't seem to understand the basics of operating systems and compilers in general. You've got some reading to do. 
If the IFC format is both complete and documented, would this mean that you could parse it to get reflection data for classes and functions? Because that would be really great, doubly so if different compilers will standardize on the same format. Currently we are using libclang for this, but it requires compiling all reflected code twice (once with libclang, once during the actual compile) and is a hassle for the build process.
Even for a casual observer I have to say you seemed to have hit the bullseye here. For want ever reason professional programmers (not just C++ programmers) do look down on web developers. 
I don't think you understand. Can you point me to the VM bypass spec for standard Java that allows you to do RDMA? I know how RDMA works. One of the only links I have seen for it are on IBM's JVM where it pretends to be TCP.. Also yes you access them via system calls but I don't know of any standard (not your own JVM) that can make arbitrary over head free system calls or control arbitrary hardware via user space calls either. Your ad hominem attacks do little to establish your credentials. Can you point me to any specific things I've gotten wrong? I've been working on using Unsafe from Java for a while now and I've seen the extensive usage of unsafe in Cassandra and other similar projects. Everything I've said about the JVM (jitter through GC, opt-deopt cycles, unpredictable safe points) is true. Your tactic to resort to personal attacks only demonstrates your lack of valid points. Have a good day, it's clear you don't want to have a civil discussion. Don't take it personally though...
Do the perceived performance benefits truly justify this complexity? 
CMake can make projects for the latest VS (2015).
So basically he is listing rules for enforcing type/bound/lifetime safety which can for example for implemented by static analyzers eg. Visual Studio's static analyzer as showed in the presentation. I am actually asking myself if this is possible with the current state of clang's static analyzer ? I had that feeling that the presentation was more focused on tools by Microsoft rather than relying on open-source implementations...
Try /r/cpp_questions.
Yeah, they really do. Schedulers like these usually run tasks which generate many subtasks - those that would be hard to effectively parallelize any other way. If creating a subtask is too expensive, there isn't really a point in using such a system. In addition, avoiding locks can help to not get descheduled, although in this case it looks like the critical sections are small enough for that to not be an issue.
&gt; Visual Studio Solutions are mostly useless for anything but visual studio users. Not to mention that by accepting this patches into an open source project the maintainers will have to consider their ability to continually support them. I've seen this in at least one fairly active project, where it had several different OS specific build files ( VS, XCode, etc ) and you find some of them are out of step or just down right broken.
You will suffer for you previous debauchery and in the light of an thousand unique_pointer correctly deleted punters shall your sins me washed away but never forgiven. ;)
I think he means that you'll have better luck finding help at that sub. This one is mainly for CPP related news and commentary.
What is the point of ´owner&lt;&gt;´ given that we have ´unique_ptr&lt;&gt;´ and ´shared_ptr&lt;&gt;´? It looks like it defines a bunch of operator overloads for ´not_null&lt;&gt;´ immediately under a comment that says "TODO ensure all arithmetic ops on this type are unavailable." Why would you declare them if you want them to be unavailable?
when `std::variant` comes out you will be able to
CMake is probably the best open source C and C++ build system currently in existence, if for no other reason than being able to target so many different things (GNU Makefiles, VS, Eclipse, Xcode, etc). Nothing wrong with being a CMake boy.
When publishing your own projects don't bother trying to publish any makefiles or build configs you haven't tested. Just put out what you've tested and leave it to others to figure out where else they can use the code. You could do your Windows development using CMake, which will allow you to generate VS project files and others to generate makefiles on Linux. Of course it's possible to have a CMake build that works on Windows with VS but doesn't work on other platforms, so it still requires testing to say you're really supporting other platforms. However at the very least it's probably easier for people to convert a CMakeLists.txt file that's broken on their platform to one that works than it is for them to write a makefile from scratch based on your VS project files. For contributing to projects that use makefiles, Visual Studio does allow you to create a 'makefile' project but it bypasses many visual studio features and takes a bit of care and babying in order to get Visual Studio to seem like it has some semblance of understanding of the project's source. https://msdn.microsoft.com/en-us/library/txcwa2xx.aspx The make tool used by VS isn't perfectly compatible with GNU make so you may have to do some work anyway just to get the project building this way. Overall you may just be better off learning to work on such projects in the environment the project developers expect.
Like `vector&lt;unique_ptr&lt;AbstractFactory&gt; &gt;` ? See [factory pattern](https://en.wikibooks.org/wiki/C%2B%2B_Programming/Code/Design_Patterns#Factory).
And did you try to get some options out of the Makefile? There could also be some symbols defined, etc.
In C++ a collection of types would be operated on via templates. For example in C++98 people manually implemented "type lists" in templates. Now with variadic templates they're effectively built-in. On the other hand, in C++ you probably wouldn't represent different kinds of game items using different types. You'd probably have a single type that could hold data representing what kind of game object any particular instance is. Then the program would load up data for all different kinds of objects into an array or something. A function returning a random kind of object would be done by picking randomly from an array of data for the different possible kinds of game objects.
This is what I meant by having to use switch statements on a variable. It's not hard to do, but it's not as clean as just passing a bunch of types you'd like to consider for spawning. void func(using Types[]) { int random = GetRandomInt(0, Types.length()); Spawn(Types[random]); } In this case Types is an array holding a bunch of class types. From which I can select one at random to spawn. The factory pattern is a roundabout way of achieving this.
The problem with passing types directly right now is that they must be done so at compile time which wouldn't make it fit for this purpose (selecting a type at runtime - factory can do this, but is a roundabout method to what I had in mind). In UE4's blueprint I can do the equivalent of Types[5] to select a class at runtime.
Like other people mentioned, CMake to create Visual Studio project on Windows, but still being able to build on other system. If you push on github, you can try [SourceTree.](https://www.sourcetreeapp.com/) Try also to link your account with [travis](https://travis-ci.org/) or [drone.io](https://drone.io/) to build your project on linux if you don't have a build system (but you may want to configure your cmake in your vm first, try to install virtualbox + vagrant for a quick VM)
I don't understand your question, but you can pass around types in a way, even in C. You can just store function pointers to creation functions, and you can hide this relatively effectively. At work I've written a factory pattern that allows construction of any type like this: type* obj = factory::construct( id_of&lt;type&gt;::value, 1, 2, 3, 4 ); and internally this looks up the constructor function in a map, casts it to the appropriate type, and calls it, then casts the return type. The construction functions are stored as functors std::map&lt;size_t, construction_function&gt; where `construction_function` is functionally equivalent to a void*, but has a vtable for dynamic casting. Construction looks roughly like this (in pseudo code) template&lt;Arguments...&gt; construct( size_t id, Arguments... args ) { construction_functor* f = dynamic_cast&lt; typeof(args)&gt;( functor_map_[id] ); if( !f ) return nullptr; return f( forward(args) ); } And there's convenience code to register types that register types through static object instantiation: struct A { A( int a, float b ) : m_a(a), m_b(b) {} }; factory::register_type&lt;0x1234,A,int,float&gt; constructor_of_A; This could then be used like this: A* obj = factory::construct&lt;A&gt;( 1, 3.14); And there's an alternative version like this: id_of_type = 0x1234; A* obj = factory::construct&lt;&gt;( id_of_type, 1, 3.14 ); This code goes back to C++98 originally, and the variadic template arguments originally were implemented by writing a template class which accepted 20 arguments at most, and all const-qualified combinations. I'm sure there would have been a better way even back then I just didn't think about. Now a few thousand lines of (generated) code representing the powerset of 20 parameters with 2 forms (const&amp;, &amp;), so about 1600 objects, has been replaced with about 10 lines of code that compile a hell of a lot faster.
Use a map or a vector to store builders. The key could be a string, an enum, etc... [example with a map,](http://cpp.sh/5da2) but a vector would be better if you want to use a random int as an index.
If you read things properly instead of resorting to your first instinct of being belligerent, maybe we can have a conversation. No I did not conflate TCP and RDMA. Please read the following very carefully: i) Standard Java has a BSD socket like api with read(), write() calls working on individual sockets. So when you use virtualization, VM bypass etc to use an alternate implementation for your network stack, you are still restricted to the read(), write() calls that standard Java provides you. You can intercept these calls and use alternate implementations but that DOES NOT mean that you can use other interfaces without resorting to JNI or building your own JVM where said interface is built in natively. ii) A BSD socket like API over RDMA is NOT the most efficient way to use RDMA. Why? Because you still have to make many system calls (even with VM bypass). Each individual socket requires its own read, write calls. When you are working with a large amount of data these calls become a problem. So how is C/C++ any better? For a high performance network stack, one alternative approach to the BSD socket api is to use batch calls to amortize system call over heads. Another approach is to not go through the OS at all and have a complete user space implementation (with custom drivers etc). Neither of these approaches are possible with Java easily. Read https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/201408-sigcomm2014-specialization.pdf for such an approach.. Please read the whole thing if you haven't already. The interfaces used by such alternate stacks specialize for your work load. For example if you are serving files you prepare the actual packets from before and before sending them to the NIC you just modify some of the headers (destination, sequence, checksum etc). So there is very very little work to be done in steady state. Similarly when reading data from clients, you directly read a bunch of packets instead of doing individual read calls for each connection. If you take longer to process the packets, you naturally get more packets in the next batch. Simple read() calls available in Java (VM bypass or otherwise) just don't have the same semantics. So you cannot get the same performance even though your network stack is capable of doing TCP over RDMA. You cannot get these custom interfaces in Java with or without VM bypass, unless you use JNI or unless you have your own custom non-standard build of the JVM. I don't think I ever argued that C++ code does not have to make system calls. You seem to have a habit of drawing your own conclusions and then retorting those. When I said arbitrary over head free system calls the over head I was talking about JNI, not the call into the VM. Want more examples? recvmmsg() and sendmmsg() calls that are available in Linux as of today (without custom network drivers) CANNOT be accessed from the JVM without JNI. They can be called from C/C++ with regular system call over heads. But you cannot access these system calls from the JVM without using JNI and VM bypass does not help you because there is no way for std java to make these calls at all. Just to belabor the point even further a lot of the efficiency of these custom stacks, comes from being able to define better APIs that handle multiple packets instead of trying to make the BSD socket api faster (DMA or just a better written implementation). If you had actually bothered to read the rest of my post on how the JVM's lack of ease when writing cache efficient data structures makes it very difficult to even saturate the packet processing abilities of these custom stacks, then I wouldn't have had to repeat it again. But here we go - When it comes to big files/messages, even the standard TCP stack is good enough. But the real the torture test is lots of small messages being sent over the network. . You typically have 2 cache misses odd to process a packet at the top end. If you are using Java without resorting to sun.misc.Unsafe, there is no way to even do this and if you do use sub.misc.Unsafe then your code is much less maintainable than similar C/C++. The JVM is also not capable of optimizing unsafe code as well as it does with safe code. Some examples of these kinds of problems can be found here - http://psy-lob-saw.blogspot.com/2014/11/the-mythical-modulo-mask.html
[Quick hack](http://coliru.stacked-crooked.com/a/75f902100cd5feca) Use `select_random&lt;B, D1, D2, D3&gt;(rng)` to get a `unique_ptr&lt;B&gt;` to a new heap-allocated, default-initialized object of one of the types `D1`, `D2`, `D3`, picked at random using the generator `rng`.
I wish I could, but I actually don't use Visual Studio anymore and as a result don't have the configuration anymore. Fortunately, I bookmarked the page that I used to set it up in the first place! [Here it is.](https://www.chromium.org/developers/how-tos/visualstudio-tricks) You'll have to fiddle with that for a bit until you get it working. Hope that helps.
&gt; Should I install a Windows port of their make system, or try to create an empty Visual Studio project myself and try to insert their source files into it and recompile? Both your questions have the same root cause - there's no basic build setup that's common to all C++ developers. On one hand you want to export so others can use, on the other hand you want to import others' work and continue with it. Best thing you can do is make sure that it's *very* clear what you need to do to use your software, and to keep that list of special-cases as small as possible. Adding that software - even if it's 9000 files large - to any build system is trivial. Inversely, having a 500-file project that requires these definitions here, these there, conditional compilation, excluding a few files here &amp; there, ... that's a nightmare. Most big projects actually are a nightmare in this definition. I've tried to make a clean import of OpenSSL and it's littered with test cases &amp; "source file only for platform X or Y" things. You basically need to cherrypick the entire project for what you want, or use their build system. If it exists for your platform. Otherwise, you're fucked.
&gt;How do I use unique_ptr and shared_ptr on C++98? You stop using C++98.
Sure, i'll just wave my magic wand and upgrade all of the C++98 compilers in the wild to C++11 ones.
This is pretty much how every other build master I've talked to feel. We all want the customization options CMake gives to use, but none of us actually like CMake itself. I'm planning to take my Senior year to work on some tooling around Build Systems and CI to make it a bit better, at least for me personally.
[Image](http://imgs.xkcd.com/comics/standards.png) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini-USB. Or is it micro-USB? Shit. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 2012 times, representing 2.4139% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cvf4llj)
No... Just no.
Boost has C++98-compatible versions of both.
For one it uses the correct namespace. Then it's just dead simple, all the functions are 1 or 2 lines and there are no real implementation details.
Some people don't want to use Boost though its a pretty heavy library which is hard to audit and some of the things it contains encourage a really horrible way of writing code.
Gotta have that signed type to index into a `vector`!
I've used the smart pointers of Boost 1.51 with VC6 by extracting them with a [bcp command](http://www.boost.org/doc/libs/1_59_0/tools/bcp/doc/html/index.html) like: &gt;C:\Libraries\boost\boost_1_51&gt;bin\bcp scoped_ptr.hpp shared_ptr.hpp weak_ptr.hpp make_shared.hpp C:\Libraries\boost-shared_ptr 
For the OP: `std::variant` / `boost::variant` internally do a switch over the type list in the variant. You use a `static_visitor` class to provide `operator()` overloads for each variant type and these are expanded by the `apply_visitor` function. Since you never write out the switch / if-else statements yourself, it makes for much more readable code! And it doesn't require the types to have a common base class; this is all handled for you.
gcc
You sir are an idiot and clearly know nothing. I have clearly wasted my time on a troll. Even if you extend the Java socket class, it still works on a single socket you moron. Why are you so thick? If you extend the socket API in Java with your own socket, that does not mean you can change the signature of the read call or the write call. It is still called on a single socket object at a time. All you can just provide a different implementation with the same signature. Have you ever written any code ever (OOP or otherwise)? I see that when you know that you don't have any points you resort to insults. Nice try buddy - maybe write some real code for a change. Maybe send a little gist on how you can transform the Java socket API with your non-existent OOP skills to work on the abstraction of batch packets instead of individual read(), write() calls on sockets. Once you are done failing on that, show me exactly how you'd emit corresponding system calls from Java that accept batches of packets. Your lack of comprehension skills is again alarming but not surprising. Why do you keep harping on irrelevant points. Can you read? Let me know how you plan to do a recvmmsg() or sendmmsg() from Java with VM bypass alone. What the heck are you going to even call from Java that you expect your VM bypass to intercept. I don't even know why you posted the socket api link when I told you that the socket is the wrong abstraction for batch calls. I am again wasting my time, seeing that you don't have any intention of actually learning anything. Read and write calls absolutely have to map to individual calls, Linux socket implementation or otherwise. You call read on each socket, your alternate implementation intercepts these calls and uses its own implementation instead of delegating to the kernel. This is completely orthogonal to pinning pages and has nothing to do with it. If your DMA engine needs you to pin pages you can do that ahead of time. It does not need to be done on every packet processing call. Step 1: Pin your buffers. Step 2: Use batch calls. So you can do your little system calls up front and never have to go through the OS again. I've realized that your writing is characterized by ignorance, stubbornness and irrelevant cavalier links strewn all over in a last ditch effort to prove that you actually know anything at all. &gt;Reads and writes easily get mapped to lower-level API functions such as Infiniband verbs. Have you even read what you posted or did you just google for something and send it over? &gt;In this paper, we propose a Java application interface on InfiniBand network, named Jdib, which provides a viable approach for Java applications to use RDMA semantics directly. Most functions in InfiniBand Verbs are implemented in Jdib, which provides the feasibility of building high-performance cluster applications in Java. Further, a JNIO-based mechanism is used to get rid of extra data copy between JVM buffers and OS buffers, and an optimized method is proposed for sharing data structures between Java code and native code. The experimental evaluation demonstrates performance improvements using Jdib. Did I just read "**a JNIO-based mechanism is used**"? Sorry you lose again. &gt;I'm honestly not even going to bother reading the rest of your drivel. Translation - I don't know how ByteBuffers in Java work and what the problems with them are. I don't know anything about high performance packet processing and what kind of data structures are needed to be able to drive at line rate. I have no idea how the JIT works and how safepoints and deopt cycles and lock biasing can cause unpredictable jitter. I don't have any idea about what you are talking about, but I'll try to hide my inadequacies by making some personal attacks instead of reading up on the inner workings of the JVM. Not wasting my time on you any more. It is very clear just from your ignorant statement about how you can extend the socket API to completely change its semantics that you have actually never written any code. Please go back to hiding under whatever bridge you crawled out from because I am done feeding your troll self.
I will second this. Windows is a second-class citizen in most open-source projects, getting a build to work is a very frustrating experience, even for projects which support windows (having tried to do it a few times, with a pretty low success rate).
Thanks for the reply. I guess C++ is what I brought up because it's what I'm familiar with and have hobbyist experience with. That being said, I would have no problem getting into something like Java, I just feel like there would be more of a learning curve. I do feel overwhelmed with how much the standards and best practices change. What are some good sources for up to date standards? I have partially read Effective C++, Effective STL and Modern C++ Design, but would you say even those classics are showing their age? I'm familiar with some of the boost library like shared/smart pointers. How does someone who isn't writing C++ everyday professionally stay on top of the best practices and changes?
I kind of feel the same, but it's in conflict with my feeling of "Will he actually succeed this time?" All build systems are shit, CMake is just one of the few that smell the least. We need one that smells even less while still giving full control to the person writing the definitions.
&gt; Don't do your c++ in Visual Studio, since almost no-one does open source stuff with it (or on windows). Open-source development is done on Linux, with gcc (or clang nowadays is also an option). Let's not conflate "ease of contribution by others" with "open-source". Yes, CMakeLists will lower the barrier to contributions compared to a VS solution file (or an Xcode project file for that matter) but the tools one uses to produce code has absolutely no bearing on its open-sourced-ness, only its [LICENSE](http://opensource.org/licenses) file does that. There's plenty of commercial software, Windows-exclusive or cross-platform, that makes use of open-source code. Sweeping generalizations about how open-source code writers and users operate don't help. I'm afraid your statement (and its underlying attitude) is *detrimental* to the open-source world. 
Thanks for linking the umpteenth paper behind a pay wall, moron. &gt;LOL. You've never heard of overloading, dude? LOLOLOL. "The Java programming language supports overloading methods, and Java can distinguish between methods with different method signatures. This means that methods within a class can have the same name if they have different parameter lists" Wow you complete idiot. Do you understand that if you extend the socket class and make some alternate API it still by definition works on a single socket at a time? Also you still need to emit a system call for VM bypass to actually intercept. Please tell me how you will emit a corresponding system call with completely different semantics (batch apis) that your kernel bypass library can actually intercept on a standard JVM? Specifically tell me how you will emit a **recvmmsg()** or **sendmmsg()** call by overloading the socket class? If you cannot especially with example code, then stop replying. Your extended Java code actually needs to do something, you fool. Kernel bypass cannot transform your call magically through osmosis without you actually emitting something that it can intercept. Please tell me how you plan to get your standard JVM to emit anything but read(), write() calls? &gt;Actually I'm talking system calls, because you said socket implementations require too many system calls. That is not correct. Even RDMA requires system calls, both to pin/unpin memory pages, and to tell the damned drivers that the data is ready to be sent. RDMA is just a way to avoid copies, not system calls. You need to read so that you don't show your ignorance even more. The precise reason that batch APIs (not BSD socket like) are used by high performance systems is that you make a single system call to process multiple packets, thus amortizing the system call overhead. If you make multiple read() and write() calls then RDMA helps you only so much since you are still paying for the system calls. If you had bothered to read the paper I linked (it is not behind a pay wall) you'd see the kind of APIs they use. And of course given that you have never written high performance Java ever, you have no idea about the things I just mentioned regarding JVM introduced jitter and memory layout issues in Java. 
So, before I debunk this, first do you now admit that 1) you were wrong about JNIO having anything to do with JNI; and 2) you were wrong about JVM bypass having anything to do with JNI; and 3) You can overload functions in Java allowing two functions to have the same name but with different signatures? These three questions will give some indication as to whether or not you're arguing in good-faith or if you're just trying to avoid publicly admitting you've been wrong. 
I'm always confused by Sean's talks. For the stable partition example, wouldn't it be fastest to first find the number of elements in the two groups, and then copy elements one by one into the correct groups? This would be 2n accesses and n copies, all completely linear and cache friendly. Meanwhile, (as far as I can tell) Sean's algorithm is going to be doing n*log(n) copies, with log(n) allocations. Sean's algorithm might save you a couple lines of code (possibly?), but it takes longer to understand. Am I missing something here?
can't upvote this enough. however i'm not super keen on trying to design around the epic lunacy of the windows object system (release, debug, MT or not, etc). i think visual studio compatibility will suck no matter what, in big part because of how MS designed the whole mess, and how they intentionally did not want interoperability with anyone else for a very long time.
`std::stable_partition` is an in-place operation, so instead of copying you would be swapping, which would lead to the result being non-stable.
Thanks; So, version 4.4.7 doesn't recognize command line option "-std=c++03". Try building using the command line in folder ./test: &gt;g++ -I../include/ -Dgsl_FEATURE_THROW_ON_FAILURE=1 -o gsl-lite.t.exe gsl-lite.t.cpp owner.t.cpp not_null.t.cpp &amp;&amp; gsl-lite.t.exe --pass 
Yes, it's harder on Windows. And people are often turned away from some good software just because Windows tries to be a special case.
&gt; I've updated the CMake files to not use -std=c++NN for g++ before version 4.8. 
His words like 'non-GUI console application' sound like the echo of the old myths about the impossibility of the cross-platform GUI.
Just like the actual GSL? If you've got what you think are improvements why not submit a pull request?
Yeah I realised that what I wanted probably wouldn't happen because of the reasons you outlined. Given your example I could probably use a recursive variadic that stops randomly like another user suggested.
1. depends upon the app. For command line apps for Mac or Linux I'd suggest going simple and hopefully compatible with what ships in all of those systems. Make is nice no doubt but it is often a separate install. Obviously what you do depends upon the complexity of your app, but good command line tools should have a minimal of external requirements. 2. Seriously step away from Visual Studio and embrace development techniques common on Linux. I say this knowing full well just how nice Visual Studio can be. 
I have the same issue with Eclipse, it does not understand gcc extensions, and most notably `__attribute__((noreturn))` so bothers you about ending your `case` with a `break` or your function not always returning a value even though the path will unconditionally throw/abort...
Why on earth preferably Ubuntu? I used to do Ubuntu but couldn't stick around after their swap to gnome3 with all that unity stuff (I think it was named unity? ). Swapped to debian with xfce and love it. But that's not the point, I'm genuinely curious why you would recommend a specific dist for Open source dev.
&gt; an array_view is a copy of the data It's a _view_, not a copy, as the name suggests. It doesn't copy anything. I also don't see the relevance of code you posted. I do agree about using the unit tests though.
If you want a concrete example to look at, see [MetadataMap.h](https://github.com/openmicroscopy/bioformats/blob/develop/cpp/lib/ome/bioformats/MetadataMap.h) and [unit tests](https://github.com/openmicroscopy/bioformats/blob/develop/cpp/test/ome-bioformats/metadatamap.cpp). This header defines a map of `string` key to `variant` value where the value is either a simple type (`int`/`uint`/`string`/`bool`) or a `vector` of one of those types. It defines some simple `static_visitor` types to process the variant and then uses `apply_visitor` to use them. It might provide some ideas!
Even Microsoft on github use CMake : https://github.com/Microsoft/GSL
It's very reasonable to have a learning curve. I think I personally suffer from a wanting to find out "what's the best way to go about this", and for CMake I haven't really found an accessible guide for that. A bizzare complaint I also had with trying to get into Javascript since there's just a boatload of stuff with many differing opinions. It's just some learning I'll have to do.
maybe it's because array_view is supposed to support multi-dimensional arrays?
&gt;Read what I wrote, you idiot: See that asterisk next to your comment? That means you edited your comment. You didn't say anything about batching of system calls, and you know it. You flat out said they don't use Linux system calls. What a farce. &gt;The batch packet processing facilities available through UIO are not available through those syscalls. Now you're starting to get it. The batching is done purely in user-space, right? The JVM, and the Java applications that run on it, are use-space code. There's nothing that's stopping Java applications, or the JVM, from batching system calls. In fact, [VMWare](https://www.vmware.com/files/pdf/techpaper/VMW-Tuning-Latency-Sensitive-Workloads.pdf) shows how they can configure the JVM, and other VM technologies, to do these kinds of things, such as interrupt coalescing and sys call batching. Nothing in the paper you posted is *unique to C/C++*, which is really what we're arguing here. Let's summarize the things you've been wrong about: 1) JNI != JNIO. 2) The userspace networking paper you posted also uses standard Linux system calls, in particular, the read and write calls.. the very same read and write calls you said were inefficient. 3) JNIO can interact with the device drivers directly, without having to rely purely on file descriptors. 4) System call batching isn't a unique capability for C/C++. Pretty much any language can use these techniques. 5) Methods in Java can be overloaded. You can have the same method name with different parameters, i.e., signatures. You really are a huge ignoramus. My guess is you do something along the lines of Web development. Stick to javascript and php, dude. Systems work is beyond your capabilities. 
Good point. In the case of libstdc++, it allocates a temporary buffer to store the elements for which the predicate returns false. It moves the elements for which the predicate returns true to the beginning of the original range. The elements that returned false are then moved from the temporary buffer back to the end of the original range.
Oh my God, finally! I was wondering when you'd finally wave that stupid wand and get rid of these horrible pre-C++11 compilers.
Maybe, but the standards proposal got rejected, so I'm not sure if that should go into the GSL.
I think this is a fair criticism, and I can certainly relate to it from my initial forays into converting a project to cmake. While each function is documented, it's often difficult to know the bigger picture such as which are appropriate to use for which purpose, even just finding what you need, and how to structure a project. I certainly looked through other projects to get tips on how to do things (or not to do them--there's also quite a few people getting it wrong!) That said, there's a CMake book you can buy which might have a better overview of some of this stuff; I should probably invest in a copy for myself!
u/mattbas - what's the difference between the string_view in the gsl and the string_view going into the standard lib?
I am weird (or maybe not so weird actually) in that once I am interested I can usually focus... and if I am really interested I get tunnel vision focus. The issue I have is sparking that interest. Edit: When I said "once I am interested I can usually focus" I meant it as 'focus like a normal person'. This does not mean I have ultra focus- but it does seem like it to me. When I can interested I can think "I want to do this" and usually I can. I still have to actively focus... but luckily it zaps my teleportation superpower (when I am sitting at my computer one second and then the next I am upside down, in a handstand, 300 feet away wondering how I got there.)
The best short book for C++ is Accelerated C++. 
I have ADD, I take medicine for it (currently in the middle of finding the right one, trying Adderall, but I took Adderall and Ritalin as a kid). For me, it's best to do bursts in any programming that I do, no matter the language(Python's my main language, but I do cpp on the side). Like /u/nocookieforu said, the best option for me is to break it up into smaller portions. This may seem like a bit more work up front, but it always saves me in the long run because I don't get lost and have to backtrack a fuck ton. That, and getting up around every 45 minutes, walking around for 5 minutes, stretching, thinking about what I just did and why I did it, that always helps. C++ has always been hard for me because of attention, it's definitely a much more complex language than most other languages. Oh, and Spotify hacking/coding/programming playlists - USE THEM, they help SO much with focus. Most of the songs don't have words, so they distract you WAY LESS. It may take a while to get used to, but it's just as helpful as the Adderall. Best of luck. 
I got ADHD and I really enjoyed reading [Problem Solving with C++](http://www.amazon.com/Problem-Solving-C-8th-Edition/dp/0132162733) 
Everyone's like that to a degree. Discipline is a skill you'll have to develop - do yourself a favor and do it now. Or be like me and figure it out at 25 and be in a world of hurt. Doesn't really matter to the planet in the long run. It matters for you, though. One thing that's helped me is to not sit as much as possible. Obviously it's unavoidable, but I can literally feel myself losing focus on important things when I'm sitting. A standing workstation is a great alternative that doesn't have any barrier of entry higher than stacking boxes/books on your desk to elevate your stuff.
I am the same way, I will read something, be like I follow it. Go to write my own stuff and be like nope, nope, nope. Primarily just go and try stuff on your own, when it doesn't compile, google the error code and figure out why. I learned more by jumping in than trying to learn something then apply it. (I haven't been diagnosed with ADD/ADHD or anything, but then again I never went in to get it checked)
Try to use TDD (Test Driven Development). One of it's aims is shorten the cycles.
I totally agree, and therefore still stand by my opinion that in order to do so (writing semantically correct, machine-independent code), one should know about memory models, sequential consistency, and the semantics involved. Just like I think one should know about the underlying implications of virtual functions, lambdas, STL data structures, and other higher level constructs before blindly applying/using them. I hope me and my posts don't come across as "x86 should be enough for everyone", because that was not my point, and is really not my position (see my disclaimer in the first blog post in the series). I have worked on weaker memory models before (PowerPC on last-gen consoles, ARM), and had my fair share of people trying to synchronize their multi-threaded code by using volatile everywhere. May I ask where you got your impression from? I would like to rephrase that sentence or paragraph to clear things up.
Eventually :). It was recorded by they take a while to be processes
Do you have clang installed?
1. /r/cpp_questions is a far better fit for this post. 2. You've given us no information whatsoever about what's going wrong. It's like saying "My car won't start!" on /r/cars and expecting a silver bullet. 3. Yes, that guide is good enough, I used it. But it's not necessarily the easiest to follow if you don't know what you're doing. 4. If you didn't install YCM with clang-completer, you need to reinstall it. [This guide](http://www.alexeyshmalko.com/2014/youcompleteme-ultimate-autocomplete-plugin-for-vim/) is catered to a C-family oriented install of YCM. You should make sure you install the newer versions of everything used in YCM (newer vim, newer clang, etc.). I didn't use this guide myself, and can't claim for its validity, but it *looks* to be clear enough for one to follow.
Yeah I normally have to read in a bathtub. But sadly my apartment does not have one. :/ I never would have survived high school or college without a bathtub. 
im 23 and figuring it out now.. hurts
There's an MIT OpenCourseware course [6.172 Performance Engineering of Software Systems](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-172-performance-engineering-of-software-systems-fall-2010/) which may also be interesting. Obviously with 23 full-length lectures they cover a lot more than just microbenchmarking, and there's no mention of the Google benchmarking tool (at least in the few lectures I watched so far). There's some coverage of `perf` fairly early, IIRC, but Chandler Carruths tricks using those `asm volatile` functions to prevent optimizations only where needed are very interesting. 
On our case it was been reduced to very specific use cases that cannot be handled directly by Java or .NET ecosystems, namely: - JNI, P/Invoke wrappers for OS and hardware APIs or SIMD - To access 2D immediate mode in WinRT before Win2D existed - A relative cheap way to keep businesses logic across mobile platforms for native code I like the language a lot, but in 2015 I see it becoming an infrastructure language for writing performance critical modules or low level hardware control while allowing to use higher level abstractions. The current trend to go back to AOT compiled toolchains will reduce the gap even more.
Visual Studio C++ dev manager here. What did you want it to do that it didn't do? I agree with /u/masterofmisc, just download community edition of vs2015 if you want a good learning environment. VS code is more of a code focused editor than an IDE.
I just want a good learning environment. Maybe once I'm more advanced I'll start using code but it's getting annoying when the book points out I can do something and that something isn't there. Thank you for your help.
In a small project, maybe. Any reasonable sized project I worked with had practically non-existent code completion.
I completely agree with you in that the ecosystem of a tool is just as important (and often more important) than the tool itself. This is why I am saying that Bazel has the _potential_ to be better than CMake if it gains enough adoption because 1) its build language is so clean 2) it is designed to support _any_ programming language and 3) it is extremely easy to extend and write tools for. The third point is what makes it appeal the most to me because writing Bazel extensions simply involves writing Python. As a result, Bazel extensions are IMO much easier to read than the code used to write CMake modules or, even more so, the messy M4 code used to implement Autotools modules. Given that Google only open-sourced Bazel a few months ago and that it is still in beta, it will definitely take time before Bazel gains that level of adoption. However, I am hopeful because it is the first build system that I have used for C/C++ code that I actually enjoy using. I have been generally unsatisfied with both Autotools and CMake because the build scripts tend to suffer the same maintainability issues as Perl codebases do, especially when written by somebody who tries to be "clever."
Yes I know, and so what? There is a difference between some uses sometimes and an code optimized to use them.
**C**ode not code.
&gt; you just have to look up how to do that task with the tools you are using Yes, the understanding should be present. Otherwise you become a 'Visual Studio operator'.
Right, thanks
1º Grab a GNU/Linux distro (Kubuntu for example) 2º Run it on a virtual box or install it 3º Use a simple code editor with highlight, for example Kate (or learn VIM) 4º Write simple programs with it, and compile it with a simple make file or running a one line call to g++ 5º Now are on the real path to learn programming instead of learn how to use a IDE. Seriously, IDE are great tools but learning should be using a code editor and launching the tools by hand. So then you will understand what f* are you doing, and you can jump across IDEs, editor, building tools, etc. PD: I recommend that you learn first **C**, so you will know EXACTLY what are doing your computer. Then you can jump to C++ or any other language and learn OO programming. And, yes, I know very well that C++ isn't any more C with classes.
I agree with the issue about cache misses. However, this is not the case for all programs. Some programs have a small footprint. Since we speak about a object oriented language. What do you prefer Pimpl or inheritance?
I don't get it?
Indeed, you did not say that, I am sorry. Rereading your posts I now see it pretty architecture neutral.
yes, thank you, but it's not the same. In this particular case, for class Widget, I need to rename handlers to have different names from signals (that are public members in base classes now), make them public and connect Widget's handlers explicitly. Second point is that now I need to watch the life time of connected object, for example: Widget w; { TestHandler handler1{1}; w.on_mouse_click.connect(boost::bind(&amp;TestHandler::on_widget_mouse_click, &amp;handler1, _1, _2)); } w.on_mouse_click(19, 84); // Boom 
The best is no indirection at all. If your class would result in huge amounts of code to be recompiled if it changes, i would go with PIMPL, but in such a case one can assume that the class belongs to the 90% of code that only results in 10% of your runtime, therefore performance is not that important. If that is not the case, dunno .. best would be to redesign to no longer have that problem.
Perhaps this one [here](http://cppcon2015.sched.org/event/5af8a33df454c128983ffc90ca1e68f9) from Bryce.
Sounds like you should ask the recruiter or just take the interview. With the skill level you described you probably won't pass the tests to get the job - but maybe you will! Like lots of famous people say; you miss all the chances you don't take.
Did you get a job offer or an interview opportunity?
Interview opportunity. I just realized the OP makes it sound like I got a job offer. My bad. 
Fair enough. Thanks for the encouragement! Any tips for what the best way to brush up on some C++ knowledge is? I'm willing to read and finish books in days if I have to. :) 
Does anyone know what the equivalent of the: static void escape(void* p) { asm volatile("" : : "g"(p) : "memory"); } trick would be in Visual Studio? ([context](https://www.youtube.com/watch?v=nXaxk27zwlk#t=41m41s))
https://github.com/NoAvailableAlias/signal-slot-benchmarks 974
I think an alternative (better?) design would be to have the `connect` function return a `connection` object that follows the RAII pattern: when the `connection` object goes out of scope, the connection that it represents gets deleted. This would allow you to compose objects out of the "connection ownership" behavior, which I believe is better aligned with what this behavior actually represents (i.e. "has/owns a connection" vs "is a connection manager"). You could probably make shared ownership and ownership transfer work as well if you follow the design paradigms from `shared_ptr` and `weak_ptr`.
Make sure you know what pointers are :) Try http://www.learncpp.com/. I would point you at some resources about learning modern C++ (C++11 and C++14), but the company probably won't be up to speed :(
I think Owner would actually be used as part of the standard stuff (the raw pointer in the implementation of unique_ptr or shared_ptr for example), but yeah, the rest seem to just be a way to get upcoming standard things in people's hands faster.
As it done in Facebook's folly library: #pragma optimize("", off) template &lt;class T&gt; void doNotOptimizeAway(T&amp;&amp; datum) { datum = datum; } #pragma optimize("", on) https://github.com/facebook/folly/blob/master/folly/Benchmark.h
So roughly speaking this STL2 ~ Concepts Lite + range-v3 sans actions?
No, it was just a mistake. Lol this kid. 
Other than ranges and concepts, what else is intended to go into STL2? Will it be a complete replacement for the current STL or will they live alongside?
In the end it seems that it's the live-streaming that was a big cost, I'm not sure why but oh well.
Junior level C++ developer here. I have been a software engineer in a professional capacity for about 6 months now. So I'm very green, and while I can't tell you how the world works, I can tell you how this has gone in my personal experience. First off, they will be well aware of your experience level when they make their decision. If they feel this job is too much for you currently they won't hire you. That would hurt them as much as you, maybe more. So if you do get the job, don't expect to get thrown into the deep end day one. Second, as others have said, they will likely be throwing things at you that they think you'll be fine to handle, useful code that needs maintenance is a term I've seen. It's pretty accurate. Third, there will be a lot of hand holding initially, if they plan to keep you around. It would behoove them to make sure you develop your skills and improve at your job. So expect them to attempt to assist you in doing so. Lastly, being crisp on C++ would be great, but they generally don't expect that at a junior level. What they do expect is for you to be generally well aware of programming concepts, data structures, how to read inherited code, that kind of thing. These are really what they expect you to have a really good handle on ~~outside~~ from of school, because they are the building blocks to become a pro at any language. Like I said, I make no claim to understand the entire environment of a programming workplace, and these are just my experiences in my very new career. Good luck! Now I have to get back to work.
I'm really curious on his vim/iTerm setup.. anyone knows what he's using?
Thanks! That's a very nice trick - and I don't have to resort to `asm`.
Eric uses VS as his editor and maintains the Solution. It hasn't been updated for a few weeks so some of the headers aren't in it. And yes, to my knowledge, it doesn't compile anything.
You have issues :( 
Then get the community edition. https://www.visualstudio.com/en-us/products/visual-studio-community-vs.aspx . Visual Studio Code is more an text editor that got lucky enough to get the Visual Studio brand name.. it's not really Visual Studio imo.
You asked a stupid question and he explained.
The sub and these comments are fine, you're in a retard spiral.
&gt; but there are peculiarities like std::back_inserter(container) not modeling the STL2 WeakOutputIterator concept. Why does it not model `WeakOutputIterator`? &gt; The "conceptified" standard library will probably end up living in a different top-level namespace (e.g., ::std2) or a subnamespace of std (::std::v2`) where "old" code won't see it. This is disappointing. Forking the standard library can be just as bad as forking the language in my opinion. Concept mapping can help improve backwards compatibility and edges cases, but sadly it is being ignored due to FUD.
&gt; dyn_array is not the same as vector. it's a vector of constant size, its implementation is therefore much more simpler. I'm slightly confused, as just two days ago I saw [this email on GCC's mailing list](https://gcc.gnu.org/ml/gcc/2015-09/msg00357.html) where a GCC maintainer mentions that "nobody knows how to implement it.". (I'm assuming it's about the same proposal)
He had already apologized for being unclear, and you posted a question that did not serve to transfer any useful information, and instead was belittling. He already knew an interview was necessary, he just didn't make it clear in his post. 
&gt;I just realized the OP makes it sound like I got a job offer. Let's see... &gt; Got an offer for a Junior level C++ job. Yup, story checks out.
&gt; Why does it not model `WeakOutputIterator`? Specializations of `std::back_insert_iterator` are not `DefaultConstructible`, and thus do not model `Semiregular`, `WeakIterator`, or `WeakOutputIterator`.
Okay, thank you!
As far as the GSL is concerned: I started a pre-C++11 version, named [GSL Lite](https://github.com/martinmoene/gsl-lite).
Currently in C++, input and output iterators are not required to be default constructible, just forward iterators(and beyond). I don't understand why they are changing it. Furthermore, it limits the type of iterators that can be created. For example, if it stores a lambda then it will no longer be considered an iterator.
Thanks! Even if you won't read it I'll leave this comment to link the post I've made on /r/rust https://www.reddit.com/r/rust/comments/3mr0z5/herb_sutter_open_to_discuss_lifetime_safety_with/
Are you saying C++ isn't transferable to other languages? Or other languages aren't transferable to C++? I feel like once you learn C++ it's easier to pick up another language than it is to go from another language to C++. 
What about Clang?
What?
i can't see how this wouldn't end up as a python 2 vs. 3 thing if stl2 replaces stl1. it's so much safer to put them orthogonal and say stl1 is feature complete, only bug fixes from here on out.
What happened? We've hit a performance wall. That's what happened.
I've sent mail; the core team is very excited about the developments in the C++ world and would love to talk!
Change your books
Wait, are you Steve Carroll? If so, love the GoingNative videos you guys do! Any idea when we should expect that precompiled header tool from episode 35?
Doesn't implement concepts.
I found the tree traversal part really interesting. Any links to resources on this subject?
The Ranges TS inherits the `Semiregular` requirement for `WeakIterator` from N3351. The authors of N3351 had a strong inclination to make everything `Regular` that could be possibly be so, and `Semiregular` otherwise. I can't find any specific rationale for requiring default construction for weak iterators, so I can only assume it falls under the same blanket reasoning. Having implemented everything in the TS, I can say that default construction and equality comparison of input and output iterators - let alone their `Weak` versions - seem extraneous. They are not useful operations for generic code.
The biggest issue I see is that we have no answer to simple questions like "how to return an object from a function". RVO, `unique_ptr`, the new `owner&lt;T&gt;` stuff - it all feels like magic. Now, I'm OK with all of this, but I'm not sure other people are.
Although all of GCC, Boost, and git (finally!) have been updated, I didn't think it was worth posting to the main page of the subreddit. My distro has absolutely no cross-compilation ability, and never will (that's frighteningly complicated to set up - keeping the native bootstrap working is hard enough).
We maintain a library that can do that (and more stuff such as external algoritnhms). The documentation of the pipelining features are here: http://www.madalgo.au.dk/tpie/doc/v1.1/pipelining.html And an example is here: https://github.com/thomasmoelhave/tpie/blob/cpp11-cleanup/test/pipelining2.cpp
yes, variable length arrays have been part of C since C99(Iirc), but not part of any C++ standard. Afaik they wanted to get it into C++14 but it didn't get to it for whatever reason.
My big problem, I’ll run into a tough bug in a personal project and set it aside for months. For example, today I just found out that `std::remove_if` does *not* change the size of the container. Instead, it moves things around and returns an iterator that is the new, conceptual `end`. So you pretty much have to `erase` every time you use it, or at least hold on to the return value and use it instead of `std::end`. It’s been months since I touched the code, and I finally just figured that out. It’s a frustrating state of mind.
I usually use capital letters for classes, not for functions though (camelCase). Also I don't use capital letters for namespaces (all lowercase, integrates nicely with `std::something`) but for variable names.. I haven't really found a nice way yet.. and that is like 90% of the code one is supposed to read :P
Plain camel case. Underscores are wasting space in long identifiers.
Yes, because memory is in such short supply in modern computers. Seriously though, readability is the key. The odd underscore is well worth it if it makes code more readable.
You've opened a can of worms here. Responses below will indicate that it is easier to herd cats than get programmers to agree on consistent naming conventions, indent conventions, etc.
I'm afraid you're right. It's hardly an objective topic. I would be inclined to think that `variableName` is nicer to see, but `variable_name` is easier to process in your brain
Having identifiers with too-long names is bad since it should be avoided in the first place, e.g. `sum_of_the_first_10_numbers_in_the_array`.. either make it a comment above the variable declaration (preferable if it helps comprehension) or avoid it entirely. But I don't think underscores are a problem in reasonably short variable names like `current_sum` instead of `currentSum`
That could make sense, also if `this_style` is more readable it makes sense to use it for variable names (which are read way more often on average than their respective types).
For member variables, I use the form of "m_TreeAdapter". For local variables, I am used to use short, one-word names like "ok", "item", "id", which are declared only on first use and have the smallest scope possible. Taking your example, I would probably name it just "max", if possible.
Personally I am a fan of the underscore, but it does not really matter. IMO you should use different styles (PascalCase vs snake_case) to embed *semantic* information of an identifier. Any decent IDE can highlight functions/types/local variables/member variables differently, and there are tools that can refactor the code automatically. If something can be done automatically by a tool, there is no point in wasting time there, focus on what is important and can not be identified automatically. For example in my projects I use PascalCase for *object* classes and snake_case for *value* classes: class Widget; class string; 
What is a value class? Can you please explain it to me? I've never heard of it
Boost is a big library, even HUGE. You don't need all of it, and you can "slice" only the parts that you want... but I know enough companies that doesn't use it because they consider boost slow and bloated (not agreeing with them just stating a fact). GSL is supposed to be the minimum code possible (remember GSL is more about the guide than the code).
I like underscores most, I find it more readable. However I tend to then have more name collisions between types and variables as with camelcase you can write :- void Conversation::addUser(const User&amp; user) But that won't work if your type and your variable name are the same. I still prefer it though
That sounds like a red herring (because I have never run out of file space due to underscores in identifiers). Best argument I've heard about one versus the other (and I know this is very subjective) was in favor of snake_case: ThisIdentifierIsDifficultToRead **vs.** this_identifier_is_easier_to_read 
&gt; When in Rome do as the romans do ... or so they say. In C++ this means do as the standard library does in whatever project you are working. Sometimes the standard library is Boost + STL and that means `snake_case`, sometimes it is `Qt` and that means `CamelCase`, and sometimes you have to use both and there is no good answer. 
In any programming language I use (including C++) the rule I stick to when it comes to naming conventions is: do as the Standard Library does. In case of C++, that means underscores.
I have heard this argument before, I don't find it persuasive. First off, this is quite easily resolved: lambdas are types, functors are types, functor instances are variables. Second, at the end of the day 99% of classes and variables are none of the things you listed. The fact that 1% of the time it's grey doesn't mean we should abandon a style that provides a clear and useful distinction the rest of the time.
It really doesn't matter. Naming conventions aren't going to make bad code readable, or good code unreadable.
I mostly follow the google style guide, except camelCase for functions. There's also some additional useful conventions: int a_variable; int m_variable; // a member variable int s_variable; // a static member variable int g_variable; // a global variable void myFunc(); // a function class MyClass; // a class It's convenient to have a quick idea what you're looking at. Of course, I use an IDE with good syntax highlighting, but it still comes in handy. Odds are at some point you'll look at some code somewhere that doesn't have the best syntax highlighting (git blame, Gerrit), in which case you'll be grateful.
it works properly, you are sending a empty string to the CHECK_SEQ
Very subtle:) also, the last if should check for if( check != aDNA.size() ). Or **else**, as u/d-frey said...
True. However, tabs are four spaces. As god intended.
Space on the screen.
I don't believe in comments like that, so I use long identifiers. 
Good questions. We've now added a [FAQ section](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#S-faq) that answers these and related questions. These particular ones start at [FAQ.56](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#Faq-gsl-owner).
I go a step further... class tMyClass { public: int PublicVar; void PublicFunc( int paramOne, double paramTwo ) { int FuncVar; } protected: int protectedVar; void protectedFunc(); private: int _privateVar; void _privateFunc(); }; Global functions tend to be treated similarly to public functions with no class (but typically don't exist anyway). User-defined types usually get named with a tPascalCase, and template types get a double ttPascalCase&lt;&gt;. Function parameters get a standard camelCase and function variables within are PascalCase again (I guess I think of them as a "global" or "public" in the scope of the function). Protected and private have the distinction so it's hopefully easier to see at a glance which parts of an interface a developer might have most interest in during inheritance. Oddly enough, snake_case seems to be something I've completely abandoned unless I'm writing C code...nothing against it, but I'm not sure why. I now see that I have more rules than I realized. This probably only scratches the surface...
Normal variables: int testVariable; Class members: int m_TestVariable; Global variables: const int MAX_ITEMS; Functions: void doSomething(int somethingHere); Classes: class TestClass Regarding member variables: Let's say I have a class with an integer "testVar" and a function like "const void setTestVar(int testVar) { testVar = testVar; }", my brain would think "Is the first 'testVar' the member of the class or not?", because it's counter-intuitive So, IMHO appending "m_" at the beginning of a member variable makes it more intuitive
When writing C++ there are more issues than just readability. You should adopt a style that minimizes conflicts between certain classes of syntactic constructs, such as namespaces and classes, locals and data member, functions and locals, functions and data members, etc. I would strongly recommend the Google naming (and formatting) guidelines as it is very readable while avoiding the above caveats.
In math and physics classes, we always use lower case for variables and upper case for constants. I like to follow this convention with my c++ code.
&gt; Less typing and better interoperability with generic code that expects functions instead of callables. Aren't functions callables also?
&gt; I'm wondering which one between current_max or Current_Max would be more readable.. This is a question that's only meaningful in a larger context of style. [For example, take google's C++ naming convention guide.](https://google-styleguide.googlecode.com/svn/trunk/cppguide.html#Naming) There they use only lowercase, underscore separated words for variable names, and capitalization is reserved for type names. So in your case, either way might be equally readable, but in the broader scope of an entire program, you'd want to keep the lowercase version so you can reserve uppercase for other things. It's probably best to start with someone else's established style guide, stick to that for a while until you think you really wanna change something.
&gt;can we come to an agreement regarding the most readable style for variable names in C++ code? No, there's no need to do it. I, personally, will use whatever is the case on the project. If I am starting one, I will look at the biggest library to be used on the project and adopt that, which often means whatever the standard library does. If Qt, then I'll use some Qt-like style. and so on. Forget the One True Way™, it's for the shallow-minded, the bigots and the like.
What about (using different styles on purpose): template&lt;typename F&gt; void foo(F&amp;&amp; callable) { // [...] // later on: callable(); } void bar() { auto Callable = []{}; // [...] // later on: Callable(); } void baz() { struct Callable { void operator()(){} }; Callable callable; // [...] // later on: callable(); } Or even weirder: auto Call = [](){}; struct FooBar { decltype(call) m_callable = Call; }; void boo() { FooBar foo; // [...] // later on: foo.m_callable(); } I find that having different styles for each kind of thing is irrelevant. Here, callable is just something that can be called, however it is defined. If you enforce a different style for each possible case, then it makes it very hard to refactor the code to move from one kind to another. The code that calls *callable* doesn't care and doesn't need to care about how it was defined and where it comes from. The only thing it needs to know is what *callable* is supposed to do.
False; tabs are tabs. Then you can choose your own damn indent size.
Bad naming conventions can absolutely make good code unreadable. Ever seen a large codebase which uses hungarian notation everywhere?
the one true way is lisp-identifier-style
I stand corrected - rust uses ' as merely a delimiter from the type name whereas you are using ' and '' to indicate levels of derived-ness from a variable. So the syntax looks similar but it's not. 
My editor automatically converts a tab into exactly four spaces. Life is good.
It is totally a matter of getting used to it. I've always used snake_case in C++ (if nothing else because the STL uses that form and I'd liked the code to look uniform. In retrospect, there's a benefit in having two styles, it makes more obvious what's yours and what's external.) Then I started working for a company that used camelCase for members and CamelCase for globals. Initially I hated it. Then I configured the glasses mode in Emacs to show the capitalized letters in a just-hinted bold font. This is enough for telling my brain to read the separate words and now I'm happy (and I actually appreciate not wasting the 'underscore' character. If you have a 80 char/line limit in your style guide, that's handy. Really, it is only what you're used to. What is important is consistency across the code base. That should be non-negociable.
&gt; snake_case ... some study backs that idea up Be careful though, because there has been other research (for example Binkley et al’s *To CamelCase or Under_score* paper from 2009) that came to a very different conclusion. On the limited evidence so far, it looks like this could be an area where consistency and familiarity are more important than the style itself.
AFAIK, they normally follow the variable naming. That's my experience though.
Problem is that when you begin interfacing with libraries and API's everything goes out the window. STL uses lowercase for everything, and underscores. WinAPI uses ThisStyleForFunctions() and prefixed variables like dwCounter, cchSize. Then you try and interface with another library and they use yet a different style. So really, it doesn't matter and it's impossible to agree on a standard. 
Thanks for the reply. I am the author of that blog. First of all, I admit that my knowledge of C++ is limited considering the vastness of the language but its not at all poor. Having said that, I am obliged to correct every sentence of yours which has hit way off the mark. May be because you did not read it at all! 1. Right in the beginning of the blog post, I have explicitly written this "..That means, don't blow me away if you don't see me using any standard library functions for achieving something which I am intending to do...". Clearly you didn't read it. 2. There is a reason why slices exist in many languages and very recently it has been introduced in GSL for C++ as 'view'. Its pretty much similar in idea. Going by your argument, event that would seem pointless to you. 3. I wrote 'slice' library just for fun. It may have taken me around 1hr to get the whole thing setup with test cases. So, obviously it's not for serious usage. This also has been mentioned in my blog, hope you read that! 4. The example which you have mentioned was not something that would have motivated me. Its the value semantics that it offers, possibility of doing bounds checking, having multiple views of different parts of the same underlying container but still in the form of container, etc.. These are the motivating points. Sorry for this flame, but you clearly missed the point.
I'm not sure what this adds to what I already said. Yes, in the specific case of callables, you may find it "irrelevant". But most things you declare are not callables to be passed around. I'd also argue that even in the case of callables, this is pretty informative. What's near the parentheses gives you valuable information. - PascalCase: you are constructing an instance of that type. This is obviously different in some fundamental ways from a regular callable. - camelCase: if a function call, this is a hard-coded, statically resolved call. If a method call, it is either the former or resolved via inheritance &amp; virtual. This is very constrained compared to... - snake_case: This could either be a functor instance, lambda (not fundamentally different), or a function pointer. This can involve a lot of indirection. Notice that the only way that code can generically use a pre-constructed callable (which is what you're talking about in your paragraph) is the third case. Following the convention I mentioned, every single callable you mention would be snake case. I misspoke above when I wrote that lambdas are types; lambdas are instances of anonymous functors (and therefore are variables).
I think that's a key point that Bjarne and Herb both talked about. Eventually, somewhere down the line, it will become necessary to call dangerous code. The less places we can do that, and the more obvious it is when we do, the better. shared_ptr and weak_ptr are "safe" wrappers around the dangerous code, and with the GSL, would have the annotations calling out their dangerous implementation. However, if they can be tested extensively and cover most use cases, they can be used, and assumed to be safe and GSL compliant.
For an existing project, use whatever the existing project is using. For new projects in a team environment, use the same coding style the team normally uses. For individual projects, consider using the style of the largest dependency. You can also employ any of the publicly available style guides that exist (Google, LLVM, JSF, Python, Java, etc). or document your own. There are plenty of style guides to choose from that cover different coding environments (Library, Embedded, etc). In general for spacing/structure, consider using Clang-Format. Configure it to your style guide needs and focus more on writing code.
I don't think it is a good idea to use capital letters at the beginning of variable names. Convention holds that capital letters at the beginning should be reserved for objects / class definitions.
Maybe try writing your own function using vprintf (as shown [here]( http://www.cplusplus.com/reference/cstdio/vprintf/)) which will print timestamp followed by passed arguments and use macro to override printf.
Depending on how accurate the timestamp has to be, you could simply add the timestamp to the output of your program externally: &lt;command&gt; | awk '{ print strftime("%Y-%m-%d %H:%M:%S"), $0; fflush(); }' Source: http://stackoverflow.com/a/21620
I hope this link helps. :) http://www.linuxjournal.com/article/7795
Sorry c++ noob here, I don't understand the "rewriting" question... if the printf is something like "printf("%s", str)", can't we just find and replace all "printf(" with "printf(timestamp(),"?
 std::cout &lt;&lt; "Goodbye world." &lt;&lt; std::endl; :v
Yeah, but then you can't do [vertical alignment formatting](https://gist.github.com/jrandom/08048c79ce0c752e9160) for anything that doesn't fall on an exact tab boundary because as soon as it's loaded into an editor with a different tab setting, it will fail to align again.
Others have already commented on the error in your code, but I'd like to comment on your approach. 1. Why are you computing the number of valid characters? That's a lot of unnecessary work, because you already know that if there is even one invalid character, the whole string is invalid. Just return false the instant you encounter an invalid character. 2. Your compiler will probably optimize this out for you, but there is no reason to index the string for every check. Just save the character into a temporary variable. Your code will be more readable that way too. 3. Don't ever use strings to hold boolean values. The `bool` type does all that in a much less error prone way. Here is my suggested version: bool isValidDnaSequence(const std::string&amp; seq) { char c; for(i = 0; i &lt; seq.size(); i++) { c = seq[i]; if(c != 'A' &amp;&amp; c != 'a' &amp;&amp; c != 'G' &amp;&amp; c != 'g' &amp;&amp; c != 'T' &amp;&amp; c != 't' &amp;&amp; c != 'C' &amp;&amp; c != 'c' ) { return false; } } return true; } 
Dont. Use an existing logging framework.
Is there a framework whose integration would eliminate months of work rewriting a large codebase?
I feel your pain on those kinds of gotchas. They can cost you a painful number of hours and you end up having to always use a personal 'patch' library to make things work how you'd expect, or copy-and-paste every time (which is **never** the solution).
I would advise against a quick &amp; dirty solution. What tools are you using to write your software ? Anyway: * Replace every `#include (&lt;cstdio&gt;|&lt;stdio.h&gt;|"stdio.h")` by your own include like "logger.h", which then include &lt;cstdio&gt; * It should still build, have a coffe * use something like `bear` to generate a compilation database for `clang`. it doesn't matter if g++ is your primary compiler * Write a log function that takes the same parameters as printf, but formats the output as desired. you may want to wrap that in a macro to capture `__FILE__` etc * Use an existing clang-base refactoring tool or[ write your own](https://kevinaboos.wordpress.com/2013/07/23/clang-tutorial-part-ii-libtooling-example/) to replace every call of the printf function. * Run the tool on the complete codebase * Done I know the solution is involved. But I fear anything else would be un-maintainable going forward. This solution may also lead to greater refactoring. I had success with using clang-modernize on a large codebase ( albeit not that large ) 
I find it hard to reason on an algorithm if the name of the variables are too long or if they integrate poorly with the "flow" of control (i.e. reading ifs, switches, returns and whatever as a *sentence*)
Furthermore `variableDIReport` is hard to read because the acronym `DI` gets automatically grouped with something a programmer is familiar with (it might be `DIR` for directory). `variable_DI_report` avoids any confusion.
But then there's a lot of extra work to make sure things are tabbed out to juuust the right spot, with spaces following. With today's IDE's treating batches of spaces as tabs, I see no reason to go back to using the tab character. Use all spaces and have guaranteed formatting in all editors w/ minimal effort.
Use libtooling like /u/c0r3ntin suggested.
I did rebuilt but still getting the same error :/
Wouldn't work in this case. The messages are generated in parallel from different processes and assembled by one main process so I'd get the time shifted time stamp with this approach.
Yes, thank you
What @tangerinelion said. It's not even clear what all the source files are that need to be updated. Some are generated and who knows what it looks like before. It'd just be a giant mess to attempt this. Best would be to hit 80% of it with cautious automation and hit the remaining 20% by hand or just accept that you won't hit it all.
Just replace printf in all files with my_printf, which prints the timestamp as well as the text. 
Or just: bool isValidDnaSequence( const std::string&amp; seq ) { return seq.find_first_not_of( "AaGgTtCc" ) == std::string::npos ); } 
Yeah, that's probably the most succinct solution. Maybe not the most performant though. Using the standard library is good in general, but if you're a beginning programmer, you don't want to rely on the black boxes too much. Otherwise you'll never figure out how to implement such functions yourself when the time comes.
The only rational solution is to have a tantrum about it and post it on reddit.
Yeah I do take medicine during weekdays. I wanted to study though in my spare time when I would not have the effects of the medicine. Music sadly distracts me more. Sometimes a youtube video of white noise on repeat helps... most often it doesn't.
Oh I really have to look into this. I started using incognito just so that if I accidentally close a tab it is gone and I cannot hoard it by control-T-ing it.
If you have a good IDE or use automatic formatting tools it shouldn't be an issue. I certainly understand the appeal of just using spaces of course since developer tools are in the stone-age when it comes to this.
Here be demons. The solutions listed by other redditors will work well if all printf statements include only one newline character and only at the end of the line. However, you'll get funky statements elsewhere. For example, printing elements of a vector: printf("[ "); for (auto&amp;&amp; i : vect_of_ints) printf("%d ", i); printf("]\n") This will result in some strange output: 12:51:07.123:[ 12:51:07.125:2 12:51:07.127:3 12:51:07.129:5 12:51:07.131:7 12:51:07.132:11 12:51:07.134:] instead of: 12:51:07.123:[ 2 3 5 7 11 ] Another example would be multi-line output: printf("Usage:\n" " --ver Display the application version\n" " --help Display this message\n"); will result in only one line having the timestamp: 12:51:07.123:Usage: --ver Display the application version --help Display this message Also, realize that puts(), putch(), fprintf(stdout,...), fprintf(stderr,...) will also need to be fixed up. And what about iostreams? I understand that you need to come up with a temporary solution and something is better than nothing. But you do need to be aware of some of the possible problems so you don't get caught offguard when you get some strange results.
`find_first_not_of` is very likely not the most perfomant implementation (surprise! Of all the possible implementations only one is the most performant so the odds are stacked) but your handwritten code is very unlikely to beat it. Can you explain the relevance of that remark, then?
I was just giving an example of what indentation + spaces for alignment looks like. The problem with your approach is that if tab space is very large (e.g. 32) then your x/y/z will look really wrong. If you wanted to protect yourself from the length of doSomething, then: &gt; def foo(): &gt; &gt; doSomething( &gt; &gt; x, &gt; &gt; y, &gt; &gt; z &gt; &gt; ) This has the advantage of being agnostic to the length of doSomething while preserving the fact that the look is consistent across any tab-stop width. 
I second c0r3ntin's suggestion. You'll eventually need to be doing this again in the future. The nice thing with the solution is that for normal builds you can just create a macro for your log function that is an alias for printf: #define app_log(...) printf(__VA_ARGS__) Then you can place #ifdef's in your header so that for special builds, you'll enable timestamp logging: int app_log_timestamp(...); #ifdef TIMESTAMPS_IN_LOGS #define app_log(...) app_log_timestamp(__VA_ARGS__) #else #define app_log(...) printf(__VA_ARGS__) #endif And with this technique, you can go further when needed: int app_log_timestamp(...); int app_log_process_id(...); int app_log_process_id_and_ts(...); #if defined(TIMESTAMPS_IN_LOGS) &amp;&amp; defined(PROCESS_ID_IN_LOGS) #define app_log(...) app_log_process_id_and_ts(__VA_ARGS__) #elif defined(TIMESTAMPS_IN_LOGS) #define app_log(...) app_log_timestamp(__VA_ARGS__) #elif defined(PROCESS_ID_IN_LOGS) #define app_log(...) app_log_process_id(__VA_ARGS__) #else #define app_log(...) printf(__VA_ARGS__) #endif 
A hackish way would be a macro and add -D compiler flag with printf expansion that adds timestamp.
&gt; The problem with your approach is that if tab space is very large (e.g. 32) then your x/y/z will look really wrong. If tab space is really large, fix the tab space. This is not an issue with my suggestion, because the rest of the code will look really wrong as well. And i would actually argue that youre not aligning the arguments, youre indenting them, so using tabs is what should be done.
AFAIK, the whole STL2 talk started to appear when they decided to apply Concepts to the entire STL, as some of the algorithms would become more restrictive than before, breaking backwards compatibility. Ranges becoming part of it is just a natural fit after the decision was made.
Eclipse is not a compiler, it's an IDE. ( a smart editor ) Do yourself a favor. Do not use Eclipse. *It's the worst*. If you are on Windows, go with `Visual Studio 2015 Community Edition`. Otherwise `Clion` is apparently quite good. Or `XCode` on OSX. `Qt Creator` is also an option. `CBlocks` is *NOT* an option, I have seen teacher use that, please don't. There are other options, most of them free. But I am afraid you have gone for the least sensible one. Note that each IDE may only be compatible or ships with a particular compiler, but I don't think you have to worry too much about that for now. 
A really disgusting, but highly effective solution: #define printf printfWithTimestamp. That said... The one who told you, **now, after 10M+ of lines have been written**, that **every logging call** has to have a timestamp, is an idiot.
&gt; They are not useful operations for generic code. This is a red flag already, concepts should be derived from algorithm requirements. If the algorithms that work on `Input`/`Output`/`Weak`... iterators don't require `SemiRegular` then they are clearly overconstrained. This is bad because users get code that works (yay!) but cannot use it because its over constrained (hate!). The fix is easy, remove the requirement and if someone comes up with an algorithm that works on `Weak` iterators but needs `SemiRegular` then one can just require the iterator to be `SemiRegular` as well for that single algorithm. Were the concepts from N3351 just inherited as a solid starting point and are still open for discussion or is there a strong commitment to not touch them much? 
They shouldn't call it V2. That's just... messy. I think better approach would be #define use_new_stl Or, if that's possible: namespace std = std2; But I'm not sure you can shadow namespace like that...
Sometimes you will want to use them both at the same time. Imagine your modern code using some old STL2-unaware library. 
And what if there will be an stl3 in 15 years? How would you call that? #define use_even_newer_stl is even messier. This problem is solved to some extent with inline namespaces.
find_first_not_of has a nested loop which introduces a lot of extra arithmetic and branches without eliminating any of the existing branches. Of course with loop unrolling, it's hard to know how much of effect that will have in practice. Why do you suspect that my handwritten code is unlikely to beat it?
Try formatting it, the `//` will comment out everything until the end of the line, so `return 0; }` will be ignored. Also, a preprocessor directive (`#include`) needs to be terminated by a newline. #include &lt;iostream&gt; using namespace std; int main() { cout &lt;&lt; "Hello World!" &lt;&lt; endl; return 0; }
&gt; If the algorithms that work on [X] don't require [Y] then they are clearly overconstrained. This is false in general. Generic programming isn't about finding the absolute minimum set of operations an algorithm requires. It's about finding requirement *clusters* that are semantically meaningful and show up across a wide set of algorithms. This is both art and science with lots of room for interpretation. One goal should be few concepts and small algorithm requirement clauses. This goal is at odds with efforts to avoid overconstraining algorithms. In a nutshell, that's why N3351 tends to overconstrain the algorithms by design. Whether for this particular case that's the right decision for the C++ community is an engineering decision.
Not easily. By necessity, they must appear at different places in the C++ grammar.
&gt; Forking the standard library can be just as bad as forking the language in my opinion. There's some truth to this, and it's something the committee is aware of. Special care will be required not to needlessly fork so-called vocabulary types like `string` and `unique_ptr` that are likely to show up in interfaces. We don't want to end up in a situation where some API that expects a `v1::string` can't be called with a `v2::string`. That would suck.
&gt; Having implemented everything in the TS, I can say that default construction and equality comparison of input and output iterators - let alone their Weak versions - seem extraneous. They are not useful operations for generic code. I disagree with this. Consider `counted_iterator`, which holds a (possibly weak) iterator and a count, which counts down 0 on increments and is `EqualityComparable` with a default sentinel. It turns `WeakIterator`s into `Iterator`s, but if the weak iterator is not `DefaultConstructible`, then in order for `counted_iterator` to model `Iterator`, it must hold the iterator in an `optional`. That kind of sucks. There may be other places where default constructibility of weak iterators makes generic code simpler, that's just the first case that springs to mind.
Right. I knew that with Concepts coming, we would have to take a breaking change in the standard library. I saw that as an opportunity to do ranges "right" without worrying so much about back-compat, so I got out in front of the process with range-v3. I certainly could have made `std::v1` my target, but I would have had to lower my ambitions.
&gt; This is false in general. Generic programming isn't about finding the absolute minimum set of operations an algorithm requires. I mean, requiring more than it needs is the definition of overconstraining. Wether overconstraining is worth it or not is a different question. Obviously nobody wants to remember/write/read a gazillion concepts on function definitions. &gt; One goal should be few concepts and small algorithm requirement clauses. This goal is at odds with efforts to avoid overconstraining algorithms. In a nutshell, that's why N3351 tends to overconstrain the algorithms by design. I see your point. I just had frustrating experiences with overconstrained functions that I wanted and should have been able to use but couldn't because of unnecessary constraints. Choosing a good tradeoff between few concepts and tightly constrained functions is as you say an art, but since it cannot be changed later one is a pretty damn hard art. I wish one day we'll have tools that tells us if the concepts we choose are enough, too much, or maybe even can tell us for a given function body the minimum number of concepts we need from a set of available ones. 
You also need to intercept `puts()`, as GCC will replace calls to `printf()` with `puts()` when they don't contain arguments and end with a newline. On higher optimization levels it will also call `__printf_chk` instead of `printf`.
&gt; It turns WeakIterators into Iterators, but if the weak iterator is not DefaultConstructible, then in order for counted_iterator to model Iterator, it must hold the iterator in an optional. The use case here is passing a weak input range to an algorithm that takes a pair of input iterators? `common_iterator&lt;counted_iterator&lt;I&gt;, default_sentinel&gt;` would cover this in the modified design, albeit less efficiently. There's a tradeoff between the performance of new code using old algorithms with new iterators, and the performance of new or old code using old iterators with new algorithms. i.e., `ranges_v1::fill_n(std::back_inserter(vec), 13, 42)` won't work without wrapping the `std::back_insert_iterator`. That tradeoff is definitely something I'll discuss in the proposal. Without having examined the issues completely, I currently favor relaxing the requirement thereby easing the transition to STL2 for users of old non-default-constructible iterators. Note that I am *not* contemplating removing the default constructors from the models of weak iterators in the library, merely removing the requirement from the concept - much as we've done with `operator-&gt;`.
Casey Carter and Eric Niebler provided some clarification in this other thread: https://www.reddit.com/r/cpp/comments/3mpv31/a_working_implementation_of_the_ranges_ts_and/cvh3rk7
I get the shivers when i see this. Never use NEW in code.. The word is time-sensitive. as /u/hex_binary says, what happens next week when there is an even newer version released. Is that the new-new? 
Automated formatting takes care of this issue.
&gt; I'm a proponent of default construction and partially-formed values I used to think that, but now with lambdas in C++, the need for partially-formed objects is non-existent. Plus, you get extra type safety by avoiding partially formed values. Default constructibility should only be a requirement if its needed by the algorithm, that is, it will use the fully formed value from default construction. 
&gt; Choosing a good tradeoff between few concepts and tightly constrained functions is as you say an art And of course, I think concept mapping would help make this less of an art. Although, I don't know how easy it would be to concept map constructors.
Yes, and now we increase the space of iterators. Ultimately, the algorithm should use optional instead of pushing this on to the iterators. That way the extra space is only added when it becomes necessary.
In maths, it's common to both have meaningful names for groups of related requirements / assumptions etc., but also to weaken the actual requirements for specific theorems as far as possible. So one might read in maths papers things like: For given WeakRequirements, we have Theorem, which is usually followed by Corollary: in particular, for Concept, we have Theorem (and WeakRequirements imply Concept). Of course, the weakening of the requirements is usually discovered after the theorem was first proved. Similarly, after discovering / constructing a new algorithm, one gets nice meaningful Concepts, but for some algorithms the requirements can be weakened, and it seems a pity not to actually provide those extra degrees of freedom to users. A related point: what is your opinion of the talk "[Generic Programming must Go"](https://www.google.nl/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0CCEQFjAAahUKEwiT_sDp0J_IAhWk93IKHY_6BPU&amp;url=http%3A%2F%2Fdconf.org%2F2015%2Ftalks%2Falexandrescu.pdf&amp;usg=AFQjCNHNzXpuQIbKEoITMuwT22od6qOagg&amp;sig2=TB_EoUM-yTprdRxdbvrK7w) by /u/andralex/ which essentially argues against naming every concept, and doing much more in-place introspection (using `static if` in D) of the actual requirements.
Well, you define it like this: template&lt;bool B&gt; concept bool Bool = B; #define CONCEPT_REQUIRES(...) class=void&gt; requires __VA_ARGS__ &amp;&amp; Bool&lt;true Although, this may break if the user uses a type trait. So instead it could be written like this: #define CONCEPT_REQUIRES(...) class=void&gt; requires bool{__VA_ARGS__} &amp;&amp; Bool&lt;true However, this could hinder diagnostics(and ordering). At least for clang, it might be better to stay with `enable_if` and only use `requires` on compilers with already poor diagnostics. 
Not only you failed to print the same text, you failed to fail properly. :-P std::cout &lt;&lt; "Goodbye world.\n";
We would like to fix things like this, but we also need to be mindful of the migration story. Using the new lib should be as simple as changing a namespace alias. If we break things, it should ideally cause a compile-time failure. Silent changes in semantics are scary. I don't know yet where to draw that line.
Well, my 2 cents would be that a keyword or specifier should be defined that can be placed on your function's declaration/prototype which will result in it being explictly excluded from the new proposed visibility.
Agreed. Maybe also repurpose the `explicit` keyword to restrict expressions from using UCS? ex: `explicit(value.ToString())` or `value.explicit ToString()`
In my opinion it should be opt-in (like in C#) for all code apart from extern "C" code (so that it can be used with system APIs).
The social sciences suggest affixing the word _post-_, possibly multiple times. After that replace _new_ with various synonyms possibly affixed by _-ist_. When you run out of ideas, reuse the old names with _neo-_ attached.
very helpful. thank you! 
Ugh, didn't see that. I'll probably do that then, or use the slightly more complicated pointer-to-member SFINAE trick (unless of course the usage of this is changed by the time C++17 rolls around). 
If you control the callers, of course, it seems easier to update them to use `.ToString()` and then have the free function print the type name, which gets rid of the need for any SFINAE and the `Preferred` trick. Actually UCS seems almost perfectly suited to this use-case. Assuming it makes it in and everything.
I considered that as well, but it just feels a little misleading to have `v.ToString()` and `ToString(v)` do different things.
You wrote that this is really great. Why do you think that, out of curiosity? On the rare occasion you need something like this for generic programming, you can easily write something with SFINAE that will dispatch the call accordingly. Personally I've never needed this. And I don't see any good reason to add yet another rule and more complexity to the language. Right now if I see a.f(), I know f is a method of a. Why throw that away? 
I don't think you need to worry, there's so much already being added to C++17, and with this being a relatively complicated and not that game-changing feature it is pretty sure to be dropped before the standard is finalized.
The main reason (as outlined in the proposal) is API discovery. When familiarizing myself with an API for the first time, I'll often just type '.' after an object and see what the IDE (Visual Studio, in my case) comes up with. I suppose a clever IDE could actually populate the list with non-member functions and then replace it with the proper syntax afterwards, but I've yet to see one that can do that.
This is a needed feature that plays well with concepts. Having to add free and non-free functions always is a no-no. It is more important than it appears at first.
So basically this is a docker image that has a compiler toolchain setup for static linking. What if my distro already has static version of all libs that i use, what's the benefit of using HBB over simple `g++ -static` and such?
Interesting. However I still think static linking is not the optimal solution. I prefer maintaining repos for major distros with automated build systems. Sure it covers lesser part of the userbase but at least you're not burdening the system by not sharing libs with other programs. Static linking defeats the purpose of having `/usr/lib`. Speaking of docker, you could make a `Dockerfile` with OS image tailored specifically for running your program. This way if you use say ubuntu as your base image you could provide a repo for ubuntu and a `Dockerfile` for other systems.
currently you have a conflicting draw to :- - Member-Functions (for superior discovery through autocomplete, and less nesting, clearer flow in complex expressions, and ability to change to &amp; from vtable dispatch) - and Free-Functions (for superior decoupling / reusability , and extendability, especially for templated code). So, today we are cursed with bouncing between the two styles, having to make syntax changes to refactor as needs evolve, or writing useless boilerplate to wrap one in the other. I've seen entire sourcebases thrown away over this issue (e.g. it hurts code-reuse, the ability to extract libraries). Although its an extra piece of complexity in the language, it will simplify millions of lines of user code, and make programs easier to extend and refactor. The correct solution would have been to have it from the outset, or something like the system seen in Go or Rust, but we are where we are. I strongly believe UFCS is a benefit that will make C++ use much smoother overall
the 'opt-in' could be an explicitely named 'this' argument, perhaps. e.g. void foo(Bar* b) {...} // not available for UFCS void foo(Bar* this) {...} // available for UFCS. also allows convenient search for 'Bar* this' // also easy to move the definition between a class member-function &amp; free-function
To me, the main draw is readability. Compare this: auto desidred_data = map(unique(sort(filter(data, [](auto const&amp; item){ return item.foo &gt; 42; }))), [](auto const&amp; item){ return toUpper(item); }); vs auto desidred_data = data .filter([](auto const&amp; item){ return item.foo &gt; 42; }) // then .sort() //then .unique() // then .map([](auto const&amp; item){ return item.toUpper(); }); We could do with terser lamda syntax too, but with UCS it's good enough.
Making it dependent on a linkage specifier is a serious pitfall. This change cannot impact working code, only code that would currently fail to compile.
How would my idea affect working code?
Why do you have to care if `f()` is a method of `a` or a free function taking an `a`? I don't want to have to care about this, or have to use a different syntax just because `f()` is a free/member function. It also helps in generic code since `f` might be a free function for some types, and a member function for others.
I'm working on [the Meson Build System](http://mesonbuild.com) that aims to solve (among other things) this exact same problem. Our wiki explains [our approach to the same problem](https://github.com/mesonbuild/meson/wiki/Creating%20Linux%20binaries). It's roughly the same as yours but without Docker. We also aim to provide for osx, win and every other platform available. For GUI apps you might want to look at [Qt Installer Framework](http://doc.qt.io/qtinstallerframework/index.html). It works really nicely. Your app does not need to be in Qt to use it, even. Statically linked Qt is a really simple way of providing cross distro gui apps, though. One thing that caught my eye was this: &gt; There is no way to automatically update application dependencies without recompilation, while also ensuring that their binaries are portable. The two things are mutually incompatible. There is no solution to this. There is actually a solution for this that prevents you from running insecure apps. Meson will (automatically) generate a [dependency manifest](http://nibblestew.blogspot.com/2015/08/proposal-for-dependency-security-scheme.html) that lists all embedded components and their versions. The app launcher only needs to be changed to verify that against a blacklist to block unsecure apps.
Currently it's dumb how you have to make an arbitrary design choice between `print(a);` and `a.print()` when you want a function to print an `A`. We see some of this mess in `begin` and `end` in C++11. They had to jump through hoops to make `begin(x)` be the same as `x.begin()`. 
I never said your idea would affect working code, I was referring to the proposal. Namely that the proposal cannot impact working code, *only code that would currently fail to compile*. In fact, your idea would not only *not* affect working code but it would defeat part of the original intention.
&gt; I think everything should be default constructible. I do not think so. For one thing, you could wrap your type in an optional-like type to make it default-constructible, knowing it does not hold a valid value. I tend to think of a default-constructed object as something that holds a valid value. I think it makes more sense. I understand that Regular types behave better in many contexts, but that should not be an excuse to shoehorn everything into one. Sometimes is not easy, or even practical. 
Oh, no, the good old N1234 numbering is gone!
All of the software that you listed are things that existed prior to C++11. It is easy to continue using the coding convention that was established during the software's development. On the other hand, software that was developed assuming the availability of C++11 would require all that to be stripped out. Just looking at my personal projects, there are a number of things that would require massive changes to run without C++11. * Use of `unique_ptr` and `shared_ptr` for memory management. * Use of `std::thread` and companions, rather than platform-dependent variants. * Variadic templates. * Lambda functions and `std::function` * Hash tables Then there are other niceties that could be removed without major redesign, but would make the code less readable and less flexible as a result. * Chained constructors * Use of `auto` and range-based for loops. * Strongly typed enums While I think that /u/STL was perhaps a bit harsh, I agree with his sentiment.
It isn’t really arbitrary, is it? If print needs to access the private state, then you make it a member function. If print can do what it needs to using public member functions, you make it a free function. (And then you have friend functions for special cases...only use them when you need to.) The downside, to me, is that it ends up _looking_ arbitrary to the user.
Why should it matter whether private state is needed though? And you can always `friend` it to use a free function. I prefer to have a function that's not part of the encapsulation to be a free function, if it would need private data then the object should have methods to get that data.
I assume that by CBlocks you mean Code::Blocks. As someone who uses Code::Blocks I am interested in why you dislike it.
And now, there's a pile of P00.
I don't think this is actually the case because the function would still need to be found through ADL which doesn't occur on completely generic templates.
I think this is interesting software, but is ultimately harmful to the C++ ecosystem. The reason for this is that it provides an excuse to use a very old pre-C++11 compiler for C++. If people are already supporting Centos 5, that means they already have a working build system, and they don't need another one. If they are not, then using this system encourages them to use a much older compiler than they would have been using and pushes back the adoption of modern C++. Criticism is much less useful without some suggestions. So here are mine Use centos 6 as the base. Centos 5 is end of life in Mar 31 2017 which is less than 1.5 years away. Given how close it is, people should at least be thinking of migrating away from it. With centos 6, you should be able to at least get GCC 4.9 running as there is a Red Hat Developer toolset that has GCC 4.9 that works on RHEL 6 https://access.redhat.com/documentation/en-US/Red_Hat_Developer_Toolset/3/html/3.1_Release_Notes/DTS3.1_Release.html The other suggestion that can be used with or without the first is to use clang. Clang has a much better build system than gcc and may be possible to build on centos 5 even, and with centos 6, you should probably be able to get the lastest version working. Once again, being able to build a portable binary on Linux is a good thing, but if it does so at the expense of encouraging people to use archaic versions of compilers that don't support C++11/14, then it is on the whole a bad thing for the C++ community.
It's not syntactic sugar. a.x() and x(a) have completely different lookup rules. In C++, the lookup rules are complicated enough as it is. With UCS, you wouldn't even be able to tell from looking at a.x() which set of lookup rules its using!
I can't upvote you enough! 
You can get gcc 4.8 from http://people.centos.org/tru/devtools-2 See, for example http://braaten-family.org/ed/blog/2014-05-28-devtools-for-centos/ (which describes using it on CentOS 6, but the repo has versions for CentOS 5 too). 
Most of the smart pointers in BOOST, for example, are no longer needed if you have C++11. But not everyone does have C++11 support everywhere, and BOOST implemented them earlier, and intrusive_ptr doesn't have a standard equivalent. http://www.boost.org/doc/libs/1_59_0/libs/smart_ptr/smart_ptr.htm There are other possibilities - I've used a system where dereferencing a "pointer" could trigger de-serialization of an object from a database, so you ended up with a pointer to an object that wasn't there until you tried to follow the pointer to it. (That was actually done with raw pointers, deliberately triggering a page fault, and having the page fault handler trigger the object construction and then rewriting the pointer. But if you wanted to do it in normal code, you would probably use your own smart-pointer-like type.)
sounds very double plus good-ist
Not exhaustive, but an all right starting point: Memory, Cache, CPU optimization links.md - https://gist.github.com/ocornut/cb980ea183e848685a36
The talk was great. I didn't realized what perf was capable of. I've always used valgrind+callgrind with kcachegrind for profiling, which has been excellent, but it isn't quite the same since it is using simulated instead of actual runtimes. Seems like perf and callgrind would be very complementary.
&gt; Then prefer non-template functions, even if implicit conversions need to be performed, followed by template functions That's incorrect. After name lookup finds stuff (templates and non-templates), template argument deduction and substitution runs for the templates in order to generate signatures, which are tossed into the overload resolution arena for a battle to the death. There, the template and non-template signatures compete on equal terms at first, and if a template signature happens to be a better match, it wins. And templates are very often better matches. Only if a template and non-template are equally good matches, does a tiebreaker rule come into play, and that's when non-templates are preferred. (There are other tiebreakers, like partial ordering when two templates look equally good.) Knowing this is *really important* to understanding how overload resolution works.
&gt; While I think that /u/STL was perhaps a bit harsh I don't think he was harsh. (If you watch his interviews or read his longer posts, he comes across very personable, patient, and generally kind.) I think he was just short, with a sentiment (laughter) that most probably honestly feel when reading that statement. And let's be fair: gcc 4.1.2 is over 8 1/2 years old -- it came out within weeks of Windows Vista and a couple of months before the very first iPhone. Would you put up with going back to Vista or XP or old monochrome Blackberry phones? I don't think so. It's time for the world to move on!
&gt; However, in the rest of the real world people do use ancient compilers. Not true at all! The rest of the embedded world perhaps, but a great deal of C++ developers have moved on to much more recent compilers. Shoot, I do lots of embedded work and feel constrained by gcc 4.4.2 and VS2010; gcc 4.1.x and VS2005 are just ancient. For reference, QNX and Green Hills (and probably many other RTOSes) now have toolchains that support C++11 and some of C++14.
Out of curiosity, what is preventing you from moving to C++11? A (very) brief glance at Phusion Passenger seems to indicate you provide a web application server with Python, Ruby, and javascript interfaces. (I don't see C++ in there as an interface.) Can't the server be written in C++11 without causing API problems? Or is it a problem because you need the server to be compiled on OSes that only support ancient compilers? Or is there some other reason?
I second that. If you do not update your toolchain every 5-8 years, you're doing it wrong (saying that as an embedded software person). This is one factor of creating legacy.
[removed]
Back when I first read about Eric starting on the whole 'ranges' thing I was trying to implement my own. I had come to *some* of the same conclusions about how they would need to operate. This library has surpassed everything I was doing. I am super excited to use it. I especially like how he has worked to lessen the boiler plate for writing custom app-specific extensions. My only frustration is that I have to wait a couple of years before I can use this.
[removed]
I'm curious how you want to take a VB.NET and C# frontend and compile C++ with it :)
I wish 'enemy' was a thing, so I could call something like a member but guarantee it only had public access.
IIRC It was specifically because the ISO requires them to place the N# papers in a very specific place (not that they can't be public). But with a P# paper, they could technically place them in a github repo, or host them on the isocpp website.
Here is a fully worked example. All compilers will display the same behavior. C:\Temp&gt;type meow.cpp #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;type_traits&gt; using namespace std; void f(string s) { // passed by value, to simplify this example cout &lt;&lt; "NON-template: " &lt;&lt; s &lt;&lt; endl; } #ifdef PLUS_TEMPLATE template &lt;typename T&gt; void f(T t) { cout &lt;&lt; "Template: " &lt;&lt; t &lt;&lt; endl; cout &lt;&lt; "Was T deduced to be const char *: " &lt;&lt; boolalpha &lt;&lt; is_same&lt;T, const char *&gt;::value &lt;&lt; endl; } #endif int main() { const char * p = "Peppermint"; f(p); string x("Jazz"); f(x); } C:\Temp&gt;cl /EHsc /nologo /W4 /MTd meow.cpp &amp;&amp; meow meow.cpp NON-template: Peppermint NON-template: Jazz C:\Temp&gt;cl /EHsc /nologo /W4 /MTd /DPLUS_TEMPLATE meow.cpp &amp;&amp; meow meow.cpp Template: Peppermint Was T deduced to be const char *: true NON-template: Jazz
I agree with you it's a matter of trade-offs. Also, I want to clarify, I'm not rabidly against this. At worst I think it's 60-40. I think the complexity is non-trivial, insofar as method lookup is currently extremely simple, and free function lookup is extremely complicated. That simplicity is basically being thrown out the window. There's also a possibility that user-error (accidentally calling the wrong name method) which would have caused compile time error before, will call some random function, with odd results (optimal: very weird compiler error. Worst: strange run time bug). I think these issues which apply to day to day development, not to mention new developer learning, are being underestimated in favor of making something that's already possible easier, for advanced programmers.
How about libCinder?
I'd never heard of that, but that's just the kind of thing I'm looking for, thank you! I'll wait to see what other people suggest though.
Well god damn. I don't know how or where I got the idea that non-templates would be preferred to templates even if implicit conversions were involved, that was pretty stupid of me. Thanks very much STL for pointing that out. Broadly I would like to add that this reinforces my point that free function lookups are hella complicated... complexity that method calls are mercifully free from. I think this is a nice benefit, and I think people are underestimating it.
Why dont you... make a library that does something interesting? Because lets be honest here... How do you personally define interesting? What are your interests?
Cinder is [very cool](https://libcinder.org/gallery), and if I were in your position, that's exactly what I'd do. Good advice, /u/meetingcpp.
C++17 currently has a smaller set of changes than C++14, which was a "minor" revision.
&gt; Supporting graphical applications such as those based on GTK, Qt, SDL, OpenGL etc is outside the scope of this project. derp
See the thing is there is a lot of work and skill that goes into making a big library like OpenCV, work that is frankly boring, and skill I do not have. Furthermore, I probably would have no idea how much I would enjoy OpenCV if it was not so easy for me to get in to. However I do want to make projects that are more stimulating than simple text, and a nice relatively high-level library makes that very easy to do, which is one of the main reasons I enjoyed using OpenCV. With that said, my interests are less important than an ability to do something interesting, I can always gain a new interest.
Wow, this also looks very cool, apparently 'creative coding' is a key word that I should be looking for, it seems like Cinder and OpenFrameworks have this description in common, very neat.
&gt; So if you're producing a monolithic binary anyways, how exactly is this better than just bundling all your shared library dependencies with the application? Which would even allow you to use tools that aren't 8 years old. Two reasons: 1. Glibc symbols prevent that approach from working. At the very least, your app and all your dependencies must still be compiled on a system with an old glibc. 2. Space efficiency. If you static link a binary, the compiler can remove object files that aren't used. Or, with the right compiler flags, the compiler can even remove unreferenced code. You can't do that with shared libraries. &gt; That said, whenever I see a company distributing their products like this instead of having a proper .deb What if *you* are that company? Would you want to spend 5 months on packaging things before you can release to users? Or would it make more sense to provide source + portable binaries at first, then incrementally work towards distro-specific packages?
Passenger needs to be compilable on old OSes. We have users on for example Red Hat 5 who wants to use the latest version of Passenger.
&gt; Using something like this is not to make things easier for your users. I think you misunderstood the marketing message. The point is that it makes things easier for users *compared to only providing them with source code*. Let's say you are a person/organization releasing open source software. You want your users to be able to easily use it. But at the same time you know that building packages for all distributions is going to take you 5 months of work. So what will you do? Will you spend the 5 months? Or will you just release the source tarball and let users figure it out themselves? Probably the latter. Given *that* situation, having binaries -- although not as good as distro-specific packages -- is infinitely better for users than only having a source tarball. In this situation it makes no sense to argue against binaries, but few developers are going to bother even making distro-specific packages due to the sheer pain of it. So calling it "lies" is a bit harsh, to say the least. All I'm asking is that you try to see other people's point of views. Also, https://github.com/phusion/holy-build-box#who-should-be-interested-in-portable-linux-binaries &gt; but these days all you need is a docker file for each distribution That's already discussed in the FAQ: https://github.com/phusion/holy-build-box#how-does-holy-build-box-compare-to-using-docker-to-package-up-an-application
&gt; very cool I had to drop openframeworks when their iOS wasn't 64 bit. Other than that I absolutely loved it. 
You can do cute stuff with Qt.
SFML is a nice library, specially for student projects (good documentation / examples) You can make a minimalist game using it, it's good fun
When choosing a library I always prefer snake_case interfaces (unless it's GPL which is a no-go) or wrap the required APIs. The only exception is WTL based windows GUI code. Wish there was a consistent snake_case C++11 wrapper for Win32 APIs plus a GUI editor. I would contribute. =)
Considering snake_case, how do you name your variables when you have only a single local variable for a type? namespace net { struct client {}; struct session {}; } // namespace net Do you do the following: namespace net { session func(client&amp; client) { session session; // ... return session; } } // namespace net Which may give warnings on some compilers and static `session` functions are inaccessible unless you use the namespace prefix. Or do you do: namespace net { session func(client&amp; client) { net::session session; // ... return session; } } // namespace net Which leads to inconsistencies when the namespace is added for clarity and when it's not. I really don't like using abbreviations or single letter variable names sinced it's not clear what they represent in a long function.
https://www.youtube.com/watch?v=pWdd6_ZxX8c
It's pretty fun. Back when they had the whole /r/pcmasterrace + /r/gaming debacle, I made [this](https://www.youtube.com/watch?v=6_fn_E4WZ40) in like an hour. If you want the source: https://github.com/Astrognome/TaxBlaster
Can't newer versions of gcc be installed on the old OS? Or do the programs need to be compiled using the version that shipped originally with the old OS?
So...this doesn't answer your question at all, but: How did you go about learning openCV? I'm in compsci 2 so I'm still getting the hang of libraries, but openCV looks like something I could spend months playing with. 
OpenCV, Cinder, OpenFrameworks, GLFW, Eigen, Cereal, TinyExr, libtarga, stb_image, lz4, lua, WxWidgets, Qt and QtQuick, NanoVG, moodycamel::concurrentqueue, embree, openGL
If you're into audio, check out JUCE
For those listeners familiar with the mostly British billiards game snooker, Anthony sounds almost exactly like Steve Davis :)
&gt;&gt; "Your team threw away otherwise perfectly good code because sometimes it used methods and sometimes free functions? You have too much free time on your hands!" its' because everyone disagrees on what should go in the class and what should be free functions. So the source code is continually refactored based on conflicting&amp;changing requirements. The specific 'throwaway' I mention happened because of excessive coupling in classes - pieces of common code from 2 sourcebases could not be easily extracted as libraries for use in a different project. The projects started at different times on different platforms, but had lots of commonality (in theory) found in retrospect. The problem is free-functions are unpopular - the discovery aspect of 'dot-autocomplete' is huge; (also many programmers are conditioned to 'think in classes &amp; methods' by education in Java, however irrational superficial that is, its' another strong preference issue you have to fight in the workplace. 'ew, its' like C'). So you've got a constant draw to bloating classes with excessive dependancies, to make it useable in other ways. You should be able to get both benefits simultaneously - decoupling, discovery,readability. If the same benefits were available with one syntax this conflict would go away. You'd write everything with one syntax, wasting no time changing it, and be able to smoothly shift code &amp; in &amp; out of the classes according to changing demands and refined knowledge as the sourcebase grows. &gt;&gt; The C++ community has no experience with this. Why do you believe it to be true? Other languages - D, Go, Rust,C#, Swift,..all have solutions for this demonstrated, so lets stop dragging our heels over this and get it sorted instead of apologising for broken features and language omissions (stockholm syndrome). The C++ community had no experience of lambdas, but lambdas were demonstrated decades ago elsewhere - we didn't need to wait for the C++ community to figure out that they were a good feature, worth adding (and now they are an absolute godsend for parallel abstractions needed for multicore programming) &gt;&gt; You actual gain one character, You lose a character but you can place the function names closer to their arguments (thats' the reason we have infix notation generally) e.g. compare `a.foo(b).bar(c).baz(d)` with `baz(bar(foo(a,b),c),d)`; it's much easier to see the imperative order of calls, and flow of values through the expression. It's also easier to write (and with dot-completion you get context-sensitive documentation appearing as you write, keeping your focus on code, saving time scouring documentation).
...why? Usual template instantiation rules apply.
&gt; Is C++ becoming obsolete slowly ? No (for all the reasons [posted by blelbach](https://www.reddit.com/r/cpp/comments/3n7fxt/is_c_becoming_obsolete_slowly/cvlhwbx)). Also, yes (everything is _slowly_ becoming obsolete). That said, it will probably be around for a long time, and it is not even close to obsolete _today_; Nor will it be so, within the next 20 (50?) years or so.
I don't see a call to f(). I don't see static or global initialization. That;s why I wouldn't expect the code to print "I'm alive!" which it according to [coliru (click)](http://coliru.stacked-crooked.com/a/eab3aff18d0d2a89) does.
Here is an example that shows the same rules in action without variable templates. The code below prints "I'm alive!" twice: once for `x` and once for `y`. #include &lt;stdio.h&gt; template&lt;class T&gt; T x = T{}; // without variable templates template&lt;class T&gt; struct y { static T value; }; template&lt;class T&gt; T y&lt;T&gt;::value = T{}; void f() { struct Test{ Test() { printf("I'm alive!\n"); } }; (void) x&lt;Test&gt;; (void) y&lt;Test&gt;::value; } int main() { return 0; } 
C++ best features is operator overload ... I designed a library called protocole that allow to code as this * D ---o--&gt;E -o--&gt;F * |¨¨¨| * |¨¨¨o--&gt;G -o--&gt; H * |¨¨¨|¨¨¨| * |¨¨¨|¨¨¨o--&gt; L * |¨¨¨| * |¨¨¨o--&gt;A -o--&gt; B * |¨¨¨¨¨¨¨¨¨|¨ * |¨¨¨¨¨¨¨¨¨o--&gt; C * | * o--&gt;P; 
In my work, we develop a large project to be deployed in industrial settings, and we need to support Linux, Windows, and Windows CE. Moreover, performance and good memory management is critical. There is a lot of legacy code of course, but even if we had to start from scratch, C++ would still be a natural choice. Also, even with the huge datacenters, performance is actually as important as ever. For example, Facebook reimplemented a lot of standard library stuff to gain a few percent on performance (look at their "folly" library at github), since that will save them millions of dollars (said Andrei Alexandrescu in the following video discussing how they optimize C++ code at Facebook: https://www.youtube.com/watch?v=MvFj8qo1iuA) C# + .NET is a fine platform, I enjoyed programming under it, but I myself don't see an increased demand for windows-only solutions. So if C++ seems a niche language to you, I'd say C# is even more niche.
Your last line in f instantiates the *global* template variable x, it doesn't create a local variable. The instantiation gets evaluated even though f isn't called because f isn't a template function, so the compiler has the whole definition and can compile it right away. Also notice that f is not static or in an anonymous namespace, so for all the compiler knows f is declared in a header somewhere and may be used in other translation units, so it must generate code for it. I think even if it wasn't though it might have to instantiate the template by the standard.
Please be aware: OP is a troll. Look at his previous postings.
C++ lack many things that shouldn't even be lacking... Filesystem ( starting from C++14 ) Socket API ( now it's ASIO C++ 17 may be ) Reflexisve object description ( C++ 17 ) Unsafe typed object ( still out of horizon ) Function's signature ( retardly not normalized : That's alone is 99.99 of why coding in C++ suck for support team ) OS version inability to be automaticly ported ( you still need to recompile your code for just using last library of OS instead of changing linking pointer ) People are quite happy to forget that using C++ make suffer all external team using your code. Black box, inability to update micro function, impossibility to guard offrun hook ( aka open the library with a hexnotepad and change calling os function to another ), impossibility to use ABI when you actually don't need the API that created the ABI break, retardly easy to hack when loadlibrary function is used, align structure dependant ( you still can't call a function 32bit with a aligned function 64bit without detonate on tarmac ), still won't have a guard descriptor for variadic and the number 1 reason ... you still can't micro prototype without been an expert at using dump memory and debugger. Micro testing in C++ is the most retarded concept * insert a load library somewhere you think can be usefull * launch the code * make a dump save point * code a loaded library * compile loaded library * call the dynamic library module * step by step until calling * stop the code * move the load library further the place to test * recompile * ... * test * ... * move the load librarty further * recompile * ... * test etc ... Where using D or C parsed ( with tinyC ) you just run a small piece of code that load and execute all .c file changed and rexecute all function. 
That's actually a very neat idea that I had not considered.
If you write this simple non-template code: #include &lt;stdio.h&gt; struct Test{ Test() { printf("I'm alive!\n"); } }; Test t{}; int main() {} It prints "I'm alive!" because of the `Test t{};` initialization despite the empty `main()`. Now lets exchange `Test t{};` for a variable template: #include &lt;stdio.h&gt; struct Test{ Test() { printf("I'm alive!\n"); } }; template&lt;class T&gt; T x = T{}; int main() {} This exact code isn't going to print anything because we haven't instantiated `x&lt;T&gt;` anywhere. The compiler essentially emits code like the `template&lt;class T&gt; T x = T{};` line isn't even there. Now we actually use `x&lt;T&gt;`: #include &lt;stdio.h&gt; struct Test{ Test() { printf("I'm alive!\n"); } }; template&lt;class T&gt; T x = T{}; void f() { (void) x&lt;Test&gt;; struct Test2{ Test2() { printf("I'm alive, too!\n"); } }; (void) x&lt;Test2&gt;; } int main() {} The compiler will look at this template code and emit this non-template version: #include &lt;stdio.h&gt; struct Test{ Test() { printf("I'm alive!\n"); } }; struct Test2_from_f{ Test2_from_f() { printf("I'm alive, too!\n"); } }; Test x_test = Test{}; Test2_from_f x_test2 = Test2_from_f{}; void f() { (void) x_test; (void) x_test2; } int main() {} So it just replaced `template&lt;class T&gt; T x = T{};` with 2 concrete instantiations and from there normal non-template rules apply, just like in the first example.
&gt; linus torvalds once said C++ was a big crap language and he prefered pure C... and yet he ported one of his software from GTK (C) to Qt (C++)
I can attest to the wonders of OneTab - you hit the button and it condenses your session to a list of formerly-open tabs and sessions. I once hit it and got rid of 136, but can go back later. I might have a problem.
Theoretically they can install a new compiler, but the process of doing that is almost always a total pain, causing the user to give up in frustration. For one, they most likely won't be able to install newer compilers using OS-specific packages, so they need to compile from source. Only reasonably technical users can go through that process, and even they would hate you for imposing that requirement on them.
Yes, Red Hat 5 is still supported by Red Hat. It still gets security patches.
&gt;Jon Kalb's book "C++ Today: The Beast is Back"[2] is a great read if you're interested in the rebirth of C++. &gt;TL;DR - No, shifts in the industry have caused a resurgence in C++. We're back, and we're not going anywhere. No, there is no rebirth, C++ is not "back". **C++ never left.**
&gt; Is C++ becoming obsolete today in 2015 with language like Java and C# who can do more stuffs I'll answer your question with another question: Why is the C# VM written in C++?
Because it's trivial to implement in terms of other more generic and powerful standard library idioms. If you think it's ugly then throw it in a function called split and forget about it.
Well, if it gets into the standard and then you look at the source code of the final implementation, I can guarantee it will be as ugly as those, or uglier, because it should be as general as possible. You better avoid learning how sausages or laws are made. BTW, this is the version I use (edited): void split(const string &amp;s, char delim, vector&lt;string&gt; &amp;elems) { elems.clear(); stringstream ss(s); string item; while (getline(ss, item, delim)) { elems.push_back(item); } }
[Here](https://www.quora.com/Are-there-any-particular-reasons-why-a-powerful-language-like-C++-a-doesnt-have-a-split-function-in-any-STLs-not-like-Boost-etc-b-has-an-implementation-of-std-map-closest-approach-to-hashtable-under-the-hood-implemented-with-a-red-black-tree) is an explanation why it's not feasible to implement a split function that's generic enough to be part of the standard library. It considers mostly C++03, so maybe we'll get one eventually, enabled by new features.
std::algorithm contains a lot of (even more) trivial functions.
Also he commented something about all the crappy programmers C++ attracts or produces, didn't he?
The procedure for submitting a proposal is here: https://isocpp.org/std/submit-a-proposal Correction, there was a recent proposal: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3510.html - you may start by contacting its author about the reasons it didn't move forward. Perhaps it's simply waiting for ranges and string_view (which are both prerequisites)
Great question, I had fun answering it ! As other have pointed out, I guess it has to do with memory allocation &amp; performance. Namely, how do you handle large inputs ? A generic solution should avoid copying the input, and should be able to behave properly in face of a large input. The solution is indeed to use views. But even then, you can have a large number of string_views returned. So a better solution is to process the chunks as you split them, in a lazy fashion. Such tool doesn't exist yet. Or does it ? See, I used your question as a pretext to try out /u/eric_niebler 's range-v3 library ( soon to be the foundation of STL2, maybe) Despite the lack of documentation, I came up with that in a few minutes. Maybe there is a better way to do it though, but it's a start. #include &lt;string&gt; #include &lt;iostream&gt; #include &lt;range/v3/all.hpp&gt; int main() { std::string words { "I guess you were eager to see a lot of words there but I am way too lazy"}; RANGES_FOR(auto word, ranges::view::split(words, ' ')) { ranges::copy(concat(word, "\n") , ranges::ostream_iterator&lt;&gt;(std::cout)); }; } **TL;DR : There probably will be a `std2::view::split` method in the future** :)
Well played! :-)
Thank you! It was way more fun to come-up with that than I expected. (but I don't think I would have been able to write split.hpp if it didn't already exist). Is there a better / more idiomatic way though ? 
Yes, Like you said, with Ranges (added on C++17), Move (added on C++11), and better templates (concepts from C++17) I think it will now be possible to write a great split template function! (Also, string_view from C++17 might also be handy)
I don't see how C++ would NOT benefit from having way more basic helper functions / methods
I'm not so sure. Once you start letting substandard stuff into the SL, where do you stop? It's not like the SL is the *only* library, or that this is difficult to implement yourself (for your specific use case, not generically). So it's just not that urgent.
The boost split seems to work on ranges and not iterators. So it might be included once the standard library adopts ranges. 
It is terribly inefficient, but you can write some decent code by using `std::regex` + `std::regex_token_iterator`, and it might actually be not so bad if your separator needs to be an actual regex.
But wrapping an old crusty C API like OpenGL with well-designed C++ is a great learning experience. ^^^although ^^^be ^^^prepared ^^^to ^^^fight ^^^the ^^^urge ^^^to ^^^gouge ^^^your ^^^eyes ^^^out
This should be the top comment.
Which is why Java and C# are going AOT. So you get to choose. [Compiling Apps with .NET Native](https://msdn.microsoft.com/en-us/library/dn584397.aspx) [JVMLS 2015 - Java Goes AOT](https://www.youtube.com/watch?v=Xybzyv8qbO) In Java, the only difference is Oracle is now looking at it, because there are quite a few commercial JVM vendors that already offer AOT compilers like [Excelsior JET](http://www.excelsiorjet.com/). However C++ is still a good companion for JNI and P/Invoke glue for those languages. And in many domains where shaving every ms or every byte counts. We get to use Java/C++ or C#/C++ in some of our applications.
This is a quick library that I've been putting together for work that is similar to string_view, except it does everything except the stream-handling at compile-time! I'm definitely looking for any feedback that anyone has, as well as issues and pull-requests!
The c++ standard library is an exercise in generic^H^H^H committee mental masturbation, not getting things done. (It's also the ugliest source code you'll ever see, lots of one letter variable names to save preprocessor time) Hence, that's why it's the most useless string class in existence. split? endswith? format? strip? nope.
Wait, what? When I looked at the released C# VM code from MS, it was in C++. When did the switchover to a C# VM written in C# happen? (Not the compiler, mind you. The virtual machine that runs the compiled bytecode.)
You are talking nonsense. There are multiple C++ standard libraries, and ISO c++ committee has nothing to do with any of them.
http://www.boost.org/doc/libs/1_59_0/doc/html/string_algo.html
Question about not_null&lt;T*&gt;. I'm trying to test if it can detect a null passed into the function at runtime via a variable. Bjarne mentioned in his talk as a subtle point. Currently it doesn't seem like declaring a parameter as not_null implements any type of checking. I get a segfault if I try to pass a null pointer into that function. I was under the impression not_null was supposed to implement some sort of mechanism to help catch this (obviously I'm mistaken)?
I didn't said it happen. I said it might happen. Currently you have four options, when looking at Microsoft tooling. - Classical JIT for .NET &lt; .NET 4.5 and 32 bit processors in .NET 4.6 - RyuJIT for 64 bit processors - The NGEN that exists since the .NET 1.0 that AOT compiles at installation time. - Compile to a static binary ahead of time with .NET Native With .NET 4.6 they introduced .NET Native, which is a AOT compiler to native code, producing static binaries. Currently they are using C2 for the backend, which is the code name for Visual C++ backend. https://msdn.microsoft.com/en-us/vstudio/dotnetnative.aspx http://blogs.msdn.com/b/dotnet/archive/2014/05/09/the-net-native-tool-chain.aspx This is an evolution of the Windows Phone 8 compiler MDIL, which also compiled MSIL into native dynamic libraries, with just the linker available on the phones. https://channel9.msdn.com/Shows/Going+Deep/Mani-Ramaswamy-and-Peter-Sollich-Inside-Compiler-in-the-Cloud-and-MDIL With .NET Native you get the same type of binary as any other language that has an ahead of time compiler capable of producing static binaries. However it isn't open source and currently is only available for .NET applications that are distributed via Windows Store. Also if you go read the paper published by Herb Sutter about C++ lifetimes at CppCon 2015, you will find a reference to System C# which is the evolution of Sing#, the system programming language used to program Singularity. 
Assuming you're on C++11, is there a good reason to pass in a reference to elems instead of returning it by value?
&gt; There are languages with much wider standard libraries and they do just fine Not in the performance department.
My purpose in programming is rather an outlier: I do original research in abstract algebra. The software to calculate what I need simply isn't available, so I write my own. Using C++ in a disciplined manner, I can obtain robust, efficient, reusable code. The extensions to C++ that appear every few years make my work easier, so C++ isn't becoming obsolete for me.
How would having a string split function in the standard affect performance?
 &gt;Is C++ becoming obsolete today in 2015 with language like Java and C# who can do more stuffs or if you want, has a broader range of applications with web dev, database, mobile, ui etc Java is most certainly dying. While C# has a few good parts it is still considered to be a Microsoft only language. Neither of these though has the flexibility to run anywhere like C++ does. The application range is so broad for C++ that it makes your first statement here hilarious. &gt;I know its important to understand the underlying concept like memory management and all that but C# and Java seem to be used more and more in the enterprise space and C++ (if we dont count games) for normal program seem to become a niche language or we just call some part of a program in C++ tru interop invoke inside a larger C# one etc. This isn't true at all. In fact many enterprises have actively rejected Java and have been reluctant to embrace C#. Microsofts push to reinvigorate C++ on Windows is directly due to the industry demanding something better than C# or Java that has universal support. &gt;What's your thought on that ? is C++ giving way to C# and Java because datacenter, and computers are all getting 24gig of ram and multicore cpu and performance is less important ? C++ isn't giving way to C# nor Java. In fact Python has enjoyed a huge ramp up in popularity and is displacing Java and C#. &gt;or the mobile revolution for example... linus torvalds once said C++ was a big crap language and he prefered pure C.... is it because the standard commitee failed at implementing a true STL What in the hell is a "true STL". Every time I've used STL it has worked as expected after reading the documentation. Eveytime, I can't even say that about Python. By the way C++ has evolved significantly over the years and is far less of a crap language than it was. &gt;or better global librairies to be used for everyone a bit like jvm or .net framework This is an acknowledged issue with C++, thus a rather massive effort to expand or improve the standard library. However that doesn't mean what they have now is ineffective or not useful. Contrast this with the morass of libraries that come with Java, many of which are outdated or hardly used. In a nut shell you have demonstrated a minimal contact with reality with respect to C++. C++ will go away one day, there is no doubting that, but I can assure you it won't be replaced with Java nor C#. 
Which means that there's a good chance it will make it to the standard library one of these decades.
Seriously have you looked about the net for the various logging solutions that exist? Why you try to munge something together, that would ver half assed, to solve what amounts to a logging problem is beyond me. 
&gt; If anything, Java and C# are on the decline. OK. This is bullshit and you know it.
This copies the strings though. Twice.
That book is amazing. It helped me learn the new parts of 11/14 and is really well written. I highly recommend it!
no. push_back stream find_first_of is a one-liner.
C++ needs a good cross platform standard package manager. Pushing stuff into the standard library because the packaging system sucks isn't the way to go IMO (coming from the land of java where they do that all the time much to my dismay). I do think that fundamental things like string manipulation should be part of the standard. I even think that "standard interfaces" should be something to push for in a language (A standard database connection interface does wonders for the java land). But I don't like the idea of pushing actual database or gui stuff into the standard (swing is horribly done). My standard for what goes into the standard would be something like "Would 99% of mid sized applications benefit from this". If the answer is no, don't put it in the standard.
Absolutely shameless plug: https://turingtester.wordpress.com. There's only a few posts so far, but more are coming. I put a lot of work into each one, I think you'd find it interesting. 
What container should the split strings be stored in? What container should be used for each string in that container?
This also means it can be misused though... I'd probably at least clear the vector in this function just in case.
by encouraging ad-hoc solutions instead of container-appropriate solutions. part of the design of c++ is to include in the standard library only things which can be implemented generically efficiently. this cannot be implemented ***generically*** efficiently. it can, however, be written as a one-liner efficiently. c++ is the language you go to when you need efficiency more than convenience. therefore it will not wrap three commands into one if it cannot do it efficiently. the correct answer to this question was given many times in this thread before you asked it.
Huh an interesting tradeoff... I'd probably choose LLVM style but would definitely want to be able to choose which one.
Not in particular. Added the clear in case someone decides to use this code.
The code is in the public domain. I think you should post your improved version, so we all benefit from it.
I think all you need in the way of language extensions would be to change `final` from "no subclasses" to "no subclasses except those specifically listed in the class definition" (and new syntax for that), and at least one translation unit would need to see the entire class hierarchy. 
It does have support for VBOs though... Which SFML doesn't have. Makes me wonder if I should port my game from SFML to Cinder.
Scott Meyers is an incredible writer and speaker. I've been following him and Effective Modern C++ since his first announcement at C++ and Beyond, and it was absolutely worth it. I'd go as far as googling him up and viewing all his presentations on his site as well: http://www.aristeia.com/videos.html Some of the material's becoming a little dated, but I've found his talks to all be very interesting and informative.
I think this is the best book regarding C++11/14 there's right now, it's very well explained, very easy to read, and always give good input as to why it as been done this way and why we needed these feature Also, if you are specifically interested in the threading features available in C++11/14 (lock based / lock free / memory model), you should have a look at Concurrency in Action by Anthony Williams (http://www.amazon.com/C-Concurrency-Action-Practical-Multithreading/dp/1933988770), but this book is not as straight forward as the one from Scott Meyers (unfortunately), you will sometimes need to see external resources to ensure you understand some concept (specially true when he explains the memory order)
There is CSV parsing in the standard library for some language!? Which one?
Heh, you say "C++" and think "C++ language and the standard library". Standard library in C++ is minimalistic, mostly for reason of performance, just like it is the case with C. So it is nowhere near close to standard libraries of other languages. However, if by "C++" you mean "C++ ecosystem", then there's a plethora of split() functions for you. I personally prefer the [boost split](http://www.boost.org/doc/libs/1_36_0/doc/html/boost/algorithm/split_id2965593.html). Now, if you look at that b oost thing, you see something interesting: this splits virtuall *anything* using anything as separators. Standard libraries of other mainstream languages will give you split on strings. From that standpoint, I hope that C++ *never* adds a split function to std::string (or a standalone one that gives you a vector).
At least Python: https://docs.python.org/3/library/csv.html But in a lot of modern languages it doesn't make that big of a difference whether something is standard or not. With package management and modules using a separate library is much less pain than in C++.
[Python](https://docs.python.org/3.3/library/csv.html), [D](http://dlang.org/phobos/std_csv.html) and [Ruby](http://ruby-doc.org/stdlib-2.2.3/libdoc/csv/rdoc/CSV.html) are the ones that come to mind, but with a standardized package manager not having it in the standard library is not a big deal: in Rust for example all you'd have to do is add a line in your `Cargo.toml` file: [dependencies] csv = "0.14" (I only brought up Rust as an example because that's what I've been working with lately)
Your arguments have merit but I don't want to continue talking to you because you just can't resist inserting minor belittling insults into your answers.
Appreciate the feedback. I feel like the type of show you're describing though may require visuals/code examples though.
This is why I don't understand why people avoid boost. Just bring in boost and you'll have access to most of what you need. 
Look for CppGuidelines on github, on the account isocpp. It's powered by B. Stroustroup and H. Sutter
Yes but it calls other headers and uses some macros (e.g. LLVM_ATTRIBUTE_UNUSED_RESULT) . Pretty sure it's simple stuff, but it's not something one could just add a submodule to.
Uhm yes, I didn't consider that. So the best approach I can think of now, is to simplify the ABI ? By using simpler structures for storing type infos and virtual tables we could inline dynamic_cast so even more optimization can be run.
LTO all the things!
For the name you mean? No particular reason. As I was starting, I went through a handful of names (including constexpr_string_view), but ended up having to give up when it became close enough :) BTW: I didn't get a chance to see it live, but I hear great things about your Hana presentation! I look forward to seeing it on video.
What do you mean? That there is a high chance that this submission will be removed by moderators? Did I violate any rules?
Nice. Looking forward to more posts!
Yes, I was talking about the name, and it's mostly a nitpick really. Regarding Hana, thanks for the comment! CppCon videos should be up soon. If you watch it and have questions/comments, don't hesitate to contact me directly.
It is a higher level abstraction layer built over enet.
The problem isn't just the creation of DEB/RPM packages though. It's also the fact that you have to create a new one per distribution version, so you need to manage a fleet of VMs or pbuilder-dist/mock environments.
It will be space constant, but doesn't the lambda run on a new thread? While that's still more efficient than higher-level languages (C#'s foreach actually does a GC allocation for no reason), it's still a lot of extra overhead for something that could be "compiled away". That's why cpplinq is so neat; its assembly output (when optimized) is as clean as the equivalent C code's and sometimes actually more efficient!
My impression from it and all the talk about it is that is isn't actually meant to be read like a book and is geared more towards the auto-tooling etc.
&gt; "Within C++ is a smaller, simpler, safer language struggling to get out." -- Bjarne Stroustrup Here is the link: https://github.com/isocpp/CppCoreGuidelines
Cool. Thanks.
I find the naming unfortunate, namespace and class with the same name?
https://gcc.gnu.org/gcc-4.8/cxx0x_status.html
Oh, excuse me! It looks like my submission was silently removed by those moronic reddit's bots. I shall try to repost.
I do not know about 'good', I'm terrible at naming ;-) From the top of my head: `namespace keane {}` or `ekeane`. The library is from you, why not name it after you? Take for example the JSON library (see https://github.com/nlohmann/json) from Niels Lohmann. He uses the namespace `nlohmann`. This way, the probability for name clashes is practically zero.
I don't really understand the problem this is trying to solve. If you want to produce a cross-distro Linux binary, you just need a Linux virtual machine with a distribution old enough. Build the binary there, it will pick the (old) glibc symbols and it will work on same or newer versions of glibc because glibc keeps compatibility. What's the benefit in using Holy Build Box? 
I'm sure you'll get people on both ends, but I find this to be one of those subjective things where what matters is that you pick one and do it consistently. I don't see anything about this in the guidelines at a glance, and the subjectivity is probably why.
Or global state.
&gt; Because using a VM is heavyweight and generally just a huge pain to setup and to use. Really? Are you running on a potato because I have several Ubuntu Server virtual machines for testing and they use basically no resources and are trivial to use.
&gt; I didn’t have a compiler that implemented any of those ideas and had to emulate them in various ways. And then Visual Studio 2015 shipped earlier this year. Wasn't this in g++ since around 2013?
Thanks!!!
Cool, amazing and interesting topics! I wonder, by when the videos would get uploaded.
The fact that you are making an assumption about "where I am" (and then, of course that must be "lower" than you are) based on just the fact that I disagree with you speaks volumes. And I very well might have a weaker grasp of the language than you, but that is not the point. It is completely orthogonal to what we were discussing. You just had to bring it up and insult me childishly at least three times. Grow up.
Another way of doing this is to build your own toolchain using for example this tool [crosstool-ng](http://crosstool-ng.org/). It supports GCC up to 5.2. Choosing fairly old glibc will make sure, that your binaries will run on most, if not all, relevant Linux distros. glibc is the only library which is not advised to link to statically due to its close connection with a Linux kernel. Then, you use this toolchain to build whatever libraries you need and link them in statically. But granted, this project saves you from dealing with this all. 
Please do. :) 
Why ain't sigc++ on that list?
Thanks. Worth waiting :)
No, GCC has not implemented async/await (and it'd be a waste of effort for them to do so before it's further along in the standardization process).
Note that this link is only for one section of the materials. There are keynotes, demos, tutorials and lightning talks as well. The [readme](https://github.com/CppCon/CppCon2015/blob/master/README.md) has a full index of all of the sessions. We're also still waiting on some of the presentation materials and will update those as they trickle in.
The keynotes are already up on [CppCon's YouTube channel](https://youtube.com/user/CppCon)
Everyone is where they are. Staying where they are means not learning from others. I didn't make any assumptions. It is valid to say "you don't want my help? Okay, then don't benefit from it." I am not sure why you're doing this. Have a nice day, buddy.
* The implementation is several orders of magnitude simpler and much shorter with in case of the facade just three stdlib-includes (and none of them is `type_traits`). * It is very small which means that it might be usable if big libraries like boost are for some reason (for instance a required review) out of question. * From what I understand boosts version requires you to implement even those helper-functions that could be inferred from the others (increment() = advance(1)). * I haven't done any measurements yet, but I wouldn't be surprised if it was much faster to compile. 
Only a pathetic cunt like StoneCypher can insult a person and spin it as trying to help them out and then insult them again for not wanting his "help". You really are a piece of work you dumb, fat, egotistical piece of shit. Guess talking down to others is all you can do when you're as dumb as you think you're smart. Hope you're having fun being the president of the Dunning-Kruger society!
1. Agreed. 2. Agreed. 3. I think boost iterator adaptor doesn't require that. 
so the next time your boss takes a vacation, are you going to write a `std::nurikabe` proposal? :)
Seems unlikely that I could get that through the Library Working Group. But I am trying to add a section named [zombie.names], so we'll see if I'm successful (really).
well, given that there now is a SG14 for Game Dev and Low Latency, who knows... Is the `[zombie.names]` for all the deprecated stuff that you would like to remove (or that has been removed in older versions)?
Yeah, it's for auto_ptr/etc. which was removed last time, and the result_type/etc. that I want to remove this time. I want to add weasel wording to allow implementations to continue providing the old stuff if they want, and forbidding users from macroizing/etc. these identifiers. So all we have to do is list the identifiers that they can't mess with.
Unrelated, but you should be using Community instead of Express. (We actually make it pretty hard to find the Express download.) My psychic debugging powers suggest that this has failed to compile. What happens if you Clean, then Build? Look at the Output window. You're calling system() without including the proper header (I suspect you haven't added anything to the PCH), so that could be why. (I forget what &lt;iostream&gt; drags in, and you aren't guaranteed that.) Also, it looks like your Source3.cpp isn't part of this Solution, as indicated by the Solution Explorer. I'm pretty sure this is the reason, now.
[Huh, I'd thought that non-auto concepts weren't making it into C++17](https://github.com/CppCon/CppCon2015/blob/master/Presentations/Haskell%20Design%20Pattern/Haskell%20Design%20Pattern%20-%20Sherri%20Shulman%20-%20CppCon%202015.pdf) (that is, no concepts would ever need/work with `concept_map`); is it?
can anyone explain if concept_maps are in the upcoming concepts TS? https://en.wikipedia.org/wiki/Concepts_(C%2B%2B)#Concept_maps 
That's a good catch on simplifying the implementation. Maybe I'll go back and provide the the implementation you suggest. I mention assuming the types are trivial, or at least I thought I did. The static_assert inside ArrayView will protect if you ever actually access the type. I agree though, if I was writing this as real code I would have included that static_assert (and others). For teaching purposes, I didn't want the digression, given that I would have had to explain how to static_assert that every single type in a pack is trivial. Likewise with the class' invariant, I considered this point. It's obviously less safe, but more performant. Again, I mostly skipped this for pedagogical reasons. That's why I consider this a "sketch" of a solution. The self safety is a good point too, I'll try to add that in. I'm not sure what you mean by use a tuple, use a tuple for what exactly? Can you elaborate? These are all excellent points. In some of the points its clearly my technical failings, but in other cases its trade-offs off of getting every detail right for conciseness. If you have any thoughts or suggestions for how I can make those trade-offs in a better way, I'm interested to hear. In many cases I consider "pre-empting" the point by at least mentioning it briefly. The issue is that there are so many details, if i pre-empted all of them it would really wreck the readability of the article IMHO.
A tuple would only work with arrays of compile-time size. I think this would be quite useful if it worked like a vector. Say you need to store a certain amount of objects and then iterate over them in different passes where only some members are relevant at each loop. If the data is packed into a separate vector for each member it could significantly increase cache performance, but using several vectors would require multiple allocations causing heap fragmentation whenever the capacity is exceeded. Ill try to write some code but i'm on my phone: struct foo{TypeA a; TypeB b; TypeC;}; std::vector&lt;foo&gt; objects; for(auto&amp; o: objects) o.a.someMethod(); for(auto&amp; o: objects) o.b.someMethod(); //etc vs std::vector&lt;TypeA&gt; as; std::vector&lt;TypeB&gt; bs; std::vector&lt;TypeC&gt; cs; for(auto&amp; a: as) a.someMethod(); //you get the idea The second case will give better performance for the loops but requires three allocations.
Are you sure your segfault isn't caused by an assertion or uncaught exception or call to `std::terminate`? Because all of those _are_ mechanisms to catch this...
In addition to STL's comments, I'm also pretty sure that `#include "stdafx.h"` is required to be the first non-blank, non-commented line of code. But starting out, I would recommend unchecking the "Use precompiled header" box or whatever it is when making a project. It's not a standard part of C++ and it's one unnecessary extra thing to have in the code when you're trying to learn and share the code with others for questions. For example, if that line of code is pasted into an online compiler, it won't work. I'd say just use precompiled headers when you know you need them.
Ooh, yes. Anything preceding a PCH is ignored, because PCHes are compiler memory snapshots.
I can be wrong about this, but i think it not true. LGPL means that any parts of code which is connected directly to your LGPL source should be either open source or use dynamic linking with LGPL sources available to your software customers. Keeping that in mind - with C++ template header-only library its impossible and makes this library essentially GPL. Because, when I(software developer) use your library, LGPL demands from me to publish any code that is linked directly to it - so either I create standalone so/dll which contains all custom iterators based on your templates (implementations for end product - not changes to the library code) or I should make my entire app GPL friendly. This, in the end, makes this helpful library extremely hard to use in any commercial end product. If you really want to lay restrictions of library changes(any change should be made public), but allow your users to use it in their end products without changing their app source licenses - I suggest you look at EPL or MPL - both of them require that changes made to the original source should be available under the original license, but allow any code that uses it to stay on different license. For example &gt; code files licensed under the MPL must remain under the MPL and freely available in source form P.S. But in reality - MIT and BSD just work. Do you really think that if anyone improves your library - they will keep that to themselves? Most of the people today contact original owner about bugs\fixes and\or improvements. Github era.... we are all friends here :)
i can't believe no one suggested this, but why not avoid the macros, write a function that calls printf and adds the timestamp with the same signature as printf then just do a find+replace on the name in all the files.
To elaborate on this, if properly organized, this can be a very useful tool when compiling code on multiple platforms. Commonly included files are explicitly included where need before inclusion of the precompiled header, and in the PCH (typically "stdafx.h" on windows). Precompiled headers can be a great tool, but they're not what I'd refer to as newbie-friendly. I'd almost rather they were an opt-in rather than an opt-out feature.
Clickbait. For the code, better look at [Rosetta Code](http://rosettacode.org/wiki/Rosetta_Code) directly. This saves you cognitive energy filtering out the ridiculous "11 most interesting throughts ever" clickbait on the right-hand-side. The C++ tutorial was copied from: [Udemy](https://www.udemy.com/topic/C-plus-plus-tutorials/)
I do the same thing. .h is as normal, .cpp is essentially only a convention at this point, and the .t contains the implementation. If a class is only partially templated I'll choose to either leave that code in the .h, or use a .t if there is enough to merit it. I tend to just use the .t even if there's only 1 templated function though in case I add more, I'd move that back to the .h if in the end there was only a small amount though when I was giving this code to someone else or sharing it.
&gt; blahblah::blahblah_iterator Yes, it's about that. &gt; is that difficult Not really difficult. But a lot of pointless work because of the huge amount of functions you have to implement even though most of them do more or less the same thing. Aka you have huge amounts of boilerplate. 
Eigen actually used LGPL for quite a while and they explained [here](http://eigen.tuxfamily.org/index.php?title=Licensing_FAQ&amp;oldid=1116) that this is not the case.
those snippets doesn't even compile :D
Thanks - I didn't know about LGPL v3 header only permissions. I wonder tho, how this will change if C++ will actually get modules.
fixed quantiative functions: https://news.ycombinator.com/item?id=10333197
Idk but I do know that 5.2 is out.
As IDE-s are evolving with much improved navigation, outlining and auto collapsing IMO some of the previous considerations should be revisited and perhaps relaxed.
I wouldn't consider the fact that it is 'header only' the main value proposition. But just a nice bonus of one less library to deal with.
Yes, exactly. https://gcc.gnu.org/develop.html#num_scheme
Exactly, thanks. So that would kind of mean C++11 support in gcc-5.0.x is still somewhat experimental as the whole branch is experimental, while it could be considered fully stable in 5.1.x and 5.2.x as they are stable releases and their default is `-std=gnu11`. Well, to be pedantic, that still doesn't say anything about `-std=c++11`.
F-J-W is talking about writing iterator classes, not actually instantiating iterators.
Default dialect has nothing to do with stability. GCC 5 branch is stated in release notes to have "Full support for C++11" and "full experimental support for c++14". 
Easier said than done. Also backwards compatibility.
In C++14, there is very very little that macros do that can't be achieved with a template or other language features - and I'd claim that what's left isn't worth it. That said, C++ won't get rid of the processor for decades to come - I expect I'll never work in a C++ compiler without it. There are simple too many lines of existing C++ code that needs it, too many existing libraries that use it. Even though I never, ever use the preprocessor and consider it a great evil, I'd have zero interest in a version of the compiler without it, because I use too many third-party libraries. (EDIT: OK - I admit to a certain fondness for the preprocessor, like a crazy relative you know really well. I have done preprocessor programming in the past - but I consider now that that was a mistake...)
OK, I have build PGO gcc and PGO clang, both with BUILD_TYPE=release and assertions enabled. Compile time of tramp3d-v4 (3d astrophysical hydrodynamics simulation with ~64000 lines of C++ code in a single file): gcc-5.2.1: 25.254 sec total clang-trunk: 33.470 sec total The generated code of gcc is ~50% faster than that of clang. (Both using: -Ofast) So don't believe the hype and measure for yourself.
You're neglecting a huge number of things that the preprocessor is used for. Look at any cross-platform library and it will be filled with preprocessor directives to tailor the code to the specifics of the platform. This cannot be done via any other method, because it requires conditional compilation — making parts of the program invisible to the compiler because they would not compile (or would not work if compiled) due to lacking that feature. Boost for instance would never be possible without the preprocessor. This is simply unrealistic. 
Conditional compilation for cross platform support, workaround macros for missing compiler support, assertion macros or similar where you need the current file and line number,...
Thanks - you're right, you're question was just what I needed. The error is actually the null check throwing std::runtime_error resulting in "terminate called without an active exception". Compiling with -Dgsl_CONFIG_THROWS_FOR_TESTING provides more insight. Effectively we are still performing runtime checks to ensure the value is never null. I was hoping that this would allow the compiler to catch these, but it still needs to rely on runtime checks.
Boo. They left out Microsoft as contributors in their slides :(
Why would someone put 64k lines in one file?
A standard way to do this would be nice indeed. I generally don't like preprocessor ways of solving things and use other approaches when possible, but there is no way to parse enum names as a string without a macro approach so this had to be an exception
are the preprocessed versions of the input file identical?
If you have more than a few lines of platform-specific code then moving it to per-platform source files is usually much nicer than ifdef soup.
C++ as it currently stands can't get rid of the preprocessor. But as the language evolves, the reasons to use it become fewer and fewer. For example, there's a module system in the works right now. That would replace `#include` directives. `static if` might replace using `#if` for conditional compilation. One day, maybe, C++ will have features that completely replace the preprocessor, using it only for backwards compatibility with legacy code. Or maybe that's just a pipe dream.
Well, there are slight differences. But both compilers use the same libstdc++ headers. And even if I use the same preprocessed input for both compilers the compile times don't change at all. (gcc ~24.5% faster than clang)
That's more for function overloading and not for inlining. Even if the desired behavior in the cases you describe is indeed inlining (which, to be fair, it might be), that still doesn't explain how you can use inline functions to replace macros (hint: that's because you can't, as others have already mentioned).
Ok, that wasn't the best example, as MAX and MIN are also done for overloading purposes like you said. But the fact remains that a traditional use of macros has been to force code to be inlined. People have been doing this for decades, even after true inline functions have existed in both C and C++. Do inline functions *replace* macros? ABSOLUTELY NOT. They replace one specific use case for them. Just like overloading and templates replace other use cases. The beauty of the preprocessor is how versatile it is and how many ways people have found to use it to make interesting things in many situations, without adding feature upon feature into the language itself. It's not going away anytime soon.
Nicely done. But you should probably make "Type##_enum_names" and "Type##_list" const.
Yeah I hope we get proper reflection in C++17.
And probably function local statics to avoid multiple copies.
Automatic generation of boilerplate code. 
So how do you keep code from platform A from compiling on platform B?
`this-&gt;a = 10;` This behavior is compliant, this is how two-phase name lookup in templates works. While parsing template `D` for the first time compiler doesn't know anything about members of `B`, so it doesn't search in them and therefore can't find `a` anywhere and report the error. If you write `this-&gt;a`, then compiler searches for `a` during instantiation of the template, when all the information about bases of `D` is available.
The solution I've always used is to abstract all platform-specific code into a library with a SINGLE header implementation (so no conditional-header-compilation) then make the implementation files (selected by the build-script) have all of the required platform-specific code. The result is very clean code that is quite easy to use, and doesn't require a ton of work when a new platform is added, or when a platform changes.
An enum class that can convert its values back and forth to a string. The only way that I've found is by making a macro that accepts as arguments the enum values, then uses those to define `operator&lt;&lt;` and `operator&gt;&gt;`.
willing to bet the answer is 'put it in a different file and only compile the files you need' Awkward, but it is tidy.
Oops, all conceded! I think I was responding to the Rust sample, which seems to introduce more issues than it solves.
I see, great answer! Thanks!
When a static reflection solution is figured out, this is one of a number of problems that can be solved with a small library.
&gt; but I consider now that that was a mistake No regrets! I still don't regret trawling through Boost.PP trying to figure out how things like nested loops with inferred dimensions work. Practical? No, not really. Fun and something that forces you to think differently? Absolutely.
It's amazing how many people don't realize you can do this. Same with classes. I'll often have class.hpp, class_common.cpp, class_win32.cpp, class_posix.cpp, etc. Instead I'll see lots of attempts at a class hierarchy or similar instead. 
You should change the static vector/unordered_map to be references assigned to a call to a function templated on the enum type that returns a static local. Then you'll be static init safe.
A codebase that I had to work with written by mechanical engineers was 250k lines of code in a single file, aptly named ``core.cpp``. Not all code is written by people who are aware of good practices.
The README didn't leave me very clear on how this was actually more useful than a standard profiler, but after skimming the paper they appear to be addressing the following sort of scenario: you profile some multithreaded code, discover that 50% of CPU time is spent in `foo()`, so you make `foo()` twice as fast... and then discover that you've actually just lowered your CPU utilization without making the program any faster because `foo()`'s thread is now just spending a lot more time waiting on locks. The actual tool appears to be of limited use at the moment due to only being able to measure the impact of a single block of code at a time (so it's more of a special purpose supplement to a standard profiler than a replacement), but that's relatively easy to solve if the technique works well.
Yes, coz does avoid the situation you described, and it also finds cases where small improvements to code that runs for a very short time actually leads to large speedups (see the paper). The key idea is that Coz tells you how much effect optimizing a particular block of code will have on your program's performance. Coz isn't just a supplement to conventional CPU time profilers. You're right that Coz only considers speedups of one block of code in each performance experiment, but it will run many experiments during a single execution of your program. It may take a few runs of your program to build a useful causal profile (10 minutes is typical for the applications we used to evaluate Coz) but it's certainly not impractical.
Sure. I am awaiting that one eagerly. Looks like it ll be macros for another few years sadly though.
And three more!
The various increments were completely useless auto make() { static int a = 1; return [a=a] (int c) { static int b = 42; return a + b + c; }; } is probably a minimal, sufficient example. And it still hurts my brain. 
how do you deal with linkage? see: https://www.reddit.com/r/cpp/comments/3npo3b/when_modern_c_does_remove_the_preprocessor/cvr496c
"This video was removed by the user." Well, we had another one.
Probably because the slides and the presenter were not well syncronized. 
No Qt? Seems like that would be a major platform to test
The biggest beef I have with the benchmark, and many of the implementations, is that it doesn't represent how you actually use the things. Connections and disconnections are rare events. Thread safety and performance of the synchronization are quite important. Signals and slots normally aren't ephemeral, there's no creating nor destroying them. Etc.
* FastFormat: http://www.fastformat.org/ * Pantheios: http://pantheios.sourceforge.net/ * STLSoft: http://stlsoft.sourceforge.net/
Of yourse you will have to enhance it - but clang does the same for other C-like languages, right? ;-)
True, but those are better abstracted off to a single header location in one place that handles all of those for the entire project, then just placing the macro name each definition. You'd still avoid putting #ifdefs everywhere. That said, compilers are supposed to ignore __attribute__ values that they don't understand, so you could likely put that where you chose. 
This is also only benchmarking runtime dynamic registrations. You can use the same design with compile-time static signals/slots with templates and completely remove the overhead, with the limitations of remaining static. This benchmark doesn't really go into the specifics of the design benefits of each. Or the fact you can use the same design with 0 overhead. Kinda crappy.
That's disappointing. That was one reason I liked it.
Is there an implementation of what you're talking about?
Boost's original signals library was basically libsigc++. Has the latter changed so much?
I really dislike boost-style code for things like this so I've never personally used it. If it is, then it makes sense. Looking again, it is the fastest in the list. Because the performance comparison literally makes no sense; I guess that's what I was getting at for this - the table doesn't really make sense as it doesn't take the above into consideration.
[removed]
Unlikely it seems. Maybe in 2020.
how does this prevent object slicing: http://stackoverflow.com/questions/274626/what-is-object-slicing this is good stuff, but there are some concerns with stl map - unlike vector, erasing a node does NOT invalidate the others. that was mentioned in neils paper, but it's not clear what they'll do about it. 
* I'm afraid I didn't see any mention of template, it'll be pointless if template cannot be exported. * Can a module be split into multiple files? e.g. ModuleA = a.ifc + b.ifc + ...
There isn't anything to export for a template though, right? That would require a template instantiation, which would then be exportable; e.g., std::string. From what I read, a module can be composed of several translation units: &gt;A module declaration identifies, in the source file, the module to which a given translation unit belongs.
Check this out: [Modules proposal rev 3](http://open-std.org/JTC1/SC22/WG21/docs/papers/2015/n4465.pdf) &gt; 4.10.1 Definitions &gt; Definitions for templates listed in a module interface are subject to constraints similar to those for inline functions. Furthermore, a class template that is only declared (but not defined) in an export declaration is seen as an incomplete class template by importing translation units.
Have you looked at CMake since 3.0? They did a massive revamp of their docs. Its much better now.
:(
C++ doesn't have http support in the standard library and almost always you wouldn't want to implement it yourself. Search around for a library that you like, maybe use boost or poco (there are plenty more). I am in the process of experimenting which Go+Cpp for this, write the http stuff in Go and create a lib which is used in C++ but that is not for everyone.
I tried CMake, and I couldn’t get it to correctly detect my various 3rd party library installation locations. I don’t remember all the details, it’s been a while since I tried. But it is more popular, I really should learn it. (Just like I should learn git, though I prefer Mercurial).
Hmm, it still looks the same to me. There is a reference documentation (which is like a collection of man pages that don't explain much), an extremely short example for the impatient and a list of links in the wiki to articles on isolated special topics and overlapping tutorials and introductions. I guess the problem I have with this is that I don't know what to look at in which order to maximize the "information rate" and not read the same thing over again by a different author who explains the basics just a little bit different. It's more of a random assortment of things to look at than something comprehensive I could read from start to finish. I guess I'm more of a book person. But I fear regretting paying the 55 EUR for the book.
I've posted the link to the /r/gamedev post instead of directly linking the video as there is interesting information both in the post and in the comments. If you want to see the video directly, [click here](https://www.youtube.com/watch?v=NTWSeQtHZ9M).
My problem with WAF evolves around it really being a framework for building your build system. Once your additions go beyond a certain level of complexity, it feels basically impossible to follow along or even - god forbid - change something. I tried SCons once, and it was simple enough to roll some simplifying classes into it without getting too complicated. But then you read about how it scales badly, which wasn't really an issue for a medium-sized project for me. I'd love to be able like CMake's syntax, but it just seems alien to me. And if you want something that is not the default way of doing things, it gets ugly real fast. So in the end, I still tend to like Make or plain shell scripts for small projects.
Any way to keep it safe and fast without these crazy hack :-$. 
SDK() is the old/new name for Platform(), as far as I can tell. Most of the docs are accurate _enough_ to enter the competition, the main missing ones are: * PcResult: despite linking to PcPtr in the docs in the warmup, _isn't_. Call Value() to access the inner object (I only needed to do this once) * "Load an image to display" challenge needs you to use an undocumented constructor, which takes an int (total data size I believe, aka height * rowsize) and data pointer, rather than the documented buffer class (the other parameters are the same). * Various functions return pointers or PcResults instead of PcPtrs etc. Easy enough to work out from the compile errors.
A fully constrained template should be exportable tho, since at declaration site the compiler can verify that the template function is valid for all types that fulfill the predicate (otherwise it is underconstrained) and thus it can be "precompiled" (to some intermediate representation). At a call site the compiler just needs to check that the parameter types satisfy the template constraints. In which case template instantiation cannot fail so nothing else needs to be checked. It is however unclear to me if this can provide a speed up at all (checking a template's body once instead of multiple times). However, even if this would provide a speed-up, constrained templates do not need to be properly (fully) constrained, so most templates won't be candidates for this anyways. 
&gt; &gt; &gt; It is however unclear to me if this can provide a speed up at all (checking a template's body once instead of multiple times). However, even if this would provide a speed-up, constrained templates do not need to be properly (fully) constrained, so most templates won't be candidates for this anyways. Honestly, the biggest speed-up is not loading and reading each header file 500 times on a full rebuild of a project. In most projects I'd argue that template instantiation time is negligible versus the time spent in the preprocessor - this can be seen quite easily when setting up unity builds.
Yes. What is your definition of "safe" and "fast"? ;-)
I'm not that sure. I now use cmake in all my projects to automatically create a cpp file for each header file to check that all headers include all the headers they need (check e.g. Boost.Hana's `test/CMakeLists.txt tests.headers target` for how to do this automatically). This results in a lot of TUs that are compiled, some of them include almost the whole library. Still, all of them compile almost instantaneously, independently of the amount of headers they include. Boost.Hana is a header only template library so all its code is actually in the headers. The moment one instantiates a single template, however, the world freezes, and compilation times explode from 2 seconds to 20-30 seconds (with clang) :/ So in my experience, while I agree that rereading each header a million times is wasteful, I think that re-instantiating all templates for each TU is even more wasteful. Compilers should have a cross-TU data-base of instantiated templates and reuse them. Anyhow, there is a Rust talk where Chandler Carruth (Google/LLVM) says that clang spends on type-checking about ~0% of its running time. 
And here I thought he was going to mention `-fsanitize=address`.
Ftfy http://www.davevoyles.com/getting-started-with-emscripten/ 
[Reposted](https://www.youtube.com/watch?v=0ti_JOyOtJA#t=2m25s). (First 2.5 minutes were mic issue fixing)
The most exciting thing for me apart from the increased conformance is that they are working on remote debugging for Linux. I think Visual C++ has the best C++ IDE and Debugger, and being able to use them to develop for Linux will be awesome. And, if Microsoft went ahead and provided a real POSIX layer for Windows, this would really make Windows/Visual Studio the premier platforms for developers as opposed to Mac.
gdb works fine on a Mac and it came with XCode up through OS X 10.8.
It says "Starting with **Update 1** of its 2015 release, Visual C++ features an ongoing implementation of the module proposal presented in [1]." VS2015 **Update 1** is not released yet. It should be released very soon if I understood correctly.
I know much less than I should about build systems. Like I said, I actually am using waf, I’m just hoping to learn it well enough along the way. I’ve been able to get it to do everything I need so far. Just yesterday, I wrote a little Python script to take a depthless folder of c++ source (read: example code from a book on c++), and automatically create a Mercurial repo and a waf build script suited to that folder’s needs (one executable per file with a `main()` in it). The repo let’s me experiment with the example with no hassle. On a more serious project, I have it running my unit tests on every compile (as it should be). I can’t get it to actually print the output from the tests, so I always have to run it again separately whenever it fails to see what’s actually failed. That’s as far as I’ve taken it. I even have machine-specific paths in my bigger project’s wscript file (generalizing it is on my TODO list)
Gonna check this out. I wish there was a way to implement communication between systems and serialization that doesn't lead to loss of hair. This probably wont be it (or rather, can't) but perhaps it will make the implementation cleaner.
We are aware of this and that is why we publish to both YouTube and Channel 9. Your patience will be rewarded.
My confusion was the distinction between Vs 2014 Dev Update 1 and the section you noted. Sorry, should've been more clear!
What's the benefit of: class IMessenger { protected: virtual std::string encrypt(const std::string&amp; message) const = 0; virtual void send(const std::string&amp; message) = 0; public: static void send_message(IMessenger&amp; messenger, std::string&amp; message) { auto encrypted = messenger.encrypt(message); messenger.send(encrypted); } }; Over class IMessenger { // ... public: void send_message(const std::string&amp; message) { auto encrypted = encrypt(message); send(encrypted); } }; You can even have the free function that calls the member if you want still.
I understand that ADTs don't use public instance functions. What you haven't explained is what the benefit is. "It's OO and OO is less generic" doesn't cut it, you're going to have to be more concrete. The C++ std library uses public instance functions extensively, and public static functions barely at all.
Why would that be a "no no"? Is there any function I marked as `noexcept` that may actually throw? If that's the case, I'll fix the code on GitHub and add a comment :)
Is there a lost of such functions or a link for more resources on such things? I am a total idiot for coding and want the compiler to yell at me every time. I am already using - wall. 
Look up static analysers for your language of choice. They generally give similar information to compiler warnings, but they're not restricted to languages with compilers and often perform more advanced analysis. The sanitizers mentioned above are dynamic analysers, which are generally built into higher-level languages as runtime checks like bounds and null pointer checks.
woah, when did lldb get a gui?
Geez, no kidding. Screw my take on the matter then. The only thing I got out of that was that you can pass around static functions more easily than instance ones, though it's a simple matter to use a lambda, `std::mem_fn` (if you want to disappoint STL), or have the receiving function use `std::invoke`.
I didn't find it when I looked a couple days before but is there any maintained playlist for CppCon 2015 (and the various separate CppCon's) videos? Maybe make it a part of the uploads on the official channel? I think it's really needed.
UTF8 w/o BOM is already possible with VS2013 or better (didn't check VS2010), I'm using this in my projects. Otherwise the GNU gettext tools wouldn't swallow my sources (learned that the hard way).
How can it statically prevent leaks? Can it detect shared_ptr cycles? Core guidelines [says that it is probably impossible](https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md#-r24-use-stdweak_ptr-to-break-cycles-of-shared_ptrs).
Clang doesn't support `-ffastmath`? That doesn't sound right.
3.6 generates the same code regardless of the flag (for complex multiplication operation), but 3.7 behaves properly and generates fast code with the flag. 
I have to admit, I really liked that that visualisation tool. 
is the whole thing neccessary for Clang? Wouldn't -ffast-math suffice?
Maybe the call to placement-new requires construtor parens? new(temp) Gizmo();
I use waf for all of my projects. The only other configure+build alternatives are CMAKE and Autotools. The troubles with Autotools are well known. I have had so many problems with CMAKE as a regular user that, if I have to modify a CMAKE project, the first thing I do is convert it to waf. With that said, yes, the documentation is difficult to understand and not always helpful. It is more written for the waf author to understand why he designed things the way he did rather than for end users. I have not found the API to change that much, and the google groups list has always been helpful. So I have always managed to find a solution after much gnashing of teeth. So if you wrote a guide, even I would appreciate it.
&gt; So if you wrote a guide, even I would appreciate it. I guess I could at least write down what I know. That’d be like a blog-post’s worth. 😐 I could start an open-source LaTeX document—write what I know then open it. If I don’t force everyone to use Mercurial, it’d be a good excuse to learn Git, as well.
Gizmo must be defined. 0. struct Gizmo {}; Also, 1: the_gizmo is not null, but in an unspecified, invalid state (most likely a random address that point to garbage). 
Thanks for the suggestion. I did try that but it unfortunately didn't make a difference. Also, thank you for making we aware of the term 'placement-new' it has made googling for this a lot easier!
It successfully compiles on Coliru: http://coliru.stacked-crooked.com/a/07fafadf8b896677 #include &lt;cstdlib&gt; #include &lt;new&gt; class Gizmo {}; int main() { Gizmo* the_gizmo; void* temp = malloc(sizeof(Gizmo)); new (temp) Gizmo; the_gizmo = static_cast&lt;Gizmo*&gt;(temp); }
It works http://ideone.com/9yGeEA
So I just tried this in XCode and it works. What compiler are you using, and which standard are you compiling for? C++11? Earlier? Later? class TestClass { }; int main(int argc, const char * argv[]) { TestClass *ptr_to_TestClass; void *temp = malloc(sizeof(TestClass)); new(temp) TestClass; ptr_to_TestClass = static_cast&lt;TestClass*&gt;(temp); }
What compiler are you using? http://ideone.com/64AY0z
The problem of compiler flags is that they are all-or-nothing. Either all the functions in a T.U. get the fast math, or none. I wonder if the committee ever considered something like `fast_float` and `fast_double`, that is to use the type system to tell the compiler that I don't care about precision or corner cases.
Is it possible to overload on `constexpr`? For example I have two algorithms for computing the same output and one is slow but can be made `constexpr` (slow compilation but zero time during run time) the other is faster (big O style faster) but cannot be made `constexpr`. I want automagic overloading, I know I can write `constexpr auto res = some_func&lt;c_input&gt;()` or `constexpr auto res = some_func_constexpr(c_input)` vs `const auto res = some_func_runtime(r_input)`, but I want to be able to write `constexpr auto res = some_func(input)` and `const auto res = some_func(input)` both invoking different algorithm based whether `constexpr` result was requested or not.
It's a bit off-topic but since Update 1 CTP for Visual Studio is already released, I wonder if some new features are there or not. After poking around with it a bit I couldn't find anything that's actually changed for C++ :)
I watched both conferences (Clang/C2 &amp; your own ), both were really nice surprises. You really managed to turn the ship around in a few years. It looks like the number of decent &amp; abi compatible toolchain is increasing from 0 to 3 ( msvc, clang/c2, clang/llvm ). Plus, afaik, intellisence is its own thing. Someone hinted at a hope of convergence someday... great. Do you envision replacing Intellisense with a clang based tool ? So. There will be a decent, fast C++11 compiler on windows. With a standalone installer. Thanks for that! Really. I may event be tempted to use VS when working on windows, now that it is a bit more modular (thanks for that too) Now.... There is this msbuild thingy. Last time I checked, it was quite bad at multi-thread builds. Plus, it really don't play well with portable project. Mind you, I dislike xcode files even more, but, it's the same problem. Granted, there is no perfect build system, but some are decent. So, my question was : Could there be some kind of plugin api to allow integration of third party build system ? CMake for example. I know Cmake can generate solutions, but it is a bit cumbersome. (One easy solution would be for the sln/vsproj to be hidden away ad silently reloaded on a modification of whatever files the foreign build system is constituted of). Other question : do you plan to support attributes any time soon ? do you plan to work with the standard / other compilers maintainers to provide a good set of common attributes in order to replace __declspec macros ? 
in case you missed STL's reply below, thanks very much for bringing this to our attention. We huddled today to figure out ideas for how to make this scenario better all up and STL's bug is one part of that. This is definitely the kind of thing we are interested in improving as we continue to emphasize open-source and cross-plat dev.
yeah, the reason I did the talk in this format was because I wanted something that was less about "what my team did" and more "if you are a C++ developer and use VS, what's new". like /u/stl says below, our blog is a great resource, I'll keep making videos like this. channel 9 going native is also helpful. And for language and platform non-specific things like window layouts and GitHub probably subscribe to the VS blog. https://channel9.msdn.com/Shows/C9-GoingNative http://blogs.msdn.com/b/visualstudio/ I hope the CppCon folks will have me back next year to do an updated version :)
Thanks for watching! IntelliSense: the trick with IntelliSense is to make it FAST and SCALABLE. today we use a different frontend specially adapted for IntelliSense (think about incremental compiles and those sorts of issues). We have what I hope are some nice improvements to our existing engine coming soon. Evaluating Clang for IntelliSense is an exploration we'll be looking at but it's not as simple as just subbing one in for the other. MSBuild, we've got some stuff I can't talk about planned here. unhelpful, I know. :) CMake I think Ayman talked about a bit at the very end of the talk. we're looking at getting deeper with it. still investigating.
Like Steve said, RTM supported attributes, including C++14 `[[deprecated]]` and C++17 attributes on namespaces/enumerators. I verified this before publishing [my big table](http://blogs.msdn.com/b/vcblog/archive/2015/06/19/c-11-14-17-features-in-vs-2015-rtm.aspx). In Update 1, I've switched the STL over from using `__declspec(noreturn)` to using the Standard `[[noreturn]]` attribute. This reduces our dependency on non-Standard extensions (even though Clang supports `__declspec(noreturn)`, I figured it was better to use the Standard stuff). As part of this work, JonCaves fixed C1XX to accept `template &lt;typename T&gt; [[noreturn]]`. (In RTM, you could mark a function template as noreturn, it just had to go after the function name, which looks really weird.)
Looks like I picked the wrong week to quit thinking about chocolate
No STL features yet (we're only missing 1 from C++14 and 2 from C++17), but we've accumulated a dozen-ish STL bugfixes (written by me, Hong Hong, and Steve Wishnousky). I'll be writing a more detailed VCBlog post, but here's a terse list (note: some stuff got into the CTP but I haven't kept track, this list is for Update 1 RTW): * TFS#917456 &lt;bitset&gt;: none() and any() return incorrect count after call set() function in a std::bitset&lt;0&gt; object [libcxx] * TFS#1127004 &lt;future&gt;: Including &lt;future&gt; does not work with _HAS_EXCEPTIONS=0 * TFS#1178296 &lt;memory&gt;: shared_ptr&lt;volatile X&gt; doesn't work with enable_shared_from_this&lt;X&gt; * TFS#1181758 &lt;atomic&gt;: MSVC 2015 std::atomic is implemented using non-conforming C++ * TFS#1184701 &lt;memory&gt;: We should handle construct/destroy returning non-void * TFS#1192603 &lt;tuple&gt;: tuple_size's static_assert is problematic * TFS#1194345 The C++ &lt;future&gt; header pollutes the global namespace with 'stdx' * TFS#1205400 C++ compiler: static_assert in std::tuple_element prevents SFINAE * VSO#125155 std::rethrow_exception is not [[noreturn]] * VSO#130290 &lt;xmemory0&gt;: _Allocate/_Deallocate could be de-templatized * VSO#134162 &lt;functional&gt;: mem_fn()'s signature should follow the Standard * VSO#144294 [STL] max_bucket_count() in unordered associative containers * The STL is now friendly to Clang and /Za. * numeric_limits infinity/NaN is constexpr, using GCC/Clang's compiler hooks implemented by C1XX/EDG. * The STL uses [[noreturn]] instead of __declspec(noreturn). (The CRT is unchanged, however.) * Fixed missing noexcepts in &lt;exception&gt;. * shared_ptr's atomic operations have been improved by avoiding unnecessary copies. * regex's stack limit has been tuned on x64.
Thanks! To you and STL. It's good to hear Microsoft are making an effort to make cross-platform coding easier. I'll keep an eye on this.
Most interesting bit here IMO was the confirmation that going all-in on the clang frontend and dropping the current one actually is their goal (although it's many many years away).
yeah this is sort of surreal that something as security and correctness sensitive as the MS compiler is going to be (eventually) half open source and a joint project with apple and google. how will they do c++/CX though and other "embrace and extend" extensions? don't see how they will ever get rid of the c1 front end. But I'm just glad that this will help swift become x-platform too. 
The reason I use free functions when overloading operators is largely because it allows implicit conversion of both arguments. The reason I asked is because ADL seems a convenience whose main purpose is to ensure operator overloading works in conjunction with namespaces. (i.e., without ADL you couldnt write `std::cout &lt;&lt; 'x'`, and instead of `mat1 + mat2` youd have to write `myns::operator+(mat1, mat2)`, or more likely `using namespace myns` before the `+`). So do you ever take advantage of ADL rules for functions other than overloaded operators?
I have to say the yield/await without OS support looks pretty juicy and it's great it's proposed as an iso standard. https://isocpp.org/files/papers/N4402.pdf
hey guys, steve carroll here. i'm the dev mgr for the Visual C++ team. Jim is the dev mgr for the Code Gen Technologies team. Think of it as "steve owns all the stuff from the IDE until the point when the frontend (c1xx) emits IL, and Jim takes that IL (from c/c++ but also other languages) and converts it to code (via c2)." Jim's team also owns the clang/c2 bridge, but we work on this project together. Just want to clarify something that I think is important. We are definitely not going to stop investing in c1xx anytime in the near future. Still investing in conformance, still respecting all the existing code out there that only compiles with c1xx but not clang. we are going to keep both going. no plans right now on C++/Cx or anything like that. Right now Clang/C2 is all about making it easier to bring standard C++ code to windows. here's the talk I did later in the week that gives a little more context: https://www.youtube.com/watch?v=UuwBG9f4ZiQ
So.... has anyone tried to get Cling to work on windows?
http://llvm.org/builds/ There is an installer which adds Clang/LLVM as a platform toolset to visual studio and MSBuild. You can also already invoke it directly form the commandline using the normal download (http://llvm.org/releases/download.html) or build your own (http://clang.llvm.org/get_started.html).
Pretty sure Cyber_Dildonics meant [cling](https://root.cern.ch/cling), not clang. Though he could've made a typo of course. &gt; Cling is an interactive C++ interpreter, built on the top of LLVM and Clang libraries.
Is Part 2 still underway?
Why are Microsoft language extensions to C and C++ "embrace and extend" and it is not a problem for other compiler vendors? There are lots of vendors besides clang and gcc.
* Part 1: https://youtu.be/lVBvHbJsg5Y * Part 2: https://youtu.be/1obZeHnAwz4 * Slides: https://github.com/CppCon/CppCon2015/tree/master/Presentations/Live%20lock-free%20or%20deadlock/ 
Hard to do the 'embrace' part with such tiny little arms. 
I recommend C++ Primer (not C++ Primer Plus), since it is mostly based around C++11. Also I wouldn't recommend learning C++ as a first language since it is somewhat complicated. You might be better off starting with a language like Python.
I would suggest learning Java or C instead if you have to use C++ in the end. Both have a syntax very similar to C++. Java will get you good results faster but if you learn C you will understand all the underlying concepts of C++. 
**NO!** Don't learn C before C++. I made this mistake in 2000 and wasted a year and a half of my life. Learning Java as a step towards learning C++ is an even worse idea (and I'm speaking as someone who had to take a Java course, before learning C++ on his own).
could you elaborate on that? I learned C first and I think it gave me a better insight into why C++ is the way it is (I generally like to learn low-level stuff first). I kinda agree that Java is weird to learn before C++ because a lot of people have problems grasping concepts like pointers, call-by-ref, call-by-value, memory management and so on. But in the end you have to start somewhere and C++ is simply so extensive that it might be overwhelming for someone who is new to programming. Especially the C++11 additions are very messy with the new trailing-return-type syntax
I learned some python with this [course](https://www.edx.org/course/introduction-computer-science-mitx-6-00-1x-5), and I can recommend taking also 6.00.2x. They both teach some things that are language agnostic. Though I am still learning C++ and I have to agree with STL that many times I try to do something "python way", eg. separating algorithms from data structures in C++ was(is) really unintuitive to me. As a beginner I first went through Jumping into C++ (pre C++11 book) paired with Tour of C++ by Bjarne. Though I mostly use Bjarne's tour to know what I want to do and then search stuff on http://en.cppreference.com/w/. But keep in mind that something else might work for you better.
&gt; I recommend C++ Primer (not C++ Primer Plus) I wish I had known this prior to wasting $65... After reading both books, Primer is infinitely better...
Thanks for all! 
Yep, I was talking about cling. I think at the moment they have binaries for Linux and osx. 
&gt;I kinda agree that Java is weird to learn before C++ because a lot of &gt;people have problems grasping concepts like pointers, call-by-ref, &gt;call-by-value, memory management and so on. I only had introductory courses/work dealing with java, but my god the struggle was real to try and grasp when/how to use pointers and references. 
In order from beginner to experienced - [Programming Principles and Practice Using C++](http://www.informit.com/store/programming-principles-and-practice-using-c-plus-plus-9780321992789) [C++ Primer](http://www.informit.com/store/c-plus-plus-primer-9780321714114) [Accelerated C++](http://www.informit.com/store/accelerated-c-plus-plus-practical-programming-by-example-9780201703535) [Effective Modern C++](http://shop.oreilly.com/product/0636920033707.do) Also if you want to learn C++ then *learn C++ and not C*. They are often mentioned together but they are not the same. If you want to do operating system kernel development, device drivers, embedded/micro systems or write libraries that can be used by as many systems as possible then sure go for C. It is *great* for all that. You will also want to get a bit of x86 assembly as well though if you are working that low. If you want to make applications then C++ is a better choice than C in my opinion. Sure you can do applications in C but honestly it is a lot more work than just going with C++. I remember seeing a video where even Linus agreed doing complex graphical desktop applications was better in C++ (with Qt) than C and GTK+. Work out what you want to do and start with the language that makes the most sense. If you want to do Android apps than C++ can be used but in all honesty you will be using Java so just start with Java if that is what you want to do. Don't get too caught up in the language you start with though. Once you understand the different concepts each type of programming has you will be able to adapt to different languages quite easily. The harder part is picking up different libraries not languages. 
Wow I was looking to compile my project with Clang but I'm a Visual Studio user and stay away from the command line, the installer is cool! I'm using CMake to generate Visual Studio project files, but how do I get it to use Clang instead of MSVC?
Just to provide a counter opionion, I would actually recommend learning c++ before python. Basically Python allows you to do things easier, while c++ gives you a lot of control over what happens. Python will allow you to do cool stuff faster, but c++ will allow you to learn the basics first, and I think it would be easier to go from c++ -&gt; python rather than the reverse.
Just came across this last week. Really found it useful: http://howistart.org/posts/cpp/1
I would download a game engine like source engine and start building small games or even Unreal Engine 4. They both require C++ and are a great place to learn the language. Don't read books. Books are for nerds.
If you're required to use C++ at school then don't bother with Python. Learn C++ because you will need it. www.learncpp.com/
Noooo. Unreal C++ usually doesn't resemble normal C++ code. Lots of macros needed for it to work right. And super verbose class names.
Shut the hell up you punk. It was a joke obviously.
Writing programs. Just sayin'.
Performance. Cross platform. Strict typing.
almost anything haha :D
STL is correct (of course). Yes, if you know C, you will have insights into C++ that will be useful. But that doesn't mean the learning C first is worth those insights. Learning C first is itself a time consuming undertaking and unlearning C habits that have better C++ equivalents is an additional cost. If your goal is to learn C++, the best way is to learn C++. But more importantly learn it from a **modern** source. Use the "C++ Primer" (not "C++ Primer Plus") or "Programming: Principles and Practice Using C++," but only the latest (C++11) edition of either of these. Pre-C++11 books may be excellent, but are not a good use of your time. For example, "Accelerated C++" is one of the best books out on teaching beginners C++. But I can no longer recommend it because it will teach you classic C++, not modern C++ and is not the best use of your learning time.
The answer could fill a book. In fact, it did: http://www.oreilly.com/programming/free/c++-today.csp
An informative talk, but the format he used wasted a lot of time, which forced him to gloss over some points. Lots of time spent answering questions that were going to be answered in later slides, and then more time spent handing out chocolate. I guess there's a reason most formats are set length speach + Q&amp;A with any time remaining afterward.
Why is it specifically with C++11? Qt supports various C++11 features (lambdas, override, move semantics/rval references). Connecting signals to lambdas is awesome... Strings have toStdString and fromStdString... They just don't force C++11 features so they don't have to be a dependency.
qt breaks 'every (modern) c++ idiom' by design? please shed some light on this
Work on Qt (not QT) started in 1993. Predating by a year or two the first STL version. It also predated the first C++ standard. It now powers a lot of applications. And still, it manages to be play quite well with modern C++. You can't judge a framework without considering the whole backward compatibility ( &amp; compiler conformance ) thing. Granted the memory model of object trees clashes a bit with the more modern unique_ptr but, hierarchical ownership makes a LOT of sense in a Gui App. I like working with Qt even for no-gui app. Great reflection mechanism, great performances, proper unicode support, decent network facilities, top notch json support, etc. ( of course, all that has a cost in term of libraries size ) Recently, some part of Qt were dropped in favor of the STL ( &lt;QAlgorithms&gt; ). They also went a long way in term of modularization support. So. what *specifically* do you dislike so much about it ? 
Well, its name is not really "Java Naming Convention". As ugly as it is, i'm fine with that, it's just a naming convention.
I use variadic templates in the definition of `JsonRpcClient::call`, to avoid having to uglify the code with multiple overloads for different number of parameters. 
&gt; &gt; &gt; Why do people come to C++ and think they should import Java's naming convention? Qt (1993 IIRC) existed before Java (1995) (and before the standardization of C++)
What kind of criticism is complaining about a naming convention? Can't you adapt to a different convention? Do you have trouble reading other people's code?
Great talk, as usual for Stephan. I always learn something from these. 
Oh no I agree. I just wanted to provide a counter prospective from someone who thought differently to /u/direfwodho
When people say "composition over inheritance" they usually just mean making objects data members of other classes. C++ certainly has native support this, so I'm not quite sure what you mean. Composition lets you reuse functionality. Inheritance lets you reuse functionality, but it also provides polymorphism: the ability to substitute one object in place of another, with the same interface, but different implementation. So they don't solve exactly the same problem. When people express negative views about inheritance, I think the most common complaint is the use of inheritance for code reuse. I also think of a lot of it is a reaction to the past where people went overboard with inheritance, creating very deep hierarchies. Go doesn't have C++/Java style inheritance, but interestingly it does have something similar with regards to interfaces: "inheritance" is implicit and deduced automatically by the compiler. It only applies to interfaces however (no inheriting of implementation or data, that I know of). There are plenty of cases where you'll want to use inheritance purely for polymorphism/interface. In this case, your base class consists entirely of pure virtual functions. Children of that base class implementation those pure virtual functions. Your program can now write functions etc that accept the base class by pointer and use the interface without worrying which implementation the client passed in. I think that sometimes in the context of having this common interface, there ends up being state or functionality that all implementations will want. In that case, it may be more natural to make such functionality or state part of the base class for reuse. There are other situations not involving polymorphism where inheritance can be good (e.g. policy based design https://en.wikipedia.org/wiki/Policy-based_design). But it's not as common. In short, I think that composition over inheritance for code reuse is a very good rule of thumb. It's not a blanket rule though; sometimes inheritance is a good solution and there's no blanket reason to avoid it.
so, next code is valid: // 1... using std::placeholders::_1; std::vector&lt;std::string&gt; strs{"x", "y"}; for_each(begin(strs), end(strs), bind(&amp;std::string::clear, _1)); // 2... auto ptr = &amp;std::string::clear; ? And next one is not valid: void (std::string::*ptr)() = &amp;std::string::clear; am I right ? Thanks
No. Consider if for some strange reason the library wanted to implement `clear()` as: void clear(int __blurgh = 42) { ... }; This is still callable as `str.clear()`, and it's allowed by point 2.1 of the quoted passage. But the default argument value doesn't really exist when dealing with function pointers; this is fundamentally a pointer to a member function that takes one argument in addition to the `this` first argument, for a total of two. You would have to do something like `std::bind(&amp;std::string::clear, _1, 42)` for the result to be callable with a single argument by `std::for_each()`. (Edit: originally this sentence didn't make any sense.) That's not to say that your example wouldn't compile, because it's exceedingly unlikely that the implementation would actually do that. It's just that it's allowed to, and you can't predict when an implementation is going to need to take advantage of that (maybe never.) 
My reading was that the first is also not necessarily valid due to: &gt; — by adding a member function signature for a member function name. I read that as an implementation being able to do the following: template&lt;...&gt; class basic_string { ... void clear() {clear(false);} void clear(bool implementationParam) {...} ... }; This would cause `&amp;std::string::clear` to be ambiguous. 
&gt; C++ offers native support to inheritance (including multiple and virtual inheritance) but not to composition Say what? struct A { int x; std::string s; }; This structure is composed of an integer and a string.
So, is that "uniform call syntax" proposal out the window in favor of `std::invoke`?
The people who are working on unified call syntax are trying to permit member functions and non-member functions to be called interchangeably, but currently I haven't seen any attempts to extend this to allowing PMFs and PMDs to be called like functions. As I mentioned in the talk (I think), if Core allowed that, plus the raw/smart pointer trickery, then invoke() would be unnecessary. The reverse isn't the case - invoke()'s existence won't stop Core innovation, just as bind() didn't stop lambdas from being developed.
/u/Rhomboid found the Standardese, but it's actually a two-part thing. The possibility of overloads means that &amp;string::clear is ambiguous, *and* the possibility of default arguments means that you can't static_cast to disambiguate. So you can't (portably) get a PMF at all, much less one with the expected signature (which might not exist due to default args). The base/derived cases are: you can take a PMF/PMD of type `Stuff Base::*`, and invoke it on a Derived, or a Derived *, or a SmartPtr&lt;Derived&gt;. This is what the Core Language lets you do naturally (if you know the right syntax), but invoke() has to detect the inheritance relationship. The reason why is the raw/smart pointer trickery - invoke() can "easily" distinguish function objects from PMFs from PMDs, but then it needs to look at the first argument for a PMF/PMD of type `Stuff T::*` and ask, "hey, is this arg a T or derived from T?". If it is, it needs to use `.*` to invoke the PMF/PMF on an object. Otherwise, it assumes it's got a pointer of some kind, and has to dereference it first. If invoke() didn't handle inheritance, then derived objects would be detected as non-Ts, and would be treated like raw/smart pointers, which we wouldn't want.
Thank you very much. I was thinking more along the lines of `std::is_function` (which already has 24 specialized cases IIRC) wondering how that could depend on base and derived classes. Thinking about it in terms of actually invoking the object makes it much more clear.
In my implementation, I added internal machinery to `is_member_function_pointer` (which already needs to detect nasty PMF types) which reports the class type and the first argument type (if any), for use by invoke() and others. invoke() contains the `is_base_of` check.
The thing is that I'm generating VS project files and CMake automatically uses the MSVC compiler instead of Clang
Maybe with a toolchain file?
Well I'm not trying to cross-compile so no
&gt; Well I'm not trying to cross-compile so no It's just a convenient way to set the compiler you want to use. 
Thanks: I increased the version for -std=c++14 to gcc 4.9.2.
&gt; It doesn't just mean "a member variable", it means enriching your object with some data and logic. Which is exactly what using a member variable does.
1. [GOTW #64](http://www.gotw.ca/gotw/064.htm): "if you want to create a pointer to a function, member or not, you have to know the pointer's type, which means you have to know the function's signature. Because the signatures of standard library member functions are impossible to know exactly -- unless you peek in your library implementation's header files to look for any peekaboo parameters, and even then the answer might change on a new release of the same library"
Let's say you have a Button class but you want to change something about how it looks or how it behaves when the mouse hovers over it. With inheritance you just inherit a new class and overwrite that one method responsible for mousing events, or you overwrite the drawing method. With any other system you probably would have to do more leg work to get the same result. GUIs are one of the (few?) fields where inheritance based OO feels very natural.
&gt; With any other system you probably would have to do more leg work to get the same result. Not necessarily. I'm writing small GUI library (as a part of 2D game engine), and it heavily uses composition - button is a Widget class that have TextStrategy, ClickableStrategy, and Drawer that paints background and uses data from TextStrategy to draw text over it. If you would want to change how it looks, you could just use other drawer, and if you want to make it draggable, you add DraggableStrategy to it. If you would want it to behave like a checkmark, just add to it PushButtonStrategy. (I probably suck at naming things, but I think that this modularity is good). That being said, those 'strategies' or 'drawers' often inherit from another, and there are classes that inherit from Widget. Inheritance is often more convenient, or better at some particular task. "Composition is always better than inheritance" sounds to me like "Forks are always superior to spoons" - good luck with your soup.
Why would you regard C as a colossal mistake? 
Because I could have spent that year and a half learning C++, instead of wasting my time with such a limited language.
&gt; But if you have a musician that wants real time feedback in the audio from his inputs, then usually he wants the effect to be as immediate as possible. Just like in a game you want the feedback from your input to be immediate otherwise it feels sluggish. One issue with an approach of "most recent value" is that in the case of audio processing this introduces noise into the output signal. Every step between values when used as a volume has an audible sound as you transition between the values. It's not so bad for 14 bit MIDI controllers but for a DJ cross fader in flight both 14 bit and 7 bit controllers suffer the same problem - undersampling/distortion of the control signal. Using timestamped controller events is one way to preserve more of the source signal so you need a less severe low pass filtering (and low pass filtering involves a delay to your signal too). A second issue with "most recent value" is that the time taken for a change to become audible is no longer consistent. Percussion performers for example can handle a little delay as long as it is consistent.
&gt; Instead the audio computation would "remember" in what frame it received the change and do a short fade to that volume (possibly but not necessarily over multiple frames). What you are suggesting here is an interpolation approach for the control values. Any interpolation involves a delay of some sort to the signal. For various reasons (under-sampling) linear interpolation will require a minimum length of double the controller event frequency. You could set your interpolation period to the audio period but you introduce noise at the frequency of the number of periods per second you have. http://www.modular-audio.co.uk/~dan/control_value_processing_tests/ For reference, here's a little test I did during my recent investigations into this particular issue - I look at two open source programs and how they handle it compared to a raw non-timestamped signal, a timestamped signal and one with a low pass filter. My actual research rig has a number of different interpolation schemes. I'm not done yet, but so far for "online" scenarios I am leaning this way: * For absolute latency where we don't mind noise linear interpolation of most recent value is the way to go. Is pretty awful for longer audio periods (&gt;256) as it doesn't properly represent the original signal and the cross spectrum noise is audible * For low latency with reduced cross spectrum noise either linear interp + low pass non timestamped, or timestamped and a lighter low pass comes out roughly equal * For absolute quality, timestamped and heavy low pass - has a cost of around 12ms on top of the delay incurred by timestamping, but is a near perfect reconstruction of the source signal. Of interest in that test: * Ardour seems to have spectral noise linked to audio period length * Mixxx seems to use linear interpolation of control values * Both seem to lag behind "ideal" processing values, even the timestamped low pass reference signal 
Good stuff as usual, STL. Regarding avoiding `std::bind` , I'm using it for packing callable types and their arguments into a `std::packaged_task`, as shown below. This helper function quite useful for constructing and asynchronously dispatching a bunch of tasks on a queue. Is there a better way of doing this, without `std::bind`? template&lt;typename CallableType, typename... ArgumentTypes&gt; auto MakePackagedTask(CallableType&amp;&amp; Callable, ArgumentTypes&amp;&amp;... Arguments) { using CallableDecay = std::decay_t&lt;CallableType&gt;; using ReturnType = std::result_of_t&lt;CallableDecay(ArgumentTypes...)&gt;; return std::packaged_task&lt;ReturnType(void)&gt; ( std::bind ( std::forward&lt;CallableType&gt;(Callable), std::forward&lt;ArgumentTypes&gt;(Arguments)... ) ); } 
No.
Just to clarify I am not the author of this framework. I just found out it in a french news website and decided to share since it looked interesting.
It will probably be most like C++AMP, except maybe on computers where the GPU and the CPU share the same memory the `array_view` won't be necessary.
I'd rather they concentrated on improving the fundamentals (no sane method of splitting and joining strings in 2015... really?) than adding something as extremely niche as that.
&gt; Every step between values when used as a volume has an audible sound as you transition between the values. Isn't this just an inherent property of digital sampling, a step consists of energy at all frequencies?
Thank you so much! 
I'd be happy if we'd get a better support for parallelism with future.then...
Splitting was mentioned in another thread just a few days ago. Actually, it can be done using std in a single loop...
Just because its easy to implement isn't a good excuse for excluding it. We're talking about something which literally almost every single language supports. If you were to apply the "easy to implement" logic further, you'd end up removing 3/4 of the stdlib.
I wouldn't call D a competitor to C++ considering it has optional GC where optional is defined as "optional unless you want to use large chunks of the standard library". DMD doesn't generate very good code either and GDC is immature and seems to be forever merging into GCC mainline but not really.
In what domains? I've seen exceptions used too, but I've seen more projects set to compile with exceptions disabled than with them enabled. Any projects on GitHub that use exceptions off the top of your head?
Modules will have no impact on class size. A module can be formed from multiple TUs.
It is not about removing or prohibiting some features. It is even not about some features being unnecessary. It is about using safer and easier to use and understand alternatives to some old (C-style) idioms. Like using std::string instead of char*, vector instead of plain arrays, std algorithms instead of plain loops, smart pointers instead of plain poineters. Of course, there always will be some problems ("hard problems" in his words) which do require those low-level techniques. That's fine. But for most problems by default, and to teach novices, there those easy things. Again: it is not about removing features. It is about style of programming. PS. You are wrong about exceptions. For example there is a common misconception that Google does not like exceptions. But they don't use it mainly for historical reasons, and now they say in their [style guide](http://google.github.io/styleguide/cppguide.html#Exceptions): &gt; On their face, the benefits of using exceptions outweigh the costs, especially in new projects.
And actually I think there is a some misconception hidden in your question iteself: Programming language is not just a set of features. Programming language is a set of features plus a set of practices how people use them. For example, C++ in 199x and 200x were already very different languages. They had (mostly) the same features, but very different practices. And what Stroustrup talks about is not language features, but those usage practices.
for life-and-death real-time latency requirements (airplanes, laser surgery robots), exceptions might not be a good idea if those guarantees cannot be met. But disabling exceptions in games is beyond me, e.g. in situations where a `bad_alloc` would have been emitted, latency is also being compromised by going heavy disk traffic from virtual memory. 
Directly from http://llvm.org/builds/: &gt;To use the LLVM toolchain from Visual Studio, select a project in Solution Explorer, open its Property &gt;Page (Alt+F7 by default), and in the "General" section of "Configuration Properties" change "Platform &gt;Toolset" to "LLVM-vs2012", "LLVM-vs2013", etc. &gt;Alternatively, invoke MSBuild with /p:PlatformToolset=LLVM-vs2013 to try out the toolchain without &gt;modifying the project files.
... or exceptions were drastically oversold as the answer to error-handling. Even if performance is a non-issue, exception-handling is cumbersome. I'm OK with it existing for corner cases (such as running out of memory or losing a database connection), but the world became obsessed with throwing exceptions for the slightest failure (such as parsing an integer from a string).
I haven't found exception handling cumbersome. It might be if you're abusing it for every single possible error condition but not if you're using them properly. The hint is in the name: exceptions. You should only use them for exceptional error conditions. What languages like Java do with using them for every single error is terrible.
Duplication is caused by lazy design and code, headers only make it easy. Modules are not going to save you from yourself. 
In what sense were exceptions oversold? Keep in mind that prior to exceptions, people would ignore return codes constantly. To take your specific example, what should a string parsing function return if it receives nonsense? Well, in C, atoi simply returns 0 if parsing fails. It's hard to imagine a worse interface (return probably the most common correct value to indicate an error). A lot of people would now say to use ADT's like Optional&lt;T&gt; or Expected&lt;T&gt;, which use exceptions, and basically allow users to choose whether they want the exception or error code paradigm. Or you could provide two interfaces, one that throws, and one that has an error code. For some people, an exception throwing interface is better, for some return codes is better. Whether one should throw depends as much on probably clients as anything else. String to integer is one of those interesting cases where I'd argue that ideally you want both interfaces.
I meant, like pay wise, it would only take them 2-3 hours. Not that I need it done in 2-3 hours. I "wanted" it done within 48 hours or so.
&gt; Speak for yourself. I've seen plenty of C++ codebases which use exceptions. Yea like the standard library, for example.
I am mostly scarred by the likes of C# and Java. They're supposed to be the exception, but they slowly become regular control flow.
 class C { void f(double); public: void f(int); }; C c; c.f(4.2); Error if not accessible does not prevent visible, C::f(int) if not accessible means invisible. Then you play SFINAE tricks... and you change meaning. I'd not be too surprised to find an example where the meaning is changed without SFINAE tricks. The original rationale IIRC D&amp;E correctly is so that you can refactor (moving code from the class to outside or vise versa) without fear of changing semantic.
&gt; Keep in mind that prior to exceptions, people would ignore return codes constantly. And people continue to ignore exceptions. http://ericlippert.com/2014/03/06/living-with-unchecked-exceptions-part-two/ Language developers thought they were doing us favor by tying developers' hands until they dealt with the errors, but it turns out they just throw down some boilerplate to make it shut up. If I had to pick one, I think the `Optional&lt;T&gt;` approach is the best of the bunch because it's semantically clear (this function can "fail") without resorting to heavy-handed stack-unwinding. Ignoring errors is extremely common and useful. I have written much code that basically says, "Parse this string for an integer. If that doesn't work for whatever reason, return 0." I cannot remember the last time I wrote code that said, "If this string is not an integer, oh man, PANIC LIKE CRAZY."
&gt; This is an important advantage of exceptions: it is more difficult to forget to handle exceptions then to forget to handle every error code for every call. As I posted above... http://ericlippert.com/2014/03/06/living-with-unchecked-exceptions-part-two/ This lines up with my experience. Exceptions just bother people. The dream of robust error-handling everywhere only happens when an engineer cares and pushes to make it happen. That happens regardless of whether exceptions or error codes are being used.
I'm saying if it could be done in 2-3 hours you should do it yourself since it will take you longer to find someone to do it and work out how to pay them. Also I'll just tell you now that you aren't going to find someone to do this for the time and money you have available. 
I read your post and you bring up a good point. I think the way to deal with this is to treat Modules like you would libraries. You can have libFooBar.a that is built by foo.cpp and bar.cpp You may also need some way of specifying modules in this manner.
I would be interested in knowing what the alternative would be. AFAIK, other languages solve this through an added layer of indirection (bytecodes, jits, etc).
The ifc file they mention is a kind of bytecode. The problem is not the bytecode but the fact that the filename can't be known beforehand.
You are correct. I am speaking in a more pragmatic sense. Microsoft used to have Windows Services for Unix - but the last update I can see from the Wikipedia page was in 2004. Given that the kernel by design supports multiple subsystems, I would like a Unix like subsystem that would be at least as compatible as MacOS X is to Linux
Ah, so if foo.cxx always produced foo.ifc and modules were always imported as something like import Foobar from usr.lib.foo; That would make it much easier to make a build system, correct? Whereas the current proposal is saying something like "foo.cxx produces Foobar.ifc and Baz.ifc" and the imports are something like "Import usr.lib.foo.Foobar" with no real way to tell if Foobar comes from foo.cxx, or if it is its own stand alone library. Right?
Yes. With the extra pain of needing to put the imported module name on the compiler command line.
There's an open standard (OpenCL) which can run on almost all cards (even Nvidia although they have their proprietary alternative too - CUDA).
Is it niche though? GPU acceleration is becoming increasingly common and useful, and there's a few different standards out at the moment (OpenCL, CUDA, METAL, etc). There was a time when a lot of people would have said native support for threads in C++ was rather niche and now it's often essential.
Like in Ada,Modula-3 and many others, stored in the module meta-data.
Please stop reading my mind point by point. Thank you.
I think the best thing of C++ is that "much smaller language struggling to get out" depends on your requirements, that is, there are multiple optimal languages builtin inside C++, just pick what best fits your needs. All work with the same compiler and are compatible between. Are you writing a desktop app? Go OOP with easy APIs like Qt. Do you need to fine tune your memory? Go low level and write your own memory pool/allocator. Also, prefer readability and correctness over "low level/without XXX_feature" for performance. Correctness is what saves you from wasting hours on the debugger or writing swear words during code reviews. Note 99% times you are not interested in performance, also the fact that top speed C++ is a completely different league too far from the usual application, even those which are usually considered to be "performance dependent". I'm currently working on embedded devices. You might be surprised there's no C except in kernel modules needed for drivers etc, else it's everything C++ on Qt APIs. These days my work is usually to get legacy "who the fuck has written this bullshit new/delete Javalike thing?" C++ code, mostly concerning serial port and internal communication protocol used between devices. You know, the usual 2k spec with "frames are x bits long, header takes 16 bits, etc". The original code was all about `new`ing return values since copying 2048 bytes frames could take a while... You don't want to look at the code that does serialization.... My solution?: RAII, value semantics, and a fancy QByteArrayView for easy byte manipulation/serialization. Simple. Correct. Using best language practices. And surprise! It performs quite well. Write code to pass reviews and unit tests, not to pass YOUR IDEA of performance constraints. 
Most games avoid dynamic allocation during the main game loop.
This is only partially true. GUI applications need some vectorized graphics sure, but they have many texture assets too, which need to be upscaled or downscaled. Providing a vector library only accommodates part of the needs of the enduser in this case, instead of the entire thing. Also, nobody writes a single GUI application and expects it to scale from a watch to 8k monitor. That's absurd. Even if the graphics scale perfectly, the UI would be all wrong. Even phone to tablet is a stretch and companies that do it properly code a different UI layout for each form factor. Citing the range of hardware resolutions isn't a good reason to prioritize vector graphics over anything else.
I wanted CMake to generate VS project files so that the IDE can be used for development but I wanted the Clang compiler to be used by CMake and VS IDE. I'll try setting CMAKE_CXX_COMPILER soon.
Edit: see [here](https://www.reddit.com/r/cpp/comments/3og22x/cppcon_2015_gabriel_dos_reis_large_scale_c_with/cvxg459)
Near the end there some talk about the status of the ISO. It should be pointed out that ISO is a [private, non-governmental organization](https://en.wikipedia.org/wiki/International_Organization_for_Standardization#Overview). Its association with the UN is that it's been granted "General Consultative Status" as a private organization. For comparison another organization with the same status is [AARP](https://en.wikipedia.org/wiki/List_of_organizations_with_consultative_status_to_the_United_Nations_Economic_and_Social_Council#General_Consultative_Status). The US member of ISO, [ANSI](https://en.wikipedia.org/wiki/American_National_Standards_Institute), is also a private organization. The governmental organization in the US responsible for standards is NIST, which as far as I know has no direct relationship with ISO. The member organizations for some other nations are indeed those nations' governmental standards organizations.
Try Embarcadero C++ Builder. Windows, OS X, iOS and Android. http://www.embarcadero.com/products/cbuilder It costs though, about a grand for the Professional edition. 
This is possible. http://www.codeproject.com/Articles/31783/Custom-User-Defined-Operators-in-C
&gt; GUI applications need some vectorized graphics sure, but they have many texture assets too, which need to be upscaled or downscaled. Providing a vector library only accommodates part of the needs of the enduser in this case, instead of the entire thing. Did you read the entire proposal? Cairo (which it's essentially a wrapper for) covers raster graphics as well, and even comes with loaders for a couple of image formats. It is most definitely not a vector-only library. It's certainly vector-heavy, but it is by no means vector-only. It also has some stuff that the C++ standard needs for any graphics workload: font rendering and metrics.
QtConcurrent is just amazing with signal/slot system: no explicit std::threads, std::mutexes or queues to write asynchronous code. And then custom classes can be exposed to the QML and their signals can be used there to drive the GUI.
Is anyone using the clang module stuff now? Is it working out OK?
True, I wonder if down the road all the different GPU standards will be rolled into either a single interface with Boost or even become part of the standard library.
It's still early, but I believe the final proposal is likely to include some kind of backward friendly mechanism. As an example, (and noting there are several ways to do this) the way clang modules work today where "#include" can magically become import when modules are turned on, so the same code will still compile on a pre module compiler.
I was going to write basically what you just wrote. Basically, at a library/module level, I'd argue that member variables of any class that is part of the interface, are also part of the interface. At the simplest level, the client can always call sizeof on any exposed type; changing member variables therefore can change observable behavior. 
Cool, I was wondering if someone had ever made this `constexpr`.
The problem is that Office and Windows aren't going to rewrite their codebase to make use of modules nor will many big existing projects. It will be on new projects to make use of modules.
[this should give more light](https://www.reddit.com/r/cpp/comments/3oi9ce/is_it_possible_to_use_a_letter_like_an_operator/cvxrmhw) If you do result = vec1 + vec2 &lt;dot&gt; vec3; What do you expect? you expect `vec2 &lt;dot&gt; vec3` happen first because thats the order we are used to with dot products. But because of the operation order of `&lt;&gt;` it happens last and so the addition happens first and you are forced to put brackets. It becomes easier to do result = vec1 + vec2.dot(vec3); As the operation order is more what you expect if you were to write out a math equation and looks more nicer than this result = vec1 + (vec2 &lt;dot&gt; vec3); which will get alot bigger and equation heavy in a math/science related application. Overloading the `*` instead should solve this but looks kind of weird. result = vec1 + vec2 *dot* vec3; 
&gt; Hopefully C++ gets partial classes though or class implementations are gonna get really big. No need. What we need is Uniform Call Syntax. The methods you use on a class/classes depend on the context. It is not desirable to have partial classes in C++, Concepts + runtime concepts + uniform call syntax and free functions is the way to go.
Clang's module system allows 'modularized' headers to be imported via `#include`. That is, if you enable modules then for each `#include` the preprocessor looks to see if there's a corresponding module and if so it imports the module instead of doing a textual include. In addition to having a modules implementation, almost the entire C library on OS X is modularized, as is libc++, so you can actually build real programs instead of having to only depend on modules you write yourself. I believe that modules can also be used with glibc on linux, though I haven't tried and I'm not sure what's required to set it up, since I doubt the glibc project itself has enabled it.
I've gone through a lot of different hoops and experimentation from using pure JNI/Obj-C/NDK to Marmalade. I'd say it really depends on what you're trying to do, but I personally thought Qt was the best I could get. For commercial licenses, it could get pricey at ~$350 a month, but it's the best I could find. The bright side is that you can do a great deal without paying first by agreeing to distribute dynamically. However, this doesn't work on iOS, and you may be forced to switch to the $350 a month then. Embarcadero seemed like a pretty good candidate as well, but it felt to me you lose a lot of the transparency. Problems that come up require support whereas in Qt, you can easily just read the code. Either way, those are probably your best bets if you're really against writing the app in the native languages (which was my case). Setting up JNI + C++ and Obj-C + C++ wasn't too bad, but it's a LOT of work later on. My first attempt was to do all the GUI logic in Java with JNI calls to C++ for the backend. Then I would use Obj-C for GUI and hook it up to C++ backend. There's just tons of room to get things wrong and mess up. You also miss out a lot on the UI consistency. If you plan on making this into a long-term personal project, that's fine. But if you have any intentions in bringing this commercial, going third-party with Qt's probably your best bet. If you want to speed things up further, I personally think V-Play's addin for Qt is absolutely great. You can get a working app up in minutes with it without losing on the low-level control.
Based on the overview, there does not seem to be much overlap?
So maybe might have occurred to you that those who grasp how compiler internals work, haven't found a solution capable of both being backwards compatible with existing code and not make semantic phases even more complicated than they already are? I seldom use C++ nowadays, but I do have background in compiler design and don't see an easy way to do it.
Modules don't affect that. If you want to include your definition inline with your declaration you can do that with a header file: struct X { void foo() { ... } }; inline void bar() { ... } 
Yes but OpenCL requires specific runtimes like Beignet and whatever AMD has that is based on LLVM (besides it only handles a subset of C++).
If a class is that big, you have a enough other problems.
Not 100% but they reimplement things like string, atomic, map, hash table, chrono stuff, decimal, float and a lot of things already available on Boost and the stl. I'm not saying is bad, or I wouldn't use it, I use Intel TBB for some things and it overlap with STL and Boost, just that for 99% of the projects is not worth to include a whole framework to use one thing. 
yes, 'it works', but you're still left with a behemoth class at the end of the day, which is just nasty.
The feature is also great for code generation scenarios: you can inject code into a (co-operating) programmer's class without having to modify their source files.
From what I understand from the VS2015 U1 flags, it is possible to not change the code and try with just using the flags with a bunch of source code files. Maybe it's harder than I think but it seems possible to test. In any way, they are developing something which have one major compile-time performance goal. I expect some improvements if they are still working on this, so why not give some of their current numbers?
You could just use Qt, the IDE (QtCreator) handles Android, iOS without too much hassle.
In a living code, it is far more common to change, add, or remove an inaccessible (non-virtual) member functions than to change or remove data members because people generally worry about ABI stability (we are talking about classes that are exported). &amp;nbsp; There is no real benefit to exporting inaccessible members; you can't do anything really interesting with them. &amp;nbsp; I am often asked whether not exporting inaccessible members mean objects will be like "Java references" or there will be a form of "auto-pimpl". No, none of that is implied. It just means that unless you're a friend or you are a derived class and the member is protected, you can't name it -- e.g. the name isn't visible to you. Everything else, e.g. alignment, sizeof, offset, etc is preserved in a faithful semantics form. 
I did. Cairo is a heavy-weight library. I don't want a heavy weight library, but I want the primitives that would allow me to implement something like Cairo using the standard library (and if that gets standardized later so be it). It's not hard to come up with things you might do in an application that require more specialized shaders, or marshalling data to the GPU or from the GPU. If you implemented your app with a Cairo clone up to that point, what do you do then?
Exported templates need to be defined in the source file containing the interface definition. The same constraint holds for constexpr functions. See [section 4.9](http://www.open-std.org/JTC1/SC22/WG21/docs/papers/2015/n4465.pdf) on page 16. 
No, you don't; and even if you did the compiler wouldn't understand it :-) &amp;nbsp; Remember, this is just one implementation of the module notion. With that said, I can tell you more about VC's implementation. When the compiler sees an import declaration, it consults its internal state to see whether the nominated module was already imported. If so, it moves onto the next declaration (importing the same module more than once has the same effect as importing it once.) Otherwise, it looks into the referenced files (e.g. the file specified with `-module:reference`) to see if any contains the IFC for the requested module. If none, you get notified; otherwise the IFC is loaded and the compile continues onto the next declaration. &amp;nbsp; The reference files you specify on the command line only need to *contain* the IFC for the imported modules. The names of the files is irrelevant. This is different from include files.
I recall there is a boost library proposed for such a thing (boost.compute -- based on openCL), but I'm not sure what it's review status is. C++AMP is a pretty interesting project, but I haven't heard any news about it since last year so I'm not too sure it's under active development. The initial implementation was done as a collaboration project between NVIDIA and Microsoft based on DX11, although there was an AMD/Clang implementation as well based on openCL.
Ok I'm a bit confused here, am I right that for member functions to be possibly inlined they definition will be put into metdata (.ifc) file if class is exported? Can this be avoided by putting function definition outside class definition but in the same file? If it is true then duplication of function signature will occur still but (possibly) in the same file, it would be really great if even in this case it could be avoided somehow.
That repository should give credit to the original author: http://www.curly-brace.com/Aspartame.html
Another way would be to use the [`pipable_adaptor`](http://fit.readthedocs.org/en/latest/pipable/index.html). So then you can call the function like this: auto filter_result = list | filter(func1) | filter(func2); auto filter_result = list | filter([](type A){ return func1(A) &amp;&amp; func2(A); }); auto dot_result = vec1 | dot(vec2); There is a post [here](http://pfultz2.com/blog/2014/09/05/pipable-functions/) that explains how to make your own pipable adaptor in C++14. 
It is part of boost. The review was successful [0], and the code is in the boostorg organization [1]. It is not part of a Boost release yet because of [2] but is coming. [0] https://groups.google.com/forum/#!searchin/boost-developers-archive/compute$20review/boost-developers-archive/SyCk7T0R8KI/Nrnyvh9LUD8J [1] https://github.com/boostorg/compute [2] https://github.com/boostorg/compute/issues/485
I went for Delphi, mainly because I've been using it for a long time. C++ Builder... not so much. Found it very difficult to use for generic C/C++ applications, gave up with long ago. Not sure if Embarcadero have made it any better since then.
yes, afair it's possible with macros and operator overloading. but you REALLY dont want to do that
Correct. If you want inlining of the functions exported from the module **without** relying on whole program optimization, you must put the definition in the module interface file.
One thing I like about header files is the ability to use it as documentation that is mostly constrained to be consistent with the implementation. In the modules proposal, I can see how tools cool be provided to parse the .ifc file and produce a list of declarations. This would be similar to what would appear in a header file, but I don't see how comments are to be handled. Python has a built-in help facility that shows what is available in a module, and it uses a convention that a string as the first line of a function or class definition will be used as documentation. Are there any proposals along these lines?
The answer is dated Feb 26 '13 at 13:47, the article I linked 2009.
This library implements polymorphic memory allocators. This is being considered: http://en.cppreference.com/w/cpp/experimental/lib_extensions#Type-erased_and_polymorphic_allocators
At the beginning he mentions this is a continuation of an earlier talk by Michael Wong, "C++11/14/17 Atomics the Deep dive: the gory details, before the story consumes you!". Has that been posted yet?
Yes. This is being discussed along the lines what other useful information compiler can stash in IFC or a separate file that can be used by tools. There is no proposal on that yet. We want to acquire more experience with how build tools interact with modules, and figure out how to add extra information in such a way that it won't cause the build system to recompile the world if you just changed a comment.
 #ifdef LEGACY_COMPILER #include &lt;stdio.h&gt; #else import std.io; #endif
I see no \* anywhere in his post.
Did all of your template definitions disappear? I see a lot of: template struct X{} type stuff, but no &lt;typename T&gt; .
Not to my knowledge, it doesn't appear the slides have been pushed to https://github.com/CppCon/CppCon2015, either (at the moment of writing, at least). Should be up at some point, though.
 In Qt/C++,its: &gt;&gt; QStringList split = name.split(" ") ; http://doc.qt.io/qt-4.8/qstring.html#split
Finally..was badly missing his talk. A talk by scott meyers would have made this years cppcon 2015 beyond perfect.
Boooo
| you can exploit a Microsoft-specific peculiarity No. Please no. Of course, it is nice to know what such code looks like, so if I ever see anything like it appearing in a project, I can immediately cancel that engineer's commit access and quarantine all of their commits. ( and yes, my sympathy *does* go out to you, as a tool vendor who has to make sense out of this crap when an idiot vendor does this sort of thing. )
In what ways does your project differ from [qjsonrpc](https://bitbucket.org/devonit/qjsonrpc)? I'm looking to switch from qjsonrpc to another library, and anything using modern c++ is a plus :-) 
Remove the header-only part from the title of this thread. That would be reasonable.
I have to disagree with a few of his points: * Allocators doing construction and destruction of objects being a bad thing: No, they are not; while not overly useful most of the time, things like wiping allocators may be very relevant for cryptographic uses or things like non initializing ones may be used very well to replace more classic arrays with `std::vector`. * It is really not hard to build something like his dispatching allocator with the current model. How you implement it, is your choice and the current model avoids getting in your way there. Andreis model in return heavily encourages a staticly known list of allocators and isn't well suited for a runtime-list of them. * He still keeps the allocators statically attached to the container-types which really can be annoying. In addition to that, most of the boilerplate got luckily removed in C++11, so today you can really concentrate on the important parts. 
*I feel bad for this, but self promotion*: I am also working on an improved memory model with implementations of freelists and stack allcoators. Adapters allow usage with STL containers. I haven't implemented the composition adapters yet, but this could be easily done. You can find it here: https://github.com/foonathan/memory
That was a very interesting set of code. You've put in a good amount of work there. Do you agree with the idea that the allocator "interface" and all its users in STL should be changed to work with a model akin to yours and Andrei's? Maybe there should be a proposal about this for the Library TS? I would make my life a lot easier because using a StackAllocator (from the talk) and some static analysis I would be able to allow for "dynamic" allocation and STL use in my embedded code and reuse / test it using a different way on my PC.
Are you in favour of polymorphic memory resources as in Library Fundamentals TS?
I personally haven't had a need to use those yet, so I cannot fairly judge the specific interface, but in general I am indeed positive that introducing those will be useful for some people.
I don't agree that the full interface should be changed, Allocator is more powerful than my RawAllocator (control of construction, pointer, ...), and also backward compatibility. The [polymorphic memory TS](http://en.cppreference.com/w/cpp/experimental/lib_extensions#Type-erased_and_polymorphic_allocators) is similar to the use of my any_allocator_reference, but does not use type-erasure.
Yeah. Wordpress. Should be fixed now.
https://www.upwork.com
What was your reason for the type-erasure?
I'd say that the gist when in a C++ environment is thinking of functions as objects that you can manipulate, modify... The simplest would be for instance to have algorithms that would take a value and return another without side effects. i.e. instead of : void sort(std::vector&lt;int&gt;&amp; v) { std::sort(v.begin(), v.end()); } This would become auto sort(std::vector&lt;int&gt; v) { std::sort(v.begin(), v.end()); return v; } The semantics of course change (and the performance may decrease a bit because you may not get all the nice optimizations that a compiler geared towards functional programming might do), but if you are in a fully functional pipeline you would have many functions like this and do : auto sorted = sort(fetch()); Instead of auto data = fetch(); // data is not sorted; we have to be careful about copy pastes around here sort(data); // data is sorted And if `fetch` return a vector of vectors instead, you could have : auto sorted = apply(fetch(), sort); instead of auto data = fetch(); for(auto&amp; vec : data) sort(vec); etc... Finally let's say you want to sort with another predicate : template&lt;typename Pred&gt; auto sort(std::vector&lt;int&gt; v, Pred predicate) { std::sort(v.begin(), v.end(), predicate); return v; } Now we could have the simplest predicate : auto sorted = sort(fetch(), [] (auto lhs, auto rhs) { return lhs &lt; rhs; }); But sometimes it's nice to have a generic predicate; let's say we want some arrays sorted only if lhs is &lt; to another value (yeah it's stupid). auto values = { ... }; // size == to number of arrays Now we create functions that will do the corret sort for us auto generator = [&amp;] (int i) { return [=] (auto lhs, auto rhs) { return lhs &lt; rhs &amp;&amp; lhs &lt; values[i]; }; }; auto sorted = apply(fetch(), sort, generator); Where `apply` will call, at some point, `fun` (which will be `sort`) with `generator(i)`which will yield the correct function. Although I may argue that a simpler way (that would ensure not killing performance) would be reasoning of a functional pipeline without a direct functional-like implementation. For instance if you have a GUI render, put clearly on paper all the phases of rendering, preprocessing as stuff that takes inputs and creates outputs, even if the output is actually a reference to the input.
I ask: what compilers and what operating systems are supported?
You don't need to inherit from a base class, just fulfill the required interface (or specialize the traits).
&gt;Currently, one is dependent on the optimizer to have this reduced to end = begin; The problem is that `std::allocator` is broken by design. Citing the standard, `clear()` &gt; Leaves the capacity() of the vector unchanged. So `clear()` needs to do 2 things only: - destroy all objects, and - change the size of the vector. None of this has anything to do with _memory allocation_ since `vector&lt;T&gt;::clear` does not free any memory! Still in C++ `std::vector&lt;T&gt;::clear` needs to use `std::allocator` to destroy the objects which for me is very weird. Any vector implementation should have the freedom to specialize `clear` for trivially destructible types: void clear() requires(std::is_trivially_destructible&lt;T&gt;) { size_ = std::size_t(0); } For example, if you are writing a "stack allocated vector type" (using `std::vector` with a stack allocator makes no sense) your allocator state must be part of your vector. Such a type is similar to `boost::container::static_vector`. `clear()` then looks like [this](https://github.com/gnzlbg/ndtree/blob/master/include/ndtree/utility/stack_vector.hpp#L244) (github link): constexpr void clear() noexcept { destroy_all(); size_ = size_type(0); } where `destroy_all` is implemented [here](https://github.com/gnzlbg/ndtree/blob/master/include/ndtree/utility/stack_vector.hpp#L80) (github link) as: CONCEPT_REQUIRES(!std::is_trivially_destructible&lt;T&gt;{}) constexpr void destroy_all() noexcept { for (auto it = begin(), e = end(); it != e; ++it) { it-&gt;~T(); } }) CONCEPT_REQUIRES(std::is_trivially_destructible&lt;T&gt;{}) constexpr void destroy_all() {} I think that having a `deallocate_all` function in the memory allocator is useful, but `clear()` doesn't need it. What it could use from `std::allocator`, if anything, is a `destroy_all` function. Adding such a function to `std::allocator` is not fixing any of its fundamental problems. Modern allocators like `jemalloc` do provide _sized_ deallocations (`free(void*, size)`) and C++14 provides sized delete which can fall backs to non-sized delete. That is, in C++&gt;=14 probably all allocators that interface with "the system's allocator" should be calling sized delete, which means that their interface can be adapted to be analogous to what Andrei proposes. 
Most C++ programmers doesn't work on portable multi-platform code. One of advantages of using C++ is that you have direct and easy access to system API's, in fact for most projects that was likely a big reason for picking C or C++ to begin with.
Why does the standard disallow binding rvalue references to lvalue references? I must admit to using that one all the time (VS user). I personally don't understand why... struct X{}; int update_X(X&amp;); int main() { update_X(X()); } and... struct X{}; int update_X(X&amp;); int main() { { X x(); update_X(x); } } ... should be treated differently. These two examples will most likely produce the same compiler output as would be expected by common sense. So why is the first one disallowed but the second one is not? EDIT: seems it's to prevent "programmer error", what a load of BS. But anyways, you can disable all this with a compiler flag. Besides, if you're going to be writing native Windows software in C++, you're going to be writing non-portable code anyways. The windows header files require that the extensions are enabled and windows software only runs on windows. Allowing the rvalue -&gt; lvalue ref binding gets rid of a lot of ugly const_cast's when calling native WinAPI functions. Plenty of WinAPI functions takes non-const char* and wchar_t* even though they don't actually modify the string you send in. See: void doStuff(std::wstring &amp;optional = std::wstring()) { ::PeculiarWinAPI(1, 2, &amp;optional[0]); } int main() { doStuff(); doStuff(L"More Stuff!"); } vs: static void doStuff(const std::wstring &amp;optional) { ::PeculiarWinAPI(1, 2, const_cast&lt;wchar_t*&gt;(&amp;optional[0])); } int main() { doStuff(std::wstring()); doStuff(L"More Stuff!"); } Personally I think the first version is nicer. 
Very sensible
dae rust is awesome and c++ is bad kek.. here you go, no copies just iterators: std::vector&lt;boost::iterator_range&lt;std::string::iterator&gt;&gt; results; boost::algorithm::split(results, inputString, " ");
Like /u/gfurnish I am missing an alignment specification. There should be another parameter to the allocation function specifying an alignment requirement. Regarding the stl_allocator: It requries the global_allocator, if I see correctly. This means that there is only one allocator of a single type for STL containers. I would pass the allocator as parameter to the constructor and the stl_allocator should take its address and use it. Your freelist does not support growing and uses only a fixed size stack. It would be nicer if it would take an implementation allocator as parameter and allocates its memory from it. Similar for the stack_allocator. Your bucketizer supports only linear growth. This does not allow, e.g. having a bucket for each power of two. If you need some reference implementations, I am working on a similar library: https://github.com/foonathan/memory 
In your first code fragment, any changes that were made to the temporary `X()` could not be used after the call to update_X(), whereas in the second code fragment, the changes to `x` could be used (even though that isn't actually happening in your example). If a function was designed to modify an argument (by passing a non-const reference), calling the function in such a way that the modifications can't be seen is most likely a bug.
&gt; We can keep patching std::allocator to unbroke it's broken design for backwards compatibility purposes but using allocators correctly is getting exceedingly dificult as a consequence of this: There is a different approach I have chosen for my allocator library: Define a new model users and new containers should use, provide an adapter for the old model. The library provides the adapter so only it needs to take care of the old model. This provides full backward compatiblity, but it is more difficult for container writers using the old model, since they cannot do the optimization. They could, however, add the ability to the allocator_traits to detect whether it is the default or custom and do the optimization based on it, since it is required that the custom functions are called.
As before said. I will implement the alignment as one of the next things. It is by design, that the freelist uses a fixed size, It uses the allocator as template parameter, not as c'tor parameter. I will check the issue with the stl_allocator. 
I kindof hesitated on this because I didn't want to hijack your thread, but if you are interested in allocators I am currently working on a conservative c++ garbage collector at https://github.com/garyfurnish/cgc1 and I have a lot of ideas for allocators implemented in there. I could probably port some of the non-gc allocators (I have some vm slab allocators...) to Andrei's style if there was interest, but the lack of alignment support in the API is a big deal that needs to be bikeshedded. Some of the code is definitely rough and I recommend looking at the development branch (although there are currently some deadlock issues... if atomics are razor blades reenterant code is nukes ) But if you want some ideas on how to implement really complicated allocators, its not a bad place to look too. (I put in a pull request on github for some fixes to get your code compiling against gcc 5.) For people late joining the party, the video is: https://www.youtube.com/watch?v=LIb3L4vKZ7U
lol the guy is on reddit too...
Is there a reason to favor doing wiping at destruction as opposed to deallocation? I took away from it more "here are some design patterns for allocators that we could make to automate common tasks" then "lets replace allocators." Was I wrong? 
&gt; The old model allows allocators to provide a std::allocator::construct/destroy that does something different than placement new and calling the destructor. It is unclear to me if that means that using the old model one is required to construct and destroy objects using these member functions. It is - §23.2.1[container.requirements.general]/3: &gt; For the components affected by this subclause that declare an allocator_type, objects stored in these components shall be constructed using the allocator_traits&lt;allocator_type&gt;::construct function and destroyed using the allocator_traits&lt;allocator_type&gt;::destroy functionand destroy objects using these member functions. (qoute break) &gt; If that was the case I don't see how you can adapt these old allocators in a model that doesn't expose these as primitives? Maybe I wasn't clear enough. I have defined a new model, 'RawAllocator' which does not take care of ctor/dtor calls. Traits magic ensure that all 'Allocator' classes are also 'RawAllocator', but if you use an 'Allocator' as a 'RawAllocator', it loses the ability to control construction/destruction, since the 'RawAllocator' interface does not provide it. For the other way round - using 'RawAllocator' where 'Allocator' is required, I have written an adapter, 'std_allocator'. It takes a 'RawAllocator' and maps the memory (de-)allocation function using the defaults for 'construct'/'destroy'.
&gt; IMO there is no good solution that would make everyone happy. For me something like the following would be the best of both worlds: I can give it to you :D std::vector&lt;int, memory::std_allocator&lt;int, some_allocator&gt;&gt; vec(some_allocator()); // or alias: memory::vector&lt;int, some_allocator&gt; std::vector&lt;int, memory::std_allocator&lt;int, memory::any_allocator&gt;&gt; vec(some_allocator()); // or alias: memory::vector&lt;int, memory::any_allocator&gt; See https://github.com/foonathan/memory Edit: Oh, you've edited the quoted part out.
It has passed review and accepted into boost. As far as I understand it shall appear in the next release. 
It is not a bad thing, but if you need a wrapper for - let's say - 10% you can also use it for the remaining 90%. Better one solution that covers everything than two. &gt; The same can btw. be said about allocation: What good is writing an allocator if I cannot use it for a std::unique_ptr? (You can btw. use it for std::shared_ptr via std::allocate_shared which is the less well known brother of std::make_shared). std::unique_ptr does not need to allocate everything, it just needs to deallocate the memory. So it only gets a Deleter. This is much simpler and has the benefit of allowing plain functions. std::shared_ptr on the other hand needs to allocate its internal reference count object, not only deallocate the object. So it can optionally get a full-blown Allocator.
Both of those are really good points. (For the record I use the complicated features, so I just saw this as things to add on, but yeah in the context of his earlier statements I see what you mean.)
This is nice, great ideas. 
&gt; He still keeps the allocators statically attached to the container-types which really can be annoying. Those two vectors you mention: &gt;std::vector&lt;int, memory::std_allocator&lt;int, some_allocator&gt;&gt; &gt;vec(some_allocator()); &gt;// or alias: memory::vector&lt;int, some_allocator&gt; &gt;std::vector&lt;int, memory::std_allocator&lt;int, &gt;memory::any_allocator&gt;&gt; vec(some_allocator()); &gt;// or alias: memory::vector&lt;int, memory::any_allocator&gt; still have the allocator attached to the vector type. Or am I missing something? EDIT: Given some_allocator another_different_allocator All of this works: vector&lt;int, some_allocator&gt; a(some_allocator()); vector&lt;int, another_different_allocator&gt; b(another_different_allocator()); vector&lt;int, any_allocator&gt; c(some_allocator()); vector&lt;int, any_allocator&gt; d(another_different_allocator()); But these fail: vector&lt;int, some_allocator&gt; e(another_some_allocator()); vector&lt;int, another_different_allocator&gt; f(some_allocator()); 
It's not that different. Your post sounded like you needed an implementation, so I wanted to give you mine. Bloomberg's and the upcoming TS are slightly different in that they require the use of an abstract base class while I use type-erasure.
Interesting research. I am not familiar with cpp-netlib but I suppose that this library has additional functional which increases code base.
I think cpp-netlib (I believe from Google) uses Boost Asio, which may explain the difference in size? I remember reading that it wants to be part of Boost. If it is possible to not expose Asio data types in your header file the header overhead could be reduced. But I understand that might be hard to do.
Ok, thanks. Just for information, VS2010 does not work. 
Unfortunately, VS2010 partially supports C++11 features - [link](https://msdn.microsoft.com/en-us/library/hh567368\(v=vs.110\).aspx).
Why is there formulaic music from an acoustic guitar in the background? Why didn't anyone at CppCon say anything about this? Can Mr. Nash hear the music during the presentation? I guess I found the faint music unreasonably distracting. 
89 easy steps? 
I know it has nothing to do with the topic of the talk and it's just a nitpick, but why bother doing an xor swap, when you return by value anyway? Just swap a and b in the return line. OTOH this violates the principle of least surprise, because any sane swap function overwrites the inputs, so anyone that uses this might actually do a nop, because they might just ignore the results. Also, why have xor be part of the name, when that's an implementation detail? Anyway, I know I am nitpicking, and there are a number of very nice suggestions in this talk. Just my OCD.
Just looking at `stl_allocator`: - Lots of unnecessary stuff: `rebind`, `address`, `max_size`, `construct`, `destroy`, and all the typedefs except `value_type`. `allocator_traits` supply correct defaults for all of these except `address`, which is not required by anything, and arguably `max_size`, which is being [fixed](http://wg21.link/lwg2466). - Not that it matters here, but `construct` and `destroy` should use built-in pointers, while `allocate` and `deallocate` should use (possibly fancy) `pointer`. You got that reversed. - `construct` is not only unnecessary but actively harmful; your versions prevent moves. `address`, if it is to be provided at all, should use `std::addressof`. - Destructor should be defaulted so that it is trivial. - It should have `using is_always_equal = true_type;` for C++17. - POCMA should really be `true_type` because it affects the requirements on the container's value type (compare [LWG 2103](http://wg21.link/lwg2103)), but for that you'll also need to make it move assignable.
Check out the thread on /r/programming too, Bjarne himself comments there. https://www.reddit.com/r/programming/comments/3oqj59/bjarne_stroustrup_on_the_30th_anniversary_of/ 
Turbo Pascal 
Cmon, it's 2015 on the yard!
https://en.wikipedia.org/wiki/Include_guard
How would you use AA's allocators with the STL?
It's more about signals and QEventLoops to link objects that live in different threads and then be able to destroy that painlessly. Now I see that QEventLoop is not in QtConcurrent. So, yes, it's not specific to QtConcurrent.
&gt; \#pragma once Also, the why is because `#include` is just text copy-pasting by the pre processor, and if you don't put guards it might happen that the same header would be copied twice and the compiler would complain (as it complains if you do: `class A {}; class A {};`)
Why then it is allowed to call non-const member functions of rvalue references, this is technically the same as passing rvalue reference as non-const `*this`? Passing rvalue as an lvalue for arguments maybe useful if lack of const in its member functions means that they are changing not object's state but state of something else and programmer is too lazy to name it explicitly :)
VS 2015 Upd1 CTP supporting C++17 modules now. Waiting for GCC and Clang and fck include guards
I remember not having them on a new project and being completely confused until someone pointed out the include guards prevent things being defined twice. Since then replacing -o object.o with -E has been a big help. :-D
&gt; \#pragma once Possible, but using ```#include``` guards is still necessary sometimes because ```#pragma once``` is a compiler thing and non-standard.
Can you name a compiler that doesn't support it? ;-)
This needs a way to prevent allocators from being constructed to any_allocators. Not all memory addresses are interchangeable. Take pinned GPU/MMIO memory, etc. Added: Basically right now you can rely on the type system to prevent you from accidentally copying memory created with one allocator to one created with another allocator. This is in some cases a desirable feature, not a bug and in the chase of usability we should not destroy that for people who need it. Maybe we could only construct an any allocator from an allocator if some constexpr boolean is set (or not set)? 
The worst thing is having them, but having copy-pasted from another class and the guards in both files have the same names...
[Solaris Studio apparently!](https://en.wikipedia.org/wiki/Pragma_once) 
Source ? I can only see this in Update 1 CTP. http://blogs.msdn.com/b/visualstudio/archive/2015/10/08/visual-studio-2015-update-1-ctp.aspx https://www.visualstudio.com/en-us/news/vs2015-update1-vs#Cdoubleplus 
&gt; (Or is there a separate stateful device allocator for each vector that knows which memory it has allocated?) This. Since the GPUs are detected at run-time, one cannot really have in practice a different type for each allocator for each GPU. They all have to have the same type, so they need to store in which GPU their memory is allocated. &gt; I don't view a run-time error as acceptable. Then don't use type-erased allocators. As simple as that. Right now they are opt-in, making all interfaces using containers complicated and relying on users to copy memory manually. They should in my opinion be opt-out. That is, whenever one writes an allocator, one at least provides a conversion to std::allocator via main memory. That way all allocators are copyable to each other by going through main memory first, and we can forget the allocator type in containers. This also allows adding more constructors for specific situations (like copying memory from one GPU to another without going through main memory), but for that one needs to know when writing the allocator the other allocator types. If a virtual function call is too expensive for a given application, one can still opt-out of the any_allocator, and your vector type would still be copyable to a vector type using an any_allocator. IMO this is the best of both worlds. When you care, you can do what you want and you still can talk to code that doesn't care without thinking much about it. 
yeah, look, i'm a total newbie, and nobody should take my word for anything.....but one of the best principles i know is "Don't Repeat Yourself", and it seems like having to go through this silly routine every time really negates that. 
I haven't used it, but IntelliJ CLion is quite new. I have used IntelliJ IDEA for Java and it's superb. https://www.jetbrains.com/clion/
I don't understand what is calling the special memcpy to do a block copy of the entire vector. The copy constructor can't call it because we are using a ::std::vector, the object copy constructors or construct can only call it presumably at the object level which would be a major disasterous performance problem with lots of objects. I don't understand this the allocator handles it stuff. In writing code for a garbage collector (internally) in which I have multiple allocators floating around, I absolutely have caught bugs that would have been nightmares to find by allocator type errors. I don't view this as a hypothetical, I've seen the productivity gains first hand when writing systems/etc code. It is preferable to not have to avoid C++ features because they are poorly designed. It would be even worse as a default where a typo would break the entire type safety system for allocators. If the default for a container is "take any allocator" that is a disaster because then not typing the allocator (easy to do) leads to breaking the type system. A wiping allocator should be copyable, but then the data should be copyable into a type erasure allocator. Unlike the above example where you might be able to argue to be careful, a wiping allocator is a common use case. So you write a library using wiping allocators and now you give it to a user who uses type erasure and they use it wrong. You can't just assume "don't use type erasure allocators." 
worth pointing out that this isn't free in all cases
CLion is still young but I love it. All of IntelliJs products are amazing. I use PHPStorm for most of the development I do since I do a lot of PHP work. But I use CLion to do all of my C based coursework.
Check Apple's `Instruments` while having breakfast ;)
In Eclipse you can launch external programs using Run-&gt; External Tools. Just configure Astyle using Run-&gt; External Tools-&gt; External Tools configuration.
&gt; This needs a way to prevent allocators from being constructed to any_allocators. Not all memory addresses are interchangeable. Take pinned GPU/MMIO memory, etc. Could you elaborate that part a little bit more?
probably sublime (not free) and atom (pretty new/young foss) will do this
Can you post the results of the execution? Because as I see from here you put pointer to the char array which is fixed size. And also the result of the execution for me is always -1 (if i change the type %zu to %d) Maybe I don't get something right?
&gt; For large (non-string or const size string) object construct/destroy is best. (So the case for construct/destruct would be const size (c) string (char[500] etc). So destroy would be called for the array. Sorry, that was unclear or large data structures (which also don't have the clear problem). 
With codeblocks you don't even need to bother with this because it comes with the Astyle plug-in by default :) 
That in itself is bad, but the worse case is creating a vector with an any allocator, passing in another vector with an allocator that allocates in say mmap io, the gpu, etc to the copy constructor, and now you have just copied data object wise (which could be very large number of objects) out of some memory that is not system ram. This could be very very slow. This could block. This could trigger a mmap io page load on a nfs file that has to go across a VPN to a remote server. This could do all sorts of horrible things. And this interface lets you do it without knowing it while looking like it should be fast. Without the any allocator you get a type error and you know to look around and do a ::std::copy and make sure you really want to do that. This makes it easy to accidentally do horrible things. 
I think it is easier to accidentally pass a temporary to a function than it is to accidentally call a member function. See this Stack Overflow answer: http://stackoverflow.com/a/1565811/951890 Note that with C++11's reference qualifiers, you now have the ability to restrict this: struct A { void f() &amp;; // f() can now only be called on lvalues };
What are the reasons to use this over something like Eclipse? Can I use custom keyboard shortcuts and launch Astyle using it?
I want something free, I seem to have forgot pointing that out.
Hmm I was thinking that it might convert. Now I feel dumb :/ That is a significant concern lifted. If we defaulted to any_allocator there would still be a concern if someone forgot to include the template parameter on declaration though correct? template&lt;typename T, typename allocator=::std::allocator&lt;T&gt;&gt; using new_std = ::std::vector&lt;T, allocator&gt; new_std&lt;int&gt; gpu_vec(gpu_allocator_instance); new_std&lt;int&gt; cpu_vec(gpu_vec); That would still work though correct? So as long as we do not change the default allocator to a type erasure one there isn't a problem. (and depending on design similar issues with polymorphic). 
You want [Qt Creator](http://www.qt.io/ide/) - it's free and works perfectly fine with non-Qt C++ code.
Easily, as you can map keys to do basically any arbitrary command. Vim is significantly "lighter" than Eclipse and will probably increase your raw speed given its modal nature, but it's also not an IDE and so it won't offer fancier features that a full IDE will. If you're not willing to sacrifice some of the fancier IDE features (automatic refactoring, more intelligent completions, etc.), then stick with an IDE.
I use a setup exactly like you want but use Sublime Text 3 (latest dev build) which is not free I am sorry to say. Worth the money though as it "just works", is super light and is crazy fast. 
Right. I like the idea of defaulting to any_allocator, but if we do that we need a way to say "except for these types which are dangerous." Also needed is a concept of "Same minimum alignment." I'd strongly consider doing that locally when I have multiple allocators, but (It would be nice to by default be able to copy construct between vectors on pool, stack, and malloc allocators for instance). 
Sublime Text or UltraEdit (both commercial) can do this.
Qt Creator. You can set your external program as a new External Tool in the Environment tab in the Options, which gives you also new entry for keyboard shortcut.
Both [Code::Blocks](http://www.codeblocks.org/) and [CodeLite](http://codelite.org/) will do what you want. They also both include built-in (well, plugin included in the standard distribution at least) support for Astyle.
I use Netbeans professionally for C/C++ development, on both linux as windows. It is really nice
I never proposed that any_allocator should be default, it shouldn't.
It also has direct astyle (and clang format &amp; uncrustify) integration.
[There several plugins which do.](https://encrypted.google.com/search?q=sublime+text+c%2B%2B+code+completion) Out-of-the-box Sublime only does completion for stuff in the same file.
Yes. See, for example ftp://ftp.rsasecurity.com/pub/pkcs/pkcs-11/v2-20/pkcs11.h which includes pkcs11f.h three times, with different #defines each time.
Emacs + Irony mode, for sure. 
Depending on your outlook, include guards tell the preprocessor not to repeat itself.
&gt; There several plugins which do. They probably work about as well as the Emacs or Vim clang based tools then. 
Thanks :-) If I think of a solution to the dll problem, I will let you know on github as well.
In case you are a student you can get all jetbrain products for free: https://www.jetbrains.com/student/
Sure CodleLite can satisfy your request
If you decide to stick with VS, have you tried the AStyle or ClangFormat extensions?
When using the free version, yeah.
No, not yet. Most of it's not really computationally complex (add these four numbers to these other 4, etc.), and in the few places where it is, I either took the naïve approach (no matrix multiplication tricks for example), or copied an algorithm I myself admittedly don't really understand (e.g. SSE sin(), cos(), log(), etc.) I do, however, have tests covering EVERYTHING, so if and when I do decide to focus on performance in a few key places, I'll be able to do so without fear of incorrect results.
I *really* like this. I didn't see any mention of AVX/AVX2 but it looks like it should "just work" out of the box, at least for non-intresnics? It looks like it would properly align if you gave it a uint32x8 or uint64x16. Is there a reason for going recursive vs using for loops and the autovectorizer? Some of those intrinsic calls could be covered by a for loop as a generic case and then you would not need to make separate functions for each data type. 
I'n not a lawyer and couldn't find anything regarding QtCreator explicitly, but if you use GPL-licensed tools you can develop commercial software. http://www.gnu.org/licenses/gpl-faq.en.html#CanIUseGPLToolsForNF
How does the performance compare to eigen, a math library that utilizes many modern chip instructions (avx, avx2, sse, etc.)?
I'm not sure, but eigen's support for integers is not great. Just by having easy to use XOR, etc this is a win for certain use cases. 
I haven't, but I don't want to use VS since it is exclusive to Windows.
Why not just use boost::string_ref?
Yes, things like `uint32x8` and `uint64x16` (well, I don't actually define typedefs for anything larger than 512-bits, but you could do `simd&lt;uint64_t, 16&gt;` if you really wanted to) should work even though intrinsics for them haven't been implemented yet. I guess one caveat is that, for some reason on Linux GCC (at least 32-bit x86, haven't tried 64-bit yet), it didn't seem to let me specify alignments greater than 128-bit. AVX acceleration is planned for the future, but I think I want to play around with NEON first. It's just SSE and SSE2 for now. As you observed, if you start using types like `uint32x8` now, then when AVX acceleration is added in the future, the same source code should "just work". I use recursion in the `simd` types so that if a particular type isn't accelerated, but a smaller vector with the same component type is, then the larger type will be accelerated by the smaller type. So, for example, in the current absence of AVX acceleration, `uint32x8` will be a compound of two `uint32x4`'s which are accelerated by SSE2 intrinsics. The `vec` and `mat` types avoid using loops for the sake of supporting `constexpr`. But now you have me wondering if maybe auto-vectorization works the way I wrote it.
No expression templates?
Shouldn't `string_view` have a deleted `string_view(std::string const &amp;&amp;)` constructor? It's very easy to get an accidental r-value in there: #include &lt;string&gt; #include &lt;experimental/string_view&gt; using namespace std; using namespace std::experimental; auto f() { string_view s = "sadfasdfasdf"s; // bam ... }
Thanks for pointing this out. I'll revisit my recursion strategy when I decide to focus on performance more.
Emacs + irony is a winning combination.
https://github.com/Cincinesh/tue/issues/19
No. Tuesday was mainly designed for use in game and graphics software, and the subset of linear algebra used in such applications is relatively small compared to what the other libraries you mention provide. Tuesday is a comparatively small, easy-to-read library without any third-party dependencies and I'm planning to keep it that way.
I don't suspect that expression templates are needed for most use cases with very small dense dimensions. Modern inliners are pretty good, especially combined with "always inline" if needed. (MSVC needs this occasionally even on templates :/) 
Can you undock panels from the main window and use multiple screens efficiently or is this still impossible? 
Having just read all of those slides, and I say this as someone who likes lock free algorithms, that seems *really* excessively syntactically complicated. Is there a better paper on the new syntax ideas somewhere or is this just a talk so far? 
Boost works fine with MinGW. Source: Have built it in my distro for 10 years. Something is severely wrong with either your toolchain or your computer.
For a talk that's an hour long, there is not much content in it. You can save a lot of time by reading the [20 slides](https://github.com/CppCon/CppCon2015/tree/master/Presentations/string_view). Basically, it's about saving unnecessary temporary `std::string` objects by changing `const std::string&amp;` to `string_view`.
&gt; is there ANY reason for keeping them???? Not everyone uses a compiler that supports `#pragma once`. If you want your code to be portable to older compilers, you can't be guaranteed support. Granted, it's pretty rare these days, but I still occasionally run into systems running an old-as-sin version of GCC. There is also the case where you have files copied in your source tree, and `#pragma once` won't protect you from duplicate header files. So until C++ gets modules, use both. &gt; as in, is there any situation where you would actually want a header to be included twice??? Yes, but that's not what you're asking. Remember that an `#include` is literally a copy/paste of text. There are use cases where large sections of code need to be copied to multiple places in the same source file, and so you could in principle `#include` it in each place. But what you're actually asking is *why* a header would be included twice. Consider: // system.h // ... #include &lt;sys/time.h&gt; // ... ------ // dateutil.h #include "system.h" // includes sys/time.h // ... ------ // main.c #include "dateutil.h" #include "system.h" ... Oops. `main.c` has *two copies* of `system.h`. You probably don't want that to happen.
i can see how the wording of my question invited this confusion. I was actually wanting to ask, "If header guards are used on every header file, then why aren't they just included automatically by the preprocessor or compiler?" The two reasons i can gleam so far are: (1) Backwards compatibility with old compilers. (2) there are some rare cases in which the same headers are included multiple times, such as /u/armb2 posted here. but yeah....seems like they're mostly just a relic, which never really got automated cos nobody wanted to break backwards compatibility. Also, i guess in their defense, they do introduce new programmers to the preprocessor. Does seem it would be tidier if their function was automatically automated. 
slides https://github.com/CppCon/CppCon2015/blob/master/Presentations/Beyond%20Sanitizers/Beyond%20Sanitizers%20-%20Kostya%20Serebryany%20-%20CppCon%202015.pdf
&gt;The C++ language has the One Definition Rule: When something is defined (whether a function or template or class or whatever), that definition is allowed to appear exactly once in any given compilation unit. yeah exactly, so why is that rule not just taken care of by the preprocessor? I totally understand the need for the one definition rule. What i don't understand is why it is not just automatically done every time you #include something in the preprocessor. the type of file would be irrelevant to this. 
I gave up on using vim (more precisely VsVim) after not being able to figure out the way to yank/delete whole C++ function definition consistently. I wonder if it's something available only through plugins. 
Do you use PCH and MinGW-w64 4.9.2? There's a few stack overflow threads on the PCH bug; the MinGW guys don't seem interested in fixing it
I was looking at this source when I came to that conclusion: https://github.com/g-truc/glm/blob/master/glm/detail/type_vec.hpp After a quick second look in the repo, I still don't see any place where dimensions are defined by template parameters. If you can prove otherwise, please do; I'd hate to make a false claim like this.
I would start with the flowchart. It may be harder for you, but it's really important to clearly understand the high level operation of the program. The second paragraph describes the program's operation, so that's where you derive the flowchart from.
This looks great, cool! And awesome that you made it header-only! Thanks! And even more awesome that it works on VS2015 too. Huge thumbs up!
I usually work with codelite and QtCreator. I tested Kdevelop and it also looks great
GCC 5.2.0 with mingw-w64 4.0.4 headers/libs. Boost is lightning fast to compile without PCHes. (I disable PCHes during Boost's own build because they used to ICE when building Boost.Math; haven't checked to see if that still happens. It made no difference to the 30-second build time for all of Boost.)
This is a podcast interview with Kate, not her CppCon session. I'm sure the video of her full session will be available soon.
Too bad there is still no official build for VS2015.
Glad I'm not the only one that fell for it :&gt;
ok?
Thanks!
I'm not sure if this is what you mean, but you can go to the start of the function, press **V** to enter visual line select, then press **]]** to go to the end of the function, then **y/d** to yank or delete, respectively.
Again with the [Cunningham's Law](http://www.azquotes.com/picture-quotes/quote-the-best-way-to-get-the-right-answer-on-the-internet-is-not-to-ask-a-question-it-s-to-ward-cunningham-77-34-90.jpg). I'm sure /r/cpp_questions will be eager to help you.
My mistake. when I need help on css on html there is no help subreddits for those and didnt know this one did.
What's so sacred about pass by ref? In functional programming it makes a lot more sense to always pass by val by default.
Are there any plans for sparse matrix support?
The problem is that there are too many ways to implement it, whose adequacy and efficiency widely depends on the input data and the operation to be executed on the output data. What if the string to split can contain escaped characters that shouldn't be confused with the delimitator? What if we don't want to modify the output and we just want to know where each string starts and ends?
OpenMP 4 has the beginnings of support for accelerators. I figure either that or AMP will end up migrating someday.
Well it works for everything except signature if I stay at the opening brace, but I would like to include signature too. `da}` which mentioned [here](http://stackoverflow.com/a/11723259/1269661) strangely works in a similar way for me. Sometimes function is single paragraph so simply `d}` will do but when some functions have empty lines and this strategy fails too. Since copying/moving functions around is something I do a lot I decided to gave up on vim for a while and focus more on refactoring tools.
You posted a suboptimal solution. You didn't simply ask to solve the problem, you provided wrong answer thus encouraging people to fix it. That's cunningham's law. Don't get me wrong this is not a bad thing - i totally get where you're coming from and i hope you will master C++ and other programming stuff! Good luck!
&gt; In functional programming it makes a lot more sense to always pass by val by default. When does it ever make sense to make unnecessary copies? Theoretically speaking, I understand the appeal of isolating function scopes. But practically speaking, you're just wasting memory. If you're developing every-day software on consumer grade systems, usually your system resources are far above what your code needs, and your arguments may be predominantly primitives anyway. So the wasted memory perhaps doesn't add up to anything noteworthy. But it's still wasted memory. And as soon as you start working with large chunks of data that should not be recklessly copied around, you're forced to chase after compiler optimizations like copy elision, which doesn't work for every data structure, or just start using pointers everywhere, at which point the value semantics become a nuisance and hinderance. So which would you rather have? What's theoretically pretty on paper, or what helps you develop better software faster? 
It would keep the first one - exactly as it does now if you include header guards. 
Can I build the module out of multiple cpp source files, like a library? Or is a module always from a single source file, more like a .o/.obj in the current way of working? Presumably source file is something like "compilation unit" in standard-speak. I am trying to understand if it's something I'd manage dependencies for in a manual way. (io module and audio module depend on the core module. main depends on io and audio) Or if it would be something I'd expect the build system to handle 100% internally, the way I don't normally specify that audio_effect_echo.cpp will compile to audio_effect_echo.o in my IDE.
Strategy: go to the very first character of the function definition (i.e. if it's not a template, the first character of the return type). Hit v to enter visual mode. Now, go to the opening brace; if you use the same line style of brace you can hit $ or f{, you use the next line style you can probably just hit j. Once you're over the open brace, just hit % and it will jump to the matching brace, and everything is selected now. You could define a macro to do this for you, if VsVim suppports vimscript you could even write a motion.
It's fine for editing random text files, for sys admin work, etc. But for working on a large codebase, vim pales compared to Eclipse or Qt Creator. YouCompleteMe lacks features as basic as find references. let alone refactor. You spend more time reading code than writing., so it makes more sense to give code navigation priority over editing. That said, I think it's worth learning vim since Eclipse and QtCreator both have good vim emulators, and it is faster than text editing otherwise.
Looks like 5.6 this December.
Nobody can agree on build systems because everybody is crazy.
To reiterate what she says in the video, she's talking about what to teach people first, not what to teach people eventually.
[Polymorphism without inheritance](https://ideone.com/GpKdNG) [Another example (similar to slide from sean parent's talk "Inheritance is the base class of all evil")](https://ideone.com/njPxcU) i personally like the second approach more so the programmer using the functions can implement their own functions for other type which might be defined by someone somewhere else and aren't editable.
With the upcoming modules, it's becoming more and more possible to imagine a build system that doesn't rely on any non-standard metadata. I have a prototype (https://github.com/automeka/automeka) that is able — or was at some point — to build itself as well as small projects, using Clang implementation of modules and a few basic rules regarding the source folders names.
Having a build system as part of the language doesn't really work, as any non-trivial project will be made up of multiple different languages and other stuff that has nothing to do with C++. There also isn't really any agreement in the software world on what a build system should be capable off, every one of them has it's own little quirks. The best you can hope for is a module system to speed up compilation.
at the Qt World Summit they said it is going to come in Qt 5.6 with full support to Windows 10 Universal Apps
this is malevolent
CMake is becoming de facto standard. Standards are made from the common practices. Not the other way around.
The code used for the presentation is in https://github.com/GorNishanov/await/tree/master/2015_CppCon/SuperLean 
You are a very engaging presenter.
&gt; UltraEdit 2002 called, they want their editor back
I have been writing some experiments and I love it. I really really hope this will actually be in C++17. 
This is exciting. I think this is one will be one of the killer, must have features of C++17. 
That was a wild ride. Thank you for explaining it with history and motivation. I too have seen the cascading Future&lt;&gt; messes that I've ended up writing; excited and hopeful to see this go through!
how does this approach compare to boost's coroutines/asio?
Awesome presentation!
boost::asio will become more efficient than it is today when used with coroutines: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0055r0.html Fibers and threads are strictly more powerful than coroutines. Coroutines can be implemented on top of them. But those coroutine emulations on top of a fiber (like boost::coroutine) will inherit more expensive context switch and memory footprint of the thread or a fiber. However, I do not view fibers and coroutines in competition. There are cases where it is more appropriate to use fibers (dealing with legacy code you cannot change, for example), whereas when you need raw performance and scalability you would go with coroutines. Threads, Fibers and Coroutines are orthogonal and you can mix and match as needed
One way to think of it is "like CMake but with a lot nicer syntax". The point is that any time you spend writing or debugging build definitions is time wasted because you could have been coding instead. It also aims to be really fast on both full and incremental compiles. A bigger difference is that Meson projects are designed to be *composable*. Suppose you have project A that uses library B. In Meson you can take the project B, embed it inside the source tree of A and use it *as if it was a natural part of project A*. On platforms that provide B via system packages (such as Linux) you can use the system one without any changes in your build definition.
The problem here comes from the fact that time(NULL) returns the current second - and you reseed the random number generator everytime you enter the random_number call. What you should do is initialize the RNG (the call to srand) somewhere else (for example the first line in main would be perfect), and not reseed everytime you enter that call.
&gt;Usable in environments where exceptions are forbidden or unavailable As a game dev, thank you!
Thanks for the details.
(ignorant comment while watching the start of the video) although I've used the yield statement in python, and I completely agree it is very good syntatic sugar, how is this different than adding a static variable?
It isn't. At the end of the day, co-routines are a replacement for switching on a state variable. It depends on your application whether the representation as a giant switch statement or as a co-routine makes your code clearer. Also, depending on optimizations and how it is implemented, co-routine code can be slightly faster since it can theoretically avoid function call overhead.
Are there any good open source examples of Qt apps that look and feel native?
Yes, and even in the first part of the video where they take turns presenting.
I love the presentation and the functionality and I am impressed by the results in terms on benchmark, etc. I am just concerned about some claims. I mean the main claim, reflected in the title that it is a negative overhead abstraction (to the C++11 way of doing asynchronous IO) seems to hold just fine. But during the talk several times there were claims made (or at least "should be"s) like: &gt; 8:22 They have forgotten that a coroutine is just a generalized funtion. It should be as fast as a function and faster. and &gt; 42:48 We want coroutines to be scalable to billions [slide says: concurrently]. Like in a browser, you can make every character a coroutine. [...] Don't worry about that. You can have as many of them as you want. And also it's a function generalization. The third operation "suspend and yield back" should be as fast as the call. So now I am thinking not so much about the comparison between coroutines and other styles of asynchronous operations. Now I am thinking about the plain cost of making any function a coroutine. And I would like to know, if any tests have been made? I mean I can clealy see that not much more than a yield is needed to convert a function to a coroutine, so syntax overhead is as low as it can get for that case. But what about performance for that? I mean clearly local variables have to be stored somewhere, while the caller might continue using the stack. Does this mean the coroutine will automatically preallocate stack for whatever is the maximum of what it will ever need on the stack, or does the coroutine automatically use the free store? In case it is the stack: doesn't the caller need to be aware of that, since the caller is responsible for cleaning up the parameters on the stack, which now will be between whatever local variables it already had before the call and the local variables of the coroutine. Also it has to do something to clean up the coroutine stack, doesn't it? But it can't, because this depends on the implementation of the coroutine, which is invisible to the caller. So the only way I can imagine is that it uses the free store and the cleanup logic is hidden behind the future, in which case I don't see how the claim that a coroutine can ever be as fast as a function and a yield can be as fast as a function call could be true. After all, as demonstrated even in this presentation, allocations (when not done on the stack) have substantial overhead. I don't mean to sound negative. I just want to understand.
The big question is: where does the state of the coroutine live? If it is like a static variable, then every coroutine can only be active once. It doesn't sound like that's the case.
De facto does not make a standard, but it may pave the way towards it.
Relative to what version? For the mobile you normally want to use QtQuick because it's hardware accelerated.
Well now I feel silly, I never realized `delete` can be applied to any function.
My [spin](https://github.com/rant/rant.kul/blob/master/inc/kul/log.hpp) on it
see my reply to your question earlier in this thread
Relative to the previous version. I don't want to use QtQuick, JavaScript's place is on the browser. Plus if I have to spend time writting wrappers to expose C++ code to QtQuick, then I rather use C++/Boost and have that effort binding to the native APIs. I had quite a bad experience with version 5.3 in terms of mobile support. Also I don't get why the C++ widgets can't be made hardware accelerated. It looks like Qt developers are fighting for JavaScript mindshare with QtQuick.
&gt; &gt; &gt; Also I don't get why the C++ widgets can't be made hardware accelerated. http://doc.qt.io/qt-5/qopenglwindow.html
I want to use accelerated C++ widgets, not write them myself.
Except I don't want to use it, but I am being forced to.
This is pretty awesome. Tuples have always been really annoying to work with. Do you plan on making a more formal proposal?
If one variant type cannot fulfill all the opposing requirements, why not provide two? One high-level and another slightly lower-level, perhaps more complex and without any overheads.
Thanks for the explanation! &gt; When the coroutine lifetime is fully enclosed in the lifetime of the caller we simply put the coroutine state as a temporary on the frame of the caller, thus avoiding heap allocation. So in this case, the local variables of the coroutines (that need to survive yields) are allocated before the initial coroutine call by the calling function?
/u/Kaballo you missed one very important advantage of the core language discriminated union that, without extensive compile-time reflection support, is impossible to implement in a library: &gt; a core language discriminated union can, in some cases, have a size _exactly equal_ to that of the largest object it contains (as opposed to `max(sizeof(Ts...)) + sizeof(index)`). For example a `sizeof(variant&lt;vector&lt;int&gt;, std::vector&lt;long&gt;&gt;) == sizeof(std::vector&lt;int&gt;)`. There are a lot of types implemented on top of a variant (`optional`, `expected`, ...), and I think it is really nice to have `sizeof(optional&lt;std::vector&lt;int&gt;&gt;) == sizeof(std::vector&lt;int&gt;)`. Doing this in a library would require extensive compile-time reflection support.
&gt; Personally, I'd opt for the solution that your consumer will want when writing a library/service--you want to choose the path that will increase uptake of your library. For sure! My biggest reason to prefer APIs strongly typed is that I think if you can specify the domain enough, it forces you to figure out the details prior to publishing it. A little less chance the API will turn into a big ball of mud, but you really have to hammer it out at the beginning. The issue I run into with C++ though is small things like adding virtual member functions (I understand why) breaks binary compatibility. And there's not a whole lot of forgiveness for deciding you need to add/remove some private members without resorting to the pimpl idiom (if there's another way, please let me know!)
Look here http://stackoverflow.com/questions/32906650/variadic-aggregates-as-core-language-feature . Proper support of proposed stuff in core language make 'std::tuple'-related stuff almost depricated. For subscription to compile-time known members by constant expression indices the using of angle brackets is more C++-like way.
"Everything that is syntactically legal will eventually wind up in your code base" --John Carmack
It's extremely difficult to maintain binary compatibility in C++. A common technique is to design a high level C++ API, and then wrap it in ugly C (e.g. `struct yarn *yarn_new()` with `void yarn_destroy(struct yarn *)`, etc.) to provide a binary compatible interface. **EDIT**: fixed some typos.
&gt; I would far, far, far prefer an invalid state. A few people argue this but I think that you are wrong. The invalid state is viral: it *always* has to be checked for. It infests the whole program, like a null pointer. It is widely recognised that nullable-by-default has been [an extremely costly design decision](http://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare). The alternative scenario, on the other hand, is safe: sure, the value inside the variant is random after an exception was thrown. *But an exception was thrown*. Your code must handle that anyway. Your program has entered invalid state, and the state needs to be cleaned up.
Why not a specialization of `optional&lt;vector&lt;T&gt;&gt;` inside `&lt;vector&gt;`?
Instead of worring about next version of "almost done" union take a look at xnode: https://github.com/vpiotr/xnode, in readme you can find example almost perfectly matching yours, it even converts on-fly string to integer (and the other way around).
&gt; &gt; [Talking about implementing a recursive discriminated union.] Each storage node along the chain would store it's own discriminator, they have to &gt; “They have to”? Why? Because they are distinct **discriminated** unions, if they did not have a discriminator then they would be plain unions (the ones we already have). Using plain unions instead, what you have shown would be one of the ways in which the functionality is implemented today (except one can't have a `union` as a base class). &gt; &gt; Unfortunately there is no compile-time relation that would allow the construction of an ordered set of types &gt; I believe this should also be solvable The set of all types is open (extensible by the users). There is no _generic_ solution today, that is not the same as saying it is unsolvable (the post even suggest this is worth looking at for adoption).
CppCon 2015: Zach Laine "Writing Great Libraries: 89 Easy Steps" https://www.youtube.com/watch?v=hcHUZE6buzE
Thanks, but I think I will stick to my own [Eggs.Variant](https://github.com/eggs-cpp/variant) in the meantime.
&gt; Because they are distinct discriminated unions ~~Well doesn’t the code I posted solve it?~~ /EDIT: Ah, got it. Yes. That doesn’t make sense then, I’d have to use plain old unions.
Rust does not perform that optimization for raw pointers (aka. our pointers).
&gt; You’re right that many situations are theoretically safe And far more are practically safe :) The OOM-killer will get you before the UB can for the node-based containers, which are really the only types I know of with throwing moves (what others are there?). &gt; conceptually true for nullable pointers and we know how that turned out The problem with null was that people wanted to use pointers as option types. That problem won't exist for variants. For one thing, it's not easy to get an invalid variant. There's won't be a need to check for validity in the prologue of every function. &gt; “possibly-invalid” is just one solution to that problem. Sorry, I couldn't exactly tell. What solution do you prefer? &gt; If a variant fails to initialise it won’t outlive the scope of the exception handler anyway 9 times out of 10, so there’s nothing to worry about. You're right that many situations are theoretically safe — but what a maintenance nightmare!
How exactly does this work? Every access to a pointer is canonicalized on read and read-mask-written on write? 
Few details at this point unfortunately.
He's hilarious, and a template guru to boot. 
Check out Boost.Hana, which turns the syntax for computations on types into the same style used for computations on values. 
Will be in my references for the paper. I took it from there.
I hope that at the end `invoke` will also be able to call functions in constant expressions, otherwise one cannot use it inside constexpr functions.
Why do you use std::aligned_storage_t&lt;sizeof(std::string), alignof(std::string)&gt;? Do you think std::string would not be properly aligned being a field in struct in union, but wrapped into std::aligned_storage_t will?
As the comment says, `std::string` is not guaranteed to be standard-layout, which is a requirement for the common initial sequence guarantee. The raw storage provided by `std::aligned_storage` will meet this guarantee.
depends what you consider human readable. You can convert to base64, Don't want case sensitivity to effect you then base32. If that's not human readable then there is hex representation. You can find libraries if you search search those terms. I think there is a boost module for all I mentioned.
&gt; The OOM-killer will get you before the UB No it wont, because: * neither C nor C++ standard have **any** notion of OOM-killer * not all platforms have it * out of those who do have it, some turn it off. People really should stop with this nonsense. OOM killer is **completely outside** the general discussion on the language level.
Sounds a bit iffy to need scope guards in inline functions.
&gt; The point is that any time you spend writing or debugging build definitions is time wasted because you could have been coding instead. I disagree strongly, build instructions are part of coding, the instructions for what to do with the source code are an essential part of the program. The treating of build systems as non-essential, “unimportant” boilerplate work is IMO a major cause for the build problems everywhere.
What's the advantage? VMs are an overhead, so what's the gain?
Read the paper linked by Kaballo: This is not going to happen for several good reasons.
if you know ruby/python libs, it's easy to rewrite them in c++
You're going through two OSes then no?
We actually agree on all counts. :) Build definitions are a very important part of your project, but current build systems are verbose, brittle and not very pleasant to use. People waste countless hours battling with their build systems trying to make them do things that really should be simple. Meson aims to make that part go away so people can focus on the bits of build definition that actually matter to them.
&gt; I mean, how exactly do you handle the situation where the constructor throws during variant-assignment? Depends on the situation. If a constructor throws this either means a validation fails, in which case I defer back to the user who provided the invalid data — or it means that the program screwed up and all you can do is quit gracefully (or, rarely, try to recover to a previous state). &gt; I thought the only UB we were talking about was calling an eg. visitor on an invalid variant. My comment mixed “UB” with “invalid state”, maybe that’s where the confusion is coming from. What I meant is that not cleaning up the current scope after an exception was thrown always leaves your program in a semantically invalid state. From the point of view of functionality it’s therefore immaterial whether your object is in a well-defined but invalid state, or whether it’s in an undefined state: both behaviours are a bug (if unhandled): variant&lt;Ts...&gt; v; try { v = initialize(); // throws } catch (...) {} use(v); // NEVER appropriate. There’s no situation where the above is OK, even if the `variant` has a well-defined “invalid” state. The only case where this is permissible is when we define our variant as follows: variant&lt;empty_t, Ts...&gt; v; And define our visitor to handle `empty_t` with a no-op, *and* when it is actually permissible to perform no operation. There are cases of this, but since we need to treat them separately anyway (by specifying the `empty_t` alternative), I’d much rather have a separate `variant` for this — in fact, this is a problem with an existing solution: `optional&lt;variant&lt;Ts...&gt;&gt;`. Allowing `variant`s to be empty confounds two orthogonal concepts. (To clarify: I don’t object to `variant` providing special treatment when one of the alternatives is an `empty_t` tag type (in the same way that, say, Boost.Variant special-cases `boost::blank`). However, I’m *not* arguing for P0094 here, either; default-constructing an arbitrary type rather than just having an undefined object doesn’t help us in general, only in this special case.)
/r/cpp_questions is the correct subreddit for this - see the sidebar Anyway, you haven't told the compiler what ``a`` and ``b`` are in the scope of ``main``. You have to declare them first, e.g. ``int a;``. I would advise to work through a [good book](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) to learn the basics. 
You need to 'declare' the variables yourself. Then the user's input is placed into those variables. You want the user to set them, not declare them. Just chuck the variable declarations mentioned above before the code you have that gets the user's input.
Build something useful, try to adhere to best practices. [NASA](https://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Developing_Safety-Critical_Code) critical code rules are probably a bit too strict, but see their [style](http://lars-lab.jpl.nasa.gov/JPL_Coding_Standard_C.pdf) guide anyway. ~~Googles~~ [this](http://www.stroustrup.com/JSF-AV-rules.pdf) style guide is probably more appropriate. Rules from me: Write self documenting code without having function/class names being too long Keep methods under 100 lines, refactor to reusable smaller ones if needed. RAII and smart pointers rather than new/delete
&gt; Googles style guide is probably more appropriate. There’s almost unanimous consensus in the C++ community that the Google style rules are crap. At best they are tailored very specifically to Google’s requirements which don’t relate to what most programmers do. At worst, they’re bad even then, ignore best practices and promote an outdated (and objectively worse) style of programming C++.
Don't forget to listen to the CppCast Episode with her: http://cppcast.com/2015/10/kate-gregory/
Any function can be inlined by the compiler so having scope guard implies having it in inline functions.
Kate discusses her discussion. She expands a bit on things such as using the debugger instead of the console, avoiding printf (when teaching C++), and a few other key points.
Finally, I can point to an expert talk about this, instead of trying to fruitlessly convince people myself. I am a strong proponent of starting with the highest level, useful abstractions first when teaching programming, especially C++.
Thank you that is a brilliant starting point, sorry it took so long just got out of Uni, I will have to look in to some of the things you have mentioned! I really want a portfolio piece that makes classwork look like dirt.
I am just about to take a look at NASA thank you so much for the reference. I will check both the style guides out. I have no real world industry knowledge here but from day 1 I was told self documenting code is a myth and to always use comments. 
Do not use Google's style guidelines if you are not a Google employee. I would use these guidelines instead. https://github.com/isocpp/CppCoreGuidelines/blob/master/CppCoreGuidelines.md They are actually developed by Bjarne Stroustrup inventor of C++ and Herb Sutter chair of the ISO C++ committee. Because of their high profile, they will be looked at and contributed by lots of experts.
I agree, for next year's CppCon, I would love a keynote by Kate Gregory on how to teach C++. C++ has to get away from being "an expert only" language, and something that people feel comfortable introducing to beginners.
Your last paragraph speaks of binary compatibility. **Do not** attempt binary compatibility with C++. You should not expect that a client built with one compiler will work against your library build with another. You should not even expect that a client built with one compiler version works with another version **of the same compiler**. The correct thing to do is to build your library for the client compiler. If you want binary compatibility, define it either in an integration technology (e.g. COM), or in C.
The key things to ask yourself are: * what is the probability/frequency that you will change the interface? * how hard is it to recompile your clients if you do If doing in-house development, and it's a small shop, don't worry about it. If it's a bigger shop, consider [binary compatibility from day one](https://www.reddit.com/r/cpp/comments/3p8lp4/api_design_strongly_typed_or_weakly_typed/cw5ef6h). If you want to appeal to wide audience and change the interface on a regular basis, consider non-C++ interface, possibly on top of a weakly typed C++ one, likely on top of a strongly typed C++ one. And so on.
The title is a bit misleading. The idea is to stop teaching C when you are teaching C++.