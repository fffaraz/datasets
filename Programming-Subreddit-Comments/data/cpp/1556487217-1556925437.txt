Just use one of the [well-established](https://opensource.org/licenses/category) "attribution" licenses. e.g.: [MIT](https://opensource.org/licenses/MIT): "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software." [BSD](https://opensource.org/licenses/BSD-3-Clause): "Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution." [Apache](https://opensource.org/licenses/Apache-2.0): "... any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file"
Of course be aware that we live in a world where way too people are self-entitled beyond belief, and think that your job is to do stuff for them for free. Any demands made of them in return makes you a fascist of sorts. This is only a slight exaggeration. Anyone doing commercial software is likely to do the right thing out of fear of legal repercussions. But it's also going to be a lot less likely people doing commercial software will depend on a library by any of us Joe Average people. I'd be using it more towards job resume fodder. Using it to leverage a job would be your more likely way to get out of the basement. Believe me, I know that you can write a lot of really good code and still remain poor, since I've done it and I am.
oh it is. yet, that's what everyone does anyway.
Would something like the [Attribution Assurance License](https://opensource.org/licenses/AAL) suit your needs?
Honestly, I've never understood why you would use signed values for something that can never legally be negative. I understand that it requires some thought and some algorithms purposefully use signed values and that's fine, because they are using them in a localized way to make specific things easier to do. But, on the whole, it just seems so against the obvious desire to have the data type used reflect the constraints of the situations in which its being used, and arrays and such don't have negative offsets.
 I watched some of John Lakos talk at the conference and he sighed rather loudly when he was talking about how Bloomberg ignored advice to use smart pointers and used raw pointers in a project. He says, "There's what they tell you" and "then, you know, the truth" . Good for them! It's around the 29 minute mark: [https://duckduckgo.com/?q=accu+2019+videos&amp;iax=videos&amp;ia=videos&amp;iai=V0gmSPICJFQ](https://duckduckgo.com/?q=accu+2019+videos&amp;iax=videos&amp;ia=videos&amp;iai=V0gmSPICJFQ)
I took a quick look at the godbolt and wanted to compare it before reading the article, just out of interest: https://godbolt.org/z/-mn8qG MSVC TF? Why are you generating 15x more code for this, I understand if this case is not specifically optimized for, but seriously... I can understand GCC's reasoning behind not doing so, however...
Because you will most likely end up using them in arithmetic operations, such as: auto size_difference = vector1.size() - vector2.size(); Where you'd want `difference` to be, say, -3 rather than `a_very_large_number_due_to_underflow`. The only way to work around this is to put casts _everywhere_.
Ive used it to implement the [double-dabble algorithm](https://en.wikipedia.org/wiki/Double_dabble) on a microcontroller using the most lightweight method available. Worked great - after optimizing in asm it was only a few bytes once compiled!
Less assembly doesn't always equate to faster. At a quick glance, MSVC appears to optimise for big `count` values by using SIMD instructions. It needs extra setup to handle cases where the iteration count is not a multiple of vector register width, and presumably code paths for CPU's that don't have those instructions. If you use `-O3` with GCC, the output is similar. For some reason, (that version of) clang didn't use SIMD even with `-O3`.
Size of assembly is **not** a metric for how fast the code is. If you use `-O3` for GCC it will get much bigger as well, which is in fact a clear sign that both of those large versions will be faster than the original. (Hint: When looking at the instructions in the large versions, there are tons of SIMD-registers in use.)
If you want to ruin a perfectly good language, you might be interested in D.
I think traditionally in embedded programming, simply keeping an int and moving around the decimal point through shifting whenever necessary/possible was more common. For example, lets say we have 10 samples of some audio data, and we want to calculate the average. If we were to (as usual) simply take the sum of these 10 samples, and then divide by 10, we stand to lose some precision in the integer division. So instead, after summing, we shift left by 4 bits (as 4 bits is what is required to hold the number 10), and *then* do the division. The shift operation we did is essentially moving the decimal point (binary point?), such that we lose 4 bits of range (e.g. if we have a 8 bit int, our max is now no longer 65535 but 4096) but gain 4 bits of precision. So, normally, the values of the bits in our 16-bit ints would be this: 2^15 2^14 2^13 2^12 2^11 2^10 2^9 2^8 2^7 2^6 2^5 2^4 2^3 2^2 2^1 2^0 But then by shifting it left by four the values instead are: 2^11 2^10 2^9 2^8 2^7 2^6 2^5 2^4 2^3 2^2 2^1 2^0 2^-1 2^-2 2^-3 2^-4 You can use this principle to try and get the best possible precision and performance out of low power hardware, but it requires a lot of handcrafting and is quite fragile and error prone (imagine a dozen calculations, each with a shift added to it, such that each is an opportunity to introduce orders of magnitude worth of error in your value).
I have been doing something similar at work lately with [https://github.com/nlohmann/json](https://github.com/nlohmann/json), except you do not have to define a whole new struct/class and give it methods. You define a type like this: constexpr char id[] = "id"; constexpr char value[] = "value"; using record_t = structure&lt; entry&lt;id, std::string&gt;, entry&lt;value, int&gt; &gt;; Which would translate into json like so: {"id": "name", "value" : 12} Then you can go ahead and start nesting that so it becomes: constexpr char name[] = "name"; using record_list_t = structure&lt; entry&lt;name, std::vector&lt;record_t&gt;, entry&lt;id, record_t&gt; ... &gt;;//makes no sense just an example And use it like so. json j; std::fstream{ "input.json", std::ios_base::in } &gt;&gt; j; auto data = j.get&lt;record_list_t &gt;(); auto identifier = data.get&lt;indexer&lt;id&gt;&gt;(); The indexer could probably be omitted in another compiler but I couldn't make a method with `const char*` nttp work with MSVC so I left it like it was. If anyone's interested in how that's implemented I can probably share the code. With cnttp it will become much nicer to use though so yayy c++20 I guess.
No, because that would be true breaking change: `vec[0]` would no longer compile on most 64bit platforms while going without warning on most 32bit platforms: Currently all arguments are converted to `std::size_t` which works flawless for all smaller unsigned types, such as `unsigned` and integer-literals that can be represented as such. Now insert an overload that takes `std::ptrdiff_t` and try to call the method in question with `0` which happens to have the type `int`. Since `int != std::size_t` and (on some platforms) `int != std::ptrdiff_t` you have no perfect match with multiple options to which `0` can be converted. Since both `std::size_t` and `std::ptrdiff_t` are considered equaly suitable matches the compiler then decides to quit his job because this is ambigous. If you want to know why I know this: Qt followed its traditional approach of doing everything wrong that they possibly could and added overloads to their own containers that take `int` and `unsigned` which leads to the same situation, just the other way around, that you cannot use `std::size_t` as index with a compilation-failure if you try it anyways.
So what should you use to own, say, the result of VirtualAlloc() then? You can't exactly call delete[] on that, afterall.
Assuming it's a company that uses your library (and you can capture their name), have you thought about putting their name on your website/resume? So, in the license instead of demanding them putting your name on their screen, ask them to put their name on your "screen". "My Customers! -&gt; name1, name2, nameN" Take a look at poco's commercial license.
Or just provide an indexdiff().
&gt; using the unsigned indexes frequently causes bugs Such as?
Of course I'd need to **know** they use my library. If they don't tell me and they don't tell anyone, thats harder. I'll have a look at poco.
Thanks. I didn't know it's called "attribution"!
&gt; Of course be aware that we live in a world where way too people are self-entitled beyond belief, and think that your job is to do stuff for them for free. Any demands made of them in return makes you a fascist of sorts. This is only a slight exaggeration Yeah I know. Its bad. &gt; I'd be using it more towards job resume fodder I know. that's the goal. But I still need to know who is using it. And besides, "leads" are always good. Who knows where a few brain-cells directed in the right-direction might land me? :)
Typically, Boost libs have left it up to the users to add their own extra layers on top, safety included. &amp;#x200B; From a library design point this makes some sense as it's easier for users to add what they want vs the lib accommodating all folks and use-cases.
That’s why smart pointers have configurable deleter functions.
(Author here) Yes, I had `std::vector` in mind. Supposing you're allocating such a struct, you'll need to know how many elements you're storing in the flexible array member. You can use the `std::vector` constructor accepting an initial size to achieve similar performance with respect to number of free-store allocations (1). Supposing you're interpreting existing memory as such a struct, you can just use pointers. For sure not identical, but "similar...with greater safety." Am I missing something?
The code is valid C: https://godbolt.org/z/wRYO59 What is "standard mode"? And what's questionable about the `malloc` discussion?
&gt;Such as const auto s = my_string.size(); s + -100; // yields unsigned. s * -2; // yields unsigned. s - 420UL; // subtraction is addition of signed, but the resulting type is unsigned.
AFAIK this isn't in the C++17 standard. This code doesn't compile: ``` struct Address white_house = { .street = "1600 Pennsylvania Avenue NW", .city = "Washington", .state = "District of Columbia", .zip = 20500 }; ``` ref: https://godbolt.org/z/4AYSUg
(Author here) I had STL containers in mind for dynamic objects, and raw pointers for other usages.
Or you could just store that char *. If you’re using VirtualAlloc or similar resource allocators, you very likely need to observe more strict constraints than with regular allocated memory. Don’t fixate on only having a hammer when a screwdriver is better suited for the job.
&gt; Less assembly doesn't always equate to faster. At a quick glance, MSVC appears to optimise for big count values by using SIMD instructions. It needs extra setup to handle cases where the iteration count is not a multiple of vector register width, and presumably code paths for CPU's that don't have those instructions. &gt; &gt; If you use -O3 with GCC, the output is similar. For some reason, (that version of) clang didn't use SIMD even with -O3. Yes, I can tell that MSVC seems to be optimizing for larger throughput via using SIMD, but the large size of instructions really does matter for small values (loading and working on AVX instructions takes factually longer than doing shorter operations that have longer "taking" instructions on non-SIMD registers is a balanced game, and there is a certain point at which the tradeoffs work against itself). As for code paths for CPUs that don't have those instructions, that is a thing it is checking for, but that isn't affecting much if any of the ballooning. Clang as far as I can tell assumes that the values here are not going to be TOO large, so... mostly values under 65536 (because 65536^2 = 2^32) MSVC does seem to be similar to GCC, but still, even if I add an assert statement with a REALLY low value, MSVC still opts to use AVX instructions instead of actually doing it the "slower" but actually faster in this case, way. https://godbolt.org/z/Y2KnIf
I went wit her the return value so that I could use ADL and also not have to enter namespaces as much. Also by specifying what the JSON types are you get rid of a lot of branching but don’t limit the output types. If I am understanding you. I am assuming yours knows an int is integral and a JSON number
If everybody jumped off a cliff...
Because the constraints aren't enforced in the way you'd want them to be: negative values aren't excluded with a compile-time warning or runtime check, but by transforming negative values into very large positive values, which is almost never what you want and almost always leads to a bug. Signed indexes "just work" in many scenarios where unsigned fail dramatically.
MSVC failure to prove that SIMD isn't worth it is disappointing. I wonder if it can do better with the help of PGO. But not curious enough to try to use it on godbolt :)
throws try; async await;
I think the problem is that you can't control how people use the language. Using generators and ranges is nice for people who know how to use generators and ranges. Personally I hate the syntax of ranges. But I use it anyway. Some other people don't and won't. Just like many people out there don't use static analysis or beefed up compiler warnings. Using indexes is a paradigm that is necessary in lots of places as well. Translating complex index based math like high dimensional tensor mappings in convolutions or similar into some kind of awe-full iterator strategy is a recipe for disaster. It is just way better to use the indexes directly. Obviously the argument you made about static analysis is valid, but a lot of math guys and engineering types just don't do that. The language in its most basic form shouldn't mess those people up by default when using vector or other basic containers. But it does.
Really nice
&gt; MSVC failure to prove that SIMD isn't worth it is disappointing. I wonder if it can do better with the help of PGO. But not curious enough to try to use it on godbolt :) It gets better even: https://godbolt.org/z/ZvwljO GCC starts to add SIMD for int64_t s but not uint64_t s for the base code, and for some reason, MSVC decides that it is no longer work it to use AVX at all when you're doing 64 bit operations.... GCC optimizer plz wtf.
Yeah, what needs to be changed here in the standard isn't the signedness of index types, but the retarded int promotion rules.
But the same is true the other way. Subtract too much and get a negative value and it's still going to fail. At least with an unsigned you only have to check one direction for index overflow.
Indeed. In math unsigned integers is a subset of signed, but in c++ promotion rules it is ass-backwards. Don't hold your breath on that ever changing.
Not at all - subtraction gives you the correct mathematical result for typical signed values, so as long as your code makes sense mathematically, it will work with signed ints. Negative indexes can be totally valid in a working program. E.g. if you want iterate up until the second to last element you may use `&lt; size-1` which blows up for unsigned values because of the discontinuity at zero, but works fine with signed values. That's the underlying problem with unsigned: it has a discontinuity at zero, the most common value in programming. You are just one decrement away from a wrap you don't want. Signed values have no discontinuity at zero.
First of all, I'm not the implementer of that library, just my usage of it seemed similar to yours. The `j.get&lt;Ty&gt;()` that constructs the defined type actually calls a `from_json(const json&amp;, Ty&amp;)` overload that "you" have to define. What I've done is that I generate the structure and by extension it's `from_json` from the template parameters themselves rather than having to do the same boilerplate over and over. So my code just converts this: struct record_t { std::string id; int value; }; void from_json(const json&amp; j, record_t&amp;r) { j.at("id").get_to(r.id); j.at("value").get_to(r.value); } Into the example shown above so: constexpr char id[] = "id"; constexpr char value[] = "value"; using record_t = structure&lt; entry&lt;id, std::string&gt;, entry&lt;value, int&gt; &gt;; As I said I'm not implementing a library (nor do I aim to do so) and I kind of suspect the [nlohmann/json](https://github.com/nlohmann/json) uses something like a variant internally in its tree. Just the way I construct my structure from its tree seemed similar.
Let's not even talk about 8bits embedded! You're forced to cast back to uint8_t everywhere or to write most complex expressions accumulator-style otherwise the compiler will regularly fail to notice that the high bytes are always zero or unused and generate code that is 3/4 useless...
What percentage of people is that though? If 1%? 10%? 20%? If what's likely a minority don't do something properly, should the majority that do it properly be forced to use something less efficient? IMO, it should be up to their seniors and companies to teach them how to do things properly (e.g. during code review). At least size_t is generally 64 bits nowadays, so even with signed indices you can still have up to 2^63 elements in a random access container, which ought to be sufficient for all practical needs. I suppose one potential approach would be to add a bool template argument to STL containers that defaults to false and determines the sign of indices? Then you can at least opt in to get signed iterators if you really need them and cast be arsed to do Int32(i) or Int64(i) once inside of loop bodies where you need it for equations.
All I can guess is that UB of signed overflow lets GCC do something clever that it cannot do with unsigned. My assembly knowledge is way too weak to verify that's what's actually going on.
I'm using (signed) int for most of the things. (Expect for bit fiddling.) Two gigabytes per object should be enough for everyone. Expect when not. Then there is really something “special“ going on and I need to keep focus on overflow, unsigned-ness, 64bit and such. But the idea is that this is rare enough that it almost never happen. So 99.99% of my code is fine with signed int, no wrap-around and 2GB limit per object or per container size. And only very small portion of my code needs to handle "big unsigned" sizes correctly.
https://youtu.be/os7cqJ5qlzo?t=3542 &gt; Q: So, I think you hit the nail on the head with the automatic vs invisible propogation, but one of the other reasons why many people, me included, don't like exceptions, is that as part of the signature, if you use something like `expected` or even `variant`, you see all the failure cases. In this case you're using something like `std::error`, which puts them all together, so that wouldn't satisfy me. I would still like to see for some particular functions what all the possible failure cases are. &gt; Yeah, so certainly `throws` tells you this can fail, so you're saying perhaps there is some way of being more fine-grained about that. *Possibly*, like “`throws(this, this, this)`”. Be very careful! Every language including C++ that tried that has failed, because that's a composability trap. Because what if you call something else? Now you have to basically union up. So every time that's been tried—it's certainly feasible, I'm not saying not to do it—what happens in the real world is users write “throws anything”, and it's worthless and it gets gets removed until people get told not to use it. But perhaps there's a way of improving it that avoids history's problems. It would just be something to be careful for. This isn't true. Rust and Haskell are two quick examples, though there are certainly more. A key difference is that these already distinguish between exceptions you're intended to handle, which are explicitly declared, and program errors, which you aren't.
I will ask you a question: When where the last time you allocated bigger than 2GB of continuous memory block? Or had more than 2billion elements of the same type at the same time? (For whatever definition of element.) For me it is never, but YMMV.
I think one of the things in Rust that helps is that `?`/`try!` call a standard conversion interface so you don't have boiler plate to adapt errors.
It actually only produces a warning. You're probably using -Werror.
Yes. This is something the talk introduces as well, hence why I think it's worth revisiting this for C++ alongside it.
I don't disagree that deciding which things to change in a fork would be a hard problem, but... &gt; * Move by default? &gt; * Yikes, that sounds dangerous and can be trivially demonstrated why. We already have warnings on use of uninitialized variables. Warning on moved-from variables is the same analysis. Make that an error in the fork and it's no longer dangerous. (Of course there are caveats here- the rare actual use of unspecified-but-valid states, what if someone wants to initialize it with an out parameter, etc. but the point is this isn't obviously a problem.) &gt; * Immutable by default? &gt; * That just disables a ton of moves. There's no reason for it to disable moves, that's purely an artifact of the current design. Especially if uninitialized uses were more closely tracked like described above.
This isn't C++, it's C. If you're going to be pretentious you should at least do it properly.
https://xkcd.com/1170/
If you created an instance of the struct on the stack and don't pass it to a function (or that function is fully inlined) then there's a decent chance that the references won't show up in the compiled result, but changing the size or layout of objects is generally not in the scope of what compiler optimizations can do.
Ah I understand better now. But yeah, C++20 will be so much cleaner for stuff like this. I am ready for it and used the non-type class template argument feature flag to enable using the string literals directly. Gcc9 is the only compiler I can find that supports it but it isn't really read(at least the version in Mac ports) as it cannot do debugging without the compiler crashing and the codegen is slow.
sry your *C* code is not sexy to me esp since you posted it on cpp reddit. and your "RandomPickupLine" function better not be using `rand` if youre trying to impress the ladies. after that stunt I would be grossed out and swiping no on you.
Checking for &lt; 0 is natural when working with signed integers. Checking for MAX_INT when working with numbers less than 10 is not. However 0 - 1 gets you everytime.
It's not, your article is correct. However, all compilers accept it unless you specifically turn on pedantic, and it's also accepted for 20. So it's probably pretty safe to say you can use them just fine in C++.
I used them when I had a memory mapped dual port RAM. The memory was mapped in three blocks and I was overlaying a data structure onto it: struct overlay { union { struct { } v; uint32_t alignment_do_not_access[256]; } block1; // Similar for block 2, 3 }; The union makes sure the blocks are aligned properly.
And `avr-g++` has a bug causing horrible output for 8-bit bitshifts.
They'll both fail if you try to use them as an index again.
&gt; When where the last time you allocated bigger than 2GB of continuous memory block Quite often, though I use `VirtualAlloc` or equivalent for that.
Rust doesn't even have exceptions. It just has an error value type, or alternately, for those cases that Rust's designers deemed "unrecoverable", a function that's equivalent to `abort()`. So functions return a type that's composed of a normal return type and a status code that's analogous to the integer status codes from C. Then there's a bit of syntactic sugar that makes this look sort of like real exception handling, except in those cases when it doesn't.
The only time I've ever used unions was when I implemented my own LISP interpreter.
That's not a geometric sum
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bij53t/urgent_help_for_final_basic_c/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html#Type-punning This is true except on GCC (and by extension CLANG) so of the three big compilers, 2 of them allow type punning via union because it's the best and easiest way to do shit.
everyone knows #pragma once too and is still not standard. it's not the end of the world.
I wouldn't describe Result&lt;_, Err&gt; as analogous to the error integer of C in any respect other than the path of propagation. It must be handled, somehow, it can be as information Rich as you need it to be, it supports chaining...
Rust doesn't have exceptions. It has `Result&lt;T,E&gt;` and `panic!`
This was a good read, I liked how you liked a bunch of relevant features within each point for extra reading.
I believe that use of string literals got dropped from C++20.
Non type class template arguments is in the draft I think. So a static string class and CTAD is all one needs. At least in gcc 9 that is how it works now
&gt;I wouldn't describe Result&lt;_, Err&gt; as analogous to the error integer of C in any respect other than the path of propagation. What path of propagation? There is none. You can only emulate error propagation by a chain of return statements, or the `?` operator, which is just syntactic sugar for "return an error object if this expression returns an error object". Without the syntactic sugar, Rust has no error handling at all, only a convention for returning values that represent errors inline with values that represent success. The only advantage Rust has over C is that -1 and NULL can be valid return values. &gt;It must be handled, somehow Only in the Java sense that there must be a block of code that "handles" the error (possibly by being empty, just like the common empty `catch` used to handle checked exceptions in Java). &gt;it can be as information rich as you need it to be, It's the equivalent of having every function in libc return a `union` that can either be a successful return value or an error code.
There's nothing constraining the type of your struct that implements Error.
A case of `not-always-auto`.
But that is again dis-allowed, isn't it?
It is also my experience that almost all error handling in interactive applications happens in an event processor, rather than somewhere specialized. I would really like to know what all the specialized error handling the anti-exception crowd is doing is, but I haven't ever actually gotten much of an answer in this regard.
Just add a static_assert and you'll know.
Why can't I watch many of them? They're there, but it says "set reminder". Are we trying to replicate TV here or something? That is a BAD idea. One of the reasons TV is failing is because of that. Please don't replicate failures. Thank you.
&gt; The code is valid C No it isn't. Not sure what you hope to demonstrate with your godbolt link. The authority for valid C is the C Standard, not godbolt. Furthermore your link even shows the required diagnostic for invalid code. &gt;And what's questionable about the malloc discussion? malloc shouldn't be used like this in C++ at all. A common mistake would be to go on to try and write `int` objects to the space, which causes undefined behaviour.
Interesting! You say another, do you have other JSON parser projects? What makes them different?
Thanks, I always appreciate a nice comment. I'll keep that in mind.
We don't need c++ 2.0 we need a new language which is intermixable with C++ but containing modern concepts as first class citizens
This is exactly the point [nobody mentions this in the above], you get the data where you need it. I still prefer the good ol' term for it, the `struct-hack`, where are the days.
&gt; Until C++17, unions were the only way to add sum types for your code And one of ways to add UB to your code.
Sure it would. All it needs is abi compatibility and seamless way to interoperate with legacy code. That is how c++ won the throne by being compatible with c. That is how next language will overtake.
I have another but I use it for my JSON to C++ interop code generator. It is like most others in that it builds a tree of variant like things. This project is different in that it directly constructs the C++ data type from the parser. For instance struct A { int a; int b; std::string c; }; A{ int_parser( ), int_parser( ), string_parser( ) }; It is somewhat analogous to that. But with a bit more hierarchy thrown in and a few customization points. The description you provide is the type and order of the constructors arguments by default, or the callable Constructor that is passed to each
How can Rust compose if foo calls bar&lt;r1, e1&gt; and baz&gt;r2, e2&gt; and foo itself has a failure mode e3?!
Fair enough, those were just a few things off the top of my head whose proposal could be met with a "BUT!"
You just match on Result&lt;T, E&gt; and return values of type Result&lt;U, F&gt; in the branches. Where is the problem?
Call .map_err on results with error types e1 and e2
&gt; &gt; Move by default? &gt; Yikes, that sounds dangerous and can be trivially demonstrated why. How about automatically moving at the last place a variable is referenced in the code before it's lifetime ends? https://stackoverflow.com/questions/45763943/compiler-deduction-of-rvalue-references-for-variables-going-out-of-scope // The compiler makes one use of bob an rvalue-reference. std::string bob; return foo(bob) + foo(bob);
Yea, I'm very much not on board with the "used signed types where possible" crowd, and it annoys me greatly that so many people claim that it's a settled conversation.
Why would you subtract two sizes in this way? That way (trivially obviously) leads to madness?
Alright, that makes sense. Here arethe problems I see: - Are we talking about Itanium ABI, MVC ABI or some obscure, proprietary ABI of a compiler for some embedded system? - If I'm not mistaken, Rust uses LLVM as the backend so it is ABI compatible. I don't see a big shift in 'market share' in Rust's favour. In fact, I think Go is in the lead.
The problem with that is getting 5.5 million developers to move away from C++ to this new and shiny language. There have been numerous attempts before. I mentioned D, but there were more languages that were touted as "the C++ killer", yet "the prophecy" never came true.
I once ran a 100 line program in Octave that allocated over 16 GB of ram before giving me the answer I expected. I imagine the majority of what it allocated under the hood was a few billion instances of the same few data types.
P0329R4 has been merged into C++20.
the problem is that for unsigned indices, you have to check everytime *before* you do a substraction on the indice, that it isn't going to make it wrap around. Even the simple addition of an unknown int and unknown std::size_t is not safe : #include &lt;cinttypes&gt; #include &lt;iostream&gt; int main() { int i = -1; std::size_t u = 0; std::cout &lt;&lt; (i + u) &lt;&lt; std::endl; } I won't tell you what this prints, but it's not -1 :-) unsigned types don't mean "cannot be negative", it means modular arithmetic, `Z/pZ`, however you want to call it. what we want for indices is a type that *gives an error* if it is negative, not one that silently wraps around 2^64. That's why it was a mistake to use them for std:: containers
That does sound like a good idea, but the link you posted contains an example that breaks with this change. Are compilers smart enough to detect which is the last use of an object in face of pointer aliasing?
using size_t here would not change anything. these bugs already existed before auto.
I do understand that. But writing it like that ~and~ use auto is for silly people only I would say.
Qt is using union to implement it's QVariant class Source https://code.woboq.org/qt5/qtbase/src/corelib/kernel/qvariant.h.html Docs https://doc.qt.io/qt-5/qvariant.html#details
And?
&gt; comparing pointers as a bitwise pattern I didn't say bitwise comparison. I said "`std::less&lt;int*&gt;` somehow manages a strict total ordering". You even quoted that! That means that `while (++pa != pb);` would terminate (if you found a `++` equivalent for `std::less`, and it was guaranteed not to skip over addresses). It also means that two pointers must compare equal if they refer to the same memory address, even if they use a different segment to refer to it. &gt; The architecture could operate only with "far" pointers I didn't say it couldn't. The second half of your comment isn't really relevant to mine.
Herb didn't say it isn't possible to do he said it leads to useless "this function can return any error" kind of specifications in practice. Remember: c++ had such exception specifications and almost no one used them (for various reasons, admittedly not all inherent to the idea)
I'm the person who asked the question on stackoverflow. I didn't really like the provided answer, because it seems to be like really bad use of an on-stack array. But technically it's behavior that's guaranteed by the standard, so there's nothing to be done I guess. I imagine there might be some way to allow the compiler to only conduct the conversion to rvalue-reference if it can prove that it's safe to do, but I can't think of a way that it ever would be able to prove that. &gt; Are compilers smart enough to detect which is the last use of an object in face of pointer aliasing? I assume you're asking about something like this? std::string bob; std::string &amp; alice = bob; foo(bob); foo(alice); ? I suppose there might have to be some caveat such that if the compiler cannot prove that the object is not aliased, it isn't allowed to .
Because you're doing some sort of ranking with a non-trivial `operator&lt;`.
 .map_err
&gt; &gt; One. There's only one standard C++. Considering that valid c++03 code isn't a full subset of valid c++17 (and that gap is widening) and you can write valid c++11 that isn't valid in either c++14, nor 03 I can't agree. Its not a question of if future standard versions are breaking backwards compatibility. It is a question of how much they do so. I agree with many points about the practicality of breaking compatibility in major ways though (considering how slow adoption of newer standards is already, despite them being almost backwards compatible).
Facts aren't insults and neither do they care about your feelings. Having 50 methods is questionable, but it's alright. Having complex methods here and there is also, questionable, but it's alright, for example Perlin Noise (something you'd call """complex""", even if it's trivial, lmao). Having 50 methods that all are complex? Your code is bad and you should feel bad.
But only as long as you ever access the members through the union. You can't e.g. use a pointer to one member
My point is that subtracting two unsigned types without checking their relative sizes is a bad idea. While I can agree that the behavior of raw unsigned int in C++ can be a bit surprising to people new to the language, it's not really hard or confusing to treat them properly. It's nonsense to think of an index into a buffer of memory as potentially being a negative. It's similarly nonsense to think of the size of a buffer of memory as negative. Further, you can't have negative objects in a container. So using a signed integer for the return value from, e.g. std::vector::size() is nonsense. It's up to the programmer to do thing's correctly. The standard specification for containers like std::vector should concern itself with having vector::size() do exactly what the operation says it does, return the number of items stored in the vector. Nothing more, nothing less, and returning a signed size means that half of the possible values of the returned variable are useless.
Agreed, my experiencing of wrapper classes that “let you change the foundation without modifying the top floor” is that you always end up having to rebuild the top floor anyway. It’s a great idea in theory but there’s usually *something* that changes in an incompatible way.
Newer versions not being valid when compiled/interpreted as earlier versions happens every time the new version's library introduces a new vocabulary type. `std::move` isn't valid in C++03, `std::integer_sequence` isn't valid C++11 and `std::filesystem::path` is not valid C++14. I don't think we should count this as breaking changes. &amp;nbsp; Now valid C++11 not being valid C++14 or C++17 is a breaking change. As long as these breaking changes are small in number and easily resolved I won't worry about them. You could say these are different dialects of C++ and you wouldn't get any arguments from me. I still think it's a stretch to call these different languages, which is what python 3 is to python 2.
&gt; I didn't really like the provided answer, because it seems to be like really bad use of an on-stack array. But technically it's behavior that's guaranteed by the standard, so there's nothing to be done I guess. It's a way to avoid heap allocations and can be very effective in performance sensitive code paths. &gt; I assume you're asking about something like this? Yes, something like that. And it gets worse if you call different functions out of which one might take only r-value references and so on... &gt; I suppose there might have to be some caveat such that if the compiler cannot prove that the object is not aliased, it isn't allowed to . Which will then cause people to learn when the compiler can't understand that it can move. For most, not worrying about it would be fine. For those who care, the currnet, simpler, rules are better. In this specific case, I don't know which side I'm on.
I understand your point and I won't be trying to argue it, but consider one more thing. Compilers can optimize more aggressively a code that's using signed than the same code that is using unsigned, because compilers assume that UB never happens, so overflow never happens. I've heard stories where, in very hot code paths, this micro optimization lead to significant performance benefits.
A lot of conversion and library code that accumulated over time.
Herb's proposal on this is probably the thing I'm most looking forward to/hoping for in the future of the language.
I think a full fat borrow checker would cripple c++. I don't think it's the kind of thing you can add at a later date while maintaining any sort of backwards compatibility. The lifetime profile is a fairly good idea (basically borrow checking as warnings) since it doesn't outright stop you from writing perfectly valid code which the borrow checker isn't smart enough to verify, but it still has a lot of false positives for relatively simple c++.
I'm not sure it's possible in the general case. What if I have one of these pointers as a data member in a struct and want to delete what it points at in a member function? You can't change the type of the data member. In general, I think solving this for owning pointers is just as hard as a general purpose borrow checker, and personally I think that the technology isn't mature enough yet. Rust solves the problem by heavily restricting what you can write, preventing some perfectly valid programs in the process. I don't think you can retrofit such a thing without breaking a ridiculous amount of code.
Whats the problem with ABIs? It is not like there has to be one multi-platform ABI. New language would implement compatible ABI on every platform it supports. Heck chances are such a new language would not even have to do this as it would likely be a fork of c++. As for LLVM - i actually have no idea how it works under the hood. There definitely must be some control over ABI. It would be strange if backend forced it on to frontend. Seems to be it would be very inflexible.
&gt; It's a way to avoid heap allocations and can be very effective in performance sensitive code paths. In the context of the *specific* answer to that stack-overflow post, no it's absolutely not a way to avoid heap allocations. That code will cause a bunch of ints to be constructed directly into the array, with value assignments, and then when the vector is copied into the run_some_async_calculation_on_vector() function, new storage needs to be allocated and all of the ints must be copied (not moved!) If, instead, we were dealing with some data type that was expensive to copy, but cheap to move (e.g. std::string, when the strings are longer than the short string optimization trick), then this would be very expensive. It'd be much less work for the programmer to use a normal allocator and std::move(0 the vector. Now, obviously there are plenty of situations where doing what the answerer's example code is doing is the optimal choice, or if not optimal, then the chosen way out of a collection of trade-offs. The example provided didn't try to claim it was anything more than an example of something legal that would break. So we can't really extrapolate anything about a hypothetical codebase that's doing that particular 3 lines of code :-) &gt; Which will then cause people to learn when the compiler can't understand that it can move. For most, not worrying about it would be fine. For those who care, the currnet, simpler, rules are better. In this specific case, I don't know which side I'm on. Really I don't think it should be implemented unless it can be done in a way that will always work predictably. Aliasing issues, issues with things that have non-trivial differences between copy-and-move, it's a mess. It's just that it's a damn shame that the compiler can't just figure out "He's passing this variable twice in the same function, and the variable can be moved, but he can't use std::move() directly in the function call because the evaluation order of arguments of a function is implementation defined, lets throw in some auto-magic!" Right now, you'd have to make a copy of the argument, and then std::move() both the copy and the original, which may not work properly, depending on the function you're calling. The compiler, at least, always knows which order the function parameters are evaluated in, which is why i wanted to see about automatically casting to rvalue-reference.
&gt; Whats the problem with ABIs? I'm not sure, I was just thinking out loud. Maybe I'm looking too hard into this. &gt; LLVM I won't pretend I know all the details, but I remember one Rust developer complaining that "signed overflow == UB" is an assumption baked into the backend that is causing troubles for rust, On the other hand there's `clang-cl` which uses MSVC instead of the Itanium ABI.
&gt; I understand your point and I won't be trying to argue it, but consider one more thing. Sure, I wasn't really trying to have a shouting match or anything :-) &gt; Compilers can optimize more aggressively a code that's using signed than the same code that is using unsigned, because compilers assume that UB never happens, so overflow never happens. This is true. &gt; I've heard stories where, in very hot code paths, this micro optimization lead to significant performance benefits. Yes, I've heard of this as well. My take on this situation is that C++'s raw types (as per our legacy from C lang) are just.... fucked. We've got: * short * int * long * long long * signed short * signed int * signed long * signed long long * unsigned ..... You don't need the full list. Then we've also got char / signed char / unsigned char, where the undecorated "char" is implementation defined as to whether it's signed or unsigned... BUT IT'S A DISTINCT TYPE?!?!?! I know this because I had to do some serious template fuckary to keep some legacy code working once-upon-a-time. Then, wchar_t, which *obviously* needs to be different sizes on windows / *nix. Now we've got char16_t, char32_t... but we only added char8_t in C++20? Wtf? I am quite excited to see std::byte though, for what it's worth. ---------------------------------------- I think that what we *really* need is a total re-do of these low level types. First of all: 1. Ditch short / int / long / long long. Disgusting naming conventions that unnecessarily complicate the learning process for everyone for no reason. There exists no computer system in 2019 that uses sizes that aren't powers of two, as far as I know, and aside from "long" being different on windows vs linux, all platforms that I'm aware of (which, I'll admit, is not an exaustive list) use the same size for these types. 2. Provide compiler support for the various capabilities of the integral types. Such as overflow, signed/unsigned, whatever other properties you can think of. Then we can provide our own integer types that compose all of the various features we might want in a certain situation. Say you want an unsigned, 16bit, non-overflowing, underflowing integer. Great, specify it as using MyIntType_t = std::integer&lt;16, std::flags::unsigned, std::flags::underflow, std::flags::nooverflow&gt;; And now the compiler, since it's readily aware of the capabilities of things from std::integer, can optimize the code properly, sprinkling in undefined behavior where ever the specified flags say to.
And that's not the same as an error code. Being able to return a struct with as much runtime information as you want is not the same as being able to return one integer
If you remember that they are unsigned and you remember how unsigned arithmetic works it is obvious. But those are things are counterintuitive, because in daily life (and many other languages) you work with signed numbers. So this is yet another low level detail you need to keep in mind when dealing with sizes. Personally, I'd much more prefer, if subtraction of two unsigned numbers would yield a signed one and comparison of signed and unsigned would be performed according to signed arithmetic. That would yield much more intuitive results.
If you remember that they are unsigned and you remember how unsigned arithmetic works it is obvious. But those are things are counterintuitive, because in daily life (and many other languages) you work with signed numbers. So this is yet another low level detail you need to keep in mind when dealing with sizes. Personally, I'd much more prefer, if subtraction of two unsigned numbers would yield a signed one and comparison of signed and unsigned would be performed according to signed arithmetic. That would yield much more intuitive results. As a note: Subtracting two pointers (which could be thought of as unsigned memory addresses) results in a signed number.
Interesting... &gt; aside from "long" being different on windows vs linux, all platforms that I'm aware of (which, I'll admit, is not an exaustive list) use the same size for these types. Except 8bit AVR and avr-gcc with `-mint8` flag which makes `sizeof(char) == sizeof(short) == sizeof(int) == 1`, `sizeof(long) == 2` and `sizeof(long long) == 4`. I'm sure there's tons of others that have these magical flags. &gt; std::integer Again, interesting, but "underflow" does't exist for integral types. It's what happens when a float is too close to 0 that the decimal points get cut off. Integral types have "positive" and "negative" overflow (not sure if that's the correct terminology) and I'd rather specify flags like the regex pattern flags are specified: flag1 | flag2 | flag3
&gt; Except 8bit AVR and avr-gcc with -mint8 flag which makes sizeof(char) == sizeof(short) == sizeof(int) == 1, sizeof(long) == 2 and sizeof(long long) == 4. I'm sure there's tons of others that have these magical flags. How is that allowed? "int" must be at least 16 bits. Does AVR have a word-size of 16, instead of the usual 8? https://en.cppreference.com/w/cpp/language/types &gt; Again, interesting, but "underflow" does't exist for integral types. It's what happens when a float is too close to 0 that the decimal points get cut off. Integral types have "positive" and "negative" overflow (not sure if that's the correct terminology) Right, I had the wiki page for integer overflow open while i was writing that. Made a judgement call that it would have been easier to understand to just say "underflow", but clearly not :-)
At this point, why not just switch to rust?
Correct.
Sometimes you want to access them by name, and sometimes in a more generic way with an index.
&gt; How is that allowed? "int" must be at least 16 bits. Does AVR have a word-size of 16, instead of the usual 8? It's not allowed. The man page says: -mint8 Assume "int" to be 8-bit integer. This affects the sizes of all types: a "char" is 1 byte, an "int" is 1 byte, a "long" is 2 bytes, and "long long" is 4 bytes. Please note that this option does not conform to the C standards, but it results in smaller code size. Keep in mind that we're talking about devices with no heap and 2kB of RAM. Oh and the CPU clocks at 8MHz. &gt; Right, I had the wiki page for integer overflow open while i was writing that. Made a judgement call that it would have been easier to understand to just say "underflow", but clearly not :-) I can't help it, I can be overly pedantic about these things.
I'm using tons of `std::variant` and `boost::spirit::x3::variant` in my hobby parser project that customizes settings of a particular game. Variants basically replace classical OO-polymorphism but there is a significant difference: the code layout is reversed. In classical OOP, you write a class which implements all interface functionality in 1 file. With variants, you write a visitor which implements 1 functionality for all types. Since the project is mostly consisting of a parser =&gt; compiler =&gt; generator modules I hardly ever need to reuse the same code (eg same function implementation). Variant-based approach makes it very easy to localize and edit relevant code as I do not care about "what this type has to implement" but "what to do with these types in such scenario".
/u/jalospinoso Isn't `std::unique_ptr&lt;T[]&gt;` an ideal replacement for this?
Why propose a solution worse than the problem?
I don't think we want a type that checks/throws/etc whenever it goes negative here. That would be a code flow and performance nightmare.
 struct Foo { int x; }; Foo *foo = malloc(sizeof(Foo)); foo-&gt;x = 1; // valid C, but undefined behavior in C++ ¯\_(ツ)_/¯ Before assigning any subobject of `Foo` you must first call constructor `new (foo) Foo;`, which obviously C code will not do, so beware of including C headers with inline functions.
None of what you’ve written makes a smart pointer less suited, or justifies not using it in this situation.
C has `restrict` but C++ has more restrictive strict aliasing rules (does not allow `signed char` to alias). Not sure how big difference it is, but C++ does lack some constructs for many aliasing problems.
I am content to use signed types and disable `-Wsign-conversion`. I get no warnings from your code in gcc 8.2 if I just use `-Wconversion`, or `-Wconversion -Wno-sign-conversion` with clang.
Can someone link me any explanation/guide article that describes what these all are? I don't get the point of launder/bless. Why are raw pointers insufficient?
https://wg21.link/P1095's proposed implementation of P0709 lets you choose a local `E` type to deterministically throw. But you get exactly one choice, so it's on you to make those composable. The strongly suggested composibility mechanism is to make your local `E` type implicitly convertible to `std::error`, but as with all things in C++, if you want to locally innovate, you can.
 void foo(int); foo(vector1.size() - vector2.size()); Same issue.
You get to make a choice of what (and to what detail) your library's error type `F` will be able to express. You get to define how errors are convertible (implement `From&lt;E&gt; for F` if you want an `E` to bubble up as `F`). The question mark operator will invoke those conversions for you so that you don't have to explicitly convolute your function's logic with error handling/propagation stuff. You get to control all this.
?
Probably not. But what you want is a `positive_integer` type where `operator-()` returns a signed type
Could you elaborate for everyone who doesn't know rust?
I don't think composability is a solved problem in either of those languages. Others have already written about Rust, where you have to manually compose errors with map_err. In Haskell, there are tons of options, but a simple *Either SomeError a* won't easily compose with *a -&gt; Either DifferentError b*. And the more advanced error reporting options either rely on some [advanced type trickery](https://hsyl20.fr/home/posts/2016-12-12-control-flow-in-haskell-part-2.html), or have other drawbacks with regards to boilerplate, safe error handling or boilerplate. Now, OCaml has polymorphic variants as a language feature, so you can use [that for error reporting which composes easily](https://keleshev.com/composable-error-handling-in-ocaml), but afaik most people actually do not do this (though I'm not really familiar with the OCmal ecosystem). Now, I gave [composable error reporting for C++ a try myself](https://fkosmale.bitbucket.io/posts/exhaustive-and-composable-error-handling-in-c%2B%2B/), but even if you fix the technical issues of my solution I think it is rarely worth the effort in practice.
Result&lt;T, E&gt; is a generic type holding either T or E. Using C++ wording, it has two methods, called `map` and `map_err`. The former takes a function T -&gt; F, mapping the variable from Result&lt;T, E&gt; to Result&lt;F, E&gt;. The latter does the same, but for E instead of T. Thus, if foo requires Result&lt;T, P&gt; and bar returns Result&lt;F, E&gt;, it is easy to map &lt;T, P&gt; to &lt;F, E&gt; let x = bar(...).map(f).map_err(g); foo(x); given that f maps T to F and g maps P to E.
This is so far from the exhaustive list... `_Atomic`, `_Complex`, `sizeof('a') == sizeof(int)`, `int* ip = malloc(4);` (doesn't compile and when you make it compile `ip` doesn't point to an object, so using it is UB. Might have been changed in C++20), recusive call of `main()`, implicit `int`, `auto` has vastly different meaning, `register` has no meaning in C++...
The `.map_err` method on a `Result` converts one error type into another. So if your function returns `Result&lt;..., Foo&gt;` and in your body you call a function returning `Result&lt;..., Bar&gt;` and you want to unwrap that result and propagate the `Bar`, you call `.map_err` passing a function to convert the `Bar` into a `Foo`, and then `?` to propagate up. `.map` just maps the value side.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/bio48u/embedded_c_developer_job_interview_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
What if the `Foo` and `Bar` are semantically different? Is piece of the information lost this way? What happens if I forget to wrap `Result&lt;T, Bar&gt;` with `map_err`?
Herb said “Every language including C++ that tried that has failed”, which is strictly false. To address your point more directly, Rust hasn't ended up with pervasive “this function can return any error”, and it's really, really nice since you can just trust the API. The same is true for Haskell. This is not to say general errors don't exist, but it's mostly outside of libraries, and in places where the only remaining job is to report an error from one of many endpoints.
If your caller is expected to handle those, return a supertype, made easy with `#[derive(Fail)]`. This is standard for libraries. If the caller is only meant to propagate up and report, return `failure::Error`. If you're OK with calling the `throws` proposal ‘exceptions’, being fussy about whether `Result` is a ‘real’ exception seems silly to me.
Well, it's still valid C++, right?
That looks pretty nice!
That depends on what you want the caller to do. If you're a library and expect the caller to handle the error cases specifically (eg. retry on async not ready), you convert to a specific type that handles all those cases. This is made more comfortable with conversions inside `?` that you can opt into, plus explicit `map_err`s when you don't want to. If you just want to propagate up until it gets reported, and don't so much care about specific things getting handled, return a `std::error::Error`.
You got me wrong at question 4. I can't quite understand, why getting a structured binding with a ref-qualifier from a bitfield struct is valid: `struct { int a : 3, : 4, b : 5; } a;` `auto &amp;[x, y] = a;` Since you can't take an address of a bitfield, ref-qualifier is quite misguiding here.
Garbage like this is the reason why SO is ridden with comments like "achteuhally, -O3 is veri bad and causes UB!!!!!!!! use -O2!!!!one!!!!!!".
Probably because C isn't C++.
Well, you literally are saying ”Smart pointer is the right tool. No exceptions. Ever. No matter what your situation or requirements are.” To me that seems awfully lot like being fixated on a single tool. Even if you can’t fit the hammer via the hole.
Identifiers in a structured binding declaration are explicitly allowed to bind to bit-fields, see [http://eel.is/c++draft/dcl.struct.bind#5](http://eel.is/c++draft/dcl.struct.bind#5).
And the irony is that in this very thread you already have people arguing absolutes. "Sometimes X just is the simpler way." "No. You must use Y."
You could always have non-union variants in C++ even before C++17. It has simply become more convenient, since now we have the variant type in the standard library. The other way - besides union - to implement sum types which is the way `std::variant` is implemented is placement-new into `char` storage.
That was a mistake, and has since been reverted.
But, isn't that irrelevant? We don't care about triviality of optional/variant constructor, since we don't want to put them into a union. They are a replacement for the union. And the point is that their members need not be trivial.
Personally, I'm okay with the `auto [x, y] = a;` syntax, without any ref-qualifiers, I don't see anything wrong with it. However, `auto &amp;[x, y] = a;` makes me think that `x` is a reference to something inside of a, which is impossible for bitfields. P.S. Interesting behaviour in the compiler explorer: [https://godbolt.org/z/AjD6c6](https://godbolt.org/z/AjD6c6) It indeed creates a reference to the bitfield and works with it inside a function, but always returns by value.
course_location?
&gt; If you're OK with calling the `throws` proposal ‘exceptions’, being fussy about whether Result is a ‘real’ exception seems silly to me Uh, no. The `throws` proposal actually is exceptions and `Result` is not. Using words to mean what they mean isn't "being fussy." The salient differences are: - error flow is distinct from success flow - error propagation is automatic This isn't a value statement about which one is better - I'm just saying that `Result` is very much not an exception.
Did you watch the video?
Bad phrasing on my side, I was referring to built-in solutions without boost, nonstd or a user-defined variant type. You could also implement some sort of pattern matching if you want to and some solutions already exist.
Fine until it bites you in the ass because you aren't using UB in the exact same way the compiler writers envisaged. If you're going to exploit UB you need to understand exactly *why* it works and the guarantees the compilers are actually providing.
And? As in, what about the rest of your shambling rant? Well, "catch(...){}" sums it up rather neatly.
That's one of the confusing things about structured bindings. While it may look like a structured binding declaration introduces a reference, it's really just another lvalue which refers to the corresponding member (and the actual type of this lvalue is not a reference).
&gt;you are starting to say ”Smart pointers are the right tool. No exceptions. Ever. No matter what your situation or requirements are.” I didn’t say this either literally or imply it. What I *am* saying is this: Smart pointers are an appropriate tool for managing resource lifetime. They are not the *only* appropriate tool, nor always the *most* appropriate tool, e.g. tracing GCs and allocators may both be appropriate, though the latter virtually always in combination with another resource management mechanism on top. It may even (very, very rarely) be appropriate *not* to manage resources, and instead leaking them and to leave the cleanup to the OS. But smart pointers are always superior to *manual* memory management in C++. If you disagree with this, find actual, factual arguments instead of putting words in my mouth.
The problem I see is that if one of them fails unexpectedly then the \`lock\` will halt infinitely the other process, as I read \`fcntl\` takes care of this problem. But are there any other quirks that I missed ?
Well it really depends. In general? Probably not. But "don't pay for what you don't use" is pretty core to C++. If you don't need a constructor you shouldn't pay for one.
Apologies, my previous comment was meant literally, but I said it poorly since I was irked by the whole ‘downvote your conversation partner’ thing. Herb, in the video, considered the four proposals he talks about both separately and in union. The last proposal has error propagation marked explicitly with `try`. Even combined Herb still referred to these as ‘exceptions’. Combined with the fact that `throws` results in a function returning a value type enum, it's very hard to see a concrete semantic difference between this C++ proposal and Rust using a `Result&lt;T, Box&lt;Error&gt;&gt;` and `?`. The things you mention are not markedly different. Rust's error propagation does the same general thing as C++, and the markup difference between C++'s `try` and Rust's `?` looks mostly syntactic. The lack of `catch` blocks in Rust might seem like a significant difference instead, but `match (|| ...try...)() { ...catch... }` is basically the same thing.
&gt;What if the Foo and Bar are semantically different? Is piece of the information lost this way? I honestly don't know what the convention is here. My guess is that people just upcast to `dyn std::Error` and let the handler do a runtime downcast, much like C++ exceptions. That's still better than C++ because the programmer gets to opt in to allocation and RTTI if and when it is convenient for them. &gt;What happens if I forget to wrap `Result&lt;T, Bar&gt;` with `map_err`? The `Result&lt;..&gt;` type is tagged with `#[must_use]`, so the compiler will bark if you just forget to handle the return value, and you can't access the value (`T`) from a `Result&lt;T, E&gt;` without specifying how to handle the error (`E`) case. It's a proper safe algebraic data type, like `Either t e` in Haskell.
&gt;Returning everything from public interfaces by value would be utterly impractical. It might be something to be aware of and do where it's reasonable, but not any sort of rule to follow blindly. I’d be inclined to agree but I think that the rule is probably *orders of magnitude* more practical than people realise, simply because people are fundamentally not aware of this possibility. For reference, one particular way in which this can be achieved is shown in [Sean Parent’s seminal lecture *Better Code*](https://www.youtube.com/watch?v=QGcVXgEVMJg). Virtually every interface that handles pointers to polymorphic objects can be converted into a value-based interface without loss of efficiency, extensibility or features. There may be exceptions but I am not aware of any. One valid reason not to want to do this is that it is, frankly, more work for the library implementor in the short run. This *is* a valid reason. But rarely; in general, we want to shunt as much work as possible from users to library implementers. As for “composition over inheritance”, you’re arguing with such an obvious straw man that I’m a bit puzzled why you’d even spend time on this. *Obviously* the argument isn’t about the kind of *composition* everybody already does — it’s specifically about the kind of *inheritance* that is done where composition would be more appropriate. I’ll grant that the cut-off isn’t always obvious: For example, I agree with your statement (made elsewhere) that it’s impractical to forbid *all* implementation inheritance^(1) because it would lead to tons of boilerplate implementations to forward interface methods to the implementation. Nevertheless, inheritance carries a well-understood *cost* (namely, technical debt through tight coupling), which is why the guideline is still valuable. --- ^(1) Though it’s worth noting that some modern languages have gone this path, and have completely done away with implementation inheritance in favour of other techniques. However, they generally offer an adequate replacement, such as traits or mixins. Well, except the good ones do (*cough*, Go).
The reference only applies to the underlying object of the structured bonding declaration. The bindings are always aliases to the appropriate members, not references.
Is anyone aware of some simple (but not toy) examples of what this kind of code would look like? Mixing different standardised and custom error conditions? I'm not really grasping how one would work with a single error type like `std::error`. Now having said that, maybe the answer is that I should be reading up on `std::error_code` first.
Why not use [`flock'](https://linux.die.net/man/2/flock)? Avoids the need for polling, and you can use it on the actual file you care about rather than a separate directory.
Fyi the ‘auto&amp;’ alludes to the type being deconstructed, *not* the type of the bindings ‘x’ and ‘y’.
Thanks, I'll make these fixes.
Thanks, I'll make a note.
Boost has an experimental implementation of `std::error` at `boost::outcome::experimental::error`. See https://www.boost.org/doc/libs/develop/libs/outcome/doc/html/experimental.html
I'll read on the `fnctl` and `flock` difference, and use one of them. Are there any other alternatives other than relying on `flock` ? (ideally a platform indep. solution :)), not trying to be picky, just curious about other ideas.
Judging from this subreddit the natural order of learning to program is Hello World, FizzBuzz, followed by a JSON parser.
If the committee chooses the P1095 formulation, then functions marked `throws` *auto-propagate* lightweight throws, whereas functions marked `fails` require explicit handling at each propagation point. Same implementation, different syntax.
You are right that C and C++ are different languages. I doubt that compiler writers are insane enough to make it behave differently in C and C++ without a warning, so I would say that as long as the compiler doesn't complain it's pretty safe to rely on C's behaviour.
The `&amp;` refers to the outer object, not `x` and `y`. The difference between `auto [x, y] = a;` and `auto&amp; [x, y] = a;` is that the former is taking bindings to an unnamed copy of `a` and the latter is taking bindings to an unnamed reference to `a` (so effectively to `a`). The fact that `x` and `y` bind to bitfields (bind to, not are references to) is totally independent from the presence of `&amp;` in front of the `[`.
Hey if I was working to teach someone C++ it would be a nice choice or an intermediate project. It is a parser that is both useful and easy for many. You can gain competence in many parts of C++ and you can test it. One visit to json.org and one can get all the info to build the ebnf for it and build a rd parser. This was somewhat an exercise in flipping the problem around a bit and using the type system to define the parts of the parser to use and where along with eliminating some branching with the assumption we know what types we are expecting. Additionally with that information we no longer need to store and traverse a tree of variant data structures, it is your reified class structure. With that it lended itself to iteration over parts or the whole of a json array and only fully parsing the parts one needed in the comfort of the std algorithms.
1. It's specified in the standard. 2. Should OCaml make a warning that it doesn't work like C and C++, which, you know, to any functioning programmer, is common sense?
For small vector optimization
Are you sure? I did not know about it before a few months, perhaps one year, ago and when I looked at cppreference, it is marked as C++ 17.
Right. nth_element is part of the job. nth_element partitions the data, so you will need another step in order to sort the top partition.
As mentioned in another comment, cppreference marks the `ExecutionPolicy` overloads as C++17. If you look at their main algorithms page, `std::partial_sort` doesn't have a C++ version tag, which means that it has been there since C++98: https://en.cppreference.com/w/cpp/algorithm If you're still not sure, I guess that you can crawl through C++17 changelogs and check that `std::partial_sort` isn't there :p
Nice, thank you! It is greatly needed.
eh. it compiles. it works. have fun.
Can it easily be combined with libfmt?
The point of flexible array member is that you can allocate memory for the struct and the 'extra' portion in one block, and than have a pointer automatically pointing to the extra block. C++ doesn't have direct replacement for that.
You realize that VLAs are optional in latest C?
&gt; I'm just saying that Result is very much not an exception. I would actually describe what Rust offers to be rather close to "exceptions" with respect to the points you mentioned. The `Result` type family is only part of the puzzle in its error handling story. Another part is its postfix question mark operator. Now, you could argue that having to use a question mark to explicitly ask for automatic propagation is not automatic propagation. But it still allows keeping error flow distinct from success flow.
ouch owie my compile times
In my view, \`restrict\` is a major source of loss of optimizations. I understand there are some issues with incorporating it into C++, but the lack of it is disheartening.
Any particular examples?
&gt; There is nothing inherently wrong with them. The problem is that an unsigned number does not behave like a normal number. Unsigned arithmetic is guaranteed to wrap modulo the max on overflow &amp; underflow Signed arithmetic is undefined behavior on overflow &amp; underflow The former seems a lot more 'normal' to me, but of course 'normal' is a subjective terms so YMMV.
Not null.
I'm not sure what undefined behavior if any it invokes, but the common work-around is to use an array of length 1, and do the same trick. This is not providing greater safety at all, and from some perspectives it is less safe since the compiler will happily stick it on the stack, whereas a flexible array member does not permit such usage (without alloca or similar).
The guard dog was barking at something all night, so I shot him and went back to sleep.
I must say that usually those kind of quiz are quite easy, but this one was definitely very challenging :-)
Do you have any examples you can show me? I'm the maintainer of `absl::InlinedVector` and we use `std::aligned_storage`. I'd love to see alternative implementations!
Yup - you are right. I simply misread cppreference. Thank you for your enlightenment. I must admit that I in my previous code always used a combination of nth_element and std::sort. ;-(
If you are allocating so little that heap allocations really matter, then you probably would be better off by using 4096 byte arrays and using as much as you need of them...
I had gsl::span behave erratically depending on declaration order: Arrays of two identical spans. The first worked. The second didn't. Don't know if that was a bug in compiler (GCC 6.x) or in the MS gsl implemendation. Switching to tcb::span fixed it after I'd spent a couple of days trying to futilely figure out why the code crashed.
Is this valid, then, assuming the target of the non-const pointer is never written to? void func2(int *iptr); void func1(const int *ciptr) { func2((int *) ciptr) }; const int x = 100; func1(&amp;x);
I'm mixed on this, partly because I think the key distinction made between errors that are destined for a human reader versus a code handler is IMO lacking a very important nuance: the human reader may very well need more context to figure out the defect and the only place where that context is in the *calling code*. That, even if the right answer is "the state of the program is corrupt and must not continue executing", if possible I'd like to handle that at the highest level to get the most possible diagnostic information. That isn't possible in OOM or stack corruption cases but in many other cases it is. So I guess what I'm getting at is that, with the exception of "really I can't run any more C++ code" (i.e. OOM or stack corruption), I think code really ought to handle all *both* programmer errors and bad input conditions, if only to provide enough diagnostic breadcrumbs for analysis later.
STL containers typically incur an extra indirection and memory allocation. I see sometimes people hacking an unsized array at the end of a class with a custom allocation with extra space after the object, but I'm not sure of the sanity of such thing with regard to C++ semantic.
And, do you think f.e. that MSVC is going to break stuff that works [and has worked for that much time]. Before that happens, pigs will [not might] fly.
No, did not know that. So the std [C11] did nothing, as it was already optional before.
Dude, how am I supposed to get internet-mad at you if you post well reasoned and thought out lists like this?! :-P Anyway, my top 10: Background: AAA game dev. Time at the grindstone: 7 years Team size: Varies, but anything from 1 person (writing a prototype for a pitch), up to 50 coders, plus artists, designers, etc... Largely using Unreal Engine. 1. Unless you're doing it as a training exercise, don't rewrite what's already in the standard library. (Or, in my case, the stuff in the Unreal Engine's libraries.) 2. Before you do anything with a container, check whether something in the `&lt;algorithm&gt;` header does it for you. (Or whichever libraries you're using.) 3. Keep up-to-date on the latest developments, whether that is new language features or new techniques. 4. Write code that's easy to read first, optimise later. The causes of inefficiency is rarely what you think it will be. 5. That said, nothing murders performance like cache misses, so try to be cache friendly from the start. 6. Even debug performance matters. 7. When optimising, start high scale. Avoid doing work you don't have to. There's no need to sort (for example) every actor in the scene by distance from the player if you only care about the three enemies closest to the player. Reworking your algorithm here will work much better than optimising your sort function. 8. Learn how to ask colleagues how their code works without sounding like you're accusing them of screwing up. 9. Break conventions if you have to, but have a good reason. 10. Users of your code should have a way to feedback to you easily. Documentation is never done, even if the code is.
&gt; The same is true for Haskell. I don't know much about Haskell, but AFAICS, [its basic I/O functions](https://hackage.haskell.org/package/base-4.12.0.0/docs/Prelude.html#g:25) does not encode the list of possible errors they may return.
This is as undefined as it gets in C++, point blank. And of course, it is not safe at all.
Can you elaborate?
Fair point. I thought IO was a weird historical accident, and the modern consensus was the superiority of `MonadError` and `ExceptT`, but I'm no expert in the language so I could well be wrong.
Hmmm - So the compiler is reading the source code, understanding what the ultimate purpose of the code is, and replacing it with special purpose code? Am I the only one that thinks this is a bad idea and waste of time? a) It's pretty specific - I'm doubtful that much if any real world code would actually be noticeably affected by this. Of course I can't prove this, but no one could prove the opposite either. b) So we're writing code and make a small change which results in a totally surprising change in performance - with no clue what we did to produce this change. c) So we end up investing a large amount of work so we can then tweak our code to fall into the right slot that generates this optimization. How about a different approach: a) I write a program. b) profiling reveals that there much time is consumed in sum/product routine. c) I re-implement that code in assembler. d) I also leave the original in there in case I need to be portable to a machine whose assembler I don't want to learn. Or need to apply the original code to types which the compiler can't process - perhaps non trivial types such as imaginary numbers. Now I have something that shows my work and doesn't rely on opaque compiler magic and side-effects to generate surpassing results. I won't be spending any future time tracking down the source of "We made a small change and the program is now running at 1/15 as fast." Moral of the story - If you start using the compiler to do the programmers job, you'll eventually regret it. Robert Ramey
Isn't that technically undefined behaviour in C++ though? I think it's valid in C, but for C++ you'd have to do some memcpy shenanigans instead if you want to avoid undefined behaviour. It probably works fine for any compiler and platform one would actually care about, but just to be pedantic
No, VLAs were mandated in C99, https://en.wikipedia.org/wiki/C11_%28C_standard_revision%29#Optional_features gives you a nice graph.
Thanks! We did not really expect the participants to come up with right answers to all the questions, the purpose of the quiz was to have some fun and give a little insight into lesser-known dark corners of the language.
Yes, but... That's not composing anything, that's re-mapping the error, *all the time* (which nobody noes obviously, everybody just uses one Error and that's it. Meh. And dig this: if I am a library, it is not easy to know what failures the caller cares about, it is presumptuous.
This is not my code, but that's what I used to play around a bit: [Bitcoin's prevector.h](https://github.com/bitcoin/bitcoin/blob/master/src/prevector.h)
thatsthejoke.jpg As a serious answer to your question, yes, most C89 idioms will compile in C++. Reverse compatibility has always been a serious consideration when introducing changes into the standard, because of how much legacy code is out there. It is rare that a new standard will not be written in such a way to accommodate old code, even if it leads to a (seemingly) janky implementation. An example that comes to mind is that in C a string literal can be implicitly cast as a pointer to a non-const char (when in reality it should be explicitly specified as const, since string literals are non-immutable), without even a warning. Not so in C++11, in which you'd probably want to use a string class-container anyway. Another that had me confused for a while, coming from C, is that expressions in C++ return lvalues, while in C they return rvalues. As an aside, C and C++ diverged from C89, so the C idioms introduced later are not C++ compatible in general.
Thanks!
Does it handle pretty indentation for user defined types? Or is it like python's pprint?
Can you give me an example of what you mean?
Apologies. Can you suggest a solution for this?
Yeah should be easy though I haven't tried yet. I'll try this out later tonight.
It's great in theory but not every library writer does a great job at exposing errors in an easy to handle way. I recently ran into an issue with config-rs that forced (encouaged?) me to write some pretty ugly code. https://imgur.com/a/G7At1NV https://docs.rs/config/0.9.2/config/enum.ConfigError.html So while I do think rust's error handling story is hands down better than c++'s is currently it's not without flaws, and herb's comment about unioning diverse error types is a valid one.
He mentions that telling people they're doing something wrong isn't a good approach. But if they are doing something wrong, and if solving their problem means making the language worse for me, why should I accept that? How does his proposed kind of exceptions affect what's been shown with current 'zero-cost' exceptions: the elimination of branches? It seems to me that those would have to be inserted for his kind of exceptions to work. It's good that they're still not visible in the source, but some programs benefit from not having those branches at all, visible or not. Something to note about the code example he showed: You can also get the small output code by _removing_ noexcept from `f()`. All the extra code is just about enforcing `noexcept`. He only showed the benefit from adding `noexcept` to `g()` but I think both things should be kept in mind. At the moment I'm pretty strongly opposed at least to part four of his proposal, putting `try` on expressions so that exception control flow paths aren't 'invisible.' I want them to be invisible. They should be invisible. Swift has these `try` decorations and, while not the worse mistake any language has ever made regarding exceptions, I still think this clutter should not be there. [Here's][1] a previous comment I've made about exceptions. [1]: https://www.reddit.com/r/cpp/comments/7hk1gs/exceptions_vs_expected_lets_find_a_compromise/dqsj5is/
It's still supported as of the final draft of the C18 standard. 6.5.2.3, footnote 97: &gt;If the member used to read the contents of a union object is not the same as the member last used to store a value in theobject, the appropriate part of the object representation of the value is reinterpreted as an object representation in the newtype as described in 6.2.6 (a process sometimes called “type punning”). This might be a trap representation. And I seem to remember a WG14 member stating that this was a deliberately supported use case of unions.
None of this code will compile because there are no main functions. Solved, ez
Putting square pegs into round holes is complicated indeed. In particular, I always found Windows API peculiar. If instead it would return the new handle (like \`dup2()\` does in Posix) the task of wrapping the handle would be easier accomplished.
Am I the only one who finds this background distracting?
So "Dude, I wouldn't let my dog run that code" probably isn't the best way to go about #8?
I understand this is trolling, but I'll take the bait. "Compilation" usually means phase 7 of translation (see [https://en.cppreference.com/w/cpp/language/translation\_phases](https://en.cppreference.com/w/cpp/language/translation_phases)), while main is required for executables only in phase 9 when everything is combined into a single image.
No. It's pretty bad.
Say what now? Got a link?
(*Shameless self-promotion:* I also wrote a single-header pretty-printing thing a while back, which you can find [here](https://github.com/tcbrindle/pretty_print.hpp). It's rather more limited in scope that this library, and hasn't had a great deal of testing. But apologies if the following is biased as a result :) ). Regarding this library, I'm not sure that I'm all that keen on the idea of a stateful `printer` class. I think I'd prefer a design which had something like a `print_options` class, passed to each call to `print`, i.e. something like: struct print_options { bool compact = false; bool quoted = true; char line_separator = '\n'; int indent = 2; }; template &lt;typename... Args&gt; void print(print_options opts, const Args&amp;... args); template &lt;typename Arg0, typename... Args&gt; std::enable_if_t&lt;!std::is_same_v&lt;Arg0, print_options&gt;&gt; print(const Arg0&amp; arg0, const Args&amp;... args) { print(print_options{}, arg0, args...); } Also, explicitly listing all the std containers (as [here](https://github.com/p-ranav/pprint/blob/master/include/pprint.hpp#L567) doesn't seem like a great idea. Not only does it mean that users of this header need to drag in tens of thousands of lines of standard library code, but it also means that (as far as I can see) this library won't work for other STL-compatible containers.
Interesting, didn't know that
[Here. ](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=82658) AVR has a ton of performance bugs on GCC.
I don't see why this would be any better with Herb's proposed unityped error. I agree that this is bad, but making authors pay even less attention to the information they're sending down the error path seems unlikely to move things in the right direction.
libfmt is already able to print ranges and tuples. Just include `&lt;fmt/ranges.h&gt;`
I don't get why it's not composition. Yes, it's less free than [union types](https://www.typescriptlang.org/docs/handbook/advanced-types.html#union-types), but it's still composition.
I think what your doing is unit testing. Your only doing it at compile time vs. runtime. I think it's very reasonable for constexpr libraries.
Suppose I have: struct Vector3 { float x, y, z; }; struct Mesh { std::vector&lt;Vector3&gt; vertices; }; Mesh quads = {{ {0, 0, 0}, {1, 0, 0}, {1, 1, 0}, {0, 0, 0}, {1, 1, 0}, {0, 1, 0}, {0, 0, 1}, {1, 0, 1}, {1, 1, 1}, {0, 0, 1}, {1, 1, 1}, {0, 1, 1}, }}; What do I do to make printer.print(quads); Print something like Mesh { positions: [ (0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 0, 0), (1, 1, 0), (0, 1, 0), (0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 0, 1), (1, 1, 1), (0, 1, 1), ] } And not something like Mesh { positions: [ (0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 0, 0), (1, 1, 0), (0, 1, 0), (0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 0, 1), (1, 1, 1), (0, 1, 1), ] } or like Mesh { positions: [(0, 0, 0), (1, 0, 0), (1, 1, 0), (0, 0, 0), (1, 1, 0), (0, 1, 0), (0, 0, 1), (1, 0, 1), (1, 1, 1), (0, 0, 1), (1, 1, 1), (0, 1, 1)] }
If you can do it, do it; but you'll probably need to switch to runtime when you project gains a little bit more complexity.
[Finding Bugs in LLVM 8 with PVS-Studio](https://habr.com/en/company/pvs-studio/blog/450002/)
Yeah... the thing about C++, at least as far as I understand the standard is that in order to have an object, you have to construct it, period. This means that we cannot just take some memory and cast it to something, otherwise, compiler is allowed to do some crazy things based on aliasing analysis - like here: https://github.com/boostorg/function/pull/15 where we spent months trying to pin point a crash after updating GCC.
There might be a problem that is not inherent to `static_assert`, but to placing tests in the same TU as the function you're testing. Compiler sees your function body, so it is able to inline. If you have a bug, inlining might affect the bug and cause your test to pass when it should have failed loudly.
I just don't see this going far enough. It's definitely an improvement to exception handling, but exceptions are still flawed as an error handling syntax. The C++ user base has already defragmented itself by disabling exceptions. When code naturally grows it has errors, and being able to debug these errors is important. C++ Exceptions somehow end up the worst of all worlds. They have no call stack info and so when you get an uncaught exception you have no way to know where it came from. You can break on exception thrown, but that requires runtime finding of a bug, much worse than if it just crashed and you had a stack dump. Also if it's a generic uncaught exception good luck with that. C++ would need to have some sort of time traveling debugger as a standard on every platform to be able to step backwards to see where an exception occurs before I would consider using them for this reason alone. The second issue is the syntax just sucks as it promotes putting multiple unrelated lines together because it uses scope, and what the scope means is too overloaded in C++. try { my_resource neato("neato.txt"); neato.burrito(); // this should not be in this try/catch scope but RAII and exceptions both use the scope so... } catch(error e) { if (e == my_resource::file_error) { // this may be incorrect if my_resource::burrito threw file_error std::cout &lt;&lt; "Unable to open neato.txt" &lt;&lt; std::endl; } } You really need to only have a single line for each try/catch which is super awkward: my_resource neato; try { neato = my_resource("neato.txt"); } catch(error e) { if (e == my_resource::file_error) { // this may be incorrect if my_resource::burrito threw file_error std::cout &lt;&lt; "Unable to open neato.txt" &lt;&lt; std::endl; } return; } neato.burrito(); // this should not be in the try/catch scope That all looks suspiciously like: my_resource neato; auto res = neato.load("neato.txt"); if (res != my_resource::error_ok) { if (res == my_resource::file_error) std::cout &lt;&lt; "Unable to open neato.txt" &lt;&lt; std::endl; return; } neato.burrito(); Really what i want is forced unpacking of error codes, like what Rust has. Exceptions in python also suck because of this scope syntax issue.
Single header files are kind of nice because you can try out the library in 5 seconds without having to properly link it to your project in CMake. That said, a header only lib turns out way more expensive to compile when added into a few hundred files. Also traversing a lib to figure out what it's doing is way more complex when everything is in one file. Ideally I would have a normal CMakeLists.txt that you can easily integrate and explore other options if you want to have a header only version (generate it perhaps?). fmt does something funky with a HEADER\_ONLY macro, maybe that?
For something like the above, I think it's arguable that that's a grey area and maybe it's worth doing some of that to just catch some errors at compile time. I definitely have a little debug only code in the main cpp file of some libraries to force instantiation of some templated stuff so that I catch more errors immediately instead of 30 minutes later when much higher level level code builds that actually uses it. I think it just wouldn't scale very far beyond something like this. A key part of unit testing, with a good testing framework, is that you get formal output that can be looked at by automated tools or humans and it can collect up all of the reported issues at once for evaluation. Serious testing requires setup of test data and evaluation of complex results sometimes, testing exception cases, and all that. And I assume the first error that happened in the above would break the build and stop any other (maybe nightly automated) tests from running which would make some folks unhappy. Whereas if it was tested in a more traditional way, it would just be in the list of errors that were found.
I don't think MSVC accepts this.
Since the function is constexpr - and thus likely in the header file - it would be inlineable everywhere at the more or less same degree.
It is always better to catch error at compile time rather than run time, so if your functions allow compile time testing, definitely go for it. A lot of template type-based meta-programming does all the tests at compile time.
How many times has that warning been about a real problem for you? (I still get warnings about things like x &gt;= 0 always being true.)
University is misspelled.
I have been planning to listen to this series. Any plans to make it available on Spotify? I have personally found that to be a very convenient way to listen to cppcast.
Actually, it's a pretty cool idea. &amp;#x200B; But have you benchmarked your compile times?
Would've liked another hour of this talk; will there be a longer version?
I noticed you copy-pasted ~300 lines of magic-enum into your [pprint.hpp](https://github.com/p-ranav/pprint/blob/master/include/pprint.hpp#L93). Do you think it's possible to do proper package management here? I know C++ doesn't have any official solution for that, but still it feels strange to create a dependency this way.
&gt; int offers a good approximation, because at least the containers can have a debug mode assert(i &gt;=0) which helps you see where you got it wrong. But they already have `assert(i &gt;= size())`
I think they claim it's a settled conversation because the committee said it should've used signed types.
could just slap all the tests in a different header and have a separate build called "compile time tests"
Sure, there's good and bad points for either side, really. The fact is bugs where you actually use an incorrect index are going to happen. In the case of signed, it's pretty likely to go unnoticed, `arr[-5]` is still likely valid memory. `arr[~0]` is not. Fail fast is better than fail silently, IMO.
It's not better, but you're dismissing that question and herbs concern off hand using rust as proof that you can have explicit error types in the return type without any problems. Even in rust people get annoyed with handling multiple error types and cast them to std::error::Error, which to me is the same thing as the "throws anything" that herb mentioned. Error handling is hard and there's no single solution that's "solves the problem", including rust. Rust is fucking amazing, and I think we're making great strides with failure and the Fail trait, and macros are making it easier and easier to derive error variants in your own error type for error variants from a foreign error type, but people still get lazy in the exact way herb mentioned. However, I dont agree with Herb's implication that rust and haskell's error story has failed with his comment that "everyone who has tried this has failed". I don't think the fact that people can use a feature wrong means that the feature is a failure, but it's definitely a problem in rust, just like it would be a problem in c++.
Another option is to put most of the header into a big `#ifdef` and require that users put something like #define MYLIB_IMPLEMENTATION #include "mylib.h" in one translation unit of their project.
I don't know, our build system won't even let me run it because we're a `-Wall -Werror` shop. Not every warning is a real problem, but some are, and you don't know ahead of time which ones are, and it costs more brain power to reason about it rather than to adopt the habit of zero warnings. Or to put it another way, not even warning is a problem, but it's demonstrably true over the long run that running with `-Wall -Werror` leads to fewer problems.
I think the article was merely describing how LLVM does its witchcraft, not prescribing what programmers ought to do.
Please submit links as links and not as text posts.
Ah yeah, I was misremembering a couple of things, including the common initial sequence visibility rule (which has been retained into C18, contrary to my expectations).
Doesn't the current implementation still have an issue with constexpr, because reinterpret_cast is not a core constant expression (even in C++20)? Or am I missing something here?
Especially with the gray text!
New to Reddit ^^ will do next time
Thanks, and welcome to Reddit! :-)
Yes, this can be achieved. See [here](https://github.com/p-ranav/pprint#user-defined-types)
Your reply isn't showing up in the thread, maybe try reposting it.
I'm definitely a fan of "`constexpr` all the things" and `static_assert`-ing anything that can feasibly be checked at compile-time. This has a very important added bonus in C++: if a code path in a constexpr function causes undefined behaviour *during compile-time evaluation* (i.e. in a `static_assert`), then it's a hard error. That is, it's possible to check at compile-time that your functions don't exhibit any UB (for a given set of inputs). That's pretty good.
I could definitely argue that having to do manual propagation is, in fact, not automatic propagation. Because having to write something is different than having to write nothing. Again, this isn't a value judgment on Rust. I happen to like `?` and would personally prefer to require annotation on new-style throwing functions. Because it is meaningfully different to require annotation.
&gt; It specializes std::unique_ptr ... &gt; This doesn’t compile because the operator&amp; for a unique_ptr doesn’t give you a pointer to the inner raw pointer. It seems like a lot of your problems are caused by that. Why not write your own smart wrapper that just does what you want it to do instead of saying how you don't get the behavior you want from unique_ptr?
C++ badly needs modules. The rest is secondary.
It doesn't inherit from `std::unique_ptr`, it's just a type alias for an instantiation of the template with suitable template arguments.
Specialization is not inheritance. It is a template feature. In the post mentioning it, `unique_handle` is defined as `using unique_handle = std::unique_ptr&lt;void, handle_deleter&gt;;`.
I want to write a loop that iterates from size() - 1 to 0. I'm using this index to index into multiple different containers, so I can't do range based for. What should I do? std::vector&lt;vec3&gt; verts; std::vector&lt;vec3&gt; normals; // Do stuff such that verts.size() == normals.size() for (size_t i = verts.size() - 1; /* what goes here? */; --i) { // ... What goes in the for loop terminate condition? If i was signed, it would be i &gt;= 0, but i is unsigned, and this will always be true. This sort of thing happens to me more often than I'd like.
May not be exactly what you want, but... I'm working on a Bus Adapter library that uses Modbus protocol (industry standard, request/response, efficient, robust). The library works on x86/AVR/STM32f103 (libopencm3/FreeRTOS). Need about 512 bytes. Currently, supports RTU over serial. Github has good implementations of Modbus. My lib actually uses those. Look for armink or cwalter The library generates strongly-typed C++ interface from a "model". API would accept integers and double types. Can transform between floating-point and integers. "Keys" are numeric identifiers internally in Modbus; in the generated API those are names of the values. [https://github.com/boltrobotics/boltabus](https://github.com/boltrobotics/boltabus) &amp;#x200B; Cheers
Use detection idiom to detect container like objects, and format the output based on the detectable traits of the iterator maybe
\&gt; "We are about to do it again in networking." No, we aren't. Almost all I/O operations return a product type. That is, an error code AND the number of bytes transferred. This of course is not representable with std::expected or any other variant-flavored type. There is a paper, I forget which, that correctly points this out. It is disappointing to see this incorrect information pop up in Mr. Sutter's video.
The alternative explanation is a lot of people here genuinely disagree with you.
Agreed. I'm arguing that the compiler shouldn't do this.
That is more of an example of library misuse. Intensive loops should be kept in the library and not in Python. An image is just an array and any operation you want to do should execute on the whole array in the underlying code. PS: Numpy is flexible and allows you to pick your linear algebra backend.
Let us all have a silent moment for the poor man who wrote the calendar and time zone handling code.
Q15's answer is wrong. The function templates are functionally equivalent but not equivalent, so the program is ill-formed NDR by http://eel.is/c++draft/temp.over.link#7.sentence-3.
When should we have it?
Makes sense. Thanks, I'll consider this option.
oh man yes. I'd rather jump off a bridge.
changed one word from "inherit" to "specialize" and the point still stands.. don't use something that's not suitable and then complain that it's not suitable.
No, I didn't benchmark it. It was more of a small project (~1000 LoC) and compile time wasn't an issue. I also always had the impression that static_asserts are much faster that unit tests which have to start up a whole framework. Could still be a problem on much larger projects where you then probably should put it in a separate header like u/IRSmoh said.
Definitely possible. I also faced some problems with third party libraries which were written in C++03 and had constructors which weren't declared constexpr although they easily could have been in C++17. Couldn't use static_asserts to test functions which required one of those types as parameters.
&gt; I think it just wouldn't scale very far beyond something like this. A key part of unit testing, with a good testing framework, is that you get formal output that can be looked at by automated tools or humans and it can collect up all of the reported issues at once for evaluation True, I unfortunately never had a chance of using C++ professionally and use it only privately because I really enjoy it. So this has never been an issue for me. &gt; And I assume the first error that happened in the above would break the build and stop any other (maybe nightly automated) tests from running which would make some folks unhappy. Yes, that's something I didn't consider at all.
If it's a small amount of data, why not an enum and a pair of switch statements? If there's no tricky type hierarchy I wouldn't feel like the complex templatey libraries are pulling their weight.
I see. That's just as valid as saying "Well, the committee said std::auto_ptr was a good idea for like 10 years. Pretty sure that means I should do it!" The committee is made of people, people make mistakes.
That was a joke. A lot of people disagree with a lot of people, and passive-aggressive down-voting is pretty toxic on Reddit in general.
It would be simple enough to make the static_assert's optional. Just make a wrapper around it that #ifdef's out the actual call to static_assert if some unit test define is missing. void static_test(bool b) { #ifdef STATIC_TEST static_assert(b); #endif }
Agree
Modules aren't even going to be used by most libraries for years anyways. Contracts will be great for the code I'm writing right now and I personally would rather have that first.
This is an excellent idea. As it turns out, [namespace aliases](https://en.cppreference.com/w/cpp/language/namespace_alias) are already a thing: namespace logsys = somelibrary::utilities::logging::files; // logsys::logger works fine I don't remember if it works inside the body of a class, but it does work inside a function.
[P0816 "No More Nested Namespaces in Library Design"](https://wg21.link/p0816) Overall, I agree with P0816 - namespaces are good for preventing conflicts between independent libraries (e.g. `std::shared_ptr` and `boost::shared_ptr`). They provide little value for internally structuring libraries, except in specific scenarios like UDLs.
I still don’t understand why we need the double square brackets for contracts, expect if one wants to make sure to reduce readability of the code.
But, even then it could be used for trivially easy swapping of equivalent but different implementations, right? Want to use the SIMD version, just map to that one, else map to the standard one, that sort of thing. Since you've aliased the namespace in your own code, nothing changes at all to change implementations except that one line and a rebuild.
This isn't entirely new, but [theres are multiple sections of the Q&amp;A](https://isocpp.org/wiki/faq/operator-overloading#matrix-subscript-op) that heavily suggest that the ISO committee has little interest in extending the language to properly support this with low overhead. As of right now, you can do what the FAQ suggests, or you might be able to get away with [overloading the comma operator](https://stackoverflow.com/questions/5602112/when-to-overload-the-comma-operator)? I began experimenting with extending `operator[]` to support some basic type introspection, but alas I feel the committees to decision to invest so heavily in templates means that we'll probably have to hack together a solution with more template metaprogramming, stuff it in a library and hope that one day it'll become a better replacement to `valarray`.
Who are they kidding? They’ve got to keep pace with major OS releases, which are about every three years.
For something like this, I probably wouldn't use the static assert. One of the things that comes up is that if you had a bug, the compile will stop if you hit the first static assert and you won't get a full error report. Now, it may be useful to turn a bug into a compile error because those are often cheaper to detect than a test error - in large projects the linking step can be the longest time, so a compile fail ends before even trying that. The places that I like static asserts tend to be things that are always true and not things dependent on variables. For instance, if I have a struct that needs to fit in a cache line, I might do something like static\_assert(sizeof(MyStruct) &lt; CACHE\_LINE\_BYTES) or similar. It serves as documentation about a weird requirement. I've done similar with std::is\_trivially\_constructible when it was a requirement for performance reasons. This is especially true in template code where it would be entirely possible to test the templates on conforming types but then have something weird happen when used with a non-conforming type. If you separate the test code from the implementation in that case, it won't be hit on template instantiation. Pre c++20 and concepts being somewhat easy to express, the static asserts can be used to give somewhat better error messages (can be done with SFINAE techniques, but that's messier and leads to the same "this doesn't compile" result).
The text is hard to read. Not sure if it's an issue with my browser (Firefox). The text is light gray on a white background: https://i.imgur.com/koqRQ6d.png
[`cereal`](https://github.com/USCiLab/cereal) is an option, it supports endian-agnostic binary serialization and adding [if required] support for your own types is quite straight-forward. Development seems to have stalled, though :-(.
What you're doing is absolutely unit testing, however I don't think I like the tradeoffs. * It's at compile time, which can bloat compile times (especially if they're in the header) since you're effectively compiling and running unit tests in one go unless you pull some macro trickery. * It doesn't work on stateful code, since compile time stuff is functional. So this leads to some skitzophrenic testing code where you use something like gtest for stateful stuff in one place but test the functional stuff in situ. Doable, but strikes me as annoying to maintain. * I don't think this generates code coverage statistics, which makes tracking what is and isn't tested an exercise purely in human diligence. &gt; Do you prefer unit tests or static_asserts in such cases or both and why? The way I see it, generally static_asserts are used to say "don't do something stupid" while traditional unit tests are used to say "don't do something wrong." So I would use static_asserts to make sure structs come out the right size, but unit tests to make sure I'm using those structs properly.
According to [this blog post](https://quuxplusone.github.io/blog/2019/02/23/not-variadic-expression-templates/#according-to-the-minutes-of-the), the proposal to deprecate some uses of the comma operator to allow for the future use within operator[] is moving forward to CWG.
Protobuf is very popular, and I have used flatbuffers as well
Isn't that argument kind of circular? The longer it takes until modules are implemented, the longer it takes until they are adopted.
You can serialize the data in json format, libjson might work for you.
? Are you suggesting that the 3 year rule of C++ standard would be linked to some global “3 year between major update OS rule” you just made up?
It is really annoying that this doesn't work in class scope. There are many classes where I'd like to define a shorthand for std::chrono.
There is a [std::launder paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0137r1.html), there is [std::bless paper](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p0593r2.html) I think detachment paper is not published yet and [Herb's ACCU video](https://www.youtube.com/watch?v=os7cqJ5qlzo) has links to relocation papers.
If only `i,j,k` meant `std::make_tuple(i, j, k)`
Seconded cereal. It has been working quite well for me.
I have done static testing like that. I put static asserts into their own TU so it's part of a test suit build
Please no! Let's not give `,` yet another meaning.
There’s a flag for “do exactly what I say”: -O0. As soon as you enable optimisations, you are admitting the C language works on an abstract machine. Then it’s just a case of what we accept as a customary optimisation and what we feel psychologically uncomfortable with. Even back in the 1980s we had to invent the volatile keyword because compilers started to optimise away loads and stores to memory-mapped IO in (at the time) surprising ways. Nowadays load and store optimisations are taken as read. But most programmers simply do not have the mathematical background to do loop flattening, no matter how good they are at assembly. The performance benefit of these optimisations is easy to measure, particularly in array address calculations, and it translates into faster code and better battery life. If you argue “I want my iPhone to have 2% worse battery life because the programmer might be confused about this particular strand of loop optimisation”, it’s not a trade-off that wins you a lot of sympathy.
IIRC all CortexM4 chips I know are little endian, just as x86. Do you really need something endian agnostic? As your types are probably not that complicated anyway, it might be enough to just put everything into a tagged union and send/receive the raw bytes.
C++ can't afford any more new keywords.
Use them whenever you can, is my stance. (Assuming that one is equally proficient in these languages as in C++, of course.) Their big advantage over C++ is ease of use. Syntactic sugar, build systems, an elaborate standard library.
Yes the reference implementation wouldn't compile under constexpr. The API is "aspirational". The implementation could be made much more complete e.g. avoid reinterpret cast for various subsets of types. But right now it's deliberately short to aid discussion. The hope is to build the new cast operators directly into the language, so they'd "just work".
Easy networking
I think what the OP meant (which I agree with) is that even after they're implemented, modules will be adopted slowly for the massive amounts of already existing code. As such, it seems prudent to prefer features that can be used easily to good effect in existing code because they have a smaller opportunity cost.
And a package manager
I haven't developed for Windows for a while but while there exists WinRT (I think it's called) for C++ which is better than C++/CLI, C# is still one of the best languages to develop windows programs in.
Ooh dear this is going to be long. You need to use C# when you want to: 1. See what a well-designed language looks like. C# is, at present, the best designed language out there, and I doubt many people would argue with this statement. Also, it has awesome tooling (e.g., Rider). 2. Efficiently query data sets. Nothing better than LINQ has been invented yet. 3. Make Windows desktop applications (WPF) or applications that target UWP (I don't recomment getting into UWP though). You need Java when: 1. Never. Use Kotlin instead of Java — it's kind of like "Java but with C# quality".
I mean, development on various features will happen in parallel by different people anyway, but: &amp;#x200B; Even if it doesn't get widely adopted right away, I think we need usage experience with the actual c++20 modules as soon as possible. Ideally before c++20 is completely baked in stone (rather unrealistic) but certainly in the time frame to add sensible fixes/improvements/clarifications to c++23 that are based on data, not assumptions. That being said: I believe modules are the number one feature that will motivate major companies to adopt c++20 in the frist place. But again, that doesn't mean that other features (especially small ones) should be shelved until modules are finished - but they imo should be given priority if there is a dev-resource conflict.
[C++ Core Guidelines - SF.20: Use namespaces to express logical structure](https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rs-namespace)
If you just remove the brackets is not enough?
Usually, when you want to choose a non-SIMD version, then SIMD won't even compile because the target platform doesn't support SIMD. So namespace aliasing won't help you here.
Question 15 asks if the snippet contains a redefinition error. As you said the function templates are not equivalent, so there's no redefinition error.
You use Java when you work for a big boring corporation, like a bank, that has some big boring enterprise software written in it. Or you’re an Android developer.
I find the PVs articles generally interesting, but the style is awful this time (like "I stopped checking for mor of these bugs bit I bet there are more"). Filled with unnecessary, snarky remarks that don't add anything, just show how uninterested the author is. It makes the article feel unprofessional. They also don't give much evidence that PVS is better than clang analyzer, just say it didn't found the bugs or it was "too complex " to set up.
Can I ask why enterprise applications use java?
Yeah, no, C# is not the best language. Its like a box full of languages and every time you need something you end up getting a result for another framework that doesnt work on yours
I use Java for rapid prototyping as it is my favourite language and which more performance in terms of coding i can get, there are more cases like you dont need to be performance critical so it best to code faster making the program less expensive or you may need to support legacy code in which case you should use the language, not all legacy code is C++ and banks from around the world uses Java by default for example, if you need to develop a plugin it cant be C++ (it could with the JNI but it is not what the company will expect/want) And C# has the best tool for UI that i has seen in my life, quick, easy and powerul, a shame that only works on Windows. It is the good old Windows Forms, with Visual Studio (because other ides dont has the assistant) you can create the GUI in no time and effortless, it is a nice option if the code will only run on windows But the language are only means to express ideas, changing it should not matter at all to any good developer, i dont know how to code in Fortran for example but if needed in one or two days i will be able to do, the most important part is independant of the language used, how i express the idea may change but my internal analysis on how to do aproach it from a code perspective will remain, i dont code thinking in C++/Java/PHP, i code logically and later i find out how to make it the code, as it should be, thats why doesnt matter that much learning I like learning new because you see things and concepts that may like you and get a better understanding of what could be the next language to switch on, i for example love how Java deals with "headers" and "imports" or i will give my left hand for a package manager as node has in C++, there are many details you can discover and will let you get a depeer idea of what you may need. In my case i hasnt switch to Rust/Go because i dont like functional programing, i keep looking for a better C (in my opinion) and because i know what i want it easy, you dont even need a book, only with the official docs you get the idea if it a good candidate or not
Faster development compared to C++ (many useful libraries, no memory management issues etc). Big corporations just want to get things done and don't care about it being performance optimal if it doesn't affect their business. If the performance doesn't affect their business, no one will bother with C++, because it takes longer to develop (debug) and thus costs more. If you want to work for big corporations, learn enterprise Java and/or C++ (for backend coding), the vast majority use this combination.
Because Java with a lot of OOP can be developed and maintained by developers with nearly no experience coming from frequently changing contractors, perhaps from the other side of the world, at minimum cost. Performances won't be the best but this is not where much of the cost is for information systems.
If you just remove the brackets won't it create ambiguity with goto labels? They could be magic functions but my guess for attributes would be that in a correct program contracts should have no observable behaviour and can be safely ignored which is a bit similar to an attribute
isn't the author russian or something? some languages are quite blunt
I got feedback here on reddit a few times that people (who apparently do not use adblockers) were frustrated by the ads on the free wordpress site. I bought a basic subscription now to remove them, but if anyone has tips on how to migrate away from wordpress I'm very interested!
And none throws an exception?
I like how half of the comments made about each stage of the language ancestry are about how 'interesting' the bugs were that you could get given such-and-such design flaw (I know, not all were flaws).
Removed as off-topic. This is more of a r/programming question.
Does networking library never throw any exceptions? Not even `std::bad_alloc`?
Apologies I wanted the opinion of people who were proficient in c++ and low level performance which is why I didn't post it in r/programming. How should I have phrased the question better?
Like a bad sales pitch, which is what they are.
just dont use wordpress lmao hahah /s
There are proficient C++ programmers in r/programming too.
Isn't this the problem that the proposed `std::out_ptr` is trying to solve?
I'd like to migrate existing content and do as little damage to links as possible.
Install WordPress yourself on a web hosting package. E.g. strato (German hosting company) has built in WordPress "website make" one click and WordPress is installed. You can customise it. WITHh the right plugins you can also get auto update which would allow you to be always on the last version.
I am very excited about this
Why would someone even consider using a macro DESTRUCT_TEMPORARIES(body) when [&amp;]{ return (body); }() is already shorter and easier to read?
An oversimplification would be to think of it as Cpp is better for CPU bound programs, while Csharp and Java are better for I/O bound programs.
Yes, the author is russian
In everyday work I use three static analyzers: Clang Static Analyzer (CSA)/Clang Tidy, Cppcheck, PVS-Studio. And from them PVS-Studio is the most useful (but propritary and non-free). CSA/Tidy are worse but they are free and open-source (also at work we extend clang-tidy with our own checkers). The worst is cppcheck - cannot parse correctly our C++14 codebase and has a lot of false positives with lambdas
Well, the piece is in English, and I don't remember their earlier articles being like this.
The text from /u/tcanens link says: &gt; If the validity or meaning of the program depends on whether two constructs are equivalent, and they are functionally equivalent but not equivalent, the program is ill-formed, no diagnostic required. So the program is ill-formed. OK, that might not count as a "redefinition error", but the question and answer seem to very strong imply that the alternative is that the code is well-formed, especially the bit that says "Clang compiles this code ... it seems that Clang is right".
It's not working at class scope for good reasons, though, I'd still love to have it as well.
It's not working at class scope for good reasons, though, that doesn't mean I wouldn't like to have it, too.
A couple of months ago I was planning to pitch buying PVS, so I made a comparison between PVS and clang static analyzer on Linux (so we don't have the visual studio plugin), and the results were inconclusive. Neither of them had anything useful on our internal projects (medium sized, relatively well written), and on 3rd party projects (I chose ones with "awful" code, on purpose), clang analyzer seemed to be either slightly ahead or very close to PVS. &amp;#x200B; It's good to know your experience, and I will probably re-evaluate the results a couple months down the line, but the original criticism stands. The article doesn't give a good explanation of why clang-analyzer is inferior. Like, why is it troublesome to setup?
They have a lot more crashes and silent errors in my experience.
/r/cpp_questions
Such as?
Qt is probably the best C++ GUI framework - well documented, performant, cross-platform - unless you have specific requirements (such as needing a Windows feature not implemented in Qt).
For a school project they might want to check Qml instead of QtWidgets. If the project needs to be C++ only, then Widgtes are the only way.
Qt framework + QML
Your proposal involves changing the rules for billions of lines of existing code. Which seems far worse than the problem it is solving.
Do we still need Goto labels?
&gt; ... substantially moving C's lifetime and object model closer to C++ 20's. Could you expand on that, please, 'moving C closer to C++' does not sound like a great proposition [without the knowledge of what that implies].
Technically correct is the best kind of correct :) We didn't mean to imply that the code is well-formed.
I guess you can use the `operator()` instead of `operator[]`. It's not as nice, but at least you can have multiple arguments to `operator()`.
Qt with QML is very easy to use.
yes, it's OOP only.
The whole point of the "functionally equivalent but not equivalent" rule is that the implementation doesn't have to use heroic efforts to treat them as distinct. Of course, "redefinition error" is not standard terminology, so you can define it however you like and claim that the answer is correct according to your definition.
Fltk is probably going to be the easiest way to actually get a a fast and simple guy up and running. Juce isn't bas either. Qt requires a lot to get started and results in very large binaries, though for large programs it is an industry standard for a reason.
Thank you guys, I downloaded Qt! I will try and give you an update in the following days :)
Internal links or external? Because if you switch to another host, you don't own the domain `wordpress` -- meaning all external links will be different even with the same url path. Otherwise you could simply update your domain to point to a new host. But if you mean preserve links as in not breaking links in your blog to yourself -- that should be more achievable. Easier if the urls are defined as relative. You can test it by running wordpress locally as a local server. For long-term hosting I'd suggest using a regular host instead of yourself.
I've never used them but if you are going to break backwards compatibility there are way more features waiting to be changed/removed before goto labels.
Just use (or write your own) zip function? Then you can just use structured bindings in a for each loop thusly: for ( auto &amp;[v, n]: zip(verts, normals) ) {...} Or if you really want to use indices, just iterate down to 0: for ( auto i=min(verts.size(), normals.size()); i--; ) {...} // 'i --&gt; 0;' might be easier to remember Or up from 0: for ( auto i=0U, end=min(verts.size(), normals.size()); i&lt;end; ++i ) {...} Or use a for each loop with a counter: assert( normals.size() &gt;= verts.size() ); auto i {0U}; for ( auto &amp;v : verts ) { auto &amp;n = normals[i++]; // ... }
:D
Phrase "error: redefinition" happens a few times in the standard, for example here [http://eel.is/c++draft/temp.alias#2](http://eel.is/c++draft/temp.alias#2), and so I can not agree that "redefinition error" is not standard terminology. IMO the question "does this code contain a redefinition error?" is another wording for "are those two functions equivalent?", the former one is just more familiar for most of C++-programmers.
Whoa! Only the casing of the name is different? This sounds like "how to write unmaintainable code" directive
Came in here thinking you were proposing _literally XML_ for namespaces. Phew.
Hi Vinnie, I think you're talking about the Networking TS as published, and I was talking about the current plans for bringing it into the standard. For several years, I've been hearing folks from the subgroups say "before we standardize the Networking TS, we need to add the dual throwing/code APIs as in Filesystem" (and, more recently, also "... and we need to add executors") as a necessary addition for it to be considered ready for actual standardization in the IS. The Networking TS is considered great but incomplete in its current form. I'd be happy to hear about if it this has changed. But last I heard, the plan was still to imbue Networking with dual-mode error handling interfaces. This is why I said, I believe correctly, "we're *about to* do it again for Networking, if nothing changes." This statement also appears in my paper (P0709, see page 6), and until now nobody said that characterization was incorrect. Unless something has changed, which again I'd be glad about, this is the committee's intent for Networking right now.
That is not entirely accurate. Deprecation of the use of the comma operator inside square brackets is already on the table and possibly coming into C++20. A deprecation period is a necessity before repurposing the comma and provide a different syntax, which is being seriously considered.
Reference: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1161r2.html
"Exceptions are for exceptional situations" is not only vague, it's also sometimes impossible for the function where the error occur to know if it is an exceptional situation or not because it depends on the situation where the function is used. I might want to use `std::stoi` to try and convert a string to an integer and if that fails I want to use the string for something else. Since `std::stoi` uses exceptions I either have to accept that I'm using exceptions for control flow (with all the performance implications), or I have to somehow validate the string before passing it to `std::stoi`.
Because choosing actual keywords has a cost, and new keywords tend to use words that are themselves ugly to avoid clashing with identifiers used in the wild. And I guess that contextual keywords just add another problem to the long list of problems the committee has to evaluate whenever they want to standardize a new feature. The attributes model is good enough to implement contracts and to have nice attribute-specific keywords, so there was seldom any reason to try another method.
Better get started then. With all due respect to the great Dennis Ritchie, it may be time to start to get rid of some of the baggage that C++ inherited, and some of the pre-03 functionalities. It’s not just a matter of “just use the modern way”. They are heavily impacting the evolution of the language. And I still think that those square brackets are painful to watch.
Why a header? Put this in a source file. Once is enough.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/cpp_questions] [How can I create a simple GUI?](https://www.reddit.com/r/cpp_questions/comments/bj3wwr/how_can_i_create_a_simple_gui/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Not to take away from your work, but I'm curious what you see as the usecase for this library. The value is clear in python/R since we have an interactive interpreter to explore the data, but doing the same sort of work with a compile cycle sounds prohibitive.
Isn't that Howard Hinnant? If so hes been through a few silent moments in the past.
Good question and I addressed that in DataFrame doc under \`Motivations\` in more details. But basically the reason is performance and scalability. Python is great, but if you want for example to analysis financial intraday data for Options, you are dead in water
I would suggest putting someting in your README since many more people will be looking at that than your docs? &gt; financial intraday data for Options, you are dead in water Is this actually the case? I also work in finance, and I've worked on some pretty large timeseries in matlab (I'm sure numpy is similar in performance). Have you done some comparative benchmarks? I think adding some to your README would also be helpful.
I think they have value for specific part the libraries: for example the `audio` proposal switched from `std::audio::*` to `std::audio_*`. If you're writing functions that work purely with audio components, it would make sense to use `using namespace std::audio;` in them to cut some noise IMO, which only imports a small part of the library in the current, and can probably be done safely enough as long as you're writing implementation files.
Needs more [UBSAN](https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html) ;-)
Very interesting and useful approach with the `clang-query`. Indeed it's very time consuming until you get the grip of it. Thanks for sharing!
Wasn't \[\[expects\]\] and \[\[ensures\]\] changed into \[\[pre\]\] and \[\[post\]\]?
Good catch. Most people oft forget about `` operator --&gt; ``.
Have you looked at [Apache Arrow](https://arrow.apache.org/)? It is limited to data frames that fit in memory. If your use case requires out-of-core processing and this provides it (though "continuous memory storage" suggests it does not), maybe you could pitch this as a companion project and recruit some help. Otherwise, maybe you can consider exporting and importing Arrow frames, or even pivoting to a DSL that works on an Arrow backend.
I am familiar with Arrow somewhat. As I understand it Arrow was meant, from the beginning, to be "under-the-hood" for Pandas. It is not a coherent C++ object or even a library. I don't believe Arrow was designed for C++ programmers. It was designed to make Pandas more efficient for Python programmers.
Looks really neat. What are examples of applications ? Is it targetting a specific type of pipeline ?
Good Point. Matlab is a different story numpy is also pretty good. But you have to build your own library on top of that. DataFrame gives you a coherent frame work to do the analysis.
This post is more than 17 years old. A lot has happened since then, in particular, std::format ([wg21.link/p0645](https://wg21.link/p0645)).
Is it too much to wish for a package manager like cargo or npm?
I don't like that question about allowed error methodologies. For us exceptions are the preferred error propagation tool, but we wouldn't use them for relatively common error conditions in a high performance path. At the same time, I do not want to be counted as "use of exceptions is restricted" - that suggests we have some sort of fundamental problem with them, and will be used as evidence in articles throughout the next decade that "x% of C++ projects ban or restrict exceptions!" I mean, there are places where I wouldn't want to see an `int`, but that doesn't mean we have banned or restricted ints...
Conan Vcpkg
I interpreted it as using exceptions is fine where it makes sense, and not using exceptions in performance critical parts fits that category.
I was looking more at for when you are targeting known but different platforms at build time, not a runtime decision. So I can provide two different compile time optimized versions of my library or application pretty conveniently. Or, if I'm creating a bespoke application for my needs, I know what I have so I can build against the version of your library that works for me, but I always have the option of easily going the other way if need be. Maybe too specialized to be much of an argument in favor of the work involved.
It is a super-thin font, that is why it is gray. I agree it's a bad choice.
Hey, that would work: #include &lt;xyz.h&gt; #pragma xnsdecl ( &lt;?xml version="1.0"?&gt; &lt;!DOCTYPE cpp:nsdecl PUBLIC "urn:std.cpp.org:nsdecl "cppnsdecl.dtd"&gt; &lt;nsdecls&gt; &lt;decl name="bob" ns="bobslib::x86"/&gt; &lt;decl name="angrylib" ns="angrylib::hateutils"/&gt; &lt;/nsdecls&gt; ) main() { }
The link title is wrong - it is C++ survey, not C.
Wouldn't it be legal here because it's standard layout? https://timsong-cpp.github.io/cppwp/class.union#5 &gt; Note: One special guarantee is made in order to simplify the use of unions: If a standard-layout union contains several standard-layout structs that share a common initial sequence ([class.mem]), and if a non-static data member of an object of this standard-layout union type is active and is one of the standard-layout structs, it is permitted to inspect the common initial sequence of any of the standard-layout struct members; see [class.mem]. — end note
How would you Break out of a nested loop without an extra flag or directly returning then?
I do like Conan quite a bit but Conan is not as mainstream as pip or npm so not every package is as easy to add with Conan.
&gt; For us exceptions are the preferred error propagation tool, but we wouldn't use them for relatively common error conditions in a high performance path. I would speculate this is actually a very common approach.
Personally, I wish for a "standardized" package description format to be supported by multiple package managers.
I'm not saying that all warnings should be switched off, but nor do I agree that it is impossible for a compiler to implement a warning that doesn't help me. There are some warnings that are not about real problems, and this is one of them.
Depends on how you want to write your content. There are plenty of "importers" out there for static site generators (I personally use [Hugo](https://gohugo.io) which has [several wordpress importers](https://gohugo.io/tools/migrations/#wordpress), having had a stint with Nikola for a few years). There's also stuff like GitHub pages, which uses a limited subset of Jekyll. The hard part is getting all existing links to point to your new location/hosting. That might take more time than you might think.
IMHO, knowing in advance which ones will bite you and which won't requires more brainpower than just fixing them all and not letting any new ones in through CI.
XML++
Pandas is certainly the origin, but not the only intended user. Arrow is a specification for an in-memory format of tabular data. It has a [C++ implementation](https://arrow.apache.org/docs/cpp/overview.html) that can serve as the backend of a C++ data frame. I haven't worked with it, but I'm expecting it to have a barebones, user-unfriendly API. That's where a contributor like you could come in and add nice layer on top that makes this memory-efficient and optimized format developed by a team of experienced people easier to use by mere mortal C++ programmers.
Seems like a 'chicken and egg' problem.
I found the [http://www.stroustrup.com/C++11FAQ.html#auto](http://www.stroustrup.com/C++11FAQ.html#auto) very helpful, however, it is not perfectly structured. But it is exactly kinda of material you are asking about - it's designed to help users of C++ 2003 onboard C++11.
Thank you!
Yeah, that'd be ideal
Conan is neat, but I could never run a single project using it Always had to fall back to the good old manual linking / make sooner rather than later
Because they are attributes and that's the syntax for the attributes?
Thanks. It was developped for fun, not for a specific area. The motivation behind this is just that sometimes you can struggle to define a clear and modulable processing pipeline at compile-time. The string obfuscation example shows you could end up defining a set of pipelines with selection based on string properties.
I posted some ideas yesterday. With Conan Vcpkg + cmake evolution/replacement towards community based package management standard [https://github.com/Microsoft/vcpkg/issues/6233](https://github.com/Microsoft/vcpkg/issues/6233)
&gt; between mars and April Didn't know they write C++ there
This whole thread is about how fixing the warnings is hard.
You cannot use exceptions on the high performance path - that sounds like a fundamental problem with exceptions to me.
I recommend you pin this list to your browsers Bookmarks. Great list for sure. [https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list](https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) &amp;#x200B; A lot of the books here the defacto literature on c++ so you should be good on this right here. But in short, look into one of these books (pdf,epub,book, whatever) and just dig in.
I use cppcheck for a C++14 project and I have not found parsing errors, but I am not using variable template. However, when I did try PVS-Studio it seemed to confuse varidiac template with C varidiacs. In cppcheck, there was FPs with unused variables or values when using lambdas but that has been fixed on the newer version. Even more so, newer versions do a nice job of tracking lifetimes across lambda captures, for example: auto f() { int a = 1; auto f = [&amp;]() { return a; }; return [=]() { return f(); }; } On the latest cppcheck this will warn about returning a dangling lifetime: lamda.cpp:4:12: warning: Returning lambda that captures local variable 'a' that will be invalid when returning. [returnDanglingLifetime] return [=]() { return f(); }; ^ lamda.cpp:3:29: note: Lambda captures variable by reference here. auto f = [&amp;]() { return a; }; ^ lamda.cpp:4:27: note: Lambda captures variable by value here. return [=]() { return f(); }; ^ lamda.cpp:2:9: note: Variable created here. int a = 1; ^ lamda.cpp:4:12: note: Returning lambda that captures local variable 'a' that will be invalid when returning. return [=]() { return f(); }; ^ I haven't seen other static analysis tools warn for such scenarios. I do believe `-Wlifetime` in clang is supposed to warn about this case but I haven't tried it.
The current draft of Networking TS has dual APIs. And there is the usual grumbling and muttering about "fixing" it (which, apologies if incorrect but I assume that your presentation falls into that category). I'm not against fixing it of course, as I am also constantly irritated by the need to maintain not only an extra set of function signatures but the documentation that must accompany it. I very much like the idea of throwing cheaper exceptions as you described. However, I have not yet seen a proposal which recognizes that networking's function signatures permit partial success. For example, a read operation may complete with an "end of file" error, and yet also return a non-zero number of bytes transacted. I could not find a mention of solving this in the presentation, perhaps I wasn't paying close enough attention (very possible)?
I've come across this a lot too. Another issue with static\_assert() is it will bypass any code coverage calculations that you perform, so your coverage report will be a bit pessimistic. So, normally what I'll do is have one traditional assert and a bunch of static\_asserts. If you have test macros, like in gtest, you could also think about making new ones that generate both the static\_assert() and the traditional runtime assert.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bj7ske/name_structure/em60kar/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Started using conan for newer projects at work, we have a jfrog artifactory... Works great, though some oss projects are still not cmake transparent, e.g. if I use conan the targets names are different e.g. Poco::Utils vs CONAN_PKG::PocoUtils... Though they are changing this step by step e.g. boost
Thanks a bunch! That is a really nice presentation!
Some notes from today's WG14 discussion of my detach and attach operations proposal: If I understood today's discussion correctly, in the current C standard, objects stored in static, thread-local and temporary storage durations have the effective type of their declared storage. Objects stored in dynamic storage duration have no declared type, and thus get a more fluid effective type interpretation that non-dynamically stored types (basically however you choose to speak to allocated storage determines its effective type at the point of use). As my detach and attach operations use a stack allocated temporary, the effective type of whatever the source object is is coerced to the type of the stack allocated temporary by the `memmove()`. When we then `memmove()` the stack allocated temporary back over the input type's storage, and return a reference to that storage, the returned storage has fully assumed the effective type of the cast's destination type. If the input was stored in dynamically allocated memory, as it has no declared type, no lifetime could end nor begin anyway with detach or attach. Under the current C standard, only `free()` (and maybe `realloc()`) ends the lifetime of the objects therein. `memcpy()` or ``memmove() into `malloc()`ed storage does NOT end the lifetime of the objects therein, only `free()``/realloc()` can do that for `malloc()`ed storage. If the input was stored in static, thread-local or temporary storage, under detach and attach the lifetime of the input object is ended by the `memmove()` back over that storage from the stack allocated temporary. The compiler knows that the input object cannot alias the output object. So, the conclusion of WG14 to my paper is that under the current C standard wording, my detach and attach operations as proposed work just fine. No issue. Greenlit. (As an aside, it seems to me that under these rules, implementations must assume that pointers of unknown provenance must be to dynamically allocated memory, and therefore never can become indeterminate without a `realloc()` or `free()` being called. Only pointers with provable provenance to a static, thread-local or temporary object can become indeterminate due to a `memcpy()` or `memmove()` over the target of those pointers. This is quite a severe difference between C and C++, and let us hope that some reconciliation of that gap occurs soon)
I think that we should try indeed to improve cmake and cmake packaging support instead of inventing yet another standard...
Always read these blogs even if you are not into graphics libraries Some great basic core structures (lib Corrada) and generally good C++ tips all backed up by measurements. Not blindly following 'STL is wonderful' or so cynical that 'I work in games so cannot ever use the STL'. I nice balanced view.
Not too bad for beginner. Programming C++ since 1989 here: Object oriented errors: Reconsider naming: image.h -&gt; bmp24.h Object.verb so, not img.flip_image() but img.flip() C++,C,asm errors: struct_size() wrong, depends on struct packing and int size sizeof(bitmap_information_header) a bit better. If learning C++, please do not do it with microsoft windows API, it only makes it much more complicated.
This and Annex K were the biggest reason why there were so few C99 compilers.
The closest thing to a flexible array member in C++ that I can thing of is something like this: template &lt;size_t N&gt; struct with_fam { int initial_member; std::array&lt;int, N&gt; fam; };
You've typoed "High" and "platforms". Removed as spam.
STL *is* wonderful.
 \*\*Company:\*\* [Woods Hole Oceanographic Institution](https://careers.whoi.edu/opportunities/view-all-openings/engineering/) \*\*Type:\*\* Full time \*\*Description:\*\* Looking for adventure and challenge in your career? How about designing software to work while submerged at 10,000 psi or fixing your mistakes in the dark on a moving ship north of the Arctic Circle? Want to work on cutting edge underwater robots for both scientific and military applications? The Oceanographic Systems Lab at Woods Hole Oceanographic Institution is a world leader in autonomous underwater vehicle (AUV) technology. This position is a software development role in marine robotics with field testing responsibilities. The successful candidate will have strong C++ development skills, with excellent software engineering habits, and a solid background in software testing. This position works creatively and independently to establish objectives, meet deadlines, and complete difficult engineering assignments by demonstrating full competency in one or more engineering areas; assists substantively in planning technical aspects of experiments, as well as design, testing, and use of major system components, with little supervision. \*\*Location:\*\* [Woods Hole, Massachusetts](https://goo.gl/maps/s1JoovHAjEcaGBzQ7) \*\*Remote:\*\* presence on site required. \*\*Visa Sponsorship:\*\* U. S. Citizenship required for this position. need to be able to obtain a U.S. D.o.D. Security Clearance. \*\*Technologies:\*\* C++98/03 in VxWorks. C++11 in Visual Studio 2012. \*\*Contact:\*\* Apply on our [site](https://careers.whoi.edu/opportunities/view-all-openings/engineering/), look for opportunity opportunity "Engineer II / Research Engineer - Software (19-03-04)"
I'm not a native english speaker. This is not a spam.
It's not a package manager, but recently I've been using Bazel and it's fantastic. It's helped getting projects with several dependencies up and running. The biggest problem is not a lot of libraries have bazel build files. I've been slowly converting libraries I like to use them.
thank you for your support and cooperation
&gt;Bazel Didn't know that one, looks interesting
I think it would be cool if they added endianness support using std::byte. It’s not hard to implement, it just would be a nice add-on.
https://www.youtube.com/watch?v=k99_qbB2FvM
that's cool
What would be cool is branching. Like, having the input split up, and have parallel paths. (That would basically implement Haskells \`Arrow\` AFAIK)
I hear what you are saying. But I don't see Arrow as any kind of gold standard. I think DataFrame being self contained, allowing any built-in or user define type, and having built-in multithreading has its own advantages.
Following up to https://www.reddit.com/r/cpp/comments/bid4zh/yet_another_json_parser_this_time_constexpr_and/. This is a tool I use to generate C++ classes, along with optionally the library code from the previous posting. It takes a json class or array and uses the type information in the data to generate C++ classes. It also accounts for escapes and identifiers that cannot go into C++. I have found it quite useful building interop code with web services that either don't have a defined structure and I have to guess from lots of data what could be there.
You've posted literal stars instead of bold text. (I've seen other employers do this and I'm not sure what you're doing; using RES or something to access my original Markdown? In the guide, I use backslash-star backslash-star to escape the stars like \*\*this\*\*; the intention is for employer posts to say star star to get **bold**.)
Annex K is C11, which is Microsoft.... which is also a stdlib problem...
Thanks! Will fix.
Thank you, I really appreciate that :)
Yes you are. I also make sure I don't miss your posts either.
Fixed now. The issue was that I cut and pasted your template into the editor in my browser, and didn’t double-check the formatting characters. Thanks again for your help.
Annex K is optional in C11. It was required in C99.
It wasn't even availible in C99, can you read? http://www.open-std.org/jtc1/sc22/WG14/www/docs/n1256.pdf No Annex K, no mention of any of the library functions, wikipedia disagrees with you, standard draft disagrees with you, C11 proposals disagree with you, do you need more?
 I stand corrected. I must have just lumped the complaints about it int o the same part of my brain as the complaints about VLAs.
FYI, I see Location and below as fixed, but not Company/Type/Description.
In (non-normative) examples. There's no precise definition of what is a "redefinition error", so everyone can make up whatever they like so as long as it encompasses the few usages in the standard. Again, the point of the rule is that an implementation is not required to treat these declarations as declaring distinct entities, so that it does not have to preserve and compare the exact token sequence used in stuff like template&lt;int I&gt; class A{}; template&lt;int I&gt; void f(A&lt;I&gt;) {} template&lt;int I&gt; void f(A&lt;(I)&gt;) {} template&lt;int I&gt; void f(A&lt;(I) + 0&gt;) {} template&lt;int I&gt; void f(A&lt;(I) + (0)&gt;) {} And an implementation that considers them to declare the same entity is of course going to emit what is colloquially called a "redefinition error". Claiming that it's not one is misleading at best: the IFNDR means that your program is entirely meaningless if you need to ask that question.
Thanks for the help.
I mean, that's all fine, but wouldn't it be nice if the obvious thing just worked?
Are you expecting to send more that just a couple of values? in my experience human readable interchange formats have a huge benefit (debugability) as long as efficiency and throughput are not significant factors.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bjanxi/how_would_you_overload_a_function_to_accept_an/em6ramp/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Or maybe Cpaml?
Ah yea there’s also BUCK, that’s very similar. I love it.
Should I ever had done that at university, I would not have passed the exam.
The best way to convert C++ to WebAssembly is encapsulate all your c++ code in a library and only expose the functionality using a public header. Then write wasm wrapper function which will only use the public header to expose those functionality to javascript. I have done once converting a c++ library to wasm and used it in my project. https://github.com/rlottie/rlottie.github.io
Just curious, why?
To my knowledge the point of std::byte is to only allow bitwise operations since the point is to only hold data. std::byte is basically uint8_t. If they also add it so there were other byte containers that could hold the same amount of data as uint16_t, uint32_t and uint64_t they could then add endianness support to those. That way you wouldn’t have to write your own, use a 3rd-party library or rely on POSIX C to do the conversion while also supporting the idea of std::byte. I know that was a long explanation, but I thought telling you my thought process would make it easier for me to explain.
Yeah I think Magnum is really leading the way in terms of the modern game engine.... Ya know what would really float my boat? Magnum's renderer replacing Godots.
I've enjoyed vcpkg so far but it still shows signs of immaturity in particular areas.
“Effective Modern C++” by Scott Meyers is really great.
struct_size() is probably right, just named wrong. It should be called header_size(), and is independent of packing - it is the size of the header written to file, not necessarily the size in memory. This is actually a case where it might be best to use std::uint16_t and things like that, or define your own. While I'm here: - first of all, I don't mean to discourage you. It is mostly decent code. Here's just some points if you want to improve: - please don't do "using namespace std" inside a header. Not all users of your code will want that bleeding into there code when they include your header. - imagine that you keep adding more image functions - do they all go into the class? Where does it end? It would be better to have all of those functions live outside of the class. This article from Scott Meyers is old, but still valid: http://www.drdobbs.com/cpp/how-non-member-functions-improve-encapsu/184401197 - In fact, an image class probably shouldn't read and write to files either - that could also be outside the class. Imagine adding different file types - png, gif, ... The class would be huge! The image class should have just one job - take care of the pixels. ie tell me how many pixels, width, height, bits per pixel, etc, and allocate/free the pixels at the right time. - operator bool() should be `const` and `explicit`. `operator!()` should also be const. One should call the other. ie `operator!()` could just be `return !bool(*this);` -greyscale should probably use a different weighting of r/g/b, as our eyes see green better than red and blue. ie take a look at RGB to YUV conversion. You probably want the Y in YUV, which will give a greyscale similar to a black and white TV. - BW_image - I _think_ `sum` could overflow on a large white image? - merge_image should probably be called average_image? - flip_image shows an example of an interesting general rule: when you have a function that is completely split by a single if-else, you really have two separate functions. Write a flip_horz and a flip_vert, then, if you really want, write a flip_image that calls the other ones. I notice you already have separate mirror_... functions - that looks better to me. - rotate_image - You have done a lot of work on all this code. I have confidence you could figure out how to rotate 270 degrees without rotating by 90 three times. - I don't think shrink_image really works. You are also writing to the same destination pixel multiple times. For image processing, it is often better to write your loops from the point of view of the destination, not the source. ie for-each-destination-pixel do ... For shrink, at each destination pixel, map the location back to what source pixels do you want to average together to make that destination pixel. - I don't know what q() does. Might want to add a comment. Even for yourself in the future, when you look back and don't remember what it does. (I'm a bit unsure what shuffle really does as well) lastly, __H__IMAGE__ is not a good header guard name - double-underscores are reserved to be used by the compiler and its headers, not user code. I personally like the pattern image_h_INCLUDED - ie filename, with exact case of the filename (which should match the class name) and then add _INCLUDED in all-caps. It is very ugly, but that's why it works (ie doesn't collide with anything else).
Here's my response - Recent standards updates have focused on experienced programmers and library authors, making their life better. There are some simple quality of life additions to std that would make development a lot better for new programmers - a matrix class (akin to what Bjarne has in his red and white books) since all options right now for making and using 2D arrays are not good for newbies. Having a bignum class in std would be really nice as well, since GMP and Boost::Multiprecision are not easy for newbies to use either. It's a pipe dream, but I'd love to make use of C-style arrays deprecated by default, since it remains an ongoing source of bugs and exploits. Or at least have some language mechanism where C++ will generate safe (bounds checked) code by default with fast (unchecked) code requiring some work. Newbies get bitten by this all the time. Experienced programmers know about ASAN and UBSAN but the people who most need it don't know about it or use it unless their professors secretly enable it for them.
Great. Today, I was thinking that there should be a data.frame library such that all scripting languages like python, R, julia can utilize. Particularly I was thinking about data.table in R -- which is the best data.frame library in my view. &amp;#x200B; The main strength of pandas and data.table are their abilities to carry out many complex operations, such as join, group-by, aggregate, etc. Any thoughts on your library as of now?
I believe sooner or later, c++ will have a decent repl.
You [or most people] probably want 32- instead of 24-bit bitmaps, though. The additional bits is the alpha-value, i.e. the level of transparency. Not all formats support that, but f.e. PNG does, while JPG doesn't. For games transparency is crucial.
Thanks for plagiarizing my code and calling it your own. https://github.com/ArashPartow/bitmap/blob/master/bitmap_image.hpp
The best operator.
What would be the fun in that?
in fairness, he added more bugs
lol :D
lol :D
&gt; This is quite a severe difference between C and C++, and let us hope that some reconciliation of that gap occurs soon) ... If you mean to make C more C++-like, no thanks.
I've always found yarn to work a lot better than npm...
I like to use a combination of either: ---- (Linux): Konsole, Tmux, GCC (or Clang), Makefile, NeoVim, GDB, GDB-dashboard + various Tmux and Vim plugins ---- (A bit more cross-platform): Clang, Sublime Text 3, Makefile, GDB, SublimeGDB, LSP + clangd, clang-tidy, Origami, GitSavvy, GitGutter etc. With this one I get linting, full debug integration, full git integration, static analysis, intelligent code completion, in-line error messages and commits, one key press building, etc. So far it has worked great.
Yeah, I suppose this is c++ we're talking about after all.
`_t` is reserved for POSIX, don't use it.
We do it in my company: a lightweight HTTP server using a a CGI-like interface for C++ on the back-end, and it serves static pages that run Javascript (via React) to provide a "app"-like UI for a small Linux device. ("small" isn't so small. In the scale of a home router or an IoT device with megabytes of RAM)
Screw CEGUI in its retarded, squandered potential, tragically unusable, dumb fucking ass. Three fucking weeks on trying to get a simple widget to work, and nothing. Fuck this piece of shit. Fuck it. If you use CEGUI then I pity you. Your GUI cannot be sophisticated in any shape. It can only be pure and utter arse. &amp;#x200B; There is goodness in there, but just because there's some corn in some poop doesn't mean I want to eat shit just to enjoy the taste of some good maize. Avoid at all costs. Don't get invested. Curse this trashfire every day as your prayer and your life will remain, at the very least, as it is. Fail to heed my warning and your life will become worse, and never better.
For creating the package or consuming it? I came across [Common Package Specification (CPS)](https://mwoehlke.github.io/cps/) for package consumption a while ago which looked promising. Sadly it also looks abandoned.
So you'd rather force all people to write `std::filesystem_path` or at least `filesystem_path` in they import `std`? Seems horrible.
Thanks for posting, i had made it and hope it helps to deliver a better C++ in the future
My current favourite line of code is `namespace std { using namespace std::chrono; };` at the top of every source file which uses chrono. Would be nice if I could write `using namespace std += std::chrono;` inside my own namespace so that I could write it once in a utils header file.
I'm a bit annoyed, that he just ignored cget. Cget does in no way work like vcpkg and the big advantage it has is, that it works with any project, without needing specific packaging, as most things are already described by the build system!
That's not even plagiarism at this point. Just literal downgrade.
Even better, put the generated classes into a configurable namespace.
just because a bunch of people sitting in a committee in 1986 said "all your name ending in `_t` are belong to us" does not mean that we all have to accept their dictatorship.
Looks good now. I’ll use my mod powers to remove this comment chain so it doesn’t clutter up your post.
Matrix is proposed as part of linear algebra. C arrays: yes. I think the first step would be removing automatic conversion to pointers and make arrays passed by value by default as any other value type.
Wow, I can't believe that's the first I've heard of that. It's also incredibly stupid that such a blanket ban exists, and shows how useful/important C++ namespaces are. If I wrote pure C I think I'd still ignore the restriction and hope that application prefixes (i.e. simulated namespaces) are enough to avoid the clash i.e. `myproj_mytype_t`. In C++ this is all academic, because using _t is an anti-pattern anyway. The almost universal convention is to use TitleCase for type names and camelCase for other identifiers, so there's no need for _t. The main exception is the C++ standard library, which uses snake_case for both types and identifiers, but it did that exactly because title case is so common that by using snake case they reduce the risk of a clash. It certainly doesn't use _t (e.g. there's no `std::vector_t&lt;std::string_t&gt;`), although it occasionally uses `_type` when there's ambiguity (e.g. `std::vector&lt;int&gt;::value_type` but not `std::vector&lt;int&gt;::iterator_type` or `std::vector_type&lt;int&gt;`).
`using namespace std;` was added in the library header. Nice.
If it helps, we’re getting std::endian in C++20, and if I can fix a missing line about undefined behavior and make it to Cologne, we’ll have a std::byteswap function. While that doesn’t solve your problem per-se, it does mean that the building blocks to implement an emulation of an endian integer type would be possible.
glad that you enjoyed!
Thanks, I wish I can update it when GCC supports coroutine.
I agree ! Do you think branching with multiple input single output filters would be enough ? Runtime example: filter_branch_a-&gt;set_input (filter_main_branch-&gt;get_output()), idem for branch b, c... and then branches merge. Or there would be a need for multiple output filters as well? Runtime example: filter_branch_a-&gt;set_input (filter_main_branch-&gt;get_output(port0)), filter_branch_b-&gt;set_input (filter_main_branch-&gt;get_output(port1)),...
Who the F said that Title and cameCase is the 'universal convention'? Boost certainly doesn't follow your 'universe' and no standard rule backs that claim. Only _This and __this are reserved conventions.
Almost universal convention not used by the standard library, boost and a plethora of other code, that is...
Yes, and I published the code there: [https://github.com/Orphis/RandoBlazer](https://github.com/Orphis/RandoBlazer) Do you have any actual questions though?
Going in the same way. Researched the internet a lot. Can find a summary here: [https://github.com/VisheshPatel/CPP\_Templates/blob/master/Master%20The%20C%2B%2B.md](https://github.com/VisheshPatel/CPP_Templates/blob/master/Master%20The%20C%2B%2B.md)
you might want to look at [bitsery](https://github.com/fraillt/bitsery). It is speed and size oriented and easily customizable. Also very suitable for embedded development.
You are not wrong. But, POSIX took a lot of good identifiers. Also, that isn't part of the C++ standard(to my knowledge). For instance any identifier that begins with to[a-z] or in[a-z] is reserved too. Along with a bunch more. POSIX is kind of being greedy.
How does this compare to [xframe](https://github.com/QuantStack/xframe)?
I agree with all your points. Please see the DataFrame doc under "Motivation". I explain in some detail why I thought this was a good idea. &amp;#x200B; Re/ join and groupby, etc., they are implemented in DataFrame
Xframe is also a good implementation. I have a star there. You tell me how it compares with xframe. The things I like about DataFrame vs. xframe: 1. It is completely self-contained. xframe depends on two other libraries. 2. DataFrame has better support to include all built-in and user define types 3. It has built-in multithreading 4. It is more easily extendible by user than xframe. Just put your algorithm inside a simple functor and you have extended DataFrame 5. DataFrame has a much simpler interface, more similar to Pandas
That's still a good start, and the sort of thing the standard committee (or *a* standard committee) could actually standardize.
r/cpp_questions is the right place to ask these questions. I suggest to delete this thread and open another one in the sub above.
hi am heap with the variables
Actually what i thought of first was to do this: class st; st. printAge{} but its not working
Is that satire?
You should use round brackets to call member functions instead of curly braces. But also, what u/famastefano said.
Hi heap, I'm stack!
let me try en see .
The short answer is no, you can’t make one file that works in both Linux and Windows. The file formats are different, but the runtime libraries and the kernel calls those runtimes depend on are also different. You have to build two libraries and as little as possible, use the preprocessor to handle platform specific stuff like declspec(dllexport).
I guess by making common portable layer .dll/.so it's possible to harmonize API's - then we will still have potential double compilation, but amount of compilation will be minimized.
Don't use it is not a valid suggestion. "do not use it if you want to be POSIX compliant" is a better one. In 2019 you probably don't need POSIX compliance.
[removed]
[removed]
Are you planning to add support for generate pkg-config files?
For consumption it’s not really needed since there are only two formats and build systems should be updated to auto-generate them. What’s missing is a format of what dependencies are needed that multiple package managers can use.
That’s because conan doesn’t install Poco correctly.
API's can be identical, ABI's however, are platform specific. If this really is a problem for you, then you're looking for a VM such as dotnet or the JVM.
If you try to safe compilation - C++ is not for you. In other words, you can compile dll/so with same compiler (gcc) with same options but you will not get different code. You can see in Wine code about how to load a dll, but most of all compilation is way easy to do.
[removed]
Cross linkage is something that's really hard to achieve because some c++ features (like thread_local) can be implemented in different ways depending on the os and if I remember correctly the clang linker (lld) which is cross platform is implemented differently for windows and Linux obj files. there for you'll probably have to still use different build systems for the two operating systems and maybe use mingw (gcc for windows) for windows compilations
It does use _t for type aliases (e.g. std::uint32_t or std::add_const_t)
I think Nix has the right model for solving the package manager problem. For the lucky people working only on Linux/Unix I'd suggest to really have a look at it. We did and although it looks intimidating it really have the capacity to solve many problems.
[removed]
&gt; Who the F said that Title and cameCase is the 'universal convention'? I described it as an "*almost* universal convention". Even that's maybe exaggerating it a little, but it's certainly more common than sticking `_t` on the end (unless it's a pure C library, where the `snake_case_t` convention is common). &gt; Boost certainly doesn't follow your 'universe' That's because it's following the standard library (which a lot of Boost types migrate to), which in turn I already explained in my comment: it's deliberately different from the usual convention. If you don't believe me, it's mentioned in [Stroustup's C++ FAQ](http://www.stroustrup.com/bs_faq2.html#Hungarian): &gt; Use an initial capital letter for types (e.g., Square and Graph). The C++ language and standard library don't use capital letters, so it's int rather than Int and string rather than String. That way, you can recognize the standard types. Of course, you don't have to use the convention that Stroustrup recommends, but it does explain why the standard library doesn't follow that convention.
The inttypes.h typedefs are inherited from C (specifically C99). The template typedefs are more interesting, I hadn't thought of that. Note that e.g. `std::add_const&lt;T&gt;` was added in C++11, but `std::add_const_t&lt;T&gt;` (`= std::add_const&lt;T&gt;::type`) wasn't added to C++14 (I suspect because it wasn't confirmed that alias declarations would be in C++11 until it was too late to use them in the standard library). I imagine that if both were added at once, the typedef would simply be `std::add_const&lt;T&gt;` and the struct would be called something else, like `std::add_const_impl&lt;T&gt;`. But that's just my speculation.
Yes, the PVS-Studio project is developed in Russia. All articles are published in Russian and English.
I already gave the reason for this in the same comment you're replying to: to deliberately be different from the usual convention. Here is what I said in my sibling comment: &gt; It's mentioned in [Stroustup's C++ FAQ](http://www.stroustrup.com/bs_faq2.html#Hungarian): &gt;&gt; Use an initial capital letter for types (e.g., Square and Graph). The C++ language and standard library don't use capital letters, so it's int rather than Int and string rather than String. That way, you can recognize the standard types. &gt; Of course, you don't have to use the convention that Stroustrup recommends, but it does explain why the standard library doesn't follow that convention.
I'm aware of .net core / dotnet, and I guess they have achieved something similar for C#, but I would like to focus only on C++. &amp;#x200B; [https://stackoverflow.com/questions/6478788/running-linux-gcc-compiled-program-under-windows](https://stackoverflow.com/questions/6478788/running-linux-gcc-compiled-program-under-windows) =&gt; [https://github.com/wishstudio/flinux](https://github.com/wishstudio/flinux) &amp;#x200B; Allows to run arch linux binaries on windows, but seems to support only 32-bit archlinux, not 64-bit ubuntu linux.
They achieve this by using the Boehm VM. At which point you might consider any other type of VM such as qemu of virtualbox/vmware as well, or WINE even. However, portable this is not, it is simply adding in a translation layer.
[removed]
I plan to use a template of sorts for the codegen. Getting the flattened AST with the approximate structures is the hard part. Using a template this problem will just become use whatever style you want
Can you support other json containers besides daw? I prefer nlohmann::json and I think your generated code would actually be cleaner with it.
It is impossible to convert a compiled DLL from Windows to SO shared object, even if you manage to do it, let's say a DLL foo.dll to [foo.s](https://foo.so)o (Shared object from UNIX/Linux and BSD). It is not going to work because Linux and Windows have different operating systems APIs and different system calls. You can cross compile your code to a DLL for Windows from Linux. Howerver, you will not be able to test it due to the motive I have stated, unless you use wine, but even in this case you will have to use Windows. &amp;#x200B; &gt;11.18 I have problems porting my Windows application to Linux because the Gnu compiler has a more strict syntax. Can I convert the compiled Windows code instead? While you are trying to solve a small problem you are creating a much bigger problem instead. There are so many compatibility problems when converting compiler-generated code that this method is unlikely to work. Try to use a compiler that supports both operating systems, such as Gnu or Intel. You could try to run the code with Wine, or try to modify to make it work with wine that parses PE32 which is the binary format of Windows object-code, executables and DLLs and translates the Windows API calls to Linux API calls.
I believe it is the biggest thing holding c++ back these days. That and an easy to use static analysis library. I am working on a prototype now to see if modules can be used to solve the inherent issues with distributing c++ code as source packages. Seems to look promising so far!
Posix is a C API. It doesn't know anything about C++ namespaces (and if it wanted to in future, the namespace `posix` is [reserved for that purpose](http://eel.is/c++draft/namespace.posix) in the C++ standard). So by all means avoid `_t` names in the global namespace if you want to be pedantically Posix-compatible (and I hope you're also avoiding any identifiers beginning with `E` followed by any capital letter or number, any identifier beginning `to` or `str` followed by a lower-case letter, and the myriad other things Posix reserves for itself). But within your own namespaces, you should be fine.
Add labelled breaks to the language, like Java. Alternatively, throw an exception, although there are obvious reasons that isn't as good.
I'd like to see the same comparison with [Doctest](https://github.com/onqtam/doctest) added in, since it seems very similar.
WWasn't it `is[a-z]` for `&lt;ctype.h&gt;`?
&gt; Strided views and strict aliasing: Im­por­tant thing to note is that nei­ther Con­tain­ers::StridedAr­rayView nor std::mdspan can be im­ple­ment­ed clean­ly with­out hit­ting any un­de­fined be­hav­ior [...] Can someone breifly explain? I don't understand exactly why/where? Even the author of the linked stackoverflow thread himself does [reply](https://stackoverflow.com/questions/49665881/mdspan-and-the-strict-aliasing-rule/50364568#50364568) that he was wrong himself
(Happy to be proven wrong about this.) In my implementation (and I assume the proposed `std::mdspan` as well), getting an element out of the strided view involves: 1. taking the base address (which is stored as `void*` so I can have the constructor `constexpr`) 2. `static_cast`ing that to `char*` so I can do pointer arithmetic, then adding the calculated byte offset to that 3. `reinterpret_cast`ing the calculated address to `T*` If I understand correctly, this sequence of operations is UB, the same as reinterpreting `float*`s to `int*`s and similar.
you don't have to output the interop code, just the C++ structures. But I thought that nlohmann::json was more of a variant tree parsing or a SAX eventing of json data? My is more a direct parsing to C++ data structures without any variants in between. I am thinking yes though.
As the author notes, this is a big win for the community. Write your tests using the googletest 'API' and choose which feature set to use and plug in utest or jctest and for more advanced cases the actual googletest framework. Nice write up and very interesting that the runtime performance of utest is so much better than either of the other options.
I've recently switched from catch2 to doctest, and color times are much much faster.
What kind of music do you guys play?
Ah thanks, I didn't know void* was used. I'm not qualified enough to say this with absolute confidence, but I still think you are fine. Since your original type was of T* it's not an aliasing problem. And char* is a valid alias. Afaik it's even save to reinterpret_cast this to any type, as long as you don't dereference it. The only issue is probably the pointer arithmetic on char* . It's so easy to achieve UB here.
If there's really a `T` at the address used in step 3 then there's no UB there.
you are correct, yeah I didn't remember correctly. http://pubs.opengroup.org/onlinepubs/9699919799/functions/V2_chap02.html
&gt;ABI's however, are platform specific (and with C++, even compiler version specific) Hmm.. [https://clang.llvm.org/docs/MSVCCompatibility.html](https://clang.llvm.org/docs/MSVCCompatibility.html) &amp;#x200B; clang seems to be on some level with Visual studio compatible. Wondering now also whether it's possible to use \` -fms-compatibility \`-flag also on linux to compile shared objects.
Do I read correctly that your actual goal is to have a portable codebase, and you see "making an .so from a dll" as a way to achieve it? And you currently compile and run on Windows and gcc balks at your code because it is strict?
Do you know where those differences are located in source codes ? clang or some ported application ?
I think the problem is not conan but the way poco was packaged
It could be also vice versa - compile windows compatible elf binary code instead of normal pe/coff. Must have only one compilation for x64 platform binary ABI compatible with windows and linux, can have multiple conversions if necessary or loader. But code must be debuggable from Visual studio at least, if you want recommend me better IDE or debugger, would like to hear it as well.
&gt; So I did some digging, and it looks like utest.h is so much faster because, and you could probably have guessed this, I avoided any C++. To handle test cases in utest.h I didn’t have the ability to use classes to define the test case, and thus I had to resort to functions and taking pointers-to-functions to handle the test case registration. Both jctest and googletest resort to defining classes with virtual members (mostly as a way to handle test case fixtures), but this means there is inherently extra bloat because of C++. So he wrote a C unit test framework and not a C++ one. I would bet that there is at least one memory leak in there.
&gt; as long as construction took place at that address before the type was discarded That's the thing, it didn't have to. A valid use of the strided array view is to construct types via placement-new in uninitialized memory. From what I understand, that's what [P0593](http://open-std.org/JTC1/SC22/WG21/docs/papers/2018/p0593r2.html) (linked in the SO comments) aims to be fixing. However, apart from "violating the language laws", in practice and with current compiler implementations I don't expect this workflow to be problematic.
I don't think that flag does anything or even works on Linux. I think what you're trying to do is kind of pointless. Not trying to be rude but just get over it and compile it for two platforms. Using the same or different compilers, it doesn't matter - but the target platform (and output executable/library) will be different. Building with different compilers / for different platforms is good, different compilers spot different bugs / problems with use of C++ standard. An importantly: Set up CI for all platforms so you don't have to build "manually".
That would be a valid criticism, if we had better tools available. The simple fact is this: we don't. And no, "herb-ceptions" ain't it either. Checking return codes after every function call, whether you do it or the compiler does it for you, is overhead.
&gt; It certainly doesn't use _t There are [`enable_if_t`](https://en.cppreference.com/w/cpp/types/enable_if) and a bunch of other helper aliases that use `_t` to extract `::type`.
You did not answer my question. Are you making a protable codebase? Or your goal is to invest a year or two in making a portable plugin that can plug into an SO or a DLL? Compile once, run anywhere. WebAssembly or maybe even Java. If this is your true goal, you chose a wrong audience to ask. Visual studio connects to Linux targets just fine. You can compile with gcc or clang, either does.
\*\*Company:\*\* [Moody's Analytics - GGY - AXIS](https://www.ggy.com/) \*\*Type:\*\* Full time \*\*Description:\*\* [The full posting can be found here.](https://www.ggy.com/Staff/Software-Engineer) \*\*AXIS is a comprehensive actuarial modeling system\*\* for life insurance companies that provides a complete and seamless integration of pricing, valuation and modeling. The \*\*Software Engineer\*\* is part of an actuarial team, working with actuarial programmers to build new features in a high-performance computing application. You will also be responsible for assisting with ongoing maintenance of the code and assisting internal clients with issues related to AXIS. \*\*Location:\*\* [Toronto, Canada.](https://goo.gl/maps/a2uN33WinUta7W5A8) \*\*Remote:\*\* No. \*\*Visa Sponsorship:\*\* Not at this time. \*\*Technologies:\*\* Our code base has been recently transitioned to compile under C++17, but much of it is still C++11 and older. We are a Windows product working with Visual Studio. Our application has largely been built upon the MFC framework. \*\*Contact:\*\* Applications should be sent to [our Technical Resumes inbox](mailto:MA_GGY_TechResumes@moodys.com). Recent graduates are required to supply their transcripts.
Are the YAGBS. Yet Another Google Build System.
tl;dw?
Date is a marvel. it is beautiful. Now if only we could get the second literal suffix to be s because we are all capable of distinguishing between a string and integer literal. But date is awesome and with full implementor support the curl/timezone stuff will be even better.
In OpenLoco and OpenRCT2 we took the original PE32 binary, linked it into our x86 ELF binary as a section with fixed VMA, provided some shims for platform interaction and it worked fine. This is a similar concept to what wine and some other projects do as well, e.g. thyme.
**Company:** [CoreLogic](https://www.corelogic.com/) **Type:** Full time **Description:** The group the position is for, is a part of our Science and Analytics team, focusing on building catastrophe models (for Hurricanes, Earthquakes, Flood, Wildfire, etc.). Some more information about our group [here](https://www.corelogic.com/solutions/catastrophe-risk-management.aspx). As a member of CoreLogic’s Science and Analytics Catastrophe Risk Modeling Engineering team the candidate will participate in the design, development, coding, testing, debugging, deployment and maintenance of distributed catastrophe models. This work will require the candidate to work closely with scientists/modelers to create new models using a variety of techniques. The candidate will be responsible for the implementation and integration of catastrophe and analytic models with solution platforms and backend databases. The candidate responsibilities may include leading teams using agile methodology. Please see full details on the application/contact pages below. **Location:** [Oakland, CA](https://goo.gl/maps/m6ZV9DzoaWhvc1HV8) **Remote:** No **Visa Sponsorship:** Not at this time **Technologies**: C++11, CMake, GDAL, boost on both Windows and Linux. Some of the code uses MFC (transitioning to STL). Some Python for scripting, Java, and C#. Also Docker and google cloud. Visual Studio 2017/2019 on Windows. **Contact:** Apply [via LinkedIn](https://www.linkedin.com/jobs/view/1237989237/) or [via Brassring](https://sjobs.brassring.com/TgNewUI/Search/Home/HomeWithPreLoad?partnerid=25651&amp;siteid=5472&amp;JobId=3773617&amp;PageType=jobdetails&amp;noback=1&amp;fromSM=true&amp;actiontype=savefromjobdetails#jobDetails=3773617_5472) &amp;#x200B; You can PM me if you need additional information.
Great episode. As someone who hasn't kept up with the coroutines stuff, this was a really good introduction to both why you might want them and how you'd use them. I'm really excited for the generators stuff.
First of all: Very nice, despite what I'm going to say now. &gt; To compare compile time performance I’ve added simple test cases that include the header for the library and have a single test case defined. What would be interesting to me: How much impact do the respective compile times have if my test code actually exercises some real library code that includes the stl anyway. Microbenchmarks are nice and all but in order to interpret those numbers you need real world (or at least close to real world) work loads. Another detail: What's the output of the respective libraries if an assert fails (e.g. do they show the expected and actual values like catch does?
&gt;Reason ??? Sums it up pretty well. If I'm not writing library code, I have little reason to use namespaces.
&gt;Are you making a protable codebase? yes. \&gt; Or your goal is to invest a year or two in making a portable plugin that can plug into an SO or a DLL? Looking for easy solutions, not heavy ones. &amp;#x200B; \&gt; WebAssembly or maybe even Java. If this is your true goal, you chose a wrong audience to ask. No VM, .NET or Java, pure C++. &amp;#x200B; \&gt; Visual studio connects to Linux targets just fine. You can compile with gcc or clang, either does. What I have tried out now - gcc works (compilation, debugging, intellisense (somehow) ), but clang I've got working only compilation &amp; debugging.
Tried to google, but could not find related code. Can you pinpoint me where loading happens, also conversion / loader functionality. Does debugging works ? Does this works for C++ code as well with c++ exception handling ?
No virtual machines if possible, only if can be extracted as portable layers.
&gt; I would bet that there is at least one memory leak in there. Assuming the test cases work correctly, and gives no false positives or false negatives, does it matter if the test framework leaks memory? Unit tests seems like it would be one of the few places where a memory leak is not actually a big problem.
Then don't bother with "compiling once". It is very hard, and even if done, your debugger still won't work. Now, if you have a portable codebase you can develop on Windows compile and run everywhere, mostly debug on Windows and infrequently debug on Linux. My recommendation is /permissive- for your MSVC and then you can chip away with incompatibility between msvc and gcc.
This is unrelated to my criticism.
How would you know that the leak is occurring in the framework and not your own code? You can’t without testing the framework independently. I am so glad for all of the available tools in C++ that allow you to write memory safe code with more ease than plain C.
I think what you're really looking for, but don't realize it, is an automated build (CI) solution. Building binaries for multiple platforms is effortless, once CI is setup. Using something like Azure Pipelines with GitHub is pretty easy, and let's you very easily compile for Windows, Linux, macOS, iOS, Android, WASM, etc. For local testing on a single platform, you have a few options. You can build with Clang or GCC on Windows to test compiler differences, and you can easily build and test on Linux using Windows Subsystem for Linux. Either way, you can stay right inside Visual Studio for editing, building, and even debugging (VS can debug via GDB over a "remote" connection to your WSL environment). I'll reiterate that you want automated builds, though. I don't build for Linux or Clang/GCC manually very often; I only bother whether my CI system tells me the builds are broken on those platforms, or I get a bug that isn't caught by the test suite. :)
[A better way to do symbol visibility is described in the GCC wiki.](https://gcc.gnu.org/wiki/Visibility)
You can design a C app so its functions return a struct with just as much information as you might be inclined to put in your Rust error object.
And as in what part of that do you mistakenly believe couldn't be done in a C program?
As it happens: https://open.spotify.com/search/podcasts/cpp :-)
Good for you, but some people don't have the luxury of using helpers to manage memory.
So you can’t use unique_ptr or STL containers? Because that’s what I was talking about. That and the concept of object lifetime and all that entails by way of constructor, destructors, scope, etc.
Yes, under some circumstances some people can't use them.
Of course it's possible, it's just not as nice to use. In any case, the bit people were responding to at first was &gt; So functions return a type that's composed of a normal return type and a status code that's analogous to the integer status codes from C. So we were just pointing out that returning a sum type allows for more than just an integer status code like many C functions do. And rust functions tend to take full advantage of that
So then why use C++ and not just stick with C?
C++ has a few niceties, but yes, many people are finding C to be superior as a tool to implement their solutions. Programming languages are just tools.
Yes, they are just tools but I was commenting on my opinion that C++ is superior to C because of the growing ease of memory management. I was also trying to point out that I don’t believe that he should somehow claim that it is C++ code. It’s like claiming your JavaScript program is actually typescript even though you use none of the features of typescript. (Had to look this analogy up since I didn’t know if it was factually true or not)
I knew about this trick, but I have suggested the macro to disable Windows declspec as hack to get the code working in the easiest manner. But surely, making the symbols private by default is the best solution. In Linux is usual C libraries be written in this way: // Function with not visible symbol static void set_network_name(const char* name){ ... } In C++ there is also another trick of anonymous namespace: &amp;#x200B; namespace{ class ClassWithHiddenSymbols { ... ... ... ... }; }
So... which IDE is JetBrains' favorite child? ReSharper or CLion?
QtCreator... Just kiddin :) &amp;#x200B; love both CLion and ReSharper (C++) though QtCreator is another great IDE!
I honestly don't really care about the compile time of my unittests, since generally it's not the rate-limiting factor of what I have to do. I also really don't care about single header files, because it isn't 1998 and subprojects are a thing. I do, however, actually care about the million features Googletest has, because I've had to use most of them before. So, rather than re-implement them or worry about compatibility with systems I never use, I'll gladly take the "inferior" product and not reinvent the wheel.
What do you think the literal suffix [is](https://en.cppreference.com/w/cpp/chrono/operator%22%22s)?
I think I was completely wrong and should have probably double checked. oops. I don't know why I thought that
yup and that would be difficult in a case like this. I am taking the member name and if it is describing a class type I need to give that type a name. I chose the easy path of suffixing with _t, but to ensure CamelCase I would have to use a word lookup, hopefully it is a word in the list, and then do the cases. But it is worse, one can have a class in javascript(some of the are kv maps too) with two identifiers where the only difference is the case. In the future I will have configurable namespaces and type suffix/prefix. I chose not to touch identifier names more than ensuring they are not keywords and are escaped when the range of the character is outside what g++ can handle(mostly ASCII) Also, one could always use refactoring tools after, the important part is not having to go through many many classes in a json array to determine the most probable class structures
Typically you have the source for your dependencies so it's easier to just compiler everything together and then not have to worry about these baroque issues There are a few options, but I've found bundling with Hunter the most robust. I made a write up about it a while back : https://geokon-gh.github.io/hunterintro.html (It probably needs a bit of an update for the latter sections) The only caveat is if you need some libs static and some dynamic then it's not really set up for that scenario - but that's a messy not entirely solvable problem
find it out ;-) imho, its a great review
For those like me that have struggled with the memory footprint of ReSharper and its impact on Visual Studio, JetBrains added a feature to not load Web Languages support. When they added this in the EAP, I went from Visual Studio crashing due to OOM nearly every day to no crashes. Whoever thought up this feature for ReSharper has my gratitude. It was getting to the point I wanted to get rid of ReSharper. This feature is not mentioned in the link about the C++ features but it is in the Ultimate 2019.1 release post. https://blog.jetbrains.com/dotnet/2019/04/30/welcome-resharper-ultimate-2019-1/
Legitimate question. For instance, in light of what they announce about Unreal Engine support, for someone willing to dive into it, do we have to conclude that VS + R#er is the better solution and that Clion isn't on par ? I'm not one to blindly say that anything microsoft is intrinsically bad, but that doesn't mean I wouldn't mind avoiding their stuff if I could.
The thing I don't like If I just build the dependencies, is that they get installed in the install prefix. I would prefer to have them private to my library/app.
What does it mean to have unreal engine support? Why would there be special support for a specific C++ project?
It would help, if you would explain what you are trying to achieve with one binary for Linux and Windows. As others have pointed out, that would be close to impossible and just for that goal "only one compilation" pretty pointless.
Huh. Well, thanks for the link! I must have missed the '.' in the name when I searched for it.
I did get rid of r# in favor of VAX. Not because of crashes, but because it makes everything terribly slow. Did that improve as well?
I'm not entirely certain about that. I think it might have but I'm not sure if it is placebo or not. I should try without r# and try VAX at some point to get a feel.
While I love ReSharper (use it at work), it's the IDE that's the limitation, and the general mess the whole thing is (ReSharper adds a bit to it). What I mean is that you end up with things that could be done several ways. &amp;#x200B; CLion on the other hand is clean. I have only one wish, and I would pay for it - an IDE that supports any language - java, C++, go, etc. I have the Ultimate version, but it does not have C++ &amp;#x200B; Another + for CLio, or more like big "-" for Visual Studio is that the IDE is not going to be 64-bit anytime soon.. Yes I could hear now tremors, people speaking why you need it - but you do need it. I don't want to be slowed down by GC cycles in the IDE, or not have enough memory to finish an operation, on a machine with 128GB (and 3.5gb address space only for the IDE)...
Visual Assist just kept on crashing on my machine, but other coworkers are claiming it's the best thing for them (like ReSharper C++ is for me). Now ReSharper is not really fast, but it's much more reliable than Intellisense.
Thanks for your insight, very interesting to have that kind of POV :-)
Yikes, I code plenty of C++, but this is a pretty ignorant comment. You can’t judge a program’s abstractions based on the language used alone. The kernel I’m using while typing this is probably way tighter than the majority of crappy C++ programs out there, and yes, including those that purport to use modern idioms.
I only submitted it a couple of days ago - and it takes 24 hours to show up, apparently. So likely when your first searched it wasn't ready.
Except for C++ explicitly imports several parts of the C standard library, and has lots of inter-operation features for C. C++ has no such features for OCaml, and Java has no such features for Javascript (or didn't the last time I used either)
Most likely for the reflection macros
The entire world runs on libc, what's your point?
Have you actually tried to compile that?
What leaps of logic? The C++ Standard literally includes multiple sections of the C11 standard, and has numerous aspects intended to maintain compatibility between the two.
Compatibility. Exactly. Do you know what that word means?
The install prefix can be whereever you like. So why not build the dependencies with *ExternalProject* (or something similar), install them into your build folder and use them from there?
No I hadn't, and I hadn't considered the problems with constexpr. It's probably easy enough to get working with a less pretty macro though.
I disagree that it is ignorant. My opinion is based around my own experiences. The language choice can inform me of what pitfalls I could stumble across. It has been my experience that most C code will end up with a memory leak sooner or later. I don’t doubt that the kernel you’re using was tested to heck and back but that still doesn’t dissuade me from my opinion that memory management in C is tough and that I would prefer C++ over C for most problems. Really what this boils down to is that I felt the comment about the bloat from C++ was unnecessary and decided that I needed to respond in kind with something I dislike about C.
Unreal has all kinds of weird macros that get parsed by their "header tool". R# most likely got confused by them in the past.
Performance is Resharpers biggest problem right now. VS sometimes freezes for seconds or completely crashes. At some point they announced out-of-process execution. I wonder when they will deliver this.
I've been looking for this for a while, thanks!
[This will serve you better.](https://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list)
Good question) But the answer is that we do care about all our tools for C++. So both are important to us. They have different platforms they are built on and different teams maintaining them. But we try to keep the general features aligned. However, products have different targeting. For example, specific UE4 support is obviously for ReSharper C++ as most of the developers are on Windows with MS toolchain. While embedded dev goes to CLion.
The worst combination is R# + Perforce VS plugin than you can get a coffee. I am happy to hear that R# has a (better) support for UE now! I hope that the performance issues are better now. I'll test it asp. Thanks !
I can recommend Chili Tomato Noodle. He knows his stuff and has very in-depth videos that spend an hour explaining only the stack or pointers, for example. Much better than my university lessons. His beginner series is great too.
I used ReSharper for a year and loved it, but the load time took around \~1-2 minutes and the performance on large projects is abysmal. Don't do Java kids, mmmkaayy
Agreed, I believe I learn best from videos and prefer them in many cases, learning C++ as a beginner was not one of those cases. Learning from the books in that list (I particularly like reading Bjarne's work, you're not going to find a list of errors in his books for certain) gives you a smooth roadmap to learning C++.
If you don't have time to watch this video I guess you don't have time to read the book... ;-) But if you still have time to read the book - just do it! It's a great read!
I'm currently trying to wrap my head around the whole C++ game and really like Cherno's videos. I'm by no means an expert, so let me know what you think about it. [here's the link](https://www.youtube.com/user/TheChernoProject)
Do you have some documentation on this? Sounds interesting.
His explanations are very intuitive, he knows his shit, he calls out bad programming styles. One of the good C++ tutorials on the web atm
`do` notation is, so to say, an imperative-style syntax for dealing with monads. The pipe notation is a functional-style syntax for dealing with monads. For things like these, `do` can be much nicer. The closest to `do` with `&lt;-` that we have (C++20) is `co_await`.
&gt; For example, specific UE4 support is obviously for ReSharper C++ as most of the developers are on Windows with MS toolchain. That's unfortunate. I wonder how much of it is a chicken and egg problem: if CLion worked as well as Rider even without debugger, people wouldn't mind leaving Visual Studio.
Do you not run your tests under leak detection tools and fail your CI if leaks are found?
There is no Java is ReSharper/++
&gt; we do care about all our tools Spoken like a true diplomatic parent.
There is nothing factually true about anything you have said.
And if you need to do this with MSVC, the way is: `lib /out:ALL.lib A.lib B.lib ...`
Yes, I implemented it. See https://github.com/OpenRCT2/OpenRCT2/pull/1956 where the binary was first `mmap`ed, then I improved the process to prevent ld.so or features like ASLR from reserving this region, by forcing the section into ELF with custom linker script: https://github.com/OpenRCT2/OpenRCT2/pull/2503.
See https://www.reddit.com/r/cpp/comments/bjgt0j/make_portable_dll_without_second_compilation/emb8h46
I agree with /u/fbhc . Get two books - C++ Primer and Modern Effective C++, the former will teach you the basics, the latter will teach you good practices for those basics. Along with that [https://en.cppreference.com](https://en.cppreference.com) is the best friend for any C++ developer, it will educate you more in depth on the features of C++. This is a good starting point, good luck.
Why not Qt? Give it a try
Rule number one of Programming: DO NOT USE DRAG AND DROP FANCY ASSISTANCES! no but seriously, would need to install it, its mostly xml and if we are going the "Assistant drag and drop like a no-brainer" path then I wouldn't have posted this question specifically in the programming section.
You can use Qt programmatically without any additional files/formats. I suggest doing some research before drawing any conclusions. Perhaps be nicer to people trying to help.
You appear to be comparing a library (SDL) with a compiler (Visual C++) and presumably its associated IDE (Visual Studio). That doesn't make sense. Of course you can (and many people do) write applications using the SDL library in Visual C++. I suspect the thing that "feels like learning a different Programming language" is the use of the Windows API or MFC. Both of those date from the 80s/90s and don't exhibit what would be considered good design or best practice these days. Visual C++ itself is a highly compliant C++ compiler (with a few proprietary extensions, none of which you need to worry about) and can be used for virtually any type of application. Don't like the Windows API or MFC (I don't blame you)? You can program exclusively against the C++ standard library and/or use some other framework/library like SDL, Qt, etc. These days, you can even use the Visual Studio with GCC or Clang/LLVM... SDL is used extensively for game development, so if that's your field of interest it's certainly worth knowing... There's no one compiler that's used for all game development; obviously most Windows and Xbox games will use Microsoft tools, but other plaftorms and consoles use GCC and Clang/LLVM based toolchains.
What do you mean by "Visual C++"? The Microsoft C++ compiler? The Visual Studio IDE? The MFC GUI framework? It's not clear to me how any of those compare to SDL, which is a library for abstracting graphics and event handling across platforms.
Did I came over as offensive / hostile? If that's the case then it was not my intention. In fact the first sentence was meant with humor.
Yep, absolutely. Ditch video tutorials for C++, read books.
Visual C++ is an IDE, it is not a UI SDK. There are many options for creating UIs that (optionally) come with Visual C++ depending on your version, like MFC, WFC, straight Win32 API, etc. You can also install and use any UI library you want with Visual C++, like QT or wxWidgets or whatever. So when you say Visual C++ is a total mess, what exactly are you referring to?
I'm an idiot. Thanks for *pointing out WinAPI, meant that but actually wrote VC++ multiple times. ← This is what happens when you work with VC++ or Visual Studio in general. Thanks for great answer, path is pretty clear now thanks!
Yes, a little. All caps is a bit much. Sarcasm and humor are difficult to do via text, I suggest avoiding it on programming forums unless you really know your audience.
obviously WinAPI, especially after mallard and my EDIT makes this clear but thanks for pointing it out again.
It is okay. Just give Qt a try, it has what you need I’m certain of it.
The whole WNDClassExWAB (the ExWAB part is obviously false code-wise, but you understand what I mean by that) and Callback procedure looks like a mess to wrap your head around. The whole story with T_Chars, LPCWStr and L"Strings" are honestly bug-traps that should not exist.
I'm not really understanding why you would do this? You can just litterally use templates or overloads. I'm not sure what Update value is doing here, doesn't look like you're updating shader uniforms with it. Looks like you're just updating a CPU Union. Typically you would just use templates specializations (to avoid implicit casts) that take in the values you would use, and set uniform by name or by handle.
Okay I'll look into it before heading into SDL. thanks for the recommendation.
From where does the "Assistant drag and drop like a no-brainer" idea come from? You are talking like Qt is something like Visual Basic. No, you can program Qt fully analytically, and a lot of people do. Look at some Qt examples and you'll see that they are pure C++ code. Qt Quick with its QML language is a little more closer to a "just add water" approach.
When we use tools to detect memory leaks the whole premise of your original comment becomes irrelevant. Leaks in the framework will be found and fixed quickly.
Sure, but when we use leak detection, the original question is irrelevant, since memory leaks in the test framework will be quickly found and fixed.
Use this https://www.learncpp.com/ its very helpful and it helps you understand C++
Or C# with a C++ backend.
Can you debug this kind of plugin as well with debug symbol information ?
Mostly, yes. The part that comes with C/C++ sources (our implementation) is capable of generating standard frame walking DWARF that debugger understands. The original binary was hand-written assembly and was not tied to any specific calling convention (apart from platform shims) and we had written custom assembly to provide call gates both to and from original code. Obviously the assembly code did not have any DWARF available, but if you were sufficiently determined, I'm sure you could provide the necessary parts yourself. That said, I believe making it work with exceptions would be really hard. I recall winedbg being capable of switching calling conventions between client (Windows) and host (Linux, etc.), that might be worth of taking a look at as well. You can join OpenLoco gitter channel if you have more questions about our approach.
The typescript language spec explicitly says that it is a superset of JavaScript. All valid JavaScript is valid typescript. Pretty sure that’s one thing that is factually true. The rest is just my opinion.
&gt; Of course it's possible, it's just not as nice to use. It isn't nice to use in Rust either. And the "exceptions are too hard to understand" meme has metastasized to other languages, some of which have real exception handling. I encountered a Python library this week that returns status objects instead of throwing exceptions, and it wasn't even a wrapper to a C library. In every case, this type of error handling is a huge step backward. It's like turning the clock all the way back to 1975 or so.
True enough. I did not think of that point. But I still stand by the idea that it is easier to write memory safe code in C++ than C.
So ... why exactly do you post C# on r/cpp and randomly tag it nsfw ?
This is for us to remember that /r/cpp is still reddit.
You can't be stuck choosing Win32. But on a new project you may better look at winui/uwp for some new way to do applications on Windows 10 and above.
Isn't the problem with bundling static libraries that you almost inevitably end up with multiple, conflicting copies of the bundled libraries. * `cool.a` contains a bundled zlib and libtiff. * 'awesome.a` contains a bundled zlib and libpng. * Try to link both into the same executable and... kablooey! Multiply defined symbols!
When I started this project, the idea was to not hard-code every single object that I'll be displaying into the renderer. I wanted to have an editor as well. Someone could write their own shader and use the editor. In order to do that, I need a flexible way to store shader uniform values in an **lvalue**. That's why I used unions. I don't need to make separate variables for each type. I can just have a variable with enough memory to store values for all of the uniform's data type. &amp;#x200B; Once I have the UI layer set up, I can display the uniform and users would only need to assign a value to it. At the back-end, the pseudo-code would be something like this (Note: I overloaded the `[]` operator to do this function `GetUniformWithName()`): &amp;#x200B; &gt;SomeShader\["lightPos"\]-&gt;UpdateValue&lt;glm::vec3&gt;(somevector); &gt; &gt; &gt; &gt;// Somewhere at in the renderering loop, I can do this ... &gt; &gt;for (UniformAttr &amp;Uniform : Shader.Uniforms) { &gt; &gt;switch(Uniform.Type) { &gt; &gt;case UNIFORM\_TYPE\_BOOL: &gt; &gt;SetShaderBool([Uniform.Name](https://Uniform.Name), Uniform.Cast&lt;bool&gt;()); &gt; &gt;break; &gt; &gt;// Rest of the code here ... &gt; &gt;}
it would be very nice to upstream this function as an official CMake module
A french guy in an english world, my bad :p
Or you could use a test framework that you don't have to fix first.
Why would you ever want to overload sizeof?
ReSharper is not a IDE by itself and it targets VS which runs exclusively on Windows.
There's literally a [section](https://blog.jetbrains.com/rscpp/resharper-cpp-2019-1-responsive-better-unreal-engine-new-language-features/#unreal_engine_support) in the post about this :) Unreal Engine is very popular, but it also has many peculiarities and its own style guide. We've added several features for UE4 developers to make their life easier - like completion support in UE4 specifiers, naming checks and support for RPC functions in navigation/code generation features.
If it's the same \`zlib\` built with the same flags, you can pass \`-Wl,--allow-multiple-definition\` linker flag, and all should be fine.
Create a constexpr template function for that and overload it to your heart's content. Something like: #include &lt;stdlib.h&gt; template &lt;class T&gt; constexpr size_t mysizeof() { return sizeof(T); } int main(int argc, char *argv) { return mysizeof&lt;int&gt;(); }
Out-of-process is still being worked on, but it turned out to be involved due to tight integration with VS, so we can't give any estimates yet. In the meantime we're working on ReSharper's memory footprint, 2019.1 in particular includes many fixes which result in better memory usage on large solutions compared to previous releases.
I posted my comment before I saw mallardtheduck's comment or your edit. If you expect help from other people, a little politeness goes a long way.
Another option to reduce memory usage in very large solutions is to exclude parts of the solution you are not interested in from indexing (see [this page](https://www.jetbrains.com/help/resharper/Reference_Options_Code_Editing_Third_Party_Code.html) for details). Still, frequent OOMs are not normal, and we'd love to investigate. If you'd like to help, please DM me.
Please let us know if performance issues are still there with 2019.1. In our experience all VS source control plugins noticeably affect VS performance, that's why ReSharper's "Performance Guide" has an option to remind you if a source control plug-in is in use.
#define sizeof(x) 42 Busted.
I have Resharper++ and performance has been a huge issue for me. The editing behaviour is atrocious, with keystrokes being visible delayed, occasionally I'll even getting mini-freezes lasting for several seconds on larger projects. None of this happens in CLion.
If you haven't used it for some time please give 2019.1 a try. Both load time and performance should be much better on large projects. ReSharper C++ does not use Java, but it does use a managed runtime (.NET). On the one hand, it causes some performance issues. On the other, we get to build on the powerful ReSharper platform, and most importantly a random error in our code does not get to crash the VS process. Consider how easy it is to get an "internal compiler error" basically on any compiler, and that R++ implements its own C++ frontend to use in all the features.
read stroustrup principles and practices. just make this a sticky and drop the mic
c++ primer is a reference manual not a good way to learn the language. if you want to learn the language use stroustrup principles and practice
I just wanted to check what is special about sizeof that it can't be overloaded to which i understand a bit through the link, sizeof gives the size of types if we overload it , it will impact getting size of type which is not what is desired
Enjoyed it! Jon played a great straight man, and I liked the operator new/delete trick.
&gt; We could just build only the static library, with hidden visibility and ship that. But this also means everything (including client code) needs to be compiled with the same compiler / toolchain. Euh... problems are exactly the same with shared objects, no?
Compiling twice is **way** better than converting. If it wasn't, people would have been converting all over the place.
Pycharm
Same reason why pycharm supports django
it's a 20 minute video why is this getting downvoted. book reviews take me 5 minutes to read at most.
There is a reason why I'm asking this stupid questions. Besides ABI compatibility we also considering of using Chrome crashpad, which in a turn is highly process / exception / file format specific. Also interested now in this just in case if will be able to harmonize that code as well.
Please DM me or contact our support team if you'd like to help, we'd be interested to investigate.
after you read a book review that will take you 5 minutes to read you will not have the same information like after this video. and if your &amp;&amp; OPs time is so valuable, why wasting it and posing with tl;dw comments? just to show you &amp;&amp; OP know some hype acronym? &amp;#x200B; but let me help you, here the 3 seconds plot for you: The book is good
`sizeof` can't be overloaded because C++ doesn't allow overloading `sizeof`. No more needs to be said on the matter.
The article is not entirely correct. `sizeof` is not necessarily compile-time operation.
SDL isn't a GUI library. It's meant as an abstraction layer to get windowing and events, along with some nice functions to setup rendering contexts and stuff, but it doesn't provide any conveniences for traditional GUI programming. There's no concept of buttons, etc. You'd have to find a third party library that does that for you and is capable of rendering into SDL. Save yourself sometime and look into the more traditional UI toolkits. Qt is a great one and widely used. So is wxwidgets. If you're developing for Windows only you may want to take a look at XAML and C++/WinRT.
maybe /u/TartanLlama/ /u/marian_l can help
Yes, that is absolutely true.
Hmm my college text book definitely isnt in there. Cant seem to grasp too well working with linked lists templates inherited classes and recursion all at the same time so maybe one of these will help
As stated, Cherno's videos on C++ are reallyy good. I would recommend checking them out.
I meant that it is highly likely someone else would have found the bugs already if it is widely used. Also, google test has 92 open issues at present time, but I don't think most people would argue against using it because "you have to fix the framework first" I am not arguing for or against any of the test frameworks in the article, just that anyone of them would be better purely because of the language it was written in.
Eh. "You can't recover when `new int` throws." Sure, but it never does. When `new frame( 1920, 1080 )` throws, I recover from that just fine. That is, the scenarios in which `new` actually throws, are recoverable.
Oh! I have dealt with this before, but my setup didn't have the newest and greatest visual studio cmake integration feature. Is this using the ninja generator or MSbuild/VC projects? For the latter I have a solution, for the former I haven't tried anything yet but would love to have a go at it
I do not see any point in `using class` construct. `Using` namespace gives you less typing - `using namespace std::chrono` allows to do `auto x = duration_cast&lt;microseconds&gt;(x)` as opposed to `std::chrono::duration_cast&lt;std::chrono::microseconds&gt;`. This is visible benefit. On the other hand, `Superverylongtype superverylongvariable; using Superverylongtype; superverylongmemberfunction(superverylongvariable, args)` is not shorter than `superverylongvariable.superverylongmemberfunction(args)`. One could argue that it would allow to name free-standing functions as class members and than call either one or another through uniform syntax, but to me it is an evil outcome - by adding another overload outside of the class someone would be able to change an outcome of a function called through this syntax, while users of the function might expect it to be the part of the class contracted API.
But none of what you said was true, except for needing to install Qt. SDL isn't even a GUI library, it just creates a window.
You could have the path hardcoded as you said to \`${cmake.buildRoot}/whatever\` and from CMake copy all the files from Conan you need to that folder. Or you could make a symlink too if you have permission for it (depends on your Windows configuration). The problem is that you cannot specify any environment options from CMake that are passed to launch.vs.json (without overwriting it, but that's quite icky). If you were using actual VS projects, you could set the property [https://cmake.org/cmake/help/git-master/prop\_tgt/VS\_DEBUGGER\_ENVIRONMENT.html](https://cmake.org/cmake/help/git-master/prop_tgt/VS_DEBUGGER_ENVIRONMENT.html) but there's no equivalent for the Ninja build file integration in VS.
I'm done engaging with you. You're unnecessarily hostile.
I'm pretty sure it is, in C++. Can you give a counter-example?
In lack of a more simple option you could use add\_custom\_command point it to the file that conan writes out, and let it trigger a small script which in turn edits/creates the launch.vs.json.
&gt; On the other hand, `&lt;snip&gt;` is not shorter than superverylongvariable.superverylongmemberfunction(args) Agreed. This is not very useful -- and I even say so in the post. &gt; One could argue that it would allow to name free-standing functions as class members and than call either one or another through uniform syntax, but to me it is an evil outcome I'm not sure about "evil", but essentially this is what has held up UFCS proposals so far, as I understand it. The point of `using class` is that it gives you a way to say "yeah, I know this might happen, but I want to do it anyway".
How did you solve that? I suppose for MSVC 2015? Is it possible to avoid copying the deps to bin/ dir? I assume OPs question is for MSVC 2017.
Variable length arrays (which admittedly aren't standard).
Since when could `sizeof` be used with variable length arrays? Or what compilers have this non-standardized feature? Last time I (not knowing better) tried to do `sizeof` on a variable length array, I just got the size of a pointer back.
At least GCC. See https://stackoverflow.com/questions/8715465/is-the-sizeof-operator-evaluated-differently-for-vlas-by-gcc
Teach me. Consider this snippet from the article: &gt; Today, C++20 ranges implementations have to go to quite some lengths to handle the different ways that begin() and end() could be written (not to mention size(), data() and a host of others). With this form of opt-in uniform function call syntax provided by using class, almost all of that becomes unnecessary, and is handled by the language itself. How is the following deficient for handling the different `begin`/`end` cases? ``` template &lt;typename R, typename T&gt; bool contains(const R&amp; range const T&amp; value) { using std::begin; using std::end; auto first = begin(range); const auto last = end(range); while (first != last) { if (*first == value) { return true; } ++first; } return false; } ```
&gt; The compilers are also packages… &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Useful; reminds me of how OCaml has OPAM lets you manage various installed versions of its compiler as packages by making what it calls 'switches' available.
Too dangerous in my view. Behavior could change completely underneath the user of the class through no fault of either of actors (original class writer, free standing function writer or user of the class who simply used available language feature). C++ already has enough guns to shoot in the foot, I believe, we do not need another one like that. The feature of uniform calling (like begin/end for ranges, swap might come to mind, few other common function names potentially) is really limited to library designers (and even more so STL designer) and can be dealt with on this level with overloads similar to `begin`/`end` safer without exposing everyday programmers.
If you talk about C++, as in standard, here http://eel.is/c++draft/expr.sizeof we can't find any indication that it is a compile-time operation. All is required that it's result is a constant of type `std::size_t`. If you talk about C++ as implemented by compilers, as already noticed, a sizeof of VLA in compilers where VLAs are supported is a run-time operation.
I've spent the last few years learning C++ from books and videos. Stroustrup's "Principles and Practices..." is a good book BUT the supplied .h files don't work in all compilers and IDEs. I eventually gave up on using his .h files and rewrote the example code using standard C++ practices and then used sublime and gcc on the command line to do the editing and compiling. "C++ primer" is NOT a good book for beginners and I don't know why people keep suggesting it. It's a great book if you have a solid grounding in comp sci fundamentals and at least an intermediate understanding of another OO language. This book made way more sense to me after I spent a year in university studying comp sci in Java than it did before I had that foundation. If you can afford it I would heartily recommend paying for pluralsight and taking Kate Gregory's C++ courses. She's a great teacher. I just finished her "Beautiful C++: STL algorithms course" and it was one of the best put together and executed computer programming courses I've taken. Including my university courses. She offers several beginner level C++ courses that I wish I had known about 2 years ago. If you can't affod plurasight then buy this Udemy course [https://www.udemy.com/beginning-c-plus-plus-programming/](https://www.udemy.com/beginning-c-plus-plus-programming/) It't the best course I've found for beginner's using MODERN C++. This is important. A lot of courses/tutorials on youtube are teaching outdated C++ or some weird mix of pre and post C++ 11 stuff. This is bad and makes the language seem even stranger and more monolithic than it is. Youtube is really a mixed bag. Do some research on the youtuber before you commit to a series of tutorials. Otherwise you'll be learning some very bad habits that may hinder your development down the road. You get what you pay fo sometimes.
Just out of curiosity and completely off topic, do you share much code with OpenTTD?
Hahahahahahahaha ah yes, the old "C is inherently less safe" argument. Let's look at some counter points, shall we? - Valgrind - Good ownership practices and conventions - Valgrind - Debug symbols and gdb/LLDB - Valgrind - Stack allocation favorability - Valgrind - The fact that some of the most ubiquitous code ever is written in C and does t eventually just crash randomly - Valgrind - Even C++ can succumb to memory leaks or segfaults, **even in the standard library** - Fucking Valgrind
Then you must not code enough in C to really understand how little a problem memory leaks really are. They're one of the easier classes of bug to not only fix, but also to detect. I'd take a memory leaks over a race condition any day.
It depends exactly what you mean by "compile time operation". If you mean in the sense of: is `constexpr auto x = sizeof(...);` legal for anything you can put in the ..., then yes, it's a compile time operation. If you mean, does it result in code getting executed at run time, strictly speaking the standard does not speak of such things and the compiler can do what it wants within as-if. But yes, it's guaranteed to be "doable" at compile time. This is not "C++ as implemented by compilers", this is C++ with common extensions, which is the default in gcc and clang (likely for compatibility with gcc; unsure about MSVC). If you turn on -Wpedantic which is the main flag to tell gcc/clang "no really I just want C++", then usage of VLAs will be flagged. On top of that the reality is that the majority of the C++ community has rejected VLAs and there's no prospect of them being standardized anytime soon (unlike, another common extension such as designated initializers, which I've seen before in C++ code and were accepted for 20). The bottom line is that in a discussion of C++, today, the statement "sizeof is a compile time operation" is correct.
Not much, if anything. The window system was done already before I joined the project, I think I was told there were pieces that might've been influenced by openttd, but can't say for sure. Openttd had almost exactly 10 years of head start so it diverged quite a lot from its original, but if you squint really hard, you can still see some of the shared structure and sometimes even functions/algorithms match as well.
Ah, that explains it all. Thanks!
Those are Win16 and Win32, and have long been considered legacy. New Windows projects should make use of either WPF or UWP.
Too bad valgrind isn’t available on windows where I do 100% of my development. It is my opinion that Language features &gt; practices and conventions. People can ignore practices and conventions so much more easily then to have to fight the language to do something bad. I never tried to imply that all C code is going to crash or whatever. I’m just saying that it has been my experience that it is easier to write memory leaks in C code than C++ using modern tools like unique_ptr and stl classes. I think you’re taking my opinion as something that can be objectively proven false.
Yeah, standard never mentions compile time explicitly (at least to the best of my knowledge), so we can't find support for either point of view there. As for VLAs being extension, I am familiar with that. It is also default on icc: https://godbolt.org/z/Kp3Ggk The bottom line is that if you are using C++ with VLAs, which your compiler might support by default, it's important to understand that operation might be happening run-time. MSVC doesn't support VLA, most likely due to the fact that they do not support any recent C specification in general.
The dance on the library's side avoids the need for `using std::begin;` in order to have a proper overload set and to call the most correct overload. If a user does `std::begin(foo)`, they miss out on a `begin` made specially for that type. If they don't have the using-declaration, `std::begin` might not be in the overload set. This is more commonly discussed via `std::swap`. Eric Niebler had a proposal to make `std::begin(foo)` Just Do The Right Thing™, and it's not the most trivial feat without inline variables. Thankfully, the ranges in C++20 feature this new customization point design.
I wasn’t trying to say they’re a huge problem. I was just reacting to the comment that C++ is bloated by pointing out an issue I see in C code a lot. I’d definitely take a memory leak over a race condition any day as well.
Maybe you were remembering visual basic while writing that
sizeof is a reporting tool. It's reporting on the internal representation of an object by the compiler. What would it even mean to overload it even if it were in a constexpr expression. That's like asking someone what color your red car is and they say it's blue. It's still not blue. But now it's useless to tell someone to look for your car by color.
I posted the question also in r/programming and got great insights there. I attached the link
I prefer NeoVim, it is nice, simple and effective. Of course I am biased because I started with Vi. EMacs and Vim are both powerful; however, Vim/NeoVim are easier to install plugins for (tab complete, .etc).
Vim
As just a dabbler in programming, I’ve found them to be pretty interchangeable, especially since both have good LSP implementations. My guess is that if you want to manage every aspect of a project with one tool, Emacs is the way to go, but if you just want good autocompletion/navigation/linting Vim will get you productive with less effort.
This is using the ninja generator with the CMake integration on VS2017. Please do and let me know if you figure something out :) &amp;#x200B; Using MSBuild/VC projects you can already use `VS_DEBUGGER_ENVIRONMENT` like u/OrphisFlo suggested below. We were using that before, but want to try and get rid of VS projects now and just go with native CMake.
Thanks for the reply! &amp;#x200B; Copying/linking the files is indeed a solution, we were doing that a while ago. Thanks for the suggestions! &amp;#x200B; Overwriting `launch.vs.json` (or rather`CMakeSettings.json`, since `launch.vs.json` is the same for all configs, while `CMakeSettings.json` has blocks for each config) is our current best bet, I believe, but it is indeed quite icky. &amp;#x200B; We were using `VS_DEBUGGER_ENVIRONMENT` when we used VS solutions, but like I said in the OP we are trying to get away from that and just use CMake natively in VS.
The issue with that is that CMake does not get executed everytime you switch configuration types in VS; only the first time for each config, or if any changes are made to CMake files. So the current best idea is to use something like what you said above but to generate `CMakeSettings.json` instead, adding a variable to each config type with the path to all the needed libs for that config.
I'm a vim user, but I mainly use Slickedit as my main editor for Brief emulation (an ancient DOS editor). The only reason I would suggest learning vim/vi over emacs is so that if you end up on some small embedded device, or ancient UNIX, its pretty much guaranteed to have a form of vi. So even if you just learn some of the simple edits, it'll come in handy in that (specific) case.
If you are using VS solutions/projects, you could have CMake set the `VS_DEBUGGER_ENVIRONMENT` target property to something like `PATH=%PATH%;${MY_CMAKE_VARIABLE_WITH_PATHS}`. This requires CMake 3.12+, see [https://cmake.org/cmake/help/git-master/prop\_tgt/VS\_DEBUGGER\_ENVIRONMENT.html](https://cmake.org/cmake/help/git-master/prop_tgt/VS_DEBUGGER_ENVIRONMENT.html)
&gt; Today, C++20 ranges implementations have to go to quite some lengths to handle the different ways that `begin()` and `end()` could be written (not to mention `size()`, `data()` and a host of others). With this form of opt-in uniform function call syntax provided by using class, almost all of that becomes unnecessary, and is handled by the language itself. C++20's `std::ranges::begin` actually rejects rvalue argument, unless a non-member `begin` function can be found that accepts said rvalue by value or by rvalue reference. How would you implement this with UFCS?
For GameDev, go for Qt or learn how to write GUIs using C#. That's what most studios will use. Then, what is your goal?
Back in the day I was solving it by "extracting" the bin path from conan (e.g. the variable CONAN\_BIN\_DIRS defined by conanbuildinfo.cmake contains the entire runtime path where hopefully all the required DLLs live) and then generating a .props file that overrides the debugging environment with the correct path. See an example here: [http://www.jamesebutler.com/setting-the-visual-studio-debugger-path-using-cmake/](http://www.jamesebutler.com/setting-the-visual-studio-debugger-path-using-cmake/) You can then "attach" this .props file to any target by setting property VS\_USER\_PROPS. Alternatively like /u/gusmedeiros is saying, VS\_DEBUGGER\_ENVIRONMENT property can do this more directly. E.g., if you are using the cmake\_multi conan generator, you could do something like this: `set_target_properties(hello_world PROPERTIES VS_DEBUGGER_ENVIRONMENT"PATH=%PATH%;$&lt;$&lt;CONFIG:DEBUG&gt;:${CONAN_BIN_DIRS_DEBUG}&gt;; $&lt;$&lt;CONFIG:RELEASE&gt;:${CONAN_BIN_DIRS_RELEASE}&gt;")` If you are \_not\_ using the cmake\_multi generator and your packages contain both debug and release (on windows it's pretty common for both to coexist and have a "d" suffix for debug ones), it's even easier: just set it to `CONAN_BIN_DIRS`. I'm happy to publish a quick test project on github as well
If you want UFCS, just add a new syntax for calling non-member functions with a new operator ".." aka double dot. &gt; int a; &gt; Foo foo; &gt; void bar(Foo, int); 1. foo.bar(a) always calls Foo::bar(int) *as before* 2. bar(foo, a) always calls bar(Foo, int) *as before* 3. foo..bar(a) always calls bar(Foo, int) **new** This allows you to call "non blessed" functions for Foo, without having to build an unintelligible tree of parentheses, and while also being explicit about calling non-blessed functions for Foo that aren't in the Foo class. eat(then(useFork(x))) becomes x..useFork()..then()..eat() without any breaking change to existing C++ code. Namespace lookup for UFCS uses existing rules 1. Namespace scope *as before* 2. Argument dependent lookup (ADL) *as before* 3. Explicitly mention namespace in call e.g. foo..ns::bar(x) **new, non breaking** 4. Add a new namespace import for UFCS, "using.. namespace ns; foo..bar(x)" **new, non breaking**
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Hmm, curious. If I might ask, which bug was that?
Where's the link to your question?
I've updated the article with MSVC support.
No. The linker will find the symbols in the static library, even marked as hidden, and they shouldn't be showing up in `nm -CD executable` symbols.
Visual Studio Code supports every language via extensions.
In the post. Here again: [https://www.reddit.com/r/programming/comments/bjx0ha/should\_i\_learn\_emacs\_or\_vim\_is\_there\_a\_winner\_in/](https://www.reddit.com/r/programming/comments/bjx0ha/should_i_learn_emacs_or_vim_is_there_a_winner_in/)
Test both, pick the one you like more. &amp;#x200B; I think it's a matter of taste. Also you should try Clion, I use vim in general but the other day I tried Clion and it looks very nice.
I have used vi/vim for 38 years(!) so I will never change but I tend to agree with that top post there. I would strongly recommend new developers have a good look at vscode, it really is excellent and has changed my antagonistic view of Microsoft entirely.
If you're not aware: anybody not using the new garbage reddit design doesn't see your markdown rendered.
I've opened [https://gitlab.kitware.com/cmake/cmake/issues/19224](https://gitlab.kitware.com/cmake/cmake/issues/19224). Let's see the CMake people's reaction.
VSCode + vim plugin for big code bases, vim for all other editing.
Why do the dance at all? Why not just `using std::begin` and be done?
Literally 5 seconds on Google: https://stackoverflow.com/questions/413477/is-there-a-good-valgrind-substitute-for-windows
From the perspective of most people coming into C++ and learning how to implement something like copy-swap, needing to say `using std::swap;` before calling `swap` is stupid, not to mention that they need to be taught to do this because it's not obvious and can easily still compile if missed. In addition, it's sometimes impossible to do this without pollution, such as in the declaration of a template. (That said, I bet lambdas in unevaluated contexts will help there.) Having the standard library make it so that calling `std::*` has the effect of auto-adding the using-declaration solves both of these.
Due to not correctly implementing `execvp`-compatible `$PATH` lookup, `execve` may fail even though a working program exists later in `$PATH`.
Is that 'new' that's throwing in your example though, or is it the constructor of the 'frame' type?
Compilers hate this one simple trick
&gt; The operand is either an expression, which is an unevaluated operand ([expr.prop]), or a parenthesized type-id. If it's not evaluated or is a type-id, then it's compile-time. VLA extensions break this rule.
Although, I like Emacs, none of them are good enough for coding C++ due to the additional time required to setup those editors and also because a C++ code base has many files split between headers and sources. In addition, both of them lacks refactoring tool and good code navigation. But, Emacs is useful for coding single C++ files without any projects for experimentation purposes and also for using git through magit interface.
You must not code enough in some more sane language to really understand how that's not a bragging right. :-]
r/cpp_questions is a more appropriate place for this
thanks
I think Visual Studio as an editor is terrible. I like the class/function definition sneak peek features though.
Where was I bragging? I maintain two of the top 10 most downloaded npm packages. Do you consider that a sane language? What about Python? C#? C++? RAII has its problems. What's your point?
I mean std::array already solves these problems. It doesn't seem like there's much motivation to make this a language feature or make C arrays work differently (massive backwards compatibility issues).
vscode and Visual Studio are different products. &amp;#x200B; i just switched to vscode this week myself, and can confirm.. you will like it
You should look into debugging capabilities. I'm a vim user, and I'm jealous of emacs' gdb integration.
Use evil in emacs and run vimacs in it. Then you get all the benefits of emacs with the modes of vi and the keybindings of emacs. And nobody will ever be able to exit your editor except you.
I was a bit careless with the pseudocode here, but yes, it's the constructor of `frame` trying to allocate 1920\*1080\*3 bytes and throwing `bad_alloc`.
$500
500.1
*swings banhammer*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bk3q59/will_pay_10_paypal_for_hw/emdn25b/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/blelbach) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/bjsoni/c_tutorial_videos/emdnz9c/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
I use CLion and its great. And there are tricks, so you use CLion completely free too, if cant cant afford.
FTLOG can we finally just get CMake to use relative paths instead of writing abaolute paths for everything?!
well I wanna try and see if I like it.thanks
I ll keep that in mind thanks
Nice ill try this.
I dont wanna spend money at first and I might settle first on videos on youtube cause I still dont know If im gonna like it or not just testing out.Thanks though
Nice ill be sure to check his channel.
ill check him out. thanks
It depends, if you like to work most with keyboard - yes. I've using Linux more than 10 years, i've studying in uni (vi most) i can do the things in but i'm don't like it.
Personal opinion: vi is nice for one-off edits, but I find it easier to handle multiple files in emacs.
Interesting article as a definition of what currying is, not really very ground-breaking for experienced programmers who do this sort of thing without thinking too hard about it. \`\`Are curried objects worth it in your opinion?'' It is all about creating a higher-level interface to existing functionality, thus hiding complexity behind abstraction. This is the essence of what writing complex C++ applications is all about, and is 90% of the effort of software architecting. Just like class inheritance or plain class data hiding, of course it is worth it when abstracting a function; it is another tool in the programmer's chest to be used whenever appropriate.
\`neovim\` and \`coc\` (Intellisense engine) is perfect for c++ development. This allows VS Code -style symbol lookup and completion through LSP (I use ccls). It is \_very\_ fast, and objectively superior to any combination of \*tags/cscope/...
I used vim for over 20 years and I can really recomend it! Most of my work is C++ but I also do a lot of scripting. If I had to start from zero again I would probably give emacs a chance but only with evil-mode since I don't want to hurt my hands. Emacs has horrible keybindings.
The biggest blocker to this is the need to use GCC 9. Support (workaround) for g++ 8.2.x would open up OS access particular on Linux Of course making a variant that could run with C++ 14 would be even better but probably a lot more work
Doesn't it force me to learn both before getting productive?
Thank you. What is your alternative? CLion (I am using Ubuntu)?
The fact that there are vim modes for nearly any editor is a strong argument for learning Vim...
Thank you for your advice. But learning both takes much effort, doesn't it? What is LSP? Lisp?
Thank you. I guess I will have to learn Vim in any case. For the reason you mentioned and the fact that there are vim-keybindings in almost every editor.
Interesting. I expected that it would be easier with plugins in Emacs from the stuff I saw so far. But I will check out NeoVim
There is no hiding when statically linking obviously, but surely that's not the problem of the build chain version. Build chain changes influence stuff like padding of data, calling conventions and name mangling, all of which are exactly the same problem with both static and dynamic link.
Thank you for sharing. I am currently with VSCode but I seek for an alternative that is "keyboard-native". I guess I will not switch completely but have more tools in my pocket. Do you think this is an unnecessary idea?
The problem is that learning both takes a loooot of time. But I got this advice so often that I will do that. In the moment I guess I will learn Emacs first (because it fits more to me) and Vim afterwards (because of the keybindings, that I can use everywhere including Emacs)
Wow, thank you. This is a huge point!
Thank you! This is a good summary
Nice, thanks. I will give it a shot
Thank you! As I have no experience with both of them: Why does Emacs hurt your hand? I heard this argument before
Thanks for the article, I appreciate the numbers. Well done on the improvements! It wasn't clear throughout when you were talking about Clang's LTO whether you were referring to regular LTO or ThinLTO. It would've been nice to see performance and compile time numbers for both.
Brag about it.
One workaround is to use a non-compiled language, such as Python.
That was a very interesting and easy to understand explanation. Functional programming is one of those ways I see discussed very often, yet I don't have much experience with it. Maybe I will incorporate this in the library I'm writing right now, this seems to be a good fit. Thanks for sharing.
If I get time, I’ll reach out. I suspect that the issue I was seeing is directly related to our very old code base (25+ years for some parts) and our relatively new WPF UI coexisting in the same solution. It’s not a gigantic code base but I’m sure we’ve just got some really pathological cases that trip up the various parsers and just make things hard.
There is a Github issue submitted to the Conan project for this thread: [https://github.com/conan-io/conan/issues/5089](https://github.com/conan-io/conan/issues/5089) . I'd recommend /u/gusmedeiros and other interested to follow up there.
If you're going to use it as your main development environment, either will take a long time to get set up just how you want it. But I think both are worth learning, at least to some level. If you ever do embedded work, vi is **everywhere** in a way emacs is not; the basic installed size of emacs25 is an order of magnitude larger than vim, and even busybox provides a vi emulator. You should know at the very least how to basic navigation, search and replace etc. If you're really trying to develop a large body of code, I find vi's modal interface annoying. And emacs-lisp is an easier to use for customisation than... whatever vim uses, IMO.
As I said, the keybindings are horrible. You find some tips on ergonomics for emacs in [`http://ergoemacs.org/`](http://ergoemacs.org/) There is also [http://spacemacs.org/](http://spacemacs.org/) which is an Emacs distribution with evil-mode preconfigured. Spacemacs is a good starting point for beginners. All that said, I really recommend vim (or neovim) as they are much more lightweight and still powerful. I guess that emacs org-mode is the only reason some vimmers change to emacs.
I’m unhappy with the terminology: “curried objects” really doesn’t make much sense. I realise that this blog post simply adapted the notation from the linked paper but that paper doesn’t make me happy either. In reality, what’s being discussed here is a *partially applied function*. A *curried function* is something related but distinct, and mixing up the concepts just creates confusion.
It does not support automatic hierarchies of modules based on their names. But you can use modules names like you did `aaa.bbb.ccc` if you want, and then make `aaa` export that module. You are not forced to do that and it's not a requirement. Maybe some convention will emerge, maybe not.
Scratch should have familiarised you with variables and loops, as well as user input / output to a degree, but the C++ language features many more concepts that Scratch either does not expose to you or it lacks entirely. *Object-oriented programming* and *memory management* will be a significant departure from Scratch and may take a long time to adjust, especially if jumping directly from Scratch to C++. If you're up for it, learning C++ first will allow you to learn "easier" programming languages better, and will quickly teach you the inner workings of many things. Otherwise, if you find the learning curve of C++ to be too steep, you can have a go at learning an "easier" programming language, such as Python.
For a standardized package description, I think /u/vector-of-bool libman ( [https://github.com/vector-of-bool/libman](https://github.com/vector-of-bool/libman)) is really good, a very good candidate for standardization.
There is also an open feature request, that seems it will be added, to be able to explicitly define the target names from within the conan recipes: [https://github.com/conan-io/conan/issues/4430](https://github.com/conan-io/conan/issues/4430)
I think you may learn an intermediate language first to understand well the important things and concepts as they will not has the overhead C++ has, Java, JavaScript, Python, C# or any similar Then it will be the time to switch back to C++ with the Bjarne book, a must, and really go deep, I think it is the correct aproach as learning for yourself is harder and if you the overwhelming that C++ adds i think you may end frustrated From an IDE aproach use one, dont use an text editor, they work and it is great, less resources used, faster and much else but the tool has to be the most useful you can find, the one that you trust and like, try as many as you need until you like what you see. My recomendation is for JetBrains IDEs, they are great and because JB is a company that care about us, the developers, has tools for many many things and it products has very good quality
What about module partitions I read about it in vector-of-bool's blog?
Thanks for the tips for this!
I'll take your advice for this. Thanks!
Awesome! That’s what I was hoping for. The only downside I can think of is now names might become a bit long within hierarchies, as they’ll have to be aware of their depth. Instead of using same names in different directories.
After the first benchmark thinLTO is mentioned.
Direct link to the code: https://github.com/sasq64/autotidy/
C++ is an awful way to introduce yourself to coding. Learn some other high level language instead.
I have no choice. My school is implementing robotics for the first time and I wanna know the basics.
If you are not comfortable with ROS C++ (roscpp), you can try with ROS Python (rospy). Rospy trades runtime execution for fast implementation.
Since you said in other comment that your school has requirement to do Robotics, I'd recommend to start with ROS Python (rospy) first before embarking on ROS C++ (roscpp) if you are not entirely comfortable with the latter. Rospy trades runtime execution for fast implementation. Roscpp is the advanced level C++. Your learning curve will be extremely steep if you haven't been introduced to OOP and many other advanced C++ features before.
Just for reference, this is about [Sean Parent's talk at GoingNative 2013 C++ Seasoning](https://www.youtube.com/watch?v=W2tWOdzgXHA).
Got it. Thanks for the heads-up!
I think admitting your mistakes and making developers' lives easier is a very noble goal. I never use plain arrays in my code because they are extremely dangerous. I'd rather see them fixed then see every C++ developer being bitten by them.
Module partitions are not sub-modules in the sense that they are part of the module name they refer to and they cannot be imported by other modules than the module they are part of. It's a bit like inline files for headers, they are a way to organize the internals of a module, not a way to organize the interface of a bunch of modules.
Modules names are decorelated from their physical location indeed (and you could have modules names like "aaa-xxx" and "aaa-xxx-zzz") from the language POV. However the tooling working group (SG15) is working on publishing a set of strongly suggested setup so that tools can coordinate easier and setup some kind of standard organization of files. The good part is that you and your tools are not forced to follow it, but that might be the simplest way to handle a lot of dependencies.
I only clicked on it because I saw the word curried. Was disappointed.
Yeah. I can’t wait to get my hands on these. I hope the implementation from clang and/or GCC finishes up sometime in the fall!
Fastest way to get it working on Ubuntu 18.04? Couldn't find how to install it without building it on my own
Ah, the groupthink brigade is out in force yet again. Someone goes to the trouble of trying to explain something, then people swoop in to tell people how it's not impressive to them because they can do it in their sleep, as if every piece of programming writing has to be about ground-breaking research. &amp;#x200B; Because everyone should be at the expert level and should not be allowed to write or read about a concept they personally may not have heard before, because YOU have heard it before. &amp;#x200B; At the end of the day, they tried and wrote something. You just downvote people. You done fuck all.
Maybe confusion when it comes to reading other sources that adhere to the distinction. But no one really cares when it comes to writing the code. They'll either end up implementing partially applied function, or a curried object, when it fits the use case, using quite similar code.
**Company:** Mellanox Technologies **Type:** Full time **Description:** Looking for a software/computer engineer to develop tools for the R&amp;D group. The position includes developing and supporting software tools used by the Backend design group, solving challenging design problems using innovative approaches and software development, and being an EDA tools and backend flows expert. Learn more [here](https://relocate.me/denmark/copenhagen/mellanox-technologies/design-automation-engineer-4017?utm=5ccc328ca79e61.97565721). **Location:** Copenhagen, Denmark **Remote:** No **Visa Sponsorship:** Yes. Relocation assistance is offered. **Technologies**: C, C++. **Contact:** To apply, please follow [this link](https://relocate.me/denmark/copenhagen/mellanox-technologies/design-automation-engineer-4017?utm=5ccc328ca79e61.97565721).
Woooo!
Nobody knows what a `rotate` does.
My tip is that you should not do any tricks; write code that is easy to understand, free from any trickery. Another tip is to read a book or two by Bjarne Stroustrup.
built it.
I disagree. This is a huge coincidence but I came across this exact issue in code today (different programming language, same issue). The code used a function `curry` but performed partial application. Due to the arguments it was obvious that the code didn’t perform currying but it took me a moment to realise that it was performing partial application. Not a big issue, but definitely made the code confusing and less readable.
Interesting. In how many cases do you need virtual base class at all? How many times even normal multiple inheritance is used? Anyway, my guess is that the `virtual` case is harder as there is no standard layout for it, but probably the relevant paper includes the reasons for this restriction.
Nobody but Sean Parent, of course
It would be interesting as to what your use case for virtual bases in constexpr is. &amp;#x200B; According to this [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1064r0.html#\_can\_a\_constexpr\_virtual\_function\_override\_a\_non\_constexpr\_one](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1064r0.html#_can_a_constexpr_virtual_function_override_a_non_constexpr_one) it looks like they went with the minimum necessary changes.
What's wrong with building it on your own?
In my experience, wait till its in the ppa [https://launchpad.net/\~ubuntu-toolchain-r/+archive/ubuntu/test](https://launchpad.net/~ubuntu-toolchain-r/+archive/ubuntu/test) . Usually doesn't take too long.
To each their own. I never trust names to begin with so I have a habit of looking at what a thing does rather than what it's called. Inaccurate naming is just too common in programming in general, so may as well not let something like that psychologically affect readability and adjust expectations accordingly.
Loved the talk, and this is a good laugh, well done :-)
Any information on what the actual OpenMP 5 GPU support actually.. *supports* in terms of actually running code on GPUs?
All this did was to make me crave some good curry for lunch!
I think this kind of articles are really insightfull and are worth much more than simply showing some numbers.
I ended up learning both because I kept getting frustrated and bounced back and forth between the two until I ended up getting both (somewhat) figured out :P LSP is [Language Server Protocol](https://microsoft.github.io/language-server-protocol/). You’ll want to read up on it if you plan on using a text editor for c/c++ development. For vim/neovim I use coc.nvim as the client, but there are a few other options as well, and with emacs there’s LSP-mode and polyglot. As far as I know the best c++ language server for both is MaskRay’s [ccls]( https://github.com/MaskRay/ccls).
This looks useful. It reminds me of git add -i
I haven’t looked at VSCode much. What are some of the advantages it adds for large code base management?
linuxbrew
General advice: * Take advice from blog posts, tutorials, books, ^(reddit posts) and teachers with a grain of salt. Quality varies, opinions differ and the language evolves, which erodes some of the older material. * Try to avoid relying on assumptions. What you have learned from one language doesn't necessarily apply to C++. * Be persistent. It takes time and effort to learn a language, especially in case of C++. C++ specific: * Learn about undefined behaviour and adjust your expectations: * Just because program has the behaviour that you want doesn't mean that the program is correct. * Having a bug in the program doesn't necessarily mean that you get an error message. * Occasionally error messages may be misleading and might not directly point to the source of the problem. * Don't use `new` and definitely not `malloc`. All dynamic resources should be managed by a smart pointer or a container. * Don't ever use explicit conversions (called C-style cast), which looks like `(name_of_a_type)expression`. Don't use `reinterpret_cast` unless you know exactly what it does and why you need it. Those can often hide mistakes by circumventing the type system and replacing helpful compilation errors with undefined behaviour.
This helps me quite a lot. Appreciate the help!
Will do. Thanks!
Whats going on with GCN support for OpenACC?
 for (float angle = -3.14; angle &lt; 3.14; angle += 0.2) Don't do this at home kids, use an integer counter and `i*0.2` instead.
This video delivers as promised
CLion is the best IDE for Unix, I mean, Linux, BSD and Mac OSX. Clion has the best completion; CMake support; code navigation and and exploration, for instance it is possible to know all files and lines that uses some class, function or symbol; Another navigation feature is the possibility of listing all classes that inherits some class; listing of symbols on the sidebar; helpful refactoring menu and a C++ linter that shows possible errors before compilation. CLion also shows doxygen comments and type signatures if you hoover your mouse over some symbol. &amp;#x200B; The best free alternative I have found is QT Creator, it is a lightweight IDE with CMake support; code completion; limited refactoring, only symbol renaming; reasonable code navigation, you can go the definition of a symbol by holding Ctrl and clicking at it; listing of functions and classes on the sidebar and a button; button for running CMake targets; Listing of CMake targets on the sidebar. Another good alternative, is KDevelop, which supports CMake too, but QTCreator is less buggy. QTCreator also provides a good GUI for GNU Debugger and UI User Interface Designer for QT Widgets and QT QML. Despite those good features none of those IDEs can match all CLion features including plugins/addons for providing Emacs keybidings, other languages such as Rust, D Language and so on. &amp;#x200B; TL;DR Best CLion; 2nd best QT Creator; 3red KDevelop.
One use of this I am aware of is to "move const T".
That’s the Windows API for you, it is utter junk. Its design is no reflection on what can be done with C or C++. You can use the modern Windows 10-only UWP APIs, they are much saner and better designed and you can use them with standard C++. But, I think Qt still has it beat. There are more resources available to learn it, Qt documentation is of high quality, and it is cross platform.
const rvalue references never made much sense to me. I am yet to see a convincing example of justified usage.
It's used to prohibit rvalue arguments. For example, [https://en.cppreference.com/w/cpp/regex/regex\_search](https://en.cppreference.com/w/cpp/regex/regex_search) does that: it has an overload `regex_search(const string&amp;&amp;, /* other stuff */) = delete`, so that it won't compile if you try calling it with an rvalue string as the first argument.
Game development is still done in C++. C# is a very bad suggestion, partly because it is a language more suited for the same use cases as Java. Churning soulless enterprise apps.
Normal multiple inheritance is very useful for encoding some metaprogramming stuff at compile time.
You are missing the point. When it comes to making native GUIs in game development, it's not about making the game but the tools to support the game. There, C# is widely used as it will make it easy to write GUIs and interface with any native code as needed.
The standard library uses `const T&amp;&amp;` in a few cases to declare rvalue reference overload as deleted. [https://en.cppreference.com/w/cpp/utility/as\_const](https://en.cppreference.com/w/cpp/utility/as_const)[https://en.cppreference.com/w/cpp/utility/functional/ref](https://en.cppreference.com/w/cpp/utility/functional/ref) `const` prevents the argument from becoming a universal reference. It's also used as a return type when of a wrapper (such as `std::optional`) when accessing the wrapped value so the value category of `*this` is maintained: [https://en.cppreference.com/w/cpp/utility/optional/operator\*](https://en.cppreference.com/w/cpp/utility/optional/operator*) [https://en.cppreference.com/w/cpp/utility/optional/value](https://en.cppreference.com/w/cpp/utility/optional/value) I don't quite know the corner cases where these become relevant.
C# is a mixed bag, and as far as I know doesn’t have a cross platform GUI toolkit. Qt is easy to use and cross platform. There’s no good reason to use C#.
What is the difference between moving and copying a const T?
For me it's the debug tools and typical IDE tools like go to defintion/declaration. Also the Vim plugin is top notch
It's not about "admitting mistakes". Changing C arrays would make many, many developer's lives way harder by breaking tons of code in the wild. Not everyone is on the cutting edge all the time. More reasonable would just be to have a compiler warning or clang-tidy check for C arrays. If C++ were going to break backwards compatibility on something so major, there are things that are a much bigger mess (like initialization) that don't have a good solution like "just use this class from the standard library".
&gt;My use case is that I have serialization library that is designed very similar to standard streams. Standard streams are a cute design for demonstrating virtual base classes, but it's kind of doing it unnecessarily. I personally don't find myself only using one of the i-or-o side of streams a lot, and it doesn't cost that much more to just include both i-and-o.
Imagine a file opened in read only mode.
According to [this](https://gcc.gnu.org/ml/gcc-patches/2018-11/msg00628.html) mail, we won't see GPU offloading at least until GCC 10
So? If you opened a file a read only mode, you know you'd only want to read it. Therefore you won't use the write functions. No one has ever screwed up so royally as to try to do that, not even when it was just stdio.h. It's no different from trying to open a file in read-write mode when the file itself is read-only. At some point, you have to know what you're doing and be prepared to handle errors. And since we're talking about constexpr-friendly serialization, you'd know fully well what you are using it for, and you'd have defined the constexpr stream as const or something. Virtual base classes are overkill for that. Like I said, it was cute, but is quite unnecessary.
I recommend installing clang-format. People will probably be more happy to help when your code is formatted in a familiar way. Starting with C++ has improved a lot since I did years ago because error messages have gotten better. Compile early and often. I remember I once wrote a couple hundred lines of code as a beginner, hit 100 errors, solved one, and had 200 errors. If you're missing a semi-colon, the compiler will likely point at a nearby, but different and innocent piece of code. C++ lets you re-use names for functions and picks the right one based on the arguments you pass it. This means that if you make a mistake, the compiler will tell you about all the functions it tried. The function signatures can be pretty confusing, but I think it helps to know that's why you have 30 errors for one mistake. If you hit a segfault, run your code in a debugger like gdb. It will usually tell you what line is responsible.
It's not so special if compilers seem to handle the concept pretty easily.
Well, in my case I almost never needed to read and write to the same stream at the same time. Hence I either take input stream or output stream. And if you have I and O, you have 2 stream positions. Why pay for what you don't use? Even `std::cin` and `std::cout` are different streams.
I'm late to the party, but are these filesystem issues not a problem for includes?
Thanks for the info!
You can get go to definition/declaration (and preview on hover) in vim with LSP, but debugging integration certainly seems to be a weak point.
In [CppCast episode 135](http://cppcast.com/2018/01/arno-schodl/) Arno Schödl makes the case that `tc::min()` from his `thinkcell-ranges` library needs to return a `const T&amp;&amp;` if the arguments are a `const T` and a `T&amp;&amp;` because the result might be `const` or might be an rvalue (jump to [31:01](https://youtu.be/1m9HjBW_3i4?t=31m01s)).
Any word on when the register allocation performance regression introduced in 5-series is going to be fixed? [https://gcc.gnu.org/bugzilla/show\_bug.cgi?id=78972](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=78972)
thinLTO, because LTO with something as large as Firefox would take ages to compile and need something like 50+ GB of RAM. That's the main reason thinLTO was added, even though it has only a part of the optimizations done by LTO and inlining in not quite as good.
You can move the mutable parts of const T&amp;&amp;.
Ah, gotcha.
Any details on setup? I've used YCM in personal projects but had zero luck on my work project which is large and confusing.
On slide 18 around time 23:32 he finishes discussion about node based containers using monotonic allocator. But he didn't say that some containers allocate temporary nodes. This might waste memory. \u\BillyONeal recently [improved](https://twitter.com/MalwareMinigun/status/1123466931271499778) this situation for Visual Studio 2019.
I never had much luck with YCM, but I haven’t tried it for a long time. Right now I’m using [coc.nvim](https://github.com/neoclide/coc.nvim) with [ccls](https://github.com/MaskRay/ccls). As long as there’s a compile_commands.json it should work, but I haven’t worked on any large confusing codebases.
(among other things) First learn the pros and cons of the standard data structures. Then learn and understand what an iterator is. Finally learn about algorithms.
/r/cpp_questions
Use the cmake_multi generator instead of the cmake one.
Thanks for the top ill try it out. YCM is okay typically but always good to see alternatives
What?
Great thanks for the summary.
 [https://godbolt.org/z/GcApri](https://godbolt.org/z/GcApri) Is this a bug or is this intentional? Line 26 breaks compilation.
[https://godbolt.org/z/NOzTsd](https://godbolt.org/z/NOzTsd) And this ICEs it completely.
While I do use Visual Studio Code a lot (daily editing), I'd rather pick something proven like Visual Studio, CLion, QtCreator over it, when comes to debugging, and refactoring. For anything else, I'd gladly use it. I also use "mg" the emacs-mini clone whenever I can. (Folks convince me I should learn vi/vim, but just not my... tempo :))
I have been waiting for GPU offloading using OpenMP for so long.
Why do they always start with some retarded shit like "omg ur "tone" hurts my feelings" when they lose the argument?
I often see articles and implementations of ECS, but cannot help the itching feeling - are they really useful for something or rather a pattern that sounds great on paper but turn out to be useless/overkill in practice?
Why????
Unfortunately, you missed the most common thing that works in C, but does not work in C++; which is the simple pattern: &gt;char \*mem = (char\*)malloc(some\_size); &gt; &gt;//do something &gt; &gt;free(mem); This pattern of matching news and frees, which is perfectly fine in C, is broken in C++. It cannot be made to work. It is the first thing that a C programmer coming to C++ needs to understand. While I understand that you were focusing on compile errors, given the goal of your post this should have been mentioned.
If you add `0.2` to itself enough times you'll start notably diverging from the real multiple of `0.2`. This is not the case with `i*0.2`.
Man I have been saving this article till I had time to read it. What a disappointment. I thought this was going to be a serious discussion of error handling. Instead it is a tiny article written by some guy that looks like he is about 14. Why was this even posted here?
c++2a draft support is not complete. status is experimental. couldn't hurt to report it.
Their bugzilla and its rules are quite intimidating to me TBH. If this qualifies as minimal example though, I'd be glad to do so!
It was sarcastic. According to Sean, his then manager at Google said these words when Sean proposed to refactor a big bunch of explicit loops with a `std::rotate`: "nobody knows what `rotate` does".
I learned a ton from his talks. Big fan
Well it depends how much is it important if you diverge a little. If you just wanna scan the Interval (say for a plot) the i*0.2 is more complex...
I don't think it's appreciably more complex to use an integer index. I think it's well worth never having to think about whether the floating-point errors matter.
They are quite useful. The basic pattern of them has been around in games for decades at this point, with (almost) every major game engine using some form of component-based game-object model. The specifics of ECS (entities are just ids, components are just data, systems are the logic that manipulate components) have various pros and cons over other component models. A lot of words have been spent on those and I won't reiterate them. There are then various ways to implement ECS. With relatively few exceptions, every open source ECS I've ever seen has been very subpar, this one included. And that in turn is why I used to feel similarly to you: I thought ECS was mostly pointless. A _good_ ECS however unlocks all kinds of things that aren't obvious from the basic ECS literature, though. Various people talk about the performance implications of a data-oriented ECS (this ECS is not data-oriented), though that's kinda just the tip of the iceberg. TL;DR: ECS done right has a lot of awesome benefits. Open source ECS are rarely "done right," including this one.
Can you give examples of data-oriented vs. non-data-oriented ECS?
The new Unity ECS is extremely data-oriented and is rather extensively documented in design and architecture, so is probably the best example.
They make compilation much faster
A non-data-oriented ECS would be one like this which uses hash maps to find things. Hash maps are great because they're amortized O(1) lookup, sure, but when you're looking up lots of things, they lead to many cache misses. Non-data-oriented component models also make it a lot harder to do things like snapshot the game state and provide instant game state restoration (e.g., instant mission restart). Every game I've worked on with non-data-oriented models requires _swathes_ of code and serialization and so on just to save a subset of game state and the perf was always bad enough that it requires loading screens and such.
I've reported it. I hope it's in the right format.
The emacs hotkeys are control and alt key combinations. The vim hotkeys are mostly single keys, like the letter keys such as A, B, C, D etc, though there are also some control keys. The constant stretching to reach the control and alt keys in emacs is more likely to induce repetitive stress injury. I don't know if there are any specific scientific studies on this exact topic but this has been my experience. You won't be prevented from RSI by using vim, but I feel the RSI risk is less with vim. My fingers have developed some obvious separation because of my patterns of vim key usage - nothing can prevent RSI except not engaging in repetitive motion. Both vim and emacs however do eliminate a big source of RSI, which is the mouse.
First settle on a build system. That can be CMake, Meson, or Make. If you want package management like you are familiar with in JS or Python you will need either vcpkg or Conan. I recommend using your system package manager though.
If you want to delivery a self-contained *tool* then you can just statically link all of the dependencies and delivery the binary executable. There's a lot of different philosophies and approaches to this problem. I think the first thing to recognize is that your project shouldn't really care *where* the dependencies are. The perspective of the project should be "these are the things I need to work, and these are the versions of those things I have been tested with." When you provide dependencies with your project, whether as git submodules in `./external` or `./third-party` or `./lib`, as a shell script that downloads dependencies and builds them, or whatever you do so simply out of convenience. However, I would be careful to not take away the agency of a person to specify "I know you use this libjpeg, but I use this one in my environment and I think it should be compatible so I'd like to use this one instead." Whether they're installed on the system, in `/usr/local`, in `./lib`, or whatever. You should be able to configure your project to use different dependencies in different locations. A common way to do this is via CMake. If you use `find_path()`, `find_library()`, etc. to search for dependencies then you give the user the option to reconfigure. Those `find_*()` calls in CMake follow a well defined search order which can be configured at build configuration time with the `CMAKE_PREFIX_PATH` variable or in a more fine-grained manner by editing the `CMakeCache.txt` (the `ccmake` text-user-interface program is another way to edit that). Then you can specify arguments such as `HINTS` or `PATHS` to those find calls to help it default to whatever dependencies you might deliver with your project. This way if there's a naked `cmake` call it'll grab your dependencies but if someone goes out of their way to do something like `cmake -DCMAKE_PREFIX_PATH=/opt/my-special-environment` it'll use theirs.
CMake should get generated, at the very least, when a "build" command is triggered, even if it is the first time you issue a build command for a given configuration. You can also make cmake "reconfigure" itself when conanfile.txt or [conanfile.py](https://conanfile.py) changes (I cant remember what command makes this happen but I can look it up). So if cmake is running conan itself, at least you'll know. The problem that I see is that the generated conan/cmake files are typically placed in the "build" directory, but Visual Studio seems to be reading these files (like launch.vs.json ) from the .vs folder in the source directory. Am I wrong? Can a launch.vs.json also exist in the output directory?
Which ECS was done right?
EnTT is pretty good although way too template heavy for my tastes. It uses a custom sparse set container to do lookups which is better than a hash map. Lookup basically boils down to `stuff = dense[sparse[id]]`
It's not very minimal, but it's enough. Here's a smaller example: template &lt;typename T&gt; struct foo { constexpr foo(T) {} }; template &lt;foo&gt; struct use {}; template &lt;typename&gt; using type = use&lt;[]{ return 1; }&gt;; https://godbolt.org/z/dGSynm
If you use meson, you can use the wrap db system and thus don't need a separate package manager; I recommend it for this reason (it's also very easy to use, and cross platform as all heck)
That's for OpenMP 5.0. OpenMP 4.5, which is fully implemented in GCC now, supports GPU offloading. GCC has had support to offload to NVIDIA GPUs for a little while already. GCC has had support to offload to AMD GPUs since GCC v9. Some links: https://sourceware.org/ml/newlib/2018/msg00314.html https://www.phoronix.com/scan.php?page=news_item&amp;px=Radeon-GCN-GCC-Merged