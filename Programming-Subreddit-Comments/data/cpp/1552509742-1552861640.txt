In the case of a buffer that is freed on destruction this would fail pretty hard. This is effectively for a POS. But PODs were not the motivation for move construction. It was for larger objects for which copy was expensive and move would be quicker. E.g. simply swapping the vector buffer rather than doing a deep copy of all objects. So the author's point is the obvious one, IMO
Of course the moves need to be done one by one, the optimizer has to take aliasing into account. There's no way to tell if the two arrays overlap. And there's no way to tell if any of the foo objects are pointing to the same int as another foo.
i wouldn't put it above myself to try and move something into itself (i am not a smart man). yeah tried it i can move things into itself. My implementation is identical to this one (even though i have seen other people do the check, op used). good thing is after freeing the memory with delete x we set the pointer to nullptr with f.x = nullptr. No dangling pointers, at least i've got that going for me. 
delete on a nullptr will call no destructor, or release any resource.
Sorry, I'm lost. Could you please specify, which of your statements belong to which of mine? One of my questions was, where the `copies` code is deleting the objects that may already be in the destination buffer? If the answer is there are none, then we would actually be talking about move construction and not move assignment.
It comes down to short term vs long term productivity. Particularly when you are new to it, using Boost is slow and there are lots of unanswered questions. You will probably do things wrong and have to deal with all of the problems you just mentioned. As you learn more those problems fade away. Doing things three times yourself begins to look inelegant. You are able to do more with less code to maintain. As your project gets bigger this allows you to continue to move quickly. You can focus on hiring employees that already know boost and thus do not need to learn what is available and how to use all of your internal library code. Employees that do not know Boost are eventually happier at work because they know that they are building a marketable skill set instead of just learning the way to do things in your project. &amp;#x200B; Just my 2 cents, but I have seen this work in practice.
You linked to log4cxx, not slf4cxx. I think that's a big difference. log4cxx is not a facace I think.
It depends on what you mean by good and bad. I think C++ is the prime example of "worse is better". I do think it is a bad language in many respects, naive. Designed by someone who was not a language specialist. I could make many examples - but it's probably besides the point. What Bjarne did great though is to think of the language as a bolt-on on C, and keep it that way. He understood people and engineers, and that is more valuable than the academic perfection of other languages, say, the ML family for example. So, it's a great, fantastic bad language. This happens often, I think if you look around, most great technology is not "great", and that's a huge lesson. A similar argument could have been made for example in the heydays of Visual Basic, but it's really a very common and well known thing. Technology per se does not matter as much as we think it does, it's mostly people. That said, I do not understand your specific example. My point was that r_values were not useful because if your structs were always made with certain restrictions, which we needed anyways, there is no cost associated with moving the temporary. So there's nothing to optimize anyways. But more regardless, I would not use unique_ptr, at least not the std one, because then again, all the implementations I've seen are unusable in my context. I counted and in one case it went 7-deep (callstack) for a dereference, in another 10+. Of course, in debug. That is literally, unusable. I do not know what are the constraints why such deep callstacks are everywhere in basic STL stuff, I guess tricks are needed to cover obscure corner cases, but in practice that makes them unusable.
Hmm, not sure what difference that does make? I mean my compiler toolchain is much bigger than that? Should I not use that either?
hijacking this chain. I've used boost asio to implement a primitive http server in the past, but boost beast seems to help reduce the complexity of some parts of that by handling the sockets a bit more automatically and parsing http requests for you. Are there any downsides or additional requirements for beast? I'd love to ditch the request parsing bits I have, but I have to upgrade two versions of boost to get beast.
Sources?
In C++11, a constexpr specifier used on a non-static member function implied const (i.e. the member function _itself_, not in its body); since C++14 it does not.
IMHO this is completely wrong. A copy constructor should do a deep copy, including the dynamically allocated memory (copy of std::vector doesn't alias the original), a move just copies the pointers. Coping a single value is obviously cheaper than allocating new memory and then calling a copy constructor for each allocated object.
Oh yes your right. Unfortunately it is 
Do you have a list of warnings you disable when using -Weverything?
Unless I'm misunderstanding things, you want `#include source uut.cpp` to automatically trigger compilation of `uut.cpp`, as if you had specified it in the compile command? How would you do this? In particular, what includes and defines would be used to compile `uut.cpp`?
Indeed. Or just install it, or request it to be installed. There's **absolutely** no reason or excuse to rely on plain Makefiles.
yes, apparently I was playing around with it too much.
No. The lower the quality of lint warnings, the more effort they are to deal with for little benefit. Linters have been heading towards being less useful as they avoid the hard work of understanding context and add dumb pattern matching. For example, cppcheck doesn't appear to try to do any escape analysis so flags the last line of this as "Same expression on both sides of '-'": const int prevLinesTotal = LinesTotal(); PerformChange(); const int linesAdded = LinesTotal() - prevLinesTotal; This is not helpful and understanding and suppressing it takes time away from more productive work.
you have to open up visual studio installer and add component "C++ Modules for v142 build tools (x64/x86 ‚Äì experimental)", this is required for module support I believe.
https://blog.jupyter.org/interactive-workflows-for-c-with-jupyter-fe9b54227d92
What's so unusual about this? Isn't a try/catch block a normal statement that you can put anywhere that statements can go?
Another important point is that `if (x) delete x;` and `delete x;` do not in general generate the same code. If `x` is `nullptr` with reasonable probability, the branch before the `delete` invocation can be an effective optimization.
Got any example? Is it something that you can't do using a regular try/catch block inside the function's body?
I use: -Weverything -Wno-unknown-warning-option -Wno-c++98-compat -Wno-c++98-compat-pedantic -Wno-disabled-macro-expansion -Wno-global-constructors -Wno-range-loop-analysis -Wno-ctad-maybe-unsupported
For gcc I use: -Wall -Wextra -Wpedantic -Wconversion -Wshadow -Wsign-compare -Wsign-conversion -Wsign-promo One of the sign warnings is included in -Wextra but I list it as documentation. For both gcc and clang I use -Werror -pedantic-errors.
I've actually tried installing using conda install -c conda-forge xeus-cling a few times in the past but it never worked for me. "PackagesNotFoundError: The following packages are not available from current channels:"
&gt; How would you do this? Consider this main.cpp file: #define MAIN #include source "a.cpp" void main() {...} If you will run this : g++ main.cpp then upon parsing the list of input files will be appended as if you issued g++ main.cpp a.cpp As of #defines and other environment variables: a.cpp inherits ones that are active at the point of inclusion. So a.cpp will see MAIN defined. Nothing too sophisticated I would say. 
As far as I know the [std::exchange](https://en.cppreference.com/w/cpp/utility/exchange) is the right way to do it.
So give me a sound borrow checker... Back to the wonderful world of C++: like STL said, it's not perfect, but it's (WAY!) better than nothing.
The if on this == &amp;f is required, some algorithms do assign back to the same object and require it to no-op. I forget which one it was but I've run into this using the STL.
Does `delete` not effectively emit its own branch?
&gt;I need my programs to run well in debug. I'd wager this is not an absurd thing to ask. Compile time and run time is important, and a too slow debug build is as good as no debug build for real-time applications (yes I do videogames). Depending on how you define ‚Äúrun well‚Äù, that may or may not be an absurd thing to ask. I also develop video games in C++, and during day-to-day development my company uses a hybrid of the default `Debug` and `Release` configurations that gives us the best compromise between performance and debuggability.
Both these stacks are caused by implementing empty base compression of the deleter in unique_ptr, since we don't want to pay an extra pointer of space to store stateless deleters. [[no_unique_address]] was added to 20 to eliminate a lot of that stuff.
I am also a modern C++ skeptic and in fact I suspect there are a lot of us out there even though we don't tend to blog a lot. So to answer your question, why is this thing implemented in such a convoluted way!?!? Well first... a ```unique_ptr``` is not just a wrapper over a pointer, it's a wrapper over a pointer and a deleter that allows for the object to be deallocated in a custom manner. So a naive implementation would be as follows: template&lt;typename T, typename D = SomeDefaultDeleter&gt; struct unique_ptr { D m_deleter; T* m_pointer; ... }; But now here's the thing... the overwhelming majority of deleters don't have any state and don't actually use up any memory, they are empty types. But if we implement ```unique_ptr``` the way I just did, then we actually have to reserve some space for the deleter even if the deleter would not otherwise take up any space. That means our implementation will always have a ```sizeof(unique_ptr&lt;T&gt;) &gt; sizeof(T*)```. Since the overwhelming majority of deleters behave this way, we should optimize that situation so that ```sizeof(unique_ptr&lt;T&gt;) == sizeof(T*)```. Okay well there is a trick to do that and it means we need to reimplement it as follows: template&lt;typename T, typename D&gt; struct unique_ptr { compressed_pair&lt;D, T*&gt; ptr; }; ```compressed_pair``` is like a ```std::pair``` but it is optimized to use up only as much space as is actually needed by ```T*``` and ```D```. That is if ```D``` doesn't actually need to consume any space, then ```sizeof(compressed_pair&lt;D, T*&gt;) == sizeof(T*)```. This optimization is known as the empty base class optimization, or EBO. This solves the problem but now in order to access our ```T*```, we can't access it directly, we need to access it through the ```compressed_pair&lt;D, T*&gt;```, specifically it's ```get_second``` member just like how ```std::pair``` has a ```second``` member. So that should help explain MSVC's implementation. Clang's implementation is very similar in that it uses the same technique, but whereas MSVC used a ```compressed_pair&lt;D, T&gt;```, Clang generalizes the optimization even further and implements a ```compressed_tuple&lt;A1, A2, ...&gt;``` which has a more complicated interface. Ultimately the point here is that the STL's implementation is optimal, in fact it's more optimal than what you would have written, or even honestly what I would have written. Every tiny little detail you can imagine has been considered to death to provide an implementation that is minimal both in terms of time and space.
I guess the problem is that unique point can have a custom deleter, but in order to make sure that the deleter doesn't take up space if it is stateless, implementers use EBO techniques, which are themselves encapsulated in a helper class because EBO is used all over the place. But in any case: Yes, I believe there is a far too common believe that layers and layers of TMP induced indirection don't matter because the optimizer will inline them anyway, while completely disregarding "secondary" effects like debug performance and compile time. 
@vecotr-of-bool: Don't you mean '\`export import\`' here? 
I'll agree with you on the standard library implementations looking like black magic, but I also trust them to be well tested for both correctness and performance (when used correctly!). However, it is difficult for me to make any statement on the severity of the issue without seeing any measurements. I use `unique_ptr` all the time (yes I also do videogames), and I have not seen it become a bottleneck. So whether or not this is an issue can only be said after we see some actual numbers.
Yes, I've made a typo.
Note: * The list below is quite long and some of those might actually be useful, I know. * This is not "usually", rather just an initial attempt to compile warning-free a medium-size project (\~200k sloc, \~5 MB) without too much effort (already warning-free in GCC with -Wall -Wextra and some minor exceptions). &amp;#8203; -Weverything -Wno-unknown-warning-option -Wno-c++98-compat -Wno-c++98-compat-pedantic -Wno-conversion -Wno-covered-switch-default -Wno-ctad-maybe-unsupported -Wno-deprecated-this-capture -Wno-disabled-macro-expansion -Wno-enum-compare -Wno-exit-time-destructors -Wno-global-constructors -Wno-gnu-anonymous-struct -Wno-gnu-zero-variadic-macro-arguments -Wno-invalid-token-paste -Wno-keyword-macro -Wno-language-extension-token -Wno-microsoft -Wno-missing-braces -Wno-missing-field-initializers -Wno-nested-anon-types -Wno-nonportable-system-include-path -Wno-old-style-cast -Wno-range-loop-analysis -Wno-return-std-move-in-c++11 -Wno-reserved-id-macro -Wno-shadow-field-in-constructor -Wno-shadow-field -Wno-shorten-64-to-32 -Wno-sign-conversion -Wno-switch-enum -Wno-undefined-func-template -Wno-unknown-pragmas -Wno-unused-member-function -Wno-unused-parameter
How dare you question god's gift to mankind, unique_ptr?? I should downvote you into oblivion! :angryface:
&gt;I am also a modern C++ skeptic From the detail with which you described this, you sound more like a very knowledgeable modern C++ realist.
First, let's talk about what is a `std::unique_ptr`. It is a wrapper around a pointer, providing a guarantee that the pointer stored within the class will be deleted. How does it get deleted? By calling "the deleter". That's why `std::unique_ptr&lt;T, D&gt;` exists. This also means that `unique_ptr` needs to allow for the consumer to tell `unique_ptr` to *store* the deleter, if the deleter is, say, a function pointer. Which means the easiest way to keep track of things is to store something akin to `std::tuple&lt;T*,D&gt;` as an implementation detail. In libstdc++ `operator*` calls `*get()`, `get()` returns `_M_t._M_ptr()`, which calls `std::get&lt;0&gt;(_M_t)`. What all that gibberish means? - `unique_ptr::get()` should return `T*` so `operator*` resolving to `*get()` makes sense. - `_M_t` is actually how the implementation calls the hypothetical `std::tuple&lt;T*,D&gt;` - `_M_t._M_ptr()` is actually `std::get&lt;0&gt;(_M_t)`, which actually pulls `T*` out of the tuple. Why you should not worry: - Default deleter is `std::delete` which is an empty class, so it doesn't need to be stored, making `sizeof(std::unique_ptr&lt;T&gt;) == sizeof(T*)` - All of these functions are defined in headers and will all be inlined if you turn up optimizations. - As a proof, let's analyze the assembly of https://godbolt.org/z/LmL-SR - On line 6 we call `std::cin::operator&gt;&gt;` - to make the compiler actually use the unique_ptr. - On line 8 we call `operator new` - On line 9 we store a value in `r12d` - Lines 10 and 11 store 4 in `rdi` and `esi` which I'm not sure why. - On line 12 we call `operator delete` and free the memory - Line 13 adjusts the stack pointer. - Line 14 copies the value of `r12d` int the `rax`. - Line 15 `pop`s `r12` off the stack. - Line 16 `ret`urns `rax` from `main()` As you can see: - The only `call`s that were made were the calls to functions with sideeffects - `::operator new`, `::operator delete` and `std::istream::operator&gt;&gt;`. - There was no deep nesting of function calls. - `operator*` was not even called. There was no need to. - As long as you let your compiler optimize your code, `std::unique_ptr` is a very desirable vocabulary type.
Cheers.
No epoll fixes yet. ASIO is pretty broken if you need to do thousands of calls a day.
[https://www.etymonline.com/word/skeptic](https://www.etymonline.com/word/skeptic)
Lines 10 and 11 store the address stored in x (i.e. x.get()) and 4 (sizeof(int)) in rdi and esi as they are the parameters passed to operator delete
I've used it a bit in a fairly complex piece of server software to make http requests using an existing asio environment. It's good, no complaints really. Simple API that looks and operates very boost.asio ish if you catch my meaning. I don't think there are any other requirements other than boost.asio but you'll have to examine the documentation to be sure.
Exactly. If OP uses unique_ptrs without custom deleters or with stateless ones, which I suspect, then they could do a simple benchmark by swapping out std::unique_ptr in their project for a simpler implementation and comparing how it runs.
Every time I hear people complaining about debug performance I wonder why they don't enable optimizations or compile in release mode with debuginfo. There is absolutely no reason that you can't have the optimizer turned on while debugging with any modern compiler.
The word skeptic has been abused to mean 'person who just randomly dislikes or disbelieves things for no real reason', I don't think that's how the commenter above intended to use it.
&gt; they are the parameters passed to operator delete I knew they were parameters, but I wasn't paying attention to the arguments of `operator delete`. &gt; the address stored in x (i.e. x.get()) How can `x.get() == 4`? What is actually stored, since actual addresses are not known upfront, thanks to address space layout randomization?
&gt; Every time I hear people complaining about debug performance I wonder why they don't enable optimizations or compile in release mode with debuginfo. Every time I hear people complaining about debug performance I ask myself why they care about debug performance. Invariably if you poke and prod them enough about it you can get them to admit it's because their development cycle is pathological and so "*testing*" what they're writing involves actually running it and manually testing it, and so they care about the performance. The solution isn't to fix the debug performance, the solution is to stop developing software irresponsibly.
Other than the fact for example that optimizations will inline lots of calls you actually -want- to step into (not silly things like an unique_ptr dereference), and a lot of variables won't be accessible? Yeah... I wonder. Mystery
You skipped the fact that the entire point was that -debug- builds matter. I know that the compiler, after some time, will figure things out with optimizations on. That doesn't help.
Could you give https://jwakely.github.io/pkg-gcc-latest/ a try please?
rdi does not contain 4, it contains what is in rax, which in turn is what was returned by operator new.
So how do you debug your tests?
There are many of such tests done by people over time. One recent one is https://zeuxcg.org/2019/01/17/is-c-fast/ Specifically he measures an impact of an order of magnitude, in MSVC, by dropping std::vector. This is not related to unique_ptr, but it's just an example, my choice of talking about unique is also just an example, I could have talked about lambdas or vectors or a large number of other basic things that create way, way too deep callstacks in all STL implementations (again -in debug-)
Have you tried changing `-O3` to `-Og` in my example? It still doesn't call `operator*`. Sure, it gets called with `-O0`, but that is not a useful optimization flag.
&gt; Lines 10 and 11 store 4 in `rdi` and `esi` which I'm not sure why. Only one 4 is stored, in `e/rsi`. The pointer value (`rax`) is copied to `rdi`. These are the two arguments to `delete`.
Perfect! Thank you. This also fully answers my question. I actually did know about the empty base compression and the deleter things, but I always imagined you could still easily avoid the deep stacks. It seems that most STL authors do not care about that, the ease of internal implementation is considered more important than the ease of use. But of course I never dared to assert that positively, because the standard is so complex that maybe all these things were instead required to work around things I can't imagine. MSVC seems to be understanding that's not a good compromise, in fact even in this example it was already the one with the smaller callstack. Which is great.
30 fps debug for a 60 fps release game is a great target. But yes, you can fine-tune compiler options and use lots of tricks and so on. But I don't think you -should-, I think it's a failure of the STL if all that is required tbh.
I hope you're being sarcastic because you've obviously not seen the shitshow that is Rust's `Box` type.
Right... For some reason I read `mov rdi esi`. Well, thanks for the explanation.
&gt;Should have it been an actual language feature (which would also have been made possible checking for actual uniqueness)? How? Why? &amp;#x200B; A unique\_ptr is a pointer and is in charge of cleaning up the object at that address. It can't be copied/shared, so there can only be one owner at any one time, and you can't allocate (through normal ways) a new object at the underlying address. How is that not unique?
Afaik -Og is just -O1 in Clang, added only for compatibility with the "real" -Og that GCC has? It might have changed though
Yes.. lol apparently not obvious I'm being sarcastic, I got downvoted to hell last time I pointed out unique_ptr sucks and everyone just told me I don't understand it when I said it is slow cruft. 
They are indeed ([stmt.stmt]), but I think it's stretching to say that most C++ programmers are aware of that.
Couldn't they use template specialization for the most common case of using the default deleter? Something like this (I haven't tried compiling it, so I don't know if it would actually work): template&lt;typename T, typename D&gt; struct unique_ptr { T *ptr; D deleter; }; template&lt;typename T&gt; class test &lt;T, std::default_delete&lt;T&gt;&gt; { T *ptr; };
My point was that you can find the set of flags that will get you those 30fps in debug builds you mentioned in another reply, though I also know you don't want to do that.
Couldn't they use template specialization for the most common case of using the default deleter? Something like this (I haven't tried compiling it, so I don't know if it would actually work): template&lt;typename T, typename D&gt; struct unique_ptr { T *ptr; D deleter; }; template&lt;typename T&gt; struct unique_ptr &lt;T, std::default_delete&lt;T&gt;&gt; { T *ptr; }; 
The downsides are managable. I almost exclusively use RelWithDebInfo builds. Any issue that requires me to open a debugger (rather than insert a few prints/write a test case) and do serious examination is one that is rare enough and complicated enough that some inlining/inaccessible variables will be the least of my problems.
&gt;but I always imagined you could still easily avoid the deep stacks. &gt; &gt;It seems that most STL authors do not care about that You're always welcome to show how much the STL authors should care about it, if you're so certain they aren't caring enough, and you're so good with your imagination.
If you check the release build, both work just as you'd expect, no overhead. There are ways to optimize to get this improvement without losing helpful information.
You can have a custom deleter that is stateless, it is quite common. I think it'd be better to go with SFINAE, with two definitions that check if `D` is stateless or not. But that's more code than using `compressed_pair`.
[Catch2](https://github.com/catchorg/Catch2/blob/master/docs/Readme.md#top), my tests are fairly simple so this works out for me. Seems like it's got great support for the more complex stuff. What do you use?
I'm not the parent poster. And I don't work on games But I strive to have an automated test of some sort exercising every line of code I write, and in continuous integration before merge/submit all affected tests run in debug and optimized mode (along with runs that use various sanitizers). In my basic iterative development it's minimally optimized builds with all assertions on, optimized for compile time effectively. When debugging a problem I try to quickly get to a point where I can write a failing test that tickles the bug. And if you need to access a variable just add something that prints it out and then run the test again. You can iterate very fast. If you have good test coverage and can iterate on debugging by exercising the buggy code in a test rather than normal operation then you don't really need to care that much about the run time of code in debug mode, and you get nice rich debug information.
As a few others have pointed out on this post, your fixation with the performance of debug builds is what seems misplaced. You shouldn't need it, and if you do then you're either working with poorly tested (or poorly testable) software, or not leveraging all the potential tools at your disposal. If that's where you are at then there's probably not much you can do about it, and probably isn't even your fault, but it's also not the fault of how modern C++. I work in realtime software as well. Though unlike in a video games, violating our realtime contract doesn't result in dropped frames, it results in a hard stop that wastes significant amounts of both time and money for our customers. Any crashes in the field are a major problem for us. Plus we ship our own hardware which means we are profit motivated to use the least powerful devices we can. Even if our debug builds could run at a significant fraction of the speed of our optimized builds (which we'd never expect) it would still be grossly insufficient. Instead we have things modularized and unit tested, and any code path we want can be accessed via a unit test small enough to run in an arbitrarily slow debug build. If there's an integration level crash/corruption/etc missed by the tests, then a combination of code sanitizers and optimized debug builds is more than enough to locate the problematic code. By that time the error is either obvious, or localized enough to be reproducible via a new targeted unit test (which should be added anyway) for more low level debugging. We use full on modern C++ throughout our code and it's been nothing but a boon, allowing us to write high level and safe abstractions that completely optimize away (and I spend a lot of time neck deep in profilers ensuring it really does optimize away). Yes our debug builds are majorly slow, but it's never been a large impediment to us. Now on a related note, it *can* be super annoying when you use a debugger and have to step through your seven layers of stl just to get to the other side of something like a unique_ptr dereference. For gdb at least you can configure it to skip such things, though it sounds like you work on windows in which case I'm less familiar with what options you have.
If the overhead was unavoidable, and the benefits of using these things were great, I would agree with you. But the overhead is totally avoidable it turns out (MSVC 2019 apparently fixed this as per someone else's reply). So it's good to point out every time STL is wrong, for me this is closed now as I got a reply that answered the question (and the answer is - there is zero reason for this to happen) Re: the software quality. Of course we don't drop frames and things can be tested at any FPS, but that doesn't mean that the team won't feel the pain. A bad debug experience is bad, debugging is a significant part of software development, let's not kind ourselves. No excuses.
Good for you. That's not my experience nor what I asked. I asked if there is a reason why this -has- to be this way (and the answer btw, is no, someone else proved it). I don't care that you can find some workarounds that work for you 
https://bartoszmilewski.com/2009/05/21/unique_ptr-how-unique-is-it/
I believe the feature in MSVC is just my code. https://devblogs.microsoft.com/cppblog/announcing-jmc-stepping-in-visual-studio/ https://docs.microsoft.com/en-us/visualstudio/debugger/just-my-code?view=vs-2017 https://docs.microsoft.com/en-us/cpp/build/reference/jmc?view=vs-2017
Not on all compilers no, and in my opinion, it shouldn't. There are cases where you know the pointer is not null and it would be a deoptimization. Also, even on compilers where the check is inlined, it appears that `std::free` does not receive the same treatment.
I didn't do a good job with that class :( I sort of haphazardly tried to extract code from a larger class I've had and it's definitely got some bugs. The point I was trying to illustrate was only the relocation behavior. 
This is a super combative way to say this.
By far the biggest problem with modern C++ is the approach of "if it can be done in a library, it should be" because it means instead of getting nice syntax and things that are implemented properly, we get horrendous hacks and syntax that looks like brainfuck. I use very C-Styled C++ and I avoid STL when it's reasonable to work around it. Even something like a closure is a pain in the ass in C++, and that's one of the few times we got new syntax IIRC
You're suggesting that an object with an owner should never allow non-owning pointers or references to exist?
None at the moment. I'm on the Curriculum team at Codecademy and we are currently picking out a testing framework for the Learn C++ course. We are currently looking at Catch2 and doctest.
11 years, processionally. 18 years overall. I wouldn‚Äôt worry about the language, just focus on solving problems. The language is just a way to express a solution. C++ is big and heavy, but you only need to use what you need for a given problem. Personally, I like the extreme programming methodology of simply solving the problem you have at hand and refactoring a working solution into an optimal one. I‚Äôve found, professionally, that always works best.
I just went ahead and created a sub-reddit, so that there will be a good way to have real discussions (aka, a real way for people to abuse me.) [https://www.reddit.com/r/CIDLib/](https://www.reddit.com/r/CIDLib/) &amp;#x200B;
I'm suggesting that two unique_ptr(s) can trivially point to the same object. Of course it would be ok to allow non-owning pointers out of an unique_ptr, but there aren't such things in C++ as all these things are not language concepts, just some library things. That doesn't mean they couldn't be
Yes they added this. Before you couldn't even debug modern c++, now you can but it's slow
Sorry, but that blog post is abusing the word unique to fit more into it than reasonable. Use-after-move and thread safety are real problems, but isn't anything specific to "uniqueness".
You have to go out of your way to have two unique\_ptrs point to the same object. So no, not "trivially". Your argument amounts to "unique\_ptr isn't a shared\_ptr".
Much less combative than the OP...
&gt; By far the biggest problem with modern C++ is the approach of "if it can be done in a library, it should be" That approach isn't "modern". It's always been part of C++'s core philosophy. In Stroustrup's book "The Design and Evolution of C++" from 1994, for example, he says this: &gt; More often than people realize, designing a library is better than adding a language feature. Classes can represent almost all the concepts we need. ... Designing libraries is more often than not the most constructive outlet for enthusiasm for new facilities. Only if the library route is genuinely infeasible should the language extension route be followed.
STL authors definitely don't care most about ease of implementation, otherwise they would have a member to store the deleter even when the deleter was stateless. They go to ridiculous lengths to ensure that the unique_ptr is one word smaller, which is definitely not easy. All STL implementations have the exact same API so they are pretty much equally easy to use. The implementers don't have much say here.
Catch2 is great. But I have a mixed feeling about it. The `#define CATCH_CONFIG_MAIN` thing really bums me out. I am not comfortable with the same header behaving differently in various translation units within a single build target.
It's not an STL specific problem. Games have never run well in completely unoptimised code, ever. My earliest games were written in straight C (pretty much, a touch of "C with classes" here and there), and they performed poorly in debug too (unplayable). It has always been this way. Interestingly, one of the games I worked on recently used STL profusely, including the algorithms, and it actually performed alright in debug. It turned out that using std::algorithms is a performance win in debug because they unwrap the iterators before calling the actual implentation and thus don't rely on the optimiser as much. 
Yeah it's awkward, but that's inevitable for the type of thing it's trying to do right? Single headers with heavy on the macros. Maybe there is a better solution that doesn't involve other files.
I get that, but it has really only become a major problem recently with all the new additions. I don't know why.
I really want a debug optimisation mode that fully optimises/inlines STL code but doesn't optimise my code. Something like VSs 'Just My Code' debug stepping but for optimisation. Obviously this could get messy when we pass lambdas into STL functions but it would really help the vast majority of my debugging work (ie. inspecting why MY code isn't working) while improving debug performance by not running through all the function chains inside STL code.
If i'm not mistaken it can be re-written in C++/WinRT "projection". which is basically a standard C++17 wrapper around the same platforms(UWP) underlying API's.
The reason is actually pretty good. When designing a feature, the standard library dictates the API, but implementors can try various things to see what works best. std::string is a perfect example of this (while this class isn't perfect API wise ...). Most languages consider strings to be a built-in feature. By making it a library implementation detail, we were able to explore different methods of implementing its API and learn over time what works best. For a long time COW seemed superior, but then we learned that it has real problems in a highly concurrent system. So now we know that SSO is generally a better approach for best performance. If this was built into the language, people would have to wait for a new version of the standard to get the performance increase. But since it's a library detail, they can upgrade just the standard libs and get it sooner. It also encourages innovation among groups such as boost. Since they can add robust features without having to try to get something through standards approval or hacking on the compiler to try put ideas.
I get this. It definitely has advantages. But it's also why the language feels so clunky to use so often and has so many things in it that feel like workarounds while being standard in other languages. If I want something like properties, for example, I can either live without them (which I guess is possible), or create a hacky property object which will likely result in so much extra code that it defeats the purpose anyway.
Sure. Fair points. I do feel that concepts and herbs Sutter's meta class concepts will help a lot. With those downsides though. So hopefully we'll get those sometime before I retire üòÇ
Does that also affect vector etc? In a tight loop, with or without iterator debugging, vector op [] bites because of the same reason
tbh I would be happy if they implemented properties, readonly variables, and a few other minor features from other languages as keywords, and let everything else be library stuff.
I would *love* to hear how you test games without playing them.
This is why I don't use debug builds of our client 99% of the time.
Not really.
[removed]
Your comment has been automatically removed because it appears to contain disrespectful profanity or racial slurs. Please be respectful of your fellow redditors. If you think your post should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Vulgar%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b0sq6p/unique_ptr_seven_calls_to_dereference_why_is_this/eihkhsm/?context=3.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
[Doctest](https://github.com/onqtam/doctest) \- covers all my needs and the tests have really fast compile time.
I find your reasoning hard to follow. If the problems you‚Äôve experienced were problems with the standard itself (STL), then they wouldn‚Äôt be able to be fixed/avoided by any compiler. The fact that this issue has been resolved in MSVC is evidence that the STL is *not* ‚Äúwrong‚Äù, but that compilers have room for improvement. It‚Äôs not Modern C++ that has problems, it‚Äôs immature implementations. How is this acceptable? I suppose because people value correctness over performance. 
&gt; their development cycle is pathological &gt; The solution isn't to fix the debug performance, the solution is to stop developing software irresponsibly. Going off as though game developers have never heard of automated testing makes you sound like a huge jerk.
if could recall, knew this from Effective C++'s item 'Write placement delete if you write placement new', whew\~ long time ago :-P 
OP used veiled language, like "byzantine" and "incompetence", and a loaded question like "why is the implementation so bad"? And saying most STL authors "do not care". What makes that less combative than my comment, which was merely using his own words?
OP heavily qualified use of that language and went out of his way to be charitable to the people he was criticizing. The same cannot be said for your comment.
We disagree whether the PVS Studio warning is useful then. To me, it is. I would have preferred that the encountered begin/end sequence is used consistently, even for the error case.
Boost.Test as we are using the Boost library anyway. It's very good, but if we wouldn't use Boost it would probably add too many dependencies.
OP didn't qualify anything, let alone be charitable. I quoted the exact words he used. Pray tell where are the qualifications and charitability? At best, they were sarcastic.
My argument is that unique is not a language feature and thus cannot be checked for actual uniqueness. But it's not the only or biggest issue. See in the original post, how it already degrades if you store uniques in a vector. So you got a convoluted implementation in STL for something that is still not quite great. Either make the implementation simple, or make the feature powerful.
Most Call of Duty games run at 30+ fps in debug.
I should have said "STL implementations are wrong" - the whole point of this post was that I didn't know if these were just implementations that didn't care about debugging, or if they were forced to be bad because of some obscure standard thing
&gt; But I am not a language lawyer and **I am open to change my opinions*, so I want to run an experiment here, *among people who surely understand the language more than I**. &gt; One of my core issues with modern C++ is that relies a lot on STL, and that STL seems always to be implemented in byzantine ways. **I assume that's not due to incompetence, but to the complexities of the standard**, but still that makes most things a no-go in my use scenarios. Perhaps you confused sincerity for sarcasm.
But it is unique. It's unique by construction. Unless your allocator is buggy, no allocator, not even "new", can create two objects in the same location. Therefore they are unique. Therefore you don't need to check it. Storing uniques in a vector is slow. So what? So is storing a bunch of file objects in a vector.
People who are open to changing opinions don't need to say it. The second bold is obviously sarcastic. The third bold is also sarcastic. Why would he need to assume its not incompetence, and tell everyone about it? Sincere people don't say such things in the first place.
Note, I'm not trying to convince anybody that they should use makefiles, but it seems odd to me to say that there's absolutely no reason to rely on plain Makefiles, so I want to share my perspective. Most of my open-source projects have a custom small Makefile and CMakeLists.txt. I add CMake for other people to use to integrate my code, especially for Windows/Visual Studio, and make for me to work on my libraries (and for other people to run tests etc. if they need to). &amp;#x200B; Here's why. &amp;#x200B; CMake pollutes source tree with build artifacts by default. You can use command-line options to fix that, but just typing "cmake" in the root of the project will always do the wrong thing. My Makefile works if you just type "make". (this one is especially puzzling - it already creates CMakeFiles folder, why doesn't it put \*everything\* in it?!?) CMake is not terribly fast when it needs to rebuild configuration, so whenever you switch options - I tend to do this often - you're waiting for tens of seconds to just start the build. I think this might have gotten better over the years. CMake is painful to use if all you need is to run a few shell commands. With Make you need to remember basic syntax - target : sources\\n&lt;tab&gt;command - and know your way around shell, which I already have to, with CMake it seems like you either need to keep a lot more in your head or Google/StackOverflow the recipe for a particular problem you have. CMake doesn't build your code so you need to either alternate between cmake / make, or type cmake --build every time. \`make\` is short. CTest is abominable - the default output is horrendous, it's clunky to set up. I don't recall the full set of issues, sadly, I remember I tried to use it in pugixml and ended up giving up and using add\_custom\_command. &amp;#x200B; Fundamentally, CMake adds a level of abstraction that is useful when you consider other people who might want to build or install your code, include your library as a CMake submodule since they're already using CMake, or environments without working make or shell, but I find that make is the build system with least friction for small projects. Make doesn't scale super well to large projects although you can push it.
I burninated _Get_second.
I believe you are mistaken. It's hard to communicate sincerity on the internet, so you frequently need to spell it out. At the very least, there is this ambiguity, whereas there was no ambiguity as to how we should interpret your comment.
At the end of the day, the benefits outweigh the downsides.
Googletest - as it offers also a mocking framework, which fit good together. 
Thanks, for clearing that up! I was right somewhere down the line ;-), no longer so.
Funny how you think OP was ambiguous, yet my deliberate mirroring of his words are somehow not ambiguous. Maybe you should think about that.
The easy integration with CMake is why I chose this for my latest project.
&gt; may well go back to try and clarify it better when I get a chance. I'd enjoy that! I'm picking up what you're throwing down (comparison to [[trivially_relocatable]] helped), but I'd be interested in reading more details.
I did think about it, and I have been sharing my thoughts with you. ¬Ø\\\_(„ÉÑ)\_/¬Ø
Also using Catch. It's got some minor issues, mainly that assertion macros can only be used on the main thread (I haven't upgraded to Catch2 yet, hopefully it's fixed now). For the most part though, it's simultaneously clever and easy to use.
While the standard doesn't explicitly say that null pointers result in a no op, it does say that the pointer is allowed to be a null pointer and it also describes the behaviour of operator delete as "if the pointer is not a null pointer, then ...".
I think he's saying that you shouldn't need manual testing at all until much later in the process. Your development loop should lean heavily on automated testing, and you can do final validation of your change manually with an optimized build just to make sure everything works right.
You thought really hard about how to interpret OP generously and how to force yourself to see a similarly worded comment in a completely different light, that's for sure.
Just wanted to say thank you for doing this. It really is very important to a whole bunch of people and a welcome dose of common sense against all the ‚Äòjust use an optimized build with debug symbols‚Äô nonsense in the comments.
Didn't take *that* much thought ü§î
I enjoyed reading through this thread. He won‚Äôt admit that saying, ‚Äúhere‚Äôs why I think this is bad and could be better, can anyone explain why I‚Äôm wrong?‚Äù is much less combative than saying, ‚Äúif you don‚Äôt like it, fix it yourself‚Äù
11 years in the industry, a fair bit more if we count freelancing and working on personal projects. C++ demands a deep understanding of its dark corners and its multitude of features before it can be used effectively. It's conceivably possible to learn e.g. JS by doing, to use it with just a superficial experience, but with C++ you have to read a lot and practice even more until you feel comfortable with all of its many crucial nuances. Failure to do so leads to mediocrity that is evident in many so-called C++ developers on the market today, writing glorified "C with classes" that is neither maintainable nor safe. Don't be afraid to make mistakes, but know that without some sort of tight mentorship your first several projects are going to be embarrassing when you look at them years later. This is speaking from personal experience.
Are you aware that you can turn on debug symbols in release mode? You may find that's good enough for debugging. It's not ideal e.g. you can't put a breakpoint on every line (because some have been optimised away), and single-stepping through the code sometimes causes the current line of code to jump around (because the compiled code has been reordered), and you can't view all variables in the watchlist/locals (because some have been optimised away). If this is a problem you could turn off some selected optimisations. The main thing is that you leave the debug version of the STL turned off. You should be able to find an acceptable trade off of performance and debuggability. You could save this as a new configuration alongside "debug" and "release" in your project (CMake gererated projects have this as "relwithdebinfo"). Or you could just replace the "debug" config with it.
Maybe a naive question, but wouldn't it also be possible to achieve that by partially specializing for stateless deleters?
I don't know anything about game development, but I'm not sure how well you can automate testing for such highly interactive software. Remember a lot of what games do is focused on human perception.
Can you elaborate more on this - 'epoll fixes'? I mean, we have proxy applications for HTTP and P2P traffic which use ASIO as a networking library. We run something like 300 proxies in different locations. For example, one of them is currently handling 12 Gbps HTTP traffic and it's doing relatively well. I agree, that ASIO has some stuff that may have been done in a different way and it could have been made more performant (the mutex near epoll, for example) but 'pretty broken' is probably a bit of a stretch. 
This is one of the most important optimizations done by modern compilers, glad that it gets mentioned, it's quite seldom to find any article or research paper that talks about it. Which is strange, considering that it has quite a big impact on a lot of the code that's common in C++.
Prior to the addition of Concepts to the language, you couldn't partially specialized the whole class template, because that would require adding a new (defaulted) template parameter, which would change the class API, and not conform to the standard. So you partially specialize some piece of the internals instead, which adds an extra level of indirection. Which is what the OP is complaining about. With concepts you could do it, but now you have to implement the whole class template four times (for each combination of single object or array, and stateful or stateless deleter).
I have quite the opposite impression: A small CMakeLists.txt file is very easy to write (from scratch), and much more readable than any Makefile, including the one you posted. Makefiles, when growing larger, tend to become completely unparseable in my opinion. (And don't get me started about *autoconf*, which is a more apt comparison to CMake, capability-wise.) CMake abstracts from the compiler; in fact it's made for cross-platform development. Try taking your Makefile to non-UNIX-like platforms. Need to test some properties, or generate some files? CMake has you covered; with Makefiles, you're at the lowest possible level of abstraction. &gt;CMake pollutes source tree with build artifacts by default. You can use command-line options to fix that, but just typing "cmake" in the root of the project will always do the wrong thing. Well, *don't* build in-tree then. which is bad practice anyway. It's quite easy to not do that. Even a sub-directory called `build/`, and your source code is clean. I don't see what's so difficult with that. &gt;CMake is not terribly fast when it needs to rebuild configuration, so whenever you switch options Haven't noticed this yet; especially when re-run, it's quite fast. Unless you maybe do lots of very custom tests. &gt;CMake is painful to use if all you need is to run a few shell commands. I don't think so. In most cases, you just need `add_project`, `add_executable`, `add_library`, and the `target_* commands`, and maybe a bit more boilerplate for installation. If you think it's complicated, you're not using the "modern CMake" subset. And, if you want a maintainable and distributable build script, please, \*don't\* call shell commands out of the blue, since you can't expect the user to have command X installed. &gt;CMake doesn't build your code so you need to either alternate between cmake / make, or type cmake --build every time. `make` is short. That's totally a feature for me. Without any custom configuration, it's only a few letters more, but you gain so much. (Generation of any kind of build file, cross-platform, etc.) &gt;Fundamentally, CMake adds a level of abstraction that is useful when you consider other people who might want to build or install your code, include your library as a CMake submodule since they're already using CMake In most of the cases, that's going to be *you*, not just other people.
I said this a couple of times: The fact that you can write your own string class to satisfy specific needs is a strength of the language. The fact that there is no built in string (whose implementation could be changed just as the implementation of std::strings) and the compiler really has no notion of what a string is is imho a deficiency in the language and imho a problem for optimizations (an I think we still won't have a constexpr string in c++20 - right?). A while ago I ranted about native arrays vs std::array. std::array has the right semantics, but there are some edge cases, where even with c++17 it is less convenient to handle and even in one of the later gcc versions it had some compilation problems in constexpr contexts. Not to mention compile times.
With "C/C++"? 0 years, since I've never heard of that language. But seriously, please take it as good advice to not lump C and C++ together like this -- they're different languages. You also wouldn't write "How long have you worked with PHP/Python?" without getting raised eyebrows from the Python community.
Turn on optimizations, disable inlining (or enable only for `__inline`).
This is _kind of_ off topic, but as someone who works in games I feel your pain. &gt; and a too slow debug build is as good as no debug build Obviously it's ok if a debug build is slower than a fully optimised build, within reason. My go-to for this has been to add an extra build configuration, and compile _everything_ with the release CRT (in MSVC) and then my actual application with inlining turned on. At that point some bad pointer chasing should be acceptable 
That makes sense. Thank you. Still, 4 levels of indirection (not to mention 7) sounds a bit excessive. Out of curiosity:Is the STL allowed to add public base classes to a type?
C or C++?
One thing missing from that is using the release CRT with the debug build (which is what clang and gcc do) , and also checking std vector with a custom allocator, which would be my first call. 
The STL was a library of algorithms, iterators and containers in the 1990s. The C++ Standard Library can do anything it likes if it doesn't change the behaviour required by the standard. Generally the presence of base classes, public or not, is not observable to a conforming program, because a conforming program never names a type like __uniq_ptr_impl&lt;T,D&gt; (but reflection will change that). An implementation might impose its own limitations on such things, e.g to avoid changing the layout of types between releases.
Not that reddit is representative, but that seems to be the answer. Thanks. 
Thanks for the offer, but I have no intention to use it. It's just that every now and then I tend to stumble over some ifdefs or docs that seem related to stl port and that made me wonder if there are still users or if those are simply remnants.
I don‚Äôt know anything about automotive software but I‚Äôm not sure how well you can automate testing for such highly interactive software. Remember a lot of what cars do is focussed on human perception.
I know, but I as long as the c++ standard library doesn't get an equally simple abbreviation I tend to follow u/STL's example (at least in forums like this) ;) Anyway, thanks again for the explanation. 
&gt; Your development loop should lean heavily on automated testing How, then? Specifically, how do you automate testing of complex real-time simulations that don't require perfect results nor are safety-critical, *while being financially responsible*?
I like std::lib.
&gt; the solution is to stop developing software irresponsibly. Maybe what you don't realize is that software development is not done in a vacuum of infinite time and resources. In particular, doing what you say would actually be irresponsible, not engineering-wise, but financially.
&gt; it results in a hard stop that wastes significant amounts of both time and money for our customers. Any crashes in the field are a major problem for us That is the key. Videogames don't really care about crashes. They are not safety-critical. Of course they try to minimize them, but having one every X game-hours is not really a problem. Going the extra mile to ensure there aren't any crashes at all by having an automated test suite covering every single condition takes a huge amount of money and it is simply not financially responsible nor possible in the long run. People like to discuss engineering principles, which are all dandy, but fail to put them in the right context.
I'm a little confused what `compressed_pair&lt;D, T*&gt;` contains. In the case that `D` is not a custom deleter, how does `~unique_ptr()` call it? I tried looking at compiler explorer, but [it's not totally clear to me what's going on](https://godbolt.org/z/b4orWS). Thank you for this in-depth explanation. I've always wondered why `sizeof(unique_ptr&lt;T&gt;) == sizeof(T*)`.
ok,thanks for your advice. but in some scenarios like network,filesystem,C++ developers still have to use C instead,right?And they can be combined easily.
&gt;in some scenarios like network,filesystem,C++ developers still have to use C instead,right I'm not sure where you might have heard that. There are excellent C++ libraries for networking and filesystem operations, either external or in the standard. You definitely won't have to drop down to pure C. You might want to *call* the occasional C function in C++ (e.g. some OS-level functionality), which is certainly possible, but I wouldn't call that "having to use C".
I happen to know a bit about that and for one, they use far less automated testing than I'd like (that might of course vary from company to company and department to department). Second, most requirements that hand-written software has to satisfy has nothing to do with human perception (things like control algorithms are largely written in simulink and apparently there is a lot of hand-tuning going on there), third the complete development process and constraints are probably drastically different between the two industries (again, I've never worked in game dev, so I might be wrong), which leads me to fourth: I'm not sure what the point of your post is to begin with. What has gamedev to do with development of automotive software? If your point is that I should not make comments about things I don't have experience with, well, that is why I qualified my statement and why I said, "I'm not sure" and also I'm convinced that the same is true for most posters here anyway.
Not exactly mobile friendly, but I like the idea.
ok,thanks. But i have some doubts about "writing C with class". after all,C++ standard libraries are so incapable of handling network,filesystem,time and so on.So,i what to know what your opinion is about this.
Debug build with optimizations
I remember that chandler carruth said on a talk that you'd probably not get a lot of performance benefit out of that, but it would be interesting to see some numbers on that. You'd certainly save a lot of function calls.
Though that might, for example, optimize away the range check of std::vector::operator[].
&gt; **‚Äù** Got any example? Well, it's non-trivial. The exception type can sometimes be crucial, e.g. for the result of `std::stoi`. Which means that rethrowing should better not just rethrow a `std::runtime_error` with the same or extended message. And since `std::exception` is imperfectly designed, not supporting clone-throwing, the original exception should be rethrown. Which means that the stack trace items need to be just *associated* with that exception. Which means static storage. Which means threading issue, which means using `thread_local` storage. Then, adding a stack trace item should better not itself throw (!), or there should be some way to ensure it will have the resources it needs. Which means using a free list. In the support machinery below I use a simple linked list of pointers to C strings, which represent the functions that an exception has propagated through: #include &lt;cppx-core/_all_.hpp&gt; // https://github.com/alf-p-steinbach/cppx-core using C_str = const char*; #define STACK_TRACE_BEGIN \ try{ #define STACK_TRACE_END \ } catch( const std::exception&amp; x ) { my::add_stacktrace_item( x, __func__ ); throw; } namespace my::impl { $use_std( exception, exchange ); struct Node { Node* next; C_str function_spec; }; void link( Node*&amp; a_next_pointer, Node* new_node ) noexcept { new_node-&gt;next = a_next_pointer; a_next_pointer = new_node; } auto unlinked( Node*&amp; a_next_pointer ) noexcept -&gt; Node* { return exchange( a_next_pointer, a_next_pointer-&gt;next ); } auto length_of( Node* p_list ) -&gt; int { int n = 0; for( Node* p = p_list; !!p; p = p-&gt;next ) { ++n; } return n; } struct Free_list { Node* first = nullptr; auto allocate() -&gt; Node* { return first == nullptr? new Node() : unlinked( first ); } void deallocate( Node* p ) noexcept { link( first, p ); } ~Free_list() { while( !!first ) { delete unlinked( first ); } } Free_list() {} }; struct Stack_trace { Free_list allocator; Node* first_trace_node = nullptr; exception const* p_exception; void clear() noexcept { while( !!first_trace_node ) { allocator.deallocate( unlinked( first_trace_node ) ); } p_exception = nullptr; } void add( const exception&amp; x, const C_str a_function_spec ) { if( !!p_exception and p_exception != &amp;x ) { clear(); } Node* p_new = allocator.allocate(); p_new-&gt;function_spec = a_function_spec; link( first_trace_node, p_new ); p_exception = &amp;x; } void set_capacity( const int n ) { const int n_current = length_of( allocator.first ) + length_of( first_trace_node ); const int n_new = n - n_current; for( int i = 1; i &lt;= n_new; ++i ) { link( allocator.first, new Node() ); } } ~Stack_trace() { clear(); } }; thread_local Stack_trace the_stack_trace; }; // namespace my::impl namespace my { $use_std( exception, string, vector ); void ensure_stacktrace_capacity( const int n ) { impl::the_stack_trace.set_capacity( n ); } void add_stacktrace_item( const exception&amp; x, const C_str func_spec ) { impl::the_stack_trace.add( x, func_spec ); } auto stack_trace_for( const exception&amp; x ) -&gt; vector&lt;string&gt; { auto&amp; tr = impl::the_stack_trace; if( not tr.first_trace_node or tr.p_exception != &amp;x ) { std::clog &lt;&lt; "Gah!" &lt;&lt; std::endl; tr.clear(); return {}; } vector&lt;string&gt; result; for( impl::Node* p = tr.first_trace_node; !!p; p = p-&gt;next ) { result.push_back( p-&gt;function_spec ); } return result; } void clear_stacktrace() { impl::the_stack_trace.clear(); } } // namespace my The shown macros can be used as function try blocks or within a function: namespace app { $use_std( cout, endl, stoi ); void present_answer() { STACK_TRACE_BEGIN cout &lt;&lt; stoi( "forty-two" ) &lt;&lt; endl; STACK_TRACE_END } void run() STACK_TRACE_BEGIN present_answer(); STACK_TRACE_END } // namespace app The main problem with placing them within a function is that it opens the possibility of maintenance placing code before or after, code that can throw, so that the function won't show up in a trace. Of course, since the scheme is so ugly and impractical for ordinary programming, it's doesn't really matter. :) Anyway, a main function, showing one way to present a trace: auto main() -&gt; int { $use_std( cerr, endl, exception, string ); my::ensure_stacktrace_capacity( 42 ); // Not necessary, just playing nice. try { app::run(); return EXIT_SUCCESS; } catch( const exception&amp; x ) { cerr &lt;&lt; "!" &lt;&lt; typeid( x ).name() &lt;&lt; " " &lt;&lt; x.what(); for( const string&amp; s : my::stack_trace_for( x ) ) { cerr &lt;&lt; "\n -&gt; " &lt;&lt; s; } cerr &lt;&lt; endl; my::clear_stacktrace(); } return EXIT_FAILURE; } Output with g++: !St16invalid_argument stoi -&gt; run -&gt; present_answer 
I work in telecom, developing software for a node in the core network. It's a very complex piece of software, that depends on communication with many other nodes. If you are not careful when you implement a feature, it's very easy to break some other feature. In order to avoid this, part of our responsibility is to write automated tests to verify that our feature works. This is somewhat useful for us to verify that our feature works, but it could also be done manually during development. However, it is *critical* in verifying that the feature continues to work as more features are piled on top of the old features. In fact, the regression testing is so important that significant work has gone into developing an entire framework for running functional tests in Google Test, enabling us to write tests that previously would have taken at least 10 minutes to start running (needed to make a full installation on a virtual machine) to now being able to run in more seconds and as part of the build process. And why is this important? Because if clients find bugs or have crashes, it cost a lot of money for us (fines, or even worse lost customers). My point being, if you actually work with software that generates a lot of revenue, the financially responsible thing is to have *a lot* of automated tests.
As far as I know there isn't a standard rule for self-move, so it's the responsibility of class authors to avoid it. Prominent members of the standard committee argue that self-move should leave the class in a valid but unspecified state (as if it had been moved-from). However the standard requires that `using std::swap; swap(x, x);` leaves `x` in its original state, which means that class authors either have to provide an ADL-found `swap` that does the right thing, or write their class in such a way that `std::swap` does the right thing.
This tool would probably be even more valuable if it was available as a plug-in in C++ IDEs.
And they run at 200+ FPS in release. 
I've successfully used CMake on Debian, Ubuntu, Fedora, and Arch.
Optimizations like this are like asking for trouble in long-lived codebases with many tens, if not hundreds, of developers. I would avoid it except if it was proven to be critical. On the other hand, for really critical stuff, I'd avoid reallocations alltogether. 
An STL Dev making Trogdor references, my life is complete! üëç
On a console? I highly doubt that. Unless your debug build is actually alightly optimised plus asserts and logging, which is not uncommon. 
Actually MSVC fixed it only recently because - as mentioned - doing so requires `[[no_unique_address]]`, which is a C++20 features and is only getting implemented in compilers. Before C++20 they would have had to use a non-standard feature, which in turn introduces a few pitfalls: even `[[no_unique_address]]` has observable behaviour wrt to `sizeof` and thus influences the C++ object model. Changing said object model is most likely something compiler vendors want to avoid for non-standard features.
Somebody mentioned `std::exchange`, did not know about that. For the move-assigment-operator, duh, but in the move-constructor, we get: foo ( foo &amp;&amp; other ) noexcept : x ( std::exchange ( other.x, nullptr ) { } as opposed to: foo ( foo &amp;&amp; other ) noexcept : x ( other.x ) { other.x = nullptr; } 
What are your main points against modern c++?
For std::default_delete (and other types without members) the pair looks like this: struct compressed_pair : std::default_delete&lt;T&gt; { T *ptr; std::default_delete&lt;T&gt;&amp; first() { return *this; } T *second() { return ptr; } }; The standard generally requires members to have distinct addresses but allows that the base class has the same address as the first member if it is empty. Though as /u/sakarri already mentioned the gcc implementation is more convoluted because they implement a tuple instead of a pair.
That is move construction, not assignment. And yes I tend to use `std::exchange` as well, but in principle you can replace the whole class with a unique_ptr&lt;int&gt; anyway and as the author seemed to be keen on avoiding the STL, I tried to stick to native language primitives. 
Can you explain your requirements using fewer words? Kk thx.
&gt; it‚Äôs ok to not invoke the destructor not only OK, but potentially necessary for correctness. 
It never causes a bug you found.
I'm skeptical of the linked blog post. No mention is made of the benchmarking methodology - are the tests run multiple times and the numbers presented are means, or are they run single run. What is the variance? Without some more robust statistics it's unreasonable to argue the move from vector to a custom vector replacement is in fact an improvement.
I don't think anyone is disputing what you are saying. Of course C++ isn't perfect and certainly pushing a lot of responsibility to the library has both get pros and cons. The question I was responding to was "I don't know why?", so I answered that question. I think it's fair to bring up the downsides of that answer though and there are some areas of the language that I wish the committee was more willing to make aggressive changes... But it is what it is ü§∑‚Äç‚ôÇÔ∏è.
I still think skeptic is the wrong word: there's nothing to be skeptical about, C++17 clearly exists and that's beyond dispute! It's fine to be skeptical about using absolutely every single feature in every bit of code, but that's hardly unique to C++. Modern C++ is a bit prone to it because it keeps giving us new toys and when you have a new toy you want to play with it ALL the time. But this is the case in all languages. Remember back in the 90s when OO was the new toy and people build massive elaborate class hierarchies in C++ (and the Java)? That's what common "old" C++ looks like and I don't think the modernity skeptics are harking back to that. I think what they're referring to is that period from about 2006 or so when the compilers were finally compliant, but people had mostly got over playing with all the new toys (and mega template metaprogramming tended to not really be in production much), and the new drop of toys in C++11 was a way off. For a while writing straightforward code that didn't use unnecessary class hierarchies, didn't use unnecessary metaprogramming and wasn't full of free-floating new/delete was called "Stroustrup style". I think "modern C++ skeptics" are really "skeptical" of not writing silly code, but that's an odd thing to be skeptical about; it's the only sensible default position.
``` if (x) delete x; ``` simply ``` delete x; ``` No need for additional checks
Very well written article. I think though that C++ modules are way more complex than what they need to be. All we needed is a module statement, an import statement and public/private keywords. We certainly don't need all this stuff. 
I do apologise for how long it took. But finding the hundred or so hours I needed to Boost-ready it required waiting until my last contract ended so I could work on it full-time. Better late than never!
All good things take time, no worries! We're all just human after all.
You can write very clean C++ nowadays. You need to know how to do it. But it is really possible except for template hacks, which improved a lot anyway and with concepts a big amount of those hacks will go away. Now add modules and you have a quite cleaner language.
Got any links?
I have been trying out the experimental standard library c++ support in Visual Studio for a while. The latest dozen or so bugs and crashes are in a public solution at [https://developercommunity.visualstudio.com/content/problem/437267/visual-studio-2019-preview-2-standard-c-library-mo.html](https://developercommunity.visualstudio.com/content/problem/437267/visual-studio-2019-preview-2-standard-c-library-mo.html) . My view at the moment is that you still can't really build any significant body of code using the current, VS 2019 RC2, modules. The core stuff in std.core does seem to be nearly there but things like std.regex and std.filesystem are mostly unusable. Note the community issue does mention the warning issue as well. Also I am well aware that modules are not in the standard yet and that the MS stuff is experimental. However I am very impressed that MS are even trying to do this, kudos to them. My bug reports are not meant to disparage their effort in any way but to hopefully help them get this stuff more production quality so it can go live as soon as possible. I am hoping that even though modules for the standard library are not going to be in c++20 that standard library developers, primary MS libc++ and libstdc++ can at least not do completely different things. I think there is a suggestion of just mirroring the headers so "import std.vector;" which seems like a good idea but I have no idea if it is workable and still may not solve the include closure issue. &amp;#x200B;
&gt;so i want to know the main application scenarios of C++ and how to improve my competitiveness in the future. How would the answers to your titular question "how long have you worked with..." help you with that? (as /u/kmhofmann, I never worked with C/C++, since it [does not exist](http://www.stroustrup.com/bs_faq.html#C-slash))
It's easy to throw around generalizations, and even to look at certain parts of the language now and say that something or other is bad. But when you take into account the history, specifics, etc, more and more things go from simply "bad" to unfortunate. I think to call C++ naive, or even to call Bjarne a non-language specialist (whatever exactly that means), you'd need to know an awful lot about C++. More than I suspect you know, to be frank. You can take your argument and simply say, well, all language features are useless because when we want code to be fast we just write assembly. Done, right? Given any C++ language feature, it's always possible to achieve similar performance without that feature. You can even get the kind of inlining that C++ achieves with passing functions, without templates, by using macros. The question, like I said, is how maintainable can your very fast code be. Rvalue references give you a much better combination of optimal code and maintainable code. As another example, prior to rvalue reference, you would basically never return a vector in high perf code for fear that during maintenance, RVO would get disabled. So you have to use out parameters everywhere, which is ugly, and bug prone (and actually negatively influences some optimizations). Less maintainable. With vector being cheaply movable, I just return by value. It's not faster, but it's equally fast and more maintainable. Just like my example with unique_ptr. As I see you are learning in the other thread, unique_ptr is this way for many reasons but one reason is implementing empty base optimization on the standard deleter. If you don't like it, you can implement a simpler unique_ptr that doesn't support a deleter at all in 5 minutes, and use that. And the debug performance will be barely different from a raw pointer, compilation cost negligible, runtime performance the same, and it will still clean up memory in a far less bug prone fashion. This is exactly the kind of thing I mean. Rather that complain about std::unique_ptr, you should simply understand what's going on better, accept that std::unique_ptr is good but not a good fit for you, and see how you can still leverage similar C++ functionality to deliver value. If I needed good debug perf and ultra fast compile times, I would just write my own unique_ptr and be happy that C++ enabled me to do that, rather than criticize the perfectly reasonable std implementation.
With C++20 (where `std::exchange` is `constexpr`), this allows for a `constexpr` move-constructor.
[https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/statements-expressions-operators/lambda-expressions](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/statements-expressions-operators/lambda-expressions)
&gt; Specifically he measures an impact of an order of magnitude, in MSVC, by dropping std::vector. I mean yes but the reason it's of note is because people don't understand their tools. By default debug mode on MSVC switches in the debug STL[*] which IIRC is not actually standards compliant (algorithmic order is specified, the MSVC debug STL breaks that), and includes a ton of super detailed consistency checks. It's a different ABI, so it's not link compatible. The common way of debugging in GCC is simply to not have optimizations on. You can also enable link incompatible, non-compliant intensive STL by defining _GLIBCXX_DEBUG. I don't know about clang/libc++: I assume it has a similar option. Thing is on both platforms you can mix and match your options. You can run the normal STL in non optimized mode, or if you want the strong consistency checking without glacial performance you can run the deb STL with full optimizations. To me it's a really strange complaint to enable a ton of heavyweight consistency checks then complain it's slow. [*]yes I know. Standard library. Everyone knows what I mean.
The debugging macros would all still be set in this hypothetical mode, so those checks would still happen 
Same here, but we don't use any of the other Boost features, because management...
cmake doesn't build anything. cmake generates files for others to build. The "others" can be Ninja, Makefile, msbuild, etc. 
You're never building "solely with cmake". Cmake always generates files for another build system. On linux the default generator is "GNU Makefiles". If your question is "is `ninja` faster than `make`" The answer is "maybe". For a local build on a project that is not enormous, the difference is most likely negligible. Building a huge project over network with a terribly slow filesystem? Sure, `ninja` is probably much faster.
&gt; CMake abstracts from the compiler This unfortunately isn't really true - whenever you deal with the project that needs to be compiled on gcc and msvc, you invariably have to add compiler specific options. My favorite example for this is adding precompiled header support for MSVC in CMake, it's certainly not even trying to abstract anything here. &gt; Well, don't build in-tree then. which is bad practice anyway. It's quite easy to not do that. How do I do that without switching my source directory when I need to build? Is the answer still cmake -H. -Bbuild that is undocumented and requires a lot more typing? make allows me to stay in the source directory so whenever I need to grep the sources or run git commands or do *anything* else it's just there. &gt; In most cases, you just need add_project, add_executable, add_library, and the target_* commands Sorry, I should've clarified - I meant shell commands for custom builds, not for C/C++. For example, building documentation, or using WebAssembly build chains or other things like that. For these, the "compatibility" argument goes out of the window because you have to rely on very specific tools being installed, but CMake custom commands aren't as ergonomic as make in my experience. &gt; In most of the cases, that's going to be you, not just other people. Sure - I sometimes use my own libraries with CMake, although often this happens in the context of a specific application where it's easy to create a MSVS project instead. But again, for workflows that are centered on the single project make works best for me, the downside being lack of MSVC support.
Same. Only problem with Catch2 I face is that it lacks death tests, so I can't test my `assert`s. But with contracts in C++20, this problem should be solved soon.
I don't know if it's a problem with c++, but if your code throws an exception, catch doesn't deal with it well either. No traceback or anything
&gt; My point being, if you actually work with software that generates a lot of revenue, the financially responsible thing is to have a lot of automated tests. False. It is not a matter of "a lot of revenue". It is mainly a matter of whether the software is safety-critical or not, whether the software is long-lived or not, etc. In summary, it is a matter of the *requirements* of the software. Revenue has nothing to do here. Now, notice that I specifically said: &gt; simulations that don't require *perfect results nor are safety-critical* Simply put: if writing automated tests takes more time/money than simply debugging the code to make it good enough for its purposes, you are wasting time/money. Which means being financially irresponsible. The fact that, for most software and fields out there, tests are worth it does not mean they are for every single project. Proof: consider a one-off script. It does not make any sense to write automated tests for it -- it is a waste of time and money. And no, I am not biased: I have worked on software that is safety-critical and changing a single line of code required a paper trail. But I don't mislead myself into thinking a given workflow applies for every single project out there. Video games are a very rare beast in software engineering.
Nothing specific to C++.
Also with Visual Studio.
What do you mean? How contracts would allow you to test that? If you mean using the continuation handler, why cannot you do something similar yourself when hitting your `assert`?
Has this shipped? Somehow the call stack looks like this for me: ``` &gt; meshoptimizer.exe!std::_Compressed_pair&lt;std::default_delete&lt;int&gt;,int *,1&gt;::_Get_second() Line 1548 C++ meshoptimizer.exe!std::_Unique_ptr_base&lt;int,std::default_delete&lt;int&gt; &gt;::_Myptr() Line 1831 C++ meshoptimizer.exe!std::unique_ptr&lt;int,std::default_delete&lt;int&gt; &gt;::get() Line 1947 C++ meshoptimizer.exe!std::unique_ptr&lt;int,std::default_delete&lt;int&gt; &gt;::operator*() Line 1940 C++ ``` This is with VS2019 preview 4.2, platform toolset v142
And nonetheless, it was in the name of the main magazine covering C++ until 2006. 
In the post two basic approaches considering usability and maintainability to write good code. 
Rubbish. A ton of old C-only game engines (including my old), ran perfectly fine in debug. In fact, I know of a dozen games who just shipped their debug builds, since it was either more convenient, or the performance difference was small enough to ignore. In modern/post-modern C++ the, by far, most important optimization is inlining. A pass which does almost nothing if you build your applications in a very C-like architecture (essentially, using header files as header files, not implementation files). 
Is no debug build at all when you lose information (or worse, get incorrect results) for half or more of local variables.
If you get different results in debug than release you are abusing the language
Take a look at the following resources: https://github.com/MattPD/cpplinks/blob/master/debugging.md#lldb (e.g. LLDB Scripts and WWDC talks)
I meant that the debugger shows incorrect results, of course.
Exactly - you can call C functions from Java and C#, but I wouldn't refer to them as C/Java 
Does your app have 5 million lines of code?
Well, it turns out that symbols and stack frames disappear with optimizations turned on. This makes debugging difficult, even with symbol names.
I don't think that can be done without a custom `assert`. The standard `assert` terminates the program, so I can't test it without death tests. Is there any way of continuing after hitting an `assert`? I believe the contracts proposal allows the program to continue after hitting an assert, so I can simply log the error and continue in testing mode.
&gt;This unfortunately isn't really true - whenever you deal with the project that needs to be compiled on gcc and msvc, you invariably have to add compiler specific options. True, but that's just a small part of whole CMake file(s) for any appreciably-sized project. Which is easily factored out into a seperate `.cmake` file. This has never been a big issue for me. And you also add these compiler-specific options in a Makefile, so... &gt;How do I do that without switching my source directory when I need to build? I'm not sure why you would want to switch back and forth. You just stay in the build directory; for everything else (git commands, etc.), I either do them from there, or I just quickly switch to another tmux pane. I don't see how that would be hindering my workflow at all. &gt;For these, the "compatibility" argument goes out of the window because you have to rely on very specific tools being installed... Well, the tools might have to be installed, but you still can (and should) use CMake's respective find modules to find e.g. `git`, `doxygen`, etc. Which gives you a clear error message in case a tool is *not* installed. You'd have to bake that yourself in a Makefile. CMake does abstract from many of the specifics there. And even if you have to use shell commands, execute\_process isn't that complicated to use. I agree that checking the return type is a bit tedious, but I doubt it's a lot easier in Makefiles.
Google test for most of the code, QTest for Qt widgets that I want to test.
It's not like they were doing it to annoy people before and now they are motivated by kindness. Standard libraries are hard and have to try and make everyone always happy; something new in C++20 has allowed things to get better, putting lie to the narrative C++20 wants to be python and and make people who like performance sad.
I have been programming in C++ for about 10 years, with a few years of C before that. I started out implementing optimization algorithms for the faculty of Engineering at my local university. The typical work pattern was: hook into CPLEX and execute the mathematical model of the problem, and benchmark it against the implementation of the new algorithm the researchers were testing. Since then I've used C++ in computational geometry, and now I'm working for a company that specializes in ultrasonic imaging, so I use C++ for data processing, infrastructure (servers for collecting data), GUI's, etc. It's fun.
That was more words.
C++20 wants to leave no room for a lower level python. The goal of C++ is and has been to generate a language with bare metal performance and highly abstract idioms in the same line of code. Sometimes "slower in debug" has been accepted along the way. In this case consider doing debug builds with aggressive inlining and redundant variable elimination, but not reordering. That'll remove most of the std function call overhead.
The dead giveaway here is "in debug". In debug (no optimization, debug symbols on) both the standard library bundled with MSVC++ and libc++ (and presumably still libstdc++, but I haven't poked around in there recently) do a lot more than merely fail to elide some code. They use things like bounds-checked iterators, instrumenting metrics, and so forth... they are explicitly *not* designed for performance, but rather for debugging mistakes made by whoever is using the standard library. Don't use the debug library if you need performance. Simple as that. 
&gt; All standard library components that need to allocate storage (with the exception of std::array, std::shared_ptr and std::function) do so via an allocator. And `std::any`. And if array is included, then pair and tuple and optional and variant should be too. &gt; The heap is the other region of dynamic memory allocation; this being used by malloc/free. That's not what the standard says. The standard only talks about the free store, and malloc use it too. &gt; Finally, the pointer must not be nullptr/0. As long as the pointer was returned by a call to allocate, it can be null. An allocator is allowed to return null for allocate(0). &gt; namespace pmr (presumably short for Polymorphic Memory Resource?) Yep. In your examples you use `unsynchronized_pool_resource()` as though it's a function returning a `memory_resource*`, but it's a type. That means you're creating a temporary object, and so it won't compile. (You could test your examples using GCC trunk in an online compiler like wandbox or godbolt). Your `Tracking_resource` example fails to handle alignment. You might want to mention that.
Googletest because we could get it to work equally well with some older C code and our new C++ code. Now we are happy that it integrates well with Cmake and Visual Studio.
At a high-level, sure. That's a basic philosophical difference between programmers: is volatility (or atomicity) a property of the \*type\*, or of the \*code\*. The C++ committee chose \*type\* but is walking it back with things like \`atomic\_ref\`. Codebases like Linux chose \*code\*.
**Company:** [Mixlr](https://mixlr.com) **Type:** Full-time **Description:** Mixlr is the simplest way to broadcast live audio. Our cross-platform tools enable audio creators, anyone from radio stations, podcasters or professional sports teams to easily manage and distribute live content to millions of unique listeners each month. We have a bunch of exciting new features lined up, so we‚Äôre looking for a talented C++/Qt engineer to drive our development process forward, while also contributing a positive impact to the team and culture at Mixlr. We‚Äôre a small, tight-knit bunch: social, hard-working, family-friendly and heavily inclined towards coffee, snacks and absurd sound effects. To find out more check out [careers.mixlr.com](https://careers.mixlr.com). *Key Responsibilities* * Ensure code quality and maintainability of an existing Qt/QML codebase with best practice in mind * Design and implement new features on new versions of our broadcasting client * Develop automated tests and custom tools to optimise our CI/CD pipeline * Contribute to every step of the product development: sprint planning, requirements definition, retrospective * Contribute to code reviews and positively influence the team‚Äôs development process *Core Skills* * Deep knowledge of modern C++ and best practice in Object Oriented programming * Inherent and instinctive understanding of requirements, from testing to shipping * Communicative skills to share learnings and best practice with ease and clarity * Ownership, especially when writing code * Sense of curiosity to properly assess and positively influence the entire product delivery cycle **Location:** London, UK **Remote:** For the right candidate, we'd consider applicants within GMT¬±1. **Visa Sponsorship:** No **Technology Stack:** * Application: Qt, C++, QML * Network: HTTP, Websocket, Icecast streaming * Integration: Cross-platform builds using CMake, Vagrant, Jenkins **Contact:** Apply here [https://mixlr.workable.com/j/E1F050525A?viewed=true](https://mixlr.workable.com/j/E1F050525A?viewed=true) or contact [erika@mixlr.com](mailto:erika@mixlr.com) (hope to hear from you!) 
Not something you would want to use for a large codebase, but I use [https://github.com/keithalewis/xll12/blob/master/xll/ensure.h](https://github.com/keithalewis/xll12/blob/master/xll/ensure.h). It works like `assert(3)` except it throws a `runtime_error` exception. My tests are just C++ functions that have a bunch of ensures. So I guess that would make C++ my C++ testing framework.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b12iob/networking_ts_beast_new_tutorials_read_this_to/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
What is your point, do you think good test coverage is hard to obtain for 5 million lines? Unless you are having a combinatorial number interactions between all your components then writing tests for 5 million lines is not inherently harder than writing the 5 million lines in the first place. And if you *are* having combinatorial interactions that sounds like a system that wasn't designed to scale to that size. To answer your question more directly, it looks like the parts I personally work on clock in at about 1M lines. I'm just on one component of a tightly integrated system though, and our product is going to be several times that easily. 
No, Update 1 isn't in previews yet. That will probably happen shortly after RTM comes out. (The train for RTM for compiler and standard library changes ended early Febuary; a week or two before your "is C++ fast" post that prompted much of the investigation.
[Hello I am an epic gaemor](https://www.youtube.com/watch?v=IvhS9pKNWpU) I play fortnite i play roblox epic gucci gang lmaoalalalalal 3.1415926535897932384626433832 But I dont know that. Girls are cool and all but in science the other day I got a quick glance at Big Chungus 174~@#$ big is ian nnasndajdgniansfdnasoidiasniod Excuse me, but I must ask you to remove this post. My grandson uses this website and I do not want him to see something as inappropriate as this post. I cannot accept you posting such awful things on the good Christian Internet where innocent children can see them! The Internet should be a safe place for kids to spend their time without adult supervision! I am reporting you to Facebook and contacting my state politicians to inform them that such filth is being posted online, and I hope they will pass some laws to prevent this from happening again. Thank you and God bless you. Facebook please post my comment now I am done talking, thank you. Bob, can you get some Beano at the store? My gas has been acting up and it is really getting out of hand and I don't want to offend the Franklins when they come over for dinner tonight. Oh, and have you tried this voice thing on your phone, dear? It lets you talk into your phone and then it turns it into text so I don't have to push those tiny buttons to write on Facebook anymore. Isn't that great? It's been so hard to type on that damn keyboard. It's so little and my arthritis makes it impossible to use. It's bad enough that I don't understand all the things our little Johnny is posting on his Facebook. What are these me me things? A lot of them are very inappropriate and rude. I think his account was hacked, because our grandson would never post such terrible things, right? He's such a sweet boy. I can't wait to see him graduate from university! That reminds me, remember to pick up a gift for his graduation. Maybe get a bottle of sparkling cider, not champagne since our sweetie bear doesn't drink! He's such a good boy. Okay, I'll talk to you later honey. I love you. Goodbye. orange man bad evil drumpf dumpf domf trumph blumph. reeeeeeeeeeeeeeeeeee3333333333333eeweeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeee my tendies were stolen ree[eeeeee](https://www.youtube.com/watch?v=yrWaL9FrtCM) i used mom's credit card to buy vbucks and now we have to leave the house but i have the epic skins and brag to my friends Sodium, atomic number 11, was first isolated by Humphry Davy in 1807. A chemical component of salt, he named it Na in honor of the saltiest region on earth, North America. V TBG XVYYRQ BA ZVARPENSG KOBK NAQ FPERNZRQ NAQ ABJ VZ TEBHAQRQ TQEFTFRSTOUSQFGT QFSQFN !# #TWRS ^epic gamer mmermgmsdmf What is happening my wednesday my dudes. I have epic gamer syndrome it make too epic lol i'm so rich i bought an extra chromosome lmaoooooooo get rekt n00b i shot you on call of duty you dirty hacker..12.3.52.2.435.234.1.33.12..52.4.23.4.1.34.2. . my credit card number is 5324-5658-9357-5682 and the 3 squiggly numbers are 101 lmao what asd apology for poor english when were you when john lenin dies? i was sat at home eating smegma butter when pjotr ring ‚Äòjohn is kill‚Äô ‚Äòno‚Äô No, r/Update r/1 r/isn't r/in r/previews r/yet. r/That r/will r/probably r/happen r/shortly r/after r/RTM r/comes r/out. r/(The r/train r/for r/RTM r/for r/compiler r/and r/standard r/library r/changes r/ended r/early r/Febuary; r/a r/week r/or r/two r/before r/your r/"is r/C++ r/fast" r/post r/that r/prompted r/much r/of r/the r/investigation. lmao get plarankkrnkkakekdnkankdnk sakdnsakndnkajust a rbank pro i beat you up in roblox florrtniet help i safjsafj sarjfasfj :ok_hand: lmao got em roflasf i have ligma what ligma ligma fortnite hahaha gotem do u kno de fortnite hahahahahah deGweuasld dance duuuaudsuasudausduud` ;;;g;;g;g;g;;g;;g;g;g;g;gg;;g;;4;2623twehshdfhoiaodhoahsdhiasdhoiaosdhoiashoig epic gammermem faisfianignadnfanodifinadoipifaspdiaipsdpi ahsid i jkilld oland blumph he racits and biggit. fhafhashofashfasd i sjw it is MAAM! REEEEEE IT IS MAAM !!!!!!!! DOLAND TUJDAOS IS BAD AND A RACISTST BIGAOSDO REEEEEEEEEEEEEEEE You now have stage 5 terminal ligma. I hae diagnosed you with the big gay. Lol get pranked. [][][] #FORTNITE Me and my son have always had an up and down relationship. I think this is due to us not really have much in common, its hard for us to bond. He is a huge fortnight fan, and his mother made him a John Wick costume for Halloween (His favorite skin). He was beyond happy. He really loves Fortnight. I took Halloween as an opportunity to bond with him more, so without him knowing I had his mother make me a fortnight costume to surprise him. I scrolled through google looking at different skins and eventually decided to go as what they call "Rust Lord". The outfit seemed easy to put together and it had a bad ass feel to it. I even researched some of the more popular dances (The Floss, Best Mates, and Orange Justice) I spent hours learning these 3 dances, I don't consider myself all that coordinated but after some time I felt I had them down perfectly. Halloween night came and my son went out trick or treating with his friends. As they were out I put on my costume before handing out candy to the kids. I was surprised with the amount of kids that recognized my costume, I was a hit. Until this group of kids, dressed up as skeletons, I guess they are called skull troopers nowadays? I dont know, looked like skeletons to me. Anyway, what seemed to be the leader of the group didn't seem impressed with my costume, he actually seemed bothered. In a demeaning tone before even getting any candy he asked if I could floss. That smirk on his face turned into full blown surprise as I dropped the bowl of candy, and put every bit of energy into the best floss I could muster up. I nailed it. Surprised but still unimpressed the leader said not bad, but lets see your orange justice. I don't know what came over me but I completely blanked, he caught me off guard despite my hours of preparation. I couldn't let this 10 year old alpha me so I closed my eyes, gritted my teeth, and started flailing around like an inflatable tube man caught in a hurricane. I finished my dance, and silence followed for what seemed to be an eternity. Next thing I know it the group of skeletons erupted into laughter and started jumping left to right while holding their hand in an L shape formation. I was embarrassed, I slammed the door and I kid you not, thought about crying at that very moment. My man hood compromised by a group of young children, but that wasn't even the worst of it. 20 minutes later my doorbell rings, which is strange considering I turned off the porch lights after that embarrassing incident. I turn the light back on, opened the door, and my jaw dropped. a Group of what seemed to be 50+ characters gathered across my lawn all jumping left and right with simultaneously while forming the L shape with their hands. I yelled at the kids, slammed the door and ripped off my costume. What have I done. 30 minutes later my son comes home and I guess word travels quickly in a small community, he already knew what happened. He didn't even make eye contact with me, I tried asking how trick or treating went and he ignored me, went up to his room and slammed the door. He hasn't talked to me since last night and I really don't know what to do.. I don't think he respects me anymore. homer sexual got him me parents are fuqin nonces they like putting "RULES" on legit everything i wanna get its dumb so for example i buy headphones rules will be put in place for the headphones wanna buy a game they will put rules on that like a couple mins ago i asked for a legit credit card and there like NAH youll have restrictions and im like shut the fuck up youve already put rules on my phone, laptop, most shit i own and i dont even listen to the rules cos there that fucking stupid like one rule for my phone is "dont bring your phone to any place except home and school" like what type of gayass bullshit is that but ofc i dont listen then there like O_O and try to fuck me then i make them realise just how reBarded the rules they make are. Basically, frICK my fortnite....d.as.d. MOMO MOMO MOMO MOMO MOMO TIDE POD MOMO People have been sending me this! Why??? I'm honestly feeling in danger right now... This makes me feel very unsafe. I'm honestly shaking and crying whilst writing this I can hardly hold myself together please kindly tell anyone who post this without a trigger warning to PLEASE add one to keep their followers safe! I had to take a 30 minute breather after seeing this in my camera roll when posting this before I even typed it. Just... Stay safe... LIGONDESE lmao $$$$$$$$$$$$$$$ 
Hmmm not referencing anything here. I think you can actually blame /u/STL :P
This is not a help post...please whitelist my account.
Good, I'm glad you don't want to use it :-) For the most part, those are simply remnants. No one should *start* using STLPort, and the people who are currently using it should try to cut that out. So I expect that a large number of projects will drop those ifdefs eventually.
How does this all compare to Go and its standard libs?
Favorably I hope!
nice tutorial, good job and thanks. will try Beast after fixing my spaghetti asio complete handlers.
I agree the dependency should be used instead of linking and remembering directories manually this removes redundant blocks and makes is more readable. If you see anything else that can be improved than I would like know, thanks.
We were discussing implementing a feature as STL vs language, right? I just said, if it was part of the language, it could be checked for proper uniqueness, and it could be as performant as a raw pointer. Also, all the complexity in the implementation of unique is to make them as performant (in optimized builds) as raw pointers. I just was showing you that they don't even achieve that. Having an array of pointers is one of the most basic things ever, it's not "storing a bunch of file objects" whatever that even means
And let's not ever actually try to reason about this.
Another big problem is I think that much of the STL consists of templates, which can only be compiled once yoou instantiate them in one way or another in your code.
Or, I can code my code in a way that you can actually use the debugger well, as that's one of the most important part of programming, instead of finding half-assed compromises of compiler switches. The productivity, on a team, of having proper, easy debugging can easily outweight the paper-thin guarantees of an unique_ptr imho, but YMMV
Wow! That would not only mess w/debugging, but also not solve the problem at all, as the unique_ptr stuff is nothing to be optimized (the calls are all trivial), the overhead is exactly due to the lack of inlining.
Yes. Depends on which cod made by which studio, but generally that's the reality. They remain playable. 
That guy is an optimization specialist and if you want to look at things more in detail the code is opensource, and he runs a programming stream of that stuff I think on youtube and/or twitch.
&gt;level 1ShillingAintEZ6 points ¬∑ \&gt; how much they will increase my binary size and how much they will increase my compile times. Yes Boost is template and header-heavy but so is the standard library. There are techniques you can use to help. In fact I am working on a brand new open source server project which demonstrates how to tuck much of the template definitions away in the .cpp file to get nice fast builds. The latest version of Beast also has a lot of work in it for "split compilation" (compiling function definitions separately) this means faster compile times, and there is also work to make binaries smaller.
&gt;when you are new to it, using Boost is slow and there are lots of unanswered questions &amp;#x200B; Wow yes, your post exactly describes my experience with Boost!!!
I would never return a vector from a function because it's all kinds of ugly. We are even past the simple times of "effective STL" suggesting, rightfully, that STL containers are for implementation, not for interfaces. Unfortunately.
&gt;ASIO is pretty broken if you need to do thousands of calls a day This again? Stop blaming Asio for your broken code!!! I get 5k+ requests through PER SECOND in the apache bench on beat's example-http-server-async, and that's without even running the "fast" example (which gets even higher throughput).
Sure, but that's irrelevant to the point I'm making - which is that the reporting on his timings is poor: Either: 1. He didn't run his experiments multiple times, so his numbers are suspect 2. He did run his experiments multiple times, but he didn't report the variance/confidence/standard error Either way, it weakens whatever point he's trying to make. I'm not critizing his optimization chops, but his numerical hygiene isn't good enough.
doctest for unit tests and ctest for everything else has worked great on all my projects so far.
Apples and oranges?
Yes, but the fact of the matter is still that while games are a big industry, they're not the largest users of C++ by a long shot and 1. We need our code to be fast 2. We need our code to have predictable performance 3. _while we're debugging it_ Is not a problem literally anyone else has. And of course even in those case a lot of the time you can get most of the way there by just doing a release build with debug symbols.
This brings a few questions. Why does the `std::pmr::polymorphic_allocator` constructor take a `memory_resource*` and not `memory_resource&amp;`, since a precondition is that pointer should not be null. Also, the documentation on cppreference.com doesn't say anything about the ownership of that raw pointer.
You're still missing the point. They were never bad. Those were the best implementations possible with the tools available at the time. Now we have more and better tools (yay modern C++?), so we can write better implementations.
&gt; paper-thin guarantees They are pretty well defined guarantees...
&gt; As a few others have pointed out on this post, your fixation with the performance of debug builds is what seems misplaced. You shouldn't need it, and if you do then you're either working with poorly tested (or poorly testable) software, or not leveraging all the potential tools at your disposal. ...wait, what? Is the debugger not part of "all the potential tools at your disposal?" Why does it get kicked out because of implementation flaws but tests/sanitizers/fuzzing don't? These pissing matches between the various C++-using fields don't help anyone. The debugger is (or can be) an incredibly valuable tool, even when you're already using all the other tools in the box. Maybe let's trust our fellow professionals that they actually know which tool is most helpful in their case? Besides, in this instance [the fix is quite straightforward](https://www.reddit.com/r/cpp/comments/b0sq6p/unique_ptr_seven_calls_to_dereference_why_is_this/eigy84a/)! There's no reason to call a desire for faster debug builds misplaced.
Are there still magazines?
No, the MSVC fix does not use `[[no_unique_address]]`- it just manually inlines the superfluous utility functions, while still relying on the empty base class trick.
Were the three exclamation points really necessary?
To the best of my knowledge very few people involved with tech do still read or write magazines. There are lots of blogs of... varying quality, some excellent, some not so much. Some regularly updated with relevant content that's applicable to every C++ developer, some with content focusing on some specialised areas, some that are no longer maintained but nevertheless contain a good amount of still relevant information. Some suggestions: I found some of the videos on C++ weekly pretty interesting, although depending on your level of knowledge they may be either overly specific (for a beginner) or sometimes too slow paced (for a full expert I guess); Nevertheless overall good content and I'd recommend checking it out if you're at least at the intermediate level: https://www.youtube.com/playlist?list=PLs3KjaCtOwSZ2tbuV1hx8Xz-rFZTan2J1 CppCon is a yearly convention that uploads their talks on YouTube: https://www.youtube.com/user/CppCon - some of the videos I'd definitely recommend to beginners like https://www.youtube.com/watch?v=XkDEzfpdcSg or https://www.youtube.com/watch?v=2olsGf6JIkU, some are more about fairly advanced subjects, future C++ standardisation work or industrial use cases which may be of less interest to you. Herb Sutters [blog](https://herbsutter.com/) has lots of interesting stuff on it, talking about language features, upcoming C++ standards and what not. You can also always check out the [C++ tag on Stackoverflow](https://stackoverflow.com/questions/tagged/c%2b%2b), which of course is a huge stream of unstructured information but you'll get exposure to lots of things other people are doing by browsing it every once in a while.
Note that you could: - Add a `private` base. - Pull all its public methods with `using`. Which would allow you to have specialized implementations with no method delegation and no exposed base class.
To be honest, for me it's less about performance and more about getting sane behavior from `step` in gdb :/
Could you tone down the clickbait just one notch? You're making Buzzfeed look like second rate amateurs.
I miss Dr. Dobbs and C/C++ User Journal... But I second what other people say -- nowadays people mostly follow blogs, including some written by former writers for the good ol' magazines. I find this subreddit to be a decent aggregator of blog posts, both good and bad (mostly good, though) at least.
Attention is the reserve currency of the information economy!!
For sure it depends. Games where the hot path was optimised with loads of assembly and other techniques might have been closer. 
Clickbait, sensationalist headlines and "ads" like "don't forget to ~~subscribe~~star" may steer some people away too.
Nice. I've been thinking of making a simple multiplayer game with OpenGL for a while. I will be diving into these libraries when I have some free time.
Let was never used to denote immutability in any other language. I think const, when no type is provided, should behave as const auto, but that maybe impossible to implement. 
Isn't let used for immutable variables in Rust?
My own.
 When you say "order of magnitude", you're speaking about the complete debug build, which isn't what one is looking for in this situation; rather, one wants an unoptimized build against a retail STL. (The linked article isn't doing that at all). A true retail build though... The post you linked to got 2x improvement by changing algorithms, 10% by dropping std::vector and nothing at all by dropping the ++ of C++.
Only because is const by default. 
If you count C as well, then 31 years professionally. If you really just mean C++, then more like 27'ish. Of course C++ was sort of like rubbing two sticks together back then, and not that far from C. It had been called "C with Classes" up to the mid-80s actually. I can't remember who had the first PC based C++ compiler. Borland? &amp;#x200B;
Maybe you can look past the cover and find the great content inside!!!
:o
I did a video on it a while back if anyone cares. [https://www.youtube.com/watch?v=0Yzcwk95bm8](https://www.youtube.com/watch?v=0Yzcwk95bm8) &amp;#x200B;
Doctors hate this one simple API
I found the "Networking Refresher" very useful for me. Thank you!
!! is a no-op, unless... Please tell me you didn't overload operator! with a side effect!
It's not quite the same, but doesn't gdb have a just my code feature?
That's an absurd characterization of games, and a terrible reason to dismiss the benefits of faster debug builds. "Not being gratuitously slower in a debugger" helps everyone- maybe not to the same degree, but it's hardly *useless*.
Modern C++ is not used at all to fix the issue in question here. `[[no_unique_address]]` is a *possible* solution but it's not necessary- you can just manually inline the helper methods, even in C++98.
I‚Äôve been working with asio and Beast for a while now and am looking forward to see what goodies this update brings. My expectations are quite high from obvious(?) reasons! :-)
Have you thought about adding beast to the benchmarks here [https://www.techempower.com/benchmarks/](https://www.techempower.com/benchmarks/) Would be nice to see a how it stack up performance wise and always good to see how much code and what's the correct way to use the library. I have tried before to get the examples working and got errors compiling on windows so gave up.
Considering adding yourself or your company here: https://github.com/boostorg/beast/wiki/Companies-and-Individuals-Using-Beast
But it doesn't need to check for uniqueness. It IS unique. Why do something unnecessary? And a unique pointer IS as performant as raw pointers - for access. That's the only claim that's been made. unique_ptr is a memory management object, so when that stuff kicks in, of course it's not as performant as raw pointers. You seem not to understand what unique_ptrs are about.
Oh, my bad then, I misread.
Hmm.. Beast is not really a "web framework" it is a low-level protocol library. Someone might use it to build a web framework. So I'm not sure how relevant these performance tests are. Faster is always better though!
I've had good success debugging with no optimizations except for inline function expansion. I've only done it with MSVC, but I guess it would work with gcc/clang as well?
Surely you are trolling at this point with the exclamation point being incremented? If not or you aren't aware, it does not present a good image of you.
I'm in no way an expert, but AFAIK the options and why people use one over the other seems to be quite clear and stable? Or am I missing something? &amp;#x200B; \* [https://github.com/google/googletest](https://github.com/google/googletest) Simply the default option. With the benefit of being integrated with Google Mock and supporting pre-C++11. Did look a bit dead (1.7.0 from 2013, 1.8.0 from 2016, 1.8.1 from 2018), and the support for pre-C++11 was limiting what it could do (the documentation has more than one recipe explaining how to do something that should be simple in a difficult way). People disliked that it is more difficult to integrate into your project than single-header alternatives, since it actually needs to be built. But with CMake getting popular and some recent backlash against header-only stuff because of its compilation times people don't care about this so much any more. Post-1.8 they will stop supporting pre-C++11, so they should be able to improve. Not sure they will be able to before the popularity disappears. &amp;#x200B; &amp;#x200B; \* [https://github.com/catchorg/Catch2](https://github.com/catchorg/Catch2) or [https://github.com/onqtam/doctest](https://github.com/onqtam/doctest) "I use doctest because is like Catch2 but faster" "I use Catch2 because is the popular one/safe option. It's fast enough for me and I don't want to mess with less known frameworks" If you want something similar but even less known: [https://github.com/martinmoene/lest](https://github.com/martinmoene/lest). Not really sure what this one offers over doctest/why people use it. &amp;#x200B; Since these are only testing frameworks people combines them with: \- [https://github.com/eranpeer/FakeIt](https://github.com/eranpeer/FakeIt) Used to be the cool kid. But it seems quite dead. It does have serious limitations. And I think it does depend on undefined behaviour and compilers can actually break it if you enable any serious optimization. I don't think anybody would select it for a new project nowadays. &amp;#x200B; \- [https://github.com/dascandy/hippomocks](https://github.com/dascandy/hippomocks) Not sure, I think it created the cool/undefined behaviour syntax used by FakeIt. Seems quite dead, there is a cpp11 branch in a I'm not sure what status. I don't think anybody would select it for a new project nowadays. &amp;#x200B; \- [https://github.com/rollbear/trompeloeil](https://github.com/rollbear/trompeloeil) When people realized the issues with FakeIt they moved here. Doesn't have the cool/undefined behaviour syntax, but it's as nice as you can get until C++ gets Reflection (and your company starts to let you use it) if you want to stay with defined behaviour. The default syntax/support is for C++14, but it has a special C++11 syntax support that is not a lot worse and offers the same features. Really nice, it does even support movable mocks. It's the default "modern" option. &amp;#x200B; \- Google Mock Used by people who doesn't know trompeloeil exists, I guess. I can't think why anybody would use this over trompeloeil if they are not using also Google Test &amp;#x200B; &amp;#x200B; \* [https://github.com/cpp-testing/GUnit](https://github.com/cpp-testing/GUnit) The Test/Mocking framework for dreamers. For some reason it seems to be quite unknown. It requires C++14, so if you need to support C++11 it's discarded. If you want to combine it with \[Boost\].TE I guess it means C++17. &amp;#x200B; I do need to support C++11 so I have not looked at it in detail. It's basically... impressive, very very impressive. It seems to depend on the same undefined behaviour than HippoMocks/FakeIt, so that worries me a bit. It builds on top of GoogleTest/GoogleMock, I guess to make easier the transition from the most popular framework... IIRC I think it sacrifices a bit because of this decision, but it's still really impressive. &amp;#x200B; &amp;#x200B; \* Boost.Test OK, I don't really know why people use \*this\* one. Not saying it's bad, I don't know it (I don't think it's great) but it isn't the most popular one or the most cool one. So, again, I don't know why people use it. But being part of Boost... I would not say it's popular, but people know it does exist. &amp;#x200B; &amp;#x200B; \* Any other testing framework probably has an insignificant market share. &amp;#x200B;
That's essentially a bool cast.
&gt; I can't remember who had the first PC based C++ compiler. Borland? Pretty sure it was Zortech 1.0 in 1988 
Long answer: https://foonathan.net/cppnow2018.html Short answer: there are two differences between T&amp; and `T*`. One is non-null and the other is not, and one is created implicitly from an object while the other is not. The latter is what made them choose `T*` over T&amp;. Consider: pmr::vector&lt;T&gt; make() { my_resource resource; pmr::vector&lt;T&gt; vec(resource); ‚Ä¶ return vec; } It is not immediately clear that this is a bug. But you have to write `&amp;resource` in the ctor, which makes it more obvious.
I believe I'll wait for the 3.14.1 or 3.14.2 release. 
Hah aren't you a little overdramatic over some person's writing style?
Yes! If you become a member of ACCU (https://www.accu.org/) you can get the print editions of CVu and Overload, the price of which is included in your membership fee. 
Duplicate links can still be submitted, but there's a box that appears just above the title textbox with "This link was submitted to /r/cpp: X days ago (see more)".
The caller owns it, and it must remain valid for the lifetime of the `polymorphic_allocator` using it (and any copies of that allocator, which will also use it). There's no ownership transfer happening via that raw pointer.
"Burninate" is a Trogdor reference, he burninated the countryside.
FYI, we try to preserve the big-O complexity (so we avoid doing linear-time validation in log-time algorithms), but the comparator checking (to detect things that aren't strict weak orderings) inherently violates exact complexity guarantees for the number of comparator invocations, which only STL test suites tend to notice.
Look at the examples. That what normal people want in language 
Just the plaintext one would be nice to see. &amp;#x200B;
&gt; CMake now supports Cross Compiling for iOS, tvOS, or watchOS using simple toolchain files. Wasn‚Äôt this the case? Or are the toolchain files now part of the new cmake version?
If more people posted "clickbait" of this calibre, I'd have no problem with it. It's useful information.
On Pi day too. They must have been really excited about the timing of this release for a while. 
Pi Day is definitely the best day to release CMake 3.14.
 The ‚Äúinstall(CODE)‚Äù and ‚Äúinstall(SCRIPT)‚Äù commands learned to support generator expressions. See policy ‚ÄúCMP0087‚Äù Ooh nice.
Start with a book like Strouptup'd tour of C++. Corr Guidelines is another good resource on how to make your snippets and code more effective. Learn at least: - Basic data types and language constructs and std::string. - Functions - Understand the rich parameter passing - Containers: at least vector and unordered map. - Basic data abstraction. - OOP and polymorphism. Good chance to understand Smart pointers at this point. - Containers, vector and unordered_map - Data abstraction as in records of data - Error handling with exceptions. - *Understand the ideals of memory safety, type safety and lifetime safety profiles from the Core Guidelines*. This will help you a lot to understand the language. - Understand GC vs non-GC tradeoffs: it will help you code more effectively. C++ is not Java or C#, even if it looks alike. - Understand zero overhead abstractions Additionally: - understand the STL design: containers, algorithms, iterators and function objects. - understand templates to be at least capable of using them. Take a look at the Core Guidelines. If you want a complete reference that also includes a Tour of C++, get Stroustrup The C++ Programming language, but be warned, it is over 1000 pages. You can pick up topics from there when you need. Effective Modern C++ is also recommended. As for multithreading, C++ concurrency in action is a very good book.
Great work Vinnie! I'm looking forward to integrating the new streams into my server.
Toolchains are now built-in 
We are iterating towards a better approximation
I've been using boost::beast for a while now, i've come from a background where i'm not new to networking protocols or networking in general, and was integrating it into an application that was already successfully concurrent. I've worked with GPU level concurrency all the way to supercomputers but have no familiarity with boost::asio specifically Boost::beast is hard to use because there's no clear cut standard unambiguous way to use it, while simultaneously introducing a bunch of new concepts that are exclusive to boost For example, for a very simple websocket game server, I might only need a maximum of 60 clients. For this use case, it would be completely acceptable to use a blocking thread per client model. While boost::beast would appear to support this on the surface, in reality there's no way to tell if a socket has data available to be read (and you cannot use two threads due to concurrency constraints), which means that boost::beast's blocking model is only good for toy applications This means that you have to dive into boost::beasts async model, which is obviously the whole point of async io but makes me wonder why the synchronous model or examples are there at all, they simply serve as a big ol' red herring to people who are familiar with the constraints of network programming When diving into the async model you realise that there's no one way of getting async with boost::beast, but instead absolutely loads. Boost::beast introduces a bunch of boost:: specific concepts which are not common pieces of terminology in programming, which is what makes it particularly unintuitive to work with. io_executors, strands, multi buffers etc. This also means that the examples and code in the wild tend to be very fragmented, and associated documentation and error reporting is very poor due to it all being extremely boost specific In my opinion, if boost::beast wanted to shed the label of being hard to use, the following things would be good: 1. Cut the synchronous model entirely. It is not useful in its current form 2. Build better error checking into the library itself to check for incorrect usage by users, eg race conditions 3. Pick one method of async, write all the documentation for that method, and provide non toy examples of how to use it (bidirectional datastream with n users per m threads and optional ssl) 4. Support standard containers better, make your containers work exactly like stl containers, and strip out as much boost specific ecosystem as possible 5. Very high compile times make experimenting tedious even in trivial projects, although I have not yet had a chance to play with split compilation Pieces of code like (*this)({}, 0, false); That are a bit crazy, or things that feel like a totally different language like reenter(*this) { Or having to fill buffers like this unsigned char buf[9]; auto const n = net::buffer_copy( net::mutable_buffer(buf, sizeof(buf)), buffers); Tribools, dependent types even in the most trivial echo example auto begin = net::buffers_iterator&lt; typename DynamicBuffer::const_buffers_type&gt;::begin(buffers); auto end = net::buffers_iterator&lt; typename DynamicBuffer::const_buffers_type&gt;::end(buffers); auto result = std::find(begin, end, '\n'); Non standard containers which don't follow STL conventions // Commit what we read into the buffer's input area. buffer_.commit(bytes_transferred); Altogether boost::beast lives in a world of its own, totally divorced from regular c++ Don't get me wrong, boost::beast provides a tonne of power but its most certainly absolutely crazy to use So now lets compare this to something that vaguely competes in the same space, valve/steams networking sockets Here's how you initiate a connection to a user, relay through intermediate servers, punchthrough nat, and send a packet all in one bool SendP2PPacket( CSteamID steamIDRemote, const void *pubData, uint32 cubData, EP2PSend eP2PSendType, int nChannel = 0 ); If you wish to read a packet, you can call IsP2PPacketAvailable followed by ReadP2PPacket These are obviously two different spaces with two different sets of constraints, although after HTTP/3 they will unify somewhat due to QUIC, but overall I hope this illustrates why boost::beast *is* hard to use outside of people just not understanding
It was half luck that our standard release pattern makes a March release very likely. Around RC3 we noticed that the timing was perfect and made sure it happened. 
Cmake is garbage.
Ooh, the little kiddo got maddie-maddie? What a gutchie-gutchie... *squishes cheeks*
&gt; Boost::beast is hard to use because there's no clear cut standard unambiguous way to use it, while simultaneously introducing a bunch of new concepts that are exclusive to boost Beast follows the design principles of Networking TS, Asio, and Boost.Asio - it doesn't invent any concepts with respect to networking. "Clear-cut standard unambiguous way to use it" is the characterization of a high-level interface, which Beast is not. Take for example the POSIX socket model. There are almost limitless ways to put programs together which use those sockets. That is because these interfaces are low-level and take a "toolbox" approach - they give you the tools, and then it is up to you to decide what to build with it. There's a simple principle that Beast's design follows: "Don't make odd choices on behalf of the user." &gt; it would be completely acceptable to use a blocking thread per client model... &gt; ...boost::beast's blocking model is only good for toy applications YYou are talking about using the synchronous websocket interfaces in particular. The websocket stream requires full-duplex (simultaneous outstanding reads and writes) to operate effectively, so the synchronous ("blocking") model is only useful in limited contexts - but it IS useful. For example, it can be perfectly capable to write a blocking client which submits JSON-RPC requests over WebSocket. &gt; This means that you have to dive into boost::beasts async model, which is obviously the whole point of async io but makes me wonder why the synchronous model or examples are there at all Beast didn't invent the async model, that came from Boost.Asio, which is a flavor of stand-alone Asio, and which is in the Networking TS which means that soon (maybe 4 years if we're lucky) it will be in `std::`. &gt; In my opinion, if boost::beast wanted to shed the label of being hard to use, the following things would be good: I think a better way is to educate users, so that the people who have the talent and experience writing concurrent programs, will have a big head start and they can build those higher level abstractions that you are clamoring for - where there is only "one way to do things." &gt; Here's how you initiate a connection to a user, relay through intermediate servers, punchthrough nat, and send a packet all in one &gt; &gt; bool SendP2PPacket( CSteamID steamIDRemote, const void *pubData, uint32 cubData, EP2PSend eP2PSendType, int nChannel = 0 ); This is a completely different thing, you are comparing a low-level protocol library interface with a high-level application-specific interface. Beast could be used to build that high level interface above though. 
&gt;This advice, in fact, applies to any namespace that you are not in control of: not only std. One exception: `std::literals`.
Instead of asserting, can't you just throw an exception (and not catch it?). Or use a macro that's either an exception (for debug) or nothing (for release, like assert)?
Same for me. I really like that you can use C++ syntax directly like \`EXPECT(foo() == "bar");\`.
What do you mean, it's all kinds of ugly? And I don't understand your comment afterwards at all.
intetrseting, have you thought about preventing that each sub hash map from share the same cache line to prevent false sharing ? this can improve performance further.
Thanks. This interests me because I have a project where C++ code is generated, so I could easily add something like this. (In fact, I just did :)) Do you have any idea what the performace cost could be of adding this to every function?
Returning a vector out of a function means your function allocates something, then gives it away. Which is generally not a great idea. Whay if I wanted to store stuff on the stack? Or using my custom allocator? Or in a mmap? So in general it's a good idea to ask the caller to decide where and how memory comes from, if it's the caller that it's going to own the memory. This is in general. In particular, STL templates "bake" in the template lots of implementation decisions. For example, the allocator to use. Returning a vector or in general using STL in interfaces means you both "fix" and "leak" all these decisions, which is bad. So the general advice is to not use STL in public API (headers), only on the implementation side of things, as suggested wisely by "effective STL" by Meyers
As a Fedora user, the Gnu install dirs updates are music to my ears!!!
That's great news!
Good stuff. I think I can skip the basics since I know those and they are similar to other programming languages, as well as things like polymorphism (we did a while subject on that) but I'll definitely get these books
Instead of the repeated posts about pi day, what are your favorite features/fixes so far for this release? Or any other recent releases so far? 
Personally I like: the ability to see if a cache variable is defined, easier builds with $ORIGIN rpaths, and default locations for the install command. - 
There is no "generally" here. It's a fine idea if you know you won't need those things, which happens all the time. if you want to support a custom allocator, great, make it a template! Or, if like you said, you really want to keep it fully general, pass in an array view. It just depends on the situation. None of this detracts from the general utility of rvalue references; you can't use out parameters everywhere, eventually you have to move objects between scopes. For example, into a container. At which point rvalues are still a huge help. Unless you have something more concrete, this is just silly. All code bakes in lots of implementation decisions. If you don't want to bake in the allocator, leave the allocator as a template parameter. If you are completely unhappy with what the STL bakes in, write your own data structures. Of course, you'll just be baking in something different. Which is the whole point. The STL is supposed to be a reasonable set of default data structures, and it succeeds at that. C++ intentionally doesn't privilege the STL (in practice) so that you can write your own data structures that better suit your own needs. It succeeds at that too. New C++ has given lots of new, amazing tools for this, things that help with your own data structures and not just STL (rvalue references, variadics, perfect forwarding, lambdas, etc).
Yeah this one annoys me. UDLs have a very strange ergonomic story...
why not for 3.14.159?
The principle I follow (and encourage) is to forget "using namespace" even exists. Especially in headers, where it can propagate freely. The pain of name conflicts combined with the relative ambiguity of using types without their proper namespace makes "using namespace" a net negative in my books.
Interestingly, half your complaints are only applicable to Asio and actually miscredit Beast with many core abstractions. &amp;#x200B; That being said, this makes me realize that the biggest obstacle to the adoption of Asio and subsequently the Net TS is a combo of things: community ignorance and Asio just kind of being old while simultaneously being ahead of its time. &amp;#x200B; The only true solution is a series of practical blog posts that go into the nitty gritty of Asio and Beast all the way from building the CMakeLists.txt to writing unit tests that actually work.
It probably doesn't work for everybody. Just a somewhat large number of people. 
I'm aware of what asio is and how beast fits into that, but the OP is saying that people simply think beast is clunky because they do not understand it - this is untrue, and it being derived from asio doesn't mean that it is not clunky to use I don't *blame* beast for these problems, but it is still true of beast regardless of whether or not it is *because* of beast
I‚Äôm excited to try the iOS tool chain. I‚Äôve never been comfortable with the home-grown ones, although I haven‚Äôt looked at them in awhile either. Also, relative RPATH support is immediately useful to me for a new project. 
In a very tightly coupled source file, I don't see any reason not to use your own namespace. For instance FooLib.h namespace Foo { A bunch of stuff } FooCLI.cpp using namespace Foo; int main(...) { Do lots of stuff with Foo's names } 
At the heart of this problem are three requirements which are not all mutually satisfiable: 1. Performance 2. Debugger-friendliness 3. Safety &amp; genericity You can have any two of the three. unique_ptr at O3 gives you (1) and (3). unique_ptr at Od gives you (2) and (3). Raw pointers at -Od gives you (1) and (2). Maybe (3) is not worth enough to you to justify giving up either (1) or (2). If so, more power to you -- C++ is much more than the STL after all. 
Concepts will reduce the size of most template-related error messages to the size of a limerick 
Perhaps it's a matter of taste. I prefer to be explicit: &amp;#x200B; Foo::Bar baz; // now we know exactly where Bar came from, and the snippet is copy-pastable if need be &amp;#x200B; Same reason why I avoid using auto in most circumstances. Code should be easy to read and understand without IDEs and syntax highlighting. This includes the types of variables, and the provenance of these types.
Great tutorial. I have a question. How tight is beast integrated with boost ecosystem? Is it possible to have a non-boost variant like asio?
if you think it's fundamentally broken, it's just you.
This looks nice! Out of curiosity, how does it compare to sparsepp,, 
Default paths on installation and 64Bit on windows. I love everything that makes default build setup easier. 
I switched from GoogleTest to [Catch2](https://github.com/catchorg/Catch2) awhile ago, haven‚Äôt looked back. I really like the Scenario/Given/When/Then [Gherkin](https://docs.cucumber.io/gherkin/) BDD syntax. First class support in [CLion](https://www.jetbrains.com/clion/) was a nice bonus, and completes the ‚Äú4 Cs‚Äù (CLion, CMake, Conan, Catch). 
Not quite serious, but still: One feature I like is no official WinXP support. Every hour that is invested on keeping new sw running on XP is a waste on humanity. Even more so for Dev tools.
\&gt; And you also add these compiler-specific options in a Makefile, so... Oh yeah, absolutely - I'm just saying that in my experience, CMake doesn't really do a good job at abstracting compiler controls. It only provides a unified way to set them. \&gt; I don't see how that would be hindering my workflow at all. I guess this is the running theme here. CMake conflicts with the workflows I'm used to, that don't even have much to do with make - I used to use jam and the configuration and criteria were exactly the same. I used to use SCons and they were exactly the same (although I didn't like SCons because it was sloooow). If they work for your workflows - fantastic! They don't for mine. \&gt; I agree that checking the return type is a bit tedious, but I doubt it's a lot easier in Makefiles. Every line of every action by default fails the entire recipe if it returns 0.
Oh Update 1 vs Preview, got it. I was confusing the different numbers. Thanks! Can't wait to have faster STL :)
The usual problem that I hear is that GUI design with c++/winrt still has very bad support (don't know the details)
It depends on your project/code convention. If you use unity builds, you might have conflicts with using namespace on .cpp files. I usually wrap again my source with the namespace block, and I get the same results. 
Lol. Does it mean that ranges are super slow comparing to STL?
Uhhh. Sorry to disappoint you, but you certainly do not need assembly or obscure optimizations to make it fast. Just some decent engineering. 
It's always interesting to see creators of something rejecting users' feedback. I also hate having to wade through the lists of warnings to find a new one to manually enable. 
You can see the [archive of Overload issues online](https://accu.org/index.php/journals/c78/) without being a member.
This was a bit disappointing. Is there any reason as to why the ranges implementation they tested is so much slower than the STL algorithms?
Could you develop ?
&gt;CMake doesn't really do a good job at abstracting compiler controls. It only provides a unified way to set them. Which is... drum roll... some kind of abstraction. :) I completely agree that it doesn't unify everything 100%, but then, difficult things are difficult. It does a *lot* more than you could expect from a plain Makefile, and what it does, it does usually quite well. &gt;I guess this is the running theme here. CMake conflicts with the workflows I'm used to I guess that adapting your workflow just *slightly* to the tool in question would go a long way. Although I doubt you'd have to adapt very much, especially if it's just about being in a different directory.
&gt;[https://github.com/google/googletest](https://github.com/google/googletest) Simply the default option. That, I think, is not a true statement.
This is not appropriate.
If it makes you feel any better, we get just as confused :)
I'm curious to also see the timings for the non-fancy way of doing this. For example, for the first one, something like this: vector&lt;int&gt; results; results.reserve (inputvector.size ()); for (auto &amp;v : inputvector) results.push_back (v *= 2); 
Does any one else think the reason something like beast hasn't really taken off is a lack of a proper cross platform package manager for c++. I have tried previously to use beast at work to replace our own custom http server and it just has so many holes it would be a massive task to use. For example it doesn't have the ability to parse URL's which Is normally very useful for a webserver. So now I have to research into what's the best c++ url parser. I was hoping boost already has one as adding another third party lib is a massive pain but no. I need to parse json which one do I use and now I need another import but it uses cmake to build and I'm using msbuild. :-( One of the selling points of beast is that it's a header only library to try and side step this issue but makes compile times longer. compare this with [https://actix.rs](https://actix.rs) a complete webserver written in rust. If I want to start playing with this I create a project and add this to my Cargo.toml actix-web = "0.7" I now have a full webserver with http2, router, urlparser, ssl and json support . It is so easy to build on top of other peoples projects C++ really needs this. The only library I know of that tries to build on top of beast is [https://github.com/octobanana/belle](https://github.com/octobanana/belle) and i just cant get it to compile on the version of MSVC I have to use at work. &amp;#x200B;
&gt; of course deleting const X&amp;&amp; binding isn't a panacea - however, it prevents easily-preventable errors, and doesn't cause significant headaches in practice. so you did it? Aren't you afraid of the `Babies that look like bathwater` issue?
Why do you think that? Which build system do you prefer?
Boost has practically no examples and if you don't understand it immediately from the documentation (and I went batshit crazy with ASIO and coroutines) you need to spend hours diving in the messy source code or asking on SO. Qt is way easier to work with and if you want to get stuff done quickly it's definitely an advantage.
&gt; brain-meltingly weird stuff with it Unless performance-forced (and that could be the case for stuff in the STL), most people just have fun bragging their smartness with a very convoluted piece of code. I feel this way stronger in the C++ community rather than, e.g., python community or C users groups.
I think you are aware of that, but it merrits pointing out explicitly: Explicitness does not automatically equal better readability. If the presented information is redundant or inconsequential, it becomes noise distracting from the important parts of the code. For a short prefix like std this is usually not a problem for ::boost::filesystem it can become annoying and typing `::my_name::my_library::moduleA::submoduleC::my_well_chosen_function_name` all the time becomes outright ridiculous (that is the situation you are in when you use some Windows APIs ). One of the big reasons I'm looking forward to modules is that I no longer have to write std::chrono:: in header files.
Yes, of course, I assumed a custom `assert` -- which is a good idea anyway (i.e. not just for this reason).
I'd be interested in seeing the compile times and text segment sizes as well
Obviously everything is subject to common sense. In the above case, I'd alias the namespace/type. By Windows APIs I presume you mean WinRT here (because Win32 is C without namespaces). Yeah, those names get tedious.
Based.
Nice. Reminds me of TeX's version numbering system , which works by adding another decimal to pi every version. It's currently at version 3.14159265.
&gt; they're not the largest users of C++ by a long shot No one is saying we should worsen others' situation by improving game developers'. &gt; We don't care if our code is wrong That is an exaggeration, but fine, let's put it like that for the sake of the argument. &gt; Is not a combination of problems literally anyone else has. You don't need that combination to discuss debug builds: assume debug builds took infinitely more time than a release build. Then no one would use them. Thus it isn't true that performance of debug builds doesn't matter. What actually happens with games is that their tolerance for the slowdown factor is way lower than most other projects. &gt; And of course even in those case a lot of the time you can get most of the way there by just doing a release build with debug symbols. If that were true, no one would use debug builds. Yes, there are many cases where you don't need it, but it is the ones you need them that matter.
I wanted to advise caution on an aspect: check if your local area has a previous history of companies working with C++ if you don't want to relocate. Most C++ jobs might be overseas (e.g. if you're european) or require you to relocate to far away places from family/friends. That's something to also consider when choosing a tech stack to study.
The problem is function pointers usually don't inline. So if lambdas are used instead of functions, then there is an improvement. Also for clang, LLVM standard library wasn't used. Once those are added the ranges algorithms are faster or on par with SmartOutputIterators faster than Algorithms.
how would they be faster than Algorithms?
I rerun benchmarks with Clang + libc++, O3 and additional test (BruteForce) - ranged for without function calls. Here is results: [transform (Clang + libc++)](http://quick-bench.com/l8fvGXCoBAcd2YCGTtA-i-fZFSg) ranges = x algo = 1.2*x smartOut = 1.2*x bruteForce = 1.2*x [filter (Clang + libc++)](http://quick-bench.com/Ym8fcwoDskTzPGomuNNzPS95Kqk) ranges = 2*x algo = 2.3*x smartOut = 2.3*x bruteForce = x [filter, transform (Clang + libc++)](http://quick-bench.com/SI-n8ypW60zfXY7i5bD7_tDp3dc) ranges = 3.2*x algo = 2.1*x smartOut = x bruteForce = x [transform, filter (Clang + libc++)](http://quick-bench.com/SI-n8ypW60zfXY7i5bD7_tDp3dc) ranges = 3.2*x algo = 2.1*x smartOut = x bruteForce = x As you can see range-v3 is faster with one view and slower with multiple views. 
The disassembly would have to be: analyzedhttp://quick-bench.com/ZeLxIN2gt4JxCBtznrPiewjAtiY
The disassembly would have to be analyzed : http://quick-bench.com/ZeLxIN2gt4JxCBtznrPiewjAtiY
&gt;compare this with https://actix.rs a complete webserver written in rust. If I want to start playing with this I create a project and add this to my Cargo.toml C++ community much, much largest and much, much, much oldest than Rust's one. And this community is highly fragmented. There are a lot of people who prefer to use a particular Linux distro's package managers. There are people who are bound to just one platform (like Windows). There are people who prefer one C++ dependency manager to another (someone likes vcpkg, someone likes conan, someone likes hunter and so on). Add a lack of standardized build-tool (CMake is becoming de-facto standard, unfortunately) makes the picture much worse. But this is not all. There are a lot of in-house dependency managers that are used privately and were never shown in the public. It's very hard to bring something that quickly becomes the standard dependency manager for C++. There are some attempts we can look right now but I don't think there is a clear leader. Rust doesn't this problem in principle. So it is a not fair comparison. The main problem with Beast, IMHO, is the assumption that Beast is an end-user solution. Many C++devs (especially novices) are looking for an embedded HTTP server for C++ and found Beast as the most famous framework. And that framework is in Boost, so many can think that it is a "recommended" way to deal with HTTP in C++. So they don't look around for alternatives. But Beast is not a top-level tool that many ordinary developers want. It is a powerful, flexible and customizable basic building tool. Low-level tool. Maybe too low-level for many tasks.
&gt; so the synchronous ("blocking") model is only useful in limited contexts No. Both blocking *and* non-blocking synchronous models are very useful; and both are supported in the Networking TS. I understand you try to sell the asynchronous model (which is great), but please don't try to imply it is the only way to go about it or that it is the best. For instance, the per-thread synchronous blocking model is still very useful, very easy to reason about and with the best performance in many cases. The non-blocking operations are also extremely useful in many situations, without the need to go async with all it entails.
Did You try to use lambda's instead of functions?
Not yet. And I copied wrong links. I am fixing it now.
No. It just means that for this combination of compiler and standard library, and this type of application design, this code is slower. If clang compiler is used with stdc++ and lambdas are used instead of functions, then a diffrent result is achieved. 
&gt; In the above case, I'd alias the namespace/type. Exactly. That is still being explicit, without injecting names and keeping readability high. Same for template instantiations.
Who knows more about this file API. It seems to be the replacement for cmake-server but I can't find a discussion about it anywhere. [https://cmake.org/cmake/help/v3.14/release/3.14.html#file-based-api](https://cmake.org/cmake/help/v3.14/release/3.14.html#file-based-api)
Fixed wrong links in previous post and rerun with lambdas: [transform](http://quick-bench.com/SbIt3coZ9EVHkNJlfCHrJbCGBGQ) ranges: ?x algo: 3.5x smartOut: 3.5x bruteForce: 3.5x [filter](http://quick-bench.com/MoQy7YlNC2AYnYILMJbnPi0rynE) ranges: 1.6x algo: x smartOut:x bruteForce:x [filter, transform](http://quick-bench.com/XMBa-ytfnaH8plfAcr5irws0-HY) ranges: x algo: 2.5x smartOut:1.2x bruteForce:1.2x [transform, filter](http://quick-bench.com/L1qeM3BtDZFVkyBhUQswnB42Jwg) ranges: x algo: 3.1x smartOut:x bruteForce:1.1x 
No sorry I have no actual experience with it, I just encountered it once.
I just started learning it and it seems to have full support of all the XAML GUI kinda stuff that other windows apps use. It is written in standard C++17, which I like. they have written their own code generator that makes writing the interop classes a lot simpler. I like the direction they are going with this.
Here it is: [Last column](http://quick-bench.com/SbIt3coZ9EVHkNJlfCHrJbCGBGQ). [From my other post](https://www.reddit.com/r/cpp/comments/b18zpa/performance_benchmark_ranges_vs_stl_algorithms_vs/eiks145/)
With modules, you can use `using namespace` as much as you like anywhere.
I know its low level but the real question is why has no one built a full fledged http server on top of this library already. As /u/james20k says it could be its just too complicated for people to want to or I think it's more to do with how do you add a url parser/http2/json to this and then actually ship the thing to people that want to use it ? Unless it's also included in boost it is such a nightmare to do no one bothers and we don't get a full production ready http server. I was hoping modules would be the thing that allows much easier code reuse in c++ projects and to have one standard way of building things. It looks like i'm going to be disappointed. 
&gt;I know its low level but the real question is why has no one built a full fledged http server on top of this library already. AFAIK, many similar projects were started before Beast become known. There is no sense to rewrote those projects on top of Beast. And Boost.Beast itself is a rather young library. So maybe it just needs some more time. &gt; we don't get a full production ready http server. There are at least 5 or 6 rather mature projects of embeddable HTTP server for C++. Do you think no one of them is "production ready"?
The tutorial is splendid! Thank you for all the hard work.
But we are talking about beast here its over a year old and the only http server built on it I have found doesn't build on windows not exactly a glowing endorsement of it. It's pretty much the same age as actix-web by the way. which c++ http servers are there that support http2 / json parsing / ssl ?
Ah interesting. Was this always the case? As in, have I always been misinformed? FWIW, I have no objection to debug mode having a worse order than release mode. It's not unusual for me to have asserts that add an extra factor to the order since the conditions are slow to validate.
&gt;its over a year old It's not much time. And, as I said earlier, many C++devs just think that Beast is the best tool and use it as is and even don't know that Beast is a low-level tool. &gt; which c++ http servers are there that support http2 / json parsing / ssl ? First of all "json parsing" is not a task of http-server. You can easily do JSON-related stuff with [nlohmann/json](https://github.com/nlohmann/json) or [RapidJSON](https://github.com/Tencent/rapidjson)+[json_dto](https://bitbucket.org/sobjectizerteam/json_dto-0.2). But some frameworks like Silicon has support for JSON (but it is a different question how useful this support is). SSL is supported by almost all more-or-less mature frameworks. HTTP2... I just don't know. AFAIK, http2 is not widespread now and in many cases where it is needed it can be obtained by using nginx or similar proxy before your app. IIRC, [Cutelist](https://cutelyst.org/) has support for http2. There is a list of C++ projects that provide embedded HTTP server: [RESTinio](https://github.com/Stiffstream/restinio), [Silicon](http://siliconframework.org/), [Pistache](https://github.com/oktal/pistache), [RestBed](https://github.com/Corvusoft/restbed), [served](https://github.com/meltwater/served), [C++REST SDK](https://github.com/Microsoft/cpprestsdk). There is also [CROW](https://github.com/ipkn/crow), but it seems to be abandoned.
Excellent! A long-awaited feature for cross-platform mobile developers. I'm a bit worried about replacing cmake-server with cmake-file-api, though. Android Studio/Android Gradle plug-in was slow enough with gaining support for the former, and now they'll probably take years to integrate with the later.
You were faster than me. Was going to mention exactly the same thing.
Catch if you want to define tests with nice names. Need data-driven tests? Boost.Test is good at this. Death Tests, need mocks? Google Test + Mock. 
I think you're being intentionally daft if I have fully explain my meaning. We're talking about the optimiser, and the point is that older games were much smaller in code size, and some had very hand optimized paths that reduced the influence of the optimiser. None of the early games I worked on had that -- they all ran poorly in non optimised builds. 
I think I'd do namespace gh = LibBar::GadgetHelpers; An alternative is to introduce a nested namespace, to serve as your "using namespace" scope. 
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b1dqtp/beginner_question_about_using_a_library/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
That's an old way of doing structured bindings (minus auto) Here's a comparison of the various ways of extracting a pair through the versions of C++:
&gt; HTTP2... I just don't know. AFAIK, http2 is not widespread now and in many cases where it is needed it can be obtained by using nginx or similar proxy before your app. Every major browser supports http2 and prefers to use it so to say its not widespread is just plain wrong. True that json parsing is not a task of a webserver but every api endpoint I have written uses json to talk to clients from a browser. Now we are back to I need to pick a json lib and build that and include it in my project which can be a massive pain. The http server I thought looked most polished was proxygen which does support a lot of this stuff. Still its not anywhere near as simple as add actix-web = "0.7" to Cargo.toml and your up and running is it ? &amp;#x200B;
&gt; Every major browser supports http2 and prefers to use it so to say its not widespread is just plain wrong. I think that requests from browsers are not the major use case for embedded HTTP servers in C++ applications. Usually, embedded HTTP servers are used for microservices and in that area HTTP2 is not dominant yet (maybe HTTP2 is intensively used inside Google, Amazon or Facebook, but HTTP/1.1 is almost everywhere else). &gt; Now we are back to I need to pick a json lib and build that and include it in my project which can be a massive pain. I prefer to use full-fledged, performant and robust 3-party JSON library instead of a limited set of JSON-related operations supported in some HTTP-server. And adding nlohmann/json or RapidJSON+json_dto to your project is not as hard as you say. &gt; Still its not anywhere near as simple as add actix-web = "0.7" to Cargo.toml and your up and running is it ? It highly depends on the tools you're using. Modern tools like vcpkg or conan make dependency management for C++ much easier that 2 or 3 years ago.
He burninated the peasants too!
Catch2 still doesn't support using asserts on multiple threads - [doctest does](https://github.com/onqtam/doctest/blob/master/doc/markdown/faq.md#is-doctest-thread-aware)
If anyone knows where this could be better please let me know 
Why does it need to be proposed? Right now, this is possible: { using namespace LibBar::GadgetHelpers; SomeGadgimathing foobar(SomeGadget&lt;type&gt; gadget, GadgimathingOptions options); }
A global `using namespace XYZ;` is not a very good idea. But it can also be used in a local scope. For example in a function which heavily relies on `std` it can look like this: bool func(/*....*/) { using namespace std; // Use std functions ... }
&gt; struct SoundIo *soundio = soundio_create(); this is C, not C++
I did not compare with sparsepp, but I would assume the parallel hashmap would be significantly faster, and that its memory usage would be higher when resizing. I will post the comparison soon.
I don't really understand your suggestion. The submaps do dynamically allocate the arrays into which the values are stored.
Here is the growth of doctest: [https://starcharts.herokuapp.com/onqtam/doctest](https://starcharts.herokuapp.com/onqtam/doctest)
In the case of doctest you could just use the 2 files which make up the final single-header separately from the parts folder: https://github.com/onqtam/doctest/tree/dev/doctest/parts The .cpp extension of the implementation is like this only in the dev branch but I'll soon be releasing version 2.3 with an xml reporter so this will be in the official branch as well
No. Do not use using namespace std. It can cause ADL issues and naming ambiguity.
And, maybe - hopefully, some higher level libraries built on top of these that provide the simple interfaces people are wanting. It is quite crazy right now. While I haven't used Beast, I did use ASIO and it is not trivial for a non-trivial protocol to keep track of state and who does what and said what and what should be the response now and ... ugh.
It's actually both, assuming you refer to the quoted statement. libsoundio is a C library though, if that's what you mean.
Beast is pretty heavily dependent on Boost. These dependencies come to mind: Boost.Config Boost.Core Boost.Intrusive Boost.Mp11 Boost.Utility In theory I could just copy the files I need from these libraries (although Intrusive I would need to pare down and refactor since it is enormous and I don't use all of it) and make them private implementation details. However, there are disadvantages to doing so: I have to manually maintain my own fork of these files, and this fork of beast will no longer receive the enormous amount of testing and resources in the Boost CI systems. As I am just one person, I do not have the resources for this. However, if someone were to fork Beast to make it stand-alone (and maintain it) I would be more than happy to provide assistance. That said, I place little value on a standalone version. There's nothing wrong with using Boost. Yeah its big but so what? You aren't using all of it. The quality is high. I think it would be easier to just set aside an irrational fear of Boost and just use it. 
&gt; Does any one else think the reason something like beast hasn't really taken off is a lack of a proper cross platform package manager for c++. Beast *has* taken off, it is wildly popular because of its low-level approach. You're right that more things are needed, like a URI parser, JSON, etc... those are being worked on, and might appear in new libraries. I agree about the package management being a problem. Another problem is that C++ still has no standard networking, and there are no plans to add it until the year 2023 (not a joke). Or maybe 2026 (also not a joke). I believe this more than anything is why we aren't seeing the great libraries that we should be seeing.
I can confirm, I was flabbergasted that the synchronous HTTP server consistently outperforms the async by at least 5%. It makes sense though, there is some overhead to asynchronous which is not present in synchronous. Async scales better though, so like anything it is a tradeoff. People forget that Asio is not just networking. Synchronous interfaces make perfect sense for a lot of things, such as serial ports, file I/O, etc... 
You're welcome, and thank you for the kind words!
You are right. This is c, but still valid cpp. It gets handled this way because it has its own cleanup functions at the end. Next one I make, though, will be using a lot more cpp specific 
Fwiw, I'd prefer to find the first version in a header file. It may take slightly longer to parse, but that's mostly solved by the formatting and in exchange it's unambigously clear that `SomeGadget` and `GadgimathingOptions` belong to the same library and are not some locally defined helper classes.
I don't there are similar examples of scopes being used like that in C++? (Where something that applies to the entire scope is expressed right before the opening curly bracket. `if` comes to mind...). However you can always do: ``` { using namespace a::b::c; some statement; } ``` Which is similar to your example but with the using statement inside the scope. And this applies to any scope as well: functions, classes, it statements, etc. 
&gt; highly depends on the tools you're using. Modern tools like vcpkg or conan make dependency management for C++ much easier that 2 or 3 years ago. Modern tools like vcpkg and conan don't make it anywhere near as easy as cargo does to build things. What happens if the library isn't in vcpkg or I want a older version. Half the dependencies i need to build for work fall into this category. Saying it's better then 3 years ago doesn't tell me anything as three years ago it was terrible now its only slightly less terrible but no where near as good as other options. npm, cargo even go has a new modules for reproducible builds. C++ is archaic in this sense and people really should stop pretending it isn't.
Confirmation! Indeed sparsepp is slower, but does use less memory, especially when the flat tables resize. I used `#define SPP_USE_SPP_ALLOC 1` for spp because I was testing on windows, and the default windows memory allocator is not friendly to sparsepp. https://github.com/greg7mdp/parallel-hashmap/blob/master/img/spp_flat_par_both.png?raw=true
sorry i didn't mean to say it wasn't used i'm sure it is as its part of boost but can you point at any high level http servers that use it which is what i believe it was intended for. The reason for the delay of the networking TS was meant to be what if asio doesn't use the right approach. What if using co routines is a much simpler and safer way to do it. It makes sense to me but as someone who wants to have a standard way of doing things that works for a cross platform app it is annoying. Same with utf8 support they are doing nothing in c++20 apart from adding [https://en.cppreference.com/w/cpp/keyword/char8\_t](https://en.cppreference.com/w/cpp/keyword/char8_t) which libraries can then build off. It does make sense but again seems to be 4 years until we have a chance of having anything nice for utf8 support.
I don't think package manager are the problem, I think the low level focus of the API and the complexity that entails is. Also, most open source c++ projects are 1-3 man shows, so the feature set is usually pretty limited.
&gt; What if using co routines is a much simpler and safer way to do it Asio works with Coroutines TS, stackful coroutines, fauxroutines, std::future, boost::future, fibers, and user defined primitives, in addition to normal completion handlers. &gt; can you point at any high level http servers that use it which is what i believe it was intended for. They are out there, although many are not open source. I've started a list: https://github.com/boostorg/beast/wiki/Companies-and-Individuals-Using-Beast Beast is not intended just for HTTP servers. It is intended for anyone who needs a low-level implementation of HTTP and WebSocket. More likely, people will use it to create higher level libraries. And yes you can build a server with it as well, although depending on your use-case you may have to add quite a bit of code to it. This doesn't mean Beast is bad or deficient, it just means that the C++ open source community needs to get a fire in the belly and start making up for lost time, by writing those great high level libraries on top of Beast!!
Modules were never intended to simplify the c++ build or packaging process.
&gt;I prefer to use full-fledged, performant and robust 3-party JSON library instead of a limited set of JSON-related operations supported in some HTTP-server. I'm working on a JSON library for another open-source project of mine, and I think you will like it very much - it is designed with networking in mind (for example, by supporting incremental parsing, and allocators).
&gt; Saying it's better then 3 years ago doesn't tell me anything as three years ago it was terrible now its only slightly less terrible but no where near as good as other options. You can't change the past. The C++ history is what it is and you can't change it. There was no something similar to the current vcpkg or conan 5 years ago (not telling about 15 or 25 years ago). But now we have them and a couple of alternatives. And more: we have a strong understanding now that the problems of dependency management in C++ should be solved. It is a big change in C++ world. It's good that other languages (especially young ones like Rust with user base few orders of magnitude lesser than in C++) have tools like Cargo or Cabal. But complaining about their absence in C++ world doesn't change anything. Instead of complaining you can contribute to any of modern C++ tools or make ports of existing libs for vcpkg/conan/hunter/build2/... Or just promote them. For example, you can switch from msbuild to CMake and this will be another step to just one standard build tool for C++.
In this case would something like `namespace short_ns = ::my_name::my_library::moduleA::submoduleC::my_well_chosen_function_name` be an option to maintain explicitness and not cause an annoyance?
&gt;which c++ http servers are there that support http2 HTTP/2 is officially dead now: [https://en.wikipedia.org/wiki/HTTP/3](https://en.wikipedia.org/wiki/HTTP/3) I am SOOOO GLAD I did not invest the 12+ months it would have taken (minimum) for me to focus exclusively on implementing HTTP/2.
 [https://xkcd.com/927/](https://xkcd.com/927/) :)
VS 2019 Support. Preview is quite stable already and the final release is only two weeks away.
&gt; Beast has taken off, it is wildly popular because of its low-level approach I don't want to dispute that, but I'd be interested on what metric you base that statement.
There are problems at the language level for why we cant have nice things like cargo. Me contributing to Cmake will make no difference to this. Modules I was hoping would be a big step towards, but it doesn't look like it is which is a shame. Me pretending cmake is great and telling everyone its great doesn't make it so. Just because something has a huge number of users does not make it good. Stockholm syndrome is a thing and the shear number of hours people have sunk into learning C++ and job prospects mean they will lie and pretend it's all okay which I understand. 
HTTP3 is not standardised yet and http2 will be a thing for a long time, reports of it's death are greatly exaggerated. 
Any progress regarding the migration to CMake?
I see that as a massive missed opportunity. 
Why not in source files? They are isolated, using namespace affects only them.
I think packaging it is a largely (although not quite) orthogonal issue to the one modules try to solve.
A lot of great content here. Out of curiosity was there any development on P1100R0? I'd run into similar problems as you in my own work with ASIO.
What is wrong with re-opening namespace? (Besides it looking uglier than usual, but that's kinda arguable.) namespace LibBar { namespace GadgetHelpers { SomeGadgimathing foobar(SomeGadget&lt;type&gt; gadget, GadgimathingOptions options); }}
&gt; There are problems at the language level for why we cant have nice things like cargo. I don't understand which problems at the language level lead some people to make, some to SCons, some to CMake, some to Meson and so on. From my point of view, the main problem is the absence of the standard build tool from the very begging. But we understand that standing on top of almost 40 years of C++ evolution. &gt; Me pretending cmake is great and telling everyone its great doesn't make it so. Point is not telling that CMake is great (it isn't). But using CMake you reduce the number of concurrent solutions of the same problem. It is not possible to make a de-jure standard for C++ build-tool, but it is possible to make a de-facto one. It shouldn't be CMake, it may be Meson or SCons, or Build2. But switching from msbuild to any of them makes C++ world better. &gt; Just because something has a huge number of users does not make it good. I speak not about goodness of C++, but about factors which prevent creation of Cargo/Cabal analogs in C++ world. These factors a based on long-long C++ history and you can't change things in just a moment because there are huge number of users. Rust is in very different situation.
GitHib stars are healthy, and I get emails (which I must keep confidential) from various companies having beast questions related to their implementation. Every who integrates Beast is very happy with it, usually the comments from experienced network devs go along the lines of "we've been waiting for a library like this for a long time."
This is true because `std` is special -- it's outside your control. Using your *own* namespace (or one from a tightly-coupled library) is a totally different story. Different things are different.
Christopher Kohlhoff presented my paper, P1100R0, in Kona. The result is `DynamicBuffer_v2` which you can see here: https://github.com/boostorg/asio/commit/9be88fb1924d84816848c38e0337f19a73dcf29a Unfortunately these changes were dropped on my head days before the Boost 1.70 release process started, so I was not able to get them integrated into Beast. However, I am working on it and Beast in Boost 1.71 will provide a unified set of interfaces which implement DynamicBuffer_v2. Classes like `flat_buffer` are going to be turned into opaque storage objects, and renamed - e.g. to `flat_storage`. Given a flat buffer `b` you can call `b.dynamic_buffer()` to get a lightweight object that you can pass to asio and beast where a `DynamicBuffer_v2` is expected. Or you can call `b.buffer()` to get a buffer sequence representing the bytes. To make it easy to inspect the object and manipulate it like a dynamic buffer, I am overloading `operator-&gt;` to give back a dynamic buffer proxy. So you can write `b-&gt;size()` to learn the size of the flat storage. This will likely cause some people's code to break but oh well.... 
Long Live HTTP/2!!!
I wouldn't give much on the github stats considering how aggressively you tell everyone to star it. But feedback from actual users is indeed a good sign. 
Can you already design your UI in visual studio?
Doesn't work. You can't have a "{" in headers.
Why should I invest time and energy and company resources into moving to something you yourself admit is not very good ? I believe its things like macros and having to reparse all includes because of macros which make c++ pretty terrible for packaging. Everything in the global namespace by default as well doesn't help that i can include something else that clashes with another include. When i try and remove includes I have no idea what is using it either. Spent 6 months getting a old windows code base to work under Make on Linux and it was not a nice experience and probably soured me on C++ forever to be honest.
Doesn't work because it puts foobar in that namespace.
Correct, misread.
It can still cause issues when you have unqualified calls. Because then ADL happens which might select a different function than you've expected.
https://en.cppreference.com/w/cpp/language/namespace Is the namespace body usage not sufficient in that case?
&gt;I don't there are similar examples of scopes being used like that in C++? (Where something that applies to the entire scope is expressed right before the opening curly bracket. if comes to mind...). namespace foo { } class bar { } extern "C" { } &gt;And this applies to any scope as well: functions, classes, it statements, etc. No, it only applies to block scopes, i.e. in functions. You can't have a using-directive at class scope. 
&gt; Why should I invest time and energy and company resources into moving to something you yourself admit is not very good ? Just because there is such thing as de-facto standard. CMake is becoming such a standard. I don't like CMake, but I understand that if I provide CMake-files for my project that makes use of my project a lot easier. If you switch from msbuild to CMake you won't make complains like "_I need to parse json which one do I use and now I need another import but it uses cmake to build and I'm using msbuild_." &gt; I believe its things like macros and having to reparse all includes because of macros which make c++ pretty terrible for packaging. You're wrong. A long history of deb- or rpm-packages in Linux, or modern history with vcpkg or conan shows that headers and macros don't prevent the creation of packages for C++ libraries. 
I think that "(although not quite)" could be quite a big issue in practice. When I import a module I really want it to never interfere with my current code. Not forcing all modules into a namespace means two modules can declare the same function name in the global namespace and wont work together.
Oops! You're right. The most obvious example escaped my mind on this one. Wonder what was going through my kind regarding a using directive at class scope! Thanks for pointing it out 
Unless you ever decide to use unity/blob builds, which are a relatively common build acceleration technique.
https://medium.com/@eirc.m/exploring-conan-21bcd355154 https://pabloariasal.github.io/2018/02/19/its-time-to-do-cmake-right/ https://www.youtube.com/watch?v=xBLjXdyh3zs https://www.youtube.com/watch?v=sBP17HQAQjk I don't know if you use cmake, but either way you should know how to pack a library before to know how to use conan. If you want basic usage, the conan doc will help you. 
As far as I see they should support it? https://godbolt.org/z/UJ_qY_ is something like that what you're looking at? I haven't mucked about enough with pointers to completely know
Consider this example: #include &lt;unordered_map&gt; class unordered_map { public: bool is_my_custom_written() { return true; } }; int main() { unordered_map um; std::cout &lt;&lt; um.is_my_custom_written(); } So far so fine. But now if we add "using namespace std"... #include &lt;unordered_map&gt; using namespace std; class unordered_map { public: bool is_my_custom_written() { return true; } }; int main() { unordered_map um; std::cout &lt;&lt; um.is_my_custom_written(); } Now this results in "error: reference to 'unordered_map' is ambiguous." This might seem at first like a contrived example, but it's actually very real. This exact kind of scenario is why "unordered_map" didn't get named "hash_table", because lots of people had defined their own "hash_table" class _and_ used `using namespace std`, and if std had introduced their own hash_table type, then it would have broken existing code. `using namespace std` undoes the whole point of namespaces. Don't do it. Ever.
Saying CMake is de-facto standard is bending the truth a bit. There is no way I get to tell my boss we should use cmake and its going to take me X amount of hours to do it even though it's not very good. Centos 7 ships with opensll 1.0.2k so what if i want a newer version because it supports TLS 1.3 ? This is very far from a solved problem in c++. I also never said header includes and macros stop creation of packages it just causes problem. As a stupid example what's to stop me adding this in a header and pretty much everything breaks that includes it. \#define true false The new modules proposal I believe prevents it leaking out of the module. 
To play devils advocate, though I would never do this and myself recommend paying the namespace tax, you could define foobar in said namespace LibBar, and then in global scope, bring foobar in with a using statement. Just for argument's sake.
In your example std::vector works fine, but i you use std::list it gives the error: `error: cannot convert 'OffPtr&lt;std::_List_node&lt;int&gt; &gt;' to 'std::__cxx11::list&lt;int, Alloc&lt;int&gt; &gt;::_Node*' {aka 'std::_List_node&lt;int&gt;*'}` And if you look at the [definition of \_List\_node\_base](https://github.com/gcc-mirror/gcc/blob/aa2e3429d2f11fb7c474cfe0663da4323b77622b/libstdc%2B%2B-v3/include/bits/stl_list.h#L80) you'll notice there are raw pointers all over the place. It's just ignoring whatever type your allocator is returning and trying to use a raw pointer.
Have you bothered the GCC devs by submitting a bug report? They can't fix it unless they know about it.
You could easily use a unique_ptr with a custom deleter.
file a bug report. i dont think there are any active plans right now, but there will never be if people dont complain. out of interest hat is your usecase?
I guess I assumed they knew about it since there is an LWG issue open, but maybe no one's actually asked for it so it's not a priority for them? I'm not sure it's technically a bug since it's not in the standard yet, but I'll look for a mailing list or something where I can ask them. Thanks!
Just don't use list. Problem solved! Two problems, actually (the other one being that you were using list.)
&gt; Me pretending cmake is great and telling everyone its great doesn't make it so. You are completely deluding yourself if you think the language is the main problem why building and packaging in c++ is more difficult than other languages. It also has nothing to do with cmake being bad. The problem is that every library out there thinks it has to use it's own build system, it's own directory structure, it's own way to be installed, it's own opinion on which build flags should be used for debug or release builds, it's own way of compiling and running unit tests, it's own way to find dependencies (and or to decide if certain dependencies should be used at all on a particular system). Modules could have solved exactly zero of those problems. Fragmentation and clinging to backwards compatibility above all else is what's hurting the c++ eco system. Not a few quirks in the language. 
It's in a header file though, so now you have this gh defined every time you include the header. Depends on the intent of this library and how it will be used so I wouldn't recommend this globally as a solution, but it does work well in many scenarios.
Yep, that's what /u/chugga_fan suggested as well. I'll do that, thanks! The use case is zerocopy serialization over for sending objects over RDMA. You don't want any raw pointers since when the objects gets sent over to other machines, all the raw pointers break.
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b1glno/in_need_of_critiquing_if_you_are_willing_please/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
What an asinine response. Don't assume the OP is a moron. There's been an [issue](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=57272) on this for more than half a decade. The fact that issues get filed with GNU, despite the barriers they've put in place to discourage newcomers from doing so, blows my mind.
&gt; As a stupid example what's to stop me adding this in a header and pretty much everything breaks that includes it. &gt; #define true false I hope common sense? Just think about it: How many integration problems did you actually have due to bad macros (that didn't come from c-headers?) and how many problems where caused by library x using a different build system / package management system than your library? 
I think he was just trying to be helpful. Somehow I hadn't seen that issue before, thanks for linking it! It seems like that patch to std::forward\_list made it in, but not yet for std::list. Is there a procedure for poking old issues? I see someone is assigned to it, but it's been a couple years. I'm more than happy to make the change, but I'm not sure they'd want some random person to do it.
Modules could solve a few of these if only with the new modules we had the ability to say things like : All code for a module must be in a single directory with the same name in a set place. All unit tests must go in a test folder in the module. All code in a module must be in a namespace of course the committee said this is not part of the language so let the world work it out which is why we are exactly where we are now. It is also an issue with the language not having a standard unit test framework or just a standard way of running them and a set place to look for them. I appreciate you often get prebuilt libs in C++ and headers which complicates it but they are desperate for people to easily move to modules but i think they are removing the features that make them worthwhile to do it.
But that's false. It has been established in this thread that we can indeed flatten all the calls in unique_ptr, but even if that was not true, you could have then decided to add unique_ptr to the language instead of the STL and all would have been well (arguably, better) too.
r/learnprogramming, r/programming, and r/coding come to mind. 
Does that also include microcontrollers of the cortex-m variaty?
Aren't the fancy pointer types deprecated in C++17, removed in C++20? (according to [this page](https://en.cppreference.com/w/cpp/memory/allocator))
Hahaha if only it were that simple!
I agree with your reading and desperately hope you're mistaken. &amp;#x200B; For those occasions in which you don't have a single unified address space (distributed/coprocessor) or the address space comes with caveats to be useful (shared memory), fancy pointers are a god sent.
&lt;humor recognized and ignored&gt; &amp;#x200B; Setting aside there are (rare but existent) occasions when list is the preferable data structure, this issue also impacts map, unordered\_map, and deque
They are removed from std::allocator because the definitions in the std::allocator and std::allocator_traits&lt;std::allocator&gt; overlap. Thus it is not necessary to define twice. You should be checking [this page](https://en.cppreference.com/w/cpp/memory/allocator_traits)
Nobody runs custom webservers on Windows.
I knew they were deprecated in C++17, but didn't realize they were getting removed completely. Does that mean STL containers will go back to using raw pointers everywhere? (since right now containers use something along the lines of `allocator_type::pointer` , etc) Getting rid of fancy pointers completely seems like a regression to me for shared memory use-cases, maybe they're just going to provide a different mechanism for using them? I'll have to look into this more, if anyone knows about this let me know!
Forgive me for being dense, but how is the deprication bad? From what I see, the "work around" is to provide a allocator specified for the type you want to allocate.
[https://en.cppreference.com/w/cpp/named\_req/Allocator#Fancy\_pointers](https://en.cppreference.com/w/cpp/named_req/Allocator#Fancy_pointers) &amp;#x200B; It's looks like cppreference still has a blurb on fancy pointers with no C++20 annotation. Maybe the particular field on std::allocator was deprecated? 
Right back at you. What a needlessly rude reply, especially because you totally mis interpreted the post.
There was [P0773](https://wg21.link/P0773) to solve those problems. Polls are also available: https://issues.isocpp.org/show_bug.cgi?id=366 and there is R1 draft: https://quuxplusone.github.io/draft/fancy-pointers.html but I don't think it will be in C++20
Is that really supposed to mean "using simple toolchain files", or rather "without using toolchain files"? So a toolchain file is still needed, but only a "simple" one? What constitutes a "simple" one, as opposed to what was needed before? &gt; Toolchains are now built-in Also not sure I understand this one - Does that mean "An iOS toolchain.cmake file is now shipped with the cmake distribution"? The 3.14-RC also had quite a number of problems with iOS - see https://gitlab.kitware.com/cmake/cmake/issues/17870 and related issues. Have these been ironed out? It's an awesome first step that you guys have done but from what I read I am not convinced it's quite "production-ready" yet. But yes let me point out again... awesome work on all this, it's great how you are all advancing cmake, really love all the new stuff and improvements!
Congrats on the release! It's also worth noting that Craig Scott's CMake book ([https://crascit.com/professional-cmake/release-notes/](https://crascit.com/professional-cmake/release-notes/)) has already been updated for 3.14. I am not associated with the author or book in any way but I just wanted to say what a fantastic book it is, and the updates are amazing, updated for 3.14 on the day that it is released, with no other book I have experienced such regular, fast and large updates! Amazing!
Yes, Just get the C++/WinRT IDE extension. It's made by Microsoft and includes project templates, debugger support and some other things that make the process a little more seamless. [Documentation](https://docs.microsoft.com/en-us/windows/uwp/cpp-and-winrt-apis/) is decent.
It seems that `ranges::push_back` uses container::insert when the input range is not a SizedRange (which is the case with `ranges::filter_view`). So given ranges::push_back(results, numbers | ranges::view::filter(isEven)); // #1 for (auto&amp;&amp; e: numbers | ranges::view::filter(isEven)) { results.push_back(e); } // #2 std::copy_if(begin(numbers), end(numbers), std::back_inserter(results), isEven); // #3 auto v = numbers | ranges::view::filter(isEven); results.insert(results.end(), v.begin(), v.end()); // #4 \#2 is roughly as fast as #3, while #1 and #4 are as fast and are slower than the other two. 
I think map and unordered\_map use allocator\_type::pointer, but deque might not, haven't checked deque recently.
Good to know. My company is use a bit of a dated gcc, but now I'll be on the lookout for such such a change.
If the one defining the functions in the header needs `gh`, then chances are that those using the header, also need `gh`. So providing it in the header is probably a Good Thing&amp;trade;. You sound like it would be negative, I fail to understand.
Thanks for the links! I've actually seen that draft before, but I mostly wasn't sure what the process was for getting this into the standard, and whether libc++ and libstdc++ would both have to support it before it was voted in.
Again, a c++ module is not a library or a package, so why should namespaces be tied to it? And except for macros I never had collision problems from other libraries. To be more precise: the only libraries I'm using that use the global namespace are either c libraries, or very old and "mature" c++ libraries. Neither of which are likely to get modularized. Everyone else uses namespaces. So no, I don't think it makes a big difference *in practice*
of course that was a stupid example so hopefully common sense would prevail but I have had a few integration problems with including headers. Stuff like macros that redefine type names that when you remove the include break existing code - took me a while to work out why. I have had a third party lib include an old version of mysql.h which my project was picking up so when I upgraded libmysql the memory layout was just slightly different leading to crashes. This took about 2 weeks to find. &amp;#x200B; &amp;#x200B;
They know about it but it's an ABI breaking change, so I wouldn't hold my breath.
It depends on what you're referring to. It appears that the nested typedef of `std::allocator` was deprecated rather than fancy pointer support in the allocator model. While the former was (I think) an unnecessary breaking change for existing code, it's easy enough to work around and at the end of the day, probably a minor inconvenience rather than a total PITA. Regarding the latter, it's not so much the type in to be allocated, but how and where. As an example, take `boost::interprocess` as an example. If support for fancy pointers was dropped, one could not write an allocator which 1. returns memory using a fancy pointer implemented as address-space agnostic handles into shared memory AND 1. interoperates with the standard library containers We can't count on this in practice today anyway (and has been exacerbated by the polymorphic memory resource proposal), but at least it's a defect that could be (and I would argue, should be) resolved in the future. This is why libraries like `boost::interprocess` provide their own implementation half of the standard library containers.
It is the simple toolchain version, which means that you will only need to specify the system name for very simple projects. More information on the toolchain is at ( [https://cmake.org/cmake/help/v3.14/manual/cmake-toolchains.7.html#cross-compiling-for-ios-tvos-or-watchos](https://cmake.org/cmake/help/v3.14/manual/cmake-toolchains.7.html#cross-compiling-for-ios-tvos-or-watchos) ) . Basically the simple version requires you to only know the deployment target information rather than also knowing compiler/linker information. &amp;#x200B; The issues with FindThreads still exists ( and will require you to have a small external toolchain file to fix for now ). The ExternalProject issue is a long standing issue with any cross-compilation and I don't know what timeline that work is on.
If you flatten calls to small functions, then you don't have debugger friendliness because breakpoints/stepping no longer works as expected. Someone suggested an optimizer mode to flatten functions conditionally -- a "my code" optimizer. That is doable I guess, although where it ranks on the priorities of an experience compiler dev is obviously subjective. Finally, things that are implementable in the library don't belong in the language. That's a key tenet.
So such big difference in `transform` (and probably in some other cases) seems to stem from the fact that range version is able to utilize knowing the size of the range thus `ranges::push_back` effectively is doing `std::vector::insert` with three iterators instead of actual mass `push_back` with `std::back_inserter`. This is very nice feature but we can also do it by hand in algorithm version (+ transforming directly into `result`) making it 2 times faster than ranges. [link](http://quick-bench.com/3XcXjP2fv2HJ0L2IYYP-KGBClzA) Why is it 2 times faster though? It seems for some reason resize + direct copy/transform is much faster than three iterator insert, at this moment I have zero idea why to be honest. With libstdc++ `insert` seems to be even more slower. And once again we can make ranges as fast if we resize by hand. [link](http://quick-bench.com/wpmFoRbeCuzmTur2MzhOW3J_L7I) But I guess in this case we will already get too far from what is considered to be idiomatic code for ranges/algorithms.
So you agree with me that fragmentation between libraries is the main problem? Standardizing a project layout, a unit testing frame work are all things completely orthogonal to modules (which again, are not libraries, nor packages)
You cant force people to change old code, you can force them to stick to a standard for new code though so modules was the chance to do this.
and Again I think its a missed opportunity that they are not a library or a package in a namespace. So apart from c and mature libraries which i'm guessing is a big chunk of code most people use it isn't a problem. 
You know, it's fine to disagree but insults aren't really called for when you disagree with someone on here. 
Could you go into more detail about that, or is there a discussion of it I can read through? This [draft](https://quuxplusone.github.io/draft/fancy-pointers.html) mentions that it would be an ABI breaking change to support segmented pointers for libstdc++ (but not libc++) &gt; Some vendors' containers (e.g. libc++) already use fancy pointer types internally (in order to support Scenario A), so no ABI-breaking changes to class layouts would be required in order to support segmented pointers. Other vendors (e.g. libstdc++) use native pointer types internally, and thus even to support Scenario A would involve ABI-breaking changes for them. I'm actually not familiar with the specifics of segmented pointers, but it they seem to be a special case of fancy pointers, so would this still be an ABI breaking change for all fancy pointers or just segmented pointers? Since it seems like most of the libstdc++ containers use allocator\_type::pointer internally, it's just list (and maybe deque?) that don't what is stopping them from changing the last few that use raw pointers? I'd like to submit a PR to fix this if there isn't a good reason for it to be left this way. 
I was pointed in this direction to get a background on this: https://gitlab.kitware.com/cmake/cmake/issues/17753 I've played with the new file API and found it quite useful! And _hopefully_ can help things like the VSCode cmake plugin or Qt creator deal better with very large projects (i.e. many targets). While I'm not too familiar with the old cmake server API, this new one looks like you wouldn't have to get one single big reply, and probably provides a way of knowing which files/targets have changed rather than having to parse the entire response every single time 
So why is `filter` so much slower?
This. Turning on inlining only for functions marked as inline (which includes all functions declared in header files, and thus most of the still) comes with huge performance gains with minimal debugging pain. There's always \_\_declspec(noinline) for those rare times you need to debug an inlined function, and ideally you should be putting everything complex in cpp files unless you want to murder your compile time.
I am not aware of it; it certainly would be super useful! At the moment, stepping into a function which takes a `shared_ptr` by copy as argument is such an exercise in frustration :(
currently from what i understood parallel hash map holds multiple sub hash maps in an array(i assumed in an array). each sub hash map takes 56 (with mutex) or 48 byte. cpu cache lines being usually 64 bytes. so your sub hash maps share cache lines. this isn't great as each modification from one thread will invalidate the cache for other threads to keep cache coherence. if you added padding byte between sub hash maps it could improve performances.
But that would not break existing applications that don't use fancy pointers (because they can't), would it?
May I ask about your niche use case? Why would you not want to store any raw pointers?
I have GreatestHero namespace for which I do \`namespace gh = GreatestHero\` &amp;#x200B; Now I cannot include lib\_bar.h because the \`gh\` leaks out of it and collides with mine. &amp;#x200B; It would be nice if we could limit the short alias to just a certain scope. &amp;#x200B;
I guess you are asking about online, resources, but in case you might be interested, there is a workshop in CoreC++ conference: [https://corecpp.org/schedule/#session-14](https://corecpp.org/schedule/#session-14) 
`gh` would be limited to the namespace it's declared in the header. When you get name collisions by `using namespace` for two or more namespaces, that's what you have to fix. It has nothing to do with headers, all with `using namespace` uncritically. 
&gt; so there is no ABI change for existing applications You are mistaking ABI and API, it seems. You are correct that the API itself would not change. On the other hand, the ABI (Application Binary Interface), may. Specifically, users can still specify allocators that return smart pointers which are implicitly convertible to/from raw pointers, and those allocators will currently work with libstdc++. However, should GCC start using `Allocator&lt;T&gt;::pointer` internally instead of `T*`, then the ABI will break: data members, arguments/returns of internal methods, etc... in template classes all of this ends up being exported and part of the ABI.
Fancy pointers at all. It would change the size of list&lt;T, fancy_alloc&gt;.
Yes, I did it. No, I'm not afraid. If it's so important, give your baby a name.
Really dumb question, can I restrict this to a specific namespace scope? So that I can safely use it in headers.
We had a small number of bugs but overall it was the case.
It seems like they already are using `allocator_type::pointer` in most of the containers, just not all of them.
I don‚Äôt do this nearly enough, even though I know you can...
Got it, that makes sense to me. So I guess my question boils down to: why was it changed for other containers but not list? Since it seems like making this change for any container would change the class layout/be ABI breaking.
The functions do almost nothing, the deep call stack hinders debugging, doesn't help (try to look at the code perhaps). Core tenets aren't something that can be discussed? Were they written in stone by some sort of god? Moreover, it depends what you mean by "implementable in the library". Yes, you can get an unique_ptr in the library, but it would not be as powerful as having it in the language. Both in terms of performance, debugging and actual static checking of the uniqueness contract.
That's great for you, I suppose :) My point, though, is that the containers in which this was forgotten may very well require an ABI breakage to be fixed, and that's going to cause grief.
&gt; The use case is zerocopy serialization for sending objects between machines. You don't want any raw pointers because when the objects gets sent over, all the raw pointers break since it's a different address space.
This sounds like one of the problems that modules will solve.
You might be interested in [this thread](https://www.reddit.com/r/cpp/comments/b1clyc/was_a_scoped_using_namespace_ever_suggested/).
Yeah I guess I was just surprised they just never changed it for list.
Let's summon /u/jwakely , maintainer of libstdc++. 
Yes. You can use it inside another namespace.
Very interesting, thank you for the explanation, I'll investigate to see if it makes a measurable difference.
Why would it? I really don't get it. Raw pointer AREN'T THAT BAD. 
Not saying anything about whether they're good or bad, but unfortunately they don't fit my use case. 
/u/jhUfGriTA1j, you are right, aligning each submap to a 64 byte boundary makes the multithreaded insertion a little bit faster (~6%). See [chart](https://github.com/greg7mdp/parallel-hashmap/blob/master/html/img/par_align_test.png?raw=true). Thanks for the tip!
I doubt it was changed for them.
Even modularised code isn't written in a vacuum but will largely be part of a gradual transition inside existing code bases, so they will have to fit into those project structures. More importantly, mor all new code is automatically modul code anyway. There will be lots of new code for years, maybe decades to come that will not use modules and if you think the c++ standard can require a particular project structure for modular code, then why can'tit require this for new "regular" code too? I stay by my opinion that those are orthogonal issues, but I think we won't come to an agreement here and in the end it is inconsequential. Btw.: In case you are unaware of it, the pitchfork proposal might be of interest to you: https://github.com/vector-of-bool/pitchfork
I didn't say it isn't a problem (although I really didn't have any problems except the infamous windows header). I'm saying the libraries that exhibit such problematic behavior won't be modernized anyway, so it is completely irrelevant what modules could or could not contribute to the easier packaging of those libraries in practice. &gt;and Again I think its a missed opportunity that they are not a library or a package in a namespace. You want a completely different feature from what we currently call a module. Its a bit like saying "the committee missed an opportunity when standardizing std::vector to also standardizing a vector math library". The only result you would have gotten from increasing the scope of the modules TS in sich a way is that they would have never become standardized at all. 
I didn't say it isn't a problem (although I really didn't have any problems except the infamous windows header). I'm saying the libraries that exhibit such problematic behavior won't be modernized anyway, so it is completely irrelevant what modules could or could not contribute to the easier packaging of those libraries in practice. &gt;and Again I think its a missed opportunity that they are not a library or a package in a namespace. You want a completely different feature from what we currently call a module. Its a bit like saying "the committee missed an opportunity when standardizing std::vector to also standardizing a vector math library". The only result you would have gotten from increasing the scope of the modules TS in sich a way is that they would have never become standardized at all. 
Wrong on so many levels.
How do you reconstruct the objects on the other side, though? Not just the vector (or whatever), but the objects in the vector? How do they get a lifetime?
I found this video very useful in this topic: [CppCon 2018: Mateusz Pusz ‚ÄúGit, CMake, Conan - How to ship and reuse our C++ projects‚Äù](https://www.youtube.com/watch?v=S4QSKLXdTtA)
No it won't, because I'm going to partially specialize for fancy pointers, so nothing changes for raw pointers. Since fancy pointers don't work at the moment, there's nobody using them, so nobody depending on the ABI of such containers.
It would break if you do it naively. I don't plan to do it naively.
Almost right. The `pointer` typedefs are removed from `std::allocator`, but those were never "fancy pointers" anyway, they were always just raw pointers. So no, fancy pointers have no been removed from `std::allocator`, because they were never there in the first place.
&gt; but my understanding is that it probably won't get added until libc++ and libstdc++ both support it, is that correct? No, completely wrong. The committee decides what _should_ happen, and if implementations do something different they have to change. There's no requirement for implementations to change first. And in this case, it's already clear what the intended behaviour is, even if we haven't made the standard say that yet. This is just [a libstdc++ bug](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=57272), that's all. &gt; If so, does anyone know if/when the libstdc++ community is planning to make these changes? Thanks! Why ask this on reddit? Wouldn't asking the libstdc++ community make more sense? It's a bug. It is [hard to fix without breaking the ABI](https://www.reddit.com/r/cpp/comments/b1fyc9/does_anyone_know_when_libstdc_will_stop_using_raw/eimdu9m), and not breaking the ABI is higher priority than supporting fancy pointers. I hoped to get time to finish the work for GCC 8, and for GCC 9, but now maybe it will happen next year for GCC 10. Of course if somebody wants it badly enough they could fix the bug themselves, or contract somebody to do it. GCC is free software after all. 
I just tried deque on compiler explorer. Seems like it works with GCC (at least trunk, haven't checked the rest).
Right. And that was never a fancy pointer anyway. `std::allocator&lt;T&gt;::pointer` is just `T*`, nothing fancy about it. And `std::allocator_traits&lt;std::allocator&lt;T&gt;&gt;::pointer` still exists, and since C++11 you're supposed to go through allocator traits to use allocators anyway.
&gt; whether libc++ and libstdc++ would both have to support it before it was voted in. No, that's not how it works.
Oh piss off with this "wah, filing a bug is too difficult" shit. LLVM have also restricted account creation on their bugzilla, but for some reason they don't get shit for it.
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;I should note that there was actually discussion on one of the public ISO mailing lists&amp;thinsp;‚Äî&amp;thinsp;it was either 'std-discussion' or 'std-proposals,' but I can't recall which at the moment&amp;thinsp;‚Äî&amp;thinsp;about changing the consequences of forgetting to include a '`return`' statement before the end of a non‚Äì'`void`'-returning function from your program containing undefined behavior to it being ill-formed. (Maybe I can find the relevant thread‚Ä¶) 
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Ah, [here](https://groups.google.com/a/isocpp.org/d/topic/std-proposals/Uu2QViiWh4k/discussion) it is. 
What about fancy pointers that happen to work today because they can use pointer_to?
I'd be surprised if they work. If they do, I guess we might have to break things for that small fraction of users to properly support a different small fraction (and keep the old behaviour behind a macro or something horrible).
My opinion on that topic is that they are fine if what you want really is multiple return-values that should be descructured right after receiving with structured bindings in the first place. `std::map&lt;K,V&gt;::value_type` is perfectly fine, because I don't think that there are any remotely common use-cases in which const auto&amp; [key, value] = *it; and friends aren't better anyways. The same is true for `insert`. And since I don't plan to ever access the contained values as members, a class `insertion_result` really wouldn't help me at all. I think this is a good place to draw the line for return-values. (There are many other valid uses for tuples, for instance to implement comparison, but those are mostly outside public APIs.)
They're fancy pointers; not doing something useful was a given
https://media.giphy.com/media/p7lObou4IdWUM/giphy.gif
I think the point is that you use a special allocator that places the objects on the vector in a specific area (and the vector itself). If you memcpy a struct you can get a pointer to the target struct and it has the same values. If you're careful you can do the same thing with your classes. So the point is, copy the whole memory arena and (somehow) get a pointer to the vector. The vector is pointing in the arena as well, and the fancy pointers make it point correctly to the copied over objects. The vector will continue to manage the lifetime of the objects in its internal array. If you do things right everything just works, no need to call constructors, just keep going from the original state. The vector will call destructors when the time comes.
The functions are necessary to allow a custom optional deleter but take no space if it requires no state. You can‚Äôt do both without the extra compressed_pair.
I'm assuming that the fancy pointers aren't just smart pointers to memory, but more along the lines of a database index or filename, etc.
Indirect calls through a function pointer can be inlined if the compiler can see which function it points to and the body of that function is available to the compiler. And in the cases where you'd use a lambda, that's often true. The cases that can't be inlined are when the function pointer comes from a caller in another translation unit, or the body of the function is in another translation unit (e.g. calling `std::qsort`, where the function is in your code and `qsort` is defined in libc). But that isn't relevant if everything is a template or is inline.
You still haven't begun the lifetime of the vector on the receiving side though. You have a copy of all the bits and bytes, but that's not a valid object.
&gt;but I'm not sure they'd want some random person to do it. ??? I would **love** for some random person to come and fix a bug that they care about. That's one of the most important aspects of open source! This bug is hard to fix, as there are constraints that limit how it can be fixed, but with enough gumption and dedication, and the right guidance, it's a Simple Matter of Programming. https://gcc.gnu.org/wiki/GettingStarted 
As an alternative, you might consider doing class-level typedefs to create shortened type names to use in the rest of the header file.
&gt;No, completely wrong. The committee decides what *should* happen, and if implementations do something different they have to change. There's no requirement for implementations to change first. And in this case, it's already clear what the intended behaviour is, even if we haven't made the standard say that yet. Got it, thanks for clearing that up. &gt;Why ask this on reddit? Wouldn't asking the libstdc++ community make more sense? Yep that's where I should have asked, I just browse this sub fairly often so I thought I might as well post it here. I can post it elsewhere if you think it would generate a good discussion, but it sounds like you're all aware of the issue. I'm absolutely interested in working on this, I think my first step is to actually understand your planned fix a bit better. You're talking about specializing all the pieces of containers that use pointers, one specialization for raw pointers and one for fancy pointers, right? Since you said you don't think people are depending on the ABI for containers with fancy pointers, why can't you just use the types from allocator\_traits (e.g. `allocator_traits&lt;allocator&lt;T&gt;&gt;::pointer` ) everywhere? I think this is the naive fix you referred to in another comment. &amp;#x200B;
Perhaps using an anonymous scope is satisfactory? void f() { // import the namespace within an anonymous scope: { using namespace LibBar::GadgetHelpers; // ... } } 
Maybe this question is naive, but what does it mean to say you have all the bits and bytes correct but not a valid object? What else is there to a valid object instance besides a region of memory with expected contents?
Why on earth do people go through all that trouble to return multiple values when you can just use output parameters? &amp;#x200B;
A license has been selected (MIT) and all of the source files were updated to include the copyright notice and license link. I also put up the build instructions, in the Wiki section, though I've not yet had a chance to set up a virgin scenario and test the instructions. &amp;#x200B;
Great answer! I'd love to know how you learned so much about C++, I'm assuming you know a lot based on the depth and detail of this post! thanks! :)
I don't understand how this is a "lot" of trouble, at least if you're using 17: pair&lt;key, value&gt; foo(); const auto [key, value] = foo(); vs void foo(key&amp;, value&amp;); key k; value v; foo(k, v); Output parameters are bad for a few reasons: 1. Readability. In more complicated code it's not immediately obvious for a given function what the inputs and outputs are. 2. Invisible mutation. C++ call by reference is invisible at the call site. A codebase that uses output parameters extensively, it's very easy to get surprising bugs because your function calls are mutating their arguments. 3. Const incompatible. Notice how in my previous example, you can easily make key and value const when you return directly, but not with output parameters. 4. Nonsense initialization. Closely related to 3. With output param approaches, you have to do initializations that are never meant to be read. This is much more likely to lead to certain bugs, e.g. passing the wrong thing as an output param, and then reading the uninitialized value later, potentially even leading to UB. 5. Inconsistency. When you return one thing, you return it by value, it's lame to have to do things completely different just because you want to return more than one thing. After all, we don't have to completely change our approach between passing one argument, and passing multiple arguments. You can partly solve 1 and 2 at the cost of a bit of cruft by writing a small simple class called `out_param` void foo(out_param&lt;key&gt;, out_param&lt;value&gt;); key k; value v; foo(out_param(k), out_param(v)); But readers of course still have to be aware of this new class. I try to avoid output parameters in this situation even in 14, but in 17 frankly it's a no brainer. And I'm not a zealot about it, I still do use output parameters, mostly when I have functions that populate large structs and I don't want to be totally dependent on RVO. They just have a lot of downsides and you need an excellent reason to use them.
That's two values. What if it's three or four or five? And the const thing makes no sense. If it's an output parameter of course you are going to update it, so it shouldn't be const. If it's input only it will be a const reference. And it will be vastly more efficient if the call is made multiple times, or in a loop, since the same object can be passed in and the called method can re-use content. As to readability, it's not immediately obvious what the return values of a method are either, unless you read the documentation. 
It means that the standard says that you do not have a valid object even if all the bits are in the right place. It's very likely to happen to work, but the standard says you aren't allowed to do that and so the compiler will assume that you don't and may make optimizations that break your code abusing UB.
You just use tuple? You can use tuple for just 2 values as well, and some people would probably argue you should. I'm not talking about the const on the function, I'm talking about the const on the k/v. In this example, even if I have no further plans to modify k or v, I still cannot make them const (without using other workarounds like IIFE). In the first case you of course don't have to make k/v const, but you have the option if it is appropriate. Being able to use const, when you want to, is good. Not being able to use it for totally artificial reasons, is bad. It will only be more efficient if you're talking about something like a vector, or a string, that reuses memory. It will not be faster for a primitive type, and possibly/probably very slightly slower. But yes, if you have a function that returns a string, and you are likely to call it in a loop in a performance sensitive area, then you should consider alternatives to return by value, including potentially out parameters (I did say they can be used when you have an excellent reason). In most of those cases though I still find there are better solutions. It's not about *what* they are, it's the simplest fact that they *are* return values, things computed purely by the function from its arguments. Whereas a codebase that uses output parameters extensively, you don't even know if `foo(k, v)` is using k/v as inputs, outputs, or inputs/outputs. Avoiding output parameters makes your call sites much more informative on average, not sure how you can deny this. There are degrees of inconsistentcy? Even in all those examples, you are still always returning something. Not passing a reference/pointer to a function, to get populated.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/gamedev] [constexpr properties header only lib](https://www.reddit.com/r/gamedev/comments/b1p639/constexpr_properties_header_only_lib/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Agree, I think reading developers/companies' blogs and following them on Twitter is the most effective way to keep us up to date nowadays.
I think you‚Äôre looking for an entirely different forum.
Look at the code again. The allocator type isn't known by `_List_node_base` so how can it use the allocator's `pointer` type? You have to make the list node and list node base depend on the allocator, which is an incompatible change.
http://eel.is/c++draft/basic.life#4
Oops sorry. Not familiar with reddit üòÖ
I'm a bit undecided between Ryan and *UB*
\+1 googletest is simply default option. I don't know if I should consider CMake's `add_subdirectory` is something difficult to add a library to my code :)
So (according to the homepage) there exist .net, lua, ada and rust bindings, but no c++ binding? I find that very sad. 
&gt; Hello everyone, ive just started a programming subject and seem to be stuck with my coding. This is a common occurrence. &gt; Is there a clear answer as to why my code wont progress from this point? With absolute certainty. Post your question here https://www.reddit.com/r/cpp_questions/
I don't want a completely different feature I just don't think they went far enough with the feature. This is their one shot to change a lot of things that are not great like project layout and they are basically saying its not part of the spec you figure it out. So from what i have been reading this means we don't need header files any longer (not sure how beast will change as a header only lib), The order we declare things in is no longer important as long as its present and you might get a speed bump of 20% in some circumstances though this seems to be hotly debated at the minute. I was hoping for a lot more from modules. 
You are completely deluding yourself if you think people will willingly change their code layout and tooling they spent a long time getting working to move to a non standard standard for some imagined benefit. I have never heard of that project and I'm betting 99% of the C++ community hasn't either. The reason C++ cant require new code to follow this standard is it has to support old code working exactly like it does now, If I add new code how does it know the difference. Modules are brand new and no one uses them, you could set a standard which all the compilers, build tools will follow for modules then you don't get a choice you have to set your code out the correct way or your build tool of choice wont work.
For C++ questions, answers, help, and advice see r/cpp_questions or [StackOverflow](http://stackoverflow.com/). This post has been removed as it doesn't pertain to r/cpp.
Please CAPITALIZE your macro names and identifiers starting with `__` are reserved for the standard library or the compiler, so please don't use them in your code. 
Do you have any other edge cases in mind, beyond `Allocator&lt;T&gt;::pointer` being convertible to `T*` or `T const*`?
Am I missing something or don't you have a motivating example anywhere?
Click on the documentation link or look at the examples.h
I have, but what I'm missing is a "here is what you can do if you use this system" example. Not just how I can add properties to my types.
And then?
Could anyone please explain the meaning of 'manifest' in manifest constants? &amp;#x200B; In dictionary, I found &amp;#x200B; adj. clear or obvious noun. list of passengers or cargo &amp;#x200B; This is very confusing to me. &amp;#x200B; Thank you. &amp;#x200B;
Yes, this is the way you define constants in C.
Please provide an example for a simple serialization / deserialization with a custom class. Just write out an object in key:value pairs and read them back.
Sorry for the wrong use of Reddit. I'm a new user here. I added a comment with a question below as follows. Thank you. Could anyone please explain the meaning of 'manifest' used in manifest constants? In dictionary, I found adj. clear or obvious noun. list of passengers or cargo This is very confusing to me. Thank you.
There's a good definition [here](https://encyclopedia2.thefreedictionary.com/manifest+constant): "A value that is assigned to a symbolic name at the beginning of a computer program and is not subject to change during execution."
Normally you would create a text post and put both the question and the link in the body of the post.
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b1qqi0/the_c_programming_language_second_edition_page_230/einikoz/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
This reddit is for articles about C++ or discussion about new developments, rather than questions from learners. Plus, it's about the C++ language rather than C, although your question does also apply to C++. But I'll answer anyways. According to one dictionary, a "manifest constant" is "A value that is assigned to a symbolic name at the beginning of a computer program and is not subject to change during execution." It is "manifest" in the first definition you posted, i.e. self-evident, because the code that uses it is self-evident. In that first example, if they didn't `#define TABSIZE 100`, then the other line would be int table[100]; It's not self-evident what the 100 is, so you might have needed a comment instead.
Hey, looks very nice! Well documented as well, thanks for sharing this. Do you have any indication on performance?
That is what the examples do when they run. They serialize to a STD:: vector and serialize in by copying from that vector to another instance of the class. But I can dump it the a file if you guys think it will be more clear.
Thanks for the feedback I will extend the documentation to make that more clear.
I thought for a while I was the only one who didn't get it.
Just that there is no telling, if you correctly mapped the returned values (which can actually be a problem if first and second have the same type).
I'm pretty sure it's on the adjective sense of "clear or obvious" here. As in, you can use macro definitions for things which are clearly constants. This isn't good practice in C++ these days, though. You should use a constexpr variable instead.
&gt; adj. clear or obvious It's this one. The first of those two #define directives is to make the code more self-evident.
The key/value is in property::entry. It contains a std pair which is a string and a variant which holds the data and type. At the bottom of the documentation you can see the test to serialize to vector and back.
Your nameof library reminds me of a library I wrote recently ([cleantype](https://github.com/pthom/cleantype#cleantype-readable-c-type-introspection---compiler-decipherer)). It provides services close to your NAMEOF\_TYPE macro, with a focus on readable types and consistency accross compilers.
Can `std::launder` help in this case? 
So I **did** miss something ;). You might want to put an example like that at a more prominent place.
Same. After looking into several examples, I didn't see what this is supposed to accomplish.
No. std::launder tells the compiler about a change in lifetime that it couldn't see, but it doesn't _cause_ a change in lifetime. It's purely informative, it doesn't _do_ anything. For a type with non-vacuous initialization the only way to create a valid object is to construct it.
So if you are really interested in getting help, why do you invest so less energy to describe what's the poll and your article all about? I would have to look at this tweet, without any information here. For me a no go üòâ
Thanks allot for the feedback!
OK I will make it more clear by pointing that out and adding a link in the examples. Thanks for the feedback!
Thanks, I will make it more obvious. 
Not to mention things like: \`value.second-&gt;first.second\`
No really I did not focus on performance yet. I was first trying to have the basic structure. There are two different directions for optimizations. One is to have relative paths, which I will add first. This will make batch setting and getting of properties faster. The second which will be even faster is having a master hash for all entries however this second path is more complex and may break some features. But step by step, still ongoing. However I have shipped games with the current level of performance before. &amp;#x200B;
NP. Usually I hate it when people start nitpicking code details instead of commenting the general design, but this time it really took my brains a couple of seconds to understand what was going on. So I thought is was worth mentioning.
Yeah, sorry. I can try to make up by copying here the poll of the tweet. Thanks for the advice. Have you read the last edition of "The C++ Programming Language" by Stroustrup? - from cover to cover - partially - no
I saw this comic once and it changed my life: http://hyperboleandahalf.blogspot.com/2010/04/alot-is-better-than-you-at-everything.html?m=1
ELI5? The Boost interprocess offset ptr seems like it could be useful...
\&gt; and the right guidance I think this is crucial, especially with more complex projects like GCC. I wish big projects like GCC, Rust, LLVM, the browsers, etc. , would have formal mentoring programs to get people involved. I know there are ways in which this does happen, e.g. GSoC, Sage Days (SageMath), and other things, but they tend to be one-offs rather than sustainable programs. I think a part of it is that the best potential mentors tend to be the busiest contributors. (Another issue is our culture of independence and, to be blunt, lack of social inclination.) But that's short-sighted. A sustained mentoring program would benefit in very strong technical talent and would grow the base of productive, quality contributors, taking some of the burden off of the busiest contributors to allow them to do more mentoring. We have a better understanding of this in pure mathematics, a field in which the typical graduate student does not bring a whole lot to the research program of the advisor due to the incredibly high learning curve and specialization of the field. But we know that mathematics needs a pipeline of well-trained people to feed our field, and we therefore generally value the training of future high-powered researchers. Not everyone will be a u/jwakely or u/BillyONeal or u/cpp, but everyone doesn't have to be, just like every mathematician doesn't have to be a Terence Tao or Andrew Wiles or Donald Knuth. Most mathematics is produced but more obscure contributors. Finding ways to bring in great talent who otherwise face significant barriers to entry to be a much higher priority for community-drive projects, in my view. And from my personal experience, mentoring is an absolute blast and easily among the most rewarding parts of my job.
&gt; it is not trivial for a non-trivial protocol to keep track of state Funny you should say that ‚Äì I've had great experiences implementing protocols using ASIO + Boost.MSM. Really _really_ formalizing everything into a proper state machine adds a great deal of clarity to the end product.
&gt;so there is no ABI change for existing applications &gt; &gt;You are mistaking ABI and API, it seems. &gt; &gt;You are correct that the API itself would not change. On the other hand, the ABI (Application Binary Interface), may. Nope, you got it wrong. The ABI for existing applications stays the same because they keep using T\* regardless whether its called T\* or allocator::pointer.
We are using P7 ([http://baical.net/p7.html](http://baical.net/p7.html)) in our embedded products, so far it is good experience. * support plenty of sinks * very fast (depends on sink, for binary files and network - millions per second without CPU penalty) * shipped with open source server to receive logs&amp;telemetry over network: * [http://baical.net/img/BaicalMain.png](http://baical.net/img/BaicalMain.png) * [http://baical.net/img/TraceViewer.png](http://baical.net/img/TraceViewer.png) * [http://baical.net/img/TelemetryViewer.png](http://baical.net/img/TelemetryViewer.png) * support different languages (C, C#, Python) &amp;#x200B;
Why does insertion return \`pair\` instead of throwing? I had to write wrappers and only use them.
I think that use case would have been better served with a purpose specific container. For example, you'd store more things as sizes rather than pointer ranges to avoid so many offset applications. The metaprogramming / debug codegen / specification / complexity costs of fancy pointers are significant and dwarf any potential benefits. 
Makes sense, thanks for the explanation!
This is off-topic, see /r/cpp_questions.
Cool! Now go grab /u/vector-of-bool 's https://github.com/vector-of-bool/pitchfork files layout for completeness ;)
Thank you for your information. I will go grab that convention and fix the project's files layout. :)
My apologies! Thanks for your help.
Unless `Allocator&lt;T&gt;::pointer` was: struct SpecialPointer&lt;T&gt; { SpecialPointer(T* ptr): ptr(ptr) {} operator T*() { return ptr; } T* ptr; Layout layout; }; In which case assigning `Allocator&lt;T&gt;::pointer` to/from `T*` was transparently handled, and those implicit conversions would be lost, leading to a different ABI.
Most of this kind of templates are either to complex or too simple. For me a minimal project is something like the pitchfork example mentioned before but it already too complicated cmake stuff there. Basically what I need is a project with static and dynamic library a third party library and a basic app using all of them. Bonus if the libraries a ‚Äúsocial libraries‚Äù as mentioned in some cmake videos
&gt; Reading std::pair&lt;bool, iterator&gt; does not tell us anything except that there are some boolean value and an iterator crammed together in a single data structure. If on the other hand, we had the name InsertionResult, we would have an idea where those values came from. Too bad C++ does not have a way of renaming types. The following would be so useful `typedef InsertionResult = std::pair&lt;bool,iterator&gt;` Unfortunately, C++ lacks such a basic mechanism. &gt; The same goes for the access to the single members. first, second for pair and std::get&lt;4&gt;() for tuple tell us something about the position of the data we access, but nothing about their semantics. With named members, we do not even have to know the position, Too bad C++ does not have a structure of data. Being able to do something like: structure pair_thingy { bool first; iterator second; }; would have been useful, but C++ lacks that. But even if it had that, this is a "Data class" code smell. So having that would actually be a bad idea. &amp;#x200B;
That can be a valid objection in some cases. The whole zero-copy approach is an optimization that relies on undefined behavior. You have to be careful with the objects you create and ensure that they are valid with this type of shenanigans as it puts the burden of getting it to work correctly on the programmer. This thread is about giving tools such that std containers fall in that class. Not required by the standard, but a nice tool to have For more fun, the same approach can be used for shared memory, so you'd have a single object in two address spaces. Has the object's lifetime started on the second one given that it's the same object? Irrelevant, the whole thing is undefined behavior, the standard doesn't talk about shared memory (or didn't in the old ones, maybe the new ones do)
How does this compare to Beast?
How does this compare to Boost.Beast?
What networking is this based on? I see \`::select()\` and \`FD\_SET\`
So I'm going to repeat everyone else's comment! :-) There are a lot of us out here, but there are a lot of packages being written every day. If we can't figure out in the _first few lines_ what I might get out of this, then most of us will go elsewhere. For example, look at this [very popular library](http://docs.python-requests.org/en/master/). Indeed, up until a year or two ago, the yellow box wasn't even there - it just went right into "a short code example". You want to make the absolutely shortest example that clearly indicates what your angle is! --- The nice part about the internet is if you come back next week with all this fixed up, no one will remember you tried to get traction this week and failed. :-D
The standard doesn't even admit that more than one process can exist at a time!
Your post has been automatically removed because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20False%20Positive&amp;message=Please%20review%20my%20post%20at%20https://www.reddit.com/r/cpp/comments/b1x0hl/birthday_message_help/.) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
 ‚ÄúThe lifetime of an object of type T begins when: (1.1) storage with the proper alignment and size for type T is obtained, and (1.2) its initialization (if any) is complete (including vacuous initialization) ‚Äù Is ‚Äúinitialization‚Äù supposed to be a precise synonym for ‚Äúconstructor call‚Äù?
Do you know how t by eye compare to boost.Signal2?
What would be necessary to make this work on windows?
They provide a benchmark. 
Who is they and where? Also I'm not so much interested in performance than API/ feature comparison.
Broadcast-Listener needs more code to be written than both Qt Signals/Slot and boost::Signal2. But I would say, Juce code is more readable than boost::Signal2. 
Would be nice, if you could add a filter for the callback (only call on error, only call for regular message etc)
It is incompatible because mangled names depend on the template arguments, right? I didn't have a good understanding of how the ABI works, so I went and skimmed some parts of the Itanium C++ ABI and found [this section](http://itanium-cxx-abi.github.io/cxx-abi/abi.html#mangle.name) which defines the grammar for mangled names, which is what I'm basing this off of.
It is incompatible because mangled names depend on the template arguments, right? I didn't have a good understanding of how the ABI works, so I went and skimmed some parts of the Itanium C++ ABI and found [this section](http://itanium-cxx-abi.github.io/cxx-abi/abi.html#mangle.name) which defines the grammar for mangled names, which is what I'm basing this off of.
Ninja sucks on Windows with MSVC, it gives me stupid errors that don't exist while compiling normally. I don't know why does Microsoft have it as the default generator for CMake...
What kind of errors?
No, scalars and aggregates don't have constructors.
Precompiled headers for example, it just doesn't work when compiling through Ninja, some weird bugs saying that the PCH file is not available. But whatever, I just switched the generator to MSVC and I can work fine with CMake. Just don't know why Ninja is the default one. Maybe it's already fixed in VS 2019 though, I dunno.
To be precise: fatal error C1083: Cannot open precompiled header file: 'stdafx.pch': Permission denied Again, there's nothing wrong with the script and works fine when compiling regularly with MSVC. I'm not experienced with reporting bugs so I'm not gonna bother. You can do that if you want. 
I maintain the vscode plugin (and I've been ignoring my backlog for too long, sorry...) The CMake Server design was initially meant to have allot more interactivity and introspection. Having a debugger was a good example. It turned out to be the case that you run the `configure+generate` rpc and then ask for the `codeModel`, and that was it. A huge amount of effort to getting the IPC working and bug-free, when the result is almost entirely synchronous. The file API may look extremely ugly and primitive, but it will be soon much easier and more reliable. Plus, the results can live between sessions. With CMake Server, you _must_ run configure before you can ask for the `codeModel`. I'm not too involved in CMake development, but as a consumer of the server API, I consider it to be a failed experiment. It will be useful when it has actual interactive features.
There's more to ABI than mangled names and sizes of types, and more than is defined by the ABI spec for the platform. A library has its own (implicit and explicit) ABI. Raw pointers are default constructible. Fancy pointers don't have to be, so the `_List_node_base` type needs to gain a constructor that will set the non-static data members. Now you have to worry about whether old and new code consistently initializes the base class in an equivalent way, when the old code (compiled against the old definition) thinks the type is a POD and the new code thinks it's initialized by a new constructor. Welcome to the game of deciding which ODR violations are safe and which are not.
"permission denied": this error is probably due to the fact that when Visual Studio is open it "owns" some of the files in your project and Ninja might be trying to open the file in write-mode. I could be wrong, but it's my best guess.
How did you set up precompiled header in CMake? I suggest you try to use the [cotire](https://github.com/sakra/cotire), it was really straightforward in my experience (and cross-platform to boot).
That might be the thing, I don't know
That's what I have right now: target_compile_options(&lt;target&gt; PRIVATE &lt;other stuff...&gt; /Yustdafx.h ) set_source_files_properties("src/stdafx.cpp" PROPERTIES COMPILE_FLAGS "/Ycstdafx.h") Very simply. Cotire seems nice, haven't tried it because this is just simpler and works good, and I'm only targeting Windows. I tried many other combinations and things, none successful on Ninja, all fine on MSVC
CMake does not support PCHs, there was some work done on this by Daniel but it was never followed up on.
So then what‚Äôs the difference between an object, and initialized memory that looks like an object? The doc you pointed to reads to me as saying an object‚Äôs lifetime starts when it‚Äôs allocated memory is initialized, which OP is doing. I‚Äôve heard a talk before, and you say here, that setting up memory with the right bits is not enough to make the compiler believe this region of memory is an object. But since constructors are optional I‚Äôm real confused about what is the magic missing step.
Regarding your CMake usage: * Don't use `CMAKE_CXX_STANDARD` for what you're doing. It only defines a default, but not what is actually required to build a target. Instead use `target_compile_features` and `cxx_std_17`. * _NEVER_ set `CMAKE_&lt;LANG&gt;_COMPILER` in a project, and definitely not after `enable_language` or `project` with languages set has been called. It will break. Other than that: Do not hard code `CMAKE_&lt;LANG&gt;_COMPILER` or assume that `-stdlib=libc++` is a valid flag. This is bad practice for a project and to hammer this point home, `clang` is probably the wrong binary for Windows, as it should be `clang-cl` most of the time. In this sense, don't have a `FATAL_ERROR` when your "operating system is not compatible" - CMake supports even very arcane UNIX systems like HP-UX or AIX and other than a lack of POSIX or C++17 functions, code should work. CMake supports toolchain files for the purpose of enabling compiler toolchain specific flags or settings being made _afar_ from the actual code itself. Use those instead of hard coding toolchain parameters in the `CMakeLists` file.
Yeah I know that, I just pass the compiler options about PCHs through it
Appreciate that. I think this project is too simple now as you said. and the explanation is so too short also. I will make it up whenever I get a opinion or suggestion. Anyway what exactly the "social libraries" is?
The project is even almost a draft. There a lot of things that I have to make up. Very very thank you for your pointing out. I can't even know that unless you commented this.
I echo this! Also, style-wise, there is little point in the 'SRC_FILES' and 'OUTPUT_BINARY' variables - they are just adding needless lines and complexity to the CMake source imo. And the INCLUDE_DIRECTORIES(headers) should probably be a TARGET_INCLUDE_DIRECTORIES(md5 PRIVATE headers) call instead, which will prevent include directories from being needlessly (or incorrectly) propagated in large projects.
How did you learn assembly? I struggle with it a lot. any pointers? :)
Well, IUC, the problem comes with implicit dependencies between pch and all other sources. Simple flag doesn't establish them, so generators that are more strict in that regard fail. Cotire takes care of it automatically, but you can do it yourself. So I wouldn't really call that a Ninja problem. More like built-in pch support in CMake problem if anything (then again, it's nicely solved by cotire in my use cases and it's just as simple, if not simpler, than adding a few flags. For most project you just copy cotire module and add 2-3 lines in your CMakeLists.txt).
My CMake skill is so humble as I'm watching comments here. But very happy to see that fact that I have the thing to learn from them then I can improve both my skill and the project. Thank you.
`cxx_std_*` requires CMake 3.8. If able to require this as a minimum, use this method. Otherwise set the target properties `CXX_STANDARD` and `CXX_STANDARD_REQUIRED`, which are available since 3.1.
\&gt; So then what‚Äôs the difference between an object, and initialized memory that looks like an object? Seriously, eelis links above are the answer here. \&gt; I'm real confused about what is the magic missing step The magic missing step is, in standard C++ the compiler gets to assume that a \`T\` can only come to life in one of a specific set of ways. There are a lot of reasons for this. One is type-based alias analysis which allows optimizations. One is, objects of class-type may have lifetime invariants and nontrivial destructors. The compiler is responsible to emit calls to destructors in appropriate places. If the compiler cannot easily figure out when an object is coming to life then it cannot do that. There are many other engineering reasons for this, but at this point the reason is now "because the standard says so". &amp;#x200B; If you take arbitrary bytes and cast them to a \`T\` via reinterpret cast of pointers and then access the data as a \`T\`, it is generally undefined behavior, except in specific cases described in the standard. &amp;#x200B; This is not a magic shortcut to zero-copy serialization, it's just broken code.
I like the initiative but it doesn't cover the most common layout, src/ class.h class.cpp include/ libfoo/ public_header.h 
It uses raw sockets (BSD Sockets ?). [IXSocket.cpp](https://github.com/machinezone/IXWebSocket/blob/master/ixwebsocket/IXSocket.cpp) is the class where most of this happens. ::select is used to know when data is ready (on the background thread). I need to start using it too to know when the send buffer is flushed.
I don't know Beast very well. I'd say that 2 notable differences are that IXWebSocket doesn't support Windows yet, and that IXWebSocket does not have a boost dependency so it is easy to import in a code base. You can look at the [CMake](https://github.com/machinezone/IXWebSocket/blob/master/CMakeLists.txt) to see for yourself. &amp;#x200B; Beast has been out for some time so it's probably more robust, but IXWebSocket is used by many users. 
At some point I almost had it working, my main problem is that I don't have access to a Windows Box (I could get one loaned at work). There is no SSL support though, but getting that working through OpenSSL shouldn't be too hard.
Quite honestly, if you're developing a new project, the CMake version should be the least of your concerns. CMake offers binary downloads for Win/Lin/Mac and the Linux binaries are linked so that they only require glibc 2.3 or newer and nothing else - in this sense, one should think of the latest CMake being available everywhere.
You can do that essentially by looking at the messageType argument &amp;#x200B; \`\`\` webSocket.setOnMessageCallback(\[\]... { // only handle messages if (messageType != ix::WebSocket\_MessageType\_Message) return; // decode json or do whatever is needed } \`\`\`
&gt; any pointers? [Sure!](https://xkcd.com/138/) "0x3A28213A", "0x6339392C" and "0x7363682E" Now on a serious note, I do know only the basics, making x86 assembly a read only language for me. ### Instruction - Arithmetic ones are obvious mostly - `ADD`, `SUB`, `IMUL` etc. - `MOV`s are all over the place and while the instruction itself [is turing complete](https://www.cl.cam.ac.uk/~sd601/papers/mov.pdf) and there's even [a compiler outputting *only* `MOV`s](https://github.com/xoreaxeaxeax/movfuscator), compiler will most often use just a few forms. So let's take a look at the compiler explorer link above: - `MOV EDI, 4` - In C that would be `int DI = 4;` - `MOV R12D, DWORD PTR [RSP+12]` - in C it would be `int R12D = *(RSP+12);` which is the same as `int R12D = RSP[3]`, assuming `sizeof(int) == 4`. - `MOV RDI, RAX` this is just `int RDI = RAX;` - Jumps are fairly obvious - `JMP`, `JNE`, `JE`are (unconditional) jump, jump if not equal and jump if equal. You can guess the others. - Note: ARM branching is much more powerful. - `LEA` is magical and used everywhere. `ADD RAX, 5` actually does `RAX += 5;`, but what if you need `X = Y + 5;`? That should be, if I'm not mistaken, `LEA X, [Y+5]`. - `pop` and `push` place onto and take off the stack ### Registers - Register A is the return value by convention, unless the return variable can't fit. - `RSP` and `RBP` define current position and begin of stack. - Prefix/suffix defines length of the register - Prefix R and no suffix means 64 bits - Prefix E and no suffix means 32 bits - Prefix R and suffix D means 32 bits - No prefix and or suffix means 16 bits - Prefix R and suffix W means 16 bits - No prefix and suffix H means "high byte of a 16 bit register" - No prefix and suffix L means "low byte of a 16 bit register" - Function parameters are passed as registers, in order, `EDI`, `ESI`, `EDX`, `ECX`... (god this is awful). You can always check this by looking at https://godbolt.org/z/udXjKl ### Syntax Compilers by default use AT&amp;T syntax that is similar to `typedef old_type new_type;` and compiler explorer defaults to Intel syntax which is similar to `using new_type = old_type;` but more importantly `int x = 3`, not `int 3 = x;`. Though both, compilers and the compiler explorer, have way of choosing one syntax or the other. ### Useful links - Creator of compiler explorer talking about compiler optimizations by taking a look at assembly. There's a crash (and burn?) x86 assembly course at the start - https://www.youtube.com/watch?v=w0sz5WbS5AM - Similar topic, same presenter - https://www.youtube.com/watch?v=bSkpMdDe4g4 - Some college's quick start guide. It refreshed my memory of suffixes and prefixes - https://wiki.cdot.senecacollege.ca/wiki/X86_64_Register_and_Instruction_Quick_Start ### Congratulation You are now a local assembly expert.
:o Thank you! this is amazing! made my day with your kindness :) 
My goal is to make C++ version of Python [cookiecutter](https://github.com/audreyr/cookiecutter). then people can create C++ project files layout very simply by a single line of command. I hope some contributors to participate.
Oh yeah, once you feel up for a challenge, look up Chandler Carruth's CppCon talks. His talks were mostly about achieving better performing code, analyzing assembly, running benchmarks and improving the benchmark scores... live in front of the audience, so the talks aren't a bunch of slides.
I've actually seen those ones, but yes, i'll rewatch again after getting some sense of how x86 instructions work.
&gt; The magic missing step is, in standard C++ the compiler gets to assume that a `T` can only come to life in one of a specific set of ways. The "specific set of ways" was what I was asking after. I missed it the first time but, for anyone following this thread it's (linked on in full detail)[http://eel.is/c++draft/dcl.init] from the definition of object lifetime u/jwakely posted above. Thanks!
You're getting a lot of critical feedback. This is good. Thank you for starting this initiative.
I personally think this site is pretty good. Series of tutorials for direct x 11 that use c++ A little out of date as we are now on DirectX 12 but 11 is a lot easier to learn starting out. http://www.rastertek.com/tutdx11.html
This is actually one of the goals (or at least one of my goals) for vector-of-bool's [pitchfork](https://github.com/vector-of-bool/pitchfork) tool. I don't want to discourage you from making your own, but we should definitely collaborate either through pitchfork or through your own project.
https://youtu.be/S4QSKLXdTtA 22:25 is the reference to social/asocial code
I‚Äôve found Udemy to be pretty useful for some tech courses. They have tons of courses on all sorts of topics - lots of them seem to be project based. And also good to note with Udemy if you check it out - they list that their sale of the courses for $10 - $15 is only going on for like ‚Äú3 hours‚Äù more or something, but that is not true; those are the prices they always offer. They just want to get people to feel a sense of urgency and buy more things at once. There are some mixed feelings out there about Udemy, but I‚Äôve liked what I‚Äôve gotten from there - especially if you already know how to write software. https://www.udemy.com/
Offer to help in a C++ open source project of your choice. That will get you practice and experience. 
Yeah I know that. I never be discouraged because of that as there are opinions say it‚Äôs too complicated for a C++ beginner to use. Anyway thanks for your detailed reply and I have a plan to contribute pf project. Of coarse, I entirely agree to that developers have to collaborate to make big useful things.
What? It actually covers exactly this... *src/* Main compilable source location. must be present for projects with compiled components that do not use submodules. In the presence of include/, also contains private headers. *include/* Directory for public headers. may be present. may be omitted for projects that do not distinguish between private/public headers. may be omitted for projects that use submodules.
Sure, and I am asking you to do it for me as a matter of convenience ;) But of course that only makes sense, if your library supports multiple callbacks- I haven checked if it does.
No last time I checked it said you'd have to to do src/ libfoo/ class.h class.cpp include/ libfoo/ public_header.h where the src/libfoo directory was mandatory. This is of course crazy and not common at all. Also it points to a bigger problem, in pitchfork you'd group multiple libraries all in the same `src` BROKEN: src/ libfoo/ class.h class.cpp libbar/ class.h class.cpp include/ libfoo/ public_header.h libbar/ public_header.h which is fundamentally broken because want each library to have the same structure as I posted originally. This for example how https://rix0r.nl/blog/2015/08/13/cmake-guide/ does it, which is the only sensible way. CORRECT: libfoo/ src/ class.h class.cpp include/ libfoo/ public_header.h libbar src/ class.h class.cpp include/ libbar/ public_header.h See the cmake link above
You already quoted it yourself! The lifetime of an object of type T begins when storage with the proper alignment and size for type T is obtained, **and its initialization (if any) is complete (including vacuous initialization) ([dcl.init]),** For some types that initialization requires a constructor, for others it requires different types of initialization, but it still requires initialization.
They are not idempotent. You can do far more interesting stuff with Ranges so is a bit naive to expect Ranges to be always as fast as STL algorithms. It would be like comparing vector + STL algorithms with this code: static void OldFashioned(benchmark::State&amp; state) { static const int MAX = 10000; int results[MAX]; for (auto _ : state) { int* pResult = results; for (int i = 0; i &lt; MAX; ++i) { if (isEven(i)) *pResult++ = times2(i); } } } BENCHMARK(OldFashioned);
I understand that the functionality provided by ranges is a superset of that provided by STL algorithms, but from what I‚Äôve seen of the interface there‚Äôs no inherent reason for ranges to be slower than the STL. In fact, because it seems like ranges exposes more information about the computation (STL relies on iterators, whereas ranges could, in theory, be based on expression templates), I‚Äôd expect ranges to end up being more performant in some cases, and equivalent in the rest. 
Curious, what was your reason for not supporting text messages only binary.
Nice, but shouldn't the order of the arguments be reversed? Thinking of `std::is_base_of_v&lt; B, D &gt;` I always think of these as the name of the template being in between the parameters. "B `is_base_of` D?" Hence I'd prefer this: `is_instance_of_v&lt; std::string, std::basic_string &gt;` which to me reads as "std::string `is_instance_of` std::basic\_string?"
Whether or not you want to go into the game industry, I'd say it's still hugely educative to build your own game. It's probably one of the more fun and creatively rewarding projects you could do.
Hey, I'm the author of [Belle](https://github.com/octobanana/belle). What issues did you encounter while compiling? Feel free to open an [issue](https://github.com/octobanana/belle/issues)!
For better UTF-8 Unicode string support, such as being able to iterate over code points or grapheme clusters, check out the [ICU](http://icu-project.org/apiref/icu4c/) library.
You could try writing an emulator in C++. I saw a post a few months ago about a guy that made a guide on how to do that. This is his website: http://www.emulator101.com/
I think it covers both cases. It just states that you can organize things like that, but what you have described is covered by it as well. Maybe it tries to cover too many things in order typ satisfy everyone so that the most commonly option is not prominent enough?
I'm afraid to confirm that for what's supposed to be a template, there are far too many things set inside *CMakeLists.txt* that really shouldn't be set there. The OP is making a *lot* of assumptions about the user's environment, which is also reflected in the extremely lengthy *Prerequisites* section in the README file. The use of Conan should be completely optional, as every *CMakeLists.txt* file should be package manager agnostic. This can be easily achieved via the Conan *cmake\_paths* generator, which generates a toolchain file. It's best to then not mention this inside *CMakeLists.txt* at all, or to make inclusion of this file optional (i.e. if it exists). My advice to the OP: buy [this book](https://crascit.com/professional-cmake/), and follow the guidelines given in it. (Yes, I know, I also wish CMake resources of this high quality were free, simply because CMake is in need of good, comprehensive tutorial documentation. But the book is *absolutely* worth its money, and otherwise there are many other great, free [resources](https://www.reddit.com/r/cpp/comments/aqi7bk/and_then_there_was_cmake/egii4gw/) out there. They're just a bit piecemeal, while in the above book, everything you need to know is tied together.)
I prefer `CMAKE_CXX_STANDARD` globally in the top-level CMakeLists for a simple reason: different C++ versions are not compatible and libraries compiled with one version can easily fail to link when the its headers are parsed with a different C++ version. Even worse, sometimes everything compiles and links but is subtle undefined behavior. The bigger things that come to mind: * `constexpr` member functions implying `const` in C++11 but not in newer versions (there are warnings for this though) * Libraries that have workarounds or optional features depending on the C++ version (e.g. defining their own `optional` when used pre-17 but use `std::optional` if C++17 is available) * `auto x{1};` behaves differently in C++11 and C++14 * `foo(a, b)` in C++17 guarantees `a` is evaluated before `b`. If this is used in inline function with different language versions this is a potential ODR violation. * return type of `emplace` changed in C++17 (a candidate for ODR problems) Thus, my libraries complain if `CMAKE_CXX_STANDARD` is not set and require an opt-out cmake option to suppress this error. The rationale of course is that most users are probably best served by having the same C++ version for all their files and different versions are treated as a special case.
I am very thankful to all people that commented. From my point of view this post was a great success. I will work on the feedback that everyone provided and keep upgrading the lib. Cheers everyone!
The combined apply+invoke would fall over if the function took a tuple as an argument. I know you're just trying to show how is_tuple could be useful but it's something worth pointing out in case anyone wanted to copy it in their codebase
&gt; I can't even know that unless you commented this. You can, if you read a good book about modern CMake, a couple of good blog posts about modern CMake, and/or watch one of the handful of fantastic talks from the last few months/year. :-) Just educate yourself using good &amp; up-to-date sources.
Thank you :) actually I meant ‚ÄúI didn‚Äôt‚Äù. Anyway you‚Äôre right.
Indeed... wget cmake...zip from cmake.org, unzip, and optionally add the cmake/bin directory to the PATH - DONE. On all platforms. The latest cmake version is **easily** available on **any** platform without **any** effort. (just don't use the old versions from the system package managers......)
What happens if you set `target_compile_features` to `cxx_std_14` and then someone during cmake-configure sets `-DCMAKE_CXX_STANDARD=17`? Will it add both flags to the compiler command-line or will the std17 flag override the std14 flag?
Sorry, but an article about "very well hidden" bugs, that involves using const_cast to mutate the key of a dictionary on the fourth line... ? The actual content is ok but saying this is a "worst bug" because it's hard to find is a bit silly. It's probably hard to find for a beginner but then so are all bugs? I would be fine with it if the title and intro paragraph were different (i.e. less hyperbolic). As far as the solution goes, the solution you discuss, and the omissions you make, are rather dangerous. Your original problem involved a loop over the whole container. For some reason in the solution you no longer have a loop. A beginner might take the solution you present and naively apply it back to the loop code, i.e. update all the salaries by iterating over all employees, extracting them, updating, and re-inserting. The problem with this solution, is that modifying a container while you are iterating over it is in general a very dangerous proposition. Looking at the verbiage, AFAICS for both map and unordered_map, extract invalidates the current iterator. So, if we look the original problem, with your solution applied: for (auto it = employees_sorted.begin(); it != employees_sorted.end() : ++it) { if (it-&gt;get_salary() &lt;= total_funds) { total_funds -= e.get_salary(); auto node = employees_sorted.extract(it); node.value().pay_salary(); employees_sorted.insert(std::move(node)); } } It's hard for me to understand all the verbiage, but AFAICS even for map which has very strong iterator guarantees, `it` will be invalidated by the extract, and does not get re-validated by any subsequent call. Which means you are going to increment an invalid iterator, which is probably UB. Even if it does work for map/unordered_map, it's definitely not going to work for alternate, faster, open address hash table implementations you might want to drop in at some point in the future. Ironically, the bug that you are subtly leading your readers into, is a lot more subtle than the original bug you claimed was hard to find!
&gt; Don't use 'CMAKE_CXX_STANDARD' for what you're doing. It only defines a default, but not what is actually required to build a target. Instead use target_compile_features and cxx_std_17. Ugh. Why does 'CMAKE_CXX_STANDARD'
You shouldn‚Äôt start testing only _after_ finding a bug, how are you going to find bugs if you‚Äôre not running your code? (Or would you prefer 100% of your bugs to cause a problem in production at some point?)
No last time I checked it forbid it. And it encourages a broken way to organise public headers by completely missunderstanding why have public headers in the first place
Dear quicknir, Fair point in the beginning. The thing is, this article was intended for a wider range, including those "beginners", one of which I was when faced it. Regarding the rest, the example with the map had nothing to do with the inital one. It was just a replica of what I had faced. The idea of this article was to remind the "beginner" to take time and consider the underlying data structures of the containers and their specificities. And if the reader did understand this all, I doubt he would go ahead and write such a code (maybe I think to highly of them). But maybe some might (as you, being so experienced, could think about it), so big thanks for highlighting this scenario. Eventually, good comments as such are not less important than the article itself. :) Note that in my solution I did take care of the iterator: `it = container.insert(std::move(node_handler)).position;` I just didn't want to go too deep into the details again and repeat myself, explain how the binary search tree works and why do iterators get invalidated. That whole iterator invalidation is an important topic too and worth a separate article.
The `cxx_std_*` flags are supposed to be used differently. If your header files require them, then use `target_compile_features(mylib PUBLIC cxx_std_17)` and CMake will ensure that this version is _needed_ whenever the library is used. This also works if you use `install(exports ‚Ä¶)` and write a config file. `CMAKE_CXX_STANDARD` (or rather the `CXX_STANDARD` property on targets) on the other hand sets the _desired_ standard. If it's not available, CMake will downgrade it. Now, if you build a library, and use it externally (for instance through a config file), your global `CMAKE_CXX_STANDARD` variable or the local property will not be considered. In this sense, using it, even when used together with `CMAKE_CXX_STANDARD_REQUIRED` is deceptive and breaks the config file logic. If you've got several standards that all your libraries can be built at (with only the requirement of it being consistent), a clean way might be to use `target_compile_features(mylib PUBLIC cxx_std_${CMAKE_CXX_STANDARD})` on all libraries. This will enable the standard being selectable, but requires it to be consistent.
If they are so experienced, you should hire them anyway? Knowledge can be acquired after all.
Can you explain what behaves differently for \`auto x{1};\` or how it can realistically bite us? I checked [http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1319r0.html#modified](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2018/p1319r0.html#modified) and saw something about [N3922](https://wg21.link/n3922) (DR). But I have a hard time coming up with a code that behave differently between C++14 or C++11 (tested with g++ and clang++ only).
I don't think that your "taking care of" is guaranteed to be valid. It avoids UB, however when you modify the element and re-insert it's not guaranteed to go back in the same place (that's the whole reason you only get const references to keys, in the first place, it's not an arbitrary restriction). That means that in the context of a loop, you aren't guaranteed to actually iterate over all the keys, or you may iterate over some keys twice! You can see how tricky it is to adapt extract to the original problem. I have to say I strongly disagree with your doubting the reader would write code like that. At any rate though, I think it's not great that a) you did not solve the exact problem you used to motivate the example, b) directly adapting the problem you did solve to the original question, is not correct. I'd highly recommend in your future articles, solve the exact problem you pose to the reader. After all, you control both the problem and solution, since you are writing the whole article, right? So you have both options available; make the problem more like the solution or vice versa. I'm not sure which one was better in this case, but you should have picked one IMHO.
You say you're in the game industry, and then you're looking for C++11/14/17? I'm pretty sure you're doing something wrong, or maybe performance is not what you're after. 
Sure, but we would need to invest into training and education, which costs additional time and money. Also sometimes I get the impression that the applicant isn't really interested in learning modern C++ practices. They believe their knowledge in C++ is good enough and they tend to have a strong dislike of some modern features (especially auto). So I don't know. It's a hard decision. For a junior positions I don't care too much about language skills as long as he displays intrinsic interest and good problem solving skills. For a senior position though...
Read again, never said I work in the game industry. Graphics is not necessarily about games. Also the claim that modern C++ can't be used for games is bullshit.
I can think of two possible answers: one is the prevailing attitude among far too many programmers that once you know how to do a function call, for loop, and if-statement in a language, you are a proficient programmer and are able to get the rest of the internet. And the other is that you are being too critical. If I hired someone I would prefer a decent software engineer (because I could teach that person about move semantics and smart pointers in the space of, uhh, five minutes) over a code jockey (because it would take years to instill decent engineering practices in such a person). I'd be absolutely delighted if we got someone with excellent C++98 skills; teaching him or her the rest will be easy. As for "strong requirements", employers regularly ask for the impossible (like ten years of C++17 experience), so applicants have already been trained to not take that stuff too seriously. I'd happily apply for a job that demanded that I have indepth knowledge of three obscure industrial standards I've never heard of, requires a decade of experience in a language that is two years old, and the ability to speak fluent Swahili. The odds that even a single person exists in the world with that combination of skills are astronomical, so why wouldn't I? 
In my experience most candidates are pretty weak on C++ specifics. I‚Äôd recommend getting more comfortable with on the job training.
I decided to write an LLDB data formatter to make debugging code involving rapidjson easier. At my job we use rapidjson quite a bit but debugging that code can be quite tedious. This should make it a lot easier. Hopefully someone else can benefit from it as well! :)
We will discuss that internally. Thanks for the recommendation.
A lot of people seem to have many years of experience but stopped learning after the first year or so. ‚Äú10 years of experience‚Äù can mean 10 years of skill growth or the same year repeated 10 times. 
You're basically re-stating the whole point of the article. Keep in mind, this is an article, and is not supposed to break down everything to the atomic level. One, who reads and understands it all, isn't too lazy to do a little more investigation, specifically, find out what is that `insert_return_type`, what are those `position`, `inserted` and `node` in it, would obviously understand that iterating that way (as you mentioned) is a total nonsense. Regarding the validity of my "taking care of": auto it = container.find("five"); if (it != container.end()) { auto node_handler = container.extract(it); node_handler.key() = "two"; auto ins_result = container.insert(std::move(node_handler)); it = ins_result.position; // We don't care how 'it' is going to be used further, // or whether it's going to be used at all, // we just make sure it's valid! } Regarding the first problem, which, again, has nothing to do with the second one, if you take a closer look, there is a solution provided, performance of which is asymptotically equal. These two problems, with their solutions, are about two different situations, covering the same specificity of the binary search trees.
I wish this was our problem, we have trouble finding anybody who knows any decent C++. Ask them why they dont have the knowledge. If they say "our company/project/... forced me to use the old version", hire them anyway if they look good and teach them. If they give you some polite version of "I dont give a fuck", pass them.
Thanks for the detailed answer. I generally agree on the sentiment that hiring a *good* engineer is far more important than hiring a C++ language lawyer. We made some bad experience though with hiring people from a C++98 background. Their code constantly requires refactoring, because it looks more like C-with-classes than actual C++. And I feel like this is hurting the overall quality and consistency of our code. But I guess it makes good sense to invest in training, if the applicant is otherwise experienced and talented. We will discuss this.
&gt; If they give you some polite version of "I dont give a fuck", pass them. Exactly. I think it's about how pro-active they are. If they display Interest in improving their skills I'm certainly willing to invest in training. However, as mentioned above, some applicants are not really interested in learning modern C++.
If it really was just "C with classes" then maybe they weren't such proficient C++ programmers. Even 98 had a lot of the OO and metaprogramming pieces in place. We used Boost for years to get pre-11 things like bind and smart pointers. From there, transitioning to newer C++ was pretty easy. I helped run a lunchtime book club. We read a chapter or 3 each week from "Effective Modern C++" , discussed implications, brought up demos in Compiler Explorer, and in a couple of months people were using it. 
I feel like the code quality issue could be mitigated with a good code review culture. Pull requests, for instance, would not only increase visibility on what a developer is attempting to do incorrectly, but also give those with better experience and domain knowledge a chance to coach that developer into doing the right things. Also, with strong community participation, the people most qualified to identify a bad developer would be able to say very quickly whether the new dev is actually getting up to speed quickly enough. (I of course write that with the possibly incorrect assumption that you're not already employing such a strategy.)
I'm guessing that anyone who knows enough about the horrors of "modern C++" also probably wants to stay away from it.
If you don't like modern C++ don't apply for a job that uses modern C++. It's *that* simple.
My experience as an interviewer is that a lot of experienced applicants just did not get around to put any of the new standards into practice for a variety of reasons but are reasonably skilled otherwise. But most of them can be brought up to speed quite quickly by mentoring them and giving them the time to learn. One big reason is being stuck on old build infrastructure that makes switching to compilerd that support C++11/14/17 hard. The other is "political" pressure inside companies preventing them to modernize existing applications because "never touch a running system". The intersting phenomenom here is that many of the very good and experienced C++ coders are responsible for the older, more complex projects becauese they ard able to handle them, while the less experienced coders often are working on the new and modern codebases. 
To play devils advocate: Who wants to work for a company that isn't prepared to invest in a candidate? I hear what you are saying but having worked in the video games industry for 25 years I can tell you you're missing out on a huge pool of hard working, highly experienced programmers that may be behind on C++ features but will eat the rest of the industry alive when it comes to debugging, optimization and working within strict real time limits. Video games programmers are often conservative my nature but are highly skilled.
we stuck with same problem, with, with offers far above market for C++ jobs (Not US here). After year of hiring we were able to hire only 3 developers for ~7 openings, however, all 3 developers were pretty good, so, we still consider it a big success. I'd recommend not to lower bar and continue searching.
Or, you know, apply as a c++ programmer, knowing that most companies stay away from the modern features, and then if you do run into an Uber-neckbeard who insists on template metaprogramming, just back away slowly and find a better job. Life‚Äôs to short to remember things like The Most Vexing Parse, and play the game of ‚Äúwhat does the const do when it‚Äôs here?‚Äù The language is fundamentally broken, and most rational programmers know this, and only bother with the parts of C++ that matter.
We find it hard to find good C++ people full stop. We give them some test questions, and the first question about references weeds out 90% of them.
Out of all the jobs I've been in, I am the one who knows the most about C++. But I got all that knowledge from trial and error and Googling compiler error messages, and not through any paid education. &amp;#x200B; So my question to employers is why are you always looking for fully-formed "Tech X" programmers, instead of widening your search for people who can/will learn the things required for the job? Why are you always relying on other employers to have people develop under them just so you can poach their employees once they develop the skill? A developer is going to have to develop the skill somewhere.
You can write high performance c++17 for years and not require smart pointers or std::move. Your design choices are not everyone else‚Äôs design choices and whatever problem you work on, is not everyone else‚Äôs problem they work on. The complaint about knowing these functions in specific, combined with you saying that there were problems with previous hires, would make me not want to work for you. Perhaps you should evaluate your own organization, rather than blame others.
I mean the statement that older code bases are developed by more experienced developers is not really an phenomenon, but really just common sense. They're older, working for longer period in the industry, so - naturally - they're more experienced. I don't think this translates to modern C++ programmer being less experienced though. There's quite a few developer that switched to C++11 coming from C++98. It is true, however, that development or management constraints are preventing many people from making that transition. 
My experience is that in the real world you just can not write pure C++11. That is; Your program has library deps: one is written in pure C, another in C++98, another one is half-modernised to C++11, then you need some low level os api for some corner case.... Some of these use their own String, Vector, Smart pointer, whatever class because they are not available in year x/standard x. In such an environment, using modern C++ features can add just one more complication. Which is really sad.
BTW: we had long discussion if you are *obliged* to learn modern c++ on your own time if you cannot use it in work. Decided that no, but that candidate should have at least some casual theoretical knowledge of the new standard (i.e. "i know there is memory safety and move semantics, but i didnt use it yet")
Even easier than that: `pip install --user cmake`
Then the answer to the question "Why is it still so hard to find applicants with decent knowledge of modern C++?" is also fairly simple.
And the horrors are?
&gt; They believe their knowledge in C++ is good enough and **they tend to have a strong dislike of some modern features** (especially auto) But this is a sign they have at least looked into the features. This sounds like an opportunity to have an interesting discussion. Either they just looked at it quickly and dismissed it without even fully understanding it. Those are probably people you don't want to hire. But if they have thought about it, and give you solid explanations to why they don't like it, that seems like someone you do want to hire, or at least continue talking with. Some things are just preferences. As for *auto*; when auto was new there was a tendency in some people to over-do auto, and use it absolutely everywhere, completely ignoring if it made sense or not. So being anti auto could both mean "never use auto" or "use auto very seldom, but do it when appropriate", and those I think show completely different mind sets.
Auto is without doubt the feature that is most frequently criticized. But that's also the case for type deduction features in other languages like C# or Java. `auto` is not really that important though. It will help with some edge cases, but it's not a tragedy if you don't use it. I think it's far more important to have a good notion of ownership and what it means to transfer ownership (I.e. move semantics) etc.
They're still stuck on 3.13.3 from Jan 14, 2019 though, so not an option if you want Beta/RCs, if you want to test new releases, or if you want them straight away when they come out.
Since we're not developing a product that has high-performance requirements I couldn't care less about people that claim to have worked with C++17 and in reality just cherry-picked some abstraction features to spice up their embedded code or whatever. IMO using smart pointers is not a design choice, it's an intrinsic part of the modern C++ philosophy, which our company just chooses to trust in.
Where is your company?
Fair enough! Still, a really quick way to get a newer version than your system version
Same problem here. I believe it‚Äôs because knowing anything more than what they need day to day to follow the company coding standard isn‚Äôt practically valuable. And Management doesn‚Äôt like change, because it feels like risk. Proactively filling in holes in knowledge is a good test of whether an engineer has the grit (or not) to be a senior engineer some day. But there are lots of coders out there who just want to plumb UI all day. One tact is to take the most promising interviewees in other areas (say, they did well on the programming test) and tell them the next interview will be on modern C++ concepts, in a week. If they rise to the occasion and can fluidly talk about move semantics, for example, maybe they‚Äôre worth investing in.
I am not giving away any details about my company. It's located in Europe. That I can say.
This sounds more like you don‚Äôt like their attitude vs not hiring them for their C++ knowledge. Which is still fine, but just pointing it out. 
I teach people at work about move semantics on a weekly basis. 4 years ago when I took this job, I hadn't used C++ since 1996. The knowledge is totally acquirable. I literally learned all I know about C++ from using it on the job and looking things up as I came across them; from /r/cpp and a few internet searches. Knowledge can be acquired. It's much harder to find people who can think and can learn.
Never found that to be a problem to be honest. Sure, a lot of graphics APIs are plain C, but you can write abstractions. For the rest we haven't really struggled to find a well-maintained modern library. (Like logging for instance).
isn't c with classes cleaner? my introduction to c++ was inheritance hell ala java. We switched back to exposing data members whenever possible, checking object state for usability and of course heavily use collections and &lt;algorithm&gt;. I recently mostly retrofit the last code base i worked on with string_view but its been painful as the windows compiler is limited to vs2013 as i have to swap out malloc to get any decent threading performance. a shame so many formatting libs, etc require null terminated strings...
I agree. The hard part is to search and identify the applicants that would thrive under a training or schooling environment. 
No, Your university's approach to teach C++ just sucks. (IMO)
I don't think I'd want to work for a company that doesn't understand that there is more to life than C++, and more to life than work.
Maybe the lack of good C++ engineers, willing to learn *modern* C++, is what will be killing the language in the long term. We are also searching desperately for software developers with C++ knowledge. We are ready to invest time and money in any applicant but the market is completely empty. Especially for a smaller company like ours which is not able to pay the highest salaries. I am asking myself what the longterm strategy is for us. Maybe we will just move to a different language (we are talking about 1.5 million lines of code) where the chances to get an able software developer is better. 
You wouldn't want to work for a company that tests their applicants for their knowledge and skills? Um, okay then.
as you should. auto makes code unreadable months after the fact, unless its something like auto * const val = (cast*)pointer; type stuff. auto inside lambdas would be nice....just keep the lambdas under 3 LOC!
It's not about breaking things down to the atomic level at all. Like, I said, you are the one who brought in the initial problem (in significant detail), as someone who's teaching it's then your responsibility to make sure the solution to the initial problem is clear. You keep saying the problems are unrelated over and over; that's just bad pedagogy on your part. If the original problem isn't related, you shouldn't have mentioned it at all! Why not start the article with the problem you end up solving? Here's a good article: http://ericniebler.com/2013/10/13/out-parameters-vs-move-semantics/. You'll see at the beginning, Eric discusses the usage API of getline. At the end, he takes his suggested API and explicitly compares it the original, even re-listing the code. Anyhow, to be frank I don't really care whether you improve at writing at writing teaching articles. So whether you choose to continue arguing, or learn something from the feedback, is up to you... Either way I'll be stepping off, cheers.
Do you mind if I ask where your company is operating? Never felt that the market is *empty*, but it's certainly becoming harder to find good people.
You can dislike something without knowing a lot about it. I'd even claim that in software engineering this (dislike site to ignorance) is the prevalent form of dislike that people express. People who spent time getting to know a feature/language/technology tends to lean to accept or even appreciate it. And even if they still dislike it they tend to be a lot more nuanced and less vehement about it. There are exceptions (PHP prior to version 6 is a strong contender) but it otherwise seems to be universal.
Let's not pretend that Modern C++ isn't at all contentious though. Nico Josuttis has interesting things to say about C++ experts not even agreeing on how to teach new features on Cpp.chat (https://www.youtube.com/watch?v=_CaP_xwfAFU). Personally I would rather stay up to date than not, but these are increasingly treacherous waters in my opinion. I don't envy you having to do recruitment. Not so long ago I worked with a developer who spent all day of Facebook, because the company culture sucks, so why bother right? A couple of weeks ago a new hire wanted to write their own replace_all untill I pointed out that we use boost for that (hey, at least he asked before re-inventing the wheel). It's all a nightmare and there are no easy answers. I'm assuming a decent C++ replacement will come along eventually, but in the meantime I will stay up to date as much as possible as new editions of C++ come online.
I also find that it's true that modern C++ jobs are rare compared to those requiring C++98/03. It really sucks for new developers who started in C++11/14/17 to get dragged back 20 years. At the same time these companies bemoan "Why can't I find developers?". Gee, maybe it's because middle aged established developers aren't interested in moving from one old code base to another old code base? The answer to increasing their talent pool is moving to at least C++11. &amp;#x200B; That you're getting candidates \*at all\* means there's at least some initiative there to learn new technology. &amp;#x200B; I score candidates on two traits: temperament and skills, ranked in that order. Skills can be learned, but if your attitude sucks, you're resistant to change, and you're hard to work with etc. Those come from personality and basically who you are; no amount of carrot/stick management is going to appreciably change that bias IMHO. &amp;#x200B; You're going to have to train them. That cost is insignificant compared to the opportunity cost of not putting your capital to work building value for your company.
What you describe from your University comes pretty close to what's now known as "C with classes". Historically this might not be entirely accurate but given the time line of C++ development, it's pretty close. Especially considering that it predates the STL and thus the use of templates and algorithms based development. So, to answer your question: no, C with classes absolutely isn't cleaner. In fact, it's over-emphasising inheritance and other concepts you'd find in Java more than in modern C++.
Yeah I found it hard to reproduce as well. Apparently most compiler "fixed" it for C++11 as well. You can see the difference between GCC 4.8.1 and 4.9.1: [https://godbolt.org/z/e79Mh4](https://godbolt.org/z/e79Mh4)
&gt; auto inside lambdas ... Uh [the subject went modern c++]? 
Good tip with the config file. We currently always build everything so `install` is not a use case yet. We also usually set `CMAKE_CXX_STANDARD_REQUIRED`. I'll try your last suggestion but as others said it requires a higher cmake version. We are kinda stuck with a stable-ish Debian system so we might not have that version yet. Selectable but consistent with certain minimum requirements is exactly what I want.
When an interviewer asked me to write a linked list, I wrote down "std::list&lt;int&gt; x;". They offered me a job. I turned it down. I now happily work for a company that respected my past work. At some point these questions are just insulting.
I like drinking beer, where do I sign?
Wow, now I *really* don't want to work for your company. Good luck with your search. You're going to need it.
The problem isn't the applicants. It's your attitude.
Indeed. Why actually interview the human being when you can simply demand a bunch of arbitrary requirements?
To clarify: we *are* willing to spend money on training, but it's hard to identify the applicants that are worth the money and effort of training. As I pointed out in other comments it really boils down to how pro-active they present themselves. Some applicants have absolutely no interest in learning modern C++ whatsoever. I don't know, they read somewhere that everything from STL is evil, bloated and complex and hand-rolling their own containers full of nasty bugs and memory leaks is the way to go. We had these people, wasted time and money on them and I am just trying to avoid that scenario. Unpopular opinion: game devs are experienced and usually quite talented, but also tend to be quite opinionated. It can be frustrating to work with these guys as they tend to have a strong opinion on pretty much anything related to C++. 
Please elaborate. Assuming language and domain skills is a wrong attitude?
From what I've read on the documentation: * it has an internal *PATH like* behavior, allowing you to open "file.txt" without specifying the relative or absolute path. * it separates the logic between reading and writing by setting a *read path* and a *write path* * it **always** open files in binary mode. On Windows it might be a problem for text as you need to encode/decode /r/n to /n and vice versa * it has some archive support To be honest, I prefer std::filesystem because it's just a wrapper instead of a library with more functionalities. 
In my experience it's hard to find applicants that know C++ at all. So much screening time spent on people with years of experience that cannot answer even the simplest questions, even pre C++11 stuff. It's quite depressing actually.
In a way you're touching the crux here I think. The 'where' question. I think there are plenty of good people/programmers willing to put in lots of hours. But, but, they are not necessarily willing to move to your neck of the woods [like London f.e., renting a card-board box will put you [financially] into misery], or cannot, because of restrictive (at the border of xenophobic) immigration laws (yes looking at you, the realDonald[Duck] - appreciated you're not in the USofA, though). 
We are offering a [MES](https://en.wikipedia.org/wiki/Manufacturing_execution_system) mostly for automotive customers and we are working on Intralogistics with our own Material Flow Controller and a [Warehouse Management System](https://en.wikipedia.org/wiki/Warehouse_management_system) We are competing here with big players like Mercedes Benz, Porsche, Bosch, Siemens and hundreds of other small and medium-sized enterprises to get decent software developers. The region here is highly industrialized. You don't have to be a genius to work on our software but it requires good knowledge of databases. Being able to work on big code bases. Write efficient and fast code. Sometimes we have to implement the interface to some production machines or [SRMs](https://en.wikipedia.org/wiki/Automated_storage_and_retrieval_system) ourselves close to the hardware or you have to come up with an intelligent allocation strategy for an optimal material flow. So this is a broad field. Every customer has its own way of working and all of this must be implemented in our software. So good communications skills are also needed to understand what is going on in the warehouse or factory. 
I started looking into Stephen Kelly's original implementation not long ago, as I was curious as to how he had managed to implement a proof of concept for a cmake debugger. Was surprised at the amount of (potentially very useful) information the file API can spit out. Still unsure as to whether it can allow cmake debugging in its current form, but hopefully it can be updated to do so down the line. I'd be happy to contribute to the VSCode plugin if you have some pointers as to where to start! :)
You: Here are the links to my open source projects so you can evaluate my C++ usage. Interviewer: I'm don't give a damn about that, but here, try to 100% this arbitrary test I pulled off the internet just before lunch.
&gt; I also find that it's true that modern C++ jobs are rare compared to those requiring C++98/03. It really sucks for new developers who started in C++11/14/17 to get dragged back 20 years. Well this is a strange mentality to me. I don't feel like the intent of "modern" C++ is to supersede what was before, but to add new tools on top for **when** they're useful (and not just be cause "oooh, new toys!"). Ergo, if you haven't mastered and aren't proficient with previous standards ( except for deprecated features ), then you can't claim to know C++11/etc.
Out of interest as a top 99.6% C++ programmer, what's the question about references? I'd like to see if I could briefly make it into the top 10%.
I have experience on the other end of your transaction. I'm trying to really answer your question the best that I can. I'd like to think I'm the person you're looking for. If you had to boil it down to one word, it's politics. If a handful of words: "Game theory machavellianism, hidden attacks from within mixed with plausible deniability." The Unknown unknown holding you back, behind your perceived problem is as that you are either a non programmer who's got a bunch of pointer-trivia and gotcha-type brain teasers in your head, in the context of a very narrow niche language and you're asking programmers these trivia and brain teasers, and conflating all that with "expertise in creating positive outcomes that directly relate to increasing revenues and decreasing expenses at company operations". Or more likely, given available information and assuming you're a mediocre programmer who knows just enough to not be fired but also knows how to keep your head low, and enjoying a little bit of drunkeness on the power you perceive yoruself having, you have incorrectly conflated your narrow band of Alex Trebekian brain puzzles as genuine C++ proficiency. The people like me, the one you're after, can see and smell this a mile away, and thus we respectfully give you what you're after, aloofness and we flunk your shit tests. Gladly. I could probably drill down deeper and show you how you are the problem here, not the market, but that would be more pearls before swine. If you're honest with yourself, you really do prefer the shit and the shit-tests. 
I work at a company where most projects are stuck on C++98, with a huge number of employees just aching to use Modern C++ features. I have been able to use C++14 on one part of one project, but that is it. Usually we are stuck with old compilers to provide compatibility with some old platform we aren‚Äôt willing to kill off yet.
You're turning down experienced developers because they don't have the exact arbitrary knowledge you decided upon. IME experience is much more important than some specific knowledge about a programming language. I want to hire smart people. I don't care if they worked in Python, Java or Emacs Lisp previously. Hell, IBM Watson hires psychologists, physicists and English majors because they know how to train people. I don't work at Watson but I respect them tremendously because they actually invest in their employees.
I agree with /u/gravitt. If you consider smart pointers _intrinsic_ to your design - then your design is probably a hopeless mess. Shared ownership of data should be the exception, not the rule.
I would generally agree on engineering skills being more important than language skills. Having knowledge about concepts that lay the foundation of our code base is anything but arbitrary though. C++ just happens to be language with a lot of technical depth. The question is how much time and effort you wanna put into mentoring the applicant, when - in theory - you can pick someone who is already experienced with language concepts.
Not willing to invest (training/education) in a employee is one of the biggest BS traits of the development world. I've had about 4 different careers in my life in 4 different industries. All with their own particular difficulties. I've held roles responsible for hiring and managing. Some of the best employees I've had were the ones I recognized potential in who had basic skills but just needed a bit more focused training. 
Sorry; I don't recall the detail, and it's probably a secret.
lol, Using smart pointer does not necessary imply having shared ownership. In most cases using a unique_ptr is sufficient. 
I clarified my position on training below. 
Thank you! I will take a look at that. Many useful and helpful feedbacks here :) Thank you all again.
Not really, since it was an introduction to C++ that's exactly how it should be taught. Universities are not interested in teaching best practices or industry standards, it's about understanding general computer science concepts. An introduction to C++ will prepare a student for writing a custom implementation of basic data structures like vector or linked list. Using raw pointers and manually managing memory, writing custom iterators and so on. That's not how modern C++ is written, but it teaches general concepts like pointers, memory, copy, move, swap, iterators and so on. An advanced C++ course would include things like smart pointers, copy+swap idiom, meta programming, allocators and multiple inheritance.
&gt;My advice to the OP: buy [this book](https://crascit.com/professional-cmake/), and follow the guidelines given in it. I've just bought the book!
Hello there! It looks like you are re inserting a node while iterating through the container, which due to there being multiple equal-by-order values (because you used multiset) might be inserted at a later point in the sequence, making you check that element twice (!!!)
You're correct to say a lot of games developers are very opinionated and some of that comes from arrogance and some from experience. When your level runs with 1K of RAM left on a PS1 and you've got an artist who wants to make a texture bigger you really need to be a strong character and even after generations of consoles that attitude tends to stick and genuinely offer benefits to the product. For some it's a hard habit to break. However, this doesn't help you. The STL bloat comes from two factors, compile times and some implementations habit of allocating internal buffers before use, causing heap fragmentation leading to poor performance. You can tease these things out of the good programmers by asking why they think these things matter to YOUR application and code base. Ask about STLPort and EASTL and see what they say. They will be defensive so try and relax them in to criticising their own position first. Any programmer that can't be self critical and flexible isn't worth it not matter how good they are. Also if you think game developers have hand rolled containers full of memory leaks and bugs then you completely miss understand them. They have probably rolled containers that far outperform the STL in the very niche cases they were used and in the dimension that they care about. The problem is that they then discard all of the STL based on this one small case. Good luck with your hiring anyway, it's always a nightmare for both sides :)
When people talk about smart pointers I assume shared_ptr. If you're really hung up on unique_ptr - does anyone really care? If the ownership is clear then who and when to delete something is trivial anyways. But sure, use unique_ptr. I didn't say it wasn't possible to write reasonably efficient code with smart pointers. Relying heavily on shared_ptr is just a mess.
&gt;You can dislike something without knowing a lot about it. That's why you need to keep talking to them. Some people dislike because they don't understand it properly. Others because they really do understand it properly, and have seen some not so obvious pitfalls. Many features have both pros and cons, and not everyone values them equally.
Am I wrong or can't you (in cases of ambiguity) resort to naming the namespace to resolve that ambiguity? (I.e. ::unordered_map or STD::unordered_map)
Lol, this read like a bad article from doctor Freud after one of his cocaine binges. I don't think OP's said enough for you to have that strong of a negative opinion of him. 
I don't understand why you got so much push back on this question. Anyway, I'm a student and my school just teaches c with classes. I'm always on the lookout for way to expand into modern c++. If anyone has any suggestions I'd love to hear then. 
But the very existence of your post indicates you *can't* just hire someone who meets your expectations. Ergo, your expectations must change.
I did interviews for a year for a c++ position doing turbomachinery meshing. Most candidates who states they were 'experts' in c++ balked at the simple algorithm tests that could be written in a one-line + lambda in STL speak. It was so tough to find someone competent. Eventually we found two guys who were not experts in modern c++, but took the effort to learn enough to do our coding test. &amp;#x200B; Knowledge can be acquired. Intelligence, not so much. Look for the smart guys who are willing to study something new.
&gt; your expectations must change. Well, that's what I'm trying to find out with this post. It's either a change in expectations (which will probably go hand in hand with training programs) or expanding advertisement, because I honestly can't believe there are no decent C++ engineers with good grasp of modern concepts on this world.
I never claimed that using smart pointers is intrinsic to our design. It's intrinsic part of the modern C++ philosophy, which translates to "don't use raw heap allocations". This absolutely doesn't mean that where don't heap allocations everywhere, nobody every claimed that. But *if* we do, we do it in the form of a smart pointer.
But yet every time someone tells you your approach isn't the most helpful, you argue about why they are wrong. You seem to want validation of your approach. You just aren't going to get that. If you want to keep doing what you're doing, that's fine. We're not being paid to give you hiring advice.
How about paying more?
People have suggested training programs, which I completely agree being a good solution. What's your point? Judging by the traction this post got I think it's safe to say that other people also struggle with finding applicants that meet their requirements. 
How hard is it to find a C++ developer who knows multiple languages? Not rhetorical. I think that someone who knows multiple languages will naturally be open to learning the newer features of C++. Java emphasizes OOP. Golang will make you comfortable with \`auto\`. Javascript will get you familiar with lambdas. I'm not saying that an employer should shove a bunch of languages down an employee's throat for the small ROI it would provide, but if looking for candidates, it's a good sign if they've learned another language before because it means that they can understand different paradigms of programming.
Easy, because your salaries suck.
I guess I don't understand why you're so concerned with it then. If someone uses a raw pointer somewhere then in the code review you say something like "coding standard says use unique\_ptr". Maybe I've been lucky with who I've worked with but I can't imagine that being a problem for anyone at any level. If you're bringing it up in interviews then I can only guess candidates are getting the same bad feeling I am. &gt; Oh god, why is he talking about smart pointers? Why is that important? Is this going to be one of those projects where people pass shared\_ptr around as method arguments and cache them wherever they please and then I have to spend hours tracking down cycles and other bugs because it's impossible to cleanly shut anything down? I swear to god, if he asks me if shared\_ptr is thread safe, I'm walking out of here.
I love modern C++ but the other C++ devs I know are *highly* resistant to c++11 and beyond and I cannot for the life of me understand why not. Not only do they not want to learn it, they're *angry* at its existence. It's completely bonkers. And then there's me, unable to find C++ work since my resume is filled with boring C# and Java enterprise work because that's all anyone is really hiring for these days so that's all that's on my resume. Agh. I need to finish this 16-bit VM demo project and get it on github or something as a demonstration of C++ ability. I'd love a job that isn't "take this dependency-injected java object here and translate it to this other dependency-injected object over there..."
&gt; Well this is a strange mentality to me. I don't feel like the intent of "modern" C++ is to supersede what was before, but to add new tools on top for when they're useful (and not just be cause "oooh, new toys!"). Just moving the compiler to C++17 and doing nothing else will improve the product thanks to guaranteed copy elision. * I don't think std::thread, a unified memory model, and a cleaner allocator interface are toys * futures and async * packed template parameters * perfect forwarding * variadic templates * lambdas! Just these concepts dramatically reduce the labor involved in writing great code, increase overall quality, and most importantly, it increases momentum. If the language sucks less, you're write more libraries because your labor burden goes down. That's what we're seeing today in the greater ecosystem, an increase in library frequency and quality. &gt; Ergo, if you haven't mastered and aren't proficient with previous standards ( except for deprecated features ), then you can't claim to know C++11/etc. I'm sorry, but if that's the standard we're going to hold new devs to then this language is a dead and it just doesn't know it yet. Faced with that learning curve no wonder people are using golang and rust or just stick with C.
You're absolutely correct, applying that extract/insert approach while iterating is incorrect. It was applied for the other example, with a map and without a loop. Obviously, it wasn't clear from the article and led to misunderstanding. Thanks for noticing!
The most likely reason is that they never needed to learn it. People in senior positions (or people who have been working full-time as programmers for a while) are probably more interested in spending their free time with families, or on non-computer hobbies. If their current work does not use C++11 then they have no opportunity to apply it in practice and so the motivation to learn C++11 on their own is relatively low.
Ah my bad, I must've misread
I've found modem c++ to be useful, but not very often. Unique pointers save a little debugging headache down the line. Auto, range based for loops, and lambdas save a few keystrokes. On the other hand many modem features have a code smell. Using shared pointers probably means your code is a mess, std::function has terrible performance, and using heavy move semantics probably means you underutilize (N)RVO. It seems like you want a team of people writing in a very specific way that doesn't come natural to other people in the industry. I think people use c++ because they want the performance. The style of code you're after doesn't seem in line with that goal. Another language seems like a better fit.
Yep. My latest project requires a syntax tree, so I opted for a vector of unique_ptrs (thank you move semantics) and (non-owning) raw pointers in the tree nodes. I would like to see observer_ptr be a thing personally (I have my own typedef/using for that currently). These are the kind of Modern C++ features that genuinely help.
It runs on Windows 95 and compiles with GGC-2, so all good.
They have very different use cases. One is the standard library's abstraction for working with directories and files in the file system. The other is intended for providing specialized access to files in different kinds of archives/isos/etc., like a game often requires.
Candidates from the game industry, working on graphics. I'm gana guess your demographic for people applying is the early to mid 30's and older, especially for C++. It would help a bit more if you posted more questions you would like answered, but from my perspective I'd apply to a job like this w/o extensive experience using C++14/17. The thing is, these people have families. They probably don't spend a lot of time outside of work coding or keeping up the latest trends because it's essentially a waste of time if you aren't doing it for fun or your own personal enjoyment. The places they work have large and established code bases that can't easily be converted to build or make use of the latest language features. The flip side however, is that if these guys are established, they're very likely bright and should be able to pick up the new standards and idioms you guys employ very quickly. If anyone is going to learn the latest C++ faster, it's going to be people already incredibly comfortable with C++98/11. What are you guys asking these dudes and crossing them off your list for getting wrong? Why do you think it's not worth bringing someone in who's willing to learn the new techniques in a few weeks and use your established practices? To me, it seems really weird that knowledge of C++'s latest features is a higher priority than knowledge and understanding of graphics engines and pipelines, which is a much more specialized knowledge. Who cares if they don't know about &lt;algorithm&gt; just tell them about it, tell them it's part of the coding standard to use it and they can pick it up quickly. Imho, your biggest fear should be hiring guys who have an ego and will push back against using the features you guys want for their own reasons. They might have good reasons but if they are that experienced, hopefully they have the wisdom to integrate comfortably. That's what I'd be looking for. 
Can‚Äôt agree more. I absolutely love programming, like most of you here. But I‚Äôve been taught the old C++ for the past 2 years in school.. I‚Äôve tried learning the new/modern C++, but they always seem complicated to me. I‚Äôve tried contributing to open source code, but half the time I don‚Äôt understand because it‚Äôs all using smart pointers and what not, and I just don‚Äôt even understand the reasoning for the purpose of using it. When asked, the reasoning they provided made me even more confused! I‚Äôve suggested to the school that the should teach modern C++, but all they said to me was ‚ÄúWhy not you come and teach?‚Äù My internship was terrible, not a single full time software developer. Was just hired for cheap labour for their quick prototyping.. I sure as hell learnt alot. But by no means was that industry standard.. I couldn‚Äôt even ask anyone for code review. I struggled really badly All I want is to look for another internship which is able to teach me more about the industry standard of programming, I‚Äôm more than willing to learn. But so far it‚Äôs not easy when the requirements are near impossible to fully grasp. Sorry for the rant! 
&gt; Using shared pointers probably means your code is a mess Depends on the scenario, there are cases where having shared ownership makes perfect sense. &gt; std::function has terrible performance It's a general-purpose container for all kinds of callable objects, but most importantly it's an owning container. The (main) reason why people claim it's so slow, is because it potentially needs to perform dYnamic allocations when the function state is larger than the SFO buffer. In most cases you don't need owning semantics for a function though, the upcoming function_ref will help in these cases. &gt; and using heavy move semantics probably means you underutilize (N)RVO. That statement doesn't really make sense to me. RVO only applies in specific scenarios, you can't utilize RVO to move a local unique_ptr to the arguments of a function. ___ Using modern C++ and getting reasonable performance are not at all mutually exclusive. &gt; It seems like you want a team of people writing in a very specific way that doesn't come natural to other people in the industry What industry are you talking about? Not everything pivots around game development. 
One of my favorite quotes was: "10 years of experience or 1 year of experience, 10 times." You run into lots of people who fall into the later category :/
C++ is traditionally conservative language. Early adopters of so called "modern C++" are doing great job of exploring all those bad practices later adopters are going to know and avoid. You know, all that overuse of auto, misuse of constexpr and std::array and that's just couple of examples from C++11, i didn't even go into C++17 yet. But it's a good job nonetheless, all that exploration is going to be used for a (not necessarily) good cause (e.g. more work for me). Think some people tend to learn from their own mistakes while other people learn from other's mistakes. &amp;#x200B; Regarding game industry: when you have to deal with a variety of platform and toolchains, you are effectively locked to the common denominator across all target platforms. It doesn't matter if C++ committee is publishing new revision every 3 years, if one of the target platforms is C++11 only, then C++14 and C++17 are out. Just like that. It will take reasonable amount of years for compilers supporting newer C++ revision to land to the target platform, and most likely, it will be another platform already. Think Playstation 5 *gradually* replacing Playstation 4, but Sony won't give up on Playstation 4 consumers because some dudes published new revision of C++. Cross-platform development is a bit different from developing for single platform and single compiler, sometimes you don't have complete control on tools and runtime you have to use to do work. &amp;#x200B; Hope this helps.
Contribute to a public project. That's a really good way to hone skills, develop collaboration techniques and learn. As for the pushback, my guess is it's mostly from experienced developers in the field who understand mastery is not the same thing as knowing the latest and greatest tends. Masters can learn whatever they need to, they know it and they know their worth in the marketplace. Masters can pick and choose their jobs and understand (unlike too many interviewers) that the applicant is also interviewing the people he is she may be working with.
You could train your employees . . The shaping of their work habits and loyalty derived would be worth it . .. { train workers profit }
I'm genuinely curious what sort of training you're thinking about. Do you have resources that show why your approach is the better one, rather than just how the semantics for your desired features work? I'd read them. Also, which features do you think are most important? I'm struggling to convince myself that move and auto need to be used often, for example.
I said "when". std::thread is my most used feature out of "modern" C++, as well as some other things here and there. My point is, people tend to jump onto new stuff just because it's new, it's a fad. It was the same issue with the "inheritance everywhere" fad, even (and somehow, especially) when it wasn't needed. As for switching compiler, you're not always free to decide that. &gt; I'm sorry, but if that's the standard we're going to hold new devs to then this language is a dead and it just doesn't know it yet. Faced with that learning curve no wonder people are using golang and rust or just stick with C. Well, isn't that exactly what you're advocating then? If the old standards need to be forgotten, people would effectively just be learning a new language that somehow is also called C++. So, I guess we we have six different C++ languages now.
Define "struggle." Hiring is challenging for most organizations. The smart ones understand that the job description is a way to attract people with certain areas of interest, not a filter to screen people out. Unfortunately, most HR department take that later approach, leaving us engineers to try to work around the system.
That's a good questions. I don't have specific approaches for training. This is an idea we will discuss and develop plans for. 
The classic question I'm familiar with is: "What's the difference between a pointer and a reference?" I've also heard "What's the difference between an lvalue and rvalue reference"? Which is different than the semantics related to reference types but it has the word reference in it :P 
Are you from ThinkCell?
Are you from ThinkCell?
No.
I think any engineer with 10+ years of experience who really only feels comfortable in their one language is very telling. That would raise some red flags for me, mostly about their attitude to adopt and learn. I've gone through the frustration of using new languages and techniques, reading someone's code and having no idea wtf the black magic syntax their using is doing. Then you learn it and are even angrier that something so obscure is used when a simple for loop is 'more clear' about what's going on. I've met so many engineers who stop there. "My way works fine, why change! Your way is dumb and confusing and hard to understand'. That's the person I'd want to avoid. You just need to stfu and force yourself to learn and use it, after your comfortable then reevaluate your opinion on it. I love python and use it all the time but holy shit do I still VASTLY prefer statically typed languages. God forbid I have to dig through someone's monolithic code base where the types for function parameters change based on who called the function..
I'm a computer scientist who basically just has basic skills in C++ nowadays. I haven't touched it since school. Graduated about 10 years ago but ever since I graduated I've coded exclusively in Java, C#, Node.JS, Go, and Ruby. I believe Python is still pretty popular too. Unless you're making an embedded device app, a drone, an operating system, or something similar there isn't a big need for C++ as it was back in the late 90s early 2000s.
Never seen or heard anyone being concerned about a company overusing shared_ptr anywhere. Besides, that doesn't really matter. Smart pointer are just one element of modern C++, it helps preventing memory leaks and reason about memory ownership. There's nothing magic to it. I generally agree on code review being a good way to enforce code style and semantics. However it's just stupid to waste time and money refactoring PRs that Are effectively written in C++98. You can guide people in the right direction, give hints here and there, but they should be aware of the basic concepts IMO.
It's because they haven't heard of the premier tech stack of 2019: Beast/Asio!
For game developers (I have been at it for over 2 decades) there is a LOT of skepticism about language and library features. Some of it is arrogance (they write their own performant, yet bug-ridden container classes) or got burned (went to bleeding edge standard library implementations that caused some headaches, especially with poor vendor implementations). I am not defending those positions, because some of that is "Not Invented Here" mentality and they are so tired of crunch and trying to keep up with the "new hotness" that disappoints that they burn out a bit. That may be why you see some experienced C++ devs not really up to speed with modern C++. I think with standard updates becoming more frequent, this will become less of a problem. There are some excellent additions to the standard that do require experts to keep current if they want to remain experts. 
I can answer basic-and not so basic-questions about smart pointers and move semantics. Why? I genuinely find it interesting. I'm one of those weirdos who would like nothing more than to puzzle over arcane C++ rules and to pour my soul and being into it-extra cool if there's cool math involved-all day. What I don't know, I'm pretty sure I could learn fast. Unfortunately, though, even weirdos have to eat, so I have to focus on finding stuff that will pay me. I don't even need a huge amount-I just can't work a full-time job for free like I could when I was a teenager. But, ah, I don't have experience in a C++ development position. I don't even have a CS degree. I certainly don't have the right internships or the right background to overcome these handicaps, for which I take full responsibility. But unfortunately, as we all know, you need to have "10 years of experience in C++14" for this totally world-changing (read: mundane, as pretty much every other employer insists that this is a world-changing, top of the line opportunity for which only the BEST people with the BEST backgrounds should dare apply for to their not-at-all ordinary company) opportunity. C++, unfortunately, is a language that seems to only have jobs for experts or the top-tier. Makes it very hard to motivate a large amount to come in. They'll go find jobs in other fields, because they need to get started on their careers today. \*Sigh\*... Look, I don't want to be come off like a total jerk. I get that the costs of hiring a potential dud candidate could be disastrous. I'm sure you are sick of dealing with self-proclaimed coders that can't actually code. But please, please don't pretend that a lot of employers aren't responsible for at least some of their hiring woes. There's myriad complaints, but above all, your complete lack of willingness to invest in people who can learn today is a big part of why you'll have a hard time finding senior developers 10 years later. There won't be enough to go around. 
If there's no high-perf requirements then why not use a newer language?
Again you can achieve reasonable performance even with modern C++ features. We just don't optimize on a super low level. Besides, it's easier to interact with native graphics APIs using C++, it's easier to find graphics engineers in that domain (in general, with or without skills in modern C++) and, at least in theory, we will end up with better performance (at least for computationally intensive pats) than, say, C#. To be perfectly honest we could have developed that project in C# and it would probably run just fine. Dotnet core brought some great stuff to the table.
Why? In my experience large non-trivial code bases in C/C++ adopt a set of libraries and never change, and at most are refactored to support new versions of compilers that the target OS ships, e.g. get rid of warnings the new compiler throws because of whatever anti-pattern is currently baked in to the code base. Because of this most folks employed to work on these code bases are spending their time coercing the prescribed requirements in to whatever set of libraries the team's technical leadership has decided to use. Until company culture says paying down tech debt and refactoring legacy code is prioritized over feature delivery, there is no incentive for software engineers to adopt new language features. If you are lucky you have a team of talented and motivated individuals willing to put in the hard work to do this kind of thing, with buy-in through the entire business chain... I have seen this in exactly one company I have worked for, and that environment only lasted for a few years. Why do applicants bother? Well, I can't remember the last time a job description accurately described the job, so that is more of a problem with the current software business world and how most companies are no good at hiring. If knowing particular language features is a requirement then screener questions are going to be the most important, given by folks who know when the candidate is bluffing (usually not recruiters/HR). Most candidates are just throwing their resume out there and hoping something sticks. Most candidates don't have much specifically directed effort in their job search, and they have seen "the other side" where recruiters and hiring managers clearly don't understand what they need because the interview didn't accurately reflect the specific job expectations. Most interviews are general and expect the candidate can adopt whatever technology requirements, given a minimum understanding of concepts. 
Haven‚Äôt used Ignition, but quickly skimming the API docs, it‚Äôs a very basic library. It provides, small fixed size vectors only and doesn‚Äôt appear to use expression templates, which means non-trivial expressions will be slow. Unless you‚Äôre using the rest of Ignition, I‚Äôd stick to Eigen or Blaze. 
Hire me pleasee 
From the games industry myself. C with classes (or nowadays data-oriented design) is pretty much the zeitgeist. Games deal with a lot of data, but the relative shape and lifetime of that data is well known ahead of time. It makes essentially no sense to ever allocate memory after startup, since memory is also finite. Nor do things like event handlers, function pointers, or smart pointers make sense, because the structure of the program is also known. A frame should be easy to break down into its constituent stages and what data each stage transforms. A perfectly engineered game frame would be absolutely deterministic, perform no allocations, and have no context switches. What does C++17 bring to a program that is structured this way? Very little. Lambdas obfuscate function calls and introduce memory allocations. Smart pointers are useless overhead when dynamic allocations are reduced to 0 per frame. Templates are built to deal with uncertain types of input and output data, which we don't want to have, so all template features are just compilation time bloat. In general, modern C++ mostly doesn't cater to games, where performance rules supreme. There are very few features being introduced that further that goal. 
I dislike auto. I think it makes it impossible to see what is actually happening. I'd much rather read obfuscated variable names than obfuscated typenames. Especially when we're talking about STL types, which are themselves massively obfuscated. auto return types for templated functions on templated classes just makes code impossible to read in my opinion.
Regarding 'auto', it's plainly evident even on this subreddit that the AAA advice isn't all that good.
Where are you located?
`unique_ptr` is for when the ownership is clear, only one owner at a time. It does not need to have a clear lifetime or one owner over the lifetime, it is only restricted to one owner at a time. 
I know how to write modern C++ but I can get paid pretty well for writing C#. C# is much more forgiving and is way easier to debug.
futures and async are currently almost unusable. I genuinely do not think you should use them yet. There is no wait_all(), for example. async does not give you adequate control over the threads used to run the task, leading to potentially spinning up a ton of threads instead of using eg. a thread pool. They may eventually become good features, but as of yet I think they add complexity without adding useful features compared to rolling your own.
As someone who has spent considerable effort finding any C++ work at all in my neck of the woods (Hamburg, Germany) I'd have to guess the biggest impediment is possibly your location and whether or not you hire remote. Solid C++ work seems to have congealed into certain metro areas. Everywhere else it would appear either that there is either a shortage of roles or a shortage of developers. Personally, though I assume others share a similar situation, I'd be happy to travel the world doing interesting work with modern C++ but I'm firmly planted by family and a mortgage. 
Not sure if expression templates are all that valuable for small vectors. Would be interested to see benchmarks. 
Click [here](https://www.boost.org/doc/libs/1_66_0/libs/beast/doc/html/index.html) to jumpstart your career in 5 minutes.
&gt; misuse of constexpr and std::array How does one misuse either of these (I am curious not challenging you)?
Do you offer remote positions? Is conversational German required for applicants? 
&gt; Maybe the lack of good C++ engineers, willing to learn modern C++, is what will be killing the language in the long term. Or the (lack of / fragmented) ecosystem. I'm very experienced in C++, use modern features, however.. I've recently also written a lot of code in C# and Java. Coding experience and productivity is heaven and earth compared to C++. If I had to apply for another job, I'd think twice before applying to a C++ job... unless the project had a dedicated "build/dependency manager" person. Anecdote: I compiled a netcore DLL on windows and transplanted it (like, just copying the file) to an OSX machine and it worked. This is sci-fi in the C++ world and it'll remain sci-fi for the forseeable future. So maybe "all the good C++ programmers" _not_ applying for the OP's job are just looking for greener pastures, like me.
As an applicant - I've had the opposite issue. I have yet to have a professional C++ project, but I have made it a personal goal to stay fresh with my C++ skills, but all of that is discounted by employers when I apply. They see my background in iOS and web and tell me that my background doesn't match what they want.
Interesting... I watched a PluralSight video about latest C++ features and learned a lot about STL and the new C++11 etc stuff. I should say I've never been a fan of STL from the years I've used C/C++ (20+) partly because it was a broken mess in Visual C++ for a long time. Now the modern stuff is here, I see one of our other engineers is using it in our twenty year old CAD codebase. Our product is a mixture of C# and C++. C# I find I like a lot more, but I can still use C++. Using Pluralsight it indicates I'm an expert at C++ while I'm merely proficient with C#! Oh yeah, I did work in the games industry. They avoided STL like the plague, preferring to write everything themselves in order to control everything - like memory allocation etc.
Every game developer I know is worried about shared_ptr. :D 
I'm used to putting the thing that is checked last, but I get your point. Though, I'd rather think of a different name then :)
&gt;&gt; My experience is that in the real world you just can not write pure C++11. &gt; Sure, a lot of graphics APIs are plain C, but you can write abstractions. Which is more or less my point, you cant write pure in C++11 (or later). You can: - Use the old api as is, and skip Modern C++ - Write your own wrapper api around it But both require that you understand the Old C/C++ style and its conventions. So neither is really writing a pure Modern C++ program. Compare this to say Python3 where you can write the whole program in Python3. The result is that you cant really be a Modern C++ Programmer in the sense that the original poster means, i think. You always need to also know the old stuff and how to handle it.
Check out an interesting open source project and dig in a bit to see how it works. Rpclib is one example. It's used by some cool simulators (Carla, Airsim) and simple enough to grok. 
I dunno about 98, but really 'modern' C++, as in what you see a lot of around here, may not be all that interesting to people who already know C++ very well. It's become byzantine, vastly over-templatized, it continues to lean more towards something Javascript-like, and it sometimes seems to be more about being a language lawyer than about creating real product. The tools to create good software in C++ have been around for along time now. What you pay in return for saving a few keystrokes with auto or the new loop syntax, is kind of an overweight Elvis version of C++. Or God Forbid you actually allocate something in the ctor and have to struggle to remember to delete it in the dtor instead of using a smart pointer (because we have to keep our template to code ratio up, up, up.) Or use an output parameter. Or use an actual inheritance hierarchy. Honestly, you can use less modern C++ and spend a hell of a lot less time on language lawyer activity, get better performance, a lot less code bloat, way better build times, and vastly more comprehensible errors. And experienced C++ coders already know how to do that. In the time it would take me to go dig through a list of hundreds of algorithms and figure out the gotchas involved, I could have written it myself, just as reusable, and without a hundred-weight of related template baggage. That's not to say that some features aren't undeniably useful, in that they allow for more explicit compile time semantics, so the compiler can watch your back day after day. I'd say that override, explicit, default, and enum class are solidly in that category. Lambdas can be quite useful if not abused, but as soon as you start using them, you are into 'a hundred obscure error messages' land for the slightest mistake (since capturing lambdas cannot be passed to an explicitly defined function pointer parameter, and capturing lambdas are mostly why they are really useful relative to actual function pointers which are much lighter weight.) &amp;#x200B;
This was the consequence of a bug where passing [MsgPack](https://msgpack.org/index.html) messages around wouldn't work ; converting the sending to work over binary messages fixed it, and we could still send JSON messages or text data as well by still treating everything as an std::string(). I just re-read what the RFC says about TEXT, and it requires that the messages are utf-8 encoded. I guess I could just validate that text messages are valid utf-8 and fail otherwise, and same deal on the receiving end. Maybe we should support TEXT. This lib is used with Erlang ([cowboy](https://github.com/ninenines/cowboy)) and Python ([websockets](https://websockets.readthedocs.io/en/stable/)) and the binary only aspect doesn't give us any noticeable problem in practice.
You're right of course. I couldn't post the original code because it would require quite some explaining soI came up with the simplest example I could think of :)
What nonsense. std::unique_ptr&lt;Foo&gt; Thumbnail::GetFoo() const; Foo* Thumbnail::GetFoo() const; exact same ownership semantics, one is ckear and highly bug resistant the other is a recipie for leaks. void ProcessChicken( Chicken* ); void ProcessChicken( std::unique_ptr&lt;Chicken&gt; ); ditto. Except in the raw pointercase, was it an ownership transfer or not? Where the docs clear? How about the 13 layers of calls the `Chicken*` was passed down, or the `Foo*` was passed out; did they all have extensive, updated, accurate documentation on the ownership semantics of the pointer? And this isn't just internal APIs; the amount of documentation lacking in large, ancient libraries (like OS APIs!) about ownership transfer is ridiculous. Unique ptr moves the question of ownership from being something humans have to get 100% right at all times to something you inject into the type system once and watch for `.get()` and `.release()` and explicit casts. The "holes" in the lifetime management type enforcing become explicit and isolated, instead of being basically every use of the pointer. While there is an initial cognitive load from learning the rules of unique ptr, the margnal load of ownership-correct coding plummits. Mental load plummits, allowing more brain-space to make the rest of the code better. But if you don't know unique ptr, you end up having the same or higher load, and the added complexity permitted by using smart pointers could fry your brain. The same comes from a myriad of other C++ features. Taking a 100+ line and replacing it with less than 10 lines of easier to show correct code repeatedly can not only improve the code base, but permit entirely new things to be done that would have been impractically expensive to maintain/write/debug without the simplification modern C++ brings. 
&gt;your expectations must change Well, here's a statement I really disagree with. Whatever you do, ***don't*** change your expectations, i.e. lower the bar, unless you want to run the risk of destroying your teams' C++ culture. Your expectations are entirely reasonable &amp; decent C++ software engineers exist. This subreddit (though maybe not this thread, for reasons that elude me), C++ conferences, Twitter, etc. are clear proof of that. There might just not be that many in your area, so you (and your company!) have to invest more work to find them. Work together with HR &amp; marketing to expand advertising. Have HR actively source the right candidates. Find C++ meetups in your area, and talk to people there. Or host a meetup. Etc., etc.
If your transferring ownership around a lot then I'm back to my original point. The problems smart pointers are really good at solving are almost universally problems you should really try to not have in the first place. I don't want to be able to easily transfer or share ownership of data. Whatever allocated that data should be responsible for it's entire lifetime. If something else really needs to touch it then should through some kind of handle.
I would look at the individual firms hiring sites to see what skills they are looking for. 
Yeah same here. I will use auto for an iterator or something to save myself some typing, but sticking auto wherever possible just makes the code harder to read. One of the things I love about C++ is it's strong typing, and while auto has its place, it is not "everywhere". Especially when trying to read some new project, when I'm not yet familiar with all the types, all the methods and everything, seeing a type being returned can shed a lot of light on what is supposed to be going on in a given method.
I'd echo a sentiment expressed by some others in this thread. Programming in C++ is often related to programming in an older project, which means an older version of the language. It also happens to be that a lot of the C++ I've worked on target a wide range of platforms and toolchains, and requiring C++11 or anything newer can be a problem.
I've seen worse! Can't recall the specific project or file, but somewhere in the NetBurner code (embedded TCP/IP stuff) there was a "volatile int" being returned. &amp;#x200B; And then to take the trophy, I've seen ["volatile void" being returned](https://github.com/BrianGladman/aes/blob/d11266f63dc2e14bab55215ba66211f8308529e2/aes_via_ace.h#L405-L406) in some cryptographic code (also work in security) &amp;#x200B; You do this stuff long enough, you've seen just about everything. &amp;#x200B; Paraphrasing only slightly the good Mr. Charles Babbage: "I am not able to rightly apprehend the kind of confusion of ideas that could provoke such a line of code"
Wut? I have plenty of applications at work where data comes over a wire and gets passed between multiple objects. E.g., * event comes over wire. * Object is instantiated in a `shared_ptr` to record the details of this event. * This data gets passed to step 1 in a processing algorithm in another thread via a lockfree queue. * Step 1 checks to see if the even is sufficiently similar to another event and if so merges them. If not, gets pushed into a tree. * When enough time has elapsed, the event comes out and is pushed into another lock free queue to pass to another thread. * In this thread anywhere from 1 to infinite (though likely 1 to 7) objects may want to have access to the data at any given time. * After enough times has passed the event will come out of this thread and get passed to a fourth thread (possibly multiple times) and possibly through multiple lock free queues. * The final thread handles reporting the results of all this processing to a user. &gt; Whatever allocated that data should be responsible for it's entire lifetime. This really only works if the allocator of the data has someway to automatically know when to free memory. This does not work in the application I described above as the memory allocated for the individual events can last anywhere from tens of microseconds to several hours. This may be true in the applications you write, but it is not true in everyone's applications. &gt; The problems smart pointers are really good at solving are almost universally problems you should really try to not have in the first place. I don't want to be able to easily transfer or share ownership of data. While you may have the luxury to do this and insist upon this, I do not. I am at a loss to explain why this would be a problem in the first place. 
Yeah me too, worried that I've been writing some pretty naff code without knowing it, (C++ in a nutshell anyone?)
We're all happily working where we're working. I have a never ending swarm of recruiters emailing me. I tell them my hourly rate and never hear from any of them after that. I'm the only C++ guy in my department and designed and built the core of a video test automation system. Pretty much everyone else is Python or Go. The guy writing python tests using the API I put together for him is pretty fantastic though. He's doing stuff I never actually designed the system to do. Which is great, because that pushes some more requirements my way to implement.
That seems very handy. I'll definitely give it a try! Thanks for sharing.
I strongly suggest using clang-tidy and cppcheck. This is what I do to keep a clean modern C++ codebase while working with developers with different backgrounds. They run during CI, and I set github to require it to pass before it can be merged into the protected branches. The `modernize-*` checks work nicely to get developers to use the better version of many features(ie range-based for instead of raw loop or `using` instead of `typedef`). More importantly, [`cppcoreguidelines-owning-memory`](https://clang.llvm.org/extra/clang-tidy/checks/cppcoreguidelines-owning-memory.html) work nicely to enforce the usage of smart pointers or RAII classes. The `LegacyResourceProducers` and `LegacyResourceConsumers` can check for functions more than memory allocations such as `fopen` or more. Cppcheck has checks for raw loops that can be written using STL algorithms. It only checks for some basic patterns, but can get developers familiar with using the algorithms. Also, cppcheck has user-defined rules you can add. I defined several rules [here](https://github.com/ROCmSoftwarePlatform/AMDMIGraphX/blob/develop/cppcheck.rules) for one of the projects at work. A rule does a regex on the token stream in cppcheck(which is after it has been lexed and simplified). This could be used to find problematic patterns in the source code. Of course, this wont catch all issues, so reviewing PRs would still be needed, but it wont need to focus on the small things(like using `make_unique` instead of `new`) and instead can focus on the overall design. The developers will learn a lot from the process if they are open to learn. For developers who are on the fence about modern C++, they will more likely embrace it instead of spending time trying to fight clang-tidy and cppcheck. For the developers who are strongly opinionated against modern C++ and refuse to change, its best to filter them in the interview process because they will most likely be miserable working in such an environment. But its best to have an environment where they would be miserable rather than you being miserable dealing with their code. 
Speaking for myself, I can't stand the language because it's a hodge-podge that's been cobbled together and you have to memorize annoying workarounds for even the most basic tasks.
Because they haven't been paid to learn it yet, honestly. Hire good programmers and they can learn modern C++11 just fine in about a month (less with dedicated training).
To be fair... you can be strongly opinionated about something and still do it well. Professionals are getting paid, and if your employer wanted you to write code with purposeful bugs in it, well he's writing the checks so a pro will do that. If he wants you to write in a style you would never use yourself, the same applies. I'm sure plenty of people who don't hate modern C++ per se are still fairly contemptuous of plenty aspects of the way code is written at their companies, but they still do it well. &amp;#x200B;
They are more or less useless bloat for that unless it is 100% scalar implementation. The key idea with scalars is to evaluate one vector lane at a time to reduce spilling. If your SVM library (Short Vector Math) has a SIMD back-end it will do nothing useful, just make error messages two pages long and increase compilation time. I should know, I went full retard with meta expression templates 15 years ago when they were a upcoming trend. I am more ashamed of that nonsense now than anything else. :) 
Another thing worth mentioning is that "keep it simple, keep it scalar" -approach has some auto-vectorization fanclub members but that is very random approach. I'd prefer explicit vectorization with intrinsic functions or ISPC over brittle and unreliable auto vectorization.
Personal experience: learning Golang did indeed make me comfortable with C++ auto, and both Go and Javascript worked together to familiarize me with C++ lambdas. *(I knew C++98 before either)* So, anecdotally, it does seem like learning other languages can help a C++ programmer adopt modern techniques.
Some resources to learn: [Herb Sutter's blog](https://herbsutter.com/) [Fluent C++](https://www.fluentcpp.com/) [Bartek's blog](https://www.bfilipek.com/?m=1)
I wouldn't compare these at all. The std::filesystem seems more like something you want to use as a lower level abstraction FOR the PhysicsFS -like library so that don't have to write as much platform dependent boiler-plate. I like the concept that you can have container mappings for different compressed archive formats and unified API for accessing them. Path path("foo/bar.zip/data/"); File file(path, "something.jpg"); Or.. File file("foo/bar.zip/data/something.jpg"); and so on. On my similar system the Path mapping is recursive, so you can have parent Path's for files and paths. In fact, so the second example above with "just" a File in it, will internally have a Path. The idea here is that you can simply access a file.. but if you going to access a lot of files from a path, you should create a path object to pay for the overhead (of parsing the container headers) only once. Even better, have API to memory map the contents as well; if a file is stored inside archive the file can be directly mapped into the offset in the archive the file is stored at. TL;DR: PhysicsFS &gt; std::filesystem, no hesitation :D 
Thank you very much. Sincerely appreciate it :), will utilise the resources well
Because they‚Äôre not that different and you can learn the changes quickly. How long did your 5th programming language take you to learn? A day?
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b254aj/what_math_skills_does_a_c_programmer_need_to_get/eiqyh7h/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
!removehelp
OP, A human moderator (u/STL) has marked your post for deletion because it appears to be a "help" post - e.g. asking for help with coding, help with homework, career advice, book/tutorial/blog suggestions. Help posts are off-topic for r/cpp. This subreddit is for news and discussion of the C++ language only; our purpose is not to provide tutoring, code reviews, or career guidance. Please try posting in r/cpp_questions or on [Stack Overflow](http://stackoverflow.com/) instead. Our suggested reference site is [cppreference.com](https://cppreference.com), our suggested book list is [here](http://stackoverflow.com/questions/388242/the-definitive-c-book-guide-and-list) and information on getting started with C++ can be found [here](http://isocpp.org/get-started). If you think your post is on-topic and should not have been removed, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fcpp&amp;subject=Help%20Post%20Appeal&amp;message=My%20post,%20https://www.reddit.com/r/cpp/comments/b20ok3/handson_course_on_c_projectbased/eiqyozz/,%20was%20identified%20as%20a%20help%20post%20and%20removed%20by%20a%20human%20moderator%20but%20I%20think%20it%20should%20be%20allowed%20because...) and we'll review it. #####&amp;#009; ######&amp;#009; ####&amp;#009; *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/cpp) if you have any questions or concerns.*
Out of curiosity, what industry does your software ship for?
To build on this, while it‚Äôs often that the engineering team puts together a list of skills, the HR team then ‚Äúmassages‚Äù it which tends to make things less attainable. I know a lot of applicants just use the spray and pray, hoping that something in their resume will spark an interest and get them an interview even if their skills are exactly what you need. If you can find a good C programmer teaching them what new approaches to use shouldn‚Äôt be too hard. May take a bit longer to get them productive in your environment but very well could be worth it. I would take someone with good fundamentals and a willingness to learn in a split second. 
Is anyone using the [PolyCollection](https://www.boost.org/doc/libs/1_69_0/doc/html/poly_collection.html) library? I have [serialization support](https://github.com/Ebenezer-group/onwards/tree/master/example/poly) for base\_collection&lt;&gt;. I think that's an interesting library, but haven't found many using it so far. 
&gt; Lambdas obfuscate function calls and introduce memory allocations. *Record scratch* Lambdas usually turn into the equivalent of a struct with an operator(). Not sure how you think that allocates memory.
Its probably because any job learning you are requesting needs to be done off the clock and in the current job market fuck it I'd rather spend my free time on me.
[CppCon 2015: Kate Gregory ‚ÄúStop Teaching C"](https://www.youtube.com/watch?v=YnWhqhNdYyk).
std::move can make things easier to read. worst case is you have to execute a few more instructions on already fetched pod data. Nowadays the worst killers are iterations and in the case of MS, heap management.
What are you paying?
nah that wasn't university, that was a real satellite control system.
Most C++ jobs I've found involve working with legacy code, writing something you don't really need to maintain and use once it's done, or both. Legacy code introduces a lot of issues: &amp;#x200B; * Fear of fucking shit up. This causes: * Fear of anything new. This includes: * New language features. * New library features * New compilers * New techniques (which can be difficult to integrate anyway). * New build systems * Fear of refactoring. Copy-pasta is much safer and you can get a LOT more out the door that way. * Lack of automation and mountains of obstacles in the way of doing so, like: * Obscure, obsolete, abandoned, and unsupported build systems. * Builds that are not reproducible. * This makes onboarding a new member or ramping up in a different area of a complex system really difficult and time consuming. * Experienced developers spend way too much time on menial, manual tasks that require a great degree granular concentration. * Missing specs...etc...etc... &amp;#x200B; And here is where it gets ugly. Production crawls. Who gets the brunt of that though? The people complaining that we need to slow down even more and take care of all this technical debt? Nope, it's the people who go slowly to get it right. What ends up happening is that all of the above continues and becomes institutionalized even further and further as things slow more and more. Eventually the layoffs happen when many of the best people are booted. Those who can produce and produce, at speeds that are impossible to actually accomplish, that end up sticking around. &amp;#x200B; I've been laid off 3 times and it's gone this way every time. Each of them, except for the last and time will tell, fail cascaded within a couple years and were bought by some investment company and all jobs shipped overseas. If they were using C++ they'll work to change that into something entirely different so they can hire more people at a cheaper rate. Then they can just pound the problem with more and more people the less it scales. &amp;#x200B; Other languages, newer languages, benefit from current state of the art in architecture and DevOps (a fairly new title) advancements like Docker. There's no existing code that was written before these advancements in many cases. Better decisions can be made at the beginning. Eventually all end up in similar spirit though and suffer the same problems...eventually. It's what the industry supports, encourages...and it's a perfect fit for those who got into it just for a big paycheck (of the 30 or so people gunning for the same degree at college I was among like 4 peers that actually wanted to learn the subject and not just get a degree). Developers can spend whole careers not learning any new thing and they'll quickly develop all the above fears if they don't have them already straight out of college. Anyone suggesting they stretch their skills quickly becomes a threat. &amp;#x200B; It's frustrating to anyone who wants to really help and give the company the most for their buck. You can't help it eventually coming out in work and affect...especially when the blame starts trickling down. That's just my thoughts though looking back on the various places I've worked for. It's understandable too. You build up a business and you don't want to rock that boat...but the drive is very counterproductive.
i learned fortran77 in university on ibm mainframes and got one semester in turbo pascal. My major isn't CS although i did afterwards take some important grad level cs courses.
Perhaps they all have jobs already and employers are holding onto their skills?
&gt; they tend to have a strong dislike of some modern features (especially auto). Note that overusing `auto` is disliked by quite a lot of senior developers.
We have been working on modernizing our codebase. For a long time, we simply weren't allowed to used exceptions, which in turn threw out the core STL and a lot of other things. Code size was another concern. A couple years ago, things changed and we created a "coding culture club" group to get up to speed on best practices and advocate them to the rest of the team. As long as people are willing to learn, going from C++98 or just C is better when you have a few people to pave the way forward.
constexpr by using it as replacement for const on constants, but not using it to describe actual constant expressions. People often think of it as an "optimization technique", some dark voodoo magic that somehow makes your programs faster, rather than a tool that lets you do particular computations at compile time. constexpr std::array&lt;..., 41&gt; arr = { &lt;skip&gt; } - funny pattern too. Imagine you encountered such piece of code, what data is stored in this array, why do you think it's important to assert that this array has to be 41 elements long exactly? &gt;!No particular reason, people just read somewhere that in "modern C++" they should use std::array and so they do without thinking about it too much. It just happens that it won't compile if this number is different from 41 because that wouldn't match length of initializer list.!&lt; I'm not saying that std::array or std::make\_array are bad things, not at all, it just has to be used where appropriate and programmers need to have some minimal comprehension of what they are doing, that's all what i'm saying.
Many (most?) languages don't explicitly mention the types of variables, even though they have a type. 
&gt; Not only do they not want to learn it, they're angry at its existence. It threatens their job security.
I don't like it in them either. The most commonly used one of those in Javascript now has several statically typed extensions built for it that are becoming the de facto standard.
I don't see how. There's nothing in the new stuff that prevents one from writing purposely-nightmarish code. C++ *excels* at that. It may be my favorite language, but it does allow for writing the most horrendous code you've ever seen if you're not careful.
I only use auto with nested types, most commonly stl iterators. The code is just as easy to understand and it gets rid of unnecessary verbosity. 
Capturing variables allocates memory. There may be a small, implementation-defined buffer associated with the lambda, but if you capture enough things you will cause a dynamic allocation. int a[100]; auto x = [=]() { foo( a ); }; // allocates And for the most part, a lambda that doesn't capture should just be a function call.
Have you considered casting your net a little wider? There might be people out there who are "blank canvases" for you to train up. Here's my story. I have no formal CS background; I'm a mathematician by training who programmed for fun and for curiosity's sake. I'm 6 months into a junior C++ position, after completing postgraduate studies. I'd never written anything _specifically_ in C++ before, but I had enough experience of tinkering with C, Java and Python to know the lay of the land. I don't have any formal training---it's more like mentoring, or an apprenticeship. I can ask impromptu questions (especially "why?" questions) any time. Sometimes these are brief sanity-checks; other times they can spawn a half-hour discussion. It's rewarding for both sides, and the fact that it's a personal process rather than "go away to an intensive training course" does a lot for my morale. This gets backed up by a more formal code review, which is better for discussing specifics. I guess there are downsides too---it's a bigger risk for the employer, it takes time to train someone up to be effective and productive. In my own case, I wouldn't be at all appropriate for a small company, or for starting a new project. I just wanted to point out the option and that there are people like me out there. Hopefully food for thought?
See, this mentality among the employers is clearly not helping the situation.
We had sort of similar problems in my ex company: a pool of very talented and smart people but not really nuanced in C or C++ programming nor familiar with the concepts these languages require you to understand. Some of them were not nuanced in programming of any kind actually. With not much choice left what I did is that I proposed a kick-start process for each new employee. It was comprised of a programming assignment that they had to complete in 4 weeks time. Assignment was a real world problem and complex enough that solution would usually require few kLoC. They would get a supervisor who would do the code-review and generally provide instructions on the best practices, motivation behind those etc. To make sure that the trainee makes most of the assignment and becomes autonomous, there was only one time slot per week for questions and discussions. Short and quick questions otherwise were ofcourse allowed. I must say that we had quite good success with this approach and trainees were also actually quite happy. Precondition for all this is that people are eager to learn new things. Having good supervisor is also crucial.
Could also be that they just don‚Äôt work 24/7 with c++, might take them a day to remember all the things you care about, might also be that they know c++11 and could pick up c++17 in a day and be better coders than the best ones you know.
Another factor that seems to be very common around here is that university does not prepare students for the kind of knowledge/interview. I have gone through uni and haven't heard a single thing about modern cpp (it was a while a go, but still during/after 11). It was only after I joined a specialized college that I could get in touch with the modern standards. There are so many of these students thinking they know stuff, but actually knowing just the basic/theoretical stuff they were taught, that it is hard to guide them when they ask for advice. People should start realizing that self-study is more important than just going through education.
Man, imagine a computer where CHAR_BIT = 1. All the string libraries would break.
Can I apply?
That sounds like a curriculum by which to waste your time. Let's not forget that languages are just a tool for accomplishing other things. Learning them is not the end game. Learning them in a way that they aren't used is pointless. 
... isn't that the problem?
You apply to a big company for something you mostly know, then after working for around one year you ask to be transferred to another team that can give you new challenges an new learning opportunities.
So, typically, it is better to have strong foundational knowledge than knowledge of any specific language. If you're looking for people who know a language, you're looking for tye wrong thing.
You could just have a requirement that every copy-constructable type implement the same named copy-constructor.
&gt; Learning them in a way that they aren't used is pointless. By that logic learning how to implement your own binary search algorithm or quick sort is a waste of time, since you would never actually do that. 
Yep. Vectors have been around for a long time, but nobody seems to know how to use them. It's mostly the education system, IMO, still teaching as if it is the mid 80s. Our local state college will actually mark you down significantly if you use a vector, or worse, a range-based for loop. 
My recollection from the last time I looked into the CMake code for this is that CMake will choose the standard that meets all of the requirements. That means if a target has compile feature `cxx_std_14` but its `CXX_STANDARD` target property is set to 17, it should get C++17 compiler flags. It should be fine to use both `CMAKE_CXX_STANDARD` and compile features together. This may happen if a lower level dependency has to support an older CMake version that doesn't have the compile feature support necessary but a project higher in the dependency hierarchy requires a more recent CMake version and relies on compile features alone. Note though that there is no compile feature for an equivalent of the `CXX_EXTENSIONS` target property and the `CXX_EXTENSIONS` target property is only honoured if `CXX_STANDARD` is also set. Some discussion of this [here](https://gitlab.kitware.com/cmake/cmake/merge_requests/1519).
&gt;The classic question I'm familiar with is: &gt; &gt;"What's the difference between a pointer and a reference?" And 90% of people can't answer that? Ouch. &gt;I've also heard "What's the difference between an lvalue and rvalue reference"? Heh. Every time I think I have a good grasp on revalue references I read some Effective Modern C++ and realize I know a lot less than I think. But I could see a lot more people failing that. 
Thanks
I think usually all they look for regarding the second question is that you don't have a named reference to rvalues, they are temporary objects. If there's anymore to it than that, I don't know and in all my years of programming it's never been an issue. I don't particularly care for esoteric language questions like that one but I have heard it before so :/
unique_ptr ensures that you code will function as intended, reduce congintive load, and make it highly resilient to whatever changes to the code might take place in the future including adding new code paths, removing exist code paths, altering existing code paths, change what or how something interacts with the code, etc. Not only does it prevent leaks but it also all but eliminates defects that would otherwise be a risk with any changes to the code. Whereas proper usage reduces the chance of regression issues to an almost zero. And given that the performance overhead for the technique is zero then what possible reasonable argument could be made against it? It's fine if a developer doesn't appreciate these benefits early on in their career. But such an attitude from even a midlevel candidate, after have had the benefits explained to them, would be a disqualifier for any candidate in my view as it's just plain reckless and unprofessional.
std::filesystem has the problem of not existing in C++11.
My [`lock_ios`](https://github.com/potswa/lock_ios) library can help synchronize your streams, and it also helpfully unties them.
I think the first thing needed is an actual (non-preprocessor-based) import system. This would allow us to release C++ 2.0 and import C++ 1.0 definitions into it without one compiler option needing to parse both.
It's worth pointing out that C++20 is getting `std::osyncstream`, which should be helpful in this area.
Well, when in doubt, use std::filesystem. As others have pointed out, they are pretty different APIs that solve different problems. So if you need to access data with a file, PhysFS might be useful. But it only makes sense to add a dependency to a project if you are certain you need the extra complexity. For a lot of use cases, it's fine just to have a directory with a bunch of small asset files, and std::filesystem is great for iterating over a bunch of files in a directory. It may come to pass that you eventually build something that has performance benefits from using one big packed file with a bunch of assets. When that happens, you can investigate various options. But if you are just starting a project, you won't have zillions of assets so you won't have any significant overhead from open()ing them separately, and you can focus your efforts on other parts of the game or whatever.
I assume you're answering the specific comments of the OP. I wish to remind, tho, that it makes more sense to run vscode on linux.
Wait. What? Why would that allocate? Are you sure?
You say that as if you know. Have you learned how to do so and come back to an old style? Or do you think you know without ever having learned?
See my edit. It copies onto the stack. I was thinking of initializing an std::function from a lambda.
On github? How does that work? Go through the source code to see what it does and see how you can improve it?
Is building a game really one of the best ways to implement/learn OO principles?
&gt;Or God Forbid you actually allocate something in the ctor and have to struggle to remember to delete it in the dtor instead of using a smart pointer Yes. I don't want to see a new or a delete without a really good reason. Humans are bad at accounting. Using patterns that obviate the need for things that humans are bad at is *good*. It has little to do with keystrokes though fewer keystrokes is good in that it's often easier to read and notice intention and mistakes.
Yeah they do seem to have cool courses but the ones specific to C++ are mainly gaming related. Did you get a chance to take any C++ course?
&gt; I think any engineer with 10+ years of experience who really only feels comfortable in their one language is very telling. Why should someone have to have significant experience in more than one language if their problem domain doesn't use more than one language? Take embedded systems, for example. The languages of choice are C and C++ along with a bit of Python for tooling. You could easily have worked 20 years in the field in many different projects without needing any other languages.
I think in this case using C would have been better then. As it would not have skewed the students understanding of C++.