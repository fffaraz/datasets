It's another joke
This is excellent news. Great work by you and great work by your compiler guys
In April, [we announced](http://blogs.msdn.com/b/vcblog/archive/2015/04/29/c-11-14-17-features-in-vs-2015-rc.aspx): "We're planning to start implementing Expression SFINAE in the compiler immediately after 2015 RTM, and we're planning to deliver it in an Update to 2015, supported for production use. (But not necessarily 2015 Update 1. It might take longer.)"
 Sums it up nicely. His counters to JBlow are pretty spot on The only real contender with C++ is Rust, but only if it gets serious C++ interop.
&gt; &gt; If you need to add two numbers, don't create a future for that. &gt; Why not? (Disclaimer: I want "tolerance" for constexpr stack-allocated futures). All existing mainstream implementations of std::future have heap-allocated associated state, so there will always be some non-trivial overhead when creating a std::future. &gt; This makes me wish that we had a Future concept and would specify standard utilities in terms of these and not any particular future type. Agreed, and this is the approach the await proposal is taking. The std::future meets the requirements, but something more light-weight would work too. &gt; Given your "insider" position, would you mind telling us your take on Google's executor proposal? I think this was a solid proposal that got better in subsequent iterations, in particular after removing mandatory virtual dispatch. SG1 (Concurrency Study Group) actually approved it as the basis for future work at the Redmond meeting in the Fall of 2014. Other proposals were just too big, so they didn't get enough traction. I really hope that we can come up with a design agreeable to everyone and include that into v2 of the Concurrency TS.
Are exceptions very common in modern C++? They always seemed like an unfortunate feature, unnecessary and slow, at least to me. And it seems that Qt, at least, agrees with me: [exception safety][qtexc]. The quote in question: "Qt itself will not throw exceptions. Instead, error codes are used... This has historical and practical reasons - turning on exceptions can increase the library size by over 20%." [qtexc]: http://doc.qt.io/qt-5/exceptionsafety.html
Google glog also works with c++98.
Yup; the code's been fixed with no measurable change in speed. Latest image generated is [here](http://xania.org/201506/rust-path-tracing-many-samples).
&gt; They always seemed like an unfortunate feature, unnecessary and slow Exceptions aren't slow, just go read [TR18015](http://www.open-std.org/jtc1/sc22/wg21/docs/TR18015.pdf). Also, Qt is not a representative for elegance in error handling. Just stare at this code: bool ok; int unsafeValue = str.toInt(&amp;ok); if (ok) // use unsafeValue Seriously... Exceptions do have their problems and I very much prefer the Haskell/Rust-approach of using its sum/algebraic data types (i.e. the C++'s `variant`). One proposal that I'm passively following is the [C++'s expected proposal](http://www.hyc.io/boost/expected-proposal.pdf).
It seems to me like it should be possible to compile Rust to C++.
I agree, I'm a Rust programmer (who has an interest in C++). To be honest, I'm trying to see why we should add exceptions for interop with C++. Again, they've always seemed unnecessary to me. Is there a good reason to use them instead of an algebraic type, especially when you look at the very real performance penalties?
If you're concerned about the performance implications of thrown exceptions, you're probably using them wrong.
Thanks for sharing.
I work on high frequency trading systems, I'm concerned with the performance of everything.
When I use exceptions, it means the user did something outside of the API and they should know about it because they're using the API wrong, or for very rare logic flow (connection lost, going to take relatively forever to reconnect anyways, etc). For everything else, or any logic flow, return values. How would you using exceptions?
steve, vc dev mgr here. yes, this is still the plan. Team is designing the approach we'll take to deliver this in an increment without breaking folks now. it's major surgery but it should be binary and source compatible surgery so we were comfortable slotting this (and more) into the updates. 
&gt; But always validating that an API was used correctly at runtime would cost too much in terms of performance. You must not deal with any input from humans. :P Just curious, what does stuff like that run on? I picture you guys using FPGA accelerators and other cool things. XD
Input validation is an acceptable use for exceptions. Take as an example an API that only operated on even numbers, it would be fine to validate input from an external system to ensure that it provided an even number. What wouldn't be fine would be if every call to the API checked if its parameter was even. So given this snippet: auto input = read_input_from_external_system(); if(input % 2 != 0) { BOOST_THROW_EXCEPTION(std::runtime_error("Not even.")); } api_call_1(input); api_call_2(input); api_call_3(input); Validation there and throwing an exception is perfectly sensible. But if each `api_call_n` was verifying that it was being used with an even number, it would simply be an unacceptable and needless cost. Now if I wanted to be really strict and enforce at compile time that all calls to the API used even numbers, then I'd encode that requirement in a type, just very briefly to give an idea: struct unchecked_t {}; static const unchecked = unchecked_t {}; struct EvenNumber { const int value; // Constructor performs validation. EvenNumber(int value) : value(value) { if(value % 2 != 0) { BOOST_THROW_EXCEPTION(std::runtime_error("Not even")); } // An unsafe version that by-passes validation. EvenNumber(int value, unchecked_t unchecked) : value(value) {} }; void api_call_1(EvenNumber a); void api_call_2(EvenNumber a); void api_call_3(EvenNumber a); This way you can take input from a system, wrap it into a type that does the validation needed to guarantees certain properties required by your API, and then that validation gets reused on subsequent calls, rather than every call to your API needing to do redundant checks. &gt;Just curious, what does stuff like that run on? I picture you guys using FPGA accelerators and other cool things. Mostly Linux servers but also Windows servers too, there are often cases where drivers on Windows are superior to the ones on Linux. Yes we do use FPGAs for parsing NASDAQ market data, but those are fairly standardized and we just buy ones developed by third parties.
steve, vc dev mgr here. sorry, definitely can't give a date, but we already released the RC a few weeks back so we wanted to prep the web compiler to get any last bugs found in time for the release.
The OP is about games. In the game shops I've worked in, exceptions are impossible to use in most if not all of the game code. They simply cannot be used. Far too slow. Asserts, while highly unwieldy, are used instead. And a nice benefit of asserts is that they can all be disabled when compiled for production code, but try catches have to be hand maintained. The whole premise of a try catch is excruciatingly slow, especially for code that expects to execute 60 or more times a second in a massive system. When programmers spend more time figuring out if their custom vectors are allocating cache friendly than actually implementing most actual game features, its not unreasonable to maybe consider that exceptions are not on the table for folks. Its not a question of using them, yet alone how they're being used. EDIT: The demand for sources and people "not understanding" has grown unruly. There is a source above and here is a [bunch more](http://www.reddit.com/r/cpp/comments/38am0o/why_c17_is_the_new_programming_language_for_games/crv37lw) which can mostly be accomplished from simple google searches and watching a GDC talk or two from programmers from Naughty Dog or Bungie and such.
Yep I work in high frequency systems as well and exceptions were always something I would not touch with a long stick. Before that I worked with OpenSceneGraph, a 3D graphics library mainly used for scientific visualization. There also they leave exceptions out for performance reasons. In HFT we try to get rid of layers. For example, my main work is to get rid of glibc and the kernel altogether since atoi(), clock_gettime(), etc can all be rewritten in a way that takes a fraction of its original time. So I concur with sakarri that we test and are concerned with performance everywhere.
Submitted. It behaved a little wonky on my phone... The touch detection was off and I had to go landscape-to-portrait to fix it.
I'm ok with that. Exceptions are not important to me, I much prefer the Rust approach to error handling.
Unless you are linking qt statically you'll need to distribute the framework with your work. QT is not a small framework (especially if you need audio and graphics support). On windows if I'm not mistaken the dlls can accumulate up to 200 Mgb and a "simple" OSX bundle will start from 80 Mgb.
For everyone concerned about the speed of exceptions, please read about zero cost exceptions. There is very little cost to exceptions on the regular path, however the exceptional path is much slower. This means if a function fails infrequently, it is faster to indicate errors with exceptions than return codes.
Not really. C++ is very tricky due to templates which means any language properly interacting with C++ directly would need a C++ template parser at least.
It is easy, if you understand the many orthogonal options that are involved. All of these things are orthogonal: * Release mode (/MT, /MD) versus debug mode (/MTd, /MDd). This controls the separately-compiled CRT/STL you link against, and it affects the representations of STL objects (to add extra bookkeeping information for exhaustive correctness checks). They are inherently binary-incompatible. * Whether your own code is built with debugging information (/Zi, and other options). This emits PDBs so the debugger can understand the binary. * Whether your own code is optimized (/O2, etc.). The debugger can step through optimized code, and there are new options to make this less painful, but it's still way harder than stepping through non-optimized code. * Whether assert.h is enabled (controlled by NDEBUG, and that's *all* it does). What you want is to build your code in release mode (and use release mode libraries), and build your code with debug information (/Zi), but without optimizations. Then you can step through it happily. (Stepping into separately compiled CRT/STL stuff or other libraries will be "fun". Stepping into header-only STL stuff will be actually fun since that won't be optimized.)
While I agree C++ is getting nicer with every standard revision, the problem are the existing codebases. Starting a greenfield C++14 project with all developers on board feels really nice. And I have been using it on some hobby coding. Now for existing codebases, I dread to think about the mix of C++98, C++03, C++11, C++14, C++17, depending on what the developer currently responsible for a specific module did. Specially taking into consideration the deprecated C++ between releases (e.g. traits in C++11 vs C++14). Regardless of what gets written on the Interwebs, code reviews are seldom done at enterprise level, so the code will just grow organically to something that no one fully understands. This is the reason I am happy only to use C++ for OS integration or speeding up some algorithms, but not for full stack applications.
I take it you didn't even watch the SOA video?
To me, the main feature of JBlow is being able to abstract the memory layout of data using SOA/AOS annotations. I cannot wait to hear about "How does C++17 solve this problem?", since the reflection proposals aren't even close. The Rust community actually expressed quite a lot of interest in this feature, but no RFC yet.
I watched the full SOA video and I agree with this commenter. C++'s power is in the millions of hours that have been poured into the ecosystem, tooling, debuggers, engines, and more. There are plenty of "better" languages out there aesthetically, syntactically, and feature-wise, but that's not why people choose C++.
Would be great if this had a category for PhD students. They kind of fall inbetween "Full time employee" and "Student". Also, "How many years have you been programming before symptom X started" - would be nice to have a free field there, because the symptoms might result from something else (e.g. gaming ;-) )
No, you don't, at least not according to the standard. `struct` and `class` are interchangable. In practice clang (can) issue a warning if you do so, mainly for the benefit of interoparability with (older) MSVC compilers which did different mangling (and thus different RTTI). AFAIR that has been fixed in recent versions of MSVC 
Exceptions are designed to be used in Exceptional cases. The clue is in the name. If you are worried about the performance impact of an Exceptional case coming up then you've got bigger problems to worry about. If you have a method that can perfectly well succeed or fail, then that's not an Exceptional case, that's a normal case. For example, looking up a user in the database is perfectly reasonable to fail - the user might not exist, for example. In that case, the failure is not Exceptional. However, it's perfectly reasonable to assume that you will be able to connect to the database, and failing to even get a connection is an Exceptional case. That means that throwing an Exception could make a lot more sense than having some return from the function that indicates that the database connection was unavailable.
&gt; [...] They are inherently binary-incompatible. I understand the options, but THIS incompatibility is the extremely annoying part. Why is this so? &gt; What you want is to build your code in release mode (and use release mode libraries), and build your code with debug information (/Zi), but without optimizations. Ow. Nice tip, thanks! But if this is what I want (Release w/o opt), when is it appropriate to use Debug mode at all?
Exceptions should only be used for errors that meet two criteria; a. Uncommon, so having the error handling muddy up the processing code would be unfortunate b. Uncheckable before hand. APIs that can be checked beforehand should just assert. What do I mean by this? - deleting a file and having it fail could be an exception because it's probably rare and it's impossible to check ahead of time if it will fail or not - adding to an array that's full should not be an exception because it's possible to check ahead of time if it will succeed. - parsing user input should not be and exception because it's expected that users will pass bad input. That being said, this one is tricky because it can be convenient to get the stack unwinding feature in a complex parser. But, I still think the parser should work without exceptions if possible. 
Because the automatic stack unwinding feature can be pretty handy. 
A map reduce library that isn't in Java. Oh happiness, oh joy!!! 
The questions about weight and height don't mention which units to use. Should I type the number and the unit (e.g. 185cm)?
It does indeed depend on the context, but there are certain errors that are always to be expected and certain errors that are much more exceptional in nature. The problem is then the big grey area in between. I'd argue that failing to get a connection to the database is only an expected error in the situation where you are doing a healthcheck that the database is there. Outside of that, if the database is missing then the application just doesn't work so that is an exceptional situation. There's loads of situations that fall under exactly that same idea - network missing, disk full, file corruption, etc.
Millions of hours do not make great tools. Beyond visual studio, the tooling is practically non existent. Sure there are some amateur quality things out there, but no better than any other tool that also exists for those "better" languages. Except, they're not better, they're different. JAI is finally the first much better language in almost every respect, not just a few neat improvements over C++.
&gt; To me, the main feature of JBlow is being able to abstract the memory layout of data using SOA/AOS annotations. For me its' not just that. I think his reasoning across the board is sound. For refactorable code - the syntax tweaks matter - and the semantic tweaks handle whats' really important -cache friendliness etc. The generalizing of 'this' allowing you to cut structures up differently without having to refactor everything is a really big deal. In other fields they have many languages to choose from . Why in games, after so many years, are we stuck with just C++ ?
More precisely, there is exactly zero cost on the regular path. If fact, it might be faster than returning error code because you don't have to check at multiple depths for the same error. The exceptional case is way slower, but it should'nt be a concern. The only cost is binary size if you care about it.
Honestly... I'd be willing to bet you could throw 60 times a second and still maintain 60 FPS. Even in the thrown case, exceptions are not _that_ slow. But anyway, I agree with what you're saying. Since it's exceptional, any performance issues it might have in the thrown case isn't important. Exceptions are still fast in the no-throw case though.
Thanks for the feedback, I had originally had it in feet/inches and pounds but was receiving feedback to open it up more generally and others would just provide what is natural for them and I'll covert them all to one unit.
Hmm. Good idea! 
Imagine an application that get data from a lot of sources/databases. These sources are not dedicated to our application, they simply expose an API to get data. A failure to get data from one source is not exceptional at all, but a library may have chosen to represent failure as it was. Because, as you in your comment, the library has expectation as how it will be used. It's ok for one lib, but each of them have to do this choice. It can be very inconvenient for the application writer. Besides, when an application grows the exceptional becomes the norm. network missing, disk full, file corruption are all common errors in some circumstances. That why I think a non-opinionated error mechanism is much better. in other language, an Option/Maybe is really good. in c++, error codes is all that we have.
What about e.g. C#? It also has quite many versions by now. I don't think this is that big of a problem. If a new feature makes something easier in an existing code base, just go ahead and use it (sensibly!). C++17 will still be C++98 as well after all. Minus possibly deprecated features, but those you have to look out for when upgrading compilers anyway.
Not type-safe, a source of UB (dereferences NULL pointer) and ugly. A [native-language support](http://rustbyexample.com/std/result.html) would be much better.
I never said it was ideal. Just that it was possible to achieve something that would work. And no, that code was crap, but it was also written in a few minutes in the comment box on here and not actually in any real projects.
&gt; This makes things crazy verbose. Proper pattern matching make code really beautiful. And Rust also has a good macro system to make things even better. &gt; But avoiding them at all cost is just an, irrational, religious mindset. Most of the irrational religious mindset I see comes from the ones worried about performance. Exceptions have other problems too (in C++, you can easily forget to handle some exception, you're never sure you are handling all errors, cannot easily pass values among threads, doesn't fit nicely in asynchronous code...). If the language has good pattern matching and algebraic data types support, I'd vote on `Result` without a blink. EDIT: Another problem with exception is the question: what should happen when you throw an exception during stack unwinding.
Actually I like constexpr, a feature that they took from D. C++17 will take yet another feature from D, Universal Function Call Syntax (UFCS).
- Compilers: gcc, clang, msvc, icc, ibm xl, oracle... - IDEs: Visual C++, Eclipse, CLion, Codeblocks, Emacs (yes, well configured is very powerful). - GUI libraries: Qt, WxWidgets, FLTK. - Interoperability: LuaBridge, Boost.Python. - Unit testing and Mocking: Boost.Test/Turtle, Google mock, Catch. - Graphics/Multimedia: SDL2 (because, remember, compatible with C), SFML. - JSON/XML: Jsonpp, RapidJson, TinyXml. - Database: SOCI, sqlpp11. - Game engines: Ogre3d to name only one, Crystal Space, Panda3d. - Build tools: CMake, Autotools (yes, autotools work well in non-windows), Meson, Waf, Biicode. - C libraries can be used with C++ easily as well. - IDEs: Visual Studio, CLion, Eclipse, Emacs (yes, well configured is what I use, my favorite). - Tooling: Valgrind, Cppcheck, PVS Studio, gprof, gperf, Eclipse linuxtools project, memory sanitizers integrated in the compiler and mature. Platforms that you can target: Windows, Linux, Mac, Android, iOS and Windows Phone easily. Many others I do not even use, but basically you can run it everywhere, the only language that beats C++ at this is C. Let's not talk about the amount of years the compilers/optimizers have been improved, because there is no contest. About the libraries, everything I mention there is *mature* and *usable*, not amateur projects where you will find too many bugs to be usable or will have to fork. All in all... do you think this can be replaced by a nicer language *only*? This ecosystem can get you very far in getting the job done, more than just a nice syntax, which... is nice, but not enough. You will need a lot of this stuff and a mature compiler. P.S.: I am not against new languages, I just say that catching up is not easy. 
&gt; In other fields they have many languages to choose from . Why in games, after so many years, are we stuck with just C++ ? C++ does the job. Java doesn't, Python doesn't...
Not fully, in all honesty. Lack of time. But will.
Any ETAs for full C++14? It's funny to see, how everyone seems to be excited, to see how Microsoft is deliberately trying to catch up in the compiler game. 
Good call. I like that. 
The biggest problem with C++ all the way up to C++17 is that the standard library is just insufficient and it'd be nice to have a language that had things like intrusive containers and non-global allocators built in.
Can't make promises yet. The compiler is fairly close and the STL is one feature and about a dozen Library Issues away from being 14 complete.
&gt; but it's not universally used (in particular it's not used on Windows). 64-bit Windows took advantage of the forced ABI change to also switch to table-based exception handling.
I'm focusing the team on finishing c++11 right now but to give you a general feel of it.. we only have 3 "no"'s left in the C++14 list: - variable templates: relatively straightforward to implement, no major refactorings necessary. small. - NSDMIs for aggregates: requires some updates to our initialization code paths. medium - generalized constexpr: large :) 
Hey, you can put two spaces at the end of a line before hitting enter and it'll properly show when you post the comment (just learned this myself): - variable templates: relatively straightforward to implement, no major refactorings necessary. small. - NSDMIs for aggregates: requires some updates to our initialization code paths. medium - generalized constexpr: large 
Good luck with the release! I personally switched over to WebStorm but VS is a very fine product.
I am pretty sure all SHA algorithms do that. The implementation of those is also reasonably simple so you won't need a library. 
Why do you need them to be in the standard library? Intrusive containers are here: http://www.boost.org/doc/libs/1_58_0/doc/html/intrusive.html Non global allocators are here: http://www.boost.org/doc/libs/?view=category_Memory
Because I would never use boost even if there was a gun held to my head.
No, they didn't. Stroustroup thought of it first, but as C++ goes through the standarization process, D just implemented it first. I'm talking of constexpr. 
What's the final compiler leg? Relaxed `constexpr`?
&gt; However, the programmer must decide what it means to be exceptional in a given program. ffs, everyone arguing about this needs to read that line. They may or may not be appropriate for a certain situation, but you can't rationally claim exceptions should be avoided at all costs (or used for every line).
It would be interesting to see how much it increases misses. I would naively assume it would be much much less than 20% (if at all).
&gt; Enormous even if you are very careful and only pull in what you need. Do you mean resulting code size? Do you have any references? Are you stripping symbols? Or do you mean source size?
Both libc++ &amp; libstdc++ support the non-standard extension of disabling exceptions. They do that via macro magic. Some functions even change signatures depending on whether exceptions are on or not so as to allow error-handling that would normally be performed via exceptions.
Not sure why you sound surprised, this is just the usual yearly repost of his same tired old project. eg: https://www.reddit.com/r/cpp/comments/1l6a7k/mapreduce_c_library_for_singlemachine_multicore/ Craig Henderson has been posting "his" project around the various MLs for some time now, even once attempted to make a boost submission. 
You don't want to use a cryptographic hash for normal storage. They are purposefully made to be expensive to calculate, which kind of kills the O(1) insertion/lookup you get with a hash table. To OP, your choice of hash/checksum algorithm should be based on that data (you want it to be as cheap and small as possible while minimizing conflicts.). What are you hashing?
Eclipse is for Java, it's C++ is an plugin. CLion was released a couple of weeks ago. Codeblocks, are you serious? Emacs... what? Emacs and (and I'll add vi) are not C++ tools. You've also listed a lot of useless shit up there, and shit that is needed to get around C++'s inadequacies. I'll say it again rephrased, because it you missed it the first time. *Quantity does not equal quality*. JAI is not just a nice syntax, it is a game changer the likes of which you've never seen before. That's why it is easy for C++ zealots to dismiss, because they feel like they've seen it all before in terms of a new language that advocates say is a C++ killer. This will get downvoted as well, but I don't care, because there are real programmers here too that might see it.
thanks!
Map reduce is simply a programming paradigm. It doesn't even have to be parallel. Although it is fairly trivial to parallelize so it's a common model for parallel systems.
It's a "programming paradigm" in about the same sense as a "for loop." The entire point is handling many, many terabyte pieces of data on a cluster of computers. As the term is commonly used it's approximately meaningless on one machine.
Map reduce (single thread, one machine) is part of the built in functionality of many programming languages including Python, Ruby, JavaScript, and just about any functional language you care to name. It's a genetic paradigm that can be used for the single thread implementations I mention above, the massively parallel implementations such as hadoop that you're talking about, as well as for everything in between, including OP's project. In that sense it's exactly like a for loop, which coincidentally can also be parallelized by frameworks such as OpenMP. But you'd never say it doesn't make sense to talk about for loops outside of that parallel context. You've practically made my point for me.
How does that make it less efficient? He doesn't have network overhead, or the overhead of coordinating different boxes, but also doesn't get as many hardware resources as a result. They're different and for different purposes. I don't think you can say it's less efficient just because it's on one machine.
Was counting element operations only the intent? Because *any* *single* operation that finishes (in a finite time) is O(1).
&gt; anything wrapped in a try is immediately subject to overhead. Huh? If you mean code size overhead, perhaps. If you mean instruction overhead, then no.
C++ 17 will have optional and expected, and I am really really hoping that we will be able to use the await operator from the coroutine proposal with optional.
Sorry, you are right in that point, and maybe my statement was unclear. What I meant was, the purpose of MapReduce is not to achieve the highest performance. So on a single machine, there will be other options which are more efficient for multithreaded data processing. And probably more efficient in runtime perf + development resources. I think that when it comes to clusters, its generality has more advantages especially on development.
thank you.
So far what I've seen mostly boils down to "VC++'s exception handling sucks". (The reference to gcc not having zero-overhead exception handling seems likely to be out of date, if ever correct, given the age of the article.) Which hardly surprises me - I really don't know why anyone would be using that compiler where performance was an issue if there was any alternative. There also is a large lack of hard numbers in many of these cases. A lot boils down to cargo-cult programming and the belief that exception handling slows things down since "surely it must be so". The cache is not certain to be affected because if no exceptions are being thrown, that part of the code isn't going to be loaded into the cache in the first place. It may differ depending on the size of functions, etc. but it's not a hard rule.
It's useful in that things like vector reallocation can be said to be O(N) even though it might be a vector of vectors.
Module system mentioned there is very great! Please, add them in C++17
&gt; feet/inches and pounds &gt; studying
I follow C++ since 1994 and never saw a reference to it.
FPGAs are just ASIC prototype tools. They are not faster currently than a well carved C++ binary - only for very small logic where eg you send a simple order over UDP (eg Nasdaq UFO) upon receiving a multicast packet (eg Nasdaq TotalView). But they are very good for problems that can be parallelized - same for CUDA/Tesla as well. [Reasons to avoid FPGAs](https://www.linkedin.com/pulse/14-reasons-avoid-fpgas-henrique-bucher) 
This is at best misleading at worst off-topic. So you allocate memory, and you are out of it, so you fail hard? Why not throw an exception? abort( -1 ) and throw bad_alloc have more or less the same outcome and you pay no runtime cost (*) for either. For the bad_alloc you get the point where the exception was thrown from when you have a debugger attached, otherwise you get a callstack from windows in the crash dump. In the abort/assert case you have to roll your own. If your safe file is corrupted, your idea is to fail hard, because you could loose frames in the load screen? Before or after your game crashed? The idea of exceptions is to not throw each frame, but to throw on exceptional states which either cannot be handled or should trigger some form of reset. Examples: * So your multiplayer game lost connection to the server after some timeout? Why not throw an exception so that the main loop can show some information and return to the Main Menu. * So your display adapter was reset and you do find out? Why not return to the Main Menu and reset your graphics engine? Maybe even save the progress of the player into a separate save file? * So your 1 on 1 multiplayer game discovers the opponent is cheating? Really abort? Or check each run through the main loop? * So while loading a level, a texture/config/... file cannot be opened? Why not throw and tell the user that this file is corrupted. Each of these can be explained away. And there may, in your concrete circumstances, be better ways to handle this, but really? Out of hand denying any viability of exceptions for exceptional purposes even though they do not harm runtime performance when not thrown? (*) Yeah, I know, not under Windows x86, but on Windows x64/Linux/etc not throwing is free (**) Note: Binary size may get larger, but this will/should not have an impact on hot-code-path length.
As a user, I avoid using programs which depend on boost. It is just too big to keep on my SSD... So as a developer I think twice before using it.
* **TurboPFor: Fastest Integer Compression** - **Direct Access** w/o decompression - Fastest **Variable Byte** implementation - Novel **Variable Simple** faster than simple16, better than simple8-b - Scalar **Bit Packing** decoding as fast as SIMD-Packing - Bit Packing incl. **Direct Access/Update** w/ zero decompression - Fastest and most efficient **SIMD Bit Packing** - Fastest SIMD-**Elias Fano** implementation - Novel **TurboPFor** (PFor/PForDelta) with direct access or bulk decoding More efficient than **ANY** other "integer compression" scheme. ---------------------------------------------------------------------------------- * **Inverted Index + Intersections** - Novel **Intersections w/ skip intervals**, decompress the min. #blocks - **2000!** queries /sec on GOV2 (25 MB docid) on a **SINGLE** core - **Parallel Query Processing** on Multicores. **7000!** queries/sec, **quad** core CPU
Do you have the performance target? If yes, did you compare it with performance using operator&lt; as compare function? If yes, what's the difference between expected and achieved and did you try to improve the performance of operator&lt;? ;-)
hmmmm .... how about a BIG data to be processed on a single CPU !??? a naive implementation will hit VM on first new [1GB] :D and things go to oblivion while mapreduce technique will allow you to partetion the task in relation to your available RAM.
can you step in ? and if yes in the next lambda or somewhere deep into the underlying state-machine :))
do you have a description somewhere how "turbopfor" works and how your work compares to the FastPfor library and why you are faster? also: does SIMD elias-fano just refer to bit-(un)packing the lower parts with SIMD + the scan operation on high? 
&gt; Type traits transformations were augmented by alias templates in C++14, and not advisable to keep on using. There is still useful cases to have lazy-based transformations traits(aka metafunctions), especially when using conditionals or when doing specializations. So alias templates have not surpassed metafunctions, it just made its usage much less. There is room for both in C++. 
Lock-free DS are so much easier to implement in garbage collected languages than in C++. A good memory reclamation scheme (that you need to add yourself, for example [Hazard Pointers](http://en.wikipedia.org/wiki/Hazard_pointer)) is crucial for the performance of unbounded lock-free DS and is certainly going to be the hardest part of porting.
Unless you can provide more precise citation from that report, it isn't saying what you are claiming. But yes, the exception handling overhead in 32-bit Windows is well known and annoying (MS once again ruins things for everyone), but I find it hard to believe that XBox One's EH has regressed back to 32-bit Windows.
Assuming no exceptions thrown? ~0%. Modern EH is all about penalizing throwing exception to improve the non-exceptional cases.
* The **"TurboPFor" function** is fixed BitPacking for the values and exceptions + flags bitmap indicating an exception. Very good compression and speed + direct access. In my experiments it is more efficient than any other FAST "integer compression" scheme incl. elias fano. * **TurboPFor vs. FastPFor:** - Well, you can't compare the speed without considering the compression ratio. This is why I'm sorting the benchmarks by compression size. - The **"FastPFor" function** has a major drawback, it can only encode/decode large arrays (default 64K) efficiently, resulting in decoding entire blocks, even if you need a single value. The standard block size used for PFor/PFordelta is 128 bytes (see lucene and others). The default block size for **"TurboPFor function"** is 128, TurboPFor compress better than FastPfor and direct access is possible. Unfortunately there is no c-implementation of the "FastPFor function" to include in the benchmark. * Scalar **variable byte "TurboVbyte"** is faster and more efficient than "VByteFPF" in FastPFor-library. It is even faster and more efficient than the new **SIMD [MaskedVbyte](http://engineering.indeed.com/blog/2015/03/vectorized-vbyte-decoding-high-performance-vector-instructions/)**. - **"TurboPack"** scalar bitpacking is faster than any scalar bitpacking and direct access is possible. - **"TurboPackV"** SIMD bitpacking is faster, bitunpack speed is same, but TurboPackV is more efficient on delta encoded integer lists (like docids in inverted index). * **Elias-Fano**: yes, SIMD bitpack/bitunpack is used only for the lower parts, but the higher part is also accessed efficiently using the ctz function. This is the first and only implementation that beats "OptPFD" in decoding speed.
The most important advantage that C++ has over C is clearly RAII. Aside from that there are still tons of things like templates, classes, …
Destructors.
Basically from what I understand he wants to give a function pointer and have it inlined which no compiler will optimize (or at least I wouldn'd expect it unless maybe in some trivial cases.) He needs a refresher on lambdas, std::function, function pointers, functors, and the rules of inlining.
A seriously underestimated feature. So much of what we do in modern C++ depends on destructors.
Designing a language that ticks all the boxes for game dev is *hard*. So far Rust seems to be the only one that really comes even remotely close besides C++.
Beyond exceptions leading to ugly code, the reality is people use them everywhere. They are in fact an ugly solution to simply checking for the state of a resource. The fact is exceptions are often abused and as such that can lead to lower performance. If they where used as you suggest, to handle exceptional situations, you might get some support. Frankly I'm hoping the world of language development moves away from C++ style exception handling. 
For now I must say that C++ is my favourite programming language.
Title Edit: Better Code Concurrency
Well, executing step into will go into a function call or step to the next statement or step out (depending on if there actually is anything to step into), just like normal. Stepping out will put you somewhere in the internals of Linq, like the implementation of `Where()` or ` Select()`, to stick with my example. So, if we change the lambda inside my `Where()` to something like `x =&gt; IsFrobbed(x) &amp;&amp; IsBazzed(x)`, step into will go to `IsFrobbed()`.
What you're saying doesn't even make sense. Both the assertion &amp; exception throwing happen in the exact same way: inlined branch check &amp; a call to a function. Whether that function throws or aborts() is an implementation detail. Your icache will not have more or fewer misses. If you have an assert in a tight-loop, it's just as bad an idea. I think you're also conflating my points. I had 2 that are orthogonal to each other: 1. assertions should be always on 2. it's a better idea to throw than abort(). The first one ensures you have good test coverage however you build; it's difficult to test debug &amp; not a good idea because it's not what the end-user will be running. Yes there are runtime implications; you can address them the same as you would with anything by profiling &amp; optimizing the code. Rarely is putting an assertion in a tight-loop a good idea. On the off-chance you need to and have no choice, then yes, use a version of your assertion that can get compiled-out. The second point is a stylistic one &amp; has no runtime implications if you're already using exceptions &amp; probably no real ones if you're not (you can always write your code with &amp; without exceptions &amp; run with exceptions on until you ship). The advantage of using exceptions is that you can write tests to exercise that your assertions are correct (negative tests are important). Tests that abort() typically take down the entire test runner in many unit test frameworks (gtest, boost::test, XCTest etc) unless you run each test in a separate process.
I don't think its hard in itself - IMO it would only take a few changes to C++; I think its hard to get people to agree on an alternative (Rust was promising, but I totally understand why jonathan blow started. The priorities for gamedev are different, and the Rust team have a clear niche that didn't want these tweaks)
Yep. Made possible by RAII idioms. 
`}` would be useless without `{`.
C11 introduced type generic expressions that make this a *bit* better in C, though not as convenient or powerful as C++.
.. but but [Destructors Considered Harmful]( http://www.drdobbs.com/cpp/destructors-considered-harmful/232300573) by By Andrew Koenig, January 08, 2012
The meaning of `}` in C++ is radically different than in C, i.e. destructors get called and RAII is enabled. 
That problem is confined to cases in which you use a destructor to delete a bare member pointer or otherwise improperly implement copy/move semantics for a class that owns a resource. The suggested solution of using a shared pointer relies on the fact that said shared pointer decrements its reference count each time its destructor is called. Without destructors you'd have to explicitly increment and decrement the reference count whenever you want to take ownership of the pointer - which has its use cases, but that's beside the point. Destructors are extremely useful and give you explicit control (which is what C++ is all about!) over what happens when an object goes out of scope or is deleted.
You are very convincing. I'll use both of these things probably
I haven't touched C for a long time, but I really like C++'s implementation of polymorphism and inheritance. I also really like C++'s lambda expressions: static auto myFunction = [&amp;](std::string text) -&gt; void { std::cout &lt;&lt; text &lt;&lt; std::endl; };
Everything else listed. But, a big feature I like that hasnt been mentioned is easy information hiding. You hack around it various ways in C, but C++ was built to do it. Polymorphic dispatch can pretty useful in small doses also. Early on it was the hammer that hit all nails and screws, but nowadays its used less, but at critical times. 
lambda's 
This is the real one for me, because it prevents having good data structures sometimes. You have to reinvent them with macros, but that can be frustrating. 
I think the most simple and obvious feature is being able to give structs member functions.
All of them...sorry! 
&gt; Destructors Considered Harmful I think there's a flaw in that article in that his proposed solution also depends on destructors, just the destructor in the shared_ptr.
This demo does nothing that a plain function definition wouldn't... might be more instructive if you showed something with an interesting capture or return type deduction
RAII.
You may still want to do some logging in the destructor. The correct solution is to use the [rule of zero](http://flamingdangerzone.com/cxx11/rule-of-zero/).
Not sure if /u/donvito meant this, but C++ community is much larger.
That's source, including everything optional... Here's are *all* of the libs (11Mb): https://www.archlinux.org/packages/extra/x86_64/boost-libs/ That's all your binary needs. If they're compiling from source...well that's silly to complain about.
I mean if we're going to be pedantic, `{` means the same thing in C and C++. Both languages introduce a new scope and RAII is not enabled by `{`. RAII is initiated by explicitly invoking a constructor, regardless of whether there is a `{` involved or not. In other words, creating a scope does not call constructors, it doesn't call or do anything. Closing a scope, on the other hand, does implicitly invoke destructors, which is different from C.
...well yeah. What, in a driving game, just throw YouHitAWallException()? That's not what exception are for. Maybe "the socket just died" or "this file I need is missing".
Namespaces
&gt;macros Say what?
Why stop at OOP? Functional programming, Generic programming...
I'd also like to add that with RAII, resources are released when a destructor is invoked, whether a `}` is involved or not. For instance, when a program terminates any objects in the global scope have their destructors called.
Gonna throw type-safe variadic functions into the mix.
And less full of hipsters
So, you're saying don't use C++ like it's C? Interesting...
Absolutely! Modern C++ has facilities for all of those wonderful paradigms. I just focused on OOP because that is the roots of C++. It was originally conceived as "C with Classes," and learning OOP was the journey I took when moving from C to C++. That certainly doesn't make it the only path you can take. I mean, without that foundation learning generic programming would've been a little mind-bending for me but maybe OP already has that coming from Rust.
* RAII * Variadic templates * Lambdas
Definintely RAII. Honorable mentions: type safety, templates and exceptions. My advice is try not to use C++ like a C programmer, but embrace the new language constructs and learn how to use them (and not to use them). Make sure you understand how advanced language constructs works (virtual classes uses vtables, templates are instantiated, etc.). You probably be delighted that a lot of the features are powerful stuff and have no runtime-costs. Also, get familiar with STL (the C++ standard library).
Meh, I guess it's bold to be dismissive of *hipsters*, but it's nice to see a new native, performance oriented language that appeals to a modern generation of developers even if that means appealing to hipsters. Learning C++ today is a huge chore plagued with legalese, having encyclopedic knowledge of the standard, and involves too many idiosyncrasies. Seeing a new language that intends to be in the same domain as C++ but appeal to people who would otherwise learn C# or various web-oriented scripting languages is promising.
At the moment you're still better off with a c-compatible struct of function pointers due to C++ not having a stable ABI.
I agree. Any one feature by itself is only so good, but it is the way that many of them work together that makes C++ what it is. I don’t know that I’ve ever wished that another language had only one feature of C++.
/u/Dragdu wrote: &gt;&gt; it is a game changer the likes of which you've never seen before. &gt; Riiiiight. Would you like to buy this bridge over here? Just keeping this here for when you delete it after JAI beats C++ for game development.
For me the oposite is true. Like, do i _really_ not have to release that?
The header file works regardless of the OS. That header (*.h) extension is not a "Windows" extension. It basically works on all OSes. Thus, you already have the file you need. :) http://www.stroustrup.com/Programming/std_lib_facilities.h
namespaces + ADL
and more full of blowhards
Java has all of those and so does objective c?
All these comments and only one person mentioned exceptions.
Maybe not for XBox, but ICC is definitely an alternative for Windows apps. There's also mingw.
Operator overloading. Since when doing physics, it's nicer to type: vt = v0 + V*t + 0.5*g*t*t; when v0, V, vt and g are vectors with 3 components. Likewise, for 3D graphics, its nice to do: Pos = M*V; where M is a 16 element matrix, and v is a 3/4 element vector 
actually, sutter i think had a say about that (i don't remember the article exactly) but the idea was that you should specifically declare everyone (rule of 5) and set them as =default. then logging in the destructor is perfectly ok. 
Unfortunately my reply will be buried in the middle of a bunch of other stuff. This couldn't be more true if you tried. [Stroupstrup himself agrees -- see second page](http://www.stroustrup.com/CVu263interview.pdf): &gt; A lot is said about elegant code these days. What is the most elegant code you’ve seen? And how do you define what elegant code is? &gt;&gt; I’d say that one of the best answers I’ve seen for what makes elegant code, is something I’ve read from ACCU’s own Roger Orr: } Just that closing brace. Here is where all the ‘magic’ happens in C++. Variables get destroyed, memory gets released, locks get freed, files get closed, names from outside the closed scope regain their meaning, etc. This is where C++ most significantly differs from other languages. It is interesting to see how destructors – an invention (together with constructors) from the first week or so of C++ – have increased in importance over the years. So many of the modern and most effective C++ techniques critically depend on them. 
Didn't GCC recently break ABI compatibility?
Not with respect to virtual functions. GCC 5 comes with a flag that preserves all ABI compatibility with the 4.xx series, and a flag that breaks it with respect to some stuff (to conform to C++11 requirements such as `std::string`) But class layout, virtual tables, RTTI, dynamic dispatching and a host of related issues have preserved compatibility for over a decade and can be found here: http://mentorembedded.github.io/cxx-abi/abi.html
It's actually a digraph, &lt;: , part of c++17...
References cannot be null. Null is a value taken on by pointers, which references are not. If you're referring to the classic silly example of dereferencing null, then you have not created a reference to null, you've created UB; reasoning about the state of your program afterward is meaningless.
Yeah, I think the object thing is gonna be the most difficult for me. I love a lot of ideas that C++ uses: RAII, for example, or templates (that's probably my favorite). But objects... I'm pretty scared for.
It's a digraph, `&lt;:` is `[`, but this hasn't been a problem since C++11 when [they added a special rule in the lexer to handle this particular case](http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_defects.html#1104).
I'd like to avoid that. Preferring one group of people over another one is highly subjective (I guess it can't get more subjective than that). I just 'resonate' better with the people in the cpp community. But that doesn't mean that the cpp community is "better" and the Rust one is "worse".
Can you elaborate? In my data structures class we just defined TYPE in a separate file. 
I will try to keep the list short: Templates combined with lambdas and RAII. Vs Rust: Template specialization and true overloading. Very useful in generic code.
&gt; well-defined construction and destruction times and orders, I mostly agree with this, but they did drop the ball with global initialization ordering. 
Constructors are nice, but it'd be amazing if they also added tagged initialization syntax from C99. Sometimes a struct is just a struct. 
error: expected declaration before '}' token
Classes and overloading.
That really depends on the components of Qt he uses. I don't think there are good alternatives to Qt for creating GUI desktop applications. But for stuff like networking or multiprocessing, file i/o, there are plenty of alternatives. Qt's GUI components are so good that Qt seems to be the primary GUI toolkit for python.
Tedious but more readable. 
I don't think I bundled debug libraries but it was long time ago so I maybe I forgot, my project depended on the Qt's webkit wrapper which drags a lot of dependencies. 
Favorite features over C: - stronger type checking - STL replacements for strings and vectors - reference parameters instead of relying in possible invalid pointers - iostreams (Yes I do like their composition capabilities) - stronger type enumerations - namespaces (no longer primitive common prefixes) - struct names and typedefs on the same namespace - overloading (operators and functions) - type safe generic code - RAII So anything that brings C++ closer to Ada/Pascal safety, plus some convenience features. C++ favorite features over other languages. - Modern C++ is a bit like Haskell with curly brackets (I know this is stretching the example a bit too much, though) - Tooling. While not as great as Java/.NET, the available IDE and graphical debuggers still rock vs other languages. C++ features I dislike: - C copy-paste compatibility, the cause of many C++ warts and makes it as unsafe, unless care is taken to use STL collections and modern C++ constructs. - C mentality in many libraries, which prevents rich frameworks like what JVM and .NET worlds have to prosper. Only Qt, WinRT, and VCL come close to it. - Lack of modules. (Hopefully this will be fixed in C++17) However nowadays I seldom write full stack applications in C++. For me it has become a library language, e.g. libraries that are then called by JVM, .NET, QML code. Usually for portable code or OS integration.
const. const references, const parameters, const member functions. I'd like to be able to declare const classes - instead I have to resort to a pimpl variant to achieve this.
That's my bread and butter: g++ -ggdb2 -O3 testMe.cpp -o testMe objdump -SCt testMe | less 
These may have been mentioned before, but: - RAII - Strong typing - Templates &amp; compile-time polymorphism - STL - Lambdas
Ouch! I don't know why you quote "his" as if it isn't mine - it is mine. And, I didn't submit it to boost, but it did live in the boost sandbox initially.
&gt; This is in contrast to languages that do actually provide such guarantees, like Rust. In Rust, one can not assign a null pointer to a reference in safe code, Rust's type system guarantees that such a thing will never happen, furthermore one can not access an array out of bounds in safe code. In languages with stronger type systems, things which are not permissible in C++ becomes not possible. Could you take a reference and then destroy the underlying object in rust? That's the one way where I think one can fuck up with references in C++, because *deliberately* creating a reference to null is just silly and falls under the "don't point your loaded gun at people"-rule. 
Sorry, I'm going to be one of *those guys*, but someone has to be the douche. C and C++ are syntactically similar, but two completely different languages. The approach to solving any non-trivial problem in any of the two languages will (and should) differ wildly. Singling out a single feature between two languages that are fundamentally different (as in, how you approach software development) is hard to do and not very constructive. I'm saying this because you're approaching this shift the wrong way. It's very cool that you want to learn C++, it's an awesome language. However, please approach it as a completely new language, instead of comparing it with C or trying to single out certain features. Just be happy that some of the syntax will be familiar to you.
Since you mentioned Physics: SI-Unit template classes. Write it once, never make conversion error again. Ever.
Library != core language.
Not having to see: char *p = (char *)malloc(50 * sizeof(char)); when reading questions on the internet. All the unnecessary repetition and redundancy makes me rage insanely. It's bad in both languages of course but in C++ there are fewer people who do it. Of course, `char *p = new char[50];` is also rage-inducing but not on the same level. 
Just calling fooWithReference(*some_ptr) can cause an invalid reference. This however leaves the error on the callers side and more code using references means less code that could introduce a NULL where none should be. 
Doesn't C++ require pimpl though? That requires heap allocation internally.
Even better would be `char *p = malloc(50);`. Simple and clear.
but why not just use c#. It interops very well with C++. I say this not knowing much about Rust (I just joined this conversation, not OP)
No, in Rust's safe code, an object can only be destroyed if it is uniquely owned.
***Value semantics!!!***
Can you explain how it doesn't answer your question? You asked if something was possible, I said the conditions under which it wasn't possible and the reason why it wasn't possible under those conditions. Seems like the question is answered to me. In unsafe Rust there are no guarantees about the correctness of any operation.
Is the below something that should work at this point? It compiles fine but crashes at runtime, in both the RC and the version that's up at http://webcompiler.cloudapp.net/. #include &lt;iostream&gt; struct foo { int bar(int x) { return x; } }; template&lt;typename T&gt; struct traits { static constexpr auto bar = &amp;T::bar; }; int main() { foo x; std::cout &lt;&lt; (x.*traits&lt;foo&gt;::bar)(15) &lt;&lt; std::endl; }
In unsafe Rust you can do what you mentioned, and no guarantees are made about the validity of pointers or dereferencing. Unsafe Rust is basically like C++. In safe Rust, only things that are uniquely owned can be destroyed.
Okay, I think I understand. Would you use this if you wanted to use the data structure for multiple data types in the same program, then? Probably as a matter of convenience, too. 
The conversions perform perfectly well in other situations. It's the conditional operator that implements rules that depart unsafely from any other reasonable way of implementing the same intent. The conditional operator would be intuitive and safe if its behavior was identical to this lambda: [&amp;]() -&gt; T { if (EXPR) return (A); return (B); } The reason the behavior is unsafe is because *the developer does not expect it*. It's because the rules for this operator are unsafe. In the template example I show, the following would not compile: return Cond(h, *h, Light()); You have to explicitly specify the type: return Cond&lt;Light&gt;(h, *h, Light()); This is correct. The compiler complains - and should complain - that there are two ambiguous paths, so it doesn't know if T should be *Heavy* or *Light*. In the case of the conditional operator, it just goes ahead with *Heavy*, despite the ambiguity. No warning, no error. Note that if I simply turn the operands around: return !h ? Light() : *h; Then the compiler decides the result type should be *Light*, and the code works okay.
I've been using Boost.Log and found it OK; I haven't pushed it too far yet, but it's worked for everything I've tried so far. But the docs show it has support for stuff I haven't used in anger yet, so it should fit our future needs as well. It is more complex than others, but the macros for logging keep it manageable. I did look at glog, but it was too simple and the source had worrying comments about the state of its support for Windows (I needed it to work on Linux/MacOSX as well).
Sure... void g(int*&amp; x) { delete x; x = nullptr; } void f(const int&amp; x) { std::cout &lt;&lt; x &lt;&lt; std::endl; } int* x = new int(5); f(*x); // Well defined. g(x); // Well defined. f(*x); // Undefined. &gt;Generally, you can pass by value, reference, or pointer in C++. You can only pass by reference or by value. Passing a pointer into a function is passing by value. &gt;If you pass by pointer, it won't be copied but dereferenced when needed (and perhaps cached, which is why we have volatile). If you pass a pointer into a function, the value of that pointer gets copied into the function. &gt;If you pass by a constant reference the compiler would be able to choose if it uses a reference No choice can be made by the compiler. If you pass by const reference then no copy is permissible. A copy involves invoking an object's copy constructor, producing a new and unique object which implies its own unique address. void f(const int&amp; x) { std::cout &lt;&lt; &amp;x &lt;&lt; std::endl; } int x = 5; std::cout &lt;&lt; &amp;x &lt;&lt; std::endl; f(x); The above snippet of code **must** output the exact same address twice. No copy is allowed.
&gt; The main reason why we post our articles to medium as we believe that the medium post appearance is better then ours. Next time just be straight forward with the disclaimer. In this post it is at the very end in and in small font. Next time just put it at the very top, big, and add some wording: &gt; Disclaimer: this is a post about PVSStudio and I am one of its main developers so weight everything I say accordingly. Enjoy! This would be enough to help me put the post in the right context. It would also help if you guys would submit the posts from a single URL. There was already a submission of this post yesterday in a different subreddit that is not under "other discussions" because it has a different URL. http://www.reddit.com/r/netsec/comments/38isgf/static_analysis_of_wireshark_by_pvsstudio/
I don't get it... See my code at http://ideone.com/Wu6WJj Firstly, your example as stated doesn't compile. Secondly, (once it does compile) it doesn't do anything I would regard as unreasonable. Thirdly, &gt; The C++ standardization body wishes you a happy stack corruption! ... seems to be completely unjustified. I don't see stack corruption anywhere in this code. Unless I'm just being dense...
You are mistaken in your belief that the compiler can optimize better when using a reference-to-const. Reference-to-const exists for the programmer only.
It doesn't make any sense to reason about what happens after UB has taken place. The same logic you gave could be used to say that "std::vector&lt;int&gt; v(10);" is not safe because you could have previously corrupted the stack.
It's better to give links to the playlists. [Dive into C++11/14 ](https://www.youtube.com/playlist?list=PLTEcWGdSiQenl4YRPvSqW7UPC6SiGNN7e) [Bo Qian's playlists](https://www.youtube.com/user/BoQianTheProgrammer/playlists)
There's an active VC compiler bug in this area, which I filed as DevDiv#553676 "If you want a picture of the future, imagine a conditional operator stamping on a human face - forever." (Yes, that's actually the title.)
But doesn't this assume two's complement, which isn't guaranteed by the standard?
You are correct. I assumed the behavior implemented by Visual Studio is standards-compliant - which it may in fact be - but GCC refuses to accept the code (it produces the exact error I would expect). I have made edits to the post and title accordingly. I unfortunately cannot fix the reddit title. &gt; I don't see stack corruption anywhere in this code. Unless I'm just being dense... It depends on how Light and Heavy are implemented. If data in Heavy is stored within the object, and if Light allows modification of data it references, then such modification would be performed on the (now destroyed) temporary Heavy object, which was allocated on stack. This would definitely result in stack corruption. In this setup, the DataOrDefault function would also take a non-const Heavy pointer. At the very least, the behavior you get is reading of freed heap memory (if data in Heavy is heap-allocated, and Light provides a const reference to it).
&gt; All one can say is that if one assigns a null pointer to a reference, that the behavior of the program is unpredictable. I don't know why you are using the word unpredictable in addition to undefined, but otherwise I agree with this statement. The difference between C# and C++ is that in C# _every_ variable of reference type is essentially a nullable pointer, this makes it much harder to reason about the validity of variables. In C++ it's just the things that could cause UB that you have to worry about (although I admit the consequences of UB are worse than a NPE). This function is easier to reason about in C++ than the C# equivalent: void Foo(Bar const &amp;bar, std::string const &amp;message) { ... } because in C# have to worry about whether any of the arguments are allowed to be null. EDIT: and if the C# function does _not_ allow null then Foo(bar, null); is not a compile error and Foo(bar, GetMessage()); where GetMessage may return null is not either. In this way it is more than just documentation, it is actually part of the type system. That pointer is an unsafe abstraction has nothing to do with references.
Exactly. In the background, C++ is just creating repeated instances of your object with the template class replaced by whichever class you use in your code. So if I have my object declared for an int and float at some point in my code, the object definition is repeated for each of those types. However, templates should be instantiated in header files: https://stackoverflow.com/questions/5612791/c-template-and-header-files
Yes, thank you.
I am not mistaken, what you are referring to is known in the standard as a non-normative clause. Such non-normative clauses are not meant to formally define the semantics of C++ but rather as a note to provide some informal context for compiler developers or users of C++ certain expectations. These notes often contains inconsistencies and errors... The specific clause that you cite is known to technically be incorrect, a fact that can be reviewed at the following site where such defects are reported on and discussed: http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_active.html#232 Some relevant passages: &gt;232. Is indirection through a null pointer undefined behavior? &gt;At least a couple of places in the IS state that indirection through a null pointer produces undefined behavior: 1.9 [intro.execution] paragraph 4 gives "dereferencing the null pointer" as an example of undefined behavior, and 8.3.2 [dcl.ref] paragraph 4 (in a note) **uses this supposedly undefined behavior as justification for the nonexistence of "null references."** &gt;However, 5.3.1 [expr.unary.op] paragraph 1, which describes the unary "*" operator, does not say that the behavior is undefined if the operand is a null pointer, as one might expect. Furthermore, at least one passage gives dereferencing a null pointer well-defined behavior: 5.2.8 [expr.typeid] paragraph 2 says &gt;If the lvalue expression is obtained by applying the unary * operator to a pointer and the pointer is a null pointer value (4.10 [conv.ptr]), the typeid expression throws the bad_typeid exception (18.7.3 [bad.typeid]). &gt;This is inconsistent and should be cleaned up. What follows is a discussion among members of the C++ committee which clarify that that particular non-normative note is incorrect, and their resolution to this issue is... and I quote: &gt;We agreed that the approach in the standard seems okay: p = 0; *p; is not inherently an error. An lvalue-to-rvalue conversion would give it undefined behavior. Note that no lvalue to rvalue conversion occurs when assigning an lvalue to a reference and hence it is in fact legal to have a reference to a null value, it is only the conversion of that value to an rvalue that produces undefined behavior.
Read the rest of the discussion. What you've said is incorrect and I and others have explained like 5 times in detail. Even when no exceptions are being thrown, there is overhead. It really can't be explained, quoted, and shown anymore than it has. Also, no one anywhere in this thread is 'denying any viability of exception handling'. Making stuff up at that point. Handling whether you can allocate memory or not with exception handling is a gigantic NOOOOOOOO in particular. You pretty much used a scenario that is worst case usage. I also mentioned elsewhere network code scenarios like establishing a connection maaay be scenarios where you can, I myself have, but primarily because they are fire once scenarios while the majority of conversation regarding rendering or game logic or most memory managenent scenarios are not. Again, just read the conversations and sources. Also, you mentioning loading a level. Sorry but no, if a level throws an exception when loading, it shouldn't load at all. When at production and release level, that scenario should never ever occur. And if it does, fail hard. You can't have players loading the game differently because one guy had an exception. The rule is everyone has the same game running. Game software is entirely different from common desktop software in that things like... file read exceptions can't occur. Out of memory scenarios should never ever occur. Ever. Period. No debating. And if it does, then something is horribly amiss that shouldn't be attempted to recover. Which, going back to memory allocation, is the same time thing. Many teams have people dedicated to hand tracking how much memory is allocated - every class, every alloc call recorded. Those people will strictly enforce what can or can't be allocated in code. A game on one person's system should not be using more memory than someone else's running the same code than the known maximum unless its explicit in configuration. If you have more RAM and VRAM in your machine, and I as the game programmer know that is a scenario and will provide you that option to enable more allocation than other people can have for... prettier particles or higher resolution textures or something. You *do not handle that with exceptions.* That makes no sense at all, you're not even using exceptions properly in that scenario *anyway*. That's not what they're intended for. Hell, you can't possibly do that on console systems anyway. If you hit a scenario where you're trying to allocate more memory and the programmers have not intended this allocation, then the whole system needs to stop because something uncontrollable is amiss. No exception is going to help you. 
See http://www.open-std.org/jtc1/sc22/wg21/docs/cwg_active.html#453
Yes that is correct, and a pointer to null points to what is referred to as an empty object. Empty objects are still a valid objects (object in C++ means something different than in say Java) just like a null pointer is still a valid pointer. You may not convert an empty object from an lvalue to an rvalue, but that does not mean that the empty object itself is invalid. In fact, the very proposal you cite is to change the language so that references can not refer to empty objects, because as things currently stand, they can.
Exceptions are excellent for some purposes. The problem people have with them is they make thinking about your program harder. But if that's your primary problem then you shouldn't be using C++ in the first place. If you want Go, you know where to find it. Also, I like Go, though I love C++, so there.
An object in C++ has a type, storage, storage duration and a lifetime[1]. There is no such thing as an empty object in the standard. I believe you are thinking of an "empty lvalue", which is something introduced in #232, but is not currently part of the standard. And even then, #232 is coupled with #453, which removes the "A reference shall be initialized to refer to a valid object or function." language, but then disallows null references using different wording. [1] http://eel.is/c++draft/intro.object EDIT: Fixed citation added
If you feed it slightly broken code, it triggers an internal compiler error: Here it is using s instead of *s for ternary #include &lt;iostream&gt; constexpr int hash_that_string(const char* s){ return s ? hash_that_string(s+1) + *s : 0; } template&lt;int T&gt; struct Thing{ void print(){ std::cout &lt;&lt; T; } }; int main() { Thing&lt;hash_that_string("stl")&gt; sad; sad.print(); } Result is: Compiled with /EHsc /nologo /W4 main.cpp main.cpp(16): fatal error C1001: An internal error has occurred in the compiler. (compiler file 's:\dd\feature\wcfb01\src\vctools\compiler\cxxfe\sl\p1\c\constexpr.cpp', line 4557)Compiled with /EHsc /nologo /W4 
Templates are the new duck typing. template&lt;class D&gt; void likeADuck(D duck) { duck.quack(); }
Thanks, reduced and filed as DevDiv#1184213 "constexpr.cpp 4607 ICE triggered by "ptr ? 3 : 4" in a constexpr function". (The line number is different in our current development build.) This is actually an ICE-on-valid.
Bo's vids are excellent. Just wish he keep making new ones about C++.
An empty lvalue is an empty object. All lvalues refer are objects, including this lvalue `*static_cast&lt;int*&gt;(nullptr)` which is an object and in and of itself perfectly valid, the object however is empty. I'll be honest, at this point I don't even know what this discussion is even about or what the point is. I'll leave you to have the last word.
"Simple C++: Featuring Robodog and the Profound Object-Oriented Programming Method " by Jeffrey M. Cogswell? Never read it. Just did a GS.
If you're interested in the subject, I recommend "The Art of Multiprocessor Programming" by Maurice Hearlihy &amp; Nir Shavit. It is an excellent, in-depth text that really delves deeply into the subject. Beware! Not for the faint of heart.
Your google foo is better than mine. Yes, this is the book. Thank you. 
Mad google skillz! Yw. For reference: "c++ book object oriented robot example"
I don't know modern C++ very well, but this video is pretty cool. C++ is becoming D with a slight "more confusing" syntax.
A side effect of C culture in the language that shifts all worthwhile libraries into POSIX, instead of the language standard. 
Good to see the concurrency stuff is making strong progress.
In the author's example, std::function could be avoided entirely by taking advantage of the fact that a stateless lambda will degrade into a function pointer. using fp = int(*)(int); // Define the function pointer std::vector&lt;fp&gt; v1; v1.emplace_back([](int n) { return n + __COUNTER__; }); It would be interesting to see how this example compares to those using std::function.
That clang++ chokes with minor optimization is indeed baffling. It means little for the run time performance, but that compile time skyrockets to 5+ minutes is hard to comprehend.
Exciting times indeed. I wonder what SG14 (Game Development &amp; Low-Latency Applications) will produce? RTTI and exceptions are mentioned but perhaps they'll also look at pulling in some aspects of EASTL as well? Something to keep an eye on certainly.
Now if only I knew what SDP was. It's not mentioned anywhere on the page... [This](https://www.google.com/search?q=microsoft+sdp&amp;oq=microsoft+sdp&amp;aqs=chrome..69i57j0l5.2007j0j4&amp;sourceid=chrome&amp;es_sm=122&amp;ie=UTF-8#) is as unhelpful as [this](https://www.google.com/search?q=microsoft+sdp&amp;oq=microsoft+sdp&amp;aqs=chrome..69i57j0l5.2007j0j4&amp;sourceid=chrome&amp;es_sm=122&amp;ie=UTF-8#q=sdp+conference) :\
&gt; I assumed the behavior implemented by Visual Studio is standards-compliant Thanks for the laugh.
How to setup SDL2 core framework 
&gt;"I am ashamed to admit, that I have not been able to understand and successfully apply std::enable_if yet." &gt;&gt; I recommend against attempting to teach something to people before understanding the basics. Thanks for providing a clear example of a use for enable_if. I wanted to clearly point out that I didn't understand enable_if well enough beyond naming it as a technique that is built with the concepts of SFINAE. That's also why this is an entry that describes SFINAE and not enable_if. 
Good post (as usual :)). Apart from the pure disambiguation, I would like to just give another example where `enable_if` can also be really useful and makes the code more efficient: With [policies](http://en.wikipedia.org/wiki/Policy-based_design), `enable_if` rocks! It allows you to select a (private) overload that is more efficient when a specific type is given. For example, for a job I had to develop an object that was keeping track of other objects and was ordering them. One of the class' policies was to indicate if the tracked objects can be ordered by group. I used `enable_if` to make sure that when groups were not used, all the call to the group functions (usual suspect, `addInGroup`, `forEachElementInGroup`, `removeFromGroup`, etc.) were no-ops. Also, while I love `static_assert`, they may not be visible in the source at first glance, so while I agree with /u/STL that they are often preferable, I personally find `enable_if` useful in function declaration such as: template &lt;typename ConcreteType, typename = std::enable_if&lt;std::is_base_of&lt;BaseType, ConcreteType&gt;::value&gt;&gt; // I also sometime use macro to shorten those enable_if. void create(Conf const&amp;); `create` implementation is still hidden and yet you know that the type must inherits from `BaseType`. The only problem with this approach is that the compiler gives you a kindda nasty error message. 
You are correct, the example is still relevant for the many situations where state needs to be captured. I'll see if I can't get some free time to do a proper comparison.
Being a general purpose library, it solves a large range of problems, and many times in a much simpler way without resorting to metaprogramming. Of course, it may not always be clear because it involves combing many different componenets together. Projections ----------- Instead of writing the projection multiple times in algorithms: std::sort(std::begin(people), std::end(people), [](const Person&amp; a, const Person&amp; b) { return a.year_of_birth &lt; b.year_of_birth; }); We can use `by` to project `year_of_birth` on the comparison operator: std::sort(std::begin(people), std::end(people), fit::by(std::mem_fn(&amp;Person::year_of_birth), _ &lt; _)); Ordering evaluation of arguments -------------------------------- When we write `f(foo(), bar())` there is no guarantee from the standard what order the arguments `foo()` and `bar()` are evauluated. So with `apply_eval` we can order them from left-to-right: apply_eval(f, [&amp;]{ return foo(); }, [&amp;]{ return bar(); }); Extension methods ----------------- Like in C#. By using `fit::pipable` we can write methods work just like extension methods, except we use the `|` pipe operator instead of the `.` dot operator: struct sum { template&lt;class T, class U&gt; T operator()(T x, U y) const { return x+y; } }; assert(3 == 1 | pipable(sum())(2)); assert(3 == pipable(sum())(1, 2)); Working with tuples ------------------- Many times to do things in C++ with tuples requires a good amount of metaprogramming. However, combining things together we can write some things much simpler. For example, if we want to write a `for_each_tuple` function as an example, we can simply write: FIT_STATIC_LAMBDA_FUNCTION(for_each_tuple) = [](auto&amp;&amp; tuple, auto f) { return fit::unpack(fit::by(f))(tuple); }; Logical overloading ------------------- By doing conditional overloading, we can accomplish some very simple things without needing metaprogramming. For example, if we wanted to convert types generically to a string, we could write this: FIT_STATIC_LAMBDA_FUNCTION(stringify) = [](auto&amp;&amp; x) { return static_cast&lt;ostringstream&amp;&gt;(ostringstream() &lt;&lt; x).str(); }; However, this is fairly ineffecient for simple types. Rather, we should try to call `std::to_string` first, then use `ostringstream`. This is simple with the Fit library: FIT_STATIC_LAMBDA_FUNCTION(stringify) = fit::conditional( [](auto x) FIT_RETURNS(to_string(x)), [](auto x) FIT_RETURNS(static_cast&lt;ostringstream&amp;&gt;(ostringstream() &lt;&lt; x).str()) ); Recursion --------- Although, we are defining our functions with lambdas, we can still make them recursive using the `fit::fix` adaptor. So we can write a recursive `print` function that will print elements of ranges and tuples: namespace adl { using std::begin; using std::end; template&lt;class R&gt; auto adl_begin(R&amp;&amp; r) -&gt; FIT_RETURNS(begin(r)); template&lt;class R&gt; auto adl_end(R&amp;&amp; r) -&gt; FIT_RETURNS(end(r)); } FIT_STATIC_LAMBDA_FUNCTION(print) = fit::fix(fit::conditional( [](auto, const auto&amp; x) -&gt; decltype(std::cout &lt;&lt; x, void()) { std::cout &lt;&lt; x &lt;&lt; std::endl; }, [](auto self, const auto&amp; range) -&gt; decltype(self(*adl::adl_begin(range)), void()) { for(const auto&amp; x:range) self(x); }, [](auto self, const auto&amp; tuple) -&gt; decltype(for_each_tuple(tuple, self), void()) { return for_each_tuple(tuple, self); } )); Make Stephanov happy -------------------- The problem with lambdas is that they are not regular because they are not default constructible. Well, using `boost::optional` we can make the lambdas default constructible: FIT_STATIC_LAMBDA_FUNCTION(regular) = [](auto f) { return fit::indirect(boost::make_optional(f)); }; Plus, a whole lot more ---------------------- Including many traditional functional constructs such as partial application and composition. 
&gt; fit::by(std::mem_fn(&amp;Person::year_of_birth) This is difficult to optimize (VC can't, don't know about GCC/LLVM) because the PMF is stored as a data member. In contrast, the lambda is happily optimizable because its function body is a normal candidate for inlining. Micro things like this don't usually matter *except* in inner loops, like sorts. 
&gt; It allows you to select a (private) overload that is more efficient when a specific type is given. Tag dispatch is a superior technique for this. &gt; and yet you know that the type must inherits from BaseType. A comment would serve the same purpose. static_assert results in friendlier diagnostics, especially if you do extra work to suppress other errors.
&gt; Would someone be willing to explain this to me (recent comp sci grad), and why it's important? The degree seems to have done oodles for you.
Just because I have a degree doesn't mean I want to read a super dry article about templates. 
Putting aside snark for a moment, it's a valid question. I'm sure I wouldn't have understood this stuff in 2004 with just a BS in CS and a couple of years of C++ experience. This sort of stuff (processing packs of types) is unlikely to be useful to you unless and until you're implementing advanced template libraries like bind() and tuple_cat(), or especially customizable things (e.g. that you want to give lists of properties at compile time). Then it's exceedingly useful. Even metaprogramming 101 (tag dispatch on specific properties of types, like being integral or being a random-acess iterator) is useful only in template libraries, when you're not sure what concrete types you're working with. Lots of application code is completely concrete and contains no templates itself, although it may (and should) use template libraries extensively. I have a grand total of four helper templates in my game-engine-in-progress, for example.
&gt; This is difficult to optimize (VC can't, don't know about GCC/LLVM) because the PMF is stored as a data member. In contrast, the lambda is happily optimizable because its function body is a normal candidate for inlining. Ok, interesting. Instead of using PMF then a lambda could be used for the projection: fit::by([](auto&amp;&amp; x) { return x.year_of_birth; }, _ &lt; _) 
Cool, thank you.
Thank you for the response.
You are using the terminology "viable" incorrectly. During overload resolution, an overload is viable if it could possibly be called (i.e. if it would work in isolation). SFINAE happens before overload resolution (it prevents things from being added to the overload set in the first place). Overload resolution then discards non-viable functions and determines a *best viable* function (or announces ambiguity). In the given example, Scalar&lt;Field&gt; produces the signatures Scalar(double) and Scalar(Field). The argument is int, which can be converted to double (so viable) but cannot be converted to Field (it's an aggregate, with no constructors). So the Scalar(Field) signature is non-viable.
Do you have a copy of the source you were using for this? The article describes filling a vector with 1000 lambdas. With -std=c++14 -O on the following code, clang compiles in less than a second. Perhaps there is something amiss in your environment as those numbers you are reporting seem off. https://gist.github.com/apathyboy/0f9f9431749d9370f611
Last I looked, the GNU implementation of std::function didn't use virtual functions. Devirtualisation of the DIY vtable could still be happening though
I think one more thing that is notable about template meta-programming that I would like to mention, is that it takes the form of functional programming. Functional programming requires a different mentality than imperative style, which is generally how the logic in C, C++, JAVA etc. is developed. It is worthwhile practicing with a functional language, not necessarily C++ templates, something more like Haskell, Scala or F#. This different mentality that you need to develop effectively in these languages will change your thought processes and make you a better developer all around. You will see the benefits in your imperative programming as well.
&gt; Thanks, I will clarify this example with your information. Also, do you know of an example where you call something in two different ways that SFINAE would exclude one, then the other so both demonstrate SFINAE? 
Heh I see it doesn't make much sense to you because you truly don't realize you are mixing two different things.There is a huge difference between design time errors something where you should use assert to actively (this is important) state your assumptions of how the client of your code should use your function. Client being you or another coder! Preferably in c++ most or not all are const_assert. No you don't need unit test to test those. Those must be correct before that. Again, preferably you don't even get a .exe to test :P On the other hand exceptions are for runtime-error when the situation is truly exceptional and outside of your control. Can it it be triggered by your client? The client in this case can be both a end-user in front of GUI or another programmer using your PUBLIC API. This situation in fact does not preclude the using of asserts in inner functions as long you use exceptions on some outer layer of your software (e.g. validation layer). Just to wrap. Both asserts and exceptions can be used in respect to 'DesignByContract' the key to understand is who the client of this piece of code is. Private or public. Also there are additional concerns to consider, what you refer to as impl detail. Maybe one example can shred more light: Imagine you are building GUI lib and you have some base guiControl which has public method setParent. However, your design disallows setting a parent once one is defined that is two calls to setParent. This is perfectly reasonable assert that does not need to be an exception. The benefit is that you don't need any exception handling or to consider it a run-time concern for your app in general. There is only one way to correctly use the GUI and the app will always exit() if you try running it the unexpected way. However, in case your design is enriched with supporting dynamic loading of the GUI, e.g from qml/json/xml layout file, you might re-consider to use exceptions and think how to report it to the front. Now it truly became a run-time concern since anyone can edit those files. Please look at: http://stackoverflow.com/questions/117171/design-by-contract-tests-by-assert-or-by-exception not the accepted answer but the comments with the most upvotes and the the answer with the substantially more votes than the accepted. for your points: 1- no (makes no sense for release-production) 2- yes (for runtime error exceptions should be used but nothing wrong with using functions with asserts in the code after the throw part which never got hit) " If you have an assert in a tight-loop, it's just as bad an idea." nope they are gone in production unlike exceptions. You don't care about assert overhead in debug considering it is already slower. There are more concern about exceptions in tight loop for both exceptional and non-exceptional paths. 
The time for the macro expansion is completely insignificant, as is easily measured. I get approximately .6s for all compilers, regardless of what's enabled and regardless of optimization setting, if the inner most macro expands to nothing.
I don't think that the standard defines the term "viable". I used it correctly so far as English is concerned. The functions are viable at that point in the sense that overload resolution is required to decide between them if it can. They've passed all other filters and can both be instantiated and both match the name. Besides that, you said exactly what I said.
I can't think of something off the top of my head that matches what you want that I'd actually do that way. I use SFINAE for when I want to eliminate a single signature, not for when I want to have the compiler decide between alternatives. For that I use a different mechanism, and the one I chose is generally tag dispatching.
&gt; Andrei Alexandrescu made the concept of meta-programming accessible to the masses in his book Modern C++ Design, published in 2001. I would argue that it was Abrahams and Gurtovoy that really made TMP accessible to the masses. They established a protocol for metafunctions and such that is more or less what the standard follows with traits and such.
This looks nice, I would like to try it. Can I use HPX for node-level parallelism only, i.e. without distributed memory / PGAS support, in an application that already uses MPI for distributed memory? 
Very cool. Unfortunately there is seriously a giant problem with tech talks having terrible sound. In the future remember that you can't just set up an iphone. Use a separate mic. 
Is this in the stdlib or a third party library?
Only if you really really want that implementation hidden.
I'm open to PMs if you want to ask questions. Also, /r/learnprogramming is a better place for this sort of stuff.
Yes, this can be done. The cancellation has to be performed explicitly, though (passing a cancellation token to all sub-tasks would do the trick). 
I'm sure almost anyone you see around /r/cpp would be happy to help you out with specific problems, and you should also check out /r/cpp_questions.
thanks guys
Yes. It's to simulate some random requests that a typical key-value store should take.
there seem to be two versions of the C++ code - is that in response to some of the feedback? Which version of the code were used for the performance analysis at the end? edit: oops I see, the first writes the histogram to a file and the second reads it and randomly messes with the data, re-allocating the entry buffer each time there is a collision, and sometimes deleting the entry altogether I dont really understand the reasoning behind the raw pointers and reallocation though, it would be interesting to see the impact of putting a vector in there
After looking into Milewski's blog to find more resources, I found a series of posts on this subject ([here](http://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/)). This may help you and anyone looking for more info.
It's not a contest but not the way you imply. Comparing these two languages are like comparing apples and oranges.
As said earlier, you can disable all communication related stuff (the parcelports), PGAS can't be turned off as we don't have that, we only have AGAS ;) Jokes aside, it can't be turned of completely there is too much code depending on it (performance counters for example) and you don't have to have a distributed application to make use of the AGAS facilities. So yes, using it on a node level only should be perfectly possible! We might need to make some minor small adjustements though to disable the automatic detection of batch environments etc. but this is not really a show stopper, as there exist workarounds for that already.
Please stay in touch with us when you try as there will be things we need to adjust for this mode of operation. On a related note, for quite some time I wanted to apply certain optimizations for the shared-memory-only case. If we know that HPX does not need to support any distributed operation, AGAS can be internally simplified, which would speed up certain things (I just created a corresponding ticket: https://github.com/STEllAR-GROUP/hpx/issues/1591). 
Thank you Tiago, this is very helpful.
OP could also use codeeval.com or projecteuler.net to test their skills!
This is a common question on /r/MachineLearning you may start from there.
Oh, thank you!
OMG so harmful, let's never use anything ever again!!!
I'd love to see how it can be applied to an audio processing engine. My design is very simple, it is a tree of nodes, each one having a processing function. Some rendering context is passed to the processing tree. I've been hacking on my engine to enable parallelization of processing (using futures) and I think I could benefit from the category theory. The problem is in fact pretty simple, nodes can either generate audio data, process input data, or both. It should be easily to make my nodes "monoid"; and the processing functions "pure functions", enabling composition and identity. I am trying to understand the whole concept and I am just starting, hence the need for pointers regarding this topic ! I'd love to get /u/DrBartosz insights, or anyone really, on the subject: are categories viable for a (multi-threaded) audio processing engine ? Maybe the remove of side effect in the code is too complex, but I think it is feasible. Thanks.
Thanks for the reply! Regarding the server, I'm wondering, what were the most convincing reasons for you to go with cpp-netlib over, say, Casablanca or POCO also mentioned in that thread (again, question purely out of curiosity)?
Preprocess the code separately using the -E option to a new .cpp file.. It takes approx .1s. The time to compile the the preprocessed source is indistinguishable from the original. The preprocessor is not the cost. The other stuff, sure, but that doesn't retract from anything. It's equal for all compilers but the result varies wildly, to say the least.
I'm not discounting any of the effort and contributions both Abrahams and Gurtovoy have made with meta-programming and Boost. In fact they took it to an entirely new level as you are saying. However, MPL wasn't released as part of Boost until 2003, and their book wasn't published until 2004. I also believe that their material much more advanced compared to the material Alexandrescu presented in Modern C++ Design. That's why I stated he made TMP accessible to the masses. Either way, I realize that I am standing on the shoulders of giants that pioneered these techniques.
The first part of this article series got a lot of constructive criticism a few days ago in a now deleted post by the original author: https://www.reddit.com/r/programming/comments/38nkrx/graph_engine_vs_c_unordered_map_memory/
ah didnt see that - did he update the results? and it seems like there's still some weirdness in there with explicit heap allocations edit: I see he did update the results
His code can be optimized in so many small ways, he is doing an unnecessary cast from size_t to int32_t, not using references in the for loop, deleting void*.... all those small details add overhead to your code. I would honestly remove the blog entry or make it properly as it is trying to prove something with a wrong and unfair code that will mislead programmers with less knowledge. With the changes I comment in my setup went from 70 seconds to 10 seconds.
THERE IS NO WORLD OUTSIDE REDDIT
Depends largely on who you tutor, IME
It is usually recommended, and not without a reason, to get a real book. If you want it absolutely free, check if your nearest library has one.
&gt;*2015* &gt;*No CMake, GNU Autotools instead* Yeah, modern...
Totally agree. C++ is losing not because it is difficult. It is losing because of its bare bones standard library compared to the competition. In my view all the 'improvements' being made and proposed are totally missing the mark. If I want to use C++ to write a mobile app, my concern is not lack of generic lambdas. My concern is tooling, GUI, network libraries, unicode support etc.
&gt; lots of things it checks at runtime via string comparison That has changed in Qt 5 already (look up new syntax for signals-slots). Moc is still used to add introspection, but that's not possible with C++11 alone (without writing boilerplate).
convert to utf8 or gtfo. The internal use of utf16 is one of my biggest beefs with Qt.
Yeah that will stay in I guess until well after C++17 when the Reflection TS is available. Until then too much of Qt is based around this introspection feature for them to switch away. 
I think the removal of Cmake for autotools and the use of 4.8 is a bit weird. This seems mostly be about getting rid of moc because it is a bad C++ parser (and it is). I think it would be much better to pay attention to [moc-ng](https://github.com/woboq/moc-ng) which aims to use the standard compliant parser of clang as a library. It would allow Qt to continue having their introspection features and have a parser with a much better understanding of C++11, templates and all. At least until C++20 ;) when we probably will be able to enjoy compile-time reflection which should allow Qt to implement nice solution for the framework in Qt 7? Maybe? Probably not though because of backwards compatibility.
I stand corrected. Thanks!
Interesting, thanks for the reply, again! I have had some good experience with POCO with respect to the build times (much faster than, e.g., cpp-netlib, even though I've tried it after it's abandoned its initial header-only design -- although I do like cpp-netlib's design choices w.r.t. the interface conventions, etc.) which I found important for quick iteration times. That being said, the docs could have been better than just the slides (they did work all right for getting started, though) and auto-generated API reference (to be fair, cpp-netlib's docs weren't really better, IME). One more question after looking at cURLpp (sorry about pestering you; as you can probably tell by now, network programming is one of the things I _really_ find interesting ;]). Looking at the [examples](https://github.com/jpbarrette/curlpp/tree/master/examples), there seems to be a very heavy use of heap allocation, with a lot of focus on low-level memory allocation using raw `new`, e.g., https://github.com/jpbarrette/curlpp/blob/master/examples/example02.cpp#L84 I'm wondering, is this something that you have found to be an issue in practice or not so much (are there any issues with leaks? is the ownership taken over when passing the pointer to `setOpt`, akin to how Qt does it? is it possible _not_ to allocate on the heap and just pass pointers to the stack-allocated objects in all of these places?)?
Qt is binary compatible within major versions, so this kind oft switch can not happen before Qt 6.
I was just talking with colleagues at work today and it dawned on me that a lot of OSS software is such a PITA to build natively on Windows (with VS) _because_ it uses autocrap instead of a truly cross-platform alternative.
I'm not sure about the "well after" part, they reacted to C++11 features pretty quickly. Also this looks like fun to implement so I'm betting that as soon as there are working compiler implementations of C++ reflection there will be people working on patches to remove moc. 
Even if they start adding C++17 code the day the spec is released, it'll be a few years before they can require it. They need the overwhelming majority of users to be using working C++17 compilers, including on embedded platforms before they can eliminate older code paths. On exotic poorly supported platforms like MSVC/Windows, that'll probably be 2020 or so. That said, if I was emperor of Qt, I'd make 6.x require C++17 and use that release to start killing off a lot of the re-invented STL and MOC and let my user base mainly use 5.x until they caught up. Transitioning to a compatibility breaking release like that would take a long time (See Python 3!) but I think it would be a net benefit in the long run.
Coupled with the fact that mainline Qt is using C++11 where it is feasible then it is down to API design limitations. Meaning that there are probably limits to the API design of Qt due to their platform / OS support that probably precludes going full C++11 only.
Yeah I think so too and compile time reflection combines really well with concepts and metaprogramming to create really useful and powerful serialization features for example. However they haven't agreed on which way they want to go with the Reflection TS yet so it is hard to say if it will be a fancy library/template thing or even better a special keyword. For example you could easily imagine having an "is" keyword and a "mirror" keyword to add to the classes you want to opt-in to the reflection support (what they should have done with RTTI as well).
What about platforms who doesn't use UTF-16 in their API (like OSX and Linux)? For them you need to do this conversion already right now!
Doesn't OS X use utf-16 too?
You could have referred to Howard Hinnant's 2014 ACCU keynote (http://accu.org/content/conf2014/Howard_Hinnant_Accu_2014.pdf, page 28) The rest of the talk is good, too.
because "CopperSpice" is such a cool name for a library /s
Yes we do want to support Android. 
Yes. But you need to play well with the C++ ecosystem. C++ developers care about their code being cross platform. Compiling C++ code only using GCC and autotools is not what people have in mind now days. All the hip stuff regarding C++ is using CMake: * LLVM is moving away from autotools to CMake * CLion IDE is using CMake for their project management * biicode dependency manager is using CMake * CMake supports ninja build system
OP: you should remove the blog author name of the title. As for the questions can c# data structure be faster than c++ data structure : The answer is yes. At least out of the box. have a look at this http://stackoverflow.com/questions/6974719/c-sharp-to-c-dictionary-to-unordered-map-results 
https://github.com/boostorg 
Thank you very much for the videolink and to Bartosz Milewski to try to getting us to a higher level (of abstraction). Category theory indeed is a very interesting topic. It sort of reminded me of the formal specification languages that I learnt about in university, especially the [Z notation](https://en.wikipedia.org/wiki/Z_notation). So interesting that I dreamt about it after going to sleep. Happens sometimes, but not often. I found the introduction about what we programmers often do, decomposing and composing to a higher abstraction level a refreshing perspective. Particularly the comparison to musicians way of reasoning with/about musical notes. Good analogy. Remember though that to understand and reason at the higher level you will need a great deal of education and understanding (of concepts etc). I find that one human endeavor is about to get to a higher level of abstraction. In the most pure form to make your own job redundant. This is so that we can work on the "next level" with the interesting topics at hand, rather than getting dirty with smaller nitty technical details, although people doing that are often still needed. That is one reason for why most of us do not program in assembly language anymore. Why use a complex programming language if the same can be expressed in a less-complex - at a higher abstraction level - programming language? The problem to getting to a higher level is often to get everybody on board to understand "the context/concepts" on/of the higher level. If is often quite difficult to cope with at the beginning. Like learning object oriented programming. Sometimes it takes many years to get - everybody - to the higher level. This is why it is particular good that we have people, like Bartosz Milewski, that with a theoretical foundation can help. In theorizing, in researching, in practicing and in education. Good examples are often the key for getting peoples understanding of why the higher level abstraction is better. So more of these, please. With that I would just close with a comment about one of the last slides in Bartosz Milewskis presentation - namely that of the opportunity for the C++ community to get to a higher level. It seem to me that he have identified something here and I would hope/suggest that he and others actively helps with that. PS. Do you know about the [sortest letter ever written](http://quoteinvestigator.com/2014/06/14/exclamation/)? That is high abstraction level. But a lot of context has to be known/learnt to understand it.
Our CI builds CopperSpice on Debian, Ubuntu, and Fedora using multiple versions of gcc and clang. On OS X we are using Clang. On Windows we are using MinGW right now. The current version of clang does not support exceptions on Windows. They are very close and we will test with clang when it is ready. We have found a good deal of support with Auto tools but I agree, we should add CMake support using ninja.
Sadly VC does not support constexpr and they currently have no plans of adding it this year. I have worked with Windows for many years but sometimes it baffles me why Microsoft leaves out important features.
As I understand it, moc has had issues in the past with some template constructs. But mostly (I am not an active participant) I think it is done so you don't have to maintain a complete and up to date C++11, 14, 17 parser for the future
Yup, TS first then probably in C++20 
I actually went to download boost the two days, and was hesitant to use the main download link because of the way SF has gone, because it was source I was thinking, surely they wouldn't have modified that to put adware somewhere.
If you want to go to the first person who discovered that templates were a programming language of their own and explained to the community how to use them as such...then Alexandrescu is a good decade behind the times. http://www.cs.rpi.edu/~musser/design/blitz/meta-art.html ...and there are earlier examples still.
&gt; It has serious limitations and it is not true C++. Nor are .y files "true C" but you don't see people pitching a fit when C-based projects do the *right* thing and use a parser generator where it fits in the design.
I suppose that it should have a build option whether to use UTF-8 or UTF-16 strings. [Poco](http://pocoproject.org/documentation/index.html) does!
That would be awful for cross-platform support. WinAPI is doing similar thing for anis vs wide chars - A and W suffix for WinAPI functions. All the code using that is terrible (_T macro, special string functions, etc...)
Why? Do you have a problem with toolbars and download managers or something? [I can't live without them.](http://imgur.com/GW6cFME.jpg)
Do you have benchmarks? 
&gt; and then my compile times go through the roof when I use it Well you're already using boost, so how could you tell? ;)
Wx seems more amenable to a modern sprucing up than Qt, mostly because it's so much smaller. There's nothing tricky about ripping the obviated bits out of Wx and going with a modernized event and namespace approach. Qt is huge, and a lot of that bulk is increasingly obviated by other projects and the standard.
CopperSpice was not developed just to remove moc, it is however one of the key issues we wanted to address. Parser generators have their place but it depends on what they do. Moc is not optional with Qt and when you hit its limitations the best approach is to either improve it or find a better way. We choose the latter. One of the limitations of moc is that you can not write a template class which inherits from QObject. Other problems are due to losing data type information, no understanding of typedefs, etc. 
Yes, for Cocoa. But even there, it's not compatible with Win32. Cocoa is strictly NFD, Win32 is (effectively) NFC. TL;DR Unicode is complicated.
Moc is not a C++ parser. It only parses certain constructs and gets confused by complex data types and many templates. The basic idea behind moc is to build a string table for run time lookups. This is done with string comparisons and can be slow. The design of moc was cutting edge 20 years ago but there are better ways to implement this functionality today. CopperSpice offers a better way.
I see. I love using Qt so I think I should learn about this stuff.
Qt has many design decisions that have implications that restrict developer options. moc isn't even the worst of them. For instance if you multiply-inherit from QObject you have to have QObject as the first class in that list otherwise you'll get horrible bugs. Likewise you can't store QObjects in container classes, in general you can only store pointers to them... and those two issues alone probably have large implications for trying to write template classes that inherit from QObject, moc or no moc. Could `moc` the executable be better at handling C++ input files? Sure, I guess, but it pretty much never comes up in practice, and even if it did an approach like moc-ng is the better way to go.
I could not agree more with several of your points. * QObject is quite large. The right thing to do is refactor the different functionality upward into several separate base classes, which QObject can then inherit from. This could not be done in Qt since moc does not understand multiple inheritance. It should be possible, for example, to declare a slot and connect to a signal with a lot less overhead than the full QObject system. * The Qt object lifetime management is a bit obtuse. We want to make CopperSpice play nicely with shared_ptr and we have plans in that direction. The unique_ptr may not be as amenable to smooth integration. * The container and string libraries are poorly designed in many ways. This is a work in progress, and one of our goals is to make most of the Qt container classes thin wrappers around the standard library classes. This will give us improvements in both speed and code size, as well as supporting the whole container API that C++ programmers expect. (For example, it would be nice to have reverse iterators.) * The namespace issue we did not yet have on our wishlist. Thank you for the feature suggestion. 
I'd love to know how much bandwidth Boost does in a month.
Ok, that's $56.38/mo on a Linode (and that's without doing anything clever like CDNs or whatever the kids are using these days).
Well Hitler doesn't know what he's talking about. Modules are nice to have, but the language works, and compilation time, if one uses a sensible build system and multithreaded compilation, is alright. Pimpl reduces that even further. I build a few million lines of code in 5 minutes, and then subsequent builds are incremental unless I fuck around with the core lib and take 5 seconds or so for major commits. 
I love boost, but I still chuckled
Following the news much? Apparently SF has been taken over by aliens who hijacked free and open source projects to include non-free and non-open source propaganda designed to turn us into mindless consumerists in order to ease and fund their invasion. Actually, this may have just been a failed experiment on their part and they said they'd stop this particular stunt, calling it a "test," but I think the loss of trust and reputation will be permanent. That reflects on projects like Boost if they continue to rely on it. People may be apprehensive to download it if they have to go through an untrusted service.
common criticisms include: - no future cancellation tokens or similar - no progress feedback mechanism - no continuations (.then()) which are necessary for composition of futures. This is actually tricky to do if you have cancellation tokens and progress feedback - edit: (remembered another one) futures wait on destruction, cannot be detached Sean Parent did a presentation recently where he discusses his alternative futures library (https://github.com/stlab/libraries/tree/develop)
http://blogs.msdn.com/b/vcblog/archive/2015/06/02/constexpr-complete-for-vs-2015-rtm-c-11-compiler-c-17-stl.aspx
Exactly. Give the Visual C++ users a chance to report issues to Microsoft. Heck /u/STL might compile and fix bugs by testing CopperSpice with Visual C++! But that will never happen if you stick with autotools :)
The WinAPI macros are ugly because they use preprocessor. When using templated libraries there is no issue. The POCO libraries achieve this nicely; you can build them as UTF-8 or as UTF-16, and so long as you build your application the same way it works. FWIW the `_T` stuff has been obsolete since about 1998 although you still see it crop up in code from people who don't realize that (much like casting `malloc`). There's no reason not to just use the W versions. 
What's the better scenario in your opinion? - Having the C++11 futures as they currently are, and getting a thoroughly discussed standard library extension with C++17, or - A potentially misguided class design that can never be changed, or - No futures in C++11 at all. Keep in mind that a sane base design can be extended without huge issues. Yes, futures are not everything they should be, but slow, iterative progress is being made. Is the committee being too conservative on adoption of certain features? Maybe, but keep in mind that anything in the standard is pretty much set in stone, and cannot be removed. Overall, I'm willing to take the tradeoff of "fewer features right now, but let's learn how to do everything properly" over "quickly adopting every feature someone is crying for, but making mistakes we can't correct." Also, this is purely a libraries issue, and everyone is free to use complementary implementations until we get a new standards update.
We checked the MS site about a month ago and constexpr was listed as not being fully supported in VS 2015. Glad to see they are in beta. Thank you for the link. 
I like open source [as much as anyone](http://nuwen.net/mingw.html), but I have to say: autotools is the worst thing ever. *The worst.*
The open source community helps each other. Now we want to help Boost. Leaving them be is not knotting any knickers, but saying nothing about a potentially abusive relationship.
&gt; keep in mind that anything in the standard is pretty much set in stone, and cannot be removed. Except conversion of string literals to (non-const) char*, exporting templates, std::auto_ptr (deprecated in C++11, but set to be removed in C++17), std::gets, std::random_shuffle (and friends) (deprecated in C++14, but set to be removed in C++17), and in the future: unary_function/binary_function, ptr_fun(), mem_fun()/mem_fun_ref(), bind1st()/bind2nd(), and trigraphs. But redesigning / deprecating / removing is challenging. You are right that we shouldn't just jump into adding premature designs. EDIT: Added conversion of string literals to (non-const) char* and std::gets
Oh this was so awesome/cathartic.
I feel a little deflated about this myself. This means we'll literally have to wait for another 5 years. That's a lot of time, considering many other languages have these features already implemented. My fear is that these delays will hurt the language in the long run.
Because Sourceforge has become incredibly sketchy recently. Since Sourceforge hijacked GIMP For Windows's account and added adware to the installer, I've become wary of installers from Sourceforge.
Great, so it looks like C++ won't have modules until 2020, at the earliest. They will be dropping concepts (again) next. The language is truly past its sell by date and descending into decrepitude. (Sadly, I don't see a good successor on the horizon yet).
Yeah, that's my fear too. C++ is too slow to change.
The commentary on defaulted move special members is incorrect as of C++14. A defaulted move constructor/assignment operator that is defined as deleted is now simply ignored by overload resolution.
honestly that timeframe is eons in internet time, i expect something might come along
But C++ actually changes and improves all the time. This is good. For real slowness look into C, which has been almost exactly the same since 1989. Having something like RAII for C (which already exists as a GCC extension) would make the lives of all C developers a lot better but no-one cares so C programming is still mostly an exercise in manually chasing malloc/frees and refcount leaks.
I would disagree on the "ignored by overload resolution in C++14", anyway I sent a request since the example shows an explicitly deleted and not implicitly (not sure if relevant though).
Yes it's an issue, but it doesn't break anything or make working with cpp hard, it just makes compilation inconveniently long. It's not something one has to recruit Hitler to address for 
Lol, I didn't see his link, so I missed the joke entirely. :-D
I really see C++ compilation times as a huge deal and the main wart surrounding C++ after so much has been done with C++11. Personally I would architect around it from the start of the project, making sure there is as much separation as possible at every level so that header files don't end up including hugely exponential amounts of extra code. At the same time any separation through separate projects that create dll files increases modularity and reduces monolithic compile times. The thing is though, that this shouldn't be necessary with respect to compile times with modern computers. Every other language can compile ridiculous amounts of code in fractions of the time. It shouldn't be necessary to have a compile farm. An 8 or 16 core computer shouldn't be legitimately useful when compiling programs. 
I didn't hear that modules are dropped from anywhere but this post here. Where is this information coming from? I just read http://developerblog.redhat.com/2015/06/10/lenexa-c-meeting-report-core-language/, and it sounds like modules weren't rejected.
I can understand why you are quick to defend the standard as it stands now, but you didn't answer the poster's question at all.
SF is only taking over inactive accounts at the moment. Active accounts are still opt-in. If Boost stops being active, it will cause what you're worried about because Boost will have no say in the matter. For now it's in their best interest to leave the SF account active and add other official locations.
For developers: we've created a fiber io object which matches the Boost.asio stream socket interface and multiplexes data into a single underlying stream (e.g. a TCP socket). It's isolated in the code so it can be easily reused. Fill free to checkout it in the repo. Checkout: https://github.com/securesocketfunneling/ssf/tree/master/src/common/boost/fiber
&gt; PIMPL is not a general-purpose solution to the problem. It might be fine for a big heavyweight class that's always allocated on the heap anyway, but it's performance suicide for small classes. Custom strings, 3d vectors, etc... and those are the ones that really slow down your builds when you change them, because everything depends on them. I recognise that this is a problem. As I said, compilation for me also takes long when I change something in the core of the project, which includes things like custom containers. In a past project I actually set up a debug build using pimpl that was disappeared in the release build, using defines. Code would look like class A { PIMPL(std::vector&lt;int&gt;) a; }; A::foo() { PIMPLD(a).clear(); } That's a workaround. &gt; We need Modules desperately. Slow build times are a productivity killer. Every time my build takes more than ~20 seconds, I start doing something else and get distracted. I don't have this problem. Usually my builds are faster because I'm working on maybe 5 files, none of which are core; and if not, I can compile in the background and continue working.
I honestly don't understand the brouhaha about modules. Unless you're including everything you possibly can, perhaps by using catch-all headers (don't do this), or you routinely change core files used throughout your project (why are you doing this, consider changing your process), you should be compiling 1-2 TUs every code/compile/run cycle. This shouldn't take longer than 5 seconds, and that's generous. Having recently implemented the variant from [N4542](http://open-std.org/JTC1/SC22/WG21/docs/papers/2015/n4542.pdf) the poke at the never empty variant except when a copy constructor throws was pretty amusing, I'll give them that, but I can see where the paper authors are coming from (allowing heap allocation as `boost::variant` does ruins -- in a lot of ways -- the performance/allocation properties, and allowing emptiness as a regular, banal state ruins composability with `optional`).
We respect your opinion and thank you for comments. CopperSpice is not going anywhere, no matter how many developers use it. CS is being used in developing applications. Qt 5 does use many C++11 features however the source is riddled with #ifdef's to turn things off which will not work on many compilers. Moc was an amazing concept 20 years ago. If you take the time to really look at what moc does, it is a poor design with today's standards. Moc uses string comparisons which are slow. The way moc is implemented all data type information is lost at run time. Everything is converted to a void *. There are also ABI issues which require extensive attention. The idea of using moc-ng was interesting but to limit users to clang only does not work. There is no way we consider the time we elected to spend on developing CopperSpice pointless. We learned more about C++, we learned team programming, we learned about project management, we learned SourceForge has it limits, we learned about about Jenkins for CI, we became involved with our local C / C++ users group, and we are having fun.
That's true the other way around also. 
&gt; The idea of using moc-ng was interesting but to limit users to clang only does not work. I think moc-ng can either be build as a clang plugin, or a standalone, drop-in replacement, binary ( while still leveling the power of libclang). &gt; There is no way we consider the time we elected to spend on developing CopperSpice pointless. We learned more about C++, we learned team programming, we learned about project management, we learned SourceForge has it limits, we learned about about Jenkins for CI, we became involved with our local C / C++ users group, and we are having fun. Anything that can make you a better programmer is worth pursuing but if you have the will and time to manage such project, maybe you could contribute to open-source in other ways. Did you contact some Qt devs and share your concerns about moc with them ? 
I upvoted you out of sympathy.
Not only in language specification, it seems all that C++11 (and beyond) "wave" made compilers to catch standard much faster than before (well, even before they make into standard).
Is it not? I thought they moved to github last summer?
&gt; That is a clever workaround It has a lot of trouble with ',', because the preprocessor uses that as a token separator, so `std::map&lt;int,int&gt;` can't be pimpled this way trivially (needs a typedef). &gt; I'm wondering why you argue against modules I don't argue against modules, I just think the panic is overblown. Quick compilation is a nice-to-have feature. I'd really like to have it. I'm not that fond of having to simulate modules with include hierarchies and such. But it doesn't break the language. Modern C++ is a very broad, effective language with quick execution and very little overhead (unless one explicitly wants it), and unlike C++98 it rivals dynamically typed languages in flexibility in many ways (worst case: type erasures). In this thread people are claiming the lack of modules as the end of C++, or that modules are the most important part of a modern programming language, or tell horror stories of having to compile the whole codebase regularly. As an aside, especially the latter seems rather contrived to me. I'm currently working in a medium-sized codebase, with about half a million lines of code, and about the same in library includes and such. I compile that on 8 cores in 30 seconds (single core takes about 5 minutes because at least my code heavily uses the STL), but I don't have to recompile everything regularly. Usually only a very small subset has to be recompiled. I'm using autotools for this, the windows guys sadly have to recompile everything more often. 
So you're saying ... you *agree with Hitler?*
man...how did i miss this? i live very close.
They've actually not rejected modules, they're just pushing it back as the modules TS and test implementations, although in progress, will almost certainly not be ready in time. Since this is arguable the largest and most fundamental feature added to C++ in a very long time, they don't want to rush and get it wrong.
&gt; Constant bitching about the cost of a function call or the moving of a pointer and whatnot... lol
Too little, too late, Bjarne.
There's a metric crapton of C that is never going to be translated to C++. There's also a second metric crapton of new C code that is written every day. We would all (yes, all, even those who never code in C) would be better off if C were improved to make bugs such as the ones in OpenSSL become harder to write and easier to detect. But it's probably not going to happen ever.
IIRC, the entry fee is $1200
I live in Lenexa and didn't know about this. :(
Sure, but past C is not really the issue since it is already written. I'm not saying anything written in C is obsolete, that would be ridiculous. 
https://isocpp.org/std/meetings-and-participation : "Meetings are open to the public, and we welcome people to attend for a meeting or two as an observer; this lets you participate and argue and do most everything, except only you can’t actually participate in change approval polls. As a courtesy to the host, though, it’s nice to have notice of who’s coming so that we can be sure there are enough seats and refreshments, so if you plan to attend as an observer please contact the respective meeting’s host (listed in the meeting’s announcement paper) to let them know."
awesome, thanks for spelling this out
so was the `random_shuffle` overload without generator "transported" to a new `shuffle` overload? (i.e. was [N4316](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4316.html) voted in?)
&gt; Concepts(they allows us to precisely specify our generic programs and address the most vocal complaints about the quality of error messages) The goal of concepts is not to improve error diagnostic. Compiler should already give good error messages(it shouldn't matter if you use `enable_if` or `requires`). The goal of concepts is to reduce the syntactic overhead from defining and checking type requirements. That is why in the video it says "But we have new syntactic sugar for SFINAE", which is a reference to the Concept TS. &gt; Uniform call syntax(to simplify the specification and use of template libraries) Concept maps would work a lot better, and would be less controversial.
I'm not very familiar with modules, how would they help the build time? If you change the code for vector, you'll have to rebuild the module it's a part of and subsequently the code that depends on them will have to recompile if you changed the definition right? Link times don't seem to change either. But when I think of modules I think of basically syntactic sugar for a static library. **edit** ok I googled it. Sounds more like automatic prexompiled headers, so the header of the module is only parsed and compiled once instead of once for every object file that needs it. Cool for really large projects.
The most obvious thing is an automatic registration of modules, and not having to change linker options. As it is right now is okay, until you need to do any of the following: * Support anything other than Linux * Install a library and link with it on Windows * Run two (incompatible) compilers on the same system In general, to handle building cross-platform today means having to juggle include paths and all that jazz. Modules would make it easier.
I think Herb Sutter has a very similar table in one of his talks as well IIRC.
I haven't seen anything like that website before. It really made me laugh when I read your comment and then viewed the website :D
Run some benchmarks. Maybe they'll go for it if your code size shrinks or speed increases enough or (whatever is important to them).
This makes you bad and you should feel bad. edit: Nazis in da house!
As I've understood, the solution to modules is to install Linux everywhere. So, what are we waiting for?
If everybody wants to use modules ASAP, then having it in a TS isn't a problem, because universal adoption will make it the de-facto standard anyway, right?
How can you do a one-to-many (broadcast) message if you've moved the data to be sent? Moving the data on a `get()` makes perfect sense, but moving the data on `put()` eliminates the possibility of a very common use case in inter-thread communication.
Good thing that it was voted. Now this part has got some attention and tests.
No modules?!?!?! Wat the helll. And maybe no introspection too? :( EDIT: I've written this comment **before** watching. I was blown away when at 2:30 hitler said the same thing about reflection. Am I a Hitler descendant? :O 
And Linus influence... I hate his rant. If it was written by someone else then it would be just ridiculed by everyone. &gt;Quite frankly, even if the choice of C were to do *nothing* but keep the C++ programmers out, that in itself would be a huge reason to use C. Personal attack on a few millions of people. &gt;C++ leads to really really bad design choices. You invariably start using the "nice" library features of the language like STL and Boost and other total and utter crap, that may "help" you program, but causes: &gt; - infinite amounts of pain when they don't work (and anybody who tells me that STL and especially Boost are stable and portable is just so full of BS that it's not even funny) Meritorical arguments; maybe he should show how STL is not 'portable'. &gt;In other words, the only way to do good, efficient, and system-level and portable C++ ends up to limit yourself to all the things that are basically available in C. Basically available in C. Like OOP, generic programming or RAII? &gt;So I'm sorry, but for something like git, where efficiency was a primary objective, the "advantages" of C++ is just a huge mistake Yeah, C++ is inefficient, maybe he should show the benchmarks. 
&gt; Pimpl reduces that even further Except it's ugly design pattern which doubles the work.
I've been seeing more talk of C++20 than C++22 lately, unless you mean five years from now. At least there should be implementations of modules by 2017.
It can be really useful if you want clean interfaces without exposing any implementation. And I don't see how it doubles the work. The only difference between a pimpled and none pimpled function is the pointer indirection size_t SomeThing::countSomeOtherThing() { return m_d-&gt;m_vector_of_things.size(); } versus size_t SomeThing::countSomeOtherThing() { return m_vector_of_things.size(); } 
I've done similar things in the past. Now, unless performance and or memory management is a legitimate concern, I just use boost::asio. It does everything you could need, and more. The proactor pattern in use there is very flexible. 
It isn't supposed to be something to reduce compilation times but to reduce coupling to the bare minimum.
You can't say it about any library, mostly just C++. Most other languages have one consistent library across all platforms, such as Java, C#, Python, Ruby etc... and even when they don't, the semantics of their standard libraries are so simple as to leave little room for ambiguity. That can't be said for C++ which leaves waaay too many aspects unspecified or under specified. Linus isn't concerned about C++ as a formal language, his criticism is against the actual use of C++ for the development of real software. Sure in some abstract form C++ is very ideal but in reality no vendor knows definitively how the STL is supposed to be implemented, they all have different ideas about what certain things mean. As for it not being a problem with C++ on major platforms, Windows is considered a pretty major platform and MSVC's implementation of the STL leaves much to be desired.
Unity builds are a pretty brittle feature to begin with. Have you tried LTO? Also, personally I would try to keep Unity/LTO off for the majority of development so that I can mitigate the hit to incremental build times. I'm sure you have a reason why that doesn't work for you.
Given how long Python 3 adoption took (&amp; it still seems like no one actually uses it even if they have tried to add Python 3 compatibility), I would be surprised if such an option was viewed without a giant dose of skepticism.
Or if your programmers become more productive when they're able to use the improvements in the newer language versions.
I had to wipe the tears of laughter from my eyes three times.
Yes, you can import things via modules. It just doesn't do anything useful. Despite what they claimed when they announced obj-c modules, I've never actually seen an improvement in compilation speed from turning them on when compared to precompiled headers, and they *increase* symbol name clashes because they make it impossible to only include the specific header you need (e.g. including any Darwin header with modules enabled drags in [AssertMacros.h](https://opensource.apple.com/source/CarbonHeaders/CarbonHeaders-18.1/AssertMacros.h), which by default defines macros named `check` and `verify`).
&gt; One of the few things we were using from STL was wcout in a few console mode programs. The STL stands for Standard Template Library and usually refers to the containers and algorithms in the standard library. The iostreams are not usually included in that, and most C++ programmers who have had to work more deeply with it, will agree that it is a horrible mess.
I'm not a fan of *Pimple*, but - instead of wrappers calling actual methods, you can simply have the actual methods, and store only the private members (no methods) in the "Pimpl" struct. You then have no problem with exposing public variable members, either.
This is the best answer. Teaching someone who puts in the effort and wants to learn is great. Most people give up when they realize they have to put in work and can't just get your knowledge matrixed over to them.
It's still being revised for C++17. [N4531](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4531.html) is the latest revision, in response to LWG review at Lenexa (there were lots of fiddly things to get right, like stateful distributions and reseeding).
Barbarossa was actually delayed from its intended date even earlier in the year in order to go put down one of those pesky revolts in the Balkans (Greece, IIRC).
&gt; I'm guessing Bjarne wants C++ to continue reaping the benefits of the momentum in the C++ community right now, .... Well, I really wasn't expecting there to be a sensible interpretation of that statement. But, yes, I guess the fact that a lot of people now view C++ as a PL that can change and improve -- as opposed to the static thing it appeared to be a decade ago -- is a phenomenon worth encouraging and nurturing.
`'` means a character, and `"` means a string. Never realized there was a difference.
Well tooling like the Address,Memory, Leak, Undefined Behaviour, and Thread Sanitizers all work on C code.
&gt; Okay what is this concept fiasco I keep hearing about? Originally, there was a "kerfuffle" in the meetings and an agreement on concepts couldn't be reached between the two proposals(Doug Gregor's and Bjarne Stroustrup's)(see [here](http://www.gregcons.com/KateBlog/ConceptsWillNotBeInC0x.aspx)). After concepts were yanked from C++11, Bjarne Stroustrup's proposed the concept lite proposal. Later, Doug Gregor also proposed a simplified form of the original concepts(see [D3629](https://docs.google.com/viewer?a=v&amp;pid=forums&amp;srcid=MDIyMDc3NjUwMTczOTM0Mjk3NjABMDY0MzIwNzAxMTY2ODcxNjg5ODABTXN4MjR4YjZ5Q01KATAuMQFpc29jcHAub3JnAXYy)). At the time there was still caution about the possibility of concepts maps, since the only reference implementation was the horrible implementation in GCC. Futhermore, since it wasn't Bjarne's proposal, he proposed that concept maps remain dead(see [here](https://docs.google.com/viewer?a=v&amp;pid=forums&amp;srcid=MDIyMDc3NjUwMTczOTM0Mjk3NjABMDY0MzIwNzAxMTY2ODcxNjg5ODABOUFfWHE1SUdXSndKATAuMQFpc29jcHAub3JnAXYy)) for the ridiculous reason that "It’s a failed approach with an inferior model of concepts compared to Concepts Lite", which is never fully explained in the paper. However, since that time, Larisse Voufo has implemented concepts in clang(see [here](https://www.crest.iu.edu/projects/conceptcpp/)), including: * constrained template parameters * implicit and explicit concepts * concepts overloading * concepts-based overloading * use-patterns * associated types, functions, and requirements * concepts refinements * explicit refinements * late-check Also, she has done research on solving the problem of name lookup with concepts(which was a sticky point in the original concepts). All this research is being ignored by the committee all because of the unfounded argument that the original concepts proposal was "fundamentally flawed". 
/facepalm
It looks like 2 in 1. It's the type-erasure of std::function (without heap allocation) with the argument binding of std::bind. Personally I'd make DeferredCall just take a callable, no arguments, and expect users to call it with a capturing lambda or a std::bind - I think otherwise you're reinventing more wheel than you need :) Even if it does take args, you could internally call std::bind to save yourself some work.
You are absolutely right. I wasn't aware that std::bind does not allocate before STL pointed this out in a comment.
'h' is a char "h" is a string, thus a char[2] = { 'h', '\0' }; basically, double quotes define null terminated strings (and his elements are characters)
Also, you aren't using aligned_storage - your char buf doesn't have the proper alignment. Note that std::function is smart and avoids dynamic memory allocation for sufficiently small function objects. Function pointers and reference_wrappers are guaranteed to activate this, the rest is implementer discretion. In VC 2015, anything up to and including the size of a std::string counts as small.
Sometimes a simple message with no payload data (a command initiating a state change in the consumer thread, for example) is enough. So it makes sense to instantiate `Msg`.
Sure, if you have your precompiled headers set up correctly &amp; don't have any modules for your own project (which I believe is true - I believe modules are at this time restricted to base system only), modules probably won't make much of a difference. However, precompiled headers frequently aren't &amp; there's a maintenance burden since it encourages fragile headers (since it's easy to forget to include things). So think of the current ObjC modules as basically adding precompiled headers to all projects for free without the maintenance burden. I was unaware that AssertMacros are dragged in. Have you filed a radar? Maybe it's unexpected behavior. In theory modules are specifically not supposed to drag in unrelated macros unlike regular headers.
How the hell vector is too abstract? Ho it could be *less* abstract? The same with string, especially that you could just access underlying data.
At the time we made this decision, STL spec had just changed so that you had to do: &amp;s[0] to access underlying memory, and *then* you weren't guaranteed the memory was sequential. (It was in nearly all implementations, but not guaranteed.) So, you couldn't use std::string or std::vector&lt;byte&gt; for buffer I/O. We rolled our own, and haven't looked back since.
I guess you're describing a situation where besides the private data, you have additional internal methods that you don't want to declare in the publicly visible class/struct? If that's the case, I agree - I don't see a nice solution without stated drawbacks.
Oh interesting. Do you know why unity builds are much faster? I would expect them to be slower since typically it's hard to parallelize them &amp; typically if they need to compile anything they need to compile everything whereas traditional builds can get away with compiling less. Have you done any investigation into why they are they able to skip rebuilding? It would seem like they wouldn't be able to but I've never really dug into them; do they strip comments whitespace &amp; pre-process the code &amp; just do a diff against what was previous built to determine if a build is necessary?
I am pretty sure that this is incorrect, at least when it comes to the std::vector, and I believe it changed for the std::string in C++11.
Switches don't support strings.
I'm not sure that there was ever a major implementation for either that used non-contiguous memory. However, according to this: http://stackoverflow.com/questions/849168/are-stdvector-elements-guaranteed-to-be-contiguous ... there was a time when std::vector was not guaranteed by the standard to be contiguous, much like std::string. As far as I know, with C++11, both are now guaranteed to be contiguous, but that's about 10 years too late (for the particular decision I am describing).
Many implementation of std::function will also preform a small buffer optimization - if your size is under a certain amount, no heap allocation will be performed, since it can fit directly into the std::function datastructure (perhaps with a little extra buffer allocated so that more simple functions fit.) This just makes the size of that buffer configurable and forces it as a standard. I don't hate that personally and I see its use in some applications. Sometimes also when I've been working on queuing up a lot of commands (things like command buffers for rendering) I'll also allocate those all to one gigantic dynamic array (think function_vector where all function push_backs go to the same object), instead of std::vector&lt;std::function&lt;..&gt;&gt; where the memory usage may be list ideal. Type erasure for function calls is one of the most useful forms of type erasure I think, and sometimes going a tad bit beyond is sometimes nice. It's also nice to know if you ever have to do this stuff in straight C for whatever reason.
Vector being sequential is guaranteed. Well, about your example, I don't understand the issue. Of course address of array is the address of first element. You want implicit conversion, like in builtins? I don't understand why.
http://www.reddit.com/r/cpp/comments/30tqx0/simple_question/
Oh, sorry to hear that question got downvoted to death. I think this is actually useful and better than named tuples (I used 2 `ints` in my example for a reason, named tuples won't work here ;). In the post you cited /u/tongari95 shows [the same thing](http://www.reddit.com/r/cpp/comments/30tqx0/simple_question/cpwfxlo). IIRC this has been usable without debug information in clang since 2013, and with debug information since late 2014 The same thing is used when returning a lambda from a function, for example range-v3's [calendar example](https://github.com/ericniebler/range-v3/blob/master/example/calendar.cpp) defines: auto by_month() { return view::group_by([](date a, date b) { return a.month() == b.month(); }); } The return type of `by_month` is `group_by_view_fn&lt;anonymous type&gt;` (+/- `pipeable` and other implementation details)due to the lambda, which is actually an anonymous struct with an `operator()(date,date) -&gt; bool`. EDIT: See [my post below](http://www.reddit.com/r/cpp/comments/39fe55/named_multiple_return_values_with_anonymous_types/cs309hs) for how this would look in C++11 and why this really really useful. 
Yes, the concrete return type is not always important. In the particular case of ranges and range views however, see the range view example in [my previous comment](http://www.reddit.com/r/cpp/comments/39fe55/named_multiple_return_values_with_anonymous_types/cs2zvih), you would not be able to return the _same_ range view otherwise. They call them Voldemort types because one cannot write down the type _even if you want to_ (the language doesn't allow it if a lambda is involved). In C++11 one could type-erase the lambda e.g. using a `std::function` and return a _different_ type: auto by_month() -&gt; view::group_by_fn&lt;std::function&lt;bool(date,date)&gt;&gt; { return view::group_by([](date a, date b) { return a.month() == b.month(); }); } The performance of this is much worse than that of `group_by_view_fn&lt;anonymous type&gt;` tho, and since ranges are typically tight loops this feature is not only nice to have, but really important for performance.
I got an F in c++ this year.. If it werent for u...
You would rather get a C in F, wouldn't you?
&gt; The language is so complicated already Agreed, so much indeed that the feature is already in the language: http://ideone.com/Ir1Hpu
Not an engineering marvel. It's a huge old tool that gets the job done, and is just getting patched up all the time. Unfortunately everyone has agreed that it's the ultimate language because you can get very low level and optimize stuff. For me working with C++ is like having one single tool that will let me build a whole house from the bottom up, but then I'll even have to make my own screws.
&gt; C++ needs simplification, or else it will become an engineering marvel that nobody can use to its full potential Isn't that already the case? I can use C++, but i am in no way a specialist.
One of its nasty features as its system of pointers. I accidently created one SO lethal, its crashed the HP 9000 minicomputer it as running on by not trimming off old ones.
I find it simpler to use Python and C. Plain old C for the optimized bottlenecks, Python for everything else.
I have the impression that with some training you can, but rvalue references are getting out of control IMO
Fortran? No thanks! 
Pimpl also guts performance
Just to add, case labels need to be constant expressions if I remember correctly. 
Maybe a C+ in F#?
He must make a promise first. 
Bring me a Ruby book.
I see this movie meme everywhere, what movie is this?
Depends on the wife?
It's been too hard to use since its very inception.
How can any of it be good, considering they met thanks to c++?
I finally had a concrete metric for measuring my education and growth in computer science: I understood more and more of the jokes in /r/ProgrammerHumor . Now I see I'm still splashing in the kiddie pool. This stuff is way over my head.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Downfall (2004 film)**](https://en.wikipedia.org/wiki/Downfall%20%282004%20film%29): [](#sfw) --- &gt; &gt;___Downfall___ ([German](https://en.wikipedia.org/wiki/German_language): ___Der Untergang___) is a 2004 German [war film](https://en.wikipedia.org/wiki/War_film) directed by [Oliver Hirschbiegel](https://en.wikipedia.org/wiki/Oliver_Hirschbiegel), depicting the final ten days of [Adolf Hitler](https://en.wikipedia.org/wiki/Adolf_Hitler)'s reign over [Nazi Germany](https://en.wikipedia.org/wiki/Nazi_Germany) in 1945. &gt;The film is written and produced by [Bernd Eichinger](https://en.wikipedia.org/wiki/Bernd_Eichinger), and based upon the books *[Inside Hitler's Bunker](https://en.wikipedia.org/wiki/Inside_Hitler%27s_Bunker)*, by historian [Joachim Fest](https://en.wikipedia.org/wiki/Joachim_Fest); *[Until the Final Hour](https://en.wikipedia.org/wiki/Until_the_Final_Hour)*, the memoirs of [Traudl Junge](https://en.wikipedia.org/wiki/Traudl_Junge), one of Hitler's secretaries (co-written with [Melissa Müller](https://en.wikipedia.org/wiki/Melissa_M%C3%BCller)); [Albert Speer](https://en.wikipedia.org/wiki/Albert_Speer)'s memoirs, *[Inside the Third Reich](https://en.wikipedia.org/wiki/Inside_the_Third_Reich)*; *Hitler's Last Days: An Eye–Witness Account*, by [Gerhardt Boldt](https://en.wikipedia.org/wiki/Gerhardt_Boldt); *Das Notlazarett unter der Reichskanzlei: Ein Arzt erlebt Hitlers Ende in Berlin* by Doctor [Ernst-Günther Schenck](https://en.wikipedia.org/wiki/Ernst-G%C3%BCnther_Schenck); and [Siegfried Knappe](https://en.wikipedia.org/wiki/Siegfried_Knappe)'s memoirs, *Soldat: Reflections of a German Soldier, 1936–1949*. &gt;The film was nominated for the [Academy Award for Best Foreign Language Film](https://en.wikipedia.org/wiki/Academy_Award_for_Best_Foreign_Language_Film). &gt;==== &gt;[**Image**](https://i.imgur.com/IYhUgtr.jpg) [^(i)](https://en.wikipedia.org/wiki/File:Der_Untergang_-_Poster.jpg) --- ^Interesting: [^Parvenu](https://en.wikipedia.org/wiki/Parvenu) ^| [^Death ^of ^Adolf ^Hitler](https://en.wikipedia.org/wiki/Death_of_Adolf_Hitler) ^| [^Conversation ^with ^the ^Beast](https://en.wikipedia.org/wiki/Conversation_with_the_Beast) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cs33r43) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cs33r43)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Cython?
It doesn't? Where does it store the bound arguments?
Denying is a bit harsh :P I know you are joking but I feel people don't really appreciate how hard it is to standardize something, in particular given that most of them do it in their _free time_. In my free time, for example, i don't write proposals, implement them in compilers, take holidays to flight to wherever the committee is meeting, defended them against 100 people that find 1000 flaws in it, go back home to improve them, and repeat the whole thing every six months for years.
I can't seem to load the link. Anybody else have issues? Or a mirror they could throw up? P.S. Bjarne, you da man. I wanted to be able to say that one day. Edit: Finally able to reach it
Do you think aspiring actors do the same thing to celebrity actors doing AMAs as you're doing right now? Why not?
I work in scientific computation, and more and more of us are just gravitating *back* to using Fortran, except this time we're just wrapping it all up in Python because F2Py is fucking brilliant and simple. So what you get in the end is a blazing fast number cruncher that you execute with a clean, idiot-proof Python API. 
Those with great power have great responsibility.
Biar-neh. Biar-nella.
That book is a bit misleading, C++ became simpler to use. C++ compilers became harder to write.
C, while fantastic for low level, is hard to optimize. While indirection is an easy abstraction, it makes compiler optimization harder due to limited type based aliasing.
Wow. I am pretty sure this video had the opposite effect on me compared to what was intended. 
The current rules require opt-in for active projects though. Abandoning the project would give them the ability to add malware to this popular project without needing to change the rules. Abandoning it gives them exactly what they want, so use their rules against them until they do possibly change them.
Why not do an AMA? Maybe get some people from the commitee to help out or provide different perspectives and talk this over the Reddit way.
One of my biggest gripes with C/C++ has always been the existence of pointers. Every other sane, usable language on this planet passes everything by reference every time, all the time. And then they provide deep copy operators for when a user needs it, like once every century or something. It's the safe, fast, reliable thing to do This isn't particularly the fault of C++. It's really a huge glaring mistake that Dennis Ritchie made way back when he was developing C, but in all fairness it's difficult to criticize him, because we only know the mistake with the benefit of hindsight. FORTRAN66 was the very first ever attempt at a call-by-reference standard, and it wasn't clear back then as it is today whether the call-by-value standard was a horrible idea destined to be abandoned. The decisions Ritchie made weren't necessarily bad decisions in the context of what he knew then. They're bad decisions in the context of what we know *now*. Nonetheless, I think it's productive to recognize that some of the biggest problems that C++ struggles with today can trace their origins all the way back to C being developed in the ALGOL tradition. And there's no going back from that now. It is what it is. But understanding the past might help us chart a better future.
Most of the C code I end up writing for resolving python bottlenecks don't use non-optimizable indirection. Most of it is scientific computation working on large arrays and scaling in parallel is my biggest priority. Much of the difficulty in optimizing C comes from coding styles using indirection that cannot be resolved at compile time. 
You can say that but all I'm hearing is nutella.
large arrays of primitives is always going to be aliased to itself. A problem for optimizers is to recognize disjoint access and perform some kind of flow based aliasing. This in turn guarantees safety for things like reordering load/store, vectorization, etc. Often, the cost to do these things in an array is to perform runtime check because the language couldn't tell us things are disjoint. Good news is these runtime checks are mostly going to be highly biased (assuming datasets will be disjoint) and branch prediction will do its job.
Thanks! Cool! I didn't knew this, always thought it was freely to allocate memory if it wanted to.
I work with C++ for a living, I'm actually pretty happy with the language as it stands now. New things are always nice, but I'd rather they take their time and not push something in just because it's new and exciting, because it just makes my job harder when poorly thought out features start cropping up, especially when they have vague syntax and are easy to invoke by accident.
You can go right ahead and play by their rules. I choose not to just put up with this bullshit and publicly shame them at every opportunity until they change their awful policy.
That's the opposite of a mistake. The distinction between values and pointers exists in the hardware, and C's machine model maps to the hardware directly (well, hardware as of the 1970s). This is *even more important* today, because modern hardware's elaborate memory hierarchy means that processors hate indirection. Accessing contiguous things is blazingly fast, traversing data structures infested with pointers is agonizingly slow. And since C++ prefers value semantics by default, you get locality by default, which is awesome. Now, owning raw pointers are a problem, but they have been solved by shared_ptr and unique_ptr.
What the fuck kind of language requires you to get variable names right ;)
It seems that latest version of c++ try to care about the developer, but it seems it introduce more traps. Hope c++14/c++17 will be better. 
Dunwich Technologies?
&gt; One of my biggest gripes with C/C++ has always been the existence of pointers. Every other sane, usable language on this planet passes everything by reference every time, all the time References are just a variation of pointers, so your issue is with value semantics and not with pointers. &gt; Every other sane, usable language on this planet passes everything by reference every time I hope you don't mean to include Java or C# in that since these are pass by value by default, with pointers being passed by value. /pedantic, the point just keeps coming up. As /u/STL points out having to access every object with the indirection of a reference/pointer is bad for performance. What he does not mention is issue with compiler optimization, objects passed by reference could be touched by every other method call you make and the compiler has to limit its optimizations accordingly. In contrast objects passed by value are local, nothing else can change them and the compiler is free to optimize as it wants.
FORTRAN MASTER RACE!!!1!
I think if you use a universal reference with `std::forward` you can avoid writing two `put()` methods. It would copy lvalues and move rvalues, allowing the caller to decide which strategy to use. template&lt;typename T&gt; void put(T&amp;&amp; msg) { impl_-&gt;put(std::forward&lt;T&gt;(msg)); } Then Msg msg; queue.put(msg); // copied queue.put(std::move(msg)); // moved queue.put({message contents here...}); // moved I might be completely wrong about this... I'm new to modern C++ and a lot of this is still confusing!
Note that even though the introduction seems to be in Russian (with *very* weird Youtube-generated subtitles), the actual talk is in English and quite understandable.
Nothing I said means that you can't publicly shame them. But immediately abandoning a popular project like Boost only gives them more advertising money and gives more users malware. At least make them work for it.
Yeah, aliasing greatly complicates optimizations. Good catch, forgot to mention that.
&gt;This is even more important today, because modern hardware's elaborate memory hierarchy means that processors hate indirection. Yes, processors hate indirection. But memory loves it. Your attitude in this post kind of perfectly encapsulates what's gone wrong with C++ development. You have forgotten that most of the userbase out there are not seasoned veterans and uncompromisingly perfect programmers. And in doing so, you have begun to trade away stability and robustness in exchange for fringe performance. The practical reality that software developers out there face every day is that whatever you're gaining by eliminating indirection is entirely, miserably lost by the introduction of excruciatingly stealthy memory leaks and the ease at which less-than-perfect human beings will unnecessarily duplicate data. And this is why an increasing number of people believe that C++ is becoming just an engineering marvel that nobody *new* can actually use effectively. Your easy way out of this is to just yell at people to become better programmers, but that doesn't actually help them do that. It just makes this language exceedingly hostile to newcomers and condemns it to eventual obsolescence. &gt;Now, owning raw pointers are a problem, but they have been solved by shared_ptr and unique_ptr. Right here is the most tragicomic part of all of this discussion. Passing by value is such a horrendously bad idea for memory management that C/C++ was forced to provide optimizable indirection to the overwhelming vast majority of the user base who just resorted to raw pointers everywhere. I mean it's better late than never, but I feel compelled to point out that Fortran figured this out 50 years ago. We shouldn't pat ourselves on the back too hard for re-inventing the wheel.
Sir, I love you so much! Thanks for making C++!
&gt; You have forgotten that most of the userbase out there are not seasoned veterans and uncompromisingly perfect programmers. C++ focuses on value semantics which is easier for new users to understand than pointers and references since types work the same way integers do. &gt; And in doing so, you have begun to trade away stability and robustness in exchange for fringe performance. Most very smart engineers in C++(such as Alex Stephanov, Sean Parent, John Lakos, etc) agree, that focusing on value semantics and avoiding pointers not only makes code simpler but also leads to more robust and stable software &gt; The practical reality that software developers out there face every day is that whatever you're gaining by eliminating indirection is entirely, miserably lost by the introduction of excruciatingly stealthy memory leaks I don't see how memory leaks can be introduced when developers are not using pointers.
&gt;References are just a variation of pointers, so your issue is with value semantics and not with pointers. The concept of a pointer does not belong in call-by-reference languages. Therefore having a gripe with pointers is equivalent to having a gripe with call-by-value semantics in general. And I stated my issue with value semantics explicitly later in my post too. So not sure what you're objecting here. &gt;I hope you don't mean to include Java or C# No, I don't, given that neither of them are sane, usable languages. We use them anyway, of course, but that has to do with industrial/commercial inertia. In case you were wondering, I don't believe C++ is sane or usable either. But again, I torture myself with it anyway because I have to. &gt;What he does not mention is issue with compiler optimization, objects passed by reference could be touched by every other method call you make and the compiler has to limit its optimizations accordingly. In contrast objects passed by value are local, nothing else can change them and the compiler is free to optimize as it wants. Please see my response to him on the subject of shared and unique pointers.
Well, I don't know much about history. Maybe you're right, but that would be ridiculous for vector. And even if, who sane would implement it using other data structure? And what would it be?
Just some background, Sean Parent leads the mobile and web development at adobe. So the software he writes has to work on machines with low memory requirements. Even before that, he worked on Photoshop back in the days when memory on computers were much less than what we have on phones. So I do take their advice, not because of some fad, but because it has proven to be very successful.
Never thought I had a chance to see you here! Thank you for C++.
I'm very excited about this program, which has been in the works for the last few months. We CppCon organizers are very thankful for Bloomberg's generosity and dedication to the community. Now all three of the major C++ conferences have a student attendee program which provides some form of travel stipend! -- Bryce, CppCon/C++Now organizer
https://youtu.be/s-mOy8VUEBk
 void DoStuff(Thing* t); // Much better! I disagree with this. Raw pointers shouldn't be used anywhere at all IMO as it could encourage use of new. void DoStuff(Thing&amp; t); // That's more like it
Even DoStuff should take shared pointers because now you have to make sure destructing doesn't happen while DoStuff is running, which defeats the point of shared_ptr. &gt;If you are putting 100% of your stuff into shared_ptr... well, maybe Java is right for you! shared_ptr has so little overhead that such a statement is extremely exaggerated.
Every compiler caches them, at least at the level of preprocessing tokens (well, every compiler that came after CFront, which actually re-parsed headers). They just don't persist between TUs.
&gt;shared_ptr has so little overhead that such a statement is extremely exaggerated. How is it exaggerated? Shared pointers do have a **significant** amount of overhead. When discussing overhead one must consider it with respect to the alternative. Copying a word sized value is incredibly fast compared to incrementing an atomic integer through a virtual function (due to shared_ptr's type erasure), as well as copying the deleter and two word sized values. Basically, if your function doesn't need to take ownership of the pointer, just pass in a reference to the underlying value.
Pointers are fine. I'm not sure how much of an amateur someone would have to be to see a pointer argument and suddenly use new. If you have a pointer as an argument to a function you know that it is a reference semantic instead of a value semantic, which is valuable information. Also certain objects like atomics can't be moved, so a vector&lt; atomic&lt;float&gt; &gt; then can't be moved. A unique_ptr to the vector can be moved however. Edit: I think I was mixed up with a vector of atomics. Atomics can't be moved, and a vector&lt; atomic&lt;float&gt; &gt; can't be initialized using a default value (I think) but the problem I worked around with atomics is now hazy. At some point I used a unique_ptr to make sure I didn't initialize a vector, because once initialized, the vector can't be resized. So initializing a vector without allocating memory, then allocating it later is not as straight forward. This came into play for me when using a map, which will automatically create an entry with a key when you use operator[key] if it isn't already there. Maybe the vector can be reassigned instead of resized. Whew!
Ever? If so I didn't think that was possible.
Similar feeling here... I'm halfway through the C++ primer and thought that I knew a good deal of C++ until I watched this video.
`Thing*` indicates that it is permissible to pass a `null` value or an uninitialized value. `Thing&amp;` indicates that only initialized, non-null values are permissible. Basically prefer to use `Thing&amp;` by default.
As someone who's learning C++ to implement on his Master's Thesis later, I salute you, you great Danish genius!
I'd personally do this: void DoStuff(shared_ptr&lt;Thing&gt;&amp; t); This means that you avoid the refcounting overhead when passing to the function, but the function can then take its own reference by copying it if they need to. And you avoid any use of a bare pointer. This is safe of course, because the reference won't be invalidated during the call. And for cases where there's no ownership sharing, you can just use `unique_ptr` which has minimal overhead.
tell me more about this F2Py.. I'm trying to leverage my math degree into something Data Science related and I just took a course based in Python. I was thinking of learning C++ but this sounds like a much better solution for me given the time commitment of learning a new language
&gt; If you have a pointer as an argument to a function you know that it is a reference semantic instead of a value semantic, which is valuable information. Pointers provide value semantics. If you want reference semantics, you use a reference. &gt;I'm not sure how much of an amateur someone would have to be to see a pointer argument and suddenly use new. In my experience, the amateur is the one who wants to pass a reference to something by passing in a pointer, when a reference is freely available, safer to use, and documents the precise requirements (non-null initialized value).
Thanks a lot for your explanation!
IIRC Herb Sutter at CppCon encouraged use of bare pointers where there is no ownership. Not just for performance but to express intent more clearly.
So what do you do to know if a function is going to modify an argument or not? 
C++17 will include [`std::observer_ptr`](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4282.pdf) for this purpose.
There is an atomic increment, but it isn't through a virtual function. What makes you think that?
Last I benchmarked an atomic integer increment (required by shared_ptr having a thread safe count) was ~300x slower than a regular increment.
Why shouldn't it be?
Can't you use a regular reference then? 
Because checking for null pointers is not fun and we already have `optional`.
Obviously, there is where it becomes important to distinguish "slow" code and "fast" code. I agree that `shared_ptr` has negligible overhead in most cases, but I disagree that your code should be littered with `shared_ptr` over raw pointers "just in case". Know your object lifetimes. Make good decisions about when it makes sense to spread ownership of something. What if you have a function that accepts pointers from both `unique_ptr` and `shared_ptr`?
Never ever. (If the functor or arguments allocate when copied/moved, that's their doing, not bind's.) Another way of putting it: bind is like make_pair in that it doesn't allocate memory itself.
`const T&amp;` if it's not modifying, `T&amp;` if it is? Where's the difficulty?
shared_ptr/weak_ptr's atomic refcount operations are **not** performed through virtuals. (All objects have refcounts in the same location, regardless of their origin as plain vanilla, custom deleter, make_shared, etc.) Source: STL maintainer. Also, deleters aren't copied. They live in the control block.
The performance argument should usually be a non-issue, anyway, because when you really need refcounting you will need to have *something* that refcounts with or without `shared_ptr`; after all you're not using `shared_ptr` all over the place just to fix some use-after-delete's that came out of an unclear design, *right*? A rule of thumb I have now is "*you should use `shared_ptr` if you need `weak_ptr`*"... which I don't know why it works, but it happened to be correct for me.
All pointers are nullable, including `shared`/`unique_ptr`, it's pretty much an axiom. If you read the paper you'll notice that `observer_ptr` is mainly intended for &gt; Code that predates or otherwise avoids [`shared_ptr` / `unique_ptr` / `optional`] it's a drop-in replacement for raw pointers that improves documentation.
Then how would you know if an argument which is not to be modified by the callee is passed by reference or value? `func(T t)` and `func(const T&amp; t)` mostly behave the same as well.
I'd rather do something like this: auto foo() { struct result {int i, j;}; return result {1, 2}; } 
I find this argument very weak considering how common calls to member functions are, which are no better than a free function taking a reference-to-T.
&gt; Member functions can be declared const for one thing. But you can't tell if they are const from their use: x.DoFoo(); gives no more constness information than the free function taking reference-to-(maybe const)-T: DoFoo(x); 
Awesome, I'm looking forward to competing!
Question: is it even possible to write the name of the type in this case if all you have is a function that returns something like this, or is like "Voldemort types" in D?
No point in having the Big Red Button, if you're never going to push it.
The hardest part was deciding on a name!
These CPUs with SIMD etc. etc. also have lockfree atomic increment.
If you find neither C++ nor C# sane or usable, then what do you consider a good language?
No, pointers provide reference semantics too. They just do it in a different way to "references". Dereferencing the pointer yields a reference to an object. 
`str` would be `const char *`, despite `"fish"` being `const char[5]`. Since C++14 there are literal `std::string`s too: #include &lt;string&gt; using namespace std::literals; auto str = "fish"s; 
Yes, those lock free atomic increments are not free or cheap.
I got boned by this just the other day. Something along the lines of: void AsyncDispatch::PostMessage ( const Message&amp; message ) { /// } generated a baffling compiler error, because it was being preprocessed to PostMessageW somewhere in the bowels of winapi land. 
It's tough online to find good reliable sources. If you're wanting to learn the new stuff in C++11/C++14, I really have to recommend Scott Meyers' Effective Modern C++: http://www.amazon.com/Effective-Modern-Specific-Ways-Improve/dp/1491903996/ref=sr_1_1?ie=UTF8&amp;qid=1434079277&amp;sr=8-1&amp;keywords=effective+modern+C%2B%2B&amp;pebp=1434079273847&amp;perid=2C075EFBB1FD49F990C9 Once you're familiar with what's in the book, then you can watch CppCon videos and Boost Con videos for more intermediate and advanced topics: https://www.youtube.com/user/CppCon
Sweet thanks.
I've never been able to get std::function to avoid dynamic allocation even with a simple void function pointer. I override operator new to throw an assertion and it always fires. What am I doing wrong?
Also interesting is that you can do inline initialization: auto foo() { struct {int i=1,j=2;} result; return result; } Unfortunately, that isn't helpful if you want to return local values. 
Possibly, dependent upon the context. You could use a reference if: - the value is guaranteed never to be null - the function doesn't require the shared_ptr to be stored or passed elsewhere as part of its functioning I would certainly use plain references or const references where this is possible.
I never need to call into the windows api directly, as all my windows specific code is buried in a segregated platform layer, but windows still manages to make itself a nuisance in my cross platform code. 
It's not possible for it to go out of scope: the caller holds a reference count on it in its stack frame. Consider if `DoStuff` is actually doing this: container.push_back(t); That's going to increase the refcount by 1 if I pass by reference. If I pass by value it's going to increment by 1 on entry when the t argument is copy-constructed, increment by 1 when the container element is assigned/copy constructed and then decremented by one when the scope is exited and the t argument is destroyed. That's 3 times I have to lock and unlock a mutex (or the equivalent atomic op) vs. 1, so this does have a concrete benefit, especially in a multithreaded context.
Because if you want non-nullable, you pass a reference.
Can you provide a code snippet of what you're doing?
A simpler solution I feel is to change the language so that anything passed by const value is not copied - this works if there are no const_casts - but this ship has probably sailed too far already. You could then write void DoStuff(const shared_ptr&lt;Thing&gt; t) void DoStuff(const unique_ptr&lt;Thing&gt; t) This improves performance in other places too. In fact, I feel the whole parameter passing thing needs a slight overhaul in presence of templates for performance reasons.
And why was that, f4hy?
Modern Fortran. Python (and Cython). Perl. Ruby. I'll even reluctantly add Swift into the mix, but leave out Objective-C.
N4542 seems to have permitted variant&lt;int,int&gt; and made get consistent with the tuple interface since I last looked, which is great, but the visitation didn't keep up: the visitor can't distinguish between the alternatives of variant&lt;int, int&gt;... I'd also really like a form like visit(var, v0, v1, ... , vn) that applies vk to get&lt;k&gt;(var) where k = var.index() so you can do eg. visit(v, [](int) { /* use left int */ }, [](int) { /* use right int */ }); or something. Btw, did you implement constexpr variants too? That bit sounds like a pain.
How do you infer the erased message type at the receiving end? `dynamic_cast` ?
There will surely by a notme_ptr typedef somewhere in my codebase
&gt; Also interesting is that you can do inline initialization In-class member initialisation is a feature introduced in C++11, which is an alternative to constructor initialisation.
To me there is value while coding in doing things inline (like with lambdas). Going out of the function, maybe possibly to a header file, thinking of a name for the struct, figuring out good names for the data members, writing a bit of documentation... it just breaks my train of thought completely. I come back to the function and it feels like "What was I doing here again?" Doing it inline means i can give them "better" names than 0, 1, 2 (which is what I get with a tuple), and continue with what I was doing. This is the only situation where I use it, and for me it works so much better than tuples! Removing an element of a tuple is a pain since the indices of the other elements might change. And as opposed to a real struct, if I want to return a new element I just need to change things in one place. Until I have completely solved the problem I am probably not 100% sure anyways if I am returning exactly what I need. Sometimes I return too little/too much. After solving the problem I put them almost always in their own structs, but that is also easier since I already gave them some names, used them, and know how that worked out in practice. Everyone programs differently, but this is just the way my brain works best.
Yes I sometimes do this too.
Yes, it was moved into the Library Fundamentals TS, so we might see it in C++17. Some standard libraries are already implementing the TSs.
youtube link: https://www.youtube.com/watch?v=CQANOtQ9IvE
&gt; What's the use of passing a reference in the first place? To have pointers with value semantics. So it's a *little* harder to create a null/invalid reference, but certainly not impossible. You are correct that many of the problems with pointers, regarding ownership and scope, apply to references.
I doubt it requires any major changes to calling conventions. As long as you don't remove the constness inside the called function, there should not be any problem. You cannot modify a const object inside the called function anyway, so there is no need to copy the original value.
Awesome! Thanks for the info. The more I learn about python and all the tools and wrappers available for it, the more useful it sounds. It's like.. the duct tape of programming languages. 
Any full-time student is eligible.
Not directly, but if the variable is declared const, you can't use non const member functions. That is the same as the free function of course, but you can make sure that the variable isn't modified. I think this strays pretty far from the original point of pointers still having their (albeit much smaller thank god) place in the language. Again, I'm not trying to stick up for all the nuanced rough edges of C++.
Ah, yes, you're right. In terms of being able to reassign the referenced pointer that is true. For the const reference cases that's OK, but for the non-const cases a value should be used. Thanks for pointing that out, it's a subtlety I missed here--I never do modify the reference but for safety and to inform the user it won't be modified that will need changing.
I wonder why this was. It seems like a relatively small and simple thing to add, which would have made sense for C++14.
And if you are then the virtual call is probably not anywhere close to your bottleneck.
It mostly comes down to the general assumption that if you're using C++, it's because you need C++'s performance. If you're using C++ in a context where you don't need to wring every last cycle out of your program (which is probably the overwhelming majority of C++ written...), most statements about "fast" and "slow" will be ridiculous nonsense. Most of the time avoiding `shared_ptr` for performance reasons will be a premature optimization, but that still doesn't mean that there aren't times where it's a massively useful optimization.
Thanks. I am interested in modern C++ myself, but unfortunately due to work requirements I have to make sure that the code is compatible with older compilers. That's why I'm looking for a way to migrate the codebase at least partially to C++11 while maintaining compatibility via an additional transformation step. The transformation output doesn't have to be particularly readable. I am considering writing such tool myself based on clang's libraries and I have some experience working with their AST, but my hope is that someone has already done (or at least started working on) this in which case I could contribute to existing project.
"Python is written in C" Wouldn't python be written in python :P (I know underneath python boils down to C) Also, yes, I agree that "C++ will make you a better Python programmer", but I feel that holds true for most languages...
Don't do it! You're making work for yourself, adding a layer of things to go wrong, and for what business advantage? I love C++11, but if you want to do C++11, start a brand-new project for your own education. Don't try and shoehorn bits and pieces of C++11 into your old legacy project that doesn't support it. You're opening yourself up to a world of hurt for nothing.
&gt; Shared pointers do have a **significant** amount of overhead. Citation really needed for this claim. Pointer management using `std::shared_ptr` is many times slower than pointer management using e.g. `std::unique_ptr` - but if your program spends any significant portion of its time doing pointer management, then something is badly wrong. I believe that if I did find and replace on any of the C++ programs I work on, replacing all the pointer management with `std::shared_ptr`, I would never be able to detect a practical performance difference! In real-world programs, the overhead of `std::shared_ptr` is so low that you should choose the solution you need for _design_ reasons, not efficiency reasons.
There's also the question of who deletes the `Thing*` - and you can even use a `Thing*` to pass in a pointer to the base of an array which contains many `Thing`s - so it's quite ambiguous.
&gt;Citation really needed for this claim. Pointer management using std::shared_ptr is many times slower than pointer management using e.g. std::unique_ptr Your next sentence makes the exact same claim mine does. It's as if you read one single sentence in my post and jumped to reply to it.
Well, if you come from a non-Indoeuropean language, I would argue that any modern Romance language is a better entry point for the rest than Latin. Even English is a better entry point for a Romance language than Latin (not to speak about Greek!). One thing is "help recognize some possible meaning for a word sometimes", and a completely different thing is "to become a better speaker of all Romance languages". Etymology is just that, leftovers and ruins from thousands years ago; you will not be a better speaker if you know that the word for mother and the word for wood are related in Romance languages, or that the word for the Pope originally referred to a person who built bridges. Classical languages are still taught because there is a corpus of knowledge that is the foundation of our Western Civilization written in those languages: from early philosophy and science (Greek), to religion (the New Testament was written in Greek), law (Latin), literature (both). I don't think anybody would put Ancient Greek or Classical Latin in the school to make you a better Romance language speaker, when nobody expects you to even speak it, no matter the level.
&gt; Your next sentence makes the exact same claim mine does. It's as if you read one single sentence in my post and jumped to reply to it. It's true that I'm mainly disagreeing with the bolded word "significant". My claim is that there is an _insignificant_ amount of overhead and that you shouldn't worry about it.
Video Gaming, OS Development, Databases, VM other languages use for their runtimes, ... Most language interop mechanisms wind up using some variation of C function calling convention, so any industry that wants multiple languages to interoperate and use one of the following: Swift, Rust, Ruby, Java, Javascript, PHP, Lua, Scala, Graals, Cobol and others. I have called C functions from those languages, know how to call C from JVM languages or read docs (Rust, Swift, Javascript) that said how that language does it.
As smarmy as this is it is hard to say it is wrong. The way it reads it is like they think they are revealing some hidden truth that is beyond reproach. It makes me want to punch them in the face and I am a C++ dev.
Article may read as back-patting to a C++ dev. Might be more informative to Web developers who've never seriously looked at C++.
Just to clarify, ktoll2 is correct, he/she just didn't word themselves very clearly. Python isn't written in another programming language, it's implemented in another language. It's a language to instruct computers to do things. People write software that, in the case of Python, interprets the syntax and transforms it into instructions for the computer. Python's traditional and most commonly used *implementation* is called CPython and that is indeed written in C. But technically, Python 'is written' in Python and like all languages, implementation agnostic. 
No, Python is not in any sense written in Python unless you're talking about PyPy.
Think about this - all code ends up being "procedural" eventually at the machine level. So when we use the word "procedural" vs "OOP", it's best to look at it as labels that help to define the particular ways in which code can be implemented, not as a strict description of how that code works. Using a procedural or object-oriented or functional paradigm is more about ways of expressing computations, or problems in different ways. For instance, OOP is one way of being able to abstract away and package up code for reuse in a manner that might not be as easy to do in a procedural way. It's about writing your code in a way that is best suited to your requirements, and the requirements of others. 
Check out [clang-modernize](http://clang.llvm.org/extra/clang-modernize.html).
I never thought about it like that, but smarminess is totally perspective driven. Perhaps someone who has only web dev experience would see it otherwise. I will read it again with that perspective in mind. Edit - After re-reading I could how a PHP or Rails dev without this knowledge could see this as simply surprising instead of preachy. I think the author intended a "Hey Surprise!" kind of tone an I totally mis-interpretted.
Right, macros is what we use right now and it's a bit of a mess, especially with variadics. Besides IDEs have tough times understanding this macro magic sometimes.
Games and HPC, besides that -- not really.
Is that really unexpected? Of course popular languages like JavaScript or python doesn't have the same popularity in the industry.
The majority of embedded systems too. Oh and desktop applications. And operating systems for that matter. Actually, besides web apps, where are you claiming it *isn't*?
Well... it **is** hard to argue with the basic premise. C and C++ hit the "hard but god damn useful to get things done" spot. So people who do those work hard and get things done - and they tend to do it in other languages, too.
Don't forget CLion https://www.jetbrains.com/clion/
&gt; It's true that `std::shared_ptr` introduces a performance hit - but a substantial one? Unless you're writing trivial programs, I strongly doubt it. My comment wasn't to say that it brings the speed of your entire program down. You're right that you probably will not notice a speed difference just by swapping a few pointers for smart pointers. However, the speed of smart pointer acquisition/release is indeed huge _compared_ to the almost-zero cost of just working with a pointer is something you have to keep in mind. If you have an extremely tight loop that is acquiring and releasing millions of smart pointers, you'll notice how "slow" it is. Atomic increment/decrement is a problem in those cases, but they are easy to avoid. I was only bringing it up to entertain this idea that `shared_ptr` somehow brings the speed of a program down to the level of Java/Python. &gt; Can `t` be null? Yes. I chose a pointer over a reference specifically to allow null. &gt; Who destroys `t` - `DoStuff` or its caller? In modern C++, this is no longer a difficult question at all. The answer is simple: not `DoStuff`. Pointers are no longer associated with ownership. &gt; Is this a pointer to a single `Thing` or the start of a C-style array of `Thing`s? This is a fair question. I'd argue that it doesn't really matter. Since there is no length being passed in, either it is clear that it is pointing to one item, or the function is inherently aware of how far it can run with that pointer. (The array is terminated some other way, or `Thing` represents some kind of cache objects that is always packed between `Thing` neighbors or something.) For my own code, I have introduced a `struct View&lt;T&gt;`. It holds a pointer and a count. This helps make things absolutely clear that I am referring to a range (sub array) of elements. &gt; If it can't be null and doesn't need to be destroyed, FFS pass a reference which enforces these properties at compile time. If it needs to be destroyed, pass an `std::unique_ptr&lt;Thing&gt;&amp;&amp;`. I try to avoid nullable pointers, and it isn't much work to avoid - or `boost::optional` is really good here, if you are already using Boost. I agree with pretty much all of thus. You just take it a bit too far. &gt; You should really avoid passing a raw pointer. Nope. I'm quite happy with the paradigm I've adopted: if a function accepts a pointer, that means null is acceptable, and the function will react appropriately. It's clean and simple. I have nothing against `boost::optional`, but I simply prefer to avoid more noise in my code. There's nothing wrong with using a raw pointer with the rules I've established. &gt; Honestly, I wouldn't worry at all about using `std::shared_ptr` because of resources. You should always prefer `std::unique_ptr`, of course, but that's because having unique ownership for the pointer means you know exactly who owns the pointer and exactly when it's deleted, because you have tighter control, not because of the near-infinitesimal cost of `std::shared_ptr`. Agreed!
I was expecting Chinese.
Huh. Did you read the article? &gt;So here’s the short answer: Learn C/C++
Python and C++ I think. 
&gt; Web Isn't all performance sensitive code at like Google &amp; FB written in in C++? 
Again, people are bundling c and c++ together, when they are now vastly different language... Not very surprising from someone from Google when u have a look at their coding guidelines though
I do disagree; C and C++ are inextricably linked. A good C++ programmer will have a solid foundation in C. Also C++ is not a "nightmare."
If you're not coding with move semantics and references, you're writing shit C++. This, and the lack of objects, templates, and the fact that there is a completely different standard library -- i would say bullshit - C is written differently, with different goals, in different style. Whether or not it's a nightmare is a persons personal opinion, here is a video of some of the issue: http://www.ustream.tv/recorded/47947981 
Video games, yes -- C++ is widely used and is still quite necessary. All of the other examples you cite are C, and have nothing to do with C++.
Or: Compiler bug considered harmful.
Well you're drifting pretty far off topic here. And you're picking out some random C++ elements to claim that the language is entirely different. (BTW C does have "objects", that's an abstract concept not a feature specific to C++...) And ironically, you didn't even mention RAII. But in any case, those things are fluff. At its core, C++ is *C* with extra niceties, hence the naming convention. So I repeat; a good C++ programmer will have a solid foundation in C. &gt;Whether or not it's a nightmare is a persons personal opinion Whether it's a nightmare *for you* is a matter of personal opinion. Maybe you've struggled to learn it? It's gained enough traction (again, being an *industry standard*) that I think it's safe to say the majority of us don't consider it a "nightmare."
I agree the FFI thing is all C, but I explicitly listed the V8 Javascript Engine which is C++ - https://code.google.com/p/v8/ MongoDB the most popular NoSQL is C++ - https://github.com/mongodb/mongo Per the Article Oracle database and windows are both mixed C and C++ projects. I left out, but should have included web browsers. I don't know why I am wasting my time though, you clearly put minimal effort into your posts and probably aren't interested in actual discussion. You seem interested only in minimizing C++.
When I help someone learn C++ I accept there are a number of epiphany points. Some people have trouble with pointers, function calls, objects, references, const correctness, whatever the first few times. After a while that person starts getting it. At first they might only get the mechanics of it, the results or the underlying principle, but rarely all at once. During this time people struggle with the language feature and force it into incorrect solutions. Then eventually everything around that concept clicks. Once "it clicks" they then see how to use it as part of solutions instead of it being a stumbling block in learning the language. For me I think RValue references just clicked last week. I thought I knew quite a bit up to that point but I can see how this can be used to describe things that simply cannot be done in other languages. Teaching them to someone will be very difficult. 
A bit of a click-bait title, and not too much content in the article. Bit of a shame. If analyzed properly and backed up by actual data, I'd expect something like Fortran to be quite high up in the list - old languages that are still in use by banks &amp; stuff but are hard to find people to maintain their systems for. &gt;And the hardest problems, the ones that the top engineers are asked to solve, will sooner or later hit some foundational C code. Well, here they put C and C++ in the same bucket. This same foundational C code you'd most likely write quite different in C++ than in C. The article should probably write about C only, and not C++. Just a bad article (I wouldn't even call that article) imho.
Good. Marginalization through the preponderance of idiots is always a good thing for people with skill.
&gt; The majority of embedded systems too. I highly doubt this. If I had to guess I'd say the majority of embedded systems are programmed in C, not C++. edit: I guess we are grouping C/C++ together? They are very different languages and the embedded industry treats them as such.
I'm talking about C/C++. Which is what the article is talking about.
&gt; Yes, processors hate indirection. But memory loves it. I think you only try to make this argument because you don't realize you are arguing with an implementer. As much as I hate microsoft, STL is one of the devs on visual studio (I think the lead STL implementor) and a freaking genius. Every time I have gone to argue with him on some vehemently anti-ms I always fact check myself and I am wrong. Also he is correct and it is trivially easy to check this with benchmarks. Memory usage is reduced with crafty indirection but execution time is increased with more queries to memory. All that matters is time in the end. As for the rest of your claims. Where your complaints are valid you are complaining about older versions that have language fixes in places now. RAII allows us to create smart pointers. Smart pointers and other resource owning objects allow us to balance Memory Usage, CPU time, Code Readability and other concerns as each project demands. Any forced strategy, particularly this references everywhere strategy interferes with this and forces decisions in that balance. If you need greater usability you have plenty of language options that follow the references everywhere strategy, (Java, Ruby, PHP, etc...). If you need performance it is hard or impossible to get the performance from them you can get from C++ and well formed C++ code is not always much harder to read.
And if that doesn't take them out, usually the physics and/or calc will.
&gt; And if he doesn't use pointers, then he's not writing memory-limited code. A neat feature of C++ is that it is specified pretty precisely what the compiler is allowed elide and optimize. Local copies of items passed by values can be elided which is why sometimes copy constructors are not called when items are passed by value to functions. https://en.wikipedia.org/wiki/Copy_elision You have no backing for any of your claims or arguments, back off.
I would say that functional languages abstract the ordering of your program, so anything that doesn't do that would be imperative. Which would mean yes.
That's because you lived your entire life in the darkness, programming to EE.... That C++ book is just a spot light of truth, pointed right at your eyes.
&gt;All that matters is time in the end. Sorry but this just made my head hurt. Most consumer grade software on personal computers can afford to be reckless with their memory footprint because they typically run on systems that far supersede their hardware requirements. That doesn't mean it's good practice in general. Mobile systems are still frequently memory constricted. Scientific computing applications on clusters and supercomputers are almost always memory constricted (I develop PDE solvers on an IBM BG/Q for a living). We are a long way away from memory no longer being a limitation in code development. Explain to me why I should care about CPU time if rampant copy constructor calls prevents me from running my code on the size of problem I want to solve in the first place? Am I not better off taking a CPU time hit from indirection in exchange for reducing my memory footprint so that I can actually use a larger physical domain? Your entire post is honestly one of the most egregious cases of horse tack. You're making proclamations about C++ efficiency that every single individual using the language on parallel systems would laugh at. &gt;If you need performance it is hard or impossible to get the performance from them you can get from C++ Modern Fortran, which happens to be pass-by-reference, begs to differ. It blows C out of the water. 
Cantonese (Yue) is equally valid as it's the primary language of Guangdong and Hong Kong, as well as large parts of Southeast Asia, which, while a much smaller number of total speakers, is a sizable number of major manufacturing areas. Yes, Mandarin has more speakers, but many of them are farmers.
No it was originally written/bootstrapped in OCaml. LLVM and allocation (jemalloc) are the only things written in C or C++.
Funny enough... I love programming but Calc is the fucking death of me. (I'm on my third time taking Calc I ... mostly from stupid tiny mistakes ) 
While you might write it differently, the underlying concept of whats happening still stays the same, even if it's "hidden" by C++.... So if you know C++ well enough to know what it's doing under the hood than combining it with C in this context isn't that bad (from what I can tell ^^^I'm ^^^still ^^^learning ) 
Only the compiler was bootstrapped from OCaml. The runtime was bootstrapped from C.
Oh, I do C++ and further think that C is dumb and that, bar existing unknown codebase and absence of a compiler, nobody should use C, not even for kernel-level work. That earns me [much dislike](https://www.reddit.com/r/programming/comments/7k4iz/linus_torvalds_rant_against_c/1ik) :-). I, too, do not really get the "hard" part. Yes, it does require that people grok basics of the machine operation and a thing or two about the language, but one can't, IMNSHO, be a professional in our field without it. I wouldn't go for the beauty argument easily, though. Yes, as in "life is beautiful...and complex, and has seemingly strange warts" :-).
&gt; mostly from stupid tiny mistakes many program bugs are just like this. in a way math is like programming -- it's binary: either you solved the problem correctly or not. 
Funny how you get downvoted when this is exactly true. If anything the article is talking more about C than C++. I guess very few people actually read the article.
&gt; Java, C#, Python, Ruby etc... and even when they don't, the semantics of their standard libraries are so simple as to leave little room for ambiguity Python stdlib covers much more area than the C++ stdlib : https://docs.python.org/3/library/ vs http://en.cppreference.com/w/ Still, the C++ standard lib description spans about 700 pages (from 480 to 1100) in the standard : http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4296.pdf
This is an FAQ: http://www.stroustrup.com/bs_faq.html#pronounce
&gt; But you should learn C. Because it’s the abstraction other languages use to understand the physical machine. Now that is complete and utter nonsense. If C was the abstraction used by other languages then they would suffer from arbitrary issues and limitations. For example no language would have had threads until recently, exceptions would be an unusable mess build on setjmp/longjmp and lets not even talk about the feasibility of most modern GCs. 
As a native Romance language speaker, I did not get a single advantage by learning Latin and Greek.
I hate it when people do this. It would be like correcting someone because they said "Spanish" instead of "Castillian".
Officially, but they do have their own dialect which is used more often, colloquially at least.
In a language like Haskell it figures out the data dependencies for you, and what you are describing is a data dependency, not a state based ordering of instructions. Feeding one function into the other is very different than saying: x = 1; y = x; x++; z = x; That depends on the order the statements are executed in. In your scenario f depends on the output from g. If g has no side effects, it doesn't matter when g is executed as long as it is ordered before f of course. Thus the compiler figures out the actual ordering of statements. 
&gt; it doesn't matter when g is executed as long as it is ordered before f of course I would say it very much matters then.
In C++ you can stack allocate a structure containing private data. In C you can't... All members are directly accessible.
You can go back and debug code, you can't go back and debug a math test
Which in a way is 'syntactic sugar'. You can stack allocate a structure in C; you must **manually** assure that you don't access *private* struct data. C has no concept of private or public members, but nothing is stopping you from not using certain members in some contexts.
&gt; How do become a better speaker of all Romance languages? That's the point I argued. You can't really derive the meaning of the words based on classic Latin etymologies. 2000 years passed, everything changed. Knowing Latin, if anything, would serve for the curious of language history.
You just have to take care to not slip any exceptions from the C++ guts into the C world.
Global Interpreter Lock(GIL?), I thought that was a Ruby thing, and even then just a CRuby thing. Do all versions of Python have that? Are there competing Python implementations?
At this point you are being so petty, holier than thou, petulant and wrong that I cannot continue this discussion. I can't say much about your copy ellision failures but I will try. Learn to use your compiler or get one that doesn't suck. I have measured it, it works. Facebook uses it at least according to Alexandrescu, on systems that handle many (millions?) of requests per second.
I didn't even read your post, as per my previous post I am no longer responding to you. I must assume this was full of trolling and half-truths like your other posts.
A magnetic needle and a steady hand.
Check out the early github repo, bootstrapping was a big event. Don't worry about it, though :P
&gt;It is obviously better than C, but most people are too feeble-minded to learn it, and usually die of an aneurism when they begin to learn how to use templates I died.
I thought the article was ok, until the author briefly addressed whether one should look at C or C++. I don't think that they are very similar; modern, idiomatic c++ looks almost nothing like C. And while OO is an important feature of C++ over C, it's odd to give it sole mention and ignore templates and generic programming. Although knowing some C on the small level is good (and is used on occasion in C++), for understanding memory layout, system calls, etc, I don't know that knowing C on the large scale is very awesome or helpful. C lacks some very basic tools that very broadly considered A Good Thing, like namespaces (or some way of scoping). Or that the language has incredibly few tools for abstraction compared to virtually any modern language. Anyhow, it's just annoying to still see people talk about C/C++, as though they were dialects and not completely different languages.
I posted on the blog a couple of comments, one point has already been made here, I'll make the other though. Why wouldn't you just use a std::function with a custom allocator? This seems strongly preferable to your solution as it involves much less hand rolling of code, and this sort of thing is the entire point of allocators in the first place: http://stackoverflow.com/questions/21094052/how-can-i-create-a-stdfunction-with-a-custom-allocator
As mttd pointed out, in 2003 (12 years ago), it was already guaranteed that vector had to be contiguous. You wrote that it was sequential in nearly all implementations, implying you found one that wasn't. Did you actually? If you didn't check all the implementations you supported and find one that didnt implement vector the way you wanted... that frankly just seems like wasting energy swimming upstream.
I wrote a threaded network server in Rust as a side project, and haven't used Swift at all. (I was not interested in Swift 1.0 but 2.0 puts it on my radar now) My interest in Rust started when I watched a youtube presentation on it that started out like - "you see these three ways you can segfault yourself in c++ just using the STL? those all won't even compile in rust". [Even though the rust code has the exact same memory layout and performance] My jaw was on the floor. And I have to say I never had a segfault developing 1500 LOC in it even though I didn't know the language. Anyway, although writing a compiler is apparently easy these days, getting a decent cross platform stdlib is hard (due to unix-windows differences), so Rust and especially Swift will probably have some work to do there. But I'm optimistic, which is rare...
 It is obviously better than C, but most people are too feeble-minded to learn it, and usually die of an aneurism when they begin to decipher template error messages FTFY :-) 
&gt; Swift 2.0 is announced to be coming to Linux, &gt; I haven't used it, but it looks fast, safe (at least far more so than c++), and productive. Yeeeeeeah no offense but you may want to look into Swift first before you assume anything particularly good about it. I say this having learned / used swift for some sample projects, and have 20 years in C++. I find Objective C far more sane (but I like to interop it with C++), but to each his own I guess.
I find this link completely ridiculous. I see no semantic difference between "expression" and "command" there. The "expression" `A3+B1` might as well be a command to compute the value of `A3`, compute value of `B1`, add them together and place the result into whatever cell may contain the formula. "How" the value is computed is abstracted away, but it is also abstracted away in imperative language with a statement like `x=y+1`. If unspecified order of evaluation is the main point there, this is already so in C++: between sequence points, the compiler is free to reorganize the computation at its own will. E.g, in `x=a() + y - b()` the compiler can choose any of the 6 permutations for computing the values of individual subexpressions before combining them into the result. And yes, mutable state *does* define data dependencies, expect that 1) it is implicit, 2) the information is not complete, which is often a source of bugs. Think the other way around: if mutable state did not define data dependencies, the compiler would be allowed to reorder the following two statements: x++; y = -x; But it is not allowed.
Yes, it's being squeezed at the other end now, at last! A long time ago it started being squeezed at one side and now it has almost vanished from that realm. Let's see what happens now. I see these other system languages can sure be used for high end games too, they just lack the ecosystem by now.
Out of interest, what are the things you find missing in C++? 
I can research the vector implementations relevant to my scenario, *and* adjust my code every time something changes in one of them that affects how I use it (which is less of a problem now than it was 15 years ago). *Or*, I can write my own implementation, which is fairly fun and trivial; and then I never have to deal with the problem again. *Then*, if I want my vector or my string to do something, I can just change my vector and my string, and they do something. I don't have to check all the STL implementations to make sure what I'm doing is compatible with them. In my situation, there was additional motivation, in that we have usage scenarios where it's preferable to not use the C++ run-time library, including no use of C++ exceptions. In those circumstances, you either write your own string class to accommodate the situation, or use manual memory management and make your code more error-prone. That's just one way an external abstraction layer fails you, because it fails to address your niche situation. You are overestimating the savings of external abstraction layers (i.e. part of some infrastructure you don't control), and underestimating the cost of relinquishing control. Given enough years, there will always be a niche situation. Luckily, the STL is very general, and if I want to use something from it, it works with my vector, too!
This is one of the more misinformed projects I've seen in recent years. For one and two, Qt *does not actually need moc to compile sauce and actually is pure C++* Just look at the options of qmake. qmake-qt5 --help
Like D was supposed to kill C++... but still here!
You don't happen to have a link to that presentation?
I'm using C++ to write embedded applications for Cortex-M0 right now with startup-work-shutdown cycles of 3ms. Which of those would let me cross-compile on my desktop to ARM for, say, 64k flash systems with 16k of RAM?
not sure if this [link](http://acmsel.safaribooksonline.com/book/programming/cplusplus/0321334876/4dot-designs-and-declarations/ch04?uicode=acm) will work. It is in chapter four of Effective C++: 55 Specific Ways to Improve Your Programs and Designs, Third Edition If you have an ACM membership you can view the book for "free".
[maybe this will work?](https://books.google.com/books?id=azvE8V0c-mYC&amp;pg=PT54&amp;lpg=PT54&amp;dq=when+in+doubt,+do+as+ints+do&amp;source=bl&amp;ots=47de2hGf1f&amp;sig=HwMmwI21R96WVW_E0nGV0OJpDms&amp;hl=en&amp;sa=X&amp;ved=0CCoQ6AEwAmoVChMInP6gjK2PxgIVRQySCh1Q5gDu#v=onepage&amp;q=when%20in%20doubt%2C%20do%20as%20ints%20do&amp;f=false) there is also [this](http://stackoverflow.com/a/8000542/1681678)
There are bounds checks on everything, like using vector.at(), however depending on how you iterate through things that might not be a problem. (In fact the presentation was using std::vector as a comparison). That is counter balanced by the fact that Rust has *much* better aliasing information than C++ about variables (you in fact can't have a mutable reference alias any read only references). I'm not going to say something like a game wouldn't have anything written using unsafe though. The point is you have to opt in to it, and have much fewer places to worry about, and the unsafe code can be behind a safe API. I never used unsafe in my project, since security was a focus.
I have. The move constructor semantics in C++11 are nice, but even more pervasive in Rust. However C++11 doesn't make much of a dent in safety, in fact the move semantics add even more undefined behavior that can bite you (e.g. the variable you moved from is often in an undefined state, for many STL types, so god help you if you access it).
It had GC though, which is a blocker to many adopters. I've been learning Rust, and it does seem good so far. Of course, I need to do a reasonable scale project and re-evaluate in face of real issues in real world development, and some of the implementation details still need ironing out - executable sizes are a bit off putting at the moment, but I'm hoping these will get resolved as it stabilizes. With C++, however, I feel that the language has just grown too baroque for many programmers. The backward compatibility constraint has, I feel, led to a language in which broken features are retained, with workarounds added, resulting in a language that is so complex that almost everyone uses saner subsets. I can't help but feel that while new features help - modules and concepts will be particularly welcome - the language has reached a point where just adding features won't help much (both library and language). IMHO, C++ desperately needs to start deprecating warts, with an aim to removal after a suitable grace period. Rust uses semantic versioning to allow this occur in future, which is an excellent piece of foresight. I don't think Rust is quite there yet, but I'm really hoping it develops to become a serious challenger to C++, enabling more programmers to work safely at this level.
&gt; For example, you can't (yet) parameterize a struct or function over integer constants à la I'm not sure this will ever happen. Some of its users are blind: &gt; [It's also quite easy for a user of dimensioned to make their own type aliases, so **I'm not sure it matters** all that much what they are.](http://www.reddit.com/r/rust/comments/398dr2/integerprimitive_compiletimevalueconstrained/cs2fy96) They seriously think `foobar&lt;Zero&gt;` is better than `foobar&lt;0&gt;` and [they will not acknowledge `foobar&lt;Zero&gt;` is hacky](http://www.reddit.com/r/rust/comments/398dr2/integerprimitive_compiletimevalueconstrained/cs1mmnp).
I wouldn't know how … unless leaving the safe subset counts: of course, you could write your own `unsafe` block and dereference an invalid raw pointer or violate some other invariant. But you shouldn't be able to provoke seg faults in the safe subset. If you are, you've found a bug that is not supposed to be there.
But the pointer makes it clear from reading where DoStuff is called that DoStuff intends to write to the object. 
If you're talking about out of memory, that will cause a panic and destroy that thread (after doing stack unwinding / destructors). [And out of bounds attempts will also panic]
The phrase itself has biblical connotations, Proverbs 6:6: "Go to the ant, O sluggard, Observe her ways and be wise". I.e., do as the *ants* do :)
I can see Rust take C's place in some applications once (or if) it matures enough, but C++? I'll scratch that as wishful thinking.
The initial open-source release of Swift will not support windows.
I wasn't worried about it any more than I was was worried about being wrong anywhere else on the Internet ;) I did a little reading and it looks like bootstrapping Rust was messy. OCaml at times and C++ at others and occasionally both. There is no simple "Rust was bootstrapped from XXX" story, the reality is just not that simple. Thank you for bringing that to my attention.
See also: [GiNaC](http://www.ginac.de/) [SymbolicC++](http://issc.uj.ac.za/symbolic/symbolic.html) 
&gt; They tried to replace it with finer-tuned locks and it made performance worse. What!? That's crazy. I mean I believe you, but that is so counter-intuitive. Do you know why? The python environment sounds a lot like the Ruby environment. Let me guess: CPython is to CRuby (MRI/YARV) is the most popular but most hackish implementation. It has a GiL to simplify the code, makes strides with memory management each release but still remains slower than we want. To make it faster C extension is quite common. JPython is to JRuby has good Java integration pretty good performance but is a second class citizen in some ways, like compatibility with major packages. IronPython is to IronRuby built on the .net vm and not really used for much of anything. PyPy is to Rubunius and strives to be [LanguageName] implemented in [LanguageName] via some neat trick. More of a cool feat of academics than actually useful. Was I close on any of it?
great stuff, looks well done and documented! btw, why don't you separate the unit and the perf tests into named targets? it's kinda surprising to have different effects when running in Debug vs Release mode.
Moved-from STL objects are in a "valid but unspecified" state, i.e. they satisfy their invariants but you cannot assume that they hold any particular value. (Some classes provide stronger guarantees, e.g. moved-from shared_ptrs/unique_ptrs are empty.)
http://www.slideshare.net/sermp/mikhail-matrosov-c-without-new-and-delete-russian-c-conference-2015-v15-45522731
&gt; I think if Rust wants to go after C++ people It worked for me. :)
Cheers! Good point, it is mostly that I learned the basics of CMake-based testing and never went much past that. I imagine I would need to add different specific targets, like test_perf, unit_test, etc.?
Here's the paper explaining more than the "help" in the link http://www.cl.cam.ac.uk/~pes20/cpp/popl085ap-sewell.pdf
I have no interest in Rust because I have acquired the ability to write virtually error-free C++. I don't make compile-time mistakes very often (although working at the frontier of C++17, it does happen), and I almost never make run-time mistakes. I'm actually trying to remember the last run-time mistakes I've made. At work, years ago I accidentally wrote a full shift in uniform_int_distribution (i.e. shifting 32 bits out of a uint32_t), which x86/x64 liked but ARM hated, since it's UB. At home, also years ago, I accidentally passed a temporary string to regex_match(s, m, r) and then later accessed it through match_results, which worked for years until it failed one day. I literally *fixed the Standard Library* (via Committee) to make that a compile-time error. There are things in C++ that give me headaches (primarily revolving around the absence of good libraries for various things; often there are decent C libraries that need to be wrapped). Writing correct, efficient code is not one of them.
&gt; counter-intuitive. Do you know why? Off the top of my head, the fact that it means a lot more lock/unlock operations have to be executed, and a lot of the time you need multiple locks held at once (which means paying for deadlock prevention) so you don't win much for parallel stuff. &gt; PyPy No, that's all wrong. The fact that PyPy is a python implementation of python is solely a side effect of the fact that it has an amazing JIT.
Don't really know what you mean? 
Are you denying the progress of C++? Have you not noticed it, or maybe you think it's negligible?
At the end of statements;
I like to use semicolons to indicate which lines are part of my function, such as, int main() { ; int a = 0 ; int b = 5 ; cout &lt;&lt; a + b &lt;&lt; endl ; return 0 ;}
http://i.imgur.com/Dbcd91y.jpg
Sorry guys! I MEANT CURLY BRACKETS!
 clang-format Manually formatting code is the biggest time waster ever.
Ok that makes more sense haha ok so this is what i do. statement: { statement: { } } something like that is what I usually do so they are all lined up vertically and can see each block. edit: wow that did not work whatsoever just a sec ill fix it edit2: fixed
Fun fact: Use semicolons to comment in x86 assembly.
Yes, do not just place them all to the left!
You mean braces? 
My point was, that was the one time as an experienced programmer that I actually ran into lifetime issues. The vast majority of the time, lifetime issues just aren't a problem, with techniques to avoid them and instrumentation to detect them (e.g. VC detects invalidated iterators in debug mode). There is very little mental cost to this. I spend a *lot* more time worrying about issues outside of the Core Language and Standard Library, like calling Windows API or OpenGL functions and not understanding exactly what they're going to do or what their side effects will be. So when people say, "C++ is unsafe, we need safe languages", I am not persuaded in any significant way. Safety in C++ is a *solved problem*. That's not to say that it's perfectly solved, but it's solved well enough, for other issues to be much more important.
Thankfully they have been addressing this aggressively lately; there are a lot of libraries being pushed through the standards committee (including a vector graphics library).
;}
By uniform you mean the same throughout the entire code? And other scripts too? Or just one file?
Projects usually follow a style guide for the specific language they are working in. Basically, all source code for your project (C++ in this case) that your team is working on would use the same formatting. This would exclude things like libraries that you link since that's someone else's code.
I don't see swift as a systems language. The entire swift book (700 pages) has one mention of 'thread'. Ouch. And always refcounting (classes) or copying (structs) is a bit heavy handed. I consider it more application/productivity, which was what I meant by 'squeezing c++ at the high end'. 
Perhaps this is what you need? [AStyle Bracket Style Options](http://astyle.sourceforge.net/astyle.html#_Bracket_Style_Options)
Depends where you are. I usually say/hear brackets in reference to only the glyphs with straight lines [] and &lt;&gt;. My British colleagues usually count () as brackets, and might well consider {} brackets as well even though I always call them curly braces.
Rust does not allow out of bounds array accesses. In the worst case it will perform bounds checking, but actually it turns out many bounds checks can be statically eliminated or a single check can be performed and reused.
You missed an empty statement there;;;
Maybe you should ask your intro to computer science TA
oh, reading this makes Mondays just a tad more tolerable
https://github.com/urho3d/Urho3D/blob/master/Source/Samples/39_CrowdNavigation/CrowdNavigation.cpp Kind of what I was looking for. But they should definitely feature code in their docs. It looks a bit ugly though, way too many raw pointers and `new`'s for my taste.
For json you could use jeayeson which is header-only and permissive-licensed
Apart from situations where you can (mis)use `shared_ptr` and `weak_ptr` you can also avoid some object lifetime problems using deleted rvalue overloads: template&lt;class T&gt; class reference_wrapper { public: reference_wrapper(T&amp; x); reference_wrapper(T&amp;&amp;) = delete; // don't accept temporary objects … }; That's *something*. And checked iterators and containers do help, too. It's not something the standard guarantees to exist but it's a common courtesy for vendors to offer this kind of debug mode. One more reason to prefer `std::array&lt;T,N&gt;` over `T[N]`. But to be honest, since I've seen how Rust does it, I'm not impressed with these kinds of memory safety stopgaps in C++.
C++ is a safe language if the programmer is not a monkey. I have been coding for 16 years and I can presume I write safe c++ code. It is easy, and you only need expertise on the area, but is possible. It gives me the possibility to make EVERYTHING on a computer, as you have low and high level access. I usually audit and teach my co-workers how to make code safer and faster without headaches and I'm one the youngest in the team. The problem is not the language but programmers, c++ is hard, is big and not for everybody.
...more?
It's a Google Image Search brand. Don't remember the model number.
He got fired.
The sanitizers I've seen make compromises to keep execution time reasonable, and it's been a while since I've looked at them (a year) so off the top of my head - bad uses of the stack are the hardest to catch IIRC. Also the thread sanitizer looked especially hacky and probabilistic - you have to hope a race actually happens or it won't catch it. It could run out of memory so you have to keep increasing it. And it doesn't really know that a mutex lock was actually meant for a certain piece of data or not, so there's a false negative chance. Basically, there are big, complex caveats devs have to understand. By 'hierarchal' I'm just trying to (poorly) say that I'd guess there are some problems Rust's ownership and borrow checker isn't going to be great at. If you have objects that have a single owner and are scoped to a certain function (in a single thread), or are global, that's the best case for it and you can use 100% safe code. The middle ground is probably ref counting and interior mutability (the weirdly named RefCell), which is still doable but now the safety checking has been punted to runtime. The extreme other end is intrusive raw pointers / doubly linked lists, and you'd probably need unsafe code for that, so depending on how pervasive that is it could make switching from c++ questionable. So Rusts applicability is correlated to 'how complex is your object graph', because that means 'how often are you going to be fighting the borrow checker'. [edit: I think all the c++ projects I've done in the past would be a good fit for the rust memory model]
"Maybe the only hold out is game programming?" And applications. Just those two, really.
TIL that blaze is really way faster than eigen in some micro benchmarks: http://baptiste-wicht.com/cpm/etl_blaze_eigen/ 
Most if not all shared_ptr methods would be inlined in an optimized build, so I wouldn't expect them to show up in a profile unless your compiler manages to preserve inlined functions in the debug info.
Eigen uses OpenMP to parallelise some of it's algorithms. I recently noticed that it parallelises on gcc and VS, but not on clang. For example, Eigen's `PartialPivLU` uses all cores if you compile with `-fopenmp` on gcc, but on clang (I tried 3.5 and 3.7-svn) it never uses more than one core. I think clang doesn't have full (or much/any) openmp support yet, but I didn't dig into it - there's a separate [clang-omp](https://clang-omp.github.io/). Maybe that's what's happening here as well (the benchmark is done using clang). Also, it would be interesting to benchmark a bit larger matrices as well (4000x4000, 8000x8000), I've had good experience with Eigen so far but I never tried blaze or etl.
The american terminology: http://www.cis.upenn.edu/~matuszek/General/JavaSyntax/parentheses.html 
Thanks for the tips :) &gt; Keep the units common through multiple tests and within a test, Internally, I have only one unit, but the most adequate is chosen for display, otherwise it would lead to very large numbers. Do you think it would still be better to only display microseconds ? Or at least a command-line option ? The web reports uses only microseconds. Do you think I should also change the throughput to an element/microseconds scale ? &gt; From a latency pov, knowing the 99%, 95%, 75% and 50% tranches are much more important. I'm not sure I understand this. You take the 99% better and make a range, the same with 95% and so on ? &gt; The mean/stddev pair hide multi-model distributions. Makes it hard to detect either emergent algorithmic and/or architectural problems. What would you advice in place of mean/stddev ?
Mutable global state data dependency gone wrong is what produces quite annoying BSOD bugs at kernel level. 
Completely shit site on mobile. Even forcing desktop changes nothing. 
Those type of questions belong to this channel: /r/cpp_questions ;)
Being able to consume information in whatever form it's viewed on should be a priority. Voicing my frustration about not being able to view a topic I'm interested in certainly shouldn't qualify as fascinating, even in the sarcastic tone you replied with. Thanks for providing not only no help at all but doing so in the most obscure way possible. What's fascinating is that comments such as yours get upvoted while providing absolutely nothing to the discussion. Granted mine doesn't fair better but my comment would have if I could see the full story. 
UPDATE: found it! :-) It's basically one talk in two versions (or, two very similar talks, if you like ;]). Slides: - How NOT to Measure Latency: http://www.slideshare.net/howarddgreen/how-not-to-measure-latency-london-oct-2013 - Understanding Latency and Response Time Behavior: http://www.slideshare.net/howarddgreen/intelligent-trading-summit-ny-2014-understanding-latency-key-lessons-and-tools It's worth noting that they also bring up a very nice visualization idea -- High Dynamic Range (HDR) Histogram: http://hdrhistogram.org/ // GitHub: https://github.com/HdrHistogram/HdrHistogram It looks like this: http://hdrhistogram.github.io/HdrHistogram/PercentileHistogramExample.png Note how much more informative it is (including how much more one can extract from it) about the profile of the application's performance behavior -- compared to simply looking at the few, select numbers (whether it's mean, std. dev., or a percentile). For more context, I'd actually recommend watching the talks. Here are the videos: - Understanding Latency and Response Time: Pitfalls and Key Lessons: https://www.youtube.com/watch?v=G5UskyPG9_o - How Not to Measure Latency: https://www.youtube.com/watch?v=DxF077s081Q // Thankfully, there's _very_ little Azul/Zing/platform-specific in the talks -- mostly a minute or two by the end, and all can be safely ignored :-) Takeaways: - Standard Deviation and application latency should never show up on the same page - If you haven’t stated percentiles and a Max, you haven’t specified your requirements - Measuring throughput without latency behavior is [usually] meaningless 
Even more fascinating.
Can you elaborate on the differences between this and etcd? Is it just another implementation of the same algorithm or is there a reason someone would use this over etcd? I'm not as familiar with the state-of-the-art in this space so apologies for the silly question.
if you don't care about hardware acceleration then AGG (http://www.antigrain.com) is a very good pure C++ 2D graphics toolkit. It does everything in software and has zero dependency (not even STL), which makes it super easy to port to different platforms (especially embedded systems). AGG's software rasterizer is also significantly faster than Cairo's (about 2 to 3 times faster in my tests).
agg2.5 went gpl so that's a consideration for commercial software, etc.
Actually, I believe -- I cannot back this up, and I would love to be confirmed or corrected by someone who knows better, but sources I've skimmed seem to indicate it is the case -- that iOS, Android, and Windows Phone all expose C APIs. iOS is a given, seeing as Objective-C is still the *lingua franca* of that platform. Android has the NDK and JNI stuff, but I seem to remember also reading somewhere about Android libraries exposing "low-level" interfaces with which you could write an app, compile it for the given platform (not necessarily a trivial task, given how much "flavor" there is to phone hardware and how difficult it is to get precise specs for phones nowadays), and load it onto the phone and run it. Revolutionary! Windows Phone also seems to support native apps, though I haven't done much looking into that platform. With the promised platform integration of Windows 10, however, I can only see native code interfaces expanding. If all my assumptions are correct here, what it boils down to is C++ is the *only* high-level language that compiles and runs without bridges or bindings on all phone platforms. Well, I guess Objective-C theoretically would as well, but why would you ever subject yourself to that monstrosity? It doesn't sound like this is the route Facebook is taking, and I don't blame them, having seen firsthand how difficult it is just to get comprehensive documentation on the native APIs for some of these platforms, but I am convinced a cross-platform mobile native library solution is possible.
I have been using c++ for over 10 perhaps 15 years and I cant remember a single instance of segfault. Anyone can drive a Ferrari into a lake and it's not the Ferrari's fault if you're not the smartest fox in the forest. Just because it's possible it doesnt mean it's likely.
Cairo and Skia are for high performance 2D vector graphics. You can check Skia source code and see how big and complex a library offering such features can get: https://github.com/google/skia/tree/master/src 
&gt; but why would you ever subject yourself to that monstrosity? As opposed to C++?
AFAIK the 2.5 code is identical to 2.4 so you can just use 2.4.
At least C++ *looks* clean :P
I call them squigglydoos.
We use both internally in our products. We find that Cairo is better documented and easier to compile and use, while Skia on the other hand is somewhat faster.
We have to thank Oracle for dropping the ball on Java mobile support, by not providing neither JIT nor AOT compilers, instead trying to push that monstrosity known as [Oracle ADF Mobile](http://www.oracle.com/technetwork/developer-tools/adf-mobile/overview/adfmobile-1917693.html). Which leaves C++ as the only free solution that is available in all OS vendor SDK, although those of us that wish to use it on Android have earned our scars, given how the Android team deals with those that dare to touch it.
I'm back again ;) And I tough about your project. It would be possible to make your code usable with any solver: to the command line, the user should pass the path (and optional arguments) to the solver. You could then write the instance to a file, run the solver and parse the std output to obtain the response. This method is already used for quite some tools [cnf fuzzer](http://fmv.jku.at/fuzzddtools/), [runsolver](http://www.cril.univ-artois.fr/~roussel/runsolver/), ... Another thing you could do, is to use the interface defined for the next SAT competition, incremental sat [ipasir.h](http://baldur.iti.kit.edu/sat-race-2015/downloads/ipasir.h)
How about OpenGL? That gets you the best hardware support.
Why not C++'s SG13 upcoming [Proposal to Add 2D Graphics Rendering and Display to C++](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4073.pdf)? Is based on Cairo but it should be more C++. The reference implementation is under [github](https://github.com/mikebmcl/N3888_RefImpl). If you have comments / thoughts about SG13's work, use their [forum](https://groups.google.com/a/isocpp.org/forum/#!forum/io).
similar to maven, Amen?
I think it's too religious.
Caven.
In their *applications*. Aside from games and applications, C++ is dead, dead, dead :) I can't even *remember* the last time I used an application written in C++. Apart from the browser I'm using this very second, obviously. Office applications. IDEs and various other programming applications. Bits of my operating system and associated gubbins. All of my media players. Pretty much everything I ever use, really. Apart from all that, C++ is DEAD.
Haven
savant
sdl2 gives you the drawing context and handles things like events and has apis for other stuffs. Also there is some vector drawing support. So you would still use sdl2 for these other things?
Regarding Qt, it lacks maturity in the mobile space vs alternatives like Xamarin. They are still catching up with basic UI components (check their bug tracker), require that you write your own glue for most OS services and expect users to replicate native widgets on their own with QML. Last time I checked Qt didn't even support all material design or basic stuff like application lifecycles. So if one is expected to spend the effort writing extra glue across all desired OS, better take the approach to use the native frameworks for the UI instead of QML. Apparently they are focused in customers that want to bring existing code into mobile platforms and not as a platform for writing apps across mobile OS like Xamarin. 
No I didn't. It isn't part of Android SDK, hence why I left it out. Also the point being native apps. JavaScript belongs in the browser. 
&gt; no-modules Oh no! Why did you have to remind me? \**gloomdooms around*\*
I agree on this. I understand the need for a catchy title, but defining C++ "wizened" sounds just wrong to me.
This is what I am hoping :) Everything that interests me is C++ (or C) which is why I have picked it as the language I want to work with most. It will be a long time before I am not-awful but every day I am learning something awesome about C++. It is huge but it seems like there isn't anything I can't do with it! 
Yay! You're lucky to start learning now - stuff was so much more primitive when I started with C++ back in 2002.
Native widgets look'n feel is already available in QML for Desktop and at least Android, isn't it?
I agree that default construction should leave it in an empty state. Since the empty state is unavoidable, then *maybe* it's OK for a copy-exception to leave it in the empty state. The empty state should explicitly be an invalid state where any attempted operation throws including copy, copy-assignment, etc. I would be interested to know when the destroy after copy-complete state can cause issues. Is this something that can be detected &amp; unsafe values rejected at compile-time? I'm also curious why allocating a temporary if the type you are copying is not noexcept copy constructible is such an undesirable behaviour that it's worth it to introduce potentially unwieldy API semantics rather than take the hit of allocating on the heap.
It always bothers me that the majority of the bugs found by this sort of thing are easily solved by "don't use raw pointers".
A concise [description](https://bugs.webkit.org/show_bug.cgi?id=146064): "[WebAssembly](https://github.com/WebAssembly/design) is a new format for native programs on the web. It aims to support everything that asm.js supports, but allows the VM to sidestep the JS parsing and profiling pipeline entirely. This is a good thing for the VM - less work to support native code." More information: "WebAssembly is a new virtual ISA being designed to efficiently run compiled code in web browsers and other things, starting with C/C++, and eventually many other languages. WebAssembly distinguishes itself from other virtual ISAs with optimizations to reduce download size and decode time, strong portability and predictability invariants (for example, the base has no undefined behavior in the C/C++ sense), and participation from several browser vendors." - http://thread.gmane.org/gmane.comp.compilers.llvm.devel/86952 - https://github.com/WebAssembly/design/blob/master/README.md - https://github.com/WebAssembly/design/blob/master/HighLevelGoals.md - https://blog.mozilla.org/luke/2015/06/17/webassembly/ - https://blogs.msdn.com/b/mikeholman/archive/2015/06/17/working-on-the-future-of-compile-to-web-applications.aspx 
Not to mention Turbo C++ and the like on DOS. (In a way that was easier though since as a platform DOS is somewhat less complex in some ways than what Win32 was back then, but still. There's just so much that has happened in development tooling the past years it's totally silly.) 
You can say that just about everything, I fail to see how this specific thing affects code that isn't terrible to begin with though.
I was at the committee meeting where this was discussed, and I argued strongly in favor of the current design. The problem with default-constructing to an "empty" state is that your programs are now replete with empty variants. It is promoting the empty state to a valid state. This complicates code every time a variant is used. You must now sprinkle your code with ASSERTs or conditionals. That's really undesirable. By default-constructing to the first element in the variant (like built-in unions do), the only source of "empty" variants will be throwing moves. Not only are these rare, but since it's an exception, *you have already been notified that your variant is now invalid*. Yes, if you swallow the exception and proceed as if nothing has gone wrong, then you can end up accessing an invalid variant. The answer is simple: *DON'T SWALLOW EXCEPTIONS.* You shouldn't be doing that, anyway. The design the committee is currently looking at makes it possible to code as if a `variant&lt;int, string&gt;` can only have an `int` or a `string`, without paying for the never-empty guarantee. Notice the changed terminology. The current design doesn't have an "empty" state. It has an invalid state. I don't consider that mere sophistry. If you don't swallow exceptions, you can have your cake and eat it.
&gt; move constructors are noexcept for most of std types The node-based containers (`list`, `map`, `set` and friends) do not have noexcept move constructors, and can't (depending on how you choose to read the standard). &gt; I want variants to be default constructible, and thus they should have an empty state That doesn't follow. &gt; All the arguments about default constructing the first type that is default constructible seem very complicated. Nobody is arguing for that (at the moment). 
I used to work in oil and gas and I saw two dudes almost come to blows over brace placement (really) :-)
Forget love, forget resources, forget power. World War III will be started over a brace.
They give free licenses for open source projects. http://www.viva64.com/en/b/0092/ Other options if you are interested in doing that. The [Clang Analyzer](http://clang-analyzer.llvm.org/) is free and open source. [Coverity](https://scan.coverity.com) has a free scan system for open source projects. Visual Studio has a built in analyzer in some versions (used to be ultimate only, but I think it's on more now).
So now C++ looks clean?
I can't say I've ever run into a situation where I had to particularly care about the performance of my widget toolkit.
Not writing throwing moves seems like a pretty good rule of thumb too. Are there any actual sane use-case for them?
Shoulda seen it in 1992... *shudder*
A *valid* variant can never be empty. It *is* possible to have an invalid variant, but only by ignoring exceptions. Well-behaved code doesn't do that.
For rather obscure reasons having to do with sentinel nodes and iterator invalidation, the node-based containers (`list`, `map`, etc.) have potentially throwing move constructors.
You could also make the presence of a default constructor conditional on whether `void` is one of the possible types. If it is, enable the default constructor and have it construct a void variant. Also, if void is a possible type, you could drop the requirement that the move constructors be `noexcept` and do it like the article suggests.
And compile with "warnings as errors" if at all possible. That said, there are a few errors in the article that even a pedantically configured gcc or llvm wouldn't find.
Finally. This is what I've been arguing for for years!
I didn't try it (yet) but Nana seems interesting: http://www.nanapro.org/ 
I think the current std variant design is about as close to ideal as we can get with C++. I was also at the meeting where this was discussed and was strongly in favour of the design. std::tuple is an attempt to mimic the mathematical cross product. In other words, given types A and B, I want a std::tuple&lt;A,B&gt; to have a value of type A **and** a value of type B. No one would argue that std::tuple&lt;A,B&gt; should also have another state called "empty" where it contains neither a value of type A nor a value of type B. The same reasoning works with std::variant when we see what it is attempting to model. std::variant is an attempt to mimic the mathematical discriminated union. In other words, given types A and B, I want a std::variant&lt;A,B&gt; to have a value of type A **or** a value of type B. Again, a state called "empty" makes little sense given what we are trying to model. std::variant has an invalid state because of the strange C++-ism of throwing copy-constructors. An invalid state certainly isn't desirable, but it beats all the alternatives. The case where it arises is very rare and, because an exception is thrown, the programmer is already informed that there is a problem and can deal with it. The end result is that we get a std::variant type that we can safely assume is valid when passed as a parameter to a function. We make the same validity assumption when we skip null checks for references passed to functions.
Thanks for the links. I don't actually have my own open source project, so I don't think I qualify for a free license, I was thinking more about being a free-floating open-source bug-fixing angel, but perhaps I can do something similar with one of those.
Could you explain why those containers can't be moved without possibly throwing exceptions? As I understand them, default-construction followed by an elementwise swap should be a valid move constructor.
It comes down to your test coverage in any case, in any language. Logical bugs are far more common and harder to catch than any of these issues. I think that the Rust advocates are making a big mistake in emphasizing the safe reference/pointer system; a mistake analogous to optimizing a part of the program that takes 1% of the time to run. Almost every experienced C++ dev working with a modern codebase will tell you that they spend very little of their time dealing with memory leaks, double frees, or dangling references in single threaded code.
Hmm ok so we'd have to wait a little bit for Rust to catch up speed. 
Then perhaps RAmen? Long Live the Flying Spaghetti Monster! :P
Same. The great thing is it has support from Mozilla, Microsoft, and Google. This is happening! Finally, the browser is going to break free of its JavaScript shackles.
AFAIK, some node-based containers require allocation of sentinel nodes even for the empty state and as such may throw while making the moved from variable destructible. Maybe [/u/STL](https://www.reddit.com/user/stl) can give us more insight into the problem.
Those containers use so-called sentinel nodes to mark the end of the container. So `std::list` has a dummy/sentinel node to represent the `end()`. These dummy nodes can be dynamically allocated, or they can be embedded within the container. If they are dynamically allocated well then obviously even just constructing the container may throw an exception since that involves a dynamic allocation. The same goes for moving it as well since a move operation will have to allocate new sentinel nodes which could fail. So dynamically allocating the sentinel node can not be `nothrow`. If they are embedded within the container then you avoid a dynamic heap allocation, which is generally a good thing... but the downside is that you end up with iterator invalidation when doing a `swap`. Since the sentinel node is embedded inside of the container and is used to refer to the `end()` it means that after a `swap`, the iterator to the `end()` will be invalid. Now this is where there is contention. The standard says it's permissible for a `swap` to invalidate an iterator to the `end()`, but it also implies that it's okay for it to not invalidate that iterator. It's basically up to the implementation to decide. An implementation can choose to make move constructors non-throwing, or make `swap` preserve end iterators, but it can not do them both.
Why can two different lists not share the same sentinel node? That is: list&lt;int&gt; x; list&lt;int&gt; y; will have the same sentinel node, which will be a static member of list&lt;int&gt;. Does that not work ? Also, are sentinel nodes mandated by the standard? You can have an end iterator without using sentinel nodes.
Valgrind too, although it's being (been?) subsumed by the sanitizers.
&gt;I want variants to be default constructible, and thus they should have an empty state &gt; &gt;&gt;That doesn't follow. How can I default construct a variant of non-default constructible types without an empty/invalid state? IIUC at least one type must be default constructible for this to be possible. &gt; Nobody is arguing for that (at the moment). That's sad! The OP mentioned it briefly: &gt; One alternative options is that default construction picks the first default-constructible type from the list, if there are any, but this still has the problem of different orderings behaving differently. I don't want empty variants but I want default constructible variants. When should a variant be default constructible? If - _all_ of the types are default-constructible, or - the first type is default-constructible, or - _any_ of the types is default-constructible, and why? After giving this some thought, all options suck a bit. In the mathematical discriminated union that the variant is trying to model, the order of the types does not matter. I am getting more inclined to eliminate element access by index and allow only access by type, which is possible if there are no duplicated types. Then, the variant should try as hard as possible to be default constructible, that is, be default constructible if any of the types it contains can be default constructed. Which type it will be default constructed should be unspecified, if the user didn't care to default construct a particular type, then that is just the way it is. In particular, I would hate to see variant wrappers or generic code in the wild that reorders the element of the variant just so that it can be default constructible. &gt; The node-based containers (list, map, set and friends) do not have noexcept move constructors, and can't (depending on how you choose to read the standard). TIL this. That's really unfortunate! These have to be left in a valid state and this requires sentinel heap allocated nodes so I don't see a way for them to provide a noexcept move constructors.
&gt; Who the hell writes a type that is not nothrow_move_ constructible, seriously? That's just what I thought but it seems this is very common :/
I'm a little sad to admit this but as I read more and more code from my colleages and our legacy code (all C++) I more and more get the "go argument". If your language doesn't have many features then it's harder to write unreadable/unmaintainable code.
/u/mttd linked to this bug at WebKit: https://bugs.webkit.org/show_bug.cgi?id=146064 Filip Pizlo opened this issue and according to https://www.webkit.org/team.html, he is an Apple employee which is a promising sign in the absence of an official statement from Apple Inc. 
It is easier to say not to use C++ :). But if you need high perfomance of the library there is no getting away from C++ and raw pointers.
IIRC one of the motivations to allow throwing move ctors was `std::pair&lt;some_legacy_type, some_move_optimized_type&gt;` where `some_legacy_type` only has a possibly throwing copy ctor and `some_move_optimized_type` comes with a non-throwing move ctor. So, you end up with a possibly throwing move ctor for this `pair`. But it will be preferable to its copy ctor in the situations where you don't need a move to have the strong exception guarantee. But yeah, throwing move ctors are making things complicated. In other languages like D and Rust, the move semantics story is *much* simpler (and a teensy bit less powerful but that's IMHO ok). 
`std::pair&lt;legacy_type_with_throwing_copy_ctor, std::string&gt;` has a possibly throwing move ctor.
I don't know of any widely used variant implementation with a double buffer so I doubt anybody wants to standardize one that does. What is probably going to happen is that if copy construction fails, an exception will be thrown, and the variant will be left in an invalid state. Using an invalid state will be UB, and that can only happen if the programmer explicitly swallows the exception and uses the variant without assigning it a valid state. All other alternatives are too complicated and have too many downsides.
I'd stick with C++.
My biggest gripe with Valgrind is that some libraries perform black magic with memory allocations and throw it for a loop. Xerces-c comes to mind here. It requires some deep, dark knowlege in order to get such configurations to yield usable information. I would much sooner rely on black-box testing of heap behavior, coupled with a tight style guide and static analysis, as you mention. For me, Valgrind (with all it's amazing potential), is a tool of last resort.
On slide 32, isn't this broken in a more fundamental way then what is outlined on slide 33? This is the bit of code in question: std::atomic&lt;unsigned&gt; push_pos{0}; void push_back(T t){ unsigned my_pos=push_pos.load(); while(!push_pos.compare_exchange_weak(my_pos,(my_pos+1)%buffer_size)){} The author states that "The problem on the previous slide only occurs if the buffer is full." That's not true though, is it? Isn't there a fundamental race between obtaining the value of the atomic and the compare_exchange_weak? Two producer threads could obtain the same value for my_pos, no?
Slightly offtopic, but can anyone tell me what do these voting results mean? SF=0 WF=0 N=8 WA=4 SA=2 
Imagine a variant `visit` function that lets you pass a polymorphic function object. You pass a `variant&lt;int, string, float&gt;` and a function object with three function call operators that take an `int`, a `string` and a `float` respectively. The first and second return `int` but the third returns `complex&lt;float&gt;`. What should the `visit` function return? Well, it could return `variant&lt;int, int, complex&lt;float&gt;&gt;`! Duplicate `int`s, but they are semantically different. The first "slot" is occupied if the original variant held an `int` and the second is occupied if the original held a `string`.
Two threads might at some point have the same value for `my_pos`, but two threads can never end up with the same values for `my_pos` after the while loop: After the loop `push_pos` has been successfully, atomically, updated. That means that the compare_exchange operation a) observed the expected value in `push_pos` and b) modified it. Because the operation is atomic, it's not possible that any second thread will also observe the same value and successfully update it to the same new value. Instead a second thread would fail, `my_pos` would be updated to the new value, and the second thread would try again with the new value of `my_pos`. (This is of course ignoring the issue of `push_pos` wrapping around due to that `%buffer_size`)
That just shows how little C++ you know.
&gt; But this type checking is already solved with visitors for variants. They avoid the conditionals and in case of an empty variant, it can simply do nothing. Do you really want nothing to happen when you visit a variant that has been made invalid by a failed move? *Nothing?* Don't you think this would be more likely to hide bugs than avoid them? IMO it would be better to permit the implementation to ASSERT and find your bug for you.
&gt; Do you really want nothing to happen when you visit a variant that has been made invalid by a failed move? Nothing? No, I want nothing to happen, when visiting an *empty* variant. And a variant can get empty after being default constructed, manually reset or as a fallback for a failed move. And you notice a failed move because an exception is thrown. But with a variant which is allowed to be empty, it is safe to access it after the exception without harm. Because it has a valid, well-defined state: it is empty.
This behavior is easily implemented in terms of the `variant` currently proposed and `optional` with some trivial forwarding functions.
Of course it is. I was just argueing against your point that an empty state leads to conditionals in user code. This is not the case (idiomatic use taken for granted).
The problem I see isn't so much with the atomicity, but rather the behavior. The thread that failed the compare_exchange_weak is left waiting for that position to be push_pos again; not to mention it could be beaten to it again. It's a strange way to enqueue.
It doesn't seem like any intentional hiding to me. The C manual states that it was based on B, and the B manual states that it was based on BCPL, so the chain of derivation is all there. The C manual omitting that it is based on BCPL doesn't seem that much different than the C++11 standard omitting that it was based on B.
I play the long game, generally. /be
If I understand what you mean, that doesn't happen; when `compare_exchange_weak` fails, it updates `my_pos` to the new value, so when the thread tries again it's expecting the new value, not the one set by its initial `my_pos = push_pos.load()`.
Ours are not marked constexpr. I do not believe that the Standard permits them to be.
Indeed, and I am really hoping these guys make the move to GitHub soon: http://astyle.sourceforge.net/
I've written one when I had to pass the address of an object to a legacy C function and couldn't modify it after initialization. But that's a rare case...
Between them, /u/sakarri and /u/Plorkyeran have explained it. Move assignment doesn't have to allocate, ignoring POCMA.
The node-based containers can be implemented with dynamically allocated (Dinkumware/VC) or container-internal (libstdc++, libc++) sentinel nodes. While container-internal sentinel nodes avoid allocating in default/move ctors, they sacrifice iterator stability guarantees.
I started it and played around with it but I couldn't even figure out how to make functions work. 
This is awesome. I hope Visual Studio adds some tooling support in the near future. That part I found particularly interesting: &gt; WebAssembly applications can use high-level C/C++ APIs such as the C and C++ standard libraries, OpenGL, SDL, pthreads, and others, just as in normal C/C++ development. Under the covers, these libraries implement their functionality by using low-level facilities provided by WebAssembly implementations. On the Web, they utilize Web APIs (for example, OpenGL is executed on WebGL, libc date and time methods use the browser's Date functionality, etc.). In other contexts, other low-level mechanisms may be used. I'm a bit afraid though that they nowhere mention C++11/14. 
I tried it for a bit back in the day (2011) and it basically was completely useless to me. Maybe I approached it wrong but it went like this: - write some code, and run it, my program goes to state A - write some more code containing a syntax error (missing ;), and run it, error happens - try to find a way to come back to the previous program state (like reloading my commands in order from the beginning). Never found out how to do this. - go back to an editor, copy the code back there, compile it, fix the error, compile it, run it - never tried cling again Most REPL are convenient because you don't have to wait to compile the code. The interpreters are just blazing fast. In python or ruby the waiting time between editing the code and running it is essentially zero. Try feeding a small C++ code base to cling (is there a way to do this from a CMake compilation database?). In C++ a big problem is that modifying a single function changes the code of all functions that call it (via inlining), so changing a single function leads you to recompile at least a single TU, and if the code is generic you might have to recompile the world. Rust is able to compile generic functions to an intermediate representation because all generics are constrained, so there might be a future where such a smart compiler might be possible in Rust. C++ will always have unconstrained generics so this is just too hard. 
i use it to test small snippet of code where i try to use constructs that i'm not too familiar with. Cling also helps me in embedded programming: if a piece of code is not directly tied to the hardware, I can check it quickly without having to write immediately a unit test. It helps in the prototyping stage.
&gt; they sacrifice iterator stability guarantees. Is this only for iterators pointing to the old sentinel nodes (end iterators) or are there other cases? I think storing end iterators in e.g. a vector is not common (one typically stores iterators to the elements), but I guess this means that these can't be moved while iterating since any loop [begin, end) will break if end is invalidated. &gt; container-internal (libstdc++, libc++) sentinel nodes Does this mean that for move assignment the container needs to find nodes pointing to the sentinel, and change them to point to the new sentinel?
I'm pretty sure too that is not the book you were looking for. I hope you can get your money back.
...or simply look at what you're buying before you buy...
&gt; Beginner's
Jumping Into C++ Head First C++ Learning C++ Easy Beginner's to Expert's edition C++ Programming Step by Step Beginner's guide Fast Track C++ C++ Brain wash style Accelerated C++ C++ Programming: Principals and Practise Beginning Programming in C++ ... **ALL** of them (*and more*) are have the EXACT number of pages (260), SAME 20 chapters. This is the shittiest of the shitty authors.
There's nothing incorrect about it. It is correct and faster. Can you perhaps explain what you consider to be incorrect about it? I'm not sure I follow on your second point. Doing the notify before you even perform the push only exacerbates the issue I mentioned, since it makes it that much more likely that a consumer thread will wake up, try to re-acquire the mutex, and then go back to sleep because the mutex is still being held by the producer thread who is in the process of doing a push.
Huge improvements from VS 2013, looks like I can finally use some of the modern C++ libraries that weren't compiling with 2013 :)
An amazing job, well done :-).
&gt; Terse static_assert | No | No Dammit, of all the C++17 things to not implement... It should take like 5 minutes, right?
Probably very much OT but there was some work on getting MS C++ ABI documented, probably mentioned by Herb Sutter first if I remember correctly. Any idea if thats still on the table?
Herb is still working on his ABI proposal. It's for ABI stability throughout Standard C++, not just "documenting MS's ABI". For example, GCC's libstdc++ was unable for *many years* to provide a C++11-conformant basic_string due to ABI concerns.
I asked, and they told me that it wasn't trivial. It's not *hard*, but it's not a one-liner that we could sneak in at the very end of the product cycle.
We can't talk about future release scheduling, but history is fair game. I believe that "3 years between releases" is an inaccurate characterization. Observe: 2003 (+2) 2005 (+3) 2008 (+2) 2010 (+2) 2012 (+1) 2013 (+2) 2015
Holy shit you guys must have been working like crazy!
VC++ Dev Mgr here! We know! Expression SFINAE is our highest priority for conformance. 
vc dev mgr here, although ironically one of the most common pieces of feedback I hear from customers is "why are you wasting time on &lt;insert c++17 feature here&gt; when you don't have &lt;insert c++11 feature here&gt; ?" So these aren't necessarily the slam dunk you would think they are. In general, we try to get features in a priority that includes cost to implement, importance to build common libraries, and a few other dimensions. Then we have to weigh it against our work items to clean up the compiler infrastructure which have been the key to helping us up the implementation pace. 
I still remember your last post, and was kinda disappointed Microsoft still couldn't keep up with clang / gcc / icc, but this is looking great! Unfortunately this should've been in VS 2 or even 3 years ago. Honest question: What takes so long? Why is every other compiler vendor faster? Especially clang. 
bump
One-word answer: 2012. By the way, I invite you to compare VC 2015's STL feature table to [clang/libc++'s table](http://libcxx.llvm.org/cxx1z_status.html). I believe that 2015's STL is comparable to, or even slightly ahead of, libc++ 3.6 (current) and even 3.7 (next), although not strictly ahead (as VC lacks result_of/function SFINAE).
Check out [Modern C++ Design](http://www.amazon.com/Modern-Design-Generic-Programming-Patterns/dp/0201704315) by Andrei Alexandrescu. It's a bit dated now, but it's a good starting point for wrapping your head around TMP. You can also find his latest talks on template programming on youtube and msdn's channel9.
For me, they never really clicked until I started writing assembly. I initially found references pretty confusing too. They have confusing syntax, imo.
It would be really nice to have a toolchain only edition. There's a lot of reasons i don't like to download the whole IDE. But the most important one is, i don't use IDEs. I code on Sublime, and my build system is CMake+ninja. So, having only the toolchain (including the Windows SDK) would suffice for me.
Will there be a way for projects to create custom C++ generalized attributes? For example: allowing some kind of script to run when they are encountered. I could see generalized attributes being used in things like Unreal Engine 4's reflection system or something similar for other projects.
It's not enough, you know. I want you to drop everything and get variable templates working. :P Nice work by the way. I'll look forward giving VS 2015 a spin.
You just have to indent your code by 4 spaces: #include &lt;iostream&gt; using namespace std; int main() { cout &lt;&lt; "Meow" &lt;&lt; endl; } 
Thanks, that's very informative.
Releasing the mutex before notifying the condition_variable is absolutely correct and more efficient. Source: we're doing this in the STL's implementation.
By the way, as far as formatting on reddit goes, add a "\" before the "\#" so that your includes don't show up as header text.
If you want your mind absolutely blown, then do one simple change to your test to see just how much faster it is to do the notify outside of the critical section rather than inside of it. Change this snippet: for(size_t i=0;i&lt;N;++i) { { lock_guard&lt;mutex&gt; lg(mtx); //my variant //if(q==0)cnd.notify_one(); ++q; } //your variant cnd.notify_one(); std::this_thread::yield(); } To this: for(size_t i=0;i&lt;N;++i) { bool notify; { lock_guard&lt;mutex&gt; lg(mtx); //my variant //if(q==0)cnd.notify_one(); notify = q == 0; ++q; } //your variant if(notify) cnd.notify_one(); std::this_thread::yield(); } The correctness is preserved. I changed your code so that N = 30000000 and these were the results: notify inside of the lock time ./a.out 22+21=43 real 0m20.619s user 0m15.595s sys 0m25.506s notify outside of the lock time ./a.out 2+1=3 real 0m13.668s user 0m10.268s sys 0m16.920s That's about a 1.5x speedup.
there's some vsvars.bat fil or something like that which sets up a cmd.exe to be able to run the compiler stuff. i stole/hacked it to use with cygwin so i can keep my sanity and do pretty much all my dev through ssh and (on windows) rdp.
As a non-Microsoft user, I have to give you (that is: the whole VS team) some credit. It's obvious that you are taking things serious and you've made some impressive progress. VS2015 is the first version which is reasonably feature-complete and bug-fixed that it was able to compile some more advanced code of mine, e.g., https://github.com/ColinH/PEGTL That said, a feature list on its own is nice, but the usability and acceptance also depends on being more than just that. As a Unix/Mac developer, I often find myself looking for two things in VS: First, an online compiler where I can try to check some code in order to write a proper bug report (and a reasonable way to report those bugs) and secondly a reasonable build-system that I can support *without* having VS. The first part is partly solved by http://webcompiler.cloudapp.net/ - except that there seems to be no way to pass flags to the compiler. I have one bug in the above mentioned PEGTL which seems to apply only to Debug-mode, but I can't create a SSCCE without the online-compiler. Also, it would be nice to have some *easy* way to report those bugs. Something like Bugzilla or even a simply email-address. The second part about the build system is mostly about out-of-the-box support for VS from some project. If you look at the PEGTL, there is a 66 lines Makefile which should work for almost all Linux/MacOS users. It doesn't care which version, etc. Something similar for VS would be very nice, just telling it: Here's the headers, here's the code, here's the unit-tests, ... Does something like this exist? I don't want to use some non-preinstalled tools (that I can't even test) and then generate large amounts of project files for each version of VS and commit all of that to my small library. 
Yes, I was quite confused about references, particularly because of the dot notation for accessing `class` members. Took me a little while to arrive to the realisation that references were kinda like a safer alternative to pointers.
That was helpful. It was kind of hard to find clear examples with Cling.
We use CMake for this, which allows generation of solution/project files for any visual studio version without the need for vcvarsall.bat or %VS1nnCOMNTOOLS%. And locally, I do use the VS IDE with the cmake-generated solution files on occasion. However, it's on remote build nodes it becomes painful; these are completely hands-off Windows Server 2008R2 vmware instances running as jenkins slaves. Here we never ever run the IDE except once after initial install to input the licence key; they run completely automated jobs triggered by e.g. git repo commits/pull requests. Because it's a shared cluster, resources such as disk are limited and this currently constrains us to the number of VMs we can run with visual studio installed, and with a few versions installed the &gt;20GiB of space wasted by the unused IDE, that's space we should have been using for our builds. There's also the lack of agility in our processes. Installing VS is not quick, and it costs admin time and money to schedule. Since we don't actually *need* it, that's wasted time and money. In contrast, yesterday I needed to do a test build with clang 3.4; it took less than a minute to run "pkg install clang34" (on FreeBSD) and another few to rerun the build with the new compiler. I can't tell you how much I wish the process was as streamlined and quick on Windows! 
Thanks guys, great to know you're aware of this!
So do we have an ETA for 2015 release? I am guessing the plan is to release sometime just before the Windows 10 RTM on July 29?
How do we compare this library to hpx? 
&gt;"why are you wasting time on &lt;insert c++17 feature here&gt; when you don't have &lt;insert c++03 feature here&gt; ?" FTFY
Actually you didn't... On mobile I see no difference
c++11 vs c++03 I should have probably said c++98 tho, since the feature I had in mind was two phase look up.
I've been tutoring EE Engineering students in their third year and sadly the most "common" mistakes have been syntax related. I am a huge fan of using fully fledged IDEs for learning as it makes the students focus more on the logic and implementation instead of the syntax, but I know many do not agree with this because learning the syntax is important for a beginner. I would however suggest to use some sort of syntax-aware code editor to avoid mistakes like missing semicolons after class definitions. As for what you should be very knowledgeable in; debugging! Being able to quickly decipher compiler errors and narrow down the cause is extremely helpful. I saw the labs as three hour debugging sessions for my self, and there was rarely a day without seeing a new type of compiler error produced by some of the students. :-)
Maybe returning optionals could be better if emptiness is allowed.
Yeah, that was what I thought. Thanks for the reply!
Is lack of proper two-phase name lookup really a big deal if VC++ has now managed without it since C++98/03? Or would it be a big deal to finally get support for it? 
Count my vote for tool-chain only installations as well. I have cross-platform software that I need to build and test on MSVC, but we never use the IDE at all.
I've been a tutor for an algorithms-lecture and have taught several people stuff about C++ in a non-official context, so I guess my experience is close enough. ---- First of all: If you haven't seen it, watch this talk: https://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Keynote-Bjarne-Stroustrup-Cpp11-Style After you covered the basics, watch it with your class. ---- Teach the language in a top-down fashion. Pointers should be the last thing that you touch, the first 90% should be showing ways how to avoid them. There is no legit reason at all for people being able to understand details about pointers to pointers if they don't even understand `std::vector`, iterators and the algorithm-library. Pointers are for experts to implement advanced functionality. The common beginner should be taught how to avoid them, just as they should be taught functions and loops instead of gotos. ---- Do not hide the fact that there is undefined behavior. In fact: Teach that a the very beginning. These are the safety-instructions that are required for the language. And if you ask any biologist/chemist/, they will tell you that safety-instructions may be boring, but they are always taught at the very beginning, before you can seriously blow things up. ---- There are tons of very typical problems that badly taught beginners have, try to look into what those are and make sure that you apply countermeassures. For a list of some of the things that I often encounter on /r/cpp_questions, you can look here, including explanations what better ways are: https://florianjw.de/en/modern_cpp.html ---- Teaching the “how” is utterly useless if you don't teach the “why”. I remember painfully how I wasn't able to understand why the hell I would want to use const, even though I understood how it worked. (I learned C++ from bad online-sources, you don't want to give your students that pain. It *can* be done, but it is neither efficient nor usefull.) ---- Whenever I have some time and feel like it, I write on my C++-tutorial, which you can find [here](http://cpp.florianjw.de/); The pre-alpha warning is to be taken very seriously and you should certainly not use it for teaching, but it might serve to give you some ideas and demonstrate what I personally would do. (https works to, but you need to trust ca-cert (which you should)).
I disagree.
Really? That is truly awesome news! Do you have a link to that? 
Pointless? Also, lel `#define LET double` (and this limitation is also mentioned), so it isn't even particularly elegant. Could have at least made a variant type.
Thank you!!
Thank you so much for your suggestions!!
Regarding icc: From the feature tables I've seen, icc lacked even more behind (or similar to) VS 2013. Are you sure about that?
Well what about the whole C++11/14/17 STL? It sounds like they are using their own somehow? (I didn't read it in too much detail, but it sounded a bit like it)
Gah, I think I'm mixing two phase lookup and expression SFINAE! Sorry about that. Anway, I still think it's a little unfair to snark too hard given the recent progress - and I say that as someone who was mightily pissed off how far they were behind with previous releases.
Kind of cool! :-) It doesn't allow nested `FOR` loops, right? (IIRC they were allowed in basic?)
Which parts? If it is data structures and algorithms, they just operate on memory, there is no need for an underlying compilation target to care about high level libraries. This isn't a new language they are creating.
Yeah. It's unlikely that we'll ship two-phase name lookup in an Update, because it can break (non-conformant) code. We do that sort of thing in major versions, but Updates really shouldn't do that. (The exception is when we discover silent bad codegen; blocking that with an error is a reasonable thing to do in an Update.) In contrast, doing Expression SFINAE properly has basically no potential to break code, conformant or otherwise.
It has some uses, but they're very limited.
On a side note: from what I can tell from the blog post their `collect` looks like `sequence` for the Future Monad, with a signure similar to `Monad m =&gt; [m a] -&gt; m [a]`. I quickly skimmed the documentation and indeed, they even have a section about [Futures as Monads]( https://github.com/facebook/folly/tree/master/folly/futures#future-as-a-monad).
I don't understand what you say. I didn't know where to post it, so sorry about that. Thanks for the answer anyway
Yes, jokes are normally pointless beyond the humor value.
It'd be hard to find a realistic scenario where you can't work around VC++'s name lookup rules. It's mostly just an extra testing burden; if you're doing anything remotely complex with types and you aren't testing with both VC++ and gcc/clang regularly you're basically guaranteed to write code that only works in the one you're testing.
You... you can overload the comma operator? TIL
http://www.itworld.com/article/2936294/social-networking/facebook-turns-to-wizened-old-c-to-power-new-photosharing-app.html maybe? "for portability".
Does "using base_class::base_class` to import all inherited constructors finally inherit constexpr constructors properly? It was broken in the RC. Great job on VC2015 apart from that :)
I'm not sure why this is really a big issue. Having the option to pick and choose made a lot more sense back in VS6/2003 days, when disks were much much smaller and more expensive. Now one can buy a 500GB Samsung 850 Evo for $270, or a 4TB WD Black for $200, or a 1TB Black for around $65 if you're really pressed for budget. With disks being so cheap, it doesn't make a whole ton of sense to really worry about a few GB of features being added that some people might not use.
And overloading `.` is proposed for c++17.
After you've been using .net languages, which make things very cushy for the developer, it's going to be very hard to convince anyone to give up things like, garbage collection, modules, a HUGE plethora of 3rd party libraries to serve any purpose you could imagine, decent build times, and decent enough performance... Unless you really need the performance and Mono just doesn't cut it for some reason, you won't be getting any benefit from C++ in terms of longevity. How long do you want this code to last? What's the likelihood that it *needs* to last that long? Most codebases last 5 years or so before they get obsoleted to the point of being rewritten from scratch anyway. Standards change, new technologies get implemented, and new patterns become prevalent--you don't want your company to get stuck in 10-15 year old code that becomes so huge it's unmaintainable while simultaneously being the company's primary product... (been there, done that...)
I was really just stating that it probably doesn't make much difference to most people if their disk is 34% full or 36%. Unless you're hoarding mp4s or something, it's really hard to fill up a modern drive. I'm a huge data-hoarder myself, but I keep it all on a NAS (well, a Windows 2012r2 server, actually), so my system disks are for the most part rather empty.
On the other hand, real apps are running along with other apps, right? I did some more tests, remade it into more realistic way, with actual queue and deviation decreased a lot. But still no noticeable advantage for notify outside of the mutex lock. I also googled about this topic, and here is what I've found: * Most modern operating systems have wait morphing optimization. I.e. what I mentioned above - the thread is simply moved from waiting on condition to waiting on lock, without any context switching. * notify outside of the mutex lock increases number of unnecessary awakes (we saw this). * notify outside of the mutex lock breaks predictable scheduling behavior. I.e. if your operating system supports FIFO scheduling policy , it won't work with notify outside of the lock. * notify outside of the mutex lock leads to more cases of priority inversion. And finally - in real apps queue overhead is so small compared to other activities, that even 2x performance gain probably won't be noticeable on a bigger picture. But the person who will support the code after you will probably scratch his head look at that notify...
Except that I ran your version and my version where the time varied by about 2%, and the difference in performance between those two versions is 1.5x. You keep running these benchmarks and the deviations keep radically changing, the times vary by 100%s of percentage points, the misses go from 0% to 25%, it's all very ad-hoc and my point is when something is that ad-hoc and wild, you can not make any meaningful statement about it. Now you can argue that a difference of 1.5x on a queuing operation is tiny or insignificant and by all means depending on your domain it may very well be. Furthermore if someone wants to do a notify within a mutex, by all means go ahead and do it, it's not actually the end of the world and I wouldn't have even bothered to comment on this issue except that you decided to make the following rather bold claim: &gt;A little bit of nitpicking, but this is a bad push ... &gt;A proper push would be something like this: You can't say you want to nitpick on an issue, claim something is improper, it's incorrect and suggest a correction... and then when it turns out that your correction is actually not really a correction at all but just a personal preference of yours... decide to retreat on your original nitpick. If it's just a personal preference of yours that doesn't make a big deal because you feel the OS will take care of it anyways, then that's fine and you can simply make a post saying "Hey, I prefer doing a notify within a critical section." But if you decide to go all out and claim something is actually **wrong**, well you can't fault people like myself and STL who actually maintains the C++ standard library for pointing out not only that it's right, but actually is standard practice. http://en.cppreference.com/w/cpp/thread/condition_variable/notify_one Quote from the above: &gt;The notifying thread does not need to hold the lock on the same mutex as the one held by the waiting thread(s); in fact doing so is a pessimization, since the notified thread would immediately block again, waiting for the notifying thread to release the lock. And your point is also reflected as follows: &gt;However, some implementations (in particular many implementations of pthreads) recognize this situation and avoid this "hurry up and wait" scenario by transferring the waiting thread from the condition variable's queue directly to the queue of the mutex within the notify call, without waking it up. But that point only serves to show that you can hold the lock and many pthreads implementations will accomodate your usage, it doesn't justify your claim that doing the notify without the lock held is bad or incorrect or worthy of a nitpick.
&gt; You can overload anything, except for . and whitespace. Can't overload ternary conditional either.
First of all - I already replied that point about incorrectness was a mistake and even apologized about that. Second - I can't do anything about the fact, that on systems and compilers available to me 'notify outside of sync' optimization just doesn't work. Third - as I mentioned, possible benefits of this optimization are outweighed by quite significant drawbacks. So, from my point of view this optimization doesn't look like the kind of optimization that everyone must use unconditionally. 
I never claimed that everyone must use this optimization unconditionally. It was you who asserted with authority that the author's use of notify was a bad push and that your use of notify was the correct usage. All I did was point out that the author's use of notify is standard practice as used by C++ standard library writers, by the authors of boost, by the website I linked to which states that it's an unnecessary pessimization, and by text books that deal with writing multithreaded code. If someone doesn't want to use that optimization, by all means go ahead and ignore it. But for someone to claim that such an optimization is wrong and should not be used, then that is what I am justifiably arguing against. If you now also agree with that position then there is nothing more to discuss. It would be like you nitpicking over tabs versus spaces, claiming that tabs are bad, spaces are good. Then I come along and say that I like using tabs, they offer some advantages that spaces don't provide. I'm not claiming that spaces are bad and people should unconditionally use tabs... all I'm saying is that it's not something to nitpick over and your assertion that spaces are correct is actually wrong, they both serve their purpose. &gt; I can't do anything about the fact, that on systems and compilers available to me 'notify outside of sync' optimization just doesn't work. Of course you can. If you don't have a suitable environment to benchmark something as sensitive as a context switch, you should hold off on making conclusions about it. One should only do these kinds of tests that are very sensitive unless they have a suitable environment for doing them, and in your case you do not.
Ok, let's close this. &gt; Of course you can. If you don't have a suitable environment to benchmark something as sensitive as a context switch, you should hold off on making conclusions about it. One should only do these kinds of tests that are very sensitive unless they have a suitable environment for doing them, and in your case you do not. If optimization requires some perfect conditions to be noticeable, I seriously doubt that it's a good optimization. It's ok to have perfect environment to show a possible problem. Then this problem might occur in real project as well. But having perfect environment to show the benefit it awkward.
&gt; One-word answer: 2012. What happened in 2012? 
C++/CX.
Pardon my ignorance, but what makes this useful? Like... what's the application for something like this?
And the `.*` pointer-to-member operator.
You could support other data types too by using `auto`.
Hmm... there seem to be many Indian "IT" professionals who do this sort of stuff. 
Didn't click the link either, I see.
Assuming you read one page a year, it would take about 976 years. 
You will never get any answer. This is useless in the industry (and over-complicated)
&gt; competition does wonderful things :-) I'm not going to disagree!
Here are two things that I wish I had known or been taught directly: 1. Teach students to manage their frustration. Teach them to monitor their frustration and say things like "I feel frustrated, but that's a sign that I am experiencing a challenging programming situation." 2. There are different styles of programmer. Some want to plan and design carefully before writing code. Some want to start by writing enough code to be able to iterate a design. Both approaches are valid.
Are you saying C++ is only ever useful when for some reason you *have* to interface with legacy code?
I don't think they have been sent yet. I am on the program commetee (but not part of the group that makes the final call) and this year there are even more submissions than last year. So that makes the job harder. Also remember that all this is done in people's free time on volunteer basis (I know I dropped the ball on my reviews this year because of work demands). So let's give them a bit more time. Boris
Reviews seem to be done, notifications are pending. Not sure how long it will take, but I guess you'll know soon.
Monad are an incredibly useful programming pattern and having a generic monad library helps avoid code duplication by building libraries that work with any monad. Is is also often the case that all you need to know is that "X is a monad" and you can write your code without caring what X is. Promises, futures, async calls, computations that may fail, computations that return errors and many more are monads. Suppose you have two futures `f1` and `f2` that both return an integer. You want to combine them into a future that returns a sum of those integers. How do you do this? What if I told you that `future&lt;T&gt;` is a monad? Then you don't even have to look at `future&lt;T&gt;` api! The code will be something like ``` f1.bind([](int x) { f2.bind([](int y) { return x + y }) }); ``` What if you have a `vector&lt;future&lt;T&gt;&gt;` but you want a `future&lt;vector&lt;T&gt;&gt;`? You can implement this for any monad and not just `future&lt;T&gt;`. So when you'll need it, you'll know that it is a valid operation because it is for any monad and `future&lt;T&gt;` is a monad. Few months ago I was looking at `Elm` language (compiles to JavaScript) and I was writing some code to parse JSON data. The author chose to hide the fact that JSON parser is a monad and so this information was omitted form the documentation. Furthermore the two monadic operations have strange names: `succeed` instead of more typical `return` and `andThen` instead of `bind` and unhelpful documentation: ``` succeed : a -&gt; Decoder a A decoder that always succeeds. ``` What? That's not useful at all. `return` of the `Decoder` monad, that would tell me all I need to know. So I was staring at the documentation trying to figure out how to write my parser (which was too complicated to be easily handled by the library's built-in -- written in JS and exposed to Elm -- convenience functions) until it occurred to me that `succeed` is `return` and `andThen` is `bind`. The rest was trivial since I know how to write monadic parsers. So if you know monads and I tell you `X` is a parser monad, go write a parser, then you'll immediately know where to start and how to proceed. Sure, the specific library you may use will have richer API and most certainly will contain functions that will simplify the code, but from the moment you hear `monad` you know the general structure of the code you'll need to write. Monads are not complicated. They are incredibly simple. Bind and return is all you need to get started :)
&gt; As a beginner I would say that const indicates a clear message that the variable is not to be changed once initialised Yes, but why would I want to do that? Why can't I just write the values directly into my calculations? These questions are relatively easy to answer, but they must be answered and way to often they are not or not in a good way. Furthermore making a variable const is a nice thing, but you can really live without it; the really important point for const is to add it to function parameters and, in case of methods to `*this`, the important point being that this eradicates entire classes of bugs without much effort and makes the code much easier to understand. Contrary to popular opinion however, const doesn't help that much with optimization (unlike constexpr). ---- &gt; Why is there `const_cast` Because some library-authors are idiots and don't anotate function-parameters that never change their argument as const. `const_cast` can be used to work around that without having to sacrifice const-correctness in your own code. If you only use well written libraries, you should never need it. &gt; Why is there `mutable`? Because a const method should not change the semantic value of an object but may change the bit-representation of that value. A very simple example: class foo { public: void set(const std::string&amp; str) { std::lock_guard&lt;std::mutex&gt; guard{m_mutex}; m_str = str; } std::string get() const { std::string tmp; { std::lock_guard&lt;std::mutex&gt; guard{m_mutex}; tmp = m_str; } return tmp; } private: std::string m_str; mutable std::mutex m_mutex; }; Putting aside that we would normally like to stay away from that lowlevel synchronization, this shows how we can use mutable in a reasonable way: Even though the const-method actually changes the value of the mutex, the value that I care about from a semantic perspective (the string) will stay the same. Yes there are only very few situations like that and the important thing to note is that C++ is a language that is not intended to be extremely pure but for experts in the real world where it is important that you are able to override some rules.
Ok, please realize this isn't a compiler it is a compiler target. They aren't making a new stl or C++ compiler. 
You do not need to specify the template parameters inside the class body. This already works: /*start of file, pragma once and misc headers*/ /* A simple stack only array like container with an opt-in no-except policy that specializes the container */ template&lt;typename stored_t, size_t storage_allowed, bool no_except&gt; class Array { public: Array() = default; Array(Array&amp;) {...} Array operator =(const Array rhs) {...} /* etc...*/ };
&gt;Also. Object.notify in Java and Monitor.Pulse in C# are prohibited from being called outside of synchronized/lock sections. May be for a reason? Yes it is done for a reason, and you should inform yourself of that reason is before using it as a justification in your case. The reason is to reduce the size of an object. In Java, objects have a mutex and a condition embedded within every single object. Both of those require certain synchronization primitives in order to be implemented. So there are two options... those objects could have those synchronization primitives be independent of one another which would allow notify to be called outside of a synchronized section but which would cause the object to be greater in size and add more bloat to it. Or the synchronization primitives used by an Object's embedded mutex and condition could be shared between them, reducing the size of the Object but requiring that notify is called from within a locked section (to avoid race conditions). Note that when using a stand-alone `Condition` object, it is not a requirement that one invoke the `signal` or `signalAll` from within a synchronized block. &gt; I'm 15 years in the telecom. And my rule of thumb is to doubt and recheck everything. Neither Sutter nor authors of STL are omnipotent gods who can't be wrong. Sutter had changes of mind in the past. C++ committee made some decisions which had to be corrected later. Everyone can make a mistake. Including me on this issue. If you wish to doubt and recheck everything, as you claim, then next time be a little more humble in your approach to correcting people rather than jumping to nitpick details that you don't have the means or the tools to investigate properly. It's a little funny that you're now doing this complete reversal about being skeptical and wanting to question everything, going so far as to suggest that you are more well versed on this topic than fairly well known experts in the field, given how this whole discussion began with you deciding to nitpick something which actually turned out to be entirely irrelevant. Everyone can make a mistake on this... and that everyone includes you. You would be best to reflect on that before nitpicking people in the future.
A tiny bit of criticism (some might call it nitpicking): - Slide 7: You're using the default by-value capture mode for the lambda. The default capture modes are considered bad. Prefer C++14 init or copy r into it explicitly. - Slide 24: Consider adding a hint the init capture is a C++14 feature. - Slide 28: Modules, most likely, wont make it into C++17. Co-Routines is mentioned twice. 
No, but in his described situation ( a lot of existing .net code, asp.net...). If the client part was graphics, then C++ gets interesting, esp. on mobile, but that doesn't seem to be the case. The low levev C doesn't need to be legacy, who knows? :-)
but andrew is not scientifically hacking professional :/
From personal experience, I was a C and then C++ program for 20 years, and now pretty much do everything in .NET. I'll never go back. As a person who programs in .NET, but deals with C++ programmers, I'm constantly frustrated at how frickin slow C++ development is. Everything is hard; nothing is easy. Those trivial libraries in .NET that are awesome? In C++, you slowly and painfully initialize your apartment threading, initialize, set, addref, and more crap. Or you painful wade through pages of documentation for "helper" classes that break, or have weird side-effects. Worse, every time we think about making the code faster, it's a painful conversation. "Can't we just switch the type of blah?", "Can't we try moving this here and wait for that". The answer is generally, "no" or "if will take a week to get the allocations straightened out and to stop crashing." Whereas with C#, refactoring is simple and fast. And now that I've gotten used to the Async/Await pattern, every language that doesn't have that pattern is frankly a loser.
Hmm, well I know of some reasons to go C++ for cross platform mobile support (since C++ is the only language equally available on the major platforms so code reuse is a factor there). And for backend with the emergence of the high speed web framework platform such as https://github.com/stefanocasazza/ULib, the OkCupid libraries, Facebook's Proxygen and so on I'd go: - HTML5+JS+CSS or - Native Mobile + C++ on the Mobile end and C++ Web / Microservice on the backend. And for the data model I'd use http://www.codesynthesis.com/products/odb/ (C++ ORM) with a PostgreSQL database. Mostly all code in one language for everything and you'd be sure there was no weird GC/VM or large environment issue slowing you down and everything would be one language (C++11 or better depending on your selected compiler). Get GCC5 or clang and just go nuts. Developers available if a bit more expensive but you'd have massive control over your entire product. If you suddenly needed RPC, parsing, protocol serialization, unit testing... All out there right now for C++ there is no need to drop into stuff like JS, Java or C# unless you really need a lot of already existing libraries packaged into a large environment.
That was seriously considered at one point. I'd have to ask a compiler dev about the reasons for the decision, but I believe that compiler throughput was one of them.
Great to hear. The webcompiler is linked from https://isocpp.org/get-started (by its old URL rise4fun, which is rewritten-redirected). For clang/gcc, I prefer wandbox.
It works there too. This is called an injected-class-name, and it's available as soon as the compiler knows what class it's working with. C++ is (conceptually) parsed left-to-right, top-to-bottom, so this information is known when the compiler sees MyClass::meow. That's why trailing return types let you use injected-class-names.
I have been hoping for leaps and bounds in eInk screens since I first heard of the Kindle. Its really strange to me that it seems to be going slow or the news is just dodging me. to be fair I wasn't putting the good of the world first, more like "that would be cool" and "maybe my sleep pattern will get better"*. *(fake sunlight effect and the possibility that eradiating my face with whatever these monitors give off might be found to be less that optimal 8++ hours aday.)
Technically, it's an injected-class-name in both cases. The difference is whether it's being used as a *type-name* or a *template-name*. (See [temp.local]/p1.)
But what about `TakesATemplateTemplate&lt;Array&gt;` ? That's the case I meant.
(vc dev mgr here) This is GREAT feedback. I'll pass the webcompiler feedback on to the team. We weren't sure how much it would get used but after all the amazing stuff that the community helped us find after the constexpr feedback request, i'm very interested in investing more in webcompiler. project system pain for cross-platform devs is something we understand and are doing some exploration of.
don't feel stupid. it's relatively new and we just started updating it regularly recently. :) it's been very useful though
You're absolutely right - I had either forgotten that, or didn't know it in the first place, despite dealing with injected-class-names in the past. (It's "fun" with private inheritance.) Please enjoy your gold!
The 'get rid of STL' seems a little bit risky, especially when dealing with strings. B. Stroustroup &amp; co. suggest the way around, 'use STL as much as possible'
WebCompiler should have an API to use from command line, I hacked up a small Python utility to do that for now: https://github.com/ismail/hacks/blob/master/compilers/vcpp.py
Me too, a couple hours ago. 
Oh I had no idea, well this simplify's things dramatically... I feel silly now having brought it up but I have honestly never seen/noticed this in the 5 years i have been using C++. 
Exactly! :-)
I'm hoping that Herb's proposal, the clang people's efforts to be binary compatible with VC++ 2013/2015, and your clang/LLVM support for iOS/android will lead to a seamless clang integration soon-ish :)
Great article on optimizing memory usage. Lots of cool tips with practical usage, for the occasions when performance is really important.
C++/CLI is (hopefully) dead. You should use either Win32 with modern C++ or C++/CX for Windows 10 apps. P.S.: WTL is still an option.
hehe yeah I was just acting a little extra paranoid about what LCD/LED monitors mix in with their photons :)
[This](https://github.com/Corvusoft/restbed/blob/master/source/corvusoft/restbed/detail/session_impl.cpp#L519) (`^(.*): *(.*)\\s*$`) does not look like correct headers handling, for instance try to parse `User-Agent: Mozilla:4.0`. Are you aware of [RFC 7230](https://tools.ietf.org/html/rfc7230) to speak about compliance?
It looks like the handbook got posted here about a month ago when it was still being written. I therefore didn't see any of the comments on it then, and many things have since been fixed. Now it is finished, and it also now has the ability for people to comment on each section directly which should prevent me missing bugs, mistakes, inaccuracies or other such problems. Enjoy!
Is there a copy that doesn't require using an untrusted connection?
It only looks as simple as. :-)
The answer to the first part (why does Ninja provide a bigger boost in Debug vs Release builds) is that since wall-clock time is being measured debug builds are faster so the overhead of the build system is going to be more pronounced. In release builds most of the time is spent in the compiler so you won't see as much of a benefit.
The old Trac wiki and issue tracker originally installed for svn is still in heavy use, including for wiki pages such as the Best Practices Handbook. We are currently deciding whether to upgrade it from v0.12 to v1.0 in order to make it git and github compatible, or replace it entirely with something different. That particular committee will likely report in Sept, and again in May 2016. Action may happen sometime thereafter.
Wiki pages can be created on github as well. So this could be posted there for easier access until the SSL problem is corrected.
The only thing I can think of off the top of my head is support for variable-sized objects. That is, a class that looks like this: class Foo { // data... char extra_data[]; }; It's a somewhat common pattern, especially in C code (many Win32 APIs use it). By storing the optional value at the end of the struct, it means you can do this: struct Container { std::optional&lt;Foo&gt; foo; RandomType data; }; And container.foo-&gt;extra_data will be equal to &amp;container.data. It's a minor feature, but it does have some use.
Using cotire also speeds up cmake-based builds a helluva lot. It's especially cool with unity builds... On travis CI we went from about 25 minutes to 3 minutes for our build with it.
Flexible array member is not part of C++ ; all objects have a fixed size.
Also, `typedef Array self;` can be written to achieve the same effect as OP. I occasionally do this for clarity, and `typedef ParentName inherited;` for the parent class. Not when using multiple inheritance though!
Hmm, posted to /r/cpp even though the allocator interface doesn't have a "realloc" function, so standard containers won't have this behavior. And couldn't for non-POD types anyway. *Edit:* Yeah, this sounded snide. Other comments go into more detail.
[] is syntactic sugar for [[0]](http://stackoverflow.com/questions/6180012/array-with-size-0), which is a 0 sized array. Since c-style arrays implicitly convert to a pointer to the beginning of the array, it means that the variable is equivalent to a pointer to whatever is after the structure in memory, but without that pointer actually existing in memory (until you use it).
That is correct &amp; explains why it's up to a sizeof(void *) extra. Do you have any insight into why sentinel values aren't supported?
You still have to do the little dance of if(value) {} each time you use optional, which is equivalent to the amount of work you have to do to check a sentinel value. You're certainly not going to try{}catch{} around it instead are you? Think about it this way: sometimes you want to put up a nice picture of your family. You get a frame, commit a nail to the wall, and hang your picture. Sometimes you just want to put up a neat poster in your dorm room. You just tape that shit to the wall. Framing and hanging it is superior in every way except that you don't need any of that for a poster in your dorm room. If you need the features provided by optional&lt;T&gt;, then use optional&lt;T&gt;. But don't just use a tool because you can -- use it because it actually meets the requirements of your problem in a way that a simpler tool cannot. 
Becaues the standard defines this for optional &gt; The initialization state of the contained object is tracked by the optional object. making sentinal values a moot point.
What standard? It's not part of ISO C++. 
Obviously, the general case cannot have sentinel values because all possible values of the type might be valid. I guess you could write your own specialization for your own types that uses a sentinel value. 
According to [the docs](http://www.boost.org/doc/libs/1_58_0/libs/optional/doc/html/optional/tutorial.html) it does not seem to be specified that `boost::optional` must be implemented in any particular way. One suggestion was to use a Boost::Variant with a null type option. Are you just referring to some particular compiler/library's choice of implementation? 
It wouldn't be, as such an object cannot be copied by value. If you tried to return `boost::optional&lt;something_with_struct_hack&gt;` the extra data would not be copied.
Right, but you can't copy that struct in any case.
I've already figured it out thank to /u/uint65_t. So thanks anyway
There is no reasonable way to implement optional without some kind explicit initialized/uninitialized state. However, domain-specific knowledge can often be used to alleviate this problem.
`std::experimental::optional` is designed for the case in which there is no sentinel value; you can always write your own optional-like wrapper for your particular use-case with a sentinel value.
Hm, then this I'd guess? http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n3848.html#optional.general Not sure, seems existing implementations follow the cut optinal text I posted. Plus, sentinals are a can of worms if you ask me. A NaN may be a sentinal value to you, but to someone else it may be a meaningful result. To solve this, you'd have to injecting sentinal detection code into optional via a template, since there are no valid defaults for built in types. Ninja edit: It may be that you are looking for a different class? Optional, as it is now, is pretty clear in that it only is interested whether the stored type has been initialized or not. What about this far fetched example: auto foo(){ auto val = std::optional&lt;super_complex_class_type, complex_sentinel_function&gt;{}; //no bool flag, just a inlinable function that check the value ...code which does not assign/initialize a value to val... return val; } //Uh oh, got an uninitialized sential guarded optinal auto foo_result = foo(); //What is the correct thing for the sentinel check function to do here? //Seems like a case of undefined behaviour, which was *not* present before with the bool guard. if(foo){ cout &lt;&lt; *foo; } Using a sentinal guard causes optional to be undefined, while with the initializtion flag it would have been safe. Two wholy different behaviours. The only proper solution for this is a whole new class, where it is clear that it **must** be initialized, so that the sentinal function does not cause undefined behaviour.
0-overhead abstraction is the language philosophy. The philosophy of libraries (including the standard library) and of compilers is completely separate.
Basically problem boils down to expectations and assumptions - with `optional` people expect the type to potentially contains all possible values of embedded type and use it assuming so. But with `either` you explicitly state that value belongs to one of two domains. For instance: either&lt;Error, double&gt; result = someOperation(); // by convention "right" result is "the right one ";) if (result.hasRight()) { // code for double } else { // code for error } It would obviously need to store one of two possible values and indicate somehow which one it has. One way to optimize space would be to store both of them in an `union` (if this is possible - AFAIK this can be checked with template metaprogramming, some predicates should already be defined in either `boost` or `std` in newer versions of C++). But that doesn't get rid of left/right indicator. Let's say however that our templates declaration is something like this: // for clarity I skipped SFINAE checking whether L and R can be packed into the union but final version should do that template &lt; class L, class R, Pred&lt;L&gt; predicate = defaultPred&lt;L&gt; &gt; class either; Then you could do some optimization: template &lt; class LR, Pred&lt;L&gt; pred &gt; class either&lt;LR, LR, pred&gt;{ // ... bool isRight() const { return pred(value_); } // ... private: LR value_; }; Then you could just us it like: bool sentinelCheck(double value) { return } typedef either&lt;double, double, sentinelCheck&gt; guarded_double; guarded_double value = getSomeResult(); if (value.isRight()) { // function passed in as template argument is used - no overhead for additional variable // code for valid value } else { // code for sentinel value } Main difference here is in people's expectations about both types - in `optional` people expect *any value* of a wrapped type indiscriminately or no value at all. With `either` people expect that there is some sort of distinction. Functional programming use it to avoid throwing exceptions - you simply return left value and when you use `map` or `flatMap` it remains unchanged and keep on indicating that error occurred and needs to be taken care of (and you still have the access to the value describing said error). Sentinels are within expectations - you simple make some distinction on `right` and `wrong` values, and in case when their type happen to match and some predicate can assign value to the left/right domain, you can use that knowledge to avoid overhead.
These discussions are always so funny. Advocates of high level languages love to talk about how "speed isn't everything" and that "performance doesn't matter as much as developer time does". Oh, but suddenly, if there is a hint of that high level language being faster than the low level language, it's time to talk about it.
Firstly, github's markdown is not trac markdown. The conversion is non-trivial. Secondly, the web presence committee is tasked with converting all the content from the existing website and trac to whatever the new platform they choose. Content, and issues on github are not included. Indeed, though nothing is currently ruled out, my best understanding is that the direction will be less github, not more github. Github isn't trusted. Thirdly, the SSL cert problem is not a problem apart from that it looks bad. No security problems result, and no one is trying to M2M Boost's trac server as there is no point. I'd worry far more about the antiquated trac install on there and general - approaching total in some places - lack of infrastructure maintenance. Heartbleed for example was entirely ignored at the time, though I am told we were running such an ancient OpenSSL library it didn't matter, but my point is that we couldn't have responded quicker than in a few weeks even at best effort speeds. I have advocated hiring a full time employee dedicated exclusively to infrastructure and maintenance, but Boost is very conservatively managed. By past standards, it takes about two years from arguing an idea to them accepting it.
The people banging out web related python or perl are mostly just slinging around and dicing large utf8 strings with regex and so forth. Naive scripting code is likely to be *faster* than naive C++ for that stuff. So at a certain level the misconception is understandable. It's a bit puzzling that so many scripters remain unaware that C or C++ numeric code is going to be, like, 300 times faster.
Yes, so this struct does not provide evidence against a particular implementation of `boost::optional` because it could not be used in a `boost::optional` anyway.