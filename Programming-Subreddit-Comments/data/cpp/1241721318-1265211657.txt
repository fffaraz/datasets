Exactly. I never really understood why so many people are using 'const int' instead of 'int const'. That 'const int' is valid is only because it's an exception of the rule: the const (and any modifier, for that matter) always applies to the element left to it, except if 'const' is the first keyword provided. It just feels more natural to use one consistent way of defining modifiers.
(I know it's posted in /r/programming, hopefully we can have C++ discussion with less hater clutter.) Anyone know how much like his, the current Boost ranges are? Obviously not too much, or else it wouldn't have been worth a talk. Too bad, once again Alexandrescu has a better solution that doesn't make it (last time was his policies-based version of the shared_ptr, from his Modern C++ Design). 
Sadly, the 1975 c copy is still the most readable and intuitive of all the approaches given.
I was pretty skeptcal at first, thinking it was just more whining and complaining about how c++ isn't like some other pet language. After getting past the bullet points and getting into the actual proposed solution with code samples, I really like this solution. Although it's not *hugely* better than current iterators it does bring advantages with no major drawbacks that I can see. I'll need to look this over again
Alexandrescu is a serious c++ guy, not just some random. On the order of Herb Sutter and Scott Meyers.
Sure, if you like shallow copies.
ooo, sounds like I've got a new side project
I think having code like that do a deep copy could be more troublesome than helpful, especially given the context.
It seems to me that his C example is not directly equivalent to the C++ one. I like the 'ranges' though. I have written myself a string class that is somewhat like that (string = substring = range) and it's great (it's also immutable, so it's more like Java String class.
Thinking more about this... STL's claim to fame is the use of half open intervals...inclusive begin and exclusive end. Our code base has used this paradigm quite successfully ...it provides real meaning for managing and merging real spaces while still providing a way to manage discrete spaces. This range implements a closed interval with both ends inclusive. This works only with discrete spaces. And from what I can tell thats the simplification of the difference between iterators and ranges. And here's an example: Screen pixels and sub pixel mathematical operations. STL iterator speak says a pixel (for example) is [0, 1) meaning pixel 0 begins at zero and ends at one. Extend this to sub pixel operations... that means the pixel goes from [0., 1.) which still has valid meaning since the next pixel goes from [1., 2). The size of a pixel still being 1. (note for screen rendering purposes the pixel center is .5) Using the range idea a pixel would be [0, 0]. And then trying to extend this paradigm to real numbers falls down (since 0 - 0 == 0) I can write meaningful transforms that work in both real and discrete space with the iterator paradigm while it falls apart with ranges.
So I was bored last night and decided this would be an interesting challenge: http://pastebin.com/f7ce828a9 I'm still learning, so I'd be interested in hearing criticisms.
Why would anyone want the "new Foo" behavior over the "new Foo()" behavior. Why not make the former act like the latter? For that matter, why doesn't C/C++ always initialize POD to zero?
To save the few cycles spent on setting fields to 0, if you're about to fill it with actual data anyway. 
&gt; For that matter, why doesn't C/C++ always initialize POD to zero? Because the C++ community is mostly composed of people who think of not initializing stuff as an important optimization while neglecting to optimize higher level things (like algorithms).
It actually makes a lot of sense in the case where you are implementing your own memory management bits. A lot of times you allocate tons of space for your objects, but the real values aren't even available yet. You could fill them with "reasonable defaults", but that assumes that such beasts exist.
This is slightly misleading IMO. The `()` in this context denotes `value-initialization`. Section 8.5.5 of the C++03 doc covers this in detail. Since the parenthesis are empty the POD is `zero-initialized`. This only works because in this specific case the POD doesn't contain an user declared constructor or const or static variables.
Sounds like the wrong way to manage objects in the first place. Don't make one until you can fill in the values! (Premature optimization is the root of all evil)
It's nice to believe all that, but I challenge you to find an allocator that doesn't clump up its memory allocations. Every runtime does it. It allows you to reduce fragmentation, improve performance, etc., etc.
A reasonable default is that all bits of an object's memory are zero.
You can always build class-specific allocators and use any of some well-known algorithms that minimise fragmentation as well as optimizing the behavior for the particular class that is, uhm, suffering. Not worth breaking the object-encapsulation model. You'll end up with many more obscure problems to debug by not returning fully initialized objects. 
Yes, and the runtime has the option of doing that.
&gt; You can always build class-specific allocators and use any of some well-known algorithms that minimise fragmentation as well as optimizing the behavior for the particular class that is, uhm, suffering. Yes, and when you do that, you will find that you allocate chunks of memory and then initialize the objects when you need them. &gt; Not worth breaking the object-encapsulation model. You'll end up with many more obscure problems to debug by not returning fully initialized objects. I'm not defending the syntax. I'm defending the notion that there is a use and a place for the capability of allocating memory for an object without *yet* initializing it. In fact, if you think about how stack allocated objects work, it's pretty hard NOT to have that functionality.
Huh? Can you explain what you mean? I've never heard of such a feature of C/C++.
No ---- in the case of the 'string', for example, by the time I return from 'new', the object will be properly constructed. If it isn't, you aren't doing OO (which, given Alan Kay's observation about C++, is probably the case anyway!) --------- Yes, and when you do that, you will find that you allocate chunks of memory and then initialize the objects when you need them. - Yeah, if C++ hadn't tried to do both stack and heap management for objects, much of the crap that has made its way into C++ would not have been necessary. This is just one of the many reasons I stopped using C++ years ago. ----------- In fact, if you think about how stack allocated objects work, it's pretty hard NOT to have that functionality.
99.99999% (approx!) of the time, saving those few cycles is just not worth the grief you'll get from trying to debug incompletely constructed objects.
That's all stuff the article said. What's misleading about it? 
Man, you're in the wrong forum. C++ is a descendant of C, you know? Portable assembly and all that. Multi-paradigm, not OO. If you stopped using C++ years ago, what do you still find so interesting about it? Have a nagging feeling that you're missing something?
I was just hoping I could persuade others to move on to something better! (grin) Just because I no longer use it doesn't mean I don't follow its evolution....I track a lot of languages that I don't actually use. Last time I looked, C++ descended from multiple languages (including Simula and Algol) and since most (if not all) of its proponents argue that it's an OO language, then criticism of its failures in OO are quite legitimate. I understand entirely (and applauded) its original goals but it's my sense that it has gone out of control (a bit like Ada) --- almost every new feature added to C++ seems to be there to repair the problems introduced by previously new features.
The article doesn't fully specify under what circumstances the POD will be zero initialized. Simply calling `new Foo()` on __any__ POD type is not sufficient.
The language standard just says that the memory can be in any state you want. All 0's is fully compliant.
&gt; No ---- in the case of the 'string', for example, by the time I return from 'new', the object will be properly constructed. If it isn't, you aren't doing OO (which, given Alan Kay's observation about C++, is probably the case anyway!) Yes, if I want a string, then I always want an initialized string back. If I'm doing memory management for strings, then I want to be able to allocate space for 1000 strings without having to initialize them (actually the underlying arrays are probably far more important). Since you brought Mr. Kay in to this: try to find a Smalltalk implementation that doesn't grab chunks of memory at a time. ;-)
Maybe some of us C++ programmers know what we're doing ;-)
This show why C++ compatibility with C is great even if it has some drawbacks. 
&gt; I was just hoping I could persuade others to move on to something better! (grin) I would gladly move to something better if there was such a thing. Well, maybe Ada, but it is pretty much dying. The "alternatives" people usually mention are not alternatives at all (Java, C#, D, even Lisp and Python).
wikipedia doesn't have 'attribute' or 'final', yet the author mentions POSIX functions like fork so it's not MS-specific. Is C++09 still advancing so fast? edit: And I'm starting to think like the C++ haters; a choking amount of complexity! Not to say that it's not needed or that you can't absorb just those features that you need but man, the length and number of new books (&amp; book series') there are going to be!
Where the hell did these things come from? I've never heard or read of them, can someone else confirm this is legit about part of the forthcoming standard? 
I think they were proposed late last year. Microsoft has already stated they refuse to implement them because they clash with their existing attribute system.
Bjarne Stroustrup's book "The C++ Programming Language" has C++ exercises at the end of every chapter, but some of these are pretty tough.
[[citation needed]] please? :) 
[pages 169 to 173 of this](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2009/n2857.pdf) (edit: page 182 in PDF numbering) edit2: sorry I thought you meant about attributes existing at all; ignore me :)
7.1, motion 8, first two Cons of [these minutes](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2784.html).
"C++ Primer" by Lippman, Jajoie and Moo
[Project Euler](http://projecteuler.net/)
I like me some C++, but that's godawful ugly syntax.
^^hard!(for me)
I really liked this one: http://www.amazon.com/teach-yourself-C-Al-Stevens/dp/1558285520 He goes through all of the c++ features, chapter by chapter, with simple, easy to understand examples. 
"Accelerated C++ - Practical Programming by Example" by Andrew Koenig and Barbara E. Moo of Bjarne Stroustrup's C++ In-Depth Series. It's pretty practical and not a CS approach (IMHO). Lots of practical exercises in here. For example, the book will tell you that chars are evil if all you want is a string where other books will get you started on char pointers. It will also tell you about size_type and other neat C++ standard library stuff.
Well that's cool, but not even g++ 4.4 supports lambdas. I wonder what compiler he using.
I have this one, but there are no examples in it...
He says the Intel one.
Ahh. I'm pretty sure that note was not there when I read it.
What do you do if you want a ptr that can be NULL? 
First and foremost, he's first using a std::set&lt;int&gt;, most likely implemented as an RB-tree, to store his data then moves to a bit array. Then he is surprised that the end result is 10 times faster. Secondly, is he using MSC++, and if so did he disable iterator checking? That can slow things down a lot. 
I thought it was fairly common knowledge (among C++ programmers) that containers like std::set are not very optimal when dealing with small number of elements. The benefits of logarithmic search don't overcome the overhead until you are dealing with large collections of objects. Even a std::vector would be better if you only have 9 elements.
If you only have 9 elements, why not use an array? This is why I don't like C++ :P
Precisely. This is very far from an apples to apples comparison, it is like moving from std::string identifiers to an enumeration and pretending like this is revealing a crushing inefficiency the STL. Misinformation, FUD, or just simple ignorance.
There is nothing wrong with std::set or C++ necessarily, it's just that the overhead of a red-black tree is too much when dealing with so few items. It would be the same in any other language. A dictionary object or whatever is going to have a lot of overhead. The guy switched to something that was much more efficient, not because STL is bad but he effectively choose a more efficient algorithm.
&gt; Solving all 50 of Project Eulerâ€™s sample puzzles took 2 minutes in debug mode (in which a lot of extra checking of iterators and the like takes place.) The release build was more reasonable, but still took 3.7s.
Iterator checking is normally enabled in release builds. You have to explicitly disable it. 
I'm sorry, it is just dumb to implement a grid using a set of sets. This is screaming for a vector of vectors at least (and actually something with bitwise logic makes far more sense). If this had been a one-dimensional grid, one *anyone* have thought of using a set instead of vector or array?!
In C++ it'd be entirely logical to use an array. Honestly, this guy tried a deliberately boneheaded approach to start with.
He kind of proved Linus right, didn't he?
Right. It would have been interesting to compare with std::bitset
Besides regular C arrays, we also have Boost.Array ;-)
No.
Oh come on. He went for a more C-Like solution, because he was too much of a dope to pick a reasonable data structure to start with. I think that is totally Linus' point.
std::bitset is probably best for the method he chose. But I used a std::bitset implementation to unlock the Project Euler answer and saw that my ass had been thoroughly kicked by better algorithms. Naive brute force with a bitset is pretty good though, &lt; 120 milliseconds for the 50 sudokus.
Oh yeah, brute force is brutal for this, but if you are going to go that way, don't be an idiot and make it impossibly slow, and the gripe about C++.
Screenshots here: http://www.josuegomes.com/codeblog/vs10b1.html
Other than the ribbon this is basically the same. Speaking of the 'ribbon', have any of you ever watched, **[The Story of the Ribbon](http://blogs.msdn.com/jensenh/archive/2008/03/12/the-story-of-the-ribbon.aspx)**? That's a submission in itself, fascinating video there.
And using a terminal with vim is still more visually pleasing. What do I need all that crap for again?
What's the difference with the previous versions? The editor changed from white to dark-blue, and that's all?
You can spend more money. 
This is the only studio I use: * [GCC](http://gcc.gnu.org/) * [Emacs](http://www.gnu.org/software/emacs/)
[These are some of the changes](http://www.microsoft.com/visualstudio/en-us/products/2010/default.mspx). I don't understand why everyone is downvoting this submission. Visual Studio is one of the few things that Microsoft did very well.
OK, nice screenshots. What about standards compliance? I'm fed up with VC++ catching exceptions I have not exported :-/
Really? I was recently on a project where I had to use a terminal and vim for lack of tools on the box. I thought I'd enjoy going back to that world, but it was frustrating and less productive than using a sensible ide. It's also not like I'm not used to vim, I used it a lot in the past and I'm pretty comfortable with it but you really can't compare a half decent ide to a terminal and vim. These days I use Visual Studio or Emacs depending on the environment I'm working in and I find that you need "all that crap" so you can spend more time writing/debugging code rather than flicking between editors, debuggers and the shell.
Too many screen shots too little content? 
The screenshots are the content.
I just want to say that /r/cpp sucks. There are never any articles about stuff that interests me or relates to my field (game programming) and you all guys seem to do is whine on and on about C++0x and how it's going to change the world forever. My personal opinion is that C++ is not suited for any application besides games. Templating and overloaded operators make things an absolute nightmare and it's ridiculously easy for a newbie programmer to bring down your entire project. Unless you absolutely need the speed (embedded programming, games, physics simulations), please please use a different language. Does your tax auditing program really need C++? How about a wrapper language, like [AutoIt](http://www.autoitscript.com/AutoIt/)? Or Python? Or C#? Please note that this is my personal opinion and that I will be downmodded to oblivion for it. And I respect that.
You are correct: c++ is very dangerous in the hands of inexperienced/bad programmers. However it's very powerful and expressive in the right hands. Back to the article...are there any benchies on these libraries...cpu vs device operations? I'd be interested in seeing numbers on a spread: 9500gt, 9800, etc, not just the $500 cards.
Thrust.
Oh. I hadn't realized Microsoft started trying to support standards.
Yes, they do a very good job these days.
I use first and two only when necessary
Actually they don't. Try doing io on bigger than 4G files. Even on 64bit.
Do you have any sample code so that other people can verify your ridiculous claims? 
That's weird. There will be two front-ends: one for intellisense parsing and another one for the actual compilation. I have a bad feeling about this. -- www.josuegomes.com 
Who does? GCC? Blah.. -- www.josuegomes.com
bigest thing missing here is utf8 support but that's not too hard to put in.
That's the way I do it. I like it because it sidesteps the issue of grouping with the type and causing confusion for multiple variables at once, or grouping with the variable and causing confusion by separating the modifier from the type. Putting a space on both sides of * or &amp; emphasizes it, because it is important enough to need to stand out.
I started C- and C++-programming in an IDE environment: Think C and Codewarrior were my tools of choice on MacOS 7. Then I went Unix and there really weren't any decent IDEs, so I got used to working with makefiles and an editor of choice (at that time, nedit). I'm on OSX now, but these days, IDEs just piss me off. They always seem to want to handle my source files the way iTunes treats mp3-files: they suck them into their own little world, making it harder or impossible to manipulate the project directory from anywhere else. That's a double-whammy if you're dealing with a VCS that is not directly supported by the IDE. The other beef I have with what I see in those screenshots is the tabbed/MDI setup. This is something that annoys me in more Windows programs, but with code editors I really don't get it. How can you live without the maximum freedom to drag your editor windows to wherever, for those moments where you want to look at more than one source file at a time? 
XCode in OSX and VS in windows both let you put your code windows where ever you like and you can min, max, split them etc. Netbeans works everywhere and is pretty sensible IMHO. Also all the above keep source files in a fairly sensible format and you can customise project layout if you can be bothered. Having said all that, I'm not trying to convince you about any of the above IDEs. They all take a certain amount of persistence to get used to, and for some there's just no compelling reason to change.
&gt; XCode in OSX and VS in windows both let you put your code windows where ever you like Is there a way in VS to make that your default workflow? From my impression of those screenshots, that one huge-ass project window looks like that's supposed to be what you're working from most of the time. I've got a terrible short term memory so I really need to have relevant header files open on my screen while I'm implementing things. XCode doesn't have this specific problem. My beef with Xcode is that I don't like its code editor (I'm a BBEdit junkie). I'm not doing any Cocoa at the moment anyway, so it doesn't really add value.
That's actually quite awesome and pretty. More direct link [here](http://img-fotki.yandex.ru.nyud.net:8080/get/3602/jim1537.52/0_27f8a_eab3e192_orig) 
Where be dragons?
I have the same problem with needing the header files open! Actually the best thing is that there's a window called the code definition window. It displays the definition for what ever the cursor is on. It's actually got to be the best thing about it. As for arranging windows VS is pretty good. You can drag the tabs off and then tile, split etc the windows how you like. When you pick up a tab you get a group of floating icons that you can drag the tab to to allow you to control how they dock relative to the windows that are there already. I do like how XCode does it, but i reckon VS does it best, with netbeans joint second. I have to use VS for work, but if i had it on Linux and OSX i'd use it in preference.
It's cool!
So I'm trying to decide on a multithreading solution for C++ that doesn't add too much overhead to the application from a maintenance standpoint (assuming that my design is good). OpenMP seems like a good choice because I want to be able to open the application and develop cross-platform. I thus don't care too much about Windows-only libraries. Another thing I stumbled upon is Cilk++ but it doesn't seem to be free. It looks convenient since it manages itself. Then there's the Threading library in Boost which seems to be cross-platform but somewhat lacking and rather inconvenient to use (but I might just not be able to appreciate the magic just yet). Also a couple of general questions: * What are the usual multithreading threats in C++? (I guess bad design and racing conditions but you guys tell me!) * Do random third-party libraries generally play well with MT? SDL, for example? * Any good recommended books on my issues?
OpenMP is meant for high performance computing applications rather than the sort of multithreading you'll find in most applications (or games.) It looks to me like a system to take the message passing and serialization required in an MPI program and have the compiler do it for you. If you're looking to do things like numerical simulations in parallel, then OpenMP is what you need. (Or better, just use MPI since I don't know of any OpenMP systems that scale to modern clusters.) What you likely want is the sort of parallelism constructs you'll find in the boost lib. This is the sort of stuff you'll see in typical desktop and server applications, things like processing an image in a worker thread while not locking the GUI.
Why do you say Boost is inconvenient to use? Also, you can try the threading library in the ACE framework, that's fairly straight forward as well. Just don't waste your time with all of that reactor/proactor framework nonsense in there. The threading libs are standalone.
Boost owns :P From a quick look at the threading library it simply seemed less convenient than say Cilk++. 
Things to watch out for, race conditions like always, static variables, and OpenGL. OpenGL does not play well with multithreading. As for SDL it has it's own multithreading support, though I cannot vouch for it's quality. I would recommend pthreads, because it is the greatest.
Qt has a nice C++ thread class. There's always posix threads, but you know, you'll end up doing some ghetto tricks with that from time to time. Doesn't sound like the type of thing you want to do.
I would recommend Boost, especially if you are already using it for other purposes. It is a bit large of a library to use if the only purpose is for threads, but the Boost thread library was a heavy influence in the design of the C++0x threads. Another good option is Qt, but ONLY if you are using it already using it in your project. Boost is worth learning and including regardless, but I wouldn't quite say the same for Qt. The major problem here is licensing, but it's got more baggage than Boost also. If you must stay away from Boost for whatever reason and you weren't using Qt already then I would probably just use pthreads. They are native on any *nix and there is a good port to Windows. It's a C interface instead of C++. Write a small wrapper class to clean up the interface and it works nicely. Oh, OpenMP is mainly designed for large cluster type applications. It isn't really geared towards small multithreaded applications running on a single host.
What are you aiming to achieve through your threading? There are two main goals: 1 - Responsiveness (running a seperate thread for HD access, UI, etc) 2 - Performance (paralleling operations) The various libraries out there meet these goals in different ways. OpenMP, for example, is focused on performance threading. Boost provides convenient threading constructs which makes it useful for responsiveness, but more work for performance. Of course even these are just huge generalizations with no knowledge on exactly what you are doing and (more importantly) what data you are processing. My advice is to just jump in with Boost and maybe also take advantage of Intel Threading Building Blocks library for it's parallel-loop if that is something that is really going to help you. You probably need some experience working with real threads in a non-painful way to appreciate what Clik++/OpenMP/IntelTBB really aim to do. Boost can provide that (it is WAY less painful than using native threads directly)
&gt; It is a bit large of a library to use if the only purpose is for threads Boost is not one monolithic library. You could build/link/distribute only individual libraries (e.g. threads, asio, datetime, etc). There's overhead, sure, but it's not that large. Just saying
Boost::Thread is basically what the new c++0x standard includes for threads. 
Sorry, I wasn't speaking to the size of Boost in general, not necessarily the executable library.
Boost has a MPI libary now, too, if you need it. But usually you don't. Before I parallelized my app I read Allen Holub's articles on [Java threads](http://www.javaworld.com/javaworld/jw-10-1998/jw-10-toolbox.html?page=1). The same principles apply to C++, and I haven't had any trouble since.
I commented on his blog about it, but I find it odd that he didn't template on the hash functions.
It's worthy of a course, if there's a university around you. Wrt books, probably a pthreads book (pthreads I believe are the model for the Boost and new C++ standard threading library, but there aren't any books for those yet; you'll get lots of nice diagrams and discussion that you can't get for Boost or std), and / or a general parallel programming book that _includes_ pthreads along with OpenMP (MPI is more for clusters). Also another shout out for TBB (also free). 
&gt; reactor/proactor framework nonsense It's not nonsense, just networking. It's in Boost as well, in asio (well at least _reactor_, not sure about _proactor_). Of course he'll have to skip it to look at just threading. But truthfully, I'd say ACE has been pretty much outmoded by Boost, between the threading and asio libraries. 
Unfortunately it's not standard yet :-/
This is an unbelievable complicated piece of code! http://www.boost.org/doc/libs/1_32_0/boost/array.hpp
I hope you are joking.
This is only 5 days late but I find the boost RAII scope locks are a wonderful abstraction. I don't know what other libraries use but I practically use scope locks exclusively with my work.
no. it has function prototypes and junk. 
And what did you expect from boost??? It's a library full of stupid template tricks.
His comments on garbage collectors are quite wrong. Most modern garbage collectors have no problem with circular links because they do not use explicit reference counting. Modern garbage collectors check whether an object is accessible (directly or indirectly) via the roots (stack and static). If an object is not accessible is is deleted. There are even some experimental garbage collectors for C++ that also work this way. http://www.hpl.hp.com/personal/Hans_Boehm/gc/
Yeah, a lot of the stuff in this article was "true, except... totally not".
In what world does it make sense to test gnulib array_list performance but not std::vector performance?
wow, you're totally right. "While the STL provides one list implementation, gnulib provides a number that all implement the same interface." I don't mean to insult his intelligence, but the author is obviously inexperienced with STL. Lets see, for sequence containers there's std::vector, std::vector, std::queue. As for non-sequence containers, there's also std::set, non-standard but common extension 'hash_set', and soon to be standard std::tr1::unorderd_set. So maybe the author meant a very large value of one. This article comes across as foolish at this point. I hope the author sees some of these comments and fixes the bugs at some point. 
Author here - thank you for your feedback which I fully take on board - it was my mistake for not thinking this through fully. I'm experienced with STL but not with gnulib and only realized that I misinterpreted the true meaning of the gnulib "list" interface shortly after I published the post. I've updated the post to point out the error and to clarify that only the comparison between the stl::list and gl_linked_list containers is relevant. I will publish a follow-up post shortly with a more complete comparison using the full set of STL containers. Thanks again!
Here is a review of [video lecture of parallel algorithms](http://www.catonmat.net/blog/mit-introduction-to-algorithms-part-thirteen/).
Wow, coding with Fost feels really awkward. What's with that FSL_MAIN instead of 'int main(int argc, char* argv[])? Take a look at http://webtoolkit.eu for something less intrusive (and more Qt-like). 
The FSL_MAIN provides a cross platform `main` that you can use which provides proper Unicode support. If you use the normal `main` on Windows things get converted to the machine's non-Unicode program's code page which leads to all sorts of really hard to track down bugs that turn out to be wholly environmental. Of course if you're doing web apps then you don't care about `main` anyway as you're running inside a web server's environment.
where did you find samples? i looked but couldn't find any :/
If you are looking to write secure and fast web applications in C++, it would be a good idea to look at OKWS. http://www.okws.org/doku.php?id=okws Might want to read its corresponding publication before doing so: http://pdos.lcs.mit.edu/~max/docs/okws.pdf
None of them show the web applications, but there are some examples of the lower level APIs * http://svn.felspar.com/public/fost-base/stable/Examples/ * http://svn.felspar.com/public/fost-py/stable/Examples/ There's also the code in the test folders alongside the source code: * http://svn.felspar.com/public/fost-base/stable/Cpp/ * http://svn.felspar.com/public/fost-orm/stable/Cpp/ * http://svn.felspar.com/public/fost-postgres/stable/Cpp/ * http://svn.felspar.com/public/fost-py/stable/Cpp/ * http://svn.felspar.com/public/fost-windows/stable/Cpp/ 
I keep looking at D as an option... what failings do you find with it?
Warning: damn fork bomb I svn checked out the base stuff cd'd in there and typed "./build". Started asking me a bunch of questions about username, etc. I couldn't 'ctrl-c' out of this at all, killed the window and it started forking "/bin/bash ./build" like mad.
Bugger. You're right. The Boost checkout was using the svn protocol (which requires a username/password) and not the HTTP one which is anonymous. That's fixed in fost-base now. We'll go through the others and make sure they're ok too. Sorry :( EDIT: I think those are fixed up now. The svn username is 'guest' with a blank password in case you hit anything similar again. If you have any trouble let me know -- thanks.
I don't think it's expecting too much that pointers to the same function should compare equal. Unlike the author of this blog, I have found uses for such a wild and crazy feature. Example one: generic adaptor functor for memoization or caching. If you instantiate it in multiple compilation units, it'd be great if the memoized values were shared. Without this feature, good luck making it work for arbitrary functions which may be inlined. Example two: multicast callbacks. A callback is added to the list in one compilation unit and removed in another. The remove will fail without this feature, because the callback functions will have different addresses.
The author also overlooks the obvious: just because the function has the same address in all translation units _doesn't_ mean that it must have the same code in all translation units. It means that &amp;foo must produce the same value; it doesn't mean that 'foo()' needs to go to the same address. And there's another detail -- 'extern'. If you declare the function (and all inline functions that consume it) to be static instead of extern (for example, put in an anonymous namespace), you can opt out of this rule. You aren't paying for something you're not using, you're paying for something you _are_ using, just intentionally. I was expecting this article to perhaps be covering the potential runtime benefits of folding identical functions, or the overhead of function static variables in various contexts. Maybe I'm the odd one out, but I was expecting more technical details or measurement.
disclaimer: I wrote the post
Bad thing in so many ways. If you are using c++ then use stl. If you're using 'c' then consider using gnulib. Never use gnulib if you're going to use c++. Templates can allow for much greater readability and type safety you won't find with all the void* casting games found in traditional 'c'.
Using gnulib with c++ was not the intent. The intent was to see which was quicker: C and gnulib or C++ and STL for a simple list.
http://www.amazon.com/Primer-Plus-5th-Stephen-Prata/dp/0672326973
First, macros BAD BAD BAD. I would avoid this like the plague. Second, what does he mean by "auto will be a standard C++ feature"? Hasn't auto been in there since the beginning of time itself?
Yes but not as meaning 'infer this type', that's in C++09.
This seems like an odd example to give for using the new auto feature in C++0x, seeing as how range based for loops are going to obsolete the FOREACH macro anyways.
Unfortunately range based for loops won't be in Visual C++ 2010. Does not matter for those who are only interested in targeting GCC but for others whose requirements include Visual C++ compatibility it may well be 2012 before they can use this feature. 
I've programmed in C++ for a decade. I've never used boost, and likely never will.
boost sounds like a great idea until you actually start to use it because then you get disapointed with what it doesn't actually do.
The fact that boost is considered such a gem to the C++ community says a lot more about C++ as a language than it does about boost.
Why?
Boost is a good library. I use what is needed when it's really needed. In my last project, the only library out of boost that I used was file system. The one before that I used the regex library. Unless you have a specific need that boost handles well, there's no pressing need to learn it.
The only reason I use C++ is for working on game consoles. This causes a bunch of restrictions: 1. We *really* care about code size and memory usage. 2. Using *any* open source code is a very complex matter. 3. We've been doing it so long that we likely already have internal libraries that do what we need and are tailored to games. Making C++ libraries that anyone can use is horrendously challenging. I respect the hell out of the boost guys, but it's a lot easier to work with C++ libs designed for a smaller pool of customers. Our internal libs can make a lot of simplifying assumptions that libs like boost can't.
Boost is a programmer's curiosity: a good attempt, using some very clever tricks, to solve a mostly obsolete problem. Older, established C++ projects probably won't adopt a whole new library like Boost widely enough to make it worthwhile given the learning curve. For newer projects, C++ is rarely a good choice of programming language with the diverse range of other possibilities today. The kinds of language limitations and portability issues addressed by Boost simply don't exist in almost any modern programming language. For those projects where C++ remains a good candidate, it is likely that use of Boost is either inappropriate (not enough fine-grained control of generated code) or unnecessary (established application-specific libraries already provide similar functionality).
It says that C++'s philosophy is to not include stuff that can be done with libraries in the language. 
No, (before anyone complains before thinking about it), the notion of using a private constructor to prevent stack-based objects won't help. Here's the thing....if an object can ONLY be instantiated on the heap, then it is no longer necessary to declare instance variables in the class interface. Instead, they could be declared in the implementation of a class since the compiler no longer needs to know the size of the class. That way, you can REALLY hide an implementation from an interface without having to resort to tricks such as opaque pointers etc. "Real" OO languages let you do that (grin)
PImpl Declare your functions in the PImpl class and declare the data in the (defined in implementation file) Impl class. /*filename: PImpl-example.hpp*/ #include&lt;boost/scoped_ptr.hpp&gt; class Impl; // contains instance variables, opaque class PImpl { private: boost::scoped_ptr&lt;Impl&gt; impl; public: PImpl(Pimpl const&amp;); PImpl(void); int foo(void) const; int bar(void); }; /*filename: PImpl-example.cpp*/ #include"PImpl-example.hpp" struct Impl { int foo_var; }; PImpl::PImpl(void) { /*make sure Impl can only be allocated on the heap*/ impl.reset(new Impl()); } PImpl::PImpl(PImpl const&amp; o) { impl.reset(new Impl(*o.impl)); } int PImpl::foo(void) const { return impl-&gt;foo_var; } int PImpl::bar(int nv) { impl-&gt;foo_var = nv; return impl-&gt;foo_var; } &gt; tricks such as opaque pointers etc. s/tricks/standard repertoire of techniques for C++ programmers/ Okay, okay, fine, if you don't want opaque pointers at all, don't use C++.
Sigh.... I'm well aware that that's the "standard" approach do doing this in C++. But that's a lot of effort for something like information hiding, which should be as simple as possible to do. Indeed there are even easier ways to handle this without the need for a separate class by the judicious use of some clever macros and conventions and they're way more readable. But no matter how you hide it, you still have to shove that private field (opaque or otherwise) into your class. I would LOVE to not be using C++ ..... I essentially stopped using it many years ago. Unfortunately, it looks like I'm going to have to use Qt for a cross-platform project and even though people have done some work to make Qt usable from better languages, C++ seems to be the only safe alternative. A lot of those tricks (sorry, I mean standard repertiore of techniques) wouldn't have been necessary if C++ didn't have to handle both stack and heap based objects. But I'm sure such arguments have been hashed out a gazillion times already. I'm just a bit fed up that what seems like a beautiful cross-platform environment (Qt) has to be married to a language that makes Ada look like BASIC.
operator new() ?
This just doesn't make sense in C++: where do you expect temporary objects will be created?
That wasn't an excuse, that is _the_ reason. And it does not concern only priority_queue, it is more general, it affected most, if not all, sequence containers in STL, e.g. vector, deque, list, and adapters, e.g. stack and queue. 
BTW, move only work as "move", when user-defined type in question supports it, i.e. a move constructor, which is not mandatory. Otherwise it's just "copy". Unless we make move ctor a requirement for use with STL containers, the old reason still stands.
&gt; Am I missing something? Yes. The Command/Query Separation Principle. http://en.wikipedia.org/wiki/Command-query_separation
If they're needed, on the heap! That's where temporary objects get created in other dynamic languages! Works very well. Also, if you try using C++ in a really OO fashion and think about methods and sending messages to objects as opposed to "member functions" that return stuff all the time, you end up not needing lots of temporary objects, nor having to create all sorts of complicated mechanisms to allow temporary objects to be "combined" properly with other objects. I believe strongly that C++ has become incredibly complicated because of the need to support both stack and heap-based objects. I understand the historic reasons for it, but these days, I think C++ as it stands has become too complicated. As I've said on numerous occasions, I've never encounted a project where I've thought "I really wish I could use C++ for this" and I don't really see anything going on that just couldn't be done much more simply in languages like Delphi (object pascal), Ruby, C#, perhaps even Haskell, with far less complexity. Those boost libraries are totally out of control, and they're not providing anything that you can't do in these other environments with much less effort and more readability. Having said all that, and now needing to use C++ again (after giving it up sometime around 1996 or so), I just thought it was worth pointing out that for many applications (essentially anything that you could do easily in those other languages, including systems programming, device drivers, embedded stuff where people have often claimed C++ is more efficient), restricting C++ (well, essentially adding a feature) to force objects to be always created on the heap) would end up simplfying things enormously with no loss of power. It's an outside the box view but sometimes when people are too close to something, it's worth trying to shake things up to cause a little "rethink". In other words, instead of responding with all the reasons "why it's bad", it would be nice if people would pause for a moment and think a little about why it could be "good". These other languages are being involved to simplify the programming experience while leveraging new technologies. Yet C++ continues to get more and more complex --- it just doesn't make any sense. Instead, migrate it to begin to leverage what we have learned in more modern languages and move C++ in that direction. It certainly could be done without losing backward compatibility. 
The problem isn't just the work involved, it is the problem that you can't have clean exception safety because the copy can throw. AFAIK the move is also allowed to throw (if it exists, if not you get a copy). So, the old reason is still there.
The problem here isn't C++, it's you. Creating temporary objects on the heap would require an entire garbage collection back-end to be written _manditorily_ into a stack-and-heap based language. Perhaps you should endeavor to understand the benefits of also having stack-allocated entities instead of deciding that one methodology is the only way to do something. P.S. All of your favourite languages are written in C, which is _also_ a stack-based language. Find out why. P.S.S. C and C++ are committee-driven specifications. Asking Stroustrup individually do to anything is ignorant.
You _completely_ misunderstand the point of encapsulation. It's a compile-time protection against the impact of change. It has _nothing_ do to with you being able to look in the header file and see what member a class has or whether the compiler knows what the size of the object is.
I'm doing some open source games programming and generally playing around now and then and I use Boost extensively. Without it, I just couldn't bear C++.
There are good reasons to disobey the command-query separation principle, such as when designing multithreaded data structures. If we're designing a message queue, then it's dangerous to check `empty()` and then get the top message, there's a race condition lurking there. The better thing to do is to implement a `check_empty_or_pop()` method which will return a `std::auto_ptr` with 0 if the queue is empty or the top. This latter can be implemented with a mutex lock entirely inside the method, while the former pairs of methods can only be implemented safely by having a mutex outside the pair of methods, an approach I feel violates encapsulation.
Yup, and since we don't have a mutex inside the class it makes sense to follow CSP and let a thread-aware wrapper class do the violation.
And here is the biggest problem with C++ right here. it takes a demi-god to keep track of everything that can possibly go on in even the simplest of code.
Writing a generic library is always tricky (actually, more accurately it is a skill... learning how not to make assumptions mostly), regardless of language (well, Ada's generics are somewhat easy to work with, but that is because they are so limited). *Using* a generic library is actually pretty easy in C++. In general, writing truly reusable code is just hard.
Thank you --- I was confused about that. I have now banged my head against the wall three times and I'm feeling much better! ------------------ The problem here isn't C++, it's you. --- Yes, but my point was to have a mechanism to ELIMINATE stack-based objects completely. It is the need to support both stack and heap based objects that has made C++ become so complex with no particular gain over other modern languages. ------------ Creating temporary objects on the heap would require an entire garbage collection back-end to be written manditorily into a stack-and-heap based language. --- I do understand the benefits --- but for most purposes, I believe that those benefits do not outweigh the complexity of the solution. Modern languages do just fine with "just" dynamic objects for (probably) 99% of applications. Having been deeply involved in the development of large apps in C++ years ago (large meaning &gt; 200,000 lines, for example), since switching to other languages to do similar things, I have yet to encounter a problem where I've thought "I really wish I had C++ to do this" ------------- Perhaps you should endeavor to understand the benefits of also having stack-allocated entities instead of deciding that one methodology is the only way to do something. -- You have no idea what are my favorite languages. I actually enjoyed using C with Classes when it first came out and used Cfront for many years. But the other day, when I was looking at the source code to the free pascal compiler, a very good compiler for my favorite language, I'm fairly sure that there wasn't any C code there....looked a lot like Pascal to me! (well, object Pascal actually) Damn them anyway, how dare they write a compiler in anything other than C (sigh) ---------------------------------- P.S. All of your favourite languages are written in C, which is also a stack-based language. -- Don't treat me like an idiot, please. -------------- Find out why. -- Using Bjarne's name was just for fun --- the same as writing "Dear Linus" with respect to Linux stuff. More seriously though, being committee-driven is probably a big part of the problem. Pascal, Ruby, Haskell, Smalltalk and many others have done an extremely good job without committees... -------------- P.S.S. C and C++ are committee-driven specifications. Asking Stroustrup individually do to anything is ignorant.
As I said "we're designing a message queue," so it makes sense that your wrapper class should offer a check-and-if-so-command interface rather than separate check and command operations.
Which is why all C++ programmers program in assembly, of course. Oh, wait, they don't, and it's a really dumb argument. The reason we use higher-level languages is precisely because they standardise certain core, expressive constructions in the language. How those constructs are *used* belongs in libraries, though ideally the usage of the two is so close to identical that a programmer does not need to know exactly where the boundary lies. In C++'s case, they consider things like functions and classes important enough to standardise in that way, but not things like higher order functions and type inference. Some of the alternatives recognise that such additional constructs are worth incorporating into the core model of the language. On the other hand, C++'s core model is full of special cases and undefined behaviour, while other languages are much sounder. In languages with more powerful and elegant cores, much of the functionality of Boost is simply irrelevant, because the same functionality is already available (and typically in a much cleaner form without the nasty corner cases). Arguing otherwise is like saying the Gang of Four design patterns are essential to programming, and failing to notice that many of them, too, are unnecessary with a more powerful programming model that inherently handles the cases where those particular patterns were designed to help.
People are free to choose whatever language they like, but that is the C++ philosophy as mentioned by Stroustrup. That is why the STL and Boost exist in the first place. &gt; higher order functions and type inference. Actually they do, C++0x includes both. 
actually, I believe it's for exception safety reasons. if 'pop_with_value()' existed, returning the value that had been removed, and that value's copy/move constructor should throw, then the caller would have no way of recovering that item, it would already be removed. If the function can throw and have modified the container, then you only have the 'weak' exception guarantee. As it stands, 'front()' provides the no-throw guarantee, and 'pop()' provides either the strong guarantee or no-throw guarantee, depending on container, making it strictly more exception safe.
&gt; People are free to choose whatever language they like, but that is the C++ philosophy as mentioned by Stroustrup. Yes, I understand that this was the criteria for deciding what was to be included as a language extension for C++0x. I just happen to disagree with the principle. &gt; Actually they do, C++0x includes both [higher order functions and type inference]. No, it doesn't. It includes a poor approximation of closures, which does not actually close over the context properly. It includes basic type inference in one common situation via `auto`. I rather suspect that the difference between C++ with these tools and a language with real support for such features is what Kranar was alluding to above.
personally i'd go with 'pop_if' :P
boo; all but spam.
book reviews = spam?
It's a blurb more than a review. Has more ad content than worth-reading content. 
I disagree about it being a blurb - it has opinions about the book and not all of them are positive. But I like the book and some reviews are overall positive.
Header files are a useful mechanism for keeping your users from having to recompile. The movement to put more implementation in header files is not a smart one.
I prefer to use Googletest with Googlemock. It has virtually every feature you could wish for in a C++ unit testing framework AND is actively maintained (unlike most others).
Without having read the article, I'd rather use a bag of dead rats for a GUI library than MFC.
The English grammar in that article was just abysmal.
I'd rather invent my own GUI widget library than use MFC.
It came off as more of a shill for that product that any real comparison of the libraries, though I admit I didn't do much more than scan it.
First, Qt is cross-platform, you can't beat that. Second, a little rant about COM: &gt; COM technology is a good solution for many problems No, COM is just awful. &gt; unfortunately the misunderstanding of this technology makes it very complex or maybe COM is just an interface like most programming languages have but it's the usual Microsoft mess, and almost impossible to use seriously.
Absolutely. COM is a nightmare, and it has the same WTF sort of style of most of MS's C/C++ code.
So, which one is the root to it all?
The most useless and wrong article I have ever read. Even if you only want to develop on Windows, MFC is many times harder to use than Qt. The article is completely pointless. -1.
*cries*
the google cache http://74.125.95.132/search?q=cache:_5pjesCbTIoJ:www.informit.com/guides/content.aspx%3Fg%3Dcplusplus%26seqNum%3D441+The+Removal+of+Concepts+From+C%2B%2B0x&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us&amp;client=firefox-a
/cheer
Yikes. So does this mean we're stuck with page-long template compiler diagnostics, or are there other techniques available to improve that situation?
Why is COM a nightmare? It is very easy and fast. Usually people that only have read about it thinks it is difficult. The base technology is just a simple vtable
&gt; the Committee Draft has plenty of features that need to be reconsidered or dropped. Not the new lambdas I hope. &gt; it might easily turn into a bloated tumor that impedes the natural growth and evolution of the language (namespaces anyone?) What's wrong with namespaces?
I don't understand why frameworks [use lower camel case](http://c2.com/cgi/wiki?LowerCamelCase) like QT. it sucks!
http://www.bdsoft.com/tools/stlfilt.html
Does this also help in boost? Because compared to boost errors the stl-error messages start looking short. 
&gt; What's wrong with namespaces? Two guesses: * They're hard to keep contained. If I want to rework the internals of my library to use namespaces, it's difficult for me to *not* require you, the client of my library, to start using namespaces as well. This was particularly evident because the entire C++ standard library was namespaced, though there I suppose they *intended* to break client code. * They add yet another scope to a language that already has [too many of them](http://msdn.microsoft.com/en-us/library/b7kfh662\(VS.80\).aspx). 
&gt; Not the new lambdas I hope. I think that lambdas are safe and secure, because the VC++ Team [already announced](http://blogs.msdn.com/vcblog/archive/2008/10/28/lambdas-auto-and-static-assert-c-0x-features-in-vc10-part-1.aspx) that Lambdas are implemented for VC10, together with auto, static_assert and decltype. Since they are pretty close to the ISO comittee (i.e. Herb Sutter) I guess that these features aren't problematic.
It does not matter whether COM is "awful" or not - there are scenarios where it does not have an alternative: Shell Extensions, for instance.
BOOOOOOOOOOOOOOOOOOOOOOO!!!
I skimmed through the [C++0X page in Wikipedia](http://en.wikipedia.org/wiki/C%2B%2B0x) and must say that there is awfull lots of going in C++. It is safe to say that 0X will not be available before 2010. 
Well I appreciate the answer but, to me, in code of any size or promiscuous use of 3rd party libraries they're a necessity. And scopes, well, almost all of those mentioned are wrapped in { and }, hardly mentally taxing. FWIW both Java, C# (and hey, Python) use, via their modules or whatever, the equivalent of namespaces. 
It won't. The formal removal of concepts will take a year. Still, almost all compilers are already implementing some of the features.
Apparently they didn't get your memo, Your Highness.
You mean they use "thisIsAClass" for their types? That's a shame. I use "ThisIsAClass" for types and "thisIsAnInstance" for instances. Funny how our personal coding styles can sometimes become so important. I've been working mostly on my own on a research type project for a few years and have grown desperately used to my own style. In fact I'm almost powerless when key format options aren't used like the 'm' prefix for class members.
Regarding Python, [The Zen of Python](http://www.python.org/dev/peps/pep-0020/) even says: &gt; Namespaces are one honking great idea -- let's do more of those! But as you say, Python 'namespaces' come built in with the module system, and there's no equivalent to the namespace statement to explicity declare one as in C++. 
Yeah, I wonder if they'll eventually call it 201X.
How you code is extremely important, much more important than the language if the language meets your demands. The language is just a tool. The code is what the programmer produce. lowerCamelCase is always bad. It doesn't make the code more readable. There are plenty of bad code styles in QT that makes it much harder to read the code. MFC is more readable compared to QT but it could be improved too. If you need to do your own stuff in QT you are in big trouble. In MFC that is not that difficult. Of course QT need to have much more functionality because it should compile on more plaftorms but they could have made the code more readable.
Uh, can't you just include the alternate version instead if you really, really don't like namespaces? Anyway, namespaces are a god send. Maybe you haven't worked on projects with a lot of overlapping terms and class names. Consider a game. You might have different libraries for rendering, physics and AI, and each of these might have their own definitions for "Vector3" or "Quaternion". Without namespaces those common types would have to be prefixed with the name of the library to keep them from clashing. That would get old quick.
Huh? I agree namespaces are a good idea. I was just positing reasons why the author might think they're a blight on the language as implemented.
I'm afraid thats just your opinion. Variables starting lower case and claases starting upper case is one was to differentiate. Also it shows that you've been using MS products since thats where a lot of the leading caps stuff started. Every where you work will have a different convention. You have to learn how to deal with it.
-1 not the place for random software releases
I have used a lot of products. MS is stronger when it comes to readable code if you look at code in general and compare it to open source. That may be one reason why it taken some time for open source to compete better with MS. The problem with lowerCamelCase is that you can't explain that type of style with added logic on what you are looking at or there is much better ways to code that add much more logic on what the code does. Of course that is my opinion but it is one opinion that I can explain with other facts than "it looks good". If you look at the QT framwork there is a lot of single character variables and no comments. A good framework shouldn't have that type of code and I don't think they focus that much on how things are named. You need to be good at remember names if you don't want to jump around in the code just to check what the variable was in QT.
&gt; why frameworks use lower camel case like QT. it sucks! That's really a subjective thing. I don't use lower camel case (or upper camel case when I have a choice) but it is just another coding style; the only really important thing about it is that it is consistent.
Oh, gotcha. It seemed like you were actually opposing namespaces rather than just citing reasons people often give for disliking them.
It does for the libraries which use templates the way they were intended to be used.
Which of your needs are not met by boost?
...or.. "How to program the morning after a rather fun weekend." Sometimes, if I'm burnt out for the day, I use this kind of technique to do the coding. . . &gt;ASP.Net Is this a zero based array? Lets iterate through it without -1 and see if it crashes... . . &gt;Java What's my 3 deep indexed stack doing? Let's loop via the console! writeln(a[b[c[d[index]]]]); . . . &gt;C++ Write line of code. Compile Fix errors. . . &gt;BASIC Read code out loud, slowly. 
Using a tool like CppDepend to evaluate the quality of a framework such as Qt is pointless. For me, the comparison is really simple: * I enjoy programming with Qt, it was a pleasure to learn and it is a pleasure to use it. It is probably the best C++ collection of libraries that I have ever used. At first I had doubts about the meta-object compiler and the signal/slot implementation, but as time passed and I used it more and more I have come to appreciate its flexibility and simplicity. * I don't like programming with MFC, I think that it is overly complicated and difficult to use.
http://en.wikipedia.org/wiki/Monte_Carlo_method
Danny Kalev needs to stop pretending he knows anything about C++ and writing these articles. He's been doing it for years, but (as recognisable people who were actually at the meetings have already pointed out in comments on the article) he is basically just a guy who gets a lot of stuff wrong.
&gt; more of a shill Agreed, but it I thought it was nice to see what it can do and wonder how they do it. 
They use QSomeClass, someObj-&gt;someMember(). 
I thought MFC hadn't been updated in years (in favor of ATL); I was surprised to see that it has more classes than Qt. Anyone know, is that because they're folding in controls from all the latest apps? 
MFC isn't an option, its locked into a single platform. I started on qt almost 9 years ago working with intractive te3cnical apps. One of qt's biggest problems is that it isn;t very orthogonal. Theres 3 different ways (I know of) to get events from widgets. Interactive apps have performance issues with too much sig/slot usage and sig/slot is easy to screw up resulting in possible dependence on what order the signals are being handled and other very messy issues. I would have to say that Qt is a better choice for writing general purpose apps, especially now that it's LGPL. Cross platform capable apps give freedom to your users and not enslavement.
if fstream doesn't support 64bit file offsets and more than 1024 file handles it's all trash anyways. I was pretty shocked this was the case for studio 2008 64bit.
c++0F anyone? Base 64 gives you even more leeway.
Generally inexperienced programmers should not have blogs on teaching programming ...
But I *love* my Uint16s! I drop them everywhere I go to indicate (to other programmers reading the code) that the variable is not meant to take negative values. 
This and Bjarne's writeup were the most enlightening of the 'concepts voted out' write-ups to me.
This and Herb Sutter's writeup were the most enlightening of the 'concepts voted out' write-ups to me.
Well, maybe sane error messages are a bigger deal than he thinks. Everyone using something like boost::function stumbles upon some really bad errors. And at least so far I could always think "doesn't matter - in a year or two it will look fine". Now it won't. Not that it's the only problem with those constructs (debugging with the stack they produce is real fun!). I suppose there are enough average c++ users shocked that concepts are removed simply _because_ of the impact this has on error messages. 
They have added code from BCGSoft [http://blogs.msdn.com/vcblog/archive/2007/11/09/quick-tour-of-new-mfc-functionality.aspx](http://blogs.msdn.com/vcblog/archive/2007/11/09/quick-tour-of-new-mfc-functionality.aspx) 
lowerCamelCase is a style that is less informative compared to other styles when you read code. This is very important i languages as C++. Languages like python, java etc. there is less importance because the developer things a bit different compared to C++ (in general).
Perhaps he should learn/read idiomatic C code before writing this idiotic post.
from the article: "Itâ€™s important to remember that, in 1994, C++ was the only major language whose type genericity capabilities were strong enough to create the Standard Template Library (STL). Today, 15 years later, that is still true; you canâ€™t express the STLâ€™s containers-algorithms design separation well, or at all, using generics facilities in Ada, Java, .NET, or any other significant commercial or research language that I know of; as we learned when doing STL.NET, you can do the containers well with other generics, but not the orthogonalization with algorithms that is the heart of STL design style. Concepts or not, that hasnâ€™t changed." That's not quite true...Walter Bright's D language version 2 has IMO greater power to express templates than C++ with or without concepts, all through a context free grammar. Also, the standard library is very interesting, with their ranges being a better generalization of algorithms (possibly..time will tell). 
How is one casing style "less informative" than another? Just a matter of habit.
&gt; [...] other significant commercial or research language that I know of [...] Keyword significant.
&gt;Today, 15 years later, that is still true; you canâ€™t express the STLâ€™s containers-algorithms design separation well, or at all, using generics facilities in Ada, Java, .NET, or any other significant commercial or research language that I know of; I very much disagree with this point. I have used many languages which always make me cringe when I have to write STL afterwards. 
Using upper and lowercase letters you are able to inform more about the code. Samples: int iBlaBlaBla; //&lt; prefix says it is an int enum enumType { eTypeBlaBlaBla, eTypeBlaBla } //&lt; e informs that is a enum class CApplication { ... }; CApplication applicationBlaBla; //&lt; application specific object class value { ... }; value valueBlaBla; //&lt; general value object used by a lot of projects e.t.c Using different type of code styles you can help other to read and debug code without jumping around in code to check what different variables are etc. lowerCamelCase screws a lot of options you have to make code simpler to debug and learn from.
that comes off as a little trollish -- D may not be Java, but it's certainly significant.
I think 'significant' in this case means 'of significant popularity'. Maybe I've been living under a rock, but I haven't heard that D has suddenly become *significantly* popular in the last two to three years.
I think I've seen enough code over the years to make a valid estimation that the "average" C++ user won't care about or use concepts anyway. These are usually the same people who can't be bothered to wrap a heap allocation in a scoped/shared/unique/auto_ptr or even check the return value of a function call to see if it succeeded. Safety and validity are not at the top of their TODO list. As for me, so far I haven't seen many advantages that the proposed native concepts would offer over using Boost's Concept Check library, except that the syntax would be much easier to use and read.
Nice license :p &gt;DO WHAT THE FUCK YOU WANT TO PUBLIC LICENSE Version 2, December 2004 
Here's what he's written since 1995: http://www.stepanovpapers.com 
I always found surprising that A. Stepanov don't try to create his own language to implement a STL-like library without the limitations coming from the host language ... And I learn in this article that he tries this before creating the STL !!!
I like his honesty: &gt; I thought, however, that template functions should work like Ada generics, that is, that they should be explicitly instantiated. Bjarne did not listen to me, and he designed a template-function mechanism where templates are instantiated implicitly using an overloading mechanism. This particular technique became crucial for my work [...] . I view this particular design by Bjarne as a marvelous piece of work, and I'm very happy that he didn't follow my advice. 
People should just give up on the compiler/os/hardware specific hacks. Biggest bang for threading comes at the engineering level, not at the bits and bytes level.
Add "const" to hide and conquer. In addition to hiding functions, also see how well "constness" might propagate through the code. Another addition to brute force programming is to throw in a plethora of "asserts" into code paths to make sure they're getting hit. I do this early on during debug, just to make sure the code I'm working on is the code that's getting compiled and run. Nothing more frustrating than working on the wrong source file/wrong working directory.
So let me get this straight... Unsigned ints are harmful because this programmer doesn't know how to properly program? Writing a for loop that crashes or stuffing signed int values into unsigned unsigned int variables is just bad programming. The problem is not the data type, it's his inability to program. 
The optimization has nothing to do with C++ and everything to do with using a library.
I agree with you : it's a bad article which try to be sensationalist. &gt;&gt; "A Mutex type shall be DefaultConstructible and Destructible. [â€¦] A Mutex type shall not be copyable nor movable." &gt; These two sentences alone reference four different concepts! And the CD contains 1,340 pages of text, charts and code. He doesn't even know the same sort of concept exists in the STL and are in the current specification ...
[http://www.agner.org/optimize/#manuals](http://www.agner.org/optimize/#manuals)
Did you see this one of Ulrich's on memory, cache-size etc? http://lwn.net/Articles/250967/ (first of several parts) But it looks like you might have memory covered. I'd say, try to use a compiler that has the new C++ [rvalue references](http://www.reddit.com/r/cpp/search?q=rvalue) aka perfect forwarding + move semantics, or even, I believe Boost::move() might fake it if your compiler doesn't, yet. [MIT lectures](http://www.reddit.com/tb/8u91v) [Intel's Threading Building Blocks](http://threadingbuildingblocks.org) is a very efficient task decomposition and scheduling library (has a free version). Good bunch of links you have there. If you're into lock-free algorithms, 'The Art of Multiprocessor Programming' has some. Also, spend time on comp.programming.threads, you'll get all kinds of leads there. 
Seconded. I came here to post just that link. 
A tip for useful tools is using the valgrind tools callgrind and cachegrind (very easy to use, good high level profiling overview) and oprofile for low level inner loop analysis and figuring out exactly what the processor is spending precious nanoseconds on. That is, assuming your platform is linux. If it's not, Intel's vtune or parallel studio is mostly equivalent in functionality, but I found the interface to be absolutely horrendous. 
&gt; comp.programming.threads I had completely forgotten about newsgroups, thanks!
I had never heard of these manuals before. Great tip!
I think about 27.3%, 28.9% if you study the appendix too.
I disagree. It is clearly 25.45%, reaching 26.1% with references. Did you maybe count overloading twice?
That's almost 30%!
Stackoverflow.com is made for programmer questions. Try there. 
Intel releases books (or downloadable pdfs) on this subject: http://www.intel.com/products/processor/manuals/ EDIT: scroll down to download the pdfs for free
"Accelerated C++" teaches you enough to be a danger to yourself and others. Much of the code in the book is neither thread safe nor exception safe. Please also read "Exceptional C++", and its sequels, and "Effective C++" and its sequels (including Effective STL). Then you'll be ready to read "Modern C++ Design". I don't think any of the above really cover writing facets of locales, though.
&gt; "Accelerated C++" teaches you enough to be a danger to yourself and others. Much of the code in the book is neither thread safe nor exception safe. What the hell are you talking about? Maybe the book isn't good (I haven't read it) but it's not like an introduction to C++ should have code samples that are *all* exception or thread safe. The real answer this guy needs to hear is this: Find a book that will work as an easy to read introduction. You can check on that using Amazon ratings. Don't worry about whether any single book contains everything there is to know about C++ -- no single book does. Like resotrembla said, you'll need to look at various aspects of the language and software design that are too specific to be all together in one giant book. Effective C++, More Effective C++ and eventually their STL counterpars are the "second step" from the introduction. From there you'll need to learn about design patterns, again as suggested. For now, focus on learning the basics and gaining experience. Once you've got a little time under your belt the rest of it will be more clear.
If you've never programmed before, this is a good introduction to programming. It focuses on C++ and the STL, not C with classes, etc. For comprehensive coverage, assuming you already know how to program, you should probably go w/ one of Stroustrup's books.
So your project has already been going for a while and you've found out that performance isn't acceptable? It's nice to keep performance in mind while coding but getting something working that's correct should be first priority. Choosing correct algoriths will also trump hardware tricks most every time. What you're asking for here is #3 priority (although I have no nidea what you are doing).
This would be the right approach for something modern. C++ users need to de-emphasize OO in favor of generics. Thats where most of the power in C++ is.
I figure they need to learn C++ first, then they can learn boost.
I hate how none of the examples look like they actual do anything. I think these are going to be very useful, especially used with STL algorithms and some templates, and I would think drawing up some real practical examples wouldn't be that hard. Taking in x, adding it to sum, and then letting sum go out of scope just is as retarded an example as anyone could draw up. This feature, along with the initializers, actually do a lot to improve a complaint I have about C++ where I feel that a lot of code that should be quick and dirty to write ends up requiring the declaration of several small functions. This harms readability because it is no longer able to be read all in one place.
Thread safety is a bit of a niche requirement. I have even worked on massively parallelized applications, but they were all multi-process (since you can't thread across a network anyway.) Writing leak proof code and maintaining some minimal guarantee of consistancy when an exception is thrown should be taught pretty early, though not necessarily in ones very first introduction.
The actual physical books are free as well. I ordered them all when I was taking a compiler class in college.
As someone who has worked on some large projects with Qt and signals/slots let me tell you that you have to be awfully careful not to overuse them as they make it very easy to lose sight of what is executed when and why, especially when you emit signals in slots (i.e. signals cause other signals cause other signals,...). You also need to be careful with threads that the slots are really executed in the thread where you think they are executed.
&gt; I personally think this book is as important to the field of software engineering (and programming in general) as how the Principia Mathematica was to mathematics. Credibility fail, and I'm afraid this overly long review doesn't get any better. By halfway through, all I knew was that the book required some knowledge of C++, had some connection to concepts (which are no longer going to be in C++0x), and was going to be Very Important (though there was no indication of why). In the second half, there are various allusions to basic decomposition and generality principles, which contrary to the reviewer's claims are probably familiar to most well-read and experienced software developers already. If this book really is important, I'm afraid this review doesn't tell us why.
The .org address is better than their .com one: http://www.threadingbuildingblocks.org edit: free one has been available since Aug 12th.
Where do you see the actual books available? I would love a set for my bookcase.
\#1 tip on writing C macros: don't do it
The project hasn't started. Correctness and optimal algorithms are taken as a given of course, but a key driving requirement is actually extreme performance on affordable COTS hardware. 
Sorry, macros shouldn't look like the rest of the code because they aren't like the rest of the code. A macro doesn't have a symbol, or a return type, but you can "pass" stuff to it in parenthesis and suddenly it should be dressed up like a function? The concept that macros don't need a semicolon is a useful visual cue (in additioin to the all-caps) the remind the programmer that this doesn't follow the normal rules of syntax and should be treated as such. If you have macros that terminate themselves: if( ... ) MYMACRO(4) else MYOTHERMACRO(0) Will just plain look *wrong*, because, hey, it could be. Meanwhile if you have macros that need termination: if( ... ) MYMACRO(4); else MYOTHERMACRO(0); Looks *misleading*. Maybe those are just all-cap functions. The essay that leads up to the do/while trick could be curtailed with a more common sense approach: Make your macros look like volatile chunks of magic, so that programmers will treat them properly ie. encapsulate them with {} in "single statement" if/else blocks.
Masochism? If you're a masochist, you should avoid Boost.
Thanks. I was asking because I'm getting a bit too used to them.
Yes, of course: my company doesn't allow it for complex licensing and platform reasons.
The [Boost Software License](http://www.boost.org/users/license.html) is not viral. How can it possibly affect your company's license?
why the fuck are you dropping my toolbar dear Jeff Atwood? why the fuck do you blame it on security when you've faced many security issued based purely on incompetence? fuck you.
It doesn't affect my company's license, but getting corporate approval for any open source software requires our legal staff to review it. In addition, we care very strongly about every single line of code that goes into our products. For us to start using Boost, we'd need to: 1. Get legal approval for it. 2. Go carefully through each module we want to use and ensure that it has the performance and memory characteristics we require. 3. Decide which portions are and are not safe for use. 4. Thoroughly train our engineers on which parts are kosher and which aren't, and how to use the parts that are kosher. It could happen, but it doesn't seem very likely. I'm not familiar enough with it to know if it's a good idea or not, but my suspicion is that it wouldn't be a good fit for us: we have a *lot* of C++ code, but many of our engineers aren't C++ gurus, so I'm leery of packages that do lots of metaprogramming, operator overloading, or other template magic. (For the record, *I* like that stuff, but not everyone at work feels the same way.)
Out of professional curiosity, might I ask what industry your company is in, and what sort of software you develop?
Console games.
I figured it would be something 'close to the metal'. :) Your reasoning about Boost is easier to agree with with that key piece of context. 'features' versus performance is a constant debate in C++ apps, because so many are in C++ in the first place because of the need for excellent code performance.
I believe this belongs in /r/batshitcrazy, because you'd have to be to still be writing macros.
Agreed. This is why "Is there a reason to not use Boost?" is such a presumptuous question. If you *are* programming in C++, odds are good you're doing so for the exact reasons that would make it hard to use Boost in the first place.
A lot of it isn't ported to embedded devices, like the threads library. Sometimes it's easier to write wrappers for things like this and use those instead of using boost for them. 
&gt; While Alex makes effective use of stories in his lectures, I was uncomfortable with the somewhat self-indulgent, conversational style in Alexâ€™s written lecture notes. I advocated the impersonal style used in the mathematics and computer science books from my college courses in the 1960s. Alex quickly agreed, and we evolved a style that we both find appropriate. That's too bad. I love the style of Stepanov's lecture notes. It's useful to hear about the mistakes he made in the past, or the ideas of standards bodies he finds shortsighted.
The last time I checked (which was a long time ago; crossing my fingers that this is resolved now) the Graph library does not use the same license as the rest of Boost. This may be a valid reason for avoiding it.
The fact that you have so much C++ code and that your engineers aren't experts is in my opinion an excellent reason to let Boost do the heavy lifting and save yourself a few thousand maintenance nightmares in the long term. Metaprogramming is a very important part of Boost's implementation, but you can use the majority of the libraries without ever having to write a single template yourself. That's kind of the point of installing it.
Compiler errors can be tricky to figure out (hint: often the last line seems to contain the most important info). Depending on what you use debugging can get harder (boost::bind does for example often push a lot of stuff on the stack which can be rather confusing at times). Aside from that - I'm using it for a year now and still learning, but already wouldn't want to miss it anymore. I might even use it a little too much sometimes, but I guess I'll learn where it fits best after a few projects. 
Same question on SO, but with better [answers](http://stackoverflow.com/questions/755439/boost-is-just-great-and-free-is-there-a-catch).
This is bad news for me. I hope it gets fixed.
Alternatively you could use a separate io_service for each thread and handle load distribution at a higher layer. This would probably give better performance in CPU limited applications anyways by reducing cache line contention.
Yes, storm in a teacup. Of course there's just one thread running the epoll, it's a reactor design. The solution (if it's a problem) is as you say. People always have to understand what's happening under the covers. From cmeerw's answer (highest rated): "...there is a big lock around the epoll code in boost/asio/detail/epoll_reactor.hpp which means that only one thread can call into the kernel's epoll syscall at a time." Well, the lock is per epoll-reactor instance, so one call per _thread_ running an instance, but, as many threads as you want, not just one syscall per app, as though it were a global lock. Unfortunately I don't have enough stackoverflow points to comment on his answer, so feel free to take this. I just looked at the code to verify it. 
There's no error, it only makes sense that only one thread can run each epoll. Just do magila's solution and use a couple io_services in separate threads if you determine that's what's really needed. 
Since this is on the cpp reddit how about using a templated inline function instead???
I wasn't aware that it was considered sound practice to share an io_service instance between threads...
**Compile time rate** Couldn't a programmer just turn them off for the edit-compile-test cycle and then turn on all the fancy gadgetry toward the final product? **Purpose** &gt; Representing all these possibilities as concepts is a lot of workâ€”and has in fact helped us discover ill-defined details that would eventually have caused problems for someone. Indeed. That's the whole purpose of: * Strict static typing (take Haskell as an example). * literate programming (in an informal way) * test-driven development (more formal than literate programming) What do, say, Haskellers have to say about concepts? Are you guys frustrated that not many people have appreciated the formalism you've enjoyed? **Misc** * I thought this was pretty cool: *BS: Again, I object to the "Joe Coder" moniker. At best, it is patronizing. Realistically we are all "Joe Coder" outside our little comfort zones. Modern software is far too complex for a single person to be more than a novice in most aspects. I'm "Joe Coder" most of the time, and so are you. Since we are all "Joe Coder" most of the time, let's retire that way of talking and start attacking the issue of complexity in all its varieties the best we can. "Divide and conquer" is the basic weapon; abstraction and layering are popular and effective variants.* * You can defitely tell that BS is getting tired of inane questions: *BS: Sigh! The exercise is not to minimize the number of keywords.* * I think the "equivalence operator" is missing in the MultiPass example.
I think it's allowed, I just doubt it's useful, which you seem to be saying. But I'm not sure! I'm still trying to understand ASIO, I understand it enough to know that each io_service is a reactor (select loop) implemented one way or another (epoll, select, /dev/whatever, kqueue), or possibly a proactor. Hmm, mebbe I still don't understand it. My little bit above though was against cmeerw(sp?)'s comment on stackoverflow, that makes it sound like ASIO is the bottleneck, that only one epoll can be run at a time through ASIO. Which is not true. What the right move is for the OP to fix it though, I don't know. To be clear, what I was envisioning (not that it's necessarily the right solution) was, multiple threads each running their own io_service (io_service is an object, not a fn). Not sharing one. 
BS: ".. one of C++'s greatest advantages compared to proprietary languages is stability. " Could Bjarne have been thinking of C# and Java? Aren't both of those backward compatible? 
Yeah, and who is Danny Kalev? He injects himself too much into the interview, says it's no secret that he's never been fond of concepts. Well who is he that anyone should care what he thinks? I've never heard of him. I guess he's an amateur, at least at interviewing. edit: ah, it says at the end. He was on the committee in previous times. 
...but they also change a lot.
Just rifling through some boost stuff again after several years. Complaints It suffers from over featurization/over engineering in some cases. The format library suffers from this (could simplify this greatly by allowing single format calls only (local format), and used another class to deal with argument ordering (local grammars). Also problems with massive include chain. Rifling through something like dynamic_bitset, this includes that which includes....a very deep cycle which ends up pulling in a bunch of boost.
Wow. That's just... wow.
Pretty awesome. 
I hope they get font rendering right for release because as it is, it's deal breaker for me.
Intellisense... the thing that no one uses since Visual Assist was created
I hate visual assist.
I haven't used Visual Assist since VS 2008 came out. Does it doing anything 2008 doesn't do?
I don't know honestly, but I mainly code in unmanaged C++ and intellisense never seemed to work properly or fast enough in the past. Visual Assist is just a blast to work with...I haven't bothered coding without it since we always get the latest version of VA. Maybe VA is pointless in .NET I don't know...
transactional programming is a very interesting area of computer science. we in the database world have had transactions for decades and are constantly wondering how programmers get along without them.
Good point. I rarely do C++ these days, it's mostly C#.
I dont get it. Someone explain?
They made Intellisense type-aware, meaning it can follow code paths more accurately, providing you better help.
vim? Please vim have a plugin!
Intellisense has always been type-aware, but because c++ is hell to parse correctly, Intellisense often fails to know what type something really is--especially when someone is getting fancy with templates.
yeah, font rendering, priority #1 in an IDE!
I sort of agree. I think some sort of concurrent queue (that should generally be lock-free where possible) should be in the C++ standard, so we don't have to worry about specific hacks. That said, it should be much easier to implement this sort of queue in C++0x without all of the hacks, so the point may be moot.
I found this book to be good info on the subject: http://www.amazon.com/Write-Portable-Code-Introduction-Developing/dp/1593270569 It got a good portion about data portability too, how to detect endian-ness, etc. One of the few programming books I've read cover-to-cover, although that might be because it's also a relatively small book. This, however, doesn't teach you anything about serialization specifically: it merely teaches you how to treat data in a portable way.
If it is limited to just strings and ints why not come up with some ad hoc ASCII based format. For example use one entry per line separated by '\n' and an initial code, say "s:" and "i:" to indicate if the line should be interpreted as a string or an int? If you data are simple and small, keeping the file format ASCII removes the need to worry about endianness. For full blown arbitrary C++ object persistence that is optimized for space and speed you might look at root.cern.ch's I/O subsytem.
Just use an off the shelf binary serializer. There are so many to choose from already: Protocol Buffers, ASN.1, Thrift, XDR, Boost Serialization, MFC Serialization, etc. If you've never done it before and don't know the problem domain, you'll undoubtedly screw it up, and there are so many fully baked solutions out there.
Given how tightly coupled most of the ROOT code is, I'd hesitate to use it if all I needed was serialization.
Start here: http://en.wikipedia.org/wiki/Abstract_Syntax_Notation_One
ASN.1 seems like a great idea, but the language and encodings are complex, and the free tools that support it are buggy, incomplete, or otherwise poor quality. It doesn't see much use (and therefore much community support) outside of one or two areas where it's seen commercial standardization (telcos, SSL, ...). (I spent 6 months a few years ago developing an ASN.1 protocol and C based implementation) Any of the open source systems like Thrift, protocol buffers, or Ice make excellent choices. Protocol Buffers in particular is so simple to understand that you can read the resulting files with a hex editor, and the C++ libs come from a very mature implementation. I think Boost.Serialization ties you to C++?
Very cool stuff. The DDJ article's link for more details requires Google Groups group membership, though. Are there more openly available details somewhere?
Yes, you have a good point. OpenScientist has a stand-alone libRio (or maybe it's libRIO, if forget who had which capatalization) that just does just ROOT I/O and is (vehemently) independent from ROOT.
Actually, at least in 1.39.0, the lock is released before entering the epoll syscall. The lock is then reaquired afterward. It looks to me the lock is used because a large portion of the epoll_reactor class is not thread safe.
You're exactly right, although I agree with you for different reasons. If we were to abandon the half-open interval design of iterators, how would we efficiently create a range for a singly-linked list? Right now the iterator range is [first_node, nullptr). If we used his range design, you would have to keep a pointer to the end item, or calculate the end of the range each time.
I've always been frustrated that this is not possible. This makes me happy.
This makes me very happy. I've always been frustrated by this.
Hey wait a second. But you.. but he...
Shouldn't you use a lot of stuff like boost::mpl then to do more calculations at compile time instead of runtime?
Like what calculations?
Calculate lookup tables where speed matters, generate several specialized but similar classes from one template that cut out runtime decisions without having hundreds of virtually identical copies of code in your source. That kind of thing.
That is one scary picture
c++0A is next. c++0F for hex. They could even use base64 if they wanted.
 auto_ptr is sharp but dangerous and I can't believe they included auto_ptr without a shared_ptr and weak_ptr in the last round of standards. C++0x corrects this.. and so does boost. edit: hmm.. formatting ate my underscores so i pre'd the whole damn thing
Considering autoptr has been deprecated in C++0x, this article is pretty poorly timed. You're better off switching to the uniqueptr if it's available in your includes. And no, after 2+ (counting the year I didn't have an account) years on reddit I still have no idea how to escape an underscore.
You escape it with a backslash, eg `\_` will appear as \_ I made a [post](http://www.reddit.com/r/ideasfortheadmins/comments/9agdm/disabling_underscores_in_markdown/) to /r/ideasfortheadmins a couple of days ago to stop \_ being treated specially in markdown, so if you think it is a good idea you might want to vote it up :)
I wouldn't mind either way, but it doesn't appear in the formatting help below the comment's edit box, and the asterisk italicizes anyway. They both do the exact same thing, unless there's some special nuance I'm missing: *With asterisk* _With underscore_ Edit: You've summed up most of my beef with it. Upvoted in ideasfortheadmins.
So what can we use for "source and sink" in C++0x?
Wow... talk about an old article. We've kind of moved past this. For collections of pointers, it is much better to use [Boost's Pointer Container Library](http://www.boost.org/doc/libs/1_39_0/libs/ptr_container/doc/ptr_container.html).
Sweet fanfic!
&gt;Guru of the Week is a regular series of C++ programming problems created and written by Herb Sutter http://gotw.ca/gotw/index.htm
Did you take a look at the implementation for scoped\_ptrs (not shared)?
Yes, but it doesn't answer the question of how to properly handle the object-embedded refcount variable used by the intrusive_ptr system.
You can make a unit converter! 
Great write up. Got a question though - is there any reason to make the class a singelton? How is that for convenience if he added something totally unrelevant to the subject for unknown reasons.
No. There is no reason to make the class a singleton. OpenGL on iPhone renders into an offscreen buffer, and the window manager composites that buffer onto the screen, so that OpenGL drawing can interoperate with Quartz drawing, Core Animation, etc. So, it is quite reasonable to have multiple instances of a class controlling a drawing surface. (for example, you might be implementing the rear-view mirror of a car by means of a second surface with a different viewing transform, textured onto the mirror of the car in your main model, main view.)
so where is the link?
www.touchideas.com
Wt, anyone?
MySite from touchideas.com is a MVC framework with an ORM. It has all the features of other big products (check the site for a feature comparison). Like: MVC, Web services (JSON, XML), ORM, database access / connection pooling, caching (memory, disk, distributed), session data with automatic serialization, internationalization / localization, view template engine, custom memory allocator (no delete needed), and many others.
I guess I didn't look hard enough :) 1 upvote for you sir. This sounds much more complete than Wt.
He was suggesting creating one io_service per thread I think....
But it seems to lack the incredible support to create interactive online applications that Wt has. More specifically instead of thinking about the webapplication as a real application, the programmer needs to break it down in different views which is very similar of the old thinking about a website : as a collection of interlinked pages (or views). For example I would be curious to see how [the treeview Wt example](http://www.webtoolkit.eu/wt/examples/treeview-dragdrop/treeview-dragdrop.wt) would turn out in your framework. I agree Wt lacks a lot of functionality wrt the backend like database support and helper libraries to access other web services. Their take on that seems to be that the programmer should use dedicated libraries for those functions instead of providing a single integrated framework. edit : link
Link is down. Besides that, old book that every C++ developer knows is great, so why do we care about some random guys blog postings about it a couple years too late?
Link is up, and no, not everyone knows this book and knows how great it is. I'm glad you know it, but think about the beginners.
Not saying it's a great review, lacks any serious content - I did learn however that TR0 and C++0x is now covered in the new edition and my edition must therefore be out of date. 
considering g++ even has a "-Weffc++" option and has had it for many years, I think you missed the boat on that one!
Kind of rambly, but worthwhile to me for having pointed out C++0x's addition of 'attributes' to C++. ([Bjarne's FAQ write-up](http://www.research.att.com/~bs/C++0xFAQ.html#attributes).)
&gt; I think Boost.Serialization ties you to C++? Yep. It also has some limitations in that not all STL/Boost objects are supported for serialization -- an issue that I've recently run into myself.
This is one of my biggest issues with XCode -- Intellisense totally trumps it.
Where is license? and source code please?
Wt+LiteSQL FTW!
Real men use malloc/realloc/free.
INCOMPETENT rant from somebody that does not understand C++ ...
&gt; INCOMPETENT rant from somebody that does not understand C++ ... Agreed. I just recently used operator new to create a base object that can allocate from either the heap or a memory pool and still work with smart pointers w/out having to call any extra special code upon deallocation, nor having to use a static memory pool via STL allocator (no locking/unlocking necessary for multiple threads if they aren't sharing objects between themselves). That was fun, and I only broke one little tiny C++ rule to do it.
They do... until they suddenly have to implement a non-trivial data structure where objects have uncertain lifetimes and multiple ownerships by various parent objects. This was what actually got me to switch to C++ from C, even though I find C++ to be horribly ugly.
My comment was a joke and I agree with you, I use a frankensteinish C/C++ way of coding because pure C++ can be ugly and overkill for some things, and C a bit a too low-level for other things. The resulting soup is only for my personal projects, I don't think I would do it like this for enterprise work (never had to, yet).
:) I once had a job working on a large-scale C++ project. That experience was so horrible I didn't touch C++ for 8 years. It has also made me *extremely* cautious in the implementation of my current project. My progress could be described as "frozen sluggishness", but if I'm careful, this thing might actually wind up being maintainable.
&gt; I only broke one little tiny C++ rule to do it. which was?
If he's not changing how the smart pointers are deallocated but still freeing them in an unusual way, I assume the rule he broke is ignoring the custom deleter functionality in shared\_ptr and rolling his own workaround.
I'd love to see how you did this. It's working out which heap / pool to deallocate from which led me to finding this article. 
Some justification for your claim would be welcome...
&gt; C a bit a too low-level for other things. What you call low-level in C is actually just a worthless type system.
I'm accessing a member variable after the object's deconstruction. This appears to work for PODs, at least under gcc.
When a shared\_ptr's object refcount hits 0, it has to delete the object it points to, but if the object can be either from the heap or a memory pool then the only way to make sure that the shared_ptr deletes it correctly is to overload delete and have the object carry around a pointer to its memory pool (NULL, if heap-allocated). Well, not the *only* way, but the other option is to pass an STL allocator to the shared_ptr template, and STL allocators can't have local state -- my little experiment needs local memory pools for performance reasons so this approach wasn't an option.
I'll post my code when I get home. (I'll have to clean out all the printf() breadcrumbs I've been using to make sure that derived objects, and derived-derived-objects still worked under this design. They do. Made me happy.)
Update: It looks like serializing intrusive_ptr should be fairly simple, but the fact that my state includes memory pools is the deal-breaker. Serialization libraries (any of them) are unable to deal with the type of data structure I have. So, back to the drawing board.
The license is in the docs folder in the download. Only the binary is available for now.
**The Code** Here is my header file that defines my base object + a derived test object. /* * BaseObject.h * Tools_Object * */ #ifndef __BASEOBJECT__ #define __BASEOBJECT__ #include &lt;cstdlib&gt; #include &lt;new&gt; #include &lt;boost/pool/pool.hpp&gt; #include &lt;boost/intrusive_ptr.hpp&gt; // ============================================================================ Forward Declarations // Forward Declarations // ---------------------------------------------------------------------------- // Object::BaseObject namespace Object { class BaseObject; } // Declarations for boost::intrusive_ptr support for BaseObject namespace boost { void intrusive_ptr_add_ref(Object::BaseObject * p); void intrusive_ptr_release(Object::BaseObject * p); } namespace Object { // ============================================================================ Base Object // Base Object // ---------------------------------------------------------------------------- class BaseObject { private: // ---------------------------------------------------------------------------- Member Variables // Member Variables boost::pool&lt;&gt;* memory_pool; long references; // ---------------------------------------------------------------------------- Friend Functions and Classes // Friend Functions and Classes friend void ::boost::intrusive_ptr_add_ref(BaseObject * p); friend void ::boost::intrusive_ptr_release(BaseObject * p); public: // ---------------------------------------------------------------------------- Constructor( heap ) BaseObject() : memory_pool(NULL), references(0) {} // ---------------------------------------------------------------------------- Constructor( pool ) BaseObject(boost::pool&lt;&gt;* _memory_pool) : memory_pool(_memory_pool), references(0) {} // ---------------------------------------------------------------------------- Destructor() virtual ~BaseObject() {} // ---------------------------------------------------------------------------- new( heap ) void* operator new(size_t size) { return malloc(size); } // ---------------------------------------------------------------------------- new( pool ) void* operator new(size_t size, boost::pool&lt;&gt;* memory_pool) { return memory_pool-&gt;malloc(); } // ---------------------------------------------------------------------------- delete() void operator delete(void *p) { if(p) // Ignore NULL { // Prepare to access member variable after object deconstruction. // This probably breaks some kind of rule, but it works for non-object // member variables. BaseObject* this_base_object = static_cast&lt;BaseObject*&gt;(p); // Free from either heap or pool, depending on allocation method if(this_base_object-&gt;memory_pool) this_base_object-&gt;memory_pool-&gt;free(this_base_object); else free(p); } } }; // ============================================================================ Test Object // Test Object // ---------------------------------------------------------------------------- class TestObject : public BaseObject { private: int some_data; public: TestObject(int _some_data) : some_data(_some_data) {} TestObject(boost::pool&lt;&gt;* memory_pool, int _some_data) : BaseObject(memory_pool), some_data(_some_data) {} virtual ~TestObject() {} }; } // ============================================================================ BaseObject Reference Counting // BaseObject Reference Counting // ---------------------------------------------------------------------------- namespace boost { // ---------------------------------------------------------------------------- Add Ref inline void intrusive_ptr_add_ref(Object::BaseObject * p) { ++(p-&gt;references); } // ---------------------------------------------------------------------------- Release inline void intrusive_ptr_release(Object::BaseObject * p) { if (--(p-&gt;references) == 0) delete p; } } #endif **How to Use** And here is some code demonstrating its use. The downside is twofold when using the memory pool -- the call to 'new' is a little ugly because you have to pass in the memory pool twice (once to 'new', once to the object's constructor), and the derived objects must have two constructors (one for heap allocation, one for memory pool allocation): #include &lt;boost/intrusive_ptr.hpp&gt; #include "../Tools_Object/BaseObject.h" using namespace Object; int main (int argc, char * const argv[]) { boost::pool&lt;&gt; *memory_pool = new boost::pool&lt;&gt;(sizeof(TestObject)); // Allocate objects from heap and pool boost::intrusive_ptr&lt;TestObject&gt; object_from_heap( new TestObject(10) ); boost::intrusive_ptr&lt;TestObject&gt; object_from_pool( new(memory_pool) TestObject(memory_pool, 10) ); // Get rid of everything! object_from_heap = NULL; object_from_pool = NULL; delete(memory_pool); return 0; } 
&gt; You must have Javascript enabled to view this site. So, is it linked to Javascript? It's just a blog powered by WordPress...
Thanks for posting that :) I was doing a similar approach that involved accessing a variable after the object was destructed. This worked fine on PC (compiled with MSVC) but fell down on the Xbox 360 (also compiled with MSVC - but of course the specialized 360 version). I didn't look too much further into this because the easiest fix at that point was to fudge my allocations to allow me to store the pointer to the heap outside of the object. There's a couple of things that C++ could do to make this a bit nicer though (and was what the author of the original rant was getting at). Firstly, when you use the pool you need to specify the pool twice: boost::intrusive_ptr&lt;TestObject&gt; object_from_pool( new(memory_pool) TestObject(memory_pool, 10) ); Ideally you'd be able to say: boost::intrusive_ptr&lt;TestObject&gt; object_from_pool( new(memory_pool) TestObject(10) ); Secondly, there's a problem when members of the object allocate memory themselves: class AnotherTestObject : public BaseObject { private: ThirdPartyLibrary::ObjectThatAllocates some_object; .... }; I'd like to be able to have it so that any allocations that some_object makes in its constructor will use the same heap that I used to create AnotherTestObject, but without changing ObjectThatAllocates. If we had more control over how operator new worked - for example, say that operator new had to call the constructor itself then we could do something like: template&lt;class T&gt; T* operator new(Heap* heap) { void * mem = heap-&gt;malloc(sizeof(T)); Heap* previousHeap = set_my_global_heap(heap); T* t = new(mem) T(the args somehow); set_my_global_heap(previousHeap); return t; } There's some half-baked hand-waving going on here about how parameters get through. The point is, though, that C++ doesn't provide as much control when changing the allocation / construction process as would be ideal in some situations. TBH in the domain I work in (console games - where we want fine control and debugging for memory management) would benefit much more from improvements in this area than in some of the things being considered for the next C++ standard. 
Being young, I've always heard of C++ as this godly programming language. I've learned it well and it is very useful. C++ was created before I was born, and before C++ was C so I felt like everyone else had a head start. Now with this new C++0x programming language, I can be on par with most other people! It's a strange feeling like telling your kids that when you were young Pluto was a planet, or ThePirateBay.com was taken over. 
That dude has a massive kneck...
Good points. I never really thought about that too much because I'm just used to C++ being a pain. I don't actually expect it to make sense, and then I work with what's left. (I realized last night I can get rid of the dual-constructor model by using the memory pool as the last argument with a default value of NULL. Amazing how often the obvious solution eludes me.)
Shouldn't it be C+=2?
Funny. I don't remember pressing Ctrl-+ Ctrl-+ Ctrl-+. EDIT: Weird. It's only renders huge by default for me in chromium.
I've been a hobbyist programmer since just before high school, many years ago. I've taken CS courses in my EE curriculum, and for everything I've stuck with C or C++. I've made a couple of attempts at getting into Python, but worries about performance and how to integrate it with more efficient C++ code where necessary made me lose interest and I went back to hacking in C++. However, I feel like in the last year, even with all of the new developments and planned addons to C++ (including 0x and all the others), I can't help feeling like C++ has become a dinosaur, and that perhaps my inability to really get my projects off the ground has stemmed from the complexity of C++ code. I'm wondering when C++0x and all the others will be ready for showtime, which for me would be when they are integrated into either GCC or the Microsoft compiler since these are the tools I use, and if the changes will really make C++ easier to deal with. EDIT: Why the downvote?
If you feel this way, then you need to learn pre-0x C++ better. Most people do not use it to it's full potential, most people don't even realize it's full potential, heck it's full potential is still being researched.
Probably because you voiced your opinion about a programming language. CPP subreddit probably wasn't the best place to call C++ a dinosaur. It wasn't me that downvoted you btw. *ducks*
Renders gigantic in Firefox-3.5/Ubuntu Jaunty.
&gt;my inability to really get my projects off the ground has stemmed from the complexity of C++ code The programming language can be an obstacle, but unless you're doing something that's not really fit for C++ (e.g: webdev - yes I know about Wt), it's more likely that it is something else. What parts of C++ did you have trouble with?
Well, I get conflicted between efficient code and code that is easy to maintain and understand. This leads to imlementation and design difficulties when I try to implement a design I read about and find that I get confused about expressing the pattern in language (probably because I "design as I code" a lot, which I know is a bad way to do things). I expend a lot of mental effort on things like "should I pass this by value or by reference" or "if I made this class public, I wouldn't need all those accessor functions and just use the data directly, that's faster". I know a lot of programmers have this irrational fear that C++ code is inefficient, so maybe that's it.
Depends on what you are coding for, but you can probably have both unless you are coding for some performance critical domain. Even then, you might have a few surprises (Pete Isensee has some interesting blog posts about using the STL in games). Re passing by reference/value: most of the times I pass by const ref and ref. I only pass by value when I need to make a copy. Re public/private members: your getters and setters will probably be inlined and even if they aren't it won't matter at all unless they are called very often. I also had this fear that I was writing inefficient code, but my approach in the present is to not pessimize prematurely, let the compiler take care of the rest and optimize if needed. So far, so good. Bottom line is: if your program meets its performance requirements, don't worry about it.
I have been trying to used STL as much as possible. I find that when it works, the resulting code is fairly clean, but if I make a mistake and get compiler errors, it's pages and pages of template-specific error messages which are often hard to decipher. And yes, the application is a game, because I like playing games and I think it is a very challenging piece of software to write.
Try STLFilt, it makes stl error messages more readable. Recent versions of vc++ are pretty good at reporting errors too.
&gt; You don't pay for what you don't use. That's one of the must basic design philosophies underlying C++. Why should my code carry around metadata if I may never need it? That's a bullshit reason. Support for RTTI can be disabled at compile time, why couldn't reflection? He wouldn't be paying any penalty his project isn't specifically configured to support. &gt; For example, your classes aren't required to actually be there. The compiler can optimize them away, inline everything they do, and it frequently does just that, because even simple template code tends to create quite a few template instantiations. One could argue that's a _terrible_ idea. Did you ever try creating something like compile-time plugins in C++, where one library expects derived classes of some base interface to statically register themselves in other translation units? It's a fucking pain in the ass, because the compiler will see your static instance variable, see that nobody outside of that file ever references it, and proceed to strip it out. Sure you can work around it with pragmas and disabling optimizations per-file, but that's really much more work than it ever should have been, and inhibits separating code into smaller, more flexible pieces -- especially when it appears to work with compiler optimizations disabled. &gt; And finally, reflection isn't quite as vital in C++ as it is in C#. The reason is again, template metaprogramming. It can't solve everything, but for many cases where you'd otherwise resort to reflection, it's possible to write a metaprogram which does the same thing at compile-time. Want a good example of why template metaprogramming (at least now) blows for reflection? Compare the serialization (ok, "archiving") support in languages like Objective-C where you can get a class object and call methods on it, or query an instance for its properties, to the suckfest of all the current C++ serializer libraries. Factories in general just become incalculably easier to write (and read, and maintain!) when you don't have to create some huge array of class constructors and pass it down to a serializer or overload a stream operator 400 times.
Actually, I suspect C++ lacks a reflection because it is a vampire.
Sadly, no one seems interested in truly bringing modern Objective C to other platforms... :(
&gt; Support for RTTI can be disabled at compile time, why couldn't reflection? Reflection are RTTI mean the same thing as far as I know. Reflection is being able to get **t**ype **i**nformation at **r**un**t**ime. &gt; One could argue that's a terrible idea. For many use cases, you're right. Agressive compiler optimization and little type information at runtime is a drag. However, for *some* use cases (realtime, embedded, games, or other high-performance software), it's an absolute necessity. C++ was designed to support those use cases. If you don't *need* to use C++, the best solution is to not do so.
I think this list could be better argument for not using c++ rather than an argument for why c++ doesn't have reflection. Does c++ really have more love for the compiler guys than those coding in c++?
C++ is a systems programming language. Objective C is an awful systems programming language. Therefore, Objective C cannot replace C++ in the areas that matter.
Agreed. The "some" cases you listed are the only places where C++ really makes sense. And if you want lots of dynamism and programmer niceties, Python and Ruby destroy ObjC, IMHO. Therefore, ObjC lives in a strange in-between zone that is constantly shrinking. It's much nicer for fast, non-systems level programming than C++ (ie. desktop apps), but it's much worse than Python/Ruby in areas where performance is not critical (everything other than real-time and embedded software, including most desktop apps).
huh? -&gt; http://gnustep.org/
Well, I'll be damned. That also explains why it only makes sense at 2am.
GNUStep isn't "good". Cocotron is a much better attempt. 
Runtime reflection is a layering violation in a way.
&gt; Reflection are RTTI mean the same thing as far as I know. Reflection is being able to get type information at runtime. RTTI in C++ boils down to two things basically: dynamic\_cast and typeid. They come nowhere close to the kind of metainformation you get in other languages at runtime (i.e. there's no concept of class objects, there's no way to query a class for its methods or members at runtime without building your own system for it, etc.). And while dynamic\_cast can be considered a success (I find it and covariant return types to be two of the most necessary features that make C++ actually usable for OOP), I don't know anyone who uses typeid on a regular basis, nor have I seen it used nor used it more than a handful of times. &gt; However, for some use cases (realtime, embedded, games, or other high-performance software), it's an absolute necessity. C++ was designed to support those use cases. Those environments usually have RTTI and exception-handling disabled. I see no reason why a more complicated reflection system would be any different. Don't need it? Then shut it off and work without it. I on the other hand would be glad to turn it on. I would even argue that C++ should have an optional base-class system where, if enabled, all objects derive from a common base. So many void stars could be avoided. &gt; If you don't need to use C++, the best solution is to not do so. I agree. Sadly I have needed to use it for 10+ years. It's better than C, but that's about as far as I can go with my compliments about it.
That's fine: you can always mix C and C++ code in the same files as Objective-C.
&gt; When (**not if**) automatic garbage collection becomes part of C++ Wow, I didn't know that. Thanks. 
Yeah, but read the next quote: &gt;It's easy to win forgiveness for being wrong; being right is what gets you into real trouble. Don't know if you should count on that standard garbage collector..
This is pretty basic stuff that isn't c++ specific. The examples just happen to use libstdc++ from c++0x.
Seems like it was written by a college student who just learned about race conditions in a parallel programming class. Nothing new here.
That's a lot of vitriol for such an ill-conceived article. If you're going to bash C++, talk about template nastiness or something, not an OS-enforced stack size limit that does exactly what (by my account, anyway) it should do.
Much if it requires exceptions (and by extension RTTI), and many of the libraries aren't ported to various platforms (like the Wii, for example). 
Does anyone use ORM? I was required to learn it at my university, but so far everyone I've seen uses UML. EDIT: My bad, I was thinking of something else.
Kinda handy - Dijkstra's algorithm in dense graphs will often fill up a heap with multiple entries per node, potentially slowing things down. Also eliminates the need for a separate type to record "observations" in a shortest paths algorithm. Selecting the code on the website also selects the line numbers for me. I have `cut`, but it's awkward nonetheless. Pastebin copies of the code so you don't have to clean it up yourself: [test.cpp](http://pastebin.com/f3ce9c018), [heapplus.h](http://pastebin.com/f3e75e033).
msdn.microsoft.com is very good
[Qt Reference](http://doc.trolltech.com/latest/)
[C++ Reference](http://www.cplusplus.com/reference/) 
Reddit obviously. I refer to it for all my news.
http://www.cppreference.com/ I like the simple interface. It's not 100% complete, doesn't have a lot of examples, but usually gets me pointed in the right direction.
[Google code search](http://google.com/codesearch) (actually, the internal version).
not really a reference, but I like the [Google C++ Style Guide](http://google-styleguide.googlecode.com/svn/trunk/cppguide.xml) when I clean some code or refactor stuff.
I've been using this site for years now.
nothing, keeping a reference open is weak :P
I aggree, if you are developping for a windows system, msdn is not an option, it's just necessary. The library references and the forum are one of the best resource.
Yep
Well, I was gonna post CPPreference but somebody jumped the gun. So I'll just say what hasn't been said yet: http://www.google.com. A well-targeted search can really help you solve a problem; odds are, somebody has blogged about it. 
I used to find [this page](http://msdn.microsoft.com/en-us/library/aa383686.aspx) in particular quite handy when I did stuff for win32.
[gotapi.com](http://gotapi.com)
You are doing it wrong.
Seems someone got trolled hard by Torvalds. Congrats, Mr. Cook. 
Usually [sgi stl](http://www.sgi.com/tech/stl/)
C++ Standard, on PDF http://home.att.net/~jackklein/c/standards.html
This blog entry reminded me of that famous quote by Douglas MacArthur - "Old Linus Torvalds rants never die. They just fade away." It seems like somebody discovers his tirade against C++ every few months and the C/C++ pissing contests start up all over again. And for what? If you spend any time following Linus' comments on mailing lists you notice he seems to sometimes say things in the most offensive, uninformed way possible just to get a rise out of people. It's better just to ignore them. He's a brilliant guy, but kind of a douche. But then that can be said about most of the people who excel in their field. 
Funny, I just found this site a few days ago.
Many of their recommendations seem so specifically tailored to their environment that they don't make much sense w/o context. I'd be cautious with following that too closely. For example, why not boost::shared_ptr?
C# for the win! :)
Failing to make sweeping generalizations tells me you're not ready for the big leagues.
Don't disagree with Linux Torvalds. Make something better than him.
Sometimes I think life is nothing but a contest to see who can be the biggest douche.
Great site!!
long time c++ programmer here. I feel like Linus is mostly right -- C++ is a mess. One of biggest problems is C compatibility actually. I think the STL (and, templates in general) is awesome but the syntax is too complex and the C++ grammar is absolutely out of control. If C had RAII (templates can be rigged with the preprocessor if you are so inclined) I would hardly miss C++. The best of all worlds though is 'D' IMO.
&gt; For example, why not boost::shared_ptr? shared\_ptr must allocate memory to hold its refcount variable. If you're just throwing items into a container you'll take a performance hit, use more memory, and potentially increase memory fragmentation. A scoped_ptr works much better in this situation since it only takes up the same amount of space as a pointer and doesn't allocate any extra memory. (Personally, I've been playing around with intrusive_ptr since I get to design my entire class structure from the ground-up and can include the refcount variable in my [base class](http://www.reddit.com/r/cpp/comments/9goev/interesting_rant_on_cs_operator_new/c0crbmv).)
This is the first code style guide I've seen that I actually agree with more than 20% of.
So is wearing clothes.
Linus Torvalds' rants? Meh! I carry around my own set of rants, and most smart, thinking programmers do too. When we hear someone else's rant, if we agree or at least don't disagree too strongly, we just keep walking. If we disagree, we might gawk. If we disagree stronging, we might post some flames. Different languages have different strong points. I personally like Forth-like languages for OS work because you can execute arbitrary amounts of code at compile time, making boot times instantaneous, recompile your OS while it is running, among many other nifty OS tricks. Not to mention the total control of optimizations and what executable code gets generated, something Linus doesn't like about C++... (to those that might think Forth an interpreter, I'd point out that is only one option. The variant I used, Fifth, was 32 bits and fully compiled, with tree structured dictionaries and heap memory management.) Of course Forth is pretty much dead, pretty much like the horse being beaten in this thread. Nobody should be surprised when I say I don't use Forth much at all anymore, not for OS work or anything else. I drifted into C++, then into Java. This transition followed my transition from hard core OS level programming (Done in Assembly and Fifth) to embeded systems, to applications, to server side business applications. You get to a point in life where you want to earn a paycheck, so you do what is needed for your job. It is fun to rant about this or that, but in the end you write your code, kill your bugs, and take your paycheck. 
You didn't answer my question. You gave an example of why one might choose not to use it, not a reason why it should be disallowed outright. Also, a scoped pointer is not appropriate in a container that you'll actually use as it's noncopyable.
&gt; You didn't answer my question. You gave an example of why one might choose not to use it, not a reason why it should be disallowed outright. Ah-hah! I have misunderstood the question! I don't actually agree that it should be completely disallowed -- like most code style guides, there is a fair amount I disagree with. &gt; Also, a scoped pointer is not appropriate in a container that you'll actually use as it's noncopyable. I'm still fuzzy on using scoped pointers so I may very well be talking out my ass. If I'm using iterators on a container of scoped pointers, will that work? (All I will ever do is locally access the object pointed to by the scoped_ptr and call some methods, but never actually copy the object and/or retain it elsewhere.)
&gt; If I'm using iterators on a container of scoped pointers, will that work? An iterator is basically a pointer (in many {most?} STL implementations it's implemented as such). The problem with using a noncopyable pointer container in an STL collection is that the insertion needs to be able to copy the value, thus the only way to have a vector of scoped_ptr would be to do something like: std::vector&lt;boost::scoped_ptr&lt;int&gt;*&gt; v; // and this'd just be stupid since you haven't avoided a raw pointer! Here's an example: std::vector&lt;boost::scoped_ptr&lt;int&gt;&gt; v; boost::scoped_ptr&lt;int&gt; sp(new int(5)); v.push_back(sp); You get a compiler error on the last line because it's trying to copy sp, but the copy constructor is private! I can't even put the integer in directly like this: std::vector&lt;boost::scoped_ptr&lt;int&gt;&gt; v; v.push_back(new int(5)); This fails because the constructor for scoped_ptr is declared as explicit. Moreover, it'd still want to make a copy after constructing the temporary. You really cannot have a vector of noncopyable stuff.
*(moved comment to new response from twowheels)*
Oh geeze, it's right there in the Boost documentation: &gt; scoped\_ptr cannot be used in C++ Standard Library containers. Use shared_ptr if you need a smart pointer that can. Figures. I are programmer. I kan reed gud. Your explanation was better, though. :)
&gt; You get to a point in life where you want to earn a paycheck, so you do what is needed for your job You've been crushed by the Man, dude. 
I disagree with both of them! Or maybe I agree with both of them... I think I need a lie down. Linus has a point that compatibility is a major problem with C++. However for work stuff (where I can control all the compatibility variables) object orientation and the STL is worth paying the compatibility price. Yes and the STL sucks - it does not cover anywhere near enough stuff and is very inconsistent in places - why do I need to pass a c-style string to fstream when the STL has the string class? Different tools for different jobs.
Everything is easy, if you know how to do it
Qt, making C++ safe for us dummies. (Yeah, I love Qt).
nice. bookmarked it.
Standard gotta have bookmark.
Indeed. I even did a recursive wget of it on my laptop, for the (rare) times when I have no internet connection.
&gt; why do I need to pass a c-style string to fstream when the STL has the string class? They're fixing that in the upcoming version. 
At least he's not starving on a street corner.
Every time I see devx.com mentioned on Reddit, I wish the title of the submission was "Use common sense and put all the content on one page to reduce boilerplate banner ads in article hierarchies."
allow me to introduce you to my favourite Firefox extension: Autopager. http://www.teesoft.info/content/view/68/1/ Tired of articles spanned over 93 pages of ads? Autopager reformats them into single pages. 
Give me a moment to soak your comment all in. I'm not used to seeing so much useful information presented in one place and not surrounded by advertisements.
I'd just grab any C++ book and skim the index and read the sections that you are fuzzy on.
I recommend the C++ FAQ: http://www.parashift.com/c++-faq-lite/
Step 1: Buy any C++ book. It doesn't matter which one. Step 2: Find a dark, quiet room. Step 3: Hit yourself in the head with the book until you can no longer hear anything other than the throbbing madness within your own skull. Step 4: Pound relentlessly on a keyboard for twenty-nine hours. Step 5: Add the line "Fluent in C++" to your resumÃ¨.
A very good reference. For completeness we should also refer to the [C++ FQA](http://yosefk.com/c++fqa/index.html).
"The C++ Programming Language" by Stroustrup, "Effective C++" by Scott Meyers "More Effective C++" by Scott Meyers. That should be good to get you rolling.
Haha. That is eerie... I dont recall if I had seen his comment first, but I sure hope so :) Otherwise, that'd just be weird.
Accelerated C++ (by Koenig &amp; Moo) is one of my favorite programming books of any kind. It's only 300 pages, but packs in the essential core of the language. It doesnt require a C background at all, but it wont bore C gurus either. I cant speak highly enough of this book, and it has near-perfect reviews on Amazon. 
That's the same site that I posted...
Or just skip right to step 5. That's what most people seem to do, based on the talent (and I use that term loosely) that I've interviewed lately. Don't even get me started on the whole "C/C++" business... as if they're twin brothers who always go together...
[Lippman's C++ Primer](http://www.amazon.com/Primer-4th-Stanley-B-Lippman/dp/0201721481) (4th ed) won't disappoint.
At first glance I thought this article would be a waste of time, but it really is a very efficient (though evil) implementation of delegates that ought to be useful to people aggressively using boost::bind all over the place.
I started using this technique, but then switched over to [The Impossibly Fast C++ Delegates](http://www.codeproject.com/KB/cpp/ImpossiblyFastCppDelegate.aspx). They're far more elegant, a bit faster and actually standards compliant. Unfortunately, in real life, they're not as well supported as the "Fastest possible" despite not venturing into implementation defined behavior. 
One of the benefits of Boost.Bind/Function, however, is that you can partially apply a function call if you have some of the parameter values at one point, and the rest of them at another, later point. I don't see any way (or at least I don't see an example in the article) of how you can do that with these delegates. As a really stupid example: int addTwoNums( int x, int y ) { return x + y; } boost::function&lt;int (int, int)&gt; plus5 = boost::bind( &amp;addTwoNums, _1, 5 ); int shouldBeFifteen = plus5(10);
In what cases have you found it not to be as well supported?
Yeah, it isn't a general purpose Boost.Bind replacement, as it really only gives you delegates.
It works well for all the compilers I target (gcc 4+, MSVC 2005-2010 and Intel ICC), but I have not tried older or more obscure compilers. According to the article, it fails to compile using Borland C++ and has some problems with the preferred syntax not working in MSVC 2003. 
I guess this is a bit pedantic but shouldn't there be a check for `(this != &amp; rhs)` at the start of the move assignment f'n just to make sure we dont fuck up the state of the vectors internal data structures?
I love cpp-next. It's the only site I know of that's writing these kinds of advanced c++ articles. 
I think you're confusing a fork with a development branch.
Intellisense had problems before. I haven't had any major complaints with it in VS 2008 (it solved many previous issues). I've used it in massive and non-standard projects too. For makefile projects though, you might need to set additional include directories in the project's NMake settings (it doesn't do that automatically for you if it's a makefile project).
See my post above - Sounds like you might be able to get it to work if you set it up as a makefile project (or if it already is one, then that would explain your problem) and give it some prodding in the NMake settings. Though if you've got Visual Assist and you're happy with it, then it doesn't matter.
Meh. I don't know who "the Man" is.... Other than an excuse by some as to why they don't do anything.
Uhhh, I know the language, and don't have to refer to a website.
&gt; But weâ€™re still screwing around with â€™70s debuggers and linkers, and itâ€™s stupid. I donâ€™t know why we put up with it. Isn't that really the crux of the problem? People like Java and .NET stuff because of the active evolution of the core tools. EDIT: One could also construe "core tools" as language features.
There are excellent C++ debuggers and linkers. VisualStudio is no '70's debugger. It supported edit &amp; continue debugging of c++ fifteen years ago. Ok I take it back, there is __one__ excellent c++ debugger and linker. NuMega Soft-ICE is no more :(
I'm surprised he left out Linux Torvalds, who seems to hate C++ with a passion. He said C++ is a horrible language. "It's made more horrible by the fact that a lot of substandard programmers use it, to the point where it's much much easier to generate total and utter crap with it. Quite frankly, even if the choice of C were to do nothing but keep the C++ programmers out, that in itself would be a huge reason to use C."
If you don't like C++, don't use it. I don't see why people have to stress out about the things other people choose to do when it doesn't affect them. I promise I won't force you to code in C++.
:'(
Are you kidding? Badly written C++ code is actually quite easy to understand. It's because the bad programmers use a subset of C++ that they are most familiar with, which tends to be getting-the-job-done code with everything in one class or singleton does everything or some such antipattern. 
C++ is a fantastic language. The reason we hear so many vocal complaints is that it's too hard for many people who are used to scripting languages. They probably make projects with a bunch of global functions in Python and sit around and congratulate themselves about it. I'd rather stab myself in the hand with a knife that write a large and complicated project with a language other than C++, C#.
&gt; I promise I won't force you to code in C++. But you do. Any library written in C++ is forcing people to use C++ because C++ has such a shitty and ill-defined FFI.
So you say you either have a lot of holes in your hand or you never did any large or complicated projects? If there is one thing new and experienced C++ programmers can agree on it is that the language is far from perfect, let alone fantastic.
Wow, what a silly and backwards way of looking at things. Don't use the library if you don't like the language it uses. Seriously, nobody owes you a solution to your problem. If you find a library that does what you want and allows you to use your favorite language, great. If not, solve your problem yourself.
The problem mainly occurs with very large libraries, the kind you can't just write yourself in a matter of weeks or months, like cross platform GUI toolkits, 3D engines, XML parser libraries with full standards support,... By writing stuff like that in C++ you basically waste effort on the little C++ walled garden instead of writing the same code in a language that could be used from the majority of languages out there.
Ah, ok. I'm not sure I like the way you said it, but I do see what you're saying. 
I'm not sure what makes you think only Java and .NET stuff have been evolving... Honestly, to a large degree their "core tools" have been evolving merely to catch up to other tools (heck, Eclipse was built by Smalltalk guys trying to get Java programming tools to where Smalltalk was).
So, everyone should stop writing python libraries, java libraries, haskell libraries, etc etc and start writing libraries in C, because C is the only language easily embeddable in other languages ? I'm sorry, segmentation exists, apparently there are lots of good reasons to still write libraries only for the C++ community (possibly the size of this community itself is a reason too), you should learn to deal with it.
The recent Matasano C++ challenge comes to mind... :-)
Some more: * Ex-C++ users that dealt with the language pre-standardization and pre-useful libraries * Programmers that are really stuck with and have only seen bad C++ code bases * Language advocates for X, where X competes with C++ * Old C programmers that never made the transition and don't understand C++
If C++ has a well defined interface to C (like pretty much every other language you mentioned) this wouldn't be so much of an issue but it does not.
&gt; So you say you either have a lot of holes in your hand or you never did any large or complicated projects? Or the obvious alternative, which is that I have been working on large C++ projects for years. &gt; If there is one thing new and experienced C++ programmers can agree on it is that the language is far from perfect, let alone fantastic. Whatever, I'm not some starry eyed newcomer nor some ego-inflated Javascript punk. I'm a professional C++ programmer and have been for many years. And I and the professionals I've worked with all know that C++ is excellent. What's that noise? Oh, I think I hear your mom calling. Maybe if you pay attention you can use C++ like a big boy when you grow up too.
/me runs in /me yells VIM FOR LIFE /me waves vim flag /me runs off /me laughs hysterically 
Sorry, but at this point you're just bonkers. If you have some shiny library in C++, create your own wrapper that only export extern "C" functions. What's so hard about that? Yes, it may take a little time, but do you really expect everything to be handed to you on a silver plate? Do it yourself, share this your work, and make the world a more productive place - the library writers have already done their part.
I agree with you. I've developed from both ends, scripting, VMs and C++ over the years. using perl,python,java and c++ and I don't find anything wrong with c++. Maybe the development tools can be improved with better run-time support. You simply have to be a lot more precise and understand your compiler and target hardware. When I use c++ I feel a lot more control of what I'm doing. Today's libraries like STL, Boost and ACE make it so much easier than before. Maybe it's because I'm a control freak and my perl background that doesn't make my afraid of ugly syntax sugar is what makes me not too hard on C++.
Do you even know c++? C++ is backward compatible to C. 
You can use C from C++, you can't use C++ properly from (or via) C unless special glue code has been written, wrapping everything C++ in C functions compiled with a C++ compiler.
http://code.google.com/p/v8/
This. It really is incredibly easy to work with, not to mention cutting edge.
Flusspferd appears to be an extension on top of the SpiderMonkey engine, to provide an API that makes it easier to embed. For V8 there is a project called [v8-juice](http://code.google.com/p/v8-juice/) (linked from the Flusspferd page), that claims to be similar to Flusspferd but for V8. 
Flusspferd currently uses Spidermonkey. But it is designed to be portable. At the time we started writing Flusspferd v8 was not mature enough. It only worked on x86 (no 64bit support) and had several other issues. That's why we choose Spidermonkey which after all is well tested and very fast. In the future Flusspferd might also support v8 (or other Javascript engines). Flusspferd has the advantage over directly using v8 or Spidermonkey that it provides a much nicer C++ API, has support for Modules and provides a CommonJS standard library. Though Flusspferd is used mostly as a Javascript programming environment outside the Browser. Currently there is a web framework for Javascript ( http://juicejs.org/ ) developed on top of it. But it was actually developed for embedding Javascript in an in-house C++ application.
C++ TMP indeed is obfuscated functional programming. And like Haskell, it is strict (NO side effects) and has lazy evaluation. You can do a lot of things with it, though it is always much more effort than in a language with cleaner syntax.
So 'extern "C"' = glue code. That's fairly easy. No need for wrapping anything though you do need a function that is outside of a class. Frankly, this is very minimal work compared to what you have to do to use other languages from C. 
&gt; You might ask why C++ chose such horrible syntax to do compile-time functional programming. Well, it didnâ€™t. Yes, because it was never really meant to be used that way. And it's "obfuscated functional programming" only if you want it to be - like the preprocessor and a number of stack operation hacks (oh the horrors) long before. Also: Did I miss function templates going extinct? Not that it would make that much of a difference, but at least it might be a little more readable.* *) Actually I'm dog-tired, maybe I really missed something.
&gt; you do need a function that is outside of a class. Yeah, and virtually no C++ is so in all practical situations you do need to wrap all methods in functions, not to mention more complex stuff like templates.
It's not lazy by default, you need to build a framework to support it as does boost::mpl.
Finally! Someone writes up a template metaprogramming article that has more than just the factorial example!
"Modern C++ Design" by Andrei Alexandrescu was first published 8 years ago. And it started with the infamous typelists and recursive templates. Then it went on to blow your mind.
Nothing wrong with using C++ in a simple way. It doesn't necessarily make you a bad programmer to write simple, yet comprehensible C++.
Maybe this is the reason? [Why Not Specialize Function Templates?](http://www.gotw.ca/publications/mill17.htm) Or did I miss something in your comment?
Indeed, you have to work hard in order to be lazy ;)
&gt; But once you are equipped with the C++/Haskell decoder ring, things become a lot clearer. 
He's moved on to D, hasn't he?
That website doesn't give a lot away does it
what do you mean? Did you check http://eces.colorado.edu/~gottschl/tboostSTM/pubs.html 
I hate export as much as anybody but what will i use in its place?
Despite TFA being about C++ users who dislike the language, half of the respondents don't sound like they've actually used C++.
Well the headline's the article isnt it. Herb Sutter, you may be the cat's pyjamas but your blog needs to be not a blurb.
What? Export isn't even supported by most compilers. I only wish I could implement my templates in a separate file.
They should either deprecate it, or compilers should start supporting it. I would love for exports to actually work :(
&gt; [Why Not Specialize Function Templates?](http://www.gotw.ca/publications/mill17.htm) Interesting article. However, I think the author got the reasoning partially wrong. Here's the climax: // Example 3: The Dimov/Abrahams Example // template&lt;class T&gt; // (a) same old base template as before void f( T ); template&lt;&gt; // (c) explicit specialization, this time of (a) void f&lt;&gt;(int*); template&lt;class T&gt; // (b) a second base template, overloads (a) void f( T* ); // ... int *p; f( p ); // calls (b)! overload resolution ignores // specializations and operates on the base // function templates only Now, I'll admit that I was surprised, but I don't think the right reason is completely that "function template specializations don't overload." After all, the first example (which just switches the definition order) *does* (ultimately) work as expected: // Example 2: Explicit specialization // template&lt;class T&gt; // (a) a base template void f( T ); template&lt;class T&gt; // (b) a second base template, overloads (a) void f( T* ); // (function templates can't be partially // specialized; they overload instead) template&lt;&gt; // (c) explicit specialization of (b) void f&lt;&gt;(int*); // ... int *p; f( p ); // calls (c) The reason the order matters is that specialization occurs for the matching base template that is in scope, so switching the order here switches the base template of the specialization. In my opinion, this fact *completes* the reason for the surprising behavior and should be mentioned more explicitly than in the comments of the example code. In any case, the author is completely correct in assessing that the ability to overload functions is the culprit for the confusion; the result is a kind of compile time "global variable" (which template is currently in scope for the specialization?) that can cause the "program" (compilation) to have non-intuitive results.
It's a grand effort but in my opinion, having used it in a multi-threaded Windows environment, there are just too many subtle bugs that using it introduced that I decided using shared_ptr was a better approach. I figure the purpose of a GC is the convenience of not having to deal with explicit memory management so that I can focus on other aspects of my program. But with the Boehm GC, I found I had to be an expert on how it worked if I wanted to stand a chance of using it and identifying strange behaviour I was getting from it. I figured the time needed to be an expert using the GC may as well be spent dealing with memory explicitly. A better approach for my situation was to just go with shared_ptr and know when to use weak_ptr to avoid cycles.
When I control the templates and all the code that uses them, what I do is split the declarations and definitions into separate files (like normal, non-templated code) and then add explicit specializations at the bottom of the files with definitions. Somewhat tedious but not too bad on a small-medium-sized project. (If you forget a specialization, you just get a linker error.)
Hey thats not too bad of an idea. Thanks! I know some people that will #include their cpp file with the implementation at the bottom of their header file, I don't like that at all though.
Thanks for replying. In your case, were you trying to use it for the entirety of memory management or in a contained, specific capacity? In my case I was thinking of only using it for the core data model. Everything else would use explicit memory management. What were some specific problems that you encountered (if you can recall any)?
While I have not used Boehm's GC library, there are certain things I'd like to point out. It's a conservative collector, so it'll play safe on releasing memory. This can lead to situations of where there is dead data that could be free()'d but Boehm's GC doesn't. Secondly pbiggar has made comments on his exprience with Boehm's GC, I suggest trawling thoguh his histroy to find the relevant reddit postings.
Yes, I'm aware it's conservative. For my specific case, small "leaks" are acceptable, and from what I've read, that facet of it should not be a problem. Thanks, I'll check out some of pbiggar's history.
A shame about the unified function syntax not going ahead, it seemed like a reasonably smart idea. Really, anything that makes the language smaller without compromising on speed and functionality is a godsend for C++.
I investigated Boehm GC back in 2000-2001 while working on Mozilla. Mozilla had many malloc/frees on startup, in the 100s of thousands, so we were looking for a way to decrease the time spent in malloc/free (40% of boot time was in those routines). I only tried Boehm on Linux, but at that time it did have a measurable improvement on performance. I did a quick Google, but couldn't find where I had posted the actual speed up percentages - sorry. I had made no changes to the source, I just forced Linux to use Boehm instead of the standard memory manager. We also used it to track down memory leaks. I never tried it as a GC, but it sounds like you weren't looking to use it that way. Summary: on Linux, it was an easy drop in and there was a speedup, back in 2001-ish. I hope this helps.
&gt; When I control the templates and all the code that uses them, what I do is split the declarations and definitions into separate files (like normal, non-templated code) and then add **explicit specializations** at the bottom of the files with definitions. Just to be pedantic, I think you mean **explicit instantiations of generated specializations**. In any case, doing this really would require having *complete* control over how the templates are being used; third-parties wouldn't really be able to use your templates without editing the implementation file to add an explicit instantiation. However, I guess you could make the implementation another "header" file that *must* be included in a *mandatory* translation unit. Then, all third-parties could just maintain these translation units by hand too. Would this improve compile times appreciably, I wonder? Isn't this as close to a working *export* as you can get?
&gt;Just to be pedantic, I think you mean explicit instantiations of generated specializations. Yep. Thanks for noticing something was up. Believe it or not 11 am was early morning for me on a Sunday. &gt;However, I guess you could make the implementation another "header" file that must be included in a mandatory translation unit. Then, all third-parties could just maintain these translation units by hand too. Yep. Another option would be to split into three files, one for template "headers," one for template definitions, and one just for explicit instantiations (where as you suggest your `#include` the definition file. Then clients could also have a file for explicit instantiations.
My use case was being able to share data amongst multiple tasks, and when all tasks completed the shared objects they were using would be freed. The tasks ran as part of a thread pool. I do a lot of financial software so it's heavily event driven. I needed to share objects that would publish market data events and then tasks would get notified about new market data, do their thing and then wait for more data. This was on Windows about a year ago and I was getting weird pop up error messages, I don't remember the exact message though. The problem was when I went to read about what would cause the message, there was no documentation explaining it, I had to grep in the GC source code for the message and all I found was one literal string in a giant switch statement so I knew it was coming from the GC itself. Now that's just my one instance of using it, but suffice it to say it left me with a perhaps unjustified fear that even if I end up fixing this particular bug, if I use the GC and begin relying on this library, who knows what other cryptic error message I may end up with and I don't consider myself smart enough to dig deep into the GC source code which is full of magic and hacks that are way beyond me. I understand why it's like that, it's designed to be cross platform which is no easy task. So I figured I personally was better off to just use an approach I do understand, reference counting. Perhaps C++ will get GC one day part of the language core and when that day comes I will be very happy and I have no doubt Boehm's GC will be a integral part of its development since a lot of research has gone into it.
Faster and buggier.
If it wasn't buggy it wouldn't be beta. Of course it'll be buggy when it ships. What large piece of software doesn't have bugs? That said, I've been using it for C++ development, even without Visual Assist, and it's pretty fucking awesome. 
Buggier than Beta 1 I meant. Things that were working with B1 are not working now. It happens.
I think I can summarize it a lot better than that - it's sort of like the Ten Commandments: don't, don't, don't, don't... don't! Seriously though, operator overloading is a very powerful feature of the language that has select applicability, but is very easy to misuse, and makes it really easy to needlessly obfuscate code. Example: A coworker of mine had overloaded the void* operator on a buffer class we used internally, his argument being is that this way, it's easy to use the object as a pointer seamlessly. However, it also leads to monstrosities like this: memset( &amp;buf_obj, value, size ); Apparently, this had worked just fine on gcc, but for some reason, on MSVC, the operator overload didn't work, and, since buf_obj was created on the stack, it ended up destroying the stack and causing a subtle crash later in the program. The moral of the story is, unless operator overloading really makes SENSE in your case, and isn't just done as a minor convenience, avoid it.
I'm not seeing the win here over using [Boost's Program Options](http://www.boost.org/doc/libs/1_40_0/doc/html/program_options.html "Program Options"). I'll confess to only having skimmed, but this code looked, if anything, clunkier.
Ditto. I'm surprised when I find people who prefer not to use boost yet they haven't bothered to look at the features provided. Some people really get fired up by doing it themselves, even if it's already been done.
Maybe it's just someone's course work, so it's a perfect candidate to be released as OSS
The win over the Boost program options would be that it doesn't come with Boost's dependencies. I worked with the guy who wrote this tool a few years ago. He's pretty damn smart. 
Also, from his blog: http://www.codesynthesis.com/~boris/blog/2009/07/05/cli-cxx-existing-solutions/
Danrik already provided a link to the blog post that answers this question in detail. You may also want to check this one for context: http://www.codesynthesis.com/~boris/blog/2009/06/28/cli-cxx-the-ideal-solution/ For those who want a 30 seconds answer, Boost program_options has the following main drawbacks: - verbosity - the use of strings to identify options (easy to misspell) - the need to specify the option type every time its value is retrieved (lack of type safety) CLI addresses these problems by using a concise, special-purpose language to capture the option specifications and by using functions with static return types to access the option values. 
&gt; * verbosity Okay, I see a win here... if you don't count usage and ignore the fact that yous till need to *access* these options. &gt; * the use of strings to identify options (easy to misspell) The strings might have a mispelled name as compared to the variable name, but that doesn't actually kill your program. So long as you use the same string throughout your program for getting to that option, no biggie. Note that *unlike* the CLI solution, Program Options autogens the usage message, which means at least you don't have a typeoh *there* which causes your option names not to match. * the need to specify the option type every time its value is retrieved (lack of type safety) Okay, that part does seem like a nice win.
&gt; The strings might have a mispelled name as compared to the variable name, but that doesn't actually kill your program. So long as you use the same string throughout your program for getting to that option, no biggie. What I mean is this: po::options_description desc; desc.add_options () ("compression", po::value&lt;unsigned short&gt;()-&gt;default_value (5), "compression level"); po::variables_map vm; po::store (po::parse_command_line (argc, argv, desc), vm); po::notify (vm); compressor c (vm["compresion"].as&lt;unsigned short&gt; ()); Here, you have to use the string in the option specification and when you access its value. If you spell them differently it won't be detected at compile time and can actually "kill your program", at lest in the sense that your users will find it buggy and stop using it ;-). &gt; Note that unlike the CLI solution, Program Options autogens the usage message Of course CLI will support automatic usage generation, probably as soon as the next version. This is such an obviously useful feature. We will go even further and also generate man/html pages automatically. 
&gt; What I mean is this: And what I mean is: const char* COMPRESSION = "compression"; 
Yes, you can do it this way at the cost of additional verbosity. Also, if there are several modules in your program that need access to option values, you will need to place these string variables into a set of header/source files, include the header everywhere, etc. I am not saying it can't be done this way. All I am saying is that there is a more elegant way to do this.
If I'm reading that right, I'm actually not sure how that code ever did what was expected, except perhaps by accident. Taking the reference of an instance of your BufObj class will return a pointer to that instance of type BufObj\*, and then that pointer will be implicitly casted to void*. Taking a reference to the class instance will NOT invoke the (void\*) conversion operator. Also, your coworker sounds a bit dangerous, playing with things he doesn't understand.
The code that accesses this stuff and the code that defines it should be in one place, and generally you use assign anyway so this really isn't much of an issue.
Honestly, I didn't bother to figure it out, I just saw it, shook my head, and rewrote it via std::fill() and begin()/end(). The large majority of my coworker's code is great - I guess it just goes to show we all make blunders sometimes :)
Good discussion and interesting examples from major projects.
Imho, you try to free something and recover with simple extremely well coded applications. Make the app a bit more complex and not as well maintained and I'd go to something like what Git does. Even more complex and in just plain bad shape, go with a simple success or die approach like xalloc. But I would not just rely on it segfaulting. It's C, do you know what's going to happen to that NULL pointer, no you don't! Who knows when and where it will finally segfault, possibly long after it failed to allocate. For libraries, if you are returning that pointer, then leave it to the client app, which may mean it just segfaults. But if you're allocating internally, see above. 
Unfortunately, all the strategies are wrong. The way to deal with allocation failure is to fail the operation, unwind the stack, release anything allocated along the way. This requires patience, attention to detail, and good design (such that aborting an operation from resource exhaustion doesn't require more resources). There's nothing worse than a program randomly aborting. Take a real-world example: you attempt to do a huge filter on a image. It needs gigabytes of memory, and tries to allocate it. Now, either the program aborts because it can't do what you asked, taking the whole app down and losing your work; or it informs you nicely that the machine is low on memory, so you kill a few other apps first (Firefox, OpenOffice, other memory hogs), and get on with it. Memory allocation failure is no different from failing to get a file off disk or any other failure, so it should be handled as gracefully. Stack allocation failure usually can't be handled gracefully, so alloca and such should be avoided. The Linux memory allocator, with its optimistic overcommit, is stupid because it lets your program think it has allocated memory when it hasn't, and prevents your program from any graceful handling of allocation failure; instead, you get a segfault further down the line when you could not have expected it. Or worse, a random unrelated process (even one belonging to someone else) is killed. So if you're on a shared Linux machine, you can be antisocial and kill other people's process just by using lots of memory. Thankfully, you can turn overcommit off. For the tl;dr crowd: Fuck you I'm not simplifying.
Completely ignores OOM killer. Verdict: worthless.
I'm reporting you to the tldr police for abuse of the tldr doctrine as per section 34, subsection V. tl;dr: you abused tl;dr. 
Don't forget Lee... But yeah, STL is a fine piece of work that has saved me days of effort.
It's a good sign that Qt, Boost and STL are more and more used in job descriptions.
Wtf? This video ends mid-sentence without describing what the fences do. Downvoted.
PDF of the talk http://www.nwcpp.org/Downloads/2008/C___Memory_Model.pdf 
RIP MFC
It's sad, MFC is great when programming on windows plateform in c++. I think about the desktop but about mobile phones too. I think the fall of MFC is because it's a non-free feature of visual studio.
MFC is great? I have been working with MFC for at least 15 years (almost since its afx days (2.5/1.52c) and since no sane person wants to touch it) and my conclusion is: it's a festering bag of puss. Half the time spent on working with it is trying to work around it.
You can add C++ webkit and it just starts to poke at the end
I stand solidly between the two of you. MFC is meh. Fact is, though, that Microsoft has let MFC wither on the vine for almost a decade, so the only surprise is that there are as many positions as there are. My biggest complaint about Microsoft platforms is how they build and discard new platforms at a phenomenal rate. How many MS database platforms can you name? here is my best attempt (off the top of my head) * ODBC * JET (which powers access) * DAO (same as jet?) * ISAM * OLEDB * ADO * ADO.Net All this in what, 15 years? Platforms should have a longer shelf life than that.
It's still the second most popular one their. It's more undead, than dead, I'm afraid.
STL is kind of an empty job requirement. "C++ Programmer wanted, should know the C++ standard library" The only excuse for not knowing STL is that you were programming in some platform like MFC that is so integrated with its own data types that it is an inconvenience to mix them.
Distro(s)/release(s) you've used it on? IIRC the only drawback was limited target support. But it has x86_64 and i[3456]86, right? Do any distros contain the binutils release(s) that have `gold` included?
It's too bad it'll never be ported to MinGW. I don't really have any complaints about compiling/linking on Linux, but Windows is hellish. My MinGW build is 4 to 5 times slower than a comparable Linux machine.
I've used it on both 32 bit x86 and x86_64, on arch linux and opensuse. I don't recall for sure, but I think I had to compile it myself on both distros (which didn't turn out to be too hard).
Sadly there are a lot of people who pretend to know C++ well and doesn't know STL at all.
I thought the making-COFF-binaries-on-linux thing was pretty mature now. Have you tried building your Windows targets on linux?
The point is that gold does not support COFF by design.
I'd love to, but it's a big project. It'll take time. For example, there are a bunch of libraries we depend on, so it would be a one-by-one process of porting/testing each one with the cross compiler. On top of that, you lose the ability to do any kind of autoconf tests that involve running a program that you just compiled, unless you can use Wine somehow for that... So yes, in theory, it's possible. But I think it's a distant possibility for me right now.
Y'know what'd be cool? A JSON implementation in boost. When can I have that one? We could call it "boost: ponies edition". Especially if it worked with the `boost::archive` stuff. I think "Sweet Persist" does it already. Too bad it's GPL'd. It'd be sweet (no pun intended) if we had one w/the boost software license.
There has been talk (I think it was a Google Summer of Code project even) of making a YAML backed for boost serialization.
You mean, like the one they are adding in this version? http://kaalus.atspace.com/ptree/doc/index.html#json_parser
Excellent! Ok, now, like I said, we have to call the release that delivers this content "ponies edition." :)
There is a list of JSON C and C++ parsers/generators - some of them seem to be very Boost-friendly: http://2wav.com/node/86 
"Boost-friendly"? Doesn't sound like a pony to me.
MFC is great? Do a project or two (on Windows!) with Qt and be enlightened. MFC is unsaveable, MS is right to abandon it. 
Oh, it's really 1.40.0 beta one - I /thought/ they were moving fast!
I like the new **std::async** function.
So totally true. I'm now in my 2nd job where the STL is either an exotic mystery, or something vaguely disliked, NIH, and too much trouble to learn. So, while I've been here they've had to implement sort and set_difference on their own implementation of a linked list. Life at the bottom of the corporate C++ market I guess. 
"I can do better than that. With a cooler name. I'll call it ____!"
Overcommit and the OOM killer are the strangest additions to a kernel I've seen. It's like a bank, they're allowed to give out more money than they have, but when everyone asks for their money at once, they have to kill a few people to take their assets and honour their promises to their other customers.
JIT! I've been procrastinating about installing 1.40.0 for days!
C++ almost always gets it right. However, the programmer almost always gets it wrong.
Well done, Hartmut!
false
Sure. I'll do it. But not if it's gonna take too long.
Qt, or gtkmm, or Windows.Forms, or ... anything, really. Except maybe AWT.
Wow, I've been looking for something like this (and not needing it enough to write it on my own, naturally) for years! More languages need this capability.
&gt; More languages need this capability. What are you talking about specifically? I don't see anything there that hasn't been possible before. The only difference is how it's achieved in C++(0x) compared to some other language.
Is it okay, that I feel slightly underwhelmed by this, as well as Closure Tools?
These guys are so fast at releasing!
Yeah. Lets throw away the type system!
Yes, its ok. Not everything has to be revolutionary if it comes from Google.
Most things from Google aren't revolutionary. Even Map-Reduce wasn't revolutionary; it's an old idea. Google is the king of taking existing ideas and integrating them.
Templating frameworks such as this are so trivially uninteresting as not to even require standardisation. Substitute the symbols contained within text for the values in a symbol table? They wouldn't put such tat in the standard library, and I don't know how it even justifies itself as a library. It's barely more than a function.
I just mean the ability to easily run a block of code asynchronously (i.e. with nice syntactic sugar like std::async provides). Certainly, other languages *can* do it, but until recently, it seems like this feature hasn't been high on many language wish-lists.
There are more posts of the dev blog. This release includes Qt Creator 1.3, GCC 4.4 and binaries for MSVC 2008.
woo-hoo!!
But are there well designed templating frameworks for C++? I really like the design of stringtemplate from Terence Parr (http://www.stringtemplate.org/). It has java, c# and python implementations.
That's pretty cool. What sort of applications could stuff like this have from a practical standpoint?
Actually, there are 2 important points to observe : - It emulates variadic templates, but stands in a bit different view. We do really have a container whose elements are *types*. That means we can do anything we do on containers in the functional programming world. People having written Haskell probably have noticed the exercises are just about implementing some of the standard List functions. - That's aimed at generic library implementers. Typelists and manipulations on them let us write highly generic code without caring about the actual types on which it'll be used. Such stuffs can be used to write, e.g, ORMs, Maths libraries and maybe even Remote Method Invokation. Anyway, it's a basical tool for much more advanced metaprogramming. See the boost.mpl sequences, boost.fusion and others for similar tools.
[Oh, that way madness lies](http://www.refactory.org/s/template_haskell_with_list_processing_integer_factorization_and_rational_numbers/view/latest "Let me shun that")
Nice indeed. But these are int lists, not type lists. The way it is tackled is a bit different.
Oh, sure. *int*s just seemed easier to fool around with. (Although type lists could probably be a lot more useful.) Can you elaborate on how they are tackled differently? The techniques used to implement the lists themselves look very similar to me.
Indeed, type lists should have much nicer and more useful applications. The implementation, I mean the kernel, will remain the same. But the implementation of the operations will be a bit more complicated. I mean look how short is the code you linked to, and how "long" are the ones I posted in my blogpost. Of course, you have lists, and list implemented the FP way are the same, whatever they contain. But since we're mapping types to types, list of types to list of types, and so on, people have higher chances to get headaches when doing compile-time metaprogramming on types than on constants. We have less language tools to do metaprogramming on types, we have to implement everything ourselves. I'll try to go on deeper that way in my future blog posts if it is of any interest for readers.
&gt; look how short is the code you linked to, and how "long" are the ones I posted I don't know. My *length* should work pretty much the same for your lists, no? template&lt;typename L&gt; struct length { enum { val=length&lt;L::tail&gt;::value+1 }; }; template&lt;&gt; struct length&lt;EmptyList&gt; { enum { val=0 }; }; (Untested) The same applies to *map*. And my *filter* is only shorter if you ignore the *IF* struct, which replaces your *FilterAux*. Still, I am looking forward to any future blog posts expanding on this.
Yeah, for length, what we're operating on doesn't matter that much -- at all, actually. It gets more interesting with the function I left as exercise. With the Int2Type trick, we could even think about writing once such utilities and get them instanciated at compile-time for both types and values. Anyway, I'll try to write further posts about these topics.
http://www.boost.org/doc/libs/1_41_0/libs/mpl/doc/refmanual/list.html
Who cares, I like it and that's all that matters to me
Because if you are absolutely positively bored, you start creating yet another programming language.
"There are languages that nobody uses and languages that people always bitch about", this can't be more true, especially when about C++. And the most important part - if you do not like C++, go code in something else and prove that that is better by coming up with greater products, but please stop wasting our time trying to convince that the tool we use with joy is not superior [iPhone vs Android w/ respect to games, anyone?] ;)
the code samples don't autowrap and there's no hscroll so chunks are not visible on my netbook
Wow, a distributed team, and none in Bangalore! Is that possible? 
Not only legit, but sometimes even necessary. Don't forget that operators in C++ are just special functions/methods.
reddit != StackOverflow
The more C++ I know, the less I like it, and this is a perfect example of why.
Cool, taking a look on your recommendation. ANTLR is good stuff and maybe there's something here worth looking at.
I saw the 1.0 release posting a few weeks back, and I couldn't help wondering, why would I use this over something like [TCLAP](http://tclap.sourceforge.net/), which is a header-only library, generates the help text automatically, as well as documentation like DocBook. It seems like CLI adds an extra step in the build process while TCLAP does not.
This "company" seems weird in general. Check out their other product, CodeSynthesis XSD. They support [dual-licensing](http://www.codesynthesis.com/products/xsd/license.xhtml), but with the explanation: &gt; By linking with the XSD runtime library and/or the generated code &gt; (directly or indirectly, statically or dynamically, at compile &gt; time or runtime), your application is subject to the terms of the &gt; GPL or the FLOSS Exception, which both require that you release &gt; the source code of your application if and when you distribute it. But to say that you have to pay them a license fee just because their program generated code from your input and it's otherwise automatically under the GPL is total bullshit [according to GNU itself.](http://www.gnu.org/licenses/gpl-faq.html#GPLOutput)
You are bullshit. The GPL license itself has nothing to do with this. They are the authors and they can request whatever they want (including that you poke on eye out if you want to use their software).
TCLAP is a fine library. The difference between CLI and libraries that try to capture the command line interface in C++ (TCLAP, Boost program_options, etc.) is that in the latter case the result is either quite verbose, lacks type-safety, or inconvenient to use. In case of CLI, there is a special language for specifying the command line interface (so the specification is concise), which is then translated to C++ classes which are both type-safe and convenient to use. In case of a simple program with a handful of options learning CLI if you already know, say, TCLAP may not be worth it. But if you have to handle a large number of options (for example, I work on a compiler with over 100 options), then it makes a huge difference. If you would like more information on various trade-offs between the "library" and "compiler" approaches, I wrote a blog post covering this: http://codesynthesis.com/~boris/blog/2009/07/05/cli-cxx-existing-solutions/
Well, it is not that clear cut. Quoting the link to the GPL FAQ from your post: *So the only way you have a say in the use of the output is if substantial parts of the output are copied (more or less) from text in your program.* In case of CodeSynthesis XSD, the input is XML Schema (XML vocabulary specification). The output is C++ classes that can be loaded/saved from/to this vocabulary. In this case *all* of the output is copied from the text of the program and none from the input (well, except maybe XML Schema documentation is copied to Doxygen comments). A different example would be a program that indents your source code. In this case saying that the output is covered by the GPL would be absurd. Hope this clears things a bit.
Its not even this case. They are using a GPL license with additional requirements and exceptions.
I do find it funny how the comments attack it. I think there are many reasons to want to use Java over C++, but this sort of application is certainly not one of them, unless you want to lag behind others in performance.
* For selected algorithms.
You can compile almost any C code with a C++ compiler with minor modifications. And a good C++ compiler is no worse than a good C compiler at optimizing. So almost never you have a C code with a slower C++ counterpart. On the other hand you have more constructs in C++ (templates, etc.), so in some cases you tell the compiler more about your code so that it can optimize it better. So usually there are cases that can be better optimized using C++-specific features. Result: C++ &gt;= C
That's a lot of raw data. Seems to me it could benefit *a lot* from better visualizations. Tabular formatting is a terrible way to confer information to a human being. Having said that, I'm going to see if I can come up with anything better. If I can, I'll report back.
But it _has_ a nice graph!
It has *one* graph, and it's not particularly well-explained. I'm still unclear on exactly what it was trying to illustrate. [This](http://corte.si/posts/code/devsurvey/index.html) has some nice (and well-explained) graphs.
Selected, commonly used, algorithms. 
I suspect that for just about every C++ program, a C program *could* be written that was just as fast. I believe that's what cfront did, decades ago, and what Comeau does today. The problem is that that C program would be more of a PITA to write than the C++ program, due to C's lack of compile time abstraction. So for programs that *actually* get written, C++ gets a speed edge. 
Intel created a C++ ABI for IA-64, which was then extended for most other processors. GCC, Intel C++, and several others have used that ABI by default for a number of years.
How is it a perfect example? rvalue references *simplify* existing methods of doing things. move constructors (powered by rvalue references) make stl containers of user defined types more efficient, etc ... 
Easy one: Write a struct "Tests" that contains a vector of function pointers (paired with a function name if you like). Push functions to be run onto this vector. Test drivers are functions that return a std::string(). Functions that pass return an empty std::string(). main() instantantiates a "Tests" struct, pushes functions to the struct, returns tests.run(); There's your unit test framework without the over engineered framework.
I found TUT to be really good: http://tut-framework.sourceforge.net/ But I wrote my own based on a similar model - mainly due to TUT not being able to meet my particular needs.
You've probably already realised that the ["Exploring the C++ Unit Testing Framework Jungle" article](http://gamesfromwithin.com/exploring-the-c-unit-testing-framework-jungle) *was* written five years ago, and the available frameworks have probably changed a bit since then. One testing framework that's been introduced since this article (and my preferred option) is [UnitTest++](http://unittest-cpp.sourceforge.net/). I like it a lot because it has everything I really need and nothing that I don't. Easy to get started with, and it just works. Heh, and I'd actually forgotten this detail - UnitTest++ was actually *written* [by the author of the above article](http://gamesfromwithin.com/unittest-v10-released), in early 2006.
Actually I hadn't noticed. Thanks for pointing it out.
Singleton is still evil and best avoided. It forces assumptions that are almost never true in the long term deep into your program design and makes future features impossible to do easily. There are a few cases where you need a singleton. I've never seen one though, and I've seen many cases where someone used a singleton where it wasn't needed.
The guy must've been exhausted when he released UnitTest++ ;-) http://gamesfromwithin.com/unittest-v10-released &gt; created what we think **itâ€™s** the best C++ unit-testing framework ^^ This is repeated a second time.
As I'm working with the [PoCo Project](http://pocoproject.org/) libraries [CPPUnit](http://sourceforge.net/apps/mediawiki/cppunit/index.php?title=Main_Page) was the default choice and it works Ok for my needs. 
We're using cppunit with HippoMock where I am, its working out quite nicely as we have to ensure that all code compiles using the MS Visual C++ compiler and GCC using MinGW
I wrote my own, taking a few ideas from UnitTest++
1) It is not standard. (sometimes you might see code that has both!) Even if gcc and msvc support it - other compilers might not. 2) Many compilers recognize include guards as special cases. (usually the same ones that support #pragma once). But at least include guards work on all compilers. Usually if you're targeting a device that uses a compiler that doesn't support #pragma once, the compilation time benefit you gain from it is the least of your problems. 
I've heard 2 reasons for it: 1. "Everyone knows include guards" Seems to me the older programmers could learn this one line without any trouble, but maybe its just me... 2. "Portability" This may actually be a valid concern if have to deal with compilers other than gcc or microsoft's, especially if you're writing code to be built on multiple compilers
It isn't standard C++ and has caused problems in the past. See http://en.wikipedia.org/wiki/Pragma_once for some information. I'm not sure there's a good reason to avoid it as long as you know that your code will only be compiled by modern compilers that support the directive. 
Used to use CPPUnit, switched to Google Test. Much happier.
It's not part of any relevant standard, is why. There are other compilers than GCC and MSVC out there, and once you start using non-standard extensions you have to keep track of which ones support the particular extensions you use. Sticking to standards means you're independent from vendor specific idiosyncrasies, and the benefits of #pragma once over include guards are not huge. 
I usually just use include guards. I'm using msvc almost all of the time, but I have worked on projects with people using other compilers. It's really not that much more typing and I haven't noticed a huge speed increase with #pragma once.
It depends on your goals. It's perfectly likely that the tool you know is the best tool for the job on a tactical level. If on a strategic level you want to get a feel for other technologies, or you have a larger team for whom the tool you know isn't the tool they know, it seems it'd be counter productive to stick with C++. The other thing: I'd really try to get past the "hate wasting CPU cycles" mentality. There is a time and a place for that, but the reality is that in a LOT of deployments these days, C++ code is going to be wasting CPU cycles, if for no other reason than the CPU will be idle.
Scripting languages are fairly easy to learn and use and are most of the time much more flexible than C++ (but slower yes in many cases but you're not writing a real-time 3D simulator as a web application are you? ;)) My background is also in C++, but I feel if you don't learn other languages you'll never be able to see other wonderful language features that can save you a lot of time. And you won't be able to bitch about C++ lacking this and that and this and that... ;) I once did a small web site using PHP and a MySQL database and it went really well back then. It was so easy to write, no need to do lots of string manipulation, it just feels like you're writing directly in HTML yet you can do much more advanced stuff. PHP is easy to learn, and ASP looks to be somewhat similar... The .NET platform is also MUCH more mature/evolved than C++ when it comes to web services programming and stuff. Why? because using C++ you need to either roll all your own stuff or try to find the best (and free) library around in order to accomplish the same things... which is something I hate about C++, it clearly isn't a "high level language" compared to many others in the sense that its standard library sucks and is too low level (which may be great for some projects but for others you'll just be wasting valuable time). Learn new languages. It'll take some time getting used to them first but it'll pay off in the future, even for your C++ code as you'll be able to see things differently.
*#pragma once* is as portable as 32-bits *int*s: it's not.
 We do not use #pragma once because we already have include guards which are standard
I would recommend Boost.Test. It is so much easier to use than CppUnit (which I have used quite a lot). The BOOST_AUTO_TEST_CASE feature works seamlessly, and if there's a need for test fixtures, all you need to do is define a little class where the ctor is the setUp() member function (as in CppUnit) and the dtor is the tearDown().
Use the tool that is suited for the job. Artists in the 3D computer graphics industry often ask the same type of question regarding the software package they should use to create their 3D models. No matter how big the flame wars get and how many fan boys join those type of discussions the conclusion often seems to be that the software package is simply a tool, a medium that can get you to your goal and that there is no definite software package that is absolutely the best. It's about the artist, the tools are secondary. What you should worry about is getting the right tool to do the job at hand. And if that tool is C++ for you, then that's simply the hammer you like to use to shape your metal. C++ can get the job done. It's widely used in the software industry. It's fast. It has its quirks, but there's no shame in using it as your primary or even your only language. However, you'll always gain by exploring other languages. You'll see that a pattern emerges of "how things are done" and "how things are done differently" and this helps with getting the big picture. Seeing the bigger picture helps with gaining "wisdom" in the field of programming. It helps you to master your craft(s) from different points of view and with a broader view. 
This is the main reason. It's not a negative though. If you're the only person who's even going to compile it, and you're only ever compiling it for Windows, for instance, go ahead and use it in your Visual Studio projects. Who gives a shit? It's only when you go cross platform, or multi-programmer where the compiler being used is not explict (i.e. open source). Of course boost isn't part of the standard, but people use that ;) (But then boost can probably compile on non-MSVC and GCC).
Yeah he put that. See his 1.
QtTest + QtTestUtil with Qt. Used UnitTest++ before that.
Loggers, factories. I use singletons not so much for the "one instance", but for the ease of global access.
I can't accept the "CPU will be idle" argument. A simple reason against it would be lower power usage. On desktop if apps use less CPU, user needs a hardware upgrade less often. Also interactive apps would be more responsive. On server this is more clear: you can do more with the same processing power. In other words: you'll need fewer machines. And remember the power bill.
You don't need to try them all, one should suffice! I have used Python, but I can't say that I'm completely satisfied with it. It's the entirely dynamic typing that bothers me: I would have preferred a hybrid type system. Other than that it's a nice language... It's refreshing to get a different perspective from C++ with things like dynamic typing, having a REPL, doing truly interactive debugging and so on. If you'll deploy on a shared hosting (e.g Dreamhost's basic), Python performance will probably suck, but if you have your own server it shouldn't matter. C++ will be faster, but you won't likely notice it. So try Python. It has some nice frameworks and it plays nice with C++.
Interesting. I didn't realize that it had caused problems before. It makes sense now why some people tend to avoid it.
gtest is excellent.
Last time I looked GCC didn't support #pragma once, if that's what you were implying.
&gt; I hate wasting CPU cycles Ug. Hate wasting memory accesses, not CPU cycles.
My native language is C++ too, the only scripting language I've ever felt really comfortable with has been Perl. It's fast (it had to be, when it was written &gt;15 years ago), and you'll like the close integration with Apache you get with mod_perl. The syntax isn't that bad when you get used to it, and if you're ok with the more exotic parts of Boost you should have no trouble :) You can use [Inline::CPP](http://search.cpan.org/~neilw/Inline-CPP-0.25/lib/Inline/CPP.pod) to interface with any existing C++ code you have, or if you really enjoy pain you can write extensions in [xs](http://perldoc.perl.org/perlxs.html).
In fact I hate both. Do any other technology optimize memory accesses? Which one? How?
You just have to be careful, often times people optimize for less CPU cycles at the expense of more memory access. That used to be a valid optimization strategy too, but these days memory is so many times slower than your processor that it can cause more harm than good. Though the cache can help out a lot.
Remember how hard it was to learn what you already know? Remember the beginner mistakes you made, that you just never make now? Well, switching languages and libraries will be like that again. Skip it, as much as you can. I like Macs. They come with Apache pre-installed. I installed the mod_fcgi to run programs complying with the FastCGI interface, and started writing my web apps in C++, deploying them in the house initially. Eventually, I bought some web space on Dreamhost that came with ssh access, and access to gcc, and its C++ compiler. I've made some forays into the trendy stuff, but the new world of the web is so hard, that I've found it easier to leverage what I already know: my familiar source code control, bug database, unit test framework, IDE, programming language, and favorite libraries, so I can focus my learning on the part that is truly new to me. (For example, U.I. written in Javascript, living in the browser, that communicates with the server-side backend.) But, with C++, watch the time your edit-compile-test cycle is taking. In a big C++ project, it's easy to have long link times. Consider structuring your application as a collection of dynamically-linked shared libraries, so you don't have to spend minutes waiting for your program to re-link. This is an optimization you can do later, when you need it. TL;DR: use your mother tongue. 
Um? It must have been a while since you looked, since it's been supported in gcc for over 10 years. :)
not again... majority of cpu intensive code is confined to lvl 1 or lvl2 cache in any case. This is some abstract bollocks spoken, again, again, again by people that have never profiled a production application in their lives, never written a multithreaded application, and read far too many AMD technical docs.
&gt; I can't accept the "CPU will be idle" argument. A simple reason against it would be lower power usage. If you really want to go there, you need to stop using C++ and move down to C, or assembler. Beyond that, you should stop using CPU's and start getting custom ASICs for all your routines... ;-) In the end, the power you are saving is largely trivial, and likely is hugely outweighed by other factors. The user is going to upgrade hardware as soon as the one performance critical part of your code runs too slowly, and so they will *never* care about the performance of the other bits of your code. A user will take an app that responds in 2ms instead of 1ms, particularly if said app has more features. Servers these days are *rarely* CPU limited. You almost always have problems elsewhere (indeed, even when you are CPU limited, it is often because of context switching or memory access issues, not actually code path efficiency). Sure, if you have a farm of 1000 machines, you can get a good win by cutting CPU time... maybe. Even if you can, the win would be immeasurable for most of the code that runs on the system (there is a reason why init scripts still tend to be "scripts" instead of compiled code, configuration management systems are typically not implemented in pure C++, etc).
fusama is talking about comprehension of the pragma, easytiger is talking about consistency among files. Different points. Personally I understand the pragma, no problem. But since the coding standards for the company I work for specifies ifndef, I'll be using those.
Expand your horizons a little and try something new. Even if you don't like it you will have learned something and oftentimes you can apply techniques you used to languages you already know.
I learned C++ in the context of game development before anything else. I had the same problem as you. Anything I would encounter, I would say "I can do that in C++". The problem is, it might be doable, it's just not the best way of doing it. I learned PHP and web development languages next. I learned Java after that. I now consider what language would be best for the job before I start. An application that could take me a day to write in C++ might take me 15 minutes (and perform well) in PHP or Java. It will save you significant time to learn a few more languages. If for nothing else, to be able to prototype something before you make it in C++.
:) I'm happy seeing someone is really doing my dream. One of my dark points in doing web apps in C++ has been deploying it. Do major hosting providers support FastCGI?
Good point. My problem is not really about trying them. I've tried Python, Java, Haskell, Perl, PHP, x86 Assembler, SML, ... usually writing a small tool in them or some university projects. I've learned very nice thing about each of them. It is about _mastering_ another language (other than C++ and BASH) and using it regularly for some type of software projects.
I don't know what you are asking then. Just pick one that interests you and go to town.
Side note: I believe [C++ is faster](http://www.reddit.com/r/cpp/comments/ag9rm/c_is_faster_than_c/) [than C](http://www.reddit.com/r/C_Programming/comments/ag9rf/c_is_faster_than_c/).
Tough decision, I've been asking myself the same. The languages I use most are Python, C++ and Java but I occasionally use C#, Matlab, PHP and Lisp. Though my favorite is Python I'm doing 90% of my programming in C++ right now, because I'm working on a computer vision project and CPU cycles shouldn't be wasted. On the other hand, I feel sometimes that my developer cycles are wasted - the relative verbosity of C++, the burden of memory management, obscure template errors, and so on make me consider Java or C#, that (some say) rival C++ in performance but are simpler to use. Python is my favorite, but too slow (I've combined Python with C extensions to get the best of both worlds, but if the logic needed at the interface between both languages is complex it gets rather cumbersome). Now, if you have a lot of experience at C++ you might find it easy to deal with all the problems I mentioned. However, I think that for a web application it might be worth considering another language, since there seems to be relatively little libraries and information for web development in C++. Python is almost trivial to program in, but it does waste a lot of CPU cycles compared to C++, besides being a very different in style. Perhaps Java or C# would be a good fit, since they are a lot like C++ but easier to program in, have lot of web and DB libraries, and don't waste much more cycles. If you do choose C++ for the project, it would still be a good idea to learn Python to perform little scripts for non-CPU-critical tasks. It's a breeze to learn and has 'batteries included', as they say. After learning Python I would never consider programming in Bash again. 
I too do the majority of my development in C++ and also feel like C++ is appropriate for web development and a variety of other problem domains other than strictly high performance applications. Having said that, I wouldn't be even close to as good of a C++ developer had I not learned Scheme and Haskell.
So you tell me then... you have a fixed set of resources on a computer such as a file system, CPU, a sound card, or other global resources that are shared by the computer as a whole... You think it still makes sense to avoid using the Singleton simply because "It's evil?"
yes, it's very easy to configure, you can have an fcgi-bin to place your programs and/or just use the extension .fcgi, when in doubt ask!
If you want to go web application in C++ the best framework is [Wt](http://www.webtoolkit.eu/) .
C++ *can* be faster than C, but generally isn't. Those benchmarks are a joke (microbenchmarks in general are, but these are bad even for that). I looked at the regex-dna one to verify what I expected to find: the differences being measured aren't real world differences and/or aren't really language differences. The C++ program still uses a lot of C libraries for its work (using cstdio instead iostreams for example). The main difference between the two is the different regex libraries they use and the C program compiles its regexs at runtime instead of at compile time.
Ug Hate wasting disk accesses, not CPU cycles or memory accesses. :)
I hate *cache misses*. Not a problem when you're on an embedded micro with no cache :) But then you get to hate anything that uses memory. At all.
I can tell you from experience, you should learn some of the common languages if you will need to find a job in the future. You don't always get to pick what language is going to be used.
Why screw around with FastCGI if you care about performance? Look at Apache modules (or better yet, nginx modules).
Lots of garbage collection algorithms either directly or indirectly optimize memory accesses. Lots of data structures around this too. Google for "cache aware data structures and algorithms".
When all you have is a hammer... http://en.wikipedia.org/wiki/Law_of_the_instrument
I'm using Boost.Test (simply because I'm already using Boost), and haven't had any trouble with it. Other than that writing tests still sucks.
Which modules do you mean? Or you mean I should implement my app as an Apache/nginx module?
There are some good thread-aware and cache-aware memory allocators which can be used with C++ (and C, and some of them with all dynamically-linked native binaries even without a recompile).
&gt; C++ can be faster than C, but generally isn't. It's been said a thousand times: C++ is more expressive than C; consequently, C++ is inherently as fast as C in every situation, and quite a bit more perfomant in many of them. If C++ is ever slower than C, it is because the programmer has chosen (probably unnecessarily) cumbersome abstractions. With the right choices, highly abstract C++ can still be faster than C.
The problem is that while other languages are easy (in comparison with C++) its very hard to master them. I'm very similar to you. I have tried pretty much everything, but once I reach complex issues I have trouble finding people, books, websites that cover these issues. Huge parts of the functionality is hidden in the language itself and it is extremely hard to uncover details. Other languages are not functionally exponential like C++ (many simple concepts combining themselves), they are mostly layered. Expressiveness comes from libraries (modules, etc...).
This is not a valid point. C++ is a universal language. Its not like using a domain specific language for something it hasn't been designed for.
Here is a real life benchmark: [shootout @ alioth](http://shootout.alioth.debian.org) If you don't like the implementation in any of the languages you can post your own.
Yes. I have a computer with 3 sound cards (bluetooth headset + two different outputs on the main sound card, which can be combined for 4 channel sounds or used separately). I have several different disks, each with different filesystems. My CPU has 2 cores. The above is pretty standard these days. Explicitly passing around an object for the device you want to use is generally better. Often this is done by having a container object that just contains the objects in use for this particular run and you do a controller.getActiveSoundCard() to use the correct sound card. This allows one program to be latter expanded to using two separate sound cards for different purposes (sometimes a separate process is better for this, but sometimes there is good reason to run both sound cards in the same process even though they are used for unrelated output). Singleton is just another name for global variable. It has all the weaknesses of a global variable. There are times when they are the right solution to the problem, but those times come up far less often than most people think. In most cases when I see singleton I see a very simple way to remove the singleton, and that refactoring removes several bugs that using a singleton caused.
The latter. Do you not notice the irony though that you are obsessing over wasted CPU cycles such that you *must* use C++, but then are using FastCGI as your interface? It kind of speaks volumes as to the whole issue.
&gt;If for nothing else, to be able to prototype something before you make it in C++. Hopefully more reasons are applicable than only this one, but even if not, this alone should be convincing enough. Knowing MATLAB and Python saves me a *ton* of time prototyping things. It even helps in the design phase, because it's so easy to significantly change an algorithm and (in MATLAB) visualize the changes. I typically use MATLAB for very mathy algorithms (especially work that involves linear algebra), and Python for others. They're excellent prototyping languages.
You can have 10 sound cards, 1000 CPU cores, it doesn't matter. The point isn't that you're using a Singleton because you only have 1 CPU, or 1 sound card, it's that you have no control over the number of them; you can't just instantiate new sound cards or CPUs as you need them. As such, in this case it's preferable to manage all your sound cards, all your CPUs, all of the global resources which you can not create using a Singleton. That's what a Singleton is best used for, managing global resources that you are not at liberty to instantiate at will.
It's definitely a valid point. C++ is Turing-complete, sure. It *can* do anything. That doesn't mean it can do it as well as another language. For example, Project Euler [Problem 9](http://projecteuler.net/index.php?section=problems&amp;id=9) can be solved in a single list comprehension in Haskell: [a*b*(1000-a-b) | b &lt;- [1..997], a &lt;- [1..b], a^2 + b^2 == (1000-a-b)^2] In fact, the notation is even similar to the set notation you would use to describe the problem. This same problem *can* be solved in C/C++ (quite easily), but it's not as compact or expressive. The *Law of the instrument* definitely applies to programming languages.
I will tell you this much - whenever I have had a question about Python, Freenode's #Python channel (irc://irc.freenode.net/Python) has been *very* helpful.
Amen! (Although DMA is kind of nice...)
I agree with everything you said, but I still use #pragma once. In the end, I don't think it really matters. I'm not writing cross-platform code, but even if I were, it would be a small python script to convert every #pragma to an include guard. 
You are using a global variable when you should be passing variables around. While the global is easier to use in the short run, in the long run your code is much easier to debug when you don't have them. I know what you are saying - you can make a program work that way. I've taken a program written your way are removed a lot of bugs when I switched to my way.
Of course it applies to programming languages, but not the way you put it. If it would then for every problem (or pretty much every line of code) there is an optimal language and no other language should be used. And the Law of the instrument is not about optimality. If it would than such law would be just moronic. How do you decide optimality? If you take Haskell for example, then yes, a lot of things can be written with little code, and it will be elegant (like the one line quicksort). quicksort [] = [] quicksort (s:xs) = quicksort [x|x &lt;- xs,x &lt; s] ++ [s] ++ quicksort [x|x &lt;- xs,x &gt;= s] What is left out is the fact, that such implementation of quicksort isn't quick at all (with n^2 aggregated complexity instead of log(n)*n).
I use C++ because I find it the good compromise of performance and flexibility/portability/maintainability/... . If I needed _only_ fewer CPU cycles, I'd program everything in assembler. I find the case of FastCGI similar. It is lowest-overhead solution which is also flexible enough (portable between web servers, available through hosting providers, ...). I don't want my web application to require at least a VPS for deploying. However I'd like to know about other similar or competitive technologies.
&gt; C++ is more expressive than C; consequently, C++ is inherently as fast as C in every situation, and quite a bit more perfomant in many of them. More expressive != faster &gt; C++ is inherently as fast as C in every situation, and quite a bit more performant in many of them. Given your assertion, it is really hard to explain why in the example benchmarks, C was in many cases faster/smaller/etc. If you are referring to C being a strict subset of C++, then yes, but then you are programming in C for the most part. That said, C isn't quite a strict subset of C++, so you can conceivably run in to issues there. For a silly example of this: struct foo {}; printf("Size: %d\n", sizeof(struct foo)); If you compute "output of C++ program" / "output of C program", you get infinity. Some people consider "infinitely larger" a significant performance difference. More importantly though: this assumes all other things being equal, and they are not necessarily. &gt; If C++ is ever slower than C, it is because the programmer has chosen (probably unnecessarily) cumbersome abstractions. So in short: "If I code it in C and compile with a C++ compiler, my code won't be any slower than C". I wasn't referring to which compiler he was using, I was referring to programming style. Here's a better pointless tautology: "Any turing complete language can come up with a solution that is as 'performant' and efficient as any other language's solution". &gt; With the right choices, highly abstract C++ can still be faster than C. This is true in some cases, but typically not. This whole thing misses the point though. C++ adds a lot in to the mix for the programmer and compiler writer to consider. This makes it a lot more complex to come up with the most efficient code possible. Sure, with an infinite amount of time it doesn't matter, but in practice, if you care about performance to the point that you aren't willing to consider other language features, you probably shouldn't be coding in C++ (and I say this as someone who prefers to write in C++)... and probably not C either. 
Make sure to look at [swig](http://www.swig.org/). It's a layer to help you use c/c++ code in other languages. Might help your transition to whatever language you pick simpler, because in some areas you can just use what you already have.
Yeah... that'd be a link to the same benchmarks. Thanks for helping out. Yes, I can post my own, but the whole exercise is pointless. I'm actually shocked that nobody has provided programs that compute the answer at compile time just to point out how silly the whole exercise is.
Maybe because such code does not exist. Or if you know about a way how you would implement for example quicksort in compile time, that it will have constant run time for every input, go ahead, the whole world is waiting.
Why not all of them?!
Right, downvote somebody promoting a helpful discussion because you don't agree with them. Hmm, [where](http://www.reddit.com/help/reddiquette) have I seen that before? Back to the point, though... Learning other languages will give you insight into different perspectives and different ways of solving problems. Whether or not you use them when you actually decide to work on a project is irrelevant: the new modes of thought will help you think about the problem in new ways even in your "mother tongue". Personally, even when I code in C/C++, I usually find myself thinking about the problem in terms of Python, linear algebra (read: MATLAB), Haskell, or something else. My brain does not work in terms of pointers and iterators; it works in terms of matrices and abstract operations. Sure, I boil them down to code, but if I hadn't learnt other languages than C/C++, I wouldn't be half the programmer I am today. The *Law of the instrument* says nothing about when to use your hammer, it simply says that if a hammer is all you have, you'll never know when another tool might be more suitable. For programming languages, the analogy starts to break down, because you *can* use C/C++ to do anything you can do in another language - you simply may not think of it in the first place.
Oh please stop trolling. &gt; More expressive != faster True, but we are talking about compile time expressiveness. &gt; That said, C isn't quite a strict subset of C++ Equivalent doesn't mean identical. There is always an equivalent code in C++ that matches C, it won't be completely identical but very close. Such code will be exactly the same speed that the original or slightly faster (usually within the measure error margin). &gt; I wasn't referring to which compiler he was using, I was referring to programming style. What programming style are you referring to exactly? &gt; "Any turing complete language can come up with a solution that is as 'performant' and efficient as any other language's solution". Interesting idea. But definitely not true. &gt; Sure, with an infinite amount of time it doesn't matter, but in practice Exactly, either you have never coded in both C and C++, or you are just trolling. If you don't have infinite time, then you will settle with the compiler's implementation of dynamic features like late binding as "good enough" (btw. I still haven't seen a C implementation of late binding that would be faster then C++ code). &gt; if you care about performance to the point that you aren't willing to consider other language features Consider doesn't mean that you have to use them even if you don't need them. The whole point of C++ is that features that you don't use have zero overhead on the final binary.
&gt; Personally, even when I code in C/C++, I usually find myself thinking about the problem in terms of Python, linear algebra (read: MATLAB), Haskell, or something else. My brain does not work in terms of pointers and iterators; it works in terms of matrices and abstract operations. Sure, I boil them down to code, but if I hadn't learnt other languages than C/C++, I wouldn't be half the programmer I am today. You are talking about algorithms. Show me someone who is thinking in terms of pointers and iterators when he is designing an algorithm. And more to the point, designing algorithms is not related to programming languages. When you are implementing an algorithm (in some specific language) then you have to think in terms of pointers and iterators, because you have to understand the cost behind these constructs, when you don't and implement something in C/C++ the way you would in Matlab or Haskell, you will end up with hard to maintain, buggy and slow code (and this works both ways).
If you can manage to read your answer before it scrolls of the screen.
&gt; Oh please stop trolling. I'm not trolling. I'm trying to point out that not being willing to consider working with other languages because you are obsessing about efficiency is stupid, particularly when you are already making compromises. &gt; True, but we are talking about compile time expressiveness. Okay: "compile time expressiveness != faster". Sometimes that expressiveness means that the compiler has to consider a lot more possibilities than it otherwise would. Sure, with a sufficiently smart compiler it can still reach the same result, but let's not fall down that rabbit hole. &gt; Equivalent doesn't mean identical. There is always an equivalent code in C++ that matches C, it won't be completely identical but very close. Such code will be exactly the same speed that the original or slightly faster (usually within the measure error margin). Except I demonstrated an example where that wasn't true. It isn't hard to come up with other examples either. Heck, C++ doesn't even have restrict yet. You can fake it out to a degree using stack local variables and a hell of a lot of work on the part of the compiler writer, or if the C++ compiler writer adds "restrict" support, but then we're out of the theoretical world an in to the real world, where a C++ compiler writer has to devote a ton more effort just to get something that compiles code, let alone optimizing it, and so is at a huge disadvantage as compared to the C compiler writer. &gt; What programming style are you referring to exactly? I'm referring to what language's features you are using. If I have a program that can be compiled as C++, but 90% of the code is inline assembler, in my book, that isn't a C++ program. Same goes for 90% of the code being C. It isn't C++ unless it won't compile as C. If you aren't going to follow that principle, then I can demonstrate that C# is just as fast as C. ;-) &gt; Interesting idea. But definitely not true. Simple thought experiment: I am challenged to write a Python program that runs as fast as this other person's hand tuned assembler. I look at their binary, then write a Python program that generates the same binary. I have now implemented, in Python, a program that is as fast as theirs, regardless of the performance merits of Python. In short: in the end, if you spend enough time at it, any turing complete language can implement a compiler &amp; runtime for any other turing complete language. It is therefore always possible to create an equivalent program. Of course, you'd be stupid to do such a thing, which is exactly why it is stupid to discuss what would happen with an infinite amount of time. &gt; If you don't have infinite time, then you will settle with the compiler's implementation of dynamic features like late binding as "good enough" (btw. I still haven't seen a C implementation of late binding that would be faster then C++ code). You can find Java runtimes that generate faster code in the case of late-binding than what you get out of the box with any C++ runtime I've been able to use (thank you JIT!). I doubt you are going to buy that Java is faster than C++ (although I have manged to pull that one off on occasion), so you have proved little. The point is that with C++ the list of performance "gotchas", where your code ends up less efficient than intended, are far more extensive and challenging to address than with C. Sure, with sufficient skill and time you can overcome that and exploit features in C++ which might even give you an advantage in some cases, but you could say that about a *lot* of languages (many which the submitter has explored and walked away from). In reality, you aren't going to spend that kind of time with the vast majority of your code that consumes precious little of the actual run time. &gt; Consider doesn't mean that you have to use them even if you don't need them. The whole point of C++ is that features that you don't use have zero overhead on the final binary. No, that wasn't the whole point of C++. That was *one* of the design goals... and one that wasn't fully realized (see my example on struct size as an example). Furthermore "need" is too strong a word here. You don't *need* objects, virtual functions, operator overloading, etc. You probably would benefit from using them, and if you choose not to use them because that is going to cost you a few cycles every couple of seconds, you either have a very unique case you need to consider, or you are an insane masochist. Sure, for that hot spot in your code you might eschew using languages that get in the way of your efforts to tune it to death, but a sane developer isn't going to let that drag the rest of their code down with it.
&gt;You are talking about algorithms. Show me someone who is thinking in terms of pointers and iterators when he is designing an algorithm. And more to the point, designing algorithms is not related to programming languages. Exactly. And without learning more programming languages and different ways of thinking, a person will naturally use the capabilities of their only language to solve every problem. The way we express ourselves naturally influences the ways we think. Cf. The [Sapir-Whorf Hypothesis](http://en.wikipedia.org/wiki/Linguistic_relativity). &gt; [...] you will end up with hard to maintain, buggy and slow code (and this works both ways). Yes; the point is to separate design from implementation. It's necessary and important to be mindful of the close-to-the-metal details when you're implementing, but during the design phase, it is beneficial to be able to think abstractly, and if you've only ever learnt one language, your abstractions will suffer from it. In machine learning, this is called "overlearning". You learn details specific to the dataset (in this case, the programming language) and confuse them with broad generalizations (in this case, high-level design).
Just goes to show how well-populated the channel is. There's little to no off-topic discussion, actually.
I actually use it too in some code bases I work on. :) I have pretty tight performance constraints (every millisecond matters) and use quite a bit of platform and compiler specific trickery - so I've gone for the second option: keeping track of what my target compilers support and what extensions I use. And it so happens that all relevant compilers for that project supports #pragma once. The important thing is to be aware of the rules before you bend them :)
C++ is as good for web development as an hand grenade is good at killing mice. And as dangerous too.
Oh, didn't mean to suggest there was. Just be prepared to delete your channel logs periodically :).
Hahaha, definitely. =)
&gt; Exactly. And without learning more programming languages and different ways of thinking, a person will naturally use the capabilities of their only language to solve every problem. The way we express ourselves naturally influences the ways we think. Cf. The Sapir-Whorf Hypothesis. No, learning new languages is completely useless for algorithm design. This is theoretical informatics.
The Sapir-Whorf Hypothesis doesn't care which field it is. When you are using langauge to express thought, the language you use affects what you are capable of thinking. This applies whether it's computer language or human language. Perhaps you find learning new languages useless, but, personally, I have found that they introduce me to new modes of thought and I solve problems in new ways after learning them, even in the original languages. (Haskell was particularly notable for this, because it introduced me not only to a new language, but an entirely new programming paradigm.)
Would you elaborate?
My point was that you are not using programming languages to express algorithms (while designing them) you use mathematical constructs.
&gt; learning new languages is completely useless for algorithm design But it is useful for general algorithm use. Most real-world algorithms are just simple variations on common ones, just minor changes to handle the slightly different data. Brand new algorithms are rare, and rarely required (does the world really need another O(n ln(n)) sort?). When I was a C with classes programmer (using code bases that were started before std::string was in the standard and thus C strings) I avoided situations where I had to remove unwanted characters from a string, instead I kept those characters around as long as I could because it was such a pain to remove them. When I learned python it became natural to use trim and the like to remove them. When I went back to C++ I was still thinking in that way, so I wrote code that did the job for me. (This is trivial on hindsight, I just didn't think it was a useful task before so I hadn't done it) 
Like an hand grenade, C++ is not focused at fixing specific problems. I miss a lot of stuff that would be very helpfull in web development: * reflection - which helps you a lot to implement flexible solutions (e.g.: dependency injection and inversion of control) * good frameworks implementing known design patterns * a vast culture of people and projects aimed at solving the problems specific to web dev * good refactoring tools for C++? Where? On the other hand, C++ strengths are less important in the web: * speed? Hard disk access is the problem; cpu is not. C++ fixes speed in CPU, not IO * access to hardware low level? - why? * direct memory management - Java's garbage collector provides allocation &amp; release of objects as fast as most C++ implementations. And as an hand grenade, it has a lot of nasty side effects: memory leaks, hard to log errors, slow development cycles, etc.
And that's certainly a good way of doing it. But the fact remains that the more ways of thinking you are exposed to (by learning new languages, in this case), the more tools you will have in your toolbox when you are designing a new algorithm. I think we agree with each other on that much.
No, [not even this is raw data](http://shootout.alioth.debian.org/u32/summarydata.php?d=ndata) but it's much much more like raw data. 
&gt; If I can, I'll report back. And 2 weeks later ... ? (Shouldn't you also report back if you **can't** come up with anything better?)
&gt; I looked at the regex-dna one to verify what I expected to find I suppose it's too much to hope that you would *look at all of them* and *try to disprove* what you expected to find.
While I agree my phrasing was quite poor, I don't think there is anything wrong with picking one of the cases showing the large differences to see why it was the case. Heck, based on the arguments presented against my assertions, there shouldn't be *any* tests where C wins, but there are. I think there is more than enough evidence that these benchmarks don't validate their arguments, and I just found a reason why the positive cases still don't.
javascript would be a good next language choice. The future looks good for it being a general purpose broad language: - every browser uses it (the *killer* app) - new javascript engines are damn fast and getting faster and... - server side javascript is picking up When I was working in a production shop I used ruby/perl/etc. since it allowed others to *hack* whatever I'd already written. Back in development I find I can do the same things just as easy with c++ and bash.
&gt; don't validate their arguments It's one thing to say (as long as you show) that "these benchmarks don't validate *their* arguments" - go right ahead! It's another thing to say "Those benchmarks are a joke..." and select one that like a *real world program* depends on libraries and then suggest that somehow in the *real world* library differences are nothing to do with the language. It's nearly 2010 - accessible easy-to-use libraries are *real*.
&gt; It's nearly 2010 - accessible easy-to-use libraries are real. Yes. The question is why use two different libraries with two totally different execution mechanisms if the test is language differences? You could easily have used the same regex library for both, or at least make the two programs do equivalent things. Otherwise, you aren't benchmarking what the benchmark purports to compare. You're really benchmarking the two different approaches to regexs.
&gt; You could easily have used the same regex library for both Can a C compiler compile the boost library? &gt; at least make the two programs do equivalent things For what definition of "equivalent"? The programs both take the same input and produce the same output. &gt; You're really benchmarking the two different approaches to regexs. Do you think Perl and Tcl use the same approach to regexs? 
The only real unit-test framework I used was Boost Test and it worked quite well. However, I am not using any such framework now - a big bunch of asserts does the job just fine.
My main problem with typical "web languages" such as PHP, Python and Ruby is that they are notoriously unstable. Write something with Python 2.6, it might not work with Python 3.0. Same goes for PHP and Ruby. On the other hand, Java as a language is very stable, but they come up with a new web framework every year or so - I lost count how many of them there are. If you are comfortable with developing for Windows only, I guess C# and ASP.NET MVC (stay away from classic ASP.NET with web forms !) looks very promissing, but it is a pretty new technology. As for C++, I did develop web applications with it before and it worked well, but to be honest the "web" part of it was a very small piece of the system. For most web applications the DBMS does most of the heavy lifting anyway and I do think C++ is too much.
&gt; Can a C compiler compile the boost library? No, but the C++ compiler can use the C regex library. &gt; For what definition of "equivalent"? The programs both take the same input and produce the same output. Okay, so you'd be satisfied if one of the programs just emitted the output without doing any computation at run time? What would that be benchmarking then? Look, its a legit benchmark if it isn't actually trying to measure the differences between the two languages. However, the benchmark itself and the poster who referenced it claim to be a comparison between the performance of the two. &gt; Do you think Perl and Tcl use the same approach to regexs? Nope, and if I wanted to compare the two approaches from a performance standpoint, I'd use the different approaches. C and C++ don't *have* an approach to regex's. They have NO built-in support for regex's. C is fully capable of working with DFA's at compile time, as proven by well established tools like yacc and lex (literally, this was how the parser for the first C++ compiler was written). So why would anyone think it is a legit comparison between C and C++'s performance? The logical equivalent to the Perl/Tcl comparison would be to have them do image processing, with the Perl one doing it with raw byte manipulation implemented entire in Perl and the Tcl one spawning a sub process and running ImageMagick, and then claiming that this shows Tcl is much faster. 
So, I checked, and actually the guys who run this site get what the issues are, the problem is the benchmarks don't reflect it: * [Do your programs avoid library use, like these benchmarks?](http://shootout.alioth.debian.org/flawed-benchmarks.php "Flawed Benchmarks") * [We are trying to show the performance of various programming language implementations - so we ask that contributed programs not only give the correct result, but also **use the same algorithm** to calculate that result.](http://shootout.alioth.debian.org/help.php "Help | Computer Language Benchmarks Shootout Game"). I took a look at another of the tests with widely divergent performance, the k-nucleotide test, and it also shows widely different algorithms towards solving the problem. This makes a lot of sense of course. In general, there just can't be that huge a difference between the performance of the two languages.
QtWui seems to be a dead project. Take a look at Wt: http://webtoolkit.eu It's not Qt-based but the API is very much like it. 
&gt; the guys who run this site That would be me.
&gt; No, but the C++ compiler can use the C regex library. So you mean we could make a C++ program that was *as slow as* the C program? &gt; a legit comparison between C and C++'s performance? What should we expect C and C++ programmers to do when there's 'NO built-in support for regex's"? 
Okay, then you have some cases where the above isn't happening.
&gt; So you mean we could make a C++ program that was as slow as the C program? Not necessarily. It would merely mean the only difference in performance would be due to the difference in the languages, rather than the differences in the implementations of the regex libraries and in this case how they are used. &gt; What should we expect C and C++ programmers to do when there's 'NO built-in support for regex's"? Well, for starters, stop pretending that the regex benchmark is actually comparing the differences between the languages. If you choose to ignore that, then try to use regex libraries with the same underlying algorithms. Finally, at least make it so that they have the same algorithmic approach to *using* the regex libraries. Right now the benchmark is almost the logical equivalent to comparing two programs that compute prime numbers, one that has a sieve prebuilt and one that is building it on the fly.
Or might you be reading something different into "use the same algorithm"?
&gt; It would merely mean the only difference in performance would be due to the difference in the languages ... If we can't compile boost with a C compiler isn't that a practical difference between C++ and C? &gt; actually comparing the differences between the languages When the accessible easy-to-use C library isn't as good as the accessible easy-to-use C++ library isn't that a difference between the languages? It would be great if Henry Spencer's regex engine was available as a self-contained maintained library outside of `libtcl` but...
&gt; If we can't compile boost with a C compiler isn't that a practical difference between C++ and C? It's a huge practical difference. It just has nothing to do with performance. &gt; When the accessible easy-to-use C library isn't as good as the accessible easy-to-use C++ library isn't that a difference between the languages? No, since you picked two random libraries that are available out there out of a legion of choices. If you tried every single library pair exhaustively, maybe you could make some kind of a statement, but for the most part it would still be difficult. It makes far more sense to control for the differences between the libraries and so the only differences are the languages themselves. This shouldn't be news to you, as your pages on flawed benchmarks talks about this. More importantly, the libraries were *employed* in a different manner, which provides a fundamental advantage to one program. You are effectively testing **two different algorithms**. The benchmark in that case compares the performance of a program that has a statically built DFA vs. one that has a dynamically built DFA. That's a huge difference, exacerbated by the small size of the data set in the test. You could use a statically built DFA with the C library, or a dynamically built DFA with the C++ library. There are subtler differences (well, some not so subtle, as the C++ one also allows parallelism, but in this case if anything that hurts the C++ one) as well that could be mitigated with more effort, but this is the huge one. Anyway, as you clearly point out on your own pages, it is vital that the algorithms be consistent from one program to the next, and this simply isn't the case here. The k-nucleotide benchmark (the other one with a big performance difference that I checked out) is flawed in a similar fashion. The C++ version uses 15% of the memory of the C code. Do you really believe that is due to language differences and not algorithmic differences, and if so, what feature of C++ is being exploited that allows this amazing memory savings (I'd sure like to have access to that for my work!)? When I looked at it, it was pretty obvious that the C++ was packing the data in a fashion that can just as easily be done in C, but wasn't being done in the C code. There are a ton of other differences as well (the two programs really only resemble each other in terms of the constraints on the inputs and outputs and some of the nouns in the code). &gt; It would be great if Henry Spencer's regex engine was available as a self-contained maintained library outside of libtcl but... You could use a cross language regex or state machine library, or you could just recognize that a regex benchmark is really not that useful for comparing language performance for diverse languages (rather than just those where native regex is an integral component of the language), or you could ensure that there aren't algorithmic differences between the programs you consider (as your site claims) or you could ensure that each program was fed a prebuilt DFA, or you could at least design the benchmark better such that the regex was only available at runtime, thereby making the prebuilt DFA a non-option...
&gt; Or might you be reading something different into "use the same algorithm"? Well that is always possible, but I can't imagine what interpretation you are providing that makes sense in this context. You are implying that it means something more than just producing the same result for the same input. With these two benchmarks that I've looked at, you very much are dealing with differences in "programmer effort and skill", which is not what you want.
&gt; differences in "programmer effort and skill" Which programmer - the one who wrote the library code or the one who wrote the benchmark program? Which algorithm - the library code or the benchmark program? (Let's join the other Q/A thread.)
&gt; It's a huge practical difference. It just has nothing to do with performance. Then you seem to have in mind some very abstract performance ideal. &gt; make some kind of a statement What "kind of statement" is made on the website? &gt; it is vital that the algorithms be consistent from one program to the next Which "algorithms"? Years ago some Ada programmer opined that it's the same *algorithm* when the assembler is the same - which is obviously true and obviously there would be no difference in performance. &gt; The k-nucleotide benchmark ... When I looked at it ... You haven't said which of the 4 C programs or 2 C++ programs you looked at. &gt; not that useful for comparing language performance for diverse languages The problem isn't with the answer, the problem is with the question. The fact that some languages treat regex as an integral component of the language and some treat regex as a library is just a particular example of the more general situation - implementations for different programming languages aren't *strictly* comparable. What should we say about an integer math comparison between Perl and Lua once we know that the Lua implementation isn't using integers? Surely that's an arbitrary comparison? However arbitrary, can we extract usable information from such a comparison? 
&gt; Which programmer - the one who wrote the library code or the one who wrote the benchmark program? Primarily the latter, but I have to wonder why it matters. &gt; Which algorithm - the library code or the benchmark program? Same answer as above.
&gt; Then you seem to have in mind some very abstract performance ideal. The xpressive library isn't inherently faster than other regex libraries. It is inherently more convenient. Therefore, the advantage of being able to use it is very much practical and has nothing to do with performance. &gt; What "kind of statement" is made on the website? The statement that I quoted: "When the accessible easy-to-use C library isn't as good as the accessible easy-to-use C++ library isn't that a difference between the languages?". &gt; Years ago some Ada programmer opined that it's the same algorithm when the assembler is the same - which is obviously true and obviously there would be no difference in performance. Yeah, said person doesn't grok what an algorithm is (although they are kind of getting the point that these kinds of benchmarks ultimately end up being silly). Look, you have two programs, one which does some of the work before runtime that the other does at runtime. That's pretty fundamentally different. The nucleotide programs differ in that one uses an inherently more efficient data model. These are high level differences that could be implemented in any other language (not always with the same performance, but certainly most reasonably efficient languages wouldn't be N times slower). &gt; You haven't said which of the 4 C programs or 2 C++ programs you looked at. The [ones](http://shootout.alioth.debian.org/u32/benchmark.php?test=knucleotide&amp;lang=gcc&amp;id=2) [that the original poster](http://shootout.alioth.debian.org/u32/benchmark.php?test=knucleotide&amp;lang=gpp&amp;id=6) [linked to](http://www.reddit.com/r/cpp/comments/ag9rm/c_is_faster_than_c/). &gt; The fact that some languages treat regex as an integral component of the language and some treat regex as a library is just a particular example of the more general situation - implementations for different programming languages aren't strictly comparable. Is it your assertion then that the C++ programs that we're discussing are inherently faster than the C ones because of some language features in C++? Can you describe those features and why they are having this impact? I've asked this several times and nobody has pointed them out. Particularly given that the C/C++ comparisons use the same compiler and only differ in the front ends, it should be pretty easy to describe what it is that gives C++ this huge advantage in these tests.
&gt; has nothing to do with performance What is the *performance* of a library that can't be used? &gt; The statement that I quoted That was a question. &gt; one which does some of the work before runtime that the other does at runtime Have you actually established that that is in fact what's making the difference or are you guessing? &gt; The ones that the original poster linked to The original poster didn't claim that the C++ k-nucleotide program was packing data in a different way than the C k-nucleotide program, so had no reason to be specific about which programs. Perhaps you didn't realize there were 4 C k-nucleotide programs shown on the site the original poster linked to? &gt; inherently faster Is it your assertion that C is *inherently faster* than Ruby? Do we need to look at a C interpreter? (Let's get by without putting rhetorical assertions in each others mouths.)
&gt; What is the performance of a library that can't be used? **Exactly**. ;-) &gt; Have you actually established that that is in fact what's making the difference or are you guessing? It is an educated guess. There isn't much point to investigating it further unless you control for external factors. It isn't a straight up comparison, which tells me everything about the nature of the problem. I do know from first hand experience that Xpressive and g++ in general doesn't provide anything resembling that advantage over gcc for regex and parsing work. I've certainly never seen Xpressive, or the higher performance parser generators (which beat Xpressive handidly) provide that kind of a win. The only other possibility is that somehow the C regex library is broken in some profound way that this test exploits, but I don't see anything that looks likely to cause that. &gt; The original poster didn't claim that the C++ k-nucleotide program was packing data in a different way than the C k-nucleotide program, so had no reason to be specific about which programs. Perhaps you didn't realize there were 4 C k-nucleotide programs shown on the site the original poster linked to? When I followed the link, there was a specific set of comparisons, with one test implemented in each language. What I saw was interesting and amusing, but it in no way evidence of the poster's statement. Now that I look more closely, I notice there is [another C regex-dna program that does in fact use Tcl's regexp library](http://shootout.alioth.debian.org/u32/benchmark.php?test=regexdna&amp;lang=gcc&amp;id=1) which appears to beat the snot out of the C++ Xpressive program (although uses a lot more memory to do it). I haven't investigated why it wins so handily, but that appears to make my case that you can't draw any general language performance conclusions from these benchmarks. &gt; Is it your assertion that C is inherently faster than Ruby? Do we need to look at a C interpreter? Your benchmarks restrict the implementation of the language, so throwing the C interpreter in there is kind of pointless. &gt; (Let's get by without putting rhetorical assertions in each others mouths.) Fine. I'll ask the question a different way for a third time: **Can you describe the features of C++ that are allowing the specific programs in these benchmarks outperform the C ones and why they are having this much of an impact?** As a follow up: Can you explain why despite awesome advantages cited in your answer to the previous question, C was able to beat C++ in other cases? But perhaps the best question to lead with since you jumped in here is: do you agree with the mebrahim's implication that these benchmarks indicate anything meaningful about the relative performance advantages of C++ over C in a practical setting?
Slides from the talk [here](http://www.hpl.hp.com/personal/Hans_Boehm/misc_slides/c++threads.pdf)[pdf].
"Exactly" as an answer to "What is the performance of a library that can't be used?" just opens up a world of misunderstanding. Is there anything *good* about the performance of a library that can't be used? &gt; It is an educated guess. There isn't much point bothering about your specific claim while you're guessing instead of measuring. &gt; When I followed the link, there was a specific set of comparisons, with one test implemented in each language. A specific set of comparisons between **the fastest programs** implemented in each language. How do you know one of the other 3 C k-nucleotide programs doesn't pack data in *the same way* as that C++ k-nucleotide program? &gt; you can't draw any general language performance conclusions from these benchmarks What makes you think you can draw general *language* performance conclusions. &gt; so throwing the C interpreter in there [Cint](http://shootout.alioth.debian.org/gp4/benchmark.php?test=all&amp;lang=cint&amp;lang2=ruby) &gt; Can you describe the features of C++ that are... I haven't profiled the code. &gt; the relative performance advantages of C++ over C in a practical setting? Earlier you answered a question with - "It's a huge practical difference. It just has nothing to do with performance." In a practical setting are you still making an arbitrary distinction between language and library?
&gt; "Exactly" as an answer to "What is the performance of a library that can't be used?" just opens up a world of misunderstanding. I'm sorry, but I thought your question was pretty illuminating all by itself. &gt; A specific set of comparisons between the fastest programs implemented in each language. Evidently not, because when I poked around I found faster programs in the same languages. &gt; How do you know one of the other 3 C k-nucleotide programs doesn't pack data in the same way as that C++ k-nucleotide program? I don't, but that is beside the point. Whatever the performance merits of that approach, they'd be the same for C and C++, so it doesn't make sense to compare programs that are using it with those that aren't. &gt; What makes you think you can draw general language performance conclusions. I don't think that you can. mebrahim is the one making that implication, citing your site as proof. I have problems in particular with the latter implication. Again, I'll ask and emphasize it because you seem to have missed it: **do you agree with the mebrahim's implication that these benchmarks indicate anything meaningful about the relative performance advantages of C++ over C in a practical setting?** &gt; Cint Sorry, I should have said the specific benchmarks linked to hold the compilers/runtimes constant. &gt; I haven't profiled the code. You don't have to profile the code to get a sense of what features could possibly explain such a huge advantage (indeed, profiling might not prove enlightening). &gt; Earlier you answered a question with - "It's a huge practical difference. It just has nothing to do with performance." I was referring to the fact that there are technical advantages beyond merely runtime performance. If there weren't, we'd probably still be writing in assembler. &gt; In a practical setting are you still making an arbitrary distinction between language and library? I am making a distinction between the language and standard libraries vs. specialized libraries written in said languages for purposes of making generalized claims about the performance of the languages. If some language has a library with awesome performance for solving problem X, that is great for people trying to solve problem X. It really has little bearing on people trying to solve problem Y, particularly if the reason for the win in the library was a function of the skills of the library writer rather than intrinsic properties of the language. It is even more pointless if you have a benchmark which is entirely measuring performance differences between two different arbitrary libraries, neither of which is the top performer available. &gt;&gt; It is an educated guess. &gt; There isn't much point bothering about your specific claim while you're guessing instead of measuring. I'm trying to assert merely that you can't draw a conclusion from those benchmarks because there are differences in the algorithms used by the program. I might be right that the algorithmic differences explain the bulk of the performance differences, and I might be wrong. The fact that both angles are possible would seem to be conclusive about my assertion. I can't believe there is this much debate about a basic scientific principle.
So did they get it right? (Given that this talk happened two years ago.)
You can keep using C++. Try Wt http://www.webtoolkit.eu/wt
&gt; Evidently not, because when I poked around I found faster programs in the same languages. Wrong. That program wasn't on the website the first time you looked. "The ones that the original poster linked to" now shows that program. As I said, and as the website said - "comparisons between the fastest programs implemented in each language". &gt; I don't, but that is beside the point. Obviously you had a mistaken impression - I'll see what I can do to make it clearer that those may not be the only C++ or C programs that were measured. &gt; they'd be the same for C and C++ If the assembler is the same then it's the same algorithm? &gt; do you agree with the mebrahim's implication I haven't looked at his comments, but "indicate anything meaningful about the relative performance advantages" is so vague and subjective that there shouldn't be a problem answering either yes or no. &gt; I am making a distinction between... And it's an arbitrary distinction. For "generalized claims about the performance of the languages" you don't seem to have completed any argument why that shouldn't include "performance for solving problem X". The fact that it may have little to do with "problem Y" may also be true for many of the things that you would include as part of the language and standard libraries. 
&gt; Obviously you had a mistaken impression - I'll see what I can do to make it clearer that those may not be the only C++ or C programs that were measured. I'm not sure there really is anything you need do on that. I think the problem was with how it was linked to. &gt;&gt; they'd be the same for C and C++ &gt; &gt; If the assembler is the same then it's the same algorithm? Again, this doesn't mean the assembler as to be the same. We're talking about some pretty big multipliers in terms of performance differences here. If an algorithm is giving C++ a 2x win, you can be sure it will provide C roughly a 2x win as well. The code will look different, but the performance will be roughly comparable. &gt; I haven't looked at his comments, but "indicate anything meaningful about the relative performance advantages" is so vague and subjective that there shouldn't be a problem answering either yes or no. He literally linked to that page and said "I believe C++ is faster than C". If you don't think it is a yes or no answer, feel free to elaborate. &gt; For "generalized claims about the performance of the languages" you don't seem to have completed any argument why that shouldn't include "performance for solving problem X". The fact that it may have little to do with "problem Y" may also be true for many of the things that you would include as part of the language and standard libraries. Language implementations can demand some intrinsic overhead regardless of the problem you solve (provided you don't go to insane lengths to get around it). Intepreted languages have the overhead of their eval loop, you have memory management overhead, function/method call overhead, etc. You can measure these things (indeed, there is a benchmark for C++ that rather precisely measures the overhead of a lot of the language features that differentiate C++ from C) and they tend to apply to all cases. You also can have overhead based on the quality of the optimizer. Now, if I have a really slow language implementation, I can provide primitives/libraries that allow it to do certain things very quickly. If those are general computing tasks, then to a certain degree, that will effect all tasks similarly. However, if I have a library that provides primitives for say image processing that allow it to perform significantly faster than it otherwise would, then the outcome of benchmarks that use those primitives would be misleading in terms of drawing conclusions about the performance of non-image processing tasks.
I've been writing web apps in C# .Net for 2 years and almost the same for php, I am still doing my best to get better at C++, but my problem is almost opposite of yours, I want to write something in c++, but I already know how to do it in some other language and I find learning new languages in general fascinating. But even though I wish I could do everything in c++ and never touch another language ever agian, I've never seriously thought about writing web apps in c++, at most I'd write back-end modules in c++ that php or python or whatever then call when needed. I'd say try something, you might end up liking it anyway...
&gt; I think the problem was with how it was linked to That's normal - someone will jump into the middle of these comparisons and decide what they are in 15 seconds. I can't change how other people link to the pages - I can change what people see when they reach the pages. &gt; If you don't think it is a yes or no answer As you might have guessed from this discussion - I would ask what he meant by "C++ is faster than C" - there seem to be a lot of assumptions packed into that little phrase. &gt; then to a certain degree It's an arbitrary distinction. Look how much hand-waving is involved once we stop talking about the performance of specific programs and try to say something more general.
Actually I had mentioned Wt in my description! Thanks anyway.
It makes sense to avoid the singleton in those cases in particular. Chances are you want to test abnormal conditions of those hardware devices at some point using some kind of mock class. Singletons can not be mocked (nor reinitialized easily as you often need between tests).
If it is implemented the way the article describes it is next to useless as a means to achieve easy concurrency. Using a fixed size threadpool you can only run pure functions in it without risking deadlocks when all threads are busy running consumers while the producer is waiting for a thread to become available in the empty threadpool.
&gt; strict (NO side effects) and has lazy evaluation. No side effects is called pure. Strict is the opposite of lazy evaluation.
I think we are in violent agreement.
LMAO, sorry. details details, who pays attention to any of those anyway?
Does that alter your view of *those benchmarks* ?
The benchmarks in question... I still think they proved little, and in general I think the pursuit of your site is interesting but far from definitive.
I like unittest++ (a.k.a. unittest-cpp) because it is simple and introduces very little overhead for creating unit tests, which helps encourages unit testing. The project page may be found at: http://unittest-cpp.sourceforge.net/
&gt; The benchmarks in question... I still think they proved little Difficult to know if you mean regex-dna &amp; k-nucleotide or you mean any of the tasks on that website. Is there some benchmark that would prove? Is there some benchmark that would be definitive? 
&gt; Difficult to know if you mean regex-dna &amp; k-nucleotide or you mean any of the tasks on that website. Actually, those benchmarks are fine (the specific code samples I had issues with, but those have since been replaced with faster ones). I'm not sure they are good for measuring overall relative language performance, but they seem fine for measuring the performance of those types of tasks. The SPEC benchmarks were pretty good for testing system performance. Sure there were ways to rig them but for the most part they managed those relatively well. Language benchmarks are challenging to do something meaningful. I think your site is pretty well done, just that you are tackling a tough nut.
&gt; to do something meaningful I'm just not sure whether you're all the way to saying all languages benchmarks are just silly - or whether you'd like to hold on to some and say "I sort-of approve these language benchmarks!" ;-) The primary motivation for the benchmarks game was simply to show working programs in more than the usual languages. The secondary motivation was to grab attention away from the drip-drip-drip of 6 line fibonacci programs masquerading as C - Java - Python performance rankings (badly- done perhaps meaningless measurements *versus* well-done perhaps meaningless measurements). Apart from that - what someone takes from the benchmarks game is mostly to do with what they bring to it and what they are looking to prove. If they bring a fixed idea they want to prove then they are likely to claim they have found data to prove that fixed idea. If they are less invested in some particular idea they may find data that challenges what they had thought. They are surprised how fast Java can be; they are surprised how slow the slowest scripting languages can be; they are surprised how fast the fastest scripting languages can be. 
I saw the three of them at a 3-day C++ conference in Boston 8 or 10 years ago and it was fantastic. If my schedule allows it, I'm going!
You can overload operator() with multiple arguments, but operator[] can only take one argument AFAIK.
You could theoretically support a syntax like array[i][j] = 42 by using proxy objects. But that can get quite complicated. Using operator() instead is indeed recommended.
It does only take one argument, but you can get around that restriction by abusing `operator,` to coalesce two values into one. This sort of clever trick is best avoided imo.
The C++ FAQ Lite has a [section devoted to this question](http://www.parashift.com/c++-faq-lite/operator-overloading.html#faq-13.11).
have array[row] return a pointer to the row then [col] will index into the row pointer.
Heh, I played with exactly that after learning Cg/HLSL. ie. vector3(2.0, 4.0, 2.0)[\_x,\_z] * vector2(0.5, 0.5) == vector2(1.0, 1.0)
 #include &lt;iostream&gt; struct A { struct subscript_proxy { subscript_proxy(int index) : _index(index) { } int operator[] (int index) { return _index + index; } int _index; }; subscript_proxy operator[] (int index) const { return subscript_proxy(index); } }; int main() { A a; std::cout &lt;&lt; "a[0][2] = " &lt;&lt; a[0][2] &lt;&lt; ", a[1][-1] = " &lt;&lt; a[1][-1] &lt;&lt; std::endl; return 0; }
&gt;subscript_proxy Thanks. The level of my C++ proficiency is archaic. With this push in the right direction I should be able to accomplish the task at hand.
Something like this should work. Just have operator[] return an array of lower dimension. template &lt;class T, int D, int N&gt; struct array { array&lt;T, D-1&gt; data[N]; array&lt;T, D-1&gt;&amp; operator[](int i) {return data[i];} }; template &lt;class T, int N&gt; struct array&lt;T, 1, N&gt; { T data[N]; T&amp; operator[](int i) {return data[i];} };
As does the [FQA](http://yosefk.com/c++fqa/operator.html#fqa-13.11).
Am I too much of a nerd if I say you should make it a struct or else it isn't good for much?
This would be great if you changed it to instead refer to the famous boxer, **Muhammad** Ali, well known for this very quote.
Then he wouldn't be able to *function*
You should learn your C++...
It's the same name is Arabic. All of these are different transcriptions of the original arabic word.
That's why people stray from C++ all right, the terrible lack of features.
Bad science. [The author cherry picked a slower serial Haskell version that would scale better when parallelized](http://flyingfrogblog.blogspot.com/2010/01/naive-parallelism-rebuttal.html) and backported only those optimizations that preserved that scalability. There is nothing "naive" about that. He obviously went to great lengths to parallelize the Haskell efficiently but not the C++. 
Actual explanation from the author [here](http://poorlytyped.blogspot.com/2010/01/multi-core-laziness-doing-less-in.html).
Where he admits that he had tried to parallelize the fastest Haskell version first but that those results undermined the conclusions that he wanted to draw so he pretended they didn't exist =&gt; cherry picking. &gt; It is ugly... So he happened to choose a version that would parallelize well with only those backported optimizations that would parallelize well over the fastest version because the fastest version was "ugly"? Give me a break. &gt; It's not robust. It stack-overflows with the default settings on 12 levels of spheres, but actually Jon knew about that already. In other words, he silently dropped the fastest of the original Haskell versions because it did not give him the results that he wanted. He fell back to a non-trivial combination of optimizations from the fourth and fifth versions that were specifically designed to give him the results he wanted and then pretended that he had naively arrived at those results. [His original article](http://poorlytyped.blogspot.com/2010/01/haskell-ray-tracing-parallel.html) *only* studied 9 levels of spheres in the parallel case and, yet, he had already rewritten the Haskell. So stack overflows on 12 levels of spheres could not have been his motive. &gt; It performs worse at anything except 9 levels of spheres Not true. He started off citing [my rebuttal](http://flyingfrogblog.blogspot.com/2010/01/naive-parallelism-rebuttal.html) that had already illustrated performance results where Lennart's original version 5 is faster than the new optimized serial code with *11* levels of spheres. The same is true for 9 and 10 levels, where the old code is up to 24% faster. On 14 levels of spheres, Lennart's original version 1 is a lot faster than his new code. So the serial performance of his code was clearly not the reason he chose it. &gt; On 13 levels of spheres it eats all of my memory. Which contradicts his original conclusion that HLVM "used exorbitantly more memory than the other implementations". In reality, HLVM uses less memory and runs faster than his Haskell in that case. His excuses are clearly not self-consistent. He obviously went to great lengths to rewrite the Haskell in order to make it amenable to parallelization and then pretended he hadn't, and then cherry picked his results to make Haskell look as good as possible. 
&gt; His original article only studied 9 levels of spheres. http://poorlytyped.blogspot.com/2010/01/haskell-ray-tracing-parallel.html has a graph with 12 levels of spheres in it.
precision from &lt;iomanip&gt; is only for output. consider the possibility of determining the location of truncation by moving the decimal point. think about the problem from the angle of NOT hunting down some standard library function to do this for you. if you move the decimal point, you should be able to specifically decide where the rounding occurs, then you can just undo any changes you might have made before the rounding step.
That was my idea too. off the top of my head: //Fill in this line of code yourself since its homework. But you don't have to take my word for it, go run it yourself. Just like the reading rainbow. I'll see you next time. EDIT: fixed my line of code.
 static_cast&lt;double&gt;(static_cast&lt;size_t&gt;((tax+0.005)*100))/100;
considering this is a person's homework, i was trying not to give the answer away, but instead let this question be a learning experience. he didnt ask for the answer, but suggestions. i want to thank the people who have thus far managed to give fully working solutions instead of leaving it as an exercise for the OP.
I didn't realize it was homework, but I should have. I edited out the solution.
Do you consider memory allocation to be an acceptable singleton?
Why are you not using the built in malloc (new in C++, different keywords in other languages), or your OSes build in functions for memory? There are good reasons not to use the built in memory allocation functions. However those reasons are rare in the real world. Short answer: each case needs to be considered separately, including the alternatives, goals, and assumptions. When you do this you discover singleton is almost always a mistake - but not always. Generally (but not always) there is a better way to solve your problem that doesn't involve a singleton. 
I wrote it this way thanks #include &lt;iostream&gt; #include &lt;cmath&gt; #include &lt;iomanip&gt; using namespace std; int main(void) { double salestax=.06; double price = 1.63; double cost = salestax * price; cout&lt;&lt; cost&lt;&lt;"\n"; cost+=.005; cout&lt;&lt; cost&lt;&lt;"\n";; int intprice = cost * 100; cout&lt;&lt;intprice&lt;&lt;"\n";; double trueprice = intprice/100.0; cout&lt;&lt;trueprice&lt;&lt;"\n";; double finalprice = trueprice + price; cout&lt;&lt;"The final price with tax included is "&lt;&lt; finalprice&lt;&lt;"\n";; }
yeah its better to learn then cheat...
Cool. My idea was something along the lines of: float final_price = price + (floor(price*(sales_tax+.005)*100))/100.0; 
This is similar to [Froglogic Squish](http://www.froglogic.com/pg?id=Products&amp;category=squish&amp;sub=editions) except 2400EUR cheaper. A welcome alternative.
This might be a good starting point: [Rounding - Wikipedia](http://en.wikipedia.org/wiki/Rounding)
I've just started using cxxtest for a project I'm working on. So far, works great.
just don't! especially if you need to create your own rules. I switched to scons and people are very positive about google's hammer system (scons-based toolset as I understood). 
Very interesting.
More useless than useful ...
In short: C++, despite its best efforts, fails to provide useful abstractions to enable C to be used effectively by programmers. Let's extend C in our own way to provide useful abstractions to enable C to be used effectively by programmers. Surely it is easy and that explains why C++ failed.
This is just what C++ needs. FINALLY.
so many downvotes .. is it the Stockholm-syndrome talking?
What a waste of time. Why does an article called "Prefer Futures" only spend less than one page (out of 3 total pages) actually talking about futures? I don't know if the kids are still using this expression, but the whole thing looks like Herb Sutter literally "phoned it in." "Hey, Herb. Our regular columnist has the flu and we're short an article. Can you just pull something out of your ass quickly? Nah, you don't need to write it down. Just give me the details and I'll have ArticleBot 3000 stretch it out so it looks authentic."
This advice makes sense for compute-bound tasks on a multicore/miltiprocessor architecture. It makes bad sense for io-bound tasks. Using futures as described in the article means that a thread has to be allocated for the duration of the task's execution. For most io tasks, that is completely unnecessary.
Depends. If the code is very UI-heavy, then the tradeoff of creating a separate thread to do the i/o versus a simpler interface and having another library handle all of the boilerplate for you may well be worth it. For example, a menu item may trigger a very long process (let's say, parsing some huge input file). Generally you don't want such procedures to block the UI, so you put it into a separate thread and wait for the result, then update the UI accordingly. Most users would gladly accept a slight increase in resource consumption if it means the app doesn't appear to "freeze" while this is happening.
I don't think I explained my point very clearly. Most io operations involve sending a command out some hardware, and then doing nothing until an interrupt arrives and you read the response from the hardware. In the case of disk io, you send a read command to the disk controller, and then block. When the data is ready from the disk, the CPU gets an interrupt, the data is delivered to RAM in some way, and then the kernel can unblock your read operation. The same applies to network io, full web services, and so on. So the thread that was doing the disk io just sat there for 99.9999% of the time, doing nothing. It was blocked. The begin/end asynchronous model allows you to avoid that waste. You 'begin', which sends the read command to the disk controller. Then your thread continues on and does other useful work (maybe UI stuff). When the driver determines that the data is ready for you, it will indicate that by signaling an event or issuing a callback of some sort. Then you look at the data and do stuff with it. At no point did you have a thread allocated that was just blocked, waiting, doing nothing. The 'futures' model can't so easily accommodate *true* asynchronous operations.
Certainly nice to know. But it's also noteworthy that C++0x will support explicit conversion operators to solve the same problem. GCC 4.5 already supports those, actually.
Wow, just looking at that gives me a migraine.
Move the definition of area below the cin&gt;&gt;radius bit. When area is instantiated, it's value is set to 3.14159 * 0.0 * 0.0; it's not changed just because radius changes at a later date. Or just declare "double area" at the top, then set area=pi * radius * radius after the cin.
#include &lt;iostream&gt; using namespace std; int main() { const double pi(3.14159); double radius(0.0); cout &lt;&lt; " Enter radius: "; cin &gt;&gt; radius; double area(pi*radius*radius); cout &lt;&lt; "The area of the circle is: "; cout &lt;&lt; area; cin.get(); cin.get(); return 0; } You need to calculate the are AFTER they have inputted the radius....
Why thank you, kind sirs/madams. I appreciate the speedy and helpful responses! have an upvote!
I could be wrong, but you should be declaring variables like this: double radius = 0.0; Also, just a tip for when you start getting more than one value, always clear the input buffer before asking for more input. You could end up with some garbage which will crash your program, and you won't know why. cin &gt;&gt; radius; cin.ignore(1000, 10); //This works, or just cin.ignore() Last tip: If you are trying to get the user to input a name or something with a space, use getline(cin, variable); it is not required to clear the buffer in this case. (IIRC)
ah, thanks. can I ask what (1000, 10) specifies?
The first number signifies the amount of characters to ignore, the second signifies which character to stop at (10 happens to be newline, also "\n")
ah, ok. thanks!
Seconded.
[tarball](http://www.softwarepreservation.org/projects/c_plus_plus/cfront/release_1.0/src/cfront.tar.gz).
This is the same idiom Boost's shared\_ptr uses. I first learned about it from there and found it to be a rather clever idea.
&gt; programming jokes like this Programming jokes? I've seen even more awesome code out there, and the people using it were dead serious. Is it for the faint-hearted? No, of course not. Is it considered good practice? I don't care if you believe it or not, but [it is now](http://www.boost.org/doc/libs/1_41_0/libs/format/index.html). All you old C programmers should not fight it, but give in to the madness, for there is hope - when the stars are right and the project shattered, the Elder Managers will rise and eat us all.
I feel the most important reason to learn other languages is that languages are not just a different way of accomplishing a task (sometimes a better way), but also a different way of *thinking*. Learning a new language makes you step out of your comfort zone and look at problems from a different perspective. This is almost always a good thing and improves your problem solving ability in the language of your choice as well. I try to pick up a new language every year two for primarily this reason. 
Looks like more homework questions. Very seriously. And someoone who doesn't undersand procedural programming. You probably should use stack overflow for these type questions.
I find compilers very hard to understand.
Hold on a minute! How did they compile the program!?
The page on Boost.Exception provides good advice on designing exception hierarchies. In general, it is good to make exceptions independent of a particular library, module, or implementation; for example, it is better for users to catch an IOException or NetworkException instead of a POSIXSocketConnectCallFailedException or the like. It is also a good idea to be consistent with existing, standard exception classes; for example, exceptions should derive from std::exception and should include an appropriate overload of "what()". See also the advice at: http://www.boost.org/community/error_handling.html
The only good reason I can think of to have different classes of exceptions is if you are going to want different behaviors in the try blocks, or for the different exceptions to be handled in different places. For instance, if you have some classes of errors that would result in retrying (maybe a network error, for example) or some exceptions which would result in log output and termination, or a type of exception that would result in moving on to plan-B. Otherwise there is little reason to waste your time over-designing your errors. Just use the most appropriate from the ones in the standard library. In my group we use one class of exception, catch it in every function to append to the error, building a stack trace as we go.
Look at the places in your code where you would expect to catch exceptions. There's no sense catching an exception if you can't do anything about it, so you should consider the places where you *can* do something about it, and ask yourself what it is you need to know. Off hand, I can think of three reasons for catching an exception: * Cleanup or rollback of actions taken. * Error recovery and reattempts. * Reporting failure to the user. For the first case, you probably already know what to do regardless of the exception (e.g., delete temporary files, cancel a database transaction), so you will probably just rethrow the exception as is. If you're really sensible, you're acquiring resources on the stack and they're being released automatically, so you don't need to catch the exception at all. I highly recommend learning about [Resource Acquisition Is Initialization](http://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization) if you haven't already. You may find yourself writing fewer try/catch blocks. For the second case, you only need to know more if there's something you can do about it. If you can do something about it, try to figure out the minimum amount of information you need to pick a course of action. For example, for an out of space error you could clean up any temporary files you created and don't need anymore. If you still got an out of space error, you wouldn't be able to do anything further, so you wouldn't handle it there. This tends to be where you have your most specific exceptions, to help you distinguish between the cases you can handle and the cases you can't. For the third case, you probably don't need to know anything about the exception, as long as it includes a way of generating a human readable message. If you're subclassing all your exceptions from `std::exception`, then you would overload `what()` to provide a key to an error message lookup table. By the time an exception gets passed back to the user, there should only be one question to answer: Is the application still in a usable state or not? If so, carry on, otherwise rethrow the exception so you can get a stack trace. By the time the exception has reached this level, you should not be attempting further cleanup or recovery. If you were designing a non-interactive program like a server daemon, this would be where you would log the error and decide if continuing to run could cause harm (most likely). So, as you can see, the only place where you tend to really care about the type of exception is where you (the programmer) can do something to recover from it. That should inform your choice of where to catch exceptions and what types of exceptions you should be throwing. If your library is throwing exceptions, try to avoid repackaging them in your own exception classes unless you really have something useful to add. If you do create your own exception to repackage an existing one, make it a subclass of the one you're repackaging, so that code which would catch the original exception will still catch your new one. For example, if you catch a `std::ios_base::failure` exception and repackage it as a `out_of_space_exception`, then `out_of_space_exception` should be a subclass (or some sort of descendant) of `std::ios_base_failure`. That way, if you realize you really can't do anything about freeing up space, you can rethrow it and it will behave the same as if you'd never tried to handle `out_of_space_exception`s in the first place. Word of advice: All your exceptions should be descended from `std::exception`. Don't `catch(...)`. At the most generic, `catch(std::exception&amp;)`.
This isn't a help forum (unless it's a really interesting question). Take it to stackoverflow.com
Yes, you are the only one. This is basic C (not even C++).
Yes. Arrays are not pointers. Arrays are second-class citizens and decay to pointers the first chance they get, but are still distinct types. The type of "abc" is char[4] (an array of 4 chars), and not char*, for example.
Ha, that's what I get for using STL containers all this time.
It's worse than that: #include &lt;iostream&gt; using namespace std; void foo(int arr[10]) { cout &lt;&lt; sizeof(arr) &lt;&lt; endl; } int main(int argv, char** argc) { int arr[10] = {0}; cout &lt;&lt; sizeof(arr) &lt;&lt; endl; foo(arr); return 0; } BTW, you can circumvent this with typedef and references: typedef int arr10[10]; void foo(arr10&amp; arr) { cout &lt;&lt; sizeof(arr) &lt;&lt; endl; } int main(int argv, char** argc) { arr10 arr = {0}; cout &lt;&lt; sizeof(arr) &lt;&lt; endl; foo(arr); return 0; } 
The typedef is actually unnecessary. The syntax for array references is a little funny, though: #include &lt;iostream&gt; using namespace std; void foo(int (&amp;arr)[10]) { cout &lt;&lt; sizeof(arr) &lt;&lt; endl; } int main(int argv, char** argc) { int arr[10] = {0}; cout &lt;&lt; sizeof(arr) &lt;&lt; endl; foo(arr); return 0; } Outputs: 40 40
I find the typedef about, oh, 1,000 times easier to grok. :) But, your point is taken. Array types in C are just wonky. Something like 'int[10] arr' would have made a whole lot more sense. To me, at least. But, I always put the "*" next to the type as well, not next to the variable, where it binds. 
Well at least you can admit your incompetence, I appreciate that! Oh and I hope you've never written anything people actually use. Thanks!
You don't need to worry. I never used sizeof with anything but primitives. I appreciate your concern... 
I like having lots of definitions on one line, and putting the \* next to the id keeps me from thinking that the \* applies to all objects int* a, b, c; // creates an int pointer a, and two ints b and c int *a, *b, *c; // creates three int pointers
If you have ever learned/coded ASM for any CPU/MCU, you would know that there is no such datatype called array (from the point of CPU/MCU). You just manipulate some pointer to access any data on that specific memory region that you call 'array'. As C is the portable assembler, it behaves the same...
Except in some older versions of STL it was safe to do a vector.resize(n); &amp;(*vector.begin()); and some not. *That* sure is fun to encounter when cleaning up legacy code.
What happened to OpenCL?
Firstly, sorry you had to put up with all of the *know it all*s who contribute nothing to the discussion; it's good to see interesting dissections of the language and tools and I'm glad you wrote this post because it prompted me to recall and discover some other interesting facts. &gt; **int arr[10] = {0};** Just for the sake of pointing it out, you could simply write: int array[10] = {}; &gt; **Apparently, these are two different types. Using typeid:** &gt; **std::cout &lt;&lt; typeid(arr) &lt;&lt; std::endl; // shows A10_i** &gt; **std::cout &lt;&lt; typeid(pArr) &lt;&lt; std::endl; // shows Pi** Firstly, it is [perfectly valid](http://www2.research.att.com/~bs/3rd_issues.html) to use `'\n'` instead of `std::endl`, [the only difference](http://www.cplusplus.com/reference/iostream/manipulators/endl/) essentially being that `std::endl` flushes buffered streams (so it might be slower); according to the C++03 standard, the effects of the `std::endl` manipulator are the following (where `os` is a `basic_ostream`): &gt; Calls `os.put(os.widen('\n'))`, then `os.flush()`. [Even more interesting](http://www2.research.att.com/~bs/3rd_issues.html) is the fact that the C++ standard provides `std::endl` only through the `&lt;ostream&gt;` header, so it is actually non-conforming to refer to `std::endl` without including that particular header file, a fact that few implementations enforce and that few people know (even some of the example code in the C++ standard just includes the `&lt;iostream&gt;` header to use `std::endl`). Secondly, your code is not correct because `&lt;&lt;` is not defined for what `typeid` yields; it gave me compile time errors and should be: std::cout &lt;&lt; typeid(arr).name() &lt;&lt; '\n'; // shows A10_i std::cout &lt;&lt; typeid(pArr).name() &lt;&lt; '\n'; // shows Pi &gt; **array[3] is syntactic sugar for *(array + 3).** I was reminded of another interesting fact: Array indexing is not necessarily just syntactic sugar for pointer arithmetic; in C89 and ISO C++ (presumably fixed in the 2003 'second edition'), it is apparently non-conforming to take the address of the one-past-the-last element of an array: char vc2[200]; copy(&amp;vc1[0],&amp;vc1[200],&amp;vc2[200]); // arguments 1 and 2 are non-conforming. However, it can be made legal for even older standards by transforming the last line to use pointer arithmetic instead of subscripting: copy(vc1,vc1+200,vc2+200); [According to Bjarne Stroustrup](http://www2.research.att.com/~bs/3rd_issues.html): &gt; It is a surprise to most experienced C and C++ programmers that `&amp;vc2[200]` isn't completely equivalent to `vc2+200`. In fact, it was a surprise to the C committee also and I expect it to be fixed in the upcoming revision of the standard. (resolved for C9x - bs 10/13/98). (this means that the example was ok in K&amp;R C, in ARM C++, an error in C89 and ISO C++, and ok in C9x - a thorny issue). I'm assuming this is fixed in ISO C++03, which brings me to another interesting fact. According to section 5.2.1: &gt; A postfix expression followed by an expression in square brackets is a postfix expression. One of the expressions shall have the type "pointer to `T`" and the other shall have enumeration or integral type. The result is an lvalue of type "`T`." The type "`T`" shall be a completely-defined object type.56) The expression `E1[E2]` is identical (by definition) to `*((E1)+(E2))`. That all sounds very confusing (especially the "one of the expressions" bit), but the generality is clarified by section 8.3.4: &gt; Except where it has been declared for a class (13.5.5), the subscript operator [] is interpreted in such a way that `E1[E2]` is identical to `*((E1)+(E2))`. Because of the conversion rules that apply to `+`, if `E1` is an array and `E2` an integer, then `E1[E2]` refers to the `E2`-th member of `E1`. Therefore, despite its asymmetric appearance, **subscripting is a commutative operation.** Woah! That means the following is valid C++03 code: #include &lt;iostream&gt; int main() { int a[] = {0,1,2}; // The following 2 lines are equivalent: std::cout &lt;&lt; a[1] &lt;&lt; '\n'; std::cout &lt;&lt; 1[a] &lt;&lt; '\n'; // The following 2 loops are equivalent: for (int i=0; i&lt;3; i++) std::cout &lt;&lt; a[i] &lt;&lt; '\n'; for (int i=0; i&lt;3; i++) std::cout &lt;&lt; i[a] &lt;&lt; '\n'; } The C99 standard also allows this commutativity. According to section 6.5.2.1: &gt; One of the expressions shall have type "pointer to object type", the other expression shall have integer type, and the result has type "type". &gt; ... &gt; A postfix expression followed by an expression in square brackets `[]` is a subscripted designation of an element of an array object. The definition of the subscript operator `[]` is that `E1[E2]` is identical to `(*((E1)+(E2)))`. Because of the conversion rules that apply to the binary `+` operator, if `E1` is an array object (equivalently, a pointer to the initial element of an array object) and `E2` is an integer, `E1[E2]` designates the `E2`-th element of `E1` (counting from zero). Here is equivalent C99 code: #include &lt;stdio.h&gt; int main() { int a[] = {0,1,2}; // The following 2 lines are equivalent: printf("%d\n", a[1]); printf("%d\n", 1[a]); // The following 2 loops are equivalent: for (int i=0; i&lt;3; i++) printf("%d\n", a[i]); for (int i=0; i&lt;3; i++) printf("%d\n", i[a]); }
Wait. What the fuck is `typeid`. ! Why have I never seen this before! C++ you so crazy!
Well, you're asking this in /cpp so I'm going to get beaten on for this, but... consider c++ again. For all its good points (it has plenty) C++ has a massive semantic overhead. You're going to spend plenty of time wrestling with problems which are related to programming in C++, rather than being directly related to your particular problem. If nothing else, I suggest moderating your C++ feature usage. Start with C, maybe with classes, maybe with the STL. Then concentrate on your application and don't use more features until you are sure you need them. 
I agree in principle with your recommendation. But I've worked with far too many developers who got to the "C with classes" stage and never went any further than that--even when it would've made their life easier just to spend a few minutes learning something new. It's a slippery slope.
Okay, new enough that I might be confused about this, but lemme see if I am getting you straight. You're telling me rather than attempting to conquor C++ in all of it's complexity first, start off with the more rudimentary C, move up to the Standard Template Library, uhm, that was what the C++ basic library was taken (loosely) from, right? ...before finally moving on to C++... am I close?
Or, for Cuda enthusiasts, [Thrust](http://code.google.com/p/thrust/). 
What makes this even more crazy is it works with constants as well. 5[a] is valid construct. Go C!
I have a suggestion. [MIT OpenCoursware](http://ocw.mit.edu/OcwWeb/web/home/home/index.htm) One of the big things when learning something new is the very question you're asking. Which direction should I take? What should I focus on? What should I focus on next? There's more than one good answer to these each time you ask them along the way. There's also some pretty horrid answers that some very educated people will give you as well. This is where MIT courseware comes in. The courses are the same ones taught to their students and come with all auxiliary materials. The way they do it at MIT is not "the one true way", but then that doesn't exist. However, you'll be given the very advice you're asking by some of the best computer scientists, engineers, and mathematicians in the world. P.S. If you don't want to learn to be a *computer scientist*, but are just interested in learning "a language" you can just skip into the 101 etc courses on cpp. Also, I've noticed from a few of the courses that MIT often uses a language like Python to teach methods, algorithms, etc. 
No. Use C subset of C++ and take C++'s features step by step.
True, the other side of the coin is that I've worked with far too many developers who wanted to use bits of C++ that were cool and new and funky. 
As cayennext said, start with C++ but don't use all the features. You can survive perfectly well without having multiple inheritance on your exceptions classes. Indeed ignore exceptions (for now), restrict operator overloading to really obvious cases (math routines, strings), etc. I would also avoid C arrays (use std::vector instead) and use std::string instead of char*. 
Start by learning C. Then learn (at least) how to read assembly. Learn how to make your compiler put out assembly that you can read. Pick up both a decent C++ book and a copy of the C++ standard. Avoid templates for a while, until everything else is pretty solid.
I would suggest the opposite of what a lot of people are telling you. Don't treat C++ as an extended C. Learn C++ from the beginning. Koenig and Moo's book "Accelerated C++" is a great start. Learn the standard library. Don't try to memorize the API, but understand the concepts. Also, learn about Unicode and the different encodings early. I would also learn design patterns simply because it aids communication among programmers. For example, singleton or factory as a concept means something. The exact implementation details are less important from a communication point of view. There are millions of lines of C++ out there to look at. I wish I could recommend some well written C++ projects. Perhaps somebody else can recommend some accessible C++. Oh yeah, Qt is fantastic. Wish I could use it rather than MFC in my current job. If you end up needing a GUI, take a look at it. And Python works very well with C++ too. Edited for clarity.
Or [Ct](http://techresearch.intel.com/articles/Tera-Scale/1514.htm), or [TBB](http://www.threadingbuildingblocks.org/), or [MPI](http://www.mcs.anl.gov/research/projects/mpi/), or [OpenMP](http://openmp.org/wp/) ...
If you are interested in Indie games and want to add a 3d twist, you could try Crystal Space: http://www.crystalspace3d.org/main/Main_Page When I was younger I worked on a game with it and I can credit my C++ skills to those years.
Can I assume you mean "Go C (but not C99)!"? :)
&gt; Don't treat C++ as an extended C. Learn C++ from the start Best advice in this entire thread... The single biggest lesson I learned back when I was getting to grips with C++ is that C++ supports several different approaches to programming. If you want to write C with a few better bits, you can do it, but you will be accepting the awkwardness of C++ without taking advantage of its power. Likewise, if you try to implement pure OO designs in C++, you will be wasting opportunities. Some general thoughts that might help the OP: - Study the basic mechanics of constructors, destructors, automatic local variables, exceptions, and the RAII idiom. Understanding how these elements fit together will bring a lot of insight into the design of the language and how to make best use of it. - Study the basic design of the standard library container/iterator/algorithm system. Use containers and smart pointers instead of arrays and raw pointers. Use standard algorithms instead of raw loops when the algorithm is clearer. But never feel obliged to write awkward functor classes and use standard algorithms when they add more complexity than they are worth. - Learn to write basic templates to represent generic containers and algorithms, such as those in the standard library. - The `const` keyword is your friend. References are usually better than pointers if you don't need an explicit concept of `NULL`. References and `const` are probably the most practically under-used tools in all of C++. - As a rule of thumb, if you write the `new` keyword outside of a constructor, there is a fair chance you have just made a design error. If you write the `delete` keyword outside of a destructor, there is a near-100% chance you have just made a design error. When you understand the advice in the earlier comments, you will know why. - Be aware of more advanced topics. Beware of more advanced topics. Clever tricks are almost always more trouble than they are worth in the long run. Leave them to people writing libraries, and use libraries where the APIs are simple even if the implementations use PhD-level rocket science behind the scenes. - Shy away from using any combination of language features that does not have clean semantics, such as using function templates together with function overloading or class templates together with inheritance and virtual functions. - A good library is worth a lot. A bad library has a net negative effect compared to just doing everything by hand. MFC is a bad library. The standard library also has many bad parts, e.g., I/O streams and the `string` mess. 
I wish I would have learned lisp sooner.
This is really great advice. I would also recommend looking into the Boost library. I'm especially fond of their smart pointer library. &gt; Be aware of more advanced topics. Beware of more advanced topics. This is also good advice. Awareness is something that you need to develop continuously. The line between common and advanced topics moves a great deal over time. There are a lot of people out there that will give advice based on the state of compilers 10 years ago. Stuff that was once considered advanced or dangerous due to poor compiler support is now mainstream and well supported. Scott Meyers books on C++ are fantastic as are his presentations. If you get the chance to hear him speak somewhere, go!
The best C++ stuff I did was where somebody else wrote the code. I wrote the program documentation first. This approach changes everything, and for the better, I think.
As others have mentioned, Scott Meyers' books are great. [Effective C++](http://www.amazon.com/Effective-Specific-Addison-Wesley-Professional-Computing/dp/0201924889), [More Effective C++](http://www.amazon.com/More-Effective-Improve-Programs-Designs/dp/020163371X/ref=pd_sim_b_1), and [Effective STL](http://www.amazon.com/Effective-STL-Specific-Standard-Template/dp/0201749629/ref=pd_sim_b_1) are all excellent. Apart from Meyers I also recommend [C++ Coding Standards](http://www.amazon.com/Coding-Standards-Rules-Guidelines-Practices/dp/0321113586/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1264787111&amp;sr=1-1) by Sutter and Alexandrescu (don't worry, Alexandrescu doesn't try to make your brain explode in this one, it's almost entirely pragmatic tips). And of course there is the classic [C++ FAQ Lite](http://www.parashift.com/c++-faq-lite/) and its "companion" [C++ FQA Lite](http://yosefk.com/c++fqa/) which provides a nice alternative look.
Be careful with C++ literature and courses. C++ is more than 30 years old and it changed quite a lot until it became an ISO standard in 1998. C++ programming style changes regularly with people finding new ways to use existing language features (especially templates) and new ways to avoid pitfalls. And in the recent years C++ started to change again due to the upcoming revision of the ISO C++ Standard (called C++0x) That's why there are so many outdated courses, books and tutorials! Maybe you should look into the new book from Stroustrup called [Programming -- Principles and Practice Using C++](http://www2.research.att.com/~bs/programming.html) which is "an introduction to programming for people who has never programmed before." If you made your first few steps and minor programs with C++ you should definitely read Effective C++ and Exceptional C++ (which is based on this series: http://www.gotw.ca/gotw/ ). Don't just start to use third party libraries! Try to focus on the language first (except maybe parts of boost. But some boost libraries are very complex and might be too much in the beginning). But be careful with MFC, WinAPI, DirectX, OpenGL and similar libs (in fact all Gui libs) they usually do some strange things and that might confuse you in the beginning (like in believing that MFC is a sane design which it isn't!) (But on the other hand I'd recommend to start with using the C++ standard library from the beginning. Especially stuff like std::string is much better to use than char arrays)
Great advice. &gt; Use containers and smart pointers instead of arrays and raw pointers. I do think it's important to fully understand proper "manual" memory management before embracing smart pointers though. Otherwise leaks like the ones that can arise while using an unnamed temporary shared_ptr are pretty easy to introduce. I think knowing the Rule of Three is important too. &gt; Learn to write basic templates to represent generic containers and algorithms, such as those in the standard library. While I was learning I found doing this was very beneficial. Implementing a container himself just so he can get a better feel for how they work behind the curtain reveals a lot of the apparent magic containers have. Implementing a linked list container and a vector will make it perfectly clear why erasing an iterator invalidates other vector iterators but not linked list iterators. This, of course, assumes he doesn't know about the traits of the standard computer science data structures. If he does this is still a good exercise in how to implement a templated interface. &gt; Be aware of more advanced topics. Beware of more advanced topics. Clever tricks are almost always more trouble than they are worth in the long run. Leave them to people writing libraries, and use libraries where the APIs are simple even if the implementations use PhD-level rocket science behind the scenes. This is why I only use part of Boost. Boost Lambda is cool but I'd only use it regularly if I were a masochist or was paid by how many cryptic error messages I could introduce into a codebase.
Get into game mods and modding, since that seems to be your motivation. If you want to learn more about the engines, start by getting into a graphics mode and get your own PutPixel() working. Yes, and as other posts have pointed out, C is not C++. They are different languages. As much as people try to relate the two you will be better off treating them as apples and oranges. 
When I first learned C++, coming from C, I was scared of the STL and of templates in general. Whenever I looked into documentation for this it all seemed incredibly complex - hierarchies of iterators, policies, adapters, traits, specialization... The cryptic error messages didn't help. So I just went with what I knew from C and made my own linked lists, safe array containers and so on. But in retrospective it was a mistake, don't go that way. It's actually pretty easy to use the STL and templates at a basic level, and then incorporate more advanced techniques as you learn.
Whatever turns you on
Can I ask what's wrong with the string and I/O streams? Im pretty new to C++ and I dont want to get used to using faulty objects.
Choose a different language before it sucks you in. It will make you a much happier person.
The string support in standard C++ is a bit of a design-by-committee exercise, which unfortunately means it doesnâ€™t really do anything very well. For example: - There are no immutable string and string-builder types, just a mutable string. - The interface on the `basic_string` template behind the `string` type is a bit arbitrary: it awkwardly half-overlaps the other standard library containers and algorithms, and has all kinds of extra template parameters that Iâ€™m not convinced anyone ever uses. - Although there is also a `wstring` type for a sequence of `wchar_t` characters, there is no serious Unicode support. As for I/O streams, my biggest peeve with them is that the way they use the `&lt;&lt;` operator for output streams forces what should be data about the order of elements into code. Consider these different approaches generating a string to display in a user interface: str &lt;&lt; "The " &lt;&lt; something &lt;&lt; " goes between the " &lt;&lt; something_else &lt;&lt; " and the " &lt;&lt; other_thing &lt;&lt; "."; tmpl = "The {0} goes between the {1} and the {2}."; str = format(tmpl, something, something_else, other_thing); Now consider what happens when the order of words and placeholder terms in your template string needs to be one of seven different variations, depending on which of the 10 international languages you support is in use. With a placeholder version, you just send all the strings off to the translation agency in a text file and back come the new versions, from which you can easily choose at run-time. With the C++ I/O streams version, you... well, frankly, you probably give up on I/O streams and find a library that does it like just about every other programming language and library in the known universe. Likewise, chaining together input terms with `&gt;&gt;` is a weak substitute for the regular expressions (or indeed full-on parser libraries) provided by many other languages today. 
I second this, particularly the Qt part. Don't be afraid to know C and compare it to C++ tho, you won't mess up anything up I think, the two are really different.
C++ is a poor first language. The cool kids are doing Python now, but I could make cases for C, Lisp, Scheme, Java, and JavaScript. C++ is insane. Many working C++ programmers don't understand what's really going on. C++ is also very powerful, and can enable some awfully clever things. Some more awful than others. If you're really not going to go work with Python for a while first, you should start with any decent textbook, and then work through Scott Myers' stuff. Beware of anyone who tells you that templates are bloated; they are, but they are a reality now. Exceptions are a fact of life, too, and must be dealt with to use any of the Standard libraries. But get a good knowledge of pure C, and keep in mind, C is pretty close to the reality of the computer, and C++ is just an abstraction on top. Go learn Python (or perl or whatever else you like) anyway. Scripting languages are too useful not to have in your repertoire. Good luck! 
Templates, design patterns, boost, Loki. Not necessarily in that order.
This could be the worst advice here, never treat c++ as more advanced C, that's like saying java is a more advanced form of bytecode. The power of C++ is that it is adaptable to any type of programming architecture you want to throw at it, just be prepared when you have to get your hands dirty applying them. C++ is not a poor first language, it's all about how you go about learning it, if you go at it with the structural programming approach you'll fall flat on your face, but if you approach it with a Computer Science background and know what algorithms and data structures to apply to a problem, then you are pretty well off. That's why C++ is the bane of a lot of developers existence, with the quick 6 month intro to programming degrees you miss out all the theory and have no idea what to do with the tools given to you and are completely lost when you have to decide for yourself. That being said, if the OP has no software engineering background, then yes, C++ is probably a very poor choice, would be much better to use something like flash or silverlight, where you can focus on the visuals and add as much or as little code as you need (as the author mentioned they wanted to make games). For myself, C++ was my first language back in the 90's when I was trying to make games in highschool, and I loved it (and still do). It's truthfully a great language to learn with because you actually need to know how data structures work, but you probably have to have a pretty sadistic mind to want to know that in the first place.
Let me elaborate on that, specifically the templates part. When you first start using them, they will invariably blow up with cryptic and frequently misleading error messages. Eventually, you will probably want to rip out your hair and destroy your computer with a fire ax, then hunt down everyone who worked on your compiler of choice and bring them to justice. This is perfectly normal. Resist this impulse, don't get discouraged, and eventually you will figure out how to make templates work correctly. Once this happens, you will be left with an absolutely wonderful tool. tl;dr: Don't learn templates on the job when there is a deadline. You may spend days watching them cause compilation errors. They are awesome, however.
This might just be what I am looking for. And you couldn't be more correct in having a focus. I will give these a look, thanks.
Thanks for all the pointers. I found [Accelerated C++](http://www.acceleratedcpp.com/) online. Seems they have the whole book published on the web. That will be nice. As far as Qt or MFC go, I don't think I'll be needing any of that for a while. And when I do, hopefully I will have an educated opinion on it by then. Right now I am inspired by Win32 Console games such as Dwarf Fortress and MUDS and such. I'm also looking at doing some programming for the Wii Console which of course has it's own set. But I think anything graphics involved are pretty far off. Thanks again.
Nice I will give it a look. I looked into things like Dark Basic, and promply decided that they we a bit...tailored and wanted something a but rudimentary. But anything that will point me in the right direction is certainly appreciated.
What order in your learning sequence did you wish you had learned it? How necessary do you think it is to learn for game programing in C++ that will involve a one person, possibly two person team?
Can you give me an example of this? I think what you are suggesting is similar to how I learned to script. By documenting others examples, then picking them apart.
Thanks. All this is currently added to the library. Right now I am taking on the 2004 Dummies book on C++. It seems to be doing well, but I will probably cap off at least another three to five beginners books to get different perspectives on what each author thinks is important. Or at least until I am grasping the concepts well enough to only need to skim the material.
The advice about the age of C++ and the datedness of the tutorials involved I have begun to figure out myself. It's made me to where I am more influenced by recent work rather than dated work. Unless of course, something dated is strongly suggested. The Programming -- Principles and Practice Using C++ as has the Exceptional C++, you aren't the first to suggest the Meyers books, so I already have a decent amount of those in the list already. As far as third party libraries. I'm still a little new to know exactly what that means, but as far as things like MFC, WinAPI, DirectX...etc etc... I won't be touching such things for a while. My first applications will most likely be written with ASCII graphics in the win32 console, and then possibly the Wii API when I decide to jump up to something graphical. But that's all tentative, as I haven't gotten close to that point yet. I won't be going heavily into the GUI, or even basic graphics for a while. Although you aren't the first to lambast MFC. Thankfully I won't be doing this professionally, and won't be forced to use it. And I probably won't. People have already suggested superior alternatives. Though so far I have received conflicting opinions on the C++ Standard Library. I will probably take that in the same stride as the books I am reading suggest so far. Edit; corrected spelling error.
While I am very interested in games, I am really not as interested in the engines for them all just yet. But what you say rings true of solid advice. As I said to others, this is essentially how I learned scripting. As for the C to C++ comparison there seems to be quite a few conflicting opinions on this. But if it's anything like learning Spoken Languages, or Musical Instruments, learning one *always* helps with learning another. Although I think you're right. I'm interested in learning C++ and I might as well tackle the ins and outs of it now, as I am not interested in C at all.
Bleh, trust me, I wish I had something more than a scripting background to come from. Luckily it gives me a basic idea. The most programming I did was in high school back in the 80s, and of course the few attempts I've made to get into it since then. But both of those other two times I didn't have a reason or purpose. I have that now, along with the drive, which is essential.
Suggestions for an alternative? Reasons why not to choose C++? This statement is very vague. Sucking me in is what I want it to do. And I seriously doubt it will affect my happiness either way. Anyone who is made unhappy by programming needs to evaluate their life, not the language they program in.
Thanks, this is a little vague, as I am too new to really know exactly what you are talking about, but I will keep it in mind.
Your sentiment seems to be a popular one. I'm certainly going to try to tough out C++ either way. But learning another scripting language like Python or Pearl will definitely be on the list. It also seems spot on that things like Templates, Exceptions and Standard Libraries are a pain, but necessary. I noticed people don't really like them that much, or speak negatively about them. But even as a beginner, it rings true that they are what they are, and they are needed. The Meyers books seem to be popular. With all the suggestions I've received for them so far, I've moved them to the front of the list, and they are next in line after I finish the one I am on. Thanks again.
http://www.extremeprogramming.org/rules.html
Also consider that people that are entusiastic about C++ vote up stories like [this one](http://www.reddit.com/r/cpp/comments/au1sq/the_safe_bool_idiom_learn_how_to_validate_objects/). You might want to consider if that is a reasonable way to spend your time. Also read [this](http://gigamonkeys.com/blog/2009/10/16/coders-c++.html) for some expert opinions on C++
I spent my entire programming career not knowing about this (Although it's pretty obvious in hindsight), then about 1 year ago it started getting posted everywhere. Now I see it posted somewhere about once a week.
Thanks, added to the library.
It's still not *his* name
lol I just noticed I got down voted for suggesting MIT is a good source of educational information. o.O
Perhaps this is an example of the [Baader-Meinhof phenomenon](http://www.reddit.com/r/psychology/comments/asqun/the_baadermeinhof_phenomenon_occurs_when_a_person/).
Herb Sutter does a great job taking apart std::string [here](http://www.gotw.ca/gotw/084.htm).
Sorry, that was a poor attempt at humor. I've been programming for 15 years and I still love every minute of it, and majority of that time I've been writing C++. The reason that I don't recommend C++ is that it has not aged well and has become a patchwork of features that really aren't well integrated with each other. Additionally, with the lack of built in garbage collection and modern programming features, it takes mountains of code to create anything robust and useful. Mo code, mo problems. If you aren't married to C++, here are some alternatives: Python Ruby Perl C# Java D If you must learn C++, I agree with some the others in here. Don't bother with C at all, it will only teach you bad habits. Start off with modular programming and get a hang of the syntax, and then study OO and get a handle on encapsulation and polymophism. Those concepts can also be universally applied to many other languages. Templates are also a big part of C++ and pretty valuable.
I tried this approach with scripting. I learned ColdFusion first. And did nothing but regret it until I learned the older, clunkier, PHP. PHP is far more inferior than ColdFusion...but what made ColdFusion suck so bad, was it's support. The fact that it was so much less popular than PHP made me feel like a Voodoo Priest in a world of Christians. Even though it takes me twice the code to write something in PHP than it does in ColdFusion, the popularity difference drove me away. In otherwords, all the other problems caused by it being the underdog were well more considerable than the fact that PHP has not "aged well". While I appreciate the advice, and will surely keep it in mind, for the same reason that 95% of the applications I use on my computer are written in C++, I will be sticking with C++. Thanks.
Where threads are relatively expensive, you are probably right. Naturally, the usual answer of it depends applies here. But the point of the article wasn't about **when** to use threads. This article is concerned with abstracting away the details of asynchronous functions **after** it's already been determined that having a thread is a worthwhile tradeoff. IMHO, this seems like a clean way to define asynchronous functions in terms of types and results instead of as collections of functions. Maybe with another layer abstraction, you could solve your case mentioned above without using threads. A factory to create these futures could match a resource policy and create async IO futures that don't use threads.
Meyers, Meyers, Meyers. Well written, heavily indexed, all of his books are worth buying. Boost.org is a good place to go after you finish your first project and are itching to rewrite it. A lot of the libraries will seem pretty esoteric at first though until you start using C++. Since you mentioned games, I suggest looking into http://www.libsdl.org/. I think codeblocks has a "create SDL project" too.
&gt; But it's also noteworthy that C++0x will support explicit conversion operators to solve the same problem. I'd say that explicit conversion operators don't quite solve the problem: They only enforce a more obvious syntax for what is essentially the double-bang trick.
For those who don't want to bother with the typedef: #include &lt;iostream&gt; using namespace std; template&lt;class T&gt; struct id { typedef T type; }; void foo(id&lt;int[10]&gt;::type &amp; arr) { cout &lt;&lt; sizeof(arr) &lt;&lt; endl; } int main(int argv, char** argc) { int arr[10] = {0}; cout &lt;&lt; sizeof(arr) &lt;&lt; endl; foo(arr); return 0; }
Chris_Newton covered most of the issues, read his reply first. &gt; I/O streams They overload "&lt;&lt;" in ways that on hindsight are confusing. At the time they did this because they were essentially the first to have the concept that you could change the meaning of language symbols in your code. They then said "cool", and went wild, overloading &lt;&lt; to mean something completely different from bit shifting. Only after several years of practical experience did people start to realize that this is more confusing than it is worth. Symbols need to have exactly one definition otherwise you get confused. There are a lot of things in C++ syntax that make the language more confusing than it needs to be. They should have made streams use a function call, which would make everyone's code clearer. Using + to mean string concatenation as most languages do is a bad idea as well - it only works because every does it so you don't forget.
&gt; How necessary do you think it is to learn Essential. Not because you will write your programs in LISP (maybe you will, maybe you won't), but because LISP forces a different way of thinking on your. Then you bring that way of thinking back to C++ and your programs become better. If you never do LISP, odds are you will never discover those ways of thinking - they are not natural in C++. That isn't to say they are hard to apply, just that the language makes it very hard to see that way of thinking. Once you start to think that way it is often very simple to do in C++ - often easier than the more natural way of thinking. The above applies to more than just LISP. A great programmer needs to know LISP, and assembly (doesn't matter which CPU). Those are the minimums, each has some things to teach you. You really should expand that list. (Perhaps Erlang to learn distributed programming, or Haskel to learn side effects free programming)
I completely agree with these two comments. Accelerated C++ is an amazing book (even for a professional C programmer, or someone who's played with C++) before.
it's in C which is already exist on that time
&gt; Explicitly passing around an object for the device you want to use is generally better. Often this is done by having a container object that just contains the objects in use for this particular run Great idea. And there is a chance that you only want one of these container objects. Rather than pass it around everywhere, why not make it available as a static getter method. Say Context.getInstance() maybe? 