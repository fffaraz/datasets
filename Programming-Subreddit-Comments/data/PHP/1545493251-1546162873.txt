You're the one popping up out of nowhere saying "my opinion is law". The only argument I need against this is "no it's not". Also, would you cut it off with the repulsive condescending attitude? 
Well here's something slightly more helpful. PHP and HTML are not "two separate concerns", they're two separate languages. PHP was originally intended to augment PHP to generate dynamic server-side content, and it's still fine with that (some might argue, but it does the job). Don't separate languages, separate concerns. Concerns being: 1. Something holds the state and business logic (PHP a.k.a. model) 2. Something lets the user view and interact with the app (PHP + HTML a.k.a. view). 3. Something wires together the model and the view (PHP, a.k.a. controller)
Classic Tanks. For everyone else watching, this is one of his standard approaches. 1. Tanks opens with an insult: "pmjones will materialize and start whining" 2. I respond with affectionate dismissal, since he does have some valuable things to say sometimes. 3. Tanks replies with further insults and accusations: "so far up your ass", "repulsive condescending attitude", "condescending prick", etc. And for the record, the research and arguments that lead to ADR are all well-documented, from primary sources. Others can read about it at &lt;http://pmjones.io/adr&gt;. Merry Christmas to you too!
&gt; For everyone else watching Barely anyone one "is watching" you sad man. This is buried under a bunch of negative score hidden comments. The only one who thinks they're putting up a big show for the crowds here is you. Stop trying to play amateur psychologist. &gt; And for the record, the research and arguments that lead to ADR are all well-documented, from primary sources. Others can read about it at http://pmjones.io/adr. And he links to himself again, of course. For that extra "primary sources" credibility. 
&gt;Come on. You cannot beat the simplicity of the regular while($row =$stmt-&gt;fetch()) &amp;#x200B; This will trigger **100.000 queries**; mine solution is at least 100 times more efficient because of bulk loading. &amp;#x200B; Do the math. &amp;#x200B; &gt;It's time to remember the great KISS principle KISS doesn't mean slow and inefficient. &amp;#x200B; &gt;[unbuffered queries](https://phpdelusions.net/pdo#mysqlnd) to the rescue &amp;#x200B; I don't think you even understand generators and my answer and are thus suggesting these subpar solutions from 15 years ago. Clearly you didn't work with large data sets. I have, and I would never resort for slow and inefficient solution that **just works;** I wan't fast solution as well that will not require me to increase memory limits or similar patching. &amp;#x200B; Again; writing generator is very simple. I populated 100 million rows with **no** increase in memory once the script started. And it was the slowest way possible because I intentionally used Doctrine entities instead of SQL. &amp;#x200B; You can't reject modern solutions because you don't understand them. Give them a try; they are super powerful once you understand the idea and far simpler to use than iterators (PHP 4). Or ask yourself; why every language has iterators? Do you think they were made for LOL's or because smart people that make programming languages understand the need for simple processing of large datasets?
&gt; I'll never ever stop telling you you're full of it, I suppose everyone needs a mission in life. &gt; It ain't a thing. It's a thing; cf. some of the links at https://github.com/pmjones/adr/blob/master/MENTIONS.md (You can have the last word on this particular thread if you like.)
I personally prefer Symfony. But you are asking easy? I'm gonna have to say laravel. As much as I would tell you to try Symfony when you get comfy - I think you will have a much easier time picking up Laravel, especially if you pick up a sub to Laracast for a month. It just holds your hand a bit more and abstracts away some of the work away from you that you can get into later if you want to. 
&gt; You can have the last word on this particular thread if you like. Here's a better idea. Let's make this thread our last thread ever, because honestly I don't care for you showing up and peddling me your off-brand MVC wares every time I say "MVC". I buy original.
I care
I second Slim, perfect for rapid development.
&gt; This will trigger 100.000 queries; I don't know where did you get that but you seems do not understand how the basic API works. Please do realize the difference between a query and a fetch. Either way, what is more hilarious is that you seem to take your generators as a sort of magic wand that magically retrieve the data from a database without accessing any resource. Well, time for the harsh truth: **every wonderful innocent generator has a dirty, filthy, out of fashion while loop under the hood**. Which means the by slandering old good while/fetch loop you are slandering generators as well. You seem to be obsessed with generators in a sort of religious way and this casual discussion is like a Holy war for you. Well, I am of a more practical stock, I prefer to use a tool, not worship it. Cheers.
Maybe this library would help you https://www.pdfparser.org/documentation 
Yeah. Basically how you inject or integrate your php woth html. Especially when calling ui components from code.
&gt;I don't know where did you get that but you seems do not understand how the basic API works. Please do realize the difference between a query and a fetch. I do. &amp;#x200B; And it is not that I religiously follow the church of generators, it is that you religiously discard them because you don't understand them. &gt;**every wonderful innocent generator has a dirty, filthy, out of fashion while loop under the hood** &amp;#x200B; No, it doesn't. It has inner iterator, not the while loop. Read the docs.
What would the difference be between this and the pretty “standard” vlucas/phpdotenv package?
&gt; Now you're acting out, as far as I see it, from a position of a fanboy who got upset because someone doesn't cheer for the same things. Personal attack, no need for that. But if you go that way, one could say that you sound like the old symfony fanboy who got upset because your framework of choice isn't the next rad thing people like. Look in the mirror... --- &gt; Yes. As I've mention, service locator pattern does not provide much room for configuration. Unlike actual DI container, where dependencies are injected, Laravel container services requests for it's dependencies. First of all it's anti pattern in it's core, you can read more on it by Martin Frowler in his articles on DI IoC. Utter bollocks, read martin fowler again, you've clearly missed some things in your knowledge. You sound more and more dogmatic tbh. https://martinfowler.com/articles/injection.html 
Coming from Laravel to a .Net backend, I felt pretty much at home, for what it's worth. 
I keep seeing this posted around. Laravel is not based on Symfony. Laravel *uses* low level Symfony-branded components like HttpFoundation, but it no no way resembles Symfony the *framework*. 
I don't know what you mean by UI components. Even when I'm developing a standard application that has the whole HTML rendered server side by PHP, it is limited to templating only, like the example I gave on last reply. Sometimes the templates are split in small reusable blocks, but I don't use PHP for UI components more than that. Nowadays I'm actually more inclined to not take this approach anymore, and prefer to have PHP responding for JSON APIs and have the interface in Javascript as Single Page Applications. I'm still confused by what you're really asking.
You're just amusing :)
What personal attack. I'm expressing what impression you leave me with, I'm not making conclusions about your character based on it, so please don't try to victimize yourself. What rad thing? I do have experience with both. Laravel and Symfony. I do work in my company with Symfony, however I do some contract work with Laravel to. &gt; Utter bollocks, read martin fowler again, &gt; I've often heard the complaint that these kinds of service locators are a bad thing because they aren't testable because you can't substitute implementations for them. Certainly you can design them badly to get into this kind of trouble, but you don't have to. Runtime errors over compile time errors. You gonna defend that it's just as good? Really, are you going to make that claim? Laravels implementation falls down under this. I'm tired of explaning point by point way if you're not willing to investigate yourself. There are lot of resources for it, example just one of them: https://stitcher.io/blog/service-locator-anti-pattern 
I am not a native speaker and sometimes find hard that some of my questions are misunderstood. I will work on it but this is a good exercise for me since you did not understood the right problem. I will post the exact story on a different thread so I can take the right approach. The idea is to take decisions in the UI based on some backend data. 1. A/B testing on showing components. Example show this section A and the other B to the customer if he is on certain "host" or if he clicked on different button. 2. Show different texts based on the hours. 3. Show different picture based on cookies. These are just some feature requests. What i need is the cleanest way to control this from php without injecting it and sepparate the concerns as much as possible. I usually don't write all the problems since want to keep the research as clean and not biased by my dark thoughts about code and data.
&gt;I will post the exact story on a different thread so I can take the right approach. &gt; &gt;The idea is to take decisions in the UI based on some backend data. &gt; &gt;A/B testing on showing components. Example show this section A and the other B to the customer if he is on certain "host" or if he clicked on different button.Show different texts based on the hours.Show different picture based on cookies. &gt; &gt;These are just some feature requests. What I am referring as Components in HTML is sections/widgets/buttons The idea is to take decisions in the UI based on some backend data. * A/B testing on showing components. Example show this section A and the other B to the customer if he is on certain "host" or if he clicked on a different button. * Show different texts based on the hours. * Show a different picture based on cookies.
I’ve used both and for me it comes down to VSCode is a text editor and PHPStorm is an IDE. I’ve saved myself so much time and work refactoring a code base with PHPStorm, it’s too good not to use even though it’s expensive and clunky UI. It’s still gets the job done better than anything else on the market for me. 
&gt; I'm expressing what impression you leave me with, I'm not making conclusions about your character based on it, so please don't try to victimize yourself. I'm not that dude, look who you are responding to... And don't kid yourself, it was a way to publicly diminish his opinions based on his persona. &gt; Runtime errors over compile time errors. You gonna defend that it's just as good? Really, are you going to make that claim ? What's the real difference in PHP. It still will blows in the face of the user, interpreted language and all that... In Java and the likes, sure, but even then, runtime error are what TDD is for. You mentionned martin fowler, I'll mention uncle bob [Type wars](https://blog.cleancoder.com/uncle-bob/2016/05/01/TypeWars.html)
Not my intention. Sorry, difficult to keep track of all the buzz sometimes :) It will blow less often. Why you think typescript is a thing and growing fast?
I see. That explains it. But I can't really contribute to the thread then. I have no experience with this.
&gt; Why you think typescript is a thing and growing fast? Because it catches errors at compile time. I'm all for Typescript. But unlike php it has a compile/build step before getting uploaded to the server/users. When the compiling happens makes all the difference to me. But php doesn't have that. &gt; And there is no evidence to my knowing of TDD preventing prod bugs (if you have it, please share) more than writing tests after you actually developed the feature. Although it's a neat exercise. I sure I read some but tbh, I didn't keep the links, and those are often from TDD evangelist, so I'm still reserved. Uncle bob defo will have some, even if he is too dogmatic for me some(more than some)times. But while I said TDD, I should have said automated test suit. Before or after dev, I don't care, but it's your only way to catch runtime bugs (except manual testing...) &gt; runtime error are what ~~TDD~~ Automated test suit is for
&gt;I'm still waiting for clean solution of common the real life problem I've proposed while maintaing same entity / data structure accross the board and not introducing more complexity in code. For a currency object like you propose I would be using an immutable, plain-PHP value object and using an AR entity to persist it when necessarry. I'm not sure I understand why you think it would be such an issue to do in a clean manner? It would be a similar amount of code to Doctrine, but I wouldn't be tied into the boilerplate for the majority of much simpler entities that compose most applications. The data-heavy applications I was referring to feature things like records from sensor arrays that return hundreds of different measurements of water chemistry, air quality and lighting amounts (with individual data points often being made up of more complex parameters than a single value, with information on the state of the sensor itself when the value was collected and confidence intervals). &gt;Yes. As I've mention, service locator pattern does not provide much room for configuration. Unlike actual DI container, where dependencies are injected, Laravel container services requests for it's dependencies. First of all it's anti pattern in it's core, you can read more on it by Martin Frowler in his articles on DI IoC. I get the feeling that you're not actually familiar with Laravel. The Laravel container *can* be used as a service locator, but it's generally discouraged and the documentation pushes constructor and method injection. For example the first code example in the documentation demonstrates injecting a repository from the container: public function __construct(UserRepository $users) { $this-&gt;users = $users; } The documentation then goes on to explain how to configure more complex bindings for injection, how to decorate bindings, etc. Conversely, I have seen far more supposedly professional Symfony code that calls directly into the container in controllers and elsewhere, rather than injecting services. The following is far more common in Symfony controllers in my experience. $logger = $this-&gt;container-&gt;get('logger'); &gt;Both can be useful, but to say Laravel scales as Symfony does is bollocks. Sure you can gut the framework, but will it be Laravel when or custom repurposed framework? Choosing not to use facades and properly architecting your business logic isn't gutting the framework. That's ridiculous hyperbole. Laravel scales fine.
&gt; But php doesn't have that. Service container of Symfony does.
I’m a self employed developer, focusing mainly on PHP for many years. If you are thinking of getting work in the PHP world and earning the most money is your aim, as well as building your own site, then here is what I’ve found. The highest paying jobs I’ve had by far have been those using Symfony framework. It’s by far the most trusted framework amongst the higher end of your potential client base. Symfony 4 is also a lightweight framework out of the box, and pretty much replaces Silex. You can then add to it as your needs change. After Symfony it’s Laravel. There are probably more Laravel jobs going around, but they tend to be small to medium sized clientele or startups . They pay less but still well and Laravel has less of a learning curve. Wordpress and Magento jobs are usually the lower end of the scale, but there’s a seemingly endless amount of work in these areas. I’d personally stay away from frameworks like Codeigniter and Cake. Hardly any work using them and they are firmly rooted in the past.
Symfony is the name of two different things and makes this a bit confusing. Symfony is a collection of components (auth, validation, orm, routing, etc). The Symfony Framework is a framework built entirely from those components.
You cannot use plain values with money, there is no such concept as money without currency, you'll need to use few libs even to read values from money objects. However you need to persist plain values. Sure if you're making small app, which is localized in one country with very few currencies you can get away. For payment processors for example that's simply not an option. You must support more to even negotiate deals with banks. What boilerplate? Doctrine is not more verbose than Eloquent. It's actually even faster to set things up with it. But it's not as straight forward to learn for people generally, and is more feature rich, stuff like discriminating tables, which is not common requirement, however, sometimes proves as a life saver for SQL dbs. Big part of it, is that Eloquent is database-first solution, meaning you have to define migrations yourself which is a major time sink. &gt; I get the feeling that you're not actually familiar with Laravel. Yeah, and javascript has classes, because there is class keyword. Really? Have you looked how Laravel is wired internally? I mean, that's the problem why I get frustrated. People who do not know how their tool work, make general claims about how great it is. &gt; $logger = $this-&gt;container-&gt;get('logger'); That's terrible. :D probably was written by Laravel developer. /joking. 
I would argue that one of Symfony's major pluses over Laravel is the *lack* of perceived 'magic' and that there is adequate documentation to do advanced stuff with it. 
I would not go that far I do plenty of serious ML work (as in deriving \*serious\* value) in PHP right now TensorFlow adds CPU, GPU, and TPU multithreading as well as symbolic auto differentiation (autodiff) which makes building and deploying large scale deep learning systems easy and scalable These systems will become more prominent in the future but they are overkill for the problems that your average business faces today
Thanks a lot man! I really work very fast and eficient with NetBeans/PHP because I know it for more than 10 years I think. &amp;#x200B; A couple of days ago my NetBeans 8.2 stopped working because of some crash. I cannot create or open any project, just work on the opened ones. &amp;#x200B; It is strange because "the only" things that might have produced that behavior is a change in my laptop's hardware, adding ssd disk and more ram. &amp;#x200B; Anyway I've got NetBeans 9 working now with PHP, so thanks very much. Looking forward to see official PHP integration into new versions of Apache Netbeans, or else, I guess I'll have to continue looking for another IDE.
I agree (disclaimer: I hate Laravel).
You use a design pattern such as [Model-View-Controller](https://www.sitepoint.com/the-mvc-pattern-and-php-1/) that separates your logic from your output.
I am using workerman. An asynchronous event driven PHP framework for easily building fast, scalable network applications. https://github.com/walkor/Workerman
active record, globals, facades ... laravel teaches you these things, they are all wrong for modern software dev
if you want to do things properly with symfony you more or less just read the label. If you want to do the same with laravel then you more or less have to throw everything but the router and kernel away.
I agree with this statement from the other end of the table, as someone that (co-)defines the roles and requirements for new hires and having professional experience with a good number of PHP frameworks, CMSes and e-commerce platforms. As far as I can tell, this generally applies across the globe. Of course there will be the odd unicorn company as an outlier, or an area that is more dominant and well paying frameworks different to what is suggested. At the end of the day my best advise normally is to stick with what you love and prefer, as long as it pays the bills and keeps you sane, healthy and happy. However, if the pay and desirability are your main concerns, you know what to do.
It's an observation, not an opinion. I've watched people try to reinvent things that exist in other frameworks but not laravel, and do a terrible job of it. There are good and bad devs, but I'm just speaking in general.
it's a real problem. it happens every day on reddit, in this thread even.
Disclaimer he didn't make : He wrote it.
If it's disclaimers you're concerned about, here's a much more comprehensive one: http://paul-m-jones.com/code
Define "works".
&gt; No, it doesn't. It has inner iterator, not the while loop. How do you think that inner iterator is coded ? Black magic ? You should stop talking now.
* You download a csv with a list of IPv6 blocks. * You parse the csv and upload it to a database on Amazon DynamoDb. * You ask the database to return the first record that has a block ending after the given IPv6 address.
It’s a goddamn bloodbath in this thread, but this made me lol.
Templating engine like Blade, in Laravel. Ignore the idiots who tell you not to mix -- the truth is that in a complex enough app, there will need to be conditional logic in the view, whether that's handled by PHP or by a front-end language like JS.
I think you should try CodeIgniter, it is light weight and easy to learn.
there is nothing wrong with the active record pattern. Facades and some globals improve readability and accessibility quite a lot. But that's more of an opinion.
$works;
Laravel has a smaller learning curve than symfony. You also have an option to use lumen, which is great if you are building an API with something like vuejs or react on the frontend. Symfony is a great choice, but requires more configuration and upfront investment to really understand it. Laravel has many excellent packages for user permissions, jwt, and saas integrations. It is definitely one of the most "comfortable" development platforms. Special bonus for homestead, for simple local env via vagrant and laracasts (although not strictly for laravel). 
Yep - I'd say the lack of functions and the implied globals are what make WordPress so hated among devs. I really enjoyed xhp back in the day (which eventually lead me to react JS) because it made returning a rendered template from a function much easier. I'll often use heredoc syntax for it now, as I'd rather my functions return the html string than echo to Stdout. 
&gt; That's terrible. :D probably was written by Laravel developer. How can anyone take ANYTHING you say seriously when you write things like that? Just take a step back for a moment - you're advocating that Laravel is bad, to a Laravel developer, and seemingly trying to convince them (or any readers of your comments) otherwise - whilst showing little to no understanding, let alone appreciation of alternative frameworks, coupled with throwing out your own facts and making silly accusations. Not cool bro.
Really? I've always assumed Taylor Otwell had Rails background because Laravel has striking similarities with Ruby On Rails.
In this particular example where there is just one setter method there is no big reason of doing that. Returning $this, just returns the object with current state of it. If you would have multiple setter methods you could use them in chain like. `$application-&gt;setLogger($something)-&gt;setSomethingElse($somethingElse);`
Easy way to do the builder pattern. Allows you to chain calls like so: ``` $something-&gt;setFoo("bar") -&gt;setBar("baz") ```
It allows for fluent interfaces. https://stackoverflow.com/questions/5956999/what-does-return-this-mean
&gt;there is nothing wrong with the active record pattern Separation of concerns is a fundamental of building quality software. AR is the opposite of this. &gt;Facades and some globals improve readability and accessibility quite a lot No they don't, but even if they did they also make things unpredictable and impossible to test. &gt;But that's more of an opinion. You guys are just proving my original point, laravel developers learn how to do things wrong and then evangelise poor coding practice to other new developers. 
Best answer! Thanks for the tip. This is exactly what I wanted.
DHH has a strong view of creating great developer experiences and calls out all the BS in the programming world, I think Taylor shares this with him which is why many concepts are similar. There maybe better articles, I’m sure Taylor gave podcast interviews about the background, but this seems to have some little interesting bits https://7php.com/php-interview-taylor-otwell/
Sounds plausible, but unfortunately my experience with both Laravel and RoR can't be described as "great".
It’s a pattern called telescoping and it can be used in any program to build cleaner code, but it is also an anti pattern in some eyes. 
&gt;Separation of concerns is a fundamental of building quality software. AR is the opposite of this. there are different approaches for separating concerns and make code readable. In the end just an opinion. Active record is very popular in RoR and node (sequelize) and many other languages and frameworks... &gt;No they don't, but even if they did they also make things unpredictable and impossible to test. Globals have been considered evil for decades ... i never had any problems in writing tests for a laravel app. Sure it's true that code that uses static methods in a poorly conceived way then said code will be difficult to test. Laravel has implemented static methods with due care and attention. &gt;You guys are just proving my original point, laravel developers learn how to do things wrong and then evangelise poor coding practice to other new developers. well, that's your opinion.
You've missed /joke tag?
&gt; As always, it comes down to the experience of the team and the thoughtfulness of the development process, far more than the tools the framework provide. This is what it always comes down to, however you cannot disagree that Symfony leads you down a far better path than Laravel. I don't think you'll find any new Symfony developers trying to tell you globals are a good thing (as I have from Laravel in this thread). &gt; Eloquent $user = User::find(1); // because fuck testing ... $user-&gt;id = 'laravelIsGreat'; // you can't do this in doctrine because setters and type hinting $oops = $user-&gt;id; // assigns 'lalalalalala' to $oops because magic, again not possible in doctrine because getters
&gt; there are different approaches for separating concerns and make code readable. In the end just an opinion. just google AR vs data mapper ... again you just reinforce my point that you don't know why one is better and double down on the crap that laravel has taught you. &gt;Sure it's true that code that uses static methods in a poorly conceived way then said code will be difficult to test. Laravel has implemented static facade methods with due care and attention. you can't mock statics. laravel has created another horrible hack to get around the fact that facades are a horrible hack in the first place. once again though, you would rather just double down on what laravel taught you than research why it's wrong
A couple of notes (OK, more than a couple - sorry about that): * I see no PHP version requirement in the composer.json. * There are multiple classes in a single file which is generally frowned upon in PHP. I don't think there's a PSR standard which disallows this though. * No tests means that most people will simply ignore your package. IMO you shouldn't ever release a stable version without having a test suite. I saw a line with a comment that it's for tests, but even with tests that's not the best approach. Separating the actual code and the tests would be much better IMO. * Having code like this `(isset($conf["options"]["keyName"]) ? $conf["options"]["keyName"] : "limitrr")` to me says that you either 1) don't know about new PHP 7 features (in this case the null coalesce operator), 2) are not utilizing them and writing unnecessarily verbose code, or 3) are trying to support EOL-ed PHP versions. * PHP constructors and destructors are meant to be used as void methods (no return value!) which you are ignoring. See https://secure.php.net/manual/en/language.oop5.decon.php. When using a good IDE such as PhpStorm (at least with `Php Inspections (EA Extended)` installed, not sure about the default inspections), your code would generate warnings. * I'd generally recommend against using functions such as `strval`. Simply casting to string is more readable IMO and marginally faster (you'd probably have to run it close to a million times to get a noticeable difference though). The same goes for the other conversion functions as well. * At the moment your library is very tightly coupled to Redis. I'd strongly consider removing a direct dependency by abstracting the persistence logic. That would also help to improve the testability since you wouldn't actually want to connect to Redis during the unit tests and could simply use a mock or an anonymous class that implements the common interface. * You're not using the type declarations or the strict types. Even if you don't, at least use DocBlocks. Having a method signature like this `public function limit($opts = [], $req, $res, $next)` makes the code more difficult to understand. * The readability could be improved by splitting the methods into smaller ones and using early returns instead of nesting. For example, I'd extract [this](https://github.com/eddiejibson/limitrr-php/blob/a5b0d4186c65ddf0d259a3b64830c6483bd6d53a/src/limitrr.php#L69) and [this](https://github.com/eddiejibson/limitrr-php/blob/a5b0d4186c65ddf0d259a3b64830c6483bd6d53a/src/limitrr.php#L85) into separate private methods. Perhaps something like `private function resolveIpAddress(Request $request): string`. * You're using this part `limitrr:${keyName}:${ip}:${route}` repeatedly. If you ever have to change it, you'd have to modify all of the occurrences instead of a single one. * It's generally better to avoid using the `Exception` class. You can create your own exceptions or simply use the SPL exceptions. * I'm not familiar with Slim, but I'd probably use a common interface for the middleware. Otherwise it reminds me too much of Ruby and its duck typing. * You're not using consistent returns. If the `$result` on https://github.com/eddiejibson/limitrr-php/blob/a5b0d4186c65ddf0d259a3b64830c6483bd6d53a/src/limitrr.php#L85 is not a truthy value, nothing gets returned. Either you're using a void method or not (I don't care that PHP would resolve the return value as `null` since it's a bad language design IMO). I'd also consider less array-based design approach, but that's not a big issue given the size of your library. It might make testing easier though. Looks OK otherwise, and the README is also pretty thorough. Commit history could be much better though. While I pointed to a lot of issues, some of them could be considered secondary. If I had to make any changes, I'd start with tests, decoupling of Redis client and consistent type hinting. That would be a great start and considerably improve the overall quality of the code. P.S. Also this `Better PHP rate limiting using Redis.`. Better compared to what? 
I care
Good for you, bot.
Content categorization/scoring/filtering Ad optimization Image captioning, filtering (porn, etc.) Detecting fraud transactions Recommending products or people Curating a learning journey Game A.I. Providing analytics to customers the list goes on ...
Thanks for the clarification.
I just upvote because others upvoted this.
&gt; just google AR vs data mapper ... again you just reinforce my point that you don't know why one is better and double down on the crap that laravel has taught you. yeah, I googled and used them myself. They both have pros and cons. &gt;you can't mock statics. laravel has created another horrible hack to get around the fact that facades are a horrible hack in the first place. once again though, you would rather just double down on what laravel taught you than research why it's wrong laravel went for simplicity first and facades play a major part in that role. And simplicity is always a key to better maintainability... at least for small to mid-sized apps. 
You said the query takes 10 mins to return rows. Sorry but that's like a barman having to go 10 kilometers far away each time somebody asks for a beer. Creating the needed indexes is like: hey, grab the goddamn beer supply near to the bar, but "you're not allowed to to so". Crazy.
Hello, thank-you so much for your suggestions, I agree on all of them - I'll get to implementing them right away. Glad to finally have some comments on how it could be improved, really means a lot. When you say less it should be less array-based, what else do you think I should use for passing things into the functions? I just meant better in regards to what it offers, many only allow limiting with just the amount of requests.
I've never heard it called telescoping or labeled an anti pattern. Interested to hear more. Happen to have an article/post explaining that position? I am a big fan of fluid interfaces.
Facades are one of the most widely recognised weak points of laravel, clearly you are not interested in anything but your own POV. Here is some simplicity for you: $user = User::find(1); // this is impossible to test $user-&gt;id = 'laravelIsGreat'; // you shouldn't be able to do this, eg type hints in doctrine setters will prevent it and prevent possible runtime errors $oops = $user-&gt;id; // assigns 'lalalalalala' to $oops because magic, SO SIMPLE
its not like laravel gives you all the necessary tools for testing facades... and if you don't like them you don't even have to use them.
&gt; and if you don't like them you don't even have to use them this is my issue. I do have to use them because I'm now working on the project you started ... nobody likes them when they understand the problem.
What about Rapid PHP Editor [https://www.rapidphpeditor.com](https://www.rapidphpeditor.com/)
 .
You can use something like: exec("screen -ls | grep 'server'", $execOutput); if (!empty($execOutput)) { // whatever code you want to run when it's active } else { // whatever code you want to run when it's not active }
Isn’t `exec` disabled by default, for obvious security reasons?
I don't think exec, shell_exec, etc are disabled by default. But yeah agreed they're generally frowned upon for security reasons. I'm not sure how to help OP get the output of screen easily without it, though. 
I think in this specific case there isn’t anything else you can do. You might be able to let the process that starts and stops the `screen` write out a file somewhere, like a `PID` and simply check in pho whether or not the file exists. That’d be at least a tad safer.
[Here's a comprehensive take on them by Ocramius](https://ocramius.github.io/blog/fluent-interfaces-are-evil/) (2013). Personally I think they have their value – sometimes – but he makes a solid case against them. Never heard it called telescoping though.
If you tell me what this is for I will send you my code that does exactly this.
It can also be used with immutable objects: ``` class Immutable { /** @var Foo */ private $foo; public function withFoo(Foo $foo) { $copy = clone $this; $copy-&gt;foo = $foo; return $copy; } } ``` Slightly different usage, but same basic theory: ``` $immo = new Immutable(); $immo = $immo-&gt;withFoo(new Foo()); ```
Good points, what do you say about CI, is a good one for freelancing? Thx
Well, you could use bash to update a text file with a 1 or 0, which then would be read by php.
Okay, thats working but.. I have 3 similar queries on one page about processes and when I refresh the page all at once they do this command in exec what causes that sometimes there are errors with showing online / offline, what can be done in that case? `&lt;?php` `exec("screen -ls | grep 'server1'", $execOutput);` `if (!empty($execOutput)) {` `echo '&lt;span style="color: #9abf7f;"&gt;ONLINE&lt;/span&gt;';` `} else {` `echo '&lt;span style="color: #f92672;"&gt;OFFLINE&lt;/span&gt;';` `}` `?&gt;` `&lt;?php` `exec("screen -ls | grep 'server2'", $execOutput);` `if (!empty($execOutput)) {` `echo '&lt;span style="color: #9abf7f;"&gt;ONLINE&lt;/span&gt;';` `} else {` `echo '&lt;span style="color: #f92672;"&gt;OFFLINE&lt;/span&gt;';` `}` `?&gt;` &amp;#x200B; `&lt;?php` `exec("screen -ls | grep 'server3'", $execOutput);` `if (!empty($execOutput)) {` `echo '&lt;span style="color: #9abf7f;"&gt;ONLINE&lt;/span&gt;';` `} else {` `echo '&lt;span style="color: #f92672;"&gt;OFFLINE&lt;/span&gt;';` `}` `?&gt;` &amp;#x200B; &amp;#x200B;
When you say errors, you mean there is some PHP exception that occurs? If so can you paste it here? 
If i have only 1 query on page its working fine, when i have 3 for example its showing online when its offline
&gt;P.S. I know laravel is the next big thing but I am more focused on a simple microframework /something small and fast for my needs... Next big thing? Laravel had its initial release on June 2011; (+7 years ago) See: https://en.m.wikipedia.org/wiki/Laravel
Are all 3 of them showing online when they're offline?
If [https://wiki.php.net/rfc/ffi](https://wiki.php.net/rfc/ffi) goes through then you could write this in C and run it, but exec is really the only way to do it.
When i run there is no process, but on site its online, its working in both sides, sometimes when process is offline and there is now process in grep showing online, is there other way to do this?
Yeah try this: if (!empty(trim($execOutput))) {
Also could be because you’re reusing the same variable. Try using a different variable for each ‘exec’ call or use the ‘unset’ function. This isn’t for certain, just something I though of while reading your code + responses
&gt;if (!empty(trim($execOutput))) { still the same with this function:(
Ya I meant do ‘exec($cmd, $output1)’ and ‘ if (!empty($output1))’ ‘exec($cmd, $output2)’ and ‘ if (!empty($output2))’ ‘exec($cmd, $output)’ and ‘ if (!empty($output2))’ The reason I would propose this is because once your ‘$output’ becomes non ‘empty’ it’s possible that it isn’t correctly being reset for the next time you use it and your old non-empty value still exists inside of it. While this is ugly and I wouldn’t recommend this is a production environment, this would eliminate that possibility of what I described. 
@dombrigia Could you show me how script should looks after yours changes? Im really noob but i want to do this:(
Sorry I’m on mobile. Maybe try stack overflow 
Well he's not accepting input, so how could someone exploit it? Another idea, have a cronjob overwrite the screen status to a file constantly, have the php script read that?
&gt;How do you think that inner iterator is coded &amp;#x200B; It is internal, why should I care? Just like I don't know how echo works internally. You guys should really read the docs first: [http://php.net/manual/en/language.generators.overview.php](http://php.net/manual/en/language.generators.overview.php), search for iterator. Or... maybe you know better than people who made PHP. So can you build generics, that would be really nice. 
Build if from scratch. You'll learn a lot more.
My guess is that subsequent `ls` commands are showing prior executions of `ls`. You could try grepping for `[s]erver` instead, which wouldn't recursively match the `ls` command.
If you stop playing Mr. Know It All, I'll explain where you are wrong. Deal? The example on the page you linked to is just a syntax sugar for the banal for loop. Just a way to disguise a for loop as a foreach loop. But in the heart it's the same for loop, just called differently. It is not another magic called "inner iterator" giving you the data. It's just the same for loop, while "inner iterator" just yields you its results. Generators are a trick. A disguise. A syntax sugar. They don't add any value that doesn't exist already in the language. Just a way to disguise a stream as an iterable array. But the implementation of the stream will be exactly the same. 
Similar solution, except a bash script running on a cron job every minute or so to check if it's running. That way if the screen process dies for any reason, you'll know. 
The biggest concern is really the fact that with exec enabled, if someone can manage to get their own script onto your server (through maybe a botched file upload script), they could run shell commands
Thanks for your work, it seems you spend many an hour on this.
Setup a cron job that'll output to a file on the server containing the status then use fopen on it...
if you want type information in your views you are having to already write /* @var $foo Foo */ so it's really no extra effort to functionise it as you would do with any reusable piece of code. As someone else mentioned, heredoc and returning the result of the template works well and of course short php tags and it's template syntax can make the whole thing look clean enough. You can even namespace it if you like. Now your IDE can instantly spot if a required var isn't passed to the view or if the view is outputting a var that doesn't exist in the function scope. Refactoring and consumption is easier too because the IDE understands what it's working with. Downsides are that it may not be great to pass to designers (apparently) and it requires the developers to handle escaping/encoding themselves. Personally, I am never going back to simple includes :) 
If you see the other post one day before yours, there's 10vc5, which includes PHP natively. I've since switched to VSCode. It misses a few features that Netbeans had, but it has a lot of others I appreciate.
if you want *this* level of control you definitely should go for the industry standard template instead of tinkering with a half-assed homebrewed solution. Either go for the simplest solution - includes with short tags/alternate syntax or install Twig. Anything intermediate would be just a support hell
Symfony is always a good choice but : 1. As you say it's closer to Java frameworks than .net, Laravel is probably closer to C# .net since it's creator used to be a .net developer. 2. I think Laravel is a little easier to learn at first. So for this particular request (easiest framework for a .net developer) my vote would go to Laravel instead of Symfony. 
Do you mean Codeigniter or Continuous Integration when you say CI?
React is an "industry standard" functional templating system, and i'm not suggesting anything different, just a simple functional template, no tinkering required, simple php+html :) if anything, it's simpler than php includes as you don't need to worry about scope. As always, it depends on what you're doing. I'm currently working on a 17 year old gigantic codebase so I'm very bias to solutions that work perfectly with the IDE as it saves a large amount of time in error prevention and refactoring.
You should really make your mind, whether it's "simple" or type declarations, variable tracking and such. Again I suggest you to try Twig. You will find that it works perfectly with your IDE. Finally, I appreciate your effort in dealing with the legacy codebase but in general the conditions are not that extreme. So sharing your opinion with the general audience, it's better to base your offerings on more conventional solutions. 
I'll admit it's been 8 years since i last used twig and I was never saying you should never use twig, it is definitely a good choice for certain use cases but can the IDE really integrate as well as a regular php function? For example, if I wanted to reuse some twig template can the IDE prompt for missing vars? Does it show the vars u need to inject in the first placr (this can be a lot of information). Likewise if I am outputting some var in a twig template can the IDE detect if it hasn't been injected in the controller/calling code? No solution is perfect in all situations and the OP didn't describe his use case so I was merely presenting another option (that i even warned was an unpopular one). I wish more people would present the downsides to their solutions when making suggestions, coding is always a game of trade offs depending on what you're trying to do and the time you have to achieve it 
When you need help regarding PHP try posting at r/PHPhelp. Merry Christmas
There's nothing wrong with the above. The issue you mention comes when passing variables. 
Not by default with default php installations, but a lot of cheaper hosts or shared hosts will disable it and a bunch of other functions. 
I would point out that one of the issues he raises about them is no longer the case, since PHP now has return type hints.
In that case you don't need to use exec to read from the file containing the cron script output
Oh, I get it now :). Thanks for the clarification. I use only *MC* the last couple of years, *V* can be *php-ish* templates, React, API-response, JS-whatever. 
tl;dr; The *V* doesn't have to be at any specific side. V is *the thing* users see - if it's HTML response, React, JSON or CLI output is just implementation detail.
We also have desktop apps and mobile apps and voice apps as well. Those are all “clients”. Yet you’re the one suggesting coupling all your client code logic with your API for web, meanwhile shipping every other client in a different fashion. Javascript is in a weird stage, but having a separation of a web client from your backend only makes sense. It’s what’s done with every other platform. The only difference is your ability to update the client without much or any user input (web). All other clients generally require more user action. People need to stop thinking about web clients the way we thought about webpages 10 years ago. The browser is a client rendering engine, period.
One thing you might be missing is that screen writes to a per user socket and php using a web server runs with a different user. 
I was in the same boat 2 years ago, learned as much as i could and built what facilitated me.
&gt;You cannot use plain values with money, there is no such concept as money without currency, you'll need to use few libs even to read values from money objects. I didn't say a plain value, I said a plain-PHP value object. Given your previous appeals to the authority of Fowler, surely you are familiar with [value objects](https://martinfowler.com/bliki/ValueObject.html). A fundamental concept like currency shouldn't be tied to any kind of persistence layer, and I'd include using Doctrine's annotations in that. Creating a separate entity config (YAML or XML) for a POPO Currency class wouldn't be so bad, but I don't particularly see how that is any better than the solution I proposed. &gt;What boilerplate? Doctrine is not more verbose than Eloquent. It's actually even faster to set things up with it. For simple entities there is certainly more overhead involved in Doctrine, though I wouldn't agree that Doctrine is that complex to get set up with. &gt;Big part of it, is that Eloquent is database-first solution, meaning you have to define migrations yourself which is a major time sink. Migrations are no more verbose than Doctrine's annotations or configuration files. &gt;stuff like discriminating tables, which is not common requirement By "discriminating tables" I assume you're referring to table inheritance, as in Doctrine's table discriminators. In which case, it's not particularly arduous or messy to implement in Eloquent out of the box, although generally I'd use the `tightenco/parental` package to make it even cleaner. It's not that an uncommon requirement in complex systems and I've used both approaches. Generally I'll use Parental if the system has multiple inheritances in different contexts or more complex requirements. &gt;That's terrible. :D probably was written by Laravel developer. /joking. DI it's probably most complex part of Symfony. And new people have most problems with it. Ironically, I took it from the Doctrine documentation, where they suggest using it in controllers. I have seen it in plenty of projects from agencies that solely work with Symfony, probably because it is given such a prominent place in the documentation.
Well, obviously, you don't tie it to persistence. What you generally have is a value object which is created when a field, which does not exist in the table as one field, gets requested or set. You work with one "field" which is stored in two fields in database. Now having business logic separated from database, allows this to work seemlessly. This is just basic requirement, your trouble doesn't end here, it only starts here. It's fascinating how there are people who suggest that Active Record is just as flexible as Data Mapper. It isn't, you need to look for workarounds, which gets messy and unmaintanable, not to mention testing becomes a bitch as you need to mock arguments / returns for your mocked services. &gt; Migrations are no more verbose than Doctrine's annotations or configuration files. Well, perhaps. &gt; Ironically, I took it from the Doctrine documentation, where they suggest using it in controllers. I think that's simplified example to illustrate how it works, because DI is not the point in Doctrines documentation. When it comes to DI, there are examples in XML, YML, php and annotations. &gt; I have seen it in plenty of projects from agencies that solely work with Symfony, probably because it is given such a prominent place in the documentation. I'm yet to see Laravel project which has at least 80% test coverage. Lets be honest here. Php developers in general tend to be lower grade than say C# counterparts. I'm not surprised to see bad practices everywhere. Nowhere I made a claim that people who program with Symfony are innately better developers by default. You know, that's why Laravel is so popular it's easier. It holds you by the hand, you don't need to be very thoughful developer to build something functional with it rather quickly. My guess is that's why takes such huge share of the php ecosystem. It's accessibility, but not precisely quality. And of course copious amounts of marketing.
Couldn't agree with this more. It's been my standard practice for 10+ years now. Personally I do all my rendering using an onRender function in a single-page action controller. Every variable and function used is explicitly defined either in the class instance or in the passed arguments. No nebulous reading from arrays. 
Very interesting sharing. I cannot say anything about the design architecture, it would take more time. But I'm really interested in your tooling &amp; Q&amp;A proposition. Because I fell you've put a lot of effort in it and also because I enjoyed this part recently. I'll start with what I like as a first time contributor (does not know the project): * the clear separation with unit and integration tests (autoloader-dev + separate test-suites). I liked the isolated unit tests classes for exceptions, though I would keep them under /unit or /integration dirs (and remove the error test-suite). I would not add '.spec.php' though.... I intuitively related it with Behat/BDD... a 'TextXXX.php' looks more easy. What I would add * `composer require phpstan/phpstan, phpstan/phpstan-phpunit, phpstan/phpstan-strict-rules`:) I you like have a look to a [config example I used here](https://github.com/soluble-io/soluble-mediatools/blob/master/phpstan.neon). * Add `-php: 7.3` in your .travis.yml file.... got recently a 'continue to break' error ;) What I would change * Husky and lint-staged. Yes they are helpful, I use them too... in js/ts projects. For PHP there's a wonderful initiative: `composer require --dev captainhook/plugin-composer` The dev is really reactive on issue too, but it seems quite stable now. Look at an [example config I used](https://github.com/soluble-io/soluble-mediatools/blob/master/captainhook.json). * I' really not sure about RoboFile.... To me everything can be solved with a proper composer script... An example [I used here](https://github.com/soluble-io/soluble-mediatools/blob/master/composer.json). * Same for pretty printer (less tooling, less requirements ;) * Delete '.vscode' from your repo ;) Exclude in '.gitignore' (yours looks is big ;) * API doc is cool, but don't commit the caches... and generate in a proper '/doc/api' directory. I'm expecting the doc folder to contain human style doc ;) BTW, I was looking for a good way to document for quite a moment. I'm not happy with pure php solutions, I've ended up using mkdocs and mkdocs-material... Not advertising my project but if you want you can have a look to [https://soluble-io.github.io/soluble-mediatools/video-info-service/](https://soluble-io.github.io/soluble-mediatools/video-info-service/). Afterwards I'm not proud with the content and the fancy boxes ;) but yeah... I'm a constant work in progress ;) &amp;#x200B; Also I realy like this kind a questions on reddit. Thanks &amp;#x200B;
&gt;Now having business logic separated from database, allows this to work seemlessly. This is just basic requirement, your trouble doesn't end here, it only starts here. Which is exactly what I proposed. The method I suggested works almost identically to the approach you would use in Doctrine with an EntityMapper and it isn't a workaround at all, it's an extremely basic approach that works cleanly and is easy to understand. A plain-PHP value object is easy to test and you could equally test the persistence of that object through a separate entity without any particular trouble. You are *seriously* overestimating how complex any of this is. These are basic requirements that are easy to implement cleanly with Eloquent as a decoupled persistence backend. I used Symfony for years prior to switching primarily to Laravel, I am not remotely unfamiliar with Doctrine (or even Propel, which was bundled with Symfony when I first used it). We transitioned to using Laravel for new projects over several years after the release of Laravel 5.1, deciding which to use on a project-by-project basis. However we haven't started a new project in Symfony for a few years now. &gt;I think that's simplified example to illustrate how it works, because DI is not the point in Doctrines documentation. When it comes to DI, there are examples in XML, YML, php and annotations. Sorry, I said Doctrine, but meant the Symfony documentation. It's directly from the documentation for Symfony's DI container, beneath this paragraph: &gt;What does this mean? When a service is public, you can access it directly from the container object, which is accessible from any controller that extends Controller Additionally, earlier you were complaining about how Laravel uses Facades to simplify examples. ;) &gt;I'm yet to see Laravel project which has at least 80% test coverage. Cool. I have, I've also seen many Symfony projects with little or no test coverage, I wouldn't say either community really has the advantage there. Laracasts, which seems to be recommended to every new Laravel developer, takes a tests-first approach to most of the videos they put out. Test-Driven Laravel is one of the best resources for giving junior developers a crash course on testing in PHP, regardless of framework. Having said all that, I'm often wary of projects that celebrate 100% code coverage rather than more comprehensive metrics, as I've seen that more than enough times where the tests were brittle and poorly thought through, with everything having just-enough coverage instead of the most critical components having thorough test coverage that has been properly planned out. Relatedly, I was asked to audit a project several year ago from a central European agency that were using Symfony and did have 100% test coverage, and maintained that coverage religiously. Except roughly a quarter of the tests had been failing for months and they were pushing into production despite that, with writing new tests given more importance than fixing failing ones.
Thanks @Nimja\_ did't saw that post. I'm downloading it to check it out too! Yes I might also try VSCode, I'm sure all IDEs out there have different cool features but for now I want to stick with the ones I know.
Twig doesn't check the input variables itself, you can simply create a method in a controller that wraps a call to render a template. Your IDE would warn you on the attempt to use an undefined variable. Most significant Twig benefits are different though and much more important - template inheritance - auto escaping - filters - any PHP code could be used only through a considerable effort, making it impossible for the inexperienced dev to litter a template with business logic. These features make Twig just an outstanding template engine which outperforms your home-brewed functions any day of a week, holidays included. 
Never said decoupling client and API was a bad thing. Just that the ball of mud client is shit. Every page making 300 different HTTP calls is shit. "JavaScript" is in a weird place", yeah that's putting it lightly. I've been doing this shit since 1997 and every year it's the same stuff. And It just repeats every few years, with some twists. I really hope everyone that is now saying OLD WAYS BAD, NEW WAYS GOOD bullshit has to support the nasty stuff they are building today for the next 15-20 years. Everyone should, it's a humbling experience. But they fucking won't. They take a job, churn out some on the newest tech they can, sit around for a year or two, then jump ship once things get stale and they need that new tech excitement. Leaving other people to clean up their mess, all the while smugging about how they are on the way out because they can't adapt to the new paradigm. And People need to quit thinking that just because a page loads instantly and then takes 10 seconds to load all the content, that it is somehow magically superior to a page that loads in 2 seconds with all the content just because of ((JavaScript client)). IM LOOKING AT YOU ATLASSIAN. FUCKING STOP
It's *fluent interfaces*. More than not they're used incorrectly for no added value. [They're evil](http://ocramius.github.io/blog/fluent-interfaces-are-evil/)
&gt;They don't add any value that doesn't exist already in the language. &amp;#x200B; With generators, memory requirements would be minimal and constant, no matter how much of data he has. OP wants to load 100.000 rows which is a memory killer. Using stmp-&gt;fetch(), it is too much queries. Loading in batches; fast and efficient. I really can't figure why this is so complicated. There is a good example of memory usage [here](https://medium.com/tech-tajawal/use-memory-gently-with-yield-in-php-7e62e2480b8d) and that is just for simple array. Not the kind he gets when loading from DB with lots of join. 
I'd recommend Python for this instead... 
A pity. You don't seem to be reading what other people say, only reciting religious sermons in your responses. It makes any further conversation useless. Come back when you grow up and start to understand things you are talking about. 
&gt; When you say less it should be less array-based, what else do you think I should use for passing things into the functions? As I said it's not a big issue right now, but as your project grows, it might get more difficult to maintain and add new features. Here are a few things I'd consider to improve it: * I'd probably separate the config value processing to a separate class entirely for 2 reasons: 1) adherence to SRP and 2) it would ensure much easier testing of the rate limiter itself which is also a side effect of the 1st reason. * I'd use value objects instead of arrays (simply pass the config array in the constructor and map the values to config class properties). I'll admit that this is more complex, but it has several pros - 1) Intellisense support in your IDE (method names can be auto-completed), 2) much easier testing (you've probably noticed I mention testing a lot). Consider this: `"error" =&gt; $this-&gt;routes[$route]["errorMsgs"]["requests"]` vs `"error" =&gt; $this-&gt;config-&gt;getRoute($route)-&gt;getErrorMessage(RateLimitReason::TOO_MANY_REQUESTS)`. For example, class Config { private $routes; public function __construct(array $config) { $this-&gt;routes = $this-&gt;registerRouteConfig($config['routes'] ?? []); } private function registerRouteConfig(array $config): array { $routes = []; foreach ($config as $routeName =&gt; $routeConfig) { $routes[$routeName] = new RouteConfig($routeConfig); } return $routes; } public function getRoute(string $name): ?Route { return $this-&gt;routes[$name] ?? null; } public static function createWithDefaultValues(): Config { // TODO - inject the default values return new static([]); } } class RouteConfig { private $errorMessages; public function __construct(array $config) { // TODO - map config to class properties } public function getErrorMessage(string $reason): ?string { return $this-&gt;errorMessages[$reason] ?? null; } } &gt; I just meant better in regards to what it offers, many only allow limiting with just the amount of requests. I see. That makes sense and it's also explained in more detail at the start of the README. I just noticed it at the very end and it looked a bit out of place without the additional context. You can safely ignore my comment then. In addition to what I already mentioned, I noticed a few other places for improvement: * Unless I'm missing something obvious, [this](https://github.com/eddiejibson/limitrr-php/blob/6f6c34291198df37c7c376c6852486c1d528167d/src/limitrr.php#L78) shouldn't work as `$discriminator` hasn't been defined. * You're declaring a class property dynamically [here](https://github.com/eddiejibson/limitrr-php/blob/6f6c34291198df37c7c376c6852486c1d528167d/src/limitrr.php#L57) and [here](https://github.com/eddiejibson/limitrr-php/blob/6f6c34291198df37c7c376c6852486c1d528167d/src/limitrr.php#L19) which is not a good practice. Setting the property directly in the constructor is also easier to understand IMO (e.g. `$this-&gt;db = $this-&gt;connect($conf["redis"]);`). * To make your library much more extensible, you could separate the storage providers (e.g. Redis, PostgreSQL, DynamoDB) and use a common interface. This would make extending your library **extremely** easy - simply create a new storage that implements the interface provided by your library and the rest is plug-and-play. For example, if you'd use something like code below, if someone wanted to add a storage mechanism that's not supported by your library out of the box, he simply would have to create a new storage class that implements `Storage` interface and use it to initialize the rate limiter. interface Storage { public function connect(): Storage; public function disconnect(): Storage; // TODO - add methods for fetching and persisting data } final class RedisStorage implements Storage { private $client; public function __construct(ClientInterface $client) { $this-&gt;client = $client; } // Ideally I'd make this and disconnect() immutable but since they both rely on Redis it's not particularly easy due to the fact that PHP uses shallow copy for cloning. public function connect(): Storage { $this-&gt;client-&gt;connect(); return $this; } public function disconnect(): Storage { $this-&gt;client-&gt;disconnect(); return $this; } } final class PostgreSqlStorage implements Storage { // code omitted } class RateLimiter { private $storage; public function __construct(Storage $storage) { $this-&gt;storage = $storage-&gt;connect(); } public function __destruct() { $this-&gt;storage = $storage-&gt;disconnect(); } } * It might be more user-friendly to use a more restrictive method signature (e.g. `public function get(string $discriminator, string $type = null, string $route = null): array`). This approach makes the usage of these methods much easier since you no longer have to look up the documentation of what to pass in the array. * I'd rename the class to `RateLimiter` (as you see in the example above) or something similar since it more clearly describes what it does. The current name is not an actual noun and is just the name of your library. P.S. I see that you already cleaned up the code a bit. That's great! Looks much cleaner and more readable right now.
&gt; Using stmp-&gt;fetch(), it is too much queries Pray, tell us where did you get such a notion?
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
You criticise me for using "home brewed" solutions but then suggest using "simple PHP includes" in your original post. All you are doing is arguing against yourself, I never said people shouldn't use twig. &amp;#x200B; I am strongly against PHP includes though. Do you reuse PHP logic using includes? No of course you don't so why suggest that it's a good idea for templates?! Go look at react, there's a reason why it's so popular along with other functional paradigms.
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
Hello there! I want to take this opportunity: \&gt; ... or simply show off your latest work. I present to your attention a fast HTTP router for PHP 7.1+ based on PSR-7 and PSR-15: \[Sunrise Router\]([https://github.com/sunrise-php/http-router](https://github.com/sunrise-php/http-router)) I'm currently writing an integration for zend-expressive. What do you think about this? Thank you all for your attention!
Yes! Minus that last rant because UX matters and I have no idea what Jira loads into the client. I left them a few years back, minus bitbucket :)
 $nids = \Drupal::entityQuery('node') -&gt;condition('status', 1) -&gt;condition('changed', REQUEST_TIME, '&lt;') -&gt;condition('title', 'cat', 'CONTAINS') -&gt;condition('field_tags.entity.name', 'cats') -&gt;execute(); Drupal uses it in their EntityFieldQuery which is part of their database abstraction layer.
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
Hello there! I want to take this opportunity: &gt; ... or simply show off your latest work. I present to your attention a fast HTTP router for PHP 7.1+ based on PSR-7 and PSR-15: &gt; [Sunrise Router](https://github.com/sunrise-php/http-router) I'm currently writing an integration for zend-expressive. What do you think about this? Thank you all for your attention!
I agree, includes is as bad as functions. It's a poor man's template that should be changed for something more robust as soon as you gown dissatisfied with it.
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
Hello there! I want to take this opportunity: &gt; ... or simply show off your latest work. I present to your attention a fast HTTP router for PHP 7.1+ based on PSR-7 and PSR-15: &gt; [Sunrise Router](https://github.com/sunrise-php/http-router) I'm currently writing an integration for zend-expressive. What do you think about this? Thank you all for your attention!
Ooopsss.. you are right, I was wrong; I **totally** forgot about DB cursors. And yes, fetch internally uses iterators so basically same thing, except that internal DB cursor is moving instead of new query. My mistake came from this known limitation [https://www.doctrine-project.org/projects/doctrine-orm/en/2.6/reference/batch-processing.html#iterating-results](https://www.doctrine-project.org/projects/doctrine-orm/en/2.6/reference/batch-processing.html#iterating-results) and because it is unlikely that someone will iterate without joins: &amp;#x200B; &gt;Iterating results is not possible with queries that fetch-join a collection-valued association. The nature of such SQL result sets is not suitable for incremental hydration. &amp;#x200B; So I have mistaken thousands of queries that would be run by **programmer**, with the fetch itself. My bad. &amp;#x200B; Unless it is just a limitation of Doctrine (which internally uses PDO), OP would not be able to use it, right? &amp;#x200B;
Codeigniter:) 
Yeah sorry for that rant. It was early and I hadn't had any coffee yet. I still mean it, but could have worded it better :) But yeah, Atlassian seems hell bent on loading their products with more clunky ajax to the point where its half-way unusable. We're actually moving away from Bitbucket to Github and the difference in responsiveness between the two web clients is like night and day. We'll still be with Jira/Confluence for a while because I really dont know of a better alternative. But if it keeps going like it is, we'll be looking for some soon.
They are called *type declarations*, see http://php.net/manual/en/functions.arguments.php#functions.arguments.type-declaration: &gt; **Note**: Type declarations were also known as type hints in PHP 5.
&gt;`if (!empty($execOutput)) {` Just in case you're still working on this, just unset the variable when it's not empty: &amp;#x200B; `if (!empty($execOutput)) { unset ($execOutput);`
&gt; The method I suggested works almost identically to the approach you would use in Doctrine with the EntityManager and it isn't a workaround at all, it's an extremely basic approach that works cleanly and is easy to understand. At this point I'm not sure you understand the root problem here. You'll what make mapper for each instance. Each time you need to convert currency, count commissions, process payments, transactions, payments in multilevel anything? Your solution is to try imitate some of Data mapper features. When just use Data mapper. And I'm not even beginning on nested transactions and lack of consistency when it comes to state synchronization between application and database. &gt; which to use on a project-by-project basis This is very telling. Project by project indicates small - mid level applications. Usually what all types of agencies do. Selling their development services to 3rd parties. That's generally small to mid size / complexity applications with very few exceptions of long term contract work. As any product based necessitates in-house developer team. And if you constantly work in such environment, sure, you'll see Laravel as best thing ever. You haven't yet ran into anything where Laravel patterns breaks down. &gt; You are seriously overestimating how complex any of this is. It's rather basic problem. However one which becomes constant source of frustration down the pipe. &gt; Additionally, earlier you were complaining about how Laravel uses Facades to simplify examples. ;) Dunno, we don't extend controllers to begin with, nowhere I claim that Symfony doesn't have issues. I claim that Laravel doesn't scale as well as Symfony, as Symfony has better toolset for applications which needs to scale, which can be taken advantage of experienced developer to higher ends than with Laravel. And I'm a bit tired of people trying to make this out as some Laravel vs Symfony which is better argument, when it isn't. &gt; Laracasts, which seems to be recommended to every new Laravel developer It's dual edged sword really. From my experience, and I had interviews with people who claim to develop with Laravel before, not understanding PHP very well or general programming principles like SOLID. I think entire Laravel ecosystem allows for rather incompetent programmers do build functional stuff. That's not to say that Laravel is a bad tool, but certain crowd seems to favor it over other tools.
FWIW we’ve made clubhouse.io work for us
&gt;This is very telling. Project by project indicates small - mid level applications. Usually what all types of agencies do. Selling their development services to 3rd parties. That's generally small to mid size / complexity applications with very few exceptions of long term contract work. As any product based necessitates in-house developer team. And if you constantly work in such environment, sure, you'll see Laravel as best thing ever. You haven't yet ran into anything where Laravel patterns breaks down and start causing problems instead of solving them. As I explained in a previous response, we generally work on long term, data-heavy projects, not small fire-and-forget applications. Some of the applications are low-traffic but high complexity, dealing with hundreds of different types of data from chemical and other sensors and complex medical records and lab work ups, others are relatively high traffic (many hundreds of requests a second) eCommerce sites with a fairly simple data model. In all cases, we operate on multi-year contracts developing and maintaining the systems in the long term. We usually take on one or two projects in a year. Additionally we provide auditing and consultancy services for in-house projects at other companies, which is where much of my exposure to the average Symfony project comes from. &gt;I think entire Laravel ecosystem allows for rather incompetent programmers do build functional stuff. That's not to say that Laravel is a bad tool, but certain crowd seems to favor it over other tools and gives people false sense of competence. I'm referring to a segment of developers, not claiming that all developers who work with Laravel are like that. Which comes back to my original point, Symfony and Laravel are just tools, both can be used to shoot yourself in the foot, both can be used to build very large scale applications, whether that's hundreds or thousands of requests a second, or extremely complex domains with large amounts of business logic.
Ah ok. No then, I wouldn’t bother with Codeigniter 
Could you elaborate on this?
I try to avoid it if I can. I hate when some some simple libraries do not offer just an "autoload.php" as an alternative. I can understand some libraries have a lot of dependencies, but someone forcing me to use composer for just a bunch of files... annoys me big time.
It is great that i am not the only one. Thanks!
I prefer more explicit frameworks, and both Laravel and RoR ( and ruby in that matter ) provide bit more magic than what I'm comfortable with. Additionally, I stick to the believing that if your IDE struggles with code completion something is not right. And both PhpStorm and RubyMine have problems with autocompletion with those. Yes, I've tried ide helper for Laravel, but seems like a workaround for an unnecessary problem. Yes, you can skip the magic parts of Laravel, but isn't that stealing the "great" part of the dev experience? Also, both frameworks ( and ruby as a language ) tend to name stuff a bit different than the 90% of the programming world, which is super confusing for me. 
Please think before you start messing with .git hooks. That would be a reason for me not to contribute. Enforcing is done by Travis/Scrutizer.
Can you elaborate ? I'm using husky for a couple of ts projects, captainhook is quite new for me but looked similar. I don't mean Travis should not test &amp; fail on cs/analysis , I use it mostly as convenience to enforce automatic cs-fix, phpstan before commit and push... I mean I'm too often forgetting to cs-fix things ;) But I'm curious, did you face problems with this ?
Thank you &amp;#x200B; Rubix is easier to use and has significantly more features &amp;#x200B; If you decide to try them both out, please share your experience
&gt; I prefer more explicit frameworks, and both Laravel and RoR ( and ruby in that matter ) provide bit more magic than what I'm comfortable with I feel like that alone shouldn't make your experience with Laravel less than great - since that's just an opinion thing and doesn't actually affect the experience. Whatevs, to each their own. &gt; I stick to the believing that if your IDE struggles with code completion Ironically, PHP Storm is the only one that really struggles with completion because if only wants to use type inference, whereas editors that can make use of tags struggle a lot less with this. That said, tags have their own downsides. &gt; Yes, I've tried ide helper for Laravel, but seems like a workaround for an unnecessary problem. Regardless of how necessary it is, if the problem goes away, why place an artificial restriction on it just for the sole purpose of being able to call it a problem? That said, Laravel 5.6+ needs ide helper a lot less because of the increasing amount of docblocks to help out with things like that. It's still not "perfect", though, and enough things still aren't documented that would probably annoy you. Obviously docblocking relationship class members would be on the developer, and I feel like a lot of people don't do that. &gt; Yes, you can skip the magic parts of Laravel, but isn't that stealing the "great" part of the dev experience? Depends on which parts of the magic you're talking about, I guess. I don't use Facades a ton which is probably the most used 'magic'. I do use them but I have "rules" about where I'll use them to keep it a little more sane (basically controllers and tests). There are other bits of magic that are flat out awesome - my favorite feature probably being route model binding. If you're explicitly talking about the (ab)use of magic methods, Eloquent is a good example of how that can spiral out of control. If you prefer stuff like method completion, but can't because you'd need the ide helper, you can instead do something like `Model::query()-&gt;` and autocompletion a thing again. I wouldn't want to see that committed, though. &gt; Also, both frameworks ( and ruby as a language ) tend to name stuff a bit different than the 90% of the programming world, which is super confusing for me. I haven't particularly noticed this but I also complain the naming of most things in general. I like really descriptive names and I feel like the only thing that comes close to this a fluent interface.
I like to commit often and clean up my Pr afterwards. And when I need to wait for an array of checks to run before I can continue that would seriously interfere with my workflow. I am not saying that my way is best, but by “forcing” a specific workflow on contributors might scare off potential contributors. If it helps in your personal workflow be my guest, but maybe not make it mandatory. 
Yes makes sense. Opt-in would be preferable in this case... Just checked the doc: `composer require --dev captainhook/captainhook`, to turn it on a `vendor/bin/captainhook install` can be added in the doc. Yes It feels better to me, especially If captainhook bugs on a particular platform. At least the contributor can uninstall if needed (platform bugs, version requirements, editor... got some with husky before it got popular and stabilized). And those who didn't opt-in are not impacted anyway. I'll update my repos too ;)
r/phphelp
`str_split` or `explode` will handle the splitting. If you want to put the split parts into other fields without reloading the page you'll need a script that watches for an event (e.g. content change) and then does the rest. jQuery is probably the most popular way of doing that.
Possible ;)
Hi redditers, &amp;#x200B; I have a client with a specific question that I'm not sure of if it is even possible. &amp;#x200B; From this text (of which there's 100s of the exact same format) he wants to save time and not fill in each form field, but rather just paste it once and magically divide them among the right form fields: Price : € 625.000,- K.K. Object : Living Type : Detached Year : 1884 Size : 165 M² Contents : 778 M³ Rooms : 7 &amp;#x200B; Would that even be possible in some way? Could I use a split function for the contents of a message field and them by pressing a button to some AJAX call or whatnot have the corresponding form fields filled? Not asking for actual code, just if I am wasting my time trying ;-) &amp;#x200B; Please advise. &amp;#x200B; Thanks!
Ugh, I just posted a support question here. I apologize :)
Yup, saw that. Sorry.
I was leaning towards that too. Did a similar thing but that data came from elsewhere. Will try and work this out. Thanks.
Javascript side: JSON.stringify, JSON.parse PHP Side: json\_encode, json\_decode Exactly how is left as an exercise for the reader.
Yeah the question was a little vague, unfortunately. Wasn't sure if you wanted to do it on postback or not. Good luck!
I imagine you could solve this by putting logic in your front controller to read the env vars into an object and then undefine them You can’t read what ain’t there 
Explode on new line and then again on colon... You’d loop through them something like this... $lines = explode(“\n”,$str); $property = array(); foreach($lines as $key=&gt;$val){ $property[$key] = $val; } $properties[] = $property; Forgive the syntax and missing logic but I’m on mobile 
Thanks. Ill look in to it this week. 
I use json on a daily basis. Simpel stuff but familiar. Thanks will see if it might help.
Thanks. Preferably all from 1 form without reload. Ajax/jQuery most likely.
This package acts as a wrapper for vlucas' package, and auto-loads the \`.env\` file from the project root.
This package appears to just be a 14-line implementation of dotenv via a global function call.
Symfony or Laravel in my opinion.
Thats what I thought.
Is anyone working on websockets in PHP, if so what libraries do you recommend?
Ah yeah so sounds like you're already familiar with those things. If it were me and I wanted to take single form input and split it into multiple fields e.g. after clicking next, I would use a no-submit form that hides and shows the fields relevant to the step the user is on. At each click of the next button I'd probably use jQuery to do client-side splitting instead of posting back to PHP where `explode` etc are available. It's faster, avoids needless server load and appears the same to the user.
[Laravel's Broadcast?](https://laravel.com/docs/5.7/broadcasting)
So you will need elevated privileges on the account that runs the script.
Yeah try running this in terminal &amp;#x200B; `chmod 755 &lt;yourfile&gt;` or `chmod 755 &lt;folder location&gt;` &amp;#x200B; Obviously don't go to prod with that, but it should work when changing permissions.
Jesus Christ, this stupid editor does not allow me to explain my error so I have to put it into the comments ----- I have been trying to resolve this problem for a good week. All I'm trying to do is create a simple txt file with the form data that I submit to it. However, whenever I submit the form I get warning messages like \*\*file\_put\_contents(/home/xxx/xxx/xxx/php/myfile.txt): failed to open stream: Permission denied in /home/xxx/xxx/xxx/xxx/views/practice.php\*\* . I've looked through many sites trying to find the answer and many of them would state to change the file permissions to 777 or 755. Or they would suggest to change the ownership to www-data. Or they would suggest to run a command like \*\*chcon -R -t httpd\_sys\_rw\_content\_t /path\*\*, but I would get an error like \*\*chcon: can't apply partial context to unlabeled file fileName\*\*. I have completely no clue why I can't create a file and I hope that I would have someone help me resolve it because all of the answers that were mentioned have not helped me at all.
That has not worked for me
The plugins do not compare either. Especially then you have major framework support like Laravel or Symfony. Although it's free so go, try, find out, run back to phpstorm. 
Ratchet. If you’re using Laravel, then Laravel Websockets is a package that implements Ratchet.
Try this: 1. cd /home/xxx/xxx/xxx/php 2. ls -la See if myfile.txt exists and is listed as the result of the second command. If it is, let us know what permission are set on it. It would be a 3 or 4 digit number or a combination of "r", "w" and "x" characters (for "read", "write" and "execute"). If the file doesn't exist then run: 1. touch myfile.txt 2. ls -ls Try to run your script once again, if the error persists, then post back the file permissions.
What error message do you get when you try those specific commands? It's completely possible your user does not have permission to do it, in which case you may need to use sudo. You also won't be able to change the permissions on the file before it exists, obviously, so you'll need to do the folder you want to write to.
...And yet, I've never seen more resistance to an idea than the resistance I've seen towards something like https://github.com/preprocess/pre-phpx
Your webserver needs both write and execute permissions for the directory where it is creating the file. Generally, you'll want to create a dedicated subdirectory for this purpose alone. e.g. in the www directory, create a subdirectory named "files," make your webserver the owner of that subdirectory, and assigned the w and x permissions for the subdirectory to the owner. Something like: cd /var/www mkdir files chown www-data files chmod u+wx files - The above assumes that your webserver is running as user www-data. - If you don't want the created files to be accessible via http, consider putting the subdirectory someplace other than in the doman's webroot. 
I don't get any error messages when I change the permissions or ownerships of files or folders because I own the files, or my username owns them. So whether I do sudo or not I still am able to change the permissions to 777 or 775, or change the group to www-data. So I don't believe that is the reason why I'm not able to create a file in php
If you are a newbie and really want to become a developer, I recommend you do it in baby steps. - A static site requires only HTML and CSS, no PHP needed! You need to be proficient in these technologies anyway (along with Javascript), so do it now. - Your first dynamic site should use plain PHP, without any framework. You need to be proficient in PHP anyway, so do it now. Later you can become proficient in a framework. 
I created the myfile.txt with linux and changed the permission code to 777. Once I changed the code then the form code started to work and I was able to insert content into the file. However, I still cannot create a file without having to already create it in linux/ubuntu, and change the permissions of the file. Why is that?
It could be a selinux issue. Also make sure what are the actual username and group used by webserver
I have been trying to resolve this problem for a good week. All I'm trying to do is create a simple txt file with the form data that I submit to it. However, whenever I submit the form I get warning messages like file_put_contents(/home/xxx/xxx/xxx/php/myfile.txt): failed to open stream: Permission denied in /home/xxx/xxx/xxx/xxx/views/practice.php . I've looked through many sites trying to find the answer and many of them would state to change the file permissions to 777 or 755. Or they would suggest to change the ownership to www-data. Or they would suggest to run a command like chcon -R -t httpd_sys_rw_content_t /path, but I would get an error like chcon: can't apply partial context to unlabeled file fileName. I have completely no clue why I can't create a file and I hope that I would have someone help me resolve it because all of the answers that were mentioned have not helped me at all.
I've heard that "selinux" might be an issue, but I don't know what that is exactly. The username of the files and folders is my name "jermaine" and the group is www-data. How would I know if selinux is the issue? 
So you managed to screw the fair play twice in one post. First you cheated on the client telling them you are qualified for the job, and then you've seen the rule telling you to post help question elsewhere but decided to screw this nevertheless. Good start.
My only thought is that the account that php runs under doesn't have write permissions to the directory where the file is being created.
I tried that, I'm still getting error messages even though I'm trying to create the file in the files directory.
If www-data is the group owner, then are you giving the www-data group the permissions? cd /var/www mkdir files chgrp www-data files chmod g+wx files
[yaf](https://github.com/laruence/yaf) - Fast php framework written in C, built in php extension
If this script is being executed via browser, you’ll have to give the http user (apache or www-data or whoever, find out with whoami) access to write to the file / directory. 
This limitation has nothing to do with joins, but with the Doctrine's process called hydration. Frankly, fetch-join is a special term used by Doctrine, it has nothing to do nor with fetch or joins. So there is not a single problem with fetching a joined query result in PDO. Neither in doctrine, unless some special condition is met (when there is not enough data fetched by the query itself and Doctrine indeed has to perform additional queries for each row to fill the linked objects). But the main point, whatever difficulties PDO or Doctrine have, generators are unable to solve them. They help you basically in just one situation - when you for some reason do not want to use a while loop, but fetching the data into array first will consume too much memory. Then with a generator you can disguise a while loop as a foreach loop but with no memory overhead. But still it has a while loop in its heart and you can use it from the start, without any generators. And no, DB cursors do not use iterators. An iterator is a syntax sugar as well, it's a way to disguise a stream as an array. But in its heart it has the same fetch. There are no iterators in MYSQL C API, only a method to consequently fetch the next row from the database. All iterators are added in PHP (say you can foreach over PDO or mysqli statement) just a syntax sugar. 
are you sure www-data is the user you need or are you just copy / pasting the answer from here? Run this in a new PHP file and see what it says. This is the user you need to give access to. &lt;?php $cmd = shell_exec(“whoami”); echo $cmd; ?&gt;
Just google selinux for your case. I don't remember it by heart, but google always do it for me ib such case. What are certain username and group: - for you as ftp/ssh user - for web-server (and php process if it is used) - for the actual /home/xxx/xxx/xxx/php/ folder 
it outputs www-data
I’ve run into almost this exact problem. If you’re sure the permissions have been set correctly and it’s still giving you a permissions error, SELinux may be the culprit. Try scanning your audit logs for any blocked execution attempts, and you can either add a rule to let that script execute, or just disable SELinux by turning it to passive mode. 
So you're saying that I should change the user to www-data? Because that is the name that it outputs when you run the script whoami. Am I supposed to change the username to where the file is being created or do I change username to the file where the code is being ran?
I just posted [this question](https://www.reddit.com/r/laravel/comments/a92846/how_can_i_elegantly_handle_nginx_timeout/?st=JQ1W5MHZ&amp;sh=f3352040) in r/Laravel but it’s absolutely valid for plain-Jane PHP.
I’ve never understood why people think it’s clunky? Maybe I’m old? Old fashioned? I switched to PHPStorm in 2013 and never looked back. I use sublime as a text editor and I’ve tried vscode. I don’t think I’ve ever said either sublime or vsc are too simple. They have their place. PHPStorm is a full IDE. It’s amazing. I don’t think I can seriously develop a proper web app without it. Even a WordPress theme or plugin. It’s never been slow, always fast. I use both windows and Mac. I’ve even worked on old legacy ASP sites using it. It’s good man. What’s clunky about it? :-/
You may look in PHP library [https://github.com/ratchetphp/Ratchet](https://github.com/ratchetphp/Ratchet) or use [https://github.com/centrifugal/centrifugo](https://github.com/centrifugal/centrifugo) and interact via API with that. 
convert all dates to unix timestamp, and compare the values if you really want to be absolutely sure. 
It is not the editor to be honest. The sidebar clearly says that help questions must be asked elsewhere. Hence you naturally cannot post the question body here. All seems logical to me. 
TL;DR: when comparing dates against a datetime field, there could be a pitfall. Either explicitly supplement your date with time ie `BETWEEN 2018-12-01 00:00:00 AND 2018-12-31 23:23:59` or use less than and a date of one day in the future, `dtm &gt; 2018-12-01 AND dtm &lt; 2018-01-01`
It won't work. The question is not how to represent a date but which value to represent. Just like it said in the article, if you convert `2019-01-31 10:00:00` to timestamp, it won't help you with an event that starts at 11 that day
I solved this, I only look for anything like between 2019-01-31 00:00:00 and start date and 2019-03-33 23:59:59 on end that. This way, something that happens at 22:00:00 is, also, accounted for. 
Yes exactly. Dunno what does a unix timestamp to do with it
Some of my own code worked better when using unix timestamp in sql requests because of some weird behaviour when trying to find entries that where in effect older(smaller) than a specific date. It, also, makes it a lot easier to debug the code. 
We use a custom `Date` object that extends `DateTimeImmutable`. It basically normalizes the time portion. This works extremely well even when comparing objects.
Timestamp is not easier as it is not human-readable. And your problem was likely caused by the daylight saving which affects timestamp as well.
Can you please elaborate on "normalizes"? `echo date_create_immutable('2018-12-01')-&gt;format("Y-m-d H:i:s");` gives me `2018-12-01 00:00:00` which retains the problem stated in the post
How does it know when you do `new Date('2018-12-31')` which time it should use - current time, the first second of the day, or the last second of the day?
 dtm &gt;= 2018-12-01 AND dtm &lt; 2019-01-01 *
Thank you!
Just to point out an issue with your logic. Yes, your way is human readable, but it isn't a human running the code, is it? (I, also, account for Daylight savings time in my code, it is actually hard-coded into it. )
&gt; It, also, makes it a lot easier to debug the code. It's a human who does debugging.
Unix_timestap is basically fed as a full integer, you can use it to determine if the current date is greater than or lower than date in a database. Unix timestamps for older dates are actually lower than newer dates. Thus, for debugging, it can be easier to see why code doesn't work if you convert to that basically because 1000 &lt; 2000. 
Good question. Time doesn’t matter when doing date comparisons or even talking about a date. It took us a bit to get our heads wrapped around this concept because we’re so used to thinking in date and time. But December 24th is the same everywhere in the world. If you’re trying to use this concept for time sensitive data, it should use time as well. We use a `Date` object for due dates, for instance, as well as a DATE column for our database. At one point we tried using DATETIME and `DateTime` objects, but that ended up being a nightmare. At the end of the day, when doing comparisons and logic, dates end up being rated static in nature and rarely even require timezone conversions. Again, this was a weird thing to wrap my head around at first. However, after taking this route, we’ve been extremely pleased and haven’t looked back at all. YMMV.
Disclaimer: I work in KoolReport's project, hope that you don't mind. KoolReport is an intuitive and flexible Open Source PHP Reporting Framework for faster and easier data report delivery. it is great if you need to build data report or construct dashboard for your application. Containing highly data-focused functionalities, KoolReport save your time &amp; effort in all data related tasks ranging from data retrieval to processing and visualization. ![Great PHP Reporting Framework](https://cdn.koolreport.com/assets/images/editor/c4/image5c136a3c699c1.png) KoolReport is free and open-source released under MIT License. You may view examples and demonstration at [https://www.koolreport.com/examples/](https://www.koolreport.com/examples/). Homepage: [https://www.koolreport.com](https://www.koolreport.com) Github: [https://github.com/koolphp/koolreport](https://github.com/koolphp/koolreport) The sweetest thing of KoolReport is the ability to integrate seamlessly to other PHP Frameworks such as Laravel, CodeIgniter or Symfony, etc.. for example you can create ColumChart inside Laravel like this: &lt;?php ColumnChart::create(array( "dataSource"=&gt;DB::table('orders') -&gt;select('department', DB::raw('SUM(price) as total_sales')) -&gt;groupBy('department') -&gt;get() )); ?&gt; Thank you very much!
Mysql datetime is basically fed as a string, you can use it to determine if the current date is greater than or lower than date in a database. Mysql datetimes for older dates are actually lower than newer dates. Thus, for debugging, it can be easier to see why code doesn't work if even if you don't bother to convert because 2018-12-01 &lt; 2019-01-01 And, for some reason, I can tell at glance which one is bigger, 2018-12-01 10:22:11 or 2018-12-01 11:22:14 yet it takes some effort to tell it for 1543656131 vs 1543659734
So it is not your class but storing dates in the date field in the database. Just like the article said. And what if you need time as well?
The only thing we are pointing out, is every programmer is different. The means doesn't necessarily change the end goal. Either way, I could tell which is greater than the other just looking at it. After all, we all learn integers long before parents make us remember the day, just FYI Happy Holidays!
An integer like 1000 is one thing and like 1543659734 as another. This is why humans invented formatting - thousand separators for prices, dashes for phone numbers, and colons for time. Happy Holidays!
Hey how's it going. I read your question and the first thing that come to mind was the php shutdown register. http://php.net/manual/en/function.register-shutdown-function.php So basically make some form of singleton access to your response API JSON system. When you detect that there was an error in your shutdown function do whatever you want as a response. function shutDown() { if (($error = error_get_last())) WhateverYouWantToEchoToPage(); This is just off the top of my head, free writan and might be wrong. It just might be a lead for you to go down. I set this up at work to force PDO pgsql connections to close no matter what happens using a singleton access to my database and telling it to kill itself on Shutdown()
Ha, not quite. You're wrong twice. Angry much?
Swoole. It's a very cool project, lead by China, so the english documentation is a bit lacking, but google translate on the original actually works pretty well.
Given your attitude I wouldn't expect anything else than allegations about my character. Surely the question whether I am angry enough is the topic to discuss here :)
Date and DateTime are two entirely different beasts. You use one or the other depending. There isn’t any mixing for us and we typehint the stack from request to PDO.
Thanks for your work and thank you for sharing!
ohh this might be exactly what our company needs. def gonna try it . thank you 
I had a very similar problem (4,000,000 records with twenty linked one to many relationships) and it was due to the time limit on php functions. The systems at work are NTS. Eventually, the solution I came up with was to use ajax to launch a Java application so I could introduce threading and record document creation progress in the db. The request is then allowed to time out without affecting user experience. A second ajax checks for completion at timed intervals, updating a progress bar and then redirects to the finished file. Best of luck.
&gt; And no, DB cursors do not use iterators. An iterator is a syntax sugar as well, I meant; using fetch is like using iterators. But this is now confusing me: &gt;So there is not a single problem with fetching a joined query result in PDO Did you try it in real situation? It would be interesting to see how one can use fetch() when there is for example 2 joins in query, used to generate 1 row in CSV. It could result in let's say total of 3-10 fetched DB rows per 1 CSV row, right? Dummy example; you want to export all orders and joined products so 1 CSV row would have order number in one column and all products in another column.
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
How do you make money?
I need this in my life!
Very Kool, very Kool.
OK, time for some critique as nobody else has done that so far. 1. &gt; PHP 5.4 or higher. What year do you think it is? PHP 5.4 was EOL-ed more than 3 years ago. Even PHP 7.0 is no longer supported. 2. $oldActiveReport = (isset($GLOBALS["__ACTIVE_KOOLREPORT__"]))?$GLOBALS["__ACTIVE_KOOLREPORT__"]:null I found usage of $GLOBALS in the 1st file I checked (not a good sign). I doubt that this is the only occurrence. 3. You're not using consistent return types [here](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/KoolReport.php#L257) which shouldn't ever be done. 4. Your code has unreachable parts such as [this](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/KoolReport.php#L177) and [this](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/KoolReport.php#L164). 5. You're mixing frontend and backend logic [here](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/KoolReport.php#L28). 6. There are a bunch of places of poorly structured code or simply weird looking statements such as `$result&amp;=($return!==null)?$return:true;`. I really doubt that it was the best possible design choice. Remember that readability matters - much more time will be spent reading the code than you spend writing it. 7. What's the point of [this](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/core/Base.php#L13)? It doesn't even do anything... 8. There are misleading DocBlocks in multiple places such as [this](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/core/DataStore.php#L500). 9. I wouldn't recommend using method names such as [this](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/core/DataStore.php#L626). Using `!$this-&gt;isEmpty()` is way more readable. 10. You're mixing mutable and immutable methods which makes somewhat hard to understand the class interface without reading the DocBlocks. 11. You're using `static` on one line, and class name on the next. Pick one and stick to it. 12. The formatting is completely wack at places (for example, https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/core/DataStore.php#L133). If you're allowing such code in your codebase, I'd start to doubt the fact that you even care about the quality of the final product. 13. You have multiple classes per file in at least one place - https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/core/ProcessGroup.php#L30. While PSR standards don't explicitly disallow this, it's still generally considered a bad practice. 14. There's an inconsistent use of braces in several places such as [this](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/core/ResourceManager.php#L341). 15. You're sending HTTP headers from a class that should be responsible for the business logic (at least that's my impression) - https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/core/SubReport.php#L40. 16. [This](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/core/Widget.php#L318) makes no sense as the method can only return `true`. 17. Finally, one of the biggest issues is very heavy use of static. I'm talking about the mysterious `Utility` class which not only is used pretty much everywhere (all static btw) but also has state which is very inadvisable. It should be completely rewritten and possibly split into smaller parts that actually adhere to SRP. These replacements then should be injected where necessary, otherwise you're just introducing hidden dependencies everywhere. Please note that these issues are **ONLY** in the `Core` namespace. If I went through the entire project, this number would probably triple. If I had to maintain such code in my work, it would be considered a legacy code despite being written recently (I'd cut some slack though since you at least have tests). Given that, I'd probably steer clear of this project until it improves. I'd probably start by setting up CI for tests (Travis is pretty good), start using a proper IDE (PhpStorm + PHP Inspections (EA Ultimate) would be my recommendation) and start using a code quality tool. Doesn't matter whether it's CodeClimate, Scrutinizer or something else, but it **will** help to improve the quality of your codebase. P.S. Sorry if my critique sounds unnecessary harsh. Please don't take it personally as that isn't my intention. I'm just pointing out places which should be improved if you're serious about maintaining this project in the long term and are planning to develop it further.
As far as I understand, they have paid packages and licenses. While the main project and some packages are free for everyone, they can still make some profit this way.
I usually solve this by casting to date, like &gt;dtm::date &gt;= '2018-12-01' AND dtm::date &lt; '2019-01-01' &amp;#x200B;
Except that you are not returning `$this`. 
That's an interesting question, given such extreme conditions. First of all, it's indeed extreme. Most of time we are either selecting only one row from each joined table (like an article with author's name, category name and such) or we are selecting for the web page where a reasonable amount of data is shown, so it gives us luxury of making 1 + n queries where n is the number of articles shown on one page where we need to show all tags for each article. Or, in case you are tricky enough, making 1 + 1 queries where first query loads all articles into array and then another query takes all article ids into IN() clause to select tags for these articles. When we need to select in one query all 100000 articles and 10 tags for each, it would be insane to multiply the number of rows selected by a factor of 10. So, It seems here is the time for your chunks or some other trick. Personally I would look into combination of CONCAT_WS() with GROUP_CONCAT(). Although clumsy, it should work making a single row for the main entity no matter how much linked entities we need. 
Well, the article we are commenting out is about datetime, though it claims being about date.
 $file_ext=explode('.',$_FILES['files']['name'][$img]) ; $file_ext=end($file_ext); $file_ext=strtolower(end(explode('.',$_FILES['files']['name'][$img]))); is my favourite part This is exactly how an archetypical code from a Bangalore-based company would look. 
It is not overly popular as most of time you are comparing against a database and applying a function to the field's value could make trouble using indexes
What a great set of feedbacks! Is the claim made in #6 really true or how true is it? It seems to be common knowledge that we spend more time reading a given piece of code vs writing it. Some even say 10-1, but who’s the authority on this?
My first thought was "ew that looks messy" But my second, and more pressing thought was "ewwwww who on earth decided that making the array dimensions be [field][header][index] made more sense than [field][index][header]"
I was under the impression that nginx timeout of gateway error leaves the php-fpm process still running. 
Oh, I didn't know that. I only came here to ask a question because I assumed there would be smarter people here with PHP knowledge that could help me.
Well, next time assume that a subreddit has rules which you are supposed to read before posting. 
Thank you, great code review 
(Sorry in advance for the length of this comment.) &gt; V is the thing users see That's a natural and common opinion to hold, based on MVC's origins in GUI applications. *Of course* the View is "the thing users see" -- it's a button, or a menu item, or a text field. Then when you begin programming server-side applications, and begin sending HTML in the body of of the response, *of course* you think of the HTML as the View. It is "the thing users see" after all. In a lot of ways, server-side developers think of their templating systems as the View system, because the templates are what generate "the thing users see." I assert that thinking of the template as the View, for server-side applications, turns out to be a mistake. The reason is that in a request/response, over-the-network system, the server output being presented is the entire HTTP response, including the headers, not just the body where the HTML is. We don't think of it that way, because the headers are not "the thing users see" in their browser. But browsers are not the only HTTP clients around. Try using `curl` on your favorite site, or even telnetting to it and entering a request by hand, line-by-line. What you get back is not a nicely-rendered HTML page; what you get back is the entire HTTP response in text lines, headers and all. So thinking of the view as "the thing users see" is an artifact of the HTML code in the HTTP response body being rendered by a browser, coupled with the origins of MVC in GUIs. But in the case of server-side applications in a request/response environment, the *real" "thing users see" is the thing seen by the HTTP *client*: i.e., the entire HTTP response. (Whether the client then processes that response to do something else with it, such as rendering HTML, is up to the client.)
&gt; V[iew] can be php-ish templates, React, API-response, JS-whatever. This is an example what I mean I say that server-side developers often think of the templating system of the view system in [earlier comment] (https://www.reddit.com/r/PHP/comments/a8j3wu/what_is_the_easiest_php_framework_for_web_dev_for/ecgfnna/) See also [The Template Is Not The View](http://paul-m-jones.com/archives/5993).
I tend to agree, `foreach ($_FILES['fieldname'] as $field)` would have looked much more natural. I suppose the current approach was just simpler to implement
[https://i.imgur.com/6TnOizw.png](https://i.imgur.com/6TnOizw.png) &amp;#x200B; Look at that shit SEO strategy XD
Don't bother, it's a case of "no true scotsman" since a few message, recognise it and move on.
www-data needs to have write permissions to the folder where the file you’re trying to create is going to go. 
Use smtp
Got to find someway to amuse myself over Christmas. :D
Can you clarify please? 
Googled like "google smtp phpmailer" or "yandex smtp phpmailer"
I'm going to tentatively say yes. However, it sounds like you're not using a PHP framework for your project, which I *highly* recommend if it's your goal to follow best practices.
There is no general suggestion, each case is different, based on the form/handler's purpose, not the HTTP method used. There is no such thing as separation of post and get methods as well. Also keep in mind that in modern PHP we don't think in terms of "files" and "forms" but in terms of controllers and templates. 
Yes but it depends on the context of the form. 
Can't believe you took time do this - really good feedback!
Very cool There's an alternative similar for java-spring? 
Use a service like mailgun. They maintain deliverability and block spams. I almost guarantee that a godaddy server has already been added to multiple blacklists. 
&gt; 1. What year do you think it is? PHP 5.4 was EOL-ed more than 3 years ago. Even PHP 7.0 is no longer supported. Why is that a demerit? He's not saying you should run php 5.4, only that it is supported. When I check the minimum requirements for a game that says "2GB of RAM" I don't think it is a demerit, quite the opposite em a few cases.
The only time they would change during runtime is during a configuration step, should the user want to rename the units, or use a different symbol notation, add their own formulae, etc. For this purpose, I feel having getters/setters defines a clear API for the user. Thanks! Seemed like a no-brainer, to me.
Wow! I did not expect a awesome critique like this. Thank you so so much for that. If I knew I could receive a great feedback like yours, I would have shared the project earlier. It took me more than half an hour just to read all of your points and surely it will take you much more than that to write. Very appreciated! &amp;#x200B; I will go through all points you made and try to add comment or explanation of why we did that. 1. PHP 5.4: The reason behind this is that we want to maximize the the range of PHP version that framework can support. Many still have old code base project in php5 are very reluctant to upgrade to php7 and we want the framework works for them as well. So everytime we released new version, we need to test with php5 to php7 to make sure all work. 2. It is not, the second place of $GLOBALS is inside Widget.php. When report renders its view, widget inside the view needs to know which report is rendering it, we don't want to bother user to provide report object to any widget they creates so we save the current report to \_\_ACTIVE\_KOOLREPORT\_ so that Widget will refer to it. 3. Most of the time, render() will output content directly and return nothing. However, in some case if user want to get the content instead of echoing the output, the render() take a boolean $return parameter to decide between echoing content or return content. The return type is always string or null. May be it is better to use "echo $this-&gt;render();" and render() function should always return content in string. Just want to save user some code. 4. It actually reaches if users forget to provide database settings in settings() function. It is just a way to remind them to provide the datasources. 5. The intent of this KoolReport::js() is to provide additional way to render KoolReport.js to the page. This file is important for loading resources for widgets. In some cases, when user want to use our Widgets but do not want to setup the whole report, all he needs to do is to add \`&lt;?php echo KoolReport::js(); ?&gt;\` to his page and then he can use any Widget such as ColumnChart or PieChart directly. It provide convenience and expand use case of the framework. 6. Agree to your point. Just want to explain that line of code. KoolReport supports event registering. For example, we can register event called \`OnBeforeSetup\` which will run before report is setup and able to approve/disapprove "Setup" action to take place. However the multiple event handler can be registered to an event. If one of handlers disapprove a action, the action will not occur. That line of code is to check through all event handlers and gather the "approve/disapprove" for final approval. If a handler return nothing (or null) it take it as "yes" or "approve". 7. Agree, we just want to let all the class derived from a Base so that later (if, in case) we need to add something for all classes, we can do here. But so far, there is no so may be we should remove it. 8. You mean we should write the document clearer, right! 9. Yeah, we provide both isNotEmpty() and isEmpty() for preference choice. Like in Laravel's Collection, they do [the same](https://laravel.com/docs/5.7/collections#method-isnotempty). 10. You are right, it may cause confusion to mix the mutable and immutable. 11. Could you please explain further on the static on one line and class name on next. 12. It is crazy time when one of our developers use to use the tab and I use spaces. Accepted the formatting needs to be consistent, we will improve that. Thanks! 13. Yes, we do have 3 classes in ProcessGroup class. I was very reluctant too when did this. My reason for doing so is that ProcessGroup is the main/important class and the other two are just helpers. They are not used anywhere else except for ProcessGroup class. So I decided to put them together. 14. Yes, just want to make string process a little faster as you know double quote will requires some extra string processing. 15. SubReport handle to request from client side to render part of report (via ajax) so in case it does not find the the sub report, it return 404 so that at client-side, you know something went wrong. 16. Thank, I agree on that. 17. Utility is a class when we put the stateless function act which will be used across the projects. I did not realize it is bad. The state you mentions is the $uniqueId, dont you. Yes, we do use it to make sure we get unique Id generated everytime we called getUniqueId() function. It is only place we use the state in Utility. Again, thank you so so much for your code review. It is my greatest moment of the day when I receive your reply. We will take all of your advice to improve our code base. Please add more comments if you could. &amp;#x200B; Merry Chirstmas!! &amp;#x200B;
Yes, we earned some money for paid extended packages. We provide support &amp; outsourcing services as well.
Please try it, if you have any difficulty please let me know.
Thank you very much!
Thank you very much!!
Please try it, anything please let me know.
downvote for use of mongoloid
A lot of spam websites, domains etc. are hosted on Godaddy, Godaddy does not know all of them because of the insane amount of websites they host (with a report the site gets shutdown)
Thank you, we test the framework from PHP5.4 to PHP7.3 to make sure it work on all those php versions. Although it is harder for us but we believe will benefit more users.
Ideally it would be one class getting both Get and Post requests, and then calling appropriate methods to process the requests. So, not one file but one class, and two methods.
Just add the dollar sign at the value before the echo
Ok cool. Hope it goes well. 
Could be Jasper report? It is really cool open-source reporting tools. Java is very strong for reporting actually.
So value="$ &lt;?php echo $amount; ?&gt;" class="wpep-amount"/&gt;
Doesn't work.
Try to add this instead of dollar sign &amp;#36;
... value="&lt;?php echo '$'.$amount; ?&gt;" ... is that?
Tried that as well. Doesn't work. It actually removes to placeholder value of 0.
You have to change the dollar sign to the html entity “&amp;#36;”
Ah like a html special character?
Yes I tried to copy it into the post but reddit changed it to the dollar sign
I was going to say that I too am interested in this little debate, but then I realized it's /u/icarebot and I am agreeing with a bot.
&gt; 11. Could you please explain further on the static on one line and class name on next. https://github.com/koolphp/koolreport/blob/master/src/core/DataStore.php#L984-L991
Docker != Virtualization
Thank you so much! I am thinking how this could happen, should not be that. I will use some above suggested tools for the team to avoid something like this happen again.
You can't do that with an input of type number, that's why css frameworks like bootstrap have [Input group addons](https://getbootstrap.com/docs/4.0/components/input-group/#basic-example). The issue is you trying to set a non-numeric value to a numeric-only input, it's not possible without a custom input. 
Thank you. I would have beat my head against the wall all day. I'm going to do the right thing here and just give up before I break it.
Yes. And IMO there should be a core Date object just like DateTime. But there isn’t, so we created one. It extends DateTimeImmutable and basically sets the time portion to 00:00:00 and ensures it always remains as such.
Great code review! I wish I had a reviewer like you.
WordPress its going on an bright path, there's an Full api and an good editor its just not as scallable as concrete5 for bigger applications.
How did using the filesystem to store files add complexity? It should be simpler. I’ve seen a couple of systems that stored files in blobs in the DB and it made the DB backups so large and awkward to handle that I’d never try that again.
I'd advise against. Replication will be slower and you're going to suffer trying to scale horizontally as connections are open longer for writing that binary data. I'd choose your favourite cloud providers solution (AWS S3 or Azure blob for example) or yeh, go the whole hog and fire based. Having said all that, why not mock up a test to prove it's a problem for your projected work loads first? Could be my earnings don't apply for your circumstances which would be a win!
I'd say [Clean Code](https://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882) is a pretty good authority on readability.
You are welcome! Please try it, if you have any difficulty please let me know.
Blobs work fine. When you're designing your database schema, be sure to consider a means to back them up that's different from your usual backup mechanism so you don't have to dump a metric ton of binary each night. For example, I've kept my image blobs in a separate schema, and make sure each one has its own unique id and timestamp. That way I can just dump everything new since the night before without having to do the whole lot - and never allow the same key to be overwritten with a new blob, append only, never replace. That way you can drop a simple web server cache in front of it to cache each individual file, and if you throw a GB of disk space at it you'll be able to cache many thousands of JPG images. If you're using something like NGINX that would take all of a couple of minutes to add.
I would advise against doing such things, it's just not practical and bad practise. Database size is going to get significantly larger, which also means your backups will be larger. If you you back up your database daily/hourly, you'll quickly end up using vast amounts of disk space. If you need a quick copy of the production database, to test that one edge case you're in for a slow export/import. If you need to restore a database, it will be slower. Save yourself from future headaches and use something like flysystem and use one of its adapters (ideally off site like s3). 
Thanks!
For forms or anything in php or any code really, use as many files as you like as long as each file is; necessary, manageable in length/scope and organized to task. Necessary, meaning you don’t have to have a file for every class or collection of constants in your project (but you might want to). Manageable, meaning that each file is short enough to be scanned by a human in 10-20s (not fully understood in that time, just scanned for a general idea of what it contains) Organized, meaning that each file contains related items, functions, a class or classes etc. Just balance those three general ideals and it’ll work out fine. Some projects are a single file with only a few methods under a class, others are hundreds or thousands of files with classes tucked in sub sub sub sub folders of their parent classes. Just chop and dice as much or as little required to make it make sense to you and anyone else you’re working with. 
In this thread there are a lot of people who've obviously never used a database to store large amounts of binary data and clearly haven't put any thought in to ways to easily mitigate the shortcomings. Using the filesystem to store hundreds of thousands / millions of small images has its own drawbacks, repeatedly reading small chunks from a drive, especially one on a spinning disk, is far from optimal not to mention significantly slows down read operations when doing large numbers of files at once, such as for backups. &amp;#x200B;
Oddly enough, I haven't had much issues with PHPStorm on my MacBook Pro and I'm almost exclusively using the EAP version. Never had issues that resulted into code loss or something that would render it useless. This is with a lot of default plugins disabled though. Any specific platform you are using?
You seem to get my point. Blobs are a way, question is, would it be reliable in our case. There are cons for filesystem based and you're mentioned some. I'm actually more worried about read performance, such as displaying product listings with thumbnails, and not about backup. We used blobs in the past but never got full-scale with them. Indeed, there are issues with files and we've actually observed that the whole thing gets far more complex with files. Having to match in-database metadata (beloging to the file) to the actual file and its existence in the CDN/file storage, should we decide to use a file-based one. Having multiple versions of the file (thumbnails) Assigning to the user. Having to "hide" files (when a record is deleted we still keep the 'version') which is very easy to do /maintain via simple fields in MySQL. A great advantage is that MySQL engine can also be tuned to cache those records in the first place. So there's an additional caching layer there. Most posters have discussed the backup issue. That's true, depending on how it's done; but not an issue for us. We're likely going to have a separate server and replica for the images hosting at some point. Since updates are infrequent, we're expecting zero issues with replication. I also think that should we later decide to another system it would be easier to create a script and export all files from MySQL, so that's kind of a forward compatibility. Still, I am considering all advice received (thanks to all who posted BTW). Files have their advantages too. 
Thanks. A test is however difficult to make, from previous experience, as it will not be using real user data. Still considering all options. Side note, we're not going to use AWS or Azure, it's a solution mostly designed for baremetal servers for certain reasons out of the scope here.
&gt; Is the claim made in #6 really true or how true is it? It seems to be common knowledge that we spend more time reading a given piece of code vs writing it. Some even say 10-1, but who’s the authority on this? Yes, definitely. I'm not sure about the proportions though as I don't think that anyone has such statistics, but in my experience the larger the project gets, the higher this proportion becomes. The same could probably be said about the project age and possibly the initial delivery time (for example, if a project was rushed to launch it as soon as possible, it will undoubtedly have many issues which makes code more difficult to understand). 10 to 1 might be even be a huge understatement in some cases. Your experience may vary though as it greatly depends on the project.
/r/lolphp
Well it also depends on how the backup is done. If you're doing full backup each time, yes - but it's not the only way to do it. An incremental option always exists, although it would have to be custom. The table structure is simple and allowing for writing a custom incremental backup thing. Side note I'm worried mostly about front-end performance (reading and displaying from db) rather than the backup itself. And perhaps database integrity issues, should there be such a thing. You have a point about backup size (if you dump everything at once) but again it depends on the overall system structure. When becoming large, images will be stored on separate db servers dedicated to images. They will also be tuned differently. Uploads are infrequent, therefore I don't foresee issues with replication and/or backup.
Thank you! I often see that people post their projects on this sub, but there are very few comments and almost no feedback. I'd hate it if I were in the author's shoes.
You don't necessarily need to store your binary next to your metadata, although you certainly could, it's best not to create that link in case you need to change it in future. The route I would go, if I were to be wanting to use a database for it, would be to have a separate database that was a AI PK, a UUIDv4 or other unpredictable unique index, and then the binary. Then, in your metadata tables just store a reference to the UUID. If it doesn't work out, you just dump your entire database to whatever other mechanism you chose to use. Personally I'd suggest planning ahead, abstract out your file storage mechanism and write an interface with simple write(), exists(), fetch() and delete() methods and then use that interface to provide a concrete service for your file storage. If it does turn out the DB can't handle it (not that it should be the case) you can just change the concrete instance behind the interface and there's no other code changes required. I'd leave the database to its own devices to handle its own internal memory management, and would layer my own in front of it in PHP. Personally I dump a lot of on-demand generated javascript / css files in to a database table because the servers are running in a cluster without sticky sessions, and the static file servers are replicated asynchronously which opens up the possibility of race conditions. My binary table is path (PK), mime type and blob. It's all processed through a service interface as described above, so on my local environment where it's just the one machine, instead of pushing it into the database, there I do just write it to disk, or in some cases, short-lived and self-regenerated blobs I just shove it into redis. Redis is actually a pretty good front-end cache if you don't have immediate access to change the webserver-side caching rules. I first hit redis, and if it can't be found in there, I fall back to the database. NGINX handles most of the work of caching though in my case.
&lt;div class="wpep-amount"&gt;$ &lt;?php echo $amountl ?&gt;&lt;/div&gt;
If images can go above icon size I’d skip the db and use S3.
This stacks thread has some relevant info for you: https://stackoverflow.com/questions/14650932/set-value-to-currency-in-input-type-number On the other hand you could just use a text input and then check if the value they enter is a number. This seems like the simplest solution to me.
I ran into this problem on a client website a while ago. Godaddy barely documents the fact that it blocks all 3rd party smtp relays. You have to use theirs: [https://www.godaddy.com/help/send-form-mail-using-an-smtp-relay-server-953](https://www.godaddy.com/help/send-form-mail-using-an-smtp-relay-server-953)
&gt; You don't necessarily need to store your binary next to your metadata, although you certainly could, it's best not to create that link in case you need to change it in future. The route I would go, if I were to be wanting to use a database for it, would be to have a separate database that was a AI PK, a UUIDv4 or other unpredictable unique index, and then the binary. Then, in your metadata tables just store a reference to the UUID. That's right down the alley of what we're considering. Besides it is clear that binary will be stored separately, needs a completely different optimization and workload type. &gt; If it doesn't work out, you just dump your entire database to whatever other mechanism you chose to use. Right. &gt; Personally I'd suggest planning ahead, abstract out your file storage mechanism and write an interface with simple write(), exists(), fetch() and delete() methods and then use that interface to provide a concrete service for your file storage. We already have a set of functions in this line, however you have a great point with abstraction. We're going to create this abstraction layer and change the file storage later should it become necessary. Forward compatibility IS very important. For some reason I see far less forward compatibility in starting off with a file-based system. &gt; If it does turn out the DB can't handle it (not that it should be the case) There's no reason not to be able to handle it. &gt; I'd leave the database to its own devices to handle its own internal memory management, and would layer my own in front of it in PHP. Correct. &gt; Personally I dump a lot of on-demand generated javascript / css files in to a database table because the servers are running in a cluster without sticky sessions, and the static file servers are replicated asynchronously which opens up the possibility of race conditions. I've had somewhat similar issues in the past, thank you for mentioning. I must observe, it's an active way of managing the content rather than file caching which might not be perfect in certain cases such as the one you're mentioning. &gt; Redis is actually a pretty good front-end cache if you don't have immediate access to change the webserver-side caching rules. I first hit redis, and if it can't be found in there, I fall back to the database. NGINX handles most of the work of caching though in my case. Only used memcached so far, but it's about time to start with Redis. Thanks! 
You need to use single quotes if you want a literal dollar sign 
Hey, thanks for the comments &amp; suggestions! It's always nice to receive feedback on the less technical aspects, such as tooling &amp; project layout. RE: testing exceptions – that makes sense. I'll probably end up doing that when I refactor the tests to be more maintainable. What you would add: - I've looked at PHP STAN &amp; think it's a great tool, but much prefer the visualization that the [PHP Metrics library](https://github.com/phpmetrics/PhpMetrics) I am currently using in dev dependencies, offers. - good idea on adding `7.3` to the CI pipeline! I'll add that in over the holidays (feel free to make a PR yourself though!) What you would change: - You both make good points about code style enforcement. After some reviewing of my current setup with `husky` + `lint-staged`, I think it fits an opt-in practice, given that it's only activated via an npm install, in a PHP project. :) - the tasks performed in the Robofile require user input, otherwise they would be simple composer scripts like the others currently in there. - the pretty printer is mostly there for easy reading of CI output. PHPUnit's default dot-matrix-like output (with no built-in alternatives) has always gotten under my skin. If the project begins to receive more contributions &amp; I get another comment about the pretty-printer, I will end up removing it. :) - the `.vscode/` is there for pre-configured debugger configuration &amp; common file formatting. This is to ensure that VSCode users are commiting the same file formats across operating systems (damn Windows &amp; their carriage returns....). FWIW – I would gladly commit the `.idea/` directory if I used PHPStorm, but I don't, so someone who does would have to commit it with the equivalent files. - good point on the API docs being nested appropriately within the root `docs/` directory. I'll get around to doing that! :) RE: documentation &amp; mkdocs – I too am not happy with any of the PHP solutions (even for API documentation with annotations...). I've tried mkdocs in the past, but found it to be a little too simple for my liking. I also dislike that it requires Python (speaking of less dependencies... 😉). If I go the route of mkdocs for the user documentation, I think I'll have to move the documentation to its own repository (both API &amp; user docs).
Only if using full backups. There can be such thing as an incremental one. Our system is actually built for incremental. Besides, updates are infrequent. MySQL storage is much more flexible in terms of forward compatibility compared with filesystem. You have a point but again it depends on how it's done. We're not going to use S3 or similar for certain reasons (longer story).
With regards to versioning and the likes, I'd recommend just using a different file name for each version and leave the files unchanged, just not exposed by any of the front end. Once the URL has been exposed for the first time it should be considered in-the-wild anyhow, unless you're worried about someone leeching bandwidth from them.
I don't think it's necessarily *bad* on its own, just that it's not something I'd announce as one of my project's selling points. There are 2 main reasons why I believe that nobody should support EOL-ed PHP versions: 1. It encourages the package users to avoid upgrading to a still supported PHP version which results in a slower new version adoption. 2. It prevents the authors from using any of the syntax improvements implemented in the last **6(!)** PHP versions. That includes scalar and return type declarations, variadic arguments, generators, anonymous classes, multi-catch exception handling etc. I could go on like this for a while. I also don't think comparing a video game to an open source library is a good example. 2GB of RAM don't become a security risk after a couple of years.
That's precisely how it's done / considered already. (note: not really worried about leeching). I've learned a lot via this post. The thing is, we already have the blob version in (can be upgraded, of course) and in fact I'm hereby guilty as charged, of premature optimization. So it will stay as it is for now (blob). Should we decide later that we need something else, through a standard interface as you suggested, changing the solution will be easy. Furthermore there's no issue to converting MySQL data to a load of files in whatever format. So I'd rather focus on something else right now. Funny thing how we see the wrong aspects sometimes.... But it's a good, ideas-bringing discussion.
I completely disagree with the php range you said in 1., this attitude don't help lazy developers who don't upgrade PHP version and there also not supported anymore in the security fields
That dollar sign is not within php tags, so ... no i dont.
But the blacklists know. 
Thanks this got me in the right direction, it works great now. &amp;#x200B; This is a short version of what works `$data = array();` `$postvars = trim($_POST['all']);` `// split newlines into array` `$lines = explode("\n",$postvars);` `$property = array();` &amp;#x200B; `foreach($lines as $key=&gt;$val){` `if (stripos($val, ':')){` `$val = preg_replace('/\s+/', '', $val);` `$lines = explode(":",$val);` `$property[$lines[0]] = preg_replace('/\s+/', '', $lines[1]);` `}` `}` &amp;#x200B; `$data['xyz'] = preg_replace("/[^0-9]/", "", $property['xyz']);` `...` `echo json_encode($data);` &amp;#x200B;
Personally, I feel like I often easily do 10-1 reading vs writing. 
No problem. Glad I could help. To be honest, I didn't expect that my comment will be that useful to you and was worried that it was unnecessarily harsh (it's sometimes hard to find the right balance between being objective and sounding like an asshole). Regarding your answers: 1) I kind of understand your point, but in my opinion it just encourages people to avoid upgrading to a supported PHP version. Perhaps it's possible to keep supporting PHP 5.4, but increase the version requirement in the next stable release? If you follow semantic versioning, breaking changes are acceptable between major versions. Any new features would be limited to the latest version, but this way you could still allow people who are stuck with an outdated PHP version to use your package. 3) In my opinion `"echo $this-&gt;render();` would indeed be better. Alternatively perhaps you could split the content generation and the rendering in 2 separate methods? For example, public function render($view=null, $return=false) { echo $this-&gt;generateContent(); } public function generateContent($view=null, $return=false) { // return the content as a string } In my opinion it would be a bit more clear since the return type would always be the same. 4) Sorry, I meant the return statement after the exception. Throwing an exception would abort any further execution, so the return part would never be reached. 7) I don't think that it's a good idea to have a common behavior for **ALL** your classes. I've yet to see a real life example where that would be appropriate. If all your classes share behavior, then it it's most likely a sign of SRP violations or simply a poor design (one very common example would be when beginners don't understand inheritance and create something like this: `class User extends Database {}`). 9) Such naming may work initially, but eventually someone will start to use negation in combination with these methods which will result in hard-to-understand code. Unfortunately I've seen too many examples of this (e.g. `if (!$this-&gt;isNotEmpty())` vs `if ($this-&gt;isEmpty())`). If it's the end user, it doesn't affect you. If it's someone on your team however... 11) Sorry, apparently I forgot to add a link. I probably meant [this](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/core/DataStore.php#L987). Unless there's a good reason for this which I've missed, you should be consistent. I believe it's possible to configure this in PhpStorm (possibly in combination with CS Fixer, although I'm not sure) so the IDE warns you if you use other options (e.g. you configure the preferred option as `static`, and the `DataStore` line will have a warning). 12) I'd suggest using https://github.com/FriendsOfPHP/PHP-CS-Fixer or a similar tool as a part of your CI pipeline. It can also be set up as a Git pre-commit hook but it's harder to enforce. Once you define your code style rules, you simply add a line to your CI script that checks the diff (e.g. `php vendor/bin/php-cs-fixer fix --diff --diff-format=udiff --allow-risky=yes --dry-run`). If there are any differences, the script will fail (pretty much the same when tests fail) and the person responsible for the commit will have to fix the code style. Internal code reviews would also help a lot, especially in the beginning as those issues will repeat much less often once your team gets accustomed to the preferred coding style. 14) I'm not sure I understand. How is string processing related to missing braces in your conditional blocks? I meant `if ($condition) { return true; }` vs `if ($condition) return true;` Regardless, your choice of string quoting shouldn't be dependent on performance as the difference is negligible. If it ever actually causes a noticeable difference, you have seriously messed something up. See https://secure.php.net/manual/en/language.types.string.php#120160 for a semi-recent benchmark. 17) Yep, that's the one. Static methods *may* be fine if they're stateless (e.g. `Math::round($number, $precision);`) and always return the same result for specific input. Once you introduce state, your application gets noticeably harder to debug and it's generally considered a very bad practice. If you limit it to 1 place, it might not cause any issues, but it rarely stays that way. See https://blog.codinghorror.com/the-broken-window-theory/ for an explanation. Another reason why you should avoid static is that it's much harder to perform unit tests since it's no longer possible to maintain isolation - you have to know how the static class works internally and adjust your tests accordingly. From my experience, unit tests can be severely simplified once you refactor the static class to a non-hidden dependency. I did a rough overview of the rest of the project and noticed a few additional things: 1. You're using PhantomJS for running browser tests, but it's no longer supported. I'd probably consider other alternatives (headless Chrome is one). 2. You can safely omit the empty `_before` and `_after` methods from your tests as they're not required in Codeception. 3. Not a fan of testing private methods such as [here](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/tests/unit/koolreport/core/WidgetTest.php#L25). They should be covered by testing the public interface of the class. I'd strongly recommend [Infection](https://infection.github.io/) as an alternate way to test them, but it doesn't support Codeception at the moment (only PHPUnit and phpspec for now). Still, it might be useful to you in the future. 4. It seems that you've hard-coded the DB settings in your tests. You should probably be using a dedicated database for tests that gets cleaned up and repopulated after each test suite (quite easy in Codeception). 5. You're mixing operators [here](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/datasources/OracleDataSource.php#L211). I'd avoid `or` and `and` unless absolutely necessary (and even in that case there would be better options). There may be some unexpected side effects since these operators have lower precedence than `||` and `&amp;&amp;`. See https://secure.php.net/manual/en/language.operators.precedence.php. 6. There are inconsistencies in method name casing - in some places you use camel case while in others it's snake case. To be honest, I expected to find more issues but there were almost no new ones as they are mostly the same as in the library core. By the way I learned something new as well - I didn't know [this](https://github.com/koolphp/koolreport/blob/f5182437c11670e34d57655ea7c1d549bdde024b/src/widgets/google/Timeline.php#L45) was possible. Learning new things is actually an underrated result of reviewing code. P.S. Sorry for the first list formatting. It's this way because Markdown doesn't allow to skip list items.
If you ever need a code review, feel free to PM me. I'm serious. I don't mind doing them (even outside of my work) since code reviews are a great way of improving the overall code quality. Besides, I might learn something new as well. There's also https://codereview.stackexchange.com/, although the results may sometimes be hit and miss.
How about you show us what you've done instead of being an asshole?
i came across this question before: [https://stackoverflow.com/questions/6313969/phpstore-image-into-mysql-blob-good-or-bad](https://stackoverflow.com/questions/6313969/phpstore-image-into-mysql-blob-good-or-bad) and more here: [https://www.quora.com/Is-it-a-bad-design-to-store-images-as-blobs-in-a-database](https://www.quora.com/Is-it-a-bad-design-to-store-images-as-blobs-in-a-database)
thanks
A few things to consider: increased bandwidth between the web server and the db, longer connections due to streaming the data and hence need larger connection limits. You will hit more limits like max packet size etc too. I would argue for using something like s3. There are plenty of self hosted s3 alternatives.
Go daddy is a terrible company that will give you nothing but trouble while up selling you every step of the way. Mail is also a complex issue. For transactional mail (automated mails from a website) I highly recommend mailgun with their rest api. Good deliverability and no bs with blocked ports. 
Thank you so much for your feedback!
It depends on their cost to upgrade their system. Problem is that company does not want to upgrade, they don't way to pay developers to upgrade ( because everything seems good to them now), so they look for library that suit them, not library that add more cost to them.
https://www.koolreport.com/examples/ "See examples" takes you here, but I can't see anything there.
You mean the url does not work?
I'll admit that I have never had the need to do this in a project on a large scale and therefore am just someone interested and commenting from afar. What nobody has mentioned yet is the possibility of storing the metadata about the file in MySQL but the blob itself in a NoSQL database. Would there be any benefit to this over using a separate table or SQL schema for the blobs (for performance, backup, or replication convenience)?
Using the file system seems like the correct choice. The complexity is keeping the dab and the file system in sync. Caching shouldn't be hard either, just use cloudflare it'll take care of it for you. I don't know what you mean by mysql storage being more flexible than the file system. You also seem to have made up your mind already.
https://i.imgur.com/y4NGgyC.png There's nothing in the example paragraph.
Appreciate the article. Our production server utilizes nginx. I’ve had a hell of a time getting a nginx php setup going that supports Wordpress. Particularly, we had some clients who couldn’t upgrade to 5.0.0 right away, and the Wordpress image doesn’t allow for old versions (I guess they delete them?). If anyone could point me at an nginx, php, mysql setup that’ll allow me to run Wordpress I’d REALLY appreciate it. 
Thank you sir for your kind words. I have not tried a WP image but I'd always refrain using such \_niche\_ images like Laravel, WP or even Drupal. The best is to have an image that supports the basic technology and then build your own as per your requirement.
Those 3 aren't niche at all!
Please browse the examples on the left menu, there are about 100+ examples. The page you view is home page.
Please browse the examples on the left menu, there are about 100+ examples. The page you view is home page.
Good advice, thanks. 
... That's pretty bad UI. Show the content I'm after in the main column, not in the menu, they're ignored most of the time.
Storing images in MySQL is not ideal. Not only do you very quickly push backup times through the roof, but it's very space inefficient to boot. When you store an image in MySQL as blob text, you've got the disk space of the image combined with the overhead of the rest of the columns in that record. Then, if you've got an index on that table, you have to add in the space for the index to boot. You could save all of that extra overhead space by just storing the image as an image on a disk. I say this not as some neophyte, but as the data engineer for a very large dating site. We have over 17 million members with an average of 3.4 pictures per profile. Additionally, we store 2 versions of the image (one original, and one with our watermark). So we're looking at somewhere in the neighborhood of 115 million images. We store it on S3, using CloudFront as our CDN (which hooks directly up to an S3 bucket, meaning we don't have to do anything special to get the images into a CDN). In the photos table, we store the uid of the image (32 byte string unique identifier). Storing the image on a CDN means that we don't have to use our bandwidth to deliver a photo to the customer. It also means that the customer gets that image faster than they'd get it if it was coming from our servers. And it's insanely cheap. S3 charges 2.3 cents per gigabyte for the first 50 TB of data. You say in this thread that you don't want to get into the issues of why you're not using S3, but I mean... availability is amazing, pricing is amazing, it's incredibly easy to use, and it's incredibly reliable. What reason could you possibly have for wanting to stick your images in a database instead of using it?
I feel your seeking confirmation instead of an answer; every suggestion to use file storage is quickly dismissed... You mention different versions. I hooe you mean actual versions and not resized variants of the images. That would remove every form of flexibility. What if your image manipulation library receives an update. You will not benefit of thus, because you have all variants stored in a database. Or consider the relative recently introduced high resolution displays; these require images double the size of how they are displayed. When storing resized images you’ll need to run resize/reindex operations which will be a pain. The reason why I would personally never store images in database blobs (again) is that you might have multiple images per pageview. These will - hopefully - all be separate calls to your application server. And every call will have to fetch a significant amount of data from your database. While thus happens your connection will be busy. And more data means longer connection time. As your traffic grows you will suffer more from this; longer open connections typically results in less concurrent connections and thus you would need to upgrade the database set up. Typical solution is to store metadata in a datastore - for example a database - and the _raw_ binary data on a file storage. This does _not_ need to be cloud based. Scale on request and cache in a proxy like Cloudflare. Reading from memory is a whole lot faster than reading from a database. Additionally you can store resized images on disk; reading from disk is faster that reading from a database. Especially now everything is ssd. You can opt to pre-rendering images on upload for faster performance. As said; I feel you are seeking confirmation instead of an answer. I’ve stored images in blobs in the past and I experienced the performance hits on the database and problems with the introduction of redesigns, new images rendering techniques and retina screens. You are much more flexible with file storage. After all, images still are files...
I feel your seeking confirmation instead of an answer; every suggestion to use file storage is quickly dismissed... You mention different versions. I hooe you mean actual versions and not resized variants of the images. That would remove every form of flexibility. What if your image manipulation library receives an update. You will not benefit of thus, because you have all variants stored in a database. Or consider the relative recently introduced high resolution displays; these require images double the size of how they are displayed. When storing resized images you’ll need to run resize/reindex operations which will be a pain. The reason why I would personally never store images in database blobs (again) is that you might have multiple images per pageview. These will - hopefully - all be separate calls to your application server. And every call will have to fetch a significant amount of data from your database. While thus happens your connection will be busy. And more data means longer connection time. As your traffic grows you will suffer more from this; longer open connections typically results in less concurrent connections and thus you would need to upgrade the database set up. Typical solution is to store metadata in a datastore - for example a database - and the _raw_ binary data on a file storage. This does _not_ need to be cloud based. Scale on request and cache in a proxy like Cloudflare. Reading from memory is a whole lot faster than reading from a database. Additionally you can store resized images on disk; reading from disk is faster that reading from a database. Especially now everything is ssd. You can opt to pre-rendering images on upload for faster performance. As said; I feel you are seeking confirmation instead of an answer. I’ve stored images in blobs in the past and I experienced the performance hits on the database and problems with the introduction of redesigns, new images rendering techniques and retina screens. You are much more flexible with file storage. After all, images still are files...
http://devilbox.org is nicely done and worth a look if wanting Docker for LAMP/LEMP local development. As with all these magical tools, you may get lucky and they just work. As soon as they don’t, you may have been better to invest the upfront time to learn each component well. 
Let's assume there is a gallery page with 20 images Filesystem: - PHP process that returns HTML - all images are served directly by a super-fast Nginx HTTP server Database: - PHP process that returns HTML - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output - PHP process that creates a database connection, allocates memory for the image, fetches it from the database and sends it to the output So well. If you have a shitload of extra CPU power and RAM - why not? 
&gt; repeatedly reading small chunks from a drive As though a database is storing its data somewhere else. Surely it reads the requested file directly from Luminiferous aether.
https://ddev.readthedocs.io/en/stable/ Ddev is another nice way to use Docker for local development. Replacement for MAMP/XAMP/LAMP. Very helpful slack community too!
If you're really interested in using a proper abstraction layer for this, perhaps you could write a MySQL adapter for League Flysystem. That way, you don't have to invest in writing a new adapter once you do need to swap out the implementation AND you could choose to use a different implementation on dev, and test (not acceptance, obviously), to simplify setup.
Devilbox just works, documentation is really well done too if you need to change the php version or something simple like that.
How it's even possible that this shit is upvoted 40%?
Looks like there are several seasons of this shit. Can we have it banned in advance? 
It's not even in English is it? Or is it the heaviest Indian accent I've ever heard? 
&gt; You also seem to have made up your mind already. It might seem so, but not necessarily. Still exploring both solutions. I guess the most important aspect I've discovered via this post is that we're doing premature optimization (yeah, we shouldn't). That's a side benefit of the discussion. The fact is, we already have the blob-version in place. We might simply just use it for now and optimize later (see above reason) and just create an abstraction layer short-term (might be good to have anyway). Each method has its pros and cons. Filesystem storage and Nginx for example is going to beat the hell out of the DB in raw performance. I do however see the blob version as simpler and easier to maintain, at least for now. Is it a solution for long-term? At first glance not, but many of us technical persons often feel the need to search/think deeper. The truth is, it's just a different way of doing storage, more organized and allowing better sync and metadata storage, but with obvious larger overhead. It does have some benefits though even if not everyone sees them. Can it be a solution? Maybe. Still cannot rule out the solution. I've just computed (based on estimated file storage needs,) that *we can easily cache and serve from RAM, about every image that is to be served*. This makes the DB storage layer nothing but a "cold storage" for images where actual calls will be made only for fewer new images or when caching server is restarted. And in fact we're going to cache as many images as we can anyway; even if stored as files. The caching layer, done properly, might make this slow bulky storage issue not perceptible. The difference here relies in the caching mechanism; and commonly, just like posted here, straight file storage will be preferred as cache will be viewed as an additional complexity and hassle. There are similar things in the CMS world, just giving an example as to how a different solution might work. Most open source CMS out there (WP, whatever) are anything but light. Raw, non-cached performance of the CMS is terrible in comparison with a lightweight custom CMS, optimized for speed. Without caching, it cannot really be a solution for a heavy load website. Yet with caching and proper hardware, it is - countless sites around the world using it. WP is good in certain directions, while other negative effects are counter-balanced via caching. We have a lightweight CMS and everything we do/use IS and will always be cached whenever possible. This changes certain aspects. This still doesn't mean we're dead set on using blob forever, again see above. I hope it makes more sense now. 
Could do. There's no reason why you couldn't, at the end of the day you usually just end up having a table that's a key-value store to hold the blobs, and the technology you use to back it, be it traditional rDBMS, NoSQL, local file system, cloud server or whatever mechanism you end up choosing, is more down to the specific business case. On many file systems, each file can act a little bit like its own database, things such as alternate data streams are used to contain information such as the last time a file was scanned by AV, or its pre-computed hash, ACL records and so forth. If you've just got one server and one location to write to, the filesystem will be the right place 95% of the time, but that's obviously different from saying never use a DB or other technology.
Thank you for your comment. We're going to research and possibly use a file version anyway, perhaps later. See other comments in this post; I've explained the reasons why the blob version is not dismissed yet, though it might be replaced later. As for S3, it's a solution favored by many (there are reasons why) but not going to be ours. We're in Europe and have extremely low cost on bandwidth and large capabilities. There is no cost advantage for us in S3. We'd stay out of the need to lock in an additional cloud provider. And not going to use AWS anyway for additional reasons, more complex ones and outside of the scope of this post. We did use and test most cloud providers out there BTW. 
Well unlike (most) file systems, databases are usually configured to store vast quantities of data, particularly that which has been recently accessed, in active memory.
My development environment depends on vagrant with shell provisioning. Should I switch to docker? What are the pros/cons?
I’ll throw in a recommendation for [Laradock](laradock.io). It’s obviously Laravel focussed, but works great for any PHP project and includes tons of different containers easily configured by a .env file. 
Not dismissing anything. I've posted some things in favor of the blob solution, just as they still appear to resist the reality check. This doesn't mean whoever favored the file solution isn't right in the end. It seems logical for us now to continue using what we have (blob), put an abstraction layer in, and upgrade to a file solution later when time comes. It won't be that difficult and we don't have to consume precious time now and delay the launch. In practice though, with the system we're thinking about, there might be no perceivable difference between file-based storage and database storage: &gt; Scale on request and cache in a proxy like Cloudflare. Reading from memory is a whole lot faster than reading from a database. Because basically it appears that each and every image served will be 100% served from the cache and not from DB. Done the math already, we're barely going to use 1-2GB of RAM to cache all images as not all images will be served, some will simply stay mostly stored long-term. DB simply becomes some sort of cold-ish storage with usage only when priming the cache and for new entries. In such a case, there is likely no perceived difference and no complexity for us. 
What does ddev offer beyond vanilla Docker?
&gt; A few things to consider: increased bandwidth between the web server and the db, longer connections due to streaming the data and hence need larger connection limits. You will hit more limits like max packet size etc too. Blob storage (if used in the end) will be done on a different server with differently tuned my.ini. Besides, the cache will take 99% of the load off as we're about to cache 100% of images served anyway. And for S3 - no reason to use as we have plenty of bandwidth at low cost here in Europe. But still there's point in your observation with packet size etc., noted. In the end, there's no telling on what we will use at the time, but preparing for it, hence this post.
:) excellent point, But caching makes it all different. The above is still valid, but done ONCE for each image - when the cache server is restarted. Then... silence. In fact, even if using a filesystem solution, we're going to cache everything anyway. That blurs out the difference between the two.
Almost all of these, in my experience, just offer a wrapper + maybe some artisan/console commands built in. Basically they are training wheels and excellent for learning, while remaining productive. Beyond that, most have lost their value over something like docker compose, now that I know how to build cli containers, and the exec command.
&gt; All I'm saying is that not everyone's situation is the same. This makes choices often harder to understand. That doesn't matter, it's Reddit, people will downvote you regardless :)
I did discuss a bit about it :)
Interesting observation and approach. NoSQL could, in essence be a part of a suitable storage layer mix.
&gt; If you've just got one server and one location to write to, the filesystem will be the right place 95% of the time, but that's obviously different from saying never use a DB or other technology. Excellent comment, nailed it.
Dunno what an "active memory" is, but apparently mysqld do not take up all free memory on the server. **While the filesystem cache does**. "vast quantities" is another hilarious statement. As though again a database stores its data somewhere in the Dark Matter, not in the files lying... in the same filesystem.
Agreed for prod and container native hosts. However, many of these projects don't have dedicated ops, and use services like wp.com, platform.sh, or acquia cloud. In those cases using something like wodby works great and will be less error prone than vm's. I wrote https://GitHub.com/bixal/drupal-project as a starter to get devs up and running and learning docker. When I can get into the project I then swap out the nginx and php services with my own built ones. But it provides a generic quick starter with an easy and smoothe migration to put hardened images.
I know :) Funny thing is, in everything I did successfully over the years, went completely against mainstream. So when posting about it, I got downvotes all the time. Yet for whoever saw the system live (market competitors; field experts; open mind devs; whatever) it simply knocked their socks off in terms of performance, easiness to maintain and even ongoing costs. If only posters could see the things from this perspective, they would rather be amazed and not downvote. I'm alright with downvotes, it's only the thing that conveying a certain reality through this medium is hard, sometimes frustrating, and represents a significant challenge for my English skills. 
You don't have a cache server at the moment. Caching isn't a silver bullet. There is always a cache invalidation problem. It seems you don't consider any opinion that is opposite to the solution you are already aimed for. Just curious why did you ask. (a rhetorical question, of course ).
There is also sprintf and encapsed approach - each better for a different situation. See [Hi, my name is Tom - Concat vs. Sprintf vs. In-String Variable](https://www.tomasvotruba.cz/blog/2018/10/11/hi-my-name-is-tom-conctat-vs-in-sprintf-vs-in-string-variables/)
If you re-read the post closely, you'd see that I'm actually considering opposite opinion. It just might appear as not. I've said repeated times that in the end file system storage might be the way to go. In the end. And that for reasons of avoiding premature optimization, we might still use what we have. For now. We'd better focus on something else at this stage, but guess what, measuring/tuning this blob system (even if temporary) is going to be interesting and challenging. Side note, we did use blobs in the past but never to a large scale. This means advice received here IS considered and weighted and might probably be the end result in production. Blob storage is what is now, and it's worth exploring at least for a while, since it's already running. We won't hit the performance wall tomorrow. &gt; You don't have a cache server at the moment. Actually we have two. One, the db server already has in-built caching. Two, image rendering from blob is already cached, you just tune your cache size and off you go. &gt; Caching isn't a silver bullet. 100% agreed here. But nothing else is. 
For me it's just easier than maintaining vm's. Dockerfiles are basically bash (easier to read than Ruby imo) and more dev friendly. Also it's layered so I can update one images shared settings (common php in stuff) and have it update all of my apps at once. All of this is possible in vagrant/vm's but I'm much much easier. I was a vagrant hard core guy but after 3 months of using docker I'm never looking back.
Yeap, after reading that paragraph I wanted some more information regarding it. Thank you by the way for this great article.
You can scale your docker based services. Check out [this](https://docs.docker.com/engine/swarm/swarm-tutorial/scale-service/) link.
Looks good!
as you can see, writing your help questions in /r/phphelp would be more convenient. Not to mention they will be much more welcomed there
My bad, can you check that ?
Oh man. I had no idea. Thank you! 
Thank you! Will they not let me use "mailgun"? Other Redditors have mentioned this service and I haven't tried to implement yet. 
Thank you! You're the 3 person to mention mailgun so I'll be checking it out. I'm learning this about Godaddy. Who do you recommend? What about Host Gator? 
It would be perfect if you could set a different PHP version for each projects without having to edit the .env and restart Docker :/
Ive never understood why a php developer would need docker? What issues can you even be solving? What am I missing?
As someone else pointed out, godaddy apparently blocks outbound smtp, so if you do end up using mailgun, you’ll need to use the API instead of smtp, unless you can use a non-blocked port.
[removed]
Post in the correct subreddit, include your link in the body so it actually comes as a link, and elaborate on your issue. 
I suggest heading over to r/phphelp for a quickly reply - We usually only respond to "help" style questions in this subreddit when there's some kind of software engineering or architecture questions to play about with.
Yes sir. Thanks for that input!
The benefits to docker are nothing specific to PHP. 
I would use the file system a long with varnish. Our own system is storing several GB of images, we serve them from NGINX. My dream this coming year is to replace it with something like cloudflare and decommission the server its on. The less servers I have to manage, the better.
What I mean is like, you don’t need anything but an out of the box linux set up?
PHP relies on a lot of external libs for various bits of functionality and a lot of people write systems that rely on external functionality that is at least a bit platform dependent. Docker lets you put a large amount of those dependencies in a container that can run on other linux systems that would otherwise not work. Just because it's linux doesn't mean it has the same version (or any version) of libcurl or that it doesn't already have an incompatible version of mysql/mariadb running that can't be swapped out for the version your system needs.
What are your difficulties with managing servers? We don't feel any of that, managing about 6 right now with no issues. (had even 20 in the past) But overall, I agree with minimizing the number. This is why we focus on baremetals mostly, and using as low number of servers as possible. Our code is lightweight for the same reason, serving as much as possible with a single server. Varnish makes sense in the stack. Never used it so far - but AFAIK its a reverse proxy/cache so it won't be an issue to get along with it. As to the final configuration choices, we'll see which one will fall into place. One interesting option I'm exploring right now is to use a hybrid approach. It's neither file nor db primarily, rather both. The database will hold a master copy of the data, and of course the meta (they are however served by separate servers). In this way the db server acts like a cold storage instead of a live serving one. When an image is requested for the first time, it is obviously pulled from DB but then saved on disk as an intermediate file and further requests will be file-based and possibly also cached at the same server level. Adding a separate caching server would make sense if the metrics will show it's worth having there (possibly so). Anyway in such a layered/fallback design there's no heavy network data or heavy load on the file storage server. And besides, setting this up is very easy for us. But I agree that many won't see the advantages here and would go for a simpler setup.
The hassle is I work for a small company and I do it all, development and infrastructure. It's another server to apply monthly patches to, another O.S. to eventually upgrade, another server to verify is in PCI compliance, and another thing that can/will break. I think the option you mentioned there is a good one. No serious changes to your architecture and you'll reduce load on the DB. You're still storing a bunch of data in that database though.
check logs and see whats failing most likely mis-configured php.ini or missing extension 
no my site was working fine i mistakenly done this. my site is working perfectly fine and i just used this command and not site stopped working 
when i use this i got this output : Redirecting to /bin/systemctl restart php-fpm.service &amp;#x200B;
without checking logs it's hard to know what went wrong this command does nothing more than stop and start try running service php-fpm status and read the log
&gt;i got this Redirecting to /bin/systemctl status php-fpm.service ● php-fpm.service - The PHP FastCGI Process Manager Loaded: loaded (/usr/lib/systemd/system/php-fpm.service; enabled; vendor preset: disabled) Active: active (running) since Mon 2019-11-25 10:44:07 UTC; 10min ago Main PID: 1247 (php-fpm) Status: "Processes active: 0, idle: 5, Requests: 27, slow: 0, Traffic: 0req/sec" CGroup: /system.slice/php-fpm.service ├─1247 php-fpm: master process (/etc/php-fpm.conf) ├─1249 php-fpm: pool www ├─1250 php-fpm: pool www ├─1251 php-fpm: pool www ├─1252 php-fpm: pool www └─1253 php-fpm: pool www &amp;#x200B;
I guess I just haven’t run into any yet. I’ve been using digital ocean droplets so you just choose your os and install what you want, I haven’t figured out what I eould need it for, yet
well it seems php service is running there supposed to be some logs just below these pool www if you are unable to find them just use this command journald -f and then visit your site it should report something there as well
&gt;i got this \-bash: journald: command not found &amp;#x200B;
Did you recently upgrade to 7.3?
what linux distribution do you use? jounald is usually part of systemd package 
no, my site was working fine, i by mistake added this code in ssh and now site stopped working
Turn it off and back on again and check the syslog.
 [CentOS](https://en.wikipedia.org/wiki/CentOS) 7
&gt;yes after above code i used **service php-fpm stop and then** **service php-fpm start but still site not working**
oh i haven’t used centos in ages try this tail -f /usr/local/apache/logs/error_log if it doesn’t work go to cd /var/logs and manually search for logs. 
Glad to hear such a positive feedback. Merry christmas and happy new year to everybody 
i opened log and i see a error but i do not understand it
you can post it here or pm me
i sent you a massage 
Is there anything in syslog?
No, you absolutely don't *need* more than that. And if you're managing a single application on a single host, that's probably far easier to get up and running. When you start doing stuff at larger scale though, Docker makes things tremendously easier. Doubly so if it's not a homogenous environment. At work I manage deployments of applications written in four different languages (plus half a dozen third-party tools), and it completely eliminates issues with missing or conflicting dependencies, resource allocation, and horizontal scaling. Compared to using a pretty comprehensive Ansible setup at a previous job (never mind SSH followed by a bunch of apt commands), it's like night and day.
yes, i got some thing like this : FastCGI sent in stderr: "PHP message: PHP Warning: require(./examle.php): failed to open stream: No such file or directory in [https://](https://gadgets7.news/js/sidebar.css)mysitename.com/example.html on line 5 PHP message: PHP Fatal error: require(): Failed opening required './examle.php' (include\_path='.:/usr/share/pear:/usr/share/php') in [https://](https://gadgets7.news/js/sidebar.css)mysitename.com/example.html on line 5" while reading upstream, client: [46.229.168.136](https://46.229.168.136), serve$
I've used both quite a bit for various OS and languages. The pros of a Vagrant setup are that it's a VM, which can be paused, inspected via the GUI and persistent storage is on by default. The cons I've found are it's incredibly slow. When you're troubleshooting steps in your provisioning, it can be painful. There are also a lot of vague error messages I've encountered when instantiating. Spinning up multiple instances pre-allocates a lot of resources. So, in the case of WordPress or anything using Local by Flywheel (Vagrant and VirtualBox, I believe), it's limited to a few simultaneous instances on a laptop. Oh, and network file share speed can be terrible. I've only used Docker in production once, so most of my experience is for local development/quick test environments, for which the speed is the real selling point for me. Next is connectivity, if I want to add on an FTP server or Mailcatcher or the like to quickly test that functionality, it's minimal code and a couple of seconds to spin up and connect once I've initially downloaded the image. Another benefit of Docker, is the ease/support of CI/CD tools, like CircleCI. I'm not qualified to talk to the merits of using it in production, Kubernetes or the like. I moved away from primary local development in Docker to get more familiar with core tools in OpenBSD. I've since switched back to an Ubuntu host and an array of local Vagrant and Docker-based hosts, along with remote VPS instances to have an array of environments to test against (I'm a WordPress plugin developer, needing to simulate a fraction of the infinitely customized environments my users have in the wild). &amp;#x200B;
&gt; The hassle is I work for a small company and I do it all, development and infrastructure. It's another server to apply monthly patches to, another O.S. to eventually upgrade, another server to verify is in PCI compliance, and another thing that can/will break. I understand. My view over the above is that it's not a technology choice issue, but rather a management issue. Perhaps you need another employee to take on part of the workload. One thing I've learned over the years is, if you're feeling overwhelmed then you're trying to do more (at once) than you can. If you break into steps and still overwhelmed, that's likely a HR/management issue rather than a technology issue. &gt; I think the option you mentioned there is a good one. No serious changes to your architecture and you'll reduce load on the DB. Indeed, it requires minimal changes over existing solution and removes some of the caveats. What people often forget is that server hardware is actually CHEAP, especially baremetal. So is bandwidth. Developer hours, that's expensive. From a developer standpoint, this solution is easy to deploy, understand, and manage. &gt; You're still storing a bunch of data in that database though. Not worried about that. I've worked with a lot of DB data over the years. I've just calculated that the total estimated image data will be in the range of less than 30GB (at its peak). Around 1GB next, and less than 30 at max usage of the platform. That's NOT a huge database, and please note that new data is more like dripping in. Plus, the data is read more in a linear fashion, no joins etc. So it's plain read and write to disk. Furthermore, only 20% or less of the images will be in active usage; and the most will be used the thumbnails. If you put all this together it shows as a fully cacheable solution, from the images standpoint, even on a single server where there is plenty of ram and managed correctly. The same will be the workload on the backup, if any. Any incremental solution will further decrease the need for additional data. I see no reason to worry about that. We're planning to have a master-slave-slave chain for the blob/file data (at least), where master is remote, but both slaves will actually reside in 2 different physical offices we have with existing high-bandwidth connections, long-time UPS backup etc. The reason for this is, should something really nasty occur with the host (as in host powerplant malfunction; been there and took them a couple days to fix the issue), having the data stored locally enables fast transfer of GB's or TB's on another SSD, hook to a local server and power up with minimal downtime. One thing I've observed in past experience is that transferring a lot of data back and forth via the internet takes looong time anyway. In this way even if the worst case scenario occurs impact will be minimal. It appears that what would be more intense is the non-blob data in database. A single account will have much more data and there is a lot of complex processing there requiring optimized application-level caching. 
This sounds more like a code problem. It can’t find a required include. Have you verified the file exists?
yes, files are exist, but now i fixed it i restarted the server and used this two commands First service php-fpm stop and then systemctl restart php-fpm.service, and now everything back to normal. thanks for your help, but i did not understand why it was first stopped working?
i fixed it i restarted the server and used this two commands First service php-fpm stop and then systemctl restart php-fpm.service, and now everything back to normal. thanks for your help, but i did not understand why it was first stopped working? 
Until someone found how to exploit an security issue and a large group of website get attacked
I haven't tried mailgun on go daddy but my guess is if they use smtp then it's probs a resounding No
There's also https://github.com/phpexpertsinc/laravel_quickstart Watch the installation demo video to see that it's easier than even trying to set up XAMPP: https://vimeo.com/254289186
We wouldn't know without access to your code and server. Could have been anything from a cosmic ray causing a memory corruption or something else on the server using too many resources temporarily or your hard drive is failing or you got hacked.
Can you paste it?? 
Thư PHP và Godaddy
Incredible, thank you for detailed explanation, it is too valuable for me.
I guess news teavels slow where he is at...
Docker files are YAML IIRC. The main problem I have with docker os that if you run it on Windows, you can't run Virtual box in 64bit mode...
Docker-compose are yaml. Dockerfiles are series of statements like ``` RUN apt install php COPY ./myapp /myimagesource ENTRYPOINT [php -s myimagesource/index.php ``` The vast majority will be sh and typical vm creation steps. It might be parsed as yaml (although I'd guess that it's not at all, I just can't say it's incorrect) but it mostly ends up exposing ports, copying and building your app, and defining the environment. Docker compose on the other hand is yaml and defines your network and service layer.
What? Dockerfiles aren't anything to do with yaml (perhaps you're thinking of kubernetes). Docker also doesn't have anything to do with virtualbox anymore (minikube is virtualbox based though) 
Developing locally? Then being that, making sure images are artifacts which help troubleshooting and reduces, 'It ran on my local'. If your developing directly on d.o droplets, you when you have a moment should consider taking the time to learn to develop locally with a more industry standard workflow. If this is your career it will help you immensely.
Install Docker on Windows and it uses Hyper-V, which is that's enabled then Virtual Box won't do 64 bit. For the YAML comment: https://docs.docker.com/compose/compose-file/
Yes, I was half correct on the YAML thing. I havent taken the time to convert my old box over to Linux so I can run Docker more natively. Of course time vs other after work projects is slim. 
Looks like a typo. `examle.php` vs `example.php`.
Ah I had not heard of that before. If you're running vms needing more than 4GB RAM then you probably won't be hitting this problem (I.e. dont use virtualbox and use hyper v to host it). As for docker-compose: that's not really docker it's just a python script that wraps it. 
Well I run VMs that are not dockerized, since they are more OS based testing. I'm running a Ryzen 1700 with 16 GB. So the Hyper-V and Virtual Box issue is a known issue with no work around at the moment.
What is the better design approach? Getting data from the database and use it for your page(mvc) , or convert the data from your database to json format and use ajax to populate your page(mvc)?
I've been hosting my own vps' on Digital Ocean for years, so I'm slightly out of the hosters market. Google (or duck) for reviews of your desired hoster, read some top review and read some worst reviews, and decide based on that. Also if their site looks like it's a difficu to navigate sales apparatus and you had to opt out of 100s of extras before getting to the pay page, you know it's a bad company. Good hosters focus on their product. Poor ones on their sales. Good luck! 
Let's try to have an argument without referring to things as "evil" please. Programming is engineering. It's closer to math than it is to poetry. Imagine a mathematician telling you shit like "elliptic integrals are EVIL".
When you see someone talk about feature X being "evil" or an "anti-pattern", don't expect a rational argument.
There’s arguments for both I suppose. The first argument is going for the simplest approach which is direct integration with your database and just populate your view with data returned from your query. This poses the questions of us your frontend too tightly coupled to your backend, which leads me into option 2. Consider your backend an “api” and query your database as a REST api. This gives you the freedom and a sort’ve safety net to swap out both the front and backend in future. What will you be using for your http requests? jQuery Ajax? Axios?
&gt; Devilbox Let me take this opportunity to reach out to the community to help test pull requests, particularly one for MS SQL and one for Oracle. https://github.com/cytopia/devilbox/pull/446 Thank you! 
Both are fine, it really boils down to how you want it to be. You can freely switch between both if you have the time to do so. For me, if mobile app/web app involved, I'll do it API way. If nothing else is consuming my data, I'll just do it plain old MVC way.
Protected $works; ??
Whichever fits the particular case. If you're just going to render the data once, just put it into your rendered HTML. If you're going to need to manipulate it in-page, such as doing updates when new user data is added, consider using AJAX. You can actually pre-encode the data that you need when the page loads so you don't have to make another trip to the server to pull the initial data.
Already developing locally. I did run into a couple issues initially when deploying but they were all due a lack of knowledge and solving them with a docker instance kind of seems like overkill... plus I am developing on windows deploying on linux so it wouldn’t even make sense
yeah, op must think this is skyrim lol
you mean save a json file on a directory and get data from it? is that a better approach that getting the data from db and converting it to json with json\_encode
i will try axios. what do you prefer?
No. Bad. 
That only works for a dev or two and never scales well. Additionally if you are working for clients who expect highly available services, than you will almost certainly fail eventually in that work flow. If it's working for you, great; but for high performing organizations which need to limit errors before deployments and catch them in build pipelines docker is the premier technology at the moment. We use it to easily and automatically catch errors and push configuration you describe for not just php developers but node, Ruby, and python projects where a particular dev may have never touched a required service. Again for any team with more than a few devs, and isn't hindered by legacy technology, containers and docker have become the defacto first consideration.
Agreed. Still like to hear differences of opinions. Couple good points in that article. Couple I can easily write off though too
Nah not that. If you load a page, and then immediately call out to the server again to load the initial JSON data to build the page from, you can improve performance by embedding the JSON directly into your rendered HTML, which you can then just pluck out and decode, saving you the initial round trip.
Consider saving the or SHA256 sum of the files in the DB instead of the actual data blob, and make this the actual file name of the image on disk. You get de-duplication "for free", and get rid of encoding / invalid file name character problems, and your meta data (File names) can be localized into different versions/languages of the same file. When an image changes, its content changes, so you get a new SHA sum, which is the file name at the same time, so you keep different versions around. You can scatter the files into several folders called "0" .. "f" to prevent an imbalanced folder structure which can get problematic on certain file systems. The file names, being a SHA sum, will only have 0..f anyway in their name. This way, you get the best of both worlds: All your metadata / boolean columns (deleted, ...), fast backups, simplicity.
I’m of the persuasion that you should load small amounts of initial data to load the page, and then pull more data using AJAX to keep the user engaged without reloading the entire page. 
I have been doing both but prefer getting data in Jason format.
and you also need to address when javascript is off?
and you also need to address when javascript is off?
Also, to add to this a bit, depending on your use case, it can be beneficial to consider what you might prioritize... I used to have a habit of executing a ton of queries for more data whenever it was "needed" by the user. In some instances, grabbing much more than you need each query (which SQL standards always seem to preach against), can be useful for having compentent and responsive UI. I think I first got exposed to this concept when working towards SPA years back and integrating something called dataTables (some kind of jQuery library). It was my habit, then, to do something like this: Pretend there is a display of website users and their data, I would know where the browser was with some integer, as well as how they have arranged the data and a few other metrics, such as results for page. This allowed me to make very tidy queries for things like paged results of tabular data. However, it is also a burden to write and has the drawback of executing tons of sequential queries, which can become an issue when you scale for many more users. The alternative is to grab damn near everything the user might need, within reason, and then use JavaScript or some other technique to selectively pipe it to the UI. This is what dataTables did that allowed for a kind of hacked "real time search feature" of the tabular data it would display. All the data is already there, rendered into that page. I am sure there is some math out there somewhere, but each case is also unique. There may even be lots of instances where the number of queries executed is not important, but rather their individual speed should be maximized. I would argue that, even in many of those cases, there are likely scenarios where a single, comprehensive query, could outperform numerous successive queries - and it does not really what all you are doing with this data after you have grabbed it, how you serialize it, stuff it into arrays, parse it, digest it or display it... The bottleneck I ran into on larger projects always seemed to involve the number of queries, which is resolved by reducing how many queries each user is making (and more importantly, by caching common queries). In the example of a user table, a properly cached query could work for nearly all users if it is versatile enough to start with and contains the proper amount of information. Another limitation you might run into with this method, however, is two-fold: some tables are just too large. A user table with 500 entries for a small company is different than one for a forum with say, 100,000 members. Even for things that might seem smaller, if new data is being composed through a recursive mechanism (for instance, an "invite tree" display) with other metrics involved, you better make extra sure those complex queries are cached and do some kind of sanity check when building them to assure you are not going to be overload either the end user or the server itself with your request, especially if your starting logic is "more data = better".
I posted a comment as a reply above this somewhere addressing this particular thing, as it can get rather complex and I take a rather unorthoxodox position. Use AJAX to load new data, yes, but minimize the amount of queries you are making via AJAX calls by maximizing the data obtained on each call, when it is practical to do so. Need to display 500 employees in a table to an administrative user with pages results and real-time search functionality? Rather than query 10, 50 or 100 results at a time, just grab them all and display only what the user requests. This makes the UI much more responsive. Obviously this does not work with, say, a table containing all 100,000 members of a forum, so it has limitations. Even assuming no queries are involved and there is no SQL execution going on, AJAX calls for extra content can be minimized in numerous situations by just hiding initial excess data or content in yout initial call. The user thinks they are getting new content/data, but it has already been rendered into the page and the UI and design serve up the requested portions. Great idea for a FAQ. Terrible idea for video galleries.
$_POST and $_GET global variables for POST and GET And $_REQUEST can be used for both I will no separate this. 
You are going to run into a thousand instances of people championing there being a "JavaScript-less" fallback for your website / content. This is VERY case-specific, however. Are you designing an application that employees of a company with predictable OS and browser combinations will be utilizing? What is your primary desire for allowing the user to opt out of JS? A lot of workarounds exist, especially with the advent of CSS3 and HTML5. However, you have to consider the time and expense associated with a "pet requirement" like sans-JS functionality. As the complexity of the project increases, so does the effort required to code it in numerous fallback fashions. Is it really worth the headache, or an absolute requirement? Somebody correct me if I am wrong, but checking for javascript functionality can also be a deterrent against certain bots and other attack vectors, as they may employ countless instances of text-only browsers in an attempt to find vulnerabilities ... While ELinks supports JS, browsers like Lynx do not. If I am using a server to initialize 1,000 instances of Lynx with directions to spam or penetrate a public-facing form on your website, in one example, checking if I have JavaScript capabilities before sending me any content or allowing me to interact with the form would be an immediate deterrent. Admittedly, it has been some time since I have crafted or have had to defend against such nuisances, but I do recall this being a suggested "catch-all" against certain brands of attacks and other nuisances. If the only reason you are trying to make a sans-JS experience is for the fun of it, go ahead. It can be a fun learning experience ... If some blogger has convinced you (or other netizen) that the internet without JS is a magical place and that is why you want to do it, ignore them. If it has come down from your project manager, investor(s) or upper-management that their project should be sans-JS, you might want to consider sitting down with them to get a better grasp on how they cameto rationalize such a request. Especially if the scope of the project is rather large, this could be akin to some kind of silent, stealthy creep of scope at every turn that causes you to miss deadlines. Making a clone of Google Maps is one project. Making a clone of Google Maps that ALSO works without Javascript is a secondary project, that, as far as I am aware, not even Google has completed.
It's a very cosmetic choice, in the end. Much like the endless "tabs vs. spaces" arguments, people tend to argue over the most pointless things. Bottom line for me is: if you like it, do it. Works fine, produces compact code. In some cases it also results in incredibly natural APIs.
I din't know what the current situation with **Search Engines** is, but I have a feeling that if you want your site to be properly indexed, make its data available on the load.
I second this. If users want to be all no-Javascript and live like its 1990 on IE or something, have at it. Just know if you even want to entertain said idea you can throw out almost all SPA approaches and even more problematic, general usability functionality.
Hey .. Looking for a help with php mysql search like olx or amazon where I can search with keywords and find a relevant match. I have so far tried using query something like this : $keyword = explode(' ',$keyword); foreach($keyword as $value) { $looped .= "concat(cat\_po, ' ', title\_po, ' ', sub\_po, ' ', de\_po) LIKE '%$value%' AND "; } $sql="SELECT \* FROM \`my\_tbl\` Where $looped ORDER BY id DESC"; &amp;#x200B; This brings me unexpected results. Like when I search 'apple mobile for sale', I get results for every keyword and looks like : ' samsung mobile','apple imac','new car for sale' etc... My intent is to get all the ads for 'apple mobile' only and then the other mobiles if at all possible. but dont need cars and all the things.. Thank you.. 
I am deeply sorry about the inconvenience
This seems totally outside the scope of /r/PHP. Try asking in a MySQL subreddit adding more info about datasets and expected results.
Indeed :)
I am from Europe as well, and have the same doubts about using AWS and they being a US company. But when it comes to S3 storage, be aware that there are several opensource systems allowing you to use the S3 protocol without tying the knot with AWS. With the same effort your are splitting your blob to a different system, you can install Minio on a instance and write your files using a S3 storage layer As for storing files in a blob, rest assured we all had that thought, and like many others I learned the hard way it wasn’t as scalable as initially believed it was. Retrieving and storing images, transforming on the fly was all fine and dandy till we needed to scale horizontally. Y adding a few slave servers to our master. Then the IO hell broke loose. But i guess giving your defensive reactions to everyone telling you to reconsider, you rather learn it the hard way. Be our guest... 
I usually use an Apache Solr backend for this sort of thing. Elasticsearch is also pretty popular, but I'm not as familiar. I'm not quite sure if this is the answer that you're looking for - "find a completely different architectural solution to solve the thing", but it is one way to skin this cat, so to speak.
Never done this. I would imagine some combination of regex and ajax
You want to look at elastic search, or Apache solr. Do not write you own search engine in MySQL queries.
he meant that saying that avoiding using Composer is a great step is a horrbile thing
Cool story about the attitude, bro.
I run a very high traffic live video streaming startup, a lot of our stuff is written in Rust but some of our tooling uses some highly optimised PHP7. We invoke calls to FFMPEG through php’s shell_exec function, but the performance characteristics aren’t great. Being able to use libav through an FFI would be a game changer for us, and potentially save us thousands per month on our AWS hosting bill, since we would be able to directly invoke the functions we need instead of loading and running the entire FFMPEG binary in to a shell runtime for every process.
[https://github.com/PhpUnitsOfMeasure/php-units-of-measure](https://github.com/PhpUnitsOfMeasure/php-units-of-measure)
&gt; But i guess giving your defensive reactions to everyone telling you to reconsider, you rather learn it the hard way. Be our guest... Why do you also have to take everything the wrong way. It's actually becoming funny. No, I'm acting like a scientist / researcher / explorer would, who is being told by everyone that you cannot fly into space with a brick, something bulky like the space shuttle. Yet you simply point out to the naysayers that actually, you can. Whether you should, that's a completely different thing. The choices you're going to make in your particular situation, are another thing. Hope you get my point. Not looking for learning the hard way, but always looking for exploring ideas, making the unconventional work, which has been root for my past successes. The only thing I don't see here is yet a reason to completely discard the idea. At base, if you take a look at the basics, it's just another storage engine that in the end saves things as files. It might add say 50% overhead in CPU usage and some additional IO compared to saving to a file. It might also save overhead in certain scenarios through server's internal caching, and you have the ability to use the database's advantages of organized information. It's not an 10000:1 performance decrease range; so when using it as a storage engine, should the CPU overhead be acceptable (it is) and the operation fast enough (SSD's help a lot today) and not hitting a deadlock situation /workload limit within the server (math tells us we're nowehere near that situation) you cannot just discard the idea, cause there's no reason to. Plus, in a caching situation, that overhead we're talking about, cannot manifest itself. I've been operating with large databases and more complex structures for like two decades. The end size of the database we talk here (few tens of GB at its peak), doesn't scare me a bit. This project's particular need is for good caching, that's in anyway, but as to the storage itself, blob might be usable so as anything else. Or, you might be right in the end - depends on the level of scaling needed - but as it is visible for now, from where I stand and measure with math in hand, there's no risk of hitting a performance wall anytime soon. This being said, &gt; with the same effort your are splitting your blob to a different system, you can install Minio on a instance and write your files using a S3 storage layer Worth a try and learning about it indeed. Will do that, thanks for your suggestion (BTW I was aware of Minio, just never tried it). &gt; As for storing files in a blob, rest assured we all had that thought, and like many others I learned the hard way it wasn’t as scalable as initially believed it was. Retrieving and storing images, transforming on the fly was all fine and dandy till we needed to scale horizontally. Y adding a few slave servers to our master. Then the IO hell broke loose. Maybe here is where you got it wrong, if I might observe. The IO hell always breaks loose because you're doing too much IO on a *single server*, duh. You're not distributing data. What I have used in the past was sharding such data across multiple servers. That's where distributed architecture actually started from, isn't it? Furthermore, in your scenario, you also seem to have either 1) served the data DIRECTLY FROM the db, which is wrong (should be cached, or else your blob storage is a bad choice), OR 2) your application was write intensive, while ours is definitely not. The write flow is very slow, data is written in a linear, no-edit fashion, multiple fast reads needed = perfect for caching. Everyone seems to be focused on hitting a wall that doesn't really exist for us. Oh, will we hit it 2 years from now? Excellent - at the time I will say, it was a nice journey but naysayers were right. However by then we will have plenty of funds to either throw servers at it (servers are cheap, BTW), I must say that we already have this. OR, through the existing abstraction layer and a larger development team, upgrading to a file storage (this time well designed for the task ahead and new conditions) will be, again, easy as pie. Frankly, at this time, I've learned a lot of things via this post, but the solution we will use? Still in debate. Maybe we'll end up with files. Maybe we'll switch to files within a few months. It's all doable and not a nightmare. I'm going just to allow a little more time for the ideas to settle now. I've seen people taking sides here like it would be a religion. Each version has its pros and cons, and no doubt file storage is faster. Blobs might, in the end, simply overcomplicate things. But again, as a solution in this particular config, I don't see it dismissed at this stage. I do understand though that everyone has a different view over things and whoever hasn't yet worked with something like this and seen it work /made it work properly, or for whoever it was a bad choice to start with, will just see it as a dumb idea. Fortunately, we're all different and having different experiences. Some are still worth exploring. The esence is the learning. Is it learning the hard way, hmm, I don't see it like that. Converting to a file system version later is dead simple.
Excellent idea, thanks! One question: How about using SHA512 instead? To decrease the risk of hash collision. As to the multiple folders, again, good idea. We're going using Linux; not sure how many files would reasonably store in a folder before becoming bogged down. On Windows anything greater than a few tens of K in numbers, gradually becomes a real pain.
This is the correct answer. 
Breaking rule 4.
Please, provide more info about the question, if you can, a link to github with your code.
hi /r/PHP is not a support subreddit. Please visit /r/phphelp for help
Update php?
[Relative and absolute paths, in the file system and on the web server](https://phpdelusions.net/articles/paths)
&gt;As with all these magical tools, you may get lucky and they just work. What are you talking about? There is nothing magical about it, it's still a full Linux OS running inside of a container instead of directly on a server, there is nothing magical about it at all. &gt;As soon as they don’t, you may have been better to invest the upfront time to learn each component well. Again what are you talking about? You need to learn each component regardless if you're using Docker or not. Docker is simply running the software there is nothing different about the software in a Container or running it directly on bare metal it's the same software.
Try &lt;?php echo include("./sub/example.html"); ?&gt;
&gt;My development environment depends on vagrant with shell provisioning. Should I switch to docker? What are the pros/cons? In short yes. The biggest pro is you run exactly the same environment on dev as you do live which is the main reason Docker was invented. It's very hard if not impossible to run exactly the same environment on live as it is in dev when using something like vagrant, this problem is then amplified by the number of members in a team.
absolute path not working like [https://mysitename.com/sub/example.html](https://mysitename.com/sub/example.html), but $\_SERVER\[DOCUMENT\_ROOT\] works but i dont want to use $\_SERVER\[DOCUMENT\_ROOT\]
Please **read the text linked above before letting such a bullshit out**.
&gt;Ive never understood why a php developer would need docker? What issues can you even be solving? What am I missing? Everyone on your team is running exactly the same stack with exactly the same versions and dependencies. Someone running random versions locally (even more so with external libs) are likely to push code that doesn't work on the live environment. It also makes what OS the developer is working on irrelevant and eradicates cross-platform issues. In short there really isn't any reason not to use it.
The guy is [perfectly aware](https://www.reddit.com/r/PHPhelp/comments/a4a3ct/database_connection_file_not_working_with_include/) of this sub's existence. He just doesn't give a shit.
Username checks out
Reddit cliché noticed: Username checks out Phrase noticed: 1130 times.
What is the benefit of putting development projects at the root level instead of your user home account? `/Users` is already in the file sharing list, so you wouldn't necessarily have to add your project directory into Docker.
My main problem with running Docker on windows, specifically Windows 10 with Hyper-V, I cannot run VMWare VMs at all.
Axios is very nice - jQuery I used to use a lot but now days with so many other good options it can feel clunky. (Not to say that it doesn’t shine in other places when needed). 
Also want to mention this: &gt; When you store an image in MySQL as blob text, you've got the disk space of the image combined with the overhead of the rest of the columns in that record. Then, if you've got an index on that table, you have to add in the space for the index to boot. You could save all of that extra overhead space by just storing the image as an image on a disk. To me, this is bad design. Blobs should be stored in a separate, dedicated table, not the same table as your meta (as in, other columns). Indexes should always be applied on the meta table (not on the blob table) and therefore have no such overhead. Blobs are not to be treated as common columns; they aren't and the best thing you can do is to keep them separately. When dealing with blobs, you have to visualize DB differently for that table, just as some sort of "binary filesystem storage" that behaves entirely different, and not as usual tables where you can add indexes and perform other complex operations.
Wow. Man Hyper-v must be doing some crazy things to knock out the competition.
No mention of interfaces? 
Writes a Company class where you can have only a single employee identified solely by first and last name... &gt; At first glance, we cannot see any issues. :-) Good one.
I don't think the article describes what i would consider to be dependency injection and the problems they solve. Please read this instead if you want to learn about Dependency Injection. [https://phptherightway.com/#dependency\_injection](https://phptherightway.com/#dependency_injection)
This is the sequel of the last post in which I discussed how to use multiple containers and make them to interact with each other to run an application. &amp;#x200B; *Sorry for the back-back posts but it was necessary otherwise readers were not going to have a full picture of a client-server application.*
Interfaces. ^^^/s
Yeah, it kind of makes running services like mysql, rabbitmq, solr in Docker and the app in VMWare impossible. Even with Hyper-V, Symfony on Docker with volumes is crazy-ass slow.
If you normally use windows and load a docker instance of linux, can you still use atom?
I need some help with it. Please check private messages here or twitter. Thanks.
Thank you! I'll keep that in mind next time. It's definitely a learning process haha 
If I have to worry about that, I usually put in a noscript tag that redirects to a static page describing that the site had specific requirements. 
Put your images in a different database than your normal one, add put a varnish cache running from a machine with some SSD infront of your web servers, and haproxy in front of that. Requests will hit haproxy, based on some rules (/images/dynamic/fii.id.jpg) send the request to a bunch of varnish servers, that in turn will either serve the cached version of the file, it load it from the database. When you add a ton of new images, before you place the client facing URLs, make a script to wget those images so they get cached in a controlled way ( not 10k requests per sec type of thing ) You can easily serve in the xxx.xxx requests per sec like this, depending on your network, with one or two mysqls, two haproxy servers and 2 varnish servers ( depending on ram/cpu, you can put the proxy and varnish on the same machine)
If you add a caching layer to the first half of your post, you solve all the problems you described. And if you add a CDN layer to that, you solve some bandwidth problems you might get on high load.
Thanks! This is right down the lane of what I had in mind. Makes perfect sense. Used Haproxy in the past, haven't used varnish but it's about time to. 
Later comment: Here's a link to a [Microsoft research paper](https://www.microsoft.com/en-us/research/wp-content/uploads/2006/04/tr-2006-45.pdf). In a nutshell, they say objects smaller than 256k are best stored in the DB, while those larger than 1MB are best stored in the filesystem. As a note, our images are all below 1MB, most ranging at 256-512KB. Interesting document. 
my thought exactly, S3 is so easy and cheap to use, there is absolutely no complexity behind it compared to the complexity of maintaining a largescale mysql install i am not sure about how many images you are talking about, but i think S3 is even free up to 50G
Cool and well written set of tutorials. I'll definitely bookmark these to pass along to anyone looking to get started using docker for PHP development.
Any real advantages over Vagrant? I've been using Vagrant with a small team, and it seems extremely easy to share boxes (when a new developer joins) and even GitLab works as expected. 
is PHP the preferred language for programming a livescore sports app like SofaScore or the ESPN app? If not, which is?
is PHP the preferred language for programming a livescore sports app like SofaScore or the ESPN app? If not, which is?
 **Merry Christmas** for the whole world . 
Unsolicited spam with misleading title is best.
&gt; Edit: Found a link to a Microsoft research paper. In a nutshell, they say objects smaller than 256k are best stored in the DB, while those larger than 1MB are best stored in the filesystem. As a note, our images are all below 1MB, most ranging at 256-512KB. Interesting document. The 256kb boundary may be subject to the details of your file system and hardware (you know, the paper was written in times where HDD was the norm for server storage, now it's SSD). But that's a good rule of thumb: keep tiny blobs on the DB, big ones on disk. However... I'd strongly advice you have a separate database for those blobs, because you will SURELY have a separate back-up and distribution strategy for them, compared to the rest of your data. So basically you have two separate storage systems: - Hybrid file system + db (for large and small blobs respectively). - DB for pure data.
&gt;Unsolicited spam with misleading title is best. what you mean ? &amp;#x200B;
Stupid question 
really I want to make freelancer website and I don't know which programming language is best?
Thank you for your comment, see below. &gt; The 256kb boundary may be subject to the details of your file system and hardware (you know, the paper was written in times where HDD was the norm for server storage, now it's SSD). Indeed. It is also a paper based on MS SQL which I also worked with a lot in the past. It's a completely different animal in comparison with MySQL for example, what we use today (actually MariaDB). Anwyay - my point is, there will also be differences due to architecture should the research be made on MySQL. Not to mention as of today (tech has evolved) but also with SSD's (might differ). But one thing that stands is that there is not a huge difference between the two options. It only becomes significant if you deviate a lot in either direction (very small, or very big files). &gt; But that's a good rule of thumb: keep tiny blobs on the DB, big ones on disk. Correct. Meanwhile I've done additional testing and improving the application as to consuming less space. My original estimates were wrong in one direction; file size. Our files will be less than 256kb on a regular basis (although a few might be larger, but not significant numbers). I expect the average to be around 100KB. This helps indeed and makes the blob option more suitable. &gt; I'd strongly advice you have a separate database for those blobs, because you will SURELY have a separate back-up and distribution strategy for them, compared to the rest of your data. &gt; &gt; So basically you have two separate storage systems: &gt; &gt; Hybrid file system + db (for large and small blobs respectively). DB for pure data. You are right. This is something I actually know very well. Been working with all sorts of large databases in the past, for about two decades (on and off). You have to keep your large text fields separately, this includes both blob and large text fields if any. Up to a certain smaller load level, they can reside in the same database /server but when things go busy the best thing is to use a separate database server for the blobs and server config tuning will be different in order to get maximal performance out. It also depends heavily on whether the application is write intensive or not. If it is, then that's a completely different paradigm and blobs might not be the right option. 
Here is a tutorial and example project that demonstrates unsupervised clustering using a Gaussian Mixture &amp;#x200B; [https://github.com/RubixML/Colors](https://github.com/RubixML/Colors) &amp;#x200B; I hope it helps you
The very first set of words is missing a space. Before the article even begins.
Merry Christmas
As of working things are pretty similar, you can provision docker based images too. The advantages are scaling, deploying and light-weight. Something you don't have in vagrant. &amp;#x200B; Unlike vagrant you can just *upload* your images as it as and no need of changes in connections. Check the first part of the post.
Thanks! Yeh sure! After all it's all about learning together.
sorry, where?
Grav is a pretty amazing CMS. I've used it for a couple of sites. With the GravAdmin plugin it's got a pretty low learning curve. Just bear in mind your client will likely need to be comfortable with markdown for editing content (not that big an issue really it's pretty straightforward) With the GravAdmin plugin you can get by with no more PHP knowledge than you'd need with WordPress. If you decide to forgo the admin plugin then you can get by with a basic level of PHP, basic level of Twig, and being comfortable using FTP. I guess the 2 biggest things I found building sites with Grav that it's worth being aware of: 1. There is not the same large diversity of plugins that you would find when using WordPress or Joomla. If you have requirements beyond content management you will likely be rolling your own solutions which given the way Grav works is really quite easy and straight forward. 2. Grav uses Twig pretty heavily so it's worth being comfortable with Twig as well. Other than that I've found Grav a pretty amazing CMS and have used it on a couple of projects now.
I think he means this? https://i.imgur.com/uEQ5NUb.png
OK if that was the case then fixed now.
Grab a Bootstrap or Bulma template and just knock it out in day. Lots of contact forms out there. E.g., https://bootsnipp.com/tags/contact. As for CMS, to keep it simple, [Typesetter CMS](http://www.typesettercms.com/) is really convenient w/ the front end editor. Boostrap-compatible, not hard to adjust the look. You'll be fine w/ basic PHP or even none, what with lots of plugins. Active support forum, however. 
Keep sharing this kind of useful articles.
Thanks
ohhh I know nothing about Twig, since I'm going to write theme, I think I should look into it, thank you :)
&gt; Bulma template wow that Bulma is amazing, thanks very much
Vs code too. I wish they added more support for php
PHPStorm. Nothing comes even remotely close to it regarding php. Especially if you work with Laravel / Symfony
Really well written. Good job m8.
PHPStorm is worth every single penny. JetBrains IDEs are first class IMO. WebStorm slaughters VSCode, and Rider actually makes shitty Visual Studio usable. Also, nothing beats the three way merge conflict tool in a JetBrains IDE.
I use Eclipse with PHP support. And then move to Atom for SASS and JS (better syntax highlighting). I’ll give PHPStorm a look tomorrow since so many people seem to recommend it. 
Wish I could afford PHPStorm. I use Sublime. Works alright! :)
Please explain what it can do that VS Code cannot (I am a newb, I would like to know).
I move between Brackets and Komodo Edit .. though both have been annoying me lately, Brackets freezes every time it takes a snapshot of the files, and Komodo has just started locking up whenever it feels like it .. on both of my completely different machines! It probably doesn't help that that some of my projects have a lot of files, but it shouldn't really matter.
It’s free for students. All you need is an edu email. 
Tried PHPStorm, but for me it feels a bit bloated. Also writing a lot of TypeScript, python and C so having an IDE which supports multiple languages is a plus for me :)
IntelliJ/PHPStorm. I've recently switched all my development to the JetBrains suite actually. PHPStorm, PyCharm, Webstorm, CLion.
Not the op, but I would also say go with PhpStorm A list of things I miss whenever I have to work without PhpStorm: - Code completion. You start typing $user-&gt;ge... and it gives you a list of usable methods from whichever class $user should be at that point in the code - Code following (don't know what this is called): You click on a function call and go directly to the definition of the function, click it there and you go to usages. I and O icons on the left guide you through the implementations or the interfaces of methods. Same goes for variables and constants Static code analysis: PhpStorm knows about how PHP works so it always checks for stuff you can easily miss; You added another parameter to a method but then forgot adding it to where you call it? It lets you know. Your return type does not match what you are returning? It let's you know. Are you trying to call a private method from outside the class? It let's you know. Doing something that is not valid for your PHP version? It let's you know. Code quality inspections: As it should, PhpStorm checks for a number of code quality things; class namespaces, includes, variable and method name case consistency, tabs/spaces consistency, line length, empty code blocks, missing returns, docblock annotations. Plugins: On top of all of that, you have plugins which can do all of these and more. For example codesniffer or sonarqube could be integrated via plugins and they offer all their analysis results through your IDE. Xdebug integration: Don't know any other IDE that let's me debug PHP this easily All in all, I am happy with PhpStorm and any problem I had with it is usually not a deal breaker, especially compared with other solutions
An evergreen topic. I would rather ask **what search engine you don't know how to use ans why?** `site:reddit.com inurl:/r/PHP/ "VS code"` will give you as much information as you can digest.
What makes you like PhpStorm for Laravel over other editors, especially say Sublime? I have both, and find myself reaching to Sublime almost exclusively for working on Laravel projects on my local machine under a valet environment. I'm legit curious if I just haven't spent enough time in PhpStorm so I'm missing features it has to make my life easier, but Sublime feels dramatically faster and more lightweight to me.
I use neovim for coding generally.
I'm using PhpStorm and VS Code together. Both are awesome. PhpStorm is my main dev tool and I've made VS Code the default text editor on my system.
Nice list. I also want to add PhpStorm Advanced Metadata. This feature has some great potential if it used correctly: https://www.jetbrains.com/help/phpstorm/ide-advanced-metadata.html
I use Atom. It can be great with IDE packages but working with Symfony can be a pain as I don't get namespaces autocomplete. Not sure if something's misconfigured but PHPstorm apparently is great about that. But I'll keep Atom as I don't want to pay for my editor/IDE (that's my opinion, go for it if you enjoy it). I like the git integration in Atom and there's many cool packages I enjoy.
I was actually thinking about this very statement a few weeks ago. I'm also super impressed how they managed to be good at everything; Java, Android (Studio, Google probably do the hard work here), PHP, Web, CLion, RubyMine etc. I'm so glad they exist and that they offer the tools they do offer for a very affordable price too. (Yeah I'm looking at you greedy Adobe masters of scam... Took you years to offer a good price plan, and even longer to offer a good monthly sub instead of annual)
Netbeans is great. Has most of the functionality that phpstorm has, I'm sure phpstorm is a little nicer but haven't heard why it beats netbeans which is free/open source, enough to warrant the price.
Moved from PHPStorm to VSCode and not looking back. The intellisense for PHPStorm is better, but I don’t miss having to use a bloated Java app in my daily life.
I use Sublime Text 3.0 with pirated cd key.
With a little tweaking and a couple of plugins, PHPStorm has a deep understanding of your PHP code, which means you can easily do stuff like: 1. See everywhere that a method is being called, or a public property is being accessed 2. Easily traverse your code base "this expects an instance of ClassA as the first argument, which is defined here, and inherits from ClassB, which defines a MethodD, which is called in these places, including from MethodE, which is passing in an invalid value...ah, so that's the bug". 3. Let's you do tons of really nice refactoring (renaming variables, extracting chunks of a method into another method, renaming classes, changing method signatures) and then having then reflected throughout the entire code base 4. Do tons of smart checks for type mismatches, missing arguments, possible null pointer exceptions, uneeded casts, buggy switch statements, mispelled class names, and a thousand other things. 5. Easily generate snippets and fix issues. Did you use an external variable inside a closure? PHPStorm will notice, underline it with a red squiggle, and when you click on it it'll ask you if you want to add it to the `use` clause; one click and it's done. Did you store something in an property without defining it? One click to add it. Want to add a new method? Just write the call, PHPStorm will let you know it doesn't exist, one click and it'll create it for you, correctly figuring out what arguments you're using. Will also generate new PHPUnit test methods, etc., etc. Much of this stuff you can make VSCode do, but it takes a lot of work, and never quite works as well. There's a plugin for VSCode that tries to give it the ability to figure out usages and calls, but it's very buggy, misses a lot, and (at least as of six months ago when I tested it) keeps losing it's cache and needing to re-index everything. Other plugins crash, or break, etc. The VSCode ecosystem is wide as the ocean, but (at least for PHP) as deep as a puddle; if you look at a feature list, VSCode looks *close*. If you try and use those features, it's not close. You'll spend 1/4th of the time configuring PHPStorm, and get something that works twice as good and twice as reliably. That being said, PHPStorm runs like a dead hippo with a RAM addiction, so I do keep VSCode around. When dealing with JS, PHPStorm seems to get even slower, and VSCode is pretty decent, so I'll often switch between them, working on the front end/JS side in VSCode, and the backend/PHP side in PHPStorm.
Already tried atom, it's great as a little tool for editing single files or small projects (same goes with sublime text), but as soon as I tried to configure it to be more like a real, complete IDE like phpstorm (which I use), the memory consumption was too huge for comfort. 
I use it for coding generally and specifically :)
Try PHPStorm. I've used Netbeans for years until recently. No looking back
You wouldn't steal a car, would you?
Vim, no plugins. Minimal config. 
I am not sure if I understand this correctly. So, it allows you to define what a factory or service would return? So PhpStorm knows the class of the returned value and handle the inspections accordingly? Is that it? I guess you can also use @var annotations to define the variable after it's returned. Or does this do something else?
So obviously the answer is phpstorm, but, for myself what always stops me committing after doing yet another trial, is speed. It feels sluggish. Only slightly, but enough that I end up at sublime and vscode every time. Phpstorm people, what am I doing wrong? Last trial was 6 months ago. 
This should just be a sticky. I recently switched from NetBeans to Storm after being on the beans for 8 years. It's a bit slower and that's saying a lot because beans was bad but all the stuff you get with it is worth it. 
Use a templating system. Twig and Blade are probably your best bets. &amp;#x200B; If you really want flexibility, then one solution that I find works very well is to simply not mix the PHP and HTML at all. Serve pages from static HTML and use a client-side library, (Angular / React / Vue) to get the data from a PHP API endpoint and present that on the page.
Just as a random note, `site:` accepts more than just the domain, so you can just do `site:reddit.com/r/PHP`.
Didn't know that, thanks
I use sublime. It's free, it's light, it's simple and supports a lot of languages. IDE's usually have a lot of features that I'll never use, and the ones I would use, it's easy to find a sublime plugin
I didn't grasp the meaning either...
The guy that made Laravel uses Sublime Text.
Phpstorm is _the_ recommended IDE, at least in r/PHP. People I know and follow in PHP community also tend to prefer phpstorm a lot, and I personally couldn't recommend it more. VS Code is a good competition I here (I personally didn't try it), bit compared to other IDEs, phpstorm works really well with recent integrations with composer, phpunit, npm, etc, really nice code refactoring, SQL browser/autocomplete, and search functions (search within scopes, search everywhere, search symbols, double shift search shortcut, etc). It has a free trial so go ahead and try it. You can get a free license with edu email addresses, open source contributions, and by being an early release tester (can't remember what this is called). 
I think you understand it correctly. If you think @var annotations are an effective alter alternative, then I don't think it'll be useful for you :p At work, we have over 20000 php files, mostly legacy code. There are many unresolved references _all over the place_. There's no way I could add @var annotations to several tens of thousands of lines of code. Spend a few hours on these meta files, and maybe, maybe just maybe, my warning minimap will be slightly less yellow :x
I am starting to get the feeling this is the go to editor of choice here and have downloaded the trial. If only it would download the code from my server faster so I can start trying it out. 
Have been using VScode for quite some time now it's quite fast and easy to navigate through. I will try out phpstorm and see how it goes.
You get unlimited usage by joining the Early Access Program if you want an extended trial. I’d say you should always run 2 editors. One lightweight for random bits and bobs which opens in ~1 second (I use sublime) Then for project work a solid IDE, I’ve used sublime, atom, vcode - all have great benefits, but a solution that has truly made a great benefit is phostorm - I got a Black Friday deal, so would recommend get a new year deal if your cautious. I think the “why is it better” is too big to really answer, there’s many great benefits which over time you will find and then it will each time keep building your love for the product. On laracasts.com there’s a phpstorm series for little tips. I think the key thing is - embrace it, I watch a college abandon it coz it didn’t do identical things to sublime - he went back, and I see him daily huffing and puffing at doing stuff in sublime which is crazy easy/automated in phpstorm, you only get from it - what you out in. Personally I love little things like live templates, built in terminal, built in test runner, JavaScript support is so good with browser support feedback. I think the key is to try it for at least a month solid, and embrace its features/shortcuts. Forget you have a mouse try and keyboard as much as possible it will eventually help you notice even more features. And remember it’s NOT a replacement for something like sublime - they can be used together for the appropriate jobs :)
I found phpstorm typescript support really good! Which ide have you found is better?
I'm a huge sublime fan, definitely for its speed and flexibility, and I use phpstorm alongside sublime. However... Sublime doesn't come close to phpstorm in terms of productivity when it comes to writing php code. There are so, so, so, so, so many features that phpstorm offers that save me hours of time. It tells me when a variable is spelt wrong, it tells me when I use the wrong type for a function, there is a separate autocomplete functionality for words that _arent_ variables, so I won't spell those wrong, I can generate tests, documentation, classes, methods, and more. I can select a block of code inside a large function, and let phpstorm automatically refactor it into its own method. The same goes for variables, select a complicated inline expression, and it'll create a variable for me. Then there's a useful debugger, a built-in database tool, heck, phpstorm even checks if the columns and tables inside sql-snippets used in your php code exist in your chosen SQL database. Then you have the advanced code usages that are very useful, you can look up where a certain function is called, you can even let phpstorm do this recursively, so you get an entire call tree! Another fantastic feature is the structural inspections feature, phpstorm already offers some useful automatic refactors... But did you know you can write your own? If your code base tends to use a specific bad or outdated pattern of code, ie: $bla = $arr['somevar'] ? $arr['somevar'] : 'not found'; You can specify this pattern, and create a replacement template, so that whenever you see this pattern, you can let phpstorm replace it for you: $bla = $arr['somevar'] ?? 'not found'; Aaaannndd. More. I've been using phpstorm on a daily basis at my work, and I tend to try to get _everything_ out of the tools I use, and the more I use phpstorm, the more I keep finding increasingly useful features.
&gt;If you normally use windows and load a docker instance of linux, can you still use atom? You can use whatever you like. The files/repo still sits on your local file system, it is then mounted into the container when the container boots. So any changes you make are instantly reflected inside of the application container.
Having a local server is one of the very first steps in good tooling, regardless of the language or IDE. Of you are looking for a good local server, I can recommend Laragon for Windows for the lack of native package managers. 
That’s because phpstorm is written in JAVA. That’s why it will never feel like a native app or have the same speed as one.
 I think that it would be more correct to say not "in" but "together". VueJS is a JavaScript framework that serves to facilitate the development of the front-end part of the application, while PHP is a scripting language for work on the back-end part. For me, the best option is to use the View to create a SPA (Single Page Application), All requests to the server will be sent as Ajax queries, and processed on the server with PHP scripts. By the way, I recommend to try Laravel. This is a PHP framework that allows you to easily and quickly implement a Web application (its server part) of any complexity. In addition, Laravel supports compiling of Vue components out of the box. 
I have MMAP Pro but this project is not on my computer. Need to download it all first. 
I think I get it, but do you store the metadata file in the repository, so it's shared with all devs? On one hand it feels like it's right to do, on the other hand the metadata is not really useful for the project because it is only relevant to the IDE and only one IDE... If the other devs don't use PhpStorm they wouldn't feel it's necessary. Is the end goal to refactor out all factor methods and get rid of metadata file? So, a stopgap solution?
Or a friend with one 🙄
I don't know, I don't use it... I only just discovered it through the post you replied to :p And uhh, I don't think the use-case is limited to Factory methods, the use case is to provide reliable type information for dynamically resolved references, in my opinion, you shouldn't ever want to use dynamic references, since they cause so many problems with static analysis anyway... But whatever.. Don't know why it would be a problem for you to include it into the repo though. I used to be really cautious about what does and doesn't get into the repo... But I found it really doesn't matter, it'll just be ignored by people who don't know what it is, and that's fine.
I love phpstorm for php, but it is kinda clunky (on Ubuntu at least). It has a few weird things (like not showing up in alt tab when you first launch it, or not coming to the foreground when a breakpoint is hit), but it's functionality is unrivaled. For anything html/ js/ ts, etc, I switch to vscode tho. 
PHPStorm (or now I use IDEA, same thing but better) is the best. I’ve used sublime, VS, Atom, and more but each of those is (or can be) a lightweight text editor that you can build up (via plugins) to be a decent IDE. PHPStorm is a medium to heavy IDE out of the box but it is so much more powerful in the long run and you can make it even better via plugins. For years I resisted “a real ide” (Eclipse can leave real scars kids) but before switching to a new company I tried out PHPStorm on the recommendation of my friend at the new company. Before I left my old company almost everyone had converted (like 10 people but still). The features that come baked in are amazing and super powerful and they all work well if not perfectly together. This was not my experience with *INSERT LIGHTWEIGHT PLUGIN-DEPENDENT EDITOR HERE*, some plugins would overlap in functionality, be abandoned over time, or not work well together. This next comment will ruffle some feather but know it’s not my intention, it’s just a good analogy for me and I think it will make it click for some other people: PHPStorm is to macOS as VSCode is to Linux. It just works, you won’t spend hours and hours of your time fiddling with plugins to make the perfect IDE, it doesn’t come with “some assembly required”, while other people customizing their editor endlessly you can be coding and making money. Note: my analogy refers to Mac/Linux DESKTOP, I run Linux servers for everything. 
That's because \`.\` is a string concatenation in Perl and PHP is just "simplified" perl ;) When time came to add OOP syntax \`.\` was already taken, so PHP devs choose something mnemonic.
Array functions got a bad meme unjustly. Reduce will filter out \`null\` if no filter callback is provided, and optional arguments can only be placed on the right side of argument list. Map will zip multiple arrays if they are provided and those extra arrays are optional thus have to be placed on the right side of argument list. &amp;#x200B; If anybody have any clue why they are the way they are in C or in PHP, please share.
I use vs code with some nasty plugins 
No typehints for functions. It drives me crazy when even official docs do not explain what arguments and what returns are expected from function I will pass as callback. "Callback" is not a proper typehint, the same way "object" is in 99% of the cases not a good replacement for class typehint.
Apache Netbeans with the PHP plugin. Personal preference I suppose: it is a full blown IDE with all the bells and whistles, and with 10+ years using it's what I feel most comfortable with.
I’m really surprised almost nobody suggested Eclipse PDT https://www.eclipse.org/pdt/ I use this at home and at work. It may not be the best IDE on the market but it’s free, open source and multi platform. 
PHPStorm, or the Ultimate if you use other languages too. Nothing else comes close. And vim when you're on the command line already and need a quick edit. When I started using PHPStorm and Xdebug together my productivity went through the roof. I try other ones occasionally, but I always go back to Jetbrains products. 
It's trade off. Would babel enabled feature allow you to write less code overall? Would that savings offset time spent on maintaining build process? Would updates handled by Composer + Composer package.json maintenance save you time compared to manual updates? You do update those dependencies, right? Check for vulnerabilities? Encounter bugs fixed in newer versions? Trade off. I do think it pays off really fast. But I also worked with large, single file monster scripts, or projects where there where 4 or 6 versions of single dependency crammed in. Avoiding that requires some discipline, but thankfully that can be automated... with composer ;)
Composer have dev and prod settings. Did you profiled against prod settings? Composer dumps static array in that case...
Neovim, with PHPactor.
I haven't used VSCode with PHP, but VSCode supports all of that in JS just fine. Just need to find the right plugins.
Yes, and this array can become quite huge. It is much more elegant to have an automatic class to file mapping.
Logical fallacy. Laravel author have great experience with PHP - fact. Laravel author have great experience with Sublime and PHPStorm - unsubstantiated. Thus it matters none, says nothing if author of Laravel uses Sublime. You still have to show he choose Sublime over PHPStorm on some sensible grounds.
If you look for "why's" for PHPStorm, check these: - [PHPStorm Tips in 9 Gifs](https://www.tomasvotruba.cz/blog/2018/12/13/kirill-smelov-s-phpstorm-tips-in-9-gifs/) - give it 2 minutes - [Be Awesome in PHPStorm ](https://laracasts.com/series/how-to-be-awesome-in-phpstorm) - video series, short and easy to undertand
Proof: https://twitter.com/taylorotwell/status/585881725030375424
It is not always necessary to update the dependencies. I had once mPDF working for 4-5 years before I decided to update it. The update was simply 1. replace the folder, 2. run the tests (automated + manual), 3. pull on the server. I did not suffer at all that composer was not a part of the project. 
Also they often release EAP which is free for a month.
&gt;You still have to show he choose Sublime **over PHPStorm on some sensible grounds.** &amp;#x200B;
Now you're putting words in my mouth. When did I ever say he uses it over something? I said he uses Sublime. Period. Anyway I heard that the guys that made PHPStorm offered it to him for free but he tried it out and just stuck with Sublime.
I'm curious what features make the difference for you?
Only step 1. have anything to do with Composer. Nothing else would change*. But that's a single dep. Statistics would demand you analyze some sizable representative (random) sub group of all of them, to assess how much effort you spend now vs composer, and then how much time you spend on security auditing vs composer automated checks. Etc. * You may need to put vendors in git if you use git for deployment, but you already have your own equivalent in git so I treat it as no-op.
Notepad++ is the best for me.
For Linux I think it depends a bit on the filesystem, but you'd want to avoid more than 10,000 files in a directory. &amp;#x200B; Doing: a/e/f/d/2/aefd2abcdefabcdef.jpg is quite a common pattern. You could also use a hostname based on the hash too (e.g. [aef.mysite.com/a/e/f/d/4/aefd2abcdef](https://aef.mysite.com/a/e/f/d/4/aefd2abcdef).... ) to distribute things. While backups kind of become easier when the images are in the database, I'd stick to the filesystem approach as it's going to be more performant (and you don't need to worry about getting your caching headers etc from PHP). 
I use Atom and/or Sublime (the latter tends to render slower sometimes on rdp and such, so I'll use the former more often for that reason) and as a general rule I opt out of functionalities like code templates, completion, magic following, plugins, integrations, etc. In my experience they just get in my way, and the above's opt-P and opt-R are enough for me to browse code. If (when) I need to get deeper than that, I will be getting out a paper notebook and grep, at the bare minimum. For integrations I use zsh/bash. I am one of those weirdoes who uses git on command line, I suppose :) &amp;#x200B; In a pinch I'll use nano or even (gasp) vim. It is hard for me to endorse vim because its learning curve seems to be too high for most people... It is excrutiating to be waiting on someone without the required vi muscle memory to take way longer than necessary to do some basic task like edit a single line in a single file, or use multiple files, etc... Yes, I know you real vi nerds have figured out how to play tetris in your editor natively by now, but most vi users are unfortunately not you :( &amp;#x200B; I suppose there is something to be said for an IDE to help you build a mental model of your code, especially if you switch codebases a lot, but I've gotten used to doing it from scratch, especially in tandem with some sort of pseudocode/drawing of what is, and what the next refactor(s) should be
I'm surprised anyone still uses netbeans. It was an abomination last time I used it for Java, only losing the top spot to Eclipse.
Thanks for the tip! Might need to find an edu email lol
Emacs. With tools like [phpactor](https://github.com/phpactor/phpactor) and PHP language servers, you can get IDE functionality like refactoring, completion and navigation in basically any text editor, if there's a plugin that integrates with these tools. I haven't used PHPStorm but I doubt it can do much more than Emacs can.
I use VSCode a lot with PHP. It supports nearly everything there. You just need the PHP Inteliphense plugin. 
Sublime Text. 
My strategy is to avoid dependencies at all unless we talk about libraries for excel manipulation or similar. The more control one have over the code the better a program can be supported. Any dependency increases the risk of reaching a point where you cannot do anything because it is not in your code. No library can do everything possible.
It would be a great luck if someone would keep using NetBeans. Because competition is the only force that could move the product forward. If there will be just a single IDE without competitors it will go stale. It's good we have a variety of frameworks to choose from, both backend and frontend. It's good we have a variety of database management systems to choose form. And it's good we have a variety of IDEs to choose from, even if there is a leader. 
You can also, hu, reset the trial countdown, but that's illegal.
it's getting better now that it's an apache product. sure, the interface isn't as nice as, say, vscode, but for a free multiplatform ide that doesn't force you to allow all kinds of tracking it is probably the best one out there. if the people using vscode took the time to read the privacy policy i doubt half the people using it would continue to do so.
I can do most, if not all of that with emacs. I have use php storm in the past, but I always find my way back to Emacs.
vscode seems to work just fine for me, for everyday use. I am just quicker using a few terminal windows (tmux) with tools like find, grep, git etc.. than the gui based versions of it.
wow, finally they support a php version &gt; 7.0 too bad i switched to phpstorm 2 years ago because netbeans was just outdated for so long
Emacs. It is worth learning and you will have an editor for life. Can do most, if not all of what php storm can do. It is free and open source, and can run almost anywhere.
Sorry for the disappointing truth, but I can tell you right away that your frarmework is severely outdated and has serious issues. The reason? First, from what you said, it is evident that you don't quite realize what Laravel is. So you are not even remotely acquainted with any modern framework and have no good example to follow. Second, time for the single-person frameworks are long gone. It's teams consists of *hundreds* of devs are working on the modern frameworks or their components. Hundreds. You just cannot keep up with all the parts all by yourself. As of the testing, it's super-simple. Publish it on Github, post a link here and get as much feedback as you can stand.
&gt; but you'd want to avoid more than 10,000 files in a directory. My thoughts exactly. &gt; While backups kind of become easier when the images are in the database, Not necessarily (see other comments in the post). There are pros and cons of backing up an image hosting DB. &gt; I'd stick to the filesystem approach as it's going to be more performant This is a long discussion and I begin to believe personal biases are at play. My own bias would also be, hell, files are much faster than DB. However. If you check my linked article in the post, you'd see that as per that research, hosting files in a database tends to be a better solution, especially for small files, under 256KB. Our files are small and perfect for this kind of storage (like 100KB or less). But as in any other live implementation, the magic word is *it depends*. &gt; (and you don't need to worry about getting your caching headers etc from PHP). True. But we prefer to control headers, caching and many other things. It's code easiness vs. fine tuning. We prefer the latter and already have in place control over browser cache control, etag, and the sorts. There is another critical difference when using blobs - one we are really trying to stick to as much as possible. Its a design concept we have. We look at images and everything else as DATA. The place to store data is in the database - not anywhere in the webroot. The only place for files in the web root is for scripting files like PHP. One of the big flaws in open source CMS-es (like Wordpress) is the necessity of having write-enabled folders publicly exposed. To us, this is a vulnerability. Instead, we only use read-only filesystems for anything under /var/www or the sorts. Anything DATA (such as text, image, styles, templates) are stored in the database. When done properly (and cached), this is actually faster than reading the files from the filesystem. If WP (or any other CMS like that) would use read-only filesystems inside /var/www, there would not be so many websites hacked on a daily basis. Even CMS developers with bad coding would have a hard time writing a vulnerable plugin, as injection and XSS would be automatically handled *inside* the CMS. Hope you understand the ideas here. 
I prefer NetBeans. I've been working on a Java project, and also PHP projects, git integration.
I am using it everyday, using PDT nightly, and it works very well. It's basically for pure PHP development on par with PHPStorm features. XDebug support is very good too. Only missing bits are a better twig support (basic support is OK, but missing a few things) and some refactoring options that seem to work a bit better with PHPStorm. Aside of that, I won't ever never pay for PHPStorm, no way, I'm working with Open Source software, and Eclipse with PDT is the most advanced PHP IDE in OSS.
&gt;Eclipse can leave real scars kids It seems you didn't use Eclipse for some years I guess. Never had any problems with it. Except when I'm playing a bit too much with nightly built plugins.
Hmm? 8.2 had support for 7.0
Perfect answer. One thing I'll add is that frameworks like sf and laravel not only have way more people working on them, but also * Endless (and I mean it) projects of various sizes and purposes that used it and contributed their opinions and/or improvements * Probably pen tested many times as well * Community that teaches new people and discusses issues and improvements between seasoned people (who don't even need to be part of dev team) - expanding knowledge base and finding better solutions. This also means that a problem that you have is probably already solved (even if partially). * Established security policies - e.g. reporting, fixing, etc * Years of development and expirience. Example: Symfony was first released in **2005**. That is more than 10 years ago!
My advice is even with all tests, you never be sure that all things will go well, just post it to Github, watch how people use it and feedback, act quickly to fix if there are issues. I think it is the fastest way your frameork can reach the reliable state.
&gt;Code completion Any IDE without this is not an IDE. Eclipse PDT has it too. &gt;Code following Code navigation. Eclipse PDT has it too. &gt;Static code analysis Every IDE out of there should have this, without this it's not an IDE, it's merely an power user text editor. Eclipse PDT has it too. &gt;Code quality inspections I personally prefer this to be set up at a lower level (project level, using composer scripts or git hooks) it leaves the choice of the IDE/Editor to each developer. &gt;Plugins Every good text editor / good IDE in the world has plugins. &gt;GIT tools Whereas every good IDE should have it too (Eclipse has one of the best git support I know of) I still prefer to use git in a shell, it's much more powerful and much less error prone. &amp;#x200B;
This. How the hell are clients "installing widgets" in a laravel-based app? 
It's it pretty clear that they are talking about WordPress and just lumped Laravel for whatever reason.
Writing your own framework is both hard and dangerous. Even Laravel is based upon other frameworks' components. When you deal with security, data validation, form handling, you can't pass around years of experience of thousands of bugfixes done by thousands of developers. Writing your own skeleton application using mature and battle-tested components would be a much better idea. Most modern frameworks are component based and not that much opinionated (maybe it's wrong for Laravel, laravel is an ugly bitch forcing you to think its own way) using any component-based highly flexible framework allows you to benefit from those many years of experience and security wise components, but still writing the code the way you want.
Yeah that's why I wrote &gt; and not &gt;= ;)
This is a PhpStorm specific feature. Other programs cannot use it (by default). There is a popular Laravel package named barryvdh/laravel-ide-helper. It generates PhpStorm meta file for more featured, accurate code autocompletion, uses PhpStorm advanced metadata. Look at generated file: https://gist.github.com/barryvdh/bb6ffc5d11e0a75dba67 For example: ```app('cache')-&gt;put('key', 'value', 10);``` When you type **app('**, PhpStorm suggests available aliases (e.g. *cache*) and then resolves the class, when you continue to typing with **-&gt;**, it will show you available public methods (e.g *put*). 
For two products to be competing, both need to be about on par. Angular, Vue and React compete with eachother, because they are about on par when it comes to features. NetBeans is less shit than Eclipse, and that's about all it has going for it. For NetBeans to compete with VSCode or Idea, it needs to be on par with them. It's not. Competitiveness cannot be forced. You cannot say "hey, let this Prius compete with Tesla, we need competition", because one is clearly superior to another. 
Does it still not have a dark theme that doesn't make me want to gouge my eyes out? 
I see. Yeah it was slow to upgrade in the transition unfortunately. Out of curiosity, excluding the release delay over the past year, what do you find better in phpstorm?
I see this type of statement often enough, but then I'm curious what features it is missing to be competitive.
This is my workflow as well. Basically if the OP can afford it, PHP Storm is a fanatic tool. If price is a worry, then VS Code can do about 80% of the same stuff. PHP Storm also requires a decent chunk of memory and processing, so the actual computer matters as well. It's basically the Photoshop of IDEs. 
If you're working and earning anything over $40,000, then PhpStorm is already less than 0.3% of your earnings. If that's still too much, get your employer to pay for it. If they won't, it's still worth paying for it now since it'll get even cheaper the follow years.
I mean...maybe. WordPress is annoying but it's never inspired me to create a PHP framework when there are so many really great ones out there (such as..you know...Laravel). I'm actually tempted to build my own framework for the novelty and learning that type of project could provide, but I wouldn't really consider it for anything else. 
As others have pointed out, writing your own framework is hard, dangerous, insecure, etc... I wholeheartedly agree and you should probably not use it in production. However, I do want to highlight a good reason to write (not use) your own framework: exercise/experience. You've now gone through all the difficult and obscure bits of what a framework does for you. You've learned in depth about routing, security, forms, request types, etc... and you've become a better developer because of it. The fact you're asking this question is a testament to that. That's also why you already know it's answer, even if you don't want to believe/accept it. So use your newfound experience and leave your framework as it is, exercise/experience/education.
Is Intelephense better than fbecker's Intellisense?
VIM for quick tweaks and phpStorm for working on the main stuff. 
In Idea/PhpStorm, open Help-&gt;"Productivity Guide". For a starter, you immediately have around 83 features, with screenshots and last-used timestamps, which are missing. That's just one part, the other part are the features like the integrated Database explorer tool, or essential plugins like "PHP Inspections Ultimate" or plugins for Symfony. The Git integration (conflict resolution, compare entire source tree with other branch, etc) is way ahead of their competitors, unfortunately. It would be amazing to have an open source project to try to compete with that, but even if JetBrains would stop existing tomorrow, it would take many years tocatch up.
Not me! I think those source are much needed progress. There is a minor mistake in interpretation. 3rd replay to earlier tweet is Laravel author giving some explanation as to why Sublime is not enough for him. So he used Sublime before and after switch to PHPStorm. Medium source make it clear PHPStorm was phased out. We still do not know why though :/
Well, for one, you can't get better autocompletion than what IntelliJ offers. There's also support for multiple projects and instances, don't know if any sane manner of doing so was added to NetBeans since I last used it or not. That's the two off the top of my head, I'd need to reinstall Netbeans and see what I'm missing to find more. Also, IntelliJ has dark themes that don't make my eyes bleed
All of that, except maybe the first part is in Netbeans.
Netbeans is way better than VSCode. Particularly in PHP development. 
Is it a requirement to skip a version number these days?
Better than VSC, sure. But still leagues behind PHPStorm.
Right. That explains it. Does it share history with eclipse? I remember a similar experience with that
That's not composer related. You can take ownership of composer dependency by removing it from package.json and copying folder from vendor to someplace else. (And updating autoloding entry, but you do it already with manual dependencies so I treat that as no-op). You can also decide to provide a Pull Request or two and fix or update dependency in question. When that PR is merged you can update versions in package.json and start tracking upstream again. Third option being the most common: dependency is OK, just the way it is, where with composer you still get benefit of unified dependency graph, security audits (with extra Composer plugins), and occasional bugfix (and a breakage ;)) that comes with new release. So it's still an trade off. Your workflow can be done manually and automatized.
&gt; I still prefer to use git in a shell There are two places that I prefer the IDE. Local commits and merge conflicts. The first just because I'm lazy. It's got a hotkey. The second because it's just a wonderful tool. Yours, theirs, the resulting merge, all line by line. It's great.
Writing software (especially a framework) can be very hard, but it can teach you as well. So don't stop learning. Somethimes it's good to see how others have solved a problem. (I personally prefer a simplified framework, where I gain maximum control, but still profit from the framework without the burden of having it too close.) To improve quality, you can do: \- codecoverage, to see if everything was touched by a test \- infection testing, to see if you're test are making sense. \- static analizing (phpstan, psalm) to see if they come up with some wierdness \- scode sniffing (phpcs, phpmd, phpcpd, php-code-fixer) \- analyzing cognitive complexity &amp;#x200B; and of course, you can publish and get some asswhips from guys who know better ;-) &amp;#x200B; &amp;#x200B;
You could use the Flysystem \[abstraction\]([https://github.com/IntegralSoftware/flysystem-pdo-adapter](https://github.com/IntegralSoftware/flysystem-pdo-adapter)). You could write your own abstraction layer, or use one that has already been written and trusted.
"vs Code is not an ide" That's not just your opinion thats also the devs of vs code's opinion. It should be seen as a lightweight editor not an ide. 
Keeping recently accessed files for quick access in memory has been one of the core ideas behind every Unix and Linux filesystem since Unix came to be.
Everybody here is right. Sorry. But be proud of what you wrote. It's no minor accomplishment. I'm sure you learned a lot and you had very good intentions. Go ahead and put it on Github. You might as well. Keep it as a hobby project.
I remember him talking on the Laravel subreddit. He said something along the lines of trying out PHPStorm for a year(?) or so and decided he preferred Sublime. Also Jeffrey Way on Laracasts uses Sublime too and I respect that guy a lot. When you watch him code, it's like watching a master craftsman at work.
It's not about support, it's about integration. You can have 200 features more, if they don't integrate with each other... it's just a big pile of crap. Which is a common problem with free software unfortunately(open-sourced or not regardless). Integration has a cost. \&gt; some refactoring options that seem to work a bit better with PHPStorm That's a massive understatement. And there is a lot more features, like workspaces, rest client, version control integration, database integration with migration generation, docker integration, debugger and test integration. My favorite is inspections, it saves me so much time on code review refactoring... Don't get me wrong I also support oss as much as I can (working for an open source framework), but when you are in a professional environment, and you are expected to provide professional code (read good quality, in time) then you need professional tools. Eclipse when it comes to PHP does not qualify as far as I am concerned. 
Earlier this year I made what I call an "unframework", which is essentially a boilerplate for starting a PHP project that pulls in a load of third party libraries for things like routing, dependency injection, and an ORM. The end result is kind of like Linux From Scratch - you'll learn a lot by doing it, but it's not something it'd be a good idea to use in a production environment.
&gt; A contemporary framework's team consists of hundreds of devs working on the core or components. often with entrenched long-term support policies or entrenched beliefs where static analysis &amp; good security practices are antithetical to the framework/cms etc.
Thank you for your suggestion. Interesting abstraction. This would eliminate dependency on a certain cloud provider and allow fast switching. But we're probably not going to use it, unless forced to. Our coding style and solution choices are not the common kind. We basically went against the mainstream. It's the hard path, but we prefer it. End result was more than favorable (reached it in 2013). Giving you some description below. We have our own framework, developed over a decade. It's the lightweight sort, highly optimized, geared on speed and security, designed for coders. We use a cluster approach and mostly baremetals. The framework also includes a DAL, a comprehensive blob storage interface (highly useful, from our experience with more complex cloud apps) and plugins for whatever need imaginable (e.g. a flexible database management interface; security enforcement; secure auth; caching; blog; logging and stats etc.) Creating a website / SaaS app is for us often more of a uploading a template and preparing the config, even if it's a distributed system. Sort of a coder's dream toolkit. Someday in the future it might go public, for now it's private. This being said, we can easily write our own abstraction. In fact due to the extensive nature of our work, we tend to rely solely on our own tech and avoid including third-party as much as possible. This also ensures a ridiculous app building speed as we always follow the same principles. There are only a couple things third-party in our code and we're working on removing those as well.
Is there anything in vscode that tracks you besides the optional telemetry?
It does a lot of the same things, out of the box, with basically zero config and it's purpose built to do it. A honda can haul dirt, but it's not a truck. PHPStorm is made to be a PHP IDE on top of a multi-language IDE core. VS Code is really nice, but it's not an IDE it can just be wrangled into acting like one.
idk man I didnt memorize the whole eula. from what I remember from reading it a week or two ago the things they track are extremely broad and open ended. they did mention that you could opt out of certain metrics but they did also explicitly mention that other tracking metrics were mandatory. it's a Microsoft product after all. that pretty much says all you need to know about it.
I found it [https://code.visualstudio.com/license](https://code.visualstudio.com/license) Certainly the license is anything but specific.
Vim. Used to use PhpStorm but it's way to bloated. After using Vim for about 6 months I could never go back. It's a hell of a learning curve but so worth it and lots of fun as well. 
Better performance, better indexing, better autocomplete, easier way of managing projects or remote connections Just some of my impressions. However I last used netbeans 2 years ago and don't quite remember all the differences
Interesting. I use Coda 2 and it does all of these things and I never see it mentioned. PHP Storm and the like have always seemed like overkill for me. If you want a clean UI that’s still got tons of features, check out Coda. 
There is a nice plug-in called Darcula that´s been available for 3 years at least. but I agree the default dark themes are quite ugly
If you want to make your own framework, then do it. The authors of Laravel and Symfony once started from scratch too. The chance that in the end, you will have something worthwhile is extremely small. But, you will gain very valuable experience. Especially if you will pry into the code of mature frameworks. Try to understand how they implemented DI, Request, Response, Form, Validator, Router modules.
Is NetBeans still a thing? O\_o
It has extensive tooling which may not be necessary for a newbie, put aside SQL integration. Which is probably most efficient tool when interacting with tools like mysql. Other than that, there are some features which are godsent for a newbie, which are not present in other editors. First, intellisense which is scoped according to what is accessible from object or function in php depending on it's arguments, properties, methods, and doesnt even attempt to suggest anything from lexical scope (same file) which is just noise. It also immediatly highlights any issues regarding it. But this isn't even the main selling point to a newbie. Major feature other editors lack is local code version control. (not related to git). Usecase: imagine you write complex piece of code. You change something it breaks. You can't recall why exactly its broken but you know it worked hours ago. At any point you can revert back to working version, are any step of your changes and have overal look of how your code looked when, and how it looks now while having all the different places highlighted for you to inspect. This works with entire folders even weeks back in Time. Hell this feature alone saves hours of development and frustration. In critical times, even in real work saves days of development. And all with keeping your git clean. There is also local patching of code, applying patches directly from Raw diff pull requests, etc. But I suppoose that's not as important for you now. There are numerous other features. Like framework specific intellisense.
Hey, wherediditrun, just a quick heads-up: **immediatly** is actually spelled **immediately**. You can remember it by **ends with -ely**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Hey CommonMisspellingBot, just a quick heads up: Your spelling hints are really shitty because they're all essentially "remember the fucking spelling of the fucking word". You're useless. Have a nice day! [^Save ^your ^breath, ^I'm ^a ^bot.](https://www.reddit.com/user/BooCMB/comments/9vnzpd/faq/)
Well, best of luck reinventing everything. I prefer to go with "mainstream" if by that you mean tried and tested following good practice that has been learned over the years by many developers. If I can pull in many man-years of development and refinement in a couple of seconds with a composer command, and even push my changes back when they are shareable, then that is what I will do to get me up and running quickly. But that's me, I guess. I've seen far too many home-grown framework horror stories over the years to want to go any other route. One question: what did you hope to achieve by posting here?
It has extensive tooling which may not be necessary for a newbie, put aside SQL integration. Which is probably most efficient tool when interacting with tools like mysql. Other than that, there are some features which are godsent for a newbie, which are not present in other editors. First, intellisense which is scoped according to what is accessible from object or function in php depending on it's arguments, properties, methods, and doesnt even attempt to suggest anything from lexical scope (same file) which is just noise. It also immediatly highlights any issues regarding it. But this isn't even the main selling point to a newbie. Major feature other editors lack is local code version control. (not related to git). Usecase: imagine you write complex piece of code. You change something it breaks. You can't recall why exactly its broken but you know it worked hours ago. At any point you can revert back to working version, are any step of your changes and have overal look of how your code looked when, and how it looks now while having all the different places highlighted for you to inspect. This works with entire folders even weeks back in Time. Hell this feature alone saves hours of development and frustration. In critical times, even in real work saves days of development. And all with keeping your git clean. There is also local patching of code, applying patches directly from Raw diff pull requests, etc. But I suppoose that's not as important for you now. There are numerous other features. Like framework specific intellisense which might also be important for a newbie You also have to take into account that editors like Sublime, VScode etc are general purpose. Therefor no matter how good the plugins are (generally they are still seriously behind in capabilities of in built stuff when compared to PHPstorm), they cannot shut off the functionality which gets in the way of trying to randomly guess what you want to autocomplete. As for me personally who works in CI &amp; CD environment. Extensive git support is crucial. I also work in code bases which are quite huge with other few dozen of developers, meaning I use code which I have not wrote and is not my responsibility to understand quite frequently. Meaning I rely on contract that interfaces will do what I expect them to do. Having PHP specific intellisense where no random stuff gets in the way to clutter it is important. Not to mention how epic symfony plugin is. Which I kid you not, feels like a mind reading machine at times. I also use docker integration, webpack integration and all the auxilary tooling as well, something freelance developers usually do not rely on as much to manage their projects because scale of applications is small enough to keep a track on everything in your head.
Hey, wherediditrun, just a quick heads-up: **immediatly** is actually spelled **immediately**. You can remember it by **ends with -ely**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
hEy, WhErEdIdItRuN, jUsT A QuIcK HeAdS-Up: **ImMeDiAtLy** iS AcTuAlLy sPeLlEd **iMmEdIaTeLy**. YoU CaN ReMeMbEr iT By **eNdS WiTh -ElY**. hAvE A NiCe dAy! ^^^^tHe ^^^^pArEnT ^^^^CoMmEnTeR ^^^^CaN ^^^^RePlY ^^^^WiTh ^^^^'DeLeTe' ^^^^To ^^^^dElEtE ^^^^ThIs ^^^^cOmMeNt.
Hey CommonMisspellingBot, just a quick heads up: Your spelling hints are really shitty because they're all essentially "remember the fucking spelling of the fucking word". You're useless. Have a nice day! [^Save ^your ^breath, ^I'm ^a ^bot.](https://www.reddit.com/user/BooCMB/comments/9vnzpd/faq/)
Hey BooCMB, just a quick heads up: I learnt quite a lot from the bot. Though it's mnemonics are useless, and 'one lot' is it's most useful one, it's just here to help. This is like screaming at someone for trying to rescue kittens, because they annoyed you while doing that. (But really CMB get some quiality mnemonics) I do agree with your idea of holding reddit for hostage by spambots though, while it might be a bit ineffective. Have a nice day!
Why do I always feel like I don't know anything? I started learning php back at the beginning of this year, sometimes I think that I'm an intermediate developer and sometimes it makes me feel that I just don't know anything. I don't know why this shit happens. Here in the small city of Punjab, Pakistan there is no community of developers. People say you must go to university to learn skills you can't dream big if you live in a small city...
Ideavim is very good and performant
The OP is asking for advice about improving a custom framework and "climb to the shoulders of symfony or laravel is the mainstream response". I guess it's not a popular opinion, but I think some people is afraid of other people's code (ie. code that isn't "bussiness logic" and/or isn't using symfony/laravel helpers/classes, which turns to be very convenient if I already know those conventions). Seeing the average comments, is like a lot of people is saying that PHP frameworks are the new cryptography ("don't do it yourself" because you know, lot of expertise is needed). Are we really saying that? &amp;#x200B;
I'm curious too. I've used Netbeans for years, in that time I won a PHPStorm licence once, installed it and tried it for a few days but found nothing there that was better than Netbeans and so I switched back. I've just started a job recently where everyone has to use PHPStorm, so I've used it more thoroughly. The one thing I've found that PHPStorm does that I don't think Netbeans offers is conditional breakpoints. These allow you to for instance specify that you want a breakpoint to become active only when a variable has a certain value. This is potentially very useful on occasion. You can also tell it to ignore framework files when stepping through code, again potentially very useful but I've not got it to work as yet. One thing Netbeans does that is better is "window pane" management, for want of a better term. It's somewhat easier to find your way around in Netbeans when you have 10s of tabs open at once. Neither of these are deal-breakers, and I really don't understand the widespread acclaim that PHPStorm gets.
Well I think a lot of people who love to hate JetBrains aren't the audience who could make most of their offered features, extensive git support doesn't come into play if you work alone or in small team, or perhaps don't bother to learn the tool, because the learning curve is quite steep compared to VSCode or Atom. However, while my employer pays for my PHPStorm license, I bought GoLand myself. Even though, it's relatively fresh product in their line, Go itself isn't overly complex language and VSCode with Go plugin is actually quite decent (although it still fails on frequent basis, even on 'simple' things like highlighting argument struct types). But once you get used to comfort, it's difficult to downgrade. And I value my time and comfort more than 90-60 euros.
Surprisingly perhaps, I agree with your comment (not going another route). And that one shouldn't reinvent the wheel. One should not follow the path of creating their own framework from scratch and I've seen enough horror stories already. So I wouldn't suggest another route. We're simply the exception and we won't recommend it too. It took a decade to mature things and countless rewrites. You have to understand that there is a huge workload and investment behind our framework. Actually, 15 years of it. And that our product isn't a half-baked one. We went the whole nine yards with it for long time. We're still going the whole nine yards with the core of the product. It started as a response to early CMS versions of WP; at that time, things were NOT like today when you can easily use Symphony and an readily available DAL or ORM. We were out of tools, nothing satisfied, so we built our own. Shortly, they surpassed the performance of whatever is out there so we continued building them for years. There are sophisticated solutions built on top of it; countless sites, e-commerce, blogs; SaaS products; even a full-blown ERP system. We're currently building a marketplace and that's pretty much straightforward in all details, except there were still some inconsistencies in the image storage zone. &gt; One question: what did you hope to achieve by posting here? Just wondering what you were looking for. Exactly what has been posted. I was questioning our original choice of using blobs. A good developer should always question what they are using, and asking the community is always useful. I already knew there are pros and cons of each method. But if you look at all the comments, there is a lot of additional info received. Give you an example, using Varnish together with HAproxy, which makes a lot of sense. Lots and lots of details. Often I'm personally looking and testing things I do not normally use. Reason? Again questioning what we use, discovery, maybe finding something better. Should the application requirements and solution be different, using a ready-made, mature existing product would make a lot of sense. I'm actually NOT recommending anyone to go on this path. But right now, I would never go back. Ever. We're all really happy about our results and progress. Productivity is insane, code is extremely fast and hosting is cost-effective. As to why questioning blobs since we already tested them in the past, that's also a story. We never planned to develop to this scale, our existing blob storage was aimed at less than 100K blobs, say under 1GB of data. Above that, things change. I've been doing additional research to determine whether our requirements meet the blob solution, and it does. Should the files be larger, we would have needed something else, namely file storage where something like an s3 replacement would have a lot of sense. It's sometimes difficult to understand someone that is / does things differently - unless you get to know their work better and see for yourself. 
I seem to remember when I was self teaching myself in the early 2000s that PHP stood for: "Perl Hypertext Preprocessor", and a google search seems to turn up this in some old tutorials as well. The official site has been scrubbed of any mention of Perl, though. Was this just a rumor or bad information that was disseminated? Or was it just rebranded? This almost feels like a Bearenstein Bears situation. 
Maybe you're thinking PECL or PEAR? Both are additional libraries that add functionality to PHP.
Don't think so.
It's a recurring acronym for the PHP Hypertext Processor. It was originally the Personal Homepage Tools, and later renamed.
I personally haven't heard it, and I disagree with those downvoting you. You're asking a simple question, that seems to have some validity (either at some point it was, or, multiple people are wrong and you're asking for clarification). My guess is, when it was an early language, it was just bad information. You would probably use perl to pick up the slack of anything PHP couldn't do at the time and I know they were used together at times. This is pure speculation though, and I'd love to hear from anyone who has any concrete evidence 
Here are some things I found that sort of validate this memory: [https://www.acronymattic.com/Perl-Hypertext-Preprocessor-(PHP).html](https://www.acronymattic.com/Perl-Hypertext-Preprocessor-(PHP).html) [https://www.allacronyms.com/PHP/Perl\_Hypertext\_Preprocessor](https://www.allacronyms.com/PHP/Perl_Hypertext_Preprocessor) [http://abanx-gian.blogspot.com/2015/11/php-perl-hypertext-preprocessor.html](http://abanx-gian.blogspot.com/2015/11/php-perl-hypertext-preprocessor.html) [https://www.linuxforen.de/forums/archive/index.php/t-99444.html](https://www.linuxforen.de/forums/archive/index.php/t-99444.html) [http://myanmaritresource.darkbb.com/f27-perl-hypertext-preprocessor](http://myanmaritresource.darkbb.com/f27-perl-hypertext-preprocessor)
[PHP in 2018](https://youtu.be/rKXFgWP-2xQ) by Rasmus Lerdorf. 
Thanks. I provided some links above that seem to point to me not being the only person who thought this. It's tough to find tutorials from now-defunct sites that were prolific in those days. Was hoping to get some insight from those who were also around back then.
Since you mentioned SSR: [https://plugins.jetbrains.com/plugin/7622-php-inspections-ea-extended-](https://plugins.jetbrains.com/plugin/7622-php-inspections-ea-extended-) has a bunch of similar inspections and more.
No problem, sadly for you (although happily for me I'm not that old) I wasn't working in it back then. I know a lot of my former companies legacy code was php3 files that called a lot of perl files, which leads me to my hunch, but that's just literally one use case and kind of anecdotal (aside from the fact I know perl was, and still is in a lot of respects, a very common server side language for sever administration) 
It’s $89 for the first year for individuals, and cheaper after that.
No, Rasmus Lerdorf liked working in C but the new trend was to use Perl; he hated Perl and wanted to continue working in C. For this he made a template language where he could give work to designers without them messing with his code. Since it looked like Perl the designers knew what not to touch and he could still do everything he wanted in C. He then opened it up to the world and PHP then became a set of tools to help with web page development and started to grow. Once people started creating template engines for his template engine and once he was approached by two kids wanting to use PHP as THE language for their project in college, then he knew he lost control of PHP and it was on track to become its own language. TL;DR: PHP was designed to look like Perl so Rasmus Lerdorf did not have to use Perl.
I thought PEAR was like composer. It doesn't add functionality itself but allows to you add packages for additional functionality. 
None of these sources look particularly reliable. It just seems to be a bunch of people mistaken about the acronym.
back when I started programming in PHP in 2001, Perl was still pretty popular for handling cgi requests. One place I worked we mixed those languages together all the time for different purposes. It was ugly, but it worked at the time. I'm glad I don't have to code in perl, and even more grateful I don't have to read other people's perl code.
To continue the Perl related discussion, PEAR was more like CPAN, really: a central repository for packages that could be installed on a server-wide basis. Composer tackles the same basic problem, but in a way more akin to something like NPM: package installation on a per-project basis. (Which, as it turns out, is by far the more useful approach in almost all cases.)
Images should be stored in a CDN.
As a former perl user that switched to PHP I 1998/1999, in pretty sure it was never "perl Hypertext Processor". The two are nothing alike except for PHP's use of perl-like syntax for RegEx. 
A couple of other people have answered this, but for an actual source, this is covered on [the PHP project history page](https://secure.php.net/manual/en/history.php.php). The short answer is: no, besides some general language design inspiration (most notably in variable sigils and string interpolation).
&gt; Only if using full backups. There can be such thing as an incremental one. Our system is actually built for incremental. You should have incremental and full backups..
You're not being a scientist/researcher, you're discrediting the helpfulness of peer review of ideas. People are telling you this is a bad idea and you don't want to listen to them.
I use PhpStorm. I love JetBrains IDE products, they are all great.
It has much more powerful code completion, refactoring, etc. It feels more robust than a bunch of extensions that sometimes conflict with each other and it just feels like a whole package because as the name suggests - it is, it's an Integrated Development Environment with all the tools you would ever need right there. I find it super helpful for navigating large codebases where it's impossible to remember every last file and every last function.
An IDE like PhpStorm ends up making everything feel more robust and stable, nothing conflicts with anything else because it was all designed to work together, etc.
Nah, it was PHP Hypertext Processor, never Perl Hypertext Preprocessor. The author of PHP hated/hates Perl.
Amazing someone obviously capable of learning pearl hated it so much he wrote a whole templating language that happens to power most of the web. Fuck pearl I guess.
perl is to php as java is to javascript
yes.
I came here to mention the three-way merge and conflict resolution tools in PHPStorm. I used Kaleidoscope for conflict resolution for years. A coworker basically forced me to try PHPStorm’s “new” merge functionality. (New to me, anyway.) I was impressed, and never looked back. In addition, PHPStorm’s code inspections help you write better code. If you work on a team, the inspections, code formatting, and code generation (like adding getters and setters) help you write consistent code as a team.
NetBeans is awesome for Java EE and it's for free. However Java EE is hated by the community, so java devs moved on Spring that it's worse, so they invented Spring Boot that it is more usable, Spring Boot is the last bastion of Java. The Java world is full of llama-drama and yet, the Java market is HUGE. About PHP, Netbeans is free and it oka-y, it's not PHPStorm or VS.PHP but it's way better than to work on notepad++ &amp;#x200B;
How is it a abomination? For Java EE, Netbeans is neat. Do you want a EJB, then right click, create session beans, and that's it!. Do you want a JSF, then the same, do you want a Web Service, then too. And so on. 
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
But it's for free. I own PHPStorm so I don't use Netbeans but for some customers, I install Netbeans because it's for free. VSCode is also part of my toolbook but it is not the same.
Hey there, I have a "small" problem with php gettext ... I used the Twig Template engine and build the Translation files normal... now i uploaded my site to a plesk powered host and i activated gettext via PHP.ini and PHP tells me that it is activated but my Texts are not getting translated ... The next thing i tried was to upload it to a different server and ... it works there ... I don't know what to do ... I also tried : `sudo locale-gen de_DE` with no luck at all...
I'm not discrediting anything. I said I might be wrong. Should I discover down the path that I'm wrong, the advice received here is going to be gold. Besides, If you are reading all comments, you'll see that not everyone thinks it is a bad idea. Furthermore, if I had 2 cents for each time I was told I was wrong, it would be a lot of money. I've been successful enough, and the main reason is 1) actually listening to what others say, and 2) never following advice blindly, and 3) seeing for myself. There is more than one way to accomplish something. It can be *good* or *bad* depending on one's perspective. There is no universal truth, and no single angle to look at something from. 
MongoDB is a NOSQL database. A NOSQL database is aimed to store inmutable information while is sacrifice data analysis. Anyways, Postgres is Oracle's cheap cousin.
As several other people have suggested, the best thing you can do is open the code up to the public and don flame proof clothing. But if you want a simple security check list then just read through the various [Symfony Advisories](https://symfony.com/blog/category/security-advisories). If you can confirm that your code does not have any of these issues then great. On the other hand, if you (like me) don't even understand what 3/4 of these issues even mean, then your framework might have some problems.
Alright, as long as you're willing to admit that you might be wrong then that's okay.
Php dot net manual is one if not the best reference manual around here. Stackoverflow, while it is usable, it is not a manual but a random guide and sometimes it misguides. Instead, Python manual is horrible, C# guide (Microsoft technet) is a clusterf\*ck, Java manual is intense (you could read pages and pages that say nothing).
It reminds me of "F\*ck Mod Perl" PHP \* Programming with Attitude [https://i.imgur.com/waLGhan.jpg](https://i.imgur.com/waLGhan.jpg) &amp;#x200B;
Why not? However, what is a preferred language is a person matter rather a technical or business decision. If it's web then PHP can do that. &amp;#x200B;
Seems odd that a bunch of people from all over the world would use the same wrong acronym, though, right?
If you are creating a front-end, then the bottleneck is not the template system but the database.
Yes you can. Write them on paper, then store them under key. Be careful with that key :)
For a sidenote: 20% of the servers are Windows Server. &amp;#x200B;
Thanks everyone for the discussion. So how did all of these people from around the world (links in my earlier comments) in the early 2000s come to the same conclusion that PHP stood for Perl Hypertext Preprocessor? 
Eh, you're not really getting my point. :P
I am, just joking. There's also such thing as a slow hash.
I actually don't find it that surprising considering how much inaccurate information is on the internet. Given enough time you could use random sources from the internet to "prove" just about anything. You need to also take into account how reliable a source of information really is. &amp;#x200B; What you listed was: * Some guy in a Geology department who happened to use PHP and the GD extension for rendering some data he was working on. * A bunch of acronym definition sites that provide no citations or clear references for how they arrived at their particular definitions. * A mailing list for perl where someone wasn't even sure that they were using the acronym in the correct way. * The guys personal blog with the animated marquee disqualifies itself IMO. Well...maybe not, but come on. That has to count against them :P I could go on. I've had to translate some of the pages to understand them.
Jeffrey also uses phpstorm and pushes Taylor to use it. https://laracasts.com/series/how-to-be-awesome-in-phpstorm
Isn't it only for Mac ?
Unfortunately yes. 
Why we need a binary folder for a PHP project? Anyways : the public/ folder is convoluted.
Code of Conduct is modern propaganda, please remove that aberration.
I wasn't implying they were PHP devs or anything, just showing that it seems a swath of people from all over the world seemed to think this was the case.
It might have something to do with the fact that Perl was actually more popular a while back. It was actually the first scripting language I learned in high school / the early 2000s. I wrote a lot of Perl and PHP then (though neither very well). However, I can see how more people woud've been confusing the acronyms easier then. Though there was never any real relation, as far as I'm aware.
I find him impossible to follow when watching him code.
Then it was associated with Perl, only negatively.
Early PHP and JS share the same core strength — an extremely small learning curve and forgiving syntax. Although Perl isn’t always used this way, it has an element of “look how smart I am” that PHP never suffered from. Like HTML, PHPs strength was its simplicity and that’s why it originally became so entrenched. Really the only downside to this was the language was so easy to use that various anti-patterns emerged around security that eventually lead to stuff like the failed Magic Quotes experiment. 
:( perl is beautiful
And those two kids? Steve Jobs and Bill Gates.
I’ve been having trouble using DOMDocument and DOMElement to automatically create a &lt;noscript&gt; tag around a cloned image. Execution keeps timing out, despite the number of elements to modify being relatively small. I’m not looking for a detailed answer, I just wanna know - is this more likely to be user error or the processing overhead? 
Vscode it’s awesome for everything and free
Used it for years for php but it was extremely heavy ide for my machine 
&gt;Seeing the average comments, is like a lot of people is saying that PHP frameworks are the new cryptography ("don't do it yourself" because you know, lot of expertise is needed). Are we really saying that? The unspoken second part of "don't roll your own cryptography" is "unless you are intimately experienced with both cryptography and the platform you are implementing it on". The same is true here, although there is certainly a much lower barrier to competently creating a PHP framework, especially if you're gluing together existing components. But if you are at the point where you can implement a framework singlehandedly that is safe for production use with paying clients, you probably wouldn't be asking on /r/php asking the kinds of questions OP is asking. That they are building sites for paying clients suggests that their clients are likely businesses, which means there is a good chance personally identifiable information about individuals will be stored or processed by the sites. The onus is on us as developers to treat that data with respect and keep it secure, one approach to which can be using battle-tested platforms to build on top of instead of building and maintaining the whole stack ourselves. If you have a solid understanding of security and software design principals, building a reasonably secure framework isn't a particularly difficult task, but remember that everyone makes mistakes and nobody catches everything.
Probably just some misremembering alongside the fact that PHP was quite similar to Perl. Between the constant name changing and the fact that recursive acronyms aren't all that frequent, some people probably just got it confused and the misinformation spread quickly. I remember it seemed easier to find the wrong information than the right back in those days
Yes, they were both server side languages maturing at a similar rate for the web. PHP borrowed ideas from perl, including its regular expressions which are "perl compatible". It's quite telling.
been using Vim for ~10 years. its not for everybody but it works for me! If you want more try using it with tmux. 
Close. It was originally "Personal Home Page Tools" and then it turned into the recursive acronym for "PHP: Hypertext Preprocessor"
&gt; in the early 2000s come to the same conclusion that PHP stood for Perl Hypertext Preprocessor? Probably the same way that people somehow still think Java and Javascript are at all anyway related.
Last time I checked, I could not switch from netbeans to phpstorm because its dark theme is not very contrasted (too macos). As I am getting old and spend a lot of hours watching the screen, my eyes tends to be less tired with high contrast fonts. (I set my 4k screens with a low brightness to avoid headaques.) Does phpstorm has a dark theme with real high contrast (of quality)?
PHP had the POSIX compatible ereg functions [apparently] (http://web.archive.org/web/20000815063651/http://www.php.net:80/manual/function.ereg.php) in PHP3 already, while the Perl regex library was included (optionally) since [PHP4](http://php.net/manual/en/function.preg-match.php) only.
It was never associated with Perl. The false association people make is that the biggest reason PHP took off was because `mod_perl` was such a pain in the ass to work with, and PHP provided the same sort of functionality in a more more user-friendly manner.
I’m new to programming, and I’ve heard that it’s best to start learning by doing projects that are appealing to you, and I’ve decided I want to start by making a derivative livescore app. Is PHP the way to go?
I really hope the lack of indentation is an artifact of the blog post and not how they actually write their code.
Conditional breakpoints do sound nice. They are actually available for php now in netbeans 10, I've yet to test them yet though as it was only just released. And yeah ignoring those framework files seems like a great tool as well, but you're correct these seem like great additions but not pivotal for me. If in your work with phpstorm you do find any major gaps in features I'd be interested to know. As yet I just can't see the benefit vs the cost and proprietary ecosystem.
Better is always preferable. Perhaps I'll spend a month on the free version to see what better means exactly, and if it really stacks up to the cost. Thanks.
I'll have to try it since better is difficult to grasp without having tried both. Netbeans does do multiple projects, and I've had to do multiples of the same project many times, though I wish their colored project tabs were more obvious. The themes could be improved but they are fine for me. I wish folks had more definitive feature differences though because it actually sounds to me like they are pretty close in features, except phpstorm is vaguely better. So I'll try it for a month and see if I can find the difference. 
I know.
Really? I find him pretty easy.
That's cool. I've never seen him use it in his tutorials. I'll check it out.
And the lack of data validation? The lack of param binding to avoid sqlinjections.... 
carlson_001 is correct most of those exist, I don't know that I need a list of features and how often I use it, or maybe I'm underestimating, or misunderstanding that feature. At this point I'm wondering if the reason people think that phpstorm is so far ahead is just because there isn't good enough documentation for nb. So far I've basically heard that it has the same features but "better", which isn't clear enough to understand so I'll give it a whirl with the free demo, but it doesn't seem like phpstorm has anything significant that nb doesn't. Perhaps having the same things but better by some degree is worth the price? I guess I'll have to find out myself.
There is a version 9, it came out in june I believe.
Vim
Ha! I misread your comment. My bad!
I would assume OP meant in the "Larry Wall" sense of the word "associated."
But for real tho. Fuck Mod Perl.
Vs code in shitty frameworks/wordpress job PHPStorm when I work with symfony/lara
Yes. Take your pick: http://www.phpstorm-themes.com/
https://wiki.php.net/rfc/source_files_without_opening_tag https://wiki.php.net/rfc/phpp https://wiki.php.net/rfc/nophptags 
Ya done good lass. Good article. 
Try Material theme extension. Has lots of dark options. After using it for a few months I can't live without it. 
I still love Perl. I think the syntax can be really ugly but a good Perl programmer can get shit done in a hurry and with a minimal amount of code. I never have liked it for big projects but for one-offs and quick shit \#!/usr/bin/perl 
Yes it is.. Way faster
make a proposol how you would see it, and how you would solve all the problems that you have now, and how you would solve all the problems that apear from the change.
These are bad
Yes, I do love using it and configuring it. I do use it with tmux for nice pane and window management, a couple of select plugins and the monokai theme. I also may have installed a vim plugin for my browser so I barely have to touch the mouse unless I'm chill-browsing. And I have reddit in my command line for covert redditing in the office. 
Well, I read somewhere C is the father of PHP and perl is the mother. 
Before php, ColdFusion and .asp (now called Classic ASP), there was... well... nothing. Literally, there was NO server side scripting that was embedded in with html. (there also was no css or javascript). There literally was only html. Then, someone figured out a way to use CGI (common gateway interface) and couple that with scripts that ran server side - PERL was the usual suspect with cgi scripts. Jesus, I still remember the horror of fucking around with badly written PERL email scripts. So PERL was the norm. What's more, the PERL devs I knew at the time were always sort of snooty about the fact they knew PERL and could do shit with PERL. The ones I knew took pride in learning it, and making it cryptic and obtuse. I fucking hated perl. And then... server side languages came out. I'm pretty sure ColdFusion was first. It was a clunky piece of shit, but at one point it was the only thing available and it wasn't perl. Whoo hoo! But soon... Microsoft declared that they were 'getting serious about the internet' and released .asp. If memory serves they made the announcement on Dec 7th as some sort of strange 'day of infamy' thing. .asp was actually really fucking good for the time. It was better, cleaner, easier to work with than ColdFusion and it beat the shit out of perl. Being server site Visual Basic script embedded in &lt;% %&gt; tags made it stupid easy to work with, especially for simple tasks like loops and if statements. It had to run on Windows though, which at the time, Windows NT was ok... But it couldn't handle lots and lots and lots of requests as well as many of the unix solutions. And then... there was php... It ran on unix - like PERL. It was open source - like PERL. The language kind of looked like PERL... So its understandable why anyone, even smart programmers, would think it the 'next generation' of web based perl interaction. CGI was sort of clunky, and php code embedded within the html seemed more elegant and easy to deal with. The first couple of versions of php were... not good. They were buggy and prone to problems and generally we made fun of it and much preferred .asp (except for really large scale projects that needed the robustness of unix, ColdFusion was used. From what I recall, MySpace was written in ColdFusion... Lots of early online stores (CDNow) were written in ColdFusion. BUT... php was incrementally improved every couple of months, and within a year or two it became a force to be reckoned with. It was suddenly BETTER than ColdFusion (and cheaper because it was free) and more popular than .asp because it was free and could run on unix. ColdFusion sort of stopped being used. Classic ASP gave way to ASP.NET Webforms, which was at first really loved because of the easy way it could handle state, and components like grids and shit like that... But it soon became apparent that ASP.NET Webforms was a colliossal piece of shit with lots and lots of messy crap that was hard to deal with. Ever wrestle a grizzly bear? Working with WebForms was kind of like that. And so... php kept chugging along, getting better, gaining followers. Classic ASP was still better in a lot of ways, but it was beginning to hit its limits with single threading and sales guys at MS trying to kill it and migrate everyone to the colossal piece of shit that was ASP.NET Webforms. And then just as php started to show its age, frameworks came out... CakePHP and a few others... I didn't use them much, by then I had moved on to ASP.NET MVC or I was working on Classic ASP projects.
I hoped so but looking trough his GitHub doesn't make me want to try and defend his blog post. &amp;#x200B; I hope nobody takes this code as-is as put it on anything web-facing.
I didn't even know about this, thanks.
I give you that for conflict resolution, it can be very handy.
&gt;Don't get me wrong No no I don't get you wrong, but I think you don't know Eclipse that much. You are right about lots of features, as you say, docker integration, database integration with migrations, those are things Eclipse doesn't have. But when you say it's about integration, Eclipse PDT own features are well tied altogether, it's not as bad as you say. &gt;you are expected to provide professional code (read good quality, in time) then you need professional tools It's not because you don't like it you can say that. For what it worth, Eclipse IS a professional tool, it's not a toy. In its own history, it probably has much much more IT professionals working on it than any JetBrain IDE. Being open source doesn't mean being unprofessional. PDT probably has much less love than JDT or other languages support in Eclipse world, but it's damn good. Docker integration is a toy, and sorry if it doesn't please you, but I'll never let an IDE touch my database either.
&gt; No spam, unsubscribe whenever you want.
If you gave an example newsletter in the page, it would be much better. In this format, it looks like a form to get email addresses of PHP developers.
Good point. I just started the newsletter so I don't have some content there yet. But you can check out my blog (https://mnapoli.fr) for some content about serverless &amp; PHP, and I [tweet](https://twitter.com/matthieunapoli) a lot about it too. If you want to get an idea the first email will be about catching up with AWS re:Invent from November: - custom runtimes on AWS Lambda (which means native PHP support) - how the Stackery PHP runtime is not good enough right now and why/how Bref will instead provide better PHP runtimes - VPC cold starts will be removed in 2019 (I'll explain why this is important for PHP apps using databases) - ALB for Lambda as an alternative to API Gateway (mainly a problem of costs for PHP apps/APIs) and other topics.
Here is a not-so-simple PHP call to preg\_match(). It is collecting some subpatterns, while some are optional. &gt;&lt;?php //[https://3v4l.org/8Qhap](https://3v4l.org/8Qhap) &gt; &gt;preg\_match('#(abc)(d)?(abc)(d)?(abc)(d)?e#', 'abcabcabce', $r); &gt; &gt;print\_r($r); &gt; &gt;?&gt; The result is the following &gt;Array &gt; &gt;( &gt; &gt;\[0\] =&gt; abcabcabce &gt; &gt;\[1\] =&gt; abc &gt; &gt;\[2\] =&gt; &gt; &gt;\[3\] =&gt; abc &gt; &gt;\[4\] =&gt; &gt; &gt;\[5\] =&gt; abc &gt; &gt;) The issue is the missing \[6\] : the last 'd' is not found (indeed, it is not present in the string). The other 'd' are also missing, but their subpatterns are present (2 and 4), and empty (as expected). Why is the last optional 'd' missing ? &amp;#x200B; Then, by simply creating a extra subpattern (the last 'e'), suddenly, '6' appears : &gt;&lt;?php //[https://3v4l.org/MBGT0](https://3v4l.org/MBGT0) &gt; &gt;preg\_match('#(abc)(d)?(abc)(d)?(abc)(d)?(e)#', 'abcabcabce', $r); &gt; &gt;print\_r($r); &gt; &gt;?&gt; This gives : &gt;Array &gt; &gt;( &gt; &gt;\[0\] =&gt; abcabcabce &gt; &gt;\[1\] =&gt; abc &gt; &gt;\[2\] =&gt; &gt; &gt;\[3\] =&gt; abc &gt; &gt;\[4\] =&gt; &gt; &gt;\[5\] =&gt; abc &gt; &gt;\[6\] =&gt; &gt; &gt;\[7\] =&gt; e &gt; &gt;) 6 is present, and empty. &amp;#x200B; Before submitting a bug, I'd like feedback : is there some magic that I'm missing ? Are optional subpatterns also optional in the result ? The behavior is consistant across versions, including the recent move to PCRE 2.0 &amp;#x200B;
Legacy projects still embedded php codes into HTML... 
Having my first interview and job using PHP in 1997, Rasmus could still be reached on IRC (his idling screened session). The recursive acronym wasnt formalized until php3 was being phased out, regardless of the revisionist history of the project page. You always lose a bit of history and gain some narrative control when you assign an "authority" to control information. That being said, there was a good portion of the web that was rotting or had always been inaccurate, without a lot of signal sources. PHP was interpreted many ways and PHP/FI was definitely a perl hypertext preprocessor form interpreter - http://php.net/manual/phpfi2.php#history if only in my mind because I remember saving transcripts of discussions with him where some people asked pointless questions (in a practical sense) after the real technical discussions about bugs in php3
Seems like an old, no-fix bug: https://bugs.php.net/bug.php?id=50887
Not a bug as far as I know. With single pattern matching (i.e. `preg_match()`) PHP only allocates the results array up to the highest captured subpattern. The only time PHP fills the array up to the number of possible captured patterns, is if you're doing `preg_match_all()` with the `PREG_PATTERN_ORDER` flag (e.g. https://3v4l.org/Q5khA). 
When PHP came on the scene, Perl was the Big Thing for server-side scripting. There were various Perl-based things that started with 'P', and many people confused PHP for being one of them.
I will just add to this comment that I was blown away recently by how good is PHPStorm when writing Javascript/React. For the past year, I was using VSCode for writing ES6/React and PHPStorm for the backend stuff. The suggestions that gives me PHPStorm for React are amazing. It always knows when I don't need to use "let", or how to better write ternary operators for readability, or when to use statics, or if I have unused methods, etc... Once I ported my project from VSCode to PHPStorm, I spent 2-3 hours going trough my code and fixing stuff that VSCode didn't catch. At the end I am so happy I can use one IDE for all of my work. 
That's a very thorough search of the bug database. Thanks! 
preg\_match\_all and PREG\_PATTERN\_ORDER are both interesting workarounds. I'll add that to the one I found. Hopefully, this didn't bite you too :)
I have been trying all the search terms on Google and luckily it's conclusive. If not I can't rest my day seeing this weird issue popping out. Thanks for resurfacing it out though.
Well, you were always welcome to write your own CGI modules in whatever compiled language you wanted, but there was a bit more involved with that. By the late 90s, Java had a reasonable way to do interact with a web server through servlets/JSPs, and other vendors were picking up steam too.
Great history lesson here. Thanks for this. I remember always wanting to learn ColdFusion as I was learning PHP simply because it sounded badass. 🤘🏻
The website is blocked by my company's firewall, which uses OpenDNS
Beginning every file with `&lt;?php` takes only 5 characters and gives PHP files their own [magic nunber](https://en.m.wikipedia.org/wiki/File_format#Magic_number), I don't see what's really so bad about it.
It is unnecessary and it feels so legacy compared to other languages and removing it wouldn't resolve anything special but to save space with a few chars per file.
This submission has been randomly featured in /r/serendipity, a bot-driven subreddit discovery engine. More here: /r/Serendipity/comments/aab1o9/serverless_php_news_a_monthly_newsletter_on/
You should be fine if you run `php artisan down` first, at least I imagine so. And `up` once you're done, of course. But not 100% sure on that. Yes, this is a late reply. 😅
Subscribe button does not work on ios, safari. Not tested other browsers
I don't see newsletter I see form with email input
The great thing about PHP is that it's an open language. If you feel you have a better solution to the problems the opening tags solve, you can go submit them as an RFC.
Same for me 😔
explains here https://youtu.be/umxGUWYmiSw?t=149
Yes? https://www.reddit.com/r/PHP/comments/aa217o/was_php_ever_associated_with_perl/ecq243x/
Then why was I thinking it started out as "Personal Home Page", but when that didn't cover it's abilities anymore they changed it to the recursive acronym "PHP Hypertext Preprocessor", until they also outgrew that and now just run with "PHP" without any meaning, as everybody knows what it is anyway.
tbf their syntax is pretty similar, which lends to that as well
Hey everyone! I recently created [Simple Wiki](https://github.com/NirvashPrime/Simple-Wiki), a simple no-database wiki platform that supports markdown, and would love any constructive feedback or pull requests you may have. Please note that this is Simple Wiki 1.0.0, so there will be bugs and plenty of room for improvement! If you know of other subs that may find this software valuable or interesting, please let me know.
Please never install this on a server accessible to the public. The code is a security nightmare. I highly recommend ditching this code and learning to use a framework such as Symfony or Laravel. Incorporating these features into a site with a modern framework could be done fairly quickly. And you'd learn a ton!
I also started with PHP in 2001. I worked in three different shops across those first couple years, and in two of those companies, the PHP code was written by Perl programmers that carried over a lot of concepts from Perl into PHP. The most obvious example being that they would use regular expressions for even the tiniest of parsing even when there was a native PHP function to do what they needed.
I would suggest doing some reading on the articles at [https://phptherightway.com/](https://phptherightway.com/) &amp;#x200B; Also, though not using a framework and creating your own can be a great learning experience, I would suggest using one. [https://symfony.com/](https://symfony.com/) is a great one, for example.
I had multiple instances where Netbeans inadverantly decided to remove files from the prod server. Not sure if this was due to a bug or waleware but I have had no issues since switching to PHPStorm. I like how PHP sets up watcher files for front end dev. It's super flexible with multiple options. Lastly, the UX is much more professional imho.
At least we don't need to start our files with `#!/usr/bin/env php`
I introduced perl as a scripting/web-app language at Western Digital, just one project for symbolic debugging of crashed drive core dumps saved thousands of developer hours per year. I think I only ever used about 40% of the full syntax of perl, and it was always a mildly "write-only" language - grokking another developer's perl (or your own six months later) took a great deal of skull sweat.
Very interesting! Thanks for that explanation. Pretty neat to read the history page for that version. I never would've guessed the association with perl at the very early stages of PHP.
Could you clarify on "security nightmare" a bit? Simple Wiki doesn't have authentication (as it wasn't a requirement for its intended purpose), but there shouldn't be any glaring risks otherwise. I'll be sure to check out those frameworks — thank you for the suggestion!
- Find out how to use Composer; you don’t commit the contents of the `vendor` folder to your repository - Find out how to take advantage of Composer to create an autoloader - Read up on testing and dependency injection - Read up on input sanitizing Right now you offer a public filedump. These are basics you will need to try to understand as a developer. Blindly using a framework like Laravel or Symfony won’t help with these issues. But you _can_ draw a lot of inspiration and learn a lot from looking at and working with frameworks. 
Are there any specific issues that you see in the codebase? I've read over "PHP: The Right Way" previously, and Simple Wiki should be fairly close to the specifications there. As mentioned above, I'll also check out frameworks moving forward — thank you for the input!
Thank you for the great feedback! To address those, and hopefully get some more insight: `vendor` was intended to be used for any third-party code, as I've seen recommended previously. I do see now that `parsedown` is available in Composer, so I think implementing that would be a logical next step. For input sanitizing, is your specific concern that someone could use something to the effect of '../../../all/your/files' for the name of a document to modify system files? Thank you again!
You must ALWAYS sanitize user input. In [https://github.com/NirvashPrime/Simple-Wiki/blob/master/models/manage\_update.php](https://github.com/NirvashPrime/Simple-Wiki/blob/master/models/manage_update.php), you use the POST variables directly. This means that someone can submit some sneaky post messages that allow them to upload any content to any directory writeable by PHP. (See line 44) Likewise, in [https://github.com/NirvashPrime/Simple-Wiki/blob/master/models/manage\_delete.php#L16](https://github.com/NirvashPrime/Simple-Wiki/blob/master/models/manage_delete.php#L16) allows anyone to delete any file writeable by PHP. I mean this as help and not as criticism. Please take this as a learning opportunity.
That's a really good point — I had meant to do that before the initial commit, but wanted to start getting input and visibility as quickly as possible. I'll make that a priority moving forward though!
Having used both Coda 2 and PhpStorm, I can assure you that Coda 2 definitely does not "do all these things." Coda 2 has it's place as a combined editor, but if you work on large scale OOP applications, or with teams, it loses it's charm very quickly. Similar to comparing Git to FTP...both can get your code to a server, but the feature sets do not compare.
Not only legacy projects. There is value in templating using embedded PHP in many contexts also with other output formats than HTML (like producing plain text, TeX, json, whatever) True, for larger projects separating concerns is important and a specific template language can have a value, but sometimes a simple script is a good solution.
A lot of the things mentioned that people love in their IDE, Coda 2 has as well. Code completion, Plugins, Version control, as well as things like database and terminal tabs, which come in handy for the full stack guys. I get PHPStorm’s usefulness, but some of us need more than just strictly PHP support when we work on apps, and for me Coda 2 is doing the job nicely.
Thumbs up for being brave to share your code here. It's the first step! However, your code will need a _lot_ of security fixes. For example [this line](https://github.com/NirvashPrime/Simple-Wiki/blob/master/models/manage_delete.php#L20) will simply delete anything the user passes in a query parameter. No access control, no path validation, nada. In addition to awesome comments by /u/wackmaniac and /u/kevintweber, I would like to point our a few more: - Use more descriptive commit messages. 3 commit messages `Update README` aren't helping that much. - Write a good README file. How to install, how to contribute, etc.
Quick nitpick: The *general* rule is to only validate your input, and only sanitize your output for the specific system that you're outputting to. Sanitizing input creates a false sense of security. For instance, if you sanitize for SQL injection, the person who picks up your project in 6 months will see `$sanitizedInput` and may not think to check for XSS vulnerabilities. Further, sanitizing for multiple potential outputs at a time may be used to inject vulnerabilities where one wouldn't normally exist; for instance sanitizing against SQL injection by removing `';` and related strings could open you up to XSS: "&lt;scr';ipt&gt;alert("foo");&lt;/script&gt;". Some of the ways to exploit overzealous sanitizing schemes are illustrated in the OWASP [XSS\_Filter\_Evasion\_Cheat\_Sheet](https://www.owasp.org/index.php/XSS_Filter_Evasion_Cheat_Sheet)... And that's just for XSS. Many similar approaches exist for many other data formats. Instead, if you follow the rule that you sanitize specifically for the system that you're sending data to, you know that everything is potentially malicious, regardless of its source, and you're certain to treat it appropriately... And, though not as important, you also get to avoid things like I saw just yesterday, "`&amp;amp;`" spelled out in the middle of closed captions.
The most obvious would be not following the style guide e.g. inconsistent spacing, bracket placement etc. Though you are free to have your own style it should at least be consistent. If you are wanting to make code open source and have others contribute, following the PSR style guides would be a good place to start. [https://phptherightway.com/#code\_style\_guide](https://phptherightway.com/#code_style_guide)
I might be late to this discussion but feel I need to comment because not one person has offered [tools](http://wapiti.sourceforge.net/), best practices, or even a competing opinion that isn't "CUSTOM FRAMEWORKS ARE THE DEVIL." I wouldn't go so far as [Rasmus about modern frameworks]( https://www.youtube.com/watch?v=DuB6UjEsY_Y), but I'm like you and would prefer using my own framework over Symfony/Laravel. The fact is modern PHP with PDO and proper user input handling is secure. If you use composer with a trusted ORM, a trusted template engine, a trusted or simplified router, follow MVC best practices etc... then you're not going to have security problems. You know how to validate user input? You know what CSRF tokens are, and how to generate/use them for ajax requests? You're offloading credit card/address info to stripe/someone else and only store basic user info such as email and bcrypt your passwords? Well then... what the hell is wrong with a custom framework? I say use whatever makes you feel more productive. The only downside is that so many people are so anti-custom these days... so I don't think it's good to mention custom frameworks on your resume. If my reddit account was more linked to my real name I might not even post this opinion here because of that. 
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
Aaaand you’ve activated my PTSD.
probably because it was http://php.net/manual/phpfi2.php#history
http://php.net/manual/phpfi2.php#history
You forgot the part about what it actually does. You just talked about how to configure it. Does it just clean up your yaml files and load them on the fly or compile them into a cached instantiator? Is the goal to eliminate the master config that includes all the child service configs?
Interesting but he is reading too much into that first sentence. [PHP's official history page clearly states the very first incarnation of PHP was a simple set of Common Gateway Interface binaries written in the C programming language](http://php.net/manual/en/history.php.php) and the first official usenet announcement from Lerdorf himself for [PHP Tools 1.0 back in June of 1995 was 100% written in C](https://groups.google.com/forum/#!msg/comp.infosystems.www.authoring.cgi/PyJ25gZ6z7A/M9FkTUVDfcwJ) and even in the announcement it was mentioned &gt; You do not need access to Perl or Tcl or any other script interpreter The most PHP can be associated with Perl was that Rasmus Lerdorf started to create tools in Perl but ran into limitations. If I tried doing something on C# but got pissed off and created a new language I would not say it has would be associated with C#.
Yeah, the initial tooling in perl that was then rewritten in C is what I was unaware of. I still don't think the actual acronym with perl in it makes any sense, or that it's associated with it in the sense you're saying. 
It is not difficult to push a fake score to this storage with a small PHP script. How does the server make sure the posted high score is real? 
You know... Now that I think about it you are right. It was possible to write whatever you wanted in whatever language you wanted (C, C++ come to mind) and compile that code and call it using CGI. I remember we marveled over some website where you could order pizza (was it pizza hut?) Anyway, you could order the pizza with whatever toppings you wanted, and a cartoon version of the pizza - with the exact toppings you just selected - would be displayed. At first we figured they just made graphics of ALL combinations of toppings, but then we did the combinatorics math and realized it would be an assload of graphics. The only way to do that made sense was to generate the graphics on the fly. That's an easy thing to do these days (shit you could do it with javascript and css if you really wanted), but back then it was UNHEARD of. The only serious way they could have done it back then was with a compiled C or C++ server side application that was given input, which output a single custom made gif of the appropriate cartoon pizza. They probably used graphics libraries to make gif files, and combined images to make one gif, which was returned to the end user.
From what I recall, it was marketed like that on purpose. The two brothers who came up with it were a small start up that came out of nowhere. They made ColdFusion to be fairly decent, then marketed the hell out of it. I want to say that in 96 it made one hell of a splash. They found success and the company was bought by Macromedia I think? Which was swallowed by Adobe at some point? But yeah... It was named like that to make a splash and sound kick ass. It worked.
Yeah, had to look it up and apparently it’s still being supported and has an active (albeit small) community and called CFML (ColdFusion Markup Language) now and has its own Adobe-developed IDE. 
What do you mean by dynamic features of JavaScript? Node.js? It's still worth learning in my opinion - and I think it will be far into the future. A lot of people who say that they don't like PHP haven't used it recently. The PHP ecosystem has improved a lot in the past years. I'd learn the basics of PHP and object oriented programming and then move onto using a framework like Laravel or Symfony. There are lots of free tutorials online
For quite a few years to come there's going to be lots of legacy code written in PHP so it's probably worth getting used to but I wouldn't bother going into the intrecacies of it. Just enough to know basically what's going on and most importantly, what to google
Thank you! What should I focus my time on if I want to learn how to actually build a full stack platform these days from scratch?
is this a weekly 'I want to learn php what do' combined with evergreen 'php is dying'? How nicely it is wrapped all in one post! and of course, there will be lots of comments here. 
PHP is worth learning, in one paragraph. It's easy to pick up and comes with a ton of server side utility, extreme wide spread availability on pretty much any shared hosting. It's very easy to get up and running with PHP, then upload your files to a live hosting environment and have it all work.
&gt;What should I focus my time on on googling stuff
It is crappy developers that become less and less relevant, but actual good devs who make a point to become guru's in a decade or so and keep on chugging and actually knowing stuff beyond a few frameworks and be able to design, build and execute (okay, this is more of a team lead / CTO level things that come somewhere in a second decade, if you make there) a project just using a bunch of libs and make it works well, be maintainable 10 years down the line and upgradeable pretty easy. These developers are always relevant and it does not really make a big difference what mainstream language they use, be it JavaScript with Node.JS, Go, PHP or C# on the .NET web. The main point is you need to get yourself to a place where it does not really matter what tech is used in your field - you can switch pretty easy in a month and be properly productive.
Well, purely on a requests per second and response time metric, hands down, NodeJs beats PHP But so does Go, Java, Rust, Elixir ... I think it all comes down to what kind of work you want to be doing. What are the use cases? Do you want to build real-time web apps? You can do it in PHP with WebSockets, but Node would probably be a better fit. Or do you want to work on existing CMS's like Drupal and Wordpress? I personally don't, so that's why I'm working more with Laravel. Even within the language, there are many use cases. Get exposed and see if you like the kind of work you will be doing. For example, with Java and C# you could make desktop and mobile apps or web apps. There are a lot of possible domains. As far as frameworks, I think its fine to start with them, but as you go you should naturally want to go deeper and understand how the code is written. I think that is the same in any language and framework. Hope that helps. &amp;#x200B;
https://phptherightway.com
https://github.com/drujensen/fib/blob/master/README.md
Also, for async, https://www.swoole.co.uk/docs/
Spoiler: Split the project in 3, Where you persist the information (database), where is the visual part (HTML and javascript), and glue together with your code. So, you must learn about the database; the minimum will do the job. And the minimum about HTML (no matter if your HTML is ugly if it works then it is fine). And finally, you could duct-tape it with PHP. &amp;#x200B;
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
If by "deep understanding", you mean learning how to write organized, properly namespaced, dependency-injected code, then sure. PHP's bad reputation is mostly based on either people who read the WordPress code running on 5.2, or the glut of blog admins who learn a few lines of the templating syntax and call themselves "PHP developers". Prioritize learning patterns and paradigms over memorizing syntax. Mostly due to its age, and also because of its unique history, PHP is a terrible language to learn by studying all the core libraries and learning all the syntax. You could learn go by going to golang.org, clicking "documentation", and reading everything from start to finish. You definitely should not go to php.net and try to read the whole thing. [phptherightway.com](https://phptherightway.com) is a good resource. I'd also recommend reading through the [PSRs](https://www.php-fig.org/psr/) to get a sense of what good interfaces look like. Even if you don't follow it religiously, [SOLID](https://en.wikipedia.org/wiki/SOLID) is good to know about. Also good to learn is [composition over inheritance](https://en.wikipedia.org/wiki/Composition_over_inheritance).
In short, NODE.JS, as server-side framework/library, is dead. The PHP community is quite neat, it's mostly clean, it's documented and it works. Business speaking, PHP is a stronghold. Instead, NODE.JS is the opposite, it is easy to create a simple "hello world" website using NODE.JS, but that's the only simplicity. Anything "higher" (such as using an image) requires a framework, libraries, and many other features. And the community is a mess, including libraries that are useless, with bugs (even well stable libraries) or with backdoors, and NODE.JS is useless without libraries. &amp;#x200B; &amp;#x200B;
Node.js is in now way dead. 
I agree. For example. Laravel uses Blade for templating and Blade is a "rip-off" (or inspirated on) of [ASP.NET](https://ASP.NET) MVC Razor syntax, so they are pretty similar. And for Controllers, they are alike too. However, what Laravel considers as Model is different of what C# considers Model. &amp;#x200B; &amp;#x200B;
Microservices is more worth for your learning and simplify each services than a framework these days if you can.
It is what C# considers Lambda (using LINQ). ``` customers=CustomerArray // aray of customers .where(c=&gt; c.active==true) // filter by customers that are active .Sort(c=&gt; c.name).ToList(); // order by customers' name then return ``` Where c=&gt;expression is Lambda and "c" is an alias to a row of customers array (i.e. c is a customer) In this case, Lambda is only syntax sugar but it works. Another example on c# ``` del myDelegate = x =&gt; x * x; int j = myDelegate(5); //j = 25 ``` However, PHP is using Lambda as **functional programming** and less than a resumed syntax. It is not as a usable as in C# because it still requires to define the function anyways in the same way that you define a classic function. PHP Lambda: ``` $myDelegate = function($x) { return x * x; } $j=$myDelegate($x) ``` PHP no Lambda: ``` function myDelegate($x) { return x * x; } $j=myDelegate($x) ``` I know that Lambda has some perks (for example, dynamic functions) but if we are only using it for the syntax, then I pass. My 2cents
PhpStorm also supports anything that WebStorm supports so has strong JS capabilities.
NodeJS has different usabilities. For a tool and visual UI, NodeJS is quite popular, especially with NPM and Atom. But NodeJS is horrible for server-side render, it doesn't work correctly, it is painfully hard to work with it and most businesses are abandoned it at all and the plus is nil. Companies are moving out of NodeJS for server-side render and not the opposite. Although, NodeJS shines for web-services. But, this market is over-crowded and even Go is taking bites of the NodeJS market. So, Node is also losing market on the web-service market. So, in comparison with the PHP market, NodeJS is a dead end. 
There is nothing to configure, just run it. &gt; Does it just clean up your yaml files and load them on the fly or compile them into a cached instantiator? The gif shows it changes yaml file. Nothing else. &gt; Is the goal to eliminate the master config that includes all the child service configs? Not really. The goal is to use PSR-4 autodiscovery, autowire and autoconfigure features of Symfony 3.3 everywhere you can without manual daunting work.
Yes. * Object oriented programming * Fast * Rich toolset * Symfony and Laravel are some of the best web frameworks [phptherightway](phptherightway.com/) and laracasts
Learn TypeScript then when you know it, look at the good parts of PHP 7.3+ and think to yourself, oh snap, it's the same thing except we're missing generators guess i'll use Hacklang... (The subtext of this post is: How much do you really know JavaScript or PHP or ... ? Keep learning.) 
While this is nice, md5 is so broken that I think either ripemd160 or sha256 would be way better for checksums, and not much harder to handle in PHP.
I absolutely agree, I did mention before the examples that md5 isn't going to be best for the use cases, I used it just because [a] it looks easily to understand but also [b] everyone of every level working on PHP has seen it at some point, so it was just the familiarity aspect for the readers
Is it too late to append a PHP hash() example to show what a "good" real world solution might look like? http://php.net/manual/en/function.hash.php I like the concise yet gentle writing style you have. Excellent organization and wording choices, not to mention the grammar.
Maybe in your paragraph mentioning the fact that md5 isn't the best choice, you could recommend both algorithms I cited?
 This is an open source extension for OpenCart, allowing merchants to start accepting cryptocurrency payments on their OpenCart website by simply installing the extension. AtomicPay is a decentralized cryptocurrency payment processor that eliminates the involvement of a third-party payment gateway, allowing merchants to accept payments directly from their customers, in a secured and trustless environment. Get it @ [https://github.com/atomicpay/opencart-plugin](https://github.com/atomicpay/opencart-plugin) 
What I've done is linked to the PHP manual, and cited you both for the edit, but I've not gone into discussions over hashing algos as it's a massive topic that goes hugely beyond the scope of the article (in that the article is supposed to give a quick-start to checksumming)
Depending on what purpose you are using checksums, if md5 isn't a sufficient solution the right solution will likely be a digital signature instead of a better hashing algorithm. 
I don't dislike Netbeans, though the only issue I found was if you switch frequently between many (dozens) of projects, it can become really clunky, because all the projects are open in the sidebar; or have they changed this in the last couple of years? I love PHPStorm but it's hard to beat free for cost effectiveness, and some of my friends and colleagues are less than keen to part with money for an IDE so I'd be really interested to see how you get around this?
http://php.net/manual/phpfi2.php#history
http://php.net/manual/phpfi2.php#history
http://php.net/manual/phpfi2.php#history
Entirely depends on why you want to learn it (you want a dev job at a company, you want to freelance, you want to build your own projects with it, are you interested in being a programmer or merely a web dev, etc). And then depending on that it also depends on where you are based, the popularity and demand for languages differs around the world. 
I didn't, personally, have an issue with Netbeans until it came to having to delve in and out of dozens of projects all the time, and then I found myself frustrated and confused with the left hand panel for projects. The key thing for me was that Storm would allow me to open separate windows per project. If I was working on one (or even just a few) projects, then I think Netbeans would be perfectly sufficient (though they can be a bit behind on PHP version releases last I checked)
Excellent, I'm glad I read someone else saying the author hates Perl without reading the history. Thanks.
&gt;No, Rasmus Lerdorf liked working in C but the new trend was to use Perl; he hated Perl http://php.net/manual/phpfi2.php#history &gt;PHP began life as a simple little cgi wrapper written in Perl. Huh?
Serialize really shouldn't be used unless you know that you need to serialize/unserialize an object and you are 100% sure it doesn't touch any user input. It is not secure.
it's kinda true that PHP is lacking behind with features for micro-services architectures. This probably will change with PHP 8 or through some 3rd party libraries that are heavily worked on right now. PHP is still the perfect choice for building a monolith (which is still the right choice for probably 95% of all projects) while node excels in building microservices it heavily lacks in terms of frameworks and proper libraries (ORMs). Building a large PHP app is so much easier since you don't have to deal with an async and a concurrent platform... an error in your node application is some serious thing that can affect your whole app... in PHP some route causing an error is not a huge deal and doesn't affect any other user or other parts of your app. In my opinion, Node is pretty bad for learning general backend and architecture principles since there aren't any proper frameworks to guide a newcomer or even general agreement on how to do thing and best practices. Tutorials are also horrible and mostly outdated.
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
Thank you! I've started more explicitly explaining what each commit is doing, and I've redone the README to consolidate some other files and be more helpful.
Great point! I've corrected the inconsistent spacing with the if / elseif statements, and I'm going to go over "PHP: The Right Way" again to see if there are any other bits I've overlooked.
340,000 merchants use OpenCart? That’s utterly terrifying
https://www.geniuskitchen.com/recipe/fried-bologna-sandwich-133272
http://reddit.com/r/PHP/comments/aa217o/was_php_ever_associated_with_perl/ecroviq
don't assume that just because i have a few downvotes that i'm wrong. this comment is absolutely 100% accurate, but people are idiots. actually, the article you linked is **dead wrong**. [PHP was actaully never written in PERL](https://twitter.com/rasmus/status/226405807305138176). It was intended to *look like* PERL, but is really very different underneath, in the same way javascript took dot notation (and a name) from the java language to encourage java programmers to use it. bunch of lemmings downvoting just because other people downvoted. learn to think for yourselves, people.
Based on stats release, they are apparently the top 5 e-commerce platforms. One position under Wix
no it wasn't. no where in that article does it say that PHP stood for Perl Hypertext Preprocessor. 
Serious question: Why does it matter when used in a checksum context? In password bash context, bad actor can try to brute force it quickly or match against known rainbow table, which makes md5 a bad choice for that purpose. However, in a checksum context, quickly checking the checksum of a file to ensure it haven’t changed is quick and painless. It also takes a lot more effort to make md5 of a modified file to match (unlike CRC32 where a few bytes is suffice). 
AFAIK, it has come to a point in which we can "easily" generate collisions for a given hash.
Hmm...? I need to read more on this. I know md5 hash is fast to generate, and rainbow tables exist for most commonly used passwords, which is why it should not be used in a password hashing context, but I didn’t know collisions are easy enough to generate for any realistic use beyond that... especially in file spoofing context. Whereas CRC32 is known to be easily spoofed 10+ yrs back so anime people used to spoof their releases’ CRC32 for shiggles. If it has come to point where md5 can be spoofed easily even as a whole file, then times have really really changed. 
Short answer: It doesn't. md5 can be regarded as a non-cryptographic hash function. Long answer: It does in a more subtle sense. Because md5 is still a cryptographic hash function, albeit one widely known to be broken, developers who aren't yet acquainted with hash functions could easily confuse it as being suitable for cryptographic functions. This is compounded by all of the old articles and snippets of code still around that use md5 inappropriately. The safest thing to do is to roundly condemn md5 as being unfit for purpose and recommend hash functions more appropriate to the specific use cases at hand, like SHA-3, Bcrypt, Argon, CRC32, and SipHash.
Notepad++ and vim, depending on where.
Aha. Ok so I’m not insane in thinking that then. Yes. In context of checking files you have control over, basic CRC32 is suffice (and faster) as a checksum algorithm for validation purposes. In cryptographic sense, md5 is outdated and inadequate. 
Yeah, aside from the confusion for new devs there's always going to be something better fit for whatever the purpose is.
Swoole disagrees with those "metrics" heavily, and so will PHP 7.4 :/
That's the central failure with md5. There are more efficient ways to calculate or induce collisions in it than brute-force.
I remember someone figured out a faster way to skip a lot of steps in md5 hash generation and was able to build ASIC to generate it at insane speed (iirc more than 10x on an already fast algorithm). I haven’t been reading up lately on collision mechanisms. I’ll be reading more about this now. Thanks for all the comments!
So you should never use != to compare hashes. It's not only timing unsafe, but let's in a class of attacks known as magical hashes due to it being a type loose comparison. If you're doing comparisons, use hash_equals(). 
Okay, I was forgetting about Swoole, but do you think 7.4 will be faster than go or Java?
What's broken about md5? Sure it's not perfect for every scenario, but what is?
&gt;So you should never use != to compare hashes. [...] a type loose comparison. Or in other words, `"0e123" == "00e99"`, because for some godforsaken reason PHP tries to auto-juggle scientific notation from strings.
More info: https://www.whitehatsec.com/blog/magic-hashes/
It's useless for checksumming because a dedicated attacker can craft a file with a hash collision. It is **entirely** useless for any security scenario.
DO NOT learn PHP. Less PHP devs -&gt; bigger salaries. ~~75% websites made using WP~~ don't mind
I wish 340,000 merchants heeded my advice [years ago](http://www.openwall.com/lists/oss-security/2016/01/19/16).
Oh! So it’s automagic! Now it makes sense!!
Not really :). Drugs were magic until people learned about neurotransmitters. Here is the responsible class: https://github.com/Symplify/Autodiscovery/blob/e72046ecb1eff74fb503b2a0244030b2e1b452f0/src/Yaml/ExplicitToAutodiscoveryConverter.php#L101-L115 
His words are fine, he just zips around his editor quickly with no visual representation of the keys he's pressing
It's had to predict what programming languages the future will bring and what to be proficient at. Personally, PHP has rewarded me well over the years, but I started in PHP 3 and that was two decades ago now. I'm now a software development manager of a team predominantly PHP devs, but we often have to use other tools when PHP can't serve delivery needs. An example of this was we needed a multi-threaded application handling TCP traffic, yes PHP could do it with sockets and forking in a horrible manner, but Java was opted for (I used to work as a senior java developer too). Then we needed to create a websocket application, again PHP fell short on support and libraries and we opted for NodeJS. My point is that PHP serves it's purpose and does it very well, but there will always be obstacles that will force you away from a technology to another. Think about your future and what you want to do e.g. if you want to be a game developer, learning PHP will have little impact on your future so go learn something like Java, C# or C++. If you want to develop networking and threaded applications, again PHP probably isn't for you. If you to make your future in web development learn PHP and learn it well.
It's been done for SHA-1: [https://shattered.io/](https://shattered.io/) IIRC there was some Windows malware that used an MD5 collision attack to forge a code signing certificate. Bottom line: when security advice is issued not to use an algorithm any more, don't use it. Real and accessible attacks are usually not far off.
If the behavior is documented, configurable, and predictable, how is it automagic? https://symfony.com/doc/current/service_container/autowiring.html What does the auto wiring feature do that is not documented here? I use it daily and haven't found any problems with it yet that would cause me to go back to manually writing out service.yaml files and manually managing all of those entries.
&gt; IIRC there was some Windows malware that used an MD5 collision attack to forge a code signing certificate. [2012 - Flame Malware](http://blogs.technet.com/b/srd/archive/2012/06/06/more-information-about-the-digital-certificates-used-to-sign-the-flame-malware.aspx)
That is actually pretty good advice where applicable.
Don’t know, haven’t had time to look into it. I just know this article written makes everything sounds like automagic and therefore is a total waste of time to even consider, since in the likely event that something doesn’t go as expected, you’ll have to read the source code and figure out how it works to even get anywhere. It’s a huge red flagged rabbit hole. Now, if the OP wanted to explain a bit more about what his lib even does/changes and why, maybe it’d be worth consideration and be a useful tool in a migration path to using Symfony’s new autoeverything updates.
Shit
LoL, why the thumbnail is an Indonesian comic?
That’s the github users avatar 
At first glance, I though the title said ## Laravel with Genitalia admin template &amp;#x200B; I was disapointed with the lack therof genitalia 
Not on Windows 10 Professional Edition with the Windows Feature `Containers` installed.
How do you see this happen? Either you’ll have to indicate this in a commit or the platform needs to extract this information automagically. Splitting a PR into multiple commits per category will already allow to follow this method by stepping through the commits.
Can confirm, also saw genitalia.
I see it as a manual step when creating a pull request, such as when you tag others for approval/review. Splitting a PR into multiple commits does not do this at all, especially in a realistic scenario where you will have much more than 2 or three commits.
Same, was very confused about what genitalia Laravel had.
autoloading?
Seems cool! What are you using it for? 
Looks like this basically comes down to following the single commit rule for PRs. As long as you're careful with your commits (i.e. each one contains only a single significant change), the rest comes naturally if you do one commit per PR. I try to do this myself ever since I worked at a company where it was enforced. It seemed a little extreme at the time, but it actually makes a lot of sense and saves a ton of trouble in PR reviews.
Looks pretty, however, shared memory is applied when you want to share data between the processes and is likely to cause race condition, and I don't see how you solve this issue. 
Some things to note: there is no explicit requirement for a PHP version or the extension your are using within composer.json. Also, I would have preferred if the Queue would be an iterator. Is there any chance you would implement The queue against an interface and implement other stacking tactics like LIFO or FILO?
I'm personally not going to use this code, because it doesn't use return types, an interface or implement tests.
Also, after looking it over a last time, I see you have real security issues with the way you use serialization. See the manual: http://php.net/manual/en/function.unserialize.php