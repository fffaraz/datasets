I completely agree. We've worked hard on our design - none of us are really designers though, although this is not an excuse. We're working on it :)
Great stuff. If it helps, I have the same problem. Back end dev, not an expert in either UX or design, even when a project requires it!
see http://php.net/manual/en/language.oop5.overloading.php#object.call and http://php.net/manual/en/language.oop5.overloading.php#object.callstatic 
Yes, on many hosted services access to private repositories could be mandatory, but this service is just a glorified cs fixer, so you could test it even on a library, or a hello world app (_if you want to test symfony and/or laravel presets_), without the hassle to setup a full project. If you don't have an open source library, fork one, add the configuration file for styleci, as seen in their readme, maybe break something on purpose, push and see the results.
Because they don't know composer yet
In each of your sentences, you managed to sound dismissive. It came off as confrontational. -- EDIT - just for the record, I didn't downvote you. 
You need to disable the psr0 fixer. That will fix everything for you.
I troll, but from everything you've said so far, including this, the distinct impression is you troll yourself at work every single day. Every bad idea I can think of, is your reality. So hands down, better troll than I can possibly be. I give up.
I've been having a similar issue, trying to send mail using PHPMailer on my own host was not working to hotmail accounts, in trying to diagnose the issue I set up gmail to be my sending server. When I sent the mail, it failed, but checking my email showed that google had noticed and blocked it, it advised me to go to (https://www.google.com/settings/security/lesssecureapps) to make gmail less secure and then it worked. 
Nice project, and a good idea, but it seems a bit off that you don't mention anywhere that this is a frontend for PHP Coding Standards Fixer. Especially as you've copied and pasted their documentation without any attribution. https://github.com/FriendsOfPHP/PHP-CS-Fixer/tree/master
I don't think I have successfully communicated my point, but never mind! Thanks for your thoughts anyway. 
Definitely RabbitMQ, message broking is a difficult thing and it is better to delegate that to a product that actually specialises on doing that.
&gt; you don't mention anywhere that this is a frontend for PHP Coding Standards Fixer It's not quite that though, and we do mention it. We even link you it in our welcome email. StyleCI does more than a basic PHP-CS-FIXER installation.
Also, php-cs-fixer doesn't require us to mention it anyway. We're not distributing it's source code.
It does say in large text that no payment is required to fix open source code.
&gt; I don't think I have successfully communicated my point, but never mind! Thanks for your thoughts anyway. I understand what you're saying. Can you contact me at support@alt-three.com, and I'll see what I can do for you.
Other than being hopelessly incomplete, your list of temporary domains appears to be out of date - there's a number of domains on that list that I know are no longer used for temporary email and haven't been for some time (and could easily be reused for non-disposable email). Using a static list like this for disposable / temporary email domains is fairly useless since a significant portion of disposable email services regularly rotate the domains that they use. Your best bet is to use an API service such as http://www.block-disposable-email.com/ - even then it will be incomplete and may lag behind changes in domains for some services. You use checkdnsrr to check DNS, but this returns the same result whether no records were found, or whether there was a (temporary) DNS error. You should improve your handling here - just because your DNS server didn't respond in a timely fashion to this request doesn't mean the email address is invalid. Your DNS check allows for A-record fallbacks. While this is technically legitimate, I've never seen it in the wild. It's, in my opinion, far safer to assume that a domain without an MX record doesn't want to receive email. Your typo domain check should have a method of returning the suggested correct domain. The domain lists should be kept in a config file, with the ability to specify an alternative configuration file so that developers can update or otherwise replace the lists as they see fit.
But it doesn't say it here http://imgur.com/A2X40UR Where I look for the available plan options. 
No, genius, you can patch in at least four other ways without risking losing your changes next time you run "composer update": - Use the existing extensibility API of the framework you use. - Use DI + extending framework classes + reflection to modify &amp; patch features in a sealed 3rd party class (monkey patching). - Implement and load the class you want to patch in your application source directory, then the autoloader won't be triggered for the vendor version, but use your version. - Fork the feature you want to patch and specify that in composer.json instead of the original You're somewhere between beginner and intermediate, which is fine. But like a teenager who knows it all, you're arguing the only way to get work done is making a mess, and anything else is impossible. You have a lot to learn yet.
I like this guy .. I have the same experience ... I finish project earlier as compared to when I was using codeigniter ... now I even got time for mountain biking,, 
I'm seeing more and more collections libs lately, and with PHP7 now in beta2 that's a good thing: the cripplingly slow overhead to using callbacks we had to deal with in PHP5 are one of the best optimized parts of PHP7. I'd even recently put out a collections library for immutables here: https://github.com/jkoudys/immutable.php . Its differentiated in specifically being an immutable collection: more efficient in-memory storage via `SplFixedArray` (since obviously an immutable collection will be fixed length, as it's fixed everything), hyper-fast concat and slice behaviour (since the referring objects are immutable, it can simply build either an iteratoriterator to merge the two immutables into another immutable, or build a custom LimitIterator to make a 'slice' by simply iterating within the bounds you give it). It's also easy to implement ArrayAccess and Countable on an immutable, since you can calculate the count upfront and can rely on your offsets always being there. My favourite lib for general collections is probably the one from [CakePHP](https://github.com/cakephp/collection). They manage iterators in a really smart way (for mutables), so you can do things like set a mapping callback that doesn't need to run until you actually traverse its element. There's definitely a de-facto standard set of methods for any Collection, so I'm wondering if it's time a PSR was proposed around this. There's at least a dozen good libs out there (one more today -- Knapsack looks quite well-implemented), and they're all using `map()`, `filter()`, `reduce()`, etc. It'd be really handy if I could type-hint on the PSR collection interface (extending Traversable), and then know whatever my function's being passed can be mapped, filtered, etc. I could then use whichever collections datastructure is best-suited to the work I'm doing. 
You don't even have any idea what you're talking about. The custom enum classes that i was talking about *is* the way you extend Doctrine. There are other ways, but they're a bit hackish, too, and don't make sense since we are ultimately planning to do the former. &gt; No, genius, you can patch in at least four other ways without risking losing your changes next time you run "composer update": Nope. I use prefer source so composer never over-writes my changes. &gt; You're somewhere between beginner and intermediate, which is fine. But like a teenager who knows it all, you're arguing the only way to get work done is making a mess, and anything else is impossible. You have a lot to learn yet. This is the best part. Yup I'm a beginner. Must be the reason my boss pays me 6 figures and credits me with saving our web codebase. Utter lack of reading comprehension + megalomania = teh win? 
&gt; Nope. I use prefer source so composer never over-writes my changes. All "prefer-source" does is clone the git repo. Unless it's pointing to *your remote repo*, it will still attempt to synchronize changes with a remote repository you don't control.
It says it in massive text just above the plan options. The plans are a list of the paid plans we have.
Haven't noticed any additional difficulties in setting up gmail over any other mail provider, but I gave up long ago trying to rely on PHPMailer. I've had sites that were using it fine for years and then just had it stop working with no discernable reason why. My guess, and I have absolutely nothing to back up this claim, is that server IPs get blocked due to spam being sent from virus infected sites, which then blocks any email originating from that server. Just use SMTP via some library (another vote for Mandril from me), and if you have control over the email addresses for the site, then set up a new email address solely for mail coming from the server because it can be handy for metrics, troubleshooting, etc. You can always forward it to another email address if the client so desires.
Look up composer prefer-source. [Voila!](http://www.reactiongifs.com/r/prnc.gif)
It does precisely what I said.
Yeah, after a ninja edit. Still, it's good to know that you can google. There's hope for you yet.
The key point is this option doesn't protect you from composer updating the dependency. So you're still a moron. You're not supposed to commit your vendor directory from the parent project, and you can't commit to a repository you don't own (Doctrine's) - so how do you version your code at all? Is that magic as well?
Lol! Yes, I'm a moron. That's why I keep using that option. Hint: try it out.
Have a look here: https://www.iana.org/time-zones and some information in [wikipedia](https://en.wikipedia.org/wiki/Tz_database).
The fact you use perforce changes precisely nothing in the way Composer works or the best practices in using it. So, again, where is your Doctrine patch committed? In your perforce repository for the project? This means you're committing /vendor contents to your project, which [shouldn't be done](https://getcomposer.org/doc/faqs/should-i-commit-the-dependencies-in-my-vendor-directory.md). It also means you can't update your Doctrine anymore unless you manually merge back your changes (or trusting Composer's attempts at that... and Composer sucks at it).
Remember the saying "the user is never wrong". If users fail to see it, it's that something could be improved.
you could also use the google timezone api if you so choose https://developers.google.com/maps/documentation/timezone/intro 
Agree with this with the exception of the note on redis: it's a superset of memcache, so I don't really see any reason to start with memcache on a new application.
Right. log n instead of n. Basically the depth of the tree. binary numbers are the easiest to visualize. So log( base 2) 1024 = 10 because 10 ^ 2 = 1024. Thus you would do 10 operations instead of 1024. 
DateTimeZone::listIdentifiers (http://php.net/manual/en/datetimezone.listidentifiers.php)
To add on to what other posters said: Read [this article](https://www.nccgroup.trust/us/about-us/newsroom-and-events/blog/2009/july/if-youre-typing-the-letters-a-e-s-into-your-code-youre-doing-it-wrong/). The summary of it is that even secure components can be assembled together in an insecure fashion. Preferably, don't put yourself at the risk of such a situation to begin with. Rather, use an existing audited solution such as [libsodium](https://download.libsodium.org/doc/bindings_for_other_languages/index.html).
I'm saying what I did and what I expect and what you have going on does not fit how I expect the site to work. There's no clear way to sign up for a free plan. When I saw it, I expected everything was paid. I had to come here to realize it was free. So, chances are you're losing conversions, users and possible subscriptions because people like me look at it and thought "Hmm, no free plan or I'm going to get somehow suckered into a pay plan." But if you don't want free user experience feedback, fine. Yell at the user for not understand your shitty UX decisions.
I have had one online for a long time: https://github.com/morrisonlevi/Ardent/blob/master/src/AvlTree.php Note that I'm not sure what I want to do with this repository in the long term, which is why it's still not 1.0. Also note that the AVL tree is not that performant in PHP, at least in 5.6. I haven't tried benchmarking it on 7.0 yet, but arrays got even faster in 7.0 so the comparative performance is probably worse than in 5.6. Basically, you probably shouldn't use the AVL tree in PHP for anything except code practice.
Memcached is better then Redis for raw data caching mainly because its a very small subset of Redis and only implements o(1) operations. OP says he needs a high traffic caching solution, and while he already implements Redis, memcached is more performant then Redis for that purpose, saving potentially useful CPU cycles. It will also save disk space when not using Redis because you don't save those cached entires to disk. If you are not using Redis for something else, just retire it and use memcached.
Hi, I have several statements that require the use of COUNT and SUM in my project. Since the library parses my input, I have to use the raw( ) function which solves the problem. You got any plans for adding native support for these functions?
How come php's traits do not have [conflict resolutions](http://php.net/manual/en/language.oop5.traits.php#language.oop5.traits.conflict.ex1) for variables?
You can't output headers after **anything** else, including spaces or newlines before the opening tag.
Would a high throughput NoSQL solution fit your needs -- such as [Cassandra](http://cassandra.apache.org/) or [Aerospike](http://www.aerospike.com/)? Aerospike has a hybrid mode where indexes are stored in memory but data on disk.
Parts Per Month
I completely agree with you. I went to pricing, looked at the chart and said "Aw, now free trial". Came to the reddit thread, and saw the top post about it.. So that's three people that didn't find the messaging clear.
As far as performance on the code level goes, I think this trial of [Solarwind's server application monitor](http://www.solarwinds.com/server-application-monitor.aspx) is worth looking into. Pinpointing inefficient code is also a feature highlighted in their application performance optimization pack.
pear doesn't need to die, what we need is a way to add pear dependencies with composer directly, same for PECL. composer should be able to build extension or download binaries for windows.
Also, it's nice to not have to move to a new system when you want to use one of redis' features later.
Keeping a static list of domains like that is a bad call imo
"Parts per month' in a price context ? Parts of what ? Maybe "price per month", which makes more sense.
Sorry, it was a joke. A play on PPM (Parts Per Million)
For what? Depends on the problem you're trying to solve.
This is really cool but I can't seem to get it to run on x86_64 Linux due to SIGSEGV errors. Gotta love address boundary errors. I'd be interested in testing it as soon as its fixed.
Having a lot of dependancies injected isn't the problem, managing them can be without the right tools. It sounds like you need a dependancy injection container. http://fabien.potencier.org/do-you-need-a-dependency-injection-container.html Basically it will have all the configurations for what your object(s) need, so you configure them in one file and summon them as you require them. How you handle it is completely up to you, you can make a master container that holds everything (ew) or make a container per package (better) or per service (better). So your code will change from $a = new AnnoyingObject(param1, param2, param3); $b = new MoreAnnoyingObject(param1, param2, param3, param4, param5, param6); $c = new Nuissance(param2, param4, param6, param8); $service = new Service($a, $b, $c); into $c = new Container(); $s = new Service($c-&gt;getAnnoyingObject(), $c-&gt;getMoreAnnoyingObject(),$c-&gt;getNuissance());
I don't see anything at all wrong with this code. It looks as concise as it could possibly be and very easy to maintain with good separation of concerns. Pat yourself on the back and have a refreshing beverage.
I agree. The command handler isn't unmanageable by any means. Having a handful of dependencies isn't necessarily a code smell. If OP is concerned about the overhead of retrieving an entire entity just to make an association, check out [Doctrine's reference proxies](http://docs.doctrine-project.org/projects/doctrine-orm/en/latest/reference/advanced-configuration.html#reference-proxies). &gt; The method EntityManager#getReference($entityName, $identifier) lets you obtain a reference to an entity for which the identifier is known, without loading that entity from the database. This is useful, for example, as a performance enhancement, when you want to establish an association to an entity for which you have the identifier. Implementing that in an abstracted way might still require outside dependencies, but will be more performant. Also, if you're interested in slimming down the handler, this logic could likely be entirely encapsulated in the Invoice model: // ... stripped the calculation of totals for the sake of clarity $invoice-&gt;setSubtotal($subtotal); $invoice-&gt;setTotal($total);
Ok, I agree people should always focus on features and catching customers before all other concerns. If you read my comments from the beginning, the objective of this post was just to point out that Lumen was not faster than the rest as Mr Otwall claims. Then there have been a lot of discussion that were not only related to this, to which you answer. If you look at what people said when I stated this, they dispute **the results** (supposed unreliable because the methodology was unpublished) then they dispute **the need**. That's what you are doing. And it always end up like you said: we don't need performance because there is cache. I even saw people claiming that Symfony was able to deliver huge request per day (there have been a press release for that): if you look closer, you finally discover that it is the cache that was benchmarked. I just want to say that not every application is cacheable. Now, just to answer to the rest of your reply: You see, I am not even sure that you are delivering faster with a bloated framework. Let me give example with the ORM: I really challenge the fact that you are supposed to create requests quicker with Eloquent - than with SQL. IF you are honest, you will admit that outside the basic CRUD, it becomes quite quickly a nightmare. I think people should learn SQL. It is near perfect. I saw the same path taken in the Java world, until they ended up with a "SQL like" for Objects (JPQL): A total waste of time. Next, the templating engine: twig or others. Is it quicker? is it more productive? I really question it. In the end, I just want to answer that performance is not the **one and only criteria** I would use to choose a framework. But for me it is an important one. 
Are these bindings safe (stable enough) for production use? I see libsodium itself is on 1.0.3, but is there any reason we might want to avoid libsodium-php until it reaches 1.0?
Regarding your setter problem. Put a static method like "createFromForm" or something on your Invoice and pass all that junk into it. That method creates the new invoice and returns it after setting the data. It makes that setter stuff easier to read from the consumers perspective and DRYs all that up if you need to do it elsewhere like a test or something.
Yes. This release introduces a major, but overdue change (everything was moved to the \Sodium\ namespace), but from now on I only expect small, incremental, backward-compatible changes to stay in line with libsodium.
Much better memory utilization - relying on either iterators, or SplFixedArrays, instead of a variable-length hashtable will definitely save plenty of memory no matter how optimized PHP is around its `array` datastructure. A 200k dataset of 32-length strings takes ~66MB as an array, but only 30MB as my ImmArray (the credit, of course, goes to the underlying SplFixedArray). On PHP7, the saving's nowhere near as much, but still significant -- 22MB vs 17MB. It doesn't matter nearly as much for smaller datasets, of course. Looking at your benchmarks, you were showing a 1100% difference in the execution time for mapping 1000 integers (doing an addition on each). I implemented something comparable: $arr = range(0, 1000); $bigSet = ImmArray::fromArray($arr); // Time the filter function $t = microtime(true); $mapped = $bigSet-&gt;map(function($el) { return $el + 10; }); echo 'ImmArray::map() ' . (microtime(true) - $t) . 's', PHP_EOL; $t = microtime(true); $mappedArr = array_map(function($el) { return $el + 10; }, $arr); echo 'array_map ' . (microtime(true) - $t) . 's', PHP_EOL; On 5.6, they tend to run around the same time -- both are taking a callback, so that's the main overhead. About 4/5 times the array_map is slightly faster, but never by much: ImmArray::map() 0.0031940937042236s array_map 0.0031459331512451s Where I see a big jump is when running this on PHP7: // run 1 ImmArray::map() 0.00010204315185547s array_map 0.0001218318939209s // run 2 ImmArray::map() 9.4890594482422E-5s array_map 8.4877014160156E-5s Again, they're both about the same, but surprisingly the map's running about 30x faster. Indeed, for only 1000 elements, half of what that's measuring could just be the time to call microtime(). I can boost it up to a 400000 count and execute in the same time PHP5.6 took with 1000: ImmArray::map() 0.031890869140625s array_map 0.032819986343384s I haven't profiled it, but I have a hunch my immutables are fast because I rely strongly on the SPL datastructures and iterators, which are all implemented in highly-optimized C. Index lookups in SplFixedArrays are quite fast, but they're offset by the abstraction cost so an ImmArray::map() comes out roughly equivalent to an `array_map()` (except that the resultant is way smaller). If we look at HHVM, which doesn't implement an SplFixedArray in C, but simply has a workalike PHP class using an array underneath, ImmArray runs faster than PHP5.6, but still _much_ slower than PHP7. This isn't surprising, and isn't a fault in HHVM: if you're on HHVM, you can use hack, and hack has its own excellent set of builtin collections and doesn't need to rely on SPL datastructures. ImmArray::map() 0.0018701553344727s array_map 0.0011270046234131s edit: I suppose a really interesting thing to learn from this, is that FP is a paradigm probably better suited for PHP7 than HHVM. HHVM definitely has places where it puts PHP7's perf to shame, and hack is a fine language, but if you're going to build a big functional-programming application (and possibly a big event loop), you may want to choose php7 over hhvm.
I have two suggestions that might help clean up your handler. 1. Rather than do the calculating for the subtotal and total in the handler, could you do it on demand within the Invoice class's getTotal () and getSubTotal () methods based on its line items, tax, currency, etc? 2. Rather than raise the event on the handler, raise it in the entity's constructor and use a doctrine event listener to gather and dispatch those after the entity is persisted. Recording the event in the constructor ensures that event always gets raised if you start creating Invoice objects elsewhere. Regarding the Invoice setters, the constructor should contain the minimum number of arguments to make a valid entity. Right now, the entity looks like its valid to new up an Invoice, use zero setters, then persist. Obviously thats not right. 
Changing \Sodium::method() to \Sodium\function() has the unfortunate side-effect that there can be no longer a PHP-only polyfill that autoloads on first use.
I freakin LOVE the command pattern! Good going! 
Usleep takes microseconds (which are even shorter than milliseconds) so I think you should multiply by one million 
Doesn't work on mobile ðŸ˜¢
I've switched one of my applications over to use a command bus pattern recently, it's pretty great. Before there were a lot of service objects with well defined roles that did roughly the same thing as command handlers. Some of those service objects went away, but a lot of them didn't -- they just get used in command handler. The point of all that rambling is say that if you're concerned about all of the dependencies [extract a class](http://www.refactoring.com/catalog/extractClass.html) to do some common stuff. You should look to extract things that have could have a well defined [role](http://martinfowler.com/bliki/RoleInterface.html). I would wait to do that, until there's a strong reason to, however -- some need to change where the refactoring would make the change easier. You're code looks fine to me, until there's some pressure to change and add new stuff you won't really know until it's as good as it looks. So relax, grab a cool beverage of your choice, and wait to see what happens.
I like the idea. Out of curiosity, do you handle validation in that very method and throw exceptions or do you handle that before and this method assumes valid inputs ? Also, what about associations ? Since all the database logic is hidden behind repositories, I guess my createFromForm method would depend on a few repo to fetch the appropriate entities (customer, author, etc). On a different note, thank you Taylor for the greatness of Laravel. We use Laravel and most recently Lumen everyday in various parts of our in-house ERP.
Thank you for your in depth answer. I appreciate that. I'm aware of DDD and I'm trying to slowly lean towards that approach. I must admit though, I find it quite difficult to deviate from my old CRUD mentality. For instance, I can't figure out for the life of me what parameters (among the 20ish) should belong in the constructor of an invoice and which ones should be assigned via setter or god knows how. I obviously can't have a constructor with 20 parameters, and I my knowledge of DDD isn't deep enough yet to understand where to place what. I'm still new to DDD.
Oh, okay. I was just going to mention that you probably shouldn't be using an ORM but never mind.
Yeah, it didn't sound like it would be a problem from what you said.
Maybe it's called php7_module now? 
Hi Joe, I stopped by the stackoverflow chatroom this evening, but I didn't see you so I figured I'd reply here as well. I'm using a similar approach in my real app, but the following stripped down example also runs out of memory: &lt;?php class Job extends Collectable { public function run() { $this-&gt;setGarbage(); } } $job_count = 1000000; $collect_frequency = 100; $pool = new Pool(10); for($i = 0; $i &lt; $job_count; $i++) { $pool-&gt;submit(new Job()); if($i % $collect_frequency === 0) $pool-&gt;collect(function($job) { return $job-&gt;isGarbage(); }); } $pool-&gt;shutdown(); Am I missing something on this? Again, thanks for your time and detailed replies. If I get this straightened out I think I'll be all set.
Thanks everybody for the responses. The only problem is that I don't have the possibility to spin up servers inside the datacenter. I'm constrained with the hardware that we have right now. I could however spin up instances outside the DC (eg Amazon) but then I don't know how much will I gain since there will be network roundtrip. In that scenario I could use redis or memcached as is with low ttl (to keep memory footprint low) and store objects on S3 for longer persistence (S3 can also have a ttl lifetime on the single objects). This way I could keep the overall api calls low in the long run while having fast performance for most requested items and acceptable performance for the other requests. What do you think of it?
Or, for a 5 year old, because statistics. 
My VO constructors have explicit args so, therefore I do not perform any raw validation prior. I perform additional validation within the VO.
Interesting. And nice performance man. I was looking into speeding Knapsack up and found that even the most simple and optimized version of lets say map (as in lazy map, maps only when iterated over, implemented as iterator) is about 500% slower than native array_map. And that's without all the mumbo jumbo Knapsack does - counting arguments, converting to Collection and applying argument templates. So my conclusion is that some small tweaking is in order but i can't expect any performance jumps. Oh well. Just a small question about the implementation of your ImmArray class. Is there a reason it's constructor is public? Wouldn't a private constructor which would do the work of setIterator function be better? 
No, it's not
I am not sure whether it's common in dark corners of internet, but that "pattern" is definitely stupid. It's a standard case of abusing global mutable state. You should be using a [Builder pattern](https://en.wikipedia.org/wiki/Builder_pattern) instead.
its certainly faster than caching in IO 
relyon, are you referring to http://ouzo.readthedocs.org/en/latest/documentation/routes.html ? I'd really appreciate constructive feedback, so that we can make it better. 
Creating accounts is not part of the FTP protocol, it's specific to a given server, so the command line is indeed the most likely candidate. The problem you're running into most likely is one of permissions. Log into your machine as the same user that PHP runs under and try typing the same identical commands you try to run via exec and see what happens.
The API calls that I make are all server side, so no client is involved in the process. Btw if I got you correctly do you mean to have a CDN in front of my third party service so that my application talk to CDN endpoints rather than the app itself? I didn't think about that but it makes sense. Since the service is GET only it could be easy to setup and test.
They need to do this, i've never heard of a static override to instanciate objects. This could fuck so many things, if anywhere in the code a change is made it could impact every later instanciation, it's crazy.
If you simply want to cache responses to HTTP GET requests, you'll most likely get far higher throughput with Varnish than you will with anything else, since it entirely bypasses your web application if it's able to serve up a response.
It's something like that : class MyClass { private static $something = false; public function __construct() { if (false === self::$something) { // do things } else { // do other things } } public static function createWithSomething() { self::$something = true; $self = new static(); self::$something = false; return $self; } } From my perspective, it's like you said a great example of what not to do...
Given my experiences with doing this kind of stuff, which appears to match your own - I don't really know what would be documented differently now. The only thing I think worth looking at is if there is a library to help you bootstrap a lot of it already, so I'd suggest checking packagist.
Thanks. That worked.
No. It's my dev machine.
This is getting very Doctor Suess-y! In my background most passed variables that change behavior used enums. PHP doesn't have a nice way to force the same behavior natively, but anything that self documents the code and avoids magic constants seems to be helpful. Nice example!
For this particular API, you'd have to use eval(). There's 98% chance, though, you can skip that and just use the closure directly. What's the use case, why make global functions at runtime?
Took a look, well, one thing that is not to my liking is using a register_tick_function and not using pcntl_signal_dispatch. But, overall, not a bad example to consult with :) Probably going to borrow some ideas.
Sure thing :) I seem to remember there being an issue with signal_dispatch but I may have been using it incorrectly at the time (as you can imagine, writing useful tests for that kind of code is very tricky). If you'd like, feel free to fork and send PRs if you have improvements!
Yeah, when I read your post all I kept thinking about was the number of blog posts out there regurgitating pcntl and forking, and not any of that has changed. The biggest thing I'd like to see is some way to unload classes/methods from running code, so I don't need a controller to kill/reload children to get things cleaned up - but that's very much a specific use case. Good luck!
ahh. we just use vagrant boxes. this way dev environment can be a linux inside of the virtualboxed vagrant box.
Have you thought about using something like Varnish? https://www.varnish-software.com/blog/introducing-varnish-api-engine
I figured it was something to solve with Linux instead of php. Thanks for confirming my suspicions. 
I just encountered the same need as you not very long ago and wrote [nexxes/daemonhelper](https://github.com/nexxes/php-daemonhelper). There is a simple daemonize mechanism (that currently more a draft) but the Watchdog component is tested, restarts the watched processes on error, etc.
Phabricator has some solid code with regard to PHP daemons IMO. Infrastructure for daemons: https://secure.phabricator.com/diffusion/PHU/browse/master/src/daemon/ Daemons that actually do work: https://secure.phabricator.com/diffusion/P/browse/master/src/infrastructure/daemon/
I think you can make use of Closure::bind http://php.net/manual/en/closure.bind.php
Oh, I didn't mean fetch that data inside that method, basically just use that method to wrap up all those -&gt;set* calls - pass all the retrieve data into the method. Some people do validation inside of that method, yes, so that the object will not let itself be created in an invalid state. That can be beneficial sometimes since if you have an instance of X you *always* know it is valid.
I mean, it's kinda of shitty if you can't go to your boss or some other higher up in the company and show them the problems your having and that [$3500 in hardware would fix it](http://cl.ly/image/152z2P253G25/Image%202015-07-28%20at%2010.37.21%20AM.png) ([even if your buying the hardware](http://www.serversdirect.com/Servers/id-SDR-1028R-TDW/Supermicro_SDR-1028R-TDW)). Thats 128gb of DDR4 2133 ECC Memory, its very cheap, and training new developers is not. I would hope it would be a simple "this is our problem: this is how to fix it" situation but you will obviously know better then us. The sell should be pretty simple: It's a one time hardware cost + one more unit of rack space, and ~450ma power needed to plug in a new server. Alternatively you could also use the clustering features of memcached or redis and take some spare memory from all your other servers and turn it into one large memory cache. It would still be a better setup though to pickup new hardware or VPS/Instance, unless your not growing users anymore. Doing the memcache externally (via amazon or otherwise) is not going to be faster then even local SSD caching. It may be faster then 5400 RPM drives but you will need to know what kind of hardware and uplinks your servers have and how many cache calls you make per request to see what kind of hell you are going to put yourself in by doing that.
Memcached over a WAN will nearly always be slower then even caching locally to spinning disks. Each request will add the base connection latency for every cache call to every request. Imagine ~200 cache calls with a 12ms latency each. It's easily much worse then caching locally, even if that creates other problems.
An alternative us retrieve said properties via a getter method that uses `property_exists()` or `empty()` to return a sane default, like so: function getLoginPath() { return (property_exists($this, 'loginPath') ) ? $this-&gt;loginPath : $this-&gt;defaultLoginPath; } It's not perfect but I find it better than the alternatives.
First - check out runkit - http://pecl.php.net/package/runkit - it may surprize you, if you are able to install an extension. There is a second option, it goes something like this: What if I said there is actually a way to achive the desiered functionality, just in a very unusual and kind'a insane way? First thing you need to remember for yourself - PHP is a dynamic language. Second - you can call a function via a variable syntax function test1() {} $function = 'test1'; $function(); Based on that, you can define the same function like function test1_v1() {} function test1_v2() {} etc... You probably see where i'm going with this, right? :) So the basic idea here is to have your own function/class/method lookup table as key =&gt; value, where key is the name of your function/class/method you would like to use (and using in your actuall PHP code now) and the value is the name of the function/class/method with a version name you are using right now. So your function calls will go like this: $result = LookupTable::$function['test1'](); $class = LookupTable::$class['my_class](); It's not pretty, sure, that's the drawback. But you get your ability to patch stuff easilly, just make an action in your daemon that scans a directory where you put your patches, load them in, update the lookup table and vuala - suddenly you run new versions of your class/function/method. Second drawback is that you namespace will fill up with different function names and that will is going to eat up memory with time (small amounts, but still). Can be fixed with a sheduled restart of the daemon as needed. Hope this helps :) P.S. I saw such a system in work, it was actually working pretty well.
i havent made that experienced but i always use memcache multiget that fights quite some of the overhead you mention 
Multiget is great when you know a good chunk of keys you will need to pull down at once. Unfortunately, most sites dont really know all the cache keys they will need to retrieve at one point. Things can be split up into views, or in multiple business logic libraries, etc. Being able to use the [binary protocol](http://php.net/manual/en/memcache.ini.php#ini.memcache.protocol) is a huge boon too. But they normally wont save you on high traffic sites if you use a WAN based cache server.
Good catch - that make more sense. The initial implementation was following the approach set in hack's arrays, so an equivalent expression in hack to `$foo = ImmArray::fromArray([1,2,3]);` is `$foo = new ImmVector([1,2,3]);`. The main reason it doesn't is because I wanted to avoid mixed-types on the constructor's argument. One of the smartest things hack did was make `array` an instanceof `Traversable`. There are so many well-meaning devs who type-hint on either `array` or `traversable`, which pretty much always excludes good code somewhere from using the method without having to do some pointless `$traversey-&gt;toArray()` or `new ArrayIterator($arr)` around it, hence the separate `fromArray()` and `fromItems()`. Still, it might not be too bad to keep the constructor and do a basic check for null/array/traversable.
My suggestion when making a daemon that needs multiple processes is to use zts-php and the phtreads extension (http://pthreads.org/). webtatic repo has a good zts-build .rpm for centos.
Just as a side note, prefixing non-standard headers with "X-" is no longer required and preferred otherwise. https://tools.ietf.org/html/rfc6648
FYI, I just updated the post with my final blog post. Thanks for everyone!
&gt; Why don't I see more about it? Because this: &gt; Yii is fucking fantastic and offers things other frameworks don't. is just not true.
The only advantage PEAR has over Composer is that you can install it from your operating system and get a GPG signed archive, instead of having to `curl | php`. In virtually every other metric, Composer wins. Even that advantage can easily be melted by campaigning the major Linux OSes to manage Composer globally. (Windows and Mac? Eh, you're on your own. Even Homebrew is installed by passing unexamined and untrusted code from the network to `ruby`.)
&gt; In theory, you could catch PDOException and look for SQLSTATE 40001 I am just thinking about replaying the transaction for every PDOException. What do you think about that?
&gt; Yii [...] offers things other frameworks don't *Quod gratis asseritur, gratis negatur.* &gt; You can't just go saying things like this with nothing to back it up. You did this, I just denied what you said. It's just not true, Yii offers absolutely nothing Symfony/Zend don't. Not. A. Single. Feature. I can't prove this negative, it's on you to show me something I can do on Yii that I can't elsewhere.
That does make good sense. I've used a `new static()` instead, since it's important this can be extended. One of the big things that annoys me with SplFixedArrays, is they're clearly intended to be extended, yet a MyClassThatExtendsSFA::fromArray() will always return an SplFixedArray. It's especially odd, since while hack enforces composition (many collection types are declared as final), SPL promotes inheritance (many datastructures are declared as abstract).
Given that the people new to the language are going to get a lot of exposure to composer through e.g frameworks I think it's always going to win out. PEAR is pretty horrible to use anyway, something I've wrestled with on many an ocassion, where as composer tends to 'just work'
Well, when you say "with composer" you need to include also Github (or similar) and Packagist, because Composer does relatively little on its own. If you do, then no. But package aggregators are less about features and more about community. I'm sure there are packages on PEAR you can't find on Packagist (even... if they may be some old packages).
Features look to be finished, composer support is being worked on. Last update was april i think
The correct way is to hash the password using a strong one-way hashing algorithm. These algorithms are slow by default, and cannot be "unencrypted". A salt is not completely necessary anymore, as these algorithms will generate their own if one is not explicitly set. PHP 5.5's [`password_hash()`](http://php.net/manual/en/function.password-hash.php) and [`password_verify()`](http://php.net/manual/en/function.password-verify.php) are recommended for hashing and comparing passwords, respectively. If you're on PHP &gt;= 5.3.7 and less than 5.5, you can use /u/ircmaxell's [password_compat library](https://github.com/ircmaxell/password_compat). If you're looking for more about the internals of why one-way hashing and things like Blowfish and bcrypt are important, I'm not as much help there (at least in having handy dandy links to share). Hopefully others can elaborate.
Composer is the tool for dependency management if libraries. Packagist is the default repository of libraries it has access to. Don't confuse composer with a library like pear.
Umm, you're calling Composer a library? 
Give me a single use case for the e modifier in preg_replace? There is a reason it's slowly going away. Also, you can't disable it as OP wanted, cept suhosin.
I think this would be off-topic for this sub; /r/PHP is for discussing the language, not for job offers. Consider startups, sideproject or forhire for this. 
Usually, disabling certain functions is done by shared hosting providers to prevent clients from doing something the provider doesn't want you to do (mail(), exec(), etc for example). IMO, disabling specific functions to try and improve your own server's security is nothing more than security through obscurity.
I couldn't think of the correct word. Do you really want to get on my case over semantics?
A project I work on uses two or three Pear extensions. Could we find alternatives? Sure. But there are more important priorities, and these Pear extensions work well. 
No problem. I mainly picked up this trick from @everzet on Twitter.
PDOStatement is already iterable...why did the author need to wrap it in another iterator? And even if he wanted to, why not [extend](http://stackoverflow.com/a/3431353/65387) PDOStatement class?
I can't bring myself to accept this as a "speeding up database calls" article when the example tries to read 250k rows (not typical for 99% of PHP scripts) and filters the results on the PHP side (vs. using SQL for this, with an index). Also a more efficient way to expose the results as a filtered iterator is to foreach() the PDO resultset directly in a generator and simply not yield those you want to filter out. It'll be two classes less, two less indirection levels.
Thanks! I found that site earlier today, but it seemed like I needed some PHP knowledge under my belt first - is that not true?
Look at the get started with Laravel 5 series, you can pick up the php as you go along 
Will do, thank you for the help!
This is probably the culprit to the high memory usage/high processing times: foreach ($data as $row) { // each row gets its own DateTime Object. $dt = new \DateTime('2015-04-01 00:00:00'); if ($dt-&gt;format('Y-m-d') . '00:00:00' &lt; $row-&gt;contact_modified) { I would love to see the results if the code was more like this: $dt = new \DateTime('2015-04-01 00:00:00'); $ts = $dt-&gt;format('Y-m-d') . '00:00:00'; foreach ($data as $row) { if ($ts &lt; $row-&gt;contact_modified) { 
Paamayim Nekudotayim
Some highlights: &gt; The primary problem with the "X-" convention is that unstandardized parameters have a tendency to leak into the protected space of standardized parameters, thus introducing the need for migration from the "X-" name to a standardized name. Migration, in turn, introduces interoperability issues (and sometimes security issues) because older implementations will support only the "X-" name and newer implementations might support only the standardized name. To preserve interoperability, newer implementations simply support the "X-" name forever, which means that the unstandardized name has become a de facto standard (thus obviating the need for segregation of the name space into standardized and unstandardized areas in the first place). &gt; -------- &gt; Creators of new parameters to be used in the context of application protocols: &gt; 1. SHOULD assume that all parameters they create might become standardized, public, commonly deployed, or usable across multiple implementations. &gt; 2. SHOULD employ meaningful parameter names that they have reason to believe are currently unused. &gt; 3. SHOULD NOT prefix their parameter names with "X-" or similar constructs. 
It's nice to hear the rationale behind this. At first blush this seems stupid and annoying because it makes consuming the Request/Response objects difficult. Actually, it still does -- I guess we'll have to downcast these interfaces every time we want to use them to something a little more convenient. Actually, I guess within a framwork you'd have a concrete type to work with, but for interopping with an external framework you may need to do some casting.
She's the third ferret, so name her PSR-3.
I would recommend go slow, if you have zero programming experience start a beginner course in php from any online site, which essentially teaches basics like variable, arrays, loops, conditions, functions etc. This will help you to write a basic php program. Now that you are comfortable with that you will have to start with object oriented programming in PHP. It might take little bit time to get used with the object oriented pattern or OOP but you have to stick and learn it and understand. Start writing simple programs/web applications by utilising OOP in it, start using PDO as the means to access the database. Create a web application with user registration and login. Next thing I would suggest is to learn about autoloading and composer. Once you learn composer you will know how to use different packages in your project to speed up things. May be start with a more simple framework, and learn why we need to use framework and how it helps us. Then start with laravel.
I think the author wanted to write about Iterators, and then made an article around it, which is somewhat contrived - but does show how Iterators might be used. 
Thank you very much, you've given me a good progressive road map to follow. Do you have any experience with Treehouse? It looks like they might be exactly the type of basic training you're talking about.
Definitely. Saw today in our profile that date functions always take at least 9ms on our dev vm. Still not sure what the holdup is.
I just took a look at https://teamtreehouse.com/tracks/php-development course and it seems to be good enough for you to start. Also look for reviews of this course. One thing I have missed in git, they have included that in this course. Good luck.
Symfony.
IRL you'd quickly discover http://php.net/manual/en/mysqlinfo.concepts.buffering.php and do a unbuffered query - which should fix the memory aspect. Having StdClass result objects being returned makes minimal difference - given PHP's array is relatively bloated. (A random test here shows it makes minimal difference when dealing with 500,000 records (objects use about 1% more memory) (php 5.6.10)). The best fix is to use an unbuffered resultset - that keeps memory usage at minimal levels (eg 5mb vs 3gb) and makes it slightly quicker (5.3s vs 7.5s). Of course, doing the date comparison in PHP is the real WTF..... 
$work has a legacy php 5.2/5.3 codebase. We occasionally grab libraries from pear.php.net (eg Net_DNS, Http_Request2 etc) .... but we don't use 'PEAR' itself. 
What about... ASP? ... http://badumtis.ch/
urm ... cURL Multi has absolutely nothing whatever to do with parallelism. cURL Multi uses non-blocking I/O to make multiple requests asynchronously; It is asynchronous concurrency, not parallel concurrency.
Totally agree, that's why I consider myself able to review their code, even if I don't know PHP.
Do you know why the include and require functions made the list? I didn't find an explanation on why those are dangerous ... how else should I include files? ;_;
The author fetches all data with `fetchAll()` in the example without iterator, instead of calling a `while` loop on the `fetch` method. All rows are stored in the memory during the process.
On right of this page: &gt; /r/PHP is not a support subreddit. Please visit /r/phphelp for help, or connect to ##php on Freenode IRC But I'll just add, it's funny people keep coming in here having issues with Yii's GridView. 
I do not want to be using a three-year old version of composer just because a distro decided to include it in its repos, and then never update it under the guise of "stability".
Composer *is* a library that can be included via composer and its code used in your project.
You can mitigate XSS attacks by disabling echo and print ;)
Setup a [rsync filesystem](http://docs.vagrantup.com/v2/synced-folders/rsync.html). This'll mean that the files are not shared via the filesystem adapters, they're rsynced across to the guest OS and are available natively. This has a huge speed boost, but you'll need to remember rsync-auto takes a few seconds to trigger and copy the files across.
You could create a small php script and calling it via shell from your C++ application. See "Running PHP scripts as shell scripts" : http://www.electrictoolbox.com/running-php-scripts-as-shell-scripts/
They can be dangerous if you input variables and don't validate the value.
Lumen
So if I use it only to include static php files on my own server it's perfectly safe?
That should take milliseconds, even on a Vagrant setup. Are you using CGI SAPI by any chance (instead of mod_php or FastCGI)?
&gt; given PHP's array is relatively bloated. PHP7 should remove a lot of the memory bloat from arrays. Wondering how much of a difference this would make to the tests in the OP's post.
The whole idea here is to do a full fledged background application, that can scale, do stuff in multiple processes (have child processes dedicated to specific stuff) and things like that. Sure, for less sophisticated stuff your suggestion is great. In my case, however, it's not enough. Anyway, great suggestion for anyone who's going to come here to look for an advice.
Hi, just wanted to mention that as a starting developper I pretty much watched all of treehouse's videos at the begining and I can say that the only courses that were beneficial to me were the html, css and js ones. I find that their explanations for php are not that good. That's one of the reasons I've stopped using this resource. If you want good tutorials for php go with Jeffrey Way (net tuts + and laracasts). He's really, for me and many others, the best teacher out there.
Hashing of a password protects in using cryptography. It's a non-reversible operation, and one can never obtain the original password from a hash (assuming it's done correctly). [Security through obscurity](https://en.wikipedia.org/wiki/Security_through_obscurity) means one doesn't protect the information in a non-reversible way, one just makes it harder for an attacker to obtain the information (for example, one pseudo-hashes a password by replacing some specific characters, in a reversible-fashion). It will assume the attacker will not have the time or the will to obtain the data by reading through the obfuscation mechanism and reversing the operation. A system can only be considered really secure if it's secure even if everything about the environment is known, but the private keys (and this includes the source code for your obfuscation mechanism). Disabling functions if by no means security through obscurity, it's just an innocuous measure. I think /u/bga9 was trying to say it will only force the attacker to look for another way to mess with your things. And it's probably true, disabling a specific function will only go so far. It won't even slow down a motivated attacker. If you assume your attacker can execute PHP code in your server, you should assume your attacker can do much more can executing simple php instructions.
Thanks, that's great feedback. I will start with Tuts+ for PHP and move to Laracasts once I'm ready.
Thanks! You and another poster recommended Tuts+ over treehouse, so I will start with them.
Well it's kinda slow, but it's 1/3 second in total. Is that really slow enough to notice &amp; bother you for *dev* purposes? I don't use Laravel much (and only select SF2 components), so I have no booting stage at all, so it looks weird to me to spend most time in "booting", but I also know it's typical for Laravel/SF2 apps, because their IoC container is quite heavy. Open your browser dev tools and see what the *browser* says for the request-response time. If it's significantly more then you know the PHP code itself is not the culprit, but the server settings, PHP extensions, SAPI and so on.
&gt; As of PHP 5.4.0, PHP implements a method of code reuse called Traits. What do you think? But for real though, you can use Composition to achieve similar results â€“ without the copy/paste code "advantage".
Works for me
https://packagist.org is down either
It's up for me. 
&gt; I guess my sysadmin will now learn the lesson of keeping a version of composer.phar somewhere in our deployment server Hope he was a fast learner cause it's up again.
composer self-update #problemsolved
It's because __set() can not return a value. See [this section](http://php.net/manual/en/language.oop5.overloading.php#object.set) of the PHP docs for more info.
I have never had much trouble with just using the standard " I should see..." steps when viewing a PDF in the browser.
Well done. There's a lot going on in that gist, doesn't get lost to over-engineering, and is as close as it gets to the shortest path between two points.
My understanding is that you can throw any kind of date formatting at a `new DateTime('')` and it'll will figure out the y/m/d, unless you specify the format yourself. If you don't specify the format, wouldn't they have to compare the date given to a bunch of different formats to see what best fits? Wouldn't that take time?
&gt; Some of these optimizations might induce crashing, which you would like to know about before production, I think ;) This bit me towards the end of a project. I'll just add that default opcache settings would cause a segfault, but only as load increased.
I'm sorry to disagree. There are so many tools out there, so many tuts and books. We could learn so much in a study group. The whole is definitely more than the sum of its parts.
For the record, pornographic material is legal, and none of the analysis' are publicly viewable. To outright disallow code that pertains to it, is pretty juvenile. Was a cool product, account deleted by you, won't use again.
Not wise, but I always install Composer globally. You can always do sudo composer self-update But yeah, it would be better to let the package manager do it.
I was trying to keep the article as general as possible and applicable to new projects, nasty old systems in need of major refactoring and even other languages. I do think this is a good call though considering the examples are all in PHP. I'll edit and add links to PSR-1 &amp; PSR-2.
Don't forget that there are a number of projects out there that will score, monitor, report on and fix code style issues.
Why don't you start with https://laracasts.com ? It'll teach you the basics of all the stuff you mentioned. Jeffrey Way is an excellent explainer/teacher and there is are a lot of freebie content. I'd recomment pay the $90 all-access for a year (or $9 for a month) though. Worth every penny. Disclaimer: not affiliated in any way to laracasts. Just a happy customer.
Who said anything about not having knowledge to be able to participate? And a blind person can help another blind person. This quote is retarded
Luna looks cool. I've looked at flarum a couple times, but every time i do, theres like 3 or 4 things about it/the team that put me off.
Considering ferrets can smell pretty bad, you should name it Ruby. :D
Thank you for calling it UBB Code. However, your code contains a significant XSS security vulnerability. You aren't performing any sort of additional validation of the format of the URL, allowing crafty users to inject javascript. For example, think of what would happen to the HTML output when passed this: [img]" onmouseover="alert(document.cookie)" foo=".gifv[/img] Additionally, "gifv" is a virtual extension used only by Imgur, backed by MPEG 4 video. This is as opposed to, say, gfycat, which uses webm instead of MPEG 4. You probably want to seriously reconsider using this snippet. You need to validate that the user input is a URL, and then further validate that it'll provide a `&lt;video&gt;`-friendly output. You might be better off determining if the URL is from a service that's known to serve MPEG 4 or webm video, and then special-case those.
I'd recommend buying (i.e. getting your employer to buy) and reading [Building APIs You Won't Hate](https://leanpub.com/build-apis-you-wont-hate) for starters. It covers most of the concerns you'll need to worry about building an API and it's fairly unopinionated about implementation details (e.g. which framework or even language you use). As far as frameworks go, I'd say look at [Silex](http://silex.sensiolabs.org/), [Slim](http://www.slimframework.com/), and [Lumen](http://lumen.laravel.com/). They're all microframeworks, so they'll be easy to grok and you can pick whichever one seems to fit your preference/style the best. Silex and Lumen are micro versions of Symfony and Laravel respectively, so if you need more power than any of these seem to have, you could use those two as a weather vane to see if one of the full frameworks might be more to your liking.
I used https://github.com/kenjis/php-framework-benchmark for the benchmark ( will submit a PR with the PHPixie implementation in a sec) Sadly not all frameworks in there decided to run, and also I had a strange issue with some frameworks taking 5 seconds per request when using the ab tool, but were ok when getting via CURL. Later on it turned out to be a keep-alive issue ( ab is respecting keep-alive and just waiting for 5 seconds for no reason). So I included only the ones that worked ok on my apache
This is nitpicky, as I know your article was trying to talk about just code readability, but part of that is applying the "information expert" and "tell, don't ask" heuristics. In your example, you asking for the user's birthday, doing a calculation, and then setting the user's age. That's the equivalent of being asked my age, but then proceeding to tell the person who asked me what my birthday is so that he can calculate my age. Instead, I should just tell him my age - I am the information expert with respect to my age, therefore it's *my* responsibility to tell him that. This is where objects come in - they help make code more readable. `$user-&gt;getAge()` * The user can know what the current date is * The user knows its own birthday (presumably it was constructed with it) * Therefore the user can tell you its age Now of course, your point still stands, you want that calculation logic to be clean and readable, just encapsulated within the user. But as an object, you can improve it slightly: public function getAge() { $birthdate = $this-&gt;getBirthdate(); // already returns DateTime object $today = new DateTime; $age = $today-&gt;diff($birthdate); return $age-&gt;format('%y'); }
What I generally try to do is to duplicate the existing style of the codebase on which I'm working. I'd rather that everything is in the same style. If the chosen style is having a major detrimental effect on readability I would then recommend a refactor. I don't see tabs vs spaces, brace position, variable name capitalisation and other such choices as having such a negative effect.
&gt; Is this stupid security-wise No, in fact it's pretty much *the* correct setup for this situation.
I noted that lack of space, too. Having that space is in one of the PSR's, too. The heuristic that I used (before standardizing on PSR) was to have spaces as closely match how they appear in natural language. Note the spacing on the parentheses in the previous sentence.
It would be good to add documentation.
You now have me racking my brain trying to figure out where I picked up this bad habit of not putting in the space before the parentheses. I have no excuse.
Just to confirm, for sake of my good night's sleep :) You suggest to set php-fpm to user:user instead of default www:www (which also plenty of tutorials recommend)? Also, could you clearify what are security implications of both setups? Thanks a ton and sorry for bothering! 
Somebody is on their period
One thing I like to do is space out multiple sequential variable assignments so that the equals signs line up. Old and Busted: foreach($users as &amp;$user) { $today = new DateTime(); $birthday = new DateTime($user['birthday']); $age = $today-&gt;diff($birthday); $user['age'] = $age-&gt;format("%y"); } New Hotness: foreach($users as &amp;$user){ $today = new DateTime(); $birthday = new DateTime($user['birthday']); $age = $today-&gt;diff($birthday); $user['age'] = $age-&gt;format("%y"); }
I have a love hate relationship with this type of spacing. On the one hand it does increase readability but on the other hand it is a pain whenever you need to change the code. Does anyone know if editor plugins exist to automate this type of spacing when editing existing code?
 try { code; assert(false); } catch (\Exception $e) { assert(true); }
This is why the vendor folder gets committed to the repository of any site I work on. People bitch me out for it, but I can not afford to rely on a third party service that could go down in the middle of a deploy. Which would leave some servers in an updated state and some in an outdated state.
Agreed. However, in not all situations can you do the filtering server side. For instance, we do web service calls to a university with inexact filtering and have to do fine grained filtering ourselves. So while this article doesn't make any sense with regards to direct access to a database it does have *some* value in other situations.
glad to see you are still working to make PHPixie the best it can be. I always noticed you had a small footprint and good response time when I tested as well. 
Hi krakjoe, Thanks for pointing that out. I understand what you mean. The request are not done in parallel but since the I/O is not blocking, you do not wait for the response of the first request before you kick on the next.
documentation is missing. i've no idea what your library does. at absolute minimum a feature list.
... yeah .... -1
That works most of the time. I use the setExpectedException() method to also look for a specific error message. public function testLookForMyException() { $this-&gt;setExpectedException('Foo\\Bar\\BazException', 'My exception message!'); doTheThingThatThrowsAnException(); }
Or you could create a build artifact before the deploy.
I personally don't like this style. In my opinion, all it does is make it more troublesome to see the values of the variables. I read left to right, one line at a time. I don't read vertically - it feels weird. Aside from that, it makes it annoying to alter/add variables.
aequasi08, hey there, if you could reply to the email that I sent you we can talk through this.
i. Read http://12factor.net/ - even if you don't agree with all of it, most of it is good advice. ii. You really don't want to have requests that take a long time to process. All of the work that takes a long time to process should be move to background worker tasks which can be managed through http://supervisord.org/ and scaled separately to your web servers. It sounds like you will be providing an API for the IOS guys to use - that will make it a lot easier to implement that than it is for servers responding to web browsers, as you can just return custom HTTP codes that mean 'try again in a bit'. iii. People will try to hack you....and you will have bugs in your code. I strongly recommend using 'event sourcing' aka storing list of events that occurred for anything related to money or in game credit, so that you can either figure out what people are up to, or recover when you have been hacked. https://www.youtube.com/watch?v=JHGkaShoyNs &gt; preventing MySQL injections Just use prepared statements everywhere....the chance of you actually needing the extra speed that not using them gives you is minimal.
I don't think "great programmer" and "in a week" belong in the same sentence. I mean, the article starts out with a cliche IDE screenshot that doesn't even contain PHP! The article contradicts itself with points #1 and #3... "Stop looking for code", "Go look for tutorials". I'm not going to go on a tangent berating the article's content, it's just not that great in my opinion. Unfortunately, the web is littered with straight-up awful PHP examples which is one of the reasons why PHP is often scoffed at by certain developers. IMO, if you truly desire to improve your abilities, published literature is the way to go and if you're serious about your career, shelling out $20-30 bucks here and there is just plain worth it. Considering how much college textbooks cost nowadays, that's an outright steal! My latest read was CleanPHP by Kristopher Wilson which I really enjoyed reading and took a lot out of and it cost a mere $25. This is not to say that every PHP tutorial or code sample out there is junk-- of course there is good stuff However for a newcomer, discerning the good from the bad isn't exactly an elementary decision!
I so wish my team members understood this concept. It's fundamental in OO programming :/ You should see the amount of times people copy and paste little snippets like this all over instead of putting it a function. 
PHPstorm has a code style setting for it.
Why does everything have to be some kind of a factory now? This isn't even really a factory, it's a wrapper for cURL. Why not just expose that as a static method of Parser itself? $parser = Parser::from_url('http://mysite.com/robots.txt'); $rules = $parser-&gt;parse();
Yea, its kind of awkward. There's no real "factory" here, really. Its just a fancy function. There's no internal state, no configuration of its factory mechanism, no way to swap its resulting object, or anything. I mean, those aren't necessary exactly, but its just kind of strange. The only reason I _do_ kind of like using a separate class here for the download building instead of just using a "named constructor" (static method) is that the complexity of the building gets to be separated from the Parser class itself. But yea, eh.
Hah, I just finished that book this morning. The comments were never necessary or useful. The loop should have been extracted with a useful name itself.
Premature optimization is the root of all evil -- Donald Knuth
This doesn't matter if you ignore whitespaces in diffs, but yes, it can be annoying.
I would argue that the two objects are so tightly coupled together (note that the "factory" returns a Parser by name; it is hard-coded) that it doesn't make sense for them to be separate objects. It adds unnecessary complexity. If the desire is to separate the downloading aspect from the parser, I would maybe create an object like RobotsRetriever that takes a URL and gives you a valid robots.txt if it exists and passes the various checks. $robots_txt_content = RobotsRetriever::fetch('http://mysite.com'); if ($robots_txt_content) { $rules = (new Parser($robots_txt_content))-&gt;parse(); }
Exactly! As a codebase grows, at least in a professional setting, the line-by-line history (i.e. `git blame`) becomes incredibly valuable. In addition to generating larger diffs for review, re-aligning code adds an unnecessary and unrelated commit to a line's history. This makes for a bad time. My general policy is to make changes that generate the smallest diff possible, which necessitates avoiding whitespace changes. Changing code just to adjust formatting adds zero value, yet introduces a chance of a bug making its way in (unlikely in general, very unlikely in PHP since it's whitespace-insensitive).
+1 I do prefer this method over the @expectedException annotation thing. 
The blame will end up with the wrong author.
&gt; Code written specifically for testing isn't subject to the same design considerations as application code. I'm familiar with that attitude, but I doubt anyone can logically back it up. Code is code.
What the hell is that even part of?
&gt; A more concise way of doing so Is it more concise? Let's put that *assertion* to the *test* (couldn't resist...): $tests-&gt;add(function () { try { code; assert(false); } catch (BazException $e) {} }); 96 bytes; autocompletion on everything; you understand what it does by knowing PHP in general. /** * @test * @expectedException \Foo\Bar\BazException */ function do_something_that_will_throw_an_exception() { code; } 131 bytes; no autocompletion on PHPUnit-specific annotations in comments; requires knowledge of PHPUnit magic; Well?
I am not specifically advocating PSR but I do think it is worth mentioning that it exists. Those looking for an already defined style standard can easily pick it up and run with it. Are there any other popular and well written PHP style standards I missed? Edit: I've changed the wording on the article slightly
Alright. If you are so privacy-conscious, then are you sure any of the other devices you use are already not collecting this information? I'm not saying this to imply that MS doing this is okay because others are doing it, but rather I am saying that it is reasonable for Microsoft to collect these information because they are necessary for Microsoft to provide the service they want. Let me give you examples: Name, email address: pretty standard for all web services. Do I really need to explain this? Preferences, interests, browsing history, searches, voice data: For interest-based advertisement and Cortana's machine learning. You can disable the interest-based advertisement in PC settings which also disables the tracking-ID. You can also enable Do Not Track mode and Ghostery if you do not want to be tracked. Do you use Google? Applications and application usage, devices and device usage: This may be needed for Smartscreen and Windows Defender to filter out and collect malicious applications. Networks: Windows's new Wifi-Sense feature? You can disable this. Full disk encryption key: This is because too many (l)users were presumably losing encryption keys - you can opt to not send it to MS quite easily on BitLocker setup. ------ Intention does matter because you imply that Microsoft is some kind of evil corporation who is offering an "operating system [that] is essentially spyware" (your quote). But just off the top of my head I can tell you many features which require the permissions you've listed. Don't get me wrong, I am not attacking you and I hate MS moving to a ecosystem-centric position, but your claim that Windows is "essentially spyware" is just pretty much wrong. Edit: Would really appreciate it if you stop downvoting my posts because you disagree with it. Try arguing instead please.
Yes. I'm not saying that what MS is doing is right. But what MS is doing is for a justifiable reason (providing features to consumers), while many other privacy breaches are not. What I'm saying is that if you are really for privacy, you should choose your battles. There are much more horrifying privacy breaches to protest about. Otherwise one would simply be a hypocrite.
Oh, absolutely in agreement. My own config for phpcs is a huge set of frankenrules.
Protip: The L in LAMP is linux. 
I know it's a bit unrelated but out of sheer curiosity, why do people prefer VB over Hyper-V on Windows?
Yeah, cuz only _that_ scenario justifies privacy. Mind telling me your full name and your email, please? Oh, and please attach to that an exported file with your browsing history. Thanks.
It's not about "hiding". It's about "why the fuck would some other person know what the fuck I'm doing?". Simple as that. Your attitudine is symptomatic of the consequences of the constant erosion of privacy: we end up saying it's normal. We.. get used to it. *I* will eventually get use to it, but some people are more paranoia/reactionary than you. Some of us are not as "normal" as you.
Thanks sethnis for the kind words. Anyway I love to receive critics when they add value to what I have done and can help me to improve. When they are empty critics I can easily skip them with no big problems.
How did you use DOMCrawler? What was your filter? It should probably be something like this: $crawler = new Crawler($html); $imageDiv= $crawler-&gt;filter('.market_listing_largeimage'); var_dump($imageDiv-&gt;filter('img')-&gt;attr('src')); More info here: http://stackoverflow.com/questions/16300958/symfony-domcrawler-find-element-with-specific-attribute-value
I've worked around this issue (for one box) by manually setting the IP of the host-only adapter via Network center.
&gt;MAJOR version when you make incompatible API changes, Have you made incompatible API changes? No. &gt;MINOR version when you add functionality in a backwards-compatible manner, and Have you added functionality? No. &gt;PATCH version when you make backwards-compatible bug fixes. Have you made any bug fixes? No. And there's your answer.
I had the same issue too. I had both outdated versions of VB and Vagrant. I then upgraded VirtualBox to 5.0 and then Vagrant to 1.7.4 and everything started working again. All my vagrant machines are booting ok.
I know it did this during the tech preview, but do you have any references to Windows 10 doing this with the release version?
Saying: "spy on me, i have nothing to hide" is like saying: "i dont need freedom of speech, i have nothing to say"
I suspect it'll be about successful as https://wiki.php.net/rfc/taint 
It's really just the API that's covered by semver.
I appreciate your review on the post. Though you are right on some points like the 1, 5 and the 9 you have to know that education system is not the same and at the same level in all countries in the world. These steps have been part of my training formula for a while. It's a king of "Learn how to learn". I believe this could help someone at least to know some places where he could improve his skills in PHP or anything he intends to learn. Beside your criticism will help me myself to improve my posts next time. So thanks for that. 
Ugh. You are doing real work man
I know this site gets recommended a lot on here, but you should really check out [laracasts.com](https://laracasts.com). Jeffrey has many screencasts on testing, and covers TDD very well. Note, this service is not free, but it's well worth the $9/month, even just for one month to help you with this issue.
If you don't believe the use cases for application components are different from the use cases for tests, I'm not really sure how I could convince you otherwise, nor do I feel obligated to do so.
Agreed. But so many people blow this out of proportion, it's getting a little annoying. That is all.
I do believe the use case "differs" in some general way, but "the use cases differ, therefore PHPDoc pseudo-annotations in one of those cases" is still just as arbitrary as a belief. I find it sad that you don't feel "obligated" to know why you believe something exists for a reason without having a clue as to the reason. The obligation is not to me, but to yourself. There is a lot of intellectual laziness in the community when people speak about why this or that is done in software design. Lots of strong opinions, not much explanation. You probably know about the experiment with the five monkeys, the banana and the water spray. Something like that.
[Robert C. Martin has a PowerPoint presentation](http://butunclebob.com/ArticleS.UncleBob.TheBowlingGameKata) you can get that will walk you through writing TDD for a Bowling game. This is how I learned. I agree that Jeffrey Way's [Laracasts](http://laracasts.com) are awesome too and worth the $9.
It is not the language's job to protect you from being a horrible programmer.
Have you checked out http://www.grumpy-learning.com/ ?
Here's what it looks like now. Taking a sleeve out of Pandas' book. $df = DataFrame::from_fwf($filename, [ 'col_name_1' =&gt; [1, 9], 'col_name_2' =&gt; [37, 40], 'col_name_3' =&gt; [43, 68], ... etc ... ], ['exclude' =&gt; '/^"\s{8}"/']);
I'm sure you read the TOS right?
So, there are two pit-falls: 1. If you allow users to upload files (as feature or maybe even a bug), they may be able to put a PHP file on your server and make your script include this. This script could do anything the author wants. But this will only occur, of course, if you have a place in your code where you input a variable to `include`, e.g. `include($className.'.php')`, which leads me to: 2. It's very commonâ€”if not even a requirementâ€”that include is used along with a class autoloader (http://php.net/manual/en/language.oop5.autoload.php). Here you cannot avoid passing a variable to includeâ€”unless you're making an autoloader for each class, which is inconvenient as hell. The point here is that it's safe to use include, but as with any other feature, you need to educate yourself around the common pitfalls. Tip: Use a framework, it will relieve these kind of issues and allow you to utilize a lot of developers' knowledge on security issues.
Or magic quotes.
Of course there is nothing wrong, it's juste the point of Composer... There are plenty of different libraries in the Composer world and this kind of tiny library / dependency is just over engineering... Of course it's just my point of view :)
Cool! I'm starting a meetup on this porpoise. It's in spanish, but almost all programmers are bilingual, so feel free to interact in English! http://www.meetup.com/es/Desarrollo-de-Aplicacion-desde-Cero
Jeffrey's testing screencasts do not cover the full process gamut that OP is looking for, they're very introductory. The other problem is not all screen casts cover unit tests, they cover full integration/acceptance tests, which is fine when you run three tests, but when your app has ***10's of thousands of stories*** to test, you can't be booting the framework, reaching into the database, and inspecting the DOM for the correct output - and I feel that strategies for minimizing the need to do this isn't adequately covered by Laracasts. As such, it makes the process of testing look deceptively simple, but in reality, a test suite is really only useful if its performant. Don't get me wrong, I love Laracasts, but I think OP is looking for something more in depth than what you can find on Laracasts.
Lots of people here are equating this to magic quotes, but I think there's an important difference. The reason magic quotes was bad is because it altered (corrupted?) our data. Taint checking doesn't do that. Instead, data that comes from the user will be considered "dirty". If we use dirty values to make a SQL string, then the SQL string is dirty. And if there's anywhere that I'm executing a dirty, tainted, user-compromised SQL command, then I definitely want to know about it.
False positives are not a problem. If you were doing a security pass, it would be useful to get a list of *potentially* vulnerable query strings for you to audit. False negatives, however, would make it completely useless.
False positives are always a problem, because if you have enough of them, you stop paying attention. A stopped clock is right twice a day about it being 3:14, the rest are "false positives" about it being 3:14. It's still worthless as a clock and you wouldn't want to carry it around for time-keeping. The software equivalent of "stop paying attention" is "I just untaint it, cause the errors I get here are never a real problem". BTW, it'll be really fun to get surprise SecurityError exceptions in production for code which passes all unit tests (because unit test uses T_STRING inputs that are not tainted). You'd have to remember to manually taint all string literals in test code.
I wouldn't blame the programmers (unless they work for/with me... :P), I'd blame the SQL APIs, which are designed so they're inherently prone to injection. SQL was designed in times when user input *was trusted*, but times have changed. And because it's an SQL API problem, it's a problem SQL providers have to solve, not PHP.
I'm impressed the author managed to say "use json_encode() for JavaScript values in your pages" in so many words.
read the EULA.
The problem is data isn't "dirty" or "clean". Unexpected behavior and security effects are a combination of: 1. Input trust context. 2. Output encoding context. There are multiple trust contexts and multiple output contexts. You can't cover this with a 1-bit flag. If I untaint data for one SQL connection it's still not safe to use it for another, for example.
As defined by the FTC: &gt; Spyware is software that aims to gather information about a person or organization without their knowledge and that may send such information to another entity without the consumer's consent, or that asserts control over a computer without the consumer's knowledge. We know about it, and we consent by installing it. 
I've read the RFC twice and I can't see how it handles strings that come from other sources. i.e. for `$foo = file_get_contents($someFilename);` is $foo considered a 'SafeConst' ?
yes, two wrongs doesn't make a right. If a person is commiting a crime that doesn't give everyone else permission to do it.
This worked for me, minus a few steps that I considered likely uneeded. I did not have to delete my VM's. (Thankfully, because that would have been a pain in the ass). I also did not have to go through device manager to delete the ethernet adapters. Simply removing them from VB was sufficient. As you mentioned, I did receive the error after reinstalling everything, but rebooting did infact clear it up. Thanks a bunch OP.
 &lt;?php $users = [ ['name' =&gt; 'John Smith', 'birthday' =&gt; '1988-02-03'] , ['name' =&gt; 'Jane Jones', 'birthday' =&gt; '2014-07-08'] ]; function makeAge($birthday) { return (new DateTime())-&gt;diff(new DateTime($birthday)) -&gt;format('%y'); } $setAge = function ($user) { $user['age'] = makeAge($user['birthday']); return $user; }; $ages = array_map($setAge, $users); print_r($ages);
Literally the next sentence: &gt;I'm not saying this to imply that MS doing this is okay because others are doing it
https://edri.org/microsofts-new-small-print-how-your-personal-data-abused/
var_dump 
And then you ignore my response with a random link about something i wasnt talking about.
Yes, I personally prefer LXC, but that is very linux centric.
Why LOL? Are there any examples of attackers controlling primitive scalar variables?
No. I was talking about you failing to read the very next sentence, let alone the whole post by /u/sekjun9878
Give "people in the past" a little credit. They weren't idiots. The reason SQL queries are plain text is because they were designed for be entered manually by human operators. The reason the SQL standard has such granular permission system is because the idea was: you create a user, and you're explicit which tables they can access, and what they can do with the data in there (say, only read, don't modify). In the environment SQL was supposed to be used (as a digital replacement of file cabinets in companies, internet didn't exist), this was fully sufficient and user input could be trusted (it either runs, or doesn't, permissions ensure DB admin's intent), and it *wasn't* a mistake. Today's use case for SQL is drastically different: we create full-permission users, and then have a detailed application-specific system of business rules at the application layer (there was no application layer typically back then). The textual input of queries that was an advantage, is now an impediment. Same story like HTML, by the way. "Hey let's create a textual markup format that humans can manually write documents in!". It picked up, then dynamic sites happened, and now we have XSS. The problem is, as an industry, we're too comfortable running on inertia rather than changing the technologies we use to fit with our new use cases. We shouldn't even be using SQL databases for web sites. Yet we do. Not just that, but some of the fancy "modern" NoSQL solutions have devolved to accept string queries as input, to appease the masses set in their old ways.
Sure â€“ there are many ways you can accomplish roughly the same thing. max_element returns an iterator which isn't desirable but not a big deal â€“ I can just deref the pointer. But that still means the calling code has to pass the iterators. This version makes the calling code really clean. 
If only there was some kind of software to create a self-contained, configurable server environment that could match a typical LAMP setup. Some kind of *Virtual Server Box*, one might say.
So does Facebook
I'm not sure if this is just an issue with your documentation or on purpose but why is your `addMethod` method named `addClass`? Also, regarding the project itself. In the README could you document the actual problem this package solves? I see you named it smart object but I don't know WHY I would use this package. 
The very first mysql API implemented in PHP (predates PHP 3) had only real_escape_string and you had to concatenate (or use sprintf) manually. Some (a lot of) developers were taking shortcuts or forgetting to escape their values because that's how tutorials were teaching it. But mysqli (PHP 5.0) and PDO (PHP 5.0) both have the ability to prepare queries using placeholders and automatic casting/escaping very easily. You can't say the SQL API is to blame, it's clearly an adoption problem or a lack of awareness or laziness from developers. [Mysqli example](http://php.net/manual/en/mysqli-stmt.bind-param.php#refsect1-mysqli-stmt.bind-param-examples) [PDO example](http://php.net/manual/en/pdostatement.bindvalue.php#refsect1-pdostatement.bindvalue-examples) [SQLite3 example](http://php.net/manual/en/sqlite3stmt.bindvalue.php#refsect1-sqlite3stmt.bindvalue-examples)
I personally don't like the idea of mixing userland documentation with API/docblock. Userland docs don't explicitly follow an internal API, and may often combine classes/services. Also maintaining the prose from a version control standpoint would clutter work history together -- I don't need a lot of commits in my source that are only for maintaining documentation. I can see some potential usefulness, depending on size of project and development style, but for me the combination adds more complexity than its worth.
And perhaps we could consider it to be ever-wandering, never truly settling on just one computer. Sort of vagrant, if you will.
Thanks for the feedback, makes sense.
There hasn't been a Windows service pack since early 2011.
Yes, I think there needs to be prose AND relevant usage examples. Everyone seems to use Sami for their API docs, but Sami is so awful it hurts. Meanwhile Laravel has fantastic skimmable docs with the right number of examples and pros, but then links off to a shitty Sami API doc that doesn't even let you see the snippet of code related to the method - you have to go to Github for that or Ctrl+P the file if you happen to have your editor open. There needs to be a proper, all-in-one tool that ***seamlessly*** (this needs to be emphasized) blends: 1. A terse and scannable API summary of a class 2. Quick usage examples 3. Extended usage examples (e.g. showing broader context) and edge cases 4. Prose explaining in more detail (what it's used for, when to use it etc) 5. And the ability to actually look at the source code related to the method (when viewing in a web context) Bonus points if it can integrate with an IDE somehow so that 2, 3, and 4 can be exposed as a tooltip with a shortcut key (the IDE will take care of points 1 and 5, obviously).
Yeah, Sami isn't that good. I use ApiGen right now for API docs, but it's not perfect. I also use [Couscous](http://couscous.io) for prose docs.
I object! composer, yes. phpunit, no. phpunit can be, and should be, a project (dev)dependency in the projects composer.json so that each project can specify which version of phpunit is uses and what other testing items it will need. This is a far cleaner way to uses phpunit these days. ./vendor/bin/phpunit And viola.
Xhprof, 
Seeing this on my front page, it took me way too long to realize that VB was Virtual Box and not Visual Basic. Then I couldn't figure out why people would need Vagrant if they're a VB developer on Windows.
HA ya you're totally right 
Makes sense. There hasn't been a decent Windows released since 2009.
I'm unaware of what their prod looks like, but am working towards parameterizing the ansible pieces so that it can be deployed specifically with the optionality of deploying for Dev, Staging, or Prod. 
Excellent! Thank you for the suggestion. What purpose would having mailcatcher serve? I'm not asking in a contrarian way - just an honest question.
Is Laravel something I should include by default? I'm not sure if their devs utilize it, or if it's an industry standard tool that pretty much nobody goes without.
It's the most popular framework being used right now. It's actively developed, has an amazing community, etc. While I will suggest learning it as it seems to enforce some good coding techniques for a PHP developer (also an inexpensive subscription to laracast.com is a must), I think it's important to learn **a** framework and be familiar with others. Another big one that's used a lot of places is Codeigniter and another is Symfony (from which Laravel uses some components).
Normally I use MariaDB instead of MySQL and nginx instead of Apache. Any reason for Apache? display_errors is a must for development, so definitely do that. I also like to have php5-cli, sqlite (for when I don't want to deal with MySQL/MariaDB), vim, git
If puphpet is yours, thank you so much for that! The few times I have used it, I have loved it.
So, I mixed up my threads. I agree with the other posters after me that you shouldn't be including a php framework by default.
Have you seen www.drupalvm.com ? It's similar to what you're going for, but much more specific just for Drupal development.
http://downforeveryoneorjustme.com/getcomposer.org
If I don't feel like writing PHP, I usually jump over to Python. I find it's very similar just with a lot of structure. Flask and Django being of course the recommended frameworks
The most important thing, alas, is the long-term organizational will to make sure it's used consistently and kept up-to-date. **P.S.:** Speaking from the experience of someone who tried to introduce Vagrant into a smaller team, my first attempt was to to manually install everything to a VM and distribute it as a "base box". Straightforward, a little bit tedious, but didn't require learning much more than "vagrant helps automate Virtualbox". Unfortunately it doesn't age well, and you end up having a set of "Post-install instructions" and eventually a replacement made from scratch. What may be far more valuable in the long-term (both to users, and to yourself for learning/bragging purposes) is to distribute an teeny tiny base box, and focus instead on [provisioning scripts](http://docs.vagrantup.com/v2/provisioning/) that handle stuff like installing PHP, XDebug, etc. It's not a bad thing if it takes a while to provision the box, as long as there are mechanisms people *could* use to speed it up, like providing local copies of whatever distribution packages the VM is trying to grab.
can someone tell me why every time after I install elastic search that I have to reinstall it every time I start the server back up?
Laravel already has their own vagrant image, called "Homestead" - http://laravel.com/docs/4.2/homestead
debugging emails
I don't understand why anyone uses apache any more. Nginx+PHPFPM scales better than apache+mod-php any day every day.
If you're installing node for front end assets and tasks then installing npm is essential, and maybe bower as well.
Docker :)
Honestly, I'd prefer that to be on the host.
Thanks, the thing about the `addClass` was an error in the `readme.md` which have been fixed by now. Thanks for pointing it out. I will try to make a better description for the package. What it does is, it make it easy for other classes to add the following methods to it. - Dynamic Getter, the dynamic getter makes it possible to easily get attributes from your object using methods like `getAttributeName()`, which then will return `$this-&gt;attribute_name` from your object. - Dynamic Setter, the dynamic setter makes it possible to easily set attributes to your object using methods like `setAttributeName('Value')`, which then will set `$this-&gt;attribute_name` to be `Value` in your object. - Dynamic Methods, this makes it possible to easily add methods to your object runtime using the method "addMethod" and as well remove those methods runtime with `removeMethod`. Thanks for your feedback, I will work on a better explanation of the package itself.
Honest question. out of curiosity what's the application of USB forwarding for in web development?
http://stackoverflow.com/questions/5815183/php-imap-exchange-issue
Thanks! Happy you like it :)
Unfortunately the PHP versions on puphpet are from repos. * Ubuntu: https://launchpad.net/~ondrej/+archive/ubuntu/php5-5.6 * Debian: https://www.dotdeb.org/ * CentOS: http://rpms.famillecollet.com/ * PHP7: http://php7.zend.com/
Would appreciate it if the downvoters could explain their downvotes.
Personally because I know it well andI can dive into config files and setup / modify things quickly. Just need to find the time to learn Nginx. I do use PHP-FPM though.
I already read that and didnt gave me any light for my issue :-(
Useful things to have on the box: - Redis / Memcached - For caching - Beanstalkd / another local queue server - Mailcatcher for testing emails without sending out emails - Node for npm - Bower / Grunt / etc - Possibly Node for websockets - Xdebug - Supervisord for making sure my queue worker stays up php.ini defaults I don't like: - xdebug.var_display_max_depth=6 (default = 3) 
&gt; and all the insecure default vagrant stuff destroyed. Vagrant seems to do this itself now as apart of the initial `vagrant up`
Unfortunately, it's not compatible with xdebug. Could come installed but not enabled though. (Maybe enable via `vagrant ssh` and running a quick symlink-twiddling/daemon-restarting/xdebug-disabling script).
you really just mean npm * ahem*
Git and svn client binaries should be installed (and maybe others, but I don't use any of them).
Multiple apache sites with different Environments set up, depending on what framework your dev uses (i.e. http://symfony.com/doc/current/cookbook/configuration/external_parameters.html) 
Error I am getting now when retrieving emails is: Fatal error: Allowed memory size of 134217728 bytes exhausted (tried to allocate 133169571 bytes) in D:\Websites\ZZ\testpop3.php on line 39
&gt; Waiting around for provisioning from a common base box (like the latest Ubuntu LTS or something) can take quite a long time, even with local packages. Depends on the provisioning tool. As I already used ansible for the production infrastructure, adapting it for the vagrant env was pretty easy and you get an idempotent environment for free. The first provisioning takes a tad longer the older the base box is, yes, but you don't have to do that that often - the occasional provisioning to update packages or to deploy new configuration is the same, whether your base box is bleeding edge or not. I modified the Ubuntu LTS base box though so it doesn't contain the whole world of cloud tools which I would need to purge in provisioning later anyway. &gt; Nowadays, you can set up a pretty good repeatable Vagrant base-box build with Packer[1] . And Vagrant boxes are also now versioned, with a JSON metadata URL. So you can get the best of both approaches: use whatever you like for configuration management to keep boxes up to date, and then also offer regularly-built base-box upgrades. And you don't even have to pay for Hashicorp's box hosting (Atlas). Just S3 it[2] instead, for private boxes. Is it possible to use versioned base-boxes w/o making it publicly available now? That's what stopped me from using versioned boxes when I setup the vagrant environment for my latest project. If this has changed, I definitely have to look into that again. And Packer sounds nice too... oh my, you're working on different things for a couple of months and everything's new again and a dozen new tools are around ;) 
At least one other back end language, go/python... I like to have other options available for the heavy lifting stuff.
&gt; you don't need to scale while you are in development. I usually try to reflect the production environment as close as possible. It's not about scale in development, sure, but if your production servers use software X, you should also use software X in dev. 
You will need to find your php.ini and increase the memory_limit. http://php.net/manual/en/ini.core.php
There are several pre-made imap libraries... https://github.com/barbushin/php-imap https://github.com/ddeboer/imap I guess you should have a look at composer (https://getcomposer.org/) so you learn how to use 3rd party packages...
"available as a web service or as an online application, that uses the information from your composer.lock file to check for known security vulnerabilities." ... dont see how my lock file can have that kind of information in it ;)... I guess if i were using say Eloquent or something... I typically roll with PDO.
Ah sorry wrong link! I was thinking of https://insight.sensiolabs.com IIRC there was something related to basic variable tainting for detecting XSS or SQL injection (e.g. if you pass a query parameter straight to HTML, or SQL), and for DB queries it checks that you use parameter binding (instead of string concatenation). Of course still pretty "basic" compared to what you described (though it's a good tool).
Looks pretty cool. I wish there was a per-project plan (procing) rather than monthly :/
Exactly what's installed in production
In CakePHP we use ApiGen for that. We have managed to make it pretty good at displaying descriptive documentation along with the api docs. For example this: http://api.cakephp.org/3.0/class-Cake.Database.Query.html#_where
You could try directly "echo'ing" all your output instead of appending to the $output variable before echo'ing.
I just use https://github.com/Varying-Vagrant-Vagrants/VVV for everything PHP.
already have my perfect stack www.drupalvm.com
Yes, reproducing production environment while you are in development it is recommended, but regarding web servers should not matter, because your application is a web application and should understand the main protocol involved: HTTP. &amp;nbsp; Because you application understands HTTP, will know that a request will come in, will do some work and in the end will return a response. From where (_as in which web server_) it comes that request it shouldn't matter. &amp;nbsp; One of the big differences between web servers is their side features and if you built your application in a manner that requires a certain feature from a specific web server, it means that you locked yourself and you are forced to use that web server everywhere.
You write all this out in the code comments, though. I'd much rather include the docs from elsewhere, so they can be self-contained MD / RST docs people can contribute to without changing my source files. Basically, if ApiGen could be extended with a plugin that includes outside MD docs in placeholders specified in docblocks, that'd do the trick.
I have to do this everytime: wget https://download.elastic.co/elasticsearch/elasticsearch/elasticsearch-1.6.0.deb // as of 6/16/15 sudo dpkg -i elasticsearch-1.6.0.deb sudo service elasticsearch start // add to startup sudo update-rc.d elasticsearch defaults 95 10 then when I restart vagrant the next time, my database is still there etc, but when I do sudo service elasticsearch start it says pid file can't be found :(
Doesn't npm require node?
Stuff like this is crap because it lets people just assume that some magic is securing their application and they don't need to worry about it. In reality you're just setting yourself up for problems down the line.
xhprof and xhprofgui, and xdebug preconfigured for PHPStorm. We also have some handy scripts to toggle/clear opcache/xdebug/xhprof, but it could be possible to use a separate vhost for that. Also to run the application in production mode, depending on the framework. And the build script, if there are any of those. Production mode is not always the same as the production build. Some kind of log viewer, preferably browser based. Oh, and from experience: It's easier to distribute prebuilt boxes than base box + provisioning. If the provisioning fails for some reason the developer might be stuck with a non-functioning environment, which in time will brew hostility towards Vagrant ("it was easier just running MAMP") and the ones managing it. ("I can't work because X messed up the Vagrant box") Prebuilt boxes removes the need to care about state; that simplifies both building and usage. It also makes it possible to reverse to an older box, that is often impossible/messy with provisioning scripts. Both provisioning and downloading a box takes time, but downloading "never" fails. Slow is better than unpredictable. (although faster than provisioning in my experience)
Perhaps. But I think what would work even better than that is a "make-it-yourself" requirement. People write PHP scripts and/or libraries and/or frameworks (or anything PHP-related), host it on their Github, and share it with the community. I know I've written a few snippets that the community might find useful, so I would definitely check out a thread like that. What do you think?
Are you sure? I think it might generate new public/private keys (they get replaced by my own script, so I'm not sure), but on my installation I can still `ssh vagrant@##.##.##.##`, login with the 'vagrant' password, and `sudo bash`. It's possible that I haven't updated recently enough.
My bad, not possible with \ReflectionClass. Another option here for dynamic method generation without a performance penalty is code generation. Magento 2 takes this route for a lot of things.
I haven't compared the keys in the vagrant box but last time I noticed, there was a specific output about replacing the insecure keys.
Or mirror your deps and have them in a satis repo.
I did not said that changing some settings in web server's configuration will cause the lock-in, but changing the application to mold after the web server specifics (_like adding a specific header that the web server is not sending_). Please read again my comments.
I think you need to re-read my comments. You said changing the web server should not matter, but it absolutely does. I never said anything about changing the application. I'm not really sure how I can make this example any clearer. Let's say you have an application where your users can upload files. Maximum file size you want them to upload is 5G. You go into your php.ini and set the max upload size to 5G. You test it on your Apache environment, everything works great! You deploy to your production environment using Nginx. The application seems to work fine. Two days later people are complaining because they can't upload a 3G file. That doesn't make sense though - you raised the limit to 5G! Except with Nginx you need to add client_max_body_size 5120m; to your configuration, but Apache doesn't require this. Had your test environment matched your production environment you would have caught this. You're not bending your application, you're making sure your services are configured to properly support your application. There is literally no good reason why your production environment shouldn't match your development environment and vice versa. Just because a server serves HTTP doesn't mean the configurations are going to be the same.
If it works and is maintainable I tend to leave as is. If it is obviously flawed, I tend to actually try to sort it out.
I just make each project better than the previous. Who has time to go back and rewrite code that works already to make it better? Sure, if it's slow and it's a highly used site and it's generating revenue or is high traffic and refactoring will help the users of the site and it's compensated for work... otherwise, if it's not broke, don't "fix" it. Also, if you're good, you should have more paid work coming your way right? So keep doing each project better. If, however, you aren't "full" of paid work, you "may" want to elect to spend your time refactoring old code, but personally, I'd rather be learning new things or experiencing life... maybe even go outside ;)
I use full stack VMs and I have been wanting to move to Vagrant. I would really be interested to see what you come up with. Some notes on the discussion of how it goes together would be most helpful. the code I work on should be in the host machine the software that drives it all should be in the guest phpmyadmin should be in the guest. 
I wouldn't say leveraging prepare is "abuse". A wrapper is also trivial to write but beyond the point of built-in API. You are correct, we won't agree whether or not prepare-&gt;bind-&gt;exec consists of a built-in facility to write proper, secure SQL for single queries. &gt;Also, aside from binding values, real-world apps often have to dynamically insert identifiers and expressions in a query (limit, offset, order by asc/desc etc.). Placeholders don't help you a bit here. I agree 100% with that part, there's no built-in fix of any sort for that and it's a big issue. Things like eloquent and doctrine fix it but at this point it's barely SQL anymore. **tl;dr** I agree that a $db-&gt;query('select * from table where id = :id', ['id' =&gt; 1]); or $db-&gt;query('select * from table where id = ?', 1); would be nice to see in the official API. 
Release early, release often, refactor between major releases.
This is the same approach I use. I utilize a git repo for code versioning and bugzilla to log my bugs and features. It's easy because I can use my cell phone to add a feature I just thought about and then once I have finished off a plugin/module/class, I can go on to the next. I also work with a basic to advanced work flow. So I flesh out the basic requirements to make it function. Then I pick the next required thing on the list just to make the next feature possible. Once I have a basic system in place, the bug zapping and feature refactoring comes into play.
Where is Symfony here?
If you like to do it, do it in your own projects, as much as you want. At work, usually deadlines prevent refactoring. I usually try to use any new thing I learned in a new project or feature. Don't bother refactoring old code, unless it's the actual goal of a project or it's a substanstial rewrite anyway (i.e. speed improvement, API changes, etc.).
I use the "refactor as you update" pattern, where if I am updating a class or a function to add or enhance functionality, I will refactor it while I am in there. For major updates that require a rewrite, it will be part of a concrete release milestone, such as a website redesign.
I limit myself to a ratio. No more than around one hour in four should go to refinement, unless there's an exceptional cause, in my opinion.
I couldn't agree more. "Lasagna code" omg I can't stop laughing. Never heard that one before. 
Yes it's a utility that services node projects (or projects using js in general) and is built with node, but node doesn't inherently do the above things (just like PHP and composer, Debian Linux and APT) etc. it's just a distinction that I think is important because it might confuse or mislead someone who isn't familiar with node
The point is so clear, I'm not sure why you're not getting it. If you had DEVELOPED using the SAME SERVER SOFTWARE AS PRODUCTION you would have caught the error. Again, this is why development environments are moving toward complete mirrors of production environments on EVERY LEVEL. Also, you still have not given any remotely valid reason why you would be developing on Apache-based servers when you're using Nginx-based servers in production.
Why would you need JS routing if you don't want to use Angular, Ember, Backbone etc? What is the backend based on exactly? Is there a PHP framework?
It's crowdsourced, so you can always add your code of choice to the list.
Thanks!!
&gt; how do you manage to "resist" the urge to refactor ? Prioritisation. Don't get precious or possessive about your code. If it's a codebase that will rarely be used or require modifications or additions, then leave it. If it's something that will get used a lot and need further additions or contributions over time? Refactor the shit out of that shit.
https://readme.io looks interesting?
This is me exactly. I'm working on a game (has some backend is in PHP) in my own time and for the last 12 months, I've basically added nothing. But I've still spend hundreds of hours changing technologies, redoing stuff... Urgh. Feels terrible thinking about it. Could and should have released it by now.
It's fine :) Remember that personal projects are about having fun and learning new things. You don't have to turn it into work. I was in the same position: starting ambitious side projects and wanting to achieve perfection (regarding code quality). When the project starts to drag on, motivation goes away. You think that the solution is to be more "organized", you start to create issues and plannings, etc. But that kills the motivation even more as it starts to be "work". Now I try to focus on **iterations** that get me to something **usable and stable**. Usable because it's rewarding and it keeps me happy and motivated. Stable because it's what makes the next iteration possible. When an iteration is finished, you are free to do whatever you want (refactor, add features, do another one project, â€¦). In the end, doing "refactoring" iterations is fine IMO. You learn a lot. What's important is to reach a point where you feel you have "finished" something, because that's what is rewarding. Working by iterations is helpful as you can chose "I'll focus this iteration on trying CQRS", then "I'll focus this one on finishing feature X". And also because it limits the scope of the refactorings (it avoids to because an endless refactoring because you have set goals at the start of the iteration).
In general a microframework is one that doesn't dictate your app architecture too much. Most of them provide a router (so you can have anonymous functions or class methods respond to certain url requests) and a way to render view files (so the function responding to a request can pass some variables to a template and have it outputted to the browser).
You can use [Browserify](http://browserify.org/) to allow you to break down your JS into separate components/modules (it's up to you to organize how them how you want), and then Browserify binds them all together for you. Think of Browserify as the equivalent of a PHP autoloader. As far as a router goes, take your pick. JS has a million of them. That said, usually projects that are primarily back-end PHP *don't* use a JS router, so I'm not sure what need you have of one if you're trying to develop mostly in the backend.
&gt; For instance, I lately picked up on trendy approaches/patterns like the Command Bus, CQRS, event sourcing and DDD. Implementing those in a project involves drastic changes, potentially a complete rewrite. There's a difference between *refactoring* and *rewriting*. Refactoring, when done correctly involves taking a single component, documenting its interactions with other systems, and then replacing it with something presents the same interface as the old component, thus requiring ideally none-to-minimal changes to the rest of the system. Refactoring is cumbersome and time-consuming, ultimately involving integration tests to make sure all the pieces fit back together. Rewriting is simply changing a component's behavior and then propagating those changes elsewhere into your system, possibly causing a cascade of changes that may cause a lot of defects and require testing before you're ready for production. It sounds like you're asking more about *rewriting*, and not *refactoring*. Generally, I have no problems keeping myself from *refactoring* because it's hard and often complex. It's far harder than *rewriting*, although sometimes that's easier to do when you're still in the initial stages of your project. I usually do refactor as I can. If I'm already working on a class/component for a particular non-critical enhancement or defect, I will see if I have enough time to clean up the code and spend about half the time refactoring and the other half actually doing the work. This generally works out well as long as the changes aren't too drastic. Occasionally, you do have to just bite the bullet and spend a week refactoring (e.g. adding name spaces) and testing if it's something that just can't be done piecemeal.
Lumen seems interesting, first time I hear about it though, but I love Laravel and I think I should have heard about this before. Any particular reasons you like it? From the top of my head I think that the main reason is the fact that if you want to go from a microframework to a full one with a project done on Lumen, you can just import the code to a Laravel install and it would work perfectly.
I don't use either. I actually prefer symfony &amp; silex. I was just surprised that lumen wasn't listed given the popularity of laravel
Wow this is exactly what I needed. I already knew that refactoring constantly was a bad idea, but I somehow refused to admit it. Your comment oponed my eyes. Thank you sir! 
My case, I see everyday new blog posts about programming and i read them. Later i realized that i'm not producing new things due to track new blog posts or new libraries, methodologies whatever. Innovation does not stop. And very difficult to make the best of the first version. So, i think you should publish release first version. Then, continued to improve it for the best!
I'm finding it marginally easier as time goes on personally. It's when you encounter the super weird bugs that no one on the team has seen before, and you just have to steel yourself for a big debugging session... Bless xdebug.
I wish I could fix the typo, but hopefully you get the point.
[This article](https://crackstation.net/hashing-security.htm) is a pretty definitive guide. It goes over everything and even provides implementation examples towards the bottom.
If you start out with garbage code, refactoring can be an endless, and tedious effort. In my years of programming (PHP included among a few), One common thing I've found to be really helpful is being disciplined about it from the start. It's very very very tempting to jump write in, slam down 1000s of lines of code, and blindly satisfy yourself, that you have something working in the short term, but for the long term, you're going to be constantly building short term hacks. The approaches you mentioned are all well thought out long term approaches to programming, and you're going to them for one reason: to find an organized and efficient way of doing things. So you've answered your own question, really. Good things come from taking your time, thinking of the bigger picture, and discipline, not in your coding, but in your approach to it.
I know that every project has a shelf life of 2 years tops. So I don't care if something is sloppy so long as it's not a problem for users. Everything is duck-tape, no matter how clean you try to make it. 
can you link me to a build that will work first try? that is the intent right? point at your project and have it just work?
I was feeling like it could be related to the nonstrict comparison of $uid to 0, or the handling of $input[0]+0 too, but I keep staring at it and thinking "5" +0 will always eval to 5 and that'll never work. [spoiler](/s "also, uid 5's md5 is from 'hund' but idk the rest of em")
Three suggestions from a fellow sufferer: 1. Remember that "good architecture" actually lets you **delay** making choices about things... Especially when the needs/requirements aren't yet clear. (This is very difficult, since making decisions feels like progress.) 2. Reverse the question: "Suppose this project is extremely behind, and we need some fast-and-dirty coding! What areas or aspects of the project will see the most benefit and least long-term-harm?" 3. Code for deletion. For some-one, on some-day, what you are writing now will seem absolutely horrific and they will want to burn it in a fire. That person might even be you. How can you design it so that they can get rid of it relatively easily when that day comes? 
Cookies are not necessarily strings, their names are array-fied like the names of GET/POST params. For example, you can do `document.cookie='user[0]=123';document.cookie='user[1]=watchthis';` in your browser and get `$_COOKIE['user']` that is an array, not a string.
PHP supports application/x-www-form-urlencoded data in cookies, and will auto-decode that data into proper arrays for you: http://php.net/manual/en/features.cookies.php
Thank you
Hashing passwords in MD5 in 2015... ^FailFish Then again, the company I used to work for didn't hash their passwords at all. In fact, their admin area displayed the password of every employee for any other employee to see, in plain text. Intentionally. By design. I just couldn't...
what in your opinion needs to be corrected?
Quite possibly because the poster appears to be trying to make out that 1 persons opinion in 1 post is any indication of PHP as a whole. It's my personal opinion that posting individual emails from the internals mailing list in this manner is generally a bad idea. This is not a single lone post that is the "official word of god" - it is a single opinion of a single developer as part of an ongoing debate in a larger issue that is frequently linked to a range of other, often wider issues. This post is slightly out of context because it's actually set against the background that up until PHP 7, core functions didn't use exceptions (disregarding the fact that most PHP developers probably don't see or care about a difference between extensions and "core functions" - it's only really a distinction that the core developers themselves make). Obviously exceptions in the engine drastically changes this, but until the random_* functions, nobody thought about whether this policy would change. Unfortunately we're now in alpha phase heading towards beta, and the developers for some reason obviously don't think it's a good idea to even consider pausing the PHP 7 release process to debate and decide what the new policy should be. In my opinion the real issue here is that the developers need to take a bit more time and push back the release of PHP 7 to get the issues of exceptions in core functions sorted (and possibly even consider whether some existing functions want updating to use exceptions instead of their current error handling) so that we can have a clear path forwards and maintain consistency, otherwise this argument will likely rage on until PHP 8 due to backwards compatibility and existing practices, and quite possibly end up creating a further mess of inconsistency where some functions throw exceptions, but some (possibly related) functions don't and the only difference is when they were introduced into the language (which in my opinion is a really bad way to split behaviour).
Deadlines
I adore your efforts on reviewing and letting me know your opinion. However, this article is more of a central idea than thesis. Its just to let people know which are the trending and most popular PHP frameworks these days. Its not a comparison, as written clearly in the first para. Every framework has its own pros and cons and scalability based on which people adopt them. Lastly, I did not wish to profoundly explain any framework and its description. May be this is why description of symfony is irrelevant for you. There are already tons of articles flowing out there explaining beautifully about symfony2 and its graceful features; and I did not wish to ruin or copy their articles. This is why I have kept it short and simple. Remember, the core purpose of this article is to let people (non technical, IT Software related and more) to have an apt idea and knowledge about the trending PHP frameworks. Nothing more. Thanks for your opinion. I heartily appreciate your comments and would love to hear more from you always. 
**tl;dr** Uses `eval()` to create functions. This is as terrible as the Smart-Object library too.
Laravel has "outperformed" because it's spam for a company that does Laravel development. You'll note none of the other frameworks link to a page selling their offerings.
...what? I guess I don't see the use cases for this.
Seems you are a newbie to PHP world. and have not put forward your steps towards researching about Laravel. Go and read about laravel and what laravel developers have to say about it.
Spend 10% of your time on things not driven by user need or without direct user impact. A certain part of your planning should address architecture, code level design, etc. and is not in that 10%.
How else could this be done?
It's all good if you sew the lasagna layers together with enough spaghetti.
Appreciate the plugin! I'm having some pretty good success with it finding nitpicks to fix in some old code.
Hit a nerve did I?
I absolutely agree, but I'd still prefer not to change the source code of my files when I only need to update documentation. I believe allowing `@prose` imports would be the best of both worlds (in addition to supporting multiple formats - RST is better than MD for such technical code documentation). Other advantages of `@prose` includes: - keeps code files small in filesize, easier to download (Composer etc) - keeps code files easily browsable, no scrolling through endless walls of text just to get somewhere - keeps IDEs snappy, makes indexing easier in advanced IDEs which go in depth with docblock parsing - allows community contributions to docs-only, without having to clonefork entire repo, tests, etc. - allows extraction of prose docs into separate entity later on if needed
I still don't understand what it does. Maybe a laymans explanation would be nice.
Glad to hear that) On daily basis it also saves lot of nerve cells (at least that what I hear from people).
Is the bug in question only present on that specific Mac OS X version of PHP? If so, this exercise is almost completely worthless, unless it's supposed to teach you about catering your exploits to very specific systems.
The hosting depends really on the traffic of the website. How many visitors are you expecting monthly? If I were you I would start with a simple VPS. You can upgrade these easily. These packages start for about 10$ USD a month. Make sure you get monitoring on it via SMS or e-mail, in case you exceed bandwidth of experience high loads. If this happens, you can upgrade your VPS if needed. If you need any help: just PM 
Another example. The inspected row is `if (empty($this-&gt;template)) {` The inspection says &gt; 'empty(...)' counts too much values as empty, consider refactoring with type sensitive checks &gt; Analyses 'empty(...)' function usages, which proven to produce issues in type-sensitive contexts. &gt; As analysis performed, inspection suggests to use 'count(...) === 0', 'null === $...' or gives general recommendation to refactor code. &gt; Working out general refactoring recommendation will cost additional development and legacy code reverse engineering, so it shall be planned accordingly. There is something seriously wrong with the English. I'm not even talking about the inspections themselves, some of them may be helpful. But what's the point of the plugin if you cannot explain the suggestions clearly?
@Revisor007 : what shall I change in these messages (why this reported, how to resolve, etc.)? What would be your expectations? 
Laravel will help you learn MVC and application development better, rather than PHP per se.
http://www.phptherightway.com/
You need to have solid understanding oops before you jump into any framework. Make couple of projects using oops and start learning any framework that you wish to learn.
Good luck, I think your plugin will be very useful.
https://www.codecademy.com/en/tracks/php
laracasts.com &lt;----- this is what you want this might be a good start: https://laracasts.com/series/laravel-5-fundamentals
Uncanny
I would start by learning Laravel. There is no point in learning how to write spagetti procedural code. And honestly, you shouldn't waste your time learning low level details. Get started with Laravel and Eloquent. 
You can write non-spaghetti code without a framework.
But it takes longer to write non-spaghetti code (eg, properly abstract things, planning your architecture) than spaghetti code. Laravel lets you write good code, fast. It's the best of both worlds. Why wouldn't you use laravel anyway?
I followed this series on phpacademy to build my own "framework" before tackling Laravel. By doing so, it really helped me understand WHY Laravel is doing certain things, which in my opinion is just important as knowing HOW. https://www.youtube.com/watch?v=c_hNNAdyfQk
As in: '99 problems' + '1 bitch ain\\'t one' === (int)100 ???
I don't get it. What is the link with hailcorporate? 
They still need to learn the underlying language. I wouldn't hire someone who couldn't code outside of a framework. Telling someone to learn a framework instead of how to use a language is idiotic at best. What happens if they learn a framework and think they know how to code, but then get a job that doesn't use that framework. Or are asked by a client to use a system like WordPress? 
I agree with previous commenters, that one guy's opinion doesn't represent PHP as a whole, but this is seriously scary, this Ferenc Kovacs guy doesn't seem to realize the power his bad and lazy decisions have, and what little power he has over the PHP repo, he shouldn't have even that. I know from experience how insecure PHP is, and how writing secure code is actually more difficult than making your program run and handle exceptions, which in most languages is the hard part (re:the orders a beer, orders -1 beers, orders nothing, orders a lizard joke). It doesn't need to be deliberately made any more difficult because of the lazy decision of one developer. I'm happy that the guy replying to him rebuked him so hard and basically called him lazy, hopefully he gets taken down a peg or removed from the main branch completely after this. I mean, imagine if this guy actually got one of his "ideas" into PHP 7, and, say, my bank upgraded their Apache server to PHP 7 without rewriting the application that handles my login to get around the deliberately introduced bugs. I understand that this is just one guy who doesn't have that much power, but he shouldn't have any power at all. I know I certainly wouldn't hire him if he listed being a PHP developer on his rÃ©sumÃ©, then I went through his publicly available emails and found this. I agree that it just doesn't matter that much and doesn't represent PHP as a whole, but this guy...Jesus. He really doesn't need to be on the main branch. If he wants a more consistent PHP, then he needs to create his own fork called "PHP for lazy people who don't care about their clients' security." Or, if he really wants a consistent server side language in which he doesn't have to be too concerned about security, he could just go join one of the many server side javascript projects.
Do you have anything in mind that you want to build? If so, use that, if not find an existing web app that you think might be simple, blogs are pretty common these days, and then break it down into functional requirements e.g. 1. Someone should be able to login as an admin 2. They should be able to create a blog post with a title, content and an image 3. Then they should be able to log back out 4. When they visit the homepage they should see the blog post title and image, with a link to view the content. etc Once you've got something figured out try to build it. I would recommend using a framework instead of building everything from scratch. A framework will handle quite a lot of boilerplate for you, and save you having to get into the nitty gritty until you're ready, whilst still exposing you to good practices and allowing you to make progress. It would be amazing if you were able to understand all the concepts, terminology and structure from the outset, but it can be very advanced and somewhat overwhelming to the point of putting you off completely if you just dove in at the deep end. Take little steps, then explore anything you want to learn more about at your own pace instead of trying to take everything in at once. You'll always be able to do better. Keep building, trying small applications, and bear in mind that Stack Overflow is your best friend. If you don't have a framework in mind, try out Laravel. Get a Laracasts account and look at some of the essential lessons on there first. If you do pursue the Laravel route, then the things you'll most likely need to look at: 1. Routing - that's how you declare which URLs your application responds to, and how it does so. 2. Controllers - your router will pick up that someone is on a particular URL e.g. /login and it's the controller that decides what happens on that page i.e. when you view it show the login form, if you submit the form then try to log the user in 3. Eloquent - a layer represents data from your database as objects e.g. BlogPost, Comment, User and allows you to query them e.g. get the BlogPost whose id is 1 (for trying to view a single blog post) 4. Migrations - how to create portable queries that will let you create and edit database tables 5. Blade - the templating syntax for Laravel that let you display your dynamic content within your HTML code After that there's still Authentication, Commands, Testing, Seeding, Caching etc, but you can have a look at them in more detail once you're ready. From there on, either follow tutorials, or just keep trying to make your application more complex. Continuing from the blog example, look at adding comments, loading commentor Gravatars, allowing blogs to be toggle between Active/Inactive etc, and even look at integrating third-party systems such as Disqus. I find building something always provides a greater sense of accomplishment, whereas following/copying someone elses code is generally tedious and frustrating but I appreciate that not everyone learns the same way.
&gt; His linking to hailcorporate isn't really appropriate though, since a single author writing a book to help people learn isn't exactly what's wrong with our corporate loving society. Yeah exactly, that's why I don't get it ;)
If he do that he will learn to write horrible, unmaintainable code: * no unit testing * no automatic database migrations * no namespacing * no tried and tested coding patterns (e.g. factories, singletons) Modern PHP is very different from procedural PHP. Giving someone a shell *will* make them learn procedual php. You don't want that.
Id say it's a good idea to learn some fundamentals of the language first. Get yourself an IDE and test out some basics from PHP The Right Way and the PHP online manual. Learning about how the parser works, and how PHP is a loosely type language, what sort of data types you can work with, how single and multi dimensional arrays work, how to use syntax in conditionals, create functions, classes, methods and properties. These are good things to know if your just starting out. 
Last time I looked at CodeCademy's PHP stuff it was a pretty great example of how _not_ to write modern PHP. Additionally, their app has some major flaws, given this code: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; &lt;?php echo ""; ?&gt; &lt;/p&gt; &lt;/body&gt; &lt;/html&gt; and the task: &gt; We've written a little PHP in the editor to the right, but it's not complete! On line 8, type `My first line of PHP!` between the `""`s. If you do this: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; My first line of PHP! &lt;/p&gt; &lt;/body&gt; &lt;/html&gt; And click "Save and Submit Code"... it gives a success message. It does not in any way validate the input to ensure you're writing it correctly, just the output.
I read [this article](http://www.johndcook.com/blog/2013/07/25/too-many-objects/) recently about over-classing. I think it always just depends on your needs. You may need to work with a user's email address a lot (searching by domain or some other such thing) but if all you need is validation, maybe just write a function that returns bool, and if you need to pull out part of a phone number, it's possible a function with the right regex could do that just fine. It would not be an OO approach, but this is a scenario where you may not need it. But, again, it depends on your needs and the context in which you are using this data in your application. 
Give me ONE example of a monolithic php code base that isn't spaghetti, and is written without a framework (an off-the-shelf one, or an internal one built for an app). Quite simply, I don't think it exists. If you architecture your app well and follow good design patterns, you will end up with a framework. So why would you make apps w/o a framework? Laravel scales from micro-services (Lumen, subset of laravel that is 100% api compatible) to huge complex apps. Laravel teaches you how to write good code. Laravel has an active community. I am not saying Laravel is the best framework. I think it's good enough that you can write amazing web apps without ever learning anything else. Yes, I agree with you on that Laravel doesn't suit all needs. But I disagree with you on that it's not suitable for the majority. I respectfully proclaim it is (Laravel being Laravel and Lumen)
&gt; Modern PHP is very different from procedural PHP. Giving someone a shell will make them learn procedual php. You don't want that. The point is that he can write modern PHP without a framework. IMO it doesn't make sense to directly jump to a framework without learning the language itself first.
I never said to not use a framework â€” though I absolutely _have_ come across applications where using one would be detrimental. Where MVC wasn't the correct pattern. There are many ways to write a framework, that's the point. No _one_ framework is the right answer. Additionally, "monolithic" is a problem in and of itself that we're working to solve with SOA and microservices architectures. We _know_ this isn't the best way to write applications, because it doesn't result in easily maintainable codebases, _regardless_ of framework use or not.
["Scientists were so preoccupied with whether or not they could, they didn't stop to think if they should."](https://www.youtube.com/watch?v=lpuS7_NPv6U) The big question here is what's the use case. Maybe there is one, but it's not explained in your readme. In order to find your library useful we need to find some... use for it. Please don't read this as me saying your library has no uses. Read it as an invitation to discuss its uses.
And you can write spaghetti code *with* a framework.
Did you manage to solve the challenge?
The only idea I've had so far is to somehow (ab)use the type-juggling system and/or integer handling of PHP by trying to introduce some second element at $input["0"] which will return 0 when used in line #56 but will still successfully pass the comparison on line #54. I tried using integer overflows (e.g. (PHP_INT_MAX*2)+2)) or something like 0x100000000 but the ultimate value of $input remains correct. It would be interesting to know if I am at least working into the right direction here!
Agreed with this. I started creating my own framework for learning purposes, forcing myself to build things I'd never built before: router, ORM, authentication/session with configurable drivers (really got an appreciation for interfaces and adapters!), and a DI container (modeled after pimple). Once I understood some of the inner workings of the basics, and how much code I had to write, I was able to better appreciate what something like Laravel was doing for me. Laravel is basically the framework I would have created had I just kept going.
This post is specific to learning laravel, and i would assume is getting downvotes for the same reason /u/goldcakes is.
The cost of creating objects and calling functions is so minimal that the performance impact is negligible. My rule is always use value objects unless I've seen benchmarks for the request that show the performance impact to be substantial.
yeap 0x100000000 works :)
&gt; The cost of creating objects and calling functions is so minimal that the performance impact is negligible. That depends on the project complexity, the amount of data you deal with, and the amount of load you get. If it's minimal, more power to you. But I wouldn't make a blanket statement about it, because from my experience the cost quickly adds up, while the benefit simply isn't there for many value objects. Let's take an example from OP's post: email address. What kind of functionality would this one encapsulate to justify its existence. Validation? Sure, but you can validate at your endpoint when accepting user input. Reading just the username or the host maybe? Not exactly a common use case (never had to do that yet unless I'm implementing an SMTP server...). &gt; My rule is always use value objects unless I've seen benchmarks for the request that show the performance impact to be substantial. Refactoring code which relies on value objects throughout the entire pipeline, to *not* use value objects in some places after-the-fact would be quite painful.
Well yeah, but I can't figure out how to (a) get the comparison in line #54 to work (except for uid = 5 and password = hund) and (b) even if I managed to get past #54, how I would introduce some element at $input[0] which == 0 in line #66. :(
I can say you are on the right track, 0x100000000 can be used for this but not directly if that makes sense :D
Cool - yeah, I am doing things like that already, just thought I might be reinventing the wheel and that someone else might have already done the ground work. The idea of throwing an exception in the constructor (how I do it), rather than an isValid() method, but allowing anything to be constructed I assume is common practice?
Awesome - Value Objects is exactly the term I was looking for. I agree with the sentiment that using them adds overhead etc, but I really like the idea of being able to just know that this instance of Person which owns this EmailAddress and this House which is at this GeoPosition is all just working - right now I have situations where the big things are 'real', e.g. Person and House, but the smaller things (email, lat/lon, distances) are all just strings/numbers that may or may not be valid and may or may not be what I thought it was - I can see that the overhead could add up in many cases though.
In case this is useful, I can **highly** recommend Treehouse - the only word I can really use to describe them is **incredible**... https://teamtreehouse.com/features#how-it-works For you specifically, check out: http://teamtreehouse.com/library/topic:php
it can be done without eval with a wrapper class 
&gt; Those hacks from Gang of Four tried to redefine what "Facade" means, but we know Taylor's definition is the real one! LOL ;-)
Awesome. Looking forward to seeing it; I'm thinking it has something to do w/ an integer overflow in array keys but I just can't seem to wrap my head around it. 
Here's a tutorial I wrote last year - [how to build a blog](http://ilovephp.jondh.me.uk). There's quite a lot to work through and learn, so don't try to do it all in one go. It's deliberately simple - no framework or ORM - but there's some SQL, some modularisation, and a login system. Security issues like SQL injection, XSS and password storage are all considered. 
I suffer from refactoring as well, even at work. I start on a simple task, run into some ugly or badly readable code, start moving things around and without even realizing it I'll have spent several hours refactoring our code base without completing the task at hand. I try to keep myself from doing this, but I'm so easily led astray it's frightening. My solution was to create a branch for stuff I want to refactor and work on it later. This allows me to complete tasks on time and be content with the knowledge that I'm not skipping over bad code, just prioritizing.
If you are working with a group of programmers and you are bringing in new ones over the course of the projects that use value objects, it is important to make sure that they are aware that they exist and that they either don't use their own sanitation for email/phones or they recreate the value objects themselves. Consistency in using value objects is the key to making them efficient in your projects.
Yes, OOPS (!!) for the win.
I thought I should mention that if you read his entire post you'll find that he's actually taking a piss at Taylor Otwell and Laravel in general. The post is missing the /s tag. Or I could be wrong.
I agree with you and followed a similar path. I wrote a complete framework bottom up. After going down the performance, security and refactoring rabbit hole, I then decided to wrap a custom framework around slim (2) using some Aura, Twig and illuminate/database|PDO (for ORM|SQL) components - plus a few custom solutions. I learned a lot from various frameworks, taking the bits that I preferred over any specific framework. I also learned a lot about PHP that I hadn't considered before.
Have you tried using Laravel's error logging library? It might solve your need: http://laravel.com/docs/5.1/errors
Are you using the composite driver? You can set it so the Ephemeral driver sits in from of the SQLite driver and acts as a per-process cache to reduce some load if you're making multiple calls to the same cached item. You can also use APC and SQLite to have a more persistent in-memory cache without going full blown memcache. I'm the author of Stash so if you have any questions let me know.
We already have the second beta, alpha phase was pretty short.
You're full of shit...
AKA glorified router. There is no such thing as a microframework. 
You could easily write a token parser for sage: http://github.com/dotink/sage
Thank you!
Thanks for that! I did mean to put private(fixed now), that was a mistake although I wouldnt have picked up on it. In terms of the P in LAMP, I would generally use it to refer to PHP but a lot of sources also use it to refer to Perl or Python which is why I have made reference to them here. I really appreciate the feedback- this is the first time I have tried my hand at blogging so its great to have people read it! Thanks again :-) 
Symfony's container reinvents some concepts we have in OOP, like a basic object container where each method returns a dependency (reimplemented by Symfony as an object where different string values you pass to get() return different dependencies, i.e. the same as methods, but stringly-typed). I haven't explored tags before, but I've long suspected some reinvention would cause more reinvention: tags reinvent [marker interfaces](https://en.wikipedia.org/wiki/Marker_interface_pattern), and interfaces in general (note how the example rules are already instances of Rule, why the redundant tagging?). Reinvention aside, the problem is when you *look up* services by tag, you're looking them up throughout the container, i.e. this *global* container, which applies to your entire app. This doesn't help you get away from the container-as-a-global-service-locator problem, it only makes it worse. You shouldn't be looking up services from the container, by tag or any other way. A dependency can encapsulate the lookups, so they can be contextual to the one doing the lookups, not global. Also, while I realize this is only an example, I'm seeing more logic in those controllers than I find comfortable. Assembling rules and wiring up plugins is typically not a controller's job. A controller's responsibility is to deal with the media (HTTP) and utilize already configured services, in order to carry out a specific action through them, and produce data for a specific view (or a set of views). Anything else is domain logic and belongs in a domain service.
I think your experience is something most of us can relate to. At least i know i can. Also at work, where it often makes a simple task take a longer time, or if i am doing a review for someone i will get real anal about the overall implementation, if it isn't "the best it can be". A colleague of mine and me also have a "contest" where we keep changing each other code into what we personally belive the purist thing is. Sometimes that leads to stupid arguments, other times it is fun.
Thats awesome... I don't have any reason why installing 'bare bones' would be a better option, its just another option, and may be closer to a lot of existing production environments. Plus you don't need to install sort of virtual machine manager, not that that is much of a problem. I will definitely check out these options in more at a later stage, they do look like a very beginner friendly way to get started with PHP development. Can you use either of these options in a production environment? If so, does it have an effect on the performance of the application? 
Only reason I can see to use barebones is laptops where you travel a lot and want to work as well. VMs and containers eat battery like cake. I would suggest using Nginx and PHPFPM which is becoming more standard install on servers these days.
&gt; either of these options Provisioning, yes. People use provisioners a lot when setting up live servers. They're particularly useful for clusters, where a single command sets up multiple servers to be identical. Vagrant, no. You wouldn't use Vagrant for anything other than development. Vagrant is there to help you set up your local development machine to be identical to your target deployment machine, that's all. The main purpose is worry-free local development that matches production as closely as possible in terms of software used.
IMO, [this box](https://atlas.hashicorp.com/ubuntu/boxes/trusty64) is just fine for most use cases. Use it as a bare-bones LTS Ubuntu server onto which you install whatever else you desire.
&gt; The Symfony container allows you to call methods as well. Eg. a service defined under the name "cache_warmer" is available either under $container-&gt;get('cache_warmer') or under $container-&gt;getCacheWarmerService() I can't find this in the documentation, I wanted to see for what purpose are two ways available to do the same thing. I hope it's not "so the user can decide what they like" - that's the component designer giving up on their job. &gt; In my opinion it's helpful to centralize the information to one definition. You can quickly see what tags are there. I'm not sure what you're trying to say? Tags are there to facilitate global container lookups. What other purpose do they serve? Why would you have tags, if not for that? &gt; As for the "globalness" of the container, you shouldn't really access the container directly and you can avoid it in all code. As long as the container is a *property* of controllers, that advice doesn't match Symfony's reality. Just look at OP's tutorial.
&gt; I'm not sure what you're trying to say. Whether you lookup services by their tag or by their interfaces, as in the Marker interface pattern, I find it useful to centralize what service is tagged/marked with what. Controllers can and should be defined as services and not access the container directly. http://symfony.com/doc/current/cookbook/controller/service.html As for the methods `get...Service()`, I'm sorry, I was mistaken, they are generated only for internal use and marked as `protected`.
Given that PHP7 is now in beta and thus in a feature freeze, I would limit my selection to books covering PHP7. It may mean that you need to wait a month or two before buying. In the mean time, http://www.phptherightway.com is always a good read. :) Cheers! =C=
How would you implement the behaviour talked about in the article, then?
While I don't think readers should consider the controller code as anything other than test code, the article is correct about how tagging works (and how it is used in many bundles). Just some nit-picking with the naming convention though: Rule should be named RuleInterface. 
If you're a programming beginner, I've heard http://www.amazon.com/PHP-MySQL-Web-Development-4th/dp/0672329166/ref=sr_1_1?ie=UTF8&amp;qid=1438522019&amp;sr=8-1&amp;keywords=php+and+mysql+web+development is good. A fifth edition is coming (http://www.amazon.com/MySQL-Development-Edition-Developers-Library/dp/0321833899/ref=dp_ob_title_bk), but not until 2015-11-22.
The behavior in the article seems like a very indirect, meta-approach to produce a few lines of initialization code for a "rule manager". Instead of all this, I'd just write the initialization code in a closure and end it there. Now... that obvious solution aside, let's explore why: - In a real application you'd have more than *one* rule manager, and they'd have different rules (this looks like a validator: you probably validate more than one type of data per project), and this scheme with global tags can't do that, demonstrating the very weakness I'm talking about. - In a real rule engine, the order of the rules often matters, another thing you can't control in this one. - If we assume we have just one rule manager, and we insist the rules be specified in YAML, I'd rather have a rule-manager.yaml, which lists rule classes the manager should add to itself, which is better than putting everything in a global container config and using tags to tease it apart again. I'm not beyond a system that auto-detects its plugins and so on, but the problem has to be better formulated for me to provide a solution. "Adding rules without writing code" seems very arbitrary as a restriction, especially as the YAML required is just as verbose (in fact, more) than the PHP required to achieve the same effect. **EDIT:** Better formatting.
Laravel Homestead *is* a Vagrant box, so your question is orthogonal. Also, regarding that article: &gt; Vagrant VMs are brutally fast to use â€“ with no graphical elements to take up valuable CPU cycles and RAM, the VM is as fast as a regular computer What a load of shit... I've *NEVER* worked with a VirtualBox VM that had less than a 1200ms latency compared to working natively. That's true on my MBP, was true on my old Linux box, and true on my gaming rig. VMs are slow as balls compared to working natively, and it's frustrating because sometimes it's hard to tell if its slow because of something I did wrong in my application code, or slow because it's in a VM. So how exactly does one set up this mythical VM that is so fast you can't even tell it's in a VM?
Dayle Rees just released https://leanpub.com/php-pandas, if his laravel books are anything to go by it'll be fantastic.
There is nothing similar about them.
Tags are just another way of making collections in the container. E.g. instead of having a `logHandlers` array (where each module can add a new service to this array) injected into `$log-&gt;setHandlers(â€¦)`, you have a `logHandler` tag and you have to write a compiler pass which will call `$log-&gt;addHandler(â€¦)` for each tagged service. It's not a reinvention, it's just a different way to solve this problem.
&gt; Rule should be named RuleInterface. http://verraes.net/2013/09/sensible-interfaces/
&gt; this scheme with global tags can't do that, demonstrating the very weakness I'm talking about. Global tags aren't a requirement, you can add additional attributes to tags and target different services. See how [monolog bundle](https://github.com/symfony/MonologBundle/blob/8c5e0923025d00c950cfc47f4026e122bd4cfec0/DependencyInjection/Compiler/LoggerChannelPass.php#L38-L40) does it. &gt; In a real rule engine, the order of the rules often matters, another thing you can't control in this one. Again, additional attributes. See [security bundle](https://github.com/symfony/symfony/blob/9fea451295fd0e8c70f52ae154bcbfa0c1c13f53/src/Symfony/Bundle/SecurityBundle/DependencyInjection/Compiler/AddSecurityVotersPass.php#L37). You can use a priority attribute to control order. &gt; If we assume we have just one rule manager, and we insist the rules be specified in YAML, I'd rather have a rule-manager.yaml You can do this with the container. Using an import or load multiple files via an extension. There's no saying you need to centralizing everything in one config (or even use configuration files at all). Here's [an example](https://github.com/symfony/symfony/blob/9fea451295fd0e8c70f52ae154bcbfa0c1c13f53/src/Symfony/Bundle/FrameworkBundle/DependencyInjection/FrameworkExtension.php#L53-L55). &gt; the YAML required is just as verbose (in fact, more) than the PHP required to achieve the same effect. The YAML is not required. You can do XML or PHP as well. Using a closure, like you mentioned above, can't be done because Symfony actually writes a class out with all of the `getSomeService` methods in place. In production this only happens once so the container ends up very fast. If you wanted to centralize your creation logic in factories and then just use the container as a bit of glue for the actual Symfony related stuff, it's easily done. Factories can be objects or static methods. Not sure about plain functions. Here's a PHP example: &lt;?php require __DIR__.'/vendor/autoload.php'; use Symfony\Component\DependencyInjection\ContainerBuilder; use Symfony\Component\DependencyInjection\Reference; class Foo { } class Bar { private $foo; public function __construct(Foo $foo) { $this-&gt;foo = $foo; } public static function factory() { return new self(new Foo()); } } $container = new ContainerBuilder(); // using the container to assemble things $container-&gt;register(Foo::class, Foo::class); $container-&gt;register(Bar::class, Bar::class) -&gt;addArgument(new Reference(Foo::class)); // or use a factory if you like $container-&gt;register(Bar::class, Bar::class) -&gt;setFactory([Bar::class, 'factory']); var_dump($container-&gt;get(Bar::class));
No, it works on any os.
But keeping the practicality in mind, consider how many live installations of Wordpress, Drupal, Joomla, etc. exist that have hardly reached 5.4 yet. They are not going to upgrade to 7 any time soon. So, "real php programmers" still have to work with 5.4 or maybe even lower! In a parallel world, a similar situation has arisen with `Python` where all the zeal is towards Python 3, but the industry doesn't want to leave the safety and stability of 2.7 anytime soon.
If you want to install packages by hand, please stop installing php5-mysql and instead go with php5-mysqlnd. More info https://dev.mysql.com/downloads/connector/php-mysqlnd/ and http://php.net/manual/en/book.mysqlnd.php
Not quite as incorrect. ViolÃ© would be raped as in he was raped. Viola is raped as in he raped.
I am very surprised to see you use *that* particular term. "Modular architecture" is defined as one where you can replace a component without affecting all other components. It's about *isolation* first and foremost, and not about having them get automatically wired through a central locator and "synergize" by themselves through magic feature-detection. In particular, in a modular architecture the default expectation is you never have guaranteed singletons, you never architect to have *one* of something, and that includes *one* container, or *one* configuration of rules fed into *one* rule manager. What's being demonstrated here is the polar opposite of "modular architecture", it's "integrated architecture" (not to use a pejorative "monolithic architecture") where things fall in place on their own through conventions and global hubs connecting components in a non-contextual way. Integration is actually really nice, up to a point of complexity at which it stops scaling, but modular it isn't. If it's modular, by definition it holds no global data. No application-wide containers, no application-wide tags, no application-wide rules and managers. Global and modular are incompatible concepts.
Yeah because it's a good starting point for learning how modem web apps work. 
Go read the comment stream following /u/goldcakes and you will see all the rebuttles you need against laravel in this specific case. 
As I said, if you want *integration*, fine. But don't call it modular. To take your example (whose validity I won't discuss :/), a modular architecture is one where you can have multiple instances of Twig: - one without gravatar() - one with gravatar() - one also with gravatar(), but a differently configured gravatar(), distinct from the second instance. And you can mix those and use them in the same request for different sets of templates, without them touching shared data and stepping on each other's toes. In contrast, bundles make a lot of "there's *one* of..." type assumptions to get their plug-and-play magic happening. Extensible, but not quite modular. I also have to question how "complex" it is to wire components together manually. Bundles are not for end-users, they're for developers, surely a developer would have no problem doing something like this: $twig = new Twig(); $twig-&gt;addPlugin(new GravatarPlugin()); Is this considered too hard for a modern PHP developer?
I work inhouse as a developer, and I mainly use PHP and Laravel to develop a lot of little applications. I mostly use Blade and a few css frameworks for display, but I'm thinking in using a js framework like vuejs and use Laravel as an api though.
I split projects in modules: - services (API endpoints which can be called either natively via PHP, or from JavaScript via HTTP XHR calls). - apps (router + controllers + templates). An app has no domain logic, it's just the UI logic. All domain logic is in the services. As such, every app relies on multiple services to do its job, without them it's just an empty UI shell with no state (aside from current session). A typical project contains 2-3 apps (public site, private site, blog etc.) and around half a dozen to a dozen services (for medium-size projects). I mix freely PHP controllers and client-side JS, because, as noted, an endpoint is accessible equally to both (so I can decide ad-hoc how to proceed for a specific feature). This blurs the line between "HTML content from the server" and "HTML content rendered in JS from API data from the server". The distinction is no longer as necessary (I only need to ensure I render enough from the server for SEO purposes, nothing more).
Laravel, or Lumen, depending on the size. I guess I'm hooked on this stuff. 
It's not too hard, it's just un-necessary trouble in most cases. The proof is how popular Symfony (and its bundles) are. You just install a bundle and that's it. So I understand your point, but: - in many application you only need one container, and the "magic" happening is useful - in cases where you want to build a "modular system" (the way you mean it) you still can with Symfony Nothing prevents you from creating entries `twig1` and `twig2`, and registering the Gravatar Twig extension manually in `twig2` only. Granted, building a whole application like that with Symfony is maybe not the easiest, but it's definitely possible. And I understand that in that case, closures are more practical. I think my main point is that you are criticizing a feature that most developers use, and that benefits a lot of people. It has drawbacks, sure, but for most applications it's perfectly fine. So instead of a "tags sucks", I would rather say "they have limits". PS: when I say "end-user" I mean developers (which are users of the framework).
tldr?
What hosting company are you using? Certain hosting companies have different rules regarding using the mail() function. Example: for godaddy hosted websites, the from address has to be similar to example@yourdomain.com.
There's this marvellous little thing called SPF which recipient mailservers use to filter unauthenticated mail as a way of reducing spam. Gmail.com has an SPF record set in its DNS which tells recipient mailservers what hosts are allowed to send emails on behalf of gmail email addresses. Since your system's hostname/ip isn't in their SPF record, your email is unauthenticated, so its being filtered by the recipient mailserver (also gmail). This is to prevent email spoofing- i.e., whats to stop you putting any email address that you like in the code? The solution is to configure your script to connect to an SMTP server and send messages through it. The SMTP server will take authentication in the way of an email address and a password, so it knows the message is genuine, then it'll send it for you. You'll need to configure your script to go through gmail's SMTP server in order to send emails from a gmail address. Hope that helps, let me know if anythings unclear!
Shared folders strike again. I have resorted to copying code to the "native" fs inside the vm and sharing that to the host with samba. This is a real PIA and is confusing because of the two copies of the project. I wish there was a better option.
&gt; Rule should be named RuleInterface. Eeeww, no... If you're using interfaces properly, they're the platonic ideal whose name you'll be typing 99% of the time, so it should get the "better" name. Even if you're excessively starved for descriptive naming, I'd still rather see `interface Thing` and `class ThingImpl` than `interface ThingInterface` and `class Thing`.
It becomes more noticeable as the number of source files, dependencies and so on grows. With php projects I haven't noticed as much, but for ruby/rails and node it's the pits. 
I use the Yii Framework primarily. My development is done in the NetBeans IDE. I am curious what IDE other people prefer.
I tend to have the client side responsible for the user interface logic and little bits of business logic such as validation. Then on the server side it's usually a REST API, although more recently I've been using a library called Ratchet to serve an API over web sockets. The server side is doing most of the business logic.
If you are stuck on hosts without SSH, but would still like to use Composer, you have two options: * Use Composer in a local build environment, assemble your application, and upload your files to your remote server (ideally with `rsync`, but whatever you have) * Push your changes to the remote environment and then run Composer using a PHP script Note that good shared hosts will offer SSH anyway, sometimes for a small extra fee. And, though there's still value in shared hosts, VPS machines are _so_ cheap now anyway. 
Sadly, I have nothing publicly to show.
Thanks for the response. Honestly I don't think in terms of oracle or mssql because having started from mysql, I look at both as heavy databases which I generally don't need. This is probably why I have never tried postgresql since I assume that it is going to be overkill. 
Thanks for putting this in front of me. I've been familiar with Dayle Rees for awhile now. Had no idea he wrote this. It looks like a perfect answer. Or idk. Maybe some o Reilly book from the 90s is better 
&gt; I've NEVER worked with a VirtualBox VM that had less than a 1200ms latency compared to working natively "_What a load of shit..._" right back at you. I'm not sure what you're doing wrong and I wish I could help you, but I use behemoth projects often on both Windows and OS X hosts with Vagrant, and everything flies.
PHPstorm has changed the way I code. I'm never turning back. 
I use PHP as purely an API to several databases. I also use it for PDF report generation because PDFLib kicks ass. 
Yeah it is pricey, but we keep a maintenance contract just because of that. We use it a lot. I've got a report builder I wrote forbusers to have a JS front end and create their own reports from DB fields. It's used heavily. But I will look into wkhtml2pdf because I like cool stuff. 
&gt; All it really does it show how to install packages, set permissions and start services on boot. As in what you need to do if you want to set up a dev environment without using Vagrant? &gt; Pretty much nobody should be installing these packages on their host machine anymore unless they can't run a virtual machine for some reason. Hopefully these people will find this tutorial useful then :-p
Great thanks for the links, I will update the tutorial accordingly. I have only had limited experience with PHP(through uni a few years back, done a lot of programming in other languages though) and I am just coming back to it as I have a job opportunity with it. Cheers!
There's no hard limit - this is most likely a configuration error of some sort. The server config can restrict what things you can change via an ini setting in your script -- are you setting the memory limit within the script itself, or within the php.ini file? Edit: Wow I totally misread the question. If you've set the max to higher and your script won't use more then it probably doesn't NEED more (or more won't benefit it). More RAM does not always mean faster code. 
A couple of things: * What do you mean it's timing out? What error message do you get? * Are you running the 64bit version of PHP? This is likely, but you never know. 
You can make a big form and conditionally hide parts of it with JavaScript.
That kind of thing generally uses Javascript, a front-end language. Might have better luck on /r/javascript. Great question though -- very ambitious for a new programmer! Good luck!
Why is it that I don't have write access to a folder on FTP that I want to upload images to, but the Joomla application that the site is running can create folders in the same location.... BUT when I upload a script (to the root which I seem to have write access to) to do the same thing *that* can't mkdir either? I'm just trying to upload a bunch of images for a friend to his site, and the last time I spoke to the host I got the message that he doesn't want to provide support because this particular hosting was a favour, so I'm trying to do it myself. If Joomla has write access, then surely my own script would too?
I will certainly give it a try. I am glad I asked.
What would be an accepted/sane way to install node? Straight from the repos (people complain about packages being old), or from the nodesource repos? Or directly from Chris Lea's PPA?
As a phpEd user since 2006, you've got my attention...
Give it a shot. 30 day trial. Jetbrains makes resharper for visual studio and intelliJ for java (which is extremely similar to phpstorm but java specific). Awesome plugins too for various types of files and languages
There are two methods to accomplish this. 1: Use JQuery to show/hide divs based on selections from above options. Generate the entire page at once and hide the data not needed until option selected. 2: Use Ajax in JQuery to actively ask the server for the new information to show based on options selected. This is a bit more fun on the back end and allows you to send a smaller page to the client. My preferred method. A lot of fun to play with, but takes a bit more to make happen.
If it's not reaching the limit assigned, then it's using all the RAM it need. If your script is timing out, you may need to run it from the CLI as there are no hard time limits on the CLI normally I think. I personally know I've run scripts that used as much as 2.5GB and took more than 30 minutes to complete, naturally run via the CLI though.
On a Macbook Air/with an SSD drive; Vagrant isn't always the most practical solution. I prefer to use local (to host) PHP and SQLite as much as possible. Quicker to boot, less resource-intensive, cleaner projects. &gt; Vagrant has pretty much become a standard for doing development work Or Docker...or whatever tool comes along next month. So no. Not quite standard. Good, for sure. Useful often. But not standard in the way many people take standard to mean. Certainly not a clear difference between developers who know and developers who don't.
This. Also, it might just be a lot easier to use built-in Apache and Homebrew PHP (for extensions/versions). That's the only reason I still happen across Apache these days...
Emacs
This is simply a stupid question because I don't know where else to file it. It surely doesn't deserve its own thread. What can I do better to reach more people and, in turn, spread the adoption of good software security habits? I do a fair bit of security research. I do a fair bit of blogging. I do a fair bit of editing StackOverflow. I maintain an open invitation to ask me if a StackOverflow answer is secure or not. Recently I've set my sights on improving W3Schools. Not because it's great and deserves to be propped up, but because it is popular for n00bs. In my spare time, I'm working on a free/PWYW eBook for PHP 7 development with the intention of exposing new developers to secure habits by default and teaching a simpler way to think about security. (Taxonomy, not checklist.) And in the background, I'm working on ideas for PHP 7.1 and a few penetration testing tools that I intend to make public in the near future. (And yes, believe it or not, I *do* sleep.) Would it be worthwhile to pursue podcasts, guest blogging opportunities, and the like to help increase exposure of better security practices? If so, does anyone have any suggestions on where to begin?
Your FTP user probably has different privileges compared to the privileges set on whatever is running the PHP script. 
In my opinion symfony didn't get dependency injection right. Instead of tags, it should have scoped injection with something like a composite DI. But it can't have that because of the symfony middlewares work. The rest of the framework is great, but Symfony container is just horribly complicated. 
Ordinarily when you click a link on a website the **browser** makes a request to the server, e.g. `GET http://site.com/users`. It receives a response containing the HTML, and links to style sheets, scripts, and images which it then loads and renders. What professor_simmons approach does is separate the responsibility properly so that the endpoint /users simply supplies user data (usually in JSON format). You can then write **clients** to make requests and render the data for any browser/device/etc you want. In other words, you go from the server rendering a page to the server supplying data to a client that renders the page and you get to reuse that data end point on all your different clients. HTH
&gt; Having a container span your entire application and use it to pile all shared objects in there is not very different from [static classes and global variables]. I see a very big difference in that developers can use dependency injection with all its benefits (code is unit-testable, less coupled, etcâ€¦) I don't think it's fair to say the PHP world hasn't progressed. And, as I said, most application don't need multiple containers/modules as you describe it. For the not so common applications that do need it, that's a reason to hire someone more qualified ;) In other words, I think it's fair that frameworks address common use cases. I don't expect to build a very complex application with Symfony full-stack following their standard practices and using all the bundles I can find.
I personally would rather have a host of tutorials to choose from than not enough. I just had to do this the other day and had to refer to a few different texts in order to get everything running properly, I thought I would just write up what I ended up doing in case it helps someone else. I will get to more interesting stuff at a later date- this was my first attempt at writing a tutorial, I wanted to start with something basic. If you have any ideas for entirely novel tutorials I am happy to take suggestions :-)
imho, work on the penetration tool you talked about. If your skills are as good as best as they can be, I think you'll be able to make one that people will be using it in no time, after all who doesn't want to scan their php sites for vulnerability and it will inevitably take of by itself. This is considering if the tool is good, and it will penetrate atleast some php applications out of the box. 
You might find [mikehaertl/phpwkhtmltopdf](https://packagist.org/packages/mikehaertl/phpwkhtmltopdf) a useful package for playing with wkhtml2pdf. This makes it easier to use the binary.
Thanks for taking the time to detail all that, you got me very interested. What I could find about Jigsaw and MinWin was cool, but do you have any link on that topic regarding web stuff, or even PHP? Do you know any framework (PHP or other) that works that way, with several isolated modules and containers?
Yes, but you can custom anything :)
Just my personal opinion - you don't go to a conference to learn from the sessions. You can always do that later on YouTube. It's not even about asking questions, or attending the workshops. You go to a conference to meet people, forge new business relationships, probably recruit new developers. Talking to people creates opportunities. In short - networking. If you don't plan to do a lot of networking there, maybe it's not worth it. If you're running a company, however, networking is a huge part of your company's long-term success.
Thanks. FYI (you maybe know about this but) there has been a lot of discussion on PHP-FIG about container interoperability, and one of the most controversial point is whether there should be multiple containers in one application (i.e. each module would have its own container, and they could all communicate in some way). The current direction it is taking is trying to come up with a configuration format or interfaces so that modules can add configuration to a single container. It would be great to hear what you have to say about this on the mailing list. I cannot guarantee that people will listen to you though ;)
I'll check it out. I feel the very debate about "container interop" shows the container is exposed in some way to services to read from and write to. This really makes it a service locator, which is the opposite of DI (with DI where you can use *any* container already, because the services are "POPO" asking for "POPO" method arguments, nothing more). Probably the thing FIG needs to figure out is why are they trying to standardize service location, when everyone else is trying to move away from it (for most purposes).
Yes, in most of the cases MySQL will be enough (not MariaDB or Percona), but if mysql isn't feet your needs (You already use mariadb for some reason), then you probably should try PostgreSQL.
Why do you need to create named functions? You can easily do $hello = function() { ... } $hello(); Alternatively, make a simple method that runs the function, like `SmartFunction::run('hello')`
You can use sublime for free as long as you want, actually, but you won't be debugging with it. A good debugger saves much time for a developer at any level.
Yeah, sure. That's why I called it "just a text editor", even though it's a bit more than that. I don't doubt that I wouldn't regret paying for phpStorm. I just kinda feel weird paying for phpStorm, while using mainly open-source code in my projects. I know it's worth it, but it kinda feels weird. 
&gt; Recently I've set my sights on improving W3Schools. Not because it's great and deserves to be propped up, but because it is popular for n00bs. I'd suggest finding some blogs that post good PHP tutorials and trying to support them over w3schools. Sounds like an impossible task, but if you search for CSS/HTML stuff you should find that CSS-Tricks and Mozilla regularly come above w3schools nowadays. It would be great to do the same for PHP.
What kind of script is it? Are you sure you need that much memory?
You could use the [post-autoload-dump](https://getcomposer.org/doc/articles/scripts.md#command-events) hook. Strange setup tho.
Thanks for your response. I don't have the option to use the CLI here. I'm adding more actions to Redis to perform in the background if I can, do you think I'd hit the same limits here? 
Hi. I'm not too worried about it being faster, I just want it to run to completion. 
Its part of a HTTP request so I think you are right. I've been trying to break it down and sending some work to queue actions. Its hard though as some steps in the code rely on each other. If I move fully over the using queued processes do you think I'll hit the same memory limits as a http request?
Yes. Of course. Again, I think it's a really good product. I just feel weird being dependant on a product that includes licence-costs each year. But I sure do value a good, working Dev-Environment and I'm aware of this being a personal issue of mine :-) It's just easier to say a tool is worth it, if you have already gotten your value out of it. Mountains always look bigger from the base. 
Maybe contribute to the security section of http://www.phptherightway.com? 
&gt; " With some delay" I second that. Worst thing you can do is force yourself to continue without a break. Best thing you can do is just let it be for the moment and to try again later. Sometimes, going to bed is the best option. I've been waking up in the middle of the night, just to write down the solution of a problem and go back to sleep several times. If I had pushed myself to stay awake and work on it, I probably wouldn't have solved it. Our subconsciousness is probably the best problem-solver there is on this planet. We just have to let it do the work. 
Any application is only as secure as the developer(s) who built it. This is true for any language. If you are implementing classes and functions, please know exactly the return values and certain edge cases. In that regard, I feel they should keep evolving PHP to be consistent in what exactly is returned, instead of '99% of the time you get this, but sometimes, you might get _this_ instead'. Classic case of old guard being lazy.
Can I just add, aside from us all trying to answer it in the comments, that I really like this idea. +1 to making this a regular thing. Would also be good for OP to post the correct answer &amp; explanation a week or so after it's been cracked.
Yeah, that needs an overhaul. Bound parameters doesn't involve escaping, it sends the params in a separate packet and makes injection impossible.
&gt; probably Understatement. :)
Yikes, they start with OWASP's Top 10? Yeah, I'll see what I can do.
http://blogs.technet.com/b/johnla/archive/2015/04/26/defenders-think-in-lists-attackers-think-in-graphs-as-long-as-this-is-true-attackers-win.aspx Teaching the OWASP Top Ten to an absolute beginner is going to make the checklist mentality more prevalent. I'm working on a proposal for a better model to understand security that doesn't require checklists.
fair enough, but also companies are starting to require it/request it in tenders/audits etc. BS I know, but its a real world thing.
It's not *wrong*. I just don't think it's the best place to start, and if someone ignores that fact that there are plenty more vulnerabilities (11 through infinity), they're going to have a bad day. Also, many times the problem isn't a specific vulnerability but rather invalid application logic that leads to compromise. ;)
It is wrong if that is their only security requirement (and it usually is from what I have seen) for the reasons you just stated ;) However you run into the problem you posted above. Companies want checklists, developers need more. It is a shame there cannot either better education for the companies or maybe just some middle ground between the two.
How about making one yourself?
I like the Symfony Live events - they're typically a good mix of local and visiting speakers. There also tends to be a mix of beginner and advanced topics + lots of socialising and interesting side-talks. Disclaimer: I am involved in organising Symfony Live London
I would recommend PHP Objects, Patterns and Practice. Good book on object oriented programming and design. It has a nice section on patterns which is a good thing to learn about.
See my reply to this [here](https://www.reddit.com/r/PHP/comments/3flnyj/make_composer_dumpautoload_in_another_folder_as/ctpy2zh). It's definitely not optimal. Just seeing that I've seen it done for this reason.
Well, I've made projects before that modified vendor location to outside the project, just so that it didn't spend time redownloading libs one deploy when it didn't need to (The project folder got blown away on deploy - or replaced with a different symlink anyway). Saved all those file operations on large libs. I guess this could have been done slightly differently by using more symlinks or different copy options, but there you have it.
I will give it a run sometime soon. But why do you say MariaDB or Percona won't be? or are you saying they are more like Postgresql?
I'm not sure that's a good idea.
1. The client sends username/password to the service. 2. It gets back a token. The service remembers that token (or it's an encrypted bearer token, same deal). 3. The client remembers the token. The client will now send that token back with every new request. The API is stateless only with regards to HTTP connection - it doesn't remember who you are, but it can still remember tokens and recognize them when sent back in future requests. The client itself is also not stateless. A non-web client has plenty of ways to retain a token once it has it. For a website, you can put it in the PHP session, or directly in a session cookie (for sensitive applications you can keep it in JavaScript's runtime state only, so on page reload the user has to login again).
OK. So after initial user authentication, every request would include an API token and a user token? Or would the API token then be derived from the user token?
Ignoring that something is probably very wrong with your configuration, the easiest way is probably a small shell script: #!/bin/sh cd /var/www/my-site.com/ &amp;&amp; composer dump-autoload -o &amp;&amp; cd - cd /var/www/my-site.com/sub-folder/ &amp;&amp; composer dump-autoload -o &amp;&amp; cd - Trying to use too many lesser-known features of composer itself to do this will likely just confuse people. This doesn't use any magic, just combines what you're already doing into a single command.
That depends on your specific project, but the best default choice is to use separate tokens, and thinking about each of them as separate, isolated layers of security, each with their own concerns and constraints. In general, when it comes to design, prefer concern isolation, and merge concerns only when reality forces you into it (for efficiency or other pragmatic reasons). Depending on your API you can get away with no API token at all. Depends how much you want (and need) to control client access to the API. API tokens are a reliable security measure only if all your clients are deployed in a controlled environment (say a specific customer server) and communication to the API is always done over SSL. For the common case, when unencrypted traffic is allowed, and API client tokens are allowed (or regardless of that) often show up in client apps that are easy to reverse-engineer (mobile apps, web apps, etc) they're never fool-proof. In this case, think about it like a soft control measure that you apply only when you need to, and for getting better metrics (which client is most popular, segregate API use patterns by client type etc.). 
There's only a single blade template, which I call "app.blade.php". Then all non-API routes in Laravel render this same template. This template loads all the CSS/JS and then bootstraps the React application. In my last project, we used React + React Router + Alt Flux.
MariaDB doesn't fit my needs. Postgresql just works for me.
Why
Capifony releases like tha, doesnt it?
Hijacking. Sorry :) https://getcomposer.org/doc/articles/scripts.md#command-events on the `post-autoload-dump` command, put in a script for `cd your-dir &amp;&amp; composer dumpautoload` { "scripts": { "post-autoload-dump": "cd your-dir &amp;&amp; composer dumpautoload" } }
I think you're right, except it's still project specific. The location on disk is just making the deployment quicker in my instance. Maybe because I know what I'm doing it for specifically? But yeah, sharing vendor across projects? Crazy.
can anyone provide me an example of how service locator is different from IoC? In the case of Pimple, how can it be used as service locator and DI?
&gt; the best solution is to try again, with some delay between. This depends a lot on the situation. I.e. the probability of dead locks. E.g. in the case of two concurrent transactions, there's no reason to not repeat it instantly as the offending transaction did already pass. Also we're talking here about dead locks. MySQL's manual says that this is a rare event (unless you're doing something wrong), and indeed I can back that up seeing those errors very rarely at my current job. Said that, the proposed [`TransactionalMutex`](https://github.com/malkusch/lock#transactionalmutex) does indeed wait with an exponential backoff.
When you deploy a new version with new deps, it will have an updated composer.lock file. All you have to do is re-run composer install on the server, and it will install the new updates. Theres no issue. Can go back to the old files the same way too.
This is all great stuff and really clearing up my mental model for this. I really appreciate you taking your time to answer my questions here.
Should be able to, unless you're defining the array as a property of a class, in which case you'll have have to do the modifications in the construct
I am sorry to inform you, but CodeIgniter has **nothing** to do with MVC.
Just to prevent someone looking at your code and thinking that's okay, the structure should be something like this: public/ [this should be htdocroot] admin/ index.php edit-profile.php index.php edit-profile.php profile.php vendor/ ... src/ [your namespace(s) / classes here] composer.json / lock (If you use the example from above)
Sorry, it looks like this: ( ! ) Parse error: syntax error, unexpected '-', expecting ')' in C:\wamp\www\uv\enforcer\application\app\Model\InsertionOrder.php on line 280
Enjoy your downvotes
Apparently all of my comments here were deleted. :\
:+1: Hesitated to even post a comment justifying *why* someone *might* do this because yeah... all I'm doing is explaining bad behaviour to begin with. Thanks for the added clarification!
not as much as i've enjoyed this conversation. In case you'd ever like to use something less cumbersome: $routesTo = function($model, $method) use($app){ $model = new $model($app); return array($model, $method); }; $app = \Helpers\Routes:: assign($app, $routesTo); $app-&gt;run(); class Routes { public function assign($app, $routesTo){ $app-&gt;get('/user/:user_id/activation/:activation_code/' , \Middleware\CORS() , $routesTo('\Controllers\UserCtl', 'unactivatedLogin')); } }
There are literally thousands of tutorials like this. Sure, they "mirror" the setup process you should be doing on a production server, but if you want a seamless dev server, it's gonna be a pain in the a. I've tried many combinations (suexec, phpfpm, etc) - I needed an enviroment where I could seamlessly create/paste/extract executable files on the go. In all cases I had to run sudo chmod every god damn time, which drove me crazy. Now running apache as myself (my user) so that it can access files that I create. I group business totally doesn't work. Still looking for an authoratitive tutorial on how to set up a dev enviroment I had just described. Cheers
Laravel isn't a package mgmt system? How would you manage your dependencies without Composer?
 &gt; Absolutely nothing wrong with NetBeans, but the ability to setup keyboard shortcuts for almost anything, and to go to specific classes/functions/files I can not understand these problems: NetBeans has a lot of keyboard shortcuts configurable and you just can hold shift and click to go directly to a class/function definition.
The problem with "vanilla php" is you're almost certain to do it wrong. An example of this is that the stackoverflow link you provided looks well written and in depth, to the point that has a reply referring to it as one of the best answers on stack overflow. It also recommends unauthenticated CBC mode (disaster). It does have a section later on authentication but it's written as though it's optional. The second most upvoted answer on that Stackoverflow link recommends not only unauthenticated encryption, it recommends MCRYPT_RIJNDAEL_256 and MCRYPT_MODE_ECB. The third answer also uses mcrypt, this time with MCRYPT_BLOWFISH and MCRYPT_MODE_CFB (also unauthenticated). I could write an article on how to do this properly, and someone will just point to this Stackoverflow question and claim I'm wrong. Use the libraries. If you can't install libsodium (I can't near most of my clients, because the criteria for "secure" is usually "does it use AES"), use defuse. It's quite lightweight.
A service locator *is* an inversion-of-control mechanism. A dependency injection container is also an inversion-of-control mechanism. The implementations of SL and DI are indistinguishable. The difference between the two is this: - When Object Foo uses the IOC mechanism to retrieve its (Object Foo's) own dependencies, Object Foo is using the IOC mechanism as a service locator. - When the IOC mechanism creates Object Foo and passes in Object Foo's dependencies at creation time, the IOC mechanism is being used as a dependency injection container. For a longer explanation, cf. my [Quicker, Easier, More Seductive](http://paul-m-jones.com/?s=quicker+easier+more+seductive) series of blog posts.
I totally agree with you, just want to give independent solution, not Laravel based, because not everybody use Laravel :)
Laravel is not a package management system. My guess is that you are seeing the consequences of package authors depending on various other packages. After a while the dependencies have dependencies, and so on, and you get a mass of code that you didn't expect. [The Aura project](http://auraphp.com) explicitly avoids this; no Aura library package has any dependency on any other package (although in the 3.x series we do allow dependencies on *interface* packages). 
Did you actually give this tutorial a go to try and get that setup?
Setting it up will get you familiar with composer, packages etc. It's really all about how deep you will delve into it. Laracasts will give you an idea on what is going on with the code and has some non Laravel content as well. If your project you're working towards will be using Laravel, I say go for it. Otherwise the youtube link from /u/taijuten linked is also very useful (aside from using phpmyadmin, imo).
This is nice. Never knew Symfony has this. Any other things like this that could make me abandon Kohana? 
That's a great idea. However, I was running out of time so I decided to pick something from internet. Will think about your idea, the next time,for sure. Thank You (:
Check out the docs :)
I usually look for software developers that have a good basic knowledge of the "web technology" such as PHP, JavaScript, jQuery or AngularJS and know about HTTP. I don't expect anyone to be a hero but they should know the basics incl. OOP. It's more important for us that the guy knows about software development in general, is motivated and has problem solving skills (ie. does not give up when he encounters a problem). I usually give tasks to see if they can implement a basic algorithm (-&gt; path normalizer) and give them a OOP task where they have to design a storage component and implement a few, for example: File Storage, InMemory Storage. I found it's best to ask the guy and not provide the answers right upfront. Just trying to get a feel how it's working. People who are not motivated have no chance even if they're skilled. I also look for "arrogant people" radar and it's important to fit in the team. He should have some sense of quality. Unit Testing, Git Knowledge is a biiig plus. Sorry for my unstructured answer, I should work now :D 
ZF3 is on the horizon? They blogged about in in January, and nothing since has been heard, and not a single line of code has been pushed. Do you have better information?
I've been there and I had to clean up the mess. If they don't know about proper OOP and abstracting things it's going to be a pain in the ass. I also find the idea of pair programming great. We usually provide them with a computer (next to me) and let them code. The big issue is that a lot of people are great talker but when it comes to coding they fail. I'd rather hire someone who is able to code.
Hehe. My colleagues always struggle with that name, but I'm sure puffpet is the intended pronunciation. The alternative (Puh P.H.P. Pet) doesn't seem very plausible. 
To elaborate, and my 2 cents: your give-away (as not-a-framework person) is that you talk about modularity outside the concept of a framework (and rather naively, like you've never been there). An experienced developer chooses to use Symfony or Django or [insert awesome framework] and a powerful IDE (IntelliJ/PHPStorm/VS) because it lowers their cognitive overhead (important term) on their projects to almost zero. Symfony is the ground-floor of your application, modularity typically starts there and often with a session/user/gadgets. I started as a developer of medical software in the mid-90's, and before and since Internet I've used a number of frameworks in various languages (Java/PHP/Python/Ruby), and you mainly sound inexperienced in how these trade-offs and such work. Giving up control can be hard but it's ultimately good, in my opinion. I focus 85%-90% in App\Model App\Domain and unit tests, and Symfony makes wiring it together (yaml and DI config) very easy and very fast, deployable, and relatively worry free. Why on earth would I be developing an app with two DI containers or various mail configs? Do you often do this for your clients?
I used Kohana previously. I have to say, Symfony is a million miles ahead.
Might just be me, but the example leaves me with a few simple questions: $AES = new \PCO\Symmetric('openssl:cipher=AES-128'); $ciphertext = $AES-&gt;encrypt($plaintext, $someKey); Am I getting HMAC with this (how can I tell just by looking at those lines)? Can this throw anything? Can I affect the HMAC if I'm getting it with this? What AES mode is this in? Can I alter the AES mode? (I mean, what if I'm implementing an algo that needs AES in ECB?) It's also annoying that I can't just create an encryption object and change the cipher type as I go. So if I'm trying to write code that interfaces between different AES modes, I'll need one Symmetric object for each AES mode. **However! I do love the concept. Do not take these questions as me saying no to this, as it's basically needed**. I'm just putting questions there that might be answered by the documentation, or might give a rethink on the way it's done. Don't make the new crypto options too opinionated, as then they'll be ignored by those who want more control. When people see those who are "in the know" ignoring it, they'll ignore it too (because they're all "rockstar developers" too!), and then we don't make progress. I'm also in agreement with professor_simmons above under the idea that it might be better to not force its own constructor string, and the name shouldn't read like PDO, less people become confused.
&gt; It took 3000 people over four years to create a barebones LAMP CMS I wouldn't call Drupal 8 barebones, somewhat of an insult to those 3k people who worked hard on what is a much more feature rich project OTB then Drupal 7 was.
Your post is made up of arbitrary statements. I'm forced to assume you just skimmed through my comments, or most of what I said flew over your head. Let's take one - where have I spoken against IDEs? Where have I discussed IDEs at all, period? Quote me. Let's take another - I was [merely *describing* how SwiftMailer works](https://github.com/swiftmailer/swiftmailer/search?utf8=%E2%9C%93&amp;q=Swift_DependencyContainer), I wasn't opinionating about how it *should* work. And, if you think I speak "naively", have the decency to point out specifically what prompted that remark. Everything I talk about is well supported both by my experience and practical applications throughout the industry.
&gt; You strike me as IoC-phobic (where inversion of control is the key differentiator between framework and library according to Fowler) If you understood IoC you'd see I'm actually the biggest supporter of IoC in this thread, which makes me wonder what do you think "IoC" is... Fishing dependencies out of a global container through string labels (like in OP's article) is not IoC, it's the opposite of IoC (hmm, how shall we call this... the IoIoC effect?). There are two parties: who sets up the components (party 1), and the components (party 2). From the perspective of party 1, party 2 is a set of libraries. From the perspective of party 2, party 1 is a framework. IoC means you're taking the perspective of the second party. It's the same relationship. The only problem is when you mix both and that control is not well defined and concentrated to one of the parties, but scattered, like in Symfony when you start interacting with a global container from within the components. If we must quote Fowler, I'll take a quote from the same article you're referring to above: &gt; The control is inverted - it calls me rather me calling the framework. This phenomenon is Inversion of Control (also known as the Hollywood Principle - "Don't call us, we'll call you"). [...] The container calls us, we don't call it. IoC means relying on an outside party to produce dependencies for you, and to control your lifetime. I.e. "you" are the library, in order words. How that outside party works should be irrelevant to the component as they should never see it, it's merely a private implementation detail of the caller. Also it'd be a big mistake to equate the EJB container which Martin Fowler discusses, with the Symfony DI container. They're both "containers" in very general sense, but EJB's container is *the framework*, it acts as a platform in which the Beans are "mini applications". Symfony's container is little more than a lazy-instantiated hashmap of objects. It does nothing on its own, it's just a *component within a larger framework*. You speak with confidence about matters you've barely researched. I hope my comments spark an interest.
&gt; doesn't having E_ALL mean ALL errors Not really...I recommend to use "-1" as setting because it will actually show all errors.
Nice ;-) 
not that my opinion matters, but whomever thought returning false from a rng function is just silly.
Here's the worst question that I couldn't answer reasonably; This was over eight years ago so my recollection of the exact question is a bit fuzzy, but you should get the jist of it: &gt; Design a database schema capable of storing an infinite amount of answers to a question from a form which the client may add as many answers as they like. I couldn't get past the DoS aspect plus the amount of storage that would be required. I just kept telling them it was a bad idea and you would never design an application that was intentionally DoS fodder. What I learned from that experience is that asking for a solution to a hypothetical (read: impossible) problem isn't the best way to learn how a developer goes about solving a problem. I interview a lot of people now and my approach is two-fold, phone screen + code samples, then a possible face-to-face with the team. During the phone screen: 1. I start by asking how they got their start as a developer. I can learn a lot about someone in a short amount of time. 2. I ask basic questions about their approach to a new feature/task. 3. I ask basic OOP questions. 4. I ask specific, but simple php questions. I'll ask increasing more difficult PHP questions that they wouldn't be able to find the answer for quick enough if they were sitting in front of their computer or had a cheat sheet. Programming and specifically PHP are easy to learn enough *to be dangerous*. My questions along with a review of code-samples are tailored to weed out the fast talkers and resumÃ© padders (the latter are often the recruiters and not the candidate). During the face-to-face: A colleague and I present three printed problems (and we ALWAYS forget to bring an extra pen/pencil!) 1. A database design problem. * then as a follow-up, we ask how they would query the db (based on the design they drew) to get certain bits of data. 2. An api design problem. 3. A logic problem. We have hired some very talented people that I have the pleasure of working with and whom I get to learn from (this is the best part) .
What is dynamic about it ? Do the fields not show up based on other fields? Is the validation of one field affecting another field? Does this behavior need to be validated on client/web-browser? Does this need to work with JavaScript turned-off? There is an answer for a combination of all of these, and then there's an answer that attacks all.
No, it's a blackbox of a framework (like a few others). It's gonna let you get things done fast, but doesn't require you to know what's under the hood. No exposure = no learn. The best way I can sum up Laravel is it's like an awkward ORM and opinionated set of classes ate another framework (Symfony). Does that sound like a good way to understand PHP better? Likely not. However it IS, 100% without a doubt, your ticket into a programming job. The marketing and brand awareness on Laravel has been one of the most successful in all of PHP framework history. So much that employers now put that in job descriptions and recruiters look for it. It has the most stars on GitHub and is Tweeted about more than any other framework. Indeed, you can use it to make things and it has a bunch of features. Pretty much everything you need. However, this does not make it the best framework. Yes, you will get a job if you put Laravel on your resume. Right now. Let's see what magic words you'll need to put on your resume in 5 years.
Well, I've written a DI container and had it used as a DI and Service Locator and brought over the whole team in order to start getting serious about it. For all examples, I am referring to Pimple when talking about DI or SI PHP object. In Service Location Method, the object within which a dependency is *used* will know about the SL object. It will use it to *fetch* the object from some Closure or some Object building - object. So, in effect - all objects users of SL become dependent on the SL object as that object is passed into them. *There is a use case for it when introducing it is a good idea, over a full blown manual or configuration based DI* About SL - Weaver, Misko Havery et al. have written numerous rants that basically denounce SL as a *worse* version of a better idea - DI. I'm offering no comment on the matter ;) In Dependency Injection - the DI object will figure out what the dependencies are, whether by introspection, configuration whichever, and then it will provide those dependencies into the objects which use those dependencies. The user objects, which use the other object dependencies don't even know that they are built with DI object. In the end, I really like the Fabien Potencier approach to understanding the madness behind DI, also he's the author of Pimple. Namely, start building up knowledge on how to do constructor, interface, setter injection. Then graduate to how that is used in Symfony, Zend or Yii. Then read the Pimple source code and try to use it in your own project, maybe go with an already written good DI framework **once you know what you want to settle for**. 
Start this monday!
Chef is great for configuration management and somewhat works like what you currently have. Deploying code should be handled by another process ( capistrano, ansible, etc .).
I truly believe that if I am allowed to give the developer a test, then he should give me one as well. The idea that I am testing you for comparability but you are not testing me strikes me as the wrong way of doing things. The way my previous employer handled it and the way I handle it when I hire freelance devs is by doing a small project TOGETHER. Find the time to sit down with the developer for an hour or so and discuss a certain problem with him/her. Construct a solution together and have them code it together with you remotely over Github. That way, you will know far more about them than just the coding skills. Also, if you cannot find the time to do this, then you should not expect the developer to find the time to do it for you. For free never the less as a part of an "interview". That's my 2 cents!
Just when loading the profile page (I assume it is profile page) get all data you can for that profile and fill out the form with collums from database. For text input it is parameter value="something", for select it is 'selected' added to option parameter, for checkboxes 'checked added to tag. Edit: Like this: http://pastebin.com/cQqGdhT8
Check out [PHPDI](http://php-di.org/) by /u/mnapoli 
&gt; Before I set off on course for building a binary dependency framework, does something exist for this use case? Yes, have a look at any linux distribution. There are plenty of package managers out there and I guess they all offer integration of personal repositories.
Oh god what year is this? OP pls have a look at PSR-3, Monolog, Composer, Git/GitHub, PHPUnit, OOP, SOLIDâ€¦
Bah humbug, such machines like WolframAlpha doesn't substitute for good old plain thinking! Besides it works only for selected cities and doesn't take into account week days nor time etc. ;)
Those who simply want to learn the basic and entrails of a language don't want to complicate their life with complex paradigms, frameworks, revision control software and other kind of tools, specially when the code is simple and small.
1) Questions regarding their habbits as a developer 2) What does the equal operator do 3) Yes. Hell Yes. A hard task involving multiple mysql JOIN's and aggregates, and how to create a report from it. 
What problems did they experience and what can their ISPs do to improve their experience?
Yikes. Yeah, that's rough. Most of the performance implications of HTTPS can be optimized, but it takes time (which means: money) to do so.
This type of content does not belong in /r/php, please post this to /r/phphelp as per the sidebar.
&gt; based on random conjecture Of course! It's not like I know you or you know me, how could I have complete set of facts about you? &gt; Akka Isn't Akka a toolkit/library? I was asking to see if you had any experience with a full-stack web framework akin to Symfony. 
Akka provides a node (think: EJB container) where actors (think: EJB beans) play in an isolated sandbox entirely designed around IoC (the control is in the node). You're the one who brought up Martin Fowler and IoC, and Akka is a great fit for this definition of "framework", while Symfony isn't. At least agree with yourself.
You can start by naming your article appropriately; Basic logging system in PHP for careless developers. 
I don't get it either, all of this can be done via a proper db transaction.
yeah, me too, but: there has to be a "secure" and efficient "middleman" solution. i mean, the webgui could've been written in node or ruby, doesnt matter, it'll be running as a linux-user with restricted rights anways. i could run the php5-fpm-process as root, but... you probably know why i don't want to do it.
This doesn't seem like something that should have to be done, but... Here are some ideas anyway. 1. Do all of this in a VM so if the worst happens you can rebuild it entirely. 2. Depending on what you're trying to accomplish, it might be possible to sandbox it even further, allowing the web front-end to edit the configuration of individual components that are containerized or virtualized so it doesn't affect the main system at all. Something like Docker might be helpful here, but I don't have a lot of personal hands-on experience with it. 3. I would find a way for the web front-end, running as e.g. www-data, to write commands into a message queue or send requests to a Jenkins or Gearman instance where workers run as a different process. This at least creates one level of account-based security where a PHP exploit could allow access to escalated privileges. Finally, the worker process that actually does the escalated privilege work, such as the Gearman worker or the Jenkins slave, should have a very specific `sudoers` configuration, allowing it to get escalated privileges for only a specific set of commands you allow. Again, in general this is probably not a great idea, but with the above pieces you could probably avoid calamity.
thanks for your reply, i know that it feels like it should not have to be done, but even some firewall webgui's are doing it somehow (like pfSense or EdgeOS, which have both a webgui written in php)!? ofc, the whole thing should be sandboxed as much as possible, it should be only allowed to restart predefined services, in my case, its a computer behind a firewall running the squid3-proxy and it should only be possible to edit the config file (only specific parameters, like excluding some domains from being cached) and reload the proxy without ssh access or linux knowledge.
Sounds like you're looking for something like webmin. http://www.webmin.com
Have your web interface run as an unprivileged user and write all requested changes to a file or database. Another process running as root can then check the db for changes and enact them, reporting status back via the database. It could be any database (sqlite if you are careful), although using PostgreSQL LISTEN/NOTIFY or Redis could avoid polling the database for changes all the time.
this is not a good question without code accompaniying it
This is a perfect example of how to kill your own server. I worked on a site that logged to email (I didn't write it, but I fixed it pretty darn quickly). It dealt with thousands of requests per minute - which started failing, and every failure threw an email. When I got to it, the mail spool was 148,000 strong, and the machine's load average was well over 300.
One could argue it the other way - PHP worked fine at Facebook because Facebook became the successful company it is on the back of a PHP product. However, the company has some pretty unique scaling challenges, and I'd wager that no out-of-the-box solution would have worked for them at this point. So... carry on using PHP, don't worry too much about the critics! 
I'm sure lots of stuff breaks when scaled up to a **billion** users.
&gt; but most colleagues are citing Facebook as an example for PHP's failure. Facebook is so far from a failure. Facebook and Wikipedia both run on PHP (HHVM if you want to be specific, but to me Hack is just a PHP variant, not a whole new language). Additionally, isn't YouPorn (one of the most visited sites in the world) powered by Symfony 2? I seem to remember one of the big porn sites being built in Symfony (someone can confirm that for me). If you ever have a project reach that scale (and most of us never will), you'll employ plenty of engineers to get around PHP's scaling "problem".
Nice, thanks for this resource. It reminded me of a few libraries that I had forgotten
Twitter dumped Ruby, therefore, nobody should ever use Ruby.
I don't think you need Twitter to have a reason to not use Ruby.
&gt; PHP is considered _faster_, and less resource hungry than say Ruby, or Python I understand that was said without a citation, but I'm curious as to where you came up with that in the first place.
Are both ini files configured? Standard set up is for cli and fpm/cgi/mod to use different config files.
Twitter moved on to Scala, IIRC.
Surprisingly, very little _at the language level_. At least, for PHP. If you had a script that did nothing but computational stuff â€” that is, zero storage requirements â€” then scaling that in PHP is a simple matter of adding servers behind load balancers. This is the beauty of shared-nothing, which PHP is **by default**, and is a _requirement_ for horizontal scaling in general â€” it's one of the reasons why scaling Ruby, Node, Python, or Java, etc, is harder than PHP, that use shared state â€” though, frankly, none of them are that hard; it's the data layer that **sucks** as it generally _has_ to be shared to work.
I have read about PHP pre-compilers and advanced interpreters for helping a PHP project scale.
I think ruby is still silicon valleys preferred for prototyping and scales find for medium size. 
There are levels of scale where seemingly minute gains end up being massive, such scales that you have to think and develop in a completely different mindset, I've done it before, I don't like doing it, I prefer SMB scale issues. It isn't that PHP didn't work out for them, if anything it worked too well for them, so much so their usage outpaced the development or scalability of the stock engine (an arguably the language syntax itself), but unless you are going to be serving literally billions of requests a day you won't HAVE that scaling issue so the argument that PHP doesn't scale well because it didn't work for Facebook had better be made by someone who writes code for google's search engine or feeds for the NYSE otherwise they're blowing smoke out their ass. Anyone who would cite Facebook as "PHP failing" has never had to write ANYTHING to that scale and can and probably should be ignored. If you want large scale but by comparison much smaller than Facebook, fantasy.nfl.com is almost all PHP, and it serves millions of requests a day during the in-game season. That said, I love Symfony2, go for it, I have my own framework on a framework built around Symfony2 for personal projects and I love it.
Choosing not to use a language that enjoys incredibly wide support because a 1.5 billion-user site didn't scale with it seems ridiculous. I'm pretty sure scaling any platform to that size would have significant pains. Unless you know for sure you're going to have 1.5 billion users next week, I wouldn't worry about it and pick the tool that makes most sense for your project as it stands _now_.
My own 2c for that would simply be my experience setting up a Ruby app, it just seems to take a long time for the server process to actually start up compared to, say, starting php-fpm. On the flip side, once it's actually running it probably process requests faster from the start (whereas php will just cache bytecode as it goes). 
&gt; Your opinion has been noted, but I don't think it's a fair description of what I'm trying to do. His description of what you were doing is accurate. I clicked the link and saw basically an internet fight between two people I don't really care about, not some official direction of the language or the internals team. The next thing I did was note that the title here on reddit was insanely opinionated, and from there I looked at the reddit username to see if I recognized them. It seemed familiar and unique, so I went BACK to the linked post and yup, sure enough, the guy posting on reddit was the guy that got the last word in the linked post. At that point my conclusion was basically that you had posted this here for either validation or to get more people to bandwagon against the other guy, neither of which are necessary for empirical discussions (for instance, whether or not X is more secure than Y), and neither of which are HELPFUL for opinionated discussions (for instance, is this increase in security worth the tradeoff of changing behavior). To put it bluntly, no one cares. Sure, if this were a discussion that the entire internals team was torn over that was stopping the implementation of a CSRN standard API, we would care. But no one cares about this, or the fact that you "won" your argument, or who it was with. And frankly, the assertion you made in the title of this thread, that PHP sucks at security and this is "why", says more than all your angry words in the post linked.
&gt; PHP is known for not scaling ^[citation ^needed] It's not that PHP _couldn't_ scale to support Facebook's needs, it was more than capable... it just used way too many resources to do so (they've said they'd need 3:1 _data centers_ using vanilla PHP). It _did_ run Facebook for most of their first billion users, and Wikipedia (now HHVM), Baidu (partially HHVM I believe), Yahoo! (still #5!), eBay, Disney, imgur (which counts Jeff Atwood, author of one of the famous pieces lambasting PHP, [The PHP Singularity](http://blog.codinghorror.com/the-php-singularity/) as one of it's advisors...), the list goes on. As noted in my [other comment](https://www.reddit.com/r/PHP/comments/3fstc9/why_didnt_php_work_out_for_facebook/ctrndgx), PHP itself is really easy to scale â€” just throw more servers at it. It's shared nothing, and will horizontally scale with ease. Don't get me wrong, I _like_ HHVM, and _really like_ Hack, but you'll see a common theme in people migrating to it: 1. They came _from_ PHP (duh!) which implicitly says they got to that point _with_ PHP 2. They remark on performance increases (compared to &lt; PHP 7, this performance gap will shrink dramatically, soon) 3. They remark on _resource savings_. The last one is the _real_ reason to switch, it saves **real** dollars. If the wall clock speed was identical, but the resource usage was still 50% less, you can bet they'd still switch.
I think you forgot to share 
Twitch.tv still runs Ruby as far as i know.
That's awesome. Should there also be a "Hosting" section? Maybe with a mention of using [ServerPilot](https://serverpilot.io/) + [DigitalOcean](https://www.digitalocean.com/).
Yeah I've had to hack together things like this for stuff on embedded Linux boards. I doubt my way was secure at all though ha 
I understand, but the thing is, you picked the rotten staircase. The CI framework is filled with bad practices and spreads misinformation. Using it as your "first step" would cause more harm than good.
For these situations, I would encourage that people build atop our APIs for their specific use cases. I did something similar here, building atop libsodium to add support for encrypted cookies to any PHP application: https://github.com/paragonie/halite_cookie
Wow, are you serious? They deleted your account because the code you were working on was related to pornography? The fuck, since when did CI tools become opinionated about shit like that? Is this run by Governor of Oklahoma or something?
I absolutely cannot come up with a reason that this even happened to him in the first place. Who the fuck are you to care if his code is for a pornographic website? Talk through it? It's none of your fucking business. Merely the fact that it happened indicates that you do some sort of analysis on the private codebases that ISN'T related to the service you're providing. I suggest that no one uses this. Think: how did they know it was related to pornography? The only possible way is because they inspected his code for things other than Coding Style. So what else do they inspect for? Do they store the private code elsewhere? Do they use it for anything? Not trustworthy at all.
It works for tumblr, etsy, mail chimp, viemo, appnexus... So unless you ever surpass any of those companies you really don't have to worry about out growing php.
Yeah, little upsetting. They gave my money back, but still. Pretty lame.
Er, Facebook continues to use a PHP dialect. They're at the scale where the small changes they add through HipHop bring them more savings than the engineers to make them cost. When you're at Facebook scale, no basic language works.
Great explaination. Thanks!
PHP "failed" in the sense that the Zend Engine couldn't sustain the load and it wasn't cost effective to just throw servers at it anymore. At this point they wrote HipHop for PHP from scratch. Shortly after they introduced HHVM, also written from scratch. The difference in performance between PHP 5.1-5.2 (probably what they used before the transition) and PHP 5.4-6 is night and day, let alone PHP 7. Claiming that the PHP as a whole is a failure because 5 years ago facebook was able to write a faster version of the engine (which is still the PHP language) is simply retarted.
I meant for Facebook's scaling needs. By issues I mean that without ironing out intricate architectural requirements and implementing technology designed for such a scale, you're going to have a bad time. Point being.. there's nothing out there that you can just install out-of-the-box and be ready to handle Facebook's scale.
There's a monstrous amount of ums, uhs, repetition, and silence between words in every sentence, which makes it very hard to follow along.
That's already what people do: build use-case specific code on top of the existing APIs. We don't need new APIs that duplicate the existing functionality, we need ones that add a few idiot-proof tools for 95% of use cases. libsodium may have a better underlying implementation of the raw crypto protocols than the existing mcrypt code, but that doesn't prevent people from using it wrong.
Every language has its warts and strengths. PHP just happened to be on the bad side of the stick for awhile, mostly because of really awkward behavior and conventions in PHP 4 and earlier. PHP 5 added real OO and PHP 7 looks to make things better. Granted, I left the PHP world awhile back and move to NodeJS and Elixir, but PHP fit my needs at the time. As others have said, PHP got Facebook to the point that it could be successful then became difficult, as almost any other language would have. That all being said, I am not interested in going back to PHP. I find other languages fit my approach and style better than PHP, though that is me and not indicative of the language.
Yes, although like any company of their size, it's not the only thing they use.
That's called the packing problem (knapsack) without weight (cost) constraint. Pick all less than 10% sought value and bruteforce combinations which add up to less than the target value or whatever variance is allowed. Your way will also work.
&gt; Claiming that the PHP as a whole is a failure because 5 years ago facebook was able to write a faster version of the engine (which is still the PHP language) is simply retarted. Yes, but people love finding any absurd reason to hate on PHP. They're usually at best out-of-date, and commonly straight-up wrong.
And how! 
The easiest way to know what language is perfect for your web project is to do this: Step 1) Use the language/framework you (or your team) are the most comfortable with Step 2) There are no step 2 Just work with something you like and feel comfortable using. A finished product is better than a perfect product on paper. When you get to problems caused by the limitation of the framework or language, then you know you've done something good. Then you analyse the benefits of changing based on the current usage.
You're/we're using PHP. Not much room to talk.
PHP was never ment to be a solution for large web apps.,,, and when i say large, I mean large. When you have apps like Facebook, twitter, etc, off-shelf solutions (frameworks, etc) are not solutions. Nor is PHP to be fair. You have to customize and optimize every single thing in order to reduce costs an dimporve your app. (basically what Facebook has done with HVMM) ....or as someone said, twitter ditched ruby once it reached a critical mass point. As for your concerns what your colleagues are saying. When I am asked 'what we will do when we reach 100 million hits' (even in reality that was always impossible) I always respond "well, then we have a good problem". In other words, when you reach a permanent scaling problem, it means you have consistent huge user base, which in turns meas your website is successful. Facebook, twitter, wikipedia, they all dint become million userbase platforms overnight. For startups - there is no point of throwing ton shit amount of money and resources on projects that are: never meant to be big like facebook , of if they were....then getting it out there to gain traction/interests/investment is more of a priority. Different matter if you have huge budget and you can put in 10 people, with 10 various skills Obviously you should always design your code to eb a good code and cater caching, scaling, etc and chose your frameworks that does this the best..... and in that respect PHP is a bad choice , because of the things above mentioned, people would deliver very bad code that basically on smallest hiccup/upgrade requires complete rewrite . I still cringe when i see shopping carts in WordPress and there are ton shits of them out there.... operating without a problem (obviously not on amazon level, etc) 
saw it in my activity feed earlier today. here's the [link](https://github.com/trq/fucking-small) for those of you missing out
&gt; This is the beauty of shared-nothing, which PHP is by default, and is a requirement for horizontal scaling in general â€” it's one of the reasons why scaling Ruby, Node, Python, or Java, etc, is harder than PHP, that use shared state â€” though, frankly, none of them are that hard; it's the data layer that sucks as it generally has to be shared to work. That's pretty misleading though. Everything involving a shared data storage of some kind is harder to scale, independent of the technology used on the application server, true. But what makes you believe PHP is easier to scale than Ruby, Node, Python or Java? All of these technologies are perfectly capable of running in a shared-nothing architecture and scale horizontally just fine - even Bash CGI scripts are. How well you are able to scale horizontally mainly depends on how well you have designed your data flows and how well the load distribution in front of it works - shared-nothing horizontal scaling is a no-brainer with probably almost any technology out there. 
It's simple. Just use PHP /s
I believe I noted exactly this in the same comment you quoted: &gt; that is, zero storage requirements Ruby/Node/Python/Java typically share state by *default*. PHP does not. There _are_ valuable reasons to share state, but it is harder to scale and that's what we're talking about. I agree 100% that the real difficulty in scaling web apps is on the storage layer. Again, from that comment (emphasis added): &gt; frankly, **none of them are that hard; it's the data layer that sucks** as it generally has to be shared to work
https://www.zend.com/en/resources/php7_infographic Apparently PHP7 increases the gap as well. The bottom of the infographic compares Mandelbrot functions to each other. In 2012, PHP 5.2 was at 9.19 sec, Python 2.6 was at 11.85 sec, and Ruby 1.87 was at 28.71 sec. http://theowoll.netau.net/benchmark.html Beyond these I could not give you any particular benchmarks.
I hadn't heard that it was S2, but yes, YP is using a standard LEMP stack. There was a fascinating writeup of their stack a few years ago. EDIT: http://highscalability.com/blog/2012/4/2/youporn-targeting-200-million-views-a-day-and-beyond.html
one of facebook's first big ways to scale up their php layer was [hiphop](https://en.wikipedia.org/wiki/HipHop_for_PHP) which transpiled php to c++ and then compiled a binary from that. in this respect, php was wildly successful. if you look at php it has a very strong correlation to c. sure, if you want to read a file you can use file_get_contents(), but you can also access fopen(), fgets() and all that c-style syntax (hell, you can even [fork()](http://php.net/manual/en/function.pcntl-fork.php) or use [pthreads](http://php.net/manual/en/book.pthreads.php)). this makes for a very strong way to develop high-performance wares: develop in php using the interpreter, then deploy as a native binary. fast dev and high performance (aeons ago i used try to achieve this natively in c by using [herb schildt's 'little c' interpreter](http://php.net/manual/en/book.pthreads.php)... but it was a disaster). now, imagine if facebook had been written as, say, a rails app. transpiling would have been significantly more difficult and would, realistically, have required a total rewrite. so, in that respect, i would say that php was not an adequate choice for facebook, but an excellent one.
If we look objectively at these two languages, and put aside the endlessly recited rules of number casting in PHP, there isn't really a good reason to prefer Ruby over PHP for the web. Ruby has a somewhat cleaner syntax (a superficial concern) and a much better PR image, but its type system is quite rudimentary in some aspects (no interfaces, no type hints, anyone can monkey-patch your class etc.). It performs worse, and its popularity is waning as of late, the community is smaller and more insular. So we have some room to talk.
erm ... I do that sometimes, apologies. This was our first go at a screencast, trying to anticipate what was going to happen next, and answer questions from edd, and stay on top of everything was harder than I imagined it would be. I don't agree with the word monstrous, and can't promise that I won't stutter or hesitate in future screencasts or conversations, but these are valid criticisms that I'll try to address, perhaps with better planning.
Well, my understanding is that Hack is based on PHP. 
See: http://fatfreeframework.com Time tested, efficient, and effective. Complete documentation, and a friendly community. Why reinvent the wheel? 
Your colleagues have never used any language that remotely touches on the scaling challenges Facebook has experienced to become the second most visited site in earth. I would argue that because of that, PHP was a blinding success to get the company to where it is. And at their current level, I would say any language Zuck started with would have been re-engineered the same way they have done for HHVM. Personally, I'd be asking them for specific examples of where PHP fails to scale at the realistic trajectory of your application. Then, ask them how their alternative would address those issues.
I wish the same.. :D
Oh no, no interfacesâ€¦ 
&gt; no out-of-the-box solution would have worked for them at this point This.
&gt; and in that respect PHP is a bad choice , because of the things above mentioned, people would deliver very bad code that basically on smallest hiccup/upgrade requires complete rewrite Isn't it really the people's fault rather than php's?
Literally the first line in his post: "Something I was tasked with making for a code test for a new role."
&gt; Why reinvent the wheel? Why not... F3 is very good, but I preferer Slim. fucking-small is very interesting :) thx (I'm a big fan of PHP (very)Micro Framework) 
&gt; Ruby has a somewhat cleaner syntax (a superficial concern) When you spend most your day writing code, syntax is important. &gt; no interfaces Interfaces aren't really a big deal. &gt; no type hints Type hinting could be nice but I guess it's kind of against Ruby's way of doing things and besides it's mainly a syntax issue (which is a superficial concern ;)), if you really want to accept specific types you can easily raise an exception yourself. &gt; anyone can monkey-patch your class I consider the fact you can monkey-patch a class a powerful feature. Yes, it can lead to bad code, but that's your responsibility to not write bad code (I think this is one of PHP's arguments as to why it's a good language in 2015). &gt; popularity is waning as of late Is PHP really growing in comparison? I honestly haven't tracked the popularity of either since I don't use them much anymore, so would be interested in knowing.
Yeah, honestly. Once your website becomes the scale of facebook, you could pivot to any technology. The fact that they decided to stick with php and improved the language should be a good sign. Compare that to Twitter's [growing pains](https://en.wikipedia.org/wiki/Twitter#Technology) (tl;dr: Ruby didn't cut it, they rewrote parts of it in java and scala instead)... To be fair, their first mistake was using MySQL for storing what could potentially be billions of rows of data. Everyone knows that MySQL is just not what you should pick to do this (not that i would know what sort of db would handle this sort of thing out of the box, maybe Cassandra could, but that didn't exist back then).
/u/katie_pornhub could probably tell you if they use symfony . I'm at work now so I don't want to check the http headers.
Criticizing PHP for Facebook is like criticizing a pickup truck for not being able to transport a blue whale.
I believe this is something they're (PHP team) heavily working toward, isn't it? A more unified naming system? 
HHVM != Hack. You can run vanilla PHP on HHVM (more or less).
Hack is definitely PHP
&gt; I've been racking my head for the last hour over this!! You know, you could have just "checked the manual that corresponds to your MySQL server version for the right syntax to use near 'GROUP BY id'". Error messages are there to help you.
&gt; BTW, type hinting is not about "syntax", but an issue of "semantics". Syntax is the specific characters used to express intent, and semantics is what kind of intent can be expressed (if it can be expressed at all). This makes the former superficial and latter quite the opposite. My point is that if you really want the effects of type hinting, you can do it in userland code. It's not part of the language, i.e. there's no `def foo(Integer i)` (due to Ruby favouring duck typing), but you can make your methods require specific types if you so wish by just raising if `i.is_a?(Integer)` is false.
This is like going to christian church and saying: Are you planning on dying? Would you like to go to heaven? Christianity is for you! Yo, you're advertising PHP (quite badly if I say so myself) to a PHP specific subreddit... Cheers for the post, I guess?
Interesting! Did they share anything more about the setup? What storage engine are they using, how do they do their sharding?
&gt;LEMP E? 
Isn't ARCHIVE just a glorified csv? I was hoping they'd be using a more esoteric thing, but i guess INNODB works for them. Anyway, I guess MySQL is another one of those things that has a bad reputation because it used to "suck" a decade ago (even though it was still pretty good as far as free databases go, just missing some features).
The solution would be to image the box with whatever updates you need to do it, or ssh into the box and do what you need to do.
I guess as a purely software middle layer for critical code I can see a use for it. As for the whole PDO integration, i don't think it has a use there because it is rather trivial to execute a transaction because the PDO API is actually quite good. 
Also wanted to point out that YouTube is using MySQL as well and has built some interesting tools to help them scale it to their ridiculous needs, like https://github.com/youtube/vitess 
What does Drupal 8 bring to the table, exactly? I know one of the reasons often cited for using Drupal was its rich plugin ecosystem, but in the modern PHP world where we have a vast amount of easy to use frameworks (pick your flavor) and an ever growing number of solidly engineered composer packages, what is Drupal 8's use case?
I hear google calendar has a good API
I would prefer if the library wouldn't depend on it, and provided only synchronization with Google Calendar. Edited my initial post. Thank you for suggestion anyway.
This! PHP works well, the only problem with Facebook using PHP was the shear size of the "app" (I have read somewhere about the deployment of the app which puts its size around 1.5Gb) and the volume it deals with on a daily basis. If your app gets around this big, I dont think many high level languages can help you here.
Was the water cold when you wrote it? :)
the same reason git failed them: https://news.ycombinator.com/item?id=7648237 /s
Hack is basically PHP with extra functionality on top. http://hacklang.org
Thanks for this Joe! There's a real lack of information out there on PHP 7 development, so this'll be a handy resource. Also, if you don't need the entire commit history of PHP, do a shallow clone by specifying the --depth flag - it'll make cloning a repo much quicker :)
&gt; That's already what people do: build use-case specific code on top of the existing APIs. Yes, yet the primitives are so hard to use that almost nobody gets it right. I can't tell you the number of frameworks and libraries that have insecure crypto code because the APIs suck... &gt; we need ones that add a few idiot-proof tools for 95% of use cases. I agree completely. I lean more on the "correct usages of a tool" fall *more* on the documentation side as long as it's not trivial to screw up...
Shipping software using repos has been a problem due to: * Proxy / firewall blockage issues * Lack of availability of latest stable releases (this remains up to repo maintainers) * Some things (i.e., Google Closure Compiler) will never be installable through a repo
&gt; that breaks backwards compatibility completely. For code, yes completely, for data not so much, there's always an upgrade path for data. We knew this would happen even when drupal 1.0 was a thing, since [the drop is always moving](https://www.drupal.org/node/65922). 
Spotify, youporn ...
The libmagic library is bundled with PHP, but includes PHP specific changes. A patch against libmagic named libmagic.patch is maintained and may be found within the PHP fileinfo extensions source.
our /etc/magic/ is empty 
Another thing to watch out for is MySQL if you are using it to store the utf8. The 'utf8' encoding is only 3 bytes. It truncates a string silently starting at the first 4 byte character. Most (all?) emoji are 4 bytes. You'll need to use 'utf8mb4' encoding.
That's not exactly how it works. Unicode is a set of codepoints, numbers, in a range that was defined much earlier. Within that range, not all codepoints are defined to mean anything (yet), but they can be encoded (as a number) before they're defined. You only need them to be defined when you display them (so at the browser, not earlier). So the fact emojis were defined recently is not a factor for their support in the JSON decoder. And UTF-8 is just a format for encoding a stream of Unicode codepoints, it's oblivious to what exactly it's encoding (emoji or not). PHP's JSON decoder blows up because (at the low level) the JSON you give it is not valid UTF-8 or UTF-16. And you need to investigate how that happens.
However HHVM != PHP. His original question and asking why they had to build HipHop stands. Lets remember Facebook ditched PHP in production years ago they just used to compile it to C++. Now a days they just change the open tag to hacks and code in Hack.
Those headlines make it seem like we want a complex product to be perfect and need no patches at all. Surely that's not the attitude we want to promote? The problem with Magento is not the fact security patches come out from time to time (that's good). The problem is they're not as easy to install for non-paying users, so uptake on these patches is poor.
Beyond that, they have terrible disclosure policies: https://www.ostraining.com/blog/general/magento-shoplift/ That was earlier this year, and (after being called out) they did do better with a security release in July. But where's the public announcement for this patch? Certainly not here: http://magento.com/blog Search Google for the patch (SUPEE-6482) and the top results are on people on stackexchange wondering what's going on.
Make a list of sufficiently complex products that face the network (web apps, connected desktop apps, server apps, operating systems), that you consider stable. Then go check their list of security issues and patches. You'll find most of them get patches *at least* once a month. There's no such thing as perfect software. "Stable" just means "good enough to release and work most of the time". Issues will be found, and they'll have to be corrected.
True. But hey, we're getting there :)
I'm pretty sure MySQL is generally a great choice for storing large amounts of relational data, if you set up your servers (and schemas) correctly and add in clusters, sharding, etc. I'm tired of this NoSQL craze and everyone thinking that switching to NoSQL is a cure-all for any database scalability or performance issues. NoSQL is fine **in the right situation** but it is not supposed to be used in **every situation**.
I have already explained, that I do not mind the concept of security patches. I don't know how you can consider 4 security patches within 6 months a "good" thing. If it was looking for eCommerce software now, frequent security patches would suggest potential risk or a previous lackadaisical approach to security. Also, as /r/stevejburge said, it doesn't help when their disclosure/patch management policies are so bad.
Once again, make a list of popular software, and go check how often they release security patches. I remember many years ago when I encountered my first compiler bug. For a couple of days, I was in a state of utter shock, it felt like my world had shattered - if compilers can have bugs, it means I can't trust any of the code I write will do what it says! But... that's reality. When you get to maintain a complex piece of software for a period of time, you realize even if you keep the strictest standards while architecting it, implementing it and testing it, issues will be constantly discovered as it gets used. It's possible, for example, when you update PHP from 5.5 to 5.6, a subtle change in PHP's APIs to open a security hole in your product. How could you plan for this beforehand? You can't. In a nutshell, there's two kinds of connected software: one that needs regular patches, and one that's been abandoned. If you visit a factory you'll spot some automation software that never touches the network, that's been working for decades on Windows 3.11 on an old Pentium II box, and no one wants or has to update it - it just works. But that's the exception, not the rule.
That was a great talk, thanks for sharing that.
~~Does it bug anyone else that the $caps variable doesn't actually exist in that `map_meta_cap` function?~~ nvm
PEAR::Calendar https://pear.php.net/manual/en/package.datetime.calendar.php It's probably a bit outdated, and could use some updating including PHP's newer DateTime features, but I use this currently to drive an event system calendar, and it saved me from about 5 months of hand-coding the actual calendar.
Legitimate question - why use a v8js extension? Is there any advantage to doing this? Currently, I use node.js / io.js natively by invoking it through one of PHP's process functions.
They removed it for the screenshot, probably to save space. This is from WP core: https://cloudup.com/c7uLmPPAoW9 
this is great, thanks for posting! ya cunt! 
You should ask this as a stackoverflow question with some example data.
I don't think anyone's going to try arguing *in favor* of the naming conventions of the standard library, even if it's mostly inherited from C (which doesn't excuse it, despite explaining it). It's very much annoying, and is a perfectly valid point of criticism, but it's not something that's just broken (I can't speak for Scheme having never used it, but Ruby for example I feel has language design choices that are just awful) There are standards for modern PHP, and they're followed, but renaming or even aliasing all of the old stuff is a BC nightmare. If that's the language's biggest fault, it's doing pretty well in my books.
your chance of becoming the next facebook: 0% your chance of pushing PHP past its ability to scale: 0% Chance of PHP becoming over twice as fast within a few months: 100% looks like an easy choice to me
just urlencode them maybe?
The most simple way here is to start_sessions() at the beginning of the file. Then use an if statement to switch between each of the 3 pages. Store something in a $_SESSION['loggedin'] variable or something like that to prove they have logged in. When they close the browser or session time expires, they will be forced to log in again. Put each page in it's own file and make sure the first thing in each is a check for that logged in session variable. Page 1 is a simple login form with a check for the password. If password is good, assign logged in session variable and bump them to the next page. Page 2 is your basic upload form. I suggest that when you do your move_uploaded_file you rename the file to something like a timestamp using microtime(true) as the function to grab the new name from. It will make sure that pretty much no files end up being the same. Then store your other bits of information, most simply, in a flat file(CSV). You would do something like this file_put_contents("image_list.csv", $imagename."|".$var1."|".$var2."|"$var3."\n", FILE_APPEND). Page 3 you will first load the image_list.csv something like this: $image_array = explode("\n", file_get_contents("image_list.csv")) Then you would cycle through the array using a for loop. Explode each line across the "|"(pipe) and then use array[0] to know the image file to load and the other variables are your information attached to it. Use the same formula if you port it up to a SQL environment of some type.
Yeah, you're kind of confused. It is common and frequent for unicode decoders to validate that the character set going through them (as well as a number of other topics, such as codepoint normalization and code sequence normalization) is valid. PHP's implementation is one such. You can validate that by checking that `ENT_DISALLOWED` exists. The functionality of that flag cannot be implemented without checking if characters are valid. The purpose of that flag is to make the decoder replace the character with the unicode placeholder codepoint for unknown characters, `U+FFFD Replacement Character`. ***This behavior is required by the Unicode standard. All compliant Unicode decoders will throw (or the local equivalent) when provided with a codepoint that is not explicitly present in their codepage tables.*** You can very easily test this behavior by attempting to place the first character after the current Emoji block. PHP's Unicode decoder will, *correctly*, refuse to decode it, because it's not valid Unicode as of the time of the code implementation. That's what's actually triggering here. The JSON decoder doesn't flag `ENT_DISALLOWED`. Therefore, when the JSON decoder asks for the Unicode decode, it never gets a response, because the Unicode decoder does the exact opposite of what you claim, as required by the standard. . &gt; So the fact emojis were defined recently is not a factor for their support in the JSON decoder. That the JSON decoder invokes some other tool that blows up isn't the problem. It's that the JSON tool is using the Unicode decoder incorrectly, and should be flagging `ENT_DISALLOWED`. . &gt; And you need to investigate how that happens. He already knows how it happens. He's using an older version of PHP which has out of date Unicode tables. Sage on the mountain mode told him to ask the question he already asked a second time. The correct answer is "Use a different Unicode decoder. PHP has bindings for, among other things, the IBM one, which can be upgraded independently of your PHP legacy requirement."
Short version? The unicode decoder in use has a flag that says "replace unknown characters, or permit them, or throw," and the json decoder you use left it on throw. The unicode decoder in use is part of the language's API, so if you need to maintain a three and a half year old PHP with security defects, the thing to do would to manually decode the unicode first with bindings to a different unicode decoder, such as the one in the IBM bindings. But really, just upgrade PHP.
&gt; Interfaces aren't really a big deal. lol.
Exactly, Ruby is the best for fast prototyping, then, if you scale as big as Facebook or Twitter you can improve or migrate.
Because I'm in such a good f-ing mood and I can tell you seem to never have done anything what so ever with PHP as I pseudo coded the whole thing in the above statement, here is the basics fleshed out. If you can't figure it out here, then you need to get a book and actually start learning PHP, not just asking for people to do it for you. &lt;?php /***** * INDEX.PHP */ // Starts PHP Sessions for temp login session_start(); // Get what page we are on if(isset($_GET['page'])){ $page = intval($_GET['page']); }else{ $page = 1; //&lt; Defaults us to page 1 if no page is set } // First checks if there is no session set. If not then load page 1 if(!isset($_SESSION['logged_in'])){ include("page1.php"); }elseif(isset($_SESSION['logged_in']) &amp;&amp; $page == 2){ include("page2.php"); }elseif(isset($_SESSION['logged_in']) &amp;&amp; $page == 3){ include("page3.php"); } // Since we are including each file only when needed we can call a general process function // If you wanted to include all files in the top of this one, then you would just name // a function different for each and call it in the if statement instead. process_page(); &lt;?php /***** * PAGE1.PHP */ // PAGE 1 - Login form function process_page(){ $error = false; // We've found a submitted form hopefully, now process it if(isset$_POST['submit'])){ // Test if password field is supplied and check it against our password if(isset($_POST['password']) &amp;&amp; $_POST['password'] == "mySecurePassword"){ $_SESSION['logged_in'] = "1"; header("Location: index.php?page=2"); exit(); }else{ $error = true; } } if($error){ echo "Password invalid or not supplied"; } // Login form here, form like this: &lt;form method="post" action="index.php?page=1"&gt; } &lt;?php /***** * PAGE2.PHP */ // PAGE 2 - Upload form function process_page(){ if(isset($_POST['submit'])){ // do a check for valid posted variables to upload the file if(isset($_POST['var1']) &amp;&amp; strlen($_POST['var1']) &gt; 0 &amp;&amp; isset($_POST['var2']) &amp;&amp; strlen($_POST['var2']) &gt; 0){ $new_filename = microtime(true); move_uploaded_file($_FILES['image']['tmp_name'], "uploads/".$new_filename); file_put_contents("images_list.csv", $new_filename."|".$_POST['var1']."|".$_POST['var2']."\n", FILE_APPEND); header("Location: index.php?page=3"); exit(); } } // Upload form stuff goes here. It actions to index.php?page=2 } &lt;?php /***** * PAGE3.PHP */ // PAGE 3 - Upload form function process_page(){ $image_list = explode("\n", file_get_contents("image_list.csv)); for($i = 0; $i &lt; count($image_list); $i++){ $image = explode("|", $image_list[$i]); echo "&lt;p&gt;&lt;img src='".$image[0]."'&gt;&lt;br/&gt;VAR1: ".$image[1]."&lt;br/&gt;VAR2: ".$image[2]."&lt;/p&gt;"; } }
MySQL -- where UTF8 isn't actually UTF8.
Always happens when you hit the record button haha
holly crap! 
I to would agree with Joe that next time more attention could be paid to the planning phase. However, as this was our first recording, we were unsure on the exact format the show would take. I feel that 'monstrous' is a heavy exaggeration to describe the ums n' uhs. The material was recorded in a single hit, and it was on me to better edit it after the fact. My idea was to make it feel like a true hands-on peer coding sessions, as opposed to the cleanly cut video screen-casts you may be more of a fan of.
One caution: Changing from `utf8` to `utf8mb4` isn't entirely seamless: You're increasing the storage space of some columns, and that can affect how different MySQL engines/settings do indexing. For example, you can usually index a `varchar(255)` column, because `utf8` uses 3 bytes per character and that fits within InnoDB's [default limit of 767 bytes](https://dev.mysql.com/doc/refman/5.5/en/innodb-restrictions.html). However, if you change to `utf8mb4`, then the largest text-column you can index is `varchar(191)`. While you can increase InnoDB's byte-limit to re-allow `varchar(255)` indices, it requires some digging into the InnoDB documentation and tinkering with a bunch of your table settings. MySQL 5.7 should ship with defaults that make things much less of a hassle.
I don't know what kind of info your db holds, but if he gave you back anything more than usernames and hashed passwords or you store anything more than that, you need to hire a professional. That being said, I would take a shot at it with [BurpSuite](https://portswigger.net/burp/download.html). If you know what you're doing and what to look for, you'll more than likely find a lot of vulnerabilities just using that. Metasploit, SQLMap, Acunetix and the like are all good things to try turning on your site as well. 
Several emojis come as a unicode character. you could replace all emojis with their appropriate UTF-8-Code. But If you have to use special character in your JSON string, you can escape it using \ character. So you could just replace :-) with \:\-\) and see if that works. But If I had the problem, I'd solve it with a wysiwyg-editor replacing everything I don't want in the json before submitting. Then the submitted JSON only has be valid, otherwise return an error. 
Up To F8 Pretty much my motto when figuring out how languages use it
Without looking at your code, I can tell you that your problem is trying to do 3 things at the same time, without knowing either of them. Password-protected page, Form with file-upload and showing the table, are 3 different tasks that you should tackle one after the other. All 3 should work on their own, without the others required. Try to understand what's required for each of them. Implement each of them individually and when they all work, put them together to form your page. the functions you use aren't programming. Designing how they should work together is. try to understand each step that happens before making complex systems. Learn forms first, then learn file-uploads. Do it all at once and all you get is the overwhelming sensation of not knowing where to step next. 
exactly so you don't have to bundle all of nodejs.
This is amazing news for php World to use appserver.io as a base :) Love it.
Thanks! 
As there's no example data to pick apart, I'd suggest you try base64_encode before json_encode. &lt;?php $toBeDecoded = json_encode(base64_encode($toBeEncoded)); $normalVar = base64_decode(json_decode($toBeDecoded)); ?&gt;
Can you explain this? I'm guessing the upper limit for a var char index would be 25% less characters?
If you want some data to test with, here's some SQL to try to insert the string `fooðŒ†bar` : INSERT INTO my_test_table (my_utf8_column) VALUES ( CONCAT( 'foo', UNHEX('F09D8C86'), 'bar') ); When it fails, you just get "foo" stored, and MySQL logs a warning.
Good question, habit I suppose ( I normally work with Symfony ). I'll remove them.
&gt; I've heard your name mentioned around here, and you're all the rumors promise. I have not heard yours. I have no time for your drama. Learn or don't learn. &gt; My advice is Incorrect.
You can repeat yourself incorrectly all you want. Whether it receives patches for critical security issues has nothing to do with that a 3.5 year old unicode parser is not expected to understand characters from less than that age ago, *and* a compliant unicode parser ***is required to reject characters it does not know.***
I don't know enough about this to determine who has his facts straight. Is SC downvoted because he's wrong? 
This is the UTF-8 RFC: https://tools.ietf.org/html/rfc3629 It has a single normative "MUST protect against decoding invalid sequences" where "sequences" refers to *UTF-8 byte sequences* that don't match the UTF-8 vocabulary (given in the sections above that remark), and not *codepoints*. The UTF-8 standard *doesn't* make any recommendations about which codepoints must be permitted (aside from their valid range which is: 0 - 0x10FFFF). It doesn't mandate a certain normalization form (which /u/StoneCypher kinda threw in there for no reason, I guess). It also doesn't make any references to the [Unicode Character Database](http://unicode.org/ucd/) (UCD) which /u/StoneCypher is incorrectly calling "codepages" (and [Unicode doesn't like this](http://unicode.org/faq/blocks_ranges.html)). As for ENT_DISALLOWED, its code is based on the provided HTML/XML doctype, which is seen in the source: http://lxr.php.net/xref/PHP_5_4/ext/standard/html.c#unicode_cp_is_allowed http://lxr.php.net/xref/PHP_5_4/ext/standard/html.c#numeric_entity_is_allowed Unlike what /u/StoneCypher said, UCD of a specific version is not referred here either. It's just allowed ranges, that come from the DTD of the respective doctypes. Nikita Popov gives the skinny here: https://nikic.github.io/2012/01/28/htmlspecialchars-improvements-in-PHP-5-4.html &gt; ENT_DISALLOWED. This flag will replace characters with a Unicode Replacement Character, which formally are a valid code unit sequences, but are invalid in the given doctype. And UPGRADING note from PHP 5.4's source (when ENT_DISALLOWED was introduced): http://lxr.php.net/xref/PHP_5_4/UPGRADING#233 &gt; Numerical entities are checked for a valid range (0 to 0x10FFFF); if the flag ENT_DISALLOWED is given, the validity of such numerical entity in the target document type is also checked. Named entities are checked for necessary existence in the target document type instead of only checking whether they were constituted by alphanumeric characters.
agreed (although, i want to find the guy who's written software that depends on this anomaly and, i don't know, maybe hit him with a folding chair, or something?). maria *does* have some extra juice on top of mysql ([regexp_replace](https://mariadb.com/kb/en/mariadb/regexp_replace/) leaps to mind) so they're clearly not committed to dogmatic recreation, but it's a superset of functionality rather than an alteration of existing behaviour.
Did not think about trying that. Thanks. 
Remove half the support?
&gt; Which is exactly my central claim It's not your "central claim". Do you even realize the difference between "UTF-8 sequences" and "codepoints"? I guess not. I already spoke about invalid UTF-8 sequences in my original comment. Read it. You don't need to consult UCD to decode UTF-8, which is what your claim was, to quote you: &gt; This behavior is required by the Unicode standard. All compliant Unicode decoders will throw (or the local equivalent) when provided with a codepoint that is not explicitly present in their **codepage tables**. Also... &gt; No, I'm not [calling it codepages]. Ok. You're not. You didn't say it. I'm just imagining it. 
Could you post the result of json_last_error(); ? http://php.net/manual/en/function.json-last-error.php
I would explain how version control does exactly what he's saying. Why is he hesitant to use a VCS?
If it's always you who makes the changes, you don't need to download a new copy first, so... we have a plot hole. That aside, your client doesn't have to be involved in your technical decisions. Say "we're hosting backups here" and put your SVN or GIT (or other) repository there. Then use it &amp; deploy from it as necessary.
As others have said, the client doesn't need to be involved in your decision to use version control. Its a tool of the trade, and ideally you'd steer away from *devs* who don' t use version control Now, if the issue is that they don't want to install git/svn/whatever so that *you* can deploy from VC, then that's their choice. You still have SSH to deploy via, right? Though, I suspect w/this client it's more likely FTP?
Of course, another problem is if the client has other developers working on the site without version control. In that case, better to find another client.
I find this can also happen when using Word Documents. Specially if the initial hit to the link loads information into a session. The internal process gets the session information, then hands it off to the browser and guess what.. no session information :P Very annoying
Dj jee re dux r4g c
PHP devs probably don't even know what a 16 bit string is
Please submit this to /r/phphelp, or visit ##php on Freenode IRC
No, please don't use it in production. That is just a super basic and fast write up. I left out things that you will need to learn to do and it is not going to be very secure either. This is just a good starting point for you to learn from. Read, understand how it functions, then rewrite it with security and proper functionality in mind. Again, this is just fast first draft of the pseudo code I wrote above. Consider it a proof of concept. 
We've currently got a client like this, a small business whose owner makes changes to a slowly evolving web site... He was used to using FileZilla to update his site. We got him to transition to using the Github for Windows client and using it to sync his changes to master. Then we hooked up dploy.io to the repository to automatically publish all changes in master. This allowed us to maintain our typical workflow with pull requests, while giving him an even more convenient way to update his site... Largely a win-win situation. Do we wish he would participate in our normal workflow and submit PRs? Of course. We can get there someday soon. But for now we have a way for us to do what our job is... Thoughtfully improve his product with small peer reviewed enhancement.
Why would the client even need to be involved in this decision? 
run away.
This simply isn't true. We had several error notices in our analyses relating to @aequasi08's repo and per our terms and conditions we're able to investigate this. We did this at a folder structure level. Simply saw the domain, checked it and saw folder names relating to pornographic material. Our terms and conditions state that we do not allow this content. We didn't need to check code.
There are a lot of benefits, but maybe for this kind of clients, this one could run: With tools like SourceTree and implement a Gitflow pattern, you can fix bugs in production at the same time that you are developing new features, saving time when you integrate hotfixes in your develop branch and then in feature branch. https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow 
Ah, got it. If that's the case, I would set up the VCS so that each push to trunk/master builds a new backup version and dumps it somewhere the client can see. Like what the other have said, I would still use a VCS for sanity purposes, but if the client isn't technically savvy, this should at least accommodate that.
download, commit, change, commit, upload? Then when they screw everything up, you can tell them it's taking you hundreds of hours (which you will bill, after which you'll just restore from your latest commit)
Those are emoticons, not emojis.
I once worked for a nation wide ISP (In Australia) that didn't give subcontractors access to CSV. And we didn't have the network permissions to host our own CSV server. The only problem? About 80% of the workers were subcontractors. Worse? Those who didn't bring in their own machines didn't have permissions to install any programs. Not even programs that were required for the job. So, many (most) of the other contractors were working in Notepad++. And, since they couldn't run dev environments they were working directly on the staging environment. Not even through FTP, they'd set up a mapped network drive straight to the staging server and were writing directly on to that in Notepad++. Wonderful... So for two months I'm doing a complete overhaul of one part of the system to make it less shitty by magnitudes (Think 2000+ lines of nested if statements and repeated SQL queries replaced with 200 lines of a micro orm wrapper inspired by Zend_Db and a couple well places if statements), and when it all worked on my dev environment (My team was one of the very few to use dev environments), I was told to upload it to the staging server. Naturally, I questioned about five times whether or not we could. Whether we were the only ones doing anything on this section of the codebase. Whether we'd be interfering with anyone. I got the all clear every time, so with the permission of my manager one final time, I uploaded my work. And, as you can guess, I overwrote a whole other teams last three weeks of work. Because they weren't using a version control system, they weren't using an IDE that had Local History, they weren't using a dev environment, and they weren't using FTP to upload the files from their machines. Any of these and they could have avoided what had happened, but no, they'd went the direct route to the shittiest way of handling code. Thankfully, I had already scheduled that day as my last day, and the Call of Wrath came in at 4PM, so I checked with my boss before leaving early. Thankfully he knew it was the other teams problem, and there was nothing to be done. I never looked back, and would never ever recommend any of that ISP's products (That's a whole other story on how shitty the system as a whole was, and how flimsy it looked from the inside) for the rest of my days
Of course you can fire a client. Clients do not employ me, my employer employs me or I'm self-employed. This is a business partnership. If the work is more trouble than it's worth, you let the client go. http://www.forbes.com/sites/allbusiness/2014/05/06/6-reasons-to-fire-a-client/
Compare it to their financial records. Would you use a piggy-bank and yellow sticky notes for your sales and payroll?
If you don't want to query on it, just use `text` or `tinytext`etc and send it to the database as the bits you want to put on the wire (e.g. entity-encoded HTML)
An alternative is to simply implement a multibyte-safe JSON decode routine yourself. Here's a good starting place: https://github.com/itspriddle/json-php/blob/master/json.php 
&gt; That's what they use at [insert big company] Genius.
"I quit."
Is the change to the page in code or database? If it's database then you schedule backups if you haven't already done so.
"I quit" At the very least just work with a git repo locally. - have 1 branch where you can rsync the latest changes from the server (master) - work with feature branches for each change you do - before you merge your feature branch with master, rsync from the server - then merge and rsync back to the server These steps are easily automated :) But seriously, try to convince him, no VCS is not allowed anymore since the 90's
"Firing" makes the end of the client relationship sound acrimonious, but it doesn't have to be. Firing in this case simply can mean explaining to the client that no professional programmer will agree not to use version control, and that if the terms of the contract require the freelancer not to use it, they would be better served by someone else. 
Do they know it's free?
While 100% secure software is not possible (aside from trivial apps) the scale for software quality, in regards to security, is universum huge. But what stands out and is a shame is that "more security bugs" in a software is way more common than "less security bugs". For example, see the security bug amount for djb's software (say, [qmail](http://cr.yp.to/qmail.html)), which shows the effect of "security is an absolute requirement" mentality. It is definitely possible to do way better than the current situation is, especially for Magento (among many many others).
Good-bye. Clients should never dictate protocol around development.
Of course. My point is shaming a product for having patches is an incentive for them to go back to hiding and ignoring security issues. Practice has shown that timely patching and disclosing is a better long-term practice for software in general. Magento's codebase quality is another matter entirely (I'm not in any way saying it's well designed).
&gt;How would you respond to something like this? No?
If you don't want to jump into a Magic Box framework for the start, maybe try this: http://symfony.com/doc/current/create_framework/index.html it is a tutorial for writing your "own" framework on top of some core Symfony components. It will help you understand how they work and maybe later switch to full stack Symfony. Phalcon is a magic box, you can't make a breakpoint in phalcon's code because it is a php extension (or I don't know something) so you can't figure what's happening during your requests. I wouldn't recommend Laravel as well, it is full of magic boxes, magic functions, proxy classes/methods, you will have no clue what is going on on the inside.
I would like to clarify something... are you suggesting getting rid of deflating a page ? (Disable compression)
Take a look at http://www.phptherightway.com/ It gives you quick overview of OOP and some design principals, but there's a lot more in there about modern PHP development. It's definately a good starting point. As for the type of projects... any really. You can use modern PHP practices for building Blogs, REST APIs, Image Manipulation libraries, all sorts really. Consider a blog/article system though, you'll have CRUD, permissions, user inputted data (comments), uploads, CRON for scheduling perhaps. There's a lot to expand on.
Cut the client lose and find other clients to work with. Your time and expertise will only be wasted with a client who interferes in the way you do work.
Look into the SOLID design principles. https://en.wikipedia.org/wiki/SOLID_(object-oriented_design)
You need either a subquery or a join: SELECT * FROM playlists WHERE id IN (SELECT id FROM archive WHERE uid = ?) SELECT * FROM playlists AS p JOIN archive AS a ON a.id = p.id WHERE a.uid = ?
Awesome, thank you.
The first step is learning the syntax for writing OOP. I suggest reading [PHP.net's introduction](http://php.net/manual/en/language.oop5.basic.php) to classes. You should be able to answer these questions in order to begin writing OOP: * What is the "new" keyword? * What are class properties? * What does "instance" mean in OOP? * How do I call a method on an object? * What is __construct used for? You should know how to: * Create an instance of a class * Create properties for a class * Write a class Don't worry about doing this all from memory. You may have to look things up again and again. Eventually though you'll begin thinking in OOP--then it becomes difficult to return to the procedural world of doing things. Once you get an understand of OOP that is not enough, though. You can go deeper. Study [Polymorphism](http://code.tutsplus.com/tutorials/understanding-and-applying-polymorphism-in-php--net-14362). Learn [SOLID](https://en.wikipedia.org/wiki/SOLID_%28object-oriented_design%29) principles. Study [Design Patterns](http://www.phptherightway.com/pages/Design-Patterns.html), which are common ways OOP is employed to solve problems. Read [Clean Code](http://www.amazon.com/Clean-Code-Handbook-Software-Craftsmanship/dp/0132350882). I'd also recommend checking [Meetup](http://meetup.com) to find a PHP meetup that is in town. There you can ask questions and learn from those who are further along. If you like video tutorials [Laracasts](https://laracasts.com/series/object-oriented-bootcamp-in-php/episodes/1) has some great screencasts that will get you up and running in no time. Ultimately, you just need a passion for what you're doing, and a drive to be better than yesterday. Don't become complacent. That is a terrible thing. Have fun, your world is about to get much larger.
One more thing: **generally speaking**, you use JOIN like that when you need information from both tables because SELECT can return columns from both of them (e.g. if Archive has a timestamp of when that user finished watching it and you want to show this information). Otherwise you may use a subquery. Also, avoid using * and actually name the columns you need.
The company I work for has been using SVN for ages, and only just recently started using Git for new projects. Do you have any resources on what would make Mercurial or Fossil more useful than Git? It's not too late for us to switch to one of those, if I can convince management why they're better.
Yes, but not for all requests. Only for the HTML pages where you are wanting to optimise for perceived load time. You should leave it turned on for images and other resources. The content you're dealing with may also play a role. If you are serving massive amounts data then it may be impractical to turn off compression (deflate) for those pages.
Thanks for all your comments, certainly given me plenty of things to get started with, much appreciated.
Honestly, don't take the contract. It's not just that they're opposed to git - they're opposed to best practices. If they don't want version control, what else don't they use? - Unit Testing? - Dependency management (Composer)? - Code reviews? - Code style enforcement? - Docblock comments? - Documentation? - Proper security and authentication? - Do they use software against the TOS or license, or worse, use pirated software or stolen code? - Nothing but free software as a rule? I love the open source community, but sometimes, the cheapest and easiest option is the one you pay for. If the client didn't use version control but was open to the idea, then take the contract. But if they're actively opposed, run.
just tilt it on its side
Not directly related but I like this kind of post, more people should speak up about what the PHP ecosystem needs.
This article was posted weeks ago, with many resources https://github.com/marcelgsantos/learning-oop-in-php
I watch too many sitcoms so I often act like I'm the main character in one...which makes my boring job really entertaining to tell to my friends. If you want some crazy office stories PM me.
Thanks for the feedback. I'll definitely look into defaulting an adapter. and yes guzzle would be the way to go. I didn't want to got straight to the api resource, as Marvel returns some attribution/copyright text that is required to be displayed, and I wanted the user to get to that, but yes I agree shorter chains would be a lot better.
I usually just charge double rate for folks like this.
Yes I understand but my question is : Why are they releasing a new major version of a very popular e-commerce framework without making any PHP7-support ? That's ridiculous.
It's a beta product that isn't stable yet. It's bound to have some kinks still. If you have concerns about the stability, contact their support or GitHub issues or whatever the proper channel is (I have no idea).
You should be right. However, if PHP7 is in Magento 2's plans, that's fine.
Im going to be studying PHP until I get it right. I really needed what you sent me thanks a lot. 
Agreed, this way you can instantly see if someone has messed with the code the next time you overlay the FTP changes into your working directory.
$pageTitle = $suppliedTitle ?? "Default Title";
I suspect years!
PHP developer in Orlando here. [I'm definitely not mid-level](https://paragonie.com/blog/tag/php), however. There are a lot of venues where PHP developers can be found: * The Orlando PHP User Group (met earlier tonight, actually) * Various WordPress meet-ups in and around Canvs * Hang around #hackucf on freenode -- lots of talented security-minded folks there, who often know people with specific language skills In particular, I know a few folks in the area that know PHP (but I'm not sure if they'd be considered mid-level or senior by your standards). Feel free to message me on Reddit if you'd like help finding someone.
Hey thanks I appreciate it. I actually will shoot you a PM in the morning. 
That. Is. Awesome.
This belongs in /r/laravel
No it isn't, patching it and not submitting those patches back is reckless.
Thanks, will do. Do you know how it works after the pull request is accepted? As in, am I expected to keep the Handler up to date? Or is it just every contributor's responsibility at that point?
But sometimes you need to store a password in a config file, for database connection in example. Then it's better to encode it with Base64. It's not a cryptographic method, it's just for legal purposes: If somebody use this password to do something not related to the business, in a trial you can prove intent, because a command execution or profund mental calculations are needed to know the password. 
Whoa, never thought of this aspect before.
If you're starting out with a framework for the first time, phalcon will not be the best choice. I recommend laravel or codeigniter. I learnt mvc with codeigniter and now learning laravel. They never felt like magic box. you can always read through source code or insert break points to see what's happening.. and laravel will be fun. so start with a smaller easier framework then try something different.. this is my way..
Oh that sounds great, I'll definitely try to get it pulled. Although if you don't mind, could you help me figure out how to do the tests? The main reason I'm stumped is that IFTTT requires a secret key to send data to it, which is obviously not something I want to disclose. What would you recommend to create a proper test? A dummy account's secret key? Maybe some sort of mock Curl request?
Don't worry about actually firing their API. That would be an *integration* test. You just want a *unit* test to prove that curl is being fired with the expected data. Usually in this situation you would just pass in some sort of HTTP client object wraps up the curl functions, so you can easily mock it out for your tests. However you can't do that here because you're just using built in `curl_*` functions (which is totally fine; a proper HTTP client like Guzzle would probably be overkill and Seldaek probably wouldn't want the added bloat anyway). Because of that, you need to do function mocking. Google around if you want to learn how function mocking with namespaces works. You could use another lib to do it (shameless self promotion https://github.com/adamnicholson/fnmock), but for the best chances of having the PR accepted you may want to see if you can mock the function call out without another dev dependency. Again, there are articles around which give you an idea how to do this. If I get time on my lunch today I'll drop you a PR with how I'd do it.
It is worth mentioning that PHP 7 brings a couple of cosmetic improvements for coroutines. While you can also do well without them, they make the ergonomics somewhat nicer: * You no longer need to wrap `yield` expressions in parentheses. This requirement was always very awkward, and now it's gone. * You can `return` a value from a coroutine. Previously you had to hack around this either using designated exceptions, coroutine keys or marker objects. So now it's `return $foo` instead of `yield "retval" =&gt; $foo`, `yield retval($foo)` or `throw retval($foo)`. * It's possible to directly call ("delegate to") another coroutine. Previously this would be handled by some black magic wrappers. Now PHP support its natively using `yield from coro()`. (With the added benefit that it's faster.)
https://twitter.com/PHP_CEO/status/618908167678918657
I could move to Ontario, just for you ;) Tho I'm from Europe :&lt;
Well Ontario wouldn't be a wise choice since I'm in Orlando Florida :)
A while back I tried David Walsh's implementation which is actually a bit old but still works (read the comments about the certificate). http://davidwalsh.name/gmail-php-imap
[What to do when you need crypto](https://youtu.be/0m2ZUS9OH4k) That's a tutorial from Pycon this year, and yes some parts are Python specific (library suggestions mostly), but there's plenty of general purpose knowledge. 
What happens with `try... (catch...) finally`?
Oh lol, my reading skills were temporarily impaired :&lt; still was joking anyway... Good luck with searching for people!
That's unaffected. `try` is a control statement, I'm talking about memory management of objects.
Kinda the point of the next paragraph is saying that platform allows you to "deploy things on Friday" without worry.
As someone that works weekends fuck off if you deploy your broken feces on a Friday so my weekend is wasted calling the "on-call" tech only to get told he can't do anything until Monday. Then I get questioned on why nothing was done all weekend. Happens nearly once a freaking month.
lol. 1) I don't deploy Friday. I don't use platform.sh 2) Feels like you ignored my message, and the message i was paraphrasing. 
But, `finally` is unrelated to program shutdown, is it not? Yes, `__destruct` would be called on shutdown and garbage collection, but you lose predictability (if there ever was one).
&gt; Destructors aren't triggered in a few places as it stands. It's hard to know exactly when a destructor is called in PHP, if ever. As a heavy user of destructors... they seem to be working just fine.
unless my regular hours are Tuesday-&gt;Saturday!
How would you feel if `__destruct` would be run arbitrary at garbage collection instead of when refcount = 0? You think the language would lose something? Could it be worth it if we gain speed instead?
It's a solid example, but since 2012 it should be "why you don't `md5` or `sha1`" a password, or more positive, hey it's 2015, PHP has `password_hash` and `password_verify` ;) Anyway the worst example I ever saw was a business offering compliance solutions for surviving an audit with an MD5 with static hard-coded salt `abracadabra`... Who the hell does that?
&gt; I was thinking of simplifying it by removing refcounts and use only garbage collection. Maybe I don't get you. But isn't refcount the basic property on which garbage collection decides what qualifies as garbage? Also it's used in cylce detection as well (in conjunction with a root buffer).
This seems to make the most sense. If you (OP) have the possibility to use a VCS of your own, while maintaining it on your own, then you should just do that. If someone else than you is modifying the codebase (as in someone not using your VCS), just rsync the codebase to a clean branch periodically and merge it with your own branches when you want to test/deploy. It's pretty low overhead, and it serves as the backup your client asks for, as long as your VCS is properly backed up. As other said though, not using a VCS is probably gonna mean quite some annoying stuff aswell (no tests, funky codebase etc), this is what you should decide if you're ready to cope with or not. Usually it boils down to how large is the scope of your contract with that client.
I don't know so much about this yet, but refcounted objects are supposed to be deleted _immediately_ when refcount reaches 0, while GC can collect the garbage on different criteria (non-deterministic).
it's related to shutdown in the uncaught exception case
I instantiate my dependency injector, pass into it all my applications dependencies, instantiate my application class and run it all within a try block, then catch all exceptions that get thrown, then unset my dependency injector and application in the finally... Am I doing it wrong?
JavaScript Promises have a chainable catch-method: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/catch Doesn't that solve the same problem coroutines are solving, but more elegantly?
While true, at the end of the day somewhere there is a password in plaintext. I don't know if I'd consider much weight of .env being any different than in a config file (presumably that isn't checked into a vcs)
Wait, did you remove your other comment? Because I think it was very interesting and highly relevant, regarding the expected life-span of a script. Because if the script is small, you could possibly configure the GC to not collect anything at all, or have a high threshold for collecting.
I, for example, use destructors for rollback of transactions. If a transaction instance goes out of scope without a commit, it's rolled back automatically. Not supporting RAII would cause my code to break (or be unreliable) in subtle ways. If you're happy with less than 100% PHP compatibility, go for it. 
I realized I'm assuming too much when making these recommendations. I don't know enough about your project or the context it'll be used in. Indeed it's possible to not collect anything at all until script shutdown and that'll be slightly faster (around 10%^\* ) but take a whole lot more RAM, RAM developers can spend on data caches that will improve performance a lot more than 10%, so I don't know if it makes sense. ^\* I was in the beta advisory team some years back when Flash transitioned from refcounting to garbage collection (from version 8 to version 9). The team had around 10% speedup, but had a new problem: hiccupy animation when the garbage collector collects. It took a lot of work to fix that. Also consider Apple - they tried garbage collection, and gave up on it in favor of refcounting. Their mobile platform is known for being the more efficient one (better performing on same or lesser hardware, relative to Android's Dalvik). GC is definitely not a panacea.
Happy cakeday!
Code generator libraries are intended to be used programatically, for example: * [phpspec](http://www.phpspec.net/en/latest/) bootstraps the class corresponding to the test that's just been written, when running the test suite * [symfony](http://symfony.com/) "compiles" configuration files (yaml, xml, annotations) into their corresponding PHP instructions * [doctrine](http://doctrine-orm.readthedocs.org/en/latest/reference/tools.html#entity-generation) provides a command that bootstraps classes corresponding the the schema described Provided that the library grows enough to get read capacity, you could also start writing [refactoring browsers](http://martinfowler.com/articles/refactoringRubicon.html) like the one created by [Qafoo Labs](https://qafoo.com/blog/041_refactoring_browser.html) (or like IntelliSense in PHPStorm). And of course there's also all those graphical interfaces that allow you to create code via "pointing and clicking", or by using configuration (see also: [Intentional Programming](http://martinfowler.com/bliki/IntentionalSoftware.html)). So to sum up, Code Generation libraries are only small building blocks used in bigger software, the possibilities are endless.
But nothing can be zero risk. It's always better to deploy when you have time to fix it if it goes wrong.
Oh, right. I think I got the wrong idea of the "coroutine" concept from this article. Your explanation is much clearer. Definitely agree that `yield/async` helps to write more comprehendible asynchronous code.
If the code that was released many months ago (or was it years ago... 'I lost track') was legitimately Facebook's original codebase, then it's absolutely no surprise why they couldn't scale well. Surprisingly that they were even able to scale (horizontally that is) at all.. Although, the amount of requests (including caching methodologies) that they have per second still blows my mind. Scaling at such a high and wide amount goes beyond just the language or languages (at such point) that they're using.
how is this different from something like Behat?
Also, someone pointed out that I own 21% of php-cs-fixer, so for all you people that downvote that comment, maybe you should so something useful to help someone...
I've used both phpspec and phpunit **a lot** and can never say I've been completely happy with phpspec. The generator functionality is great, but in every other regard I find phpunit (with mockery) to be a superior testing suite. Edit: as a final note, [atoum](https://github.com/atoum/atoum) seems quite interesting but I have not tried it for anything. One particularly interesting feature is the ability to mock native functions.
Wow, that is a pretty hefty set of expectations ... I'd be surprised if you find anything. I work an a community calendar project - this is aimed at many people adding events to one public calendar so is different from what you want. http://ican.openacalendar.org/ However one approach I've been taking is to split a lot of the lower level functionality out into separate packages, and this is a process I'd like to continue as much as possible. It makes development easier, having a clearly defined set of functionality and tests for it, and it aids reuse and thus others building up these libraries to. EDIT: One thing I find while checking other libraries out is they often don't or aren't clear about timezone support! This is one of the main reasons I've started to work on functionality that you can basically find in some other libs. I try and design my libs to be very clear about where timezones are explicitly passed in and out, with no implicit passing. Here are some of them so far: http://ican.openacalendar.org/libraries/php/ and I recently started on a library to read microformats and schema.org tags for events from a HTML web page. None of this will directly help you ... but very interested in what you find in this area!
Behat allows you to make User Stories and their acceptance criteria executable. You can compare this to functional tests. phpspec allows you to describe the behavior of a class, through use cases. You can compare this to unit tests.
Here's the two in parallel use: https://semaphoreci.com/community/tutorials/getting-started-with-bdd-in-laravel for some comparison.
PHPUnit allows you to write any kind of tests (unit test, functional test, even end-to-end test with Selenium), while phpspec only allows you to write unit test. And it forces you to follow a set of practices (test only public APIs, objects only, mockist TDD, etc). Personally I use it for smoking tests with my web APIs (if I give this HTTP request, then I expect to get this HTTP status code). I don't expect phpspec to be the right tool for every use case, nor for anyone, but I'd still highly recommend it: every time I got frustrated with its "limitations", I learned something new as it usually means that I'm trying to do something "wrong" (at least according to their set of standards). I use it to write my unit tests (also running the test suite is always blazing fast, usually less than a second). Note: I've heard a lot of good things about Atoum, especially about its assertion system but I've never tried it. Oh, and there's also [Codeception](http://codeception.com/) which makes a clear distinction between "Acceptance Tests", "Functional Tests" and "Unit Tests", I've used it a bit before moving to phpspec.
&gt; I think I got the wrong idea of the "coroutine" concept from this article. Heh, thanks for the feedback on that. The article wasn't meant to be a complete introduction to coroutines.
Yeah, those improvements will be a significant advance for implementing asynchronous code. We're planning on taking advantage of them in [Icicle](http://github.com/icicleio/icicle) (especially `yield from`). It may take some time for PHP 7 to be widely adopted though, so backwards compatibility is still an issue.
the HHVM guys are several months ahead of you. Perhaps they would share their code if you reached out?
Pay my moving costs (from NZ) and I'm there :P (I don't own anything so in reality it's just a single flight) But seriously, how would you define a mid-level dev?
destructors for resource cleanup are shit in languages that do not have a deterministic destructor and its not exception safe. GC languages commonly employ a "using" or "with" scope for cleanup or a "finally" clause that are exception safe. Not to mention that a "close" method completely breaks the type after its use since "read" or "write" methods are no longer valid.
Kudos for using SI units
It's true that the assertions in phpspec are quite different. For your example: if you encapsulate the calls to this library in a Gateway class ([as demonstrated here by Martin Fowler](http://martinfowler.com/articles/refactoring-external-service.html)), then you'd just have to mock this one class.
I'm saying, there was active work about 9 months ago on a PHP [or was it Hack?] LLVM integration. I know they at least did the prototype.
I know it's superficial of me, and very inconsequential in the big picture, but every time I see it, it's like someone shoving a stick in an open wound that's trying to heal: *those PHPuns have to stop*...
In related news Slim is changing it's name to PHPat ;) http://thoughts.silentworks.co.uk/why-is-slim3-not-so-slim-anymore/
Hear hear
If you want to use coroutines, you should really upgrade to PHP 7, adding parenthesis for every `yield` is such a pain.
It works, and if it fulfills your requirements, use it. I also have an FOSS that offers more customization: https://puphpet.com
puphpet.com is what we use (thanks to /u/jtreminio) 
I just dealt with it the first time after taking up an existing project. It looks like it has some good stuff about it, but I also feel like I prefer pure PHP. 
I'd use this https://puphpet.com/ Just pick the things you want, and download a zip with the configs. Works very well.
I tend to agree, though using generators to coalesce promise-based async operations into a single function makes the distinction less important because the coroutine library hides this logic. The error-first result style is less functional and more imperative but has seen successful both in node.js and golang. Promoting error-handling to be part of every async result appeals to me because every async operation is capable of failure. Is it a bit more imperative than functional? Sure. But PHP is not a strict functional language anyway and IMO the performance benefits of fewer userland fcalls and object instantiations at such a low-level of the application is worthwhile ... especially considering how coroutines hide this logic anyway.
You've provided what it does. What developers need to know is WHY. You should identify the problem that your package solves. When I or other developers go to packagist.org to find a useful package we have a specific problem on their mind like: "I need to be database type agnositic (db abstraction layer)" or "I need to transform data from one representation to another". We aren't searching for implementation specific details -- which is what your current description is providing. So you should document the cases where you need a dynamic getter/setter or to dynamically add methods to an object as the problems your package helps solve.
Codeigniter was a good framework, but as it took a large amount of time to implement new features, and due to ellislabs inability to maintain it, it was adopted by British Columbia Institute of Technology pretty recently. Codeigniter is out of date, and there are other better alternatives which do implement some newer features of the language. Look at: * Symfony * Zend * Laravel Or if you're looking into a microframework: * Silex * Lumen There are a few other packages which would allow you to put your own configuration together using composer packages, but my current personal preference is to use Laravel.
Matching production is the most important reason, but it's also nice to have isolated environments when I'm working on multiple things. Also, Puphpet makes it easy to have pristine, disposable VMs (the same reason I love AWS).
Overall I like this approach to domain logic and have been using a similar pattern for awhile. This makes it really easy when you suddenly need to create 2000 orders by hand for a client and you want to make sure all the appropriate events and related data is created correctly - just grab a CLI script and loop through the orders using your service class. I'm not grasping the necessity of the payload object, though. What's wrong with using classes like LogicException and InvalidArgumentException to deliver error messages? I find I don't need a return message very often in the case of a success. Things like LogicException can be caught and returned safely as an HTTP 200 response with the exception message as the error message. Another thing I've noticed with this pattern is the role of the controller becomes far less important - you're mostly just chauffeuring data in and out of your service class to your view. Lately I've been experimenting with a high level controller that reads annotations out of my service classes to determine what service needs to be loaded and which parameters need to be injected, so I don't have to write any of that chauffeuring logic anymore. Another side benefit is I can auto generate detailed API documentation for all my service class routes. 
Amazon is very Java heavy. As mentioned elsewhere in these comments, so is Twitter. I know Google was at one point, too (although not the search engine code), and I suppose you could argue that Android has a similar scale. These are just the consumer facing sites that everyone knows of. Number of users isn't the only way to measure scale - there are other businesses dealing with a similar level of transactions per second where speed is even more crucial (think financial industries and stock trading). 
Let's ignore the fact that we're not all guys here for a moment. ;) I've worked with CodeIgniter 2.1.x for a previous employer, and identified a timing attack -&gt; PHP object injection vulnerability in their session driver. Around the same time, someone else discovered that if you encrypted the session cookie, it didn't authenticate it, leading to a much more practical attack to achieve the same result. When 3.0 came out, it came out with an encryption library that was developed in part because of my feedback. Now, the guy who wrote that library has become very knowledgeable in the same discipline and continues to work on CI patches. So what's my point in all this narrative? My point is that it used to be bad, now it's better, and although I don't agree with some of their decisions (supporting PHP 5.2), they do listen to the community. It can get better. Would I recommend it today? I'd place more confidence in Symfony, to be quite honest. You can probably use CI safely into the future, provided you keep your `system/` directory up to date.
it's the Wordpress of frameworks
Were the timing attack/php obj injection issues fixed in any of the 2.-something versions?
Not sure if you're from U.S. or not (I assume not), but "guys" is just a colloquial expression used here...it doesn't literally mean men.
[Model View Controller](https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller). It's the current standard for most web &amp; mobile app development nowadays.
You sound like me before I fully explored CodeIgniter and related frameworks.
Old and flimsy. Only slightly better than just writing straight PHP.
its was ok. 
&gt; Yes, guys has always been somewhat gender neutral. My granddad disagrees with you.
It's far from dead. CI 3 was released in march 2015 and now they are working on CI 4, which target PHP 7.
I use [this](http://www.sitepoint.com/quick-tip-get-homestead-vagrant-vm-running/), which is a slightly tweaked Homestead box. Easiest to get up and running (exactly 5 shell commands from zero to running and serving VM), and closest to the production server I usually deploy on.
Some good stuff. I'm not digging the payload objects as an alternative to throwing. Don't get my wrong, I really like result and argument objects when they make sense, but if something goes wrong just throw. Maybe what I'm rebelling against here is the fact that validation is only happening in the model (the domain). That's good -- the domain *should* do its validation, but returning a generic payload object and pretending your model doesn't know about the view in which it acts is a fantasy. You're clearly writing error messages to show in the view (responder), whatever that may be, and creating those messages in the domain. The model needs to protect its own invariants, yes, but input validation is a UX concern so you can show meaningful messages to the user. For example, in a complex input scheme the user might appreciate feedback about which specific fields they messed up -- "order.items may not be empty" -- not a generic message from the domain. Your controller (action) knows how to do that. Some more coherent reading that my rambling: http://verraes.net/2015/02/form-command-model-validation/ All of that doesn't even touch on the fact that every service class that swallows exceptions now has to have a logger or something similar to make sure those errors aren't lost in the aether. In the service example should one of those database calls go wrong and an exception happens I'd want to see that in my logs to know whether its a concern. It might be as simple as a constraint violation which I wouldn't care about -- the database did its job -- or something more serious like a lock timeout. One huge benefit to using result objects, not seen here, is that you can [collect multiple errors](http://martinfowler.com/articles/replaceThrowWithNotification.html) and return a response to the user with all those errors at once. Most good input validation or form systems can do this for you.
Sounds like Laravel is something I might check out after this project. I'm pretty much stuck with CI for now, but next time I start a new one myself I'll check out Laravel. 
Just bad UX, not any specific problems. Expecially with a complex input scheme I might want to tell a user that field X was invalid and here's why. To the model field X might be the array key X, but the user might have sent a huge JSON request where field X was at the path `data.order.items.id` or something. I'm saying validation should happen in both places. Input validation needs to happen to give the user better error messages. Model validation needs to happen because you don't want to put junk into your system. It's a bit of duplication, but the contexts are so different that it makes sense.
A service is able to respond with detailed information like this (which fields are wrong and why). That's how I do it.
But are those fields the same as what was supplied to the client? With an API implementation they might not be. Take even a simple form: how does the model pass messages back to the view about which form fields to show as error states? Pass keys back? Does the view take care of associating them? Or does the model get to know what those form fields are? Do service class inputs always mimic inputs from the HTTP request? What if the service gets used in multiple contexts (HTTP, CLI), are the fields the same? Do the responses give real, actionable information when the user messes up? 99% of the time this shit does not matter, of course. You're just building a CRUD webapp. I end up doing a lot of different contexts with applications for work (CLI, background processes, web, APIs, etc) and end up thinking waaaay to much about this.
Maybe women aren't a homogenous subset of the human population and each woman has a different answer to that question? :)
Controller's only job is to map HTTP (or whatever) input to service input and service output to view output. So the controller does the mapping. Typically not much mapping is necessary, only replacing the root key of the fields, say from service_input.foo to some_html_form.foo, which is easy to automate with reusable code. This pseudo-code example is fairly close to what a service call looks like in my real controllers: try { $service-&gt;doThing($request-&gt;body('formname')); } catch (ServiceException $e) { $log-&gt;import($e, ['input' =&gt; 'formname']); } The above is when we have a classic post-back form submission. Actually as I use XHR, there's no formname and no mapping in most cases, as it's inferable from the rest of the request context: try { $service-&gt;doThing($request-&gt;body()); } catch (ServiceException $e) { $log-&gt;import($e); } Service inputs don't mimic the HTTP request, the service input is modeled independently around a JSON-compatible data tree (because JSON or JSON-compatible structures are easy to pass through any media), but this maps very well to forms, where in most cases one form field is one JSON field. This also answers some of your other questions (service input is its own thing, not HTTP specific, so it's usable natively from PHP with, say, arrays and objects, or from CLI with JSON).
it doesn't matter, what matters is what most people agree on and the existing literature to back it up. You can't expect people on an anonymous forum to never hurt your feelings. That's why you should never take anything personally here. http://www.thefreedictionary.com/guys &gt; guys : Informal Persons of either sex.
&gt; But your payload objects are missing some features that exception offer. Like explicit classes representing specific errors. (/me nods) I originally used different classes for different Payload statuses, and keyed response status codes on the class names (e.g. `Payload\Created` mapped to a 201 in the responder). However, that turned out to be a hassle when I wanted to build custom Payload classes for different Domains, or extend them. As such, I switched over to the more generic Payload you see now, with constants for Domain statuses. But there's nothing that says you have to use the generic Aura one. If you wanted to be super-diligent, you might even create a different Payload class for each Domain type and status (OrderCreatedPayload, OrderNotCreatedPayload, OrderInputNotValidPayload, etc.). That would have the same benefits you suggest that Exceptions have, except (heh) you return them instead of throwing them. &gt; Fine grained catch statement means some exceptions can be caught and dealt with by showing errors vs. propagated up the stack. I assert there is *no need at all* for a Controller (Action) to catch Domain exceptions. The Domain should catch them, and report back to the calling code what happened, in a non-exceptional way. If an exception *does* bubble up it means something truly is exceptionally wrong. 
Zend is most definitely a framework - it comes with a useful set of decoupled classes that can be used outside of the framework, but it is a full fledged MVC framework. 
The line of "exceptions only for exceptional errors" originates mostly from languages where you can't fully recover normal operation after exceptions, like Objective-C and C++. Exceptions in those languages could lead to messed up memory management (it confuses the ARC counters in Objective-C for example) and it's quite slow compared to other means of handling errors, *if you do it a lot*, like in a loop. But in scripts and in modern languages, it's not really the case we need to take such a hard position against exceptions. Look at Swift 2, which has switched to exceptions for essentially all of its error reporting ("exceptional" or business-as-usual as it might be). Considering a single PHP request will see at most 1-2 service exceptions in case of a problem, we can't really use performance as an excuse. We can't use memory management as an excuse either (PHP doesn't have that problem), and I can't think of any other excuses.
Very interesting reading, thanks for sharing. Though executing it with react look a bit extreme to me. Too "nodish", PHP is not good at it (memory management) 
&gt; I assert there is no need at all for a Controller (Action) to catch Domain exceptions. Eh, I just like to let everything throw and have... 1. The framework deal with it, showing a 500 error page and logging the exception (or showing a CLI error message, or just logging and exiting, etc). 2. Integrating with the framework and converting those domain exceptions to appropriate HTTP responses (probably a 500, sometimes 400) but using the message from exception directly since I know it represents something useful to the user. But, like I said, I'd rather something just fail hard and exit, logging on the way if appropriate. Two different ways to do things. With your example, you give the impression that you're catching all exceptions. Might be good to make a code comment or catch `DomainException` or something in your examples instead?
Why even say it?
BTW, have you tried Docker yet? I mean instead of having different VMs available. 
&gt; Let's ignore the fact that we're not all guys here for a moment. ;) If we're not all guys then what are we since "guys" is gender neutral ? I say let it go, you were wrong then you're still wrong now, whatever you thought the OP meant you are the only one here that misunderstood .
We use scotchbox for most of our dev environments, its easy and works well.