Can I use it if I'm not from Russia?
Your title is wrong. WordPress is not moving to JavaScript. WordPress.com is moving to JavaScript (Calypso project), and parts of WordPress that are already JavaScript are moving to *different* JavaScript (new Gutenburg editor, using ReactJS last I checked, but maybe switch to VueJS or something else because licensing). WordPress is currently **by far** the most popular platform on which to build a website. A good reason for that is because it's easy to setup and it rarely requires users to make complex decisions about things like hosting. Moving to a JavaScript (NodeJS) backend would not be just an "upgrade." That would be a move to an entirely new platform that would likely require users to also move to a new host. I just don't see it happening. On the other hand moving more and more of the Dashboard to JavaScript seems likely, and I'd encourage it because the current implementation has always seemed a tad sluggish. Putting more rendering on the client and fewer HTTP requests would help significantly. As a developer I love coding for NodeJS, which is why I am so excited with the improvements being made in PHP in 7.X. The fact that functions are just another data type to be passed around is incredibly beneficial, and I'm using callbacks and closures heavily in my own PHP code these days. Handling JSON is basically automatic in NodeJS, but it's only one function call away in PHP. The quality libraries available via composer seems to be every bit as extensive as those available through npm. The only really compelling feature that NodeJS support that PHP currently does not (without extensions) is asynchronous code, but I see that coming down the pipe at some point in the near future.
He-he, of course you can :) Why even asking?!
I can't help with a cursor based pagination but doctrine does have a built in pagination: http://docs.doctrine-project.org/projects/doctrine-orm/en/latest/tutorials/pagination.html. Might not be what your looking for but for most cases does the job just fine. 
&gt; Is php really dying This auld chestnut again. The answer's "no". Next question! 
This seems fairly much like a reiteration of the `global $var` anti-pattern. I agree the word `use` is poorly chosen, since it is used for drastically different things. Something like `carry` or `expose` would have been better, but - to me - the syntax is fine.
Actually seems that I haven't been paying attention. Just saw MySQL now has an alternate protocol, X Protocol these days. https://dev.mysql.com/doc/internals/en/x-protocol-use-cases-use-cases.html#x-protocol-use-cases-prepared-statements-with-single-round-trip
It's not but I did use a tutorial... Tinfoil hats coming out? 
Closures by default in PHP receive copies of the parent scope when `use`d. This makes it so that the the parents scope can be picked up by the gc after the closure is returned. Because we can't mutate those variables unless we explicitly state that we will. This has some trade offs compared to js for example. It prevents unintended mutation of parent scope but requires additional boilerplate. for ($i = 0; $i &lt; 10; $i++) { some_func(function () use ($i) { return $i--; }); } Another problem is that PHP has variable variables (`$$str`). The interpreter cannot determine what variable you're trying to import. There is some more information in the closure RFC
Another thing to note is that PHP lets you use variables without declaring them first. Requiring that the developer explicitly state their intentions is the correct choice here. If the developer starts stuffing stuff into an array that was not declared in the closure but was defined in the previous scope then it is unclear what they are trying to do. Making the language pretty is significantly less important than reducing unintentional side effects.
&gt;&gt; But one thing that Uncle Bob says ‚ÄúFrameworks are out there to get you. You should not extend frameworks‚Äù. This is only suitable if you are worried about the framework. I can confidently say most people actually do not change frameworks for the lifetime of a project. That's not what Uncle Bob means. You obviously shouldn't modify the source code of the framework your using. What he means is that you shouldn't build your application INSIDE a framework. E.g. this is what pretty much every Laravel application does, using the framework as a foundation for your app where the lines between framework and business logic are blurred. What you want to do instead is to EXPOSE your business logic to the framework by encapsulating your business logic in a library. 
How does this compare to using toran-proxy ?
I don't think there is a library but I've implemented this. Your naive implementation sounds correct. If the order by is descending the where clause will be `where cursor_field &lt; :cursor`. For ascending order it's greater than. You can only order by fields that are part of the cursor. If you support paging forwards and backwards [like facebook does](https://developers.facebook.com/docs/graph-api/using-graph-api/) the order by clause is reversed. You can then call `array_reverse` on the collection to get the sort the client expects. Make sure you have an index on the field you are using for the cursor and make sure it's unique. If it's not unique you need to use row values syntax and combine it with something that is unique. [This article](http://use-the-index-luke.com/sql/partial-results/fetch-next-page) explains that well. I just use base64_encode on the cursor because I don't really care if the client knows what it is, I just want to discourage them from trying to save it or do math or anything. The client can just keep fetching the next cursor until no results are returned. As an optimization you can fetch (limit + 1) then check if (count(results) &gt; limit) to know if you have a next page, then slice the collection to the requested limit before returning it. You could also do a count before adding the cursor where condition. A doctrine extension would be great. I really like how it's [implemented in JOOQ](https://www.jooq.org/doc/3.3/manual/sql-building/sql-statements/select-statement/seek-clause/) and I've thought about trying to implement that as a doctrine extension. It's a pain to implement but the performance it's a huge improvement for large tables over the default doctrine pagination.
just get your mum to do it
Yes. I'm using it for the classic per page pagination. But it won't handle a cursor based pagination as is.
Packages doesn't serve or host the git repositories itself, only the dist archives (if enabled). It only acts as an enhanced Satis repository, whereas it looks like Toran Proxy has additional features to help speed up Composer. Otherwise, Packages is designed to be flexible-- not just for Satis. We've written a few different private plugins that handled stuff like updating Redmine and JIRA and deploying to staging. However, it definitely won't compete with a true CI platform like Jenkins or Travis. But if you are looking for something much simpler and easier to customize than Packagist or Jenkins, maybe Packages is for you.
Thanks for the feedback. Clearly, I don't want a solution that would use post-processing. When you query more data than necessary to make pagination work properly. It has to use a nice query builder and as few queries as possible to handle cursor based pagination. A Doctrine extension might be the way to go. I'm actually also looking for a ACL query solution. Someone did a nice one using a Doctrine extension and custom SQL Walker. I guess I will have to build it myself...
That‚Äôs fantastic mate! Thanks for the explanation sincerely ‚ù§Ô∏è. It‚Äôs so much nicer to actually talk about it than just being a snide, isn‚Äôt it @SaraMG?
http://news.php.net/php.internals/101043 :)
üëèüëèüëèüëè
[Look the account of the twitter integration in the last block of sidebar : @ShrapnelCol](http://hpics.li/4408c18). I'm pretty sure I'm not full of shit.
Thanks for the comment. /u/pan069 . Well, I agree that one should not definitely modify any framework source code. That would be asking for trouble. But there is nothing wrong with extending a framework's class or using its features. If a project is big, and if you are worried that the framework might go away after some years, then yes you can shield yourself from the framework. But for small to medium projects, they will probably not outlive the framework themselves. They should not be following architectures where everything is under and interface and shielded. That layer of abstraction is pretty much time wasted. Yes it will be easy to switch frameworks, but that day won't be coming for such a project. Big projects, long term vision? Go ahead follow the Clean Architecture. I would agree in that case. That is the point I wanted to get across.
I can't really look at that pic because I get a pop-up every time I try to zoom in.. But case closed I guess? I don't even own a domain right now 
Fuck me that free image hosting is terrible.
Thanks for the suggestion but to be honest, and I know I'm a little bit of a hypocrite because I did use hijax (though I may get rid of it), I'd rather not include any libraries or unnecessary frameworks when I can just get it done in straight php and html. 
It's running on old forum software with legacy code.. Can't upgrade until the forum software changes.
Got it. That will make my code a lot smaller in my functions file. I wasn't sure the best way to go about that. I didn't really try to pretty it up so it's probably pretty jumbled, but thanks for taking your time to look through it and make a write up in the first place! I didn't really have a big php book next to me when I made it and I tried to search for the right way to do things, though I guess I'll have to read that link that was posted on how to code php 7 properly. I really wish I didn't have to make it compatible with the old versions but it's running on old forum software with some legacy code.. It's a mess.
He's the one who wrote the tutorial you were talking about right? 
Why is this better than adding a `repositories` field in `composer.json`?
I wrote it for some old forum software, though it can run without it if I make a few changes to the market file. Thanks for your suggestions on what to look out for in the code, I'll be sure to look it over a few dozen more times fixing stuff, and I'll read that giant link you posted as well. 
Well, you have more security problems. You should resolve those (and not deploy the code you've written anywhere!), and then work on your own code.
More security problems in my code? 
Well, possibly, but lets list the problems you have: 1) outdated PHP version 2) outdated mysql version 3) outdated install of vBulletin 4) your code 5) If the server is running old PHP And old MySQL, what about other software on the server? (Apache? the OS itself?) Security is a foundation you build everything else on. If your house lacks a foundation, you can't really just add one later without a lot of work.
It is not only for those who are concerned about changing frameworks. It's not a maintainable architecture. Period. Eventually you will probably need to upgrade your framework. Whether it's because you want access to new features of because you're no longer receiving security updates. Maybe a new version of a required package, or a new package altogether, modify or depend on functionality in the core framework. You run the risk of introducing obscure side effects by approaching inheritance so haphazardly. 
You'd still have to add in a repositories field. But this would be the only thing you'd add in, since it'd be able to reference this server as its own packagist server. "repositories": [ { "type": "composer", "url": "https://someurlherewhereyouhostthis.com" } ] If you have one project and one thing you just want to put your own package into (say to override one packagist) this might be overkill. However, if you have many private libraries shared across many of your own projects. This is where your own "private" packagist is handy.
You can find a lot of examples in the [docs](https://github.com/php-enqueue/enqueue-dev/blob/master/docs/index.md) for plain php, Symfony, Laraval, Magento1. Also it worth looking at Enqueue related blog [posts](https://blog.forma-pro.com/enqueue/home)
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [php-enqueue/enqueue-dev/.../**index.md** (master ‚Üí 952f592)](https://github.com/php-enqueue/enqueue-dev/blob/952f5926e887df8cad39db04c5f80bd6f29127a2/docs/index.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dpar3m0.)^.
Put google adsense on a website, have a bunch of your friends click the ad from different IPs. Done. What a joke of a midterm. What a joke of a teacher. What Uni?
standford
&gt; What is more important is that you should be using PDO, not mysqli. Just because PDO prepared statements are usable and with mysqli it's pain in the ass. Here you can find a PDO tutorial I'm refering to the PDO Tutorial colshrapnel linked. What he didn't say is that it's his writting.
Don't know why you felt you needed to make your own docker image when phalcon has a docker image available https://docs.phalconphp.com/en/3.2/environments-docker
Moodle is pure crap. 
I've been using phalcon on most of my recent projects and it works really well.
&gt; Clearly, I don't want a solution that would use post-processing. When you query more data than necessary to make pagination work properly. If you are referring to fetching +1 results that isn't necessary to make cursor pagination work, it's just an optimization to prevent the API client from having to do another request. With the linked twitter example you can get exactly :count results back and as a result have a next cursor but there is nothing on the next page. Fetching +1 results lets you know there is definitely not another page of results and prevent the client from having to do another request. &gt; It has to use a nice query builder and as few queries as possible to handle cursor based pagination. As long as you aren't doing a count it will only need to use a single query. It's also going to be much more efficient than the single query you would get with offset pagination.
&gt; Don't know why you felt [...] Oddly enough, this attitude is what I've met the most on the the official Phalcon Community forum; even though asking in the forum, this is the first reference to a docker setup I received - and even this had to be met with "I don't know why you felt you had to what you do". No interest in the real issue, no inquiry as to what I'm trying to achieve, what I've tried, just af RTFM response. This is _not_ helpful. It's exactly what I mean when I say that the Phalcon community is poorly backed up compared to the others I mentioned. 
I don't have a lot to say about this, as I haven't evaluated dozens of Slug-generation libraries before. The code looks lean, it tackles all of the use cases I could even envision needing a Slug generator for. I may end up using this.
Sounds like bs to me
i get it completely... certainty is trying to fix the CA problem and replace it with the certainty problem. certainty doesn't provide certainty... you still need to monitor it and decide for yourself who you trust. claiming you can't MITM without being detected is a lie.
You can try docker or vagrant.
https://laravel.com/docs/5.5/homestead you don't have to use the framework to use homestead. Homestead includes PHP 7.1, 7.0, and 5.6
It only breaks every existing closure that manipulates a variable with the same name in the declaring scope. I wouldn't call those breaking changes at all.
Maybe they will write better code in JS. I must say though, I am excited to see how it comes out.
Ditto. https://puphpet.com/
Yeahh I figured that out after I read it again. To be honest I'd still rather use mysqli haha
Nice package, I was reading the code and learnt about substr_compare(), handy!
If you're a Laravel user then I suggest you might want to try Doctrine for Laravel [1]. Doctrine is very different that Eloquent (Active Record vs Data Mapper) and I think if you work through the Doctrine examples given that it might give you a different perspective on persistence. I think that once you have a deeper understanding of both that you will be in a good position to choose either one or the other. [1] http://www.laraveldoctrine.org/ 
asd
First, use LTS, that way you get security updates for a long time. You can certainly set aside a day, if you are upgrading to a major release(once a year usually or less). There are even tools for auto upgrade that can help you a lot, e.g Laravel Shift for Laravel.
Personally I haven't found a single query I couldn't write out with AR queries. It feels a bit like gymnastics, but the fact that results are objects with behavior makes it worth it, in most cases. The only time I don't use AR is when I need to do a mass change on many records all at once, like incrementing the value of a column for a very large number of records, or deleting many-many relations in one shot. I think you should spend a bit more time reading about all the functions available in the framework for the query builder, like `-&gt;select()`, `-&gt;join()`, etc. There's subqueries using anonymous functions too. You'll probably find that everything you need is covered. Most of the time it's write-once anyways.
In general Doctrine used just to save or query is the same as Eloquent, only change is having to inject a dependency to save, edit, delete objects. 
entities with behavior that was 
Active Record vs Data Mapper aside I was pretty much sold on Doctrine the first time I saw its migration system in use. 
There is no such rule that you need always to use AR. I am working on quite a large project for 2 years. Almost all queries are written with the help of Laravel Eloquent. The biggest time saver are functions has() and whereHas() and also scopes. But there are several queries written in plain SQL. Mostly they agregate data for statistics. If it easier to write in AR, use it. If it easier to write in SQL, do it in SQL.
Saved! Thank you :)
Sorry for the rude opening to my comment.
Maybe i'm missing something here but have you tried just [downloading it from their site](https://www.mamp.info/en/downloads/older-versions/).
How do you implement reports? Do you fetch AR objects and do aggregations in PHP?
&gt; I saw its migration system in use. You could use it with eloquent if you like. It's part of DBAL so you could just define schema and use "diff". No ORM needed.
Here is the sad news for you: active record is an architectural anti-pattern. It's due to the fact, that it combines two responsibilities (domain logic and persistence logic). All is well if you use it to abstract simple queries, but the moment you see a `JOIN` statement in the planned structure, you should be ditching it and switching to [data mappers](https://martinfowler.com/eaaCatalog/dataMapper.html). The general options in that case are previously mentioned Doctrine (not sure how "doctine for laravel" differs from the default doctrin package) or writing the custom data mappers yourself. Again, the choice depends on the complexity of your DB schema. The "custom mappers" option would give more .. emm .. consistent results, but it would also require actually knowing SQL and some additional "setup" to get it rolling. You would also loose such features as [unit of work](https://www.martinfowler.com/eaaCatalog/unitOfWork.html), which is noe of the better parts of Doctrine.
&gt; Doctrine should be used according to Online Transaction Processing (OLTP). When you have several "entities" which are related to each other and you need to work with it. Something like aggregates in DDD. If you want to fetch list of entities for example, you don't really need ORM. You could use mapper to map results of query directly to DTO for example. Reporting is also much simpler to do with just SQL. &gt; but I think he added just a method to a User class to validate password, but I think you can do it with eloquent too I would like to see how you do such things in eloquent. For example: user should be able to change password, but only if old password correct and new password has not been used by this user for the last 5 times. For example this is how whole feature will look in Doctrine. No additional code needed. No "save" needed (unit of work will do that for you). public function changePassword(string $oldPassword, string $newPassword, PasswordEncoder $encoder): void { if (!$encoder-&gt;isValid($oldPasswordm, $this-&gt;password) { throw new PasswordNotMatchException(); } $passwordHistory = array_slice(array_merge($this-&gt;passwordHistory, [$this-&gt;password]), -5); foreach ($passwordHistory as $usedPassword) { if ($encoder-&gt;isValid($newPassword, $usedPassword) { throw new PasswordAlreadyHasBeenUsedByUser(); } } $this-&gt;passwordHistory = $passwordHistory; $this-&gt;password = $encoder-&gt;encode($newPassword); } I knew devs who does such things in eloquent using row data gateway pattern, and to simplify life they just implemented their own UoW (it's not hard if you don't need it to be universal like in Doctrine). But thus us kinda exception. Even in symfony+doctrine case most of devs uses Doctrine pretty much like passive record ORM, moving all behaviour to service layer... 
&gt; Here is the sad news for you Some devs thinks that "ORM is anti-pattern". &gt; It's due to the fact, that it combines two responsibilities (domain logic and persistence logic). It breaks separation of concern, yes, but this isn't a big deal in data-centric crud-like applications. If you have bigger application you could just move all behaviour to separate object and use AR models as data model (state). Think of it as "object, which stores it's state in data structure internally" This makes pretty clear separation of concerns and with UoW it's not so hard to implement. Doctrine users also have this strange rule "always use doctrine" which leads to mix of concerns in entities, reduces performance and so on. Doctrine is very handy for write part of application, but for read part you don't need UoW or anything like that. And "mapper" in doctrine just doesn't allow you to do stuff like "map query to DTO" without implementing your own hydrator.
Which is why the major take-away was intended to be: "you probably should write custom data mappers without a library".
Very interesting &gt; My naive implementation would be to use until_id as a cursor for database query. I'm curious how will you define what is this id ? Obvious for a defined entity (primary key) but less for an arbitrary query or composite keys. *For the latter, window functions (like ROW_NUMBER) might help. AFAIK they're supported on Postgres and recently [MariaDB 10.2](https://mariadb.com/kb/en/library/window-functions/)).* &gt; And the second step would be to obfuscate until_id using a two way hashing algorithm. I don't see why a two-way hashing algo... ? Differently from twitter.... facebook uses: cursors: {'after' : 'xxx', 'before: 'zzz' } Which is nice to get a previous page link 
"I'm curious how will you define what is this id ? Obvious for a defined entity (primary key) but less for an arbitrary query or composite keys." I don't have any composite keys on any of my entity in my current project. I also make sure I avoid using them in terms of database design. "I don't see why a two-way hashing algo... ?" Instead of displaying until_id=42 to the user, we can display cursor=c-8v7326f73, and the reverse hash would produce 42. I just don't want users to mess with the internal logic. Twitter explains exactly this in their documentation. I'm just sad they don't explain which algo they use to generate the cursor names : )
&gt; I don't have any composite keys on any of my entity in my current project. I also make sure I avoid using them in terms of database design. Good, I was more thinking about an arbitrary query... (the need to be able to specify what is the primary key amongst the columns). &gt; I'm just sad they don't explain which algo they use to generate the cursor names If your ids are not supposed to be secret, a simple encoding (base64_encode, str_rot13...) should be fine (not two way)... ? No idea about what's twitter doing :) 
You've picked up my curiosity :) Have you already an idea on when to you'll retrieve the first and last id's (after hydrating / populating the resultset ?)
I‚Äôm not a manager but understand the team‚Äôs process first to see why they are doing things, then implement change to help them become more product if needs be.
Try using jira+bitbucket instead. Fits the PHP mentality a bit more than tfs and git is arguably better than svn. If you want to upgrade the IDE experience then try Phpstorm instead of Eclipse. I guess you need to change along with them and meet somewhere in the middle. 
you say you're using laravel, then if this really bothers you and you don't use an IDE why not use [laravel's collections](https://laravel.com/docs/5.5/collections) class? Solves the very thing you complain about tbh. To answer your question. PHP has been around for a long time and backwards compatibility is one of the reasons people use the language so we're stuck with a lot of shitty design goals made a few decades ago. Some things are being corrected while others may take time or never get corrected because of the amount of time and effort to implement such changes. Eventually I hope the goal is to start a new stdlib for most things like an `\Array` namespace and a `\String` namespace which slowly corrects things like the things you rant about.
I use phpstorm + git + phabricator. all hotfixes &amp; major features are comitted against tickets in topic branches, then merged into develop, and then later into master / stable.
Please avoid using visual studio, many php developers use different flavors of linux as their primary development environment for GUI.
Create a classmap in the composer.json file. Though I'm nog sure if you can tell composer to only load classes starting with CompanyName. [Click for docs](https://getcomposer.org/doc/04-schema.md)
Use `spl_autoload_register` instead of `__autoload` and it should just work with your existing autoloader.
As far as I know, you can have multiple autoloaders, so load your customer autoloader first, then composers autoloader :-)
You can let *RobotLoader* do the heavy lifting for you. https://doc.nette.org/en/2.4/robotloader
This is exactly what we do at my work where we have a pretty big codebase (50k PHP files) and many are legacy, but we also have Composer libraries. We actually have three autoloaders: one for a very old naming convention, another for a more Composer-compatible convention, and finally the Composer-generated one. Works fine! 
Feeling a little stupid right now - sometimes the most obvious answer is the correct one :) (I was already using spl_autoload_register)
I feel like this would be the correct answer if composer wasn't a thing :)
It's generally bad form to have breaking changes in a patch release. 
You can use both at the same time. Composer for managing autoloading of third-party/Composer packages in `vendor` dir, and RobotLoader for managing autoloading of your own (eg.) `src` dir. This way you won't have to worry about your own app's dir structure, or about regenerating Composer autoload files every now and then, or about whatever.
I don't see why you can't add that method to a eloquent model, I haven't tried, but it should work already too. Of course you need to call to save, and in doctrine you will need to call to flush in em...
This!
That sounds like a really good way of working. Does it work well for you and the rest of the developers in your team? 
You can use composer autoload with classmap on that folder... It should work
He‚Äôs probably using mamp, not mamp pro. But yes, if he uses mamp pro this is very easy to do. 
From the patch : &gt; yii\base\Object still exists for backwards compatibility and will be loaded if needed in projects that are running on PHP &lt;7.2. The compatibility class yii\base\Object extends from yii\base\BaseObject so if you have classes that extend from yii\base\Object these would still work.
Yes, generally in a job queue.
Hmm, that's good to know, thanks. i never even thought to look into that.
There appears to be a pretty good tfs plug in for eclipse so hopefully any visual studio team explorer install will not be required and in this particular we are hosting apache and php on Windows.
Eclipse is not a common PHP ide - try using PHPStorm instead, and have a look at the agile plugins it can offer. Also SVN is seriously out of date. Try Jira with Git for automated branch creation and tracking. These tools helped me with implementing agile workflows and processes.
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
Another alterative to Doctrine and Eloquent is http://www.pomm-project.org/ - it's fast, and perfect for complex queries.
In your project's composer.json file, you can map specific namespaces to certain folders. See the `autoload` directive in composer.json schema. PSR-0 and 4 both work, with option to include a classmap too. 
Or just do a template in your IDE to auto-complete dd to dump();die();, it avoids to have a two lines package ;)
They are still right though. Windows is more home to the C# community and Linux is more home to the PHP community. You should consider hosting on Linux instead. You will be able to scale more easily as Linux distributions are usually free. I can't create a concrete argument for this, but switching the entire build and server stack to Linux will have less long term friction than Windows.
Yes, the lifespan of your objects may vary. So, for instance, you might have a very limited scope working with an object without the need to persist it to a more widespread storage, even though temporary. There is no reason to commit an object to a repository if you won't need it later. Depending on your data amount, saving objects to a memory repository could potentially cause out of memory errors, if they aren't GC'ed as soon as they aren't needed anymore. 
IMO, a repository lives between the controller (which should know nothing about business logic) and the database abstraction layer of choice. It is where all the real business logic happens. Just my 2 centavos. 
First of all: my repositories usually don't have a persist method, as this one is very specific to repositories which have persistance. But the whole idea of repositories is to abstract the DB query away and use it as a collection. Therefore: use add/remove and not persist/delete. The second part is a bit more tricky. Usually, the repository is not responsible for writing updates. Usual implementations of ORM/Data Mapper (e.g. Doctrine, JPA or others) have something called an EntityManager. It keeps track of all entities and updates them when flush()-ing. Usually, my repositories use an EntityManager for add/remove, but the flush() is called elsewhere. My code has a layer called Boundary between frontend stuff (controllers, forms, templates) and my business logic (which is implemented as rich (domain) entities or as services, if you prefer an anemic design). The boundary provides a single method for the controller to call business logic. It's main purpose is to begin and finish database transactions, and this includes the flush() to the EntityManager. This layer is especially important, as you can catch all implementation specific exceptions (e.g. DB not available, or any other reason why a commit() failed) and convert it to domain specific exceptions, which are then consumed by the frontend. This way, the frontend is unaware of DB related things. 
TBH it might as well be in Symfony, it's not really best practice but it's helpful *sometimes* :p
According to DDD, a repository is not allowed to change or delete data. It is only allowed to add data. The question is whether you want to use CRUD or DDD? You can't have both. A repository is usually a collection of complex queries that do not match the entity. This is the source of all the data your application needs. Also the storage logic is is just an implementation detail and can vary from database to database. You have to differentiate between collection- and persistence-oriented repositories. You are talking from a collection oriented repository (DDD). A collection oriented repository collects and manages objects "in-memory" like the Java java.util.hashSet class. Each object can only be added to the collection once. There is nothing comparable in PHP, at least the SplObjectStorage class. The storage is transactional, that means you need a a commit() or persist() method. Disadvantages: Not suitable for large amounts of data and poor performance during storage. A persistence Oriented Repository is optimized for storing data in databases. Also known as Aggregate Stores or Aggregate-Oriented Databases. The saving is done immediately using the save() or saveAll() method. When an object is updated, the old object is immediately replaced (overridden).
Your RewriteRule should be (at least how I would do it ) : RewriteRule (.*) index.php [L, QSA]
Still nothing :/
Try RewriteEngine On RewriteCond %{REQUEST_FILENAME} -s [OR] RewriteCond %{REQUEST_FILENAME} -l [OR] RewriteCond %{REQUEST_FILENAME} -d RewriteRule ^.*$ - [NC,L] RewriteRule ^.*$ /index.php [NC,L]
Nothing :(
Is your .htaccess being read? Try the gibberish trick: put a line of nonsense in your .htaccess and then try hit the index.php file. If you get a 500 error, then the .htaccess is working, if you don't then it's being ignored.
What does your AllowOverride look like for the directory?
This is most likely Apache issue, first, check your version of Apache, then find on stackoverflow configuration that you need for parameter AllowOverride. Of course, make sure you restart Apache after those changes.
i built a web socket server for a project at work and it was a nightmare configuring the operating system and web server to handle everything correctly at high loads. we were constantly hitting bottlenecks (oh, it stops at 64 connections, fix something, oh, now it stops at 1024 connections, fix something, oh, now the server is stuck at 100% CPU because it's not letting go of connections... and on and on....) PHP making mySQL requests is so standard and so much simpler by comparison, i would definitely try that first, measure the performance, and see if it's acceptable.
I guess the real question is: should we do this in c# or php? (Or solution x, instead of y)
If go with an extra layer. MySQL is definitely easier but you also want a layer to protect against attacks such as ddos if applicable. A direct path from public to server with nothing in between always scares me a bit.
Dont rely on query cache, that is being discontinued in newer mysql versions for a reason - use memcache as caching layer, consider using something like react php serving the otp demonized with persistent connections to mysql to max your qps It might be easier to reach high qps with a different stack (like nodejs) but its certainly doable with php
Do you register a router for /hello-world path?
While you can certainly have MySQL handle that, you can cache with php too. I'd set up nginx + php + MariaDB (or MySQL) + redis. With redis, you can essentially store everything in memory as well (as cache). Additionally, with this setup, it is extremely standard and secure. Everything under the sun has the ability to make http requests easily and uniformly. Most importantly, your data stored uniformly and safely. You can write a script in python, lua, php, c#, c++, etc. to connect to the database and do operations with it. Another plus is you're using such a widely setup that when you're wondering "How do I be more secure under X circumstance or perform better under Y circumstance?" the best answer is probably already out there.
to hard for them
query cache is dead and will be deprecated soon. I'd use mysql then some layer of caching (memcache, redis, etc)
Another name for your Boundary layer would be the [Transaction Script](https://martinfowler.com/eaaCatalog/transactionScript.html) pattern. Personally, I use a BlahRepository for lookups, BlahManager for transaction scripts, and EntityManager::persist for updating objects if I'm using an ORM
I don't understand how an otp would make this easier. If load is a probable issue, don't add unnecessary complexity to the infrastructure. Depending on your structure you could use jwt for authentication, that will stop the repeated requests. Or just add memcache or something similar in between. 
As a C# to PHP developer, I agree with most of your statements (from personal experience). Most of our dev team currently uses PHPStorm (thanks to me), but up until about a month ago I used Atom.IO, my main co-worker used Sublime/Visual Studio Code and our boss uses Notepad++ still. Everyone else used one of the before listened or Eclipse. We all work on primarily Windows machines, but distribute to Linux. Besides that, I fully agree that running production on Linux makes the most sense for PHP for a variety of reasons.
Been using Yii2 for multiple projects for the last 2 years. Keep up the good work!
If it's for hls, I would use a token that needs no database to be verified. If not, it will require a big amount of process time and a big infrastructure to check that. The get the first link you authenticate the user, and after that, you put something as jwt token or similar. 
&gt; the LAMP camp is saying we can count on MySQL and it is just no big deal, the server guys are saying the C# server can keep it in memory and answer instantly There are two very different things being argued here that you need to separate to make see a clear road forward. First, language: picking between PHP and C# here is going to boil down to a lot of different factors. Familiarity and raw performance are two key areas. If your team really know one vs the other well, there's a large benefit to staying that course. If performance is _key_ then *any* compiled language, especially one that remains initialized in memory ready to handle requests is going to have a major leg up on PHP. The second, and separate issue, is state. In the one ecosystem, you're putting forward using MySQL to store state. This can work really well, and 5k rps is well within the power of mysql, especially for simple, effective PK-based queries. However, it *is* another hop from the application to the mysql server. That's a certain guaranteed amount of latency. It doesn't matter (too much) which language you use, that time sink will be roughly the same. The other option, which is comingled with the C# route, is an in-memory dataset. The argument holds water that you can't beat the round trip time to memory vs. over the network :) There are some rather serious downsides to in-memory storage though -- first, it's in-memory, so a crash means you lose data not pushed to disk. Second, without the "central" nature of something like MySQL, you can't scale to more application servers. You need to not conflate the langauge with the state storage to find a better discussion for this process. It's also worth noting that you can actually run PHP as a long-running process with memory state, or even go with something like APCu to have per-server shared in-memory storage. There's a _lot_ of options out there.
True, but they are recommending [ProxySQL](http://www.proxysql.com) as a replacement.
The repository can have `save` and `delete` methods http://deviq.com/repository-pattern/. I think the logic for blocking an user should be encapsulated in a class class BlockUserAction { function execute(User $user) { $user-&gt;blocked = true; $this-&gt;userRepository-&gt;save($user); } } 
I was not aware of this - thx for the heads up!
&gt; You have to differentiate between collection- and persistence-oriented repositories. That's it. I've never heard about this differentiation, and had always used persistence-oriented repositories. And my original question was basically describing collection-oriented repository. Thanks for this clarification. In a typical PHP application, where should `commit` method be invoked?
Thank you for comprehensive response, specifically for `flush()` invokation!
Good to read http://blog.tomhanderson.com/2015/10/how-repositories-in-doctrine-replace.html.
&gt;According to DDD, a repository is not allowed to change or delete data. It is only allowed to add data. I'd like to clarify this statement since it confused me for a moment... Your DDD application can definitely alter or delete data, but the *API* to accomplish that should not be by calling methods on the Repository. 
This is reason i warn people about learning something before checking source. Everybody can write in these days and publish.
You used java/c#/etc member operator instead of php one
Already fixed -- posted and then noticed subreddit was language-specific.
Yeah, my .htaccess is being read.
Thanks for your contribution to the conversation. My question is: should we really invoke `$userRepo::persist($user)`? Can we and should we avoid invocation of this method in client code?
If you're using something like Doctrine to do the heavy lifting for your Domain objects, then you only need to use persist() after creating a freshly constructed object. Basically, you're telling it: "Here, keep track of this object you've never seen before, because later you'll need to sync it along with whatever else we do."
A "commit" belongs to a transaction and is therefore an implementation detail of the specific storage. In addition, each transaction could involve several entities at the same time. This is where the collection oriented repository fails (in my opinion). The question is, what is a typical PHP application? At the moment it is (still) CRUD, but DDD is becoming more and more popular in the next few years, especially in the enterprise segment where auditability matters. Those who do not need an audit capability do not necessarily have to implement DDD completely. If you still want to imlement a colletion oriented repository then the "commit()" method belongs to to Repository class. But you should not need a "flush" method, because this is an implementation detail. Here is an example interface (collection oriented): namespace App\Reposity; interface CollectionOrientedReposity { public function add(EntityInterface $entity): bool; public function addAll(array $entities): bool; public function remove(EntityInterface $entity): bool; public function removeAll(array $entities): bool; public function commit(): bool; } 
For a small amount of data the MySQL Memory Engine is quite fast. Then you have the best of both: In-Memory (fast) and MySQL (stable and bullet proof).
Wrong sub?
 &lt;?php echo '&lt;div style="display:flex;justify-content:center;align-items:center;"&gt; &lt;div style="width:90%;"&gt;&lt;/div&gt; &lt;/div&gt;'; ?&gt; 
&lt;div style="display:flex;justify-content:center;align-items:center;"&gt; &lt;div style="width:90%;"&gt;here is the center&lt;/div&gt; &lt;/div&gt;
This has nothing to do with PHP. You probably get closer to what you want by adding margin-top: 0; and text-align: center;
It's a trick question. There is no div.
Maybe, but I'm not really a fan of adding functions in the global scope to be honest
this kind of questions should be asked in /r/phphelp
yup, I think it went away in 8.0, but it's disabled by default in 5.6
What kind of site are you going to be building? Do you already have basic understanding of programming concepts? Do you know any other languages, particularly OOP ones? If you have a learn PHP for work, I wouldn't over-stress about the speed. They hired you to SQL and understand there's a learning curve. Anyway, I usually see (this)[http://www.phptherightway.com/] as the top resource posted for these kind of questions.
r/phphelp would be a better place to ask this question. From the sidebar of r/phphelp : [Make your own blog tutorial](https://ilovephp.jondh.me.uk/en/tutorial/make-your-own-blog) Several other tutorials are listed there which might help. I don't see PHP Pandas book listed (https://daylerees.com/php-pandas/) which is free and covers the basics. 
* https://laravel.com/ * http://php.net/ * https://getcomposer.org/ * https://www.jetbrains.com/phpstorm/ * If you develop on windows: https://www.vagrantup.com/intro/index.html 
PHP7 has reached some pretty nice speeds while not being compiled. It still doesn't compare to we'll written compiled applications but if there's a need for both familiarity and speed on the PHP front, that's a good target. I would suggest using redis for in memory store along with php and mysql if the authentication queries are more complex. But to fully take advantage of redis, you need those machines as close as possible to the Web machines.
Had a similar experience like a year and a half ago with sockets. Someone one my team mentioned they were really excited about learning them and I had to give pause because of the scaling nightmare I had. I would like to try them again because they're a pretty nice developer experience but now we're on docker/kubernetes which might be a little tough to debug.
You can't learn PHP quickly and your manager probably is clueless.
The simplest in memory repository in the world has a ‚Äòstore‚Äô and ‚Äòget‚Äô methods. Since the repository is in memory and objects in php are passed by reference updating and deleting can be performed outside of the repository. However if you need an implementation that persists the object you‚Äôll need a delete method. Updating can be done on the ‚Äòstore‚Äô method if the object has an id, it‚Äôs easy to detect.
Maybe neither? Maybe keep the files stored in Amazon S3 and generate a [pre-signed object url](http://docs.aws.amazon.com/AmazonS3/latest/dev/ShareObjectPreSignedURLJavaSDK.html)^1 to download the file when the user is authenticated? ^1 http://docs.aws.amazon.com/AmazonS3/latest/dev/ShareObjectPreSignedURLJavaSDK.html
This made realize I've been using `dd` all along not realizing Laravel provides exactly this of out the box. 
The entire idea about the repository pattern is more of a theoretical idea than a practical one. You will not be able to easily swap out your implementations even if you use the repository pattern. Go ahead and try it.. use doctrine with laravels eloquent and you will see a lot of problems that just make it absurd to try and use it. You need to normalize the results that come back from your ORM, you need to normalize or find a middle path between doctrines entities and laravels models (because they both do things differently) and once you get into more complex features like trying to add global query scopes or you want to control which part of the entity / model you want to serialize and how, you will not have a good time trying to abstract that. My opinion is that you should not try and abstract this away.. use the repository as a catch-all single source of "truth" for your queries that you can go into and maybe add a cache or optimize a query. Also i would suggest using $repo-&gt;save($user); If you use laravel then your implementation is a simple $user-&gt;save(); if you use doctrine you can simply do $em = $this-&gt;getEM(); $em-&gt;persist($user); $em-&gt;flush();
And look up valet and valet-plus if you're using a Mac
I would say node.js but be careful because you can have things mess up since strings are not binary by default.
PHP is stable enough to make an application that's long running. I would prefer C# or node.js for that though. Except I wouldn't touch C# because it's locked into windows/proprietry too tightly for my liking.
LRPs with PHP are a pain, so I agree. Node's fits nicely into the LRP scheme and most php developers will know some js to get a kickstart.
Repositories are basically supposed to be wrapper classes for code that deals directly with your database.
If you know what you're doing, it's fine which given PHP and the low bar for entry, is unlikely. It's more of a problem when you want to do more than one thing which is what node.js solves. PHP has attempts to solve this but given how much PHP layers on top of system resources like sockets it's hard to really have something you can trust. JS does have some weaknesses like states and events that can be thrown between state changes not properly diagrammed and explained. Its strings are also natively unicode and not binary which makes it more inefficient if you're not careful. Memory management can be much better in PHP as well (with a program taking up much less memory by default than node.js and being more predicable with GC characteristics). Still it's the far better choice apart from not having threads.
&gt; My code has a layer called Boundary We called ours Sentinel :3
I would think if you store your MYSQL tables directly in Memory it would probably be pretty fast. I can't remember what that table type is called but I once used these memory tables to build a big search query. Seemed pretty fast. 
How are DDD and CRUD mutually exclusive?
This is correct. I feel like the default low memory in nodejs forces more awareness to memory usage. In PHP, it sneaks up a bites harder. State transitions for LRPs should be handled outside of either system, in my experience, because it makes recovery easier. I personally use rabbitmq (for both php and nodejs) but wrote my own job queue for redis (PHP) which made state transition/transaction much easier. With PHP, my biggest issue is some fundamental socket states. I can lose sockets to rabbit mq, for example, and not know about it til thirty minutes to an hour later when I try to acknowledge a job. No amount of tweaking connections has resolved my particular issue :(
Query Cache is dead, but that doesn't mean "queries arent cached" - The INNODB buffer pool will still hold unmodified but frequently queried data in memory. Putting redis/memcached "in front of mysql" is an anti-pattern that ought to be avoided (cache invalidation becomes a nightmare). Instead, just allocate an acceptable amount of `innodb_buffer_pool_size` memory (ideally as much RAM as you have data in your database, so that the entire thing can be stored in memory) and you'll see excellent performance.
[removed]
C# is neither proprietary or locked to Windows FYI. 
Actually in PHP its easier because it's simpler with some exceptions. The JS memory profilers are much better than PHP's for example. However in JS you can't do things like have an iterable weakmap, get the ref count for variables, etc. Under the hood it's much easier to deal with memory management in PHP than JS as well. You can't externalise state transitions. That's impossible. You have state transitions within your very system of merely talking to the system you want to export them to. The problem with state transitions and an asynchronous language is that you're basically handing off flow control. If you're writing your own flow control then that's fine but when you hand it off you need to know exactly how states change in those systems and the different patterns of event emission that can occur. Unfortunately the attitude in the JS community about this is one of conceit, that their incomplete documentation is more than adequate and to shut up about the problem. Those fundamentals are more what I'm talking about and you'll realise you've had that pitfall as well. One of the reasons PHP is messy with that is because so is C. C adds a layer of abstraction on top turning all things into FDs with a lot of overlap. In addition to C's way of passing errors indirectly. This means that errors in sockets are presented weirdly. I've managed to crack sockets in PHP and in C but it's not exactly intuitive. JS has more domain specific naming but not always (like an explicit connection closed even rather than a read failed). You can have exactly the same problem in JS and that's because like I said, they don't document the states and flow control between them as well as events emitted along the way. Ironically it also starts to have problems with that using streams for everything which isn't entirely bad but adds more confusion without proper documentation. PHP has had some nasty bugs with it's streaming interfaces like connections with no timeout causing it to hang (and because it's in IO not execution the time limit wont applied).
Not fully no, but it's still too close to the control of MS for me to want to touch it and it just doesn't have the kind of benefit using it has on Windows in Linux.
With .Net core, there is no difference when running under Windows. The ecosystem is the same. The benefit is you get a really nice high level compiled language and don't have to deal with something like Java. 
It's up to you and it depends on the kinds of problems you think you might have. I prefer r-&gt;store(e). When you have e-&gt;store(), internally e just pulls along r with it and fills in the parameters it can. It varies a hell of a lot based on what I'm doing though. In most cases there's little to no gain from making your own ORM and repository patterns.
That's core though. Everything else built around it works better with Windows and MS. Java has some issues as well.
That's correct - with 8.0 currently in RC's..
Please reconsider the name. Get a marketing person to a cup o' coffee, and listen. And assuming you don't believe that "power of the name", emotional impact of words, and other purple-cow BS, add one more thing: the ability to easily find your tool using a search engine. Seriously, what made you go with... "Packages"? "Packagist" should _not_ be an inspiration.
It was the subdomain we originally hosted the app on ;P I never really considered changing the name though it has bothered me often. I'll have to think about this.
And I learn about [the Normalizer class](http://php.net/manual/en/class.normalizer.php).
I think both camps are correct and offer technically viable solutions. However, have you actually looked at any existing OTP authentication servers? Seems like you want the challenge of building a OTP auth server instead of solving the problem. There are lots of OTP servers out there that have already addressed (or not) scalability etc. 
composer is so slow
test it and see. no way to know otherwise on different hardware, different OS's, settings, etc. i mean, with dummy data, just testing raw throughput for individual requests. the c# team will have to do a lot of work to get their solution indexing faster out of the box, would be my guess, and they will turn down the challenge, but it might be worth bringing up. there's companies you can pay if you don't have access to a farm that can generate that many RPS, by the way. renting one out for a weekend and burning through test configs to find the fastest might easily save you the cost of having to redo it, in the long run.
I will start coding next year. So several months of learning should do the trick. No?
I understand programming. I have been coding since the 90's. Yes I do have experience with OOP's. The web page that I have to create is for internal use. Now it's Visual Basic, Crystal Reports and Oracle. It has to go on a web page. New management says everything has to be on a web page. The application is like an index card. It manages seating arrangements. What floor employee is on, name, phone number, what department they belong to.
Should the function not be called dump_exit since that it how it was implemented? Seems a bit misleading.
There is a tendency for developers to focus on data rather than the domain. This can happen because of the prevailing approaches to software development that place importance on the database. In CRUD your database is the "center" and your code just modifies the data in that center. In DDD you are designing domain concepts with rich behaviors and the database is just an "implementation detail". In DDD the priorities are shifted by 180 degrees, because the emphasis is on business logic and not the database. 
sorry for the double post. Can a mod please delete this.
If you're dedicated and consistent, sure.
&gt; I wouldn't touch C# because it's locked into windows/proprietry too tightly not so fast, there... https://www.microsoft.com/net/learn/get-started/windows
Love devilbox! I use it all the time.
I don't keep up with advancements in the PHP community much, so I'm curious: are there plans/discussions to add enums, method overloading, or other features to PHP that we have come to see as standard in other popular languages?
Enums: http://php.net/manual/en/class.splenum.php Overloading: That would be nice.
Sounds like you have a lot of experience coding. Picking up PHP shouldn't be too bad. I don't agree with /u/Heyokalol about not being able to learn it quickly. In my experience PHP can be can l taught and learned quite quickly. Good luck!
You can delete your own posts.
The c# socket option seems like you're trying to optimise something that doesn't need optimisation. Just use LAMP and get it done quickly. Then worry about scaling afterwards. There are so many options from that point. Adding Redis for caching would be the most obvious one. I would argue a lamp + redis setup will handle as much or more load than your C# solution. It certainly has better scaling options as redis has out of the box clustering options whereas your C# guys would have to engineer that solution. 
Instead of pushing MySQL to its limits or rolling a custom solution, you might want to look at other databases depending on your usecase. You might like Cassandra or its more performant drop-in replacement ScyllaDB. 
My goto is https://www.whatsmydns.net/
You should use a lightweight PHP framework such as: slim / silex or lumen. You should cache data using Redis / Memcached / Varnish Cache and you'll accomplish your needs easily. 
Are you talking about collaborators to work on paid project, learning, or just spare time whatevers?
Mostly for paid project. But all the while, I am also looking to find guidance/support in these collaborators in cases of learning or guidance for spare time whatevers, hence specifically wanting longer time collaborators. In terms of paid projects, senior would be the one to decide upon architecture, I'd be there to do heavy lifting that takes time and senior would rather not do it for example.
Good to hear. A few more improvements and PHP-FPM 7.3-dev will also make it in for sneak-previewing.
I like Phalcon as a framework although it's feature set is small compared to others but in a way I prefer this as it gives me much more freedom to be creative with it. This can also be negative because I can often be reinventing the wheel that other frameworks have solved. Most of my professional work has been in large corporations and this is where Phalcon falls short. It's a hard sell in such an environment and is often feared by management with it being a C extension and not having anyone with notable C experience on the team. This is not to say you will ever need to modify the source but working in such large corporations it's always a valuation of risk and it's just not worth the risk when there are other established frameworks that can be used instead. 
This is all a wrapper for the `dig` command? Does it parse the results so, for example, I can ask it for the TTL for a sub-domain?
Have you ever visited who.is and who.is/dns?
Nice..
Yeah its a "beautiful" app but it can't even show all dns records for my domain name on the same screen (2560x1440) since the font is so big, otherwise its great. The only improvement I can think of is color highlighting on the output and making hostnames/ip addresses links.
When how you read and save data start to drift apart it's time to rethink how you're working, this is a really common problem btw, don't worry. ORM's can be handy, but they can't be treated as a final solution to persistence like you seam to be doing. Eloquent and other Active Record ORM's are pretty good for CRUD but dangerous at the same time as it makes you see your models as database rows.
The TTL is automatically printed. The output isn't parsed, just blank lines stripped.
awesome! i like the terminal view . 
As an experiment it's nice I personally use https://intodns.com/ it shows everything with detail and highlights any errors in the records
Go mysql. You could easily invalidate keys instantly, vs where you have to wait for cache to update.
I don't see the point in the web app. You mention your PM is not a technical person, so your solution is to build an app, which looks nice, but then represents the results in technical language?
thanks! 
thanks! 
php sucks for bitcoin related jobs 
You're really looking at hiring freelancers then on a per project basis. Once you have a project and budget you're best posting on job boards asking for the specific skill sets you want for each project. Once you work with people you like and they like you there's no doubt they will continue to work with you on a regular basis. 
I created a clone of that website for a client using Net_DNS2 but we also have other tools like ping, traceroute, network calc, port scanner, etc. The worst part was parsing the output as client wanted exactly like ping.eu, created with Yii2 to as client wanted yii2 based app 
I'd really like to read what you did to make it as small as 43 MB from the initial size of 889 MB.
Nice terminal view 
Initially I wasn't aware about how to properly use Docker layers. I was using a final layer that did the whole cleanup. Now I am trying to keep each layer as small as possible by cleaning up any artifacts that were required at the beginning of the but not anymore at the end. For example removing all *-dev packates and replacing them with *-lib packages. So each layer only produces minimal required space. Additional the large image size was for a Debian image. My smallest image now is an Alpine Image (although Debian is also available as a slightly bigger one). Then I also use the `strip` command to remove unecessary stuff: find /usr/local/bin /usr/local/sbin -type f -perm +0111 -exec strip --strip-all '{}' + \; I am honestly not really sure what exactly it does. I found it in other Dockerfiles and applied it to mine as well. Seems to work and reduce the size. So maybe someone from here can give a brief introduction about this? And last but not least, I am removing multiple directories from inside the Image that dont seem to be needed. I was just randomly searching through them via: du -hd1 Found that `man` directory existed with quite some size as well as others. So to sum this up: 1. Cleanup at the end of each `RUN` command 2. Replace *-dev with *-lib where possible 3. strip libs/binaries 4. Remove unecessary stuff 
Any emacs users out there? I've migrated to emacs for most of my programming needs and have been very happy with it, but PHP seems like a serious weak spot. Is anyone using emacs with PHP and getting good results for things like finding function definitions?
Thanks!
Google has a nice API for this sorta thing as well. Nice when you cant be bothered with opening up a console. [dns.google.com](https://dns.google.com/query?name=reddit.com&amp;type=A&amp;dnssec=true)
1) discover thing does not do thing 2) check if there's a newer version/existing pull request to make thing to do thing 2a) if yes, use that version 3) check contribution guidelines/ code style &amp; commit log/dev activity 3a) if p.i.t.a. or no sufficiently recent activity, consider forking 4) make thing do thing 5) send necessary pull requests
Do you??
I like the look of this but the share size of this project for a simple DNS lookup service? 
Yes it does. The only file i opened was post.php and I don‚Äôt think I read more than 30 lines before confirming Never use user supplied data directly in your queries. 
ooo I think I've found my replacement for whatsmydns.net
Failing that, any recommendations for other editors? I'm getting tired of the whole mouse-centered heavyweight IDE thing.
After two years with Sublimetext I tried VSCode for PHP development and have never looked back.
&gt;beautiful Do you know what is meant by the term, *weasel words*?
Disclaimer. I don't know any good videos at all. 1. One from Kevin is outdated and wrong. With his level of expertize he has to learn himself, not teach others. 2. Linux is the Primary OS to run PHP. However, if your Linux distribution is outdated, it would be hard to obtain a recent PHP version for it. 
I would highly recommend Jeffrey Way‚Äôs ‚ÄúLaracasts‚Äù series for beginners: https://laracasts.com/series/php-for-beginners He is a fantastic teacher, and this particular series is free to watch. Best of luck!
One thing I seem to be missing is **ZendOpcache**. Does anyone have an idea how to install opcache along with PHP?
Thanks. Is CodeAcademy any good?
Thanks a bunch for this!! I've done some more research and have found out that I should stay away from W3School. This Laracasts series seem much more better. 
I don't know. I learned basic PHP before any of these sites has been up. But I can tell for sure that 95% of the courses are outdated bullshit. At least try to find one has been shoot recently, in 2017. That one from Kevin Skoglund appears to be shoot somewhere in the last century and only given a face lift in 2015. 
You were talking about books. Any book you would recommend? 
Well, a while back one from John Coggeshall used to a be a good one. But as I can see there is only a PHP5 edition, but you apparently should start learning PHP7 already.
Thank you for your award winning comment on this incredible application. 
I‚Äôve been through that Kevin Skoglund course and while I agree that‚Äôs it‚Äôs not exactly current, it‚Äôs a great run through basic syntax, OOP, etc. It would be a good starting point, then maybe look into learning a framework (i.e. Laravel, CakePHP, etc.). You should familiarize yourself with PSR standards as well, specifically PSR-1, PSR-2 and PSR-4. Compare these standards with how things are done in the KS course. Once you get through that, move to the courses on Laracasts. Jeffrey Way puts out some of the best courses available.
Here a some resources for PHP. I hope it helps you. Good luck https://github.com/odan/learn-php/blob/master/README.md
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [odan/learn-php/.../**README.md** (master ‚Üí 9a900fe)](https://github.com/odan/learn-php/blob/9a900fe867a158461619548b41ca73ee2cacad7e/README.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dpfohzb.)^.
Featuring that most unhelpful of all error messages: &gt; throw new Exception('Dns records could not be fetched'); Also, why would you perform sanitizeDomainName() in the constructor, and then escapeshellarg() on that same field in yet another function? Why touch the string at all in the constructor? Also in the constructor there is this: &gt; throw InvalidArgument::domainIsMissing(); Is that a custom Exception class? Why yes it is! And here is what the custom exception does: &gt; return new static('A domain name is required'); So sometimes you use a custom exception, and sometimes you just spit out an Exception. As a bonus, sometimes you throw an error in the constructor, which is just rude. Now here is something that is extra nice: you see the class called InvalidArgument? Here is the definition: &gt; class InvalidArgument extends InvalidArgumentException But here is the method for domainIsMissing: &gt; public static function domainIsMissing() A static method on a class that extends Exception, that is just a factory function. In fact InvalidArgument consists entirely of static methods, why does it extend InvalidArgumentException at all? 
I've been using PHPStorm for a couple year now, after years of using Netbeans. But I guess that would be a heavyweight IDE, since it does a ton of stuff.
I usually using https://gwhois.org/
&gt; I am not a millennial and able to learn from other sources like books, online texts, research etc. lol, millennials need someone on youtube with cool effects to explain things? 
Not going to use a whole package just for 1 function, especially not if it's Dev only. Also, takes a second max to type `die`. 
I second and third this recommendation. laracasts is an amazing course into Laravel, and its no coincidence that Laravel is the most popular PHP framework out there right now.
To compile opcache you need to add `--enable-opcache` in PHP's `./configure`, then to enable it you need to add `zend_extension=opcache.so` to your PHP.ini.
http://www.phptherightway.com/ and https://serversforhackers.com/
Looking at your Dockerfile, I don't think your `find` command isn't doing anything, as `strip` is provided by `binutiils`, which doesn't seem to be installed (unless I'm missing something on `alpine:latest`). ``` find /usr/local/bin /usr/local/sbin -type f -perm +0111 -exec strip --strip-all '{}' + || true ``` At the moment this is just returning `true` and is being skipped. Your optimizations are likely coming from elsewhere. Regardless however, the`find` command looks for all files in `/usr/local/bin` and `/usr/local/sbin` with `u+x` permissions, then removes non-essential symbols within the binary. I wouldn't expect to see more than 2-3MB of savings per binary uncompressed. On Docker hub the compressed sized would only differ by a few MB. An FYI that `perm +` mode is deprecated [according to the find manpage](https://linux.die.net/man/1/find), `perm /u+x` seems to be the recommended approach now. Nevertheless, the info you provided is a good approach to slimming down Docker images in general. Great job!
Since Jef is not a technical person, he should not be dealing with DNS in the first place. Jef was absolutely right about delegating these tasks to a better suited teammate. This app should not be, and it's ugly ;) (but that's just my opinion)
Great job slimming your image sized down! I went through a similar process converting my Xenial PHP images to use Alpine Linux. My savings were less dramatic however, as my [Xenial](https://hub.docker.com/r/charlesportwoodii/xenial/tags/) PHP image came in at around 151MB compress, and my [Alpine](https://hub.docker.com/r/charlesportwoodii/php/tags/) image only dropped down to 72MB on average for all PHP versions I maintain there. Comparatively however, my Alpine and Xenial images are more of a general PHP image, rather than being FPM specific. Having PHP CLI, XDebug, Composer, and Git, a bunch of extra extensions, and php's own development tools installed makes them a bit more versatile for my needs. Purely speculating, but I would guess that I could get my images under 40MB if I made a _dedicated_ FPM image that didn't have all the extra niceties mentioned earlier - that wouldn't fill my needs however. Your process was a bit different from mine though. Having and maintaining a 300 line Dockerfile was a real pain for me, especially when I wanted to iterate with new features. Compiling within Docker layers also became very frustrating with long commands. I found it much easier to front-load compilation and create a package and use that in the Docker image, but that's just my experience. I think it makes the Docker images much easier to read. The other benefit of doing it this way is that I can compile PHP for multiple platforms using the same script, package it up, then use those packages in my Docker images. Again, that just works better for my needs since I usually have distribute packages outside of Docker anyways. https://github.com/charlesportwoodii/php-fpm-build/blob/master/Makefile https://github.com/charlesportwoodii/docker-images/blob/master/alpine3.6/Dockerfile.php72 Great job shrinking these down!
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [charlesportwoodii/docker-images/.../**Dockerfile.php72** (master ‚Üí 2380611)](https://github.com/charlesportwoodii/docker-images/blob/23806112c89485c0cfd7a2367fe0ae6f060cf7b7/alpine3.6/Dockerfile.php72) * [charlesportwoodii/php-fpm-build/.../**Makefile** (master ‚Üí 2a84d8e)](https://github.com/charlesportwoodii/php-fpm-build/blob/2a84d8e19d86d228f264ae6925667a39c5d369cc/Makefile) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
I was hoping I could at least change the zoom/scaling of the site. 
Wow this site is pretty great. Nice and simple UI, plus works fast too. 
Try teamtreehouse.com Their videos are really cool, u dont need any software or whatever. Which is nice. 
No.
/u/charlesportwoodii Good catch! apk add binutils does the trick. Thanks for the info on `find`. Will make those two fixes.
PhpStorm + git + self hosted GitLab here.
It also makes a lot of sense to develop php applications on Linux (Desktop) as well. Better productivity in terms of desk workflows, not limited by the limited virtual desktops of windows. Unless you a dev doing a lot of photoshop work, there is virtually no reason to use windows besides maybe using edge, which can be installed on virtualbox/libvirt-manager/vmware workstation, and you get a vastly superior developer experience, you get access to all native linux tooling and this improves your teams ability to build tooling later, reliance on gui's much less is important for dev-op workflows.
&gt; zend_extension=opcache.so Thanks. Seems that it was already built with opcache and no configure option for that is present (at least not shown by `./configure --help`). Only thing missing was to actually enable it via your above specified method.
&gt; I found it much easier to front-load compilation and create a package and use that in the Docker image, but that's just my experience. Actually the same process, but a different approach. I also sort of *pre-package* PHP in the `base` image. It only compiles it and provides a basic working version of PHP-FPM. All other images are built on top of each other. That way it is also easy to maintain features. However, your Makefile approach offers much more flexibility and is well thought.
Whatever you do, don't enter "doom" into the search (disclaimer: if you do, you'll likely kill your productivity for the day)
looks great...I don't like the idea of adding debug code to our project (to make sure it doesn't go out to production) so I wonder if this can be started with `auto_prepend_file`? that way it can be environment specific
Article: We researched DNS record sites and found them to be perfectly adequate and fit for purpose. Wasted time making our own anyway.
Freelancer.com however you will be bidding against other programmers. There's also Fiverr but again you'll be competing against other programmers 
i prefer upwork but I don't work for indians, nigerians, pakistanis, bangladesh
I'm excited to try this out tomorrow. Thanks! 
&gt; https://github.com/charlesportwoodii/php-fpm-build/blob/make-ext/Makefile `docker-compose run &lt;truty|xenial|centos7|rhel7&gt;` Shouldn't it be `trusty` (`s`)?
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [charlesportwoodii/php-fpm-build/.../**Makefile** (make-ext ‚Üí 295e7c8)](https://github.com/charlesportwoodii/php-fpm-build/blob/295e7c8485c113cbbcf9c7a4a0e682eea0d73d67/Makefile) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dpgc78y.)^.
Just `require-dev` with composer.
Yes.
Can‚Äôt even get my Subdomain info :(
Does your city have freelancer meetups? If not, organize one.
Is there an Opera extension by any chance?
yes, that installs the library...aren't there other steps to have it run with the application? https://underground.works/clockwork/#installation
[@ShrapnelCol's latest tweet](https://i.imgur.com/9qxDKxm.jpg) [@ShrapnelCol on Twitter](https://twitter.com/ShrapnelCol) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
This series opened my eyes to what proper PHP development looks like!
If not, Clockwork actually serves a web page from your server where you can see the relevant information. No extension required!
Interesting. Is that where much of the work comes from? 
&lt;img src="https://scontent.fomr1-1.fna.fbcdn.net/v/t1.0-9/23244062_1877844332228936_4999287342545846792_n.jpg?oh=1ee05aa24ddd0b4e5e019811e4773c19&amp;oe=5AA66030"&gt;
You could try codersclan
I checked the preview. It is not "not exactly current", it's severely outdated. He's not using prepared statements and I suppose all other security must-have measures are equally flawed. His course will produce yet another PHP shitcoder. 
If you are okey with high competitors and relativly low amount of pay, then freelancer.com is your thing. If you want less competitors, more money, but higher quality compotitors (not approved, but I assume as it's a German platform), then twago.de could be your thing.
You could do it across unofficial clients
Laravel? LTS?
The "magic" is the event loop. Saved you a click.
Never seen it in use in PHP-oriented companies in the EU zone.
I switched from Atom to VS code and really loving it right know. But I would stay away from bigger full IDEs such as VS Pro. Feels just to bloated and slow
It is VS Code they are probably talking about. I like it, not bad at all for PHP development.
Wait...what kind of evil is this?
I'm talking about VS Pro.
I talk about VS Pro =)
Have you seen it outside of EU zone or is it just that you only work in the EU zone?
If Visual Studio would support PHP in a real good way, I would pull of my jeans and start jerking right now since it's a request of my since over 10 years (heavily exagerrating). Well, nowadays I am working with PHPStorm which is ^the ^strongest IDE for PHP right now. Some people also love to use NetBeans or Eclipse (?), but well that's nothing for me. Next to the fact that VS was always neglecting PHP was that VS is from Microsoft and well,.. they tryhard trying to support their own product, which is ASP. It's like when I start Chrome and a window pop's up which trying to say me that MS Edge is better than Chrome "according to Google reasearches" (external shame). Otherwise I would use VS only and probally never noticed PHPStorm.
Also, PhpStorm is the most popular and liked IDE for PHP, But since you mention node.js, a lot of devs use VS Code for that since it is great JavaScript development. Personally, I'm using Neovim with the a couple plugins which adds support for the PHP language server that was made for VS Code. I'm tempted to try out Atom and PhpStorm since they have some refactoring support. But I think I will hold out for someone to add that to the language server.
why not jetbrains? ¬∞_¬∞
Personally I'd avoid it; no real point IMHO.
I haven‚Äôt seen *anyone* using VS Pro for Node, PHP, or anything else. The only people I know that use it at all are Windows/ASP.NET developers. 
&gt; Is it common that PHP devs use visual studio to write PHP I think Visual Studio is not very common, but [Visual Studio Code](https://code.visualstudio.com/) is getting more and more popular.
I have tried many different IDEs over the last 15 years of being a developer. IntelliJ is hands down the best and most competent. PHPStorm specifically is the best PHP idea out there. 
It's usable but my advice for you: Use PHPStorm You can try to find an online license website and you can use it for free
I just looked quickly, but in the Laravel configuration for example, you can disable it from booting in it's service provider. https://github.com/itsgoingd/clockwork/blob/master/Clockwork/Support/Laravel/config/clockwork.php#L19
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [itsgoingd/clockwork/.../**clockwork.php#L19** (master ‚Üí 6590801)](https://github.com/itsgoingd/clockwork/blob/6590801d7dc94b3c44b01869c642be111f483220/Clockwork/Support/Laravel/config/clockwork.php#L19) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dpgy5me.)^.
Does it work outside of Laravel? 
Good catch, thanks.
&gt; I would stay away from bigger full IDEs PHPStorm and Netbeans have been pretty much the defacto IDE's in every PHP shop I've worked in over the last 8 years
&gt; Is it common that PHP devs use visual studio to write PHP or is it just marketing from msft? I would guess it's just marketing. Every shop I've worked in has been dominated by Mac and Linux its very rare I see devs using Windows unless it's at a hobby level or there is a specific business need to use Windows (a lot of government contracts require it). With VS being Windows only I have never seen it used in a professional shop. That being said I love VS code it's a great little editor but the majority of my career is spent with PHPStorm or Netbeans and this seems to be the norm where ever I go.
Serious question here, why not write JavaScript at this point? What are you gaining by using php I this scenario?
Literally the 2nd line on the home page...... &gt; Clockwork uses a server-side component, that gathers all the data and easily integrates with any PHP project, including out-of-the-box support for major frameworks. 
why not just use c++? What are you gaining in that scenario? 
PHP can use multiple cores, while Node is limited to only one is one advantage I can think of.
worked and went all over the globe; it's pretty much PHPStorm or Sublime in PHP land.. no one in their right mind would use Visual Studio on something that's Linux-native...
I've personally never used Linux for development, but I don't really see any benefit to migrating to a Linux workstation. I also do .NET development (as mentioned before) and last I checked, there wasn't a real extension for running .NET applications on Linux. I tried Mono a long time ago and a decent portion of the .NET framework wasn't usable. That being said, I plan on building a home office computer later and running Linux on a VM with Docker.
I think these are going to be the 2 most common perspectives... IDE users will say PHPStorm, which definitely deserves it, while those who dislike IDEs will either say VIM or VSCode. All 3 are great choices. It really just boils down to preference. Atom has had optimization issues recently and has basically disappeared in my office. Most devs either moved to VSCode or back to Sublime Text. None have have decided to go with PHPStorm because we're satisfied with the free options, but we've tried it and been pleased with our experiences in the past.
me_irl
PHP has an event loop?
No.
Libuv, which Node relies on for the event loop, internally uses a pool of threads. So this is in fact not completely true. A Node process doesn't execute code instructions in parallel. But to my knowledge, a PHP process doesn't neither. Or does it ?
Some companies won't switch technologies and languages that easily. Or at all.
thanks, I was more looking to have it completely outside of the source code but this is fine using Drupal btw so little bit of a different approach, but wrapped it in a module and seems to work fine
I'd like to interject for a moment. The IDE you appear to be referring to as *PHPStorm* is in fact written, *PhpStorm*. Don't worry, I don't expect developers to pay attention to such details, but you would do yourself and everyone else a favour to get it correct in future.
&gt; PHPStorm I'd like to interject for a moment. The IDE you appear to be referring to as, PHPStorm is in fact called, PhpStorm. Don't worry, I don't expect developers to pay attention to details, but you would do yourself and everyone else a favour to get it correct in future.
&gt; PHPStorm I'd like to interject for a moment. The IDE you appear to be referring to as, PHPStorm is in fact called, PhpStorm. Don't worry, I don't expect developers to pay attention to details, but you would do yourself and everyone else a favour to get it correct in future.
&gt; PHPStorm I'd like to interject for a moment. The IDE you appear to be referring to as, PHPStorm is in fact called, PhpStorm. Don't worry, I don't expect developers to pay attention to details, but you would do yourself and everyone else a favour to get it correct in future.
&gt; PHPStorm I'd like to interject for a moment. The IDE you appear to be referring to as, PHPStorm is in fact called, PhpStorm. Don't worry, I don't expect developers to pay attention to details, but you would do yourself and everyone else a favour to get it correct in future.
&gt; PHPStorm I'd like to interject for a moment. The IDE you appear to be referring to as, PHPStorm is in fact called, PhpStorm. Don't worry, I don't expect developers to pay attention to details, but you would do yourself and everyone else a favour to get it correct in future.
&gt; PHPStorm I'd like to interject for a moment. The IDE you appear to be referring to as, PHPStorm is in fact called, PhpStorm. Don't worry, I don't expect developers to pay attention to details, but you would do yourself and everyone else a favour to get it correct in future.
&gt; PhpStorm Out of eight Redditors, you are the only one who can spell *PhpStorm* correctly. I just wanted to thank you.
That, my friend, is minutiae. like getting your panties in a bunch because I didn't capitalize the "L" at the beginning of this sentence or for only using 2 periods for this ellipse..
I expect better from you, Danack.
&gt; referring to as, PHPStorm I'd like to interject for a moment. You look like a tool being so full of yourself and not knowing where to place a comma. &gt; correct in future. Same goes for articles. 
I want to integrate Amp into the next major version of [Porter](https://github.com/ScriptFUSION/Porter) to offer async data imports. My motivation includes a number of projects, most recently: the [Steam Top 250 games list](http://250.scriptfusion.com/) [generator](https://github.com/ScriptFUSION/Steam-Top-250), which initiates massive amounts of HTTP calls in series. This is grossly inefficient and takes over 9 hours (but due to parallel processing on Travis is [reduced to 2 hours](https://travis-ci.org/ScriptFUSION/Steam-Top-250/builds/298401204)). Since the majority of the time is spend waiting for HTTP negotiation, I feel a lot of benefit could be leveraged by the power of async pooling. However, I currently do not understand how to integrate Amp. Generally Porter's interfaces pass around iterators of arrays. I believe that if I was to implement an async API I would need to pass around promises. The real difficulty I have is understand where in the abstraction the promises can "terminate", i.e. we can stop dealing in promises and return to iterators of arrays again. If the answer is "never", and every single component that plugs into Porter must explicitly support async, I fear an integration will be impossible. Ideally I'd like to terminate the reliance on promises and return to sync land as soon as possible, but I currently haven't been able to determine where that is. Does this make any sense and can you provide offer any insight?
You would do yourself and everyone else a favor by not spamming a discussion thread with copypasta just because someone didnt stylize a name according to brand standards.
I want to integrate Amp into the next major version of [Porter](https://github.com/ScriptFUSION/Porter) to offer async data imports. My motivation includes a number of projects, most recently: the [Steam Top 250 games list](http://250.scriptfusion.com/) [generator](https://github.com/ScriptFUSION/Steam-Top-250), which initiates massive amounts of HTTP calls in series. This is grossly inefficient and takes over 9 hours (but due to parallel processing on Travis is [reduced to 2 hours](https://travis-ci.org/ScriptFUSION/Steam-Top-250/builds/298401204)). However, not only is the the majority of time spent waiting for HTTP negotiation, the amount of additional code complexity required in chunking up the import and stitching it back together accrues a massive amount of technical debt. I feel a lot of benefit could be leveraged by the power of async pooling both in terms of speed and code quality. However, I currently do not understand how to integrate Amp. Generally Porter's interfaces pass around iterators of arrays. I believe that if I was to implement an async API I would need to pass around promises. The real difficulty I have is understanding where in the abstraction the promises can "terminate", i.e. we can stop dealing in promises and return to iterators of arrays again. If the answer is "never", and every single component that plugs into Porter must explicitly support async, I fear an integration will be impossible. Ideally I'd like to terminate the reliance on promises and return to sync land as soon as possible, but I currently haven't been able to determine where that is. Does this make any sense and can you provide any insight?
thanks for the tip, snowflake.. I removed all uppercase letters, just for you
PHPSTORm.
Bad bot. 
Are you sure about that? Because I am 99.9997% sure that Saltub is not a bot. --- ^(I am a Neural Network being trained to detect spammers | Summon me with `!isbot &lt;username&gt;` |) [^Optout](https://www.reddit.com/message/compose?to=perrycohen&amp;subject=!optout&amp;message=!optout) ^| ^Feedback: ^/r/SpamBotDetection ^| [^GitHub](https://github.com/SM-Wistful/BotDetection-Algorithm)
Bummer. (S)he acts like one, and it would be easier to fix. 
Staying in your cozy safe zone.
usually, people who switch from one language to another, try to stick to the tools they've used before. I'm sure there are some people who use VS, but it's not the best tool you can use. Personally, I like Brackets, since it's free and very versatile. But there are tons of other IDEs you can use that are still better than VS. 
This reminds me of the Bl√ºcher scene in Young Frankenstein. PHPStorm. 
C++ is a much less safe, more verbose and harder to get right environment compared to a mainstream script like JS, PHP, Python or Ruby. Oh, wait you meant this to be a rhetorical question. While PHP and JS are comparable (especially with TypeScript).
Nothing is overkill when you're using PHP to do CQRS and event sourcing. PHPStorm makes digging through and learning libraries like prooph much easier.
Well, two things: - If you use a persistent PHP process with an event loop, you're using one core *exactly* like Node would. - Node's V8 is actually faster on one core, than PHP is on all cores for a typical deployment/server. So there are no advantages, except one: utilizing some of your existing PHP source code.
An example is that one of my projects builds its PHAR on travis and deploys that back to github when we tag a release. To do this, travis has to have my github key in .travis.yml - this is achieved by encrypting it: https://github.com/phpspec/phpspec/blob/master/.travis.yml I did that by hand, this lib does it programatically I guess.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [phpspec/phpspec/.../**.travis.yml** (master ‚Üí 30f329c)](https://github.com/phpspec/phpspec/blob/30f329cf253e581dac4410d5dbbd8b778b180028/.travis.yml) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
I write it like that, because I like the way it looks, but I will do you a favour.
Maybe you don't want to rely on a big tool chain required for source maps etc. that come with TypeScript. Maybe you don't like JS that much as a language. Maybe ...
No, that was clever, he's just a troll. His history shows lots of time spent dropping racial epithets on the 4chan reddit.
If you separate commands, queries, and persistence, you will need a public persistence method.
It's not a big tool chain, it's just a single compiler. Which also runs on Node.
Right, it doesn't. Amp can use `libuv` as underlying event loop, too, just like Node, but it also allows for other loop backends.
well, you can play doom on it. 
well, you can play doom on it. 
https://alistapart.com/blog/post/the-most-dangerous-word-in-software-development
I have a sad.
The "just" word is used as a qualifier for "single" here. Would you like to argue that "single" may subjectively be a very, very large number or something? Be my guest.
Which fetch mode did you primarily use? I've found FETCH_CLASS to be a really clean way to clean up all the nasty data structures in older php code.
Were they punished for their sins?
Because of the amplitude of existing, well developed, well supported, PHP resources available that you can simply add into your project. 
Aggressively? Really? What marshmellow world do you live in?
You seem a bit too obsessed with the spelling of PHPStorm.
Marshmallows can be deadly if thrown at sufficient speed.
The point where you end the promise-land is the point where you stop with concurrency. You can do blocking things without promises in between as long as they're short enough to not make your open connections timeout, but nothing in the event loop will run during that time. You could also execute certain things in another thread / process by using `amphp/parallel`, but I don't know how well that fits into your application design. Does that help?
Company of a friend of mine outsourced a part of a project once. They were wondering about the weird phone-number they provided, until they found out that it was a freighter in international waters, filled with code-monkeys, to avoid paying taxes. You shouldn't be surprised when you learn things like that. Assuming that every corporation is legitimate and working from an office-building in a respected country, is the only assumption that will most definitely cause you surprises...
I don't think saying "maybe" is aggressively. I'm just guessing reasons why people like what we do. Node is definitely an viable alternative, whether you like it or not is up to you. But why not have alternatives? Why does it have to be _"Node for everyone?"_ Alternatives and competition are the best drivers of innovation and progress. "Big tool chain" is more what I'm used to for browsers TBH and it will definitely be less tooling required for Node.
I'm very sorry for my mistake, I really hope I didn't ruin your day
I'm very sorry for my mistake, I really hope I didn't ruin your day 
I'm very sorry for my mistake, I really hope I didn't ruin your day
Maybe you just want to use it to speed up your existing application by parallelising your HTTP requests to external services or any other currently blocking I/O. You don't want to rewrite your complete application to JavaScript for that. If you have a greenfield project it might be different, then you might ask exactly that question. There are probably benefits to using either, you have to weight your current situation and knowledge inside the company and other factors.
They're pretty much exactly the same regarding multiple cores.
Are you seriously suggesting Javascript is a better language that PHP 7.1? What are you gaining by using Javascript server-side under any scenario? PHP is a far, FAR better language than Javascript at this point. People still have an impression of PHP from version 4. It still has quirks, but it's pretty reasonable these days.
It's not that I consider Node the pinnacle of software platform engineering, but when you want to write async code, just having an event loop is not enough. The event loop is the trivial part, so trivial, you're kind of having a tutorial about it in your article. The hard part? The ecosystem. The moment you start using the file API, or PDO, or most of MySQLi's API and you start blocking. And you can choose not to use them, but then the libraries you'll get off Composer will use them. And the frameworks and components built upon those libraries will use them. There's little to no async ecosystem around PHP. You're automatically in the ghetto. While with Node everything is async by default, and all the Node packages are aware of this. So that's why it has to be Node and not PHP. Because the ecosystem is the difference between a toy "Hello world" example, and a real solid platform to build your company application on.
I have started the Laracasts series and its great so far. I have noticed one thing, there is no video on Sessions or cookies. Are they not used any more or are they not basic enough for this series? 
It depends a lot on what you're going to do. If you want to write a new application server, Node will definitely have the richer ecosystem. But that's not everything we can use non-blocking I/O and async for. We can also make multiple HTTP requests in parallel in an otherwise totally synchronous application. If you have microservices communicating over HTTP and need to query multiple of them in a single request, parallel requests give you a huge speed up compared to sequential requests. Of course, writing an app server in PHP with the entire ecosystem against you is far less then optimal. But you can still use a lot of libraries that don't do any I/O. The set of libraries available will grow and grow in the future and more code can directly benefit from non-blocking I/O. In the meantime some libraries can be used by leveraging multiprocessing for blocking tasks. That said, it's entirely possible to write application servers in PHP today. No "Hello world" examples, but production ready applications.
For non-blocking I/O such as database queries or network requests there is no need for a pool of thread. Libuv only uses a pool of thread for blocking I/O like filesystem operations.
I don't know if that's relevant, but when you mentioned collections and async, [RxPHP](https://github.com/ReactiveX/RxPHP) came to my mind. 
lolphp. Its still the same language as it was in 2005. The stdlib is the same, it hs the same warts (because of bc breaks) and it is still running on one core. 
haha that's amazing! I wonder when I see a site like https://www.upwork.com/cat/developers/ how many of those are actually real people. 
I'm not going to argue which language is better, but the question was whather you'd use PHP or JavaScript for asynchronous IO. JavaScript has a built-in event-loop while PHP doesn't. So nearly all existing PHP libraries work synchronously and expect stuff to be available synchronously. In JS, synchronous IO is rare. Nearly every library expects and delivers things asynchronously via callbacks or promises and there are even built-in language features (async and await) now to write async code that looks sync. Also because everything works via the same event loop, async code is compatible with each other. In PHP, do Amp libraries work in ReactPHP and the other way around? 
perhaps the studio code or something, the one that's electron based
I hate electron apps(atom/vscode) :D and now you because you like it 
&gt; I hear a lot of chatter about visual studio lately being used for node js, php and other languages Are you POSITIVE the chatter isn't about Visual Studio Code? Because I've heard next to 0 serious talk about using Visual Studio(the full IDE) with these languages. However there has been a lot of talk about Visual Studio code in general.
Your welcome and congratulations on seeing through with it :) Excellent job in trimming the images down :) 
I used to use VS.php at my last job to do PHP development in VS Pro. https://www.vsphp.com/ It worked great, but I've since moved onto PHPStorm and very much prefer using it.
Lol this is the right answer
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
He prefaced it with mentioning that he was asking a serious question; not trying to hurt your feelings. The reason is that node is by default using an event loop and designed for async applications. Saying PHP is A "far, FAR better language" isn't just ignorant, it's flat out stupid. You're too busy being offended to realize that not every problem is solved with a hammer. You can't ignore the obvious strengths of a language, ignore the weaknesses of another, and expect to be treated as an adult, much less a professional, when trying to compare the two. 
Sheesh. I'm not offended; it's just the idea of "why use PHP when you can use Javascript?" is silly. And if you think the idea that PHP is a far better language than Javascript is "flat out stupid", then sorry, you're just plain not knowledgeable enough of the strengths and weaknesses of both languages to have an opinion. Sure, if you want to talk about some narrow toy problem, you can probably find a case where JS is a better tool. But it's foolish to mix languages unless there's a damn good reason, and if you're talking about a larger scope of application, then you have to take into account the *entire* solution, not just one narrow focus. The idea that languages are tools in a box is used way too often from people who either don't know better or should know better. If you're building a house, the more types of tools you have, the better. If you're building a software application, the more languages you have, the worse it is.
&gt; The point where you end the promise-land is the point where you stop with concurrency. I think this might be very helpful, but I won't know for sure until I spend some more time with Amp :) 
&gt; The point where you end the promise-land is the point where you stop with concurrency. I think this might be very helpful, but I won't know for sure until I spend some more time with Amp :) 
&gt; The point where you end the promise-land is the point where you stop with concurrency. I think this might be very helpful, but I won't know for sure until I spend some more time with Amp :) 
[Yes, they do.](https://amphp.org/react-adapter/) An adapter the other way around is currently missing, but not strictly needed, as things can just run on Amp's loop.
Well, you've convinced me you're just a troll.
That's pretty neat. What about their promises? It seems like ReactPHP uses A+ JS-like promises, while Amp [rejects](https://amphp.org/amp/promises/) (not pun intended). Won't that mean that libraries written in one library won't work in the other?
Here's the direct link to GitHub [ https://github.com/daveearley/cli.fyi](https://github.com/daveearley/cli.fyi) :-)
God I hope not.
That you evidently think that the idea of "fewer languages is better" is so absurd as to be trolling makes me weep for the future of this industry. On the other hand, given the general level of software quality I observe, maybe it's not that surprising.
i'm using sublime text 3, yeah sue me...
I've been a PHP programmer for 18 years now and I know exactly one guy who used it. At least I *think* that's what he used. He was a .NET developer who was forced to use PHP 4 and disliked it, and built a small little .NET framework thingy in PHP just so he could sanely work and build a reasonable application. It's not that he was a bad dev or anti-PHP, he just didn't understand PHP. It doesn't matter. My point is he's the exception that proves the rule. Like others have said, if someone told you they use Visual Studio they're probably talking about Visual Studio Code. I don't doubt that Visual Studio Pro is what you're talking about, but I do doubt it's what the devs themselves are talking about. Not to rip on Visual Studio Pro BTW, for all I know it's awesome. But in my experience PHPStorm is the way to go for every serious PHP developer, and those who can't afford it use Visual Studio Code, Atom, TextMate or Sublime Text. I suspect you'll find that PHP devs pretty much universally agree on that.
Maybe VSCode but I don't see any reason to use visual studio unless you're very entrenched in .NET. In which case you probably want to use ASP.NET instead of PHP.
Ironically - this being a PHP subreddit - `curl cli.fyi/PHP` fails, but it's there in the documentation. {"error":"\ud83d\ude22 Sorry, we don't know how to parse 'PHP' at this time"} Works with lowercase, though: `curl cli.fyi/php`
Second this. Keep things transactional at first. That way, you can part ways with someone you don't like at the end of a project. Keep cycling until you find people who gel with you and your projects and then try to keep them around.
Whoops! should be fixed now, cheers for the heads up
Working through the Laravel basics, I'm wondering why controllers use `@` when referencing methods instead of `.` or `-&gt;`? Route::get('/foo', 'FooController@bar'); // Kinda arbitrary to use @ here, no? Route::get('/foo', 'FooController-&gt;bar'); Route::get('/foo', 'FooController.bar'); This feels extra weird since you reference views using `.` return view('foo.bar'); Does anyone know the reasoning behind this? I can't seem to find a PHP-relevant explanation to the `@` symbol.
Laravel has [automatic package discovery](https://laravel.com/docs/5.5/packages#package-discovery), which will register the service provider automatically. By default, Clockwork uses the `app.debug` setting to enable or disable logging. As /u/MaxGhost said, if you install Clockwork using `require-dev`, it usually will not be installed in a production environment so long as you've configured production properly. That way, the package won't even exist, let alone be initialized during the application process.
why?
Yes, specific version explicitly in composer.json.
No choice this time.
We favor coroutines over `then()` chains. Amp supports ReactPHP's promises in coroutines just like its own promises, see https://amphp.org/amp/coroutines/. For using `then()` chains on an Amp promise, you need a simple `adapt()` method like the one provided [here](https://github.com/reactphp/promise/pull/100/files). Minor nitpick: ReactPHP implements A not A+. [There are minor differences.](https://promisesaplus.com/differences-from-promises-a)
TIL .fyi is a valid TLD. Can't keep track of them.
&gt; Because of the amplitude of existing, well developed, and well supported, PHP resources available that you can simply add into your project. and 99% of them were not developed with async I/O in mind. How do you think your RDBMS calls will perform in your event loop when the calls are blocking? 
async has already proovd to be good for normal project because of call-back hell. nodejs has semi-coroutine to overcome this such as koa. php also has semi-coroutine such as zanphp. reactphp is out of date. now the trend is coroutine: swoole2 will run sync code with coroutine, gain performance and avoid callback-hell.
You seem to confuse fewer with more. Obviously using only JavaScript would be fewer than PHP plus the generally required JavaScript for front end development. But it's easy to mix those words up I guess. Should The drawbacks of using multiple languages be considered? Absolutely. To say that the drawbacks are always going to outweigh the benefits is asinine. To say there are no benefits is just as asinine. You're opinion on the quality of software is irrelevant since you fail to grasp the most fundamental aspects of software complexity. You'll have to forgive me for not taking your thoughts on the subject seriously. 
&gt; PHP is a far, FAR better language than Javascript at this point. Typescript is a far far better language than PHP.
Except now you've got a whole new server to patch &amp; monitor. For a very small subset of the applications I build (very small, data not sensitive) shared hosting is fine. I've got CakePHP, Lithium &amp; Phalcon apps running fine on quality shared hosting.
https://sourcemaking.com/design_patterns/factory_method
Is there a signifcant reason to use async over queues? Every time I think about using async - I find it easier to just push the command to a queue and let it handle in a different process that way. It just seems simplier, and easier to "reason" what the outcomes will be (especially for debugging). Am I missing something obvious that I should have async over a queue?
Maybe because https://codegolf.stackexchange.com/ seem way better.
Because, why not?
Because PHP in 2017 has nothing to do with PHP in 2005 even though a good chunk of the stdlib from that time stayed the same :)
No problem. Good work :)
Why polluting the global namespace? Why taking that risk? You have namespaces for a _very_ good reason. The only advantage of putting things in the global namespace would be to avoid a use statement which is a silly reason IMO.
ConEmu (https://conemu.github.io/) with Git Bash shell. It's fantastic.
&gt; What are you gaining by using Javascript server-side under any scenario? In the scenario of regular PHP (not async PHP) vs Node: Don't have to use/configure PHP-FPM. Easy server side rendering of React templates. Last time I tried doing it in PHP it was a pain in the ass. Maybe it's gotten better? Don't need to use two dependency management systems (composer and npm). Websockets (any long running server process can do this). If you're using Typescript, you can share interfaces between front and back end. Makes it great when doing API calls. Parallel database queries I think basic Javascript still sucks. Typescript and async/await makes it quite usable though. 
That's really what I was curious. Competition is great but I wasn't sure why someone would choose this option over JavaScript. I see a couple of good points in this thread but I now see that I completely derailed your announcement so I'm considering deleting my original comment.
https://nodejs.org/api/cluster.html
I highly doubt Wordpress will ever leave PHP
Proper unicode support.
"event loop" is a pretty generic term. The secret sauce appears to be basically `stream_select()` which I didn't know about previously. Not sure if it really counts as "async" though since the operations aren't happening in another thread or process concurrently, you're just using `stream_select` inside of a loop to block until one of the streams you're dealing with does something and then deal specifically with that stream before you go back to blocking. That's not usually what people mean when they say "async." That's just very efficient sync.
Can you clarify what you mean? Are you talking about job queues with a pool of workers doing those jobs? If people are using "async" to do that, yeah, I think that's really unnecessary too. I do however find async (I use ratchet) in PHP most useful when doing networking: e.g. running a websocket server with numerous clients.
Hows this compare to something like laravel? 
The thought occurs that, rather than have all these unrelated services mixed up together, having them available as separate [Porter](https://github.com/ScriptFUSION/Porter) [providers](https://github.com/Provider) might be more reusable and thus useful to other PHP developers.
Been a professional PHP dev for 14 years and most of that has been exclusively on windows. Being a developer also requires communication with clients who send and expect to receive Microsoft formats. Libreoffice is great but it always screws up formatting when converting to word format. I've even worked places that don't allow IMAP or POP emails. MS Exchange protocol only. Also Testing. Testing ie versions is obviously easier on windows. Not to mention testing email templates in outlook. For me there has never been another option. In a business environment windows is the only way. However I understand how a developer who is completely cut off from clients might prefer Linux. I've wanted to switch to linux many times. Especially with js build tools which always seem to have windows quirks. I think that for day to day business stuff Linux or Mac would require too much attention to make it play nice with the corporate world. I just can't justify spending that time. 
Wow I didn't see that coming. I thought for sure you were talking about VSCode (which I use, and love). I don't think any PHP dev would be using VS Pro. Sounds like a nightmare.
You're confused. That's what async is. 
Moving things to a persistent queue and outsourcing it to another process doesn't solve the problem, it just moves it elsewhere. So let's say you enqueue a million HTTP requests and you ship it to another process. Now how is that process going to deal with that million HTTP requests? Blocking, one by one, in sequence? Then you didn't win any time, you just waited some. A job queue and async processing are both good techniques, but they're apples and oranges, their use cases are different, so comparing them is mostly unwarranted.
üëç
https://www.reddit.com/r/PHP/comments/70qere/any_good_reactphp_or_amphp_examples_with_doctrine/dn6ey2t/
I taste salt.
It depends a lot on what you're trying to do. If you just want to run stuff async after a user finished his HTTP request, yes, go with queues. But usually async as in event loop + non-blocking I/O is more used for other gains such as I/O concurrency, not off-loading work to a worker to be done later.
I haven't heard of zanphp yet, but the overall usage of async PHP seems to be much higher in Asia and Russia than in the western world. Unfortunately, there's often no English documentation for these projects, so only few people in the western world manage to use these tools.
No rabbitmq doesn't give you the queue id. Once you push thing into the queue you can't find it anymore. And you don't know it's status. So if one is interested in the status. of said item e.g still queued you don't know without having this stored inside some other persistent storage.
Yikes.
Like Ethanol responded, the mistake is by yourself and you shouldn't be "SO ANGRY" about, esspecially if it's your fault. I understand that it becomes frustating sometimes.. but composer is working very good for a third party solution. Try debuging first and understand if there is REALLY a mistake. In the error code you can see the file which tries to open the file. The file path has `\TastefullyObscene\` as path while it tries to open the file in a path like `\TastefullyObscenesendgrid-php\` which is obviously not the path in which the file lies, but obviously a combination of two directories "not" splitted with a PATH_SEPERATOR. So changing it to `\TastefullyObscene\sendgrid-php\` should do the work. By the way /r/phphelp is the right place for that.
So whats fundamentally different then? 
You mean alcohol, not ethanol, which is me. I just thought I would share this gem. The joys of maintaining open source software and all that.
Why did I wrote Etha.. seems like I am drunk too. I am sorry, I thought it's a cross post. I sincerely apologize for the inconvenience.
well, people here don't have much sense of humor, so this kind of posts should be supplied by a lengthy disclaimer with explanations.
Gather your data and use PHP to generate an RSS feed. Then use [IFTTT](https://ifttt.com/) to automatically post new content to your social networks.
Under the social rules of the Trump era, the fact that indomtrading's misfiring rage resulted in a solution, and they didn't need to say thank-you, is a simple and emphatic win.
lol what a retard blaming other for his own fault, and for OP make a better title next time so people didn't judge very quickly and think that it's your post
The real question is, is that dreamweaver I see in the screenshot? And if so, why on gods earth would you use dreamweaver?
my favourite bit here is that the screenshot actually has the answer in it
This belongs on /r/lolphp
Mostly compliments by substituting some of Laravel classes. One example would be [Form](https://laravelcollective.com/docs/5.4/html#text) which implements basic HTML element rendering can be substituted for the http://agile-ui.readthedocs.io/en/latest/form.html, which pretty much handles all Form-related rendering, decoration, layout, data transitioning. At a higher level, Agile UI is similar to Voyager or some of the other Laravel admins, but is much more modular and flexible, since you define everything through the code. Agile UI has many high-level components which Laravel simply does not have, like built-in AJAX loaders, Dynamic Tabs, Dynamic Modal dialogs, and stuff added in 1.3 which I listed above, those are quite unique and would require you extensive tinkering with JS/CSS/HTML in vanilla Laravel while taking just few lines with Agile UI. Finally, I think most of Laravel devs prefer Bootstrap, while Agile UI uses Semantic UI for CSS.
Actually, they would sneer at it too, as they insist that only PHP's own faults are on topic, not stupid users'. But, in a way, sometimes it's hard to tell PHP from its stupid users...
Sorry, I'm a noob at reddit :&lt;
I hadn't come across Porter, looks like a nice/comprehensive tool. I'll definitely look into it further.
cheers, ill check it out in more depth then. Is there a sample app of sorts with recommended folder structure? 
Their bug is clearly visible no less than **three times** in that person's own screenshot. They're really special.
On no. I can tell you as an expert that there is absolutely nothing special in this attitude. Just check /r/phphelp and you will see - all answers there don't take any reality into consideration but being plainly random guesses. 
If you work in a company where 95% of your codebase is c/c++/c# and the remaining 5% is php or node you already have Visual Studio (not VSC but any of the other versions). In that case if you are going to work less than one hour/week in php or node why would you buy an extra IDE, or install something else, you have a tool already that can read the code and do some basic tricks... Of course in that case you are not exactly a PHP dev but... 
Yeah, I ran in that kind of issues a couple of times in different codebases it was not pleasant time.
Typing, classes, autoloading, the ecosystem tooling &amp; maturity among other things but I'm sure you can read a changelog.
No, not really. I think if you are with Laravel you already have a good structure, you can just put Agile UI into your view controller and make sure call-back URLs are routed back.
Here's the list of active TLDs. I think it gets updated once a day: https://data.iana.org/TLD/tlds-alpha-by-domain.txt
Serious question, why would `FooController-&gt;bar` be better, its not an instance call, `$fooController-&gt;bar` would be. Its not string concatenation. If anything I read it as `ThisClass at thisMethod`. If anything, I would only consider something more like `[FooController:class, 'bar']`.
I don't know about YouTube but laracasts have a lot of good tutorials. Not only oop but also with laravel, design patterns, testing, etc. It helped me a lot into my transition to PHP and Laravel
The new ‚Äùtypesystem‚Äù is a joke, classes have been around since forever, autoloading (i assume you mean composer) is still hacked with same functions, that existed before.
Does Dreamweaver really display PHP error messages in the program like that?
I think it is a built in browser preview window/panel
It seems to be nice when you're working with a dawn wrongly architectured API aside. I can see that you're basically using it to access data in a very complex object graph (typically what would Drupal do). Maybe your API is nice to use for accessing stuff in such objects, but I think what it does is primarily hiding the fact that the business API you're really using is ugly and should be designed otherwise.
I dont like replacing code with strings: no auto completion, no refactoring support. if used extensively, the performance impact will become noticeable. also, why not use `.` notation instead of slashes? seems more natural
Interesting solution. It's basically something like XPath or JSONPath but for PHP objects. How fast is it compared to direct object/array access?
It reminds me of the `Hash` (previously `Set`) class in CakePHP - [docs here](https://book.cakephp.org/3.0/en/core-libraries/hash.html).
Somewhat similar to Symfony's property accessor? https://symfony.com/doc/current/components/property_access.html
Interesting. Were you aware of Symfony's PropertyAccess (https://symfony.com/doc/current/components/property_access.html) ? Your project looks a lot like PropertyAccess with a slightly different syntax and set of features.
Thanks - I kinda get it now. I'll play around with it some more.
Thanks - I kinda get it now. I'll play around with it some more.
Thanks - I kinda get it now. I'll play around with it some more.
[Actually yeah it does.(https://www.mullie.eu/parallel-processing-multi-tasking-php/) You'll notice the talk of threads because that's how you handle I/O coming back to the async call As another example, when you issue an async database query you're not issuing multiple database queries and waiting for one of them to come back you're doing some work (which might involve database queries or some computational work) then use `reap_async_query()` to block until the async query comes back. This is different than the OP where he's just multiplexed his synchronous I/O He's still behaving in a response-&gt;result-&gt;follow-up manner, he just happens to not be waiting on one particular stream to finish before continuing work. When it does though he'll still be executing it within a single thread identical to if he had been synchronous except for the multiplex stuff. I mean it's close to async but I don't know if it's really fair to call what he's doing in the OP async
The use of slashes kinda reminds me of XPath.
&gt;The new ‚Äùtypesystem‚Äù is a joke I find it being a nice compromise between strict typing and loose typing. &gt;classes have been around since forever Classes have been introduced at the end of 2005, and there was quite a few things missing like generators, constants or traits. &gt;autoloading (i assume you mean composer) is still hacked with same functions, that existed before. Right but before everyone where rolling their own shit. Composer with the PSR-0 and PSR-4 standards changed the game which is 100x times better than how things were done back then. But if you really want a language that evolves a lot, why not picking nodejs that bumps a major version every 6 months or a drastically different language like Haskell or Scala? Nobody's asking you to love PHP, a lot of the PHP user don't particularly love it either, most of us (I assume I may be wrong after all) just use it because it works good enough to get the job done and we don't feel that alternatives like Java, Python or Rails are significantly different.
Long Term Support release. Check: https://laravel-news.com/laravel-release-process
I've used this on a number of [projects](https://github.com/academe/Omnipay-AuthorizeNetApi/blob/master/src/Message/AbstractResponse.php#L40), and it works well, though you need to wrap it if you want to catch invalid dot-based paths into the data. It's great for API response data that object contains a good mix of objects, some with getters and some without, and arrays.
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [academe/Omnipay-AuthorizeNetApi/.../**AbstractResponse.php#L40** (master ‚Üí 958ef3f)](https://github.com/academe/Omnipay-AuthorizeNetApi/blob/958ef3ffbc2ade969fd8f73d663bdae584bc8b6e/src/Message/AbstractResponse.php#L40) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
php sucs
I use VSCode to write PHP and JavaScript on my Mac and Ubuntu machines all day, I love it. Visual Studio Code is definitely what you're hearing about. I'm the last person that would have ever believed I'd end up using a Microsoft IDE to write my PHP, let alone on Linux Amazing features: - Git integration - Multi-file find/replace - language server extensions for inline linting - debug extensions
So, fun fact. You know how in PHP 7.2, you can do `list()` by key? ["foo" =&gt; $foo, "bar" =&gt; $bar] = $bar; Well, part of the reason for that was I would like to eventually add the ability to do that in function parameters: function trendyHTTP(["method" =&gt; string $method, "url" =&gt; string $url, "async" =&gt; bool]) { /* ... */ } But I haven't gotten round to it, and don't know if it would succeed. 
I think it's an interesting project and a nice exploration of a certain problem, but it's not something that I would want to use in an enterprise setting. I would go for a more explicit method of extraction and hydration, also considering that I probably already have a more strict domain model in such a setting. Adding to this that I want to reduce cognitive load for current and future collaborators, so I want to keep code as naturally navigable as possible. With a tool like this, you will need to write IDE plugins and such on the side to accomplish that. &gt; The Raw PHP approach is not implicitly secure : Some of the methods/properties along the expression can return or be NULL in some case and then cause an exception. If you really want to secure expression, you would have to test some of the values before accessing them. That's a really boring point developer often have to deal with : it's repetitive, unappealing, can induce bugs and makes code less readable. This problem can (and should) be avoided beforehand. Domain modelling is actually the most important part of software development. I always model optional object properties to arrays. I disallow instantiation (by self-validation) of incomplete objects. This actually makes sense in most domain models and this makes it easier to deal with such cases upon application implementation. By this you are secured of a proper model and as a bonus, you remove the need for those boring and repetitive tasks of null checking and return value validation. I do see a use for this, however. For instance, if I walk into a semi-abandoned legacy project that has poor modelling and a lot of technical debt, but there needs to be a feature expansion while there is no time to refactor, this is one of those tools that could make life a lot easier.
Sounds a mess, I would re-build from a fresh install of Laravel and your stack of choice. Then would pull code and refactor / restructure and build from ground up. You will have a much better platform with everything you are currently missing to build the prefect system with testing, environments, package management etc etc. All on top of the latest stack you choose. And teach the current developer what‚Äôs good coding practice :)
Forgot to say, I had to go through the same, was on Codeigniter with lots of mess and was best decision to re-build from fresh. Took a while but now life is much easier and have total control.
Rebuilding from ground-up is not a bad choice, because everything we have built ourselves will be right out of the box, such as authentication scaffolding, payment (Spark). There is a new design coming our way so it can be the perfect time to build from ground-up. Right now, we're not utilising neither gulp nor webpack nor any JS compiler, nor any CSS pre/post processor. And there is no templating engine so PHP is just inlined in our views. It's a mess I tell you.
Yup, this is it! There are other ways you could do it but composer makes it easier. I had to do this a few weeks ago and wrote what I discovered here: https://www.phparch.com/2017/09/generating-autoloader-legacy-php-codebase/ 
[What a hot mess](https://cdn-images-1.medium.com/max/1600/1*5J_NHA2cTjMZ1atxJpSgOQ.png).
Great stuff. Love it.
Please don't use this in any type of production system. What a mess. If you need a module like this, your code sucks to start with.
Wait a second! You want to completely refactor a large poorly understood but working application while at the same time implementing a new design? There are all kind of horror stories about defunct companies that have tried this and failed miserably. I'd suggest making sure the CEO knows that this is a bet your company proposition. And have your exit strategy firmly in place.
that's true. in china php is very popular and the qps is higher than other country due the big population. so chinese phper have the motivation the improve the performance of php. i personally don't like laravel for its bad performance, high mem-usage and complexity. hello-world benchmark is wrong. a real-world php application has many sql/redis io and the bottle neck is io or framework. you can use flame graph to locate the bottleneck. to overcome io bottleneck, people use async but run into callback hell. to overcome callback hell people use yield to implement semi-coroutine in js,py,php...but yield is still difficult...people want to full coroutine like go. alibaba company cracked jvm to hook io funtion and implement coroutine. php's swoole extention use setjmp&amp;longjmp in zend api to implement full coroutine. js&amp;py seemed that no full coroutine yet. but the swoole community is mainly maintained by a contributor and the dev speed is slow.
very constructive
I know what you mean but this system isn't moving forward positively and isn't future-proof. Depending on the database structure and how well it has been maintained, you could build the new system and run alongside current and allow users to opt in or out of the new system sharing same DB or replication. As /u/ahundiak has said, make sure the dev team, ceo / owner etc know whats got to happen, why and what could happen.
You're right about replacing code with string, it's a fair point. beside I considered it worth it while designing the solution, but I completely understand your point. I user "/" instead of "." syntax in path to get closer to linux path and also, you can use '.' and '..' in path to refer to previous elements in path (kinda like in linux path). So slash looks good to me.
in a word, any async framework in any language is somehow out of date. backend is embracing coroutine if you need performance. however, if your app has low qps, just use any framework that run in php-fpm. php backend framework is very mature.
nice (flattering) reference ;) 
a bottleneck example:https://github.com/phalcon/zephir/issues/694
Just think, you could refactor code and make it faster / cleaner but then what? Its still old, out of date, codeigniter 2 has reached end of life support so your going to move to a new framework anyway. I guess it depends on how committed you are as the other (Lead?) developer seems to want to stick with the old and play it safe. It must be a nightmare maintaining the system, cant be much fun in its current state.
Yes, It can look alike at a first glance, but i think philosophy and use case can be pretty different ;)
The initial thought most developers have is to start over from scratch, which is [almost always](https://softwareengineering.stackexchange.com/q/6268/12319) a [really, really bad idea](https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/). A huge refactor that involves moving to a different framework is almost as bad for exactly the same reasons - it will take a long time, during which you'll be trying to merge code between the two versions, and you'll end up breaking a ton of shit while doing it. Pick up a copy of *Working Effectively with Legacy Code*. In the meantime, I'll give you the tldr: 1. Pick as small a thing as possible, say, one function. 1. Write tests for it. If necessary, do minor refactoring so that you can write the tests, but be very careful about that. 1. Refactor the hell out of it. 1. Make the tests pass again. 1. Ship it. 1. Repeat. The more changes you make at a time, the more likely you're going to break something. And this is a production app - not breaking things is your highest priority. You should apply these steps to *any* work you do on the app - add more test coverage, and leave that area of the code better than how it was when you left it. When this is how the entire development team treats a codebase, it will turn around surprisingly quickly. And you will be much more valuable to your employer than someone who came in, argued for a whole bunch of work, and then after months of neglecting the current customers ended up with something that's works significantly less well than the original project. Work with what you have, and try to understand the business perspective. If the specific technologies are really really a problem, you can go with the current trend of moving to a microservice architecture (so you could rewrite pieces in Laravel, or even better, not PHP). But this is the same idea: take a tiny piece and rewrite it, and do that continually over a period of years. Good luck!
It's fast enough (which means nothing I must say :) ). To be honest I didn't benchmarked it already but i plan to ! thanks for pointing it ! performance is a real point to me.
What's the difference between a semi coroutine and and a full coroutine for you? A non-viral effect, so you don't have to make everything in the stack a coroutine / promises, but instead can `yield` everywhere in the stack and it'll work?
Isn't emptiness yet another part of us that needs to be expressed too?
do you have any good tutorial on this topic? I need to create a gRPC client but I'm little lost in their guide it would be nice to have some tutorial how to create client (PHP) from scratch and connect it to some server (maybe also created from scratch)
I didn't heard about it till now. Thanks. I'll look into it for ideas !
semi-coroutine is a coroutine(multitask scheduler, yield cpu to other task when io happend) built on generator/yield. the famous post: http://nikic.github.io/2012/12/22/Cooperative-multitasking-using-coroutines-in-PHP.html full coroutine is like go. very simple and high perfoance on io.
I would have preferred `::` personally, but I'm okay with `@`. Either way, it's a proprietary magic string. I *think* you can replace it with a callable if you want to avoid using it entirely: Route::get('/foo', [FooController::class, 'bar']);
Used this method to migrate to Symfony in approximately 15 applications, last one is almost done. https://stovepipe.systems/post/migrating-your-project-to-symfony
This team leads Laravel development in github how dare you! /s ^^ the guy looks like the serial killer from True Detective season 1
Sounds like a great time to actually learn how the application currently works, find gaps, close those gaps, stop band-aiding shit, write documentation, and have a proper application.
The last graph (*The number of employees in your business*) was very interesting to me. It seems to me that larger companies tend to create their own frameworks specifically for their needs. At least that's what i figured while i was applying to jobs.
It's a code editor split with a browser preview. So if you know why someone would use a code editor, and why they'd want a browser preview, there's your answer. I know, you're being sarcastic, because you're kind of reaching for the "Dreamweaver sucks lol" meme. But your meme is about a decade out of date.
I spent some time working on a more general match mechanism a week or so ago: $input= [ 'property' =&gt; 'value' ]; $result = match ($input) { // attempts to match one-by-one in order until one is found int =&gt; "Is an integer", { $foo } =&gt; "Is object and property 'foo' exists with value '{$foo}'.", StdClass{ $foo } =&gt; "Is StdCLass and property 'foo' exists with value '{$foo}'.", [ 'property' =&gt; $property ] =&gt; "Is array and key 'property' exists with value '{$property}'.", // Throw when there isn't a match. Perhaps use `default` for a catch-all? default =&gt; "No match.", }; echo $result, PHP_EOL; // Outputs "Is array and key 'property' exists with value 'value'." Any valid `match` pattern could be extended to function parameters.
&gt; not a single test, throwing code all over the place, Never saw a Codeigniter/Laravel application with test to be honest... 
Fix configuration management first. That may, in fact, be impossible - it will likely take a lot of hours, your manager might get itchy about delivering features, and you might not be skilled enough to pull it off. Without a clear process to setup a new sandbox or staging deployment, the application will remain brittle.
Any questions, send them my way!
Suicide is always an option, or just do what your lead does, stack more shit on top of it and collect money until you find a better job.
&gt; Rebuilding from ground-up is not a bad choice, because a lot of features developer has built himself will be right out of the box, such as authentication scaffolding, social media login, payment (Spark), API and login throttling, etc. But you have all this working now? It may be a bit slow and not particularly efficient but why would you want to implement everything again. I was part of a company who did a rewrite. It took 12 months to reach feature parity. The opportunity cost of this was huge. There are so many issues with rewriting. Business rules are always complex and poorly documented and you have to implement them again. You then have to migrate users to the new system. All the time you have business pressure wanting you to deliver something new... &gt; It takes a lot of time to load the website because there is no caching layer and the application performs a lot of duplicate queries per request. It's a pain in the ass to maintain. How slow is it? CodeIgniter is pretty fast as far as PHP frameworks go. I assume you guys have NewRelic and slow query logging set up right? Both of these things will shine a light on bottlenecks in your system. I would start there, especially focusing on slow queries. You might be right. A rewrite might be a good idea but it doesn't sounds like you have exhausted other options yet and the cost of the business of the rewrite is huge. 
Neat library. I'm not sure I would use it but I do see some things that you could improve. `Resolver` is doing value resolution for object methods and properties, and for arrays. This should probably be delegated to a `ResolverInterface` and split up into the individual resolution types that can be injected. As it stands if I wanted to use nonstandard verb (s/get/fetch) or some other custom accessor methodology then extending your library is required.
Geez, what made you so cynical?
Yeah, he seems sharp enough that he wouldn't have a hard time finding a job where the developers write tests.
The README shows an example of how something is done with Drupal 8: $result = $node -&gt;get('field_media_image') -&gt;first() -&gt;get('entity') -&gt;getTarget() -&gt;getValue() -&gt;get('field_image') -&gt;entity -&gt;getFileUri() There must be some wacky coding principle at work to justify such a useless chain of methods. Does every function return have a custom class or something? Why do you use the "get('entity')" method in one place, and then use a property reference "-&gt;entity" in another place? I would assume there are two tables being used, a media entity table and an image table, with a many-to-many relationship so images can be reused by different media entities. The url you want is two steps away from the initial query, so with good encapsulation you should be able to get the url with only two additional methods after the query: $resultRaw = $node-&gt;get('field_media_image')-&gt;first(); // query to get the first thing, just a hash of raw data $resultFoo = new Foo($resultRaw); // some kind of Object Relational Model $results = $resultFoo-&gt;getFieldImageFileUrl(); This makes it clear that between the call to "first()" and the next method you are changing the type of object you are currently handling, which is hidden by method chaining. Isn't there some kind of coding practice that says to not change the object type in the middle of a method chain? Or that part of the new functional obsession that has swept the industry?
That's simply a coroutine. Go with its goroutines adds parallelism on top, but that doesn't make it simpler or "more" coroutine. I'm fully aware, because I'm one of the maintainers of [Amp](https://amphp.org/). We plan to eventually bring `await` into PHP so you don't need a wrapper around your generators that turns them into actual coroutines working by yielding promises.
I am a programmer
This book 'Modernizing Legacy Applications In PHP' helped me a lot in the past. Its a clear step by step guide. https://leanpub.com/mlaphp I miss working with PHP and I'd love to be modernising a legacy CI application
do you need speed? use [Phalcon](https://phalconphp.com/) low resource consumption and is loaded as an PHP extension, this is money in your pockets
Why would you need support for a proven set of php functions that is working for years?
Very wise advice. typically kind of advice I'm looking for. Thanks 
Fix configuration - easy Add cache layer - easy Add gulp/compass/whatever - easy Refactor small amounts of code - easy Add documentation - easy Redo the whole thing - you‚Äôll need ao much more time then you think. You‚Äôll break a lot of stuff. You‚Äôll miss functionality you didnt know was there. You‚Äôll miss deadlines. You‚Äôll end up with a mess again, but a different one and untested. Your lead developer seems a reasonable guy. Propose sane improvements rather than thinking you‚Äôre that much better than whoever built the current version. Rewrites are hell. 
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
You seem surprised that a 7 year old app is built using methods from 7 years ago. All problems are opportunities in disguise. Focus on finding the best opportunities to improve the situation, rather than avoiding it by throwing everything away. Or just get a new job working on a newer codebase.
I maintain quite a few legacy CodeIgniter applications in my current day job. What has worked for me is hacking in .env and composer support the beginning of the index.php boostrap of CodeIgniter 2. I then setup a PSR-4 namespace folder in the app and a phpUnit tests folder. Any time I've got to do some work on the legacy apps I pull out as much code as I touch into well tested classes and use [pimple di](https://pimple.symfony.com/) service providers to abstract away the CodeIgniter parts. Eventually you can move almost all of your logic into the PSR-4 namespace and have it covered by unit tests. You can even pull in Doctrine or Eloquent for your database access if your sneaky about it. Most of my stuff ends up using plain old PDO and query objects though.
Yes and no ... The approach is not quite the same ... Beside its basic usage (securing getting value from an object/array chain) Grabbag is mainly made to grab values and aggregate them into array or structured array. Property accessor allows more things in a way and less in an other.
Exactly what I'm doing to the word
Here is an easier way.. straight from the documentation: https://laravel.com/docs/5.5/notifications#sms-notifications
I know its not everyone's cup of tea, but I enjoy using invokeable classes in these sorts of single-responsibility or "action" classes. class BlockUserAction { public function __invoke(User $user) { ... } } $blockUser = new BlockUserAction($userRepository); call_user_func($blockUser, $user);
Slim is somewhat similar. It's a micro framework that just does routing &amp; session handling. It's not a full on framework like Laravel. 
Well put! This is an extremely important concept to understand for a business-oriented developer especially. So many times I hear junior devs trying to discuss business needs their own thought process very obviously stuck in CRUD-land. I think it helps a lot to use verbage from the Business in your Domain (the Ubiquitous Language), as it personally helps me keep my mind focused on the business's needs rather than the implementation details. For example, an Employee is not *Deleted*, they *Retire* or perhaps they are *Terminated*. 
The Drupal example was just an example. Arguing about Drupal 8 API consistency is not really my point (even if much should be said about it :) ), &gt; so images can be reused by different media entities. Thats it. there is 3 levels of entities here the (node, media, file). among other features, media entities allows images (or other kind of media) to be reused. &gt; Why do you use the "get('entity')" method in one place, and then use a property reference "-&gt;entity" in another place ? Your right -&gt;get('entity') and -&gt;entity are equivalent one is a getter the other get the property using a magic method __get(). I should (or would) have to use the same form in both places.
In top 3. Nice job! Excited to see your new articles.
How does this help OP with their problem?
OMG ML-style patternmatch, please please please. ES6 style destructuring assignmet, please please please.
You're acting like the OP was just whining andcomplaining, but it reads to me like they are just looking for some suggestions on how to get started and they gave us as much information as possible to help us.
Thank you for your opinion (which is only your point of view). I can understand your may not to be keen on the approach. Such approach has necessarily its pros and cons. I would just point that this library is is tested using PHPunit tests (84 tests, 301 assertions for now to be exact) all passing and executed on every commit (thanks to Travis). Beside the tests code coverage is about 91% as you can see on the project page (https://github.com/slavielle/grabbag). I'm working on increasing it.
Node is just a runtime, you don't have to run Javascript. I'd argue ES6 and php7 are in same league, but things like TypeScript, Reason, clojurescript are ergonomically better. Javascript isn't my first choice, but if i had to async i'd do it Javascript over PHP.
So, just doing a quick overview of your code on github, I'm seeing a few issues: 1. No unit tests 2. Using a custom autoloader instead of PSR-4 3. Your composer.json doesn't list the PHP version or the required extension in it's require section Those things are likely to make developers question how much care has gone into the code, especially since there are no unit tests. I'd suggest adding those things, and if possible provide some alternative to PECL as it's rarely used nowadays.
1. There is test script, especially created to test concurrency - look at end of readme 2. Classloader is optional, it is PSR-4 compatible 3. I might update composer.json in the future. Generally it's meant to be used on very busy websites, probably about 1-2% of PHP developers would need this library. Where do you have information from that PECL libraries are "rarely" used? PECL SYNC library is great for process/threads synchronization, but again: only few % of PHP developers would ever need it. Whole thing is meant for VSP/Dedicated server users not for simple CMS/Wordpress websites hosted on shared webserver. 
I did understand the Drupal code was just an example, I was just surprised that something so ugly would be used as an example of code that is written by Drupal developers. Well, I only wish I was surprised. Now that I think about it, what code would be using such a chain in the first place? You start with a node, so this is either a Controller that is manipulating models, or something in a Model class that isn't quite Drupal itself. And the result is a specific field, a url for an image, which is something that only has meaning to the View. That suggests this is Controller code being used to generate a View, because the only layer that should be interested in the details of the *first* media entity is something in the View. All this suggests there is no real encapsulation going on here.
What's wrong with that?
The problem you are referring to is called [Cache stampede](https://en.wikipedia.org/wiki/Cache_stampede). And there already exist a couple of decent caching libraries with cache stampede protection like [Stash](https://github.com/tedious/Stash) and [Scrapbook](https://github.com/matthiasmullie/scrapbook).
**Cache stampede** A cache stampede is a type of cascading failure that can occur when massively parallel computing systems with caching mechanisms come under very high load. This behaviour is sometimes also called dog-piling. To understand how cache stampedes occur, consider a web server that uses memcached to cache rendered pages for some period of time, to ease system load. Under particularly high load to a single URL, the system remains responsive as long as the resource remains cached, with requests being handled by accessing the cached copy. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/PHP/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
But - do they provide way to do ALL what need to be done in ONE FUNCTION CALL?
So you're using mysql or db backed cache table to handle concurrency? I feel like redis is a better option all around. It's better than memcache, faster, and much more robust. Using setnx would work though I can't say for sure. At least I solved this issue for myself using redis setnx. And it keeps cache out of your db which should be used for your last level of persistent storage.. not cache data really. 
NO I don't use mysql to control concurrency, mysql is one of optional storage methods. Concurrency is handled by PHP Pecl Sync library and SyncReaderWriter class. http://php.net/manual/en/class.syncreaderwriter.php
My advice is to start by refactoring in place. Start implementing some functional tests, even if they're a bit brittle, and target the areas with the worst code. Then once the tests are in place, begin refactoring, using the tests to make it hurt as little as possible. While you refactor, look at separating your domain code from your framework code. It'll take some time and energy to properly separate it, but it'll be worthwhile and you'll be able to start unit testing your business logic. Repeat that process long enough and you'll have an application that can feasibly be moved from CI to Symfony or Laravel.
Unless you have major plans, that are impossible to accommodate by extending the current codebase, then don't do do a complete rebuild! It almost never turns out well ... Like you suggested, refactoring and moving code into service classes/models with well defined tests will start to make you feel better about your codebase. And well tested solid code would be much easier to move to a new framework in the future. You could also consider if there might be various modules of the system that can be isolated into a seperate microservice. I only mention this because when going the route of building microservices, you typically carve out unique domains within your application, and start refactoring it into a microservice... A microservice can be built in whatever language/framework that bests suits the job. It is autonomous and has it's own database (if required). It can be communicated with via an API over HTTP, and/or a messaging system. The upside is that it scales much better, it can have its own set of code and dependencies and it can be tweaked to perform for the task at hand. Don't get me wrong though, Microservices also come with their own set of unique problems (eg. additional networking complexity, the separation of domain), and should only be considered if there is an identifiable gain. 
It doesn't. At all. "Hey, my Jeep is running like shit and leaking oil. Can anybody give me some pointers on how to repair it?" "LOL YA, BUY A BUGATTI"
Oh my god. I‚Äôve been doing a Perl to PHP migration for the last four years! Probably this won‚Äôt be useful at all for our use case, but just for the laughs, this will be tested against my code set today. I‚Äôm honestly impressed it works even a little.
The last router I've played with was Alto (http://altorouter.com/) - I know there is a fork of it that is more updated.
Thanks for finding Grabbag is &gt;an interesting project and a nice exploration of a certain problem Grabbag is not meant to be used anywhere, anyhow, anytime but I think there is parts of project or kind of project where it can be used and suit nicely. Using string expressions to refer to objects reduces of course navigability inside code in IDEs, but there is some benefits using the library too. It's a matter of balance ... beside, other famous libraries/framework use string expressions to access object/arrays breaking the navigability inside project code. Let's take Twig for instance : Twig expressions allow to access variables exposed to twig template. such variables can contain objects. Twig use a specific syntax to access those objects properties/methods chains, and it's kind of breaking the code navigability too. Some PHP framework use class name stored in json or yaml files and it's also breaking code navigability. Not speaking about annotations in PHP comments that are as useful as a completely rogue and arguable PHP comment usage :) Of course, IDE get updated to handle popular libraries/ frameworks "eccentricity" nicely. But the fact an IDE does not support a given library expressions (yet) is not a reason to not give the library a try ... you see ;)
If you take a look at the test cases, you can see that it does some more complicated conversions that you might expect, things like rearranging if statements: $a = $b if $c == $d; to if ($c == $d) { $a = $b; } Or changing =~ to preg_replace, stuff like that. It's the sort of thing where if you have a lot of code, it's worth investing the time to do handle your specific wacky cases. It's a reasonably good foundation.
Oh no, I‚Äôm sure it‚Äôs a perfectly capable project, which is why I‚Äôm curious to try it out. It‚Äôs because most of our Perl code was written by amateurs and contains no real organization or quality, so a one-to-one rewrite would not be a good move for us to implement.
A belated reply, but yes, we use Disque in production. We wrote and use our own library, Disqontrol, for it https://github.com/disqontrol/disqontrol It's worked very well so far. Feel free to take a look at it and criticize/suggest changes.
Ah ok.. that looks good.. but how does this work across multiple application servers?
It's easy to forget, but you're there to do what your employer asks you to do. If your employer is not asking you to re-write/refactor the application then you're fighting a losing battle and your energy would probably be better spent on something else...
Work burnout, I guess
Tldr: misleading and wrong
You mean situation when you use Load Balancer and multiple instances of Application? In that case it generally depends on storage configuration. You can have one central host (for example memcached server) for cache that is used by multiple instances of the Application, or you can have cache per-application (f. ex. separate memcached server on each machine), or something mixed. Really just look at source code - it's minimal. 
Yeah, definitely it's not intended to take Perl code and magically drop in reorganized PHP code. :) For my own case, I would typically convert a module and copy/paste various chunks of the converted code into the new reorganized structure. For example, I might have (say) 20 Perl modules that are structured the same way, each with custom code. I'd get one of them converted and reorganized, then use that one as a template for the other 19. Then I'd convert each one, copying the translated code into the template. It worked out pretty well.
That's the thing.. redis works just fine across multiple web servers. I only run 4 servers behind a load balancer at the moment, but setnx works just fine for load im dealing with to handle cache between them. I think your solution is overly complex and still only works for a single server. 
The lead developer is totally right being skeptic about a rebuilt. I work quite a lot with legacy code, and even though it sounds exciting and clean, a rebuild has a very small chance of being successful. I totally agree with other comments here: refactor by small bites. Watch Larry Garfield's talk "Eating Elephants". It will give you some great ideas. Also, Pmjones's book as others mentioned. 
So you have one redis server and 4 Apllication instances that uses it, or 4 redis servers - one on each machine?
I actually have 5 redis servers. 1 redis server per application server for strictly volatile information. 1 main redis server for persistent and shared cache for each application server. 
You would actually benefit from using this library, and maybe it would let you reduce number of servers needed. Typical it looks like that 1. Resource exist in the cache (redis?) 2. Yes - return it 3. No - create it, put into redis (with some timeout), return it problem is, when you have high load, the third step often will be executed in parallel way by more than one HTTP request at once. It creates performance down spike and it's magnified by number of concurrent threads/ HTTP Requests and time that must be taken to create resource before putting it into cache/redis. With my library you ding it like that. 1. Define job inside callback function 2. Execute **get** method on cache object Cache manager in step 2 will acquire READ LOCK and look if resource exists and it's not expired. If it exists READ LOCK is dropped and resource returned. There can be many READ LOCKS at one. If resource not exists exclusive WRITE LOCK is acquired, resource is created, put into cache, WRITE LOCK is dropped and resource returned. This is great - because any other HTTP Requests will wait for WRITE LOCK and then read newly created resource instead of creating it in parallel.
https://redis.io/topics/distlock
but is it fastly?!?!?!
&gt; Do you guys always use active records, even for advanced queries? Should I break this habit? Generally yes. Although I use a custom ORM that is technically a data mapper implementation but has logic on the model that allows it to invoke a repository to save itself. Below are examples of how I do things for sharing's sake, it may or may not be useful info to you. For extra advanced queries, I just query the database then pass the data to the Factory that gives me back models. ``` // Grab data $stmt = $pdo-&gt;prepare("SELECT * FROM users WHERE name LIKE ?"); $data = $stmt-&gt;fetchAll(['%Bob%']); // Create model factory and pass in data $factory = new ModelFactory(\Models\User::class); $users = $factory-&gt;makeGroup($data); ``` Of course, even in this example I wouldn't bother doing that for a query this simple. I'd just pass a partially filled out query object and let the repo fill out the rest of the query automatically: ``` $repo = RepositoryFactory::make(\Models\User::class); $query = $users-&gt;getDb(); $query-&gt;where('name', '%Bob%', 'LIKE'); $users = $repo-&gt;findAll($query); ``` For related data, it will be fetched automatically if the relationship is defined. Saves are recursive so I can save the parent object (such as User) and all related models which are loaded will be saved too. ``` // Grab user with ID #7 $user = $userRepo-&gt;find(7); // Address is a different model related to User. It's dynamically fetched when asked for. echo $user-&gt;address-&gt;street; // outputs "123 Fake st" // To save a change to the Address model, you can call save on the parent User model. $user-&gt;address-&gt;street = "321 Real St"; $userRepo-&gt;save($user); // $user-&gt;save() also works but will invoke a repo. Persistence logic not stored on model. ``` To fetch additional info about a model not stored on the same table I will either dynamically fetch by defining a JOIN. The extra data (which is not part of the model) will be added to the model and can be read, but changes won't be persisted if the data is changed: ``` $repo = RepositoryFactory::make(\Models\User::class); $query = $users-&gt;getDb(); $query-&gt;select(['users.*', 'addresses.street']) -&gt;join('addresses', [['users.id', '=', 'addresses.owner']]) -&gt;where('users.id', 7); $user = $repo-&gt;findOnel($query); echo $user-&gt;street; // outputs "123 Example St" ``` If I have data I want stored in a different table, but I want a model that will do the join for me automatically for convenience (and to reduce extra queries that ORMs are famous for) then I can define a partial query constraint which will always get added: ``` class User extends Model { public $model_attributes = [ 'id' =&gt; [ 'type' =&gt; 'int', 'primaryKey' =&gt; true ], 'name' =&gt; [ 'type' =&gt; 'varchar' ], 'address' =&gt; [ 'model' =&gt; 'Address' ] ]; public function __construct($name = null) { $this-&gt;name = $name; } public static function model_constraints($query) { $query-&gt;select(['users.*', 'addresses.street']) -&gt;join('addresses', [['users.id', '=', 'addresses.owner']]) return $query; } } 
Yes, ok, thats cool feature. But - still any PHP job you are doing (like querying DB or Redis), you are NOT doing INSIDE redis, but INSIDE PHP in parallel way creating unnecessary load. Then you are putting the same resource several times into redis. 
Whats going on with indians posting this kind of stuff
I don't know whether to salute you or run away screaming. Our legacy Perl code is absolutely terrifying.
My approach would be to develop everything from the ground up in parallel. Write some migration tools and unit tests, so when the new version is ready, it should be easy to migrate. 
Don't go Symfony. It is actually worse than CI 2 despite not supporting PHP 5.3+ features.
r/me_irl
Devs at larger corporations tend to use Macs. Freelancers and agencies are more likely to use a Windows machine. 
This book is absolutely amazing as a reference. That being said, if you‚Äôre working with a large and complicated application, you‚Äôre going to want to do some things differently to how the book describes. For example, the book suggests Table Data Gateways where I‚Äôd use Data Mappers in such a large application. The book suggests using Transaction Scripts in the domain layer where a proper Domain Model will almost certainly save you tearing your hair out in the long run. It does discuss these patterns as alternatives, but the examples will follow the decisions of the author. Absolutely get the book; but follow the process it describes rather than the exact implementation. At each step, do some research and make your own informed decisions about which design pattern you want to implement. If you are unfamiliar with design patterns I would *suggest* Patterns of Enterprise Application Architecture by Martin Fowler. It‚Äôs probably the most valuable ebook I‚Äôve ever owned in terms of how often I refer to it.
That is the opposite of my experience. Freelancers and agencies have the freedom to choose and will often choose Macs. Corporations are almost always windows. I've experienced it many times. Unless you are talking about tech companies.
This is the best shit ever. I've been trying to convert a perl script for checking gift card balances to PHP for 6 mos. thank you tytyty
Agree totally with this comment, but I'll add that when dealing with an untested legacy codebase I like starting with some End to end or acceptance tests as well. I know unit tests are ideal but until you get in there and start refactoring that can be impossible. I have also had success breaking pieces out one at a time in this kind of legacy app, but that's more up to you and where your strengths are. Microservices aren't for everyone.
I've done this. It took about a year. First step get composer set up. Get autoloading working for the rest using "classmap". You'll probably have to resolve class name conflicts. Renaming them for the time being is pretty easy. Start paring down parts from CI that you don't use. Delete it from the framework altogether. It's usually not to hard to get down to only using CI controllers, models and the router. Bring in components from your new framework early and start using them. E.g. a different database abstraction layer. Start migrating places the CI version is used to the new one. Then replace the router. That's kind of a one-shot deal since usually you only have one router in the application but you might be able to use both simultaneously, dispatch unmatched routes to CI for it's " magic" routing stuff. Introduce request/response logic. CI has none. Whatever your new framework has for configuration, use that, but you'll probably need a global instance and some global helper functions to replace stuff like config_item / $this-&gt;config. Basically mold another framework to work like CI so replacing the CI dependency is easier. Once that's done you can follow the best practice for that framework like injecting a config object for example instead of a global accessor. You'll have to become initimately familiar with Codeigniter's code to do this. Luckily it is a small framework and not too complex. Fully understanding how it works will help you restructure the application. You'll need to edit the Codeigniter framework code itself to make some things work. No worries, you were never going to update it anyway. I'd hold off on refactoring any crappy code as much as possible until the framework migration is done. Also consider using a microframework like Silex or Lumen to start, and later port to Symfony or Laravel. Since a big part of transitioning is getting your codebase more framework-independent, it might be better to just stick with only a microframework and independent packages from composer than try to rewrite a legacy application for an opinionated framework.
I have browse through amp framework. It's an awesome semi-coroutine framework. I have some suggestions: Firstly, in amp we are running app in a php-cli, only one core is available. We hope to use all cpu-core in a http/websockets/tcp application. We even hope to have tcp pool shared by all worker process. Second, you know php's web frameworks is so mature that only run in php-fpm and can't run in php-cli. we hope we can easily run yii2/symfony/balabala in it. 3rd, mysql/redis client write in raw php may have performance problem. And if I need to use amp's socket to make a client for anything(such as memcache) and keep tcp connection pool. It's still difficult for many php developers. 
Thanks Mantas. :)
Why bother using a class at all if it's one class and all public static functions?
I'm no PHP expert by any means, do you suggest not using public static functions in the case of using it the way it is now? If possible, could you provide a shorter example/explanation of how this could be done better?
because global functions/variables are rarely, if ever a good idea. Keeping them in one class ensures its all logically encapsulated in the same place.
Would it be smarter to have those functions be private instead of public or is there a better solution I'm not seeing?
Any plans to go the opposite direction?
Hi guys, I have been scouring the internet for about the past two hours trying to find a solution for how to count the number of columns in a MySQL server and echo the information. I realize that using the query, SELECT count(*) FROM information_schema.columns WHERE table_name = '$room', will work however I do not know how to echo this information. No matter how many columns I have in a table I get a result of 1. If anyone knows a fix that is PROCEDURAL, not Object-Oriented (I think it is called), it would be greatly appreciated! I would like procedural because the rest of my code that I got from a tutorial is procedural and I am just learning how to program PHP. Thanks!
Share the code you have so we can find the issue.
Don't refactor. Instead use Symfony components and replace each part by part. You can also start on some black box testing scripts by using some qa engineering tools such as selenium for regression. The idea is to build a solid integration / front end test and make sure you don't break those. 
First of all I am not Indian. I am Nepali. Why would that matter anyways?
Why did you decide to specifically make everything static? Was there a reason behind it?
At least someone gets it. ;)
Sure thing: When you start using classes in programming, 9 times out of 10 you're attempting to use an Object Oriented approach. I'm going to assume you at least understand the basics of object oriented programming, in that you have a grasp on [Encapsulation](https://en.wikipedia.org/wiki/Encapsulation_\(computer_programming\)), [Inheritance](https://en.wikipedia.org/wiki/Inheritance_\(object-oriented_programming\)), and the fundamental differences between an object *instance* and a *class*. It's mainly this latter point that I want to touch on, because when an entire application is made up of one single class that doesn't require any semblance of state and simply executes its internal static members in a specific order, we're not actually dealing with Object Oriented Programming. It's simply Procedural Programming. Is there anything inherently *wrong* with this? Not particularly, but it kind of defeats the purpose of having a class in the first place. Ultimately, this all boils down to what you want to focus on: You seem to stress the fact that this application is tiny and is only made up of 611 lines of source code. If this is something that's important to you, then you can likely switch to a true Procedural style of code, eliminate the class altogether, and simply run all of your functions in order in global scope. You can probably even reduce the number of lines of code by doing this. You'll be left with a super small Github Repo, but the code probably wouldn't be maintainable to many people outside of yourself. But what you need to bear in mind is that less lines / files does not mean greater efficiency or speed. Code should always be self-documenting to the point where just by looking at the directory structure, anybody would be able to know and understand which piece is responsible for what part just by looking at the naming conventions. Let's say that in a hypothetical scenario you continue to flesh this out over the next few years, and your codebase grows from 611 lines of code to 65,000 lines. Then, somewhere down the line the backup mechanism breaks. Where should a contributer think to look? Should it really be the index.php file - the application entry point normally used for initialization and bootstrapping? Or perhaps a `src/Backup/ZipBackup.php` file? So while I'm not going to stress the virtues or pitfalls of Object Oriented Programming vs Procedural Programming, your style of code leads me to believe that you're at least attempting to follow some kind of object oriented paradigm. In this regard, you should consider refactoring your code to better support and leverage objects, encapsulate your utility methods into private members, and expose only the public members that you actually need to be public. To give you an example using my earlier-mentioned hypothetical scenario, let's say that you will eventually allow web administrators to choose which Database systems they would like to leverage. They might be able to choose between your JSON files as a default, vs a traditional RDBMS (MySQL), vs maybe something like MongoDB. How would you offer potential admins this choice in your current system? You *could* set up another switch-case, and run the right function depending on what they pass into your init call: public static function init($adapter = 'json') { .... switch($adapter){ case 'mysql' : wCMS::_createMySQLDatabase(); break; case 'mongodb' : wCMS::_createMongoDBDatabase(); break; case 'json' : default: wCMS::_createDatabase(); break; } .... } wCMS::init('mysql'); Or you can allow an administrator to pass in their own database instance that fulfills a contract of your choosing: public static function init(DBInterface $adapter) { .... $adapter-&gt;connect(); $adapter-&gt;create(); .... } wCMS::init(new MySQLDB('localhost', 'dbuser', 'secret', 'database')); interface DBInterface{ public function connect(); public function create(); } final class MySQLDB implements DBInterface{ private $host; private $user; private $pass; private $db; public function __construct($host, $user, $pass, $db){ .... } } So while there may be more code at first glance, this actually ends up creating a much more solid foundation that will allow you to write a much more flexible application that can adapt to a wider range of scenarios. But ultimately, if this approach doesn't align with the goals of your application, then that's up to you.
**Encapsulation (computer programming)** In programming languages, encapsulation is used to refer to one of two related but distinct notions, and sometimes to the combination thereof: A language mechanism for restricting direct access to some of the object's components. A language construct that facilitates the bundling of data with the methods (or other functions) operating on that data. Some programming language researchers and academics use the first meaning alone or in combination with the second as a distinguishing feature of object-oriented programming, while some programming languages which provide lexical closures view encapsulation as a feature of the language orthogonal to object orientation. The second definition is motivated by the fact that in many of the OOP languages hiding of components is not automatic or can be overridden; thus, information hiding is defined as a separate notion by those who prefer the second definition. *** **Inheritance (object-oriented programming)** In object-oriented programming, inheritance is when an object or class is based on another object (prototypal inheritance) or class (class-based inheritance), using the same implementation. Inheritance in most class-based object oriented languages is a mechanism in which one object acquires all the properties and behaviors of parent object. The idea behind inheritance is that you can create new classes that are built upon existing classes. or specifying a new implementation to maintain the same behavior (realizing an interface). *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/PHP/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Use PSR2: https://github.com/php-fig/fig-standards/blob/master/accepted/PSR-2-coding-style-guide.md Doc blocks to describe what the functions do. Split functionality into separate classes. You have database stuff mixed with view stuff mixed with...other stuff. Maybe look at what MVC is and try to structure your code that way. It also looks like you have a rather large security hole in _installThemePlugin(): $installLocation = $_POST['installLocation']; $extractPath = __DIR__ . '/' . $installLocation . '/'; $zip-&gt;extractTo($extractPath); Can extract files to any directory I want, possibly a competitor site hosted on the same server. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [php-fig/fig-standards/.../**PSR-2-coding-style-guide.md** (master ‚Üí 23f8ca8)](https://github.com/php-fig/fig-standards/blob/23f8ca86fe0b1468813de50f2009780a8142ac29/accepted/PSR-2-coding-style-guide.md) ---- ^(Shoot me a PM if you think I'm doing something wrong.)
That's what namespaces are for. Not classes.
I'm a huge fan of micro frameworks. Looking at your CMS demo, yeah it looks pretty good. Great work! In the code, I have quite a few suggestions though. - Routing: In .htaccess, it's routing requests to `?page=$1` pattern. You don't actually have to! You can take the the requested URI from `$_SERVER['REQUEST_URI']`. Writing rewrite rules for other web servers will be much faster. You can also use Apache's `mod_dir` config `FallbackResource /index.php` instead of rewrite rules (fewer rewrite rules, the better). - It doesn't look like there are any unit or functional tests. Speaking of tests, that is one reason others have suggested to not use static variables. It makes running tests in parallel impossible, and it's not fun to write tests either. Your test files can stay out of the releases (you can `export-ignore` from your `.gitignore` file that's committed to github repo). Your users will still get the small version, but you'll have several tests. - I don't think the number of files will matter in todays opcache-by-default PHP environments. I would rather split the core into smaller chunks. This will hurt the CMS's main selling point though. - CSRF token validations are vulnerable to timing attacks ([example](https://github.com/robiso/wondercms/blob/master/index.php#L328)). &gt;=PHP 5.6 has [hash_equals\(\)](http://php.net/manual/en/function.hash-equals.php) and there are polyfills available too. - I would prefer if the CMS core was in a separte file, and the index.php file only included that file. Perhaps inside a folder, and preferably properly namespaced. - It shows age with its methods prefixed with underscores, lack of phpdoc, etc. That said, what you have from a single-file CMS is quite impressive. Al the best!
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [robiso/wondercms/.../**index.php#L328** (master ‚Üí d4741ba)](https://github.com/robiso/wondercms/blob/d4741ba620d31af7bd5d7cc3381846836e1d82c8/index.php#L328) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dpk7p34.)^.
ethanol is the "drinkable" type of alcohol...
&gt; It shows age with its methods prefixed with underscores, lack of phpdoc, etc. phpdoc is not needed in the age of type hints. Underscores have nothing to do with age, he's just following some retarded convention.
`count(mysql_fetch_assoc(mysqli_query("SELECT * FROM from $room LIMIT 1")))` Make sure $room can not be used for SQL injection. To answer your actual question, post the code, so we can find the bug. My guess: The `1` is actually `true`.
The underscore pattern is from PHP 4 era that there were no visibility controls. Underscores conveyed that the method is considered private. Most of the legacy code do not have any phpdoc because it was not standardized [back then](https://github.com/php-fig/fig-standards/commit/796b9d9cd62ae7a7319b57c9331f3c351b50e98d#diff-9a10a11696dc38209c125ea9c57a565f).
Please do not make a discussion from this, simply direct the OP to /r/phphelp
This sub gets hit often with Indian blog spam, so people often just assume. Not defending it, just letting you know :)
you seem to have very little experience with PHP, so better avoid posting any code of your own. 
It's rarely use (I guess because namespaces are usually only used in OOP projects), but you can declare your functions inside a namespace without putting them into a class.
Running an application on multiple cores often isn't really necessary. At least not in a way that one process has to use multiple cores. Our HTTP/WebSocket server Aerys just runs as many workers as you have CPU cores by default, all binding to the same ports using `SO_REUSEPORT`. Where `SO_REUSEPORT` isn't available for kernel based load balancing, we use a socket transfer to share one accept socket for all workers. You can run Amp just fine on all other SAPIs, the only library you'll have problems with is currently `amphp/parallel`, because that currently requires `PHP_BINARY` to launch its sub-processes. Indeed, parsing can be a bottleneck. I think the protocol is easy enough for Redis so it doesn't actually matter, but it's currently the major bottleneck for the MySQL client. But it's something that could easily be replaced by a C implementation that could be used if available, otherwise it'll fallback to the raw PHP implementation. We just need a C implementation that exposes just the parser instead of a whole client without any access to the parser. I haven't tried Swoole yet, but I saw that there's English documentation available now. It seems to be rather callback based, does it have a promise implementation? Depending on the use case you can just convert a library to an async library by using `amphp/parallel` to keep all blocking tasks outside the main event loop. It at least saves the protocol re-implementations, but it's of course not optimal and a real non-blocking library is preferred.
I've taken this approach for a not very large project (40 thousand lines of code). It took me 1 year and this approach has a significant disadvantage: at some stage you will show it to the managers so they provide you with more resources (more people/more time). When they see future in your version, they begin requiring new features like crazy, so it's likely that the migration will be a painful process as new features desync the old app and the new one. I ended up having to write an application in order to transfer "application state" from the old app to the new one. If you can't make a full rewrite in 6 months - don't bother, or you'll end up supporting two applications.
phpdoc are still useful when you need to reveal contents of array/collections.
Oh ok. Thanks for the heads up.
God no :)
Some people just want to see the world burn...
It's not even in english, so why you post it here?
if you do `SELECT count(*) FROM information_schema.columns WHERE table_name = '$room'` you should be able to echo out the first array section which contains the count result.
It's an interesting concept. However, I wouldn't personally like to have it heartily go down the chain. What are the performance impacts on this? And why should someone use it over other Depency injectors?
Don't rewrite everything using Laravel/Symfony. Upgrade to CI3 I suggest you to: 1) Upgrade from Codeiginiter 2 to Codeigniter 3 - https://www.codeigniter.com/userguide3/installation/upgrade_300.html 2) Make sure you use PHP 7 with OP Cache enabled and nginx 3) Autoload modules - https://www.codeigniter.com/user_guide/general/autoloader.html 4) Create unit tests - https://www.codeigniter.com/user_guide/libraries/unit_testing.html?highlight=test 5) Implement caching - https://www.codeigniter.com/user_guide/libraries/caching.html?highlight=cache 6) Start thinking about writing new parts(new functionalities) of the application in Symfony/Laravel. Implement a microservice architecture - http://microservices.io/patterns/microservices.html 
[Static class attributes/methods](https://github.com/robiso/wondercms/blob/2.3.2/index.php#L8-L13) are "global functions/variables". Why do I even answer.
I've been doing PHP for a long time, but I'd still call myself a beginner, I would never attempt to try and write something that would be released and everything I've done is either internal, or homelab, or just out of pure boredom. I see you guys saying to slice up the code into different files/classes/etc, but I've always wondered how you manage this when you're working with databases and that kind of junk that need to come from the parent. I have attempted to look this up, but examples I've seen kind of confuse me because there's so much else going on. A simple example of this would be something like: require('otherclass.php'); class MyClass1 { private $db; private $oc; function __construct() { $this-&gt;db = new PDO(..); $this-&gt;oc = new OtherClass($db); } public function get_other() { return $this-&gt;oc-&gt;pull_breadcrumb(); } } class OtherClass() { private $db; function __construct($db) { $this-&gt;db = $db; } public function pull_breadcrumb() { $q = $db-&gt;prepare('select ...'); $q-&gt;execute(); return $q-&gt;fetch(); } } I'm sure a lot of things are wrong with this, but the thing I'm concerned about is passing the $db variable between classes like this, is that the best way to do it? Is there a better way to reference the parent $db instead of creating the instance of the child with it as an argument or pushing to it after? Or am I missing the point and when you need to push/pull from a shared resource like the database, you do it all from the core and you just call on the child classes to gather the information before you push it in? The main way I've run into this is if I've developed a few different scripts over a period of time and realised that they can all work together, so I've created one site which houses all of these different little scripts which all do their own thing, have their own database connections and whatever, so instead of creating ten classes for the ten different tools, I just merge them into the main class so I can access them all better. Thanks heaps if you can shed light on why my brain is broken!
maiorano84, *I can't thank you enough for taking the time for writing your post. *Let me just clarify I am not stating it is faster or "better" because of it's size/number of lines* - I just though of it as a compact learning curve and having a website solved with. The CMS itself is fast, but it's not due to the number of lines. &gt; Let's say that in a hypothetical scenario you continue to flesh this out over the next few years, and your codebase grows from 611 lines of code to 65,000 lines. Then, somewhere down the line the backup mechanism breaks. This is scary because it's true. I very much agree it would be a mayor pain doing this. &gt;So while I'm not going to stress the virtues or pitfalls of Object Oriented Programming vs Procedural Programming, your style of code leads me to believe that you're at least attempting to follow some kind of object oriented paradigm. To be clear, since the beginning of it's development, it was basically Procedural Programming, a contributor revamped the CMS to OOP in early 2017. I'm not even pretending I understand everything but from my perspective it seemed cleaner (although it added twice the code we are using now). (You were completely correct on how this used less code, but as you mentioned, it was less maintainable. I definitely think this is a step into the right direction, I really appreciate your contribution. Mind sharing your name/site, so I can kindly add you to wondercms.com/special-contributors ?
I can't highlight enough what a ballache this library would be without auto completion. Additionally, I find this part unsettling. &gt; Both approach comparision &gt;The Raw PHP approach is not implicitly secure : Some of the methods/properties along the expression can return or be NULL in some case and then cause an exception. If you really want to secure expression, you would have to test some of the values before accessing them. That's a really boring point developer often have to deal with : it's repetitive, unappealing, can induce bugs and makes code less readable. Grabbag approach is implicitly secure. If it's not possible to walk along the objects/arrays chain, result will be NULL by default or set to a default-value to be specified. Exceptions are a *good* thing. They allow you to handle specific errors. If you're returning null on everything that didn't work, how do we know what didn't work?
Thank you, living is learning.
I know exactly what you mean. I've taken this approach three times already. The first time I did, all this happened. But after that, I started with a team bigger than the one developing the old application (yes, we had budget for this) and in another site! We tried to keep new features as few as possible. One part of the team was assigned to create the migrations tools too, so we gained some time. At the end, we managed to follow a carefully made schedule, which had a few non critical changes from the beginning. It's hard; it does need experience and it also need a fat budget, but in my experience, worked like a charm. 
That would also require what I'd consider a security flaw in the server setup as well.
Thanks for the link. MVC was a way in the past, but when developing this is came across as unecssarry for such a tiny project, but it might be the way to go in the future. The databse is split into 2 parts (config and content). Wouldn't you already have to be logged in at the competitors "WonderCMS" site, otherwise I can't see how this could be exploited with the additional conditions that are present. I've tried to exploit this myself, unfortunately (or not), it wasn't successful. Would you mind giving it a go? We award contributors like this with a donation.
Thanks for the clarification.
You bother because it matters! Thanks for spreading knowledge, appreciated.
&gt; Maybe look at what MVC is and try to structure your code that way I think you've kind of missed the point of what the OP was trying to achieve. if he wanted MVC he would go with an MVC framework or make something identical. There is some fun in just having a single file do everything. The god class :D
Is there anything stopping a backpath? ../xxx/ or ../competitor/
It is also useful for a lot of IDE, PHP storm will read type hints but you cannot provide informaiton, eg: /** * @param array $data - A list of entries to show */ public function example(array $data); Storm's inline params will list "array $data" but its documentation can also show the help text.
Thank you ayeshrajans! &gt; You can also use Apache's mod_dir config FallbackResource /index.php instead of rewrite rules (fewer rewrite rules, the better). What would be the alternatives to this on IIS and NGINX? I'll have to read on the CSRF token timing attacks, didn't know there was such a thing. Could you please clarify why you chose the line for the showcase of the timing attack, how could this be exploited in this specific cas? I'll be adding some of these things to the roadmap. If you want to give it a go in the future, we'd love to have you and reward you for contributing. Thanks for taking the time to write back! 
The conversion to OOP was not done by me, so I cannot state why the contributor chose this way - we went with further development on that version, this happened in early 2017.
*vekien* has been added to the god class: :)
Doesn't the __DIR__ return the active working directory? It's also limited to "installLocation" being "themes" or "plugins". if ($installLocation == 'themes' || $installLocation == 'plugins' &amp;&amp; ! empty($addonURL)) { Here's the whole theme/plugin function for a smaller review: public static function _installThemePlugin() { if ( ! wCMS::$loggedIn &amp;&amp; ! isset($_POST['installAddon'])) return; if ($_REQUEST['token'] == wCMS::_generateToken()) { $installLocation = $_POST['installLocation']; $addonURL = $_POST['addonURL']; if ($installLocation == 'themes' || $installLocation == 'plugins' &amp;&amp; ! empty($addonURL)) { $zipFile = __DIR__ . '/files/ZIPFromURL.zip'; $zipResource = fopen($zipFile, "w"); $ch = curl_init(); curl_setopt($ch, CURLOPT_URL, $addonURL); curl_setopt($ch, CURLOPT_FOLLOWLOCATION, true); curl_setopt($ch, CURLOPT_FILE, $zipResource); curl_exec($ch); curl_close($ch); $zip = new ZipArchive; $extractPath = __DIR__ . '/' . $installLocation . '/'; if ($zip-&gt;open($zipFile) != 'true' || (stripos($addonURL,'.zip') != true)) { wCMS::_recursiveDelete(__DIR__ . '/files/ZIPFromURL.zip'); wCMS::alert('danger', 'Error openning ZIP file.'); wCMS::redirect(); } $zip-&gt;extractTo($extractPath); $zip-&gt;close(); wCMS::_recursiveDelete(__DIR__ . '/files/ZIPFromURL.zip'); wCMS::alert('success', 'Installed successfully.'); wCMS::redirect(); } else { wCMS::alert('danger', 'Choose between theme or plugin and enter link to ZIP file.'); wCMS::redirect(); } } } 
Ah yeah, after looking at the whole snipping I am wondering where the poster assumed a security loophole, unless there is some ascii magic you can pull off there to "trick" it. Although not big deal, in your example "installLocation=THEMES" would fail :)
Thanks vakien, any specific reason behind why it would fail and how to prevent it? Please share you name/website so I can add you to our short list of contributors // wondercms.com/special-contributors if you don't mind!
&gt; Please note that /r/PHP is not a support subreddit. Please direct all support-related posts to /r/phphelp, or connect to ##php on Freenode IRC. 
It fails because of case, you're specifically looking for "themes" and "THEMES" is not "themes" hah, same for plugins. You could simply do strtolower($_POST['installLocation']) I would also add a trim for good measure trim(strtolower($_POST['installLocation'])) And change the if statement to "in_array" $installLocation = trim(strtolower($_POST['installLocation'])); $addonURL = $_POST['addonURL']; $validPaths = array("themes", "plugins"); if (in_array($installLocation, $validPaths) &amp;&amp; ! empty($addonURL)) { $zipFile = __DIR__ . '/files/ZIPFromURL.zip'; Also you don't seem to validate the addonurl? what if I put in a zip bomb?
Surely, it is useful sometimes. But most of the time i would rather prefer something like this, without any extra comments: /** * @param EntryInterface[] $entriesList */ public function showEntries(array $entriesList);
OMG nice catch - thank you for your contribution. Mind sending over your Name+website in a PM? While you're at it, please send over your PayPal address, don't expect much, it's just a token of gratitude. Plus there's someone we have to thank for this in our release notes at wondercms.com/whatsnew You are correct, we don't validate the addonURL - wouldn't that mean the admin is attacking himself in this case? On a side note of validation, we also don't validate the uploaded files (we're having a discussion about this over at our GitHub issues).
You already have received a lot of technical feedback that will allow you to improve but I have to say I really like it from a bit of a quasi code golf perspective (achieving functionality with a small code footprint). It does feel perfect for a lot of small business web pages, where even Wordpress might be an overkill.
You can put Vekien, I don't have a website as such :) Donation is fine, I like to help. It is true that the admin would be attacking himself however if he is on shared hosting then not so much. If I go to https://www.wondercms.com/ I can see A2 Hosting, maybe I assume a lot of people using WCMS have setup hosting here, so I created an account under their shared hosting and start "playing". Uploading zip bombs and what not, depending on how A2 is setup it could very easily affect all other clients on that server. You then have to debate is this your issue to solve (probably not) or the server administrators.
why are the models further away from the domain than repositories?
Thank you duplicate-uuid, I've be trying to maintain this project through the perfect balance of both worlds (and from contributions from others), but as you see it hard to satisfy all needs. I personally believe it would kind of lost its purpose when slicing it up, as it would make it similar to any other CMS available - but those CMSes are popular for a reason. WordPress was definitely starting to be an overkill for me, but I still use to for some of my customers websites. It's just a matter of when I use which project, I don't use one CMS exclusively. 
He has commented on an application that works well but is very slow and that wants to make a refabrication of it. Phalcon is an excellent choice in terms of performance. You do not always have to give all the solution, many times with showing the way is sufienciente.
You've been added to the /special-contributors page and additionally on our download page wondercms.com/latest (note that visiting this link will initiate the WonderCMS zip download after 3 seconds, you're listed a little lower on the page. To continue this discussion, I completely understand and agree with you on this point. In a similar thinking manner, what would prevent zip bombing via FTP or the file uploader from the A2 hosting panel? I still urge you to send me your PP link, this behavior should not go unrewarded, I really insist. :)
Why dont you use a shared central storage - like S3 or even your own file server? Then you only ever need to check one place, and it would seem more logical. 
Perhaps avoid php altogether ?; &lt;picture&gt; &lt;source srcset="server-1.jpg" type="image/jpeg"&gt; &lt;source srcset="server-2.jpg" type="image/jpeg"&gt; &lt;img src="known-placeholder.jpg"&gt; &lt;/picture&gt;
Thank you, I should have included this one detail. The server which will run this PHP is directly exposed whereas the 15 servers cannot be directly accessed. 
Hundred of Gigabytes of dynamic files being produces every few seconds. 
So? That still fits right in with a central file server solution? The alternative is you log the file metadata to a central place, rather than the file itself. i.e. you use a Redis cache or Database, and "log" the filenames and the corresponding server name to that central place. Your application looks up the central meta data table - then it knows instantly if the file exists and which server to get it from.
Weird... As you said, for those constantly dealing with clients (ie agencies and freelancers) it makes sense to stick with Windows to avoid compatibility issues and such. The larger corporations I've worked for though (500-5,000 people) more people tend to use Macs. 
It certainly looks like a nice idea, but could use a bit of tidying up (as per all other comments). * Definitely add unit tests (do this first before starting any refactoring) * I know the idea is for it to be lightweight, but have you thought of separating some components e.g. using Slim3 or FastRoute for your routing? (using composer)
`id="id"` now o just listed everything in the db. And that's not even malicious. Welcome to SQL injection.
You're using input from the user without doing any sanitation whatsoever. If the user passed "1; DROP TABLE table;" as the value of `id`, your table would be dropped. If you're using untrusted input in queries, use [prepared statements](http://php.net/manual/en/pdo.prepared-statements.php). This would also be better suited to /r/phphelp
You are correct, but this is still 100% better than a bunch of global functions. I am assuming the person who wrote it came from a much older version of PHP or something and just didn't know any better. The effort seems like it was there at least! ¬Ø\\\_(„ÉÑ)_/¬Ø
Use GuzzleHttp's async curl requests, so you can just make all of the http requests simultaneously then filter out the responses which have a 404
&gt; "SELECT * FROM posts WHERE posted_by_id = '$user_id' AND post_parent_id IS NOT NULL ORDER BY post_id DESC LIMIT 10" Looks like you're passing a variable directly into a query?
The only way to benefit from the speed that Phalcon provides would be to do a complete rewrite. His app is slow because of an architectural problem, not because CI is slow. Rewriting an app from scratch because it was poorly designed is never the answer.
obviously? Why would anyone think that you can't?
&gt;I proposed a huge refactor to lead developer, which would consist of removing duplicate code, commenting every method and eventually (probably) migrating to a Laravel or Symfony. I'm pretty proficient in Laravel so that's why I proposed migrating to Laravel. Anyway, he mentions that he wants to redo the whole system in laravel
&gt; What would be the alternatives to this on IIS and NGINX? For all non-Apache servers, rewrite rules would be the default way. `try_files` for nginx, likewise. Fallbackresource is particularly helpful in Apache, because benchmarks say `Fallbackresource` works faster than rewrite rules. &gt; Could you please clarify why you chose the line for the showcase of the timing attack, how could this be exploited in this specific case? I just searched for a reference and linked it. Anywhere that you validate a CSRF token with `==` or `===`, `strcmp` or `strcasecmp` is vulnerable. The attack works because string comparison is sequential and it early-out optimized. It will return the result (true or false) whenever it finds the first different bit. Because of that, an attacker can figure out in which position the strings are different. `foo == bar` will evaluate faster than `bar == baz`. Sure, it's hard to measure this small time differences in web pages, but we can't throw away the fact of such theoretical attacks if we plan to release the code into masses.
Thank you, that is exactly what I was looking for, and a quick google of GuzzleHTTP showed me this guide. http://blog.programster.org/php-async-curl-requests I've never included a package with PHP using composer so that could be fun too. Thanks so much!
That still doesn't help OP. Progressive refactoring the app is the only way to fix a situation like this because a rewrite will always take far longer than you can anticipate and will result in yet another un-maintainable code base.
I use IntelliJ and it works great. I work in a Java/PHP shop so IntelliJ was already being used for Java when we began moving some other technologies to PHP.
Just gotta say I did the same thing when wrote my own framework, and once I took it out of the class it made alot more sense. The things I kept in classes though were my database objects, authentication objects, and some other things that I would need multiple of. As I understand it, anything you only ever need one of does not need to go in a class. 
it will be plenty fast, it's not like OP is the only one to have this issue just imagine when your 15 file servers aren't enough anymore, then you need 50...then 100...
You said: "Thank you, I should have included this one detail. The server which will run this PHP is directly exposed whereas the 15 servers cannot be directly accessed. " Just create a cron which checks for the image source each 1/5/10... minutes. Cache the results and serve the image from the cache. This might help you: https://github.com/nielse63/php-image-cache (I'm not related to the repository)
Yeah, stick them all into a central DB table when they are created and use that to locate them. Or a json file. 
If you have the possibility, use json cause it's faster. Good luck!
I'm pretty sure companies like PayPal are probably legally obliged to keep transaction data stored for x amount of time. X amount of time will be enough to trace the fraudulous transactions back to you.
From unifying things, makes sense. Not exactly my favorite thing, but I get why (cleaner diffs, fewer errors, etc.) 
Changelog: https://github.com/php/php-src/blob/php-7.2.0RC6/NEWS Official migration guide: http://php.net/migration72
Should've separately added an RFC for the newline, because that's nice to have. However, I see no use for the other one, doesn't improve readability at all.
ok no problem as you say
Why? Separate votes are enough, no?
They are unrelated imo, they just touch the same feature.
He doesn't have to split it into multiple files, but he could make multiple classes, like a config class that handles anything with the config. If he only wants one class then he could at least prefix functions with their primary role. 
Ahh didn't see the $installLocation == 'themes', yeah that's OK then. 
How different are perl to php scripts? I saw some perl scripts and they looked strange but the syntax was similar 
They both touch the same feature (heredoc / nowdoc). If those don't touch the same feature, I don't know what touches the same feature.
I would expect a multiple vote to be whether it touches heredoc or nowdoc (as example), not 2 separate features
1 file, 1 static variable initialized to rule them all! :)
Honestly your whole thing could be private. The whole visibility comes from "Who will be using it", not downloading it and putting it on an FTP, i mean writing their own code and including your code. Do If someone did "include 'wondercms.php'; " do they need the ability to call "_generateToken" ? (Ignoring the _ to fake represent visibility). In most cases you have to consider public/protected/private, but since this is a self-contained project, in 1 file, with 1 class, everything could be private, public or protected, wouldn't make any different :)
What you did in OtherClass constructor is actually correct. You should do exactly the same in MyClass1 constructor, inject dependencies (in this case $db and $oc, instead of instantiating them directly in MyClass1. http://www.phptherightway.com/#dependency_injection
Images are created and deleted every few minutes.
Hasn't this been proposed and voted down like 3 times already?
Another PHP noob here, but I simply declare a global variable containing a single PDO instance and grab that within other classes if/when needed. I'm sure I've looked for details on this approach before and there doesn't seem to be any consensus on it.
It depends on what parts of Perl they decide to use. In particular, using different sigils in front of a variable changes what it does (eg evaluate an array as a number and it'll give you the length), and there are a ton of "default variables" that are auto-populated and auto-passed, so you can have a whole series of function calls that don't appear to take in parameters or assign return values, but they secretly are.
Are you sure you know, how internet works? 
They're almost the same, it doesn't make sense to have them inconsistent. 
What is the cost for parsing the "possible comma" with every function call? 
Wjy would that be parsed in every function call? PHP is compiled to zend bytecode and there would be no trace left of the comma in there.
Those are some pretty neat changes. All I need now are enums and generics (even PHPDoc would be enough) and maybe subtypes of array that are strictly sequential or strictly associative and then I might actually like PHP.
I thought this feature was meant for situations that are dynamically generating uncompiled PHP.
The consensus is that it's a bad idea. Just use dependency injection. There's literally 0 reason to re-invent the wheel or do it differently.
You could use the custom rule objects and complex conditional validators. You could use rule objects and pass those into your validators constructor. new Validator(Scenario1::class, Scenario2::class); 
Do you have some decent sources discussing the issue? I'm genuinely interested in reading more!
Not necessarily. I like to split to multiple lines when my calls get too long. I‚Äôm constantly saving my files with trailing commas and seeing my linter complain or my tests to fail. Just annoying to have to keep slowing down and asking myself ‚Äúis this an array and can I use a trailing comma?‚Äù, when I feel like it shouldn‚Äôt matter. FWIW, I get irritated with JSON for the same thing. It‚Äôs also frustrating if you make a call, decide to remove the last parameter, then suddenly you have a trailing comma and the code fails until the comma is removed. Or you reorder the arguments. You also now have a 2-line diff instead of 1, which doesn‚Äôt really matter, in and of itself, but it may also trigger a conflict you weren‚Äôt expecting.
Question. Why are trailing commas desired? I've personally never felt the need to have them in my code. They just feel out of place to me at the end of my arrays. The only positive I can see from allowing them is if your repetitively Copy+Pasting a bunch of extra entries and you forget to remove a comma after you finish. Do they actually have any positive effect on the code?
As some others have mentioned it makes your diff smaller.
How so?
When you add a new element you see only one line addition instead of change of the previous line and addition of the next one. I also observed we are getting less conflicts since we started leaving dangling comas in arrays.
Hmmm...interesting... Thanks for the response...
While the syntax can appear ‚Äúsimilar,‚Äù they really are two different beasts. Perl lives and breathes regex, and has special operators for handling it directly in the code. There‚Äôs also no ‚Äúreal‚Äù object orientation. They have a differentiation between arrays (lists) and hashes, and different variable prefixes to differentiate between them, @ and % respectively, which are handled and treated differently from scalars, defined by a $. Perl also has a plethora of ‚Äúunwritten magic‚Äù and helper variables that can make code particularly difficult to read sometimes. Perl also has references as a variable type, whereas PHP doesn‚Äôt really.
There's no over-arching plan. Individuals and small groups of people might have plans and work on them. I know at least one person who has a reasonably solid plan for decent enums in core - but unless someone wants to donate a shit ton of money for them to work a lot more on it, it might not happen. Making big changes to internals takes a lot of time, which is why a significant number of PHP internals contributors are either employed by Zend, or are students. &gt; method overloading, That's not likely to happen at all. First method overloading is a little bit stupid to begin with, but it makes very little sense in languages where types can be juggled to different types. class Foo { function bar(string $string) {} function bar(float $float) { } } $foo = new Foo(); $foo-&gt;bar(3); // which method is called, and why?
Thank you for making it non-laravel!
&gt; JSON (JavaScript Object Notation) is a lightweight data-interchange format. It is easy for humans to read and write. It is easy for machines to parse and generate. It is based on a subset of the JavaScript Programming Language, Standard ECMA-262 3rd Edition - December 1999. JSON is a text format that is completely language independent but uses conventions that are familiar to programmers of the C-family of languages, including C, C++, C#, Java, JavaScript, Perl, Python, and many others. These properties make JSON an ideal data-interchange language. http://json.org
Man, despite PHP's shitty history, it's so hard to not get mad at these assholes who hate on the language just because it's the hot thing to do. I'm a student of languages, I've dabble in many languages and all of them have some quirks to them. Yet php always gets the shit end of the discussion. I need to start finding good retorts to that shit or try to ignore it. So hard to ignore though.
- item1 + item1, + item2 vs. + item2,
start from /r/phphelp and asking a sensible question there that consists of some prerequisites and background
why not to send it to a queue already?
You could try set the ini setting "default_socket_timeout", or open the file using fopen() and then use stream_set_timeout() on the returned file handle. But i have no idea if that actually has any effect on local files (since it is a network mapped drive/folder it will look like a local file for php, even if it is not). If you have RabbitMQ in place anyway i would go the other way around, just write it to the queue and then have a process in place that fetches the messages from the queue and writes it to the file as fast as possible.
This. Plain and simple explanation.
Maybe you are both in different countries? I get the sense that widespread mac use is US-specific. Here in Belgium I also haven't seen it all that much in big enterprise contexts, and typically it's smaller dev and design agencies that use a lot of macs.
I don't really think we need to change the API of the language to solve problems in 3rd party tools or that can be solved by using an IDE.
In this case you should create a mount. You will use a single server for image hosting. You will mount this server using dynamic paths so that each other server will see it as a folder. More details: https://serverfault.com/questions/410588/how-to-mount-a-directory-from-another-server
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
best project
PHP is so God damn great these days. I still wish you could depend on the order of parameters four different methods but that's never changing and I can live with it
best project
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
I do not exactly understand what good your solution would bring to the table? Why that long ugly string in my code would be better then method calls? I really respect you for time and effort you put into this but I really hope I wont have to work with code like that.
It's a bit of a shit article. The part that covered including libraries by using Git to clone them (instead of using Composer) and then manually editing the cloned files (so you can't ever update the repo) was a personal favourite. The whole thing felt very "amateur hour" and only seemed to exist in order to promote some crappy startup website. Boo. Thumbs down. https://media2.giphy.com/media/xT5LMsoq6cIBCE6UOQ/giphy.gif
Well it is written for "amateur people". If you are offended I'm sorry but it is not written for you. 
Thank you pavlakis. &gt; I know the idea is for it to be lightweight, but have you thought of separating some components e.g. using Slim3 or FastRoute for your routing? (using composer) To be honest and short - no, I would love to see this fork out though!
It‚Äôs very bad. All you have to do is call the class and define a different value for $endpoint in the constructor!
&gt; The hack to manage your website‚Äôs static files with Digital Ocean Spaces &amp; php w/o writing a single line of code! FTP?
Ahh, could be. I am in the U.S. 
In theory it's easy; array methods are $needle, $haystack, and string methods are the opposite. Or is it the other way around? :'(
Beginner article should not present bad pratice.
What problem does this solve? We tried to get on board with the Laravel form helpers, thinking _surely these will start to make sense at some point_, only for them to be removed in 5... 5.3, was it? Perhaps form builders are a neat way of containing some instructions in your controllers, but as soon as you try to throw them into a design it becomes super time consuming, hard to read, and hard to work on, with no tangible benefit. Forms are markup, and I think belong in the views, with the data and validation in the controllers. Otherwise, what? Table helpers? Div helpers? Where's the line between frontend and backend?
I like writing lines of code
You should really consider adding a few links github repositories containing complete applications which follow your methodology. Real applications. Ideally ones in production. Doing so will demonstrate that your "Extensible Architecture" is more than some confusing (to me) diagrams and equally confusing (again to me) descriptions.
moving the form inside controller action is a back step from sensio generator which adds as a function inside the controller and 2 step back related to having the form in forms folders. Personally I think symfony is for frenchs 
Symfony is the worst framework in the history of worst frameworks
Yeah... Why didn't the OP do this? I saw editing a **default value**, why not just pass the url as an argument? &gt;.&gt;
go away troll.
Got a written version? Can't watch this because I have no sound.
90% of the comments you make here are bitching and moaning about Symfony. I have no idea why you're so obsessed and upset with it's success.
Sounds like you're trying to do something like this: https://blog.jetbrains.com/phpstorm/tag/annotated-monthly/
Oh, okay. That's nice. Cool.
I don't write front ends with Symfony anymore, I build my apps as an API and my front end as an SPA. I use the Symfony forms and data transformers to take form data from the client and create objects. I've found it easier than trying to un-serialize it myself. It works for me, but then again, I'm a one-man team and probably do a lot of things that I shouldn't.
Targeting this at "amateur people" is why we're all making sure to publicly denounce it. Hopefully they ignore it.
Same here. The Symfony Form is arguably one of the most complex component and rightly so: the problem it's solving is very complex, mainly due to the HTML handling. The Laravel form helpers are okish but really cannot compare: no proper form handling, a lot of custom stuff to have a decent configuration and having data converters would be a nightmare. It's also missing the proper translation handling of form errors. It's ok though as the Laravel form helper are just mean to be that: helpers. If you heavily rely on it you should look for a more complete package (Laravel Form or something if IIRC) or even the Symfony Form itself as it's an isolated component. That said if you don't need the HTML part, you're probably better just using a serializer and a validator, it's way simpler.
So I would have to write a class or series of classes that would be capable of * Validating my POST data against an entity * Unserializing my POST data and populating said entity * Performing data transformations that can create new entities and associate them with the parent entity Or I could just use Symfony's forms. Don't people usually advocate against re-inventing the wheel?
I know I've seen comments like that around here, but looking at his post history, it looks like a newer account and this is the only anti-symfony thing posted.
success?
They've deleted the vast majority of their comments and do so regularly. 
This is probably the primary reason PHP gets such a bad rep :-(
&gt; https://blog.jetbrains.com/phpstorm/tag/annotated-monthly/ jetbrains for the win. Visit this every month. +1 Also, check out https://github.com/sdmg15/Best-websites-a-programmer-should-visit (more than just php)
Until you've spent some time with it I think it's a natural reaction. I mean, it's forms, they shouldn't be that hard. Then you get used to it and can't see a reason to do it another way. I had a crash course in Symfony forms via an 18 month CRM project. Forms in forms in forms with a form in a modal. But now, they aren't really that intimidating now. Which is guess is obvious. &gt; Shit's hard until you learn it enough to not be hard. The one thing that bothers me is not being able to access all your form validation on the front end. You set up all this beautiful validation in Symfony and then have to redo it in JavaScript - if the project calls for front end validation. And any more - people expect it.
Not really, some related topics that is not mentioned in annotated monthly. But I will consider this and fetch the good articles. Thanks.
Damn my boss want me to deploy a site now but 7.2 is not yet stable should I go ahead and install 7.2 RC? He wouldn't allow me to update once I setup the server
got it, thanks
Yeah, the duplication of effort does bother me a lot. I suppose if I did more complicated things with the forms, it'd be a bigger issue for me. Thanks for the perspective.
The benefit for me was auto-populating forms with Model binding or with session data after an error. This is easily done with something like Vue.js now so I don't even bother with PHP form components or helpers anymore.
You need a gf/bf lol
&gt; He wouldn't allow me to update once I setup the server Any reason why?
Question for you guys: I'm a recent bootcamp grad. We were taught Sinatra/Rails, and to boost my portfolio I'm going to attempt to update a friend of mine's forum (create a new section that utilizes a pre-existing database). All he has been able to tell me despite my constant nagging and prying is that it uses phpBB. I've been waiting a good week for him to fork the repository, so I don't have anything to look at and help me guess the answer to this question. What is the Rails/Sinatra equivalent for PHP? Laravel? From my Googling and a quick scan of the phpBB docs it looks like phpBB is more of a piece of management software and you don't actually code in it.
Hello, Thanks to appreciate my implication and no offense taken ... I asked for opinions I so have to deal with any kind - positive or negative. that's the deal! Reading your comment and some others above, I think I have to change the way I introduce things about what this lib meant to be used for. The title of this thread for instance "A new way to access PHP objects and arrays" suggested this lib would be used a large range replacing php native object/array chain way. I agree with you guys. For all that you pointed out above, it's not a great idea to use it that way. Though, I still convinced Grabbag can be of great use for certain projects or parts of projects. for instance for processing/transform array/StdClass objects structured data (coming from json for instance). So, next thing I plan to do is updating my README.md to change the way I introduce the lib. Liking or disliking a syntax is a matter of personal opinion in a way. As I already said there is much to say considering very popular approach such as the usage some very popular libs have with php annotations - either about syntax or about many things too (https://r.je/php-annotations-are-an-abomination.html). Thanks for your help ! 
I'm living dangerously and using it in production, that's the sort of awesome daredevil guy I am.
You need a bf lol, besides I haven't commented on Visual Debt post :D
i wish php include mb_string extension in the core 
Tried to integrate it to symfony. And it did, kinda. But I managed to make work only request and session details. Couldn't figure out why SQL logging doesn't work (yes, I injected sqllogger) and for rest I don't see modules. So it's pretty useless for me at this state
&gt;Damn my boss want me to deploy a site now but 7.2 is not yet stable should I go ahead and install 7.2 RC? No. Stay with a stable version. You get the benefits of 1) it's built into the Linux distributions, and 2) security patches are applied through the package manager. Going with an unstable version is a bit reckless, means it's harder to keep up with security/bug fixes (manual upgrades) and could have undocumented bugs in it. &gt;He wouldn't allow me to update once I setup the server Not updating software is a terrible practice. At best, your environment slowly rots instead of keeping up with new language features and best practices. At worst, you miss out on critical security patches and get hacked. At a minimum, the operating system, installed packages (e.g. Apache), languages, libraries/frameworks should have bugfixes and security fixes applied at some interval. On Linux, the operating system, packages, and language is easy to keep up to date (`sudo apt update` on Ubuntu). Frameworks need to be updated regularly (usually semi-manual process). Composer makes it easy to keep your libraries up to date. Deploying a server and never upgrading it is an outdated and dangerous way to live. (Upgrading without testing can be equally dangerous though.)
&gt; **either** **during** some Taylor drama or the 'visual debt' drama either meaning one of the two during meaning at the time of, not on a specific post
I haven't commented neither in the post that Taylor deleted his account
&gt; **during meaning at the time of, not on a specific post** And there's plenty more taylor drama than when he deleted his account.
I believe that was related to Symfony being used on Enterprise projects. What I said it was that I don't see many symfony job offers and everyone got crazy, didn't say anything related to laravel btw which was you tagged me IIRC as a laravel crusader or something lol
DRY. With forms, you tend to repeat writing same code over and over and over again. Symfony forms solves this. - generating html form - there is big selection of field types, including more tedious ones to write, such as birth day fields - populating html form with data, including associated fields and predefining choices - translations - validation, including putting error messages to html form - populating submitted data into entities - automatic security via tokens and by making sure backend doesn't accept choice outside those which are defined &gt; data and validation in the controllers This way your controllers are going to be pretty fat. Why would you do validation in controllers? Wait, with symfony forms you too are doing it there, with this: `$form-&gt;isValid()` - finito.
You ought to have the validation server-side still. If you have a JSON/XML API, you're probably better off with just a serializer and validator than the Symfony Form though as the later is much more complex due to having to deal with HTML
The point is this stuff is tedious to do. I use Vue.js now for this even if I don't have a JSON API just so I don't have to deal with populating forms manually.
This is some great advice, if the OP refreshes the token each request it makes timing attack not feasible. But there is no reason not to use **hash_equals**
Thanks for the gold!
It's fine to use Vue.js instead of something like the Symfony Form as well if you are more comfortable with it. As long as you validate things on the server side I'm not complaining :)
I know I'm just a party pooper, but... * 160 requests * 2.81Mb of stuff * 13s to load on my laptop * my average ping is about 20ms * my network speed is 120Mbps
I love using array callback functions. But array_map and array_walk, while taking the exact same params, take them in reverse order. Drives me nuts!!!
There are many Rails and Sinatra equivalents: Rails: Laravel, Symfony, Cake, Yii, Zend, F3, CodeIgniter Sinatra: Symfony, Lumen, Slim, Flight, Silex There are more. I've never used phpBB, but to my knowledge, the most anyone does with it is theme it. You can maybe install plugins for it? I don't know for sure. If you are new to PHP, you should realize that most of skill with it is platform knowledge and tools. CMSs are the Sun of our galaxy, Frameworks are the stars.
I kept running into the same problem where I'd have an enormous set of parameters for a single function: ``` function foo($page, $limit, $filters, $selects...) ``` And I wrote this library as a way of solving that problem by condensing it all down into a series of classes that makes it easy to declare these parameters and apply them. This is vaguely inspired by Laravel's query builder and retains a similar interface, but is more generally about declaring search parameters and transmitting them either between parts of your applications, or from one application to another using the `toJson()` functionality. There's also a companion JS library which lets you define the requests in the browser and pass them on to the back end. https://github.com/mongerinc/search-request.js I've gotten a huge amount of mileage out of this, so I figured I should share with others who might find it useful as well.
But enjoy the nice design :P We still have a lot of optimisation work to do (the landing page is too big), but after the 1st download, when you come back to the site it loads instantly thanks to the service worker. It also works offline.
My spoon is too big
I understand you better now, thanks for explaining. It was quite hitting reading at first, so I'm glad you explain. I do not think topic being fine doesn't mean you ask everybody about it. You can talk about religion without asking everybody with beard about What he thinks about Islamic War. I talk (learn) about menstruation with respect. E.g. I learn to give my women more attention and care than usual before her period starts and first few days. Worth it for both sides :)
Can you share me some details about your configuration @Ocramius (especially the browser you use)? I've done some test and even the homepage, with the cache disabled load in 1.15s on my computer (Chrome).
u/dunglas I tell everyone about this that I can. I‚Äôve used this in a small production site at a previous job and now I think I‚Äôve got someone else on board to use this in a much larger capacity. I love the new react tools. It feels like the future!
u/dunglas I tell everyone about this that I can. I‚Äôve used this in a small production site at a previous job and now I think I‚Äôve got someone else on board to use this in a much larger capacity. I love the new react tools. It feels like the future!
Are you getting these numbers from the homepage? Cause I'm not. Scrolling to the bottom: * 75 requests * 911 KB * 1 second load time * Your network is way faster than mine.
I am going to go with the opposing view. If they code is TOO FAR GONE to refactor, then just toss it aside. Let me tell you my story. It also involves a Code Igniter 2 application. And btw, CI2 is a fine framework, no reason to ditch it based solely on that, even if CI2 is very dated. 3 years ago I start a new job. 2 code bases. An API and CRM. Gigantic spaghetti bowl, uses 2 different ORMs and RAW SQL with cleaning done what so ever. It was a big pile of shit. I'm not sure if it was the biggest, because you don't try and measure pile of shits, you just hold your nose and get out as fast as you can. Did I mention it was slow? Didn't even follow the very modest conventions laid out by the CI2 developers. Day 1: I guess I'm just not a very good developer cause I don't understand this. 3 Months later: Yeah its not me. I tell my boss this is being rewritten. So last Summer I started rewriting the API, so we can support more than 0.5 requests per second. I got around the existing code by putting in a cache layer, but it was hacky. I took me 3 months to rewrite the core API that customers connect to. In that time I also did other work too. I kept the same database and everything. Just new codebase in Cake3. Today, our RPS is 13. Not great, but much better than .5. It will get better when I can fix the god awful database design, but I can't yet because...CRM. Still working on rewriting this unfortunately. So I rewrote code. I committed the cardinal sin. You know what? I'm fucking happy. I have unit tests. I have code that makes sense. It scales. It's far more secure. Developers can understand it. It has documentation. It has a service layer. It has a all the shit a codebase should have. We rolled it out slowly. Putting customers on the new API, one-by-one. There were bugs, but nothing catastrophic. Can't wait to get rid of the next shit pile. This is the first time in my 10 years that I got the green light to rewrite a codebase. Wow. I would totally do it again.
Atom now has an IDE version that support PHP, it isn't as fully featured as PHPstorm, but I am not a fan of PHPstprm. https://ide.atom.io/
Security patches?
Many managers only care about not breaking functionality while not doing test driven development as they believe TDD slow things down. Security &amp; keeping up with the latest trend are minor issues to them. They will usually turn a blind eye even if it's a security patch till the security consultant raise it up much later. (we hired an external company to do a security audit maybe 2-3 times a year) Even then they will ask, how should we backport the security fixes? &amp; get us engineers to work than to update the web framework or language version.
Ahh the slowly peeling off the bandaid method. Check my post, I just ripped the fucker clean off.
So, got home today and decided to play with this. I put together a quick service utilizing Symfony's validator and serializer. In this simple example, I pass the service to my controller and I can deserialize request data and validate it with one line in my action. I could take it further and attach it to kernel events and / or a param converter. The only thing I'd have to put some more effort into would be a data transformer. If I could finish this and make it more flexible, I wouldn't need the form classes anymore, and I might even be able to drop FOSRestBundle. https://gist.github.com/dlegatt/3dc81aeee375d13a3d86b782cdb5a6bf
I am a banana!
So I have a question, and I see this a lot, specifically with pagination. If I have 10k results, but limit the page to 25 results, and I want to filter all ‚Äúincomplete‚Äù (as an example) results with that status, I always get a filtered list on the already limited paginated results, which does me no good. How would I let a user filter all ‚Äúincomplete‚Äù results AND paginate that?
I don't get your question. Is it on getting ip or on inserting to database? If the latter, then use a prepared statement. If it's on getting the IP, then ... What is the question?
Sorry I guess my question or "concern" is what i had commented out in the php code. //prevent sql injections hacking etc check the IP provided is a real IP and nothing nasty Is the function i am using to keep it clean ok.
The `SearchRequest` object always represents the current state of the filter/sort/pagination/whatever set. If your application does this: $request = SearchRequest::create()-&gt;page(5); //make api call $request-&gt;where('status', 'incomplete'); Then you'd just need to reset the page to 1. I suppose I could write it into the library to let it optionally auto-reset on changes that would sensibly need pagination resets.
Use a prepared statement and a bound parameter. You should be doing that with _every_ input to a query in the first place. No exceptions.
Can you provide a example ? Also I did only want to check and keep this $_SERVER["HTTP_X_FORWARDED_FOR"] clean for database insertion nothing else.
No. You can find examples for prepared statements on google.
You should ask your questions in /r/phphelp From here they will be deleted by mods. Try to read whet is written in the form where you typed your question. For all database interactions just use prepared statements and forget about whatever injections
Here's a sneak peek of /r/PHPhelp using the [top posts](https://np.reddit.com/r/PHPhelp/top/?sort=top&amp;t=year) of the year! \#1: [First time writing OOP can anyone check im on the right track.](https://np.reddit.com/r/PHPhelp/comments/65qzgl/first_time_writing_oop_can_anyone_check_im_on_the/) \#2: [Can someone explain what this php malware does?](https://np.reddit.com/r/PHPhelp/comments/5phn6r/can_someone_explain_what_this_php_malware_does/) \#3: [Tutorial on getting xdebug to work with phpstorm?](https://np.reddit.com/r/PHPhelp/comments/70ho0c/tutorial_on_getting_xdebug_to_work_with_phpstorm/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/6l7i0m/blacklist/)
Always use prepared statements to prevent sqli. Your real problem is IP forging, not sqli. Configure a list of trusted proxies. Then explode x-forwarded-for by comma and loop through them. The client IP is the last one after your last trusted proxy. Anything added after it is a forge attempt, so you can log that accordingly. Symfony has this feature built in.
I‚Äôll give it a shot. So far I‚Äôve only seen Angular do it with their grid component. I‚Äôm using Laravel + Spark + Vue. 
I would like to try it. 1. Does it allow different header/footer for different pages? 2. When table splits between multiple pages does it shows the header in other pages? 3. Can we directly pass Blade View path to it? I use WKHTMLTOPDF, almost works fine, no particular installation on the server. But this packages can be a good option with latest HTML5 support. 
I know people can spoof headers easly and send that header with a bunch of trash like this X-Forwarded-For: AHagjxb1827@~PP#?[]!" That is why i am seeking a way to check they don't do that i don't intend to stop the spoofing but i want what they spoof to be a IP atleast even if it is not their own. (I can cross reference it with their real IP from the $_SERVER["REMOTE_ADDR"] function and take action then if i want.) I just want to keep it clean and any function(s) i can use to do so are great. I found this so far $ipheader_valid = (filter_var($ipheader, FILTER_VALIDATE_IP) !== false); This does a good job at checking both ipv6 and ipv4 are infact valid even if they are spoofed atleast the header is clean.
&gt; X-Forwarded-For I have a feeling X-Forwarded-For may have multiple IP addresses in it (comma separated) if there are multiple proxies in the way somehow. 
Does anyone know of a plugin for vim that helps with this sort of thing?
For me i only expect the single one IP not multiple. The function i provided seems to remove all the trash but no idea if it is considered good or ideal for cleaning the header before putting the output into a database.
It doesn't matter if you follow the procedure I explained above. Here's a quick example that I didn't actually test: $trusted_proxies = ['127.0.0.1', '192.168.13.37']; $client_ip = $_SERVER['REMOTE_ADDR']; if (in_array($client_ip, $trusted_proxies)) { $forwarded_ips = explode(',', $_SERVER['X_FORWARDED_FOR']); foreach ($forwarded_ips as $ip) { if (!in_array($ip, $trusted_proxies)) { $client_ip = $ip; break; } } } Let's assume these: Client spoofed X-Forwarded-For to 'hax0red'. Client IP: 111.111.111.111 Example 1 - No proxy: $client_ip is the actual IP that the request came from, which is not a proxy we trust so we ignore X-Forwarded-For completely. Example 2 - one proxy: $client_ip is the IP of the proxy, the actual client's IP is the first IP in X-Forwarded-For. Since the client attempted to spoof X-Forwarded-For, the proxy will prepend the real client IP to it, resulting in: X-Forwarded-For: '111.111.111.111, hax0red' We take the first part of X-Forwarded-For (which we can trust because it came from our proxy) and ignore the rest. Example 3 - two proxies: $client_ip is the IP of the proxy again. Every proxy that the request passed through prepended the IP that the request came from to X-Forwarded-For, resulting in: X-Forwarded-For: '127.0.0.1, 111.111.111.111, hax0red' We loop through X-Forwarded-For and skip the first one since we know it's a proxy we trust. Then we get to 111.111.111.111 which is not a trusted proxy and we can safely assume this is the client IP. The part between 127.0.0.1, and the next comma comes from a proxy you trust. There shouldn't be a SQLi in $client_ip with this procedure, but that's no excuse to not use prepared statements.
The number of requests doesn't matter with HTTP/2. :P
Same here: - 79 requests - 1.1MB - 1.95s to load a bit part of it is the fonts and the JS itself and all the tiny individual images
you just said it's from the trusted proxy. Can't you make your mind at last. DO YOU HAVE A PROXY OR NOT?
Generics looks Java like, very verbose. The most compelling argument was auto completion on IDEs, not sure if it justifies the adoption.
While generics are a bit more verbose, adding them would significantly reduce verbosity in other places. You often see all kinds of abstractions and multiple classes which kind of do the same things. Generics would offer a way to re-use the same kind of functionality, with type safety, without having to implement functionality per type. So I'd argue there are cases (the cases for which generics are a valid solution), in which generics actually reduce verbosity. To give an example: `Post[]` is shorter than `List&lt;Post&gt;`, though for `Post[]` to work, `Post` itself would need some kind of awareness of what "a collection of posts" looks like. Meaning `Post` would have to implement some kind of interface similar to `ArrayAccess`. That's more code than `List&lt;Post&gt;`, just in another place. On the other hand: `Post[]` could just be syntactical sugar for "a list of posts", for which generics are required.
What happened to the Phinx site? Can't deal with this cakephp site for docs :/
&gt; Generics would offer a way to re-use the same kind of functionality, with type safety, without having to implement functionality per type. Theoretically yes, but PHP lacks of type safety (I mean static typing backed by an AOT compilation). So what could be the benefits of generics regarding this concern? 
Notice that the author did this with `offsetSet`: public function offsetSet($offset, $value) { if (!$value instanceof T) { throw new InvalidArgumentException("value must be instance of {T}."); } // . . . } Isn't this the exact problem the author claimed generic types were supposed to save us from? The issue is that many of our core, built-in functions and types aren't designed around generics and changing them would be a BC break. We would also need new generic versions of these interfaces that can peacefully coexist somehow. In some ways I think that's harder to do than implementing generic types themselves... ... and that's only generic types. I think we probably need generic functions and methods as well.
&gt; which leads to needing type inference At least two PHP type checking packages (Phan and Psalm) support an `@template` docblock to allow a better understanding of functions e.g. https://github.com/vimeo/psalm/blob/master/src/Psalm/Stubs/CoreGenericFunctions.php Type inference isn't a particularly hard problem. 
[Permanent](https://help.github.com/articles/getting-permanent-links-to-files/#press-y-to-permalink-to-a-file-in-a-specific-commit) GitHub links: * [vimeo/psalm/.../**CoreGenericFunctions.php** (master ‚Üí 126fd9a)](https://github.com/vimeo/psalm/blob/126fd9a3a13e6f15bce4998b9efd6cd2065d33b3/src/Psalm/Stubs/CoreGenericFunctions.php) ---- ^(Shoot me a PM if you think I'm doing something wrong.)^( To delete this, click) [^here](https://www.reddit.com/message/compose/?to=GitHubPermalinkBot&amp;subject=deletion&amp;message=Delete reply dpo3w5w.)^.
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
The cost of doing so statically is not bad. The cost of doing so at runtime is.
How bad are we talking here?
There was an [RFC for that](https://wiki.php.net/rfc/arrayof) but it seems to have failed because generics were wanted instead.
It depends on the complexity of the inference. Simple inference may be cheap. More advanced will be more expensive but result in nicer ergonomics.
Previous discussion thread: https://redd.it/6clbds
Why do we need a new version of these interfaces? Can't it just default to &lt;mixed&gt; for everything?
asking for an email adress without a privacy policy or anything makes my skin crawl ... granted i'm german and we take that whole area very serious (maybe too serious at times) 
I see no value in them in a dynamically typed language.
You mean that PHP doesn't guarantee what happens with a variable or its type after the initial check, right? Like so: public function test(Foo $foo) { $foo = new Bar(); // PHP doesn't care ¬Ø\_(„ÉÑ)_/¬Ø } The same way, there would be no guarantee that passing a value to method of a class using generics would stay that same value. But you could still guarantee the type of entry- and exit points in that class: class List&lt;T&gt; { public function add(T $value) { // anything can happen with `$value` here.. } public function get($offset): T { // ..but we can be sure that the thing coming out is of type `T` } } This is dummy code, but this would solve a few issues, for me at least: - No need to manually type check when you're looping over items in this "list": what goes in is of type `T`, what goes out is of type `T`. - From a debugging point of view, it's much easier to pinpoint where things go wrong: if you're adding something wrong to this "list", you'll get an error saying exactly that. If you're looping over its entries and the list tries to return something other than `T`, you'll get an error saying that. That's much better than what possible now (without coding it per type): $list = []; $list[] = new Foo(); $list[] = new Bar(); foreach ($list as $item) { // Can't be sure of anything without explicitely checking the type of eacht `$item` } - IDE Autocompletion I don't know if maybe I understood something completely wrong about all it (no expert at all), but these are scenarios I'm working with daily. Generics would be a real solution to those problems. They would result in a cleaner and easier to debug codebase. Did I understand your question correct?
Hi Levi, thanks for answering. I wrote the article from a PHP developer point of view, the "end user" so to speak. I'm not completely unfamiliar with the theory behind it, but I don't know a lot of things. Could you elaborate what you meant with &gt; Isn't this the exact problem the author claimed generic types were supposed to save us from? Generics for me would mean a lot less type checking in the code itself. That's what the example was about: instead of needing to do those checks in PHP itself, they would be done by the interpreter on a lower level. I understand that in PHP, there's no real type safety, because a variable could always be re-assigned to something completely different. Though I explained in another comment why for me, it would still be beneficial: https://www.reddit.com/r/PHP/comments/7c7rtm/sharing_on_older_blogpost_about_generics_in_php/dpo9b33/ Could you further explain what you meant with &gt; We would also need new generic versions of these interfaces that can peacefully coexist somehow Does this mean that `Foo` would be a different implementation when used in a generics context? Eg. normal: `$var = new Foo()` vs `List&lt;Foo&gt;`. I hope you don't mind the questions. Like I said I'm a userland developer. But I'd like to learn.
I can imagine some pathological cases e.g. ``` function takesStringArray(array&lt;string&gt; $arr) : void {} $arr = []; for ($i = 0; $i &lt; 100000; $i++) $arr[] = "hello"; $arr[] = new stdClass; takesStringArray($arr); ``` but some sane optimisations could prevent those worst-cases.
No. This is because parameters are contravariant, which is basically a way of saying that if you change the parameter type in a sub-class that it must accept at least everything the parameter did in the parent function. Since in this case that parent type would be `mixed` then the children must accept `mixed` as well.
As someone who hasn't ever done PHP and has admittedly stayed away mostly due to its public perception - know that most traditional webdevs peeking into freelance work is secretly super salty that a large majority of the work (it seems) is still done in PHP
I mean that you couldn't do this: public function offsetSet(?T $offset, $value) { if (is_null($offset)) { $this-&gt;array[] = $value; } else { $this-&gt;array[$offset] = $value; } } The engine would complain: &gt; Fatal error: Declaration of `GenericCollection::offsetSet(?T $offset, $value)` must be compatible with `ArrayAccess::offsetSet($offset, $value)`
&gt; This is not scalable. You need a separate implementation for every type of collection, even though the only difference between those classes would be the type. No you don‚Äôt, you can make a GenericCollection that takes its generic type in the constructor. Then everywhere you compared the value to Post in the example you‚Äôd change to use the stored type. 
Such a weak post.
Yes, but how many places are there where we accept object instances that would use generics in the future?
I see your point. Wasn't there a variance/contra-variance PSR addressing exactly this issue?
How would you handle return types?
This error is legitimate even if that RFC was implemented. 
Warning: Lots and lots of popup spam on the link. Other than that, 99% content free.
&gt; You mean that PHP doesn't guarantee what happens with a variable or its type after the initial check, right? Like so: &gt; The same way, there would be no guarantee that passing a value to method of a class using generics would stay that same value. But you could still guarantee the type of entry- and exit points in that class: You are pointing a characteristic of dynamic typing, but that is indeed not what I am speaking about. &gt; No need to manually type check when you're looping over items in this "list": what goes in is of type T, what goes out is of type T. Here is the problem IMO, you have not to make type check on your own, but the check still occurs at run time (i.e. when it is already too late). In other, statically typed, languages like Java or C++, type mismatches would be caught at (ahead of time) compilation stage.
&gt; Security vulnerabilities :- These are the main security threats in PHP ‚Äì &gt; - SQL Injection &gt; - XSS (Cross Server Scripting) &gt; - code revelation &gt; - Session hijacking &gt; - CSRF (Cross Site Request Forgery) None of those are language specific - the same could be said for (insert web development language here)
IMHO, `FooController@bar` is better more readable than other variants.
I applaud your initiative to come out and write your thoughts, but in the other hand i have to say you seem quite confused with a lot of the terminology and concepts... I disagree with a lot of what you wrote, so much that it would take me too much time to write it here. I strongly advise you to read the DDD book by Eric Evans, and if you did already just do it again. Furthermore, I've also been writing about software architecture. Maybe you will enjoy some of it: https://herbertograca.com/2017/07/03/the-software-architecture-chronicles/
Which is also nice because it can make `git blame` more useful.
A lot of PHP people use Phpstorm as their IDE, which is one of the few common pieces of the PHP ecosystem that is not open source or free as in beer. Phpstorm does a lot of static type checking which it expresses by colored flags and messages on the source code lines with problems. In the array case, and other cases where the applicability of a method is unknown, it places a flag to indicate a potential problem. If the problem is not in the code itself, the programmer can correct the flag by either putting an @var comment above (no runtime cost) or do an instanceof or assert() check on the object type match. This system covers many more cases than just generic collections, and it is convenient, but proprietary. For handling collections that are really mixed, I would like to see the PHP language provide better support for doing the relevant type checks in concise expressions that are similar to case expressions.
Yeah, I wouldn't put for example an app lat/long php service (difficult to cache) behind a slow framework...
Sounds like pcntl_exec (like Unix/Linux exec) is what you want for calling the script. http://php.net/manual/en/function.pcntl-exec.php
My anus is bleeding! 
/r/phphelp
Generics.
Few need convincing of the need. The blocker is in the implementation. Tell us how to implement generics successfully in PHP.
Who chooses these thumbnails?
See you again in 6 months.
!$value being a bug in the check is bothering me. It's being casted to a Boolean.
You should have your bash script run your php script.
A lot of conclusions without arguments. Absolute crap. You can't say things like 'Best framework in PHP' without trying to backup that without some arguments. Same for the advice you give.
This post was removed because you have a new account and we get a lot of spam from newly created accounts. If you have any questions or think your post should be reinstated, please send a message to the mods. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/PHP) if you have any questions or concerns.*
Is it? These two seem to work as expected: https://3v4l.org/G0OkS https://3v4l.org/Lmrqp
Plus not to mention that there is no symfony and there is no argument why its not inhis top 3
comparing CI to Yii and Laravel is like comparing a tsuru to a lamborgini and a ferrari
one thing to note. if you write your project in yii you have the project for life. Even if you give the client the source code there is little possibility he will find a developer knowledgeable enough to maintain it since yii is very structured and little known.
What you have: exec(dirname(__FILE__) . '/sendemail.sh'); What you want: exec(dirname(__FILE__) . '/sendemail.sh &amp;');
Sadly this doesn't always completely work as expected, see: https://github.com/symfony/symfony/issues/12097#issuecomment-343145050 Not sure if this is a bug in PHP or intended behavior, but it's very annoying and not what you expect :(
It could work for guards, which is what Java actually implements for "generics". C++ does a lot more in terms of selecting entire chains of methods to instantiate based on the type parameters and function overloading. PHP doesn't have a compile time to do type inference/instantiation or function overloading. Perhaps the most similar thing in PHP is traits. One could theoretically write traits that would do run time inference about properties/naming conventions of the class they were instantiated in and then dynamically add the relevant sorts of methods...it might be cool for a demo, but hard to debug in practice and obfuscating rather than self-documenting as code. 
What is the difference between PHP FPM and libapache2-mod-php7.0? I installed Apache2 on my ubuntu pc and I want to make my php files work, but when i look at tutorials, some do not install libapache2-mod-php7.0 at all and instead use some trickery with FPM to make it work, while other tutorials install libapache2-mod-php7.0 and use that instead. What is the difference? Which one do I use? I just one a simple lightweight solution.
Fair point, it‚Äôs not perfect. But you can type hint GenericCollection and check the type. However, you could still use the separate types like PostCollection but extend GenericCollection. That solves the code duplication problem above. 
Gonna give star for effort. Very interesting
You're right. The precedence of instanceof is higher than !.
That's really interesting!
fucking symfony
you could try calling your bash script via register_shutdown_function - not sure if that actually does what you want though, in the end you could just wrap the call in a 2nd outer bash/php script
The biggest problem for me with using React on my projects was getting the Javascript toolchain setup, as most of the tutorials out there seem to assume that you're going to be using it either with a node backend, or running it as a one-page Javascript application. In case it's of use to other people, https://github.com/Danack/ReactTutorial is a standalone project that creates a couple of docker boxes to: * Create a yarn + webpack box that continually compiles React sources into browser runnable Javascript. * A trivial nginx + php server. * A database that can initialise itself. Which allows you to see React compiling and being used. I haven't updated it in a couple of months, so it's presumably horribly out of data now, given the rapid changes in Javascript world.
&gt; Thanks for the gold Most welcome, thanks for tuning in!
Our legacy PHP code is terrifying too. 
I agree, the value is limited. We're already able to handle generic types fairly gracefully, imo.
please, Symfony? That over engineered pile of garbage ?
I dont see where does it say best php framework for rapid development? Author of text ment globaly, so please
&gt;‚Äúless effort and less complexity‚Äù. 
I don't know, is full of Russians that work with yii2, as Frenchs for Symfony and Indians for Codeiniter/Laravel, Perhaps cakephp is the best choice
Actually there is a lot of Yii based work in US and Germany, not just in post-USSR countries. It's just mostly in internal business tool systems or you will never can tell. It's the businesses you know little about unless you are specifically interacting with them. And those systems run for decades easy when maintained and updated.
That has absolutely nothing to do with anything.
I am not sure if thats same with this `exec(dirname(__FILE__) . '/sendmail.sh &gt; /dev/null &amp;')` but this worked for me. At least for my first test.
I dont think that will work for me because, I have form, where when I click `submit` php get executed then I get output from php and call that output from bash script
He said that nobody works with yii2 I said Russians
Do you just spend your whole day making up bs about Symfony? You seem obsessed with trashing it but never post anything factual. 
&gt; Create a yarn + webpack box that continually compiles React sources into browser runnable Javascript. Won't the webpack remove access to React from global namespace? Like enclosing it (react), to only be accessible to the bundled webpack js file only?
Should I post the top symfony bundles last commit date?
Why don't I post them instead? Top 3 bundles per KnpBundles: * FOSUserBundle: 19 days ago * FOSRestBundle: 6 days ago * SonataAdminBundle: 2 days ago In fact, the only bundle on the first page at KnpBundles to not have been updated in the past two months was StofDoctrineExtensionsBundle.
First you should ask yourself if you are willing to work with a legacy system. If your desire for a green field project is huge, seriously consider moving on. You tech lead seems not very supportive of you idea. If you want to heavily refactor the codebase, you need his support. And more importantly you need to agree with the whole team how the new codebase should look like. Doing it all alone and without team support, is a guarantee that you instantly create legacy code. And simply throwing in a modern framework or library, won't make anything better. Talk with the team, work out what you make things better for them. After that you can work out how to do it. 
Well FOSUserBundle last stable is 1.2 I believe, that 2.0 is dev(since 3 years not a single stable release) and unsupported on SonataAdminUsers and both are incompatible with Symfony 3, besides that extending these bundles is very hard and a pain in the ass
Again with the BS. FOSUserBundle is stable at 2.0.1, works with symfony 3 and takes 5 minutes to set up. If the only source to your argument is "I believe" when you can have the answer with a 3 second search on packagist or github, all you do is prove my initial point that you do nothing but make up BS about symfony and are obsessed with trashing it.
Last stable version is 1.3, and is not compatible with Symfony 3 or SonataAdmin. Don't mix my words, btw you seems to be very easy to influence as user/dmc404 tell you that he tagged me as laravel crussader or wherever and you know are obsessed too
What the hell are you talking about? https://github.com/FriendsOfSymfony/FOSUserBundle Stable v2.0.1
I don't understand. All I read is that if I don't use an IDE I am a worse person?
and as for the rest &gt; Don't mix my words, .... Never did &gt; btw you seems to be very easy to influence as user/dmc404 tell you that he tagged me as laravel crussader or wherever and you know are obsessed too. I'd seen your BS posts before, but you chicken out and delete them all the time, like i'm sure you will with this one. I simply asked another user that seemed familiar with your habbits. &gt; Can you provide a counter argument to the over engineered bundles ? lack of default features of symfony, or just lack of interest in last years? I have countered all of this, you argue these points with no evidence. I'm done here. 
&gt;I'd seen your BS posts before, but you chicken out and delete them all the time https://www.reddit.com/r/PHP/comments/7c0ins/form_builder_handson_symfony/dpmfqqo/ :\ &gt;I have countered all of this, you argue these points with no evidence. I'm done here. Where is the contra for the hard configuration/complexity to extend? 
Yes, that is exactly what I said, I'd seen your bs posts before and asked another user that was familiar with your habbits. You delete your posts and i usually don't memorize usernames so I wasn't sure it was you. Maybe some day, I'll learn to stop feeding the trolls and getting into pointless arguments online.
I find the down votes disappointing. There is so much cargo cultism and wrong ‚Äúconventional wisdom‚Äù in this industry.
Symfony is not good really, you can try to cover it calling me troll but wherever... and are you using Symfony?
Software practice evolves over time. The leading modern IDEs provide sets of features that most people find are important to enhancing their overall development productivity... ...but independently of that, most people still think of static type checking as a basic language feature. I point out that for better or worse, the Phpstorm IDE provides a level of static type checking for PHP that makes it a different language (or version) by some functional criteria - i.e. without the checking the code can fail at runtime with "method not found" errors, whereas fixing the indicated problems prevents that. The possibility of that sort of IDE dependence is unexpected in these types of discussions, but relevant. 
Your arguments have no merit and anything that I‚Äôve posted to github has no bearing on any of my arguments.
I've found https://github.com/JeffreyWay/laravel-mix to be an excellent place to start. It is loosely connected to the Laravel ecosystem, but cleanly usable outside. Well documented and hard to mess up.
Ignore the guy, he's an obvious troll. &gt; Well FOSUserBundle last stable is 1.2 &gt; Last stable version is 1.3 Saying two different things and if you look on their github (like you posted) it literally has the 2.0.1 stable icon. 
If you want global access, you can use the webpack ProvidePlugin to have them be available in the global namespace like: // This makes the components be available to all other components without having to link // them by hand. new webpack.ProvidePlugin({ $: "jquery", jQuery: "jquery", jquery: "jquery", "window.jQuery": "jquery", ScrollTracker: 'scroll-tracker' }), I should add that to the example.....but just to note, I prefer to not have React exposed globally for the project where we're using it. Although it makes sense for jQuery and other bits and bobs that need to be touched on the page, having all of the react stuff be prebuilt and separate seems to make more sense for it.
Should you really talk with a guy that has ‚Äúfucking php‚Äù in his description and still hangs around php community. No wonder he trash talk at php too
But that's the same issue as: class AnimalCollection implements ArrayAccess { public function offsetSet($key, Animal $value) {} } Which IMHO is outside the scope of an initial generics RFC, but assuming undefined generic type arguments are considered 'mixed' (same as undefined type hint) then we can change ArrayAccess to: interface ArrayAccess&lt;Tk, Tv&gt; { public function offsetSet(Tk $key, Tv $value); } which would be backwards-compatible and allow us to define: class GenericCollection&lt;Tk, Tv&gt; implements ArrayAccess&lt;Tk, Tv&gt; as well as: class AnimalCollection implements ArrayAccess&lt;mixed, Animal&gt; Is there something I'm missing here? 
Laravel should handle that properly out of the box, as long as you apply all query logic before calling `paginate()`.
The analysis in the linked article is weak. Most PHP database libs are built on top of PDO which handles a lot of differences between databases. Extra customization for specific databases is not what bloats the frameworks. In fact, "Microframework" Lumen &amp; full framework Laravel share essentially the same database libraries. They differ in the number of other services they provide and whether those are initialized by default. The concept of "framework" itself implies a degree of bloat, even if it is "microframework", but that is not because of accessing different databases.
First the database thing was just an example not the only thing - couldn't go ahead listing everything, 2ndly not all databases use PDO, a good example is MongoDB among majority of nosql dbs. If that wasn't clear, my apologies.
&gt; Symphony. Expertise confirmed. &gt; bloated with many libraries a developer may never use. Then don't know that they using it.* Modern frameworks which has dependency containers doesn't initialize anything that you don't use so there is no overhead. This also applies to all "will have libraries and ability to connect to all this database". 
&gt; a good example is MongoDB among majority of nosql dbs. Show me framework which provides you ability to use relational and, for example, mongodb out of the box? Anyway, ovehead comes only from things that in use, if you don't use library for mongodb in your project, you don't have any overhead. 
The article gives one wrong example. Example of 1, that's completely wrong. There was no other content in the article except for naming some things called frameworks and microframeworks. Microframeworks in PHP often hope to shorten the code path between a http request and it's destination service routines.
This is awesome, I actually tried to do this a few weeks back but the bit I was missing was the hydrate() call. It's really handy for CMS implementations where you have 1 or 2 small components embedded on the site that are written in React
Check out [Mapper](https://github.com/ScriptFUSION/Mapper) for transforming arrays from one data state representation to another using a mapping object that describes the transformation. 
Why do many people seem to think PHP is an awful language? 
Laravel can give me the total number of results (like 12,500 for example), but won‚Äôt load all of them when you return $result-&gt;paginate(). Can‚Äôt filter what you can‚Äôt see. This is on Laravel 5.3.30 (IIRC, whatever the latest for 5.3 is).
ok 
That's pretty cool but why'd you have to phrase it like clickbait?
I depends. As a server side web service language it's great, but for more simple scripting or even more advanced programs, meh.
Nice, a scriptfusion ad...
I personally don't like the fact that it doesn't take into account the number of people that have actually voted. 1 person voting 10 would make that certain game number one in your list. Surely it should be sorted by calculating (number of votes * player rating) then sort by that number instead? You should also consider making an age of that game a factor, so you don't keep having the same games appearing all the time.
&gt; I personally don't like the fact that it doesn't take into account the number of people that have actually voted. It does, that's part of the [Wilson algorithm](http://www.evanmiller.org/how-not-to-sort-by-average-rating.html). However, it has [already been agreed](https://github.com/250/Steam-Top-250/issues/3) that vote volume needs to be given a higher weighting. &gt;1 person voting 10 would make that certain game number one in your list. A person cannot vote *10*. A vote is simply positive or negative, same as on Reddit.
Please add an "exclude waifu games" filter
Because I thought building powerful, data-driven websites was an idea worth sharing, and if it inspires you to do the same it will have been.
Maybe I'm misunderstanding. `paginate()` will indeed perform the query with `LIMIT, OFFSET` in order to get the specified page's results. If you want to add any filters / constraints, you do it before calling `paginate()`. Are you trying to do a double record fetch? Or something else I'm missing?
Plus, doctors hate him. You may be overstating what you built a little.
I know this might not go well but, why do you feel that way?
Because they used it 10+ years ago and decided it was bad then. Also it's cool to have an enemy -- rallying point around which people can say, "well at least we aren't that." Build a community, or market something, right out of a bit of negativity.
Honestly it really depends on the use case. For example, making a script to start a few services on Linux works better using bash than PHP. Having said that, I use PHP for a lot, but have heard the arguments from all sides and I agree with both sides on different points. 
Why do Universities that have programming/web design courses teach old methods of PHP (like good practices for v4/early v5)?
See, that‚Äôs the problem. Let‚Äôs say I have 10k orders, and any given order can have a status of complete, incomplete, cancelled, and rejected. Sorting these isn‚Äôt a problem because that happens prior to the pagination, but you can‚Äôt all of a sudden filter by stays on a result set that‚Äôs limited to 25 per page (you‚Äôll only ever filter the 25). I would I guess have to make a query for each order, like getOrderByStatus, and on @click hit a Vue method that returns those results only. It‚Äôs self defeating though, because now I‚Äôm making more calls to the API than necessary. 
Fair enough, thank you.
Doctrine? Maybe I misunderstand what you're trying to get at.. 
Doctrine is an important library. It's not a preconfigured application framework.
Bullshit from the first to the last line. I thought of giving some links to disprove some ridiculous clams but then realized that all this stuff is only intended to show several ads in the middle of reading.
Well, technically, everything in Doctrine is separate package (or component) and some built on top of each other (e.g. ORM uses DBAL, etc). I'd say, Doctrine "as a whole" is a "persistence framework" in the same sense that we refer to Symfony as a framework although the majority of Symfony are individual components and what is the "web framework" in Symfony is relatively small in comparison to what is component.
I believe I understand now. This seems like a disconnect between the data fetching logic (API), and how the results are displayed/handled (front end). Not really a fault in either, just a business decision about how you want to manage searching and filtering of results. Basically, do you want to handle fetching tens of thousands of records at once, and do filtering via the front end? Or fetch only the records you need each time a constraint changes (filter, page, etc.) via the API. Perhaps there's a balance for both depending on number of records or constraints.
About your remark on method overloading: Don't u think that if it would stupid, not so many languages would have it? I feel what is actually stupid is to use different method names for the same conceptual action just because we can do the same action with different arguments. Relative to your code example: - if using strict types none of those methods would be called, you would need to explicitly cast the arguments, which u should do anyway imho; - if not using strict types, it would be ambiguous, none of those methods would be called and you would do it the same way you do it now, by specifying a different method name for the same conceptual action.
Laravel seems the closest match. I also recall the author saying that both Rails and Sinatra were sources of inspiration during the development.
What about symfony?
What have you accomplished?
The explanation in the eslint docs is that it makes adding new entries easier.
I take "framework" here to mean 1) provides code supplying all or most parts of some common type of application - all the Doctrine libs put together do not try to do that, 2) often includes facilities to manage global application state and/or configuration and/or initialization. Doctrine doesn't try to do that, though it does provide tools to help with database configuration/monitoring. Lumen and Laravel and Symfony fit that category.
Come on guys, this nitpicking on the terminology is absolutely unnecessary. This argument will take you nowhere. 
Because that is what the lecturers were taught. The exams don't really take best practices into account 
Generics with type inference open the door to having nice FP constructs, which would be abused quite quickly. Imagine a daisy-chain of "$collection-&gt;map($fn1)-&gt;filter($fn2)-&gt;reduce($fn3)-&gt;filter($fn4)-&gt;..." It would get prohibitively expensive to type infer all of that, as anyone who has worked on a reasonably-sized scala codebase with plenty of type inference can tell you. PHP's weakness is that it has to do all of the work at run-time instead of at compile-time like e.g. scala.
We don't have to use PHP for everything. We can create a RESTful service in GO lang and call it from PHP if our main app is written in PHP.
But that means the lecturers are not doing their jobs - they should always make sure their course content is up to date. Find a better university.
Ah I see, I get what you mean. Didn't know that was possible with webpack. I only bring up react because currently I'm thinking of implementing a component type pattern for a side hobby project. For example I want to reduce the initial load time and be offline ready. So when the visitor reaches the page it only loads that template component for that page, and then caches what it needs at that time only. It doesn't load the unused components because they aren't in the main.js . Then if needs comes for a new page, bringing in a template for image gallery and plugging it in to the head script or load it as a blob, and use the new Cache api to store it for future. This way it will help plug it into React and be offline first ready. The problem is that React will be in a closed off webpack namespace. So in that sense I don't want to load 5 different components which I don't plan on using. Unless i'm on a particular page that needs it (image gallery, chat, progress bar, etc). What do you think the solution for that should be, is it still a bad idea to have React be accessible in the global namespace? Since the new components are going to need the react and reactDom. Things I plan on using for this is Service Worker, IndexedDB, Cache API(MAYBE), and React. Not using any jQuery at the moment. Any help or suggestion is appreciated.
Ahh! AJAH. You know there're javascript templating libraries right?
This. Though anyone teaching it who is passionate about it will keep up with trends. But if you go somewhere to learn it, they'll teach the basics, ideally they'll teach you how to think in order to accomplish something. I think if you're starting off, a course/class would be a good starting point to help grasp concepts and fundamentals, beyond that. Just try and make something, run into an issue, come and ask here or ask Google, or SO. Chances are someones had the same problem before and the answer is out there.
&gt; It doesn't load the unused components because they aren't in the main.js &gt; What do you think the solution for that should be, The simplest solution is to splitting elements to be loaded separately per page is to use the 'entry' config entry to defined different app entry-points and also use the vendor setting entry: { frontpage: '../public/js_src/frontpage.js', images: '../public/js_src/images.js', vendor: ['react', 'react-dom', 'shared'], }, That would define two separate entry points into the app, which is what Webpack uses for figuring out what needs to be brought in and compiled, as well as one vendor library that common Javascript would be extracted to. Inside frontpage.js and images.js you would pull in just the functionality appropriate for that page. You could load that on each page like front page script tags: &lt;script src="/js/vendor.js"&gt;&lt;/script&gt; &lt;script src="/js/frontpage.js"&gt;&lt;/script&gt; Image gallery script tags: &lt;script src="/js/vendor.js"&gt;&lt;/script&gt; &lt;script src="/js/images.js"&gt;&lt;/script&gt; i.e. the large block of library code that needs to be available everywhere would be shared. &gt; is it still a bad idea to have React be accessible in the global namespace? Meh. I just haven't needed it, and seeing as all of the React stuff needs to be pre-compiled to turn the JSX into real Javascript anyway, I don't currently see how it would be useful; as opposed to having jQuery be global, where I can see that being able to do little jQuery calls here and there from Javascript to the page is quite useful. btw you can also manually export any functionality you want from within the webpack compiled javascript itself, just by exporting to the window object by hand. window.moment = require('moment'); btw I think you would need a lot of elements to make splitting the JS up into components and only bringing the page specific ones in. What we're seeing is that each component is pretty small (like about a kilobyte of Javascript), so even if you had 20 different components on a website, having them all available at once adds only a tiny bit of size overhead, and reduces the complexity of managing the JS much more significantly. 
It's not mentioned in the blog post, but the stats exclude CI systems, if they set the `CI` environment variable. For example, installations from Travis CI do not impact these statistics.
&gt; Don't u think that if it would stupid, not so many languages would have it? i) https://en.wikipedia.org/wiki/Argumentum_ad_populum ii) No. The cognitive overhead of using overloaded methods is immense compared to how much it would cost to be explicit about what you want the code to do. I hated having to try to read Java code that uses method overloading as you need to stop and think about the variable types, rather than just being able to see the code.
**Argumentum ad populum** In argumentation theory, an argumentum ad populum (Latin for "argument to the people") is a fallacious argument that concludes that a proposition is true because many or most people believe it: "If many believe so, it is so." This type of argument is known by several names, including appeal to the masses, appeal to belief, appeal to the majority, appeal to democracy, appeal to popularity, argument by consensus, consensus fallacy, authority of the many, bandwagon fallacy, vox populi, and in Latin as argumentum ad numerum ("appeal to the number"), fickle crowd syndrome, and consensus gentium ("agreement of the clans"). It is also the basis of a number of social phenomena, including communal reinforcement and the bandwagon effect. The Chinese proverb "three men make a tiger" concerns the same idea. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/PHP/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
What is the best way to store config information (credentials, paths, etc)? Google search tells me either in a file as an array or in a custom ini. But which way is better? Does it depend on the usecase? What are the pros and cons?
Or **the** rapid development framework CakePHP for that matter :)
choosing the living among the dead
We use either environment variables, or config files (YAML), depending on services. IMHO envs are good for dedicated servers, and config files for where services share hosts. Pros for envs would be that they can be defined close to where the servers get created from (ansible/docker...), and cons would be possible collisions.
This if by far in the top 5 best comment reply I received on reddit this whole year. Thanks for the detailed reply, greatly appreciated. &gt; btw I think you would need a lot of elements to make splitting the JS up into components and only bringing the page specific ones in. What we're seeing is that each component is pretty small (like about a kilobyte of Javascript), so even if you had 20 different components on a website, having them all available at once adds only a tiny bit of size overhead, and reduces the complexity of managing the JS much more significantly. You're right about that, the reason I wanted to experiment with that was to trim the fat. Goal is to have a fast first paint with offline first done with and something to show already on the screen, with the small bundle/main.js already ready (with any possible cached data from Service worker, indexedDB, and Cache). Essentially offline first. Mean while the service worker takes care of the back-end of loading fresh data separately, then when that comes back it would go into reactjs to update the newer content. Some components would barely be used at all for an obscure page, thus it felt useless if the user never even visits that page on their first visit. You're right though, I might just end up scrapping the idea of code splitting of obscure components. It might not provide that much of size difference. I was also think of doing a short test run experiment with Rollup js, just to see it in action. Oh well. **TLDR:-** Your comment is in my top 5 of best reddit reply comments for this whole year. Thanks.
There is this project that should do the frontend validation: https://github.com/formapro/JsFormValidatorBundle But I don't have any hands-on experience with it.
I've just released [colinodell/json5](https://github.com/colinodell/json5#json5-for-php---json-for-humans), a UTF-8 compliant JSON5 parser for PHP. JSON5 extends JSON to allow comments, trailing commas, single-quoted strings, and more. Check it out and let me know your thoughts!
nice, it's good to see upgrades so quickly. Back in the day it took ages.
"progressive web app" what does that even mean