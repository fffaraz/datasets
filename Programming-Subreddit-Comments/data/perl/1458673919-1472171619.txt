Other languages are much more strict about this than Perl, they would just throw an error instead of issuing a warning.
&gt; Can someone explain this, please? I'll have a go. I hope it makes sense. :) Note how, in your question, you indicate you want an explanation about something, namely "this", but you do not say what it is. Perls incorporate an analogous "this" feature via a variable called `$_`. (Some folk call this variable "it"). This (ahem) is half the story. Continuing... &gt; Or tell me where to find a good explanation? Note how you again indicate you want an explanation. But this time you don't indicate that it's about something at all. We just know because we know an explanation is always an explanation of something. So it is with Perl*. If you don't give an argument to a built in function that clearly needs one it normally assumes "this", whatever this happens to be at that point in the code. * Perl as in Perl 5. Perl 6 supports the "this" concept but requires that any use of it is made (quietly) explicit: while read-a-line() { .print } # note the prefix `.` in `.print` 
Yeah apparently this version of AIX only goes to that version of Perl. Banks are finicky when it comes to software. Has to be bulletproof. 
If this is in a subroutine (and everything should be in subroutines ) ( and subroutines should be short, and do one thing) then you can exit early unless requirements are satisfied. my %VALID_UPD_CATS = ( C1 =&gt; 1, C2 =&gt; 1, C3 =&gt; 1 ); sub keeprow { my ( $upd_cat, $updated ) = @_; return unless $upd_cat; # handle case of undef or empty string return unless $VALID_UPD_CATS{$upd_cat}; return unless $upodated == $today or $updated == $yesterday; return 1; } while ( my $line = &lt;$fh&gt; ) { my @fields = my_line_parser( $line ); print_record( $outfile, \@fields ) if keeprow( $fields[$field_x], $fields[$field_y] ); }
You know you're dealing with a company on the bleeding edge when their email newsletter uses a table-based layout that falls on its nose on mobile devices.
I think a PAUSE/BackPAN admin once said that a couple of times there have been requests (IIRC corporate/copyright related) to delete some files/releases from the BackPAN, and the BackPAN administrator complied. Perhaps someone could confirm this?
&gt; And were a critical package actually deleted by someone, we have BackPAN, GitPAN, and dozens of slow-refreshing mirrors. We wouldn't need to take NPM's "an unprecedented step" to restore order to chaos. The system would've worked fine for awhile, and the breakage would be restricted to telling people to specify an actual package URL to the cpanm client. heh, not being able to install anything that depends on the deleted modules is an interesting redefinition of "[working] fine". Far as I'm aware, the cpan situation would be just as broken as npm if a key dependency was removed from the index?
I feel like the perl6 team sort of climaxed early. There was a lot of hype when rakudo was released at Christmas, but it was released in a basically toy-like state. Now I've heard that perl6 isn't *realllly* getting released until this coming Christmas.
Hiya! It's actually really, really simple. Just call update with a string containing emoji. Here's my script: #!/usr/bin/env perl use strict; use warnings; use Data::Printer; use utf8; use Net::Twitter::Lite::WithAPIv1_1; my $client = Net::Twitter::Lite::WithAPIv1_1-&gt;new( ssl =&gt; 1, consumer_key =&gt; 'CONSUMER KEY', consumer_secret =&gt; 'CONSUMER SECRET', access_token =&gt; 'ACCESS TOKEN', access_token_secret =&gt; 'ACCESS TOKEN SECRET', ); my $emoji = "ðŸ˜¸ ðŸ˜¹ ðŸ˜» ðŸ˜¼ ðŸ˜½ ðŸ™€ ðŸ˜¿ ðŸ˜¾ "; my $result = $client-&gt;update($emoji); p $result; I copied the actual emoji string from http://getemoji.com/ (Note that "use utf8" allows me to put UTF-8 characters -- in this case emoji -- directly into the script. If you don't include that, the UTF-8 string gets interpreted as iso-8859-1 with some weird bytes, and you don't get the desired output.)
What makes it hostile?
Another example would be Jenkins from Hudson due to Oracle Suckitude.
&gt; A hostile fork is one created with the intention of usurping the established repository. yes, the evil gloating world domination plans in the DOM::Tiny docs were a dead giveaway
So, some people want a DOM parser that is independent from a web framework. What is the less "hostile" option? 
I don't think it's terribly "hostile" in the sense of the word. I think that's just a term for it based on previous OSS spats. The less "hostile" option would be to rewrite it from the ground up. Or to suggest to the original package owner that it should be split out and depended upon.
&gt; The less "hostile" option would be to rewrite it from the ground up "the biggest problem is that it takes resources away from ongoing Mojo::DOM development" solution: write a new module from scratch, that'll fix everything =) As for splitting it out, that'd be great but I'm sure the author would have mentioned that option in the review, if he'd been amenable to it.
Haha! I completely agree. [XKCD on Standards](https://xkcd.com/927/) I must say, I neither agree nor disagree with this particular forking. I honestly don't know enough about it's background or the folk responsible. It's usually the case (may not be here) that while there are collaborative and amicable agreements to be had, they may either not be happening at a desired pace, or there may be a slew of mitigating factors. I was merely stating what a hostile fork is from a high-level view of collaborative &amp; community-based coding. As you very astutely point out, there are always reasons for both sides of the argument. I'd wager those reasons always have merit to the parties involved even if a wider audience may be left scratching their heads. EDIT: Attempted to English a little better with the addition of the word 'are'. As you can see, it made a wonderful and welcome addition to the cadence, flow, and coherence of my babbling response.
[Image](http://imgs.xkcd.com/comics/standards.png) [Mobile](https://m.xkcd.com/927/) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini\-USB\. Or is it micro\-USB? Shit\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 2677 times, representing 2.5561% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d1d5hhw)
The original author is definitely *not* amenable to splitting it out.
B::Utils was a recent hostile fork, done by a completely incompetent manager, who persuaded modules@ that a critical doc needs to be fixed (it was a typo), while we, the developers, thought about how to fix the mess from core upstream. There was never any communication. Well, after the fact the involved crowd started lying all over to cover it up. And I know what happens when you start criticising the cabal, so I couldn't say anything. So they have now a module which breaks the API (and isn't managed properly), and I had to upload the original module as B::Utils1 with the proper fixes. So as user you can either keep the name and deal with additional work to deal with the different API, or use a new name. Go figure. Much worse than this example.
I still believe that to be true. CPANRatings has not helped at all with the situation, and we resolved our differences on IRC instead.
Actually it takes about 24hrs from when you break a key piece of infrastructure before people yell at you. I know from [experience](http://chris.prather.org/breaking-cpan.html).
Just a counterpoint to this -- just last week we skipped Mojo::DOM in favor of a less elegant solution using HTML::TreeBuilder for precisely this reason. We are a sizable and mature application. I like Mojo a lot and use it for lots of auxiliary stuff, but we are not going to install a bunch of other cruft into application servers that don't need it. If Mojo were to modularize their distribution and guarantee that useful submodules like the DOM parser would be usable separately and not have interdependencies introduced we would be very excited. 
I just did a quick check of the size of the HTML-Tree and HTML-Parser distributions, and together they are approximately the same size as Mojolicious, with the additional drawback that HTML-Parser requires a C compiler.
Dude, use a Compose key. WinCompose works on Windows. *nix has native support.
The Compose method is fine and dandy for characters that aren't frequently used, but it's lacking for those that *will* be used a lot (like the new operators) - it's better, in those cases, to have direct keyboard assignments. YMMV, of course.
Agreed, didn't mean to be so hasty, it just sounded like perhaps you were unfamiliar with it. It works for me for operators, but I can see your point. It certainly doesn't work for writing text in alternate scripts. Lately I've been trying to make useful compose sequences for more and more of the new unicode math/technical symbols, and it's getting very difficult... I think I too will need to move to using additional groups soon... but I'll be using XKB (and maybe trying to port the layout to Windows later.)
&gt; And who gets to decide what that "one thing" is? This is of course the million dollar question, and finding the right balance **in general** is incredibly tricky. However, when you consider the specific context (complete async web framework employed for the sole purpose of parsing XML) - the answer "this clearly crosses lines" is beyond obvious.
Well I see I stirred up quite a storm. That was not my intent. I hadn't responded because it's the weekend, and I have a family and don't much care to spend it playing perl politics, but whatever. I am not really interested in the code golf aspect here so it doesn't really concern me how 'big' each dependence might be or the fact that one project might offer additional API calls or some added other function that I don't strictly "need" either. Bottom line is that Mojo is a great project, and I respect it a lot. I also respect your decision to distribute it as a unified package if that makes things more efficient for you. Please also notice that I did not say that I selected a solution using DOM::Tiny. I skipped that because I don't like its origin for the same reason you don't. But the fact is there is a case for breaking it out, and people are going to do it. I think it would be better to figure out how to find a middle ground rather than posting negative reviews and finding reasons to tell me I'm making a bad choice for not using your module. Those things in and of themselves are pretty good reasons to stay away. In our case we are dealing with a legacy mod_perl behemoth and already using HTML::Parser, so this was a decent and safe choice for us; our application does not depend heavily on DOM manipulation; I just needed to reliably extract some inline &amp;lt;style&gt; tags and apply some SCSS transformations to them. I am happy to consider porting all of our HTML::Parser and HTML::TreeBuilder stuff to using Mojo::DOM if it is both performant and more maintainable. You make a good case that at least /right now/ having the extra modules sitting around on the hard drive is not a particularly big deal. But for the sake of argument, let's say you had to install the entirety of mod_perl to get the best DOM parser, would you still advocate for it?
I see your point, and i can assure you that we'd rather split up the distribution than let it grow out of control. At least over the past 6 years Mojolicious has constantly been shrinking, from 11k lines of code in 1.0, to 9k in 3.0, and now 8k in 6.0. Regarding DOM::Tiny, we've found a solution and i've updated my review.
I see your point. But as a Mojolicious user, I can tell you: Installing Mojolicious with its other useful modules is ok. It's ok really. It won't break your other stuff, just because you use a subset. Of course it has the side-effect that after you finished parsing your HTML, you already have the as easy to use JSON parser, or CSS selector or file slurping utils, or trimming utils, or list class or even the way more useful than LWP, UserAgent (with async support and working timeouts). With awesome documentation (Ironicaly docs and tests are the way biggest culprit if you are concerned about size). And you can still continue not using them and everything will be fine. You won't catch anything, (except maybe save time and energy if you end up using more of the available utils)
Thanks for your response and understanding. By the way in some initial testing, the Mojo::DOM implementation benches at 115% faster than HTML::TreeBuilder in this particular task. Though the speed in our case is not of huge importance, the code is more elegant (or at least it seems so after writing a bunch of css and js+jquery) So it's certainly worth us taking a deeper look at moving. True or not, a developer looking for something like a standalone DOM manipulation tool may be to skip Mojo::DOM for these reason that it is simply perceived to be dependent. Even if it's realized that it's usable standalone, there is really no way to determine if such a use case is indended or simply a fortunate side effect (Consider the same thing with some Apache:: modules able be used standalone, others with stubs, and others not at all.) I do now have a lot more confidence that many of the Mojo:: modules are suitable for independent use under an 'alien' framework and they are not in any immediate danger of becoming less suitable for such use. The documentation of course heavily promotes Mojolicious, and although it alludes to the independent use of these modules, it would be very nice to see it stated even more explicitly, and even nicer to see a roadmap indicating that they are intended to be maintained that way, at least for the immediate future.
Thanks, but when I paste this into my notepad++ or to vi on my linux machine I get blocks rather than emoji characters. The program runs but is there a way I can actually see these characters in an editor?
I like the change in name from YAPC it makes the whole thing sound so much more respectable. YAPC was a good joke 17 years ago but has always caused me problems. Me: Hi boss, I'd like to go to YAPC Boss: What's that? Me: Well it stands for Yet Another Perl Conference Boss: MmmMmmm vs Me: Hi boss, I'd like to go to The Perl Conference Boss: Sounds good where is it and how much does it cost? Me: Well, Transylvania, cost about Â£450 Boss: That's not bad for a computer conference how much for the travel and hotel? Me: that includes the travel, hotel, conference dinner, free beer, coffee, lunches and a three day, four track schedule of talks Boss: can I come? 
The goal is stated on the [frontpage](http://mojolicious.org) and in our [mission statement](http://mojolicious.org/perldoc/Mojolicious/Guides/Contributing#Mission-statement).
Ah you got it! Installed feh and it worked as intended. Strange that it needs that kind of tool to work right admittedly, but at least its working now, and into a cronjob it will go! Thanks!
Nice! I have mine in cron as well. You can change the default list of subreddits by making an environment variable pointing to a file: REDDIT_WALLPAPER_SUBREDDITS=~/list_of_subreddits.txt /path/to/reddit-wallpaper
&gt; I fully expect to be able to apply security updates, to benefit from performance and correctness improvements, and to stay in general up-to-date. All of this with the complete expectation to not have to change any of my code in the process You left out the part where you expect others to support you to your satisfaction, on your schedule, to your timeline, to your definition of "obvious unquestionable need" for free. I find *that* attitude to be the reason that I personally have been giving away maintainership on my modules. I have no desire to spend countless hours on backwards compatibility concerns I consider useless at best and actively harmful at worst. For free, especially with a post hoc justification I never, ever, ever agreed to when I released them under a permissive license.
I've only used C/C++ in the browser, not other languages, but there you can either inline javascript (like assembly), call to an external javascript function to do the work, or use an iterator-style API to traverse and manipulate the DOM yourself, which is not too dissimilar from how you would do it in js in the first place. You also get direct access to drawing on canvases, webgl, etc
I have something on my media center PC that rotates my login screen through a series of pictures. The perl part is two lines so I'll show it here just as an example: my @images = glob '/usr/local/backgrounds/*'; print $images[rand $#images]; Obviously it could be written in just about any language but I chose perl because I like it. The point being though that this code works if I want to use the background for a login screen or an X11 background, or an android wallpaper. My suggestion would be that you split your tool into a couple of tools. A fetcher and a displayer, so you have more flexibility down the line. Second point. Some of the code is more verbose than it needs to be, but it may be your personal preference. $output_prefix = $ENV{REDDIT_WALLPAPER_OUTPUT} if defined $ENV{REDDIT_WALLPAPER_OUTPUT}; $output_prefix = "/tmp/reddit-wallpaper-$$-" unless defined $output_prefix; You can change this to be $output_prefix = $ENV{REDDIT_WALLPAPER_OUTPUT} || "/tmp/reddit-wallpaper-$$-"; Or you can say: $output_prefix = $ENV{REDDIT_WALLPAPER_OUTPUT}; $output_prefix ||= "/tmp/reddit-wallpaper-$$-"; Most of the time if (defined) is unneeded. A simple if ($variable) might be enough, or it may be that if (defined) doesn't do enough of a check for whatever you want. http://perldoc.perl.org/functions/defined.html I don't want to complain though. Your code is very clean and they might be style choices. They just stuck out to me because I refactor them out when I'm cleaning up my own code.
I have found no advantage in maintaining a plan for the number of tests. I use done_testing(): use Test::More; ok(1, "some test"); done_testing; This catches premature death and allows one to have variable numbers of tests (skip) without having to know ahead of time. The exit code comes out correctly. It does not, in itself, catch dead test code, but that is something a coverage report can supply, in addition to covering the actual code being tested.
Have you poked the maintainer about this? I've found him to be extremely responsive in the past. The module had a release just a couple of weeks ago. It's not like it's abandoned.
Both your and /u/therico's questions are answered in my blogpost. Anyway, [Coro doesn't support Perl 5.22+ and the maintainer refuses to fix it](http://lists.schmorp.de/pipermail/anyevent/2015q2/000750.html). He has his reasons, but still, it doesn't work.
&gt; backwards compatibility concerns I consider useless at best and actively harmful at worst Could you please elaborate on this? I honestly can not even begin to speculate what you consider a negative in the context of backcompat.
Releasing code in 2016 that must run on every stable version of Perl released since 5.8.1. That's actively harmful, and I'm not debating it again.
I also think this is the best approach and use it all the time.
Is this a Perl5 or Perl6 conference? or both?
lol Thank you very much! :) For reference(to those who come after): the 'disbatch' table I was able to find so far is: @commandtable = ( {'show version' =&gt; 'ShowVersion'}, {'show flash' =&gt; 'ShowFlash'}, {'show system-information' =&gt; 'ShowSystem'}, {'show system information' =&gt; 'ShowSystem'}, {'show module' =&gt; 'ShowModule'}, {'show stack' =&gt; 'ShowStack'}, {'show tech transceivers' =&gt; 'ShowTechTransceivers'}, {'show config files' =&gt; 'ShowConfigFiles'}, {'show config status' =&gt; 'ShowConfigStatus'}, {'show power brief' =&gt; 'ShowPowerBrief'}, {'write term' =&gt; 'WriteTerm'} ); 
I also used to specify plan (number of tests), even so far as going into the trouble of calculating the plan dynamically. But the hassle of having to keep the plan updated finally made me to switch to `done_testing`. 
Hmm. It depends on your editor. I tend to use vim via gnome terminal, and that just works. As per http://superuser.com/questions/21135/how-can-i-edit-unicode-text-in-notepad , have you tried setting encoding in Notepad++ before pasting? It looks like it defaults to ANSI mode, which won't support UTF-8.
I'm slowly starting to think that maybe that's what needs to happen. I'm not happy about it... but the separate language thing doesn't seem to be working either. I'm very attracted to making cross-language library reuse very natural (in all languages, but Perl6 makes it easy), so maybe that'll eventually work. Or maybe I'm just being impatient :)
I'll apply then :) I've been spending most of my free time learning Haskell for the past 4 months. But everyone still needs a scripting language. And Perl is nicer than Python in my opinion.
There are lots of results for "CL": https://metacpan.org/search?q=CL Could you be a bit more specific ? Could you post the code on pastebin ? 
I can't, I am not even sure what licensing is used, it just says "all rights reserved".
You can use perl to find out where the module file is: $ perl -e 'use CL; print $INC{"CL.pm"}."\n";' This will print out the path where the CL.pm module is, if it can be found on your system (which it should be if the original script runs). One thing to check is whether the script makes any modifications to @INC or has any "use lib ..." statements, as these augment the paths where perl will search for modules. Once you locate CL.pm, you can peek inside to try to figure out what it is/where it came from.
I do not want to debate this either, but I **do** want to understand your position. [Not too long ago](https://www.reddit.com/r/perl/comments/3fx3cg/visualizing_perl_5_release_history_2015_edition/ctvanss) your stance was essentially "what u/ribasushi does is his business", yet just above you sneaked in `That's actively harmful`. I simply want to know, preferably without word-play, which of the two positions do you actually hold. Or in case they are not mutually exclusive in your eye: how do you reconcile them. 
I prefer to have my test data in the code file except in cases where it either doesn't fit or there are multiple data files. In those cases I usually put the data under t/data. Sometimes in subdirs depending on the projects complexity. My preference is to keep the test data in the __DATA__ magic filehandle. My main reason is visual, so you can see and edit both the test code and data at the same time. Thinking about this now, I believe it might be anachronistic since modern IDE's made it easy to open lots of project files. In theory I could just open them side by side and work on them together. But I like using vim so pfffftttt!
Contextual return is one of the biggest problems with Perl, which is a shame, because it's a legitimately useful feature. Unfortunately, since it often ends up interacting with data structures in a way that affects not just it's own value, but those values around it, it can be a real security problem. It's Perl's equivalent to the buffer overflow. I wonder what the difference would have been if fat comma enforced scalar context on the right, as I think contextual return in hashes is the most problematic use from a data integrity and security standpoint. If there was a pragma to enforce that, I would use it (barring some good arguments against it, which might appear).
No, no no! Please, stop this nonsense already! If I sound agitated here it's because I've had to have this conversation so many times already. Here's where everything goes wrong: my @x_results = div(6, 2); if (@x_results) { What's this? The function is supposed to return a scalar value, the result of the division. Why is it assigned to an array? I mean, you can do that if you want to, like if you're collecting many results. But in this case it's a weird scenario cooked up to demonstrate a flawed point. Let me repeat that: when successful, the function is not context sensitive, it always returns a single scalar. This seems to be the same confusion as that unfortunate chapter in Perl Best Practices which also comes to the entirely wrong conclusion (please read it again if you have the book handy). Here's the bottom line: functions should not be context sensitive *some of the time*. If it wasn't context sensitive for the successful case, then it should not suddenly become context sensitive for the failure case, and undef is a perfectly fine value to return for that case. Nowhere is it demonstrated why returning undef/empty list is actually *better*; what problem it solves. As we can see by reading on about all the workarounds, the only thing it leads to is more brittle code.
&gt; Well, I assume logic is about the same in every language, an if statement is an if statement, no changing that True, but I find most people mistake where that ends and extend the concept to things that don't apply in Perl. Specifically, context and assignment utilizing context. If the example code you are looking at doesn't use it, then it will be obvious, but if it does and you are unfamiliar with it, you'll have some reall head-scratching moments. Specifically, if you see places where hashes (%foo) are used on the left hand or right have of an assignment, or as arguments to a function, then you want to understand what's going on. The same can be said for arrays (@bar), but at least in that case you might intuit the right thing from array use in some other languages. The quick and dirty primer is this: Hashes act as lists of individual keys and values when used in list context. So: my @a1 = ( "a", 11, "b", "22" ); # Array of four items. my %h1 = ( "a" =&gt; 11, "b" =&gt; 22 ); # Hash of two keys (a,b) and their values my %h2 = @a1; # %h1 and %h2 have equivalent contents. Knowing that "=&gt;" is equivalent to "," with some formatting niceties helps here. my @a2 = %h2; # @a2 has equivalent values to @a1, hashes used in list context spit out a list of alternating keys and values, *but not necessarily in the same order they were defined*. If you understand that, most the rest can be intuited well if you know another imperative language.
This. I had to stop reading that article when they started blaming the weirdness they got assigning a hash in array context. As if that had ANYTHING to do with a return value...
Great presentation that is easy for this beginner to follow!
The more I see perl 6 code, the less I like the syntax, to the point where I find myself with no motivation to even experiment with it. Given I'll pick up and fiddle with lots of languages "just because", that's odd. I *like* the features they've added, and can see all sorts of use cases, just not the syntax.
broken link within the page.
I know what you mean. Perl 6 feels too much like APL looks to me. I feel way more inspired by some Lisp dialect than by Perl 6. There are really many language constructs one must learn and not some basic one where everything emerges around. One could argue, that Perl 5 was/is the same, but it's syntax &amp; semantics are much simpler and only weird if you concentrate on the corner cases. Maybe it's a problem with Perl 6 presentation. They focus on the most exciting parts of Perl 6 to justify the existence of yet another over designed scripting language rather than presenting the ultimate basics of the language. For example on how it solves real world problems better/easier. Like simple data shoveling scripts that interfaces two databases. And I don't talk about over designed one line solutions no junior developer that comes after you will understand in a day. And how will I be able to use the vast module base of CPAN for solving daily administrative tasks or write a simple e-mail notifier when a website changes something for my girlfriend (did this once with perl 5 to track some special offer). These were the strengths of Perl 5. Solving boring tasks in a simple and understandable manner, without special unicode characters, was/is Perl's strength and focus. Without all that, it is just a weird language that looks like line noise - and Perl 6 even more so.
yeah, but the link was just supposed to link to the exactly same page you found the link on, so it's not that bad. this is the actual presentation, you have to use the spacebar or arrow keys to go through the slides. that is not obvious from the page at all, sadly.
Thats quite sad, as I first tried to read it on my mobile phone this morning. It sadly has no space bar or arrow keys - but thats an obvious shortcoming on my side - to expect that websites behave like websites. Should've been obvious that Perl 6 is so different ;-)
&gt; And how will I be able to use the vast module base of CPAN for solving daily administrative tasks or write a simple e-mail notifier when a website changes something for my girlfriend (did this once with perl 5 to track some special offer). &gt; Ok so, you didn't watch the presentation, so why are you commenting? Perl 6 is the Perliest Perl ever, and "I don't like its syntax" is pretty confusing given it's extremely similar to 5.
Ha! Nice april fools, the best part was those operators.
Ok we're in internet lala land here where I can't figure out what's real. Come back through the looking glass with me, is this an april fools, nobody would make these features for real...
&gt; and I'm not debating it again. Is there a place you can link to where this debate happened previously, so that we can read it, without necessitating you debate it again?
I wrote [I think supporting 15 years of code and 38 releases is a burden too large to put on volunteers] (https://www.reddit.com/r/perl/comments/3fx3cg/visualizing_perl_5_release_history_2015_edition/ctv8jfj) a while back. That's a short version of things.
I use drop box. This way my script gets updated on my linux host and I can develop it from whatever platform i want and then run it via ssh.
Are you willing to elaborate on your bug reports not being accepted?
You have to ask those you refuse so
The date.
Bugs can be submitted directly to RT, RT relays them to the p5porters mailing list. I don't seem to recall seeing they get blocked when sent that way, but I'm open to being proven wrong.
Indeed, the real wtf is expecting a function that returns one-item by expectation to return no-items and then hoping that does the right thing. The "error" here is not that `if( @x_results )` is true, the error is that the code isn't writing: my @x_results = div(6, 2); if (grep defined, @x_results) { Or similar. Changing it otherwise creates even more work for yourself, with the stupid "die in list context" and "Have to call scalar just to get an undef". Because "have to call scalar" says "Well, you're going to return a list, and I expect that, but I want a scalar instead", and needing that simply because it can return `()` instead of `undef` is just dumb. I am however not innocent of this mistake and I now deeply regret a lot of my own code :( Best practices my ass. 
&gt; You yourself don't care, thus, you don't have to do a single thing. This is only true if your time has no value, and even then it's still incorrect.
&gt; You can literally do nothing other than mentally go "well, I'm not going to care about 5.6 anymore, somebody else can deal with that" and invest no effort. Do you get CPAN smoke reports? Ignoring them is not much effort, but it's not *no* effort. &gt; You don't even have to prove the patches fix 5.6 Why would I apply a patch if I don't know it works as intended? More than that, why would I open the door to *welcome* patches for 40 stable versions of Perl, when the evidence that people are going to send patches for 30 of those stable releases is absent? This hypothetical army of people so devoted to Perl 5.6 could certainly shepherd a 5.6.3 release which builds on modern operating systems if the army so desired. Given the 12 years since 5.6.2 (a release made to fix build issues), I have my doubts that anyone *really* wants that to happen.
Ugh. Thanks.
Technically you're right, but practically you're getting way too upset over this. I'm sure nobody reading kent's comment is in danger of missing the subtle implications.
Niecza was a native .NET implementation, but Rakudo has actually been developed in such a way as to make it really easy to port to separate runtimes. When Jnthn ported NQP (which is the back-end proto-language that Perl 6 is written in) to the JVM, my understanding is that he did so in a way such that the JVM specific portions were abstracted away from the rest of it, so it would be extremely easy to port to other runtimes. In fact, I've never quite understood why Jnthn chose the JVM, since my understanding is that he consults/teaches C# as his main job. Perhaps it was a play to target the most popular runtime.
"JVM languages" definitely have more appeal and traction than "CLR languages", especially in the open-source world. .NET is pretty open now, but it wasn't always so, and I think people remember that. But yeah, back when Niecza was going strong, Rakudo was still on Parrot, which was pretty moribund, and Niecza was actually implementing a lot of features and passing a lot of tests that Rakudo wasn't, although it went both ways to some degree.
Yeah, it was kind sad to see Niecza go dormant. It would be great to see a competitor to Rakudo that could try a few different ways of implementing things, even if it targeted a single runtime (its own or JVM/CLR).
In a similar situation I'm using the XML::RSS module. This code should get you started: #!/usr/bin/perl use strict; use LWP::Simple; use XML::RSS; my $rss = new XML::RSS; my $rssfeed = 'http://feeds.publicradio.org/public_feeds/marketplace-pm/rss/rss'; my $feedcontent = get($rssfeed); $rss-&gt;parse($feedcontent); foreach my $item (@{$rss-&gt;{'items'}}) { my $title = $item-&gt;{'title'}; my $showurl = $item-&gt;{'link'}; my $mp3url = $item-&gt;{'enclosure'}-&gt;{'url'}; print "$title: $mp3url\n"; }
ok, thanks, before I was using split at the \n to read it into @feed, but then I was playing with it and I erased that part. Thanks for the global reminder as well. I dont really understand what you are doing with XML::RSS. I am new at programming as well new at perl but thank you, I will play around with it. 
For XML feeds I really like [XML::FeedPP](https://metacpan.org/pod/XML::FeedPP) bonus: it can work with Atom feeds as well as RSS 2.0 :)
I do hope that's not sarcasm. :)
Thanks!
There are 3 popular ways: if (grep { $_ eq 'flour' } @ingredients) { ... } or: use List::Util qw(first); if (first {$_ eq 'flour'} @ingredients) { ... } or: use experimental 'smartmatch'; if ('flour' ~~ @ingredients) { ... } The `grep` method does not require any module, but does not shortcut after the first match (important if your array is large). In theory perl could perhaps optimize it to shortcut if it detects a boolean context? Or say in the future grep accepts a MAXMATCH option, e.g. `grep 1, { $_ eq 'flour' } @ingredients`, but this is highly unlikely). The `first` method does shortcut, but it requires loading a core module. List::Util has an XS implementation so it should be pretty efficient. The `smartmatch` method does not shortcut (according to the docs), but is fast because perl doesn't have to execute a Perl code (like `$_ eq 'flour'`) for each element. The smartmatch operator has an experimental status. It probably won't be removed in the future, but the behavior might be changed or simplified. Currently it tries to do too much, but as long as you use it for simple case like matching a scalar against an array of scalars, it should be okay. Yup, it's unfortunate that the problem of "checking whether an array contains an item" doesn't (yet!) have a shorter, builtin, single solution in Perl, but there you go. As requested, some benchmarks. I use three kinds of arrays of integers: (1..100), (1..10_000), and (1_000_000). Then I test each array with three kinds of items (the `arg_needle` column): one that matches the first element of the array, one that match in the middle, and one that match at the end. For 100-element array: +-------------+------------+-----------+-----------+------------+---------+---------+ | participant | arg_needle | rate (/s) | time (Î¼s) | vs_slowest | errors | samples | +-------------+------------+-----------+-----------+------------+---------+---------+ | grep | 1 | 2.8e+05 | 3.5 | 1 | 1.3e-08 | 22 | | grep | 100 | 2.8e+05 | 3.5 | 1 | 8.3e-09 | 20 | | grep | 50 | 2.9e+05 | 3.5 | 1 | 6.5e-09 | 21 | | first | 100 | 3.5e+05 | 2.9 | 1.2 | 3e-09 | 25 | | smartmatch | 100 | 3.948e+05 | 2.533 | 1.387 | 2.4e-10 | 20 | | first | 50 | 5.54e+05 | 1.8 | 1.95 | 8.3e-10 | 20 | | smartmatch | 50 | 7.616e+05 | 1.313 | 2.675 | 4.6e-11 | 20 | | first | 1 | 1.9e+06 | 0.51 | 6.8 | 7.8e-10 | 23 | | smartmatch | 1 | 1e+07 | 0.1 | 35 | 2e-10 | 27 | +-------------+------------+-----------+-----------+------------+---------+---------+ For 10k-element array: +-------------+------------+-----------+-----------+------------+---------+---------+ | participant | arg_needle | rate (/s) | time (Î¼s) | vs_slowest | errors | samples | +-------------+------------+-----------+-----------+------------+---------+---------+ | grep | 5000 | 3.1e+03 | 3.3e+02 | 1 | 1.2e-06 | 20 | | grep | 10000 | 3.08e+03 | 325 | 1 | 2.5e-07 | 22 | | grep | 1 | 3.1e+03 | 3.2e+02 | 1 | 1.8e-06 | 20 | | first | 10000 | 3.9e+03 | 256 | 1.27 | 4.6e-08 | 27 | | smartmatch | 10000 | 4084.41 | 244.833 | 1.32866 | 9.3e-11 | 20 | | first | 5000 | 6.77e+03 | 148 | 2.2 | 5.3e-08 | 20 | | smartmatch | 5000 | 7878.02 | 126.935 | 2.56273 | 1e-10 | 20 | | first | 1 | 4.8e+04 | 21 | 16 | 1.1e-07 | 23 | | smartmatch | 1 | 1.05e+07 | 0.095 | 3.42e+03 | 9.3e-11 | 27 | +-------------+------------+-----------+-----------+------------+---------+---------+ For 1mil-element array: +-------------+------------+-----------+-----------+------------+---------+---------+ | participant | arg_needle | rate (/s) | time (ms) | vs_slowest | errors | samples | +-------------+------------+-----------+-----------+------------+---------+---------+ | grep | 500000 | 29.3 | 34.1 | 1 | 2.5e-05 | 22 | | grep | 1 | 29 | 34 | 1 | 4e-05 | 20 | | grep | 1000000 | 29.7 | 33.6 | 1.01 | 1.8e-05 | 20 | | first | 1000000 | 34 | 29 | 1.2 | 6.7e-05 | 20 | | smartmatch | 1000000 | 40 | 25 | 1.4 | 3.1e-05 | 20 | | first | 500000 | 60 | 17 | 2.1 | 4.4e-05 | 21 | | smartmatch | 500000 | 80 | 12 | 2.7 | 1.9e-05 | 20 | | first | 1 | 2.2e+02 | 4.6 | 7.4 | 4.1e-05 | 20 | | smartmatch | 1 | 1.1e+07 | 9.2e-05 | 3.7e+05 | 1.5e-10 | 20 | +-------------+------------+-----------+-----------+------------+---------+---------+ The benchmark code is at https://github.com/perlancar/perl-Bencher-Scenarios-PERLANCAR/blob/master/lib/Bencher/Scenario/PERLANCAR/In.pm and you can run it yourself by installing bencher and typing `bencher -Ilib -m PERLANCAR::In`. Even though it shortcuts, the `first` is not that fast, probably because of the overhead of passing a million of arguments at every call. And it looks like the smartmatch operator does shortcut. **EDIT**: Rephrase, add note about shortcut behavior of smartmatch. Add some benchmarks. **EDIT**: Update/reorganize benchmark results. 
From the perl faq &gt;Hearing the word "in" is an indication that you probably should have used a hash, not a list or array, to store your data. Hashes are designed to answer this question quickly and efficiently. Arrays aren't. 
That seems wrong to me. If you want to know if an item exists then a map may be better. If you want to know if something is in an array, it may be possible for it to be in it multiple times, where a hash would not work. 
&gt; is not efficient because it does not exit early after the first match I just want to caution the reader to benchmark, and don't assume. Perl always surprises me in that it does not consistently behave in a manner that I would expect algorithmically. I actually found "grep" to often be a faster alternative to "first" in the benchmarks I was running for simple equality checks. For a small list, the difference in speed is super minute and brings to mind Knuth's commentary on optimization. But if the predicate is more complicated (e.g. queries a database), "first" is a clear winner. 
As much as I like Perl5, the article makes no sense. Perl6 is far from battle-tested and everybody should have learned in CS101 that equality is not well defined for floatpoint numbers.
You're overlooking that the implementors have so far been chasing a huge moving target. Optimization is fine and all, but hard to do when what you need to do can change from week to week.
Yes, but keep dreaming. Rather look at the broken rakudo architecture why perl6 can never be fast. You could make the perl6 multidispatch model fast with well-designed modular boundaries. But it was not designed this way. The whole ABI is not designed to run fast, neither the compilation and run-time loading model. Or look at the insane bootstrapping model. Only guile is slower, but guile has a proper compiler and VM runtime instead, which guarantees fast execution after those insane bootstrapping quirks. You could make strings fast with a proper string and ownership model. Only unicode grapheme alternations (NFG) were designed properly, the rest not. You could make numeric arithmetic fast with a proper numeric tower and fast dispatching to overflowing variants as in fast dynamic languages with automatic overflow to bigint, bignums. They did not. Every perl6 integer starts as a bigint. You could make concurrency on multiple CPU cores fast, but not with the moar nor jvm backends. They decided to use the old-fashioned secure slow locking strategies, and not modern ownership models to guarantee lock-free threading (as in parrot, rust or pony). You could have made the grammar execution (the dynamic parser) fast if you would have designed it this way. Now it's too late. You'd need a luajit engine to get around this, but moar is no luajit. There are lot of wrong design decisions in rakudo, and these will not go away by optimizing away within rakudo itself, as promised in this post. It runs, but it will never be fast enough. But honestly, nobody cares about performance. Only the worst implemented languages with the biggest feature sets and loudest fanboys do succeed. So perl6 does have a chance in history.
BTW, since Perl supports lexical scope, you don't have limit yourself with function-local variables. You can define variables at any block level, as needed. sub do_some_stuffs { my ($arg, $arg2, $arg3) = @_; # do stuffs A { my $i = 0; while ($i &lt;= 10) { ... } } # do stuffs B { my $foo_tmp = another_func(...); my $bar_tmp = map { ... } @$foo_tmp; ... } .... } This way, variables' scopes are kept to a minimum to make the code cleaner. This is especially useful if you happen to have a larger function that needs to be organized to several sections.
But it *was* pushed out the door in a hurry. You're overlooking that in those 15 years, several implementations were tried and there were social upheavals. 
Then I hope perl6's startup will be at least near ruby's. % time ruby -e1 real 0m0.021s user 0m0.016s sys 0m0.004s % time perl6 -e' ' real 0m0.202s user 0m0.164s sys 0m0.032s Still a long way to go though. Lots of stuffs are still happening at startup. As a comparison: % time perl -e1 real 0m0.006s user 0m0.000s sys 0m0.004s BTW, even Perl 5's startup times are worsening from version to version, but they are still below 2-10ms on my computers generally.
Exactly what do you base that projection on?
One thing I go by is that routines should be short. I like to invoke a number of functions, rather than have a long block of code. That makes it possible to re-use a routine, if I find a need for it elsewhere, and provides a degree of abstraction and documentation. So most of the time, I have parameters and a very small number of local variables. For example, I'll have a routine processAllDrizzles(), which contains a loop which invokes processOneDrizzle(). At some point you reach a level consisting of actual code, rather than routines.
&gt; You'd need a luajit engine to get around this, but moar is no luajit. Sometimes I think "Parrot gets an excuse for having the wrong initial design of a VM, where 'Lots of ops, all written in C for speed' is clearly nonsense", because Parrot began before Javascript proved that this approach wouldn't work. Then I remind myself that Smalltalk had already proven that this approach wouldn't work. Perhaps someday MoarVM will get past the idea that JITs are magical and address this design flaw.
&gt; You're overlooking that in those 15 years, several implementations were tried and there were social upheavals. "We're really going to focus on optimization now, this time we mean it" has been the story with every release since the first Rakudo Star release in July 2010. Five and a half years of this promise is a long time.
Why would I defend a claim I never made? Did you intend this as a response to someone else?
&gt; Disadvantages &gt; &gt; Can potentially accidentally use a declared variable before you intentionally assign a value to it (and thus breaks a "best practice"). Can use more stack than you need if the function exits early. Another disadvantage is that if you refactor out a part of your code you may not notice that variables are now unused. The closer a variable is to it's use the more likely it is that you'll catch it's un-use (or miss-use). Of course, cleanup tools can help with this. Code coverage or just a compiler that can figure out if a variable is never called, but it's sloppy to leave it up to an analyzer when you can easily remove it while taking out a block.
Would that mean I'm loading more things into memory? Just curious. 
Kind of unfair to do that specific comparison of Perl 5 and Perl 6... Just try `time perl -E ''` and see the difference. Do something more representative like `time perl -MMoose -E ''` and its far closer to reality. For example on my laptop: $ time perl -e '' real 0m0.006s user 0m0.003s sys 0m0.003s $ time perl -E '' real 0m0.068s user 0m0.004s sys 0m0.012s $ time perl -MMoose -E '' real 0m0.388s user 0m0.257s sys 0m0.048s $ time perl6 -e '' real 0m0.239s user 0m0.191s sys 0m0.039s If you want Perl 5 the scripting language without any kind of OOP sugar or modern features then sure its fast to startup. But awk is faster still and has about the same use case as Perl 5 without Moose in the post 2010s: $ time awk '' real 0m0.004s user 0m0.002s sys 0m0.002s Ultimately we need to not forget Perl 5 is right there. Using Perl 6 doesn't make it magically vanish. If you need or want fast startup time then sure stick with Perl 5, in the same way you wouldnt pick the JVM backend of Rakudo either which is slower still.
I ended up going with smartmatch, thanks for your detailed reply
Two things... the trailing `.*` isn't neccessary. And... couldn't you re-write this as: my ($price) = $record =~ /.*Â£(\d+\.\d+)/ Is the tertiary really required? It seems like it makes it harder to read.
Unsure if there is a nice way to do it in a single step, but you could do something like: my ($price) = $record =~ /(Â£\d+(?:\.\d+)?)/; $record =~ s/\Q$price// if $price;
using `perlcritic` helps tracking unused variables! âž¤ cat bar.pl #!/usr/bin/env perl use strict; use warnings; my $foo; my $bar = 2; print $bar; âž¤ perlcritic bar.pl [Variables::ProhibitUnusedVariables] "$foo" is declared but not used at line 4, column 1. (Severity: 3)
&gt; the trailing .* isn't neccessary. True, it was written quickly without much thought given (5am after working all night). It's a 30-second knee-jerk reaction of an answer to the question as it was asked, I didn't spend much time actually thinking about it. &gt; Is the tertiary really required? It seems like it makes it harder to read. Probably not necessary, although I might disagree about the readability issue: The ternary makes it a bit more explicit that $price is either going to get a matched value or be undefined (particularly to someone less familiar with what Perl might do if a match isn't found). That said, I can definitely see why one might disagree with that logic.
You are correct, although strictly speaking returning both a scalar and a list is fine as long as there is only one list and it goes last. Instead of sub getstuff { ... return $num, \@things; } my $quantity, $arrayref = getstuff(); one could also do sub getstuff { ... return $num, @things; } my ($amount, @items) = getstuff(); much the same way we slurp subroutine arguments from @_.
I (almost) always pass around arrays as references. Passing an actual array means copying the values. That's fine when you have a few dozen numbers, but if you have a million long strings, the time adds up. So I would probably return a list consisting of a scalar and an arrayref. If the two are meant to be used together, I might bundle them into a hash.
Not specific to perl but some thoughts on the Chromebook: I have a chromebook. I started out using crouton to run linux when I needed it. ChromeOS has some promises that never delivered. Like the lack of samba support for local LAN meaning you needed to jump through big hoops to browse local content. I was looking forward to android apps under chromeos because that would let me run ES file explorer and do SMB, but I never got that working. At some point I decided I needed the space so I deleted crouton but decided I could dual boot with Linux on an SD card and ChromeOS on the internal. This worked for a few days, but SeaBIOS would occasionally not see the SD card and just boot straight to ChromeOS (not sure why, maybe a flakey SD card). Then ChromeOS bricked one day without explanation. Just would not boot from the menu. At that point I decided I'd be better off running Linux directly. I've been happy ever since (aside from small hardware compatibility issues I haven't solved with hibernating yet) Cons: shitty default OS, required disassembly to remove screw to permanently get rid of BIOS warnings Pros: 9 hour battery life, 802.11ac radio, fast boot, weighs less than 1 pound, cost $200
&gt; awk is faster still and has about the same use case as Perl 5 Hmm
That is pretty clear, so thanks! I'll have to give it a whirl after I read the Perl OO chapter in my book. I figure its better to start with the old school method so I can at least understand some libraries from CPAN that use it.
Thank you! I'll remember that point.
It might have to do with going from my $neln to my $part = substr($stack, 0, (length($stack) - *$nlen*));
You should start your code with: use strict; use warnings; That will help catch any errors with incorrect variable names (amongst other things). my $part = substr($stack, 0, (length($stack) - $nlen)); `length("123")` is **3** while `length("23")` is obviously **2** - this means you're setting `$part` to `substr($stack, 0, 1)` which is `1`. This means you're doing `return "1" eq "23"` which is obviously false...
The arguments to [substr](http://perldoc.perl.org/functions/substr.html) are EXPR,OFFSET,LENGTH,REPLACEMENT (with the last two being optional). So I think you want: my $part = substr($stack, (length($stack) - $nlen)); You can make it a bit simpler by using a negative offset (which measures from the other end of the string). my $part = substr($stack, -length($needle));
okay guys, thanks for the help. I fixed it.
Is there a reason to avoid the built-in [index()](http://perldoc.perl.org/functions/index.html) function?
There's a little bit of Perl in there, but I'm most impressed that there's a pipeline of processing rather than a monolithic program that does the whole thing. Many big jobs can benefit from multiple languages when each can apply its strengths to a narrow part of the whole task.
It's just faster to do it that way when you have a big list. It's not like they had to categorize 50 coworkers they all knew. There were many hundreds, I'm sure. They really dressed up the name though like it is some piece of magic... I don't even do this sort of thing and I have at least three applications on my computer that can assign likely genders to a list of names. 
&gt; I pritned out the values I was passing intot he sub (which were blank) How did you do that? They aren't blank, they had the correct values. Do you see now how printing the values that you were comparing is the most useful debugging tool? I know not everyone likes it, but I think it's well worth getting to grips with the [Perl debugger](http://perldoc.perl.org/perldebug.html).
Check out the [`open` section of the "perlfunc" man page](http://perldoc.perl.org/functions/open.html). Specifically look for the example that "saves, redirects, and restores STDOUT and STDERR using various methods".
&gt; The problem I'm having is that even though I'm "catching" the errors when a "die" is encountered, it's still written to STDERR. This is due to how the die hook works. See [perldoc perlvar](http://perldoc.perl.org/perlvar.html). &gt; The routine indicated by $SIG{\_\_DIE\_\_} is called when a fatal exception is about to be thrown. The error message is passed as the first argument. When a \_\_DIE\_\_ hook routine returns, the exception processing continues as it would have in the absence of the hook, unless the hook routine itself exits via a goto &amp;sub , a loop exit, or a die(). The \_\_DIE\_\_ handler is explicitly disabled during the call, so that you can die from a \_\_DIE\_\_ handler. Similarly for \_\_WARN\_\_ . Thus, when a die is encountered, perl is calling your method hook prior to handling the die, printing to your log file, and then processing the die as it normally would by printing to STDERR. To avoid the normal processing, you can add an exit to your logEntry method. sub logEntry { open(my $lout, "&gt;&gt;", $logFile) or die; my $time = strftime "%m-%d-%Y %H:%M:%S", ( localtime(time) ); my $error_code = shift (@_); chomp(@_); print $lout "$time $error_code: @_\n"; close $lout; exit if $error_code eq "DIE"; #Prevents perl from further processing the die. } For the second part of your question, are you asking how to redirect a call like this: print STDERR "My error message"; to your logEntry() function? ~~If it is, the answer is you can't. The best you can do is redirect STDERR to a different filehandle as /u/squidevil mentions.~~ If it is, take a look at Tying FileHandles ([perltie](http://perldoc.perl.org/perltie.html#Tying-FileHandles)) or redirect STDERR to a different filehandle (see [open](http://perldoc.perl.org/functions/open.html)). You might want to take a look at these other error handling and logging modules to help you improve your code further. * [Carp](https://metacpan.org/pod/Carp) * [Try::Tiny](https://metacpan.org/pod/Try::Tiny) * [TryCatch](https://metacpan.org/pod/TryCatch) * [Logging::Simple](https://metacpan.org/pod/Logging::Simple) * [Log::Log4perl](https://metacpan.org/pod/Log::Log4perl) edit: added info on tying filehandles (credit /u/rrohbeck).
Great, I wasn't aware of this! Added.
Not normally, but then he attempted to use RT to continue the arguments and insulting behaviour that got him banned from the list, so, no longer.
The other answers here are kind of over-thinking the issue, imho. If it were up to me, I would start by handling the output outside of the program until a reason came up to juggle multiple output handles: # direct both stdout and stderr to output.log program.pl &gt; output.log 2&gt;&amp;1 If matching the error log up with the output is very important, I would disable buffering on stdout: #!/usr/bin/perl $| = 1; # use 'select' first if you've opened multiple filehandles .... While you're debugging the program you'll appreciate being able to see the output up front, without running back and forth to a log file. When you're ready to run for real, anyone checking the crontab will immediately know where the log file is, so net-ops will appreciate that too. My two cents, ymmv.
Tying file handles won't work for what I want but killing it when a die occurs should work for me, thanks. I really want the call to the script to not have any extra fluff around it because I won't always be the one managing the calls to it. 
The reason I want it to work that way is because I would like it to be dead silent. I have to be careful about details but basically there's another app calling it on an AIX system and I'm not always going to be the one setting up calls to it. So I would prefer it to be super simple. Plus the "others" might think stderr text means that the script is broken, rather than certain conditions just haven't been met and it's dying by design. Basically I'm using the error methods as designed but I need to make the output more comfortable. 
Wow, Pumpking is a legitimate word. I was going to get all crabby about how cromulent this word is. http://www.dictionary.com/browse/pumpking
I'm 99% sure the name came from Perl. ~~Looking for a link now.~~ http://perldoc.perl.org/perlhist.html#PUMPKIN%3f
English is defined by usage. Perl doubly so.
I feel dumb. I will try that tonight.
Just for fun, arbitrary in-line Perl code interpolation: print "${\$_-&gt;title}\n"; This is similar to the inline interp mechanism of Ruby and Elixir strings: puts "#{obj.title}" Also, later versions of Perl encourage the use of "say" instead of "print" so that you do not have to hardcode the newlines. This can look a bit cleaner.
And if this ever happens again where a hash reference is being printed, and not the contents, just "use Data::Dumper;" and print Dumper($_) . "\n"; to print the contents of the hash or whatever type of object.
Neat, but one should say that only metadata editing is done with Perl, as a post-process stage. On a side note, pdfcrop is a Perl program that I use for the same purpose, although it computes automatically the space to be removed from the actual bounding box of the PDF. However, when specific margins are desired or that algorithm fails, I understand the use of graphic tools like bliss.
Every module ... where, exactly? Please explain what you're talking about. Example, URLs etc.
Come one guys I obviously didn't mean literally every module on cpan. But she appears as the main author of many popular modules that I know she did not start, so I want to know if the original authors hand her their modules or what's going on
The problem here is that you're misreading whatever cpan website you're looking at. She's not the main author. She's the last uploader of a release for one of the modules. She does a lot of maintenance and up-keep releases because she volunteered to help with those sort of things on many distributions and was accepted to do such.
Here here. He's does an incredible job
I'm amazed that five years have gone by so quickly. rjbs++ you've done a fantastic job!
She's not the author of those. She is just on a huge power grab trip, and overtakes modules she is not technically able to maintain. But the authorities (modules@) don't care that much. I'm one of those who is absolutely not happy with the changes she does, and with the changes she does not do. We can only hope that she will burn out soon, so we can go on as before keeping some critical modules bugfree. Note that this happens frequently on CPAN. Adam Kennedy or RJBS had similar trips. And Adam Kennedy had actually technical competence. But all of them share an unhealthy portion of over engineering and over architecturing.
[removed]
So... no Perl6 for RJBS? Which, personally, I think is a not a bad thing. 
`$(echo 'ssh '{srv1,srv2,srv3})`
As a PAUSE admin I want to correct one aspect here: almost none (and possibly none at all) of the modules have been transferred to ETHER via the PAUSE admins. The owners of these distributions have chosen to give ETHER co-maint, I assume because they were happy to have someone volunteering to help.
Oh, that's interesting information. Thanks
Isn't she also PAUSE admin? Or RJBS. They would happily do such things.
`$( echo {,,,}'ssh srv'{1,2,3} ) ` Gets you closer to what he had. The slater `{,,,}` replicates the 'x3' aspect ( except I did it 4 times to get the slater to have enough legs :P ) 
I'm irritated cromulent's utility as a word is diminished by its acceptance into dictionaries :( http://www.dictionary.com/browse/cromulent 
http://irclog.perlgeek.de/perl6/search/?nick=rjbs&amp;q=
If you have no experience, you should probably stick to plain vanilla Perl and get used to it's inner workings. If you start with a framework, especially with no general web development experience, you'll never learn the core concepts and you'll likely be tied to that one framework until your career comes to a sudden halt. Once you understand even just how web development works but more importantly Perl, you'll be able to pick up any framework very easily and really utilize them to their fullest.
Word. I just looked at Beginning Perl by Ovid and it has an intro to "The Interwebs" for chapter 15. I guess I'll move to a lite framework after that.
I think you would be better off with Inline::Java http://search.cpan.org/dist/Inline-Java/Java.pod At least for accessing Java with Perl. Accessing perl via Java might be a bit different: http://stackoverflow.com/questions/274840/how-can-i-call-perl-from-java Of course, that thread also has numerous other ideas. XML-RPC, JPerl (probably dead because the webpage is dead), Rakudo-p5/v5 (running perl5 code in perl6 which is under a JVM so it can more easily communicate with Java), JERL (it's use isn't recommended by it's author. They say use Inline::Java instead for speed) 
Parrot never got full support for any language other than some created specifically for it http://parrot.org/languages Even Perl 6 is no longer supported. So its not crazy for a side project; it would just involve a lot of work on Parrot first. I imagine contributions would be welcome by the smaller team still releasing and supporting their own projects. If its Java youre interested in then Rakudo Perl 6 on the JVM lets you use Java classes natively, might be a good shout.
Was glancing through the TOC for that book last night on Amazon and was thinking between that and the two OO chapters alone (one on vanilla perl and one on Moose) the book would be worth it.
None. Just started.
Pack (and unpack) might be appropriate depending on the structure of your data. You basically create a template to read in and write out values.
I hope you don't get banned. Someone needed to say it.
Rounding out /u/kellymjones' example: use strict; use warnings; my $addition = 10; open my $fh, '&lt;', 'the_filename_of_the_file_with_your_data_in_it_yo.txt' or die $!; while(my $str = readline $fh) { chomp $str; # newline isn't part of the actual data my ($the_word_atom, $field2, $field3, $field4, $field5, $field6, @the_rest) = split / /, $str; $field6 += $addition; print join(' ', $the_word_atom, $field2, $field3, $field4, $field5, $field6, @the_rest), "\n"; } 
What's the problem with my delivery? I could have used uncivil words, but in contrary to the perl community I'm staying professional. Maybe that's the issue.
Think that's mentioned in the link? Despite my perhaps generally disparaging representation. Does it support the minor versions since 2003? Genuinely curious, especially given the whole Lua JIT thing. Would be quite interesting to compare the Lua perf of Parrot to the current standard implementation.
Definitely; my suggestions are only useful for someone with a primary goal of learning how things work, which is what it sounded like the OP was aiming for. If the primary goal is to produce a useful web app, then a framework is the way go to for most people.
&gt; Think that's mentioned in the link? If you didn't mean "never got full support", why write it?
for &gt; The amount of blanks before the number has to be reduced as a consequence you'd wanna use printf of sprintf with a suitably-constructed [format specifier](http://perldoc.perl.org/functions/sprintf.html#sprintf-FORMAT%2c-LIST) to pad your fields appropriately. For example, if your '13' field is supposed to be four characters wide, my $value = 13; printf("blah (%4d) blah", $value); gets you blah ( 13) blah I suggest extracting all of your input fields and building a format string with all the appropriate placeholders. If you have access to the software that's creating this file, it's probably using printf format specifiers to do so in the first place, so that would be the best way to find out exactly what it's generating and what it expects to consume. **Edit:** Oh, and in general? Treat these kinds of fixed-field file formats with caution. Things might look fine, might even work no problem for your test case, and then *someone* who has been happily using their old FORTRAN-77 script with these data files for years will complain that you broke something because they've been cramming some stupid extra data in a comment field somewhere and now it's broken. I hate fixed-width ASCII files.
[removed]
[removed]
So the file is just a PDB file containing ATOM records. This is a standard format and BioPerl has support for parsing and manipulating it: http://search.cpan.org/dist/BioPerl/Bio/Structure/IO.pm and http://search.cpan.org/dist/BioPerl/Bio/Structure/Atom.pm
&gt; I suspect the issue here you're picking on is "never got" rather than "doesn't currently have" which I should have used. Yes. Off the top of my head, you also left out the language Winxed and at least one more that Parrot supported fully, though I don't expect anyone to remember them. &gt; I just pointed out Parrot doesn't fully support Lua either now Parrot doesn't fully support *anything* now, because no one supports Parrot, which is why the OP shouldn't use it. Confusing the issue with what Parrot used to support and when is just noise. It's a bit tiresome that in 2016 there's still FUD thrown at Parrot. Certainly we can all acknowledge that it's been a dead end for quite a while now without making up technical inaccuracies.
Nice catch!
Thanks Rik!
I'm a fan of https://metacpan.org/pod/Data::Munge. my $x = 'bar'; if (elem $x, [qw(foo bar baz)]) { ... }
Thank you again for these articles, imho they are very well done.
Nice to see a positive mention of Perl but let's be realistic here, most devops tooling does not use Perl. There's been a growth of monitoring, configuring, deploying, containerising etc. tools and, sadly (?), hardly any of these are written in Perl. If it hasn't already happened, it wouldn't be surprising if your average sys-admin's go to language shifted to, for example, Ruby, if part of their job moves on to using Ruby for Chef/Puppet/whatever from shell/Perl scripts.
You're welcome!
crackers!
TL;DR there is no point in what you are doing, leave it wmutils are a bunch of small programs using xcb. you have NO C functions to call the way you think, since wmutils is not a library OTOH, you can use xcb to implement what they do in Perl or you can make a library out of wmutils and then write C/XS wrappers for Perl unrelated, add these lines to the top of every Perl file you write, use warnings; use strict; for further, more detailed answers, please read from: http://perldoc.perl.org/perlintro.html and http://modernperlbooks.com/books/modern_perl_2016/index.html 
I agree. Try posting this article in /r/DevOps and I imagine a very different response. The "test driven infrastructure" thing has been mostly pioneered by Ruby tools. Openstack and AWS are Python centric. Hashicorp tools and most Docker stuff is in Go. Perl still has a ton of use between all these things, but it's definitely not the language du jour. I use perl for my orchestration app that ties all this crap together in my environment, but as most new IT folks aren't learning perl as a first language, I suspect this sort of thing isn't common. However maybe there's something to be said that shops who are using DevOps practices tend to house more senior folks.
This is really getting me to think about Perl again, after a long time. The points above are great and I agree with them. Personally, I prefer Python, Ruby, Go over bash and Perl. However, I'm not a DevOps person and there's this weird anecdotal evidence about the popularity of Perl growing that sticks in my head. I go to a lot of hackathons and meetups as part of my job. I started to hear more and more examples of people using bash and perl scripts. I don't know why. Maybe it was quick and fast to use Perl? Not sure. It's probably not the language du jour, but I do see people start off with some quick Perl hacks and just keep building it up from a small little hack into a bigger system. There might be a difference between people involved with largescale DevOps or cutting edge techniques and the "common dude or dudette" person that is just trying to automate a few things and then go home at a reasonable time. I'm not sure, but I am now curious to learn more.
There's nothing wrong with trying to understand the wider community and ecosystem in which you operate. Noticing that a lot of modules you use are handled by a specific person may create some questions in your mind, such as "Were these modules abandoned and are just being maintained?" or "Is this an automated account that's used in some way to push changes?". The appropriate thing to do in this case is to ask, which is what happened here. 
&gt; Winxed was created by Whiteknight specifically for Parrot (at least as an initial target) Sure, but that's kind of an arbitrary line, unless the argument is "No mainstream language ever adopted Parrot as a reasonable backend platform". That argument excludes Lua and would exclude Perl and Rakudo, if you wanted to take it that far. FWIW, I think a better explanation for "languages created specifically for Parrot" to cover things like PIR and PASM and NQP. That's drawing the line at "languages Parrot and language implementors would have used" and not "languages end users would have used". The line's arbitrary any way, however.
&gt; There's nothing wrong with trying to understand the wider community and ecosystem in which you operate. Nobody said anything was wrong with it.
Your print statement does not have the output filehandle specified.
Is that the FASTA one? 
The print statement I think that is outputting to the command line is this one: print $kmer,"\t",$windowSeqCount{$kmer},"\n"; Just a quick hint, this could be more prettily written as (tastes vary): print "$kmer\t$windowSeqCount{$kmer}\n"; If you want that that particular output to be written into '/home/Example_directory/kmers.txt' Move the "open" clause down into that subroutine (re-write it like this): open (my $KMER,'&gt;','/home/Example_directory/kmers.txt') or die $!; and then change the print statement so that the file handle is in front of the string to print. This tells the interpreter to print the string to the file handle. print $KMER "$kmer\t$windowSeqCount{$kmer}\n";
&gt; FWIW, I think a better explanation for "languages created specifically for Parrot" to cover things like PIR and PASM and NQP. While probably more correct in a *technical* sense, I don't think that in any way expresses the desire and usage of the original comment, so it's not entirely relevant. &gt; Sure, but that's kind of an arbitrary line I'm specifically addressing the statement "Parrot never got full support for any language other than some created specifically", and your reply "you also left out the language Winxed and at least one more that Parrot supported fully". Fully supported is only half the assertion, the other half being that it wasn't created for Parrot, which I think in context means targeted at Parrot from the beginning. Not that it matters. You also mentioned Lua, which is all the evidence you needed to further your point. I merely wanted to point out the origination details of Winxed, since I remembered them.
&gt; But I fully admit I could have been reading more into your comment than you meant to express when you posted it. That seems to be the case. I asked if OP saw a problem because I wanted to know if OP saw a problem.
I should've looked at this yesterday. I spent a good chunk of time trying to use "unpack('C3', $byte\_string)" to return the first three bytes, when I should've been using "a3". Doh. &gt;_&gt;
[Actual slides](https://speakerd.s3.amazonaws.com/presentations/a3ef1f1bf9a54987bbff842e9f472438/caveman-dcbpw.pdf).
sub main { return 0; } exit main;
This scares me. The ice is so cozy!
The numerator/denominator pairs can end up getting really, really big in order to provide a completely irrelevant precision. This can cause slowdowns and memory bloat. Rationals are nice, some of the time, just like floating-point numbers are nice, some of the time. And floating-point is probably the better compromise, most of the time.
For future reference, https://regex101.com/ is amazing, and you'll probably end up using it a lot.
OH MY GOD YOU ARE A SAVIOR. THANK YOU!!! Ive been looking for something like this :D
Computational biologists. Always with the questions. 
That is good news, I shall definitely try to come then. Thank you.
fair enough. didn't mean to... reini just pissed me off with his awful personal attack on rik
\o/
Congrats
I'm not dead! I feel happy!
I still remember way back when rjbs was the pumpking.
You'll be dead in a minute.
Rik has done a fantastic job in a difficult position and I, for one, am sad to see him step down. He's overseen a great time when Perl's finally stabilizing and even making a bit of a comeback, thanks in part to people trusting the Perl core.
&gt;I can't take him like that. It's against regulations. Can't you disable strictures? He won't be long...
&gt; Others are afraid that now everything will change because my head was mostly in higher-churn code and I might not see the possible risks. I guess I count as "others." Please treat Perl as infrastructure, like C and POSIX: it should be a solid, boring foundation for building software. Switching to a newer Perl should be more likely to make programs faster and more secure than to break them.
Original Presenter here, so feel free to ask questions or suggest further improvements (thanks to delias_ for the one about Carton). I'll be giving a version of this talk at OpenWest in July, in a much longer slot, so I do need to add additional new things that have happened in the last 1.5 decades... 
Why do they NEED to exist and can't be mocks?
Suppose that any IDE is slower than any text editor. But don't know myself. It's slower than notepad++, but can do much more useful things.
To be clear, the book does explain how the basics of the HTTP protocol and how the Web works and then uses Plack directly as a very thin sugar layer so people can see how it works with software. That chapter never touches a proper web framework, but by the time you're done, it's not a difficult stretch to get from there to Dancer. My only regret is not having more time to write up better information about writing Web-based code. I touched on MVC, but didn't show it well due to time and space constraints.
Logical next steps would be enjoying Perl and getting to know the community :) No sequel is planned right now as I'm too busy with [my company](http://allaroundtheworld.fr/) and trying to launch an MMORPG. Seems to take up quite a bit of my time.
MMORPG written in Perl O_o
It's a text-based sci-fi MMORPG that runs in a browser. Not too many of those around (I'm not counting strategy games).
Use Moose, it is very intuitive for OO (https://metacpan.org/pod/Moose) Use this reference for the constructor of your class: https://metacpan.org/pod/distribution/Moose/lib/Moose/Cookbook/Basics/Person_BUILDARGSAndBUILD.pod
Thank you for the links! Sorry, I was a little hyperbolic. This semester I am taking my first course in programming, a perl course. So I have been learning Perl for the last few weeks, but this is my first object oriented assignment. I am okay-ish with procedural Perl (i.e. know basic data structures and how to manipulate them; have done other assignments where I open files). My question is specifically how to unite the three of those points. I'm mostly looking for an example of a constructor that takes a filepath as the argument.
Yes. new can have as much or as little code as you need (it's really just another subroutine. The name is only an agreed upon convention) The bless is the special part that makes an object, so you can do lots of things in new then bless the results and return them. The main reason you wouldn't do this is flexibility. The more you do in new the less choice you give the user and the harder it is to test your object. Of course you can still give the user choice with arguments, but I guess it depends on the overall goal of the module.
One minor fix to the cheat sheet: `($a, $b) = shift(@ARGV);` is misleading, since `shift()` only returns one value.
Thanks, I can relay this as an issue on github for you!
Well now I know what cperl is anyway. I had no idea.
Awesome, thanks for the work you are doing.
Were there rumors about cPanel and cperl? What is cperl? Admittedly I've been out of the shared hosting space for a few years so I haven't been keeping a close eye on the industry... 
The rumors are listed right in the email I linked to. It's basically a small cabal of troublemakers trying to rile things up and cPanel had to set the record straight.
This currently does not work (tested with 5.22.1) but maybe we can suggest so that it does: use re '/r'; $bar = $foo =~ s/a/b/; $baz = $qux =~ s/c/d/; # and so on... I personally don't like to use `use re '/flags'`, it feels a bit like we're in PHP where register_globals, magic_quotes, etc are configurable and a source of headache.
Glad you found your way. For future reference, a "package" is a Perl class. You can create classes simply, within a single file, in plain-old Perl (i.e. without resorting to an object system like Moose). Examples: https://www.reddit.com/r/perl/comments/3e5xnq/is_this_book_object_oriented_perl_by_damian/ctc6y8k https://www.reddit.com/r/perl/comments/2k5xfn/new_to_perl_how_can_i_make_my_code_more_elegant/clker68 
http://www.reddit.com/r/cperl
So? That doesn't make the syntax magically compatible. It's not.
Which has what to do with what, exactly? /u/cowens' point stands: Perl 6 is at no fault for taking away Perl 5 developers: that's exactly what one intends when they obsolete something, which exactly what Perl 6 was intended to do from Larry Wall's own speach.
Actually the syntax is compatible. All Perl 6 code is required to be prefixed with `use v6;` The same executable could, in theory, parse both Perl 5 and Perl 6 code and generate bytecode that would run in a VM. This is how Perl 6 was designed. The intent from the beginning was for Perl 5 code to run under the Perl 6 binary just like Perl 4 code runs under the Perl 5 binary. The fact that Larry got stomach cancer and a bunch of other setbacks and slowdowns have prevented this from being so doesn't change history. The name Perl 6 was chosen when the plan was for Perl 6 to replace Perl 5 the same way Perl 5 replaced Perl 4. It is still possible for Perl 6 to replace Perl 5, but given how long it has taken (and is still taking) for Perl 6 to become usable, I wouldn't count on it any time soon. In the experimental news, there is the Perl 11 project (or project umbrella more accurately) that aims to fix the gap from the other direction (making a Perl 5 binary that is capable of running Perl 6).
Does this plugin work with perlbrew properly? Or, in other words, is there some way to make it see perlbrew specific lib directories from InteliJ? I've encountered some problem: I've got perl 5.22.1 installed using perlbrew and this works perfectly fine. I can run code having only this 'use 5.22' code and it compile and run. However, if I try to import some specific lib that I've installed inside this 5.22 perlbrew environment, IntelliJ cannot find it: Can't locate Moose.pm in @INC (you may need to install the Moose module) (@INC contains: /home/user/perl5/perlbrew/perls/perl-5.22.1/lib/site_perl/5.22.1/x86_64-linux /home/user/perl5/perlbrew/perls/perl-5.22.1/lib/site_perl/5.22.1 /home/user/perl5/perlbrew/perls/perl-5.22.1/lib/5.22.1/x86_64-linux /home/user/perl5/perlbrew/perls/perl-5.22.1/lib/5.22.1 .) at /home/user/IdeaProjects/test/new.pl line 7. BEGIN failed--compilation aborted at /home/user/IdeaProjects/test/new.pl line 7. Process finished with exit code 2 Is there any workaround to this situation? 
I've still gotta figure out some hash order randomization issues in our code
It's does not anything about perlbrew itself, but it shouldn't be a problem to use it in project. Just add new sdk for any perl installed and activated with perlbrew, set it as project sdk and everything should work fine. 
https://metacpan.org/pod/WWW::OAuth The above looks promising.
As a user, I don't care about anything but compatibility: "userspace" (i.e., CPAN) code that worked yesterday or last year should still work today. Whether the `perl` executable is a little faster or slower due to some cool internal hack or maintainability cleanup is of no interest to me. The internal feuds where technically correct/useful patches get ignored because the submitter is not well-liked are also not my fave. If Perl were getting noticeably faster (2x+ speedups a la PyPy),could conveniently compile to native static executables (a la Go), etc., I'd be psyched to hear more news about internals work. As it is, I only seem to hear about this stuff when it breaks CPAN. (All of the above is given the context that I really really love Perl and understand that unpaid volunteers get to work on whatever they want, I paid $0, etc. Having said that, if you cause enough pain for me as a user I'm just as free to use another language/platform as you are free to break my user-level code.)
In reference to the prebuilt Windows build perl5 is used for prove in panda tests I thought? There is already a perl6 implementation of [a replacement](https://github.com/Leont/tap-harness6) under way. So that might be sooner rather than later? 
Thank you for doing this. I'm stoked to see someone writing a perl library for bitcoin. I'm just a newb in perl, so I can't contribute much. Let me know if I can help in testing, however. 
Hi, if you have a server/raspberry pi running debian wheezy/jessie, you can help by trying to compile the source package into a deb package and installing it. If it does not work from the get go, I'll have to make adjustments to the install scripts. 
Alright. I'll give it a shot. 
Being a windows dev the hashbang line doesn't usually matter that much to me, so i didn't think of that, but /u/wschroed's version is excellent, so i added it in.
/u/MattEOates was right in the comment below, too. we currently only need perl5 as a run-time dependency for evaluating test files in modules. however, the replacement is well underway and only a few known bugs remain, as far as i know. perl5-less Rakudo Star could be ready in a month or two, depending on how much time the relevant volunteers can find to work on these parts.
Cpan.org?
I want to add that, although cpantesters isn't good or fast enough to be used as a CI tool, it does other things one might be interested in: it will test code in multiple architectures, operating systems and perl versions. For free, the network donates these resources. No wonder it's slower, it does a much bigger job. The lack of features is also derived from this, people shouldn't ask more from the network.
It seems there's a MSWin tool these days, too: http://blogs.perl.org/users/eserte/2016/04/testing-with-appveyor.html
You might be interested in seeing [this perl project to create text based adventure games](http://www.yllr.net/if/pxif/) and the two systems it points to that are very good for actually doing that.
The Inline features enable use in Perl 6 of a module that's only in Perl 5. Or use in Perl 5 of a module that's only in Perl 6. And many other variations. So I find the following confusing and wonder what you mean: &gt; The inline feature is nice, but I would also find it more useful when you're running a script that needs a module only in Perl5.
You should really be paying people for homework help
I don't think anyone learning a programming language should ever take this type of stuff personally. We've all probably felt at some point that we got ripped apart by others concerning our code. It's a part of learning and understanding the syntax but more importantly what is happening under the hood (which /u/Rhomboid did a great job showing). 
I highly suggest you do some preliminary reading if you're having problems similar to this in the future. Here's a [Perl book](https://drive.google.com/file/d/0BzQf0taRES9UREd5UlFsX3BVMkk/view?usp=sharing) I have that you can check out!
You can escape the $0 in bash if you really wanted to, but it's ugly as hell. perl -e "\$0='hi'; print \"\$0\n\";" 
With `eval`, you can pull off some nasty tricks. For instance, you can abuse the fact a `v` version string represents a series of characters, and encode your code as a version number and eval it. eval v36.48.61 . q{q[hello]}; while(){ sleep 1 } You can of course use the more obvious `chr` eval chr(36).chr(48).chr(61). q{q[hello]}; while(){ sleep 1 } Another way to give any sysadmin a fright: eval pack q[C*], 36, 48, 61, 34, 104, 101, 108, 108, 111, 34, 59, 32, 119, 104, 105, 108, 101, 32, 40, 32, 49, 32, 41, 32, 123, 32, 115, 108, 101, 101, 112, 32, 49, 59, 32, 125; And if you wanted to be extra ~~obscure~~ efficient , eval pack q[L*], 574435364, 1819043176, 540746351, 1818847351, 539500645, 539566129, 1819484283, 544236901, 2099264305; PS: Please replace "eval" with "print" to see what they do first. I won't intentionally deceive you, but you should assume I will. I could **easily** hide a fork bomb or a `system('sudo','rm', ... )` in there. 
Thank you, `eval` looks like a suitable work-around, particularly with `chr()`. I was not aware of the `v` version string hack - has this been around for a long time, I'm not sure it is mentioned in the Camel book. Learn something new every day about Perl - thank you!
The v Version hack is kinda one of those "I wish this wasn't true, but this is good to horrify people and scare people who don't know already" things ;) I would not use that in any real task, but its good for entertainment value. But I can confirm it works back on as old as 5.6.2 perlbrew exec --with=perl-5.6.2 perl -e ' print v36.48.61 ' perl-5.6.2 ========== $0= It makes sense why it does this in retrospect. Just people tend not to be aware that v-versions are just short hand for "string of characters by ID with magic". perl -MDevel::Peek=Dump -e ' print Dump(v36.48.61)' SV = PVMG(0xbd55c0) at 0xbd2728 REFCNT = 1 FLAGS = (RMG,POK,IsCOW,READONLY,PROTECT,pPOK) IV = 0 NV = 0 PV = 0xbda110 "$0="\0 CUR = 3 LEN = 10 COW_REFCNT = 0 MAGIC = 0xbb7990 MG_VIRTUAL = 0 MG_TYPE = PERL_MAGIC_vstring(V) MG_LEN = 9 MG_PTR = 0xbda180 "v36.48.61" 
Personally? Everything I have deployed runs on 5.22 and 5.20. Professionally? Anything that's not on 5.18 or newer (and is ever going to be deployed again due to a bugfix, migration, change, whatever) should get upgraded to 5.18. On the CPAN? That's complicated, but I'll say this: I have no desire to wait ten years to start releasing code which uses signatures there only to spend ten years after that arguing about whether I'm an irresponsible maintainer for releasing code that only works with 5.22.
&gt; The internal feuds where technically correct/useful patches get ignored because the submitter is not well-liked are also not my fave. I think that overlooks an important point. The stability of Perl as a whole depends on there being *some* line of demarcation between what p5p can change and what p5p must support forever. There's never been a good line separating incidental implementation details from a formal API, so any steps in that direction to define a separation between things that can be supported and things that can't will cause pain. No matter what decision happened here, it would cause pain.
&gt; The v Version hack is kinda one of those "I wish this wasn't true, but this is good to horrify people and scare people who don't know already" things ;) My favourite is: perl -CS -wle'print v3232.95.3232'
Its not about "change" vs "must not change". Its about a change strategy that mitigates the fallout. Instead of simply breaking existing use-cases and expecting the problem to resolve itself: - Monitor breakages on CPAN with changes using smoking strategies - Understand why things are breaking - Create alternative APIs to achieve the same thing better - Work with CPAN Authors to integrate the API change - Implement progressive warning strategies to allow people to know that their code will potentially become broken in a future release - Once we are sure we've done what is necessary to mitigate the bleed out, **then** we release a stable perl with the backwards incompatible change performed. Essentially, you treat incidental API as defined API, and then apply the same strategy for deprecating defined API you would normally apply. Here, we very much could have avoided pain. All it would have taken is identifying that a change was going to cause a problem, and slate it for integration in `$^V + 0.1.0 ` instead of in `$^V`, giving people more time to react to the breakage, and requiring people do things about the breakage instead of pretending it wasn't important.
My apologies and good point. Just because I'm mainly looking forward to P6 doesn't mean the majority of the Perl community is the opposite and will be on a slow transition to P6.
Thanks for replying. Fwiw I'm anticipating the Inline modules getting a lot of use a few years from now. One could argue that half the point of the Perl 6 design was to naturally support a community that mixes polyglots with folk who want to work in just a single language. It's going to be a few years before Perl 6 is strong enough in other regards for the Inlines to start really paying off but I see it coming as I explain next. Just as a killer feature of Perl 5 was (and to a degree remains) CPAN, a killer feature of Perl 6 is (or will be if my crystal ball isn't faulty) "all-your-modules-are-belong-to-us" (where "your-modules" are modules written in Perl 5, python, Lua, C, C++, Java, Scala, Javascript, etc.). Of course, this involves increased dependency complexity, analogous to the way relying on CPAN modules increases dependency complexity, but not having to write modules and instead having access to all that existing functionality is going to be a heck of an advantage over any language that leans primarily on using modules written in the same language. Question to coders: "Hasn't someone already written some code to do most of this? Can't you reuse their code?" Answer by Perl 6 coders: "Well, we don't really know languages other than Perl 6 but let's take a look... Aha -- there are modules with pretty decent APIs in Lua and C and another in Python that might work out... *Uses Inline to `use` the Lua, C, and Python modules and play with them using only Perl 6 code* ... Cool, if we're willing to deploy Lua 5.3 we're all set; if that's an unacceptable dependency then the C library looks like it'll probably work OK too.".
&gt; Essentially, you treat incidental API as defined API, and then apply the same strategy for deprecating defined API you would normally apply. &gt; &gt; Here, we very much could have avoided pain. Once upon a time I might have believed that, but it didn't work with Parrot and it didn't work with Perl. No matter how much the provider of an API considers "incidental", if a dependent project feels free to meddle with the internals of the dependency, there will always be a gap of expectations. Even reordering struct members could be considered breaking an incidental API. No matter how much you document your deprecation process, there will still be arguments over the contents and meaning of points of the process, especially over what the notification period is, how many changes there can be, and, crucially, when something goes from "shouldn't use because it will change at some point" to "don't use because it doesn't work". You're also overlooking the most difficult part of this process, the fact that maintaining this strict backwards compatibility and support process necessarily slows down *all* development. If you want to have volunteers sit on patches for two deprecation periods (years, in the matter of Perl, six to twelve months for Parrot), maintaining their branches in the face of bit rot while simultaneously bearing all of the criticism of "not moving fast enough" or "not addressing real problems" and "not fixing bugs", you're going to end up with no developers left. This strategy is pure applesauce and should be rejected. It is unworkable with volunteers. Perhaps in a single, unified, coherent, top-down organization with a strategy measured in years. Not in F/OSS.
And using $a and $b as examples is a bad idea, due to their special meaning in sort routines.
I think this is less a goalpost shift ... probably more likely typed the wrong key because their brain had a memory problem. Hard to say. Call me naÃ¯ve if you must :)
So the question then is, if there are no clear demarcation lines and no plan to introduce any: What is the point of CPAN?
&gt; What is the point of CPAN? Serious answer: Most things--really, really *most*--don't use unsupported APIs. The borders of support are fuzzy and they move, but they don't move that much. Snarky answer: Still better than npm.
Finally can stop putting `use experimental 'postderef';` all over the place ðŸŒˆðŸ˜ºðŸŽ‰
Changes are described here: http://search.cpan.org/dist/perl-5.24.0/pod/perldelta.pod
yet the subroutine signatures is still experimental :(
http://metacpan.org/pod/release/RJBS/perl-5.24.0/pod/perldelta.pod
I'm still using v. 5.12 Am I really missing anything worth the possible hassle of making my current programs obsolete?
There may be some things you could get away in older Perl versions but which will blow with a newer one. I have used perlbrew and Perl::Critic to get some outdated code to run using Perl 5.22. 
This is the code? http://ai.neocities.org/perlmind.txt 
Can someone explain why do this: my $object = (ref $self)-&gt;new(. . .) Instead of this: my $object = $self-&gt;new(. . .)
Mainly because -&gt;new called on an object can behave differently than when called on the class itself, due to new being something like this: sub new { my ( $self, @args ) = @_; # proceed to do something here with $self, maybe; # maybe even different things depending on whether it's a class name or an object
For what it's worth: People who complain do not complain about the Perl specifically. They complain about your code breaking with almost every convention that exists in programming. You would get complaints about that source code in every other language as well.
Because `new()` is a class method and should be called on a class, not an object. What do you expect `$obj-&gt;new(...)` to do? I can see two possible options. 1. Create a new empty object in the same class as `$obj`. 2. Create a clone of `$obj`. Without reading the documentation, there's no way for a programmer who uses your class to know what the behaviour is. Far better (in my opinion) to have two separate methods. 1. `Class-&gt;new(...)` 2. `$obj-&gt;clone(...)` If you find yourself writing a method that can be called as a class method or an object method, then you should probably reconsider your design.
http://www.nothingisreal.com/mentifex_faq.html https://www.reddit.com/r/mentifex
The simplest way of explaining it I can think of is: Your code is simply too obscure to be used by, maintained by, or analysed for accuracy by, anyone other than you. So even in the event you personally got utility from it, in its present form, it is essentially useless to everyone who is not you. That sucks for you really, but there's no way you can circumvent this issue by explaining it away to people. The only way around this issue is to refactor your code into a form that can be understood, read, and used by other people. **Surely, you can feed your code into itself and request that your AI re-write it to be understood by humans?**
Interesting. Thanks.
Perltidy wouldn't help. There are far too many fundamental misunderstandings of basic programming techniques. I mean, look at those "arrays" implemented as (finite!) sets of scalars.
u/hsfrey you are not missing anything critical, as far as your already-existing (and hopefully tested) code is concerned. Barring a cataclysm you should fully expect to be able to continue using CPAN offerings with no fear easily into the late 2020's. The [answer](https://www.reddit.com/r/perl/comments/4ij857/perl_524_is_available/d2z55d2?context=1) by u/mr_chromatic is borderline-malicious FUD. That said, if you upgrade you would benefit from a number of performance improvements, and would be able to use certain syntax sugar for new code you develop. TL;DR: Upgrade if you have the resources and a clearly identifiable need for it, not because "someone on the internet told you so".
&gt;&gt;That code is deliberately obfuscated, right? &gt;No, the http://ai.neocities.org/perlmind.txt is actually written with extreme care to be clear and maintainable You failed :-)
Of course. I run perltidy not exactly hoping that Mentifex will transform himself into supreme Perl hacker, especially after his grandiose statements. But after perltidy it is a bit easier to see what is inside of "concept-based AI". If one skips any attempt at using existing NLP Perl modules / corpora(s) and instead hard codes a handful of English (~160?) and Russian (~260) words inside a one and only script it is quite strange. But if one bumps into 7k lines long MindBoot() where individual characters of words are used to populate $ear using hard coded, not calculated positions, then it is like looking into an abyss. Nothing to fix and nothing to learn, except in the field of human mental states. 
Congratulations /u/exodist!
&gt; The answer by u/mr_chromatic is borderline-malicious FUD. Nonsense. None of my CPAN code supports 5.12.
While CSV is a straightforward format, I would start by searching MetaCpan for ['CSV' related modules](https://metacpan.org/search?size=20&amp;q=CSV&amp;search_type=modules). Text::CSV seems relatively recent and the examples in it look good. Install it from the command line using "cpan install Text::CSV" (or for a long-term improvement, first use cpan to install 'cpanminus' ).
Exciting news.
&gt; possible hassle of making my current programs obsolete Great pains are taken to minimize the hassle of upgrading. You'll be gaining many years of bugfixes as a result.
5.14/5.16 bring the keyword API so you get things like Function::Parameters, Try and Moops *if* you want them (thereby finally obsoleted the horrible hack that was my Devel::Declare ;) more recently, refaliasing makes me a lot happy: foreach \my %hash (@array_of_hashrefs) { and of course subroutine signatures, though I doubt you notice their absence any more than I do
And congratulations /r/perl!
&gt; Is there a reason it's not considered stable yet? [perlpolicy](http://perldoc.perl.org/perlpolicy.html) describes the stabilization process: &gt; Experimental features must be experimental in two stable releases before being marked non-experimental. Experimental features will only have their experimental status revoked when they no longer have any design-changing bugs open against them and when they have remained unchanged in behavior for the entire length of a development cycle.
I believe there's still an open design question about whether `@_` should get set in subs with signatures.
Oh, right. http://nntp.perl.org/group/perl.perl5.porters/235332
As Mentifex Mindmaker I employ the following techniques to write good Perl AI code. **# 2016may10:** Comments start with a calendar date as a time-stamp. When I comment out a line of code and replace it with a new line, I try to keep the commented-out line in the perlmind code through at least one iteration of releasing the free AI source code, so that interested parties have a chance to see the both the old line and the new line. At the end of each subroutine mind-module I try to state to which superior module the subroutine module will return, so that Perl AI devotees may gradually acquire a sense of the cognitive architecture of the Ghost AI. While I code the Perl AI, I record my thoughts and **mind-design** decisions in the **[Perl Mind Programming Journal](http://ai.neocities.org/PMPJ.html)**. Before I upload the Ghost Perl AI to the Web, I append one more line to the Changelog at the end of the free **[Perl AI source code](http://ai.neocities.org/perlmind.txt)**. 
You should probably take the time to learn a source code control system.
&gt; why you would want to change to it This is not an option at this point. If anything in your dependency chain triggers an "I need to grab latest T::M from CPAN" - you will get the new and shiny. There is no opt out mechanism: breakage has been [accepted (incorrectly) as absolutely inevitable](http://blogs.perl.org/users/chad_exodist_granum/2016/04/test2testbuilder-update-from-the-qah.html#comment-1703334), and therefore acceptable
Take the first step, put it on github. Otherwise there is no reason to trust that you won't ignore even the most simplest pieces of advice.
Aside from that, it should still explain "This is what X is, and why you want to use it." Any announcement of a tool upgrade should do that.
I think new features are things like reliable parallel testing that bulk88 had me test on Windows at QAH. I also raised a ticket to have this lack of information rectified: https://github.com/Test-More/test-more/issues/663 That said, yeah, Test::Simple and anything depending on it now uses Test2 instead of Test::Builder, which should, hopefully, not break anything, but also make possible things that Test::Builder blocked previously. Also, here are some changes for more direct users: https://metacpan.org/pod/distribution/Test-Simple/lib/Test2/Transition.pod
That Transition.pod is especially frustrating because it assumes that you know what is different between the two.
Not in Perl, but a today's link from r/programming. A project tackling language processing: * [spaCy github repo](https://github.com/spacy-io/spaCy) * [spaCy www](https://spacy.io/) If you want to stick to Perl, first recently updated project: * [Treex](https://metacpan.org/pod/Treex) Not my field, so I do not pretend these are for best project to look at, see what is already doable/how things are being done. What you want to do with your brainchild is up to you, but: &gt; A man's got to know his limitations
How is your suggestion not [pure applesauce](/r/perl/comments/4hn0tu/the_coro_situation_aristotle_blogsperlorg/d2xmn2z)? &gt; It's still possible to do this work [of replacing XS with a real API layer] gradually I find it baffling that you consider this doable but you consider due diligence before shipping patches that break a big chunk of CPAN to be infeasible. As far as I can gauge, yours is the boil-the-ocean position, not mine. And as further I can tell, the approach Iâ€™m championing â€“ namely, that docs and use case substitutes should be provided before locking down previously hookable internals â€“ can easily be used as the process by which to get to the same destination youâ€™re aiming for, i.e. a proper API. Except that by the approach I advocate, it doesnâ€™t matter how long it takes or if that destination is even ever reached, because every step achieved is a gain by itself, since little breaks in the meantime â€“ whereas by your take on the process, everything hinges on reaching the destination, and the entire effort is a write-off if that doesnâ€™t happen (or, really, if it takes far too long).
&gt; people who haven't been following his blog and work. This is the vast majority of users. I'm not picking on him specifically. This is a common problem in open source projects, where the "living and breathing ProjectName" means that you forget about the people who are not familiar with it.
&gt; you consider due diligence before shipping patches that break a big chunk of CPAN to be infeasible Do I? This surprises me. &gt; the entire effort is a write-off if that doesnâ€™t happen (or, really, if it takes far too long) I'm surprised to learn I believe this too.
[Significant performance improvements](https://redd.it/4ivu2e). And, no, it should not make your current programs obsolete.
I know, i've told people often enough that their "ProjectYouNeverHeardOf hit v1.37" announcement isn't helpful when it doesn't explain what ProjectYouNeverHeardOf does. :) Just saying that i have sympathy for exodist in this case.
&gt; Almost ten years ago I argued that XS needed a replacement that wasn't tied to the implementation details of SVs et cetera This issue has nothing to do with XS itself, but with the Perl API. The former is build on top of the latter, replacing it won't solve this problem (even if it may solve other problems).
How it compare to lua (the fastest interpred language in my knowledge) ?
These links need to be attached to a higher-level comment.
Also AI...
It is meant to be an understated, wink-and-a-nod kind of title. Let's admit, Perl is *not* the fastest language, and it's towards the bottom of the list in most if not all the benchmarks in that suite. But, now, it is faster than Python on many of them, and I like that.
Oops yeah, i mistook the preview graph on the perlformance page for actual data. This is where the actual data is: http://perlformance.net/charts/perlstone2015-f/index.html Also, what does nbody focus on?
I have been awarded a grant for writing documentation for Test2. This is coming :-)
The N-body problem: https://en.wikipedia.org/wiki/N-body_problem A lot of arithmetic. Also, by necessity, array or member data access. Reini's optimization replaces array accesses of the form `$x[ $i ]` with `$x[ 5 ]` etc. It's a very neat trick.
&gt; Let's admit, Perl is not the fastest language It's not??? I've been deceived!
&gt; Let's admit, Perl is not the fastest language True, but for most purposes, it's fast *enough*. If I need something *blisteringly* fast I can write it in C, but if a Perl program does a job in a second that C will do in a tenth of a second, chances are that the fact I can develop the Perl code in a tiny fraction of the time it would take in C makes it worth putting up with the extra run time. Though I wouldn't fancy a Kernel written in Perl &lt;grin&gt;.
I'm using the term "XS" as synechdoche, but you're right. XS merely hides some of the details of the API.
&gt; don't publish the numbers If only someone else would! [Like this guy did for Python.](https://pybenchmarks.org/)
If you want something like this in Perl 5, checkout [FFI::Raw](http://search.cpan.org/dist/FFI-Raw/lib/FFI/Raw.pm). The interface isn't as nice, but it has the same functionality (at least the functionality demonstrated in the article) is there.
My Perl's a little rusty, but shouldn't $name = split(' ', $real_name); be @name = split(' ', $real_name); instead? Otherwise you're just pushing the first value returned from the split operation into a scalar and then dropping everything else.
That fixed it, thank you (:
I kept the use strict out because it kept telling me to define $name (or @name with /u/azod's changes), but it ran fine without it. 
/u/azod has a good suggestion, but as you say you're starting out I thought I'd help you find your way a bit better. Start every script with strictures and warnings.: use strict; use warnings; You're using an older method for warnings (the -w flag) but the pragma is more flexible and preferred. Many suggest the diagnostics module, too. There's a function built-in to get this data without reading a password file so long as this is the system password file. See these entries in perldoc.: * getpwent * getgrent * getpwnam * getpwuid If you must use split, you don't need to have named variables for everything you're throwing away. That's wasting cycles and memory and making it harder to reason about the program at a glance. Use undef to make it clearer what you need, or use an array slice. There's also no need to split beyond the first field you don't need in your data. The chomp makes no difference to the fields you're looking at. $words is unused and $line is scoped overly broad. You're specifying STDIN when an empty readline operator will default to STDIN but will also read from any files named on the command line. You're being kind of narrow with your titles. Besides that, you're getting an empty first name if someone has two consecutive spaces in that field. You're using a field for title and then conditionally counting to the next field based on whether or not a title was found. Just shift the array and get rid of the other conditions. You're checking for definedness and adding to a defined hash value, but initializing undefined hash members to 1. In Perl5 hashes autovivify. If you increment a nonexistent hash key, its value springs into existence at 0 and becomes 1 upon the increment. You're giving output assuming plurals and you're using print() as a function on a list. It's probably easier to maintain if you concatenate the string. You can use ternary operators or pre-set values in if blocks to fix that. #!/usr/bin/perl use strict; use warnings; my ( %names, $nameless ); my @titles_ary = ( 'Mr', 'Ms', 'Mrs', 'Miss', 'Dr', 'Prof', 'Rev', 'Fr', 'Coach', 'Ofcr', 'Officer', 'Pvt', 'Cpl', 'Spc', 'Sgt', 'Lt', 'Cpt', 'Maj', 'Col', 'Gen', 'Seaman', 'PO', 'WO', 'Chief', 'Ens', 'Cmdr', 'Adm', ); my %titles = map { $_ =&gt; 0, "$_." =&gt; 0 } @titles_ary; foreach my $line ( &lt;&gt; ){ # either of the next two lines works # my ( undef, undef, undef, undef, $real_name, undef ) = split( ':', $line); my $real_name = ( split ':', $line )[ 4 ]; if ( '' eq $real_name ) { $nameless++; } else { my @name = split /\s+/, $real_name; if ( exists $titles{ $name[ 0 ] } ) { $titles{ $name[ 0 ] }++; shift @name; } $names{ $name[0] }++; } } foreach my $key ( sort keys %names ) { print "Name '$key' occurs $names{ $key } " . ( 1 == $names{ $key } ? 'time' : 'times' ) . ".\n"; } foreach my $key ( sort keys %titles ) { next unless 0 &lt; $titles{ $key }; print 'There ' . ( 1 == $titles{ $key } ? 'is one person' : "are $titles{ $key } people" ) . " using the title '$key'.\n"; } print "There are $nameless entries with no name.\n";
@cestith, you made all the suggestions I was going to go with, and beat me by extending the list of titles, but you missed one I consider important ... early exit. Rather than using an if-then-else for $real_name, I would use the postfix-if/unless and early-exit the loop if there's no name: LINE: foreach my $line (&lt;&gt;) { ... next LINE unless $real_name. While you don't actually NEED the label unless you have nested loops, I think it draws attention to the fact that there will be early exits within the loop.
map {} is a way of performing a small block of commands on each element of a list or array. It corresponds to my %titles; for my $word ( @titles_ary ) { $word_with_dot = $word . '.'; $title{$word} = 0; $title{$word_with_dot} = 0; } Map is more efficient and conceptually more cohesive than the for{} equivalent, but generally best for small, concise code blocks.
You're right, I'd forgotten that. (I _did_ say I was rusty.)
TL;DR: This is a map. perldoc -f map A map takes all the items from its right and does a transformation on them, then returns the transformed data to its left. The $_ is Perl's "this present thing" pronoun scalar variable. It's seen in while readline loops, maps, greps, and other places. It can be manually set if need be, but you should probably avoid that in most cases. This is taking all the thing put in the array named @titles_ary and returning that entry, then the '=&gt;' (fat comma operator or thick arrow operator), and 0. Then it's appending '.' to each entry (via interpolation in the double quotes) and returning a fat comma and another 0. That fills the %titles hash with a key from each member of the array with a value of 0, and also a key for each member of the array with the trailing period often found on title abbreviations which also has a value of zero. The zero value makes these exist() and makes them defined() but they are at a count of zero and would evaluate as false if tested as a boolean themselves (without exists() or defined() that is). This means when the code to count titles starts adding to them later, it can check to see if they are there, then immediately start incrementing them if they are. If you dump the hash just after creation, says with this code below, it looks pretty much like you'd want it to but without having to edit the arrows, zeros, and the other half of the entries into the hash and maintain all that by hand.: print "$_: $titles{ $_ }\n" for keys %titles; That produces output like this (although I didn't sort the keys, so it may be different in your output).: WO.: 0 Prof.: 0 Adm: 0 Mrs.: 0 Maj: 0 WO: 0 Spc: 0 Cpl: 0 Pvt.: 0 Cmdr: 0 Spc.: 0 Coach: 0 Miss: 0 Gen: 0 Maj.: 0 Cpt: 0 Ms: 0 Dr.: 0 Adm.: 0 Dr: 0 Chief: 0 Miss.: 0 Mr.: 0 Ens.: 0 Cpt.: 0 Ofcr: 0 Rev.: 0 Sgt.: 0 Officer: 0 Officer.: 0 Cpl.: 0 PO: 0 Gen.: 0 Sgt: 0 Seaman.: 0 Fr: 0 PO.: 0 Rev: 0 Pvt: 0 Chief.: 0 Seaman: 0 Fr.: 0 Mr: 0 Lt: 0 Mrs: 0 Col.: 0 Prof: 0 Ms.: 0 Ens: 0 Lt.: 0 Ofcr.: 0 Cmdr.: 0 Col: 0 Coach.: 0 
Unless you get an entirely blank line or one truncated before the proper number of colons, you're going to have a $real_name even if it's zero characters. My code counts the number of lines with no entry in the GECOS field and makes use of that. You can't do that without a branch of some sort. Once the branch in the if/else is chosen, the end of either block will fall off into the end of the loop as mine's written. If you don't care about the number of empty fields, then sure you can do a next. I didn't do full error handling or bother to benchmark, profile, and optimize the code. It's to improve the OP's example. My goal in a handful of minutes was not to make the code a tense, throbbing ball of early optimizations. 
"map" transforms a list into another list. In this case it transforms each title to four items. Then it assigns the new list to a hash, which turns every pair of items into a key-value pair in the hash. So this takes a list of titles and makes it a hash where all the keys are both the titles (the $_) and the titles with a trailing period (the "$_."). The values for each key is a 0. The point of this is that with a hash, you can easily check if a title is present as a key, like so: if ( exists $titles{ "Dr." } ) ... # Yep, a doctor if ( exists $titles{ "Larry" } ) ... # That's a name Side note: An even nicer way would have been to set the values to 1, which is a true value. Then the test could have been this: if ( $titles{ "Dr." } ) ... # Yep, a doctor 
&gt; map {} is a way of performing a small block of commands on each element of a list or array **and returning a list of items that end up in the list that `map` returns**. FTFY. The difference between `map` in Perl and in other languages is that in other languages `map` returns 1 result per item. Always. In Perl you can return as many items as you like: 0, 1 or, more, such as in this particular case, 4. The equivalent code for that line is thus like:: my @_temp; foreach(@titles_ary) { # list fed to map push @_temp, $_ =&gt; 0, "$_." =&gt; 0; # 4 items added to result list } @_temp; # return value of map 
Actually you're assigning the size of the list returned by split to the scalar variable $name, but that doesn't effect the solution.
I think the cookbook is still relevant, but [the examples](http://examples.oreilly.com/9780596003135/) are available for download. I doubt the explanatory text is given along with them though.
Maybe it's using the `/x` modifier which would turn the '#' character into the start of an embedded comment. (see [docs](http://perldoc.perl.org/perlre.html#%2fx)) Even in that case, a backslash in front of the '#' should turn it into a normal character, like this: `\#`
As long as you arent using the x flag you should be fine. The x flag allows for things such as comments and also causes the regexp engine to ignore whitespaces. If you want to use the x flag for whatever reason, you can always escape the #. To do this simply use "\". This tells the regexp engine to ignore the special use and just look for the character itself. For example if you wanted to search for "(" you would need to escape this character so to do so you would simply type \(. Hope this helps.
Okay I tried this, and the link /u/zyzzogeton suggested and there was no change. It looks like this `/\#text1|\#text2|\#text3/i` If that's what will really work, it could ultimately be a bug in the program. Just figured maybe it was a PICNIC (Problem In Chair, Not In Computer). *Just noticing when I hit save, it's missing characters. However, I typed exactly what the link suggested.
Thank you for helping me, I really appreciate it!
Sorry, I meant to include that and got distracted. To match any number of characters in a regex you use `.*`. A `.` tells the regex engine to match any character. The `*` is called a quantifier; it says to match the last atom (in this case `.`) zero or more times. In your case, I would say you don't really want `.*`, just saying `/.(text1|text2|text3)/s` should work. That should match any character followed by text1, text2, or text3. It is possible you want `/[^a-zA-Z ](text1|text2|text3)/s` instead. This uses a negative character class to match any character that isn't a through z, A through Z or a space followed by text1, text2, or text3. This would avoid accidentally matching abctext1.
The Pink Camel book (as the first edition of "Programming Perl" is known) is really only going to be of historical interest. A lot of the code in "The Perl Cookbook" will still work just fine. But I would worry slightly about giving it to someone who wasn't already familiar with modern Perl programming practices. Things have moved on. And the code in the Cookbook is going to contain some rather outdated idioms and won't mention many modern CPAN modules that would make the examples rather simpler.
It hasn't been updated yet is my guess.
I have to commend you. Your support is thorough, understandable and most likely 100% correct. After trying every single one of your solutions with none of them working, I decided to do some digging on WHY none of this was working in the app. Turns out, Facebook slapped these guys with a C&amp;D to remove the feature to filter out words (most likely for advertising reasons). So all the coding in the world couldn't get it to work. So, I apologize for wasting yours and everyone's time providing me with what are most likely correct and working solutions! I really thank you and appreciate your help and if I ever need any RegExp help in the future, I know what to reference. If you're interested in actually filtering out words on your Facebook, I did find the API that works with the most recent version of Firefox. I have successfully removed the annoying baby photos from my newsfeed. [Link](http://www.fbpurity.com/fbpurity.FRTNSVN-R.xpi)
Meant to thank you for this link suggestion!
There aren't any core modules for parsing HTML. My favourite from CPAN at the moment is Mojo::DOM. 
and since it's pure-perl you can [fatpack](https://metacpan.org/pod/App::FatPacker) it if that makes you happy.
Fatpacking something pure-Perl like Mojo::DOM may be the best option. I'm amazed that app exists, so thanks for sharing!
It depends on what you are trying get out of the HTML document. I am usually after a needle in the proverbial haystack, and, for those purposes, [HTML::TokeParser::Simple][1] and [HTML::TableExtract][2] have always worked well for me. [1]: https://metacpan.org/pod/HTML::TokeParser::Simple [2]: https://metacpan.org/pod/HTML::TableExtract
I am using XML::LibXML::Simple to transform XML/HTML into a perl structure and for querying Data::DPath.
this was very helpful. Thank you. I have some more code from some template if you'd like to take a look
In response to your fourth point; what do you mean by onShutdown (main()) line? Where in onShutdown is it calling the main function? 
Definitely. The key difference, for those who don't want to go compare, is that Test::PostgreSQL sets up a whole PostgreSQL *instance*, but Test::PgMonger uses the same instance and sets up a test *database*.
It seemed like u/raiph was interested in helping me out. I am making the most out of it by myself anyway. Inexperienced perl developer looking for guidance is all. 
Thank you for your posts, they've been very interesting.
&gt;Is there a bettery way than regex? [You can't parse HTML with regex.](http://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454#1732454)
&gt;Color highlighting will not work unless you are in a console that understands ANSI escapes. AFAIK, cmd.exe versions that came with Vista through early releases of Windows 10 did not. That can't be right: `ack` on windows *always* produced its results in color, ever since (at least) XP. There moust be something else going on.
ack[1] and others don't use ANSI escapes under windows, they use WINAPI functions (like SetConsoleTextAttribute) to accomplish the same thing. [1] - ack actually uses [Win32::Console::ANSI](https://metacpan.org/pod/Win32::Console::ANSI) which wraps these API functions in perl and pretends that the console supports ANSI sequences. 
Sure. There is an issue open on GitHub regarding further progress.
I agree, I really enjoy reading these and hope you keep them coming!
Does it matter where `JESDS` is found in the filename? What if the filename is `JESDSPDM_FOO_BAR.txt`? Should the `JESDS` be replaced? Do you want to print the filename if there is no `JESDS` present? This could get you started. #!perl use strict; use warnings; use feature 'say'; my $filename = shift or die "Usage: $0 filename\n"; say $filename if $filename =~ s/JESDS/AAAAA/
So still learning Perl myself, but I can show you a similar Python solution and point you to where Perl has doc on this in Perldoc. There are already great (perhaps very perl idiomatic) examples below. How I would solve it: 1.) split the file name string into several sub strings based off of the "_" character. 2.) grab the 3rd string (2nd for languages that start counting at 0). 3.) compare that string versus "JESDS". 4.) if the string matches, replace it with "AAAAA" 5.) if it doesn't match pass filename = "PDMMEDT1_JOB01234_JESDS_JESYSMSG.txt" if filename.split("_")[2] == "JESDS": filename.replace("JESDS", "AAAAA") This should help you in the right direction, but could yield an unintended error if there is a JESDS string somewhere else in the filename. For that reason you'll want to be pretty explicit. Perl is a great language for processing text data and has the equivalent of the "split" and "replace" functions in Perldoc. Assuming Perldoc (builtin documentation program) was installed with your version of Perl (my system Perl doesn't have it at work), you could run: "perldoc -f split" without the quotes and read up on it (or google). The regex ways of doing it also work and are very common in Perl (I think the origin of modern regex), so if you use Perl I highly recommend you learn to use them. Python has an "re" module for this, but I don't see it used near as often. http://perldoc.perl.org/functions/split.html
When I click on the link that doesn't work, I get a 500 (Internal Server Error) message. When debugging web programs, you should always interpret that as meaning "look in the web server error log for more details". As the code is exactly the same in the two environments, it's impossible for us to know what the problem is without seeing any error messages. You're right to mention how old the code is. Do you have any plans to fix that? **Update:** I know you specifically didn't want any comments on your code. But over my lunch break I [rewrote your code](https://gist.github.com/davorg/207dee895ee44e84d91a230a516000f5). That's not how I'd do it (I'd use a real templating system, a framework based on PSGI/Plack and a database) but at least it is now strict/warnings clean and no longer contains any global variables. It's not shown there, but I changed singledetail.tpl too. All of the places where values from the database are inserted are now clearly marked with `&lt;% VARNAME %&gt;`. I think this makes the template more maintainable.
You could also split up the filename and join it back together like /u/captainjimboba has suggested, perhaps you'd find that approach more understandable. #!perl use strict; use warnings; use feature 'say'; my $filename = shift or die "Usage: $0 filename\n"; my @parts = split '_', $filename; $parts[2] = 'AAAAA' if $parts[2] eq 'JESDS'; say join '_', @parts
Hello, I made a big change to the libcbitcoin-perl library. I changed the dependency from cbitcoin (unmaintained) to picocoin (maintained currently by jgarzik). So, to run libcbitcoin-perl, you have to compile picocoin to get a picocoin-dev deb package. That is available on my [hk-test1-atm branch of the picocoin library](https://github.com/favioflamingo/picocoin/tree/hk-test1-atm) 
[Define updated](http://www.ithacaestatesrealty.com/dev01/property_detail_sample.htm). The sample is done in closer-to-current standards (jquery/bootstrap/html5-ish) but is still not mobile friendly and the styling is still old - the last part b/c the owner is old and likes what he likes - that part will be a slow process. Re: CGI/Perl, that's another nugget. With this update, CGI will be completely gone, just Perl at that point. The CMS, if I can call it that is very antiquated too, but: 1) the functionality does what he wants 2) I'm not sure current CMS's would be able to do it as straightforward as the Perl scripts do and 2a) Any new solution that does not keep administration as simple as it is now will be a show stopper. Back to the current issue - I turned on the GoDaddy error logs last night before posting - the error kicked back says: [Thu May 19 22:01:38 2016] [10932342] [cgi:error] [client 180.191.134.184:20995] AH01215: suexec policy violation: see suexec log for more details, referer http://www.ithacaestatesrealty.com/ [Thu May 19 22:01:38 2016] [10932342] [cgi:error] [client 180.191.134.184:20995] End of script output before headers: propertydetail.pl, referer http://www.ithacaestatesrealty.com/ [Copied to this file,](http://www.ithacaestatesrealty.com/web_error_log.html)I see 4 error log files in GoDaddy's interface, each of the 4 appears to have the same style of information - none are labeled suexec mentioned in the log. the line 60 error only occurs once, but I'd like t think that is a clue... now is that line 60 of propertydetail.pl or commonsubs.pl? It looks like propertydetail.pl to me - how would I insert CGI::Carp qw(fatalsToBrowser); to get this error to return to browser ([It does look like the CARP module is installed on GoDaddy](https://www.godaddy.com/help/perl-details-on-linux-shared-hosting-2503)) 
suexec problems usually indicate that either your web server is running under the wrong user or the file permissions of an executable file are too loose. I'd start by checking that the permissions on both the CGI directory and the program itself are 755. If that's not the problem, then I suspect you'll need to talk to GoDaddy's customer support (and good luck with that - their support for Perl isn't great!) It's worth pointing out that Carp and CGI::Carp are two different modules. The page you link to only mentions Carp, but I'd be surprised if CGI::Carp isn't there too. Actually, no, I wouldn't be surprised at all. GoDaddy are completely capable of doing something as stupid as that. To add CGI::Carp to your code, just add: use CGI::Carp qw/fatalsToBrowser/; Do it somewhere near the top of `propertydetail.pl`. The line after the existing `use CGI qw/:standard/` will be fine.
What are the permissions of the pl files? They should be set to execute. 
These programs are considered CGI. They implement the CGI protocol and they use the CGI.pm module. It is quite possible to write web applications in Perl without using CGI (either the protocol or the module). If you're interested in doing that then I strongly recommend that you investigate PSGI/Plack (or, more likely, a framework like Dancer2 which uses it).
I think I've winnowed this down to a permissions issue (now doing the GoDaddy phone wait as I type this out). That's the verdict: 604 for permission, instead of 755. Part of the problem was me using the CPanel interface and Dreamweaver CS6, neither of which show permissions. Filezilla installed and problem solved! Thank you to each of you for trying to help. As is customary, I learned a lot through the troubleshooting process. On to installing the updated html template, at least updated to 2010 standards. * 
Thank you! =D
I believe it is the goto language at where I work. I love Perl.
Do you expect an objective answer asking in the sub-reddit for that language? Or do you want us to talk you in to taking that job? Here's some things you can do to sort this out for yourself: Look at http://www.tiobe.com/tiobe_index. Then go back and look at previous years results. Where does Perl stand now? What is the long term trend? Is it growing, level, or in decline? When something is in decline, there tends to be a glut of qualified programmers that push not only wages but working conditions down (expectations for each individual programmer up with career development opportunities down). Ask employers about team sizes and typical projects. In the worst case, one programmer is responsible for multiple large clients each of which has a flood of bug reports and feature requests. In the best case, major feature efforts have teams, and there are teams on QA, support, etc. This varies radically by language and strongly effects working conditions but pay tends to be the inverse of responsibility level. Search for Perl job postings on Dice, HotJobs (is that still around? seems like they all are forever even though they're all terrible), CraigsList, jobs.perl.org, etc. Look at the pay offered for the positions versus the skills required. Try to figure out how long a company has been running the same job ad, trying to fill the same positions. This can indicate a lot of demand in a growing company, or it can indicate a badly below market pay rate. This matters if it happens to be the case that you get "stuck" working in Perl after having done it once at this gig but then move on. Look on LinkedIn etc for resumes of people who are currently employed at different companies. Did they list Perl on their resume? Are Perl programmers welcomed into Java jobs, or do they have to omit this fact? What kinds of jobs do ex-Perl programmers wind up getting? Try to find some at Google, for example. In other words, if you take one Perl job, are you going to get stuck writing Perl? Google things like "code written in Perl" and "Perl programmers". I wish I could say that we're past technology tribalism, but people have strong opinions of not only languages, but people who program in those language. When you think of VB programmers, what comes to mind? Or PHP? Or COBOL? That might be a lark; you might be free of biases and prejudices, but even so, you should be investigating how other people feel about that technology if you're concerned about keeping yourself well positioned in the industry. It's unfortunate that being a generalist willing to tackle anything does not result in a resume that makes you look like you can tackle anything, but instead too often makes people look technically irrelevant or even like they have poor choice. This isn't just a problem with Perl; I'm current doing some work with VB and QuickBooks. I have zero intention of putting this on my resume. For better or worse, there's a cycle to things here. If you look like you're taking second tier work, it's harder to get anything but second tier work, which doesn't value developers enough to give them paid opportunities to develop new skills, which continues to make you even more irrelevant in the job market. If you spent a few years programming Flash, what impact would that have on future job searches? If you spent a few years writing PHP, how would Java or Ruby shops feel about you as a programmer? It's up to you to decide how to respond to these inherent biases, but you should be aware of them. I don't want to make specific comments about Perl (you need to figure that out for yourself), but by way of context, most of the code written in Perl at the height of Perl's popularity during the dot-com boom was written by programmers who came in without a lot of programming experience (they were hiring everyone then), worked in environments without testing/refactoring ethics (high growth companies in a competitive market), and used Perl back when code in it much more closely resembled "shell scripting". Asking if something is dead is meaningless; nothing is dead. Someone ran a successful GoFundMe for a modernized C=64 clone that uses SD instead of floppies and is more compact while keeping the same styling. Someone else did a successful pre-order for updated Commodore Amiga video cards that do higher color depth and resolution. Both of those sell in the $170 ballpark. Hopefully I've given you some much better questions to ask while trying to figure out if this position makes sense for you as a career move.
Yowie, amazing and thorough advice. It sounds like you've encountered some sweatshops. So what languages are you working in these days?
Nope, my company uses Perl for their entire testing framework. Perl is a wonderful language that makes a lot of difficult tasks such as networking, or system management. Perl is also very portable, with the exception of operating specific tasks such as terminating a process.
Perl is about as dead as duct tape.
Old languages never die. People still use ADA, COBOL and so on. Perl is still a pretty elegant language and a very good glue language. If you follow fashion you will be changing programming language every week for no rational reason at all. 
Perl does have lively [conference](https://en.wikipedia.org/wiki/Yet_Another_Perl_Conference) and [events](https://www.perl.org/events.html) schedules.
So dead we had to cancel YAPC.
http://modernperlbooks.com/
Yeah, a company fork of it. We have a depreciated hardware platform from the 70s that still works. "Why fix it if it ain't broke?" mentality. 
What?
&gt; Not sure if the module namespace mailing list is still around It is! http://lists.perl.org/list/module-authors.html
Thank you. Some times the sweatshops are more or less intentional. Sometimes its a side-effect of start-up culture or the realities of a small business. Big teams at big companies aren't ideal either. I'm in transition. I still get bits of Perl work now and then and I have a KickStarter to finish, but I'm trying to retool to do some combination of Java and/or data/researchy stuff with R, which means finally finishing my degree. I love Perl and I love hacking around in it, but I'm not making ends meet with it, it never was really good to me, and having it on my resume seems to be actively keeping me from getting other work, so I'm hoping having a degree gets me into the Java club (having worked with Java on and off since 1.1 didn't; not specializing in it and not having the degree makes me look like an outsider, probably rightly so). I've been involved in some research efforts and might be able to make a data scientist case for myself. But what is very likely to happen is I'm going to go broke and weary trying to do that, and then I'll do what I should have done a long time ago and just write games for the booming retrogaming scene in 6502 assembly. I have a 3D first-person Joust inspired thing for the Atari 2600 that's so very promisingly close to done.
True :)
Making my way through it now. We've been contacted by Internet Royalty! 
The \b would stop it before any whitespace.
The \b would stop before the *last* white space, no? Remember it's a hungry hungry .* we're dealing with. ;-)
You're right! My bad. I was transcribing by memory since I don't actually have an implementation of this (I barely know how to begin). ;)
First thing missing is strict and warnings - that's these two lines at the top of the code: use strict; use warnings; They'd point out several (potential) issues in your current code. If you're following a guide or tutorial which does not use these, have a look at http://perl-tutorial.org/ for some alternatives. In your current code, $code == $lock is a numeric comparison. To compare strings, use eq instead. See http://perldoc.perl.org/perlop.html#Equality-Operators for more details. This applies to the != comparison in the while loop as well. You don't need that comparison at all - just make it an infinite loop. while(1) { ... } will keep running until the code hits last;, which will bail out of the loop. Note that this line: $code = $thirdcode or $rightcode; could be written more simply as: $code = $thirdcode; If you wanted a variable that contained more than one potential answer, use an array instead: my $code = { $thirdcode =&gt; 1, $rightcode =&gt; 1 }; and rewrite the check as if($code-&gt;{$lock}) { http://perldoc.perl.org/perlreftut.html may be of some use there. Why is this piece of code in there? #Pause $plum = 2; while($plum--){ sleep(1); } If you wanted to wait for 2 seconds, why not just sleep(2); ? What's the purpose of the starting delay anyway?
I think you mean `ne`.
Here's a simple approach. First, the Regexp::Common module on CPAN can gives you a regex that matches any URI: use Regexp::Common qw&lt;URI&gt;; say $1 if /\b($RE{URI})\b/ You can also narrow that down to certain sorts of URI if you want; see the Regexp::Common and Regexp::Common::URI documentation for details. With a URL regex from there, you can do this: my $replacement = '...'; s{\b($RE{URI})\b|/}{ $1 // $replacement }ge; At each position in the string, the regex first tries to match a URL with a word boundary on each side, capturing it into `$1`; but if that doesn't work, it falls back to matching a single slash. If neither can be found, it moves on to the next position in the string. If one of those choices is matched, Perl moves onto the replacement, as expected. In this case, the `s///` operation has the `/e` flag, so the replacement is treated as code to execute. The code merely yields the value of `$1` (the original URL as found in the string) if it's available, or the `$replacement` text otherwise. So URLs are effectively left unchanged including all their slashes, while other slashes are turned into the replacement. This seems much easier than fiddling with look-arounds, especially given the constraint that look-behind assertions must be fixed-length. 
Hey, that's clever too! It would have never occurred to me to use $1 as "default value". That definitely solves the problem even if not using the module you mention (which I will, only I didn't think of searching the CPAN either; I should know better at this point.) Thanks so much! 
vim, with vim-perl, perlomni, syntastic, nerdtree, ctrlp, and vcscommand. Because it's awesome.
Me too. Never found it to be slow, even on quite large files.
I do everything in `vim` (and could use plain old `vi` if that was all that was available). Why? Because `vi` is what I had when I learned my craft. It's really the same reason I learned Perl. It was what was available. It's hard to explain, really, how few choices we had back then (1996).
Learned on, and always used vim. 
you had emacs.
Even nicer when you throw ecb into the mix as well.
I am interested to hear your findings. I used the following two scripts to compare the two: #!/usr/bin/perl use strict; use warnings; open IN, "&lt; /tmp/texfile" or die "$!\n"; open OUT, "&gt; /tmp/outfile" or die "$!\n"; while(&lt;IN&gt;){ my $rev = reverse $_; $rev =~ s/\/(?!(.+\/\/:.+)|(\/:.+))(?!(?&lt;=\/)(?=:.+))/x/g; $_ = reverse $rev; print OUT $_; } close IN; close OUT; and #!/usr/bin/perl use strict; use warnings; use Regexp::Common qw&lt;URI&gt;; open IN, "&lt; /tmp/textfile" or die "$!\n"; open OUT, "&gt; /tmp/outfile" or die "$!\n"; while(&lt;IN&gt;){ my $replacement = "x"; $_ =~ s{\b($RE{URI})\b|/}{ $1 // $replacement }ge; print OUT $_; } close IN; close OUT; At first, I ran it through with a 2.8MB text file, containing roughly 100,000 lines containing text like this: some // text here Some more text ///////////// A word or two and http://www.yahoo.com/index.html and more http://www.google.com/some/super/long/path/and/_shit/1.jpg and some more words that ////// don/t reallt matter/that/much to me. but :/blah/blah/blah some // text here Some more text ///////////// A word or two and http://www.yahoo.com/index.html and more The resulting speeds (from the time command) came to show that mine did it in 0.292s while the second did it in 7.111s. Now, I thought that this might not have been a fair chance since some of those seconds could have been to the extra dependency so I beefed up my text file to 3.1 million lines and 128MB and ran the tests again. In that large case, mine did it in 18.147 seconds and the other method did it in a 3m45.383s. So in my cases, it seems that the extra dependency and harder working regex causes a lot more strain than text manipulation. 
Not even remotely. It's widespread. It has a lot of prior art and modules. And whilst it's looked upon somewhat snobbily by programmers, it's an excellent language, and particularly well suited for what is now called "DevOps" (Which is a new word, to describe a thing I've been doing for 15 years. In perl). Part of the reason it's looked upon snobbily is because there is some nasty perl code out there. And it's true, there is. But then, there's also some pretty horrific javascript, python, java, C, C++ etc. ... basically, you can write horrible code in any language. But you don't _have_ to, and a copy of Modern Perl and install perltidy, and perlcritic and you'll be good to go. In terms of major competition - it's a scripting language, but one that works perfectly well as a 'proper' programming language, since it supports parallelism (in a variety of ways), object oriented code (hand rolled, or many use Moose now) and lets you make a lot of the C native system calls. Perl 'feels like' C, syntactically, where Python (it's only real major competition) 'feels like' Java. I think that's the major reason for the surge in the latter, relatively.
https://xkcd.com/224/
[web-mode](http://web-mode.org/) completes the trifecta.
I'm not convinced that directly comparing the performance of those two programs is reasonable; using Regexp::Common to find URLs obviously has to do a lot more work than using a simpler but less precise regex. That is, since the two programs aren't doing the same job, we shouldn't expect them to have comparable running time. This revised implementation uses an equivalently-simple pattern for matching URLs: s{(\w+://\S+)|/}{$1 // 'x'}ge With that change, the speed advantage for your approach is now roughly a factor of two on my machine (and the advantage seems to be constant across inputs of varying sizes and complexities). There are certainly situations where that factor-of-two difference would matter greatly; correspondingly, there are also situations where it wouldn't. On the flip side, the two approaches also differ in maintainability. Changing the reverse-and-lookaround approach to use a more precise URL regex would be significantly more difficult than it was to change my program to use a less precise one. (That's why I didn't try to compare the two approaches by having both use a more precise URL regex.) I also note that your reverse-and-lookaround implementation has at least one bug: it fails to replace the slashes in a non-URL line like `://`, or the final slash on a line like `http://example.com/ /`. Fixing those isn't terribly difficult, but I do wonder whether the additional complexity of that approach and/or the difficulty of matching URLs are contributing factors in the existence of the bug(s). 
My mistake, fellow emacs apostle.
Yes, it does. I'm using Strawberry myself.
Not at a computer to test, but it looks like you're calling pack with an integer written in hex notation instead of a character string, which is probably not doing what you want. 
aha! That makes sense, thank you. This works: `perl -E 'say unpack "B8", pack "I*",0x2d`
Very interesting. I also have a soft spot in my heart for Mason. It just makes far more sense than most of the other templating systems I've used.
I'm using the Plugin on OS X with the community version and it works like a charm.
I loved Mason.
As much as I love the word hangry ( http://www.urbandictionary.com/define.php?term=Hangry ) I think he means hungry. I'd comment on blogs.perl but the site's still broken for me.
http://bootleggames.wikia.com/wiki/Hangly-Man
The example I gave only works as a oneliner, i.e. a command you run directly without any source code file. `-e` is for providing the source of the program as an argument, so you can't use that if you're putting things in a source file. And the single quotes are for the shell, they are not for perl, and using them results in an invalid program. If you must have a source file for some reason, then I suppose you could do this: #!/usr/bin/perl -i -p s/\r$//; However, what's the point? Just use the oneliner. If you don't want to type it out, add it as a shell function in your startup file, e.g. for bash: dos2unix() { perl -i -pe 's/\r$//' "$@" } 
You could modify the perl script to recursively walk a directory tree looking for files, but that would be more than a little work. There's no simple switch to flip to do that, you'd have to wire something up with a module like [`File::Find`](https://metacpan.org/pod/File::Find) or similar. There are a couple of easier ways. The first is to use `find`. If you have your script saved as `d2u.pl` and it's executable bit is set and it's located in the current working directory, then you might do something like $ find /path -name '*.txt' -exec ./d2u.pl {} + `/path` is the top of the hierarchy to search; you can use `.` or omit the argument if you want to search starting at the current working directory. And you can adjust the path to the script as necessary, including writing just `d2u.pl` if it's in the path. As written this will find all files matching the glob `*.txt`, but you can adjust that as necessary. If you're using a shell alias or shell function instead of a script file, then you can't use `-exec`. You can do something like this instead: $ find /path -name '*.txt' | while read -r filename; do d2u "$filename"; done This assumes that you named the shell alias/function `d2u`. This version is a little bit icky compared to the previous one, since it will run perl once for each file, instead of passing batches of multiple files. That would matter if you're dealing with huge amounts of files, but it's not critical. This one also doesn't work for file names that contain newlines, but hopefully you don't have any such files; there's a way to modify it to use the null character as the delimiter if that's really necessary, but hopefully it's not. Another option is to use the shell's built-in globbing function. bash has the ability to do recursive wildcard matches, but it's not set by default. $ (shopt -s globstar; d2u /path/**/*.txt) This is bash-specific. I'm sure there's an equivalent way of doing this if you're using zsh as your interactive shell, but I'm not familiar with zsh. The parentheses run the command in a subshell, which is a way of ensuring that the change to the shell option `globstar` (which enables recursive expansion with `**`, which is disabled by default) is localized to this command and is effectively undone when the command completes, since the change was made in a subshell which exits. This is not strictly necessary but it's good shell hygiene. This will work equally well for the script version or the shell alias/function version (substituting the appropriate name of the script of course), and it avoids invoking a separate instance of perl for each file, which is also good. But unlike `find` which has the ability to detect and cope with maximum argument length limits, this will try to stuff every last filename into one single invocation, regardless of whether it will fit or not. You'd probably get an error like "argument list too long" if there are too many files. Using `find -exec` (and/or `xargs`) is really the best when dealing with a large number of files, and technically there's a way to use `-exec` with a shell function/alias, but it's kind of obscure: $ export -f d2u # assuming your shell alias is named 'd2u' $ find /path -name '*.txt' -exec sh -c 'd2u "$@"' _ {} + The first command makes the shell function/alias available to the shell being invoked. That shell is not a login nor an interactive shell so it won't generally be reading your aliases (depending on how you have things setup) which is a performance optimization which makes startup a lot faster. The `export` makes the function available explicitly. The second command does the actual work, by running `sh -c 'command'` which lets the shell invoke the command, which makes it possible for the command to be a shell alias/function. The _ is just a dummy argument which doesn't do anything but take up a slot. The `"$@"` expands to the positional arguments starting with `$1`, whereas when you run `sh -c` the arguments following the command get stuffed into the positional arguments starting at `$0`, so the first one would be missed by `"$@"`. `_` is just there to soak up that spot and offset everything by one spot. This last one is probably too obscure for general use but I figured it's worth mentioning for completeness. 
Also note that if you just want to test your packaged distro, you should be able to run `make disttest`.
Considering the fact that PERL was originally designed as an 'in line text processor' makes it ideal for speedy analysis of strings and very efficiently addresses the string to hex conversion a fuckton faster that Python. All of your IDS/IPS functions are primarily written in PERL, because of it's string conversion speed. I don't think the author of the video understands the true nature of the technologies. Python is bigger and more supported, along with being so easy a caveman can code in it. PERL is for speed.
Python taught me just how cosseted I am in Perl, I was helping my son with a Python game and wanted to store the variables in hash of hashes, so I tried the Python for $game{player1}{player_name} = "bob"; and it wasn't having any of it, Google suggested I had to do some horrible deceleration thing for each level, it was only later I discovered this perfectly natural feature was called [autovivification](http://perlmaven.com/autovivification) and was an addon in Python and most other languages. I was equally surprised that something as ubiquitous as regular expressions was another Python addon I guess its a philosophical thing Perl is all mod cons Python requires you to select your furniture on moving in. The one thing I hate in Python is using white space for loops etc... I like brackets it make is explicit where each part of the construct starts and ends (and emacs will show you matching parentheses) 
Worthless, Especially since perl6 is now out.
I dunno I genuinely find it easier to identify a } rather than a to end a block.
The truth will set me free?
It's not PERL. It's Perl for the language and perl for the interpreter. Never PERL.
How many other ways can you spell it? That is the most ignorant statement I have read all day. There is only one perl() Every thing else is a description and NOT strict
I told you exactly how to spell it depending on how you use it. You need to read more apparently.
Perl is the name of the language not an acronym (not to say that backronyms don't exist)
Alternatively, you're captured by Guido's idea of what indentation should look like.
We're all consenting dynamic language lovers here, surely! What would be laughable is if the lab-coated one were using Java :-)
or library 
syntactically significant *indentation*. Other white spaces, such as trailing white spaces, are rarely significant. On the other hand, indentations, when people use them, are almost always significant. It may not be significant to the compiler, but it is always significant to the coder who indents. It is semantically significant. Unlike trailing spaces, indentations are always explicit and visible. Make semantic significance syntactically significant too, sounds to be a good idea.
Have you seen how obfuscation work? It often is indentation that makes the code readable.
And they left out the lady saying "JUST #@*$&amp; DWIM!!" after switching to python. After moving to job where I had to learn Python, I find having to cast variables to different types, mistakenly using re.match instead of re.search, etc. very frustrating. I'm sure some is just a learning curve, but I love the DWIM philosophy Perl has.
Just thought I'd add, for comparison to Python, Perl has an expression `do { }` which allows statements and so actually allows you to have block structures in the few places where Perl normally won't allow you to!
You had a few errors, as well as some odd syntax. First, it's almost *required* to 'use strict' and 'use warnings'. Unless you're doing a one-liner, they always have to be used. They're very helpful in telling you what's wrong. This part: $code = $thirdcode or $rightcode; Doesn't make a lot of sense. You've defined $thirdcode, so $code will always be $thirdcode. And if you want to compare the response to one of your answers, why not just do that in your while loop? It makes the code a lot more understandable, since anyone can see what's being compared to what. The conditions of your while loop are unnecessary and won't work, because '!=' compares numbers. You want 'ne' to compare strings. But you can omit that altogether and just use anything that would remain true and the loop will never stop asking for an answer until you get down to that 'last' in the if/else block and it terminates. You don't define $lock before using it, so that's an error as well. The variable name $lock was ambiguous. I changed it to $answer, since, well, that's what it is. Now when you read the code, you know it's someone's answer. When you do your check to see if the answer matches the right response variable, you don't check to see that it's defined; if someone just hits enter then you get an error. Also, your answers were case-sensitive. I put a call to uc() in there to make them case insensitive. Anyway, I've re-written it a little for clarity: #!/usr/bin/perl use warnings; use strict; my $firstcode = "A"; my $secondcode = "B"; my $thirdcode = "C"; my $rightcode = "Orcinus Orca"; while (1) { print "The door to the Shamu Stadium is locked and you can only enter by answering the golden question:\n" . "What is the scientific name of an orca?\n" . "A. Orca Orca\n" . "B. Orcardo Orca\n" . "C. Orcinus Orca\n"; my $answer = &lt;&gt;; chomp($answer); $answer = uc($answer); if ($answer &amp;&amp; ($answer eq $thirdcode || $answer eq $rightcode)) { print "Correct! You have unlocked the door to the stadium!"; last; } else { print "Incorrect response '$answer'. Try again."; } print "\n\n"; } I also omitted the sleep bit at the top. I'm not sure why it was there. If you want to wait before asking again, put a sleep() call at the bottom of the while() loop. Also, no reason for sleep to have its own loop if you want to sleep for two seconds. Just call it like so: sleep(2); and it'll wait two seconds. 
Nothing wrong with indentation. But using braces makes explicit where the block ends, and makes it utterly trivial to 'reflow' if you need to wrap something in a loop or condition. Or y'know, not have your code mangled because you sent it in an email, or posted it in a forum, or something. 
Lots of people use javascript too. Doesn't mean it's a good language. 
The logic is, it is the indentation that eases people identifying blocks (start and end) rather than braces (as your parent statement appears to state). Python's ':' is also extra, serves the same role as braces. In fact I have also a meta layer filter for python so when I write python I don't need type that ':'.
If you really were serious about getting programmers to join you, it would be much easier if you used a real version control system (like git) and had a public repository (like github) and removed the "versioning comments" which muddle up the code.
This may be useful to iterate result immediately, without additional checking for undef. like: foreach my $element (@{get_array_ref()}) { } Using the same with java. In some places it's null or List and just List in other places. So it's depend on situation.
[removed]
Not industry in a strict sense, but for my master thesis I wrote and simulated a device for a lot of parameters; the overall control script running all the programs (design vision, encounter, modelsim, primetime) and reading all the reports to determine the next simulation parameters, was written in perl.
Nice, did you have it on github?
&gt; if I ask for a hashref and there's no hashref that matches the request, isn't that an undefined result? Possibly. But we can ask the same thing about lists. If you ask for a list of things, but there are no things, do you get an empty list, or an undefined value? Linear algebra says you get an empty list. I guess it's the same for a hash? BTW `%{$result}` isnt' a scalar, it's a hash. `$result` is a scalar.
Right. I guess I just don't like treating hashrefs as lists. I understand it, but I felt it wasn't intuitive. Hashrefs to me are more akin to an object than a list (even though Perl can blur that line and treat/cast hashes as lists of doublets) &gt; BTW %{$result} isnt' a scalar, it's a hash. $result is a scalar. Sorry, read things wrong. My mistake.
&gt; The "Perl Best Practices" book recommends a bare return (i.e. return;) from subroutines to indicate errors, Let's be clear about one thing here. This is indeed the advice from the book, but it is in fact not a very good idea. Here's why: A subroutine should not be context sensitive **some of the time**. Either it is, or it isn't. If the sub is context sensitive for the successful case, then yes a bare return is a simple way of returning a context sensitive "nothing" for the unsuccessful case. But if the sub returns a *scalar* value for the successful case, then returning undef is the correct thing to do when things go wrong. Using a bare return in that case is just wrong and outright counter productive. This means the Perl Best Practice general advice to use bare return is simply wrong. And if you study that chapter with this in mind, you'll find that the example itself from the book does *not* warrant a conclusion to always use a bare return. *Edit:* Formatting.
I get that, but the more I think about it, the more I'm convinced this is a matter of mathematics: * You ask for a list of IDs. If there are no IDs, you get an empty list. * You ask for a hash/object of IDs. If there are no IDs, you get an empty hash. * The only way for you to *not* get a list/hash is if something actually went wrong. Makes sense to me.
Returning an empty hashref is not a general convention to indicate errors when the successful return value is actual data. 0, a false value or undef would more likely be used depending on the range of valid return values. In fact, in the DBI example you gave, *it's also not the convention*. From the docs: &gt; If there are no rows to return, fetchall_hashref returns a reference to an empty hash. If an error occurs, fetchall_hashref returns the data fetched thus far, *which may be none*. You should check $sth-&gt;err afterwards (or use the RaiseError attribute) to discover if the data is complete or was truncated due to an error. So, as you can see, in this case the author put a value on returning as much data as possible up until the error happens, which leads to there being no other way to indicate errors than for the caller to manually check. I don't think this is even the standard way to indicate errors in the rest of the DBI interface. If you're actually using vanilla DBI (which is complete, but not super convenient to use in application code), setting RaiseError is a much nicer way to deal with errors. But even then, using a higher level of abstraction API is better to avoid boilerplate for the simplest of tasks when a single line of code should do the job.
Sadly it is only too common for people to parrot the advice from that chapter, to the point of introducing Perl::Critic policies to enforce it. The book is in general very good, at least as a basis for discussion, but this chapter in particular has wasted soooo much time.
Like I said, it depends on the normal range of successful values. So undef would totally be a better error indicator if the successful return value is a hashref. I can't see any rationale for returning an empty hash. a) It is in fact not used as a convention in any CPAN library that I can think of. Probably because... b) It's the same as the normal return value of an empty hash, if the subroutine call was successful but simply didn't match anything (if that is indeed successful for this particular sub). This would be a more normal case when the return value is a list or arrayref. 
I couldn't decide where to post this because it could have belonged in several places. The general idea is that some methods in DBI are meant to return a collection of items and some are meant to return one item. From that perspective you want a consistent return type. Start with `fetchrow_hashref` you either get a hashref back or else you get undef. That is one or zero items, passed as "the item". In that way you might write: die 'got no results' unless my $row = $sth-&gt;fetchrow_hashref(...); For the collection style methods you say "give me a collection of these items" whether indexed by a key (fetchall_hashref) or a position (fetchall_arrayref). Lets take the latter because it is easier. You can now always expect that you are getting an array(ref) of any and all results, so you can code this as: foreach my $row (@{ $sth-&gt;fetchall_arrayref(...) }) { ... } If there were no results then nothing is processed in that loop.
There is no such convention in general, and in the specific case you pointed out it's because it's the obvious, most consistent thing to do. Undef would be weird and wrong. Code using `fetchall_hashref` would have to add a check for undef before using the return value as a hashref to avoid a crash, even though most of the time there's no reason to explicitly care whether there were rows or not at that point â€” code that has good reason to use `fetchall_hashref`, access-pattern-wise, will probably cope just fine with finding nothing. And if you *do* need to check, `if (%$data)` is hardly difficult. Hell, it's less typing than `if (defined $data)`.
Sorry, I don't, it was *grown* out of a need over time, more than it was designed and developed, so the comments are few or nonexistent, and there are more than a few warts. Basically it's a bunch of functions which have the task of: * Instantiating template files (read template, do some regex substitutions, save file) * Run program (export shell variables, system() a shell script stub) * Interpret report files (read file, extract data with regex) * Overall strategy main loop (binary search find the pass/fail threshold for one parameter, for a fixed set of values of the other parameters, interpolate between known successful designs to get more data points) * Glue functions
I used it primarily for * automating (from simple list of series of commands put together to a bit complicated workflow of running tests, taking care of background jobs getting hit due to various reasons, etc) * converting existing tests to suit changes for newer processor architecture * taking care of special cases for assembly tests to opcode conversion * generating verilog assertions for I/O modules like exercising particular address range, specific toggle of signals in a particular manner, etc (with consistent change in specification, it was easier to re-generate than meticulously writing it once manually, plus easier to add new modules) * and my favorite: RTG (random test generation, which required heavy text processing) for core processor.. not possible with functional verification methods like uvm which is suited for I/Os left the industry two years back, so I don't quite have a code example, but I put together whatever little portion of Perl that I needed as a [beginner guide](https://github.com/learnbyexample/Perl_intro/blob/master/Perl_intro.md)
Not in SQL. You fire off a query, and there are no results, you get an empty hash.
&gt;Edit: interestingly, fetchrow_hashref, which returns just one row, will actually return undef if there are no (more) rows to return. Makes wrapping it in a while loop easy. 
I don't do that. I don't like that it returns an empty hash.
If you don't use it, it doesn't affect you. Why do you even care then?
I was trying to find a justification for the logic. Ordering a pepperoni pizza, having the delivery guy bring you an empty box and telling you that they didn't have any pizza that matches my request, so they gave me the container.
Try `*.WHAT.say`. My point was the Whatever Star is a common feature of the language and not a special syntax invented specifically for `.pick`, as I read OP implied, which is why it's not so shocking to see it featured in the example code.
Yes, the `gather` should also explain what `=&gt;` are and what `%` is and what `my` is all about. You know, just to avoid unrealistic expectations of the reader knowing the language already. The documentation for novices exists. It's not our fault if you chose to ignore it. It's a pity you're so bitter about your Perl 6 past.
LWP::UserAgent is best in these cases.
Yes, it does
This is why I stopped taking the time to learn much Python. The tabs drove me nuts. What was worse is the nonsensical error you get when you mess the indentation up. It could only get worse from there so I packed it in. 
Is there a way with just the Perl base?
Getopt::Long has been in the core perl since version 5.0, which was officially released in 1994.
Thank you so much 
Thank you!
To see what else is a core library you can browse the docs for all included modules here: http://perldoc.perl.org/index-modules-G.html 
I am just not familiar with how to use them. I will pay around with it over the next few days.
[DBIx::Simple](https://metacpan.org/pod/DBIx::Simple) is quite nice.
My point is it isn't a lambda or closure. Try `( * x 2 ).WHAT.say` which is a code object and reports as `(WhateverCode)`. I will grant that `.pick(*)` is identical to `.pick(Inf)`.
You might want to start your perl scripts with the following; #!/usr/bin/perl use strict; use warnings; It might be a pain to adjust to `strict`, but it will enforce better habits and patterns. The `warnings` library will also generate more helpful output (though perhaps less helpful, until you get used to it) that will lead you to where your problems might be. The first problem I spot is you're opening the file with a variable-ized filehandle, `$FILE`, but when you attempt to loop through it, you drop the `$`. Try changing it to `open FILE, '&lt;', $filen or die "Can't open file file_to_reverse: $!";` or `my @lines = reverse &lt;$FILE&gt;;` edit: `reverse` will reverse an array, so in your use, it will reverse the lines (top to bottom -&gt; bottom to top), not the characters in the line. To reverse the letters/chars, you need `reverse(split(//,$string));` For giggles, I rewrote it so it wouldn't complain as much with the addition of `strict` for you; #!/usr/bin/perl use strict; use warnings; my @files_in = @ARGV; print "Files to reverse:\n"; foreach my $file_in (@files_in) { print " $file_in\n"; } my @number_contigs = (); foreach my $file_in (@files_in) { if (open my $file, '&lt;', $file_in) { my @lines = &lt;$file&gt;; # remove newline characters from the lines chomp(@lines); foreach my $line (reverse @lines) { print "$line\n"; if ($line =~ /gitnoC/) { # Assuming you want to reverse the order of the characters; my $num = reverse(split(//,substr($line,0,2))); print "$num\n"; push @number_contigs,$num; last; } } close $file; } else { print STDERR "Error: Cannot open $file_in: $!\n"; # die will cause the entire program to end; if you provide multiple # files and only one fails, do you want the whole thing to fail? #die "Error: Can't open $file_in: $!"; } } foreach my $num (@number_contigs) { print "$num\n"; }
Oh wow now I feel dumb. I have been changing around the code for 30 minutes and I didn't see I missed the $. Thanks for your answer
Thanks for your answer. Yeah I will add the first three lines. My mistake. Btw may I ask a question what does #!/usr/bin/perl do. Doesn't the compiler ignore it anways because it is a comment? 
This is a Unix shell thing. Files that have the executable bit set can be run directly (ie */path/to/myscript.pl* instead of *perl /path/to/myscript.pl*). The shell figures out how to run them based on the first few bytes. Specifically, if the first 2 bytes are '#' and '!', the shell reads the remainder of the line (up to the next '\n') and runs that, passing the original file as it's input. So *#!/usr/bin/perl* results in the shell running */usr/bin/perl* on the script. Windows, on the other hand, tends to determine how to "run" a script by examining its file extension. ^#! ^is ^sometimes ^called ^hash-bang ^or ^or ^shebang.
Oh wow that's nice. Going to use this from now on. Thanks for the tipp
`#!/usr/bin/env perl` is a better plan if you are going to share these scripts or use perl via perlbrew in your home. That will not assume a specific system perl install location.
 use CGI; my $whitelist={syslog =&gt; '/var/log/syslog', access =&gt; '/var/log/access'}; my $fkey = CGI-&gt;new-&gt;param('file_key'); if($fkey){ my $fname = $$whitelist{$fkey}; print `tail $fname`; } --------- I guess something like that may work but need to refresh it. There is no way -f will work on that script.
If you work in an environment where the version of perl you want is not located at `/usr/bin/perl`, then that may be a larger problem. I think this stems from OSX not having perl in that path, and I guess that makes sense. I honestly don't know, so I'm curious where this practice stems from. At work, there is a group of researchers that have 6 different versions of perl mounted over NFS because ... hard version dependencies? Or perhaps people who aren't aware they could fix their code, and use the standard package manager maintained versions. I don't know, I haven't had a chance to dig into it. Long story short, if that's why `#!/usr/bin/env perl` becoming more common, that seems more like a duct tape solution that will cause lots of headaches. But, maybe I'm just ignorant and there are very good reasons to support multiple versions of libraries and interpreters. Is it 'good practice' to develop in OSX, when it doesn't have the libraries and interpreters available in the code's final destination? TL;DR Why does using `env` seem like a hack, and not a proper solution to me? And why isn't it a 'hack'? edit: BTW, I'm fine with people using `env`, because it solves the issue of systems that don't have `/usr/bin/perl`, but it seems like a hack because what if they also don't have `/usr/bin/env`? Because some new version of OSX ships without it, or whatever.
You can also "use diagnostics;" which does more or less the same thing. (When code fails to run).
Some editors detect syntax. A "perl" shebang line is a pretty clear sign that it's perl. Others can infer by e.g. extension, grammar etc. 
What are you actually trying to accomplish here? Because looking at it - you read a file, then reverse it, and in doing so aim to get a little bit off the 'beginning'. The expensive part of your algorithm is 'read from disk', so reversing is pretty much a moot point. Why not instead: foreach my $filename ( @ARGV ) { next unless -f $filename; open ( my $input, '&lt;', $filename ) or die $!; my $highest_contig = 0; while ( &lt;$input&gt; ) { if ( my ( $contig_number ) = m/&gt;Contig(\d+)/ ) { $highest_contig = $contig_number if $highest_contig &lt; $contig_number; } } print "Highest contig in $filename was $highest_contig\n"; } And then you don't need to muck around with arrays or reversing or anything. 
I have multiple files and I needed to get the highest contig number(which is inside the file). I changed my code to look something liek yours after playing a little bit arond. My idea was when i reverse the array I can just use the first contig I find(beacuse it has to ahve the highest number). I was lazy and didn't want to programm a counter.
Note that currently no vendor compiles perl with Visual C++ 2013. Both Strawberry and ActivePerl use MinGW these days.
Of course, I am well aware of that. However, I have this odd desire to build a Perl with native platform tools and test modules using that. I use it to find, [report](http://stats.cpantesters.org/leaders/leaders-mswin32-all.html), and sometimes [fix](https://github.com/nanis?tab=activity) portability bugs. MinGW tools work tolerably well, but there are some [odd interactions](https://www.nu42.com/2016/03/tar-anomaly.html). VC++ 2013 was the first [freely available Microsoft compiler](https://www.nu42.com/2014/11/64-bit-perl-5201-with-visual-studio.html). VC++ 2015 is even better. Almost everything I use, including Perl6, Python, and Ruby build nicely with 2015, but Perl doesn't. And, it doesn't look like a simple config file change is going fix that.
I for one think it's great your finding these bugs, if that is what they are. To me this screams of a test suite, for verification of number precision.
I think that's pretty cool. Good on ya.
So are people being massive jerks for assuming `/usr/bin/env` exists, too?
Spam post. 
Yea I already reported it.
Raw CGI is an aging technology. Modern web application developers tend to use a framework to build their applications. I recommend [Mojolicious](http://mojolicio.us) and especially so in this case. With Mojolicious you can use forward the result of `tail -f` to the browser via a [WebSocket](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API) which Mojo has [built-in](http://mojolicious.org/perldoc/Mojolicious/Guides/Tutorial#WebSockets). I even have a [plugin](https://github.com/jberger/Mojolicious-Plugin-TailLog/blob/master/lib/Mojolicious/Plugin/TailLog.pm) (github only, not on cpan) which reads the log file of the current application (via `tail -f`) and sends it to the client. This could quite easily be extended to your use case.
Stop using perl that is different from what is standard or replace what is installed. You seem to have missed the point of my rant.
First, thank you /u/sigzero and /u/masta for the encouragement. Second, I wanted to mention that there has been some [progress in getting Perl to build with VC++ 2015](https://rt.perl.org/Public/Bug/Display.html?id=125714) since I last paid attention more than a year ago. Unfortunately, it does look like Steve and Daniel ran into a roadblock.
Thanks, I might try it out. Right now I'm using node.js and socket.io https://www.reddit.com/r/web_design/comments/4nf25y/wondering_if_what_im_trying_to_accomplish_is/
The reason is people have different requirements and constraints. That is a real problem people have, fighting against it rather than facilitating it will only exacerbate the issues of the users. Most of the large systems I've worked on end up having configurable environment systems with a prefix different groups can install to and switch between. At least then you know where everything is and who owns it.
I was interested in seeing what this would look like so I came up with the following example (perhaps /u/joelberger can point out any mortal sins I have commited): -- **EDIT** Code updated per /u/joelberger's advice - thank you. -- use Mojolicious::Lite; my $filename = 'a.log'; websocket '/tail' =&gt; sub { my $c = shift; $c-&gt;inactivity_timeout(0); # keep websocket alive "forever" my $pid = open my $log, '-|', 'tail', '-n', '0', '-f', $filename; die "Could't spawn: $!" unless defined $pid; my $stream = Mojo::IOLoop::Stream-&gt;new($log); $stream-&gt;on(read =&gt; sub { $c-&gt;send({text =&gt; pop}) }); $stream-&gt;on(close =&gt; sub { kill KILL =&gt; $pid; close $log }); my $sid = Mojo::IOLoop-&gt;stream($stream); $c-&gt;on(finish =&gt; sub { Mojo::IOLoop-&gt;remove($sid) }); }; get '/' =&gt; 'index'; app-&gt;start; __DATA__ @@ index.html.ep &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;tail -f&lt;/title&gt; &lt;script&gt; var ws = new WebSocket('&lt;%= url_for('tail')-&gt;to_abs %&gt;'); ws.onmessage = function (event) { document.body.innerHTML += event.data + '&lt;br/&gt;' }; &lt;/script&gt; &lt;/head&gt; &lt;/html&gt;
I see from that thread that you found http://stackoverflow.com/questions/3499152/minimum-websocket-nodejs-tail-example/34363535#34363535 . The example I gave you is not very different from that one. We both open a pipe from `tail -f` and send it back over a websocket.
The only "sin" I see being committed is not cleaning up on disconnect. That said, I looked at that module and I can't say that I agree with its methods. Honestly as long as you are on *nix I think that just opening a pipe from `tail -f` is enough. You might try replacing your use of it with something approximating https://github.com/jberger/Mojolicious-Plugin-TailLog/blob/master/lib/Mojolicious/Plugin/TailLog.pm#L16-L22
Will give it a go - thank you for the response!
Yes. Do you know how hackish, and how many problems that shit introduces? In addition to having to maintain all the different libraries that are needed, the tools wrapping around it to control the environment variables are often quite large and fragile. The reason people have 'different requirements and constraints' is because they do their development in different distributions of linux or OSX, FreeBSD, whatever. There's no standardization within the ecosystems that this development occurs, and that is a large problem and causes lots of, generally unnoticed, fallout. The different library requirements and versions of interpreters ends up making it exceedingly difficult for various groups to interact with one another, and for groups and developers to collaborate in development. Long story, supporting and maintaining multiple versions of the same libraries and interpreters introduces unnecessary technical debt. Devoting effort to doing something about that problem, such as driving initiatives to standardize a build environment would be very beneficial. Especially within scientific computing.
yeah last time I needed a daemon this is what I used. And because it's zero dependency pure perl, you can fatpack or otherwise embed the Daemon::Control module as well in case you have bureaucracy around your cpan stuff. It also supports plugins, an example of which is [here](https://metacpan.org/pod/distribution/Daemon-Control-Plugin-HotStandby/lib/Daemon/Control/Plugin/HotStandby.pm). Of course adding plugins means you're no longer quite zero dependency.
That's a really good idea. Maybe something to adopt at YAPC::Europe too? :)
$350 admission? Wew lad
The last time I did any sysadmin work was when for a Python dep I needed required the department environment to update libc. You can imagine how that went down. So our group bought their own infrastructure and I ended up looking after it all. About 10 servers and 6 users in all so nothing vast. The whole group became very productive, and I'm not going to say maintaining even that small setup was fun. But I think there is need for a slightly more decentralised deputised approach to systems. Sure if someone wants a different libc to the whole OS tell them to take a hike &gt;:3 But a modern Perl or an old Perl should be doable in user space without any hassle.
The last time this came up, i was told that prices of e.g. 60-100â‚¬ a ticket in europe were insane, and 300-1000$ is normal in the USA.
So YAPC was rebranded TPC?
For comparison, PyCon UK is ~100GBP, according to http://2016.pyconuk.org/tickets/, for 5 days. Droidcon UK is ~300GBP for 2 days - http://uk.droidcon.com/ From a company perspective, the YAPC prices seem quite reasonable, but it does seem to add a barrier to entry for potential new Perl users (especially when you add in hotel and travel costs). More emphasis on speaker passes might help encourage attendance? (they're free, if I'm reading http://www.yapcna.org/yn2016/costs.html correctly?)
More or less. O'Reilly owned the TPC trademark from back before that conference became OSCON. They haven't used the name in years. Probably could have argued in court that the trademark is abandoned, but who wants a legal battle when you can just email them and ask politely? They were cool with it.
[removed]
I think the point of this kind of testing is not to see how much you can squeeze out of perl5 code, but to just have 2 programs written in the obvious way and then get Perl6 to at least beat Perl5. It sounds like this goal was achieved. Given how much more advanced Perl6's runtime is, at least in theory, one would expect Perl6 code to run several times faster compared to Perl5 code. To even be relevant in today's dynamic language landscape, you pretty much have to offer competitive performance and memory usage profile while also delivering features that make programming as nice as possible. Without a good performance story, Perl6 will have an uphill battle to adoption. The fact that a huge issue like this was resolved only now, and that it singlehandedly more than doubled performance of a simple function call suggests that only very few people have really looked into the final code produced by the compiler and runtime with optimization in mind.
Yeah there is probably only three or four people who go that deep for optimisation work. Post having a profiler in Rakudo though where to go looking has improved since any user can just run `perl6 --profile program.p6` and pass on the output. You get the following sort of thing out http://mattoates.co.uk/files/perl6/bioinfo_profile_2016-05-12.html I pester #perl6 people quite often with my profile output and the runtime of the same code on MoarVM has gone from 33s down to less than 2s. Performance is getting there. The issue which is related to your worry, is that the work is not smooth over all the possible paths the compiler takes. So some syntax that is equivalent in rough meaning can be very different in how slow the produced VM instructions are.
Thanks for the details! Now if someone would do it for other YAPCs and Perl Workshops and send a pull request to https://github.com/yapceurope/perl-events... that is the source of http://yapceurope.org/
Just write a systemd config. Let the OS handle this stuff. You're going to screw something up if you try and do it yourself.
Yeah, it's not the same place it used to be. I think many of the old-timers have moved to [Soylent News](https://soylentnews.org/).
Wow slashdot still exists :)
My opinion is that one should avoid daemonizing from perl (or any other language from that matter). Write a normal program and daemonize it if needed by using specialized tools, systemd, daemontools , supervisord, daemonize, other init systems etc. 
Daemon::Control will output an init script for the circumstances when you need the os to do the management (I would assume that it's pretty easy to make it do systemd or whatever too). Daemontools is probably fine for sysadmins but it's a really hostile tool for developers. 
Putting on a conference is very, very expensive, and $350 (with a $250 early rate that lasted until a few weeks ago) is quite cheap. It also doesn't come close to covering the full costs of the conference. The rest mostly comes from sponsorship.
Why this incessant obsession with whether a language is a alive or dead?
I'd rather see people blogging cool new stuffs in Perl, than people talking about whether it's dying or not...
I'm building some production cloud AWS scripts using Perl. Found the Paws API to be one of the most complete for what I need(even if not we'll documented). It's a great tool for the toolbox when I need a Unix shell script that can handle data structures and OOP. 
I agree, lets stop taking about usefulness or death, just show me cool new applications or projects. This in the long run will help me be more productive.
it pays my bills. Let it "die." We will still use it and it will still pay my bills -- no matter what the bloggers and clickbaiters (" join us for the webinar next week and take part in the discussion!") might say.
Me too. I must be in heaven.
I found [this on SuperUser](http://superuser.com/questions/221359/count-the-number-of-words-in-a-pdf-file).
Have you tried using `pdftotext`? If you're on linux it should be part of the `poppler-utils` package - there is also a windows port. http://www.foolabs.com/xpdf/download.html You could do something like: pdftotext file.pdf - | perl -lane '$count += @F }{ print $count' However in saying that - the `CAM::PDF` sample code you linked to works for me - so I guess it's an issue with your specific PDF file. Can you provide the PDF file you're working with?
Thanks for the suggestions! Sure, here's a [link to a sample of one of my files](https://www.docdroid.net/hoXmj5w/49-pdfsam-aa.pdf.html). Additionally, for some context, my end goal is to extend this to many thousands of files in this format through a loop, and ultimately do specific word counts on individual speakers (although of course figuring out the simple word count is my first step). Edit: Just downloaded xpdf, tried pdftotext and was able to get a nice text file out of it, so making the jump to counting the words shouldn't be too difficult now! Thank you!
Admittedly, there are few interesting questions, but I'm sure TimToady will find some informative angles. Let's see how he responds to this uncouth rabble of mostly (from what I read) perl-haters.
Because a lot of people and businesses are invested in herding the masses into other languages. 
&gt; Given how much more advanced Perl6's runtime is, at least in theory, one would expect Perl6 code to run several times faster compared to Perl5 code. Being more advanced also means the p6 interpreter does more, for example type checks, which would require additional modules and overhead in perl5. Also, it has been a matter of development strategy to focus on correctness before performance. Users can expect continued improvements, now that most of the behaviors of the interpreter are properly defined and tested.
Last time I got made redundant, I had a new offer within an hour. Yeah totally dead. /s
Good to know I would be functionally dead in Silicon Valley. 
Been using [URI::XSEscape](https://metacpan.org/pod/URI::XSEscape) for a while now, and have been seeing some minimal gains. From what I can tell, it's a good module to use instead of URI::Escape if you end up using its features a lot, but as all things.. if your app or program does more than just process text/URIs (database lookup, etc) then obviously the gains made overall from using this are not as huge as the benchmark would indicate :)
When I try running this I get "wc: The term 'wc' is not recognized as the name of a cmdlet, function, script file or operable program..."
I bet the real problem was the strcat. This has to start from start of add something to the end of string every time, handily making the function quadratic in terms of string length.
Ugh they don't get it &gt; At ActiveState we are not shy about confronting myths head-on. Perl is vibrant and alive,and not nearly so fragile that our use of the term "dying" in a headline is going to do it any damage. Microsoft and IBM might be more concerned about the robustness and longevity of their products. We are not!
If this is something official, it should be announced somewhere so people know about it.
Here's my benchmark: https://github.com/perlancar/perl-Bencher-Scenario-URIEscaping/blob/master/lib/Bencher/Scenario/URIEscaping.pm (which should be pretty self-explanatory, it uses Dumbbench as the benchmarker). [The result](https://gist.github.com/perlancar/746fac9d877efd562396a19f768338ac) shows that URI::XSEscape still wins. This is on a Core i5 processor, perl 5.22.1. I've used sample strings from both URI-Escape-XS and URI-XSEscape distributions. More datasets are needed for a more complete picture. Also, URI::Escape::XS's startup overhead needs to be improved a bit (see the startup overhead benchmark). I tried replacing `use base Exporter` with `use Exporter qw(import)` and that shaves 2ms off the startup overhead so it becomes on par with URI::XSEscape.
&gt; Seeing it ruined my afternoon. That example would be considered polite compared to what happens on IRC. Perlmonks is probably the most approachable resource for beginners.
in the absence of `wc` this might do it: pdftotext myfile.pdf - | perl -nE ' $/=undef; @ct = $_ =~ /\b\S+\b/g; say scalar @ct '
Cheers, i posted a link. :)
You know, you CAN disagree with someone without acting like an asshole in the process.
My article is about `URI::Encode::XS`
ah, interesting policy, I didn't know about this
thanks! 
I think that his is a excellent article, not only for the text itself, but also for its references. As a side question, I am wondering why one could still use XS for any other thing than self-amusement, given the existence of SWIG (this is mentioned in the referenced Steven W McDougall's XS introduction): one can ship the SWIG-generated files within the package as would have to do with the XS files. They are also XS after all! Another advantage is that the SWIG script is useful not only for Perl bindings, but for many other languages. If extra dependencies are not a problem, then one could use Inline::C or FFI::Platypus. Meanwhile I will keep studying XS, because I find it to be quite fun :)
You can anchor word boundaries with \b I'm not sure if you can do numeric ranges in perl regexes. I found [this](http://www.regular-expressions.info/numericranges.html) which suggests you can't, but I only did a quick search. I think this does what you're after s/\b([0-9]|[0-2][0-9]|30)\b//g So \b binds to a word boundary at the start and end The first [0-9] matches digits 0-9 Then [0-2][0-9] matches 01-29 Finally 30 matches 30 the trailing /g performs a global replacement.
Turn it into a list and use grep. Not everything should be solved with regular expressions.
I think the more idiomatic way to do this would be to convert your space separated string of numbers to an array then filter that array using grep: #!perl use strict; use warnings; my $string = '5 1 1498543 2 511998 3 5076191 4 0 5 0 6 0 7 5076191 8 17661546 9 253871 10 749271 11 0 12 32768 13 32768 14 32768 15 32768 16 32768 17 32768 18 32768 19'; # split on all consecutive (1 or more) whitespace characters my @numbers = split /\s+/, $string; # include only values that are less than 1 or greater than 30 my @filtered_numbers = grep { $_ &lt; 1 || $_ &gt; 30 } @numbers; print join("\n", @filtered_numbers), "\n"; Regular expressions are powerful tools, but it is important to choose the right tool for each task. In this case, when operating on numeric data split and grep are the better tools. 
Derp, my bad :) The benchmark and result have been updated to include URI::Encode and URI::Encode::XS too. Now the result agrees with yours: URI::Encode::XS comes out ahead :)
Thanks for the suggestions. I've updated Bencher to use decimal notation by default (unless scientific notation is explicitly requested with `--scientific-notation`). I've also implemented the alignments. I initially used scientific notation because I want to easily see the number of significant digits. Anyway, the result now looks something like: % bencher -Ilib -m URIEscaping --include-dataset u_ascii66 +-------------------------------+-----------+-----------+------------+---------+---------+ | participant | rate (/s) | time (Î¼s) | vs_slowest | errors | samples | +-------------------------------+-----------+-----------+------------+---------+---------+ | URI::Encode::uri_decode | 2470 | 405 | 1 | 4e-07 | 298 | | URI::Escape::uri_unescape | 180000 | 5.4 | 74 | 5.5e-09 | 266 | | URI::Escape::XS::uri_unescape | 1860000 | 0.536 | 756 | 5.3e-10 | 50 | | URI::XSEscape::uri_unescape | 2910000 | 0.343 | 1180 | 3.5e-11 | 20 | | URI::Encode::XS::uri_decode | 4800000 | 0.208 | 1950 | 2e-10 | 87 | +-------------------------------+-----------+-----------+------------+---------+---------+ I hope it's more "glanceable" now. As for the `errors` column, yes, it's uncertainty/sigma/standard deviation. The numbers are produced by Dumbbench. Anyway, I've thought about producing a 2D table like that produced by Benchmark::cmpthese(). Perhaps I'll add the option to Bencher.
Put the numbers into an @array using split at the spaces and then foreach over the @array. If $_ is less than 30 remove it from the array or make a new array of only numbers over 30.
This is totally a learning experience for me and my first programming language. My intention was to update this thread stating that I actually had ended up using mcmillhj's suggestion. I can see its wider application and would let me tune what I am doing to scale a lot better than with a regex. And you are right, I do have a lot more work to do. I am far from denying that. But the only way to get better is to test things and make mistakes. I am extremely grateful for all the responses I have gotten have shed a lot of light on things I didn't even know were possible. 
I meant more you would have a lot more work to do to update the regex ;) Everyone here had to learn, no worries. But the hardest thing when learning is knowing what to learn. Regex is insanely powerful in Perl and often when new people discover it and get excited they often start doing everything as regex. There is a long history of hard to maintain perl code being produced this way through the 90s especially. People get edgy when they see new people going that way is all. Sorry if my comment came off as disparaging. I only wanted to make you aware listy things you want a list, and number things you want to deal with as actual numbers as much as possible. If you are always near the conceptual data type your code will be easier to modify later.
And, of course, you could omit the `@numbers` and `@filtered_numbers` arrays completely by chaining the operations together. $string = join ' ', grep { $_ &lt; 1 || $_ &gt; 30 } split /\s+/, $string;
Perl 5.22, 4.3.5-300.fc23.x86_64, Broadwell i5. I was missing libxmu so I installed it and make ran fine. make test failed: ... Hold down arrow keys to rotate, 'r' to reverse, 's' to stop. Page up/down will move cube away from/towards camera. Use first letter of shown display mode settings to alter. Press 'g' to toggle fullscreen mode (not supported on all platforms). Press 'c' to capture/save a RGBA targa file. 'q' or [Esc] to quit; OpenGL window must have focus for input. Idle timeout; completing test &amp;Image::Magick::constant not defined. The required ImageMagick libraries are not installed or not installed properly. END failed--call queue aborted at test.pl line 798. Unable to locate glut handler at (null) line 798 during global destruction. Makefile:1123: recipe for target 'test_dynamic' failed make: *** [test_dynamic] Error 29 But I do have Image::Magick installed ... (via Alien::ImageMagick)
(still can't post to bpo, and the author of the original article copied comments from here to bpo, rather than replying here, so...) If anybody would like to discuss any of these issues further, I'll be at YAPC::NA all next week. Find me and we can chat about what can be done. 
I saw the window but no spinning cube, just a black background
How does sparrowdo differ from Rex?
Sure: * [build.log](https://gist.github.com/dnmfarrell/0a78d4893b4ec0d696029895ba2691de) * [gl_exclude.h](https://gist.github.com/dnmfarrell/2bba1fe40eff78e89d40a1d2ff81a3bf)
Ok, this at least shows clearly what's wrong, but can be changed to fail more gracefully. GLX i can't easily test, i think, but if you feel like poking at things, let me know if you end up with patches. :)
Yep, that's another case of glut exit not working cleanly, everything else was ok. Thank you! :D
While many of the arguments presented here are uncompelling, this one is: https://chrishardie.com/files/framing-lightning.pdf Thanks to @olyenspeegul for pointing this out. The blog has been updated to keep the positive front-and-centre.
I merged some C code that is surely more efficient and yet my benchmarks showed a regression in terms of throughput. I wonder if the compiled code is less efficient. Version 0.08 is on CPAN and version 0.09 is the HEAD of master on github. There is a `bench` script in the repo.
I attempted to install it with cpanm MITHALDU/OpenGL-0.6704_05.tar.gz I see the spinning cube and the keyboard controls work, but the testing fails with: Hold down arrow keys to rotate, 'r' to reverse, 's' to stop. Page up/down will move cube away from/towards camera. Use first letter of shown display mode settings to alter. Press 'g' to toggle fullscreen mode (not supported on all platforms). Press 'c' to capture/save a RGBA targa file. 'q' or [Esc] to quit; OpenGL window must have focus for input. Idle timeout; completing test make: *** [test_dynamic] Error 9 FAIL Testing OpenGL-0.6704_05 failed. You can s)kip, r)etry, f)orce install, e)xamine build log, or l)ook ? [s] Here are some details: + Mac OSX El Capitan (10.11.5) + perl 5.22.1 (perlbrew) + MacBookPro6,2 (2009) + Intel HD Graphics + NVIDIA GeForce GT 330M **UPDATE:** MITHALDU/OpenGL-0.6704_0**6**.tar.gz fixed the problem.
Inside the callback that's being passed as the first argument to `pairwise`, the two values of the pair are made available as `$a` and `$b`. When you use `@Array2` in scalar context, it evaluates to the length of the list, and since both arrays have the same length, the result of division is 1. Edit: and after you fix that, you're going to have to deal with the problem of division by zero. Perhaps you want something like this: #!/usr/bin/perl use List::MoreUtils qw/pairwise/; use warnings; use strict; my @Array1 = qw/1498543 511998 5076191 0 0 0 5076191 17661546 253871 749271 0 32768 32768 32768 32768 32768 32768 32768/; my @Array2 = qw/1014551 382045 3173305 0 0 0 3173267 12861876 10516 22880 0 0 53 0 0 430 0 180/; my @TotalPercent = pairwise { if($a) { $b / $a * 100 } else { "nan" } } @Array1, @Array2; print join "\n", @TotalPercent; 
Hi ! I like Rex )). The main difference I see is Rex provides DSL in terms of low level resources , like pkg, file, service . While sparrowdo provides DSL in terms of sparrow plugins, which are higher level entities. Like perl-app to install perl psgi application, nginx-install to install nginx , so on. Sparrow plugins are decoupled from sparrowdo , and under the hood are _just a_ Bash, Perl of Ruby scripts to solve a specific tasks. Other interesting thing is that as sparrow plugins are just any purposes scripts , one may use them not only in deployment tasks, but also as monitoring scripts, as Outthentic ( a sparrow plugins runner ) provides some out of the box testing facilities, which is very handy when writing tests, minotoring scripts. You may see this idea in details at https://metacpan.org/pod/Sparrow and then at https://metacpan.org/pod/Outthentic Regards. Alexey
I saw your smoke result and knew the 32 bit freeglut dll was being a problem. Is there any way you can pack up your perl and make it available to me with e.g. dropbox? Or provide instructions on how to replicate your setup?
Thank you, another indicator that most things work, except for the glut exit. :)
I'll be in touch later. What is the CPU on which `perl` is going to run?
Do also look at [MooX::Options](https://metacpan.org/pod/MooX::Options). It makes CLI design and maintenance way easier.
Like the guy above said, if you use an array in a scalar way then you get the number of elements. Why don't you loop over the elements of the array, dividing $array1[$i] by $array2[$i] then multiply by 100 and print then $i++?
Fwiw an idiomatic equivalent in Perl 6 (another Perlish language) would be something like: use v6; my @Array1 = &lt;1498543 511998 5076191 0 0 0 5076191 17661546 253871 749271 0 32768 32768 32768 32768 32768 32768 32768&gt;; my @Array2 = &lt;1014551 382045 3173305 0 0 0 3173267 12861876 10516 22880 0 0 53 0 0 430 0 180&gt;; my @TotalPercent = @Array2 Â«/Â» @Array1 Â«*Â» 100; for @TotalPercent { (try .say) or say $!.message }; The `&lt; ... &gt;` form is a re-imagining of Perl 5's `qw( ...)`, i.e. it allows one to list string values without commas. The OP's values are all integers and Perl 6 automatically detects this so they will be stored as [IntStr](https://docs.perl6.org/type/IntStr)s (which stores both the integer value and the string original). The `@Array2 Â«/Â» @Array1 Â«*Â» 100;` expression (which can also be written as `@Array2 &lt;&lt;/&gt;&gt; @Array1 &lt;&lt;*&gt;&gt; 100`) divides each element of `@array1` by each corresponding element in `@array2` and multiples each of those results by 100. The "hyper" `Â«opÂ»` syntax can be applied to all but a couple ops. The language is defined such that a Perl 6 compiler reserves the right to run the overall "hyper" operation in parallel if it thinks that'll speed things up by using multiple cores. The Rakudo Perl 6 compiler does not yet take advantage of this; I would be surprised if it did not start to do so for some `Â«opÂ»` operations by this time next year. Perl 6 automatically delays most exceptions that arise in batch computations such as this until you process the results. So the `my @TotalPercent ...` line does not generate an error when it encounters a divide-by-zero. Instead it stores a [Failure](https://docs.perl6.org/type/Failure) for that value, representing a delayed exception, and continues on its merry way. Delayed exceptions act as defuse-it-or-die bombs when you later go to process the results. The `try ...` in the next line is a bomb squad. It defuses any bomb found by the `...` (in this case `.say`; the `.` at the start makes this a call to the "say" method -- Perl 6 has OO builtin and uses a postfix `$object.method` syntax; if there's no `$object` then the method applies to the current topic aka `$_`). If a delayed exception tries to blow up inside the `try`, it is automatically defused and ignored unless you explicitly provide instructions for what else to do. If the `try` *does* find a bomb (delayed exception) it returns [Nil](https://docs.perl6.org/type/Nil), which represents either the absence of a value or a failure that's being treated as benign. The `say $!.message` says the message payload of the delayed exception (stored in `$!`) without actually blowing up and stopping the program. Thus the result: 67.70249502 74.6184555 62.51350668 Attempt to divide by zero using div Attempt to divide by zero using div Attempt to divide by zero using div 62.51275809 72.82417972 4.1422612 3.0536348 Attempt to divide by zero using div 0 0.161743 0 0 1.312256 0 0.549316 The stock exception message mentions "div" not "/". This is a known bug.
For those who don't have time to view the whole thing, some "highlights": Actual content starts at: #t=5m20s -- [a 2 minute recap of last year's YAPC::NA](https://www.youtube.com/watch?v=73e6quzJU9U#t=5m20s). #t=7m35s -- [Dan Wright introduces ~~YAPC::NA~~ "The Perl Conference"](https://www.youtube.com/watch?v=73e6quzJU9U#t=7m35s). Tidbit: one day training sessions by world class presenters for just $75! #t=20m30s -- [Dan Wright explains a major shift in how the NA conference is organized](https://www.youtube.com/watch?v=73e6quzJU9U#t=20m30s). #t=21m35s -- [Dan Wright provides a historical review of the financials of NA conferences](https://www.youtube.com/watch?v=73e6quzJU9U#t=21m35s). Tidbit: Booking.com is paying for this years Audio/Video recording. #t=28m17s -- [Karen Pauley discusses fund raising.](https://www.youtube.com/watch?v=73e6quzJU9U#t=28m17s). Tidbits: Over half a million dollars raised in the last 5 years for the Perl 5 core maintenance fund and over $40k in the last year for the Perl 6 core fund. #t=38m25s -- [Sawyer X begins MCing his first state of the velociraptor as Pumpking](https://www.youtube.com/watch?v=73e6quzJU9U#t=38m25s). He talks a little about the overall Perl community himself and then introduces 8 folk representing sub-communities as follows. #t=42m06s -- [genehack (welcome back!) who focuses on the importance of supporting beginners and writing "baby" perl](https://www.youtube.com/watch?v=73e6quzJU9U#t=42m06s). #t=50m32s -- [Andrew Fresh on Perls and BSDs](https://www.youtube.com/watch?v=73e6quzJU9U#t=50m32s). Tidbit: OpenBSD is seriously committed to Perl. Will the Perl community help try to ensure that pays off for them? #t=56m50s -- [Doug Bell aka preaction, new cpantesters leader, on cpantesters and the Rugby QA hackathon](https://www.youtube.com/watch?v=73e6quzJU9U#t=56m50s). #t=70m -- [rjbs on either v5.24 or v6, depending on how you look at things](https://www.youtube.com/watch?v=73e6quzJU9U#t=70m). An amusing exhortation to "upgrade, now". #t=77m36s -- [mickey on an upcoming (spring next year?) metacpan.org overhaul](https://www.youtube.com/watch?v=73e6quzJU9U#t=77m36s). Tidbits: big jump forward not least due to upgrading Elastic Search from 0.2 to 2.3. Try it at [v1.metacpan.org](http://v1.metacpan.org). #t=80m59s -- [Chad granum (aka exodist) on Test2 (major upgrade of Test::More/Builder/Simple)](https://www.youtube.com/watch?v=73e6quzJU9U#t=80m59s). #t=86m45s -- [Dr Forr on YAPC::EU this August in Cluj, Transylvania](https://www.youtube.com/watch?v=73e6quzJU9U#t=86m45s). Tidbit: 10K programmers in a city that's "big on charm". #t=98m40s -- [Stevan Little references his infamous "Perl is not dead" talk with an "... it got better!" follow up](https://www.youtube.com/watch?v=73e6quzJU9U#t=98m40s). Tidbit: [Perl 6 is awesome](https://www.youtube.com/watch?v=73e6quzJU9U#t=110m50s). Hth.
genehack (a conf organizer) just let me know that a message about a potential audio problem has been relayed to the lead a/v person with a suggestion they might want to post here. Aiui there are no known reports of there being no audio at all other than your comment here so perhaps hobbified is right. If you confirm that it's your hardware, or that it's not, please comment back here again. TIA.
&gt; That example would be considered polite compared to what happens on IRC. Depends on who you ask. I recently saw someone say (in a Haskell channel): &gt; \#perl is so much nicer than \#python &gt; I wonder why
Function::parameters seems very similar to method::signatures, is there any reason to prefer one over the other?
year after year, and it's always the same thing: audio problem in recordings. so i guess audio is hard.
That was a good read! I'm trying to improve our development practices at $WORK, so it's nice to see what's working for others.
Even though I'm heavily invested in Function::Parameters in my current codebase, I'm playing with the idea of moving to [Kavorka](https://metacpan.org/pod/Kavorka) because it's almost identical syntax, but with a few more niceties (multisubs, easier optional syntax, etc).
Sweet! Spent most of work today listening to the panels. From someone who couldn't be at YAPC^Wthe Perl Conference, thanks. :D
I'm sure you're not the only one. I myself am neutral on this, but slightly prefers the name `puts` or `println` like in some other languages. The fact that other languages also have `write/writeln`, `print/puts`, or things like that suggests that typing `, "\n"` (that's 6-7 extra characters plus a couple of Shift in a typical US keyboard that one has to type probably thousands of times) is tedious enough to warrant a shortcut. 
Perl's goals are to be portable and work everywhere. As such, a "Screw windows" argument amounts to "screw perl". No, no thanks. I don't like windows, but that's no reason to make people who do use windows have a bad day just because you don't like it. 
The most I have the resources to do at the moment is regular `cpan-outdated | cpanm` followed by `cpanm-reporter` sessions on some laptops with the most recent version of Perl and the occasional development version. Also, while the problems most often come up in the context of Windows, this is more about the fact that, however fringe they might be considered, there are operating systems other than *nix and C compilers other than `gcc`.
&gt; I can not load `File::Spec` here Can you expand on this? What specific problem are you referring to?
A simple practical case is *I am about to manipulate @INC, so I clearly need to do it when as little as possible (ideally nothing) has been loaded* (think e.g. `local::lib`) There are other even more fringe cases of *this process needs to run very quickly 500 times in a row - even `use warnings; use strict` [become a measurable cost](https://github.com/dbsrgits/dbix-class/blob/master/lib/DBIx/Class/Optional/Dependencies.pm#L3-L10)* And then there are the cases of *I am checking the load pattern in a test - I need full complete life-cycle management of %INC*. None of these are things one usually does need to worry. But it is something **I** run into at least once a week. On the flipside I run into `operating systems other than *nix and C compilers other than gcc` **once a year**. Note: I am not trying to say *my use cases trump yours*: everything is equally important. Instead I am trying to explain why *I as a single person can not hold your case at the front of my mind at all times*. And why smokeboxes for the "fringe operating systems" (your words) are the only way forward.
&gt; The most I have the resources to do at the moment is Is this a question of hardware resources or your own personal resources? Because if it is a matter of hardware - this is beyond solvable.
For example, both python and ruby build easily with MSVC 2015, but [perl doesn't][1] due to the way it uses internals of the `FILE` structure. I don't know if this is a solvable situation and building perl on Windows with native tools may become impossible if MS stops bundling the 2013 tools with later Visual Studio versions. [1]: https://rt.perl.org/Public/Bug/Display.html?id=125714
&gt; That's my purpose. I am not asking you to hold my case in front of your mind at all times. I don't understand how politely worded advice elicits this reaction. Hm ;) I am also taken aback that my genuine "look - here is my thought process and here is why it does and will continue to fail you" was taken for more than what it is. But since we are on that tangent: &gt; I would like to remind everyone that Perl does provide tools that help improve the portability of your code The above is indeed polite. But it also is a bit...patronizing. The implication is that the author "forgot". Whereas in reality an author almost certainly made a conscious decision (which seems to be the case here). &gt; Passing a command line to an external utility does not fit with the situations you mentioned. This is correct - but "context switching" in human brains isn't perfect. If one works with the cases I mentioned, and then in the same breath moves on to fixing up the build system preparing for a release - the context will bleed through. This clearly happens often enough that "can't you just not do that" is not an answer. So let's find a non-human solution instead: what would it take to get an MSVC smoker running?
Internally, yes. When you are passing paths through the shell to an external utility, there are no guarantees.
You do realise u/haaarg has [written CPAN modules](https://metacpan.org/pod/Win32::ShellQuote#DESCRIPTION) explicitly to handle windows command parsing, and he knows this. I was aware of some of these quirks of Win32 command parsing prior to this incident, due to my conversations with him. There is no expectation anywhere in Win32 stack that this `/` would be mistreated. None. The end process that is doing it is perl, and perl's handling of parameters is well known, and `/` is not magical there. This is all `nmake` mangling parameters. 
This is such a useful feature, I use it a lot. I usually include a trailing slash on the path variable though. Not sure about include expression ... I can open Perl modules just fine without it from scripts and modules. If the filetype isn't set to Perl it doesn't work without it though. For per-project path settings, you can add a [local vimrc](http://perltricks.com/article/194/2015/9/22/Activating-Perl-6-syntax-highlighting-in-Vim/#use-a-local-vimrc:2b44acefc7661ab01fd1d69f1b86a6cb)
[What I thought of when I read the post title](https://upload.wikimedia.org/wikipedia/en/thumb/6/66/Wendy's_logo_2012.svg/1229px-Wendy's_logo_2012.svg.png)
Yes, but the problem had nothing to do with a path, it had to do with an *argument* being mangled. If that argument contained a slash that was not intended to be a path, it would have still been mangled by nmake. Using default windows directory characters instead of UNIX directory separators, but only through happenstance. That's not a solution, that's a mitigation.
It's advice that works by accident, it is most definitely not a good example of your point. The problem has **nothing** to do with directory separation *per se*, even if it is related to slashes.
Would be nice to know why this is interesting before I bother to download it.
It was clickbait. 
However in this case the problem is an unrelated nmake bug that also triggers on / - while File::Spec would've avoided triggering it this time, using / in general is apparently problematic there. So while "use File::Spec" is a good default and a good thing to remind people of, this is a terrible example of why it's good :)
I wonder why it's open office format instead of pdf... Pdf is also a libre technology right?
Wendy didn't have time to upload a PDF yet. You can use my temporary copy in the interim: http://temp.perl6.party/Perl%206%20Brochure.pdf
For instance, if the path was a URL, not a local path, then it would have to be encoded using `/`. But that would ( I imagine ), result in the same problem, where `"/"` becomes `" /"` ( Unless of course, nmake has some crazy special casing where it parses the URI protocol and treats it differently ) Here, a "Use File::Spec" would not work, as `/` **is already** the right native encoding, and translating `\` would likely break the URL from working. But `nmake` would likely break it the same way.
If you decide to give a talk, rehearse it, several times. It's a great way to build confidence and hone the material to be something special. Your audience will appreciate it!
We have a resident designer in the community. I'll see if they could take a crack at this.
Do you feel it's not new, or that it's not a service?
VIM has been my IDE for years. 20. At least half a million or more just in Perl in VIM. 
Following the same logic, there are no new sites - they are all wrappers around HTML :)
Not yet. I will.
I can see that traditional syntax highlighting for editing creates too much noise or distraction. Aside from code, there are other editor UI elements that are colored (like fold markers, guidelines, space/tab marker), and showing the code in a single color can help make these elements stand out better visually. What could be more useful during editing is to show (selective) syntax highlighting around the cursor. For example, when the cursor is on a variable, the name of variable (on the cursor as well as elsewhere) can be highlighted. Or when the cursor is inside a block, perhaps softly highlight or turn on syntax highlighting for that block only. Or for the current statement only. Traditional syntax highlighting is still useful when displaying code in article though, where there is no editing involved.
From the title I also thought that it was a new certificate issuer.
Really enjoyed this talk. Sawyer shows how to insert CUSTOM OPs (wow!) in the Perl op tree. One thing I wondered was - what's a good rule of thumb of when to use custom ops? Surely they're not a panacea
A quick summary of what is highlighted instead of the syntax?
Let's start with his Trackperlvars plugin. If the cursor is over a variable, highlight all occurrences of that same variable. my ($foo, $foobar, %foo) = (1, 2, {}); $foo{$foobar} = 42; $foo = 99; If the cursor is over either the `%foo` or the `$foo` part of `$foo{$foobar}` then his plugin will highlight those two (and not the `$foo` or `$foobar` scalars). While he's about it he automatically includes a doc hint for that variable in the line at the bottom of the VIM display based on common sense heuristics: my $bar = ...; # ... Three programmers walk in to a bar. Store the bar. ... # a hundred lines of code say $bar If your cursor is over either of the `$bar` references then the line at the bottom of the VIM display shows, using the same highlight color so one's mental focus is effortlessly unconsciously as desired: $bar: ... Three programmers walk in to a bar. Store the bar. This works for built-ins so if you put your cursor over a strange variable like `$]` you'll see at the bottom: $]: Perl interpreter version [deprecated: use $^V] There's a bunch more (eg changing a variable name without screwing up due to sigil variance etc. is trivial) but I presume this is enough for you to get the picture. So that's Trackperlvars. He also demos his equally if not more useful folding editor plugin that works nicely in its own right and also in combination with Trackperlvars. You can, for example, fold away all but the lines that contain the variable under the cursor (well, with surrounding contextual lines too as you prefer). Or view just the first few lines of all subs, or only the first line of subs plus comments, and various other views that can be extremely helpful in getting a quick overview of code. His judicious use of highlighting makes this work very nicely. Finally, he shows some other tools he's created for working with entire codebases, such as a highlighting wrapper around vim grep that works nicely. Watching this video completely reset my thinking about syntax highlighting. (I've come to accept that Damian can do that to me about all manner of topics.) I still think syntax highlighting helps when someone who doesn't understand a language's syntax looks at code in that language, so it still seems entirely appropriate when, for example, displaying/viewing uneditable code at rosettacode.org or github. But not if you're editing code and want to focus on understanding a particular variable or module etc.
As a rule of thumb: don't. It adds significant complexity and cuts down on the potential maintainers by a lot. In Sawyer's case, custom ops aren't unreasonable because ref checks can be something that ends up plastered all over your code. Most other XS doesn't get invoked nearly as frequently.
Unfortunately this doesn't work. The rebless instance function seems to merge two existing structures. It seems to somehow overwrite `$self` with a new instance that inherited from `$self` or something. I've tried a few ways of working around it and to not prevail. All I really need is a way to add attributes/methods to a Mouse class without affecting all new instances of that class. Do you know anyway to accomplish that by chance? Thanks for your help, I appreciate it. 
This seems to be it: &gt; get_comments($permalink) &gt; Returns a list ref of Reddit::Client::Comment objects underneath the the specified URL $permalink. Unfortunately, this is the only method available via the API. Comments may be more easily accessed via the Link object, which implicitly provides the `$permalink` parameter. If you don't have major API-requiring needs though, I would get my Reddit data by adding `.json` to a regular Reddit URL and just parsing the JSON. 
&gt; All I really need is a way to add attributes/methods to a Mouse ~~class~~ object without affecting all new instances of that class. So, you want to add attributes and methods to an object on the fly. As the stackoverflow reply says, you'll need to create a subclass of the original class with the attributes and methods you want, then use the bless function to make the instance belong to that class. 
He promised the slides; I hope he uploaded them somewhere?
Thanks for the idea, I've tried getting this via JSON but am getting the following error: Not a HASH reference at reddit.pl line 39 with the following code: $url = 'https://www.reddit.com/r/perl/comments/4pjwwg/staying_in_the_flow_damian_conways_%20vim_as_a_perl/.json'; warn "getting: $url"; my $ua = Mojo::UserAgent-&gt;new; my $data = $ua-&gt;get( $url )-&gt;res-&gt;json; for my $child ( @{$data-&gt;{data}{children}} ) { warn $child-&gt;{author}; }
You probably want for my $child ( @{ $data-&gt;{'data'}-&gt;{'children'} } ) { at that point. That's working for me anyway. Take a look at the JSON directly in a browser (using a JSON formatting extension), or dump it using Data::Dumper, to see the structure.
Thanks for the help, but I tried this and still get the hash error. Using Dumper like you say I can dump $data, but nothing else: use Data::Dumper; use Mojo::UserAgent; $url = 'https://www.reddit.com/r/perl/comments/4pjwwg/staying_in_the_flow_damian_conways_%20vim_as_a_perl/.json'; warn "getting: $url"; my $ua = Mojo::UserAgent-&gt;new; my $data = $ua-&gt;get( $url )-&gt;res-&gt;json; print Dumper $data; print Dumper $data-&gt;{'children'}; 
 my $links = $reddit-&gt;fetch_links(...); foreach (@{$links-&gt;{items}}) { my $comments = $_-&gt;comments(); } This is the guy that rewrote the plugin, Ive dealt with him a lot on it.. Maybe worth talking to him: https://www.reddit.com/user/earth-tone earth-tone@ubwg.net You can also view his write up at: http://redditclient.readthedocs.io/en/latest/examples/
&gt; then use the bless function to make the instance belong to that class. Yeah, this is the part that I think is tripping me up. `rebless_instance` isn't an available method in `Mouse::Meta::Class` so I need to do that manually. That function somehow seems to override the original `$self` object with the new anonymous class I made. How would I do that myself? I feel like there is more going on behind the scenes in that function. `$self = bless $new_anon_class, ref $self` Something like that? How does that actually overwrite the `$self` for the next time a method is called by that package since it's a local variable at that point.
Looks like you're missing a couple of levels of data structure. This seems to work: for my $child ( @{$data-&gt;[0]{data}{children}} ) { warn $child-&gt;{data}{author}; }
Thanks for the advice. This is one of my problems.
Thank you. This gets the author of the first reply. I'd like to be able to somehow loop this for all top level comments, and their replies. Is there a way I can 'walk' this json data easily and do this?
Nice. It would be interesting to compare this method with the [observational calculation](https://en.wikipedia.org/wiki/Sunrise_equation). From this you can then calculate [planetary hours](https://en.wikipedia.org/wiki/Planetary_hours).
$self is usually just a hash. In fact, one way to add attributes would be $self-&gt;{color} = 'green'. No accessor, needed just regular hash access. Personally, I don't know how to make an anonymous class. I think you would have to name the class, generate a name for it. Generate the code for it, then eval the code for the class. Then, bless $self, $newclass You might understand it better if you try it without Mouse, just using vanilla perl OO. Actually, it could be that your approach is the wrong one for the problem. Over in perlmonks and in stackoverflow, advisors request info about the underlying problem, because there may be other ways to solve it. 
Sorry, I was looking at a different JSON structure and assumed yours was the same. More in a minute. 
Its because Godaddy SELLS certs where as LE gives them away at no charge.. Its bad for business to offer a free option when you're trying to make money. Last I checked to install a LE cert you can do it from the command like so as long as you have access to ssh then you can use LE without issues. 
Looking at the data structure of the JSON will really help here: * Here's the JSON http://pastebin.com/raw/LVPnY3kt * It's an array * item 0 of the array is a hash with a `children` array, and that array has one child, of kind "t3". This is the original post, I guess. * item 1 of the array is also a hash with a `children` array. It contains two children of kind "t1". These are the top level comments. * each of these hashes also has its own `children` array which are the replies to the top level comments. Does that help?
Assuming we already have our JSON data turned into a perl data array reference called `$data`, this walks down the array looking at the OP and top level comments: print "This JSON has " . scalar( @{$data} ) . ' elements ' . $/; foreach my $element ( @{$data} ) { print " This element has " . scalar( @{ $element-&gt;{'data'}-&gt;{'children'} } ) . ' children ' . $/; foreach my $child ( @{ $element-&gt;{'data'}-&gt;{'children'} } ) { print " This child element is of kind " . $child-&gt;{'kind'} . $/; print " This child element's author is " . $child-&gt;{'data'}-&gt;{'author'} . $/; } } but obviously if you're going to walk all the way down each chain of comments and replies to comments, you'll want something different.
Pretty amazing timing for me. I've recently started looking into incorporating tests into some old Perl scripts at my company. Some of these scripts have the potential to cost a lot of money if something goes wrong so I'm looking for peace of mind anywhere I can get when I make changes.
Why the hell is this here?
His point -- with respect to Perl -- is invalid. That's not a null pointer exception. The author should keep the distinction between a null pointer and calling a method they didn't bother to define. Which *might* be a null pointer. And *might* crash. But it isn't and doesn't in Perl. **"All modern popular widely used programming languages are vulnerable to null pointer exception errors"** See, that's the problem. Perl isn't *vulnerable*. When you try to do something dumb, it properly stopped you. 
&gt; Show me exactly where the method 'name' is defined? In this case `$person` is not an object or a class, so methods don't come into it. The error message points this out. I agree with you it's not a null pointer exception; Perl doesn't "crash".
Awesome to see this is taking hold.
There are various possible errors that can happen here. The article is talking about this error: C:\Users\Mithaldu&gt;perl -e "$person-&gt;name" Can't call method "name" on an undefined value at -e line 1. Then you can try calling a method on a thing that is neither a class nor an object: C:\Users\Mithaldu&gt;perl -e "$person = \$person; $person-&gt;name" Can't call method "name" on unblessed reference at -e line 1. The error for an undefined method however can only be reached by having something that at least *smells* like an object, and looks like this: C:\Users\Mithaldu&gt;perl -e "$person = \$person; bless $person, Person; $person-&gt;name" Can't locate object method "name" via package "Person" at -e line 1. That is however not the type of error the article is about, since it is definitely talking about the first kind of error, where not the method, but the very object you try to call a method on, is not defined.
&gt; Methods come into it the moment that $person-&gt;name was written, since that's the syntax for an object's method call. Well that's what I get for using imprecise language. You said: &gt; Show me exactly where the method 'name' is defined? There is no dispatch to `name` because `undef` is not an object/class
You said: &gt; That's not a null pointer exception. You further expounded that you thought it is the error that happens when a *method* is undefined. &gt; calling a method they didn't bother to define I just showed you conclusively that neither claim is true by contrasting the exact error messages for both of the scenarios you propose. That he didn't make his point particularly clear is something i already stated and which you just affirmed by proceeding to entirely miss his point. I'd explain, if you had some humility and weren't in such a rage and anger for no reason that i can discern.
Thanks for defense, Mithaldu. I have encountered "unblessed reference" error myself when trying to make a code example, which was extremely confusing. What I kind of liked about Perl, is that with "use strict" it didn't let me to assign NULL. 
People do dumb things all the time. My point is that if you do something really dumb, then the compiler/parser should be able to stop you and warn you until it's too late.
It does. As the interpreter tries to compile, it correctly barfs on the stupid invocation of a method without the actual object existing. TDD says that this wouldn't even get out of development in the first place, so I really don't get what the problem is. After the *first* time, you'd think the programmer would learn.. And if they *don't* learn from their mistakes, their career ( hopefully ) will be short, and they won't cause too much damage. 
&gt; interpreter tries to compile Dangerous half-knowledge here, yeah, Perl will sometimes have compile phases in its runtime, but it does absolutely not catch any of the errors regarding undef, objects, methods at any of the compile phases, only in the runtime phase will any of those throw exceptions. Please, read [Modern Perl](http://onyxneon.com/books/modern_perl/) before further guessing at what's happening.
No, it doesn't do it at compile/parse time. Note that "perl -wc" reports "Syntax OK". It actually tries to call that method and then dies. You can imagine that this line is buried in some rare corner-case code path that was tested maybe once long time ago, and it was unpractical to have an automated test for it (for some reasons). 
&gt;**You can imagine** that this line is buried in some rare corner-case code path that was tested maybe once long time ago, and it was unpractical to have an automated test for it (for some reasons). I can *imagine* it. It's not the way things are done in my shop, though. I'd be all like, "Well, what *are* these *reasons*?"
https://en.wikipedia.org/wiki/Poe's_law Good day, sir.
Sure any user declared subroutine could return undef. Similarly an object could be expected as a subroutine parameter, but undef was passed instead. In these cases the onus is on the developer to validate the subroutine args, but a common mistake would be to just assume it's an object and make a method call, leading to the error message in your article. &gt; This doesn't mean though that Perl is perfect, but I won't argue it's NPE, it's probably something more general like complete lack of parse-time type safety. I think that's closer to the truth. Perl checks in its compile phase whether the correct variable type was used (scalar, array, hash, glob), but it cannot distinguish between a scalar which is a reference to an object and an ordinary scalar, or an undef scalar.
Sounds like a school assignment. But how about you show us what code you have and what you have attempted so far? 
Well your title says you have in a **string** yet your post says you already have an **array**? Your title also says you want to create an array of particular dimensions but your post says you want to add a line break after every 4th entry... So it's not entirely clear what it is you want to do exactly. It sounds like you want to turn a string into a "multi-dimensional" array e.g. use strict; use warnings; use feature 'say'; use Data::Dumper; my @array; my $string = 'one two three four five six seven eight nine'; push @array, [split] for $string =~ /(?:\S+\s+){0,3}\S+/g; say Dumper \@array **OUTPUT** $VAR1 = [ [ 'one', 'two', 'three', 'four' ], [ 'five', 'six', 'seven', 'eight' ], [ 'nine' ] ]; 
I guess it is a school assignment of sorts. I am a post-doctoral researcher trying to turn my biology data into something I can put into a statistics package without copying and pasting a million times. I think my boss is going to fail me. 
Example data and desired output would be useful. 
Seconded. Commandlineuser above looks to have the solution, but we cannot know unless we have an idea of the output you desire. 
He uses the USR1 and USR2 signals in his workers for abrupt and graceful shutdown, respectively. I'd never seen those before but they're just normal POSIX signals (like SIGKILL, SIGTERM) but with no predefined behavior. Good to know.
Yeah, `local` just says "take this global variable, and give it a new value, but restore it to the old value when you reach the end of this block". In its way, it's a lot simpler and less subtle than `my`. :)
`dd` uses USR1 and USR2 signals, from the man page: Sending a USR1 signal to a running â€˜ddâ€™ process makes it print I/O statis- tics to standard error and then resume copying. $ dd if=/dev/zero of=/dev/null&amp; pid=$! $ kill -USR1 $pid; sleep 1; kill $pid I've done some experimenting with signals, but by and large never really found a need in anything I've written. This is the only time I've ever seen USR1 used in the wild, really cool use.
A long time ago, when it first came out, I bought a hard copy.
apologies, should have been more specific. Originally data was a poorly formatted tab delimited file which I turned into a 1D array by using split. Many thanks for the help!
haha I'm sorry but I had to. \Q...\E is actually my favorite regex thing. At work people ask me everyday 'do I have to escape &lt;this&gt;?'. So I'm super pro about bringing awareness to this probably ancient feature. 
 perl -anle '$sum += $F[0]; print $sum if eof()' file1 file2 ...
/r/ProgrammerHumor
these videos need more views. the react based web ui is pretty nice, also, the code (https://github.com/vmprobe/vmprobe) is very nice to read. it's written by the same person who wrote the let over lambda book, if i'm not mistaken. 
Hey no problem - so are you able to solve your task? If you already have a 1d array you can just loop through it like /u/dnmfarrell has shown
Well the `=cut` type identifiers are **POD** http://metacpan.org/pod/perlpod `=comment` isn't listed there but perhaps unknown "commands" are parsed as if they were `=pod` (as it does "work" on a few versions of Perl I've tested with) Hopefully someone with more POD experience can give a definitive answer. 
Having trouble hooking Minilla up to the Pinto repo so that minil release pushes to our Pinto DarkPAN instead of CPAN. I see with Pinto you can run a pintod daemon to allow for remote coms, however the docs really only talk about using the 'pinto' client with the pintod webservice. Does the pintod service behave in a PAUSE like manner? Can anyone help in connecting up Minilla with a Pinto repo?
From [`perldoc perlsyn`](http://perldoc.perl.org/5.8.8/perlsyn.html#PODs%3a-Embedded-Documentation): &gt; Perl has a mechanism for intermixing documentation with source code. While it's expecting the beginning of a new statement, if the compiler encounters a line that begins with an equal sign and a word, [...] Then that text and all remaining text up through and including a line beginning with `=cut` will be ignored. The format of the intervening text is described in [`perlpod`](http://perldoc.perl.org/5.8.8/perlpod.html). `=comment` is not a valid POD command, so it's ignored by things that process POD as documentation, which is desired and intentional. But the compiler doesn't know or care about valid POD directives, so as long as the block follows the syntactical rules outlined above it will be ignored, which means you can use any word you want, like `=comment` or `=foobar` or `=Jason` or whatever. You'd only use `=begin` (or another valid POD command) if you were actually writing POD documentation, which you are not.
Thank you. I have checked version of Perl, its v5.8.9 built for aix-thread-multi-64all. Yeah I am hoping it does parse it and this part is a comment. Because if its not and its doing something (whole code is big and complex and it was written by vendor) we have a problem.
The vast majority of text editors cannot perform proper syntax highlighting of Perl. They usually use very simple regex-based approaches, but parsing Perl is much more difficult than that. POD sections won't be the only thing that Notepad++ gets wrong. 
what is this line?
*Shrugs* I honestly wish I could explain it's supposed to be part of a renaming scheme that the old guy made and I can't get it to run because of that singular syntax error. I wish I understood it better but I never studied the use of perl I just tried a lot of googling and couldn't come up with any reason. If it helps I can provide the prior line I just have to handjam it
So I deleted the | and that syntax error went away. Super weird since that's how it was when it was given to me and it "worked fine" anyways. Greatly appreciate your help! 
Many people want small sets of behaviors to augment the minimal OO in the language, and there are several to choose from. Initially I started with Object::Tiny, and added the minimum I thought I needed. There are other lightweight object systems, such as Mo, that are quite featured, in a small source. Might be interesting to create a taxonomy of perl OO libraries.
I find `=for comment` to be more appealing.
What do you mean, by NP++ does not recognize it? It recognizes it as POD, and "highlights" it with default POD style: black text on white background. Yes, its silly colors pick for POD, but you just go to Settings -&gt; Style config -&gt; Perl -&gt; POD, and configure it the way you like it. If you want it to be like comment, look at the "Comment Line".
You could use a YAML format for your config files, and use a YAML parser to pull it in as a complex datatype. There are a few modules on CPAN specifically for handling config files, you can check the system you intend to run code on to see if any are available in package manager, or already installed; http://search.cpan.org/search?query=config&amp;mode=all
 I always was partial to [Config::General](http://search.cpan.org/~tlinden/Config-General-2.61/General.pm)
*nod* If you'd like some code that reads in a config file and converts it to an object, let me know :)
I don't know. I still write simple config file parsers using &lt;keyword&gt;&lt;space&gt;&lt;value&gt; for config and #&lt;blah&gt; as comments. I think I have used YAML parsers for a project or two, and I like the flexibility of YAML, and do a lot of Puppet hiera crap, and I remember it being pretty easy to use in Perl, as well. It's usually more complex than I'm looking for, and if I need something more complex than key:value, then I'll end up making SQL tables.
Good question. Personally these days I stick to JSON formatted config files. I know they're uglier than YAML and don't contain comments, but I find formatting and parsing them is a lot easier. I slurp the file and use `JSON::XS` to decode it into a Perl data structure.
Thanks for sharing!
http://edumaven.com/mojolicious/
&gt; I purchased 3 books - Perl for Beginners, Perl by example, Learning Perl (6th edition) I can't find a book called *Perl for Beginners*. If you mean [*Beginning Perl*](https://www.amazon.co.uk/Beginning-Perl-Programmer-Programmerwrox-Guides/dp/1118013840/) then that's a highly recommended book. [*Learning Perl*](https://www.amazon.co.uk/Learning-Perl-Randal-L-Schwartz/dp/1449303587/) is also very good. The two books above are written by acknowledged Perl experts. [*Perl By Example*](https://www.amazon.co.uk/Perl-Example-Ellie-Quigley/dp/0133760812/) appears to be written by someone who knows very little about Perl. I really can't recommend it. Sorry you wasted your money.
That isâ€¦ rather *a lot* of code for what it does. How about a more Perl-ish solution? #!/usr/bin/env perl use 5.010; use strict; use warnings; use autodie; use List::Util 'sum'; my @fh = map { open my $fh, '&lt;', $_; $fh } @ARGV; while ( my @value = grep { defined } map { scalar readline $_ } @fh ) { say sum @value; @fh = grep { not eof $_ } @fh if @value &lt; @fh; }
In fact, the bare word "consistency" is not very meaningful per se, without a bunch of words clarifying the context. A good hundred of pages in ["Atomic Transactions"](https://www.amazon.com/Atomic-Transactions-Concurrent-Distributed-Management/dp/155860104X) book is devoted to this very subject not without a reason.
Subscribing to [Perl weekly](http://perlweekly.com) is a great way to keep up with community news and code.
Rik's talks are always a lot of fun.
Ya, I have a twitter, just to get extra energy in phone games. So feel free to share it all you want.
Yes I see it as black text on white background. Comments with # are usually in green. Thank you
I learned quite a bit from *The Perl Cookbook*, too. It's a bit dated now, I think, but it showed me ways to apply concepts I learned from other books.
I'm a fan of the [Survey on Consistency Conditions](http://www.ics.forth.gr/tech-reports/2013/2013.TR439_Survey_on_Consistency_Conditions.pdf) paper by Dziuma et al. for formal, mathematical definitions.
I'm confused a bit with your comment. Do you find "Atomic Transactions" not formal enough for your taste? I have not read it thoroughly yet, but Survey your posted looks like a very brief (and simplified) summary of a few topics from the book for me.
No objections to Atomic Transactions for formality. Dziuma is free and a bit shorter, however. :-)
Yeah, somehow he takes the driest technical subject matter and ends up with a whole room of laughing programmers. 
Thanks. I wasn't thinking about people who install the module using modern CPAN clients, I was thinking about people who follow instructions in the README - people who manually download the tarball and run `perl Makefile.PL; make test; make install`. I guess there's no way to help them. I've just released version 0.05 which includes the suggested changes.
Anyone downloading and building by hand should also be able to read the failure message and figure out what module they need to install to get Makefile.PL to succeed (of course, they could read the META first, but that's certainly not what I do). But we need to treat CPAN clients a little nicer; parsing JSON is easier than parsing error messages :)
I'd be wary about giving *The Perl Cookbook* to a beginner. The examples are great, but they use such a dated style of Perl that I'd be worried about a beginner picking up bad habits like bareword filehandles or two-arg `open()`.
Good point. I didn't think of that because I haven't looked at it for a long time. I just remembered that it was very useful to me 15 years or so ago -- but even then bareword filehandles and two-arg `open()` were frowned upon.
I see everyone has given wonderful suggestions. I want to say it again that Learning Perl is a wonderful book, and I'd also like to suggestion Effective Perl for best practices! Additionally PerlMaven has some great content if you need a quick online reference.
I'm confused! The book you linked on Amazon is called Beginning Perl by Curtis "Ovid" Poe. Is that not the book you are recommending? Are you actually recommending Perl for Beginners by Geoffrey Sampson? That's the book I have.
Google unearthed what looked to be a decent Perl Monks post http://www.perlmonks.org/?node_id=638391 I'm sure there will be backlash but Python legitimately has the edge for machine learning, at least documentation/tutorials/intros http://scikit-learn.org/stable/ . However, that said nearly all the methods either exist on normal CPAN or are accomplishable using something like PDL.
I just want something very simple that will help understand basic / and or core concepts.
Curtis Poe's book is the one I am recommending. It's great. Geoffrey Sampson's book is ok, but (on a quick skim through) the information looks rather dated. I wouldn't recommend it.
I have used this package effectively: http://search.cpan.org/~kwilliams/AI-Categorizer-0.09/lib/AI/Categorizer.pm
There's not all that many 'built in' that I'd consider worth using. I mean, you can dump/load with Storable, or Data::Dumper, but ... I much prefer a general format. JSON is pretty good, but YAML is particularly well suited to config files. Unfortunately, both need extra modules to install. But they're not going to go away any time soon, as they're increasingly being adopted in new code. (Seen quite a few YAML configured projects recently)
I go with JSON too. Different tools, maybe written in different languages, can share the configuration file. If I store external data, I don't want it tied to an internal detail such as a module with its own idea about formats.
As a PDL developer/user and someone who uses machine learning for research, I have to agree that Python has really done a great job here. If you want to get to applying machine learning, Python is a really good choice. Perl really hasn't really created any consistent frameworks for doing data science. I'm hoping that will change in the future, but I'm running out of tuits quite quickly these days so I'm not sure I can help that effor just yet.
The revision option is designed to avoid this. Any new updates can be added as new revisions without breaking compatibility. Also, it utilizes a number of plugins and roles that aren't in the core Dist::Zilla distribution, though hopefully some of them will make their way in in the future, as they're widely used.
Any thoughts on the benefits of Disque over beanstalkd?
This might help: perl -Mojo -E 'g("http://www.reddit.com")-&gt;dom-&gt;find("img")-&gt;each(sub { say shift-&gt;{src} });' Each Mojo::DOM element has a hashref key for each attribute on that element.
Well what does the tag look like that you're trying to target? To select something by id the selector is `#id` .. So if it's an `&lt;img&gt;` tag with a specific ID the selector should be `img#id` - also if you just want a single result you can use `at()` instead of `find()` e.g. $dom-&gt;at("img#$chartid")-&gt;attr('src')
I am a fan of gearman. It is really simple to use a number of clients are built for it. We switched to using it instead of a naive queue built internally at my previous job. We were able to do an order of magnitude more jobs with only 5 workers. It was crazy how much of a difference that made.
One disadvantage of JSON is: no comments (unless your program is simple enough that your config never needs comments; or you use some derivation of JSON that allows comments).
I know not every project will have this requirement: writing/modifying configuration files by nonhuman. If you want this capability, you'll probably want a config format that has parsers that preserve comments and formatting. INI has them, as far as I know JSON and YAML currently don't. For example, I write tools/scripts that insert/modify configuration to dist.ini (Dist::Zilla configuration) in a lot of my Perl projects. This will be more inconvenient if Dist::Zilla used JSON/YAML because the tools/scripts would remove my formatting and comments when it re-dumps the configuration back to files.
A bit off topic: I still use emacsclient all the time because the startup of emacs is still around 1-3s and that's still annoying.
I was wondering why it was defining an address and a port!
Just curious -- how did this file get on your server?
That's the other thing I am trying to figure out.
I think converts the scalar context of your match into list context for $x.
Thanks for your answer. As someone still quite new to perl I unfortunatelly dont understand the "code" you have posted. But I take your word for it, that the second one is less efficent. I think I have to do a little bit of reading regarding context in perl.
Thanks for your answer. Do you maybe have any good sources about readable coding in perl? My scripts somehow always become quite unreadable.
Oh sorry. That was the output from the [B::Concise](https://metacpan.org/pod/B::Concise) compiler backend. From the docs: "This compiler backend prints the internal OPs of a Perl program's syntax tree in one of several space-efficient text formats suitable for debugging the inner workings of perl or other compiler backends. It can print OPs in the order they appear in the OP tree, in the order they will execute, or in a text approximation to their tree structure, and the format of the information displayed is customizable. Its function is similar to that of perl's -Dx debugging flag or the B::Terse module, but it is more sophisticated and flexible." I was just demonstrating the number of OPs difference between each method.
It is not installed on the server. So the code is useless?
How do you really know, though, that it wasn't installed somewhere? The executable might not even be called "perl.exe" at this point.
I took a semi-random line from the code (one that looked unlikely to occur in another script) and googled for it. The earliest match was this post in a forum from 2007: http://www.waraxe.us/ftopicp-7913.html
Not entirely convinced that's more readable at all. `=()=` without the white space is fairly idiomatic and only really ever crops up specifically when you want the number of matches.
I will definitely going to check out that book. Thanks for the recommendation
I can't say I recommend using Data::Dumper with the Mojo::DOM instance itself. The object's internals are quite verbose (the entire dom parsed out as a data tree etc) and you might find yourself more confused than you started.
Aaah. Yes. Never thought of that. I'm used to working with [Web::Query](http://search.cpan.org/~yanick/Web-Query-0.38/lib/Web/Query.pm) and [JSON](http://search.cpan.org/~makamaka/JSON-2.90/lib/JSON.pm), and their objects actually *Dumper* quite well :) Sorry if I added confusion OP.
From the article: Year | 2016 | 2015 | 2011 | 2006 | 2001 | 1996 | 1991 |1986 -----|------|------|-------|------|-------|-------|------|----- Place |9 | 11 | 8 |5 | 4 | 3 | - | -
Right, it can't run without a perl.exe on Windows. That doesn't mean the file has to be named "perl.exe" though ... If `perl` is not in your path, it could still be hidden somewhere on the system. You could try searching for a core module, something Perl can't run without, maybe `warnings.pm` or `overload.pm`. Those files will not work if they are renamed, are part of the core Perl distribution. If you don't find them, I would bet there is no Perl on the system.
Thanks for sharing!
I wouldn't want us to fall into the trap of citing Tiobe only when the data is in our favor. That said, there's a much deeper field of languages out there than there was in the '90s. Perl may never return to the same relative level, but that's OK.
I am still very surprised that assembly language features on it.
"The only reasonable explanation for this is that the number of very small devices that are only able to run assembly code is increasing" - this seems like a leap. How do they rule out increases in popularity in older projects such as https://github.com/chrislgarry/Apollo-11 for example? Another reasonable explanation would be "our search terms met with false positives". Even low-power devices like the MSP430 have C compilers available (http://www.ti.com/tool/msp430-gcc-opensource). Knowing how to interpret the assembly output is a useful skill, but I wouldn't call that "programming in assembly" (might as well claim to be programming in Perl opcodes just because you occasionally look at B::Concise output!). A breakdown of architectures that comprise those assembly results would be useful, couldn't immediately see anything relevant on the tiobe.com site.
There *are* some heavy-hitting distributions. I made a hit-list of those and have been emailing the relevant authors directly.
Is anyone actually using Perl6 then? 
Exactly, unless you're doing the core of a boot loader, or the closest to the metal bits of a kernel, you're unlikely to be using assembly language these days.
When people were upset with TIOBE, I heard a number of people saying that the creator had a well-known bias against Perl. I asked for evidence, but never received it. It became thing _thing_ that just kept getting repeated. Frankly, I think TIOBE is one of several reliable sources, but its limitations need to be understood. For example, [the vast majority of financial transactions still go through COBOL](http://blog.hackerrank.com/the-inevitable-return-of-cobol/) and it has more lines of code than any other language in the world, but it ranks very poorly on TIOBE due to how they create their metrics.
The usability leaves a lot to be desired. I'm waiting until the book (or any book) is released.
That's interesting. Never thought of using a heredoc to do something like that.
The other thing that's nice about it that I didn't mention is you can copy and paste code to the terminal. Because it's formatted like real code and not a one liner, the code rarely needs to be modified. 
This is good to know about, thanks for sharing!
If you're using GNU Bash, you can use its `fc` builtin instead. [This](http://unix.stackexchange.com/questions/6620/how-to-edit-command-line-in-full-screen-editor-in-zsh) works in zsh.
Ah, it's my bad for not posting this here earlier. The event has come and gone and Damian did actually clear the needed amount via this and some in-person donations at the talks. This campaign should have been closed when the talks came and went. I've just spoken with Dave Doyle and he has just now marked the campaign as complete so that we don't accidentally collect too much money for Damian. ;)
Not a very useful article, IMHO. &gt; Why do they hate us? Who are "they" in this context? Do "they" really hate us? Where are you getting this from? https://en.wikipedia.org/wiki/Complex_question &gt; Some programming languages see more hate than others Well, yes. This isn't very surprising, is it? You could replace "programming languages" with "sports" or "fashions" in that sentence and it'd be just as valid, and just as uninformative. &gt; Well, there are plenty of reasons, which doesnâ€™t sound so good, but people dislike it for various reasons ... and this applies to every other language I use, including Java, Javascript, C++, Python, SQL and English. Hardly insightful, especially with the lack of specific details and suggestions for what can be done about improving the situation. &gt; Yes, there are a few things that make Perl a bit more different than other languages Again, Perl isn't very special in this regard. Try that sentence with "Python", "Smalltalk" or "Malbolge". &gt; stop comparing with other languages No. Terrible advice, even if not entirely serious. Keep your eyes open, head out of the sand and learn from other communities, they're doing some great things - reactive/async coding, for example: we've had POE for a while, and it's solid. More recently, we have [Future](https://metacpan.org/pod/Future) which provides a useful common base for doing async task composition. Much of the conceptual basis for that came from areas such as JS Promises/A, but Future is not just a blind copy. Learning from other languages can lead to hybrid vigour and open up a range of new possibilities. True, it can also lead to smartmatch but we can't win 'em all... &gt; Perl fits all the criteria for a good scripting language That's nice, what are those criteria? What was the point of writing this article? What does the author or the Perl community gain from it, other than yet another search hit for "Perl hate" and reinforcement of negative sentiments? 
I'm not sure what the point is in that blog post. If it's meant to be click-bait, going mental with the tags is doing nothing for your SEO.
&gt; Perl is also a very old language, one that's been around for almost 30 years, thatâ€™s older than most programmers today. And because of this, there is a sort of generation gap that leaves Perl out of the modern pack of programming languages. Itâ€™s from another time, another place, another age And yet Python, that the author lauds as popular, is 25 years old. Not to mention Modern Perl is a completely different beast from the 30-year old Perl. The argumentation in the article contradicts itself. 
**[Perl Artificial Intelligence](http://ai.neocities.org/index.html)** is going to take over the world with **[Artificial General Intelligence](http://github.com/PriorArt/AGI)**, and that's why people have a love/hate relationship with Perl. 
Please stop
regarding highlighting of keywords (addendum #3), yes perhaps it seems like highlighting the least important things, and yet: * if you are typing fast and try to make a `whole` loop rather than a `while` loop and the keyword doesn't light up, then you see the typo instantly (or at least I do) * in languages with reserved keywords it can help to see that you are about to collide with one of those * in a language you are less familiar with (picking up those first few lines of javascript, say) then when you aren't totally sure what the keyword for X is then once the highlighter lights it up you can be reasonably sure you remembered it correctly
now this would make the basis for a far better article, even if it's a bit opinionated in places =)
There's not much you _can't_ do in perl. I mean, it has all the inherent constraints of a bytecode language, but ... well, Java is still pretty popular despite that. But you can quite easily bridge to C, it's great for API hooks, and XML/JSON/YAML parsing. Inline regex is fantastic, and a feature more languages could use... And most importantly of all - you _can_ do 'proper' object oriented code (hand rolled, but probably better to use Moose). And you can do parallel and multithreaded code. I don't recommend threading _and_ forking at the same time though - that way lies madness!
Things I learned: * `parse_address` accepts an options struct and then sets all options to null. The API is implemented in Perl but I left it undocumented as its useless right now. * `expand_address` segfaults when all options are false! * libpostal crashes if `setup()` is called twice, `teardown()` called twice, or even if you `setup()`, `teardown()` and then `setup()` again. * `Geo::libpostal` is the only client library that supports options
haha
My biggest complaint about Perl ticket queues is that even big name people dont use the system properly. There are tickets in project queues that have been fixed with a patch years ago and never closed. This applies with both RT and github issues. My guess is they reply via email to ticket which updates the notes, but never go in and handle their queue directly. I understand finding an occasional project like this but I see it often, and see it in projects that get lots of use. In some cases, if a ticket was stalled without a resolution but there was a workaround I left comments explaining how to bypass the problem and begging the submitter to close the ticket. That doesn't work well when some of the tickets were filed 5+ years ago and the ticket writer might not understand RT either. Maybe it would be nice if there was a system where a passing stranger could say I reviewed this ticket and I'm voting to close it? The RT system could then append instructions like "maintainer reply to this with the keywords 'resolve ticket' or click here if you want to close" 
I find RT unnecessarily cumbersome and unintuitive, hence preferring github trackers on my distributions. Add "Closes #foo" to the commit and everything's done for you. Reply/close/reopen actions are in obvious places. It's much easier to manage a queue when the tasks themselves are easier to find. (But I have the luxury of not having to manage a queue of a big project which may have 100+ open issues. That's a whole other level.)
As mentioned in [part 1](http://perl6.party/post/A-Date-With-The-Bug-Queue-or-Let-Me-Help-You-Help-Me-Help-You), the app contains personal tags, not something to post on RT. It started as a way for me to find easy tickets for me to hack on, but grew larger than the original plan. We didn't even have a `[@LARRY]` tag in the queue until a couple of days ago, for example, which was created basically as a result of my using that app and writing these blog posts. The app uses a local SQLite file. 
If possible you should try to incorporate this into RT with either a plugin or core patches. It looks very useful and it would be nice if CPAN RT could have it.
This is nice to see!
No need for migrations :) You can learn and use both! And with Inline::Perl6 (in P5) and Inline::Perl5 (in P6) you can mix and match them together!
I am quite sympathetic with Larry Wall. When I discovered perl it was one of marvelous. But I later discovered python and never regret the switch (except for regex and one liner). I pretty much disagree with this assertion: "Perl has always considered itself primarily a programmer-centric language, while Python has always considered itself to be more institution-centric." In my opinion Perl take care of writing program and don't take care about reading them while Python do the exactly opposite. That's why python is winning in the long run (and it is a hard job with all inheritance of perl for example the rich CPAN libraries)
Well here is a decent place to start. There is also https://jobs.perl.org/ or several consulting firms including http://perl.careers or http://www.allaroundtheworld.fr/ or https://www.plainblack.com/ (edit) or http://shadow.cat (and certainly others I've missed). You might also hop on to IRC (either irc.perl.org or freenode#perl) and ask there.
Congrats on new major release!
http://shadow.cat/ specializes in that type of work.
Since this thread is about jobs with Perl as the current primary language... I am looking for software developers to join my Applications/LIMS team at the McDonnell Genome Institute in St. Louis, MO! We are currently working on projects in the areas of cloud storage, cloud compute, high-speed data transfer, and laboratory automation. If you are interested, please search for job 33387 at https://jobs.wustl.edu/, and apply through the system. They will pass along the information, and I will email you. Naturally, I'll answer questions here, too. This is not remote work. Policy inspired by the university. :( But your work can assist scientists in curing diseases, and the culture is pretty relaxed.
You disagree, but fail to provide any arguments. Then you proceed to make *more* claims without providing any arguments for them either. Particularly this assertion is meaningless: &gt; The simply fact that indentation is mandatory helps a lot. You can use Perl::Tidy to reformat any Perl code you can think of to have any indentation structure you like. Perl has forced indentation as well, only it is applied reader-side and customizable, instead of writer-side and fixed. Lastly, you entirely misunderstood what i was saying, as evidenced by this comment: &gt; I don't doubt that expert perl programmer can produce readable code. I am not saying you need an expert perl programmer. I am saying that in *every* language, someone who names things well, and avoids senseless repetition, will produce readable code; and someone who doesn't, won't. This is completely separated from any kind of feature the language can provide, since no language feature in the world will help you if a function is written using names like "handle", "count", "data", "x". &gt; readability is not a feature of a language Which actual language features do you feel increase or decrease readability of a language? Which of those do you consider to be stronger than "good naming"?
&gt; Perl has forced indentation as well, only it is applied reader-side and customizable, instead of writer-side and fixed. That means all source code you will read will not have same rules. It makes hard to switch between code bases. &gt; Which actual language features do you feel increase or decrease readability of a language? Which of those do you consider to be stronger than "good naming"? good naming is a feature to make good code and be able to understand it. In my opinion, it's orthogonal to readability. The excessive use of sigils as perl does in my opinion decrease readability as they put unnecessarily clutter. Especially when all variables are marked by a sigil. Custom operators decrease readability. As perl6 promote it, that you can build your own language decrease readability as you might encounter different flavor of language depending on the context. Generally speaking complicated things decrease readability. The more readable way to express an algorithm is in my opinion the text books pseudocode and for the good reason it has no constraint to be consumed by a computer and it's only intent is to be read by human. To my knowledge python is the closest language to pseudocode and has nearly all his virtues in readability side. All the things I quote don't make necessarily perl a bad language, at the opposite, they have a reason to be. They just don't make an as readable as python in my opinion.
Neat!
&gt; Wrong. It means all source code i read will have the same rules. My rules. Except when it occurs that you read from somewhere you can edit it, for example on a web site such as stackoverflow or github or in blog posts. &gt; What is in your opinion the difference between what you seem to consider "understandability" and "readability"? readability is a part of understandability which is the general process of making our mind understand the code. readability is what is important in the first step when you eye process the code and make it easy or harder &gt; hey don't create unnecessary clutter, they demarkate variables containing vastly different things. They're not even something new, C code does the same thing, by adding short-hands of a variable's type to the name. for **reading** the code both are unnecessary clutter, to take your C example: IShape for Interface shape is less clear than Shape for a human look and unnecessary reading clutter. I hope that you will agree hungrian notation which push this logic to the point of stupidity is largely abandon for good reasons, one being that it is harder to read. &gt; Further, they also allow machines to easily and quickly determine types of variables and treat them appropiately when, e.g. transforming or displaying code, thus increasing readability. First sigil can only match a bunch of type and all not types. If you really want give easy task to your computer you want use a typed language which as go show can be quite readable as go language experience show. Second I agree that readability is at the cost of being less easy for computer processing. It is actually a major drawback of python language that indentation significant makes hard to tools to be build around it's syntax. For example I don't know any parser generator which work with indentation significant language. &gt;&gt; text books pseudocode &gt; What this means is that you consider code that is written in a language you already know to be readable, and readability is for you only a measure of similarity to said language you already know. No that it means that I consider that text books author does great job for transmitting their intent in paper form. Other examples of highly readable description of algorithm in text book are diagram but you have to concede that they are poor target for a general programming language. I consider that you are conducting a misleading trial by implying that perl is foreign for me. I have worked during at least one year doing only perl (I remember not exactly, it was 15 years ago). I also played with perl longer than that. I am also enough familiar to at least ten language, so I think I have saw enough language to compare language which are easy to work with and the one which are harder to read. &gt; Here's my problem. You make statements, assertions and claims about things you have not fully understood; instead of doing the humble and polite thing and recognizing your own lack of knowledge and refraining to opine as a consequence. I don't pretend to fully understood any domain of knowledge in the world. I agree that aesthetic judgments depend on the eye of the speaker. However I program since 20 years (12 years professionally) in various languages. One of my center of interest is precisely how languages are designed and what are their strength and weakness. I feel very rude that you imply that I lack of knowledge about my daily tools and say that I'm ignorant.
Your explanation of readability and understandability is still hand-waving. The rest of the bulk of your response just shows that you insist on opining with a head filled of half-knowledge; instead of asking questions to see if your understanding matches reality. You didn't even bother to ask a single question. I'm done talking to you, you're not worth anyone's time.
argh, I knew I'd miss someone, how did I miss that?!
Too ubiquitous? :D
&gt; The order of iteration is guarantee to stay same between two successive call to keys or similar functions if there is no change in the hash. Even if it's true there is nearly no advantage to rely on it and moreover this guarantee makes future change impossible This constraint is to allow keys and values to be used independently but with each other, but it is not guaranteed to stay the same between executions of the program. # perl -E 'my %hash = ( one=&gt;1, two=&gt;2, three=&gt;3 ); say join " ", keys %hash;' three two one # perl -E 'my %hash = ( one=&gt;1, two=&gt;2, three=&gt;3 ); say join " ", keys %hash;' two one three The reason why it's randomized is for [security](http://perldoc.perl.org/perlsec.html#Algorithmic-Complexity-Attacks). As for why you think it can't be changed, I'm not sure your reasoning. The implementation *has* changed, so obviously it's possible. As for what mithaldu is trying to convey regarding the your assertion of pseudocode and textbooks, I think it's along the lines of you being familiar with pseudocode as it is often presented, and mistaking your familiarity with *obviousness*. That python builds upon a wide understanding of that syntax is no mistake, but let's not confuse *common* with *inherently better*. Another way to look at this, is to examine why we often use '+' to denote addition of numbers in programming languages. That's not the only way to do it, you could have (and languages have) a syntax like add(2,3). One syntax is not inherently better than the other, but we often use the '+' symbol *because we've already been taught it*. Over many years we've learned that notation in our math classes. Now, interestingly, mathematics fully embraces *multiple notations*, because they long ago discovered that certain things are easier to express and manipulate when you describe it differently. Certain operations become trivial to express, while others become harder. The trick is knowing the notation before working on those problems. Now, computer languages are the same. We do have simplistic syntaxes for making things clear to beginners, but we also have complex syntaxes for succinctly and clearly expressing complex algorithms. That is, they are clear and succinct *if you know the language*. APL is a fairly illustrative example of that. For example, see [this](https://www.youtube.com/watch?v=a9xAKttWgP4). Now, Python is very easy for beginners to pick up, and that is because the syntax is both *fairly* obvious, and *very* common. That makes it easy to read, and write for beginners. But people even moderately familiar with Python are leaving a lot of writing and reading optimization on the floor in the name of accessibility. That's fine, that's Python's choice, but that doesn't make it inherently better, it's just a different way of optimizing what your think is important to your language.
&gt; This is an assertion itself worth challenging. The syntax is "fairly obvious" and "very common" to people who have experience with Algol-derived languages. Well yes. I was working under that implication when writing that, and it's less implied and more outright stated elsewhere, as that's what the majority of the second half was about (prior exposure and learning makes some things appear "easier" or "better"). I think it's fairly safe to say that *at this point* most programmers learn some Algol-derived language as their first programming language, or the first language they use while thinking of it as "programming" and not something else (it's amazing what you can get people to do to extend/enhance/hack/cheat the game they are playing without even realizing what they are doing...). I think the assertion is true, but only because IMO there's less variation in the types of languages people are exposed to these days (but it has gotten a bit better with R, J, Scala and Haskell becoming more popular. But that could just be my HN bubble). For anyone that grew up using HP calculators with RPN, certain concepts are easier to understand as well. It's all relative.
&gt; I think it's an assertion worth challenging if only because challenging it may help us be more creative in the first languages we introduce to new programmers. Sure. I'm not saying it *should* be that way, just that I think it explains a lot of people's current view that Python is "easy" to learn and read. &gt; Or we could be honest that the first programming experience many people have is Excel. That's very, very true. Even more so when you hear stories about complex monster "excel spreadsheets" surviving for years with huge macros that nobody understands any more and everyone is afraid to look at. If that doesn't mirror at least one program/system in any company in tech that's been around for 5-10 years or more, I'm willing to bet that's because they made a concerted effort to change that at some point in the past.
&gt; In a Perl 6 variable or parameter declaration, if you write a \ where the sigil would normally go then that variable is declared to have no sigil: So you use a sigil to say that you will not use sigil, it's a bit strange in my opinion 
&gt; That's fine, that's Python's choice, but that doesn't make it inherently better, it's just a different way of optimizing what your think is important to your language. I never said that python is inherently better. Just better in readability.
Hmmm... I wonder if this has to do with the fact that perl developers are mostly at the senior level (15+ years experience). I bet there is a greater % of contractors as well which require a higher salary to cover medical insurance...etc.
Yeah, I was gonna say "what jobs", but then I realized that there are no lower level perl jobs, only "senior system admin" etc.
[removed]
&gt; How one can think it's obvious that +[1, 2, 3, 4] return the length of the list, comparing to len(1,2,3,4) or [1,2,3,4].length or any other usual formulation? I don't think anyone thinks it's *immediately* obvious to someone who has *never* encountered Perl before. That's one of the points being made about Perl in this thread -- it isn't trying to make everything *immediately* obvious to someone who has *never* encountered Perl before. (Would you consider [1,2,3,4].é•¿åº¦ to be an obvious formulation?) To make sense of what Perl does here, you have to know two things: * A list is considered to be a plural thing, not a singular thing. This directly corresponds to the same distinction in most human languages: singular means 1 thing, plural means N things. * Perls process singular and plural things differently. And, now you know these two things you can understand why Perl returns the length of a list in numeric context: * If `foo`'s basic type is singular, like the value `42`, not plural, like a list or dict, then the numeric interpretation of `foo` is based on whatever value is held in `foo`: my \foo = 42; say +foo; # displays '42' * If `foo`'s basic type is plural, like a list or dict, not singular, like `42` or `"string"`, then the number interpretation of `foo` is the number of elements in that list or dict: my \foo = [42]; say +foo; # displays '1' This is deeply fundamental to Perl (and lisps, "array processing" languages, etc.). It is *very* convenient in an amazing variety of situations and *never* inconvenient. But you do have to learn it, as you now hopefully have. &gt; I would not say that it works beautifully, In my opinion it works in a convoluted way. Presumably you change your opinions in the light of knowledge; did my above explanation make any difference?
It's a symbol, not a sigil, but yeah, it's a bit strange when you first encounter it and I still think it's ugly. But it's a tiny downside that corresponds to a lot of upsides that I haven't discussed because, well, that would be getting in to the process that Perl assumes, which is it's better for experienced programmers to be willing to invest some effort in to learn the language so things become obvious rather than everything being immediately obvious, even to a novice, without really learning the language.
I think that statement still stands when you add any attribute X after "better" that's subjective, such as "at readability", "ease of writing " or "ease of learning", etc. To bring in a point of chromatic from elsewhere here (a point I've made myself in the past), if you only had experience with Lisp and had not seen an imperative language, python may not seem very readable at all.
&gt; Apparently Bash scripters are more experienced than other developers. Perhaps that's because *they're old enough to even know what Bash is*. Ding ding ding. I run a majority Perl shop, and everyone has 15-20 years of experience because there is no such thing as a novice Perl developer anymore. It should be no surprise that everyone is paid well.
There are lower level Perl jobs available. ZipRecruiter is hiring Perl devs all the time. Booking.com the same. 
I work with several novice Perl devs
&gt; So you use a sigil to say that you will not use sigil, it's a bit strange in my opinion Again you misunderstand. You ONLY need it in the *DECLARATION*.
What's the first, COBOL? Oh, wait... bash. Close. It's an old language. Somehow I don't like the sound of that.
Don't forget [cPanel](http://job.listings.cpanel.net/)
Okay, to answer this question, you need to forget about most of the technical details technial people like to obsess about. Larry Wall didn't just tell the other language communities "here's another way", he essentially told them that they're crazy: http://www.wall.org/~larry/onion3/talk.html Since they actually are crazy, they're somewhat sensitive on this point, and they responded with what amounts to a smear campaign, a religious war unlike the world had seen since Pascal was going to save us all from the evils of Fortran and Basic. If you want some evidence on this, consider PHP: by any reasonable standard it's worse than perl, but was essentially given a free pass while the perl sneer-fest was going on. You also might look at Steve Yegge's comments on that Larry Wall talk... Yegge recognizes a lot of perl's positive features, and yet that Larry Wall guy just *burns him up*: https://sites.google.com/site/steveyegge2/ancient-languages-perl 
Bit of a mix - mostly they're learning the language on the job with different levels of prior exposure from "none" to "script and module basics"
It's an unary operator. Are you also for replacing + and - with plus and minus?
Why not instead of `my \dict` use `somekeyword dict`
If you're talking about the Active State guy's presentation, I'd take it with a grain of salt. I'm not a statistician, but his population sample was pretty low which he admits. Whether it is statistically significant or not, I can't comment on. It does fly in the face of what we seem to know as common sense. 
Those are used by generalists for whom programming is just one aspect of the job. I do storage and there's a lot of bash and Perl glue involved. In theory my programming is mostly C and C++ but in practice more than half of the job is gluing.
Is there such thing as a bash developer? Perl no. 2 yeah! But Bash no. 1? 
Will that start to change now that perl6 is out?
&gt; If é•¿åº¦ means length in japanese Chinese (so the language of well over a billion folk rather than the much smaller Japanese population) but yeah. &gt; and [Chinese] would be the lingua franca of computer Languages are increasingly moving toward allowing devs to write code in their native language. I think, over the long haul, this will be compelling in some scenarios both for devs whose native languages are already popular and for others working with those devs or hiring them. I think it's just a matter of time (maybe a couple decades?) before some Chinese devs write most of their code in Chinese and most write at least some. &gt; I would consider it as an obvious formulation. "æ–¹æ³•" means "method". Would you consider the following to be an obvious formulation for declaring the length method? æ–¹æ³• é•¿åº¦ { ... } &gt; Of course I would prefer [1,2,3,4].longueur but I can't force the world fit to my personal conveniance. I know what you mean, but you actually *can* force this for your own code right now with several programming languages if you really want to. (Of course, most folk would consider doing so to be a pretty dumb and unfriendly move if your code is shared with a lot of non French speaking devs.) &gt; The problem is not that they process it differently all languages does, is that they transform it implicitly in one to another. What's implicit in the Perl 6 case? The prefix `+` explicitly demands a numeric interpretation. Perls explicitly define the numeric interpretation of a composite structure as the number of elements in it. Note also that Larry's perspective -- and I see his point -- is that the English word "length" is obvious but also obviously wrong in many cases. One reason for this is due to the ambiguity of what "length" means for a Unicode string. Does "length" mean bytes? Codepoints? Code units? Graphemes? If "length" means the number of characters, then what does "character" mean? &gt; To my knowledge perl is the only language where [1,2,3] can be silently transformed in 3. It's not silent and nothing gets transformed. It's directly analogous to a "length" function: my \list = 1,2,3; say +list; # 3 say list.elems; # `+list` means `list.elems` if `list` is a plural value (eg a list) say list; # (1 2 3)
I thought COBOL and ABAP were the highest paid languages, but they both are not on the list.
Based on that graph, it seems pretty foolish to learn "golang" rather than "go".
I thought I saw something else the other day showing python was ahead of perl? 
Obviously not, they do Windows. You can see right through them!
Good tip, not sure why this is at 0 points. One thing though: whenever is_deeply is suitable, [Test::Differences](http://search.cpan.org/~dcantrell/Test-Differences-0.64/lib/Test/Differences.pm) with eq_or_diff is almost always better, since it will show the differences in a way more useful way. Example from the docs: # +---+----------------+----------------+ # | Ln|Got |Expected | # +---+----------------+----------------+ # | 1|this is line 1 |this is line 1 | # * 2|this is line 2 |this is line b * # | 3|this is line 3 |this is line 3 | # +---+----------------+----------------+ And when using cmp_deeply from Test::Deep, it's usually a good idea to write this: cmp_deeply($myvar, $expected) or diag Dumper($myvar); so that you can see the data structure whent the test fails (use "diag" over "note" so it's printed even if not running prove in verbose mode).
&gt; use "diag" over "note" so it's printed even if not running prove in verbose mode If you're running prove / make test directly then yes, this can sometimes be useful for a quick summary of failure info. However, there's no context - you don't have any of the surrounding TAP output to refer to. Since the diag() output goes to STDERR instead of STDOUT (where the rest of the test output will be delivered), there's a risk that it won't be captured, or that it won't be in sync with the rest of the output. In general I prefer to run tests in verbose mode with note() output - this fits in better with CI systems such as Jenkins, especially if you're using something more advanced than TAP output. TAP itself is nice and simple, but it's quite primitive compared to other formats: jUnit XML can include extra information such as test timings, for example. Even when run manually via prove, I find it much easier to identify issues when running just the failing test(s) in verbose mode.
Just to be clear, I'm only recommending using "diag" in this one specific case: the test failed and you need more diagnostics. All other manual output should be "note".
this: $ perl -e'use Test::More; diag("fail"); done_testing' &gt; /dev/null # fail # No tests run! (replace diag with note to see the difference). It's "safer than printing to STDERR" for many reasons - you might be deep in a test that's capturing STDERR for a higher-level test, for example. Although I'm not saying diag() is pointless, I do find myself using note() or a wrapper in all cases - maybe if I used prove manually without a custom formatter I'd have more use for diag().
Drifting off at a tangent here, but: If you're actively working on tests and want to poke around when there's a failure, I think the following sequence should still work (haven't tried with the latest Test::Builder): perl -d yourtest.t b Test::Builder::ok !$_[1] c That'll break into the debugger on the first test failure. Yes, it's quite primitive and I'm sure most people have more useful tools on a properly-configured dev system, but it's something I've had to resort to occasionally (running tests on newly-deployed FreeBSD/Windows instances, for example). Some people are proficient in print-tracing failures; I rarely manage to include all the needed info on the first attempt =)
&gt; The semantics of + are only about something being numeric. Prefix + (and prefix -) force a numeric interpretation of their following argument. For example +foo or -foo force a numeric interpretation of foo. If foo is not accepted as numeric (eg it's the string "foo") then +foo or -foo will raise an exception. The problem I see is that a numeric interpretation of a list makes no more sense than the numeric interpretation of a list &gt; None of this has anything to do with length. In the strange (in my opinion) mind of perl6 creator it has something to do with the number of elements of a list, which I find surprising. &gt; ... Once again the confusion between the different counting exist uniquely on unicode. There is no reason to treat &gt; If today is Sunday then "days since Friday" can mean "Saturday and Sunday" OR it can mean two. Many English plural nouns have this duality of the things themselves or their count. Maybe this ambiguity exists in english but I see no reason to report it in programming language. According to other programmers languages convention (which I don't see good reason to break) Buf[int64].new(1,2,3).elems # should return the elements Buf[int64].new(1,2,3).bytes # should return the bytes 'á¸ŒÌ‡'.encode('UTF-8').bytes # should returns the byte 'á¸ŒÌ‡'.codes # should returns the codepoints 'á¸ŒÌ‡'.chars # should return the user perceived characters You could then maybe call length or size on this unambiguous representation, if direct shortcut would be necessary, names such as nelems, nbytes, ncodes, nchars or even better name (which I don't know) would be welcome
Try jobs.perl.org next time.
I'd suggest perhaps advertising on Stack Overflow too. There's at least a few there. 
&gt;&gt; The problem I see is that a numeric interpretation of a list makes no more sense than the numeric interpretation of a list &gt;??? Sorry The problem is that there is no meaning to consider a list of thing as a number. &gt; Over the years it became clear that, while 'nelems', 'nbytes' etc. have logical merit, the versions without the prefix 'n' were actually much preferred by almost all newbies after a very brief explanation. How the elements content, bytes content and codes content are worded ? I believed that Perl6 had iteration on container as powerful as python so using number of elements of a container is rare to use. I am wrong ? That I still don't understand is how the unicode problems spread as a problem for all containers ?
Hey, next time you list those out, you can add https://iinteractive.com/ too! 
If your primary purpose is to use Perl in production, and to take advantage of existing modules, to interect with and maintain existing Perl programs, you should learn the latest version of Perl 5 ... namely 5.24. Right hand column has links to lots of Tutorials ... I recommend "Modern Perl". If your interest is in learning a new language, investigating programming paradigms that may be new, and to focus on future trends, not the past, then Perl 6 is great, but it's still in its early days: performance is coming up to a reasonable level, some features are still missing, multi-processing support only runs in serial mode, so far, but it's advancing. The advantage is that any programs you write will become more efficient as they improve the language.
&gt; The problem is that there is no meaning to consider a list of thing as a number. Prompted by your determination about this, I decided to do a quick random test. I wrote this on a piece of paper: (42, "hello", 99, Foo) I asked someone who is most definitely not a programmer what single English word would most simply describe what she saw. Her first answer was "Life, the Universe, and Everything?". I admired her joke and asked she try again. She said "Set?". I said that was close and asked for another try. She said "Group?" Then I stopped and wrote this down: 42, "hello", 99, Foo and asked again. She said "list?". \o/ One down, one to go. Then I said, "Now I'm asking for a single number that you think of based on the list". She said "42?" I said "Thanks, please try again". She said "4?" I said "Why?" She said "Because there's 4 things in it?". This is not remotely scientific of course, but I think you are the one being too clever, not Perl 6. &gt; How the elements content, bytes content and codes content are worded ? Elements content is worded without saying anything: [42, "hello", 99, Foo] is an array with those elements. Buf.new(1, 2, 99) signifies a buffer with those bytes. 'á¸ŒÌ‡'.NFC returns the codepoints corresponding to NFC normalization of 'á¸ŒÌ‡'. etc. &gt; I believed that Perl6 had iteration on container as powerful as python so using number of elements of a container is rare to use. I am wrong ? Not sure. &gt; That I still don't understand is how the unicode problems spread as a problem for all containers ? Perl is first and foremost the ultimate tool for handling text. Unicode is the ultimate system for encoding text. We can not use "length" for text. There's a little more to it but I've gotta run.
When you say you're a JS dev, care to elaborate? What do you know about JS? How comfortable are you with node? Have you mastered ES6? Do you know how to write Promises? Have you at least familiarized yourself with async/await? My advice is likely to stick to JS. Node is awesome. Perl has Moose, it's worth checking out. Shy of that, the grass is just greener in the land of node.
Do you mean 'good' Windows admins, or 'average' ones? Because we've found almost the opposite - you can get some good devopsy Linux guys, but whilst "Windows Admins" are 2 a penny, the ones that know stuff inside out are considerably rarer. 
That's the same link as the one he mentioned. Suggesting Modern Perl in a dated comment on a post that'll be archived in a few months seems quite reasonable, and it's a nice gesture to have a suggestion where to start out of the 19 currently listed on that page.
Do we still need to install Strawberry perl which was a requirement in the last release? "This version was built with mingw (from Strawberry Perl) rather than the usual MSVC which may have performance implications. In order to use the module installer â€œpandaâ€ you will also need to install Strawberry Perl and Git for Windows. Also ""
I think that's just for `panda` and even then it only needs `git`. You can use `zef` as module installer and I believe it doesn't need git: https://github.com/ugexe/zef#installation (though maybe needs the C compiler [that comes with Strawberry] for some modules that have C source to compile during build)
I've mastered of Perl 5. I've published to CPAN. I've worked with the internals of POE, and Moose. I'm a perlmonk with 11 years experience. This *more mature* is a bad selling point -- it just means it's done things wrong for longer. * Look at CPAN vs npm for instance: which is more mature? Arguably CPAN, but it does almost nothing and what little it does, it does wrong. npm installs modules locally by default. Every module can use a different version of a dependency, and it even installs and downloads in parallel. CPAN by contrast is built with tech from the 90s and downloads a gigantic 20 meg index and then does everything in serial globally. Unless you have lib::local and even then it's a hack job and a pita. npm just works. * How do you parse HTML with Perl? I've used and contributed to HTML::TreeBuilder, and others. It's always a pain in the ass. It's a hack job on top of a hack job. With Node, just install Cheerio and use the jQuery interface. * How do you parse XML with Perl? Despite having a team and a series of ways to do this -- good fucking luck. It's a nightmare. Most of the modules suck so bad, to the chagrin of some, perl users tend to use XML::Simple and just handle it like that. With js, just use the native XQuery that's in the JS spec. * Crawling websites? LWP is special sauce in perl. It shouldn't exist. It's old, and language-specific. Every other language uses CURL. Which is more mature? I'll go with CURL. It has a use-case 100 times greater than LWP. * And POE is a such a bastard nothing uses it unless it absolutely must use it. I've got bugs I opened in POE that are still opened a decade later. I'll take async/await over that mess any day. Moving away from perl's ecosystem, the node system is just droves better. I was an early adopter of Mason and Catalyst. There is nothing like Koa in the Perl world. In Koa, you can write sequenced asynchronous middle-ware. As compared to Catalyst where everything plugs into different steps of the request handler. The user builds it themselves. You may have a middleware that, for instance, that parses the request body followed by another middleware that sends adds a complex promise (that checks a database or even a foreign webserver) to the user's object so the session can later resolve that promise if need be. You may need both of those actions (like in the authenticated parts of the website). And, you may need neither of them (like on /index). Try setting that up with catalyst which is based on plugging into different parts of the request handler. And, that's just the ecosystem. Node has reasonable async built in, decent anonymous function syntax, a decent VM with JIT (actually fast method calls), and the VM has a use case outside of Node -- Google Chrome. The list goes on. Perl has Moose and that's great. It also has perldoc. Shy of that, it's just lacking.
There are some specific situations where it can go wrong. If you modify `%hash` inside the loop, it can lose track of things. I've also seen some weird things happen with error handling. A while back, a platform I was working on had a global hash for storing messages during different phases of a request. At the end of each phase, the hash was iterated with `each` to check for errors. Sometimes, when it errored out, the next request would try to start the iteration in the middle and get itself confused. The quick solution was to switch the iterator to use `foreach my $key (keys %hash)`. Now, you could certainly argue that this whole global message store thing was wrong from the start. That said, I think there's enough unexpected weirdness that it's fair to preference `foreach (keys ...)` over `while( ... each ... )`. If it's just plain too much memory, then by all means go for `while( ... each ... )`. Otherwise, it's a premature optimization.
For the issue you experienced you can use `keys %hash;` to reset the iterator count. Thanks for the advice - though I'm not using it for optimisation, just so the later code is neater. I'm fixing some code as part of a job application and the code has a few hash-refs of hash-refs, so using the while just meant I could reduce the number of `$hash1-&gt;{$hash2-&gt;{$key}} ;` type lines. 
I didn't know this kind of thing was CVE worthy. I found something like this (not perl specific but caused by PATH problems). I believed when I found it that it was just a limitation of writing secure programs in a scripting language and that it was a known flaw that you couldn't do anything about (other than the shenanigans I went through in the example below to hardcode the path for every executable inside a script that needed to be secure) To keep this on topic for perl, perlbrew/local::lib scripts tend to increase the risk because they add ~/perl5 to your path and it's prepended instead of adding it at the end. That's good because you want YOUR copy of &lt;perlapp&gt; to run instead of the system version, but the unintended consequence is that you have a directory in your path that is writable by your user, and a malicious script can put anything in there. That includes things like fake versions of gpg that capture your passphrase before running the real version. Example: https://github.com/rfdrake/pass-hardcodepaths
Well it's this using foreach: `$hash1-&gt;{$hash2-&gt;{$key}};` Or this using while...each: `$hash1-&gt;{$value};` I think it's a bit neater using the while, but probably comes with too many drawbacks.
From the p5p mailing list: &gt; While the Perl Security group has attempted to mitigate some of these problems by modifying Perl Modules, it is ultimately the responsibility of the application writer to remove relative paths from @INC to assure the security / consistent behavior of their code regardless of what directory it executes from.
Modern CPANs default to using local::lib cpanm defaults to using a local::lib, and doesn't download a full mirror index, and works fine. If you really wanted npm, use cpm, which builds an npm like interface. Mojo::DOM58 and Mojo::DOM are great for parsing HTML. If it's valid HTML, XML::LibXML handles it too. XML::LibXML is great for XML and there's lots of sugar libraries built atop it. LWP is great for the ecosystem. If you want parallel and more modern, Mojo::UserAgent is excellent. You can use curl to power LWP if you want to, or use curl directly through the modules for that too, if you must. POE is not that commonly used for new projects now, you want to look at IO::Async and/or Mojo::IOLoop as nicer APIs. IO::Async is pervasively Future based, so you get a similar experience to promises in node.js PSGI middleware allows for the exact thing you describe, although the only system that seems to use it heavily is my Web::Simple. Moose/Moo are epically superior to other languages' OO, to the point where there are partial ports to python, to ruby, and to javascript - and I'm pondering my own using ES6 decorators. All of your points are at least somewhat valid as to the ecosystem of ten years ago. It isn't ten years ago anymore. -- mst
each() is usually bad news, as others have already covered. Since you mention a job application: In the code you provide as an example, there's no context - the reader has no idea whether the iterator has been reset. Maybe it's safe, maybe it's not - we can't tell from the line provided. So, for completeness you'd need to add that 'keys %hash;' or equivalent just before the while() loop - this would at least make the intention clear. Even in real code, if the hash declaration isn't visible on the same page then it'd be a courtesy to whoever's reading the code to reset the iterator. But then the code no longer looks very neat, and presumably you'd also have code inside the while loop - so, again, in your example, there's no context: no guarantee the iterator is going to be valid anyway. Using each() tends to put more burden on the code reviewer, so in practice I find there are very few situations where it's justified. It might indicate "this is a tied hash with lots of elements", for example, so I'd likely waste some time looking for a missing call to tie()... my usual policy is "if you need each(), I need a comment explaining why". I wouldn't fail a job candidate just for using it, but I'd raise it as one of the points in the code when discussing with the candidate (things like "how would you change this code if you were modifying the hash inside the loop? how about if you're iterating over a hashref passed in from elsewhere?") Given that, I figure "why bother with each(), it's more trouble than it's worth here". If you're only doing this to avoid the extra dereferencing later: for my $k (keys %hash) { my $v = $hash{$k}; ... } or maybe List::Util::pairmap { my ($k, $v) = ($a, $b); ... } %hash; 
yes absolutely!
Thanks for the great answer. I ended up changing it back to `foreach` and lucky I did, like you mentioned - since I was actually handling a reference - I don't know the state of the hash when I get it. &gt; if you need each(), I need a comment explaining why Good advice, I think I'll stick to this in the future. Thanks again. 
I know it's /r/perl and all, but recommending replacing the extension of a file with substr() is less than brilliant, especially since renaming a bunch of files in bash is as simple as; for file in *.xml; do mv "$file" "${file%.*}.html" done Why you would replace `useradd` with a perl snippet, is beyond me. Modifying all perl files might work better using `file` than looking at a file's extension, and again, could be a simple shell loop that uses sed (or perl) to search and replace. I would call this 'Things you can do with perl, as a sysadmin, to learn a bit more about perl' more than anything.
I'll offer that perl is a really pokey command line utility, that lets you do groovy things like: perl -pe 's/word/word2/g' &lt;somefile&gt; Which works just like sed would, but lets you do some much more complicated things. Or there's 'perl -ne' which does something similar, but without an implicit print. (prints only lines containing 'somematch') perl -ne '/somematch/ &amp;&amp; print;' You can also combine these with '-i' for in place edit, and '-a' for autosplit (whitespace default) and '-l' to strip and replace linefeeds. Or do a compound search and replace: my %replace = ( 'one' =&gt; 1, 'two' =&gt; 2, 'three' =&gt; 3, ); my $search = join ( '|', sort keys %replace ); $search = qr/\b($search)\b/; while ( &lt;&gt; ) { s/$search/$replace{$1}/g; print; } There's some nice tricks with 'map' and 'grep' too, that do more than the 'base' commands do. E.g.: my @dirs = grep { -d } glob "/path/to/dirs/*/*": print join "\n", @dirs; Because grep applies a test - which _can_ be a regex - but it can also be a 'file test' such as 'is it a directory' and in this way give you a list of just dirs matching that path. The place I find it particularly awesome though, is when it comes to tackling XML. With map, you have similar functionality - except rather than filtering, map can apply a transform: my @dirs_with_ext = map { $_ .= ".BAK" } @dirs; That's not too useful, but perhaps you could do: my %rename = map { $_ =&gt; $_.".BAK" } @dirs; This uses the fact that you can assign a hash directly from a list of paired values. Quite handy for such idioms as: my @servers = qw ( server1 server2 serverK ); my %is_server = map { $_ =&gt; 1 } @servers; So now you can do: if ( $is_server('server1') ) { ##do something } And also of use - grep a time stamp: perl -MTime::Piece -ne 'print if Time::Piece-&gt;strptime(join(" ", (split)[0..2],"2016"),"%b %d %H:%M:%S %Y")-&gt;epoch &gt; time() - 60' logfile Show you log entries in the last 60s. 
I didn't mean to imply you couldn't or shouldn't rename files with perl. Also, your solution is user-facing, so having more spit and polish is important.
hi perlnacho, i am not programmer, but let me explain my situation: i have a file that contains bilingual text, english and spanish, the file i have is like this : http://imgur.com/a/2d5tX , i put color for easy reading, but in reality is plain text utf8. the color code those lines have, is for a program called anki, where i can import text, 1 field for english, 1 field for spanish. look this is the format i do use: http://imgur.com/a/rwXhp at the top is the example of one line, example shows how a line is input in anki and how ends up rendering. here i put the pastebin of the first example : http://pastebin.com/XutDxvSD now let's say that file is called output.txt , and i want to search for the word "very interesting" that is bewteen the code so it looks like this : &lt;font color="#ffff00"&gt;very interesting&lt;/SPAN&gt; in the example there are only 5 instances, i want to collect all those lines, cointaining that code, and save the collected matches into a diferent document, so i can import it into anki. if there are 20 lines, pick them up, if there is less than 20 pick them up, so even if there is only one instance , pick that one, and save it to a different document, called : collected.txt the problem would be, indeed i need to pick from a list of terms, so for the example given above : i would like to search for this list : &lt;font color="#ffff00"&gt;Good morning&lt;/SPAN&gt; &lt;font color="#ffff00"&gt;Good bye&lt;/SPAN&gt; &lt;font color="#ffff00"&gt;Very interesting&lt;/SPAN&gt; pick all the lines that contain those words within the code, from beggining of line till the end /^.+$/ but no more than 20 lines, if there are less than 20 lines, pick them up even if is one, as in the cases of "good morning" or "good bye" , in the case of "Very interesting" should pick the 5 instances that exist in the text. please can you help me with that, indeed this is beyond my knowledge. thanks
There is a general comparison of Perl, Python, Ruby and many other programming languages common test libraries on Rosetta Code [here](http://rosettacode.org/wiki/Test_a_function)
Nice collection of examples. Some very minor nitpicks - might want to use quotemeta or \Q\E on the compound search/replace example, and probably no need to sort the keys either: my $search = join ( '|', map { quotemeta } keys %replace ) Presumably this is a typo: my @dirs_with_ext = map { $_ .= ".BAK" } @dirs; and you wanted either this, leaving @dirs unmodified: my @dirs_with_ext = map { $_ . ".BAK" } @dirs; or just: $_ .= ".BAK" for @dirs; and finally that hash lookup should be $is_server{'server1'}. I think that's used up my pedanticism quota for the day ;) 
&gt; &gt; Perl 6 is the most recent release of Perl &gt; &gt; No, it's really not, and I think that's confusing a lot of people. Seems this has now been updated: &gt; Perl 6 is the newest member of the Perl language family Hardly surprising, though - same name, radically different language. If a company like ActiveState which specialises in Perl-related things can get mired in confusion, what hope for regular users? =) 
That looks more like broken HTML than plain text, so the usual advice would be to start with an HTML parser. Unfortunately the content isn't regular enough for a simple script to be useful - you *could* use something like this: perl -MHTML::TreeBuilder -MList::Util=pairmap -le'pairmap { print "$a =&gt; $b" and ++$count &gt;= 20 and exit if $a =~ /Very interesting/ } map $_-&gt;as_text, HTML::TreeBuilder-&gt;new_from_content(join($/, &lt;&gt;) =~ s{&lt;/SPAN&gt;}{&lt;/font&gt;}gr)-&gt;look_down(_tag =&gt; "font")' output.txt which should generate something like this: Very interesting =&gt; Muy interesante Very interesting =&gt; in many ways Ese libro es muy interesante en muchas formas Very interesting =&gt; Mi vida es muy interesante Very interesting =&gt; Day Resulto en un diamuy interesante Very interesting =&gt; To all of us Su biografia es muy interesante para todos nosotro but I bet it'd break on your real input data, and that's maybe not the most readable of code examples if you're not familiar with programming (it's very bad code, and I'm too lazy to write a proper script). You'd also need to have a recent version of perl and List::Util, and the HTML::TreeBuilder module. This might be something that'd be better asked in the Anki support groups - from what I understand it uses sqlite databases to store things, so perhaps there's an easier way to get to the data?
Broken as in "you start a &lt;font&gt; tag, then end a &lt;span&gt; tag". Nothing to do with colour codes. If you're writing raw HTML by hand, then maybe try this instead: &lt;span style="color:#ffff00;"&gt;English&lt;/span&gt;&lt;span style="color:#ffffff;"&gt;Spanish&lt;/span&gt; i.e. if you start a &lt;span&gt;, end with &lt;/span&gt;. Ideally you'd use something more meaningful than &lt;span&gt;, although I don't know how well Anki supports other HTML elements. I'd suggest http://htmldog.com/references/html/tags/dl/ if possible. There are probably some good HTML tutorials around that would explain this in more detail - http://htmldog.com/guides/html/beginner/ perhaps?
Best bit of the article came right at the end: put all your toys (Perl, BASH, whatever) in a git repository and have them follow you around. Makes it easy to always find the current version. It would probably work with SVN too, but who would do that. 
hi, how can i do an arrayÂ¿?
I'm dreading updating my perl on debian jessie. Don't even wanna know what kind of crazy problems this is going to cause with our applications.
Perl doesn't automatically set the namespace that you're trying to call. Try: my $obj = meinobjekt-&gt;new( API_USER =&gt; 'apiuser', API_PW =&gt; 'apipw', API_URL =&gt; 'apiurl' ); $obj-&gt;ausgabe(); What's happening here is that it looks up the package `meinobjekt`, looks for a subroutine named `new` inside, and calls it if it finds it. Since it's called with a package name, that name becomes the first parameter to `new`. We get a scalar back that remembers that namespace (which is what `bless` does), which means the call to `$obj-&gt;ausgabe` does the same package lookup. In the original, it looks for a subroutine named `new` in the current package. Since there's nothing that exited the `meinobjekt` package, it still happens to look it up there. However, in this case it does not send the package name to `new`. Inside `new`, `$Type` will be set to `API_USER`, and you probably got a warning message about an odd number elements in a hash assignment. When `ausgabe` is called in the original, `$Self` would be `undef`, and it's probably a fatal error.
ok i am officialy blind thanks very much. in python you also have to assign the instance if you want to reuse is ;-)
This is a good book. I'm amazed it is so cheap on Amazon. [OO Perl](https://www.amazon.com/Object-Oriented-Perl-Comprehensive-Programming/dp/1884777791)
[removed]
These days the best way to work with OO is with the Moose system, or the more lightweight Moo. Here's what your code might look like with either of those: https://paste.fedoraproject.org/397183/76965514/ Check out https://metacpan.org/pod/Moose::Manual for a comprehensive guide, almost everything there also applies to Moo except the MOP and built-in type handling (however Type::Tiny works well with both Moo and Moose). The Moo-specific documentation is at https://metacpan.org/pod/Moo. The use of Moose is also well-covered by the Modern Perl book, which you can read online here: https://pragprog.com/book/swperl/modern-perl-fourth-edition
Totally disagree. Moose, Moo etc. add levels of complexity that are completely unnecessary. OP is going down the right route learning how native objects work.
I'm really not sure they do. If you've learnt OO programming separately but not Perl they make Perl OO look like OO you would expect rather than some weird stuff with hashes.
With Moo(se) you have much more power, many new features, and implementation details are hidden. I *can* see how you might argue that it's less complex, but I'd disagree. I'd also suggest that the complexity is usually a good thing. For someone new to Perl, both perlootut and perlobj are required reading IMHO. I'd say the same about Moo(se) tutorials - by the time you've been through all those, you should have quite a good understanding of roles, types, traits, inheritance/composition, and the reflection/introspection opportunities that a meta-object protocol can provide. Both in terms of the abstract concepts, and the language-specific "how do I do this in Perl". You're not really going to get that from learning about the mechanics of objects and classes in raw Perl, but then again understanding those mechanics is *also* helpful in writing and debugging your own code and code from CPAN. Even an idiot like me who often writes code without Moo managed to learn a lot from that documentation. With plain OO, there's not as much going on behind the scenes: package Example; use strict; use warnings; sub new { my $class = shift; return bless { @_ }, $class } sub example_method { my ($self, $param) = @_; print "Method called with: $param\n"; } Example-&gt;new-&gt;example_method("some text"); okay, seems you're going to need to know quite a few things: * what does package mean * the first method parameter being the class name or instance * what -&gt;method does * what a hashref is * what bless does You'll probably struggle with Perl OO if you don't already know about references and the scalar/hash/array types. bless() is possibly unusual in name and function for someone coming from other languages, but even so I think it's relatively easy to explain. With Moo: package Example; use Moo; sub example_method { my ($self, $param) = @_; print "Method called with: $param\n"; } Example-&gt;new-&gt;example_method("some text"); it'd be: * what does package mean * but you told me that I should always use strict+warnings * what does use Moo; actually do * the first method parameter being the class name or instance * what -&gt;method does * where does -&gt;new come from That's still quite a list, and we really only have the bare minimum "OO" in place. Normally I start with the plain OO approach, and after covering accessors/mutators move quickly across to a Moo example - there may be better ways to approach it, but so far I've found this to be quite successful in providing a good foundation without glossing over important details that might get very confusing later. perlootut follows a similar path. tl;dr learn both. it's worth the effort.
you can use the diamond operator &lt;&gt; to quickly open all files specified in argv. throw it in as a while condition and $_ will be your line. this is pretty basic stuff, though, you may want to look into the fundamentals of file I/O.
The flip/flop operator /pattern/ .. /pattern/ may be useful as well. Do you want to write the script? If not, is this a paying gig?
it would, but live threads are a special thing - see https://www.reddit.com/live Fortunately someone has already done some of the work in proxying the REST API via websockets: https://blog.pusher.com/pusher-realtime-reddit-api/ - only covers stories, not comments though :( No idea how well supported it is, but a simple test script seems to work for the AskReddit sub in their example: #!/usr/bin/env perl use strict; use warnings; use feature qw(say); # For more details, enable this # use Log::Any::Adapter qw(Stdout); use IO::Async::Loop; use Net::Async::Pusher; my $loop = IO::Async::Loop-&gt;new; $loop-&gt;add( my $pusher = Net::Async::Pusher-&gt;new ); say "Connecting to pusher.com via websocket..."; my $sub = $pusher-&gt;connect( key =&gt; '50ed18dd967b455393ed' # see https://blog.pusher.com/pusher-realtime-reddit-api/ )-&gt;then(sub { my ($conn) = @_; say "Connection established. Opening channel."; $conn-&gt;open_channel('askreddit') })-&gt;then(sub { my ($ch) = @_; say "Subscribing to new story posts"; $ch-&gt;subscribe('new-listing' =&gt; sub { my ($ev, $data) = @_; printf "[%s] %s\n", map $data-&gt;{$_}, qw(title url); }); })-&gt;get; say "Subscribed and waiting for events..."; $loop-&gt;run; 
Using Powershell, also tried Console (windows cli app) The code is a port scanner, I can link if you'd like to see 
so, ansicon then. far as I'm aware neither the powershell terminal nor cmd.exe support ANSI colours on their own.
You could try cygwin
&gt; I'm not sure what your objections to verbatim paragraphs are? I don't like leading spaces in the generated HTML. &lt;pre&gt;&lt;code&gt; hello&lt;/code&gt;&lt;pre&gt; will render like this: hello And not like this hello Thanks for your time however, and thanks for explaining that it's called verbatim paragraphs :-)
I don't know what tool you're using to generate your HTML, but it looks like [Pod::HTML](https://metacpan.org/source/KJALB/PodSimplify-0.04/Pod/HTML.pm#L244) always adds a load of whitespace to the start of a verbatim paragraph. I bet it wouldn't be hard to create a subclass which has the behaviour that you prefer.
I'm not sure either, it's a github README.pod, used by github to generate the initial landing page for a project/ directory. I guess I will investigate and reports my findings to Github, as it seems an error in their pod parser more than a general feature wish.
It's the [github/markup](https://github.com/github/markup) repo, which uses [Pod::Simple::HTML](https://metacpan.org/pod/Pod::Simple::HTML). And it looks like that just puts tags around the existing text. Which would explain the behaviour you're seeing. So I think the best place to apply a patch would be to [pod-simple](https://github.com/perl-pod/pod-simple). But it's not a trivial problem to solve. You can't just remove the whitespace from the start of the line - as that would destroy the indentation. You need to work out how much whitespace the first line uses, and then remove that amount from every line (I think).
Perl Weekly is so great, what a wonderful milestone . Congrats! If you're not a subscriber and you want to follow the latest developments in Perl, it's highly recommended.
&gt; No, it's really not, and I think that's confusing a lot of people. Sounds like the one confused is actually you. [In the State of the onion](http://www.perl.com/pub/2000/10/23/soto2000.html), which was given by the *creator of the language* he was clearly talking about the next version of Perl. For example, look at all the references to Perl 4 in relation to Perl 5. If someone were to say "Perl 5 is actually a totally different language, Perl 4 will still live on forever", I suspect the Perl community would quickly correct them that this is not the case. The only reason this myth got started that Perl 6 is some completely different language "of the same family" as Perl 5 is just because Perl 6 took such an embarrassingly long time. For a long time Perl 5 development pretty much stopped, waiting for the soon-to-come next version of the language. Eventually people starting to think it was never coming so they started up Perl 5 development again. Sometime after that the myth you're repeating got started.
It doesn't matter if the talk is 100 years old. It's very clear that Perl 6 was created with the intention of being to Perl 5 what Perl 5 was to Perl 4: a replacement. &gt; If you're not okay with that It's not about if I'm "ok with that", I'm just not a fan of rewrites of history. Perl 6 was very clearly intended to replace Perl 5 (in time, Perl 4 wasn't replaced overnight either and is probably still around somewhere). That just became an inconvenient fact as the language kept not being finished.
&gt; Perl 6 was created with the intention ... rewrites of history ... was very clearly intended ... You do understand that it's okay for a project's goals to change over time, right? We're not locked in to what Larry envisioned 16 years ago. Perl 6 can be something entirely other than what Larry originally thought it would be (and it is on SO MANY fronts!) You really need to relax and accept that there's software out there and it can be used for all sorts of useful purposes, rather than trying to force your worldview on it. 
You'd think there would already be something that does this. Maybe it's buried in code somewhere, like how the CPAN client checks for installed dependencies?
If the goals changed, as you claim, why didn't the name change with it? Why call it Perl 6 (the previous replacement convention) if it was no longer intended to be that?
As a core developer of Perl 6, I can attest that current goals of Perl 6 are *NOT* to replace Perl 5. We're a sister language and regardless of the original plans a decade and a half ago, we currently encourage amicable co-existence with the Perl 5 community and we clarify any confusion about Perl 5's ongoing development and growth to anyone who mistakenly thinks Perl 6 is "the next version" of Perl. You can read mst++'s eloquent blog post on the topic: http://shadow.cat/blog/matt-s-trout/f_ck-perl-6/ That post is from 7 years ago and the effort to bring the two communities together has been ongoing.
Yes, there is. If there was a particular usecase that was missing one of the existing toolchain modules, we would have appreciated a bug report or even a conversation about it.
https://metacpan.org/pod/Module::Load::Conditional ?
Yes, as /r/nicomen pointed out, `check_install` in [Module::Load::Conditional](https://metacpan.org/pod/Module::Load::Conditional) does what I need, plus check for minimum version also. There are some aspects regarding require hook that it doesn't handle yet, and I'm submitting a ticket for it. EDIT: https://rt.cpan.org/Ticket/Display.html?id=116678
Yes, that was one of my concerns too. Other names that came to my head include Module::Requirable. But that is not that different from Module::Loadable, in addition to being more obscure. Strictly speaking, to truly make sure that a module can be loaded *successfully*, you need to actually load it. Statically checking the source syntax using PPI or even `perl -c` is not enough. Since my original requirement is just to check that the module is available (either on the filesystem or via the require hook). I'll state this more clearly in the POD. Also, since Module::Load::Conditional uses `check_install`, I'll follow the terminology and use module_installed. Thanks.
Yes, indeed. Thanks! I'll update the blog post and the module's POD, although I might keep Module::Loadable on CPAN for a while.
Interesting. I wonder how hard it would be to combine this with Carton? I've been playing around with Docker and Carton and installing cpan dependencies is probably the slowest part of the whole process.
Neat! I'll note that the default configuration for Dist::Milla (and thus cargo-culted into my bundle) adds "no_index" metadata for the directories "eg", "examples", "inc", "share", "t", and "xt". Sharedirs do get installed in a way, but not in a place where you can use any modules inside directly, so they shouldn't be indexed either. And of course "share" isn't the only name used for them, but it is the default for a distribution-based sharedir.
You might want to try something like [this cpan proxy](https://github.com/moltar/cpan-proxy) to speed up the downloading from CPAN part. I use a hacked version of this code to serve up CPAN modules and local darkpan modules and it makes VM/container builds go much faster.
Grammars in Perl6 looks similar. All of these are basically BNF rules.
Why Pegex and not Marpa? If performance isn't an issue, then accepting PEG's issues doesn't seem good.
According to https://youtu.be/CdpBV8BgPI4?t=14m19s the plan for making cpm working with carton is to get cpm merged into cpanm 2.0.
Turning off `verify_hostnames` is not so great.
I do understand this.. It was for testing purposes only as you see the comment that follows saying #not so nice.. This is a reminder to change it once I got it working. 
Ah, okay, that wasn't clear.. I guess because the lack of formatting ran everything into one line.
Is there any advantage to using Mojo vs LWP? I've always used LWP without issue. 
Got it installed, and still no luck.. Its still returning a 500 error: 500 Can't connect to maps.googleapis.com:443 (connect: Network is unreachable) 
what about npm?
We do exactly this at work for all dev feature branch builds App::cpm makes it possible because its so much faster for all the deps in a cpanfile.
Ordinary stuff you type will be pulled into single paragraphs, separated by blank lines. If you want to show code, indent four spaces. As far as your code is concerned, you can save space by defining multiple variables in one line, you just have to parenthesize them. You can also initialize some or all of them. my ( %hash, %key, $line ); In your case you don't need $line outside the loop, so it's common to define it in the while condition: while ( my $line = &lt;$fh2&gt; ) { chomp $line; ....
TMTOWTDI: my (%hash, $key); for "input.txt".IO.lines { when /'===|' ~ '|' $&lt;key&gt;=&lt;-[|]&gt;+/ { $key = ~$&lt;key&gt; } %hash{$key}.append: $_; } dd %hash Also, Grammars anyone? :)
Use a look-ahead assertion for the second 'A', so that the regex match looks for it, but doesn't consume it. my $count = () = /A(?=A)/g;
Looking at the Everything2 repository (which is what Perlmonks runs on), the passwords are hashed. However, it's done with `crypt()`, which nobody should be using on this side of the Pets.com crash. See: https://github.com/everything2/everything2/blob/b7e7363fc277ac1761a5343cdc89d807ceee97d6/ecore/Everything/Application.pm#L288 https://github.com/everything2/everything2/blob/b7e7363fc277ac1761a5343cdc89d807ceee97d6/ecore/Everything/API/v1/login.pm Also, this comment is dumb as hell: # Salt prefix reveals algorithm, and we store the salt separately anyway It shouldn't matter if you reveal what algorithm you're using. If it's a good algorithm, it will be secure even if the attacker knows what it is. Of course, they're not using a good algorithm. I don't know what version of the code Perlmonks is using, but this is embarrassing for all concerned.
&gt; I seem to recall the administrator of the site refusing to salt and hash the user database because, he felt, once the site was hacked an encrypted password table would not be any greater protection. If that's the case, it's an astonishingly bad decision. However, I'd like to see some evidence that someone is this careless with other people's data. That's a pretty serious accusation.
why did i get down voted :( 
I looked up the thread about the after attack response and they have it as an item to encrypt and hash, so I don't think the person is recalling rightly.
 use Data::Dumper; sub function { my ( $regex ) = @_; warn ( "Arg to 'function()' ($regex) is not a regex.\n"), return unless 'Regexp' eq ref $regex; print "got regex arg ", Data::Dumper::Dumper($regex), "\n"; } function 'a'; function 123; function {a =&gt; 1, b =&gt; 2}; function [1, 2, 3]; function qr{a.*[c]}; # outputs ... Arg to 'function()' (a) is not a regex. Arg to 'function()' (123) is not a regex. Arg to 'function()' (HASH(0x229a4)) is not a regex. Arg to 'function()' (ARRAY(0x229a4)) is not a regex. got regex arg $VAR1 = qr/(?-xism:a.*[c])/; 
I'm new to reddit so good to know! 
I used the forgot password thing a few months ago and got my password back in plaintext...
I'm obviously biased, but [CoreHackers::Sourcery](https://github.com/zoffixznet/perl6-CoreHackers-Sourcery) landed me right at the definition of .split in Perl 6. It's got a bit of NQP in it, but I always felt learning NQP was a bit like a module rather than a whole 'nother language, so I basically got to a piece of Perl 6 code describing a Perl 6 method. Compared to this thread's answers for Perl 5, this sort of thing really makes Perl 6 stand out and I hope will drive more Perl 6 users to contribute to core Perl 6.
incorrect. Passwords are still stored in plain text as of July 2016.
reddit is only occasionally rational.
Sadly it looks like they're still storing passwords in plain text. I just clicked on "Mail me my password" and it did. http://i.imgur.com/COTWEY3.png (oh yeah, note the 10 character limit. Yes, that was a temporary password and I've already changed it tosomething else)
Everything2? Wow. I remember that site from LOONG ago, when Slashdot was still a reasonably good news source (and wasn't it made by some of the same people as Slashdot, originally?).
Thanks a lot for your help
my reaction is "how did calling that class 'Cool' ever seem like a good idea". "Convenient OO Loop"?! and to think I once complained about the vague naming of perl5's "scalar"... Not that this is in any way relevant to the original question - or anything else - so I expect to be downvoted appropriately ;)
I agree totally.
_Sometimes_ when I do stuff that is clever (partly because it may be more code-efficient, or something I want to learn to use later) I will use the clever bit, and enter the long-version as a comment, so I can reference it later...
I think at this point you have all the evidence you need?
Split does a lot of [wonderful things](http://perltricks.com/article/121/2014/10/24/Perl-s-versatile-split-function/)!
Subroutine signatures are getting some new ops. It sounds like that moves them closer to losing their experimental status. Dave Mitchell mentions some optimizations but no benchmarks so it's not clear if they'll faster or not. Hope so!
Just want to clear up some terms here: Encryption is reversible by definition. The point of encryption is to take a message, encode it in some form so that the information conveyed within the message is no longer 'available', and be able to reliably decode/decrypt it to retrieve the original message. Hashing is a one way function that takes an arbitrary length message and produces(or maps to) a fixed-length hash/fingerprint. You cannot uses a hash(alone) to determine the message that it represents. So /u/OvidPerl's point(I assume) is that the fact that they are ABLE to provide you with a plain-text password shows that they are not storing credentials using best practices. If passwords were properly hashed and salted(and peppered and zested or whatever else there is these days) they would literally have to brute force your hashed password to send it to you in plain-text.
Damn it. Yeah, I was clumsy in how I phrased that. Thanks for correcting me :)
As a non-perl dev, this looks horrifyingly hacky to me
My favourite: #!/usr/bin/env perl use strict; use warnings; my %replace = ( 'this' =&gt; 'that', 'fish' =&gt; 'banana', 'oyster' =&gt; 'mushroom', 'one_with+metachar' =&gt; 'no_meta_char' ); my $search = join ( "|", map { quotemeta } sort {length $a &lt;=&gt; length $b } keys %replace ); $search = qr/\b($search)\b/; print $search; while ( &lt;&gt; ) { s/$search/$replace{$1}/g; print; } 
This is quite convenient: inline lookup table: my $fruit = "apple"; my $fruit_color = { banana =&gt; "yellow", orange =&gt; "orange", apple =&gt; "red", pear =&gt; "green", }-&gt;{ $fruit } or die("Unknown fruit ($fruit)\n"); or # Override just a few exceptional values my $local_thing = { Organisation =&gt; "Organization", Colour =&gt; "Color", }-&gt;{ $thing } // $thing; 
&gt; requires Perl 5.14+ You write that in code as use 5.014;
&gt; Perl does not have booleans as part of the language Holy hell.
If the apache logs have the referer, you can use that to associate which calls may be coming from what page (ie. the javascript calls should have the referer set as the page they're running on).
http://stackoverflow.com/questions/1212799/how-do-i-extract-lines-between-two-line-delimiters-in-perl This is similar to what you're doing but not quite the same. I'm not sure it's applicable to your case, but it's something to keep in mind. Since that isn't very helpful, here is a rewrite of your example: use strict; use warnings; use Data::Dumper; # three argument open and single quoted strings open(my $fh2,'&lt;', 'AFTER_FILE'); my %hash; while(&lt;$fh2&gt;) { # removed $line variable because it was inconsistently used. # $_ works just as well if it's going to be used for some things # changed scope of $key and gave it a default value in case the # text file has lines before the first === my $key = 'default'; chomp; if (/^===/) { $key = $_; $hash{$key} = (); } else { push @{$hash{$key}}, $_; } } # depending on how you want the output to look, you may be # better off with print Dumper(\%hash); print Dumper(%hash); here is an example: main:17(0)&gt; print Dumper %hash; $VAR1 = 'test'; $VAR2 = 1; main:18(0)&gt; print Dumper \%hash; $VAR1 = { 'test' =&gt; 1 };
You're right, I *am* an asshole. Thanks for the link. I've just had a quick scan of the perlref page and am suitably terrified. Time to learn about just more than just arrays then!
Sounds useful from your description, knowing nothing about any of that at this stage. When I inevitably come across those words again as I learn, I'm sure I'll remember they're significant. Thanks again.
Nothing unless someone is immature maybe.
I don't use that, but I probably should have. Anything cool for Atom? I'm trying Atom out for a bit and it seems nice. I'm totally onboard with Perl-FIG. First order of business: mandate that indentations MUST use exactly one tab followed by three spaces.
'Gobbling cock' is a pretty common expression. The use appears deliberate, since 'to avoid gobbling block' is not a very well worded way of phrasing it.
Ho hum. Person saying "I am not doing X" is of course doing X for all he's worth. Not that it matters. Perl 5 exists, Perl 6 exists. Why gas about it endlessly? 
Rather than Perl Best Practices which is outdated enough to almost be an ironic naming, I would check out [Modern Perl](http://modernperlbooks.com/) which is available freemium style. [PerlCritic](http://search.cpan.org/~thaljef/Perl-Critic-1.126/bin/perlcritic) as a tool also gets you a lot of the wisdom of Perl Best Practices but in a much more practical format. Sublime has a linter plugin for both perl critic and compile time warnings from `perl`.
I don't have any reading recommendations but here are a few tips from someone who learned perl on the job: Make sure you understand the difference between list and scalar context (and Boolean) otherwise you'll be confused as hell. Know what the automatic variables are. (E.g, $\_, @\_) and where they come from. Understand the different quote operators. You've probably heard this before, but there's more than one way to do just about everything. This can make it hard(er) to read perl written by other people, especially if multiple people have worked on your code base. Edit: escaped underscores
&gt; is a pretty common expression. So is gobbling turkey, what's your point? Its a perfectly reasonable word, swallow would also have been perfectly good. Would you then claim "swallowing cock" is a pretty common expression? Think it's fairly clear who needs to grow up around here...
I also recommend https://metacpan.org/pod/Perl::Critic::Freenode over the default perlcritic policies as the defaults are based on PBP and thus also outdated, and should be considered guidelines at best.
For question 3, I think one of the biggest differences (I could be acting on outdated PHP knowledge) is that scoping and strictness are important. Always have "use strict; use warnings;" at the top of your scripts and modules, and declare variables with "my" in the smallest scope they need. Also, hashes and arrays are separate data structures and don't mix. The perldata doc page elaborates on data structures. EDIT: Another thing is that lists and arrays are distinct concepts, and there are some things to watch out for there, here is a good post on the topic: http://altreus.blogspot.com/2011/08/lists-and-things-made-of-lists.html
It's humorous but not exactly a professional looking technical term. Not that slurping is much better, but at least that has precedent.
You need to escape the underscores, for a second I thought you were misnaming sigils :)
&gt; **Question 3)** Is there anything immediately obvious to you that I'll get blindsided by in the transition from PHP to Perl? Is there any specific advice you can give if you've taken that path yourself? An associative array in Php is a hash in perl. You know how in php you tell the database what you and and in what order? select FirstName, LastName, SomethingElse from Customer Where SomethingElse ='whatever' order by LastName, FirstName Well in perl, don't bother with the order by clauses. A hash sorts itself however it wants. If those were your rows you just loaded they're out of order. That one bit me a lot and I still get kind of sour about it sometimes. 
To answer question 3, two things you should read up on: - [contexts](http://www.perlmonks.org/?node_id=738558) - [autovivification](http://perlmaven.com/autovivification) These two areas often seem to be sore points for people that are just starting out with Perl.
If you get your result set as a reference to an array of hashes you will get your results in the order as requested in your database query, per DBI documentation: my $emps = $dbh-&gt;selectall_arrayref( "SELECT ename FROM emp ORDER BY ename", { Slice =&gt; {} } ); foreach my $emp ( @$emps ) { print "Employee: $emp-&gt;{ename}\n"; } A Perl hash is unsorted and for security reasons, in recent versions of Perl, the order changes between each run. There are solutions for a sorted associative array, however.
I second learning about context as a very important, if not outright the most important think you should learn when coming from a language like PHP. Without truly understanding context, you can *feel* like you understand the language, but you'll also always feel like many language choices make no sense. Perl can look like C and PHP to a degree, and you'll think it works the same way, but it won't in subtle ways. Knowing why, and taking advantage of that as a strength is key to actually learning the language, and even enjoying it.
some messing around with PPI. [PPIx::Refactor](https://metacpan.org/pod/PPIx::Refactor) can help set that up, but the analysis of the symbols is up to you.
Good news, thank you, my pre-order is in. I loved 6th edition, it's worn down now, I feel I still need to learn a lot from that book.
&gt; I can't figure it out why those print FH $garbage would write corrupt blocks, and not simply overwrite blocks on the disk with some random content? Those are two ways of saying the same thing. Overwriting blocks on the disk with random content (i.e. corrupting them) is the intended purpose of the program. 
I see, since the `print FH $garbage` is done directly through seek, it will not be handled by ZFS. So, that code bypasses ZFS's discernment of a block change, thus, by all means, corrupting it. Thank you, it is clear now.
It bypasses the filesystem because it opens and writes to the block device directly, not because of the seek. 
&gt; Changing it to a regular comma just screams "perhaps this isn't what you intended". And, also, doesn't change the context at all.
Excellent, thank you for the detail. Such nice tools from Perl.
&gt; Often times when writing a server you will need to be able to handle multiple client connections at a time. To do this you will want to create a threaded server. No I won't! Perl threads lead to wasted memory usage (a trivial server with 1k connections will set you back ~400MB RSS before doing anything useful) and unhappy developers! Use nonblocking event loops instead instead, we have loads of modules for it. I rely on [IO::Async](https://metacpan.org/pod/IO::Async) but there are other options. 
Perl threads are very inefficient. It's better to use multiple workers, each worker having its own event loop. Mojolicious gives you this for free. 
I have, it is a full window manager and I don't know enough perl or xlib to follow what he did. I was hoping to start small with just some scripts to move windows around and resizi them.
You need to know about PSGI. Beginning perl (the Curtis Poe, aka /u/ovid version) is a really good book. You'll want to get across Moo (for new code) and Moose (for older modern perl code). I would say that the PHP community has a greater tolerance for bad design in open source code.
You could do this in any language, though. It's really Unix that's nice here by making the block device accessible as a normal file. :)
The related discussion on [The Monastery](http://www.perlmonks.org/?node_id=1169901) itself.
I am learning Perl so I wanted to keep writing it perl for the moment. Wmutils can find and move windows and I have written Perl scripts to use wmutils. I was hoping to go a step further and use an X11:: model but it is still beyond my abilities.
It's very important to learn to organise your code. You need packages for encapsulation; you can define several packages within a single file. Example: #! /usr/bin/perl =pod TODO my plans =cut use strict; use warnings; package appStrs { sub showhelp { my $this=shift; return "Help:\n".$this-&gt;arg_msg1;} sub arg_msg1 { return "myarg=1"; } }; package myObj { sub new { my ($class,$objname) = @_; my $self = { objname =&gt; $objname || $class, objID =&gt; time }; my $object = bless $self, $class; $object-&gt;_init; return $object; } sub _init { my $this=shift; } #init stuff sub otherMethod { my ($this, $prop)=@_; } #another method }; sub main { my $oStrs=appStrs-&gt;new(); $oStrs-&gt;showhelp(); } ####### &amp;main; 
Use [LWP::UserAgent](https://metacpan.org/pod/LWP::UserAgent). my $ua = LWP::userAgent-&gt;new; my $resp = $ua-&gt;get('https://example.com/'); if ($resp-&gt;code == 200) { # everything worked } Note that you'll want to read [README.SSL](https://metacpan.org/source/ETHER/libwww-perl-6.15/README.SSL) and do what it says in order to enable support for "https" URLs.
How carefully do you want to check things? There are plugins for common monitoring systems (e.g. Nagios/Icinga) which handle this already, and a 200 response is pretty much a one-liner with curl. There are also cert/algorithm/revocation tests if you want to be more thorough, and [IO::Socket::SSL](https://metacpan.org/release/IO-Socket-SSL) provides access to various useful features here. Example code in https://gist.github.com/tm604/78e8cc69491925cdb4e63292c71def8a
Just a minor nitpick but search.cpan.org ("CPAN Search") and metacpan are both search engines for CPAN, and neither are CPAN. The former of course has misleading graphics to that effect, but it did come first. The actual CPAN has many mirrors, but you can [take a look here](http://www.cpan.org/modules/01modules.index.html). The [front page](http://www.cpan.org/) lists both search engines.
Nice. Notice that because you used 'return' rather than 'return undef' in the reader sub, you don't need the 'grep defined,' in the while condition. map provides list context and return gives an empty list '()' which map will throw away automatically. So this is sufficient: while (my @obs = map $_-&gt;(), @readers) { print sum(@obs), "\n"; } 
Looks interesting, I would like to replace Electron for something with better Perl integration, to bad itâ€™s GPLv3 â€“ as itâ€™s probably a no go for work. 
That's a really good idea thanks. I am actually using tinywm on my laptop.
Ah, thanks, I tried the all without the quotes and colon. Why would you not recommend it? Are any of the things dangerous? I'm not talking about long script, just ones that are slightly too long for a one-liner.
That's a good point. Is there an easy equivalent to use feature qw( :all); that only activates non-experimental features? use featuer qw( !:experimental); #probably totally wrong, but I'm too lazy to look up correct syntax for such a highly hypothetical question :) Though my hopes aren't too high; it seems I'm trying to get perl to do something that doesn't really fit it. I guess I'll just have to rely on use feature for quick hacks and check the number for real scripts, like a big boy.
I agree that what I asked about is definitely not for scripts that might make their way to other users. I'm currently trying to get a better handle on perl, and thus force myself to script some tasks on my PC. These usually require only a couple of lines, and make me learn new ways to interact with my system, but are highly specific to my install and programs I use. Add to that my rather vague memory about the specifics of programming, so that I like to set up short testing scripts before doing anything, and 'use feature qw( :all)' would save me some annoyance. When checking if system qw() works the way I imagine for my setup, I don't care that any experimental feature is activated. I just don't want to think about which feature I have to activate because it's not in perl 5.008.
In addition to experimental features, many features just aren't included in the standard feature bundle which -E enables. You can see [here](https://metacpan.org/pod/feature#FEATURE-BUNDLES) that only a few have been added over several versions of perl.
This looks very cool. A more detailed installation/compilation instruction (e.g. on Debian/Ubuntu) would be nice, including on installing/starting its showcase application Epigraphista.
Thanks. I don't know what contexts are yet, other than the clue in the name, but that sounds like some valuable wisdom.
&gt; A neat side effect is you could do if ($progress == 0xFF) as a quick check for 100% of the bits being active, Thank you for sharing that, I hadn't thought of that. Nice trick!
Hmm that's a good point, I wonder if the Pizza::Order object value was interpolated, it would thereafter start causing problems.
I'm no XS expert, and i've never embedded Perl before. However, when I came across a similar problem in some Go I was writing, the easiest solution was just to keep a small thread around to manage the callbacks, have it use normal mutex/condvar semantics and that ensures callbacks are always sourced from the same thread. Safety then is just a matter of care.
Well this is what `perl -E ...` does. $ perl -MO=Deparse -E 'say $^V' use feature 'current_sub', 'evalbytes', 'fc', 'say', 'state', 'switch', 'unicode_strings', 'unicode_eval'; say $^V; -e syntax OK $ perl -E 'say $^V' v5.18.2 On perl 5.12 the output of B::Deparse is slightly different: BEGIN { $^H{'feature_unicode'} = q(1); $^H{'feature_say'} = q(1); $^H{'feature_state'} = q(1); $^H{'feature_switch'} = q(1); } say $^V;
There is the `fileinput` for python which handles the whole temp file thing for you. Anyways, one approach would be `perl -ne 'print if /\S/'` and if you wanted to overwrite the original you can use `-i` e.g. perl -ni -e 'print if /\S/' file http://docs.python.org/2/library/fileinput.html
it'd remove lines that only contain whitespace, which matches the python script. An alternative if you just want to remove lines containing "\n" (but not " \n", for example): perl -ni -le'print if length' 
Capital S is a non-whitespace
No. It's entirely equivalent to the python code in the OP, modulo any difference in the definition of "whitespace". It skips lines that don't contain any non-whitespace characters, and prints the rest.
This is the right answer
As a one liner: perl -ne 'print unless /^\s+$/ ' test.txt Pipe to the filename of your choice
I think this will require the blank line to contain at least one whitespace character. I don't know Python to know whether this is equivalent to the code the OP posted. 
this says "print the current line only if it contains a non-whitespace character". It's a perl style for # while a line is read # if the line contains a non-whitespace character # print the line while (&lt;&gt;) { if (/\S/) {print;} } 
Subscribed! Looking forward to some good content.
 sed '/^\s*$/d' &lt; file