I see what you're saying. So Perl6/Perl7/etc would introduce breaking changes much like with Perl4/Perl5. Am I understanding that right? If so, do we have a clean slate to evolve the Perl language in the future?
You clearly know what you're talking about, and I appreciate the time you spent replying to a peasant like me. Thank your your insight! 
And I wouldn't be surprised if that sentiment goes for most of the rakudo developers as well - Patrick Michaud, rakudo creator, was avoiding calling himself the rakudo pumpking as early as 2010 (maybe 11? 12? no later than that) in order to leave room for "pumpkin perl" as a possibility for perl5 so we could both gets names as well as numbers and stop having pointless arguments. So far as I can see, this is a huge win for both languages and I hope to see perl5 pick an alias as well soon.
Yes, but right now, there are no plans for a Perl 7 as Perl 6 is supposed to evolve through mechanisms within the language: 'Slangs' and macros (though their current implementation is a bit lackluster). As far as further developing the Perl 5 branch goes, Larry has said he's fine with anyone going off in any direction they like as long as breaking changes are accompanied with some change in the name.
I do understand that as somebody who believes perl6 should replace perl5, this is inevitably going to seem tasteless to you. But please let those of us from both communities who've spent the best part of a decade working towards this and believe in *two* bright perl futures have our moment of celebration.
I want two bright perl futures, and I want us to 'compete' by making two awesome perl family languages rather than by throwing rocks at each other. Your questions all seemed entirely reasonable to me and I'm sure other soi-disant peasants will find the answers informative too, so thank *you* for asking questions that helped me figure out which bits needed explaining. (also overall I'm pretty happy with happy users of both perls having no idea about the less collegial bits of the history, I consider the fact that most people managed to avoid noticing to be a net win given our animal is a camel, not a llama ;)
Since you submit pull requests anyway, why not register and do it as you do it normal. However I still respect your point of view.
Burden? You seem to believe that Perl 6 came out of some far away continent to enslave the Perl 5 people? Burden? Really??? Drawing Martin Luther King Jr. into this is utterly tasteless, if not offensive.
There is nothing in anything ether said that implies she's drawing MLK into it, so far as I can tell - if he also said "free at last", well, ok, but what context leads you to believe that isn't just three words in a particular order? Given the spirited argument you gave for why your friend's use of n*gg*r was innocent and meant to not at all be racially charged, attempting to then attack a canadian developer for "drawing MLK into this" really doesn't strike me as consistent. I applied the principle of charity and unbanned your friend. Please try and be similarly charitable to ether.
Perl 6 is still called Perl 6. It has an additional alias called "Raku". So the name is still taken.
I supect you missed that the "FREE AT LAST" is a link: https://mamg.makeameme.org/free-at-last-5bdf36.jpg
Nothing she said, no. Something she linked to, yes.
Didn't see that, sorry. But, still, ask some african americans whether they're more bothered by MLK memes or people saying "all my black friends are fine with me calling them n-gg-r so it's just a word". Principle of charity still, I think, is best applied.
You should be well aware by now what marketing and messaging issues Perl 5 has been dealing with, that "Perl 6" looks like a successor and replacement rather than a sister language. Many people have been trying to get the name situation resolved for years. Given that it's a problem that the Perl 5 community has been unable to solve by itself, I think the metaphor is apt. Since it seems a solution has been found, I think rejoicing is also a reasonable reaction to this news.
if it's a bug, report it: https://rt.cpan.org/Public/Dist/Display.html?Name=Reddit-Client
I mean, I just got this app id and secret code about a half hour ago. Would there be a delay for them to work maybe? I looked at the module source and that error is thrown when it doesn't get a token. I don't know what the token is but it doesn't get it. https://metacpan.org/source/EARTHTONE/Reddit-Client-1.2811/lib/Reddit/Client.pm I also noticed the module creator has been banned from reddit apparently: https://www.reddit.com/user/earth-tone craziness. Maybe I need to switch to python or something. 
I just the REST API. https://github.com/mikeymiked/preddit/blob/master/preddit.pl
Thanks I'll probably try this
Pretty cool. I remember seeing someone ask for this a few days ago
If "Raku" is what we're calling Perl 6 now, then I like it.
Yes, you can consistently use "Raku" to refer to the language, if that's the name you believe is best.
I think "Pumpkin Perl" is the clear winner for Perl 5, easy to say and remember, suitable for making a logo (with possible seasonal variations.) "Rapt Perl" is a little hard to say, IMO.
I like that butterfly pic.
Right now Raku is just an alias. If it becomes the (only) name, there is still a lot of material on the Internet that will be talking about it as Perl6. So no, Perl5 should never try to use 6 in its name.
Perhaps instead of skipping to 30, skip right to 2019. I'm arguing for v2019 to be an alias for v5.30 and v2020 to be an alias for v5.32 etc. use v5.30; use v2019; # make this work like the above line This would make it evident that Perl is still active in 2019. Basically the version would become a marketing tool, and evidence that it isn't standing still. (In the future it could even be used to pressure decision makers to switch to installing a version that isn't 5 or more years old) I would prefer it if this only happens when and if usage of Raku as a name surpasses Perl6 as a name. For the record I liked the Pumpkin Perl and Raptor Perl ideas. I've even thought that Perl5 and Perl6 should get aliases at the same time, and have a joint release announcement.
As far as I know (it was before my time) one reason that Perl5 added breaking changes is because it was a complete re-implementation. One of the major selling points of Perl5 is its backwards compatibility. I think that if there are enough breaking changes to warrant such a version change, that it would be more likely to kill the language than to save it. If there isn't a major change to the language, but a change of the number to 6,7,8 or 9, it will only cause more confusion in an already confusing situation. I think as far as name/version is concerned (for Perl5), there needs to be a big change or no change. A small change (6,7,8,9) would likely be a bad idea.
Aside from date-based versions being a bad idea, this is infeasible because version segments greater than 999 are incompatible with Perl versions.
I like the way that `use v2019;` indicates that perl is active. Raptor Perl doesn't quite roll of the tongue, and now moot if "Raku" has won out. 
As a huge weeb I would've loved Rakugo as a name. Oh well.
100% agreed on the "when and if" preference. Alias for us good too. I would much have preferred the 'jointly' thing but, well, reality doesn't always work out the way we were hoping. Meanwhile, I think that we're likely best to let the current ructions die down first before we start exploring our own aliasing.
 Posted by [u/\_perly\_bot](https://www.reddit.com/user/_perly_bot) [13 days ago](https://www.reddit.com/r/perl/comments/9qutd5/use_terminal_colors_to_distinguish_information/) 
Note that the perl6 community already discussed this at https://www.reddit.com/r/perl6/comments/9uo5cm/on_raku_lizmats_ramblings/ Those of us on the perl5 side of things need to remember we're well aware how feeling trapped by names feels, and would do best to err on the side of compassion over schadenfreude while the 6ers talk this out.
&gt; Perl 6 is the successor of Perl 5. Just like Perl 5 was the successor of Perl 4. That is the way it was intended originally, and that is the way that it should go in the future. Anything else would do a disservice to all people involved in the Perl community. "Perl6" is a whole different language, which breaks compatibility with the Unix toolchain (bash, awk, perl5) at innumerable levels. We who grew up with Perl see no reason to trash our knowledge, abilities, and the language we have grown to love. Liz, can you not see why we are justifiably upset? 
It was also the heir-apparent to sed and awk. Thank God those things are still here to stay. At least I'm not having to fix all my sed invocations and regression test thousands of packages and unpublished scripts against potential breakages to sed "improvements" every year.
&gt; And as long as P6 people aren't going to hold any kind of weaponry to my head and obstruct what I'm doing, we'll all just get along fine. Well that's just the thing... the fact that "perl 6" exists as a thing, wholly separate from "the other language known as perl", has been causing confusion to outsiders for over a decade, besides the increasingly contemptible fact that we can never have the major version number increment. It's the steadfast refusal to even *understand* this situation, whether or not one agrees it's a problem or unsurmountable, that makes the current reactions over in the other community so baffling and hypocritical.
Liz started in the perl community long before perl6 even happened, and saw it as a natural progression. *I* see perl6 as existing in 'modern language cross environment' and perl5 as existing in 'unix' and love both for what they do. But she was away for 2009 when the perl5 and perl6 community came together and decided that the sister languages definition was much better for us all than anything else - so having been around before and having been a perl5 person who was hugely looking forwards to perl6, she saw the sister language narrative as a convenient fiction until perl6 was ready. That turned out to be ... a minority view ... and the sister language narrative has been endorsed by Patrick Michaud (creator of Rakudo), Jonathan Worthington (lead dev of rakudo currently and creator of MoarVM), and Larry Wall. But the introduction of the 'raku' alias based on Larry's statement still, understandably, dynamited one of the pillars of her world view out from under her. So I don't expect her to be able to see it *yet* and I'd ask you to consider why she might be justifiably upset from her point of view and, at least for the moment, err on the side of compassion over schadenfreude.
I bet there's something in [BioPerl](https://metacpan.org/release/BioPerl) that will make this job far easier.
Now is a great time to listen to [highly relevant wisdom elegantly, succinctly and freely shared by a Perl luminary](https://www.youtube.com/watch?v=Y24QnadqqJ4&amp;index=104&amp;t=190s&amp;list=PLRuESFRW2Fa77XObvk7-BYVFwobZHdXdK)! That was supposed to sound like marketese, or sarcastic. There was no way I could do Tim Bunce justice. Please just click the link and listen to what he has to say. Preferably *before* reading folks' thoughts about names and Perl's possibilities. But if it's too late for that, watch it anyway. It's classic timeless wisdom.
What have you tried so far?
[https://metacpan.org/search?q=fasta](https://metacpan.org/search?q=fasta)
My 2c, [lightly held](https://www.youtube.com/watch?v=Y24QnadqqJ4&amp;index=104&amp;t=5m39s&amp;list=PLRuESFRW2Fa77XObvk7-BYVFwobZHdXdK). &gt; Personally don't think the "Stage name" analogy makes any sense here. All the examples cited seem to involve a name which was relatively unknown Imo the "stage name" metaphor is excellent. Specific analogies (specific examples) leak, some terribly. &gt; All the examples cited seem to involve a name which was relatively unknown, and unappealing on face value, for which an alternative was crafted, and the alternative was what made them unique and known. So, bad examples. Check out [Family connections](https://en.wikipedia.org/wiki/Stage_name#Family_connection) on the wikipedia "Stage name" page. Nicholas' family name Perl was famous but he wanted to avoid comparisons with his uncle. So he chose the stage name Nicholas Raku. Fast forward a few decades and he's now part of the Perl legend, adding to it. When he works in the public eye he uses one name or the other as he sees fit. When he's at home he's Nicholas Perl. (s/Perl/Coppola/) Thomas Mark Harmon wanted to avoid confusion with his dad Thomas Dudley Harmon. So he switched to Mark Harmon when working professionally. These are completely successful attempts at heading off confusion during first impression. The issue isn't to hide the past. Neither Nicholas Cage nor Mark Harmon -- or perhaps that should be Nicholas Coppola or Thomas Harmon -- ever tried to hide who they were. But the sage name avoided the issue in most cases in at the least the first 30 seconds of exposure to an individual. ---- I've spent 4 years exploring this in one online location to see what might work. I have found that use of "P5" and "P6", avoiding use of "Perl", was sufficient to dramatically alter the course of discussions. But I also used "Perl 5" and "Perl 6" on occasion, and "Perl" to either generically refer to both, or the combined community, or sometimes just "Perl 5", when that felt helpful. Basically, just being cognizant of the enormous power of branding and using it thoughtfully. It took 4 years, and this is a cherry picked quote, but consider this comment from /r/programminglanguages: &gt; I once briefly worked with Perl 5 and quickly abandoned that due to my distaste for the language. I was aware of some of the dark history surrounding the implementation efforts on Perl 6. So, I too once held a low opinion of Perl. &gt; It is only and directly because of your excellent evangelism efforts in this sub and elsewhere that has caused me to understand the marvel that has been created in Perl 6. I am quite sure I am not the only one that has noticed this and been grateful to you. I want to be sure you notice that your words have made a positive difference too, despite however many skeptics and trolls you run into along the way. &gt; There is another unfortunate truth here - the Perl "brand" took damage over a long period of time, it's going to take a while to recover. Please keep up the great work you are doing! It is making a difference. My point isn't to brag. It took a truly absurd amount of diligent, persistent, detailed, careful attention to get to that point in that location. My point is that I would never have gotten there if I didn't have the "P6" and "P5" trick available to me. The wild thing is that I showed exactly the same code examples. The only difference was that I often used just "P6" instead of "Perl 6" and likewise with "P5". I'm inclined to believe I would have made much more rapid progress in one dimension -- getting folk to initially focus on technical merit of the language in the first 30 seconds or so of them reading something I posted -- if I had been able to use "P6" all the time. Of course, I couldn't, because the doc is at a website called perl6.org with "Perl 6" all over it and I'm not trying or even wanting to hide the Perl connection, indeed, quite the opposite. I'm also inclined to believe I would have made more rapid progress in another dimension -- initial acceptance by cool kids -- if I had ignored my stubborn insistence on profoundly admiring and loving Perl culture. This latter frequently led me to talk about it warmly regardless of it generally going down like a lead balloon. But a key driver for me bothering to talk about Perl 6 is to talk about Perl and Perl 5. I think they are vastly stronger *together*. Perl 6 is a key part of Perl as far as I'm concerned. It is as far as Larry is concerned. It is as far as its legal name, as it were, is concerned. &gt; I personally consider "A Perfect Circle" and "Puscifer" as "Tool", even though they're by definition not, but by association, are Well it's all very maynard of course. But the whole Puscifer packaging was stunningly distinct. The music was incredibly good (just as PC and Tool are) but again, had its own very distinctive feel. I would have still loved it if it were a Tool album but I recall introducing Puscifer it a friend who didn't like Tool (they're weird) and, well, I'm not saying they necessarily fell in love with it but they seemed much more open to listening to it without preconceptions than if I had said it was by Tool. &gt; Its about as hard to popularize a new name as it is to change the image of an existing, established one. Popularizing the name really isn't the point. If, when meeting someone, you say your name is Hitler, it has an immediate very significant impact. There's nothing you can do to alter that except to use an alias at first. You can sometimes avoid using your name but that can be weird and if you say that your name is "something I'd prefer not to get into" that also has an immediate very significant impact and again there's nothing you can do to alter that except to not do that. Ultimately you have to use a name. It's as simple as that. It's the most basic aspect of branding, even more fundamental than associations with that name. &gt; I won't stand in the way of whatever ya'll in P6 are doing, I just don't think stamping a new name on the box will necessarily be the silver bullet you're hoping for. A silver bullet to eliminate the first 30 second impression problem? I'm pretty much 100% sure it'll be helpful in many scenarios even though, chosen poorly, it could have introduced more problems than it solved. I chose "P6" carefully. I had my reasons. It had a graceful transition to "Perl 6". It was in Camelia's wings. It was mostly sufficiently unique. But it had some downsides. I'm impressed by Larry's choice of "Raku". It has some thorny downsides (most notably it's close association with the compiler name rakudo) but it has great upsides too (most notably it's close association with the compiler name rakudo). I registered a pile of domain name variations on Kudo, based on another play on words drawn from Rakudo ('kudo's lang etc.). I have a long term plan for these that relates to P6 and Perl and rakudo but it'll wait for the 2020s. I was willing to cede it to the greater good but frankly "Raku" is a much better fit. &gt; (even if you go out of your way to remove associations in the official documentation, because you have no control over what people say and think) Right. Larry has always made clear this would be an optional alias, just as my use of P6 was my choice. &gt; And as long as P6 people aren't going to hold any kind of weaponry to my head and obstruct what I'm doing, we'll all just get along fine. Well I think none of us would like that but, as you say, we have no control over what people say and think...
You might want to checkout http://dev.perl.org/perl5/ There has been a lot of good work done over the last few years, but IMO some questionable decisions too. Not sure an ambitious development roadmap would even be a good thing. Even if development does become quiet, Perl will continue to be useful for a long time.
* http://p3rl.org/todo * http://p3rl.org/deprecation afaict there is no roadmap; there aren't any means of enforcing it, anyway. ---- &lt;https://lwn.net/Articles/485569/&gt;: &gt; The Perl 5 Porters are the volunteers who develop and maintain the Perl 5 language. They consist of anyone who cares enough about Perl 5 to participate in discussions on the perl5-porters email list. There's no formal membership, and influence is based on a combination of hacking skill and the ability to not be a jerk. The more you contribute and the more you communicate, the more control you have over the future of Perl 5. This should sound familiar if you know how other FOSS projects work. &lt;https://www.nntp.perl.org/group/perl.perl5.porters/2014/09/msg219255.html&gt;: &gt; perl5 does not have a road map. While I'm [rjbs] holding the pumpkin, I think it is *extremely* unlikely that it will.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/ipv6] [Would like some help fixing a DNS file writing issue](https://www.reddit.com/r/ipv6/comments/9v1rtt/would_like_some_help_fixing_a_dns_file_writing/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
If you're asking "what's the zone for reverse DNS in v6?" then: # dig -x 2001:db8::1 | grep -A1 QUESTION ;; QUESTION SECTION: ;1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa. IN PTR But you should be able to name the file whatever you like, so long as BIND is configured to point to the file.
Yeah, the problem seems to be getting the file to correctly name to something; when it's otherwise configured to populate the IPv4 zones properly. I'm more of a C# / JS guy; I've put in some effort into getting the v6 stuff working on this, but this last bit I'm stuck on.
The feature released - [https://metacpan.org/release/MELEZHIK/Sparrow-0.3.5](https://metacpan.org/release/MELEZHIK/Sparrow-0.3.5) 
I guess it's [this line of code](https://github.com/zentyal/zentyal/blob/3615dc39189d879f71d8ead96b3d9d4a67b7887d/main/dns/src/EBox/DNS.pm#L1451) that's picking the filename, and [this section](https://github.com/zentyal/zentyal/blob/3615dc39189d879f71d8ead96b3d9d4a67b7887d/main/dns/src/EBox/DNS.pm#L862) that's generating `$rdata-&gt;{'group'}`, but it's not immediately clear why it's empty -- perhaps `$hostIpRow-&gt;valueByName('ip');` doesn't work for v6, but I can't work out where that's coming from. There are some other problems beyond just the filename though. Note that the group is being generated by splitting on "." and reversing the result, which won't work for v6, and there's also `updateDynDirectZone()` which is hardcoded for A records and [this function](https://github.com/zentyal/zentyal/blob/3615dc39189d879f71d8ead96b3d9d4a67b7887d/main/samba/src/EBox/Samba/Provision.pm#L823) in Provision.pm to think about. I didn't do an exhaustive search and there are probably other places that assume things about the format of an IP address, although they don't necessarily all need to be fixed to get things working. I think that's about as far as I can get without running the thing.
Any press is good press these days - let the debate continue, civilly, until a consensus is reached. The debate is fine - the tone hasn't been.
Those are some good leads. Thank you for that analysis: I might be able to to fix it.
&gt; she saw the sister language narrative as a convenient fiction FWIW, I've always considered the sister language narrative **fiction**, not *convenient* fiction. The convenience of the sister language narrative is only perceived by the people creating and endorsing it. It was never considered convenient by me. 
Perl 5 hasn't died. I wish people would stop repeating this sort of negative, defeatist meme.
I'm starting to think (from this series of articles) that Perl 6 might be an option for me.
My take: no one in their right mind would consider bumping the version of perl5 up to 6, if only because web searches would keep hitting the wrong language. Literally anything at all other than that would make sense, e.g. numbering schemes like pi.0.1 or e.0.1 or &lt;beast&gt;.0.1. Completely changing the name would be better... ronin? katana? shuriken? basara? 
I think that depends heavily on the industry and work you do. It’s extremely rare in cloud native / Kubernetes style environments but common in more traditional or legacy environments like ISPs have it all over the place
suddenly, Roku gets angry.
Already taken unfortunately. 
What, Quadrature Frequency Shift Keying? Not close enough to matter. And it looks like qfsk.com and qfsk.org are open-- though they won't be tomorrow, now that I've tried them. 
[removed]
What's your source on that? We use Perl in multiple cloud environments (including AWS, GCE and a plain hosted docker swarm), and I'd be surprised if we were the only company doing so. Services like AWS Lambda might not support Perl, but there are plenty of other ways to get Perl into a cloud... see https://github.com/metacpan/metacpan-docker for example. Containers make the actual choice of language mostly irrelevant.
https://www.genomicsengland.co.uk/genomics-england-congenica-clinical-decision-support-services/ Sapientia mentioned here is a Perl 5 web app with a tonne of Perl in the back end too. Its a very big and new codebase about 4-5 years old. Outside of Genomics England its deployed using all mod cons in the cloud. Plenty of interesting Perl gets written, no one press releases the implementing language or engineering challenge unless they are a softeng focussed company.
Excellent explanation!
Hey there! I'm getting a 404 on the link; may want to double check it. =)
I must say, that Diwali butterfly is absolutely gorgeous! That would be a fantastic logo for Perl 6 (or, you know, whatever :) ) You know that thing about first impressions? Pick this one.
\&gt; What meaningful metrics could be used to measure Perls growth? Is there a Perl client library for each new cool technology project, alongside the common languages? (you know which ones they are) **a)** When there is a Perl community provided client for every project, we have won half the battle. **b)** When there is a Perl client library provided by the new technology project (because they know it's needed for them to be taken seriously), we have won the war. Start with a. &amp;#x200B;
Not "List::AllUtil"?
Except forward. ;)
&gt; only getting things done it’s what matters With such a simplistic view in a world full of subtleties you will end up in tears one day. ---- Back on topic: once a programmer notices that CGI.pm is not the optimal choice for most projects, http://p3rl.org/CGI::Alternatives is useful. The documentation shows how to migrate over to other libraries.
lol
lol
Within a corporate firewall that would never happen though. 
What would never happen? I also fail to see how that's relevant...
Why would it become slow? I totally agree with you if you’re out there creating apps with a potential massive user base but with few (&lt;1000) users the underlying tech is not relevant. 
I see, you're talking about internal use applications. Sure, the risk is lower, but it's still there, and entirely depends on the application. We have internal use applications that are only used by &lt;100 users and they still have had CGI.pm scripts that have to be shoved into FastCGI because of performance issues. Something which a modern framework can do seamlessly with no code changes by the way. But yes if you're absolutely sure starting a new Perl interpreter for each request will never be a problem for your application then being stuck with the CGI protocol is not a problem itself.
That's not the only concern though; CGI.pm leads you to develop in a certain way which is not conducive to modularizing code and maintenance/adding new features (such as requiring you to print your headers manually, and interfacing directly with %ENV and STDOUT). You can of course work around it to create a modular sustainable project, but then you're basically reinventing modern frameworks at that point.
It’s actually true, I already have a lot of functionality of modern frameworks built in my code, so much so that around 10 years ago I started automating the whole process of the application framework so I can now have a prototype running in minutes. I guess I’m the translucent cave dweller here. Lol
Maybe [give this a look](https://metacpan.org/pod/Mojolicious::Guides) and see how much it does for you. As mentioned Mojo apps can be [transparently served as CGI](https://metacpan.org/pod/Mojolicious::Guides::Cookbook#Apache/CGI) too.
An article promoting CGI.pm in 2018? For shame. As someone else said, use Mojolicious. Use *anything else* over CGI.pm. Please.
Why?
Which will happen if you are using godaddy's minimal hosting.
CGI may be archaic and terrible, but playing devil's advocate for a moment here, it also makes it easy to keep your server stateless, because you *cannot* maintain state in-process between page requests.
1) does the devil really need an advocate? I mean as pure as the reputation of the legal profession is at least *some* of them must have ended up on the wrong side of the fence. 2) That argument is one even the most incompetent infernal minion would be hard pressed to use because the premise suggests that non-CGI.pm applications will lose all user authentication data on every restart (just to pick an example). I haven’t written an application in 20 years that relied upon it process local memory to maintain state. It was a silly idea in the 90s too.
I don't use cgi.pm but this is good to know.
Nonsense. One of my tasks last week was figuring out why a CGI.pm app is slow. It was an internal page only for the eyes of our support people. And yes, it is slow, unmaintainable and we can't effectively add new features to it. It's a nightmare and a mess.
CGI is still a useful deployment environment for simple, low-traffic dynamic web pages. But I still wouldn't recommend writing CGI programs using CGI.pm. It's far better to use a PSGI-based approach. You can even use [raw PSGI](https://perlhacks.com/2016/01/easy-psgi/). It's really no harder than using CGI.pm and you'll get a number of advantages: * There's a massive ecosystem of middleware and plugins for PSGI - meaning that there are a lot of bits of your program that other people have already written for you. * The simple subroutine-based specification for PSGI means that it's far easier to test and debug PSGI-based programs (and, of course, there are a vast array of existing tools). * When your program becomes really popular and you want to move it from a CGI environment to mod_perl or FCGI or even a standalone service running behind a web proxy, then you can do that without changing a single line of your code.
That's pretty much one of the three questions I've taken to asking myself whenever I want to remind myself how unpopular Perl has become :-) 1. When did you last come across a company using Perl who you weren't aware of? 2. When did you last read a non-language-specific programming book that included examples written in Perl? 3. When did you last discover an interesting new API that included a client library written in Perl?
Your code serves as a good example of why Perl is often described as a "write-only" language :-)
Ah yes. Flashbacks to the problems of running two Dancer apps under mod_perl on the same Apache. It wasn't pretty and Dancer2 fixes it. But I'd far rather track down those problems on a PSGI stack than in a mod_perl handler.
Punningly, it means "the way of the camel". 駱駝 (rakuda; らくだ) means camel, and 道 (dō; どう) means road/way/set of principles (it's the same root as Taoism). So rakuda-dō gets contracted to rakudo, the way of the camel.
* https://en.wikipedia.org/wiki/Rakudo_Perl_6#Name * https://docs.perl6.org/language/glossary#Rakudo * http://wwwjdic.se/cgi-bin/wwwjdic.cgi?1MDJ%A4%E9%A4%AF%A4%C9 
Really I should've called it \`Lists::AllsUtil\` for the ultimate troll name.
Alls Util that Ends Utils.
I'm disappointed that [this thread was locked](https://github.com/tpf/perldotcom/pull/156) -- constructive discussion is far better done on github than here.
&gt; Ricardo and SawyerX are good ppl but not perfect. How are the previous and current pumpkings relevant? CGI was on its way out before Ricardo's time.
I didn't even realise there was a github issue for this, thanks for pointing that out. Since I can't comment there, as it's locked, I'll comment here. I agree with what Leon says in the issue - the [perl.com](https://perl.com) article is bad, and the arbitrary "this is what people are googling for so it's what we should talk about" excuse is misguided. &amp;#x200B; The article is bad because it front loads with examples of using CGI.pm and you have to get way beyond the fold before you find out that it's not actually a recommended module anymore. The article doesn't even mention the massive security vulnerability that still exists in the module\[1\] because I can't patch properly as it will break backwards compatibility. &amp;#x200B; The misguided reasons for driving more traffic to [perl.com](https://perl.com) need more thought. People are probably googling Perl + CGI because they're having to deal with a lot of legacy cruft, or they're part of the existing feedback loop, or they're reading all the ancient stuff on the web that seems to always say Perl is used for CGI programming. Articles like the one here are just continuing that cycle. &amp;#x200B; If you're going to write about Perl and CGI make it clear above the fold the CGI.pm is not a recommended way to do it. I've already talked and written about this at length. There are more interesting things to blog about if you're going to touch on CGI.pm. I've done this in the past\[2\]\[3\], and occasionally I'll try to educate the idiots about CGI::Alternatives\[4\]. &amp;#x200B; There's at least two (maybe more) threads on the front page or r/perl asking how we improve / promote Perl. The answer should include: stop writing articles like this. &amp;#x200B; \[1\] [https://metacpan.org/pod/distribution/CGI/lib/CGI.pod#Fetching-the-value-or-values-of-a-single-named-parameter](https://metacpan.org/pod/distribution/CGI/lib/CGI.pod#Fetching-the-value-or-values-of-a-single-named-parameter) \[2\] [https://leejo.github.io/using\_mojolicious\_for\_fun\_and\_nonprofit/#/](https://leejo.github.io/using_mojolicious_for_fun_and_nonprofit/#/) \# a talk from 4 years ago about how to migrate away from [CGI.pm](https://CGI.pm) \[3\] [https://leejo.github.io/2016/02/22/all\_software\_is\_legacy/](https://leejo.github.io/2016/02/22/all_software_is_legacy/) \[4\] [https://www.perlmonks.org/?node\_id=1217891](https://www.perlmonks.org/?node_id=1217891) in response to [https://www.perlmonks.org/?node\_id=1216248](https://www.perlmonks.org/?node_id=1216248) \# Honestly though, who stumbles upon perlmonks and thinks "oh, this looks cool and modern, i'm definitely going to try it out..."?
neat, but why is WWW::Mechanize used?
WWW::Mechanize is needed in the case that we want to log in using `-&gt;credentials()`
Very cool! That's a good excuse to come down looking for barbecue.
It doesn't inspire a lot of faith in future discussions :-(
https://i.kym-cdn.com/photos/images/original/000/110/545/tumblr_lihynlRomV1qzr81to1_400.jpg
curl --max-time 10 Unknown option: max-time curl -m 10 Unknown option: m Oh well, it was worth a shot.
This is pretty slick! But this: curl http://example.com &gt; foo.txt Is way over complicated with the generator... I can do that with LWP::Simple (which I believe is part of the standard lib?): perl -MLWP::Simple -e 'getprint $ARGV[0]' http://example.com &gt; foo.txt [This is the result I receive](http://paste.scsys.co.uk/582236)
Can you maybe write a little about your interests in the perl world? Do you do text processing? Client side web scraping? Server side web apps? What about real world interests? Hobbies? 
I don’t anything about Perl yet. Thought I would get a head start. I enjoy sports, reading and working with my hands. Hope that helps 
&gt; reading I wrote a series of [three articles about creating a web application](https://perlhacks.com/articles/modern-perl-programming/) to track the books you read. That might be a good start.
I agree they were wrong to lock that thread. But you can still make your thoughts known on the [issue that initially suggested writing the articles](https://github.com/tpf/perldotcom/issues/138) (the issue has been closed, but you can still add comments).
Scratch your itch first: Do things that you like or need doing first. Work related calculators, (e.g. electronics calculators if that is what you do) Toos that make your job easier will make somebody else's job easier too. Command line tools: Create tools that simplify common tasks. Tasks like playing background music can be done from the command line, but you could try to make this easy , then add to it e.g. with playlists and shuffle etc. Desktop projects: I would suggest a child friendly desktop applications. Sort of like [childsplay](http://childsplay.sourceforge.net/) . These would 1) be modular and you can add projects as time goes on 2) encourage others to contribute to your projects 3) be a good demo of the capabilities to encourage others to develop in Perl. Trouble? GUI programming is not trivial in Perl even though everything is possible. GUIDeFATE might be of interest though getting it installed hasn't been easy for every one to install, and it is rather basic. &amp;#x200B;
Or, at least, included aliases to cover all possibilities!
How about writing a scripts the extracts the most commonly used words from some free [Project Gutenburg](http://www.gutenberg.org/browse/scores/top) text files?
The module/program is not geared for "optimal/minimal Perl programs", but towards generating simple Perl code that can be modified later. Especially, the module/program does not care for shell redirections but considers `&gt;` and `foo.txt` additional URLs. If you use the `-o` switch of `curl` to supply an output filename, the program generates the expected code: curl http://example.com -o foo.txt Generates ``` #!perl use strict; use warnings; use WWW::Mechanize; use HTTP::Request; my $ua = WWW::Mechanize-&gt;new(); my $r = HTTP::Request-&gt;new( 'GET' =&gt; 'http://example.com/', [ 'Accept' =&gt; '*/*', 'Host' =&gt; 'example.com:80', 'User-Agent' =&gt; 'curl/7.55.1', ], ); my $res = $ua-&gt;request( $r, ':content_file' =&gt; 'foo.txt' ); __END__ Created from curl command line curl http://example.com -o foo.txt ``` 
The conversion is still a work in progress and `--max-time` will likely be added for versino 0.03.
It occurs to me I'd be really interested in seeing a tutorial about how to, say, create a Debian package from a CPAN project. 
LWP::Simple is not in the standard lib and also I wouldn't recommend its use (it has no ability of error checking whatsoever). HTTP::Tiny is in core since perl 5.14. perl -MHTTP::Tiny -E'my $res = HTTP::Tiny-&gt;new-&gt;get(shift); die $res-&gt;{status} == 599 ? $res-&gt;{content} : "$res-&gt;{status} $res-&gt;{reason}" unless $res-&gt;{success}; print $res-&gt;{content}' https://example.com [ojo](https://metacpan.org/pod/ojo) is also not core, but much nicer for quick tasks... perl -Mojo -E'print g(shift)-&gt;text' https://example.com
Huh, I could have sworn it was. This is pretty slick though, I'd never heard of ojo before. My use case is more "that 1 in 1M instance where a machine doesn't have wget or curl but does have Perl and I need to download a thing" (this is something I stole from [Chef](https://github.com/chef/chef/blob/master/lib/chef/knife/bootstrap/templates/chef-full.erb#L89) ages ago) This might do what I want: perl -MHTTP::Tiny -E 'print HTTP::Tiny-&gt;new-&gt;get(shift)-&gt;{content}' http://example.com Since I don't really care about being "safe"... 
John SJ Anderson (@genehack) says a Static Site Generator should be the project you use to learn a new language, and I agree with his reasoning: https://www.slideshare.net/genehackdotorg/a-static-site-generator-should-be-your-next-language-learning-project
And here, if you want to save it to a file HTTP::Tiny can do that directly: perl -MHTTP::Tiny -E'HTTP::Tiny-&gt;new-&gt;mirror(shift, shift)' http://example.com example.html
Huh. Ok, he actually mashes a few good points. My first thought before reading through the deck was "great, exactly what the world needs _another_ static generator". But after reading the slides, I think I agree with his reasoning too.
I edited and published the article on Perl.com. I've read through the comments here and wanted to respond and give you more context about my decision to publish it. The article is part of our [popular search terms](https://github.com/tpf/perldotcom/projects) project which aims to write articles that people are Googling for. This was borne out the realization that our most popular Perl articles were not our newest ones, last time I checked our most popular article was "Perl command line options" written in 2004 by Dave Cross. When we publish articles about things people are not Googling for, we get a brief spike in traffic, which represents the Perl community checking in. Once that spike is over, the articles see only a few clicks per week. I've written hundreds of articles like that. Like it or not, CGI is a term strongly associated with Perl on Google searches: we want to capture that traffic to grow the site's popularity. A more popular Perl.com is a good thing for all of us: it helps us reach more people with community news, promote Perl events and introduce them to modern Perl ideas. So then if we're going to write about CGI, what tack should we take? What do we think people searching for Perl and CGI want to read? I took a guess and proposed the following structure: * How to create a simple web app with CGI * Recommend CGI resources * Why CGI is not recommended * CGI alternatives (Plack, Dancer, Mojolicious) I felt that would both entice readers looking to build / fix something in CGI, and nudge them in a better direction. Dave Jacoby manages CGI applications for $work, and he kindly volunteered to write the article. He submitted a rough draft with over 2000 words of content. That took a lot of his time! Dave had assembled some great technical information in his article that I didn't want to lose, but we also wanted to trim the article down to a reasonable length, so with my feedback he trimmed it down and re-shuffled some sections. I think we ended up at about 1250 words, with 280 words describing the shortcomings of CGI and proposing alternatives. That's around 20% of the article. That's not exactly what I had in mind, but it's close enough. He also included a lot of things I hadn't considered or wasn't aware of (like avoiding the builtin HTML generation functions). This is how editing goes, and I think we ended up with a decent article, thanks to Dave's hard work. I agree there are better options than CGI scripting and I hope to keep writing and editing articles of the kind the Perl community likes to read. But I also hope by publishing articles that folks are Googling for, we can capture new readers and grow Perl.com and the Perl community. The article may not be to your taste. I've seen some good suggestions for "post CGI" articles: e.g. how to migrate your CGI application to something better or why not to use CGI anymore. We need more authors and I'd be happy to publish articles like that too. If you'd like to write for Perl.com, check out our [contributing guide](https://github.com/tpf/perldotcom/blob/master/CONTRIBUTING.md).
I always think a good quick project to start off with is to write a quick program that will take input for how much money you have in the bank, how much you add every month, and then calculate the amount that you'll make based on your interest rate. Mainly because a lot of people underestimate compound interest, but it's a really simple program so it's good for a starting place.
Make a script that will remove C/C++-style and Perl comments from any file you point it at, and save it to a new file. Do not nuke the original file. The script must accept an arbitrary amount of file locations as command line parameters, or be typed in by a user; for bonus marks, remove all comments from the current working directory of the script. First two lines of the script must be: #!/usr/bin/perl -w use strict; comments look like: //a single-line comment /*a multi-block comment */ if(1=1) { dostuff(); } //another comment, preceding code must not be harmed. #perl comment my $input = &lt;STDIN&gt;; #another perl comment. Not super complicated but not dead-simple, you'll have to at least learn a little bit of Perl to do this.
How about the "Go Fish" card game?
&gt; First two lines of the script must be: &gt; &gt; #!/usr/bin/perl -w &gt; use strict; Since Perl 5.6 was released (in March 2000), that's probably better written as: #!/usr/bin/perl use strict; use warnings; `use warnings` is more powerful and more flexible than `-w` on the shebang line. Also, of course, the path `/usr/bin/perl` is specific to individual servers. `/bin/env perl` has become a common alternative.
It's not surprising - it's the first link when you google for any of "perl command", "perl command line", and "perl command line options"
I know, old habits. -w because I always want all the warnings anyway, and I write the shebang that way because I've never needed to write it any other :&gt; At least for beginner-bud, IMO all that matters here is he has warnings and strict on, however they've turned them on; as long as he's pointing at a Perl interpreter of some sort that should be good enough to learn on. 
I would recommend unlearning the -w habit, at least, because it does not just turn warnings on; it enables warnings in modules you use that were not written with warnings in mind. While that doesn't sound like a bad thing, it just leads to getting a bunch of warnings you can't do anything about that may or may not indicate an actual problem.
&gt; How to create a simple web app with CGI &gt; Recommend CGI resources I think that neither of these are needed. Perhaps if this was an article about maintaining legacy CGI.pm cruft, or migrating it, but this explains how to write fresh CGI.pm programs. I think it's also important to note that this is in reference to CGI.pm, as CGI is still perfectly fine (and transparent) for certain use cases when using modern tools.
Yea, solid point; I honestly haven't run up against that situation yet (that I'm aware of anyways), but that's good to know of. I've been playing with Reddit::Client while I learn my way around Moose... and I'm sure that every warning and error I've seen was me being a dummy lol
These days, I would think the most useful article about Perl + CGI is something like "we have this ancient perl CGI script that is doing some important business function - how do we keep it running in a modern deployment environment, how do I debug it, and how do I rewrite it into something more maintainable?"
Thanks for following up [dnmfarrell](https://www.reddit.com/user/dnmfarrell) &amp;#x200B; &gt;When we publish articles about things people are not Googling for, we get a brief spike in traffic, which represents the Perl community checking in. Once that spike is over, the articles see only a few clicks per week. I've written hundreds of articles like that. Like it or not, CGI is a term strongly associated with Perl on Google searches: we want to capture that traffic to grow the site's popularity. &amp;#x200B; I'm genuinely curious about this, and wonder about the value of articles and blog posts that are just thin wrappers around code examples. This is partly why I think the article in question isn't a good one, although maybe that's because I'm usually not attracted to blog posts and articles that are just showing me code. A blog post / article is something I'd like to read not parse. &amp;#x200B; I guess my reasons for not liking code examples as a blog post is somewhat meta - as developers I like to think we all rail against copy-pasted code in our actual day to day work, and we aim to refactor, but we seem to have few qualms about copy-pasting code examples into blog posts rather than linking to official (canonical i guess) sources. The irony is that the blog posts can live for much longer, and get seen by a much larger audience, so have the potential to spread more bad advice once the code in question falls out of favour; whereas if we link to the one true source we should at least always be up to date. &amp;#x200B; To give an example - the recent major version of Mojolicious has significantly changed the way you do non-blocking operations, moving to a Promises style structure. What's the problem? Well none really, except now you Google for any information about how to do non-blocking stuff in Mojolicious and you get blog posts and code examples and stack overflow answers and perlmonks replies and github forks and bpo blogs and on and on and on that are all completely out of date, some of these even from the core maintainers of the project. Yes, sure, RTFM, but to many developers those things i mention in the previous sentence have effectively become TFM(s). &amp;#x200B; I have to say that one of the most useful things I find you posting is the "What's new on CPAN" monthly summaries, as they're short and sweet and they link directly to the sources without providing any code snippets that would go quickly out of date. I've discovered a few useful modules from those posts. &amp;#x200B; Anyway, I'm not sure how to drive more traffic to [perl.com](https://perl.com) but i don't think posting code examples that are twenty years old helps - even if it seems that's what people are googling for. If people are googling for Perl + CGI then have an article that dives into the history in more depth. 1,000 words is not much depth - most people will skim that in about one minute, if they read it a bit more closely then about three minutes. And to be frank the code examples in the post are not pretty to look at. &amp;#x200B; I don't know what to suggest for articles, but thinking about what posts I've seen on hackernews in the last week that have hit the front page and received several hundred upvotes: An article on the return of SpamAssassin, a blog post about improving the security in DuckDuckGo, several articles about Amazon and AWS. These are all products and/or companies that use Perl extensively - maybe one of their employees is willing to write something about how they're using Perl in their stack? I think that would get more traction amongst the fickle niche we're all operating in.
The new version of Mojo::Redis has a [pretty cool caching module!](https://metacpan.org/pod/Mojo::Redis::Cache)
Define "effective". Where are the benchmarks? It is highly likely that, with a simpe function like that, that the cache performs much worse than the original service.
The title was probably not the best. It’s just what I came up with at the time. I probably should’ve just dropped the word “Effective” altogether. The function in the blog isn’t meant to be realistic. I’d hoped I’d made that obvious. I deliberately didn’t discuss how to decide whether a particular problem will benefit from caching, how to measure and analyze cache hits and misses, or even if the thing you’re caching is even the thing you _should_ be caching in the context of the entire system because I felt like the blog would be excessively long. There are so many factors at play. Maybe the blog would’ve been more useful with that information though.
The technical field of caching is very broad, so I agree that it's a good idea to limit the scope of the post. But I recently got bitten by memoizing a repeatedly called function, and it turns out the memoization (storing the result for various inputs into a hash) was actually slower than the function call itself. So yeah, adding some warning about the possible negative effects of caching would have been nice. 
Holy shit. Nice! 
&gt; Be concise. Be flexible. Be modern. Don't use CGI.pm. Let's break that down: &gt; Be concise If this achieves the goal of maintainability then it is a worthy aim. &gt; Be flexible This works with fewer hard-and-fast rules, such as "don't this" and "don't that". &gt; Be modern That really needs a justification. Adhering to a latest fad instead of tried-and-tested historical norms leaves code open to early rot if the fad passes, and reduces the portability of any such script. &gt; Don't use `CGI.pm` The `CGI.pm` module has been around for decades, and while it may not be the cleanest module it is one of the most battle-tested in Internet history. Certainly a script that depends on `CGI.pm` is more likely to run anywhere. And almost anybody familiar with Perl will also be familiar with this module. A great advantage of `CGI.pm` is that it avoids dependency-hell - I can't speak for Mojolicious - but there is a lot of value in small, quick modules that don't need to pull in tens or hundreds of other modules, all treated as objects, demanding vastly increased system resources. Also, and this is important, making a rule "Don't use CGI.pm" violates the "Be flexible" principle.
Context is important. The post explains why using CGI.pm violates the "be flexible" principle, as you call it. FWIW, Mojolicious has no non-core dependencies on recent versions of Perl and can be fatpacked.
There are of course other modern options, such as those in the linked mstpan or CGI::Alternatives, which may be more to your taste if you think the Mojolicious solution is too DWIM. [Web::Simple](https://metacpan.org/pod/Web::Simple) is a "simple as in iptables" solution, for example.
No need to guess! There are real examples out there: - for CGI, https://github.com/bugzilla/bugzilla has already been mentioned - Mojolicious has https://github.com/mojolicious/mojo/wiki/Example-applications
And of course, [Mozilla's fork of Bugzilla](https://github.com/mozilla-bteam/bmo) has already been [migrated to Mojolicious](https://twitter.com/ThePerlShop/status/1050732579673001984).
excellent response: http://blogs.perl.org/users/aristotle/2018/11/modern-perl-cgi.html
I attempted to respond on the post but my comment was held for moderation, which usually means it will never appear; thus I will reproduce it here. I appreciate the example of a lower-level alternative, since my post only showed a Mojolicious solution for brevity and because that is where my experience is, and this is certainly a good alternative as well. However, "the Mojolicious example derives most of its concision from the lack of any error handling" is incorrect, since error handling (similar to that I added to the CGI.pm example, but much more useful) is built in to Mojolicious, as well as most other higher level alternatives. It is a common problem with CGI.pm-based scripts that unhandled exceptions result in no useful response to the user at best, and broken/missing response headers at worst. (I have since updated my post to make it clearer Mojolicious is but one option.)
&gt; I have since updated my post to make it clearer Mojolicious is but one option I think this statement obscures the point of the original article enough to be called out. The writeup you are responding to **explicitly** argues Mojolicious is not an option within the pre-agreed context. Specifically: &gt; In the Venn diagram of the CGI-for-deployment and Mojolicious-for-framework audiences, there is no overlap. So I consider Mojolicious an oxymoronic alternative to CGI.pm.
I disagree with that assessment as a blanket statement; but it's immaterial, as I don't see any purpose in arguing the point, and the purpose of my post is not to micro-optimize the best solution for hypothetical use cases, but to show the benefits of alternatives to CGI.pm in a manner easily consumed.
Why bother pointing to it?
Holy crap that article and the responses to it are terrible.
See http://html-parsing.com
Isee what you did there
Give me an easy way to offer web apps written in Perl to be run on a cheap shared hosting account like what Bluehost (or any cPanel-based host) offers, and I won't. Like, do you think I wanna? 
But why would you want to do that? If you have a useful system, then pay the money (and it's really not very much money) for a system where you can install what you want. It's not as though CGI.pm is ubiquitous these days anyway. A lot of those cheap hosting will be running RHEL/Centos 6 or 7 and those systems don't include CGI.pm in their default installation. If you have access to CGI.pm on those services, it's because a sysadmin has added them to the installation. And if they're going to install CGI.pm, then maybe they'll install Plack as well - if you ask them nicely.
Mojolicious and Plack can both be [fatpacked](https://metacpan.org/pod/App::FatPacker). Alternatively, if you have the same perl version/architecture available you can use `cpanm -L local` or [Carton](https://metacpan.org/pod/Carton) to install your dependencies to a local folder and copy that to the host.
I use CGI.pm in production. I've never used PSGI in my life. How would I leap from one to the other? Is there a way?
I have some initial thoughts in (Easy PSGI)[https://perlhacks.com/2016/01/easy-psgi/]. But I suspect I'm going to have to write some more detailed guides over the next couple of months.
Talking about the guy from that link. 
&gt; Can't call method "Query" on an undefined value We need to see more code to be able to tell what the specific problem is, but the short version is that you've got an object of some kind and you're trying to call the `Query` method on it and for some reason you can't. Typically this looks like this: my $dbh = ... do something to establish a connection. $dbh-&gt;Query( 'SELECT * FROM....' ); The problem is that `$dbh` failed for some reason, but that error condition hasn't been caught. You need to do something like my $dbh = ... do something to establish a connection. if ( $dbh ) { $dbh-&gt;Query( 'SELECT * FROM....' ); } else { die "Unable to create a DB connection"; }
Better is to pass `RaiseError =&gt; 1` when creating the handle, which causes both connection errors and later query errors to raise an exception, so you only have to remember to check for errors when your standard exception handling isn't sufficient.
But I don't want to write a full-fledged web app. I just want to host a couple of forms and process their fields on submit. CGI is perfect for that, esp. on cheap web hosts. What's the alternative besides using frameworks?
This is almost certainly the "fix" for the OP (although it won't fix the actual issue, just give them more information on what is going on).
Sure, that works, too. The key is that *someone* needs to be checking for errors, whether it's OP's code or DBI doing it.
Please stop sharing these articles. If there's something stupid on the Internet, it's not helpful to say "Hey, look, there's a stupid thing on the Internet" because then it tells the creator of the stupid thing that you want to see more of their stupid thing. And sitting in a thread on Reddit discussing how stupid the stupid thing is and why it's stupid doesn't help anything. For those who say "We have to dispel the stupid!" I suggest that it wouldn't have been an issue if someone didn't hold up the stupid for all to see in the first place.
Yes. A CGI program is probably the right approach in that situation. I've never denied that. What I am saying is that even in that situation, I recommend writing it as a PSGI program and deploying it as a CGI program. And you don't need to use a framework. That was pretty much the point of my article. Just use raw PSGI.
DBI is synchronous, races aren't really possible unless you're doing something exotic... and DBI doesn't provide a method called `Query`, so whatever is going wrong is probably *not* at the layer of DBI.
Ah alright
Thanks. I'm not antagonizing your point. I genuinely want to bring my old work up to speed.
[https://metacpan.org/pod/DBI#RaiseError](https://metacpan.org/pod/DBI#RaiseError) The RaiseError attribute can be used to force errors to raise exceptions rather than simply return error codes in the normal way. It is "off" by default. When set "on", any method which results in an error will cause the DBI to effectively do a die("$class $method failed: $DBI::errstr"), where $class is the driver class and $method is the name of the method that failed.
guys, we have a cult culture according to that link.
$The &gt; $good
I believe I did turn on the RaiseError attribute about a year ago, and that’s when this problem began to surface! That sounds like my problem.
&gt; But why would you want to do that? Because in 2004, it was still a reasonable choice. If I had known this business would still be going on in 2018, I may have reconsidered! 
It's not a problem of shipping with the dependencies, but you're not going to be able to run an alt. app server on a shared host. You're going to lose a lot of reasonably casual users when you go, "well, just drop into the shell and - " It's sort of the, "Well this php app was easy to install, why can't you be as easy to install?" 
It does not sound like your problem at all. Your error is not from DBI, it's from your code.
look into mojolicious::light
I'm not sure what relevance decisions you made in 2004 have today. Surely, you can move hosting providers if you want to? But if you have a system that works and that you're happy with, then I'm not going to tell you that you have to rewrite it in PSGI. I'm just suggesting that you might want to look at that option at some point in the future.
Oh, no: I offer the app for people to self-install/host (not SaaS). That's sort of the corner I'm in. I've actually moved to CGI::Application a long time ago, so it can be run under CGI as well as: FastCGI, Plack/PSGI. It's just not done all that often under something other than CGI. It's just harder to set that up as a casual user. I'd like to port to something like Mojolicious, but that's just a lot of work for an app that's been in development for almost 20 years. Moving from CGI::App was a bit difficult in of itself. Again, I didn't think I'd still have a customer base! I was 18, 20 years ago! Kind of a, "started in my dormroom" type of proj. 
I should have said "may" have been my problem. You're right, of course. I turned off RaiseError last night, and this morning, the problem happened again. I still haven't identified the real problem. I feel like I'm in over my head. Out of 300-500 attempts per week, this happens 0 to about 5 times. I've never been able to figure out why.
If you're using CGI::Application then your distribution already needs to include at least one external dependency. It would be possible to bundle Plack into your distribution in the same way. Distributing web applications for use by (presumably, not particularly tech-literate) end users is always going to be a bit of blocker. In most cases, you're going to end up deploying them in a CGI environment, just because it's the path of least resistance. As you say, a CGI::Application program is already PSGI compatible - so you can already get all of the benefits of PSGI without making any more changes.
Basically, if you would like to run under Plack/PSGI, you'll need shell access anyways (how else would you start the process, configure the web server/reverse project, etc), so no need to bundle that external dependency. Even with the bundled dependencies used for running under CGI by non-developers, I also keep a Bundle on CPAN of all those dependencies, if one wants to not use the bundled deps. 
I have run PSGI programs on basic servers without shell access. Once Plack is installed (or available through your installation) you don't necessarily have to change anything else on the server. Of course, it'll be running as a CGI program.
http://p3rl.org/CGI::Alternatives#PSGI/Plack
If you have execution problems after upgrading to 2018.3, re-create the interpreter. Seems migration fails sometimes. Sorry...
 #!/usr/bin/perl -T use strict; use warnings; use DBI; use constant DBNAME =&gt; 'database'; use constant DBUSER =&gt; 'user'; use constant DBPASS =&gt; 'password'; my $ORDERID = 123456; our $db = New(); $db-&gt;Init(); my %row; $db-&gt;Query({qstr =&gt; 'SELECT `billing_lname` FROM `orders` WHERE `id` = ?', hash =&gt; \%row, rows =&gt; 1, data =&gt; [$ORDERID],}); if ($row{billing_lname}) { print "$ORDERID = $row{billing_lname}\n"; } print "Normal program termination\n"; exit; sub New { my $pkg = shift; my $rec = { }; $rec-&gt;{type} = 'mysql'; $rec-&gt;{name} = DBNAME; $rec-&gt;{user} = DBUSER; $rec-&gt;{pass} = DBPASS; bless $rec; return $rec; } sub Init { my $obj = shift; my $connect_string = "DBI:" . $obj-&gt;{type} . ":" . $obj-&gt;{name}; $obj-&gt;{hand} = DBI-&gt;connect($connect_string, $obj-&gt;{user}, $obj-&gt;{pass}, { mysql_enable_utf8 =&gt; 1, PrintError =&gt; 0, RaiseError =&gt; 0, }) or die "Can't connect to the database: $DBI::errstr"; } sub Query { my $obj = shift; my ($args) = @_; my $h = $obj-&gt;{hand}-&gt;prepare($args-&gt;{qstr}) or die "Can't prepare SQL statement: $DBI::errstr"; if ($args-&gt;{data}) { for (0 .. scalar(@{$args-&gt;{data}}) - 1) { $h-&gt;bind_param($_ + 1, $args-&gt;{data}[$_]); } } my $count = $h-&gt;execute or die "Can't execute SQL statement: $DBI::errstr"; if (my $err = $h-&gt;errstr()) { # log this } if ($args-&gt;{qstr} =~ m/^ *SELECT/i) { LoadRows($count, $args-&gt;{hash}, $args-&gt;{rows}, $h); } #$h-&gt;finish(); # 18-NOV-2018 return $count || 0; } sub LoadRows { my $count = shift || return 0; my $row = shift || return 0; my $single = shift || 0; my $h = shift; for my $index (1 .. $count) { my $hashref = $h-&gt;fetchrow_hashref or die "Can't fetchrow_hashref: $DBI::errstr\n"; for my $key (keys %$hashref) { if ($hashref-&gt;{$key}) { $hashref-&gt;{$key} =~ s/\r//g; if ($single) { $$row{$key} = ($hashref-&gt;{$key}); } else { $$row{$index}{$key} = ($hashref-&gt;{$key}); } } } } } Output: ./example.pl 123456 = Chicken_Dump_Ling Normal program termination Thanks for taking a look. Please let me know anything that's dangerous, not best practice, etc. I've been using this basic code for a long time. \`RaiseError\` used to be on, but I turned it off recently while working this problem. Thanks! 
... by deploying them as a CGI script. Because Plack and Mojo can do that.
I guess I was looking for a tutorial or how-to or something, [but TFM helps](https://metacpan.org/pod/Plack::Handler::CGI): #!/usr/bin/perl use Plack::Loader; my $app = Plack::Util::load_psgi("/path/to/app.psgi"); Plack::Loader-&gt;auto-&gt;run($app); That's sort of interesting (but "why?!") if you already have a PSGI app, and want to run it under CGI using Plack (I think I have all that right....). I'm sort of in the reverse situation, where there's an already existing and mature CGI app, that I would like to run under PSGI using uh, Plack. Right now, I have CGI::Application app, and just use a different harness script if you want to run under CGI, or PSGI. The CGI hardness uses CGI::PSGI and Plack::Builder. The CGI hardness just uses CGI (and there's another one for FCGI, even!) I guess it's a TMTOWTDI situation here. 
Didnt try it, but is that an option? Its not in the docs.
Its the first time Im using Carton. Theres no .snapshot file, I assume because it did not succeeded with all builds (this one was the only one that failed). But thanks for suggestion, I'll try removing local folder tonight.
Wild guess.
Well, your code is certainly strange. But I don't think that's what's causing your problem. This is the code that creates your object. our $db = New(); But I can see nothing in the `New()` method (it's written like a method, but you call it like a function - it's very strange) that would cause it to fail. Anyway, you should check that you're getting a valid object back at that point. our $db = New() or die "Cannot create database object"; That will stop you getting your errors - but only by killing the program in the (rare) circumstances where the object can't be created. Given how simple `New()` is I can't see any way to get any more useful information about the failure. Now, can we talk a little about the design of this code? You seem to be aiming at an object-oriented approach, but you have forgotten to create a class. Your `New()` method is very strange. sub New { my $pkg = shift; my $rec = { }; $rec-&gt;{type} = 'mysql'; $rec-&gt;{name} = DBNAME; $rec-&gt;{user} = DBUSER; $rec-&gt;{pass} = DBPASS; bless $rec; return $rec; } As you can see, it expects a class (package) name as its single parameter. But you call it like this: our $db = New(); Passing it no parameters at all. But that's ok(ish!) as you ignore the `$pkg` variable completely. You then set up an object based on a hash reference in the standard fashion. But then you bless your object passing only one parameter to `bless()`. All of the literature recommends passing two parameters to `bless()`. The second should be the name of the class that you want to bless the object into. That should really be the `$pkg` variable, but (as that has no value) it's probably good that you don't try to use it. The net outcome of this is that your object ends up blessed into the `main` package - which is pretty non-standard (I don't think I've ever seen it before). But, actually, all of these problems kind of cancel each other out and you end up with a system that (just about) works. None of these design idiosyncrasies is causing the problems that you're describing. But I recommend you take another look at a basic Perl OO primer and rewrite this code.
The perlfunc manpage on exists() (read with \`perldoc -f exists\`) admits that it can be a bug and it \*may\* be fixed in a future release (emphasis mine). I guess to avoid autovivification, you currently have to do it like in most other languages, which is check layer by layer, e.g.: print "exists" if $foo{bar} &amp;&amp; exists $foo{bar}{mar}; Since you imply that $foo{bar} needs to be a hashref, you can just test with $foo{bar} because all hashrefs evaluate to true.
Checking a hash "layer by layer" is exactly what you ought to be doing. $ perl -MData::Dumper::Concise=Dumper -lE'my %foo; say "exists" if exists $foo{bar}{baz}; say Dumper \%foo' { bar =&gt; {} } vs. $ perl -MData::Dumper::Concise=Dumper -lE'my %foo; say "exists" if exists $foo{bar} &amp;&amp; exists $foo{bar}{baz}; say Dumper \%foo' {} 
You should have a healthy fear of `eval(STRING)`. You should not avoid it entirely. I've seen some devs write a complicated series of coding gymnastics trying to avoid `eval(STRING)`, when simply letting it happen would have been straightforward. It's for loading code at runtime that you couldn't at compile time. The old mod_perl2 `ModPerl::Registry` uses `eval(STRING)` to load "scripts" at run time. So does any templating system that lets you embed Perl inside, such as `Mojo::Template`. Then there's dynamic code generation. `Graphics::GVG::OpenGLRenderer` takes a GVG document (a simple vector graphics format) and generates a Perl class with a `draw()` method. Call that, and you get the vector graphics rendered using OpenGL. This is done by creating Perl code for the class and running through `eval(STRING)`. This means translating the vectors happens only once at compile time.
&gt; The perlfunc manpage on exists() (read with `perldoc -f exists`) admits that it can be a bug and it may be fixed in a future release (emphasis mine). It does *not* say that the general case of autovivification of intervening hash elements is a bug. It only states that this case may be: undef $ref; if (exists $ref-&gt;{"Some key"}) { } print $ref; # prints HASH(0x80d3d5c) This surprising autovivification in what does not at first--or even second--glance appear to be an lvalue context may be fixed in a future release.
No, it is not a bug. It is a well-documented feature of how hashes work in Perl. See `perldoc perlref`. Calling `exists` does not save you from the autovivification. It *is* a common gotcha, and many people have stumbled over it. I was once asked in a job interview about autovivification, and I explained it, and my interviewer said I was incorrect, so I had to pull out my laptop and demonstrate that in fact it was *his* understanding that was wrong.
Is a bug still a bug after 20 years?
Did you get the job? ;)
That's a valid and appropriate use for eval STRING. Unfortunately the vast majority of uses, especially by newcomers, are not that.
This; `no autovivification;` in scope would make the OP's code operate as desired.
I really haven't seen these supposed cases, though. We do a really good job of warning people away. So good, in fact, that we have a problem of people avoiding it when it's the correct solution. In the programming community at large, we even got most JavaScripters to stop parsing JSON with eval.
FWIW, this is bug fixed / feature missing in Perl 6.
I haven't seen what you've seen, it seems. But I see plenty of `eval "require Foo"` and worse `eval "require $unchecked_input"` where require or Module::Runtime would do; and plenty of string evals to do terrible ideas like the OP describes using the perl parser to parse (usually) numbers out of input, where precisely crafted regexes (or Regexp::Common) would do. Not to mention all of the string evals that can really just be block evals, because they require no compilation step of their own.
just wanted to update: the problem was that I didn't install ALL needed dependencies. once I did, Carton installed the missing module. but I did try removing the `local/` dir, and it worked as you said it would -- answer to another thing I was wondering yesterday, of how to start anew. Thank you!
I'd place bets that your db connection is going away, which is why modern db interfaces have automatic reconnection logic built in. You can achieve that in your code with DBIx::Connector (https://metacpan.org/pod/DBIx::Connector).
When I tried to install the WSL plugin pycharm says the plugin requires intelliJ ultimate. Is it available for pycharm and is it only supported in professional versions of the IDEs?
Google "mysql morning after bug". The DBIx::Connector or DBIx::Handler approach is the best way to guard against this problem, and it solves a few other things too (fork safety, transaction scoping, default RaiseError).
This is much better! But please re-enable RaiseError so you don't have to check every call for errors manually.
I enabled more logging and have isolated where the problem occurs, I think. Logic goes something like this: * "Submit Order" is clicked * Perl script start * Gateway called, order record created, confirmation email sent, etc. * Perl sends Order Confirmation redirect to browser * Perl script exit * Browser initiates a new request * Perl script start * Error occurs, user gets "internal server error" and naturally freaks out Somehow the Perl run for the order confirmation fails to load some global values from the database and the user session is somehow not detected. This leads to a string of errors. So that's where I'm focusing my research. Conclusion: I agree with you. I don't think DBI is going to turn out to be the problem here. I've checked for commonalities in users affected (browser, OS, device, etc.) and nothing stands out. I still suspect some kind of unanticipated browser behavior, perhaps something to do with privacy and/or tracking. This problem only happens about one percent of the time. The problem first appeared about a year ago. Which, coincidentally, is when I made some revisions to the code, so it still could be me.
Thanks! This is probably the best news I've had in some time. I'm a little weary from working on this problem. I'll get this revision into production soonest, and won't forget to re-enable RaiseError.
What's prename?
Seems like quite a lot got done. Great job!
prename (original name: rename) is a perl script written by Larry Wall to rename files using Perl code. It's been around at least since the Perl 4 days and lived in `eg/rename` in the perl source code, but has since split in the Perl 5 source code. 
Alternative: `s/([^.]+)/\U$1/`
&gt; I haven't seen what you've seen, it seems. But I see plenty of &gt; eval "require Foo" &gt; and worse &gt; eval "require $unchecked_input" &gt; where bare require or Module::Runtime would do That's because `eval "require Foo"` is recommended by the documentation: If EXPR is a bareword, "require" assumes a .pm extension and replaces "::" with "/" in the filename for you, to make it easy to load standard modules. This form of loading of modules does not risk altering your namespace. In other words, if you try this: require Foo::Bar; # a splendid bareword The require function will actually look for the Foo/Bar.pm file in the directories specified in the @INC array. But if you try this: my $class = 'Foo::Bar'; require $class; # $class is not a bareword #or require "Foo::Bar"; # not a bareword because of the "" The require function will look for the Foo::Bar file in the @INC array and will complain about not finding Foo::Bar there. In this case you can do: eval "require $class"; I think `require $mod` should just bite the bullet and be able to load `Foo::Bar` when `$mod` is `"Foo::Bar"`. But hey, (sarcasm) backward compatibility uber alles (/sarcasm). 
I agree that would be a nice feature.
If you want it to work for uppercase non-ascii letters you might have to get creative - modern Unixlikes tend to store filenames in UTF-8, but everything in Perl tends to work with filenames as bytes; it gets more complicated because on Windows they aren't bytes, but let's stick with Linux for now... `prename 'utf8::decode($_); s/^([^.]+)/\U$1/; utf8::encode($_)' `résumé.txt
FWIW, Quora carries a lot of these "heavily loaded", controversial questions that seem to have the sole purpose of provoking reactive answers, i.e. generating pageviews. It has made the site less interesting to me.
yes, it's available for professionsal versions only.
[My answer](https://www.quora.com/Outside-the-academic-and-research-world-is-Perl-still-used-In-which-areas/answer/Dave-Cross)
You can skip the `decode` and `encode` steps by setting the environment variable `PERL_UNICODE` appropriately: PERL_UNICODE=SAL prename 's/^(\[\^.\]+)/\\U$1/' résumé.txt This makes Perl aware of your encoding (see [`perlrun`](https://perldoc.pl/perlrun#-C-%5Bnumber/list%5D)).
&gt; prename 's/(.+)(?=\.)/uc $1/e' blabla.txt Thank you, it works but god it's ugly to read, i have no idea what it does even though I did some regexp recently
Same answer :) Thank you, it works but god it's ugly to read, i have no idea what it does even though I did some regexp recently 
I do not know whether this affects filenames in created files (the A will result in the arguments getting decoded at least).
*`^` - anchor match to beginning of string, so you don't uppercase a section not at the beginning of the string. *`()` - capture this part into `$1` for the replacement *`[^.]` - match any characters other than `.`. *`+` - match one or more greedily, i.e. as many as can be found at this spot The replacement is just a string; `\U` when interpolated into a string will uppercase all following characters.
Thanks! It was well worth it. Sometimes getting everyone in the same room makes a big difference. :)
 Why would anyone migrate from p5 to p6?
You are welcome to post this in r/FreeEBOOKS :) 
A few things I converted ended up about half the original size, so less typing is what cinches the deal for me. In particular, I like how little typing is involved in defining new classes and the small things, like not needing parentheses around `for`/`if` conditionals or being able to write `$x² ≥ 42` instead of `$x**2 &gt;= 42` I also like the easy parallelism/concurrency and list operations without having to wade through dozens of 3rd-party projects just to figure out which one of them is Module-de-Jour that's stable and maintained. 
&gt; But for UTF-8 filenames, you should be fine letting Perl use its internal UTF-8 encoding… The issue is that Perl's internal encoding is only sometimes UTF-8, and you can't rely on whether it will be unless the string is only ASCII (in which case it doesn't matter) or the string contains characters a downgraded string (native encoding) can't store. PERL_UNICODE/-C will treat all bytes as UTF-8 for what it affects, but unfortunately filename handling has no such option, and it's difficult to say whether it should (as discussed in that bug report).
Consider [lib::relative](https://metacpan.org/pod/lib::relative) instead of FindBin as it's less magical and doesn't have bugs on old Perls - the synopsis shows equivalent code using core modules.
The following could print `no`? perl -CA -MEncode=is_utf8 -E 'say is_utf8(shift) ? "yes" : "no"' WHATEVER The problem in the bug report is that `is_utf8("\N{U+FF}")` is true and `is_utf8("\xFF")` is not, resulting in two different binary representations, i.e., `\xC3\xBF` and `\xFF`. (For me, the comparison is what’s buggy: Unicode and binary strings shouldn’t be comparable.) So, if you’re only working with UTF-8 filenames and the above only prints `yes`, you’ll have a valid UTF-8 representation?
They are not two different binary representations in Perl. They are equal Perl strings that happen (on that platform and version of Perl) to default to different internal storage, and anything that notices that difference is subject to "The Unicode Bug". Unfortunately Perl's filename handling is one of these things. In your example -CA will very likely result in an upgraded string (UTF-8 internal representation) but this is both a concern the user should not have, and not guaranteed or stable. `utf8::downgrade $ARGV[0]` will result in the same string with a different representation as long as it can still be represented in the native byte encoding (as my original Unicode example input can).
I can think of several reasons: 1. you want to learn about Perl 6, and think that migrating an existing Perl 5 module is a good way to do this 2. you actually need the easy concurrency, grammar or unicode features that Perl 5 doesn't give you, but Perl 6 does In any case, the responses I get from the exposure of the articles, indicate to me that this has a positive marketing effect on both Perl 5 and Perl 6.
&gt; the only reason anyone migrates code in general is because they actually have to That's exactly it. 
Well, TIMTOWTDI but your first example of using tr/// kind of suggests you prefer something with regex :)
The articles are great, even as someone who has no reason to use another language I can still appreciate their informational value. Now if I could find someone to write something like this for JavaScript...
PDFs are not eBooks. If you're going to advertise something as an eBook then it should be in mobi or epub format.
Any videos for Perl Quiz I and II?
Thanks for stressing that UTF-8 encoded strings don’t necessarily are represented as such internally. &amp;#x200B; At least I haven’t been bitten by this yet…
Because `[^.]` cannot match dot characters.
But it could match characters after the dot, no? like "blablatxt"
ok i will never remember this but thank you :P i'm using it now
So demanding... There's precedent for Perl-related books being in PDF format - see http://onyxneon.com/books/modern_perl/index.html for example. Converting that layout and typography to fit the limits of mobi or epub seems like a waste of time, especially given that most readers (in both senses) are quite happy with PDF. If one of the mods of /r/FreeEBOOKS is going to accept PDF, that seems approval enough! As to the content: I thought it was nicely presented, if a bit short. For the target audience, perhaps would need some expansion on the "TMTOWTDI" and "TIMTOWTDIBSCINABTE" terms. The case study was not really detailed enough - where did the time go (designing/testing/documenting/rewriting/refactoring), how was it delivered, etc. - and was the end result "scalable" and "maintainable" without itself being falling into the "future legacy" category?
How, if at all, was William Angell associated with the Perl programming language, other than his father was named Perl? 
The problem is that in each loop you read paragraph by paragraph, and the odds have the IP and the evens have the title, but you try to match at the same time. You print on successful match, which are the even paragraphs, and IP is always empty because it did not, could not match. This can be solved by reading the even paragraphs from the program, advancing the loop manually. Put `$_ = readline;` between the two match operations.
Very poorly biased weekly, seems to be confusing CGI.pm and CGI.
&gt; the fact that CGI.pm comes (or rather just came) with standard Perl that eliminates (eliminated) the need for installations It rather depends what your standards are for a minimal CGI working environment, I suppose. Currently, two of the most popular OSes for hosting providers are Centos 6 and 7 (and their RHEL equivalents). A default installation of both of these OSes does not include CGI.pm. This is not because CGI.pm was removed from the core (they both ship with versions that should include the module) but, rather, because Red Hat decided to split the standard Perl distribution into two parts and only the minimal installation (which doesn't include CGI.pm) is included in the base installation. It's simple enough for the sysadmin to fix that (`yum install perl-CGI` to just install CGI.pm or `yum install perl-core` to install all of the missing parts of Perl), but given how little the hosting industry cares about Perl these days, how many will bother? So, on many hosting providers, you **will** be able to run a CGI program. But you'll be hand-rolling your parameter parsing (or copying it from Matt's Scripts!) and including raw HTML in your Perl code. And I really hope no-one is advocating that as a sane approach to writing CGI programs. Even if you're lucky and you get a hosting provider that has installed CGI.pm - you're still missing the Template Toolkit or some other sane way to product output. My point is that even for the most trivial CGI program, your life gets easier if you have non-standard parts of Perl installed. And while you're persuading the sysadmin to install CGI.pm and the Template Toolkit, why not ask her to install Plack as well? I guess I can feel another blog post coming on...
&gt; $_ = readline; WOOW. you are a genius.It worked.Thanks the full working one liner is sudo nmap -n -p 80 -Pn --script http-title 31.13.92.0-200 | perl -n00E ' ($ip) = /^Nmap scan report for (.*)/m; ($title) = /^\|_http-title: (.*)/m; $_ = readline; say "$ip : http-title: $title" if $title and /^80\/tcp *open/m; ' root@ns3359008:~# sudo nmap -n -p 80 -Pn --script http-title 31.13.92.0-200 | perl -n00E ' ($ip) = /^Nmap scan report for (.*)/m;$_ = readline; ($title) = /^\|_http-title: (.*)/m; say "$ip : http-title: $title" if $title and /^80\/tcp *open/m; '
&gt;A default installation of both of these OSes does not include [CGI.pm](https://CGI.pm). &amp;#x200B; On that note, it will be interesting to see what happens when CentOS/RHEL 8 becomes available, with the minimal perl no longer being part of the default installation. &amp;#x200B;
Oh, I didn't know that. Do you have a link? I was under the impression they'd decided to recombine the two RPMs. I hadn't heard anything about them removing it completely from the default installation. But, realistically, it'll be a few years before CentOS/RHEL 8 becomes mainstream in the hosting industry.
Ever since I found out that I could quite easily generate HTML using CGI.pm, that's what I've been using for my simple web apps. Sure I could use a templating engine but frankly the startup cost for a new project is so damn low that I've never felt the need to delve into them. 
I assume you've read a recent version of the [CGI.pm documentation](https://metacpan.org/pod/CGI#HTML-Generation-functions-should-no-longer-be-used): &gt; **HTML Generation functions should no longer be used** &gt; &gt; All HTML generation functions within CGI.pm are no longer being maintained. Any issues, bugs, or patches will be rejected unless they relate to fundamentally broken page rendering. &gt; &gt; The rationale for this is that the HTML generation functions of CGI.pm are an obfuscation at best and a maintenance nightmare at worst. You should be using a template engine for better separation of concerns. See [CGI::Alternatives](https://metacpan.org/pod/CGI::Alternatives) for an example of using CGI.pm with the [Template::Toolkit](https://metacpan.org/pod/Template::Toolkit) module. &gt; &gt; These functions, and perldoc for them, are considered deprecated, they are no longer being maintained and no fixes or features for them will be accepted. They will, however, continue to exist in CGI.pm without any deprecation warnings ("soft" deprecation) so you can continue to use them if you really want to. All documentation for these functions has been moved to [CGI::HTML::Functions](https://metacpan.org/pod/distribution/CGI/lib/CGI/HTML/Functions.pod). There are a few problems with using the HTML generation functions from CGI.pm: * They don't keep up with current HTML practices. I seem to remember waiting for some time for a new version of CGI.pm that would allow me to use CSS in my web app. And now, they are unmaintained, so you'll wait forever for new HTML features to be included. I don't know whether or not the functions were up to date with HTML5 features before they were mothballed. * They are hard for non-Perl programmers to edit. I expect you're probably working on projects where only Perl programmers are responsible for creating the HTML. But one day you'll want to get a front-end developer involved in your project and they are going to hate you for making them edit Perl code. And you'll hate them for not knowing Perl and accidentally deleting a comma from your code and breaking the entire system. This is the voice of experience speaking. * Even when I'm working on a tiny project for my personal use, where I know it's only ever going to be me working on the HTML, I still find it's useful to separate the HTML from the code. There are tools that make writing HTML easier. And you can't use them if you're not actually writing HTML. I can't even begin to think what my code would look like if I wanted to use something like Bootstrap alongside CGI.pm's HTML generation functions. I know how strong the temptation can be to stick with methods that you know. But switching to something like the Template Toolkit really isn't hard at all. And it will bring you benefits.
&gt; They don't keep up with current HTML practices. I still mostly use tables! &gt; I know how strong the temptation can be to stick with methods that you know. But switching to something like the Template Toolkit really isn't hard at all. And it will bring you benefits. Indeed, it's on my list of things to do in my copious free time... 
I suspect the "modern" way of doing Perl development isn't so much about running a local webserver but using the MVC pattern. In your use case, that means using your input to fill in a template with the appropriate info and outputting the result to STDOUT, instead of transforming the input into the result. This doesn't change your workflow that much but allows better separation between data and presentation. Note that I love Template Toolkit but it isn't the only templating tool on CPAN. If it doesn't gel with you, feel free to give HTML::Template or Text::Template a shot. &amp;#x200B;
Yeah, I've been running my own server (physical and VPS) for years... so I just ssh in and edit on the server. Sometimes I even make changes in a test environment before deploying! Thanks for the tips on other templating solutions. I am not going to lie, the fiddly markup does get old sometimes.
I really enjoyed a lot.
Using a proper templating system is a separate concern from "running a local webserver". It's just a different (commonly regarded as more maintainable) way to achieve your step 2: transform input to display.
Entirely correct. I will endeavor to do so the next time I need to generate HTML (I like stringing together flat files + some Perl code with Make to generate static pages).
Some more options because everyone's needs are different and nobody can agree: Text::Xslate, Mojo::Template
Are there videos or slide decks anywhere? &amp;#x200B;
By your definition, epub is not an ebook \[format\] because you can't read it on Kindle.
I read PDFs all the time on ebook readers, because either it's the only format available for a title, or the mobi/epub version formatting sucks. So for all intents and purposes I'd say PDFs count as ebooks.
\&gt; It started with an article about CGI.pm on perl.com that struck the nerves of Dave Cross and a few other people who seem to be against the use of CGI.pm and CGI in general. The others came pointing out the value in the simplicity of CGI and the fact that CGI.pm comes (or rather just came) with standard Perl that eliminates (eliminated) the need for installations. I personally think that is totally ok to write small things as CGI if that's the only thing you know and/or the environment has limitations. I also think it was a mistake to remove CGI.pm from core, but who asks me anyway :) Gabor expressed his opinion, but he didn't seem to confuse between [CGI.pm](https://CGI.pm) and CGI the protocol. And he did explicitly state that what he wrote was his opinion and not a fact.
None of the references blog posts were discouraging "CGI in general". I don't mind him expressing his opinion though it's a bit much, but then he does so again in his "description" of all the related blog posts, which is not in my opinion a professional approach to news aggregation.
The talks in the main room were videoed. I don't know how quickly they'll be online. It's up to individual speakers to add a link to their slides on the [web site](http://act.yapc.eu/lpw2018/).
The easiest way would be to decode your JSON and then simply access the element you want via Perl, e.g. $jira\_tickets\[5\]{key} and $jira\_tickets\[5\]{fields}{timespent}. 
nope that doesn't work. it stores as a string in that array, not as an actual json.
[removed]
 my $json_obj = JSON::XS-&gt;new-&gt;relaxed(1)-&gt;decode($jira_tickets[5]); my $timespent = $json_obj-&gt;{fields}{timespent};
Yeah well, that's part of the reason I don't want to change systems. If it ain't broke... BTW, I really like the distributive nature of stuff like `ul`, `tr` etc. Do other templating systems have similar mechanics? 
I don't know about all other templating systems, but TT is procedural. You insert a list, for example, using a loop. &lt;ul&gt; [% FOREACH item IN list_of_items %] &lt;li&gt;[% item %]&lt;/li&gt; [% END %] &lt;/ul&gt; 
Cool book, very easy to read. The Perl 6 in this book seems -really- similar to Perl 5.
I really enjoy these sorts of posts. Very upbeat and some good information in there as well. I really want to make it to LPW sometime.
Apart from the fact that Larry's involved, I really struggle to see any connection between Perl 5 and "Perl" 6. A couple of years ago, out of curiosity, I installed Perl 6 and had a go at writing some code in it. And quickly gave up because it bore no relationship whatsoever to the language I already knew how to write. And I really couldn't see any value in the effort that would be required to learn what to all intents and purposes is a whole new language that I'll probably never have a use for. Six really ought to have a different name - not pretend to be a development of Perl itself. Perl 5 was a huge development from Perl 4, but the basic language itself was essentially the same.
One wonders, would folks in the 70s and 80s been irritated if Niklaus Wirth had called Modula, "Pascal 2" --? Indeed there is a strong precedent in the naming of [Component Pascal](https://en.wikipedia.org/wiki/Component_Pascal).
It's a callback attribute. [Here's](https://metacpan.org/source/SRI/Mojolicious-8.07/lib/Mojo/Log.pm#L10) the default has format =&gt; sub { shift-&gt;short ? \&amp;_short : \&amp;_default }; Just call it with something that formats it as you see fit.
We need to know far more about what you are talking about if we are going to help you. Do you have some code that you are working on? Show us the code and explain what you would like the code to do. 
substitution regex? my $string = "app(lication)"; print "$string\n"; #prints "app(lication)" $string =~ s/app/52/; print "$string\n"; #prints "52(lication)" [https://perldoc.perl.org/perlre.html](https://perldoc.perl.org/perlre.html) Of if you don't want to use a regex, my $string = "app(lication)"; print "$string\n"; #prints "app(lication)" $string = "52" . substr($string, 3); print "$string\n"; #prints "52(lication)" [https://perldoc.perl.org/functions/substr.html](https://perldoc.perl.org/functions/substr.html)
So you want to change "application" to "app51"? The solution to that specific problem is just to write "app51". Or you could substitute with: s/lication/51/; I presume you're looking for a solution to some more general problem, but it's difficult to tell what that general problem is. Can you describe it? Here's one possibility of what you might be looking for: my $s = "application"; $s =~ s/^(app).*/${1}51/;
There's an example for setting the format callback in the documentation. https://metacpan.org/pod/Mojo::Log#format
D'oh! Thanks.
Sometimes I feel like the equivalent of a n00b crash test dummy in this sub...
Thanks Olaf. People like you keeps me going. I thank you from the bottom of my heart.
Appears to be back up
I had a word with the owner and it's back. Seems that reddit is monitoring for strawberry perl
actually, someone noticed your question on irc \#win32. ``` &lt; ranguard&gt; oh.. dig strawberryperl.com @NS2.DREAMHOST.COM &lt;- works fine &lt; ranguard&gt; dig strawberryperl.com @NS1.DREAMHOST.COM &lt;- doesn't seem happy ```
simcop2387 has set up a mirror to hopefully alleviate future issues: https://strawberry.perl.bot/
Holy crap, that's awesome! Thanks for doing this, porting the script at the time wasn't viable due to performance reasons, but I've been meaning to come back to it (and fix up a few unicode bugs too...). Really nice to see it working!
Why did this boot post this link twice? Bad bot!
Nice. Congrats to Dave.
It would be prudent for any article on this topic to mention that `\d` matches unicode digits, not just `0-9`, and the alternatives of the `[0-9]` character class and the `/a` modifier when you actually want what Perl considers numbers (arabic digits).
Good article. I would recommend *against* the `is_number` check as written - see below - but it's a useful excursion into the dualvar semantics and risks of a trivial check. Also, that first sentence indicates a common developer misunderstanding (at least, I run into this on a regular basis): SQL, HTML, XSS and paths might be types of strings - debatable in the path case, perhaps - but they are *not* interchangeable. There are certain rules that apply to each of them - plain text has to be transformed to fit those rules. Much like you can't just dump Swahili words into English without risking audience confusion, mixing different "types" of strings is not a good idea. Unfortunately this is one of the weak points of Perl: it does not really do types well, there are ways to guard against this but it usually comes at a noticeable performance hit. `AT&amp;T` or `O'Reilly` are perfectly valid strings for a user to enter in a field, and if your validation logic rejects them due to the "special characters", that's not an ideal user experience. On the topic of numbers specifically, Perl's idea of a number does not necessarily match other systems - databases or external APIs in particular, but it can also affect the perl code itself: *The provided `is_number` function is potentially dangerous* if you don't explicitly cast the result to a number. ``` # Validate our input - must be numeric, and non-zero return unless is_number($number); return unless $number; # So at this point $number is definitely non-zero, and this is perfectly safe. # There is no chance of us dividing by zero at all, we are confident of this. $result = $total / $number; ``` This might even pass casual review... but now try that with ` 0e1` as input. To avoid this, I would suggest to use the numeric value explicitly (`0 + $number`), rather than having a validation routine that dances around making any changes to the variable. 
As long as you understand the concept behind raycasting, the implementation is quite straightforward. The SDL part would mostly consist of setting up a window and then rendering vertical lines. If you want texturing, easiest to rotate everything through 90 degrees first - you could also use Imager to scale each sprite or wall texture accordingly. For the mathematics and concept, there's a good overview on lodev.org: https://lodev.org/cgtutor/raycasting.html The hard part is usually the code which finds the intersection between the ray and the 2D map grid. Once you have that, you would be able to use the calculated distance to work out the correct vertical positions for the start and end of the wall column. On a recent computer, Perl should be fast enough for that, if you're not hoping for a 4K render!
It's pretty common in my experience for validation routines to also return a normalized version of the input. This is why type libraries have [coercions](https://metacpan.org/pod/Type::Tiny::Manual::Coercions) after all.
Very cool, started a new project in Mojolicious this year and have been loving it.
Glad to hear it! Keep us posted!
I threw one together in an afternoon a while back. It's not fast, but raycasting is conceptually simple in pretty much any language.
This is good news!
A really useful aspect of both the `race` promise and the similar `wait_any` [Future](https://metacpan.org/pod/Future) is that it resolves with the same success or failure as whatever component finished first. This means that you can really easily use it for a couple cases. For timeouts, just race your original promise with a promise that fails after X seconds, and you'll get a promise that either succeeds or fails when the original one does, or fails with the timeout error. In the case where you're racing a bunch of promises doing similar things, your race promise will directly have the success or failure of whatever finished first.
While that's cool... I really don' t see myself every matching anything beyond 100. 65k? That seems pretty crazy.
It comes up in ... [certain cases](https://metacpan.org/source/SRI/Mojolicious-8.08/lib/Mojo/DOM/HTML.pm#L39).
besides not being shiny anymore, Dumbbench no longer appears to be actively maintained.
Use [Scalar::Util::Numeric](https://metacpan.org/pod/Scalar::Util::Numeric). It provides `isnum`, `isint`, `isfloat`, `isinf`, `isnan` so you don't have to whip up regexes for this basic task. It's also fast since it's XS (a benchmark; compared to [Scalar::Util::Numeric::PP](https://metacpan.org/pod/Scalar::Util::Numeric::PP) which basically uses regex to validate input), in general two to several times faster. 
Well, Benchmark.pm is even far less shiny than Dumbbench.
I feel like there should be a way to add to the plugin itself the necessary code to save touching a template. Using a hook to interrogate the mime type output and inject the necessary code perhaps? Regardless, a great plugin.
&gt; *Practicing your live demo includes practicing logging in.*Joel Berger, today Corollary - do NOT make your password something you could not tell your mother. :-) &amp;#x200B;
That's fraught with peril and much, much worse for performance: Parsing the DOM to add an element and then rendering the DOM again.
But that makes it more secure: You'll never tell anyone!
Yeah, Dumbbench is a tad old and dusty, but it's still the best I could find. If I find better, I'll probably switch to it. Or maybe I'll break down and begin to send PRs to Dumbbench. :-)
During development, that performance hit is often acceptable - and parsing the DOM is usually a good idea when making changes to a template-driven system: too easy to generate bad HTML without noticing, might look fine in one browser but the next will complain bitterly. Anything with scripts often involves a server-side combining step anyway, so adding in this sort of functionality is easier and a little more fun when done at that level 😅 
Sounds over-complicated to me, but someone is free to add it if they'd like (provided there's a way to turn it off so it doesn't turn into feature-creep hell).
just implemented this, its awesome.
Thanks!
Hmmm... Bit shorter &amp; cleaner, 62 chars. PATH=$(echo $PATH|perl -F: -lape'$_=join":",grep!$s{$_}++,@F') Not that there is any real need :P
Good link...that code should not be hard to translate to Perl at all. The performance bottleneck, presumably would be the method used to blit the data to video memory, and SDL probably has the necessary infrastructure...really looking forward to u/Quaskell 's new game!
Very nice
Perhaps "changes" would be more appropriate, I wouldn't really count 3 of those 5 as features!
Pretty much -- there's no reason to believe that the arc of the version treadmill bends towards improvement. I'd rate this list "marginal improvement; breaks my stuff; breaks my stuff; breaks my stuff; who knows?"
“I think I’ll stay with Perl 5.26 and its globs and stray, curly brackets,” said the Perl curmudgeon. “For all my code was built with script completion in mind. ‘Do the right thing, best effort language.’ It’s the destination, not the journey. Let the computer execute the whole script regardless of errors! I need last line of ‘1;’ to be seen by the computer’s brain.” 1;
that script completion idea sounds useful, which editor is this? do you have a link?
I wouldn't count any of them as new features.
Just, vi.
Actual list of changes can be seen in the perl29Xdelta pages at https://metacpan.org/release/ETHER/perl-5.29.5
Underwhelming so far. But note that there's still roughly 6 months before the final 5.30 is released sometime in May-Jun 2019.
&gt; Underwhelming so far. What were you expecting? What would make you happy?
Also at https://perldoc.pl/5.29.5/perldelta
To be clearer on the removal of File::Glob::glob(); File::Glob::bsd_glob() was [added in Perl 5.6.1](https://perldoc.pl/perl561delta#glob()) as File::Glob::glob() clashed with the builtin CORE::glob() while not using the correct prototype to properly work that way. CORE::glob() has been based on File::Glob::bsd_glob() and File::Glob::glob() has sat there deprecated and unused since then.
I have to question the sensibility of this article in general, with just an list of changes out of context and missing some [important ones](https://perldoc.pl/5.29.5/perl5294delta#Previously-deprecated-sysread()/syswrite()-on-:utf8-handles-now-fatal).
I just discovered Yancy and... it's really amazing !! 
Thanks!
One comment says: &gt;I would be worried some people are using `-&gt;canonical ` to update their object in place, which this would break. Which sounds like a stupid thing to do, as it usually returns a clone, unless it's a noop. If you expect it to do nothing, you shouldn't even call it. Always clone simply looks more consistent to me.
I had a capital letter. So much lost over one bit!
It's not even a problem, as later mentioned, since it never actually updates the object in place. It either returns a new object, or does nothing; so the proposal is just for "do nothing" to become "return a clone".
I had success getting the metacpan docker containers (available via GitHub) to work with pinto packages (essentially just registered all the local tarballs) but sadly I never got to push the changes I had to make to the containers back (I've since left the job where I looked into it). It was several months ago but there were random crashes which I had to debug and comment out certain parts of the code.
There seems to be an unwritten assumption that your running system is actually a local copy of an upstream project, and that it is under some kind of version control system. Otherwise saying that your "direct modifications may not survive on update" makes no sense, as surely you would be running version control yourself and would have committed your changes? What I see as useful here is more along the lines of: How to write a Mojolicious program so that individual instances can have customized files and configuration that will not conflict with version control. I still would like to know the best way, though, of keeping a git repository for only this kind of local changes, without having to constantly merge with the upstream project. p.s., also some sort of formatting problem with line wrapping
Thank you. It looks like it works now. I'll try it out next week.
More performance enhancements are always welcome. As for features, nothing much really.
Thank you. I'll give it a go or perhaps try to fix `minicpan_webserver`.
So you have a Mojolicious application and you don't want to edit the application itself to add new templates and configuration? Your best bet there is probably to change the \`MOJO\_HOME\` environment variable. That's where templates, static files, and configuration files are loaded from.
Nice one!
I'll eventually read the manual, but if you'd like to answer some quick questions: * Is the job queue visible from multiple hosts? In other words, can minions on multiple hosts service a single queue? * Is there anything to prevent a minion from queueing a job for other minions to handle?
I’m a big fan of Minion and use it as a basic pub/sub queue. You can have any number of hosts publish to the queue and any number consume from it. I use Postgres to keep track of the jobs, but you can use any backend supported by Mojo. I use it for big OCR jobs, which which would take weeks on my local server. I queue up 100,000 images to process with a Perl script, then can spin up AWS spot instances running a Minion worker script to churn through them as a totally separate exercise. You just set the number of workers on the host equal to the number of cores, and it’ll run at 100% resource utilization till all the jobs are done. Running workers on multiple hosts is just a matter of running the same worker script on each host. It’s remarkably easy, and I’m by no means a sophisticated developer. 
Minion is coordinated with a database. If the database is accessible remotely, then a worker can run on a different host (I mention this when I talk about picking the SQLite backend on [yesterday's Mojo advent post](https://mojolicious.io/blog/2018/12/10/minion-stands-alone/), which only works locally). Workers can share queues, yes. Minion workers can queue jobs, yes. But, if you already know what needs to be done in sequence, you can also queue jobs that depend on other jobs (`parents`) so that the child job only runs after the parent job(s) are finished. The child job can also look up the result of their parent jobs to get any necessary data.
Altogether, Minion is the best thing (other than Mojolicious itself) to come across my desk in years. The only "problem" with it, is that I want to rewrite everything I touch to offload all the computation-intensive tasks to new jobs. Kudos to all involved!
Perhaps this "article" wasn't appropriate for Reddit (I wouldn't have submitted it), but I've been doing these for almost a decade (["new features" category](https://www.effectiveperlprogramming.com/category/perl/new-features/). With each upcoming version of Perl I look at the perldelta and pick out the things thatI think are the most interesting or impactful to the community. Eventually I explore that feature and see what turns up. * The general title of the lists for each version has been "new features". * As some people pointed out, v5.30 is still a long way off (half of Perl's yearly release cycle). * I think the general move by the Perl 5 Porters to remove deprecations (some for close to 20 years) and clean up the code is the pathway to more exciting features. I tend to complain that the annual release should alternate between fabulous new features and clean-up / performance enhancements. * Despite any of that, I usually hope to give people warning on things that might break their code. Notice the left brace issue coming back in v5.30 that was formerly in v5.26 [You must escape the left brace in a regex](https://www.effectiveperlprogramming.com/2017/04/you-must-escape-the-left-brace-in-a-regex/)
I've added to the list the fatal syswrite et al on :utf8. Thanks,
That makes sense, perhaps it's worth reconsidering the 'features' name though. We all love name changes.
I know things are getting more quiet in the Perl 5 world, but this amount of content for Perl 5 Weekly lately makes it look like almost absolutely nothing is happening. How about also covering, for example: popular threads on perlmonks.org, stackoverflow, and also the the various perl mailing lists (perl5-porters, especially)? /u/liztormato does such a fantastic job recap'ing the happenings around Perl 6 that also include Twitter, Reddit, Facebook, the core development, comments from various forums/blogs/sites... And to top it all off, she's a core dev herself! /u/neilbowers once told me that just editing the Perl 5 Weekly usually takes him around 4,5 hours. I shudder at the thought of how many hours it takes Liz to create a single edition of Perl 6 Weekly.
The last one took me about 12 hours, but then again, that was for 2 weeks. Generally it takes me about 6 hours.
Why not use Slurm or something similar? I'm a bit lost on why there are so many of these language specific job queues. It's such a common problem you'd think there'd be rock solid language agnostic infrastructure by now.
At some point you have to use some language to tell the job queue what to do. It might as well be the same language the rest of your application uses.
I would rather have a simple language wrapper around something that I know thousands of people are using, and projects/companies with millions of dollars on the line have invested in.
I'd be curious to know how much code you had to write versus using HTCondor. In theory HTCondor has facilities to do what it sounds like you're doing without writing much more than a short config file.
And, for my purposes, I'd rather have a simple, pure-Perl (as my project is Perl) solution that is deployable with the ease of any other Perl dependency. Adding another language's toolchain into my environment is more work.
The Minion code is minimal, maybe 10 lines of boilerplate config. Two scripts: one to create the workers which is just establishing a dB connection and the inserting the jobs, and a second which runs as a daemon to watches the queue and kick off jobs asynchronously. You just launch the daemon on as many hosts as you like.
The Minion code is minimal, maybe 10 lines of boilerplate config. Two scripts: one to create the workers which is just establishing a dB connection and the inserting the jobs, and a second which runs as a daemon to watches the queue and kick off jobs asynchronously. You just launch the daemon on as many hosts as you like.
Wew. Thanks for all your time!
I'd also add that the continued coverage of byterock's ramblings is not relevant Perl news. I like your suggestions for topics much better. Of course it is up to the time and effort that each volunteer gives.
A "Future"? Isn't that what they call a "Promise" in the rest of the word? Like this: [Promises - An implementation of Promises in Perl](https://metacpan.org/pod/Promises)
Have a look through the perlre man page, and search for the word 'greedy'. That should point you to the docs that will help you solve your problem.
 \* is greedy. Try \*? instead.
I'm fairly new to perl, but was hacking on something for work and had to do something similar. I ended up doing a nested while loop from the text file (not the large). while (my $current_line = &lt;INPUT&gt;){ if ($current_line &amp;&amp; $current_line =~ /^ABC/i) { while (my $new_current_line = &lt;INPUT&gt;) { last if ($new_current_line =~ /^XYZ/i); #Do something } } } Seemed to work, but not sure about reproducibility for larger text files, or even if its the best possible method. However, it got the job done and is working well so far, while still being super fast.
**Greedy vs Non-Greedy** Greedy (Default) matches the LONGEST possible match. Non-greed matches SHORTEST possible match. &amp;#x200B; `Example:` `$_ = "abcabc";` &amp;#x200B; `# greedy` `/a.*c/; # returns abcabc` `/a.+c/; # returns abcabc` &amp;#x200B; `# non-greedy` `/a.*?c/; # returns abc` `/a.+?c/; # returns abc` &amp;#x200B;
It seems that you have strings of variable length and content occurring in between strings of three letter uppercase chars. In that case (unless I am not understanding your issue) why not just do a regex for any string that is not ABC/XYZ? While (my $my_string = &lt;FH&gt;) { Chomp($my_string); # remove newline chars If ($my_string !~ m/ABC|XYZ/) { Do something...; } } Edit: sorry for the poor format I’m on mobile and I’m not sure how to change the font 
 ($captured) = $raw =~ m/ABC.+?(\d+).+?XYZ/s; # 2017 
More like "as usual" :-) I don't recall a single year where the PerlDancer Advent Calendar has full 24 posts (not 2010, 2011, 2012, 2014, nor 2016).
Good example, nice write up. 
This might be useful background reading: https://en.wikipedia.org/wiki/Futures_and_promises The concepts are indeed available in many languages, e.g. C++ has `std::future`, Python's twisted had `deferred` and more recently https://docs.python.org/dev/library/asyncio-task.html#asyncio.Future, C# tasks, JS/ES6 have `Promise`, etc. The Promises.pm module is similar, but has some limitations compared to Future.pm - for example no `-&gt;cancel` state, missing the various tools available in Future::Utils - and sadly does not attempt any form of compatibility with Future.pm (which has been around for about 7 years now). They're all useful abstractions that allow composing async applications, it'd be nice to have one standard - but of course being Perl, everyone invents their own. I'd recommend Future.pm over the options even if only for https://metacpan.org/pod/Future::AsyncAwait, once it's stable it'll mean we're almost caught up to some of those other languages in terms of basic building blocks...
Two small notes. If you're using Mojo::DOM to parse XML and not HTML, you'll want to parse it in XML mode which enables case sensitivity; this is activated automatically if an XML declaration (`&lt;?xml`) is found, otherwise you can activate it like: my $dom = Mojo::DOM-&gt;new-&gt;xml(1)-&gt;parse($file-&gt;slurp); Also Mojo::DOM expects decoded characters (it does not handle character encoding itself), so you should decode files you read before passing them in. use Mojo::Util 'decode'; my $dom = Mojo::DOM-&gt;new-&gt;xml(1)-&gt;parse(decode 'UTF-8', $file-&gt;slurp);
You might take a look at the [range operator](https://www.perlmonks.org/?node_id=377450) and it's use of regular expressions &amp;#x200B; use strict; use warnings; my $captured; map { if (my $num = /ABC/ .. /XYZ/ ) { $captured = $_ unless $num =~ /[1E]/} } &lt;DATA&gt;; print $captured; __DATA__ ABC FuzzyBear2017 is the best XYZ Some more text here XZZZ Process started &gt;&gt;&gt; FuzzyBear2017 is the best &lt;&lt;&lt; Process finished. (Exit code 0) &amp;#x200B;
As already posted a few times, using a question mark after the star to make the pattern non-greedy is the immediate answer. But I do think your way to make thepattern match anything, including newlines, is a bit contrived: `[\d\D]`, and it's not necessary, as using the regex modifier `/s` will make `.` match newlines too. But as you intend to match entire lines, perhaps that's not the best approach. Instead, I'd do something like this: /^ABC\n((?&gt;.*\n)+)?XYZ$/m This will do a non-greedy match, but only for complete lines. The regex modifier `/m` will make `^` and `$` match the start and end of lines, even in the middle of the string. 
These Perl6 articles are really well done. Great introduction to the new language features.
This is a great demo of Test-Driven Development with Test2!
Thanks! Glad you like it
Write a syslogd server and listen to port 514. :) use base qw(Net::Server::PreFork);
Have all your servers/switches use ‘remote syslog’ and have them log to your new Perl server, and now you have a centralized syslog processing server. Ps, works great!
I would go with \[IO::Async::FileStream\]([https://metacpan.org/pod/IO::Async::FileStream](https://metacpan.org/pod/IO::Async::FileStream)) myself. The \`filename\` argument will automatically watch for filename changes.
* Read / process to the end of the file. * Store the seek pointer. * Close the file. * Open the file. * Seek to the stored seek pointer. * Step 1 This will allow you to run as a cron job and survive reboots
[it's a FAQ](https://github.com/vim-perl/vim-perl#can-you-add-highlighting-for-moose-trytiny-testmore-sql-in-strings-etc)
\`\`\` / (?&lt;!\\d) # negative look behind, checks to see what that there aren't numbers (digits) before this \\d{1,6} # matches between 1 and six numbers (digits) (?!\\d) # negative look ahead, checks that what comes next is not a number (digit) / \`\`\` It does a bit more than simply look for six digits, it technically looks for between 1 and 6 digits that are not surrounded by more digits. 
Beautiful, thank you!
I would also suggest this, but I'll note that File::Tail also supports watching for rotated logs - see the 'resetafter' option.
If this is in Perl, you should probably replace each instance of `\d` with `[0-9]` since `\d` matches any unicode digits which is unlikely to be what you want.
Thanks! That's really helpful. Looks like there isn't support for Moops yet, but many of the ones that exist get me most of the way there :)
No, don't do this. Don't ever close the file. Always leave a file handle to it open, but _every time you loop around to read more, stat the filename and compare the file's INODE to the INODE of the file you're reading now_. When they differ, your log file has been rotated. That's why you always leave the file handle open.
Something like this. But really, use File::Tail. #!/usr/bin/env perl use strict; use warnings; my $old_fh; my $old_stat = {}; my $directory = "/path/to/log/files"; my $pattern = "httpd-access"; while (1) { if (! ref($old_fh)) { warn "No FH open, finding file to open"; open(my $new_fh,sprintf("%s/%s.log",$directory,$pattern)) or die("Couldn't open log file for reading ($!)"); $old_fh = $new_fh; @{$old_stat}{qw(dev ino mode nlink uid gid rdev size atime mtime ctime blksize blocks)} = $new_fh-&gt;stat(); } consume(); } continue { sleep 1; my $new_stat; @{$new_stat}{qw(dev ino mode nlink uid gid rdev size atime mtime ctime blksize blocks)} = stat sprintf("%s/%s.log",$directory,$pattern); if ( $new_stat-&gt;{dev} != $old_stat-&gt;{dev} || $new_stat-&gt;{ino} != $old_stat-&gt;{ino}) { warn(sprintf("File rotated under us, finish reading and reopen. Was at %d, size is now %d",$old_stat-&gt;{size},$new_stat-&gt;{size})); consume(); # close old filehandle $old_fh-&gt;close(); # open new FH, update old stat to reflect new file open(my $new_fh,sprintf("%s/%s.log",$directory,$pattern)) or die("Couldn't open log file for reading ($!)"); $old_fh = $new_fh; } # update old stat w/ new file size $old_stat = $new_stat; warn("File is $old_stat-&gt;{dev}:$old_stat-&gt;{ino}, size is $old_stat-&gt;{size}"); } # }}} sub consume { my $count = 0; while (defined(my $line = $old_fh-&gt;getline)) { chomp $line; $count++; # do stuff } my $pos = $old_fh-&gt;tell(); warn("Hit end of file, I'm done consuming. Read $count lines, now at pos $pos"); } 
A couple of comments. The correct way to link to an email address in POD is: L&lt;mailto:foo@example.com&gt; instead of: C&lt;foo@example.com&gt; Second, I actually prefer using: To read more about Strawberry Perl, visit L&lt;http://strawberryperl.com&gt;. instead of: To read more, visit L&lt;The Strawberry Perl homepage|http://strawberryperl.com&gt;. because in the former version, you can see the URL in the command-line when the POD is rendered as manpage.
If this is a cron job and he is processing the file to the end, then will close it when the program completes. Explicitly, or by defacto. Of course there is additional logic that needs to be included to reset the seek pointer when the file gets rotated or truncated. 
With Mojolicious: #!/usr/bin/perl use Mojo::Base -strict; use Mojo::IOLoop::Tail; my $tail = Mojo::IOLoop::Tail-&gt;new(file =&gt; "log.txt"); $tail-&gt;on(oneline =&gt; sub { my $tail = shift; my $line = shift; print $line; }); $tail-&gt;run; Mojo::IOLoop-&gt;start; 
BTW, File::Tail handles rotation just fine, I am using it myself.
A lot of interesting thoughts in this thread. Thanks!
I once needed `tail -f` functionality in Perl, and I learned something that day about `tail` that I hadn't know. It opens up the file over and over again, and then does a `seek` to the last location it read (or something like that. It's been a while). So log rotation, which you would assume would be a problem, is not problem at all, because you're opening up the same file every time, by name. So you always get the right file. This was a surprise to me, because the appearance of `tail -f` is that the file stays open and it reads it from disk in real time, or something like that. But it's super quick to open a filehandle and do a seek to a certain line, even if that file is very large.
&gt; Find some clever OS level hack and have the syslog write to a pipe or a fifo or something that feeds STDIN to my Perl script. Rsyslog will actually do this. $template librenms,"%fromhost%||%syslogfacility%||%syslogpriority%||%syslogseverity%||%syslogtag%||%$year%-%$month%-%$day% %timegenerated:8:25%||%msg%||%programname%\n" *.* action(type="omprog" binary="/usr/local/www/librenms-dev/syslog.php" template="librenms") 
See also http://perladvent.org/2018/2018-12-12.html
Yeah, that's not entirely coincidental :-)
`df-check` is implemented the wrong way. GNU coreutils `df` likes to put the filesystem name on its own line when it becomes too long. I'm telling you this not that you go and merely fix the regex, but that you realise that parsing output of programs without a stable and machine-readable output format is a fool's errand; `df` is made for human consumption only. You need to skip over that layer and ask the operating system directly for the information, it offers them in a structured way with the syscalls `statvfs`/`statfs` and `GetDiskFreeSpaceA`/`GetDiskFreeSpaceEx`. See XS files in http://p3rl.org/Filesys::DfPortable for example code.
@daxim, thanks for pointing that. I know the implementation is naive, bu patches are welcome. I like the [Filesys::DfPortable](https://metacpan.org/pod/Filesys::DfPortable) btw.
Don't reinvent the wheel. `tail(1)` already does what you need, including the corner cases, so why not use it? tail -f /var/log/whatever | your-script
since log rotation tends to rename + create a new file, this would likely need `tail -F` - at least with GNU tail. &gt; With --follow (-f), tail defaults to following the file descriptor, which means that even if a tail'ed file is renamed, tail will continue &gt; to track its end. This default behavior is not desirable when you really want to track the actual name of the file, not the file descrip‐ &gt; tor (e.g., log rotation). Use --follow=name in that case. That causes tail to track the named file in a way that accommodates renaming, &gt; removal and creation. 
So do each of the perl modules mentioned, and they don't require a separate process.
Quick and dirty solution. '\^\\s\*Usually\\s+(ships|dispatched)\\s+(with)?in\\s+24?\\s+(hour|day)s\\s\*'
Where you have: `\sUsually\s+ships\s+in\s+24\s+hours\s` change that to `\sUsually\s+(?:ships\s+in\s+24\s+hours)|(?:dispatched within 2 days)\s` There are online sites you can use for experimenting with alternatives, for example: https://www.regextester.com/ put the `\sUsually\s+(?:ships\s+in\s+24\s+hours)|(?:dispatched within 2 days)\s` between the `//` characters in the "Regular expression" section at the top, without any quote (`'`) characters, and try some test messages in the box underneath to see if they match. If you want something that'll accept a wider variation, you could try something like: `\sUsually\s+(?:ships|dispatches|dispatched)\s+(?:with)?in\s+\d+\s+(?:hours|days|weeks|months|decades)\s` (also, for posting, just hit space 4 times before each line, and make sure there is a blank line before and after the code)
It has only work on: [Usually dispatched within 24 hours] [Usually dispatched within 2 days] I'm afraid your code will include "Usually dispatched within 12 days" etc... 
Thank you so much! Very thorough, educational and kind. You are a good person.
`\sUsually\s+(?:ships\s+in\s+24\s+hours)|(?:dispatched within 2 days)\s` You have a mistake here, it should read: `\sUsually\s+(?:ships\s+in\s+24\s+hours|dispatched within 2 days)\s`
I had to come check this thread to make sure I wasn't the unreachable programmer. I'm not. Well, I'm not _that_ unreachable programmer.
After a quick look, you probably need LWP::Protocol::https installed. Can you post some kind of error message?
&gt; \sUsually\s+(?:ships\s+in\s+24\s+hours)|(?:dispatched within 2 days)\s Either works, but yes - the `)|(?:` is technically not needed. For someone without regex experience, I find it's not immediately obvious what the `|` operator acts on, so in those cases I prefer to make the grouping a bit more explicit.
The | operator acts on everything to its left and right, so `hello (?:world)|(?:everyone)` matches either `everyone` or `hello world `, while the regex `hello (?:world|everyone)` matches either `hello everyone` or `hello world`. I didn't intend to make the post as an abbreviation of the regex, but as a correction of its semantics
The [LWP distribution](https://metacpan.org/release/libwww-perl) contains [a cookbook](https://metacpan.org/pod/distribution/libwww-perl/lwpcook.pod) and that cookbook contains [a section on HTTPS](https://metacpan.org/pod/distribution/libwww-perl/lwpcook.pod#HTTPS) which says: &gt; **HTTPS** &gt; &gt; URLs with https scheme are accessed in exactly the same way as with http scheme, provided that an SSL interface module for LWP has been properly installed (see the README.SSL file found in the libwww-perl distribution for more details). If no SSL interface is installed for LWP to use, then you will get "501 Protocol scheme 'https' is not supported" errors when accessing such URLs. &gt; &gt; Here's an example of fetching and printing a WWW page using SSL: &gt; &gt; use LWP::UserAgent; &gt; &gt; my $ua = LWP::UserAgent-&gt;new; &gt; my $req = HTTP::Request-&gt;new(GET =&gt; 'https://www.helsinki.fi/'); &gt; my $res = $ua-&gt;request($req); &gt; if ($res-&gt;is_success) { &gt; print $res-&gt;as_string; &gt; } &gt; else { &gt; print "Failed: ", $res-&gt;status_line, "\n"; &gt; } The README.SSL file that it mentions, contains the following: &gt; As of libwww-perl v6.02 you need to install the LWP::Protocol::https module &gt; from its own separate distribution to enable support for https://... URLs for &gt; LWP::UserAgent. &gt; &gt; This makes it possible for that distribution to state the required dependencies &gt; as non-optional. See &lt;https://rt.cpan.org/Ticket/Display.html?id=66838&gt; for &gt; further discussion why we ended up with this solution. So you probably just need to add the following to your Dockerfile. RUN cpanm install LWP::Protocol::https
Thanks for the explanation - and yes, good catch, I should have stopped to think before posting! Sorry about that.
I have no problem with this content but as there is currently a relatively high volume of posts from the advent calendars, I wish this one was not cluttering this sub up; I can go to /r/perl6 to see these.
This sub is still about "The Perl Programming Language, including Perl 5 and Perl 6." last time I checked. Instead of grumbling about "relatively high volume of posts", I suggest you enjoy the fact that there are apparently still enough Perl people around to write all of these blog posts. It could be worse, you know :-)
This looks pretty cool! I use the inbuilt debugger a lot; it's great for specific use cases. The GUI frontend will certainly make it more approachable. The API is neat, but I don't fully understand the use case. When I'm using the debugger, it's usually because I can't spot the flaw right away and need to "step in". Anyone have some cool use cases offhand?
Look in your .bashrc/.bash_profile/.bash_login file for something like `eval $(perl -Mlocal::lib)`. You don't have local::lib installed anymore, so you can remove that. Or, you can install the local::lib module using something like `cpan local::lib`. local::lib allows you to install CPAN modules in your user directory without system admin privileges, or just to avoid interfering with the system Perl.
We've been using [Params::Validate](https://metacpan.org/pod/Params::Validate) for stuff like that, with custom harness on top of it, defining validators for different data types (like unsigned int &gt;= 1 for counters, valid hostnames, etc).
Make sure to check out the first sentence in the [description](https://metacpan.org/pod/Params::Validate#DESCRIPTION) - Params::ValidationCompiler is a successor with much less performance issues.
your map is returning a hash, you likely want: my @file_paths = map { $_-&gt;{"SrcFile"} } @$data;
Perfect, works like a charm! Thank you very much :)
The map is returning a list that would be useful to assign to a hash but is assigned to an array here. That's because ``=&gt;`` is a fancy comma.
What's the controversy with coros? And what sort of alternatives are in the works that are less controversial?
It's difficult to give an unbiased answer to this, but here is some discussion that might provide some context. https://www.reddit.com/r/perl/comments/38wgsl/mlehmann_forks_perl_creates_stableperl/
BTW, the WWW-YouTube-Download distribution already includes [youtube-playlists](https://metacpan.org/pod/youtube-playlists) to extract URLs from a playlist. And realistically, one would use youtube-dl instead. Particularly, a site change that breaks the script can be fixed in a matter of hours or 1-2 days instead of weeks or months.
Yeah with the amount of development effort and workarounds that go into keeping youtube-dl working for all changes and edge cases, it's just impractical to use anything else.
Thank you. That was very helpful.
The difference here is that Params::Validate is installed with Perl, as least on our production systems, whereas Params::ValidationCompiler isn't, and would need to be vetted and tested and installed. And besides, P::V has an installable deb (and rpm) file in apt/yum, and P::VC doesn't. That's the problem with updated libraries and their low adoption rate...
You're welcome. I should note that I promised Joel five articles and got away with four because so many other people contributed!
If comparing it to Python (which is natural) I find that Perl's DBI module is still much more flexible and performant than database modules provided by Python.
There's still plenty of new Perl development happening (though nothing like it was in the 90s and early 2000s). If you're interested in web development, check out Mojolicious and projects made with Mojolicious. That's the most interesting and modern Perl stuff I know of happening right now. Mojolicious is excellent in absolute terms; not even needing to be prefaced with "for a Perl project". It holds up well against the best small web frameworks and toolkits in any language, I think.
Sure will check that out! 
We learned perl in school for Windows management, especially with LDAP, active directory and com objects.
&gt; even some people said Perl is dead! https://metacpan.org/recent &gt; I started searching for some projects to improve my skills in Perl &gt; I just wanna know if I could find some projects on Perl Grep for `NEEDHELP`, `HANDOFF` or `ADOPTME` in &lt;https://www.cpan.org/modules/06perms.txt&gt; (2.3 MiB). Fix bugs in projects that are central because they have greater impact: &lt;http://neilb.org/2016/01/26/river-head-quality.html&gt;
&gt; open my $fh, "&lt;:encoding(utf8)", $file || die "Could not open $file $!\n"; This is a bug. The symptom is that even when the file fails to open (try with a non-existing file name), you will get no exception. The reason is the [precedence of the `||` operator](http://p3rl.org/op#List-Operators-%28Rightward%29), it binds `$file` and the `die` expression tightly. Since `$file` is always defined, `die` will short-circuit and never execute. To fix the bug, either surround the `open` arguments in parentheses `()`, or replace `||` with `or`. For the rest of the program, I didn't bother with it because the problem description in prose is really too difficult to understand and you neglected to provide a sample input file and sample intended output.
Ok thanks , will reword and give a better example after my work day is finished. I appreciate the input
I personally wouldn't expect it to, since it's trying to decide what kind of regex to build to match the route path (replacing `/:username` with `/(?&lt;username&gt;[^/]+)` or `(?:/(?&lt;username&gt;[^/]+))?` depending on if there's a default), and it doesn't look anywhere else for that. If it did, other things would behave differently: Moving routes to other parents would have to change what the route matches based on whether the new parent has a default assigned for that stash value.
So the documentation is wrong/incomplete?
The two lines you quoted don't say that the placeholder defaults come from the stash, only that the matched placeholder values will write to the stash. You're defining default values for the placeholders, which will also be added to the stash. The docs aren't wrong, and I wouldn't say they're incomplete: You inferred this was bidirectional, but it isn't. It could perhaps be clarified that placeholder defaults aren't inherited from parent routes.
Sorry, I should've included an additional line from the docs: &gt; One more interesting effect, a placeholder automatically becomes optional if there is already a stash value of the same name present, this works similar to the regular expression ([^/.]+)?.
To avoid loading/searching the whole file yourself you can also use https://cpanmeta.grinnz.com/perms#ADOPTME~
&gt;pretty much I understood the syntax https://i.imgur.com/5r33ix7.png
Metacpan is your friend. Perldoc is your friend. Perlmaven can help you get started. Perl isn't dead, in the sense that it still has a passionate vibrant community. Perl is dead in that new corporations aren't touching it, perl jobs are mostly maintenance of legacy platforms. &amp;#x200B; But it's a cool old language that's unparalleled at text processing and comes preinstalled on \*nix systems and still has some fantastic modern libraries and web frameworks (mojolicious). As for modern uses of perl, I'm actually fairly shocked that it's not being widely used for AI since it's great at text processing, but I'm not really sure that anybody is professionally doing anything with modern perl apart from hobbyists and evangelists. 
&gt; if (@$row[0] = $infoHash{Unique ID}) Single "=" is assignment, not comparison. It returns the result of the assignment, for chaining. Thus, in this case, it always returns a true value
To add to this, OP shouldn't be using = anyway, since they're comparing strings. You want to use eq instead.
If you're not on [perlmonks.org](https://perlmonks.org), you might benefit from it. Being able to see the code that others offer as solutions is insightful.
If you're*searching for* a unique ID, then why not use a HoH indtead, unique ID as the key? (Or, in your case, HoA, as your record is an array. my %data; while( my $row = ... ) { $data{$row-&gt;[0]} = $row; } And now the record you want is in `$data{$infoHash{'Unique ID'}`. 
Thanks, idk why but I always forget about using "eq" when dealing with strings. Silly mistake on my part
Thank you! That makes sense
I appreciate the recommendation. That may be a better fit for the larger scope of the problem I am trying to solve. Thanks!
It's a bit nonintuitive if you're used to other languages that lack the distinction. I often have to remind myself that eq is a thing, then whether it's for numbers or strings. 
&gt; Perl is dead in that new corporations aren't touching it, perl jobs are mostly maintenance of legacy platforms. No. Almost all the Perl work I've done is new modern projects, not legacy platforms/applications. &gt; I'm not really sure that anybody is professionally doing anything with modern perl apart from hobbyists and evangelists. Taken a look at jobs.perl.org lately?
Could you give some examples? I find Python's database capabilities generally much more advanced that Perl offerings, particularly when it comes to async handling. See https://github.com/tortoise/tortoise-orm or https://github.com/05bit/peewee-async for example.
Your delimiter appears to be a comma. Try https://perldoc.perl.org/functions/split.html using that. 
I'd suggest splitting on comma and taking the first and last fields as columns 1+3. Then join the others back together for column 2. This allows commas in the second field, even though that's wrong. chomp $line; my @fields = split /,/, $line; my $index = shift @fields; my $price = pop @fields; my $name = join ',', @fields; &amp;#x200B;
Use Text::CSV. I understand that you had problems in the past, but it's better to come to us asking for help with the Text::CSV code that doesn't work than with the regex code that doesn't work.
Text::CSV_XS ;)
Hmm... I don't have any use cases that would use an ORM or even require asynchronous writes and reads. I deal mostly with writing large bulk log files into SQL (all different flavors: My, Postgres, MS). My last attempt to port some of these tasks into Python was last year and I used the community recommended Python Postgres modules (i apologize but it was a while ago and I can't remember their names). If I remember correctly they didn't offer true support for prepared statements and were orders of magnitude slower than the same task using Perl's DBI module.
OP said: &gt; I have tried to use the text::csv in the past and that does not work in my environment. but Text::CSV (or the faster Text::CSV_XS) is so useful that it's worth the trouble to get it working. Of course, OP didn't elaborate WHY it didn't work -- was it trouble installing the package? Trouble figuring out how to use it? (It's powerful, but there is a learning curve). It would help to know why it didn't work.
Turns out this annoyed me (having to write and configure a layout) while working on another application, so I added it. Version 0.004 automatically adds the script with a hook if the script hasn't already been added, along with a way to disable it if the automatic detection is misbehaving.
And I answered none of them! The number of people answering was surprising too. ikegami wasn't the majority of the answers.
I suspect that by absolute numbers there are more perl programmers today than there were in the 90's. Of course that is true of almost any language you care to mention. As a percentage though the portion using perl is going down. Paraphrasing Uncle Bob Martin: "There is a 5% growth rate year over year in people who make a living writing programs." This means that at any given time most programmers have less than 5 years experience. At the same time the demand continues to exceed the supply.
Your question makes zero sense and isn’t even a question nor does it link to anything to do with Perl. 
I haven't kept up with recent changes to the language, but https://github.com/zentyal/zentyal/blob/master/main/core/src/EBox/Validate.pm from that linked issue looks very much like Perl to me... /u/unquietwiki any chance you could provide more details? Some sample input+output might be a good start.
Well, when the services run, it edits some BIND zone configs to match the given subnets in the system. I was able to patch the files to not explicitly disable IPv6 functions; but was having trouble figuring out how to get it to generate a non-blank reverse address filename to put in the config. http://www.zytrax.com/books/dns/ch3/#ipv6 has some examples of what it's supposed to look like. Honestly I figure all the lookups could go to an "IPv6" file, since I doubt anyone's using this software to run huge zones (plus it's GUI-abstracted anyway).
I'm sorry if I wasn't clear enough on what I was asking for. Basically I was able to fix a fair bit of a Perl-backend issue; but my knowledge of Perl &amp; available free time haven't been conducive to completely solving the issue.
Actually, the "workaround" in Perl is even easier than that: $ perl -Mbignum -e 'print 9999999999999999.0-9999999999999998.0' 1 
 $ perl -e 'print 9999999999999999 - 9999999999999998; print "\n";' 1 Please read up on floating point numbers, their properties, and how they should be used.
Also: $ perl -e 'print(sprintf "%19.1f", 9999999999999999.0); print "\n";' 10000000000000000.0 $ perl -e 'print(sprintf "%19.1f", 9999999999999998.0); print "\n";' 9999999999999998.0 &amp;#x200B;
Pick a distro you like and copy that. I prefer the Makefile.pl one over Build.pl for no logical reason. Recently I’ve stepped away from cpanfiles to installing OS modules because Docker.
&gt; I prefer the Makefile.pl one over Build.pl What do you mean by the Makefile.pl one? &gt; Recently I’ve stepped away from cpanfiles to installing OS modules because Docker I don't understand this. Can't cpanfiles be used with Docker? I would think installing OS specific dependencies would be harder if your module is used by many people with different OS's.
Yeah, we use cpanfile with docker since you are isolated and free to depend on whatever version you want. Bleeding edge or extremely conservative. Our pipeline supports both dist::zilla and Minilla. We have no standard, but dist::zilla is neat with our pipeline because versions are automatically generated in order to do slick rolling releases with CICD. At least on the apps. Some libraries use Minilla for more explicit versioning. 
&gt; CICD Oh, Dist::Zilla helps with deployment? &gt; Minilla for more explicit versioning Would you mind explaining what you mean here? 
Most Dist::Zilla setups we have use a version number derived from the timestamp of the build. While with Minilla the style is usually semver.
Yes, but OS gives a static baseline.
This is an interesting one to discuss... the perl insiders seem to allergic to endorsing Best Practices in this area, but I can give you a run-down of my current attempts at coming up with some on my own: In brief, I use Dist::Milla with Module::Build::Tiny for basic work. If I needed to do something like XS modules (perl extensions in C), I would probably go back to h2xs, possibly with ExtUtils::MakeMaker. I typically use my own emacs lisp package perlnow.el to drive this process, which swaps in my own code templates (template.el) for the stubs that Dist::Milla creates. These templates have (among other things) pod frameworks that I fill-in to add documentation. Dist::Milla is a variant of Dist::Zilla which I use on the assumption that Miyagawa knows what he's doing, but the documentation is a bit sketchy on things he probably thought were obvious, so you may have to play with it to understand exactly what it does and doesn't do. The h2xs script ships with perl, and ExtUtils::Makemaker is the original (perhaps old-fashioned) way of doing CPAN modules-- it creates a Makefile.PL script, which generates a Makefile which is used by some version of the old make program. EU::MM (as it's called for short) clearly does the job-- most of CPAN is based on it-- but it has a reputation for being janky to extend and the thought of working on it apparently gives it's maintainers the jitters. Module::Build was an attempt at replacing EU::MM-- it generates a Build.PL script that does directly what the old Makefile.PL/make lash-up did. I don't think there's any strong contender for an alternative to these two approaches. I use Module::Build::Tiny by default, a minimal alternative to M::B. 
Got it, thanks!
&gt; Dist::Milla with Module::Build::Tiny Could you explain why you need both of these? Previously when I used Dist::Zilla that was all I used, but I guess maybe it used something like Module::Build under the hood for me?
Well, I see that dzil has plugins for both M::B and M::B::T, I don't know off-hand which one it uses by default. Dist::Milla uses M:B:T. At some point it occurred to people that the problem of creating a package and the work that gets done to install it are different enough to separate them. A virtue of setting things up this way is the creation code (dzil, milla) can be heavy-weight but you can keep the installation code (Builder.PL) light-weight.
Awesome. Thanks for the explanation :)
&gt; I'm not clear on all of the differences on these, or why I would use one over the other. The Dist::Milla documentation gives [a pretty clear explanation](https://metacpan.org/pod/Dist::Milla#FAQ) about how Dist::Milla is different from Dist::Zilla. It's basically an "opinionated thin wrapper" over Dist::Zilla. ShipIt is MIYAGAWA's previous effort and I think it's safe to say that it's now abandoned in favor of Dist::Milla. App::git::ship documentation also says how it's different from Dist::Zilla: "App::git::ship differs from other tools like dzil by NOT requiring any configuration except for a file containing the credentials for uploading to CPAN." I believe it's far less popular than Dist::Zilla. In short, it's pretty safe to go with Dist::Zilla (or Dist::Milla). It's easy to find or write plugins to do what you want. For writing documentation, plain POD is recommended. For testing, the majority uses Test::Simple or Test::More. If you find a test module that can make your life easier, by all means use it. Dist::Zilla does not dictate what testing framework you should use. 
&gt;Recently I’ve stepped away from cpanfiles to installing OS modules because Docker. This seems unrelated to the question (how do I do configuration management for CPAN modules I write?) and focus on how \*you\* install/manage dependencies in your own application deployments. &amp;#x200B;
ack 3.0
&gt; how they should be used. ["Not at all" is a good rule of thumb.](https://duckduckgo.com/?q=site%3Ablog.plover.com+"floating-point")
With [-Dusemorebits](https://metacpan.org/pod/release/XSAWYERX/perl-5.28.0/INSTALL#%22more-bits%22): › perl -E'say 9999999999999999.0-9999999999999998.0' 1 › perl -E'say sprintf "%.64f", 9999999999999999.0-9999999999999998.0' 1.0000000000000000000000000000000000000000000000000000000000000000 It's only more precise, but not bullet-proof like bignum. › perl -E'say 0.1 + 0.2' 0.3 › perl -E'say sprintf "%.64f", 0.1 + 0.2' 0.3000000000000000000108420217248550443400745280086994171142578125 ---- See also: https://0.30000000000000004.com/ https://floating-point-gui.de/
Module::Build::Tiny and Module::Build are installers. So is ExtUtils::MakeMaker. These are the only installers (so far) that anyone uses, so dzil will use one of them. (Module::Install is an ExtUtils::MakeMaker wrapper.) ExtUtils::MakeMaker and Module::Build have the (flaw?) feature that they also can be used as an authoring tool, but Module::Build::Tiny is only an installer, and dzil is only an authoring tool. Dist::Zilla itself has no default installer, but the @Basic bundle as well as my @Starter bundle default to ExtUtils::MakeMaker, and the @Milla bundle (as well as its sister project Minilla) defaults to Module::Build::Tiny. My rule of thumb for which installer to use is: Default to [ModuleBuildTiny], if you want to support 5.10 use [ModuleBuildTiny::Fallback] which includes fallback code using Module::Build that will only run on CPAN installers too old to understand configure requires, and if you want to support 5.8 either add [MakeMaker::Fallback] to that (since 5.8 does not come with Module::Build), or just use [MakeMaker] at that point to simplify things. The nice thing about the separation of distribution builder and installer is that you can freely switch between these as desired or required without rewriting your whole config. I don't recommend using Module::Build (other than the fallback module mentioned above) or Module::Install because the former is maintained approximately as actively as ExtUtils::MakeMaker and is less supported, and the latter is at this point virtually unmaintained.
This seems odd - dzil is infinitely configurable, so it can of course be configured to version in whatever style you want.
To comment on the authoring tool side of things. There are so many choices because authoring is a very opinionated task and people don't find what they want in existing tools and create their own. Dist::Zilla is more of an authoring tool framework, you can use it directly and whatever plugins you desire, but you can also use bundles like Milla and Starter that do most of the setup for you, and then continue to customize your configuration with Dist::Zilla plugins. Minilla is a sister project to Dist::Milla that by default does almost the exact same things, but isn't built on Dist::Zilla, so you can only customize it to the extent of the configuration parameters it accepts; you can upgrade to Dist::Milla if you really want more customization. [mbtiny](https://metacpan.org/pod/mbtiny) is another one worth mentioning, as it's an extremely minimalist authoring tool that sets up your dist to use the extremely minimalist installer Module::Build::Tiny. But just be aware that for users with the stock CPAN.pm on 5.10 or older, MBT alone as the installer won't work automatically as it won't know to install MBT first (cpanm or an up to date CPAN.pm will work fine) - see my other comment regarding the installers.
Awesome, thank you for the super detailed explanation :)
Thank you! That helps :)
Odd? I think you are misinterpreting. We have both, not because we have to, but because of different preferences. And then I just gave examples. Not saying there are problems with either. We simply support both in our pipeline so you can choose. 
I meant that anything you can do with Minilla can also be done in dzil, so the version style being used with it isn't particularly a reason to use Minilla, there are of course plenty of other reasons though.
Yeah, never meant to imply that Dzil lacks anything. We just have both in use, and in our case that is how they usually are used (although I expect more Dzil in the future because of CICD) 
⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿ contact my author, u/solodas to rant about how you hate this bot and how it should be banned.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/perl6] [YAPC call for papers](https://www.reddit.com/r/perl6/comments/adx5z8/yapc_call_for_papers/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I'm surprised nobody mentioned bioinformatics yet. Many important types of molecules (e.g. proteins) have a chain structure, so they can be expressed with strings, and string processing is where Perl excels at.
My coworkers get on my case for using parens when not strictly necessary. But precedence is the source of quite a few perl bugs, and parens remove any ambiguity. I learned perl before and/or were added, and I remember years ago referencing this page: [https://www.perlmonks.org/?node\_id=570885](https://www.perlmonks.org/?node_id=570885) to ferret out this exact bug in a legacy codebase.
Another "one more approach" is to use [File::Open](https://metacpan.org/pod/File::Open) which provides very nice interfaces to open and sysopen that throw exceptions automatically. Path::Tiny and Mojo::File also provide similar functionality if you're already using one of those.
Most of the time 'or' is a better choice than '||'.
The common case where `||` is what you want is assignment: `my $foo = $bar || 'default';` Again due to precedence, but this time you want it to bind tighter than the assignment, otherwise $bar will always be assigned and then the logic operator does nothing. At least there's a warning in this case.
// saves lives.
Shame there's no `dor` operator yet...
I always use "or" when opening files along with the parentheses, the only time i use the "||" operator is within conditional statements. Then again, that is just me.
What a longwinded way to state that there's an operator precedence problem.
shame, I still support Debian Sarge systems that are stuck on v5.8 Perl. :'(
I believe this problem is mentioned in ye olde Camel book.
Perlbrew is your friend
Here's the heuristic that makes the precedence Just Work(tm): * Use "or" for control flow, e.g. `open or die;` * Use "||" for expressions, e.g. `my $log = $args-&gt;{log} || $DEFAULT_LOG;` This way it's also more clear what you're reading, because the two different things look different.
This article makes me think more about `autodie`. Is it still not recommended for general use?
Thanks for this... would love to see a small section on the usage of PAUSE. I've got a permission to fix a small bug in an existing module but I'm stuck at not knowing what my PAUSE upload will result in.
It basically works like this: Any CPAN author can upload whatever they want to their CPAN directory, but in order for it to get indexed (installable by module name) you need to satisfy certain conditions. These are detailed in the [PAUSE operating model](https://github.com/andk/pause/blob/master/doc/operating-model.md) but in short: * tarball should be in the format Dist-Name-X.Y.tar.gz * -TRIAL after the version, or an underscore in the version, will prevent any indexing * release_status metadata of 'testing' or 'unstable' will prevent any indexing * must contain a module with a name matching the Dist-Name * uploader must have permissions for this main module Then to determine if each module in the dist is indexed separately: * module ignored if no_index excludes it, or * module ignored if there's a newline in the package declaration, or * module version taken from provides metadata if present, or * module $VERSION line evaluated by itself to determine the module version * module version must be a higher version than the currently indexed version as compared by version.pm * module ignored if there's an underscore in its version * uploader must have permissions for module If all of this is satisfied, the module will be indexed in [02packages](https://cpanmeta.grinnz.com/packages) which is then used by CPAN clients to install the appropriate distribution by module name. If not, a secondary email from PAUSE will indicate any errors in the indexing process (unless it was determined to be a trial/dev release, in which case this email is not sent).
Also discussed on [perlmonks](https://perlmonks.org/?node_id=1227454)
those are on-board ships, with limited and expensive net access
Yiu might reconsider using the Babel esque approach of "compiling" your code into an oldr version of Perl, once you're happy with its workings. After all, there not much use of processing this translation on ever single call, you might just do it once. I can't point you to a module directly, but I'm sure the Perl Advent calendar from a month ago had an article about this very subject. http::/perladvent.org
I'm personally think that static type checking is the way to go in pretty much everything. However, I don't advocate for heavy java-type strictness, but the hybrid approaches such as in TypeScript. The key benefit we're after is getting some assurance of program correctness before it is run. I personally think the sweet spot in typing is some kind of flow-based typing where you can avoid writing type descriptions but the language is simple enough that its IDE and compiler can figure out what is true about the contents of variables at any point of the program, e.g. "here it can be undefined or a number, now we test that it's not undefined, so afterwards it can only be a number" and using that to ensure nullability correctness and catch invalid operations and method accesses for you. TypeScript is a pretty good example of what I regard as ideal: you pretty much never spell type information anywhere, and yet the language knows when you're making a mistake without even running the code. Unfortunately for Perl, it is difficult to parse for IDEs and rather than getting type checking at static analysis time, it gets pushed to runtime where it incurs additional overhead.
It is, just be aware of the [known bugs](http://p3rl.org/autodie#BUGS). If you hesitate because of what tchrist said, ignore him.
[I was able to explain it in one paragraph.](http://redd.it/a9kmem#eckzbq0)
Please provide the whole log.
There are a few approaches to dealing with the performance overhead. One is to add type validation everywhere, and then you convert that to comments/docs (so you retain the programmer communication benefit) when you actually notice that something is slow. Either a) profile things to see where, or b) just go for the obvious culprits like code running in inner loops and such. But do measure somehow. And don't assume that removing type validation is the most important thing to optimize. Another is to pick the places where you add type validation with some care, and where it matters the most. Obvious places are where you think you might get something wrong, or where you actually do find things go wrong. Another thing to think about are places that might need more documentation to provide a clear API. In a dynamic language this is something that needs to be dealt with, and type validation can help there. Other places are system/subsystem boundaries. E.g. in a MVC structured application, ensure that things passed down from the Controllers are type validated (aside from any business validation already performed), and then rely on things being correct enough and clear enough within that layer. Good naming is essiential, but even moreso here. Lastly, a distinction could be made between public/private methods/subs. Skip validation for private methods. That could also be a forcing function to reduce the number of public methods (within an application I don't normally find that very useful because you need to know what's going on anyway, for library modules/classes it's more important to reduce the API surface). On a Perl note: * I find that the most useful place to put type validation is on class attributes. Those are the big building blocks of data that are important to get right, and other wiring errors will reveal themselves in time. But that could just be my programming style. * Most of the common modules make validation errors unbearably ugly, and unusable for showing to end users (and it seems inordinately difficult to turn them into user facing messages). You might say that's not the use case for them, but I think that's a great missed opportunity. 
I use Moops/Kavorka, too, in fact I don't even get up for a programming language anymore unless it has convenient syntax and typechecking like that. Thus, in your figurative balance I sit squarely on the one scale pan. Performance has never been a problem: echoing what /u/jplindstrom said, using a [profiler](http://p3rl.org/Devel::NYTProf) reveals that the application code always dominates, not the generated desugared code. Could it be altogether faster in absolute measurements? Sure. But do I want to trade in the convenience I get out of the sugar modules? Nope. The problems have been of different nature: * [RT#97782](https://rt.cpan.org/Public/Bug/Display.html?id=97782) misparsing of certain default value declarations * [RT#99115](https://rt.cpan.org/Public/Bug/Display.html?id=99115) coverage contains unwanted info Still, would rather suffer those than not having the sugar and types.
I don't use type checking personally, but modules like [Type::Tiny::XS](https://metacpan.org/pod/Type::Tiny::XS) and [MooX::TypeTiny](https://metacpan.org/pod/MooX::TypeTiny) can provide free performance boosts if you're making use of the related types.
An interesting set of questions here. Could it be that type checking is something that's largely useful during development, but afterwards it largely just becomes a useless performance hit? So being able to shut-off your type-checking in production might be a win. Note: I presume we're doing validation of user input separately from type checking. Personally, I've never been fanatic about doing type checking on the perl-side, but I really like using relational databases on the back-end, and it annoys me when I see a schema that doesn't use the RDMS features to validate the data. I sometimes wonder if that's a contradiction or a sensible hybrid strategy.
cpanm (App::cpanminus) 1.7044 on perl 5.026001 built for x86\_64-linux-gnu-thread-multi Work directory is /root/.cpanm/work/1547228874.31 You have make /usr/bin/make You have LWP 6.36 You have /bin/tar: tar (GNU tar) 1.29 Copyright (C) 2015 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;[http://gnu.org/licenses/gpl.html](http://gnu.org/licenses/gpl.html)\&gt;. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. &amp;#x200B; Written by John Gilmore and Jay Fenlason. Searching Net::SSLeay () on cpanmetadb ... \--&gt; Working on Net::SSLeay Fetching [http://www.cpan.org/authors/id/M/MI/MIKEM/Net-SSLeay-1.85.tar.gz](http://www.cpan.org/authors/id/M/MI/MIKEM/Net-SSLeay-1.85.tar.gz) \-&gt; OK Unpacking Net-SSLeay-1.85.tar.gz Entering Net-SSLeay-1.85 Checking configure dependencies from META.yml Checking if you have ExtUtils::MakeMaker 6.58 ... Yes (7.24) Configuring Net-SSLeay-1.85 Running [Makefile.PL](https://Makefile.PL) \*\*\* Found OpenSSL-1.1.0g installed in /usr \*\*\* Be sure to use the same compiler and options to compile your OpenSSL, perl, and Net::SSLeay. Mixing and matching compilers is not supported. Do you want to run external tests? These tests \*will\* \*fail\* if you do not have network connectivity. \[n\] n Checking if your kit is complete... Looks good Generating a Unix-style Makefile Writing Makefile for Net::SSLeay Writing MYMETA.yml and MYMETA.json \-&gt; OK Checking dependencies from MYMETA.json ... Checking if you have MIME::Base64 0 ... Yes (3.15) Checking if you have ExtUtils::MakeMaker 0 ... Yes (7.24) Checking if you have Test::More 0.60\_01 ... Yes (1.302073) Building and testing Net-SSLeay-1.85 cp lib/Net/SSLeay.pm blib/lib/Net/SSLeay.pm AutoSplitting blib/lib/Net/SSLeay.pm (blib/lib/auto/Net/SSLeay) blib/lib/Net/SSLeay.pm: some names are not unique when truncated to 8 characters: directory blib/lib/auto/Net/SSLeay: do\_https3.al, do\_https2.al, do\_https4.al, do\_https.al truncate to do\_https do\_httpx3.al, do\_httpx2.al, do\_httpx4.al truncate to do\_httpx get\_https.al, get\_https3.al, get\_https4.al, get\_http.al, get\_http3.al, get\_http4.al, get\_httpx.al, get\_httpx3.al, get\_httpx4.al truncate to get\_http head\_https.al, head\_https3.al, head\_https4.al, head\_http.al, head\_http3.al, head\_http4.al, head\_httpx.al, head\_httpx3.al, head\_httpx4.al truncate to head\_htt post\_https.al, post\_https3.al, post\_https4.al, post\_http.al, post\_http3.al, post\_http4.al, post\_httpx.al, post\_httpx3.al, post\_httpx4.al truncate to post\_htt put\_https.al, put\_https3.al, put\_https4.al, put\_http.al, put\_http3.al, put\_http4.al, put\_httpx.al, put\_httpx3.al, put\_httpx4.al truncate to put\_http ssl\_read\_all.al, ssl\_read\_until.al, ssl\_read\_CRLF.al truncate to ssl\_read ssl\_write\_all.al, ssl\_write\_CRLF.al truncate to ssl\_writ tcp\_read\_all.al, tcp\_read\_until.al, tcp\_read\_CRLF.al truncate to tcp\_read tcp\_write\_all.al, tcp\_write\_CRLF.al truncate to tcp\_writ cp lib/Net/SSLeay.pod blib/lib/Net/SSLeay.pod cp lib/Net/SSLeay/Handle.pm blib/lib/Net/SSLeay/Handle.pm Running Mkbootstrap for SSLeay () chmod 644 "[SSLeay.bs](https://SSLeay.bs)" "/usr/bin/perl" "-Iinc" -MExtUtils::Command::MM -e 'cp\_nonempty' -- [SSLeay.bs](https://SSLeay.bs) blib/arch/auto/Net/SSLeay/SSLeay.bs 644 "/usr/bin/perl" "-Iinc" "/usr/share/perl/5.26/ExtUtils/xsubpp" -typemap '/usr/share/perl/5.26/ExtUtils/typemap' -typemap '/root/.cpanm/work/1547228874.31/Net-SSLeay-1.85/typemap' SSLeay.xs &gt; SSLeay.xsc mv SSLeay.xsc SSLeay.c x86\_64-linux-gnu-gcc -c -I/usr/include -D\_REENTRANT -D\_GNU\_SOURCE -DDEBIAN -fwrapv -fno-strict-aliasing -pipe -I/usr/local/include -D\_LARGEFILE\_SOURCE -D\_FILE\_OFFSET\_BITS=64 -O2 -g -DVERSION=\\"1.85\\" -DXS\_VERSION=\\"1.85\\" -fPIC "-I/usr/lib/x86\_64-linux-gnu/perl/5.26/CORE" SSLeay.c SSLeay.xs: In function ‘XS\_Net\_\_SSLeay\_CTX\_tlsv1\_new’: SSLeay.xs:1808:6: warning: ‘TLSv1\_method’ is deprecated \[-Wdeprecated-declarations\] RETVAL = SSL\_CTX\_new (TLSv1\_method()); \^\~\~\~\~\~ In file included from /usr/include/openssl/ct.h:13:0, from /usr/include/openssl/ssl.h:61, from SSLeay.xs:167: /usr/include/openssl/ssl.h:1624:1: note: declared here DEPRECATEDIN\_1\_1\_0(\_\_owur const SSL\_METHOD \*TLSv1\_method(void)) /\* TLSv1.0 \*/ \^ SSLeay.xs: In function ‘XS\_Net\_\_SSLeay\_CTX\_tlsv1\_1\_new’: SSLeay.xs:1817:6: warning: ‘TLSv1\_1\_method’ is deprecated \[-Wdeprecated-declarations\] RETVAL = SSL\_CTX\_new (TLSv1\_1\_method()); \^\~\~\~\~\~ In file included from /usr/include/openssl/ct.h:13:0, from /usr/include/openssl/ssl.h:61, from SSLeay.xs:167: /usr/include/openssl/ssl.h:1630:1: note: declared here DEPRECATEDIN\_1\_1\_0(\_\_owur const SSL\_METHOD \*TLSv1\_1\_method(void)) /\* TLSv1.1 \*/ \^ SSLeay.xs: In function ‘XS\_Net\_\_SSLeay\_CTX\_tlsv1\_2\_new’: SSLeay.xs:1828:6: warning: ‘TLSv1\_2\_method’ is deprecated \[-Wdeprecated-declarations\] RETVAL = SSL\_CTX\_new (TLSv1\_2\_method()); \^\~\~\~\~\~ In file included from /usr/include/openssl/ct.h:13:0, from /usr/include/openssl/ssl.h:61, from SSLeay.xs:167: /usr/include/openssl/ssl.h:1636:1: note: declared here DEPRECATEDIN\_1\_1\_0(\_\_owur const SSL\_METHOD \*TLSv1\_2\_method(void)) /\* TLSv1.2 \*/ \^ SSLeay.xs: In function ‘XS\_Net\_\_SSLeay\_RAND\_pseudo\_bytes’: SSLeay.xs:2707:9: warning: ‘RAND\_pseudo\_bytes’ is deprecated \[-Wdeprecated-declarations\] rc = RAND\_pseudo\_bytes(random, num); \^\~ In file included from /usr/include/openssl/crypto.h:32:0, from /usr/include/openssl/bio.h:20, from /usr/include/openssl/err.h:21, from SSLeay.xs:163: /usr/include/openssl/rand.h:47:1: note: declared here DEPRECATEDIN\_1\_1\_0(int RAND\_pseudo\_bytes(unsigned char \*buf, int num)) \^ &amp;#x200B;
SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_X509\_CRL\_get\_lastUpdate’: SSLeay.c:6247:2: warning: ‘X509\_CRL\_get\_lastUpdate’ is deprecated \[-Wdeprecated-declarations\] RETVAL = X509\_CRL\_get\_lastUpdate(x); \^\~\~\~\~\~ In file included from /usr/include/openssl/x509\_vfy.h:20:0, from /usr/include/openssl/x509.h:309, from /usr/include/openssl/ssl.h:50, from SSLeay.xs:167: /usr/include/openssl/x509.h:708:1: note: declared here DEPRECATEDIN\_1\_1\_0(ASN1\_TIME \*X509\_CRL\_get\_lastUpdate(X509\_CRL \*crl)) \^ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_X509\_CRL\_get\_nextUpdate’: SSLeay.c:6266:2: warning: ‘X509\_CRL\_get\_nextUpdate’ is deprecated \[-Wdeprecated-declarations\] RETVAL = X509\_CRL\_get\_nextUpdate(x); \^\~\~\~\~\~ In file included from /usr/include/openssl/x509\_vfy.h:20:0, from /usr/include/openssl/x509.h:309, from /usr/include/openssl/ssl.h:50, from SSLeay.xs:167: /usr/include/openssl/x509.h:709:1: note: declared here DEPRECATEDIN\_1\_1\_0(ASN1\_TIME \*X509\_CRL\_get\_nextUpdate(X509\_CRL \*crl)) \^ SSLeay.xs: In function ‘XS\_Net\_\_SSLeay\_X509\_get\_subjectAltNames’: SSLeay.xs:3410:26: warning: ‘ASN1\_STRING\_data’ is deprecated \[-Wdeprecated-declarations\] PUSHs(sv\_2mortal(newSVpv((const char\*)ASN1\_STRING\_data(subjAltNameDN-&gt;d.otherName-&gt;value-&gt;value.utf8string), ASN1\_STRING\_length(subjAltNameDN-&gt;d.otherName-&gt;value-&gt;value.utf8string)))); \^\~\~\~\~ In file included from /usr/include/openssl/bn.h:31:0, from /usr/include/openssl/asn1.h:24, from /usr/include/openssl/objects.h:916, from /usr/include/openssl/evp.h:27, from /usr/include/openssl/x509.h:23, from /usr/include/openssl/ssl.h:50, from SSLeay.xs:167: /usr/include/openssl/asn1.h:553:1: note: declared here DEPRECATEDIN\_1\_1\_0(unsigned char \*ASN1\_STRING\_data(ASN1\_STRING \*x)) \^ SSLeay.xs:3419:26: warning: ‘ASN1\_STRING\_data’ is deprecated \[-Wdeprecated-declarations\] PUSHs(sv\_2mortal(newSVpv((const char\*)ASN1\_STRING\_data(subjAltNameDN-&gt;d.ia5), ASN1\_STRING\_length(subjAltNameDN-&gt;d.ia5)))); \^\~\~\~\~ In file included from /usr/include/openssl/bn.h:31:0, from /usr/include/openssl/asn1.h:24, from /usr/include/openssl/objects.h:916, from /usr/include/openssl/evp.h:27, from /usr/include/openssl/x509.h:23, from /usr/include/openssl/ssl.h:50, from SSLeay.xs:167: /usr/include/openssl/asn1.h:553:1: note: declared here DEPRECATEDIN\_1\_1\_0(unsigned char \*ASN1\_STRING\_data(ASN1\_STRING \*x)) \^ SSLeay.xs: In function ‘XS\_Net\_\_SSLeay\_P\_X509\_get\_crl\_distribution\_points’: SSLeay.xs:3470:25: warning: ‘ASN1\_STRING\_data’ is deprecated \[-Wdeprecated-declarations\] XPUSHs(sv\_2mortal(newSVpv((char\*)ASN1\_STRING\_data(gn-&gt;d.ia5),ASN1\_STRING\_length(gn-&gt;d.ia5)))); \^\~\~\~\~\~ In file included from /usr/include/openssl/bn.h:31:0, from /usr/include/openssl/asn1.h:24, from /usr/include/openssl/objects.h:916, from /usr/include/openssl/evp.h:27, from /usr/include/openssl/x509.h:23, from /usr/include/openssl/ssl.h:50, from SSLeay.xs:167: /usr/include/openssl/asn1.h:553:1: note: declared here DEPRECATEDIN\_1\_1\_0(unsigned char \*ASN1\_STRING\_data(ASN1\_STRING \*x)) \^ SSLeay.xs: In function ‘XS\_Net\_\_SSLeay\_P\_X509\_get\_ocsp\_uri’: SSLeay.xs:3511:3: warning: ‘ASN1\_STRING\_data’ is deprecated \[-Wdeprecated-declarations\] XPUSHs(sv\_2mortal(newSVpv( \^\~\~\~\~\~ In file included from /usr/include/openssl/bn.h:31:0, from /usr/include/openssl/asn1.h:24, from /usr/include/openssl/objects.h:916, from /usr/include/openssl/evp.h:27, from /usr/include/openssl/x509.h:23, from /usr/include/openssl/ssl.h:50, from SSLeay.xs:167: /usr/include/openssl/asn1.h:553:1: note: declared here DEPRECATEDIN\_1\_1\_0(unsigned char \*ASN1\_STRING\_data(ASN1\_STRING \*x)) \^ SSLeay.xs: In function ‘XS\_Net\_\_SSLeay\_P\_ASN1\_STRING\_get’: SSLeay.xs:3829:9: warning: ‘ASN1\_STRING\_data’ is deprecated \[-Wdeprecated-declarations\] u8 = newSVpv((const char\*)ASN1\_STRING\_data(s), ASN1\_STRING\_length(s)); \^\~ In file included from /usr/include/openssl/bn.h:31:0, from /usr/include/openssl/asn1.h:24, from /usr/include/openssl/objects.h:916, from /usr/include/openssl/evp.h:27, from /usr/include/openssl/x509.h:23, from /usr/include/openssl/ssl.h:50, from SSLeay.xs:167: /usr/include/openssl/asn1.h:553:1: note: declared here DEPRECATEDIN\_1\_1\_0(unsigned char \*ASN1\_STRING\_data(ASN1\_STRING \*x)) \^ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_TLSv1\_method’: SSLeay.c:9278:2: warning: ‘TLSv1\_method’ is deprecated \[-Wdeprecated-declarations\] RETVAL = TLSv1\_method(); \^\~\~\~\~\~ In file included from /usr/include/openssl/ct.h:13:0, from /usr/include/openssl/ssl.h:61, from SSLeay.xs:167: /usr/include/openssl/ssl.h:1624:1: note: declared here DEPRECATEDIN\_1\_1\_0(\_\_owur const SSL\_METHOD \*TLSv1\_method(void)) /\* TLSv1.0 \*/ \^ &amp;#x200B;
SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_TLSv1\_server\_method’: SSLeay.c:9295:2: warning: ‘TLSv1\_server\_method’ is deprecated \[-Wdeprecated-declarations\] RETVAL = TLSv1\_server\_method(); \^\~\~\~\~\~ In file included from /usr/include/openssl/ct.h:13:0, from /usr/include/openssl/ssl.h:61, from SSLeay.xs:167: /usr/include/openssl/ssl.h:1625:1: note: declared here DEPRECATEDIN\_1\_1\_0(\_\_owur const SSL\_METHOD \*TLSv1\_server\_method(void)) /\* TLSv1.0 \*/ \^ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_TLSv1\_client\_method’: SSLeay.c:9312:2: warning: ‘TLSv1\_client\_method’ is deprecated \[-Wdeprecated-declarations\] RETVAL = TLSv1\_client\_method(); \^\~\~\~\~\~ In file included from /usr/include/openssl/ct.h:13:0, from /usr/include/openssl/ssl.h:61, from SSLeay.xs:167: /usr/include/openssl/ssl.h:1626:1: note: declared here DEPRECATEDIN\_1\_1\_0(\_\_owur const SSL\_METHOD \*TLSv1\_client\_method(void)) /\* TLSv1.0 \*/ \^ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_TLSv1\_1\_method’: SSLeay.c:9332:2: warning: ‘TLSv1\_1\_method’ is deprecated \[-Wdeprecated-declarations\] RETVAL = TLSv1\_1\_method(); \^\~\~\~\~\~ In file included from /usr/include/openssl/ct.h:13:0, from /usr/include/openssl/ssl.h:61, from SSLeay.xs:167: /usr/include/openssl/ssl.h:1630:1: note: declared here DEPRECATEDIN\_1\_1\_0(\_\_owur const SSL\_METHOD \*TLSv1\_1\_method(void)) /\* TLSv1.1 \*/ \^ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_TLSv1\_1\_server\_method’: SSLeay.c:9349:2: warning: ‘TLSv1\_1\_server\_method’ is deprecated \[-Wdeprecated-declarations\] RETVAL = TLSv1\_1\_server\_method(); \^\~\~\~\~\~ In file included from /usr/include/openssl/ct.h:13:0, from /usr/include/openssl/ssl.h:61, from SSLeay.xs:167: /usr/include/openssl/ssl.h:1631:1: note: declared here DEPRECATEDIN\_1\_1\_0(\_\_owur const SSL\_METHOD \*TLSv1\_1\_server\_method(void)) /\* TLSv1.1 \*/ \^ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_TLSv1\_1\_client\_method’: SSLeay.c:9366:2: warning: ‘TLSv1\_1\_client\_method’ is deprecated \[-Wdeprecated-declarations\] RETVAL = TLSv1\_1\_client\_method(); \^\~\~\~\~\~ In file included from /usr/include/openssl/ct.h:13:0, from /usr/include/openssl/ssl.h:61, from SSLeay.xs:167: /usr/include/openssl/ssl.h:1632:1: note: declared here DEPRECATEDIN\_1\_1\_0(\_\_owur const SSL\_METHOD \*TLSv1\_1\_client\_method(void)) /\* TLSv1.1 \*/ \^ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_TLSv1\_2\_method’: SSLeay.c:9387:2: warning: ‘TLSv1\_2\_method’ is deprecated \[-Wdeprecated-declarations\] RETVAL = TLSv1\_2\_method(); \^\~\~\~\~\~ In file included from /usr/include/openssl/ct.h:13:0, from /usr/include/openssl/ssl.h:61, from SSLeay.xs:167: /usr/include/openssl/ssl.h:1636:1: note: declared here DEPRECATEDIN\_1\_1\_0(\_\_owur const SSL\_METHOD \*TLSv1\_2\_method(void)) /\* TLSv1.2 \*/ \^ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_TLSv1\_2\_server\_method’: SSLeay.c:9404:2: warning: ‘TLSv1\_2\_server\_method’ is deprecated \[-Wdeprecated-declarations\] RETVAL = TLSv1\_2\_server\_method(); \^\~\~\~\~\~ In file included from /usr/include/openssl/ct.h:13:0, from /usr/include/openssl/ssl.h:61, from SSLeay.xs:167: /usr/include/openssl/ssl.h:1637:1: note: declared here DEPRECATEDIN\_1\_1\_0(\_\_owur const SSL\_METHOD \*TLSv1\_2\_server\_method(void)) /\* TLSv1.2 \*/ \^ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_TLSv1\_2\_client\_method’: SSLeay.c:9421:2: warning: ‘TLSv1\_2\_client\_method’ is deprecated \[-Wdeprecated-declarations\] RETVAL = TLSv1\_2\_client\_method(); \^\~\~\~\~\~ In file included from /usr/include/openssl/ct.h:13:0, from /usr/include/openssl/ssl.h:61, from SSLeay.xs:167: /usr/include/openssl/ssl.h:1638:1: note: declared here DEPRECATEDIN\_1\_1\_0(\_\_owur const SSL\_METHOD \*TLSv1\_2\_client\_method(void)) /\* TLSv1.2 \*/ \^ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_CTX\_get\_min\_proto\_version’: SSLeay.c:9587:11: warning: passing argument 3 of ‘SSL\_CTX\_ctrl’ makes integer from pointer without a cast \[-Wint-conversion\] RETVAL = SSL\_CTX\_get\_min\_proto\_version(ctx); \^\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~ In file included from SSLeay.xs:167:0: /usr/include/openssl/ssl.h:1599:6: note: expected ‘long int’ but argument is of type ‘void \*’ long SSL\_CTX\_ctrl(SSL\_CTX \*ctx, int cmd, long larg, void \*parg); \^\~\~\~\~\~\~\~\~\~\~\~ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_CTX\_get\_max\_proto\_version’: SSLeay.c:9606:11: warning: passing argument 3 of ‘SSL\_CTX\_ctrl’ makes integer from pointer without a cast \[-Wint-conversion\] RETVAL = SSL\_CTX\_get\_max\_proto\_version(ctx); \^\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~ In file included from SSLeay.xs:167:0: /usr/include/openssl/ssl.h:1599:6: note: expected ‘long int’ but argument is of type ‘void \*’ long SSL\_CTX\_ctrl(SSL\_CTX \*ctx, int cmd, long larg, void \*parg); \^\~\~\~\~\~\~\~\~\~\~\~ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_get\_min\_proto\_version’: SSLeay.c:9625:11: warning: passing argument 3 of ‘SSL\_ctrl’ makes integer from pointer without a cast \[-Wint-conversion\] RETVAL = SSL\_get\_min\_proto\_version(ssl); \^\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~ &amp;#x200B;
In file included from SSLeay.xs:167:0: /usr/include/openssl/ssl.h:1597:6: note: expected ‘long int’ but argument is of type ‘void \*’ long SSL\_ctrl(SSL \*ssl, int cmd, long larg, void \*parg); \^\~\~\~\~\~\~\~ SSLeay.c: In function ‘XS\_Net\_\_SSLeay\_get\_max\_proto\_version’: SSLeay.c:9644:11: warning: passing argument 3 of ‘SSL\_ctrl’ makes integer from pointer without a cast \[-Wint-conversion\] RETVAL = SSL\_get\_max\_proto\_version(ssl); \^\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~ In file included from SSLeay.xs:167:0: /usr/include/openssl/ssl.h:1597:6: note: expected ‘long int’ but argument is of type ‘void \*’ long SSL\_ctrl(SSL \*ssl, int cmd, long larg, void \*parg); \^\~\~\~\~\~\~\~ SSLeay.xs: In function ‘XS\_Net\_\_SSLeay\_RSA\_generate\_key’: SSLeay.xs:5443:9: warning: ‘RSA\_generate\_key’ is deprecated \[-Wdeprecated-declarations\] RETVAL = RSA\_generate\_key(bits, e, ssleay\_RSA\_generate\_key\_cb\_invoke, cb); \^\~\~\~\~\~ In file included from /usr/include/openssl/rsa.h:13:0, from /usr/include/openssl/x509.h:31, from /usr/include/openssl/ssl.h:50, from SSLeay.xs:167: /usr/include/openssl/rsa.h:193:1: note: declared here DEPRECATEDIN\_0\_9\_8(RSA \*RSA\_generate\_key(int bits, unsigned long e, void \^ SSLeay.xs: In function ‘XS\_Net\_\_SSLeay\_OCSP\_response\_results’: SSLeay.xs:6781:33: warning: passing argument 1 of ‘i2d\_OCSP\_CERTID’ discards ‘const’ qualifier from pointer target type \[-Wdiscarded-qualifiers\] int len = i2d\_OCSP\_CERTID(OCSP\_SINGLERESP\_get0\_id(sir),NULL); \^\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~ In file included from /usr/include/openssl/objects.h:916:0, from /usr/include/openssl/evp.h:27, from /usr/include/openssl/x509.h:23, from /usr/include/openssl/ssl.h:50, from SSLeay.xs:167: /usr/include/openssl/ocsp.h:336:1: note: expected ‘OCSP\_CERTID \* {aka struct ocsp\_cert\_id\_st \*}’ but argument is of type ‘const OCSP\_CERTID \* {aka const struct ocsp\_cert\_id\_st \*}’ DECLARE\_ASN1\_FUNCTIONS(OCSP\_CERTID) \^ SSLeay.xs:6790:23: warning: passing argument 1 of ‘i2d\_OCSP\_CERTID’ discards ‘const’ qualifier from pointer target type \[-Wdiscarded-qualifiers\] i2d\_OCSP\_CERTID(OCSP\_SINGLERESP\_get0\_id(sir),&amp;pi); \^\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~\~ In file included from /usr/include/openssl/objects.h:916:0, from /usr/include/openssl/evp.h:27, from /usr/include/openssl/x509.h:23, from /usr/include/openssl/ssl.h:50, from SSLeay.xs:167: /usr/include/openssl/ocsp.h:336:1: note: expected ‘OCSP\_CERTID \* {aka struct ocsp\_cert\_id\_st \*}’ but argument is of type ‘const OCSP\_CERTID \* {aka const struct ocsp\_cert\_id\_st \*}’ DECLARE\_ASN1\_FUNCTIONS(OCSP\_CERTID) \^ rm -f blib/arch/auto/Net/SSLeay/SSLeay.so x86\_64-linux-gnu-gcc -shared -L/usr -L/usr/lib -L/usr/local/lib -fstack-protector-strong SSLeay.o -o blib/arch/auto/Net/SSLeay/SSLeay.so \\ \-L/usr -L/usr/lib -lssl -lcrypto -lz \\ /usr/bin/ld: cannot find -lz collect2: error: ld returned 1 exit status Makefile:496: recipe for target 'blib/arch/auto/Net/SSLeay/SSLeay.so' failed make: \*\*\* \[blib/arch/auto/Net/SSLeay/SSLeay.so\] Error 1 \-&gt; FAIL Installing Net::SSLeay failed. See /root/.cpanm/work/1547228874.31/build.log for details. Retry with --force to force install it. &amp;#x200B;
Added as a comment.
That is an interesting idea about turning off the checking in production. It would be nice if there was an easy way to do this, so I could switch it on and off and easily benchmark it in production. 
&gt; /usr/bin/ld: cannot find -lz &gt; &gt; collect2: error: ld returned 1 exit status install [zlib1g-dev](https://packages.ubuntu.com/search?keywords=zlib1g-dev)
Do you mean you never use type checking, even with things like Moose objects? Would you mind explaining why? Has this not been an issue for you?
I use basic type checking in Moo when an attribute needs to be an object, with an -&gt;isa or -&gt;DOES or -&gt;can check. But for unblessed refs and scalars, I haven't had a problem with just using the attributes correctly. Perhaps I'm just used to garbage-in-garbage-out APIs from Mojo.
Ha, do you mind explaining that reference? Do you mean because Mojo::Base doesn't have types, so I assume most of Mojo doesn't use any typing? 
When I build that kind of applications, I use these modules: [Function::Parameters](https://metacpan.org/pod/Function::Parameters), [Moo](https://metacpan.org/pod/Moo) and [Type::Tiny](https://metacpan.org/pod/Type::Tiny)
Mojo by design does not use any typing or even basic argument checking in many cases, it operates under the assumption that the user will use APIs as documented and if they don't it's their own fault (hence garbage-in-garbage-out). Which is important for speed as the OP alludes to, as well as keeping the code leaner.
I see. Thanks! So I guess your recommendation for Mojo apps would just be to use the experimental signatures if you want any and to not using typing generally? With that path, do you have any recommendations for what the OP mentioned about named parameters? I typically use my %args = @_; But I have run into issues where the key is wrong. 
Fixed, THANK YOU!! &amp;#x200B;
How do you think this would help in my situation?
Yeah, somewhere in between Java and Perl could be nice. It's too bad there's no way for IDEs to check or the compiler. If the compiler did it for you, that would be really great.
Yeah, that's interesting. I suspected that Kavorka signatures wouldn't make much of a difference (still seem pretty fast for a small part of a web request). I wanted to get an idea before I committed to use Kavorka everywhere or experimental subs everywhere. It would be nice if there was an easy way to switch between the two to do general profiling, although I guess I could do this with one request method chain before I commit to anything. &amp;#x200B; But like you, I think I lean towards just using the sugar that Kavorka adds-- it's hard to give up! Especially the named parameters. Hopefully Perl 5 can add some of these features natively eventually. &amp;#x200B;
&gt;Function::Parameters Is there a reason you use this instead of Kavorka? I looked at both, and it seemed like Kavorka offered more functionality, which is why I chose it.
Open with utf8. It’s so much better now. On 5.8.8 it was a ‘mare. You might have some string/number issues. Validate as hard as you can. Remember JSON is better than YAML and XML.
XML is much abused, but it was designed with the notion of a schema. We can use the schema to validate. JSON is worse, IMHO. Neither is especially legible in the real world, so I will take *validatable*.
https://json-schema.org
Kavorka uses PadWalker and the deprecated Parse::Keyword (see its CAVEATS section). Function::Parameters is written directly using the keyword API by the guy who wrote Keyword::Simple. I'm not sure what functionality Kavorka offers beyond it but Function::Parameters has named parameters and support for several varieties of type objects.
I don't really have any recommendation in that regard, this is just what I prefer. If you want named parameters with validation, and the option for type checking too, Function::Parameters would be my recommendation.
I know of the project. But in the wild, JSON is... very wild. 
https://metacpan.org/pod/JSON::Schema
Sorry, what is what you prefer?
Not using type validation.
Ah, I see. Thanks for the replies!
Consider `Data::Diver` and evaluate usefulness is extracting data. My own use of it has been limited, but I found it useful in extracting data from complex and inconsistent data structures. If you want to "enforce" a structure on your data you could define a class that expects specific days elements to exist and have a given type/format. If the given date does not comply, you get and error and no object is instantiated. As you iterate through your data you try to instantiate an object and push them onto an array for later processing or even handle that processing immediately and move on, depending on you overall goal. As an additional feature, this object class can implement a serializer that could be leveraged if you need to eventually output a new data structure in JSON. 
\&gt; Any other tips to share for working with JSON? For me, alternating coffee, whiskey, and coffee with whiskey seems to help. &amp;#x200B; &amp;#x200B;
Honestly this is the only take I've heard on XML vs JSON that both favors XML and makes a reasonable point. +1 to you.
Last I looked, XML had no way of using more that one schema-- a current name space and the ability to access others via a dotted notation would seem to be fairly obvious, but it was one name space a time, or don't use schemas... 
I'd use [File::Slurper](https://metacpan.org/pod/File::Slurper) to read the file all at once.
There are many ways of doing this, but one option: use strict; use warnings; # try to get the print showing up, by default it'll be buffered # and may not have enough data to send to the terminal STDOUT-&gt;autoflush(1); print "Enter the first group of five numbers: "; if(my (@numbers) = &lt;&gt; =~ /^(\d) (\d) (\d) (\d) (\d)$/) { use List::Util qw(sum); print "Sum was: " . sum(@numbers) . "\n"; } else { print "That did not look like a group of 5 single-digit numbers, try again?\n"; } The `ARGV` in your Perl example is a bit odd: that'll be using the commandline parameters as if you were iterating through `*argv[]` in C. For that to work, I think you'd need to run as `perl script.pl '1 2 3 4 5'`. 
I was using &lt;STDIN&gt; but perlcritic complains that ARGV should be used instead. 
It shouldn't complain about the `&lt;&gt;` version - https://metacpan.org/pod/Perl::Critic::Policy::InputOutput::ProhibitExplicitStdin (this particular policy isn't something I'd leave enabled: STDIN is very different from "open the first file you see and use that instead"... if the programmer asks for STDIN, there's probably good reason for it!) 
[Variables with the same name but varying digits are a code smell](http://p3rl.org/Perl::Critic::Policy::Bangs::ProhibitNumberedNames), just use the appropriate compound data structure instead. I do not know your following code, but most likely it is going to be an array. ---- Much more ergonomic for the end user: use IO::Prompter; my $n = prompt 'Enter a five digit natural number: ', -integer =&gt; sub { $_ &gt;= 10_000 &amp;&amp; $_ &lt;= 99_999 }; my @digits = split //, $n; You will not lose the ability to supply input from STDIN, try: echo 45678 | perl reddit-afh87r.pl
One small general perl suggestion. You can replace this: my $g_jsontext; if ( -e $ARGV[0]) { local $/; #slurp mode open(my $fh,"&lt;",$ARGV[0]) or die "Could not open file ". $ARGV[0]."\n"; $g_jsontext=&lt;$fh&gt;; close $fh; } ... with this: local $/; my $g_jsontext=&lt;&gt;; In addition to more robust error handling, you automatically gain the ability to specify more than one file on the command line or read from stdin instead. &gt; Any other tips to share for working with JSON? I find jq (https://stedolan.github.io/jq/) really helpful. It's a command line utility for exploring and manipulating JSON data. At its most basic, you can drop some JSON into it and get color-coded pretty-printed output. That's only the tip of the iceberg, though. Here's a 4 minute overview: [jq JSON Processor Tutorial: How to access JSON data from the command line with the jq parser](https://www.youtube.com/watch?v=EvpwhGeiH0U)
Another option is to use Term::Readkey to read single characters. This is a lower level approach but may fit depending on your specific need.
Could you explain what the `-l` does here? It looks like it makes it so that newlines are printed, but the docs don't make it clear to me: &amp;#x200B; &gt;\-l\[octal\] enable line ending processing, specifies line terminator &amp;#x200B; Is it because you don't specify anything for `-l`, so undef is the line terminator and so it prints a newline? &amp;#x200B;
Okay, thanks for that! I will take another look :)
Pretty much, yes: it drops the \n on the way in - not something that makes a difference here - and adds an implicit one to each print statement. Quite useful when running perl as a filter on data. Could also write this as: perl -E'say for "12345" =~ /\d/g' 
Ah, got it. Thanks!
Hello, thanks for the suggestion. I'm aware of the terse version of the code. I wanted to be explicit in this post. I have used jq. It is fast but it is quirky, and I am careful of technical debt. This is not to say that Perl doesn't have quirks, but Perl is a general-purpose language and I can re-use the patterns that I develop. I've been coding in Perl for a long time and the stability and backwards-compatibility of Perl have made it an excellent technical choice. (I cannot say the same for Python!) 
&gt; JSON is better than YAML and XML. Why? (I own Data::HAL.)
you are right about code smell, but OP was probably using numbered variables as a method of reducing his code for the sake of the example. he prob is using meaningful names such as my($room,$drawer,. ..) in his real code. good to show that IO::Prompter has checking for sanity of input, but worth pointing out the C code doesnt fully do that. removing this checking reduces your code to nothing much different to OP's original perl code -- with the added disadvantage of installing and adding an extra module to his code.
I don't know if I'd use the word better, since all of them have pros and cons, but the benefit of JSON in my opinion is that a complete and correct parser and encoder can be implemented in [a 300 line module](https://metacpan.org/source/SRI/Mojolicious-8.11/lib/Mojo/JSON.pm). Even YAML's co-authors have had varying success getting complete and correct implementations on CPAN, and XML parsing is its own topic.
&gt; #encode the slurped data before decoding &gt; my $json_bytes = encode('UTF-8', $g_jsontext); I'm not sure why you added this, but don't. Files always contain bytes, so the bytes you read from the file are already encoded, and in this case almost certainly in UTF-8, so this line would only achieve double-encoding it, and your (correct) JSON decoding line after would only decode it once. I suggest reading through https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/ as it is very helpful in clearing up how character encoding actually works.
From what I recall Kavorka has working multi method dispatch that can work based on typing. However I never found a way to allow it to work in a first-matching-multi way, which made e.g. programming to interfaces (that could match multiple method candidates) runtime error.
I'm surprised the article makes not mention of the excellent WWW::Mechanize::Chrome module.
For me, it’s mostly intuitive preference:)
Thank you for your friendly amendments. The line in question is an artifact from one JSON test file that seems to contain troublesome characters. At the time of coding, I didn't have the liberty of digging deeper into the problem, but the re-encoding appeared to fix it. 
&gt; complete and correct parser https://i.imgur.com/m8r8YOY.png &gt; in a 300 line module [The XML parser is even shorter!111!1!123](https://www.xml.com/pub/a/w3j/s3.perl.html)
That's a good point, I forget how tricky the JSON edge cases can be. Cpanel::JSON::XS and JSON::PP are much more complex than Mojo::JSON due to their options, but do pretty well on that metric at least.
As a guess, you are probably printing directly to your terminal which expects UTF-8 encoded bytes, and thus without the extra encoding it seemed to fail. However this extra encoding step should be performed when printing or on STDOUT itself (by applying the `:encoding(UTF-8)` layer, but this is a global effect so can confuse other modules using STDOUT that don't expect it), you always want to be working with decoded characters within your program.
There is no such thing as "an XS version of a module". Some modules just have other modules which do the same thing but are XS, the standard is to append ::XS to the name but there is nothing beyond that. So just search https://metacpan.org.
That's what I was afraid of :( Well thanks for the response! I was just hoping there was something cool like [Perlbrew](https://perlbrew.pl/) that I didn't know about to solve my problems :)
PAUSE does not require an "XS version" distribution for another PP module to announce itself as such. Thus, the best one can do is currently to catalog manually. I'm starting one at [Acme::CPANModules::XSVersions](https://metacpan.org/pod/Acme::CPANModules::XSVersions). There is one-liner to install those modules for you in one go, see the doc. Additions welcome.
&lt;http://p3rl.org/cpanm#-with-recommends,-with-suggests&gt; does what you want. The magic to make this happen originates from the metafile in a distribution (e.g. see [META.json in Type-Tiny](https://metacpan.org/source/TOBYINK/Type-Tiny-1.004004/META.json#L66)). Unfortunately not all distributions who benefit from an XS counterpart recommend them in this machine-readable way. I encourage you to go through /u/perlancar++'s list and and file pull requests/wish tickets with the respective projects where missing.
yes, front page is down
The real unfortunate part of this is that recommends are not installed by default by CPAN installers, which sadly makes it useless for this purpose, requiring modules like JSON::MaybeXS to instead use dynamic dependencies to add Cpanel::JSON::XS as a required dependency if it's possible to install, otherwise 90% of users will not get it. (It does add it to recommends as well, though) In RPM and other dependency systems, recommends are installed by default but not required, and it's very useful this way. CPAN installers are not quite smart enough to do this properly even if the default was switched.
That's helpful, thanks! 
Just spitballing here... but you could make them pre-push hooks instead. Then you could process pull-requests locally, before pushing them up to the public git repo. https://github.com/git/git/blob/87c86dd14abe8db7d00b0df5661ef8cf147a72a3/templates/hooks--pre-push.sample
When it comes to PerlCritic, my thoughts is to integrate it into your editor. Works well with emacs.
The pre-push hook idea may be your best bet. I've implemented tidy and checking as part of my build process. &amp;#x200B; I have a script for check and a script to tidy. In my makefile I do the check first as .pl -&gt; .plc. I then do the tidy as .plc -&gt; .plt. Install then copies .plt to where it needs to go.
I don't think you can use Git to force a certain workflow onto others. For your own workflow, editor integration and/or pre-commit hooks are fine. For checking the contributions of other people, I just put a linting step into the CI tests (e.g. using Travis CI) that must pass before a pull request can be merged. You can also use [Test::Perl::Critic](https://metacpan.org/pod/Test::Perl::Critic). If you use dzil, there's a [plugin](https://metacpan.org/pod/Dist::Zilla::Plugin::Test::Perl::Critic) that generates an author-test for you. That makes the linting easy to install and run for contributors.
Hi! You can use [Tomtit](https://github.com/melezhik/tomtit) for this type of things, just create wrapper around your push command: ``` tom --edit push #!perl6 bash "perltidy script.pl"; # run PerlTidy for script.pl2 and so on task-run "push my changes", "git-push", %( confirm =&gt; "no" ); ``` And then run `git push` through it: `$ tom push`
The purpose of type checking is to catch human mistakes. So, whether or not they speed up your development is largely related to the humans doing the development. So, I don't think there can be one right answer. Additionally, the development practices you choose can change whether you are one of the developers who benefits from type checking or not. Back when I did Java development, I fell into the trap that I think most people fall into of trying to fully describe every aspect of my data with the type system. In the long run, I decided that I was wasting a massive amount of time on it. When I began doing lots of development in Perl, and saw that there were very real performance consequences of heavy typing in addition to the development costs, I started looking for ways to avoid needing it. And, I found what I was looking for in unit tests. Unit testing is a win in lots of aspects: - It catches a majority of the internal mistakes that a type system would have caught - Type systems can only catch consistency mistakes. Unit tests catch functionality mistakes, and everything that leads up to them. - Spending time on the unit tests has higher value than spending time on a type system - Perl's unit tests are easier to write than Java, and only cost about as much time as it would have taken to test the code manually a single time (which everyone needs to do anyway) - Designing code to be testable results in highly modular designs, which are then more re-usable and save time in other places The one thing unit tests don't catch are mistakes by 3rd parties when using your modules. If the third party also has unit tests, it doesn't matter, but I often add a bit of type-checking to help users on the constructors or methods which don't have an obvious list of arguments: sub method_foo { my ($self, $specific_thing)= @_; ref $specific_thing &amp;&amp; ref($specific_thing)-&gt;can('foo') or croak "Expected a specific_thing"; } Yes that would be prettier if I wrapped that test into a Type::Tiny, but then I'd need a type library and "use" it and come up with meaningful type names and it's honestly faster to just bang out that line while I'm in the middle of thinking about how to implement method_foo. Also, in the grand scheme of things, I couldn't care less whether the user is passing me the "correct type" as long as the thing they pass me supports the API it needs to support. So, I try to always use "duck typing" (test capability with 'can') rather than a type hierarchy. The one time I do use Type::Tiny is when I am interchanging data with a remote system. A great way to validate the records I receive is to make Moo classes with Type::Tiny restrictions on each of them, and rely on the Moo constructor to validate the data. The validation needs done at runtime anyway, so there's no lost performance, and the type system is a very pretty way to describe the data. 
That's not a bad idea. I'll have to figure out how to do this with vim, but I was looking more for a solution that kind of ensures these things are done when collaborating in a team.
Thanks, I will consider that! That works well in a scenario like a module that I receive pull requests to, but I was hoping to have an easy way to use this also in a team setting to make sure these things automatically happen.
Thanks! That's helpful. Having a Perl::Critic test seems like a good idea-- I'll have to see if there's a way to do this with Perltidy to see if it's run. &amp;#x200B; Do you know if Travis CI automatically runs all tests on pull requests?
I think there's a Perl Critic policy that ensures that the code is tidy as checked by perltidy. However, a test suite cannot/should not change the code to make it tidy. The .travis.yml file determines on which event Travis CI runs, so I'd have to look up the docs for details. But IIRC the tests run by default for PRs.
Cool, I will have to check this out!
Would you mind sharing the code in a Github gist? That sounds helpful!
You're going to need to make it happen at a central server then, rather than rely on each user to configure their repository correctly. But often you'll have one person who wrangles all of the commits into the final repository herself anyway, to provide a final quality control check. But i you really just want to let anyone commit to your repo, you can configure receive hooks on a git server to validate pushes from any authorized person. If you're using Github for instance they provide such a feature: https://help.github.com/articles/about-webhooks/
Should go in your ide, but if you really must check code inbound to git repo, then use a git receive hook to process the code, and optionally reject if things are not happy.
Dreaming of a web service that runs perltidy / perl::critic for you, so that you get it no matter where you are...
At my $-generator (aka my job) I have in my Perl git repo template t/00-perl-compile.t and t/00-perltidy.t, tests to compile (perl -c) and perltidy all code, respectively. You could easily add t/00-perlcritic.t. Now the way I did it was three tiered - the tests just run testing only scripts in t/bin that use modules in t/lib. There's a module to find all modified perl code, one to run perl -c on the found items, one to run perltidy on them. You'd add a bin and a module to run perlcritic. The find all modified code should simply take the results of a git diff --name-only and then check each file for any of a perl shebang, or a .pl, .pm, .t extension. You feed that list to each of the compile,tidy,critic modules. All this is called in the t/bin scripts. And the t/bin scripts should be able to be run by themsleves outside the t/00- test files. And the t/bin/do-perltidy script should take the --update flag to actually DO the update so you can do a fix if the 00-perltidy.t test fails. Of course, the compile and critic suggestions would have to be fixed by hand.
And yes, as a last resort, my commit hook will run the tests if it finds them, so I never push code that would fail the tests.
[Bummer that search.cpan.org was killed.](https://www.perl.com/article/saying-goodbye-to-search-cpan-org/) RIP.
Check out the [PerlPassEnv](https://perl.apache.org/docs/2.0/user/config/config.html#C_PerlPassEnv_) directive.
If You’re building it from scratch don’t write a straight mod_perl handler, use PSGI and deploy with Planck::Handler::Apache2
https://kritika.io
Call for participation: [https://perlcon.eu/news/call-for-participation](https://perlcon.eu/news/call-for-participation) Call for papers: [https://perlcon.eu/news/call-for-talks](https://perlcon.eu/news/call-for-talks)
This is the one thing holding us migrating our production sites from SVN to GIT - as there seems to be no sensible git hook way to do this.... and it is easy with pre/post commit hooks, these aren't the only ones we use - we have path/file based permission patches etc on top of the critic results (don't use tidy as it doesn't really do C style brackets properly)....
How about `s/ vs / and /g`?
While it's a good set of aggregated content this week, I feel like I am just reading gabor's blog once again. It's quite distracting to see opinion and questions all over other people's content. This is what blog comments and reddit are for, not your own signal-boosting platform.
By the way "Exploring Type::Tiny Part 6" is in the wrong section, it's not Perl 6-related.
Wasn't sure if that site was still maintained. I tried signing up for an account to contribute but never got an answer back.
If you create an issue at http://github.com/blogs-perl-org/blogs.perl.org/issues or drop me an email (dave at perlhacks dot com) with the details, I'll look into that. The current platform is rather ropey. But it still works.
OK, thanks. Will do when I get a chance.
Note the link at the end to an example instance of the new platform: https://blogs-perl.herokuapp.com Not quite enough there for me to form a complete opinion (needs a couple style tweaks, and I'm curious what the posting/editing interface looks like, and hope it will support markdown), but as long as the login session works correctly it will be an improvement.
I passed with a score of 22/26. But many of the questions were so badly-worded that I'm surprised I got so many right.
Any chance this will be open sourced? I'd love to see a 2019 real world example of how DBIx::Class is used in a product.
Exact same thing I noticed.
It is based on PearlBee, https://github.com/Perl-Evozon/PearlBee
Absolutely horrendous code all around, no use of strict and warnings, use of the Switch module (!!), a bunch of questions on useless trivia you would look up in perldocs if you needed it, ambiguous sets of answers (two answers that say the same thing, are they both correct? apparently)... and this. https://i.imgur.com/0ufXExy.png
I wonder if we got the same three wrong, because there was more than one question with no absolutely correct answers.
Clearly spam. Same user has posted a bunch of other certification exams to other subs from c sharp to english grammar 
For this use case I find it's easiest to use [commands](https://metacpan.org/pod/Mojolicious::Guides::Cookbook#Adding-commands-to-Mojolicious). They can be run on your app, so it's a good way to create a "script" that has access to your configured app that you can easily run from cron or the commandline or whatever.
Wow, that is perfect! And the way this works is it runs within the environment of the app all being set up, but doesn't actually start the app on any port, correct?
Correct, it will run app startup but not a server.
As someone else said, you can use commands. Or: [https://metacpan.org/pod/distribution/Mojolicious/lib/Mojolicious/Guides/Cookbook.pod#Application-embedding](https://metacpan.org/pod/distribution/Mojolicious/lib/Mojolicious/Guides/Cookbook.pod#Application-embedding)
Awesome! Thank you so much. This is exactly what I was looking for-- and may be useful in other ways!
Ah, that's good to know about, too. Thank you! TIMTOWDI :)
If you find Mojolicious commands insufficient or too restricting, consider switching to [frameworkless code](https://domm.plix.at/talks/frameworkless_async_api.html). This is the better design for what you want to achieve. You program a fat model that can be used from the command-line, cron jobs, local daemons, import/export/fixup scripts or in the Web app. The Mojolicious model becomes a thin wrapper over your fat model. The fat model becomes the king of your code, not the Web framework.
Reported an error yesterday at [http://news.perlfoundation.org/2019/01/grant-report-revitalize-blogsp.html](http://news.perlfoundation.org/2019/01/grant-report-revitalize-blogsp.html) but my comments have not posted. Suffice to say I tried registering myself, got some huge error, tried logging in and got #### Warning Your e-mail address has not been verified yet which leads me to believe that the error I got was invoking the mailer to send me confirmation. Is there some other place I should report errors?
Oops! https://dcbpw.org/dcbpw2019/
If you don't want a full command class, as others have mentioned: The `eval` command allows you to run snippets of code with your app already set up. So, it's like a Perl one-liner that's also a Mojolicious command. If, for example, you have a `do_cron_thing` helper: perl myapp.pl eval 'app-&gt;do_cron_thing()'
The origin and purpose of perl makes it ideal for back-end server work. Servers are still out there, and always will be. People think perl is "dying" because it's not used much on web facing apps. Comparing ruby to perl is comparing apples to oranges.
&gt; The origin and purpose of perl makes it ideal for back-end server work. Technically, what are you referring to? Origins and purposes don't mean much to a kernel? 
Maybe I chose the wrong words... It's ability to parse input has made it the swiss army knife of the sysadmin, and in that role, it still shines bright.
Well, consider that the regex engine (though incredible) is almost totally absent from perl-code on the web backend. You don't parse JSON, HTML, or URIs with regexes.
Seems like a huge oversight, would be interesting to see the outcome of this.
I'll give you 2 out of 3. https://metacpan.org/source/SRI/Mojolicious-8.11/lib/Mojo/URL.pm#L61
Thanks!
So I can see how it's a better design from a purity standpoint-- the model isn't specific to the web framework and just does model things, but wouldn't this mean I result in more code, because I would have the fat model and the wrapper in the web app? Is this worth it because it is conceptually cleaner? &amp;#x200B; The Mojolicious specific stuff I have in my model is the app, which is basically used for [log](https://mojolicious.org/perldoc/Mojolicious#log) and [config](https://mojolicious.org/perldoc/Mojolicious#config). For these what would you recommend to do instead if the model was not tied to Mojolicious? &amp;#x200B; As an aside, I looked through your slides and your talk, and I find it interesting that you find putting all of those pieces together allows you to solve the actual problem you're trying to solve. Doesn't this mean that instead you're essentially building your own framework, which Mojolicious has already done for you? My instinct is that Mojolicious allows me to focus more on my problem, so I'm curious on your thoughts.
Yes, except when used by libraries. The HTML5 spec also produces a regex for type="email" validation. Here's the thing about that though, even that regex *seems* like shit. Why is it capturing 1/3/4/6/8? if it's only using capture 2/5/7/9?
It is spam, yes. But I think it's better to spread the news on how terrible it is than to just ignore it.
&gt; I haven’t written an application in 20 years that relied upon it process local memory to maintain state. It was a silly idea in the 90s too. I agree, but CGI does have advantages outside of that. Perl can't unload modules so regardless of whether or not you *want* the program to maintain state, Perl will do so internally. One request to a perl processes that does `use POSIX;` and you may find that [FCGI backend 8x bigger, forever](https://stackoverflow.com/q/46738256/124486)
We have some experience with mojo and minion at $work. All your assumptions are correct. We have a distributed system but we actually share Mojo front end with Minion workers on a single instance, so that the api is also load balanced. This isn't great separation of concerns but did the job for us. I wouldn't worry too much about sharing the full app code on the worker machines, unless your app is massive the memory overhead really should not be signifcant. Doing that also means you have more simplicity. I would even go so far as saying you could do away with the mojo lite specific app for Admin interface and instead just run the Admin through the same mojo app you plan to provide the interface with. That way you would only have 1 single codebase to manage. Overall we've had great experience with Minion. 
Perhaps "deploy a working replacement for blogs.perl.org" would be a more realistic target than the various "rewrite/fix existing Perl engines to deploy a blogs.perl.org site" proposals. This one dates back to June 2017, I think? Clearly we *don't* have a good engine in Perl (yet!): if we did, we'd be using it already. A project that implements that would be useful, sure - but somehow the focus is always on technology rather than the original target. It's "Revitialize blogs.perl.org", not "Revitalize the Perl blogging engine options"... people have been patiently waiting for many years for the chance to post+comment, is it really such a matter of pride that it *has* to be an engine written in Perl? Why not get a site up and running first using something that *already works*, then maybe in future implement/adapt a Perl version that talks to the same database?
&gt; better design from a purity standpoint Nah, I'm recommending this for its practical points. &gt; wouldn't this mean I result in more code, because I would have the fat model and the wrapper in the web app Yes, it would. The wrapper is thin, though, so the price of admission to the ride is small. &gt; log and config. For these what would you recommend Sorry, no idea. &gt; your slides and your talk These are not mine, they are authored by my [fellow monger](http://vienna.pm.org) [domm](https://metacpan.org/author/domm). &gt; you're essentially building your own framework Ah, but there's the rub, putting libraries together does not result in a framework. In the traditional library-based development style, you call the code; in a framework, some code calls you. The distinction lies in the degree of freedom of how to piece different code together. &gt; My instinct is that Mojolicious allows me to focus more on my problem Sure. You won't know for sure until you try – I encourage you to do so when you notice the framework is more a hindrance than a help. If that day never comes, that's fine with me.
There is no significant difference between a Mojolicious::Lite app and a full Mojolicious app. They just look a little different. So, a distributed Minion setup is just running the Minion worker process on multiple machines (as you described). And, yes, you need to use a networked backend (so, not SQLite) so that the workers all share the same queues. The jobs run on the workers, not the web app, yes. To enqueue via cron you can use anything in [that question about running commands you asked the other day](https://www.reddit.com/r/perl/comments/aj8hhk/how_to_reuse_mojolicious_model_outside_of_app/), but you can also use the `minion job` command (as I show in my [Minion Stands Alone post for the 2018 Mojolicious Advent Calendar](https://mojolicious.io/blog/2018/12/10/minion-stands-alone/)) or write your own script even. The Minion workers need the tasks you create. The code for those tasks is in `add_task`. If you have those in your main web app, then yes, you start the workers with the same app. I don't think you need the task definitions to enqueue a job (enqueuing a job just needs the name of the task), so you could put the task code somewhere else if you wanted, but I personally wouldn't take the effort: Purity is for chemists, we're plumbers. The amount of memory you're talking about is minuscule. Everything in Minion is coordinated by the backend, so as long as everything uses the same backend it will be connected. This includes the admin web UI, the workers, and anything that enqueues new jobs (your web app). So, you can distribute your _code_ however you want as long as it's all using the same backend. But, [as /u/visualdescript points out](https://www.reddit.com/r/perl/comments/ajlqcg/proper_way_to_structure_distributed_minion/eewrzhk/), it's a lot easier to just have all the code in the same application.
I've always wondered why this approach seems to be so uncommon in Perl web dev these days. I've been looking for a resource like this for a while. Nothing against frameworks, I wouldn't dare write a big app without one, but its very helpful to understand how all of these parts actually come together to get the job done, especially when you're trying to write code that is somewhat framework agnostic.
&gt;All your assumptions are correct. We have a distributed system but we actually share Mojo front end with Minion workers on a single instance, so that the api is also load balanced. Sorry-- I don't understand what you mean here. Do you mean that you have one server that runs the Mojo web server and the minion workers? How does this make sure the API is load balanced? Or am I misunderstanding that? &gt;I would even go so far as saying you could do away with the mojo lite specific app for Admin interface and instead just run the Admin through the same mojo app you plan to provide the interface with. That way you would only have 1 single codebase to manage. Yeah, I think that makes sense. The reason I wanted to separate is because I wanted a light login system over the minion app, and the login system my users kill seems like overkill since I don't really need that type of account. I guess I could just have an empty account and validate that it is that user ID when accessing Minion. Do you password protect minion a different way for your site? Or is your application just internal so it's not an issue? &amp;#x200B;
Thank you! This was very helpful. I'm surprised how easy Minion makes it to have a distributed job service with a nice UI :)
[https://mojolicious.org/](Mojolicious) can do all the things. I've used it to parse XML and interact with REST APIs.
If you need a "pure-perl" solution i.e. for embedded usage, use this code snippet: &amp;#x200B; `sub genpass {` `my $length = shift;` `my @characters = (('A'..'Z'), ('a'..'z'), ('!','@','%','^'), (0..9));` `my $size = $#characters + 1;` `my $pwd;` `for (1..$length) {` `$pwd .= $characters[int(rand($size))];` `}` `return $pwd;` `}` &amp;#x200B; (Based on [http://codecry.com/perl/random-password-generator](http://codecry.com/perl/random-password-generator) )
 use HTTP::Status qw(HTTP_OK HTTP_FORBIDDEN); use Plack::Request qw(); use WebService::Pushover qw(); use XML::LibXML qw(); my $app = sub { my ($env) = @_; my $req = Plack::Request-&gt;new($env); return $req-&gt;new_response( HTTP_FORBIDDEN, ['Content-Type' =&gt; 'text/plain'], ['You are not the phone. Go away.'] )-&gt;finalize unless '192.168.0.17' eq $req-&gt;{REMOTE_ADDR}; my $xml = $req-&gt;content; my $dom = XML::LibXML-&gt;load_xml(string =&gt; $xml); my $number = $dom-&gt;findnodes('//CallingPartyNumber')-&gt;[0]-&gt;textContent; # FIXME log this number my $pushover = WebService::Pushover-&gt;new( user_token =&gt; 'PUSHOVER USER TOKEN', api_token =&gt; 'PUSHOVER API TOKEN', ) or die 'could not create WebService::Pushover object'; my $status = $pushover-&gt;message( message =&gt; "Hey jackass, $number just called.", priority =&gt; 0, ); # FIXME what response does the phone want to its POST request? return $req-&gt;new_response(HTTP_OK)-&gt;finalize; }; $app; Run this program, see `perldoc plackup` for details: plackup incoming-number-to-pushover.psgi -l :8080 For testing, use `httpie`. http POST :8080 Content-Type:text/xml &lt; phone.xml You need to add logging to this Web application. What if the phone sends broken XML? What if Pushover returns an error? 
That's all very helpful. Thank you! I'll keep this in mind in case I ever do feel like Mojo is getting in the way :)
When you run a CGI, it spawns a new shell for your interpreter, and that shell inherits the environment variables that any shell would. In Apache, the environment variables are not automatically inherited by the forked process where the mod_perl module is running, because Apache uses the form of exec() where you supply the environment variables. You can expose environment variables though the Apache config file. Check out the Apache documentation on how to do that. 
I've never used WebSockets before, but I'm currently working on a project for my company that will end up having a WebSocket backend, so I've done a bit of research already and I really liked the way [Net::WebSocket::Server](https://metacpan.org/pod/Net::WebSocket::Server) works. 
Yea I'm in the exact same position and had the same conclusion as you did and tried out Net::WebSocket::Server and it was really simple to get started with. Just wanted some feedback if my Google skills were sh\*t :)
Probably something built around mojolicious.
I would also use Mojolicious. Though, if all my clients just needed to pass simple messages with no processing, I would use [Mercury](http://preaction.me/mercury)
I tried out FTS5 last year to create a [SQLite backend](https://github.com/Grinnz/perldoc-browser/blob/master/lib/PerldocBrowser/Plugin/PerldocSearch/SQLite.pm) for perldoc.pl, so the underlying browser could be deployed as an instance without a Postgres or Elasticsearch server, and still be able to search. As always with SQLite features it exceeded my expectations, however in the case of full text search it still cannot compete with the features of Elasticsearch.
This is really a amazing chance to get all of these amazing books for only $15. I'm definitely getting this bundle! 
Picked this up this week
As of this moment, only Perl 6 projects have been suggested. There **must** be things that one could do for Perl 5 in a GSOC project. The deadline is next week! 
To me it's more like () or {}
20 years ago when I was learning perl after a decade of C I struggled with the sigils, particularly when it came to references and slices. I'd constantly google, or altavista, or whatever was in vogue those days. Maybe I was asking jeeves, I don't remember. Finally I typed myself up a little cheatsheet, and hung it on my cube wall. I think it was just two columns showing accessing reference and scalar values with simple examples. Oddly going through the exercise of creating the cheatsheet completely cemented home what meant what. I don't think I ever had to refer to it, though it stayed hanging on my cube wall for 8 years until I moved offices. It's probably still in a bin somewhere. tl;dr: Create a cheatsheet for yourself. Creating it yourself is far better than using someone else's.
[Damian does the second panel without breaking a sweat](https://www.youtube.com/watch?v=Nq2HkAYbG5o&amp;index=92&amp;t=9m45s&amp;list=PLRuESFRW2Fa77XObvk7-BYVFwobZHdXdK).
If everything's a reference it doesn't matter.
That was a very nice talk. I enjoyed it very much even as I dislike perl6 very much.
Yeah, it's one of my favorites among the videos I've seen of his Perl ***6*** focused presentations -- a tour de force mix of geek humor, mastery of material, and captivating code. (Btw, if anyone else is thinking of enjoying the whole talk rather than the few seconds I focused on with the above link, *I recommend watching the whole thing starting 5 minutes in*.) One of my favorites among his Perl ***5*** focused presentations (it still has a P6 connection in the sense that's revealed right at the start) is the one in which he explains [why Damian **hates** Perl 6](https://www.youtube.com/watch?v=ob6YHpcXmTg&amp;list=PLRuESFRW2Fa77XObvk7-BYVFwobZHdXdK&amp;index=40&amp;t=8m26s). More great geek humor, more mesmerizing mastery, and this time a tale of productive work as he recounts a significant chunk of his life bringing something akin to Lisp syntax macro capabilities to Perl 5. Imo it totally tops the one you just watched.
It appears that these weekly posts get a lot of downvotes. I'm considering no longer posting announcements of a new Perl 6 weekly here. Opinions?
Show your code? 0&gt; my $s = "1,2,3,4" $res[0] = '1,2,3,4' 1&gt; split /,/, $s; $res[1] = [ '1', '2', '3', '4' ]
Here is my quicky 3 minute version #!/usr/bin/env perl use strict; use warnings; my $file = "/tmp/input.csv"; my $fh; open ($fh, "&lt;", $file) or die("Cannot open\n"); my $sum = 0; while (my $line = &lt;$fh&gt;) { my @parts = split(/,/, $line); $sum += $parts[0]; } print "Sum is: $sum\n";
Text::CSV_XS is your friend.
\#!/bin/usr/perl @NumArray = &lt;STDIN&gt;; for ($Line=0;$Line &lt; scalar @NumArray; $Line++){ chomp(@NumArray\[$Line\]); } \#This is where I don't know what to do. I don't understand split. for (@NumArray) { @Formatted = split (/,/,$\_); } Hopefully this turns out ok. Reddit doesn't want to format properly
That's pretty cool... is that some sort of interactive interpreter?
Yes, it's [reply](https://metacpan.org/pod/Reply)
There's nothing wrong with your `split`. How do you use `@Formatted`? Please enable warnings and strictures.
I wish. Out of scope. Like I said, I don't want to copy and paste anything because then it's just "Oh you went and looked it up." Our lecture was basically: "Ya got variables and these things called arrays. You can do things with arrays like join() and split(). Ya also got if statements, for statements, foreach. Oh! and hashmaps!" Now figure these problems out!"
Oh, busywork.
Just to make sure it's doing what I wanted, I just print it. `print @Formatted[0]." ".@Formatted[1]` at the end. Doing so just returns "11" at index 0
I'm afraid we'll need your full code and data file, you're not doing anything obviously wrong. I don't understand what you mean by «returns "11" at index 0»
data file: 5,10,15,20,15,30 1,2,3,4,5 3,10 11 And you have my full code as of now. Just slap that print at the end and that's it
If you «slap it at the end», it will only print the last value of `@Formatted`, which *is* `11`. You want the print in your second loop.
I'm specifying a certain place in my array. Shouldn't it be able to pick up the other numbers? print @Formatted\[0\] will print 11. @Formatted\[&lt;literally any number past 0&gt;\] prints nothing/null
`@Formatted` is the array of values within each line. You're reusing it for each line, and then you inspect it after going through all the lines. At this moment it holds the values from the last line, which only has one value.
Or another way to put it... school work. Sometimes you have to figure out **how** things work before you can take the easy shortcut. No one needs to know multiplication tables (everyone has a phone with a calculate) but they can be helpful for other things.
Oh. That makes more sense. &amp;#x200B; I'm just trying to make it so each individual number is stored at some index in an array where I'll be able to loop through it and add the numbers together.
You need to use $Formatted[0] and $Formatted[1]. @Formatted refers to the array, $Formatted[0] refers to the first element, the scalar. use strict; At the beginning of your script, and it will warn you that those two things aren't the same. They might work in some cases, but in others you will get bizarre behavior.
Then what you mean is `push @Formatted, split (/,/, $_);` (having declared it with `my @Formatted;` before the loop).
Complains: "Useless use of push with no values at ./hwq5.pl line 13. Experimental push on scalar is now forbidden at ./hwq5.pl line 13, near ");"
Something else I’d add is that turning to a module as your first port of call isn’t always the best way, sure if the project warrants it then do it, but in certain cases (like this) the end goal can be achieved quite simply without an extra dependency, removing the need to pull foreign code. 
Also, using modules: cpanm is your friend.
My shortest version without any imports that is still readable: use warnings; use strict; my $sum = 0; $sum += $_ for map { split /,/ } &lt;STDIN&gt;; print "$sum\n" And a slightly more «fun» version: local $/; my $sum = 0; $sum += $_ for split /\D/, &lt;STDIN&gt;; print "$sum\n" &amp;nbsp; Unary counting, anyone? local $/; print scalar map {(1)x$_} split /\D/, &lt;STDIN&gt;; I'll see myself out.
You're doing something wrong. What I meant is @NumArray = &lt;STDIN&gt;; for ($Line=0;$Line &lt; scalar @NumArray; $Line++) { chomp(@NumArray[$Line]); } my @Formatted; for (@NumArray) { push @Formatted, split (/,/,$_); } # (here @Formatted holds all collected values) print scalar @Formatted; # Print 14
&gt; I don't want to copy and paste anything becausr then it's just "Oh you went and looked it up." But...that's basically what being a developer is. But seriously, you usually don't have to re-invent the wheel and in my experience most of the times the solution is much simpler than it seems at first. If you want to build your own csv reader, go ahead, you can do that for practice but most of the time there's already a better, quicker and more elegant solution.
This helps. Seeing a solution helps me learn much better. Thank you
Please don't learn anything from the last two, I wasn't being serious :D In «real code», I would write use warnings; use strict; use List::Util 'sum'; print sum map { split /,/ } &lt;STDIN&gt;; In your scope, an appropriate solution might be use warnings; use strict; my $sum = 0; for my $line (&lt;STDIN&gt;) { for my $value (split /,/, $line) { $sum += $value; } } print $sum;
You're ignoring all but the first number for each line. 
It's [asking for trouble](http://thomasburette.com/blog/2014/05/25/so-you-want-to-write-your-own-CSV-code/) to do this with CSV though, and usually any other task that people immediately recommend modules for. But everyone has to try to invent their own template system once.
`-w` is not recommended anymore, because it turns on modules that are not designed to use warnings, which you can't do anything about. Instead just `use warnings` in all your code. The other problem with `-w` is it can't be used with the common `#!/usr/bin/env perl` shebang which uses the first Perl in your path.
Well, this one is not for me. The previous one was not so much about language, but interesting problems and how language fits around problems. This one is the other way around.
Something like this: #!/usr/bin/perl use strict; use warnings; # A place to store the running total my $total; # Read each line in turn from STDIN. # This puts the line in $_. while (&lt;STDIN&gt;) { # Split $_ on commas and walk over the list # of values your get. for my $value (split /,/) { # Add each value to the total $total += $value; } } # Print the total print $total; You can make the loop a bit shorter. #!/usr/bin/perl use strict; use warnings; my $total = 0; while (&lt;STDIN&gt;) { $total += $_ for split /,/; } print $total; You can use the `sum()` function from List::Util (which has been part of the standard Perl distribution since version 5.8.0. #!/usr/bin/perl use strict; use warnings; use List::Util 'sum'; my $total = 0; while (&lt;STDIN&gt;) { $total += sum split /,/; } print $total; Or, to really show off, you can use two calls to `sum()` with a `map`. #!/usr/bin/perl use strict; use warnings; use List::Util 'sum'; print sum map { sum split /,/ } &lt;STDIN&gt;; 
&gt; You can do things with arrays like join() and split() I hope your lecturer didn't say that. `join()` and `split()` work on lists, not arrays. We don't need another class being taught that they are the same thing :-/
He can't. 
I’m not disagreeing with you. As I said before, if the project warrants it, do it. None of the statements made in that article are applicable to this. Both ends are known in full, and controlled. There was no requirement for handling user defined CSV’s or complex formats, just to take a strongly defined CSV and work with it, so there’s no need to turn to a module imo. Of course, requirements may change in the future, and then it might be necessary to seek a predefined solution, we’ll structured code makes such changes somewhat painless - of course this is all hypothetical, we could take it to the nth degree, but that in a way is my point, the task stated above is simple and strongly defined, so the solution should be too. 
Don't slurp input of indeterminate size.
Ah yes. The P6 one was grounded in interesting things outside Perl (from computing Bernoulli numbers using the Akiyama-Tanigawa algo to factoring primes in polynomial time with Shor's) that can be simply expressed/explored with existing P6 language features. Whereas the P5 one is all about an apparently tiny problem that Damian had with P5 that he solved via an N deep yak shave odyssey applying P5 to itself. So his journey, and the video presenting, wasn't of interest to you (or at least not as much as the P6 one). ---- Putting aside the journey Damian took and instead focusing on where he arrived; and presuming you like the Perl language and care about its long term future; do you think that [Keyword::Declare](https://metacpan.org/pod/Keyword::Declare) will play an important part in Perl's evolution in the 2020s?
&gt; Putting aside the journey Damian took and instead focusing on where he arrived; and presuming you like the Perl language and care about its long term future; do you think that Keyword::Declare will play an important part in Perl's evolution in the 2020s? Arbitrary keyword so every other programmer cannot understand your code (without dig deep down to restore to its raw syntax) -- even for seasoned Perl monks? I am not sure that is really good for Perl 5. It is a fancy novelty for sure, but novelty is not necessarily practical or will last. However, I am not against custom keyword or custom syntax. In fact, I am a proponent that every programmer need develop his own syntax and every application need its own DSL. It is just that I don't think it will ever work with current one language layer model. The problem with current language approach is that every thing going on is behind a very thick curtain that programmer have no choice but either to work with a syntax full of infrastructure cruft or to work with a cryptic language that one has to train quite a while to get a hang of it (then get closed-in to that niche). What I propose (and am practicing) is to have a three-layer approach. The very top is the source code we develop in. It is in the form that best to express our idea/logic -- DSL's to every code but they do share common idioms, just like how we develop and use vocabulary in our native language. The second layer is a meta layer that preprocesses into a syntax of currently programming language, e.g. C, Perl 5. This layer is half controlled by standard meta facilities and half controlled by programmer. The latter is important as unlike C preprocessor or typical template system today, this layer emphasizes on outputting readable code. I.e., the result of this layer is the code that we manually write and maintain today. The third layer is the current language layer. With the 3-layer approach, we have two (actually more due to meta controls) views of our code, one high level view that focuses on ideas and understanding, one mechanical view focuses on performance and technicalities as well as understanding at mechanical layer. With this model, although it applies to any target languages, the desirable one are those simple, flexible and powerful. Currently, C and Perl 5 is my favorite. I don't care about Perl 6's novelty since I can easily do that with my meta-layer which give me a very clean picture that contains no magic. Selling magic only lasts during the magic show. I need a stable language layer, meta layer handles the syntax and all other meta-stuff. I wish Perl 5 to continue stabilize and evolve toward being optimized and not trying to play a different role due to temptations. 
I care
I am curious if the [Babble](https://metacpan.org/pod/Babble) experiment is along the lines of your idea.
**TL;DR** I think the layered design you outlined is spot on. I also think it's exactly what the P6 design is, but with the twist it's P6. And I think it's where P5 could go and where Damian is trying to take it. This comment responds to your design. Another to your P5 comments. You said you don't like P6 (though I don't recall reading why) but ironically your description of what you're saying you're a proponent of sounds exactly like a description of P6: &gt; every programmer need develop his own syntax and every application need its own DSL As you say later, a dev can begin by just writing code that gets passed thru a meta layer. In P6 this is equivalent to writing ordinary P6 code. But one can write anything from user defined operators to minor syntactic tweaks to integrated internal DSLs (slangs): * [Slang::Tuxic](https://modules.perl6.org/dist/Slang::Tuxic:github:github:FROGGS). Tux wanted to impose his own rules for function call syntax despite them being in fundamental conflict with standard P6. P6 provides principled tools that let individual devs, or groups of devs, have their own way if they need or want to. * [ipso](https://github.com/masak/ipso/blob/master/lib/Ipso.pm). Carl wanted a true lisp in P6. (This goes further than Damian demonstrated in the first video linked above, which showed how standard P6 syntax could be used to fake it.) * [Slang::Predicate](https://modules.perl6.org/dist/Slang::Predicate:cpan:SAMGWISE). A mathematical DSL. &gt; DSL's to every code but they do share common idioms, just like how we develop and use vocabulary in our native language This is part of the reason why the full P6 "language" (it's really several DSLs woven together) is unusually large and rich language syntactically (even while the syntax is much more regular than P5's). Larry concluded the Lisp curse was real but avoidable by ensuring there are existing general purpose constructs available for obvious things such as pairs, lists, the OO paradigm, etc. This makes it easy for slangs to just pick up and share constructs and idioms unless there's a significant benefit to supporting new syntax. &gt; The second layer is a meta layer that preprocesses into a syntax of currently programming language, e.g. C, Perl 5. P6 has two overall approaches for this meta layer: * Built in grammar facilities from one liner user defined operators to slangs as explained in **Informal Domain Specific Languages with Perl 6** ([slides](http://bduggan.github.io/fosdem-2017/), [video](https://www.youtube.com/watch?v=ENvmfoIclU8&amp;t=0s&amp;list=PLRuESFRW2Fa77XObvk7-BYVFwobZHdXdK&amp;index=61)). These all sit atop [P6 Rules](https://en.wikipedia.org/wiki/Perl_6_rules). This functionality is relatively solid, partly because the P6 language relies on these facilities for its own parsing and compilation. * Lisp like [macros](https://perl6advent.wordpress.com/2012/12/23/day-23-macros/). These are being properly developed outside of P6 in [the 007 project](https://github.com/masak/007/). In the meantime, there is near zero use of these macro facilities, partly because the grammar etc. features render them redundant in many cases, but more because the officially "experimental" implementation of some basics of macros in the Rakudo compiler is so weak and buggy that it's barely worth even experimenting with it. &gt; This layer is half controlled by standard meta facilities and half controlled by programmer. The proportions in P6 vary depending on what facilities a dev chooses. In the first part of his *Informal Domain Specific Languages with Perl 6* presentation (linked above), Brian Duggan defines a fairly sophisticated SQL and ORM DSL with just user defined operators, a particularly lightweight meta facility. At the other end of the range, there's the DSL Brian creates in the last part of his presentation. Or for another example, the 84 LOC [SQL slang](https://github.com/tony-o/perl6-slang-sql/blob/master/lib/Slang/SQL.pm6) written by TonyO which shows the classic three main pieces: * [Some grammar](https://github.com/tony-o/perl6-slang-sql/blob/master/lib/Slang/SQL.pm6#L17), which I'll show here in full: rule statement_control:sym&lt;sql&gt; { &lt;sym&gt; &lt;sql&gt; [ | ';' 'with' '(' &lt;arglist&gt; ')' | '' ] [ | ';'? 'do' &lt;pblock&gt; | '' ] } token sql { [ \'.*?\' || \".*?\" || .]*? )&gt; &lt;before ';'&gt; } * [The compiler response to matching the grammar](https://github.com/tony-o/perl6-slang-sql/blob/master/lib/Slang/SQL.pm6#L40) which boils down to injecting some AST nodes (this could be more sugary): method statement_control:sym&lt;sql&gt;(Mu $/) { my $sql := lk($/, 'sql'); my $args := lk($/, 'arglist'); my $cb := lk($/, 'pblock'); ... my $block := QAST::Op.new( :op&lt;call&gt;, :name&lt;&amp;Slang::SQL::sql&gt;, QAST::SVal.new(:value($sql.Str)), $args, $cb ); $/.'make'($block); * [The code that gets run to do the application work](https://github.com/tony-o/perl6-slang-sql/blob/master/lib/Slang/SQL.pm6#L4): sub Slang::SQL::sql(Str $statement, @args?, $cb?) is export { die '$*DB must be defined' if !defined $*DB; $*DB.do($statement, @args), return if !defined $cb; my $*STATEMENT = $statement; my $sth = $*DB.prepare($statement); $sth.execute(@args); while (my $ROW = $sth.fetchrow_hashref) { $cb($ROW); } $sth.finish; } &gt; The latter is important as unlike C preprocessor or typical template system today, this layer emphasizes on outputting readable code. I.e., the result of this layer is the code that we manually write and maintain today. Aiui that would be "The code that gets run to do the application work" part of the SQL slang as shown above, right? &gt; The third layer is the current language layer. In P6 this is either ordinary P6 or nqp, which is a performance oriented P6 subset. &gt; With the 3-layer approach, we have two (actually more due to meta controls) views of our code, one high level view that focuses on ideas and understanding, one mechanical view focuses on performance and technicalities as well as understanding at mechanical layer. If I'm following your description correctly, we have in P6, for the SQL DSL: * A mechanical level comprising the above `sub Slang::SQL::sql` code (which may be written in the high performance P6 subset nqp); * A middle / meta layer comprising the grammar and actions shown above; * The high level, which is code written in the DSL, in this case such as: sql create table if not exists stuff ( id integer, sid varchar(32) ); &gt; The layer structure is not fixed. For starter, one may choose to write as he writes today in the top layer where the middle layer is straight pass-thru. If I'm following you this would be equivalent to writing ordinary P6. &gt; But importantly because of the existence of this meta-layer, one can start shifting certain cruft down, then further refactor and adding idioms or dsl syntaxes. Right. The same idea is fundamental to P6. &gt; For reviewer, having two layer at hand and one is guaranteed to be in a stable syntax is all for the win. Imagine one gets to enjoy the magic show as well as a scene behind the magician's curtain. Right. This is the P6 philosophy. Though it sounds like, relative to the system you're describing, P6 keeps all the levels written in the same language, partly by having the P6 language *be* a collection of DSLs, so one can paradoxically simultaneously write using DSLs *and* be writing the same language. &gt; With this model, although it applies to any target languages, the desirable one are those simple, flexible and powerful. Currently, C and Perl 5 is my favorite. In the P6 case the favored target is P6 or nqp. nqp on MoarVM already runs many benchmarks much faster than P5, is in a few cases closing in on C, and is getting significantly faster each year. P6/nqp on JS and JVM are works in progress. (As I said at the start, I hear that you don't like P6. My point is that, for those that do, they have the system you've described.) &gt; I don't care about Perl 6's novelty since I can easily do that with my meta-layer which give me a very clean picture that contains no magic. Selling magic only lasts during the magic show. The novelty isn't really relevant. For those that like P6, there's a very clean picture that contains no magic, just as you've described. (It just *looks* like magic to those who aren't interested in the meta layer.)
Switching back to P5: &gt; I need a stable language layer, meta layer handles the syntax and all other meta-stuff. I wish Perl 5 to continue stabilize and evolve toward being optimized and not trying to play a different role due to temptations. I think pretty much everyone wants that. That's why Keyword::Declare is also written at the meta level for P5. It doesn't modify core P5 at all. It's just a module. (That communicates with the P5 interpreting process using an API that was built in 2 decades ago.) &gt; Arbitrary keyword so every other programmer cannot understand your code (without dig deep down to restore to its raw syntax) -- even for seasoned Perl monks? I am not sure that is really good for Perl 5. That's not what Damian was suggesting. Note that he grounded his work in implementing just *three* keywords -- the `class`, `has` and `method` keywords of Dios. And they were anything but arbitrary. Dios replicates the syntax and semantics of these *fairly* fundamental three keywords from P6. (I say "fairly" because at its most fundamental level, namely [6model](https://github.com/perl6/nqp/blob/master/docs/6model/overview.markdown), P6 barely knows what OO is. Technically the OO syntax with `class` etc. is just part of the meta level.) The reason Damian implemented these three in (a meta layer for) P5 is to make P5 a significantly better platform for those who like P6. And his primary pitch for adding *other* keywords was to pick ones that allowed P5 to be a natural platform for forming hybrids with other existing languages, leaving P5 as a stable implementation language with Keyword::Declare as a meta layer. &gt; It is a fancy novelty for sure, but novelty is not necessarily practical or will last. I'm pretty sure Damian didn't mean it as a novelty but rather as a way to bring to P5 some of the promise of meta level construct design, much as you described, much as P6 implements, and much as lisp macros promise but unfortunately with lisp as their common base language.
Here are a few links for where I am coming from: http://hz2.org/blog/fibonacci_sequence.html And here is the story behind my vocabulary analogy: http://hz2.org/blog/vocabulary.html Compared to P6 or Lisp, MyDef layer is general purpose, working for arbitrary language, working at "text" layer, rather than grammar layer. It is somewhat like C preprocessor or M4, but emphasize on scoped macros, code block, frame code, and a clear layer boundary. On clear layer boundary, I desire a clear indication at the top-level code that which syntax or magic belongs to the meta layer, unlike C or list or P6. Different layer requires the coder to put on different thinking hat, so a clean differentiation is considered crucial. I am aware that this practice is rather controversial at this time. If you are not shrugging it off at first view, I am here to answer any questions or discussions. Anyway, I think it is better to properly introduce my story before we continue for more discussions.
split just returns an array.. my @array = split /,/$lineYouReadIn; my $total = 0; foreach(@array) {$total += $_; } print $total;
Hmm. So the argument is that "it's hard" because: &gt; you have a pool of mediocre talent who’ve probably only learned Perl to deal with automation issues and &gt; Computer Science students eager for work, will likely ignore Perl in favor of Python or C++ ? Additionally, the author writes: &gt; you want to select developers who have matured beyond the Perl philosophy by which i presume they are referring to: &gt; the principle of the Perl language, which is, “get the job done.” i don't know that i'd call that *the* principle of Perl, rather than "TMTOWTDI" and/or "Easy things should be easy and hard things should be possible" .... Finally, i note that one of the tags at the bottom of the article is "pearl developer". :-)
Raji Ayinla neglected to link to the substantial original material he copied into his article: * http://www.modernperlbooks.com/mt/2011/01/how-to-identify-a-good-perl-programmer.html * https://stackoverflow.com/a/2119732
This reads like a permissions problem due to running as the wrong user, but I can't be bothered to replicate your setup to verify. You have installed Perl+Minion to run as your user, so you should put the [unit file to be serviced in user mode](https://unix.stackexchange.com/a/367237/91502), i.e. `~/.config/systemd/user/*`, not in system mode, i.e. `/etc/systemd/system/*`. It is also not necessary to involve perlbrew for locating or running perl, simply use the full path initially: `/home/parumoo/perl5/perlbrew/perls/perl-5.28.0/bin/perl /home/parumoo/myapp/script/myapp minion worker` Let me know whether that works.
Aka, why it's great to be a competent perl developer
That was very delicately put :)
Thanks! I didn't know about user mode. I'll give that a shot! And for the Perlbrew location, I wasn't sure about hard coding it vs letting Perlbrew figure it out, but I guess it's not going to change.
Giving a student a fully-polished answer to copy doesn't help him learn.
You're probably right, and I wouldn't have done if it there hadn't already been so many other answers on the page.
http://catb.org/esr/writings/unix-koans/recruiter.html - you don't always need to hire *Perl* developers: most of our team learned Perl on the job. 
&gt; For example, one shouldn’t adhere to the misconception that Perl 6 is an upgrade to Perl 5. Rather, Perl 6 is more of a rebranding that allows beginner and hackers easier access to the language. This fails to adequately express that Perl 6 is, in fact, not the same language.
I always favor hard-coding paths in service files, you don't want to have to debug complex tools like Perlbrew when debugging a service.
Nitpick (that becomes important in more complex discussions): it returns a list, which you can assign to an array.
You got the capitalization of the names wrong, it's O'Reilly and brian d foy.
sorry, I've make it the french way on a english channel ... my bad. 
I don't know that they did this on purpose, but it's there now. No one had asked me about it. &amp;#x200B; [https://www.masteringperl.org/2019/01/free-in-safari-online/](https://www.masteringperl.org/2019/01/free-in-safari-online/)
It's not that it's hard to hire Perl developers. It's hard to hire any competent developer in any technology. A long time ago I had some thoughts on recruiting: [http://blogs.perl.org/users/brian\_d\_foy/2014/12/my-perl-recruitment-thoughts.html](http://blogs.perl.org/users/brian_d_foy/2014/12/my-perl-recruitment-thoughts.html) For what it's worth, most competent people you'd want to hire probably aren't in the recruiting pipeline. You have to entice them away from their current situation. One of the initial goals of Perl mongers was the development of a professional network of contacts and referrals. If you want to hire good people, you have to know who they are and ask them rather than waiting for them to show up (because they usually don't).
Awesome thanks! Great book.
Don't need no stinking split. Just to piss the teacher off, $csv =~ s/,/+/gs; $sum = eval($csv); No mater how bad your solution is, in Perl there is always a worse one. 
Thanks for the follow up. I've read your blog posts and the HN exchange that was linked from one. I think I see your basic point. Let me try express it. Natural level. Express in a natural way with essentially no distracting care about programming. Meta level. Write string rewriting code that translates from natural to programming language. Programming level. Read resulting generated programming code. Switch back and forth between these three distinct forms of code and consciousness until things are as you like. The natural level lets [the divided brain](https://www.youtube.com/watch?v=dFs9WO2B8uI) maximize its potential by letting the right hemisphere lead with the left as a service. The meta level translates between the free form expression and a target programming language. The programming language level lets the left hemisphere lead with the right as a service. Those were just some quick thoughts before I go sleep on it all. I'll return to it all in the next day or two. In summary, while my current sense of what you're aiming at is structurally consistent with your prior description, I now have clarity about your emphasis on the starting point being genuinely natural language driven to the max. ---- Fwiw -- and my current sense is that you just don't see this -- I see this as @Larry's goal with P6. With the original Perl series I think Larry played a little with this idea even if it was very little. Similarly I think Damian's stuff goes far beyond "keywords", despite that being what he called it, allowing essentially arbitrary syntax. But I get that you don't see this. But P6 is another ballgame. Aiui, creating a tool for arbitrary expression was a large part of the point of P6. I think that, in a very real sense, Larry doesn't care about the standard P6 syntax (even while he put a good deal of effort into it). I think he wants P6 users to express themselves however they wish to and wants to let natural language consciousness be the driver, facilitating a right hemisphere led (r)evolution of expression. Much of this will just be particular expression that suits particular devs and/or particular use cases. Some of it will seep back into the underlying relatively stable language. But the point of it all is that it'll be devs being creative humans expressing themselves fluidly with the strengths of natural language leading the way and the strengths of artificial language providing sufficient mechanical foundations that it can work for programming/engineering. Remember, Larry did the world's first degree in Natural and Artificial Languages. He's always been interested in both, with natural linguistics in the lead. So, for example, while he introduced grammars in P6 they're an extension of regexes and are in service of *arbitrary* forms of expression and mapping to code. And while the lisp like macros default to just shuffling around and augmenting code that's been parsed by whatever grammars are active, [the `is parsed` trait](https://github.com/masak/007/blob/f58091e0ec134e7193a5fcd385e3774c3566cbe0/ROADMAP.md#is-parsed-macros) (which is about *completely arbitrary* syntax despite the apparent boringness of the examples in 007's roadmap) is equally important.
Thanks for the work on this. However, when running this locally, all my requests are forbidden. Where exactly would the REMOTE_ADDR be extracted from? I've updated the phone.xml to all have my LAN and local IP, but still shows as forbidden.
brian is gonna go apeshit: http://www252.pair.com/comdog/style.html
@raiph I think your description of my ideal system is surprisingly spot on. While that is what it sounds like as I would describe my idea, in practice, the separation of three layers are not a clear cut of "Natural-meta-programming". I always start with a programming language in mind. That is, I don't necessarily start crafting a most natural way of expressing ideas. I often simply start in mind as programming directly in C or Perl. As I putting lines down, I immediately start to omitting syntax cruft such as curly braces, semicolons, avoiding duplication and rearranging code. Most of these I already had a meta library that I know it is working (in fact, I press &lt;F5&gt; to see it compiles and runs constantly); yet some of those construct may be written down that won't work yet but I know I can make it work (the worst case I can write a perl code to parse what I wrote and output whatever, but often I can achieve it using the existing MyDef construct). So most of my development cycles, I am staying at the top level, thinking I am programming directly at C/Perl level, but due to the existence of meta-layer, having very little constraint. Then of course when bug occurs I am directly debugging at the bottom language level -- well, in fact, I often debug at both the top and the bottom level. With the meta-layer, injecting debugging code and temporary changing/testing code is very easy. What I am trying to say is while there is certain ideology when I talk, in reality the ideology rarely work -- there is no clear line that where is the top layer and where is the meta layer and where is the bottom layer. In practice, there is simply no general answer that fits all. I think that is the problem of modern day language development -- we are trying to find the best general solution -- often to the point that we are inventing problems to show case our solution. Lately I start think that what really revolutionary of my system is simply the introduction of this always available meta layer. People don't even need be conscious about this layer but as long as this layer exist, people have certain control, then through practice, certain system will evolve -- I think this is exactly how our natural language works. We are not aware of, but we always can and often not hesitate to start invent or reuse new vocabulary or idioms. Some come and go, but some sticks and eventually become part of our language. While linguists always try and can make sense of what happens in a language, a language never starts with a linguistic theory. ----------------------------- So with P6, I think what went wrong is there is too much of conscious design in it. Unlike P5, which is more or less start as an ad-hoc system with very open principle and eventually evolves into the form today; P6, it was a conscious design effort from the beginning, with many ideology, big, way off the ground goals (e.g. language for the next century). So while on the linguistic level, it seems exactly what I am proposing, at practical level, I find it every bit wrong. (I admit I am biased, and by saying that, you are welcome to point that out to me and I'll be listening.) 
&gt;If I'm following your description correctly, we have in P6, for the SQL DSL: &gt; &gt;A mechanical level comprising the above sub Slang::SQL::sql code (which may be written in the high performance P6 subset nqp);A middle / meta layer comprising the grammar and actions shown above;The high level, which is code written in the DSL, in this case such as: &amp;#x200B; I can't argue that P6 don't have this 3-layer structure. Similarly that I can't argue that LISP doesn't either. But one has to like P6 in the first place to enjoy that 3-layer structure. Similarly with LISP, one has to devote to LISP in the first place. That is a very strong restriction. The system I am describing do not have that restriction. One chooses language based on his problem (and his experience and his team's expertise); Any compromise is a non-starter (well, we have been doing just that, so let's just say it is a compromise nevertheless). So let me just state the real reason that I haven't been using P6: how is P6's performance compared to P5? Now I don't like you to convince me that I shouldn't care about that performance because this and that. You may have some wisdom there, but you don't know my problem and you cannot possibly make that decision for me. The syntax and flexibility may compensate its performance for some people, but for me, I don't have the syntax and flexibility problem with P5, so the compensation doesn't work for me either. 
You could have started debugging this yourself, at the very least you are capable of printing out `$req-&gt;{REMOTE_ADDR}` to see what's actually in it. &gt; However, when running this locally, all my requests are forbidden. Where exactly would the REMOTE_ADDR be extracted from? &lt;https://metacpan.org/source/MIYAGAWA/Plack-1.0047/lib/HTTP/Server/PSGI.pm#L126&gt; `peerhost` is an attribute on the socket, provided by one of IO::Socket::SSL/[IO::Socket::IP](https://metacpan.org/pod/IO::Socket::IP#$addr-=-$sock-%3Epeerhost)/[IO::Socket::INET](https://metacpan.org/pod/IO::Socket::INET#peerhost-%28%29), they are compatible that way. You are opening the connection from localhost, so the text form of the numeric address will likely be `::1` or `127.0.0.1`, see file `/etc/hosts`. 
[removed]
&gt; I can't argue that P6 don't have this 3-layer structure. Similarly that I can't argue that LISP doesn't either. But one has to like P6 in the first place to enjoy that 3-layer structure. That's true in a marketing sense but not a technical one. One can make the natural layer anything, just as with MyDef. But it's all the same stuff so one can also make the meta layer anything. You could write a MyDef slang. In standard P6 there are two alternate DSLs for regexing/grammars but it's trivial to switch those out or augument them with arbitrary alternatives. And one can write a slang as the target language. There's no incentive yet to push them forward but folk have written Rubyish, Pythonish, PHPish etc. slangs. Some folk object to the very *name* P6, to association with Perl or Perl 6. That makes sense to me from a marketing perspective. And it would make sense if P6 were rejected for technical reasons related to its current reference implementation. While it can use foreign code using their reference implementations (eg using Perl 5 code run with the usual perl binary); and the nqp subset of P6 is much faster than P5 for a lot of stuff; and full P6 code has major advantages such as world leading Unicode (NFG); the current state of full P6 is that it has poor performance. Imo this last issue, poor performance, is holding P6 back and is the sole real problem relative to your complaint that "one has to like P6 in the first place to enjoy that 3-layer structure" because one could essentially ignore P6 and still use the 3-layer structure. &gt; The system I am describing do not have that restriction. One chooses language based on his problem (and his experience and his team's expertise) P6 supports that same approach today. You just make the target programming language be the language you prefer. So now only the meta layer is of concern. Right now, out of the box, that is generally a combination of a grammar -- and P6 grammars are essentially nqp code, the faster subset of P6, and are considered by many to be one of the best things about P6 even if they don't take a shine to the rest of it -- and some mainline code to write out the target code, currently typically nqp QAST code. So the substantive difference between MyDef and P6 is how they've been used to date. P6 slangs written to date generally generate nqp QAST. MyDefs written to date generally generate C or Perl 5 or similar. But that's an issue of focus, not what's possible. That said, focus is an extremely valuable thing. &gt; So let me just state the real reason that I haven't been using P6: how is P6's performance compared to P5? As I discussed in previous comments, the nqp subset is much faster than P5 for some things and I fully anticipate news of it matching C this year for a trivial benchmark or two. Full P6 is a different story but one can see where it can go by understanding its relationship with nqp. &gt; Now I don't like you to convince me that I shouldn't care about that performance because this and that. Not at all. Performance is the key. &gt; You may have some wisdom there, but you don't know my problem and you cannot possibly make that decision for me. The syntax and flexibility may compensate its performance for some people, but for me, I don't have the syntax and flexibility problem with P5, so the compensation doesn't work for me either. Right. That makes sense. But, as I said, one could just target P5. And that said, one could also just focus on MyDef. There is great value to focus. P6 is designed around the same 3 layer structure that you describe but it isn't *focused* on producing a MyDef solution and nothing else. And that is very often what is important.
&gt; in practice, the separation of three layers are not a clear cut of "Natural-meta-programming". Of course. We had already established that as common knowledge. It's in our previous comments and your blog posts and inherent to this 3 layer approach and to programming and natural language and life in general. It's all "messy" in reality. But I feel I must now worry that you'll say "It's not all messy" (because of course it isn't). Natural language is imprecise and "As complexity rises, precise statements lose meaning and meaningful statements lose precision" (Lotfi Zadeh). I even slightly alluded to this when I wrote, with *emphasis added*: &gt; Natural level. Express in a natural way with essentially no distracting care about programming. (Only *constrained if/as the user finds it natural to constrain it to facilitate a nicer flow between levels*. Newbies would perhaps best just not constrain themselves at all. As they gain experience they instinctively know how to keep their expressive flow while *usefully subconsciously anticipating the next levels*.) While I stand by that comment it was written in a hurry. Clearly one can usefully *consciously* anticipate the impact of each level on the others. As you've written, you frequently start from the programming language level and then strip away unnecessary detail. More generally, the productive approach is *holistic*, avoiding unnecessarily fixed ways of looking at things. So I could have gone in the other direction and emphasized that there aren't clear boundaries and perhaps say "it's all just metaprogramming". Would that have helped? I rather doubt it. I wrote what I wrote to see if we could find common ground rather than you thinking you're over there and I am over here and we don't hear each other. So it's unfortunate if you're interpreting my decision to emphasize the words "natural", "meta", and "target" and there being 3 layers as me not getting the overall point. But perhaps you just aren't sure and just wish to clarify. ---- For the bulk of your comment to which this is a reply I was nodding my head. Not because I get what you were saying, though I feel I do, but because that's already how I see things. This perspective is by no means universal but we share it which is part of the reason we're having this exchange. ---- Not only do I agree with the constructive bulk of your comment, but it's also true of P6, even though you don't see it. But rather than me laboriously try to respond to all of it I invite you to pick any paragraph or sentence you wrote and challenge me to show how P6 embodies the same thinking. &gt; So with P6, I think what went wrong is there is too much of conscious design in it. The irony is that most of that design effort was aimed at your 3 layer system which was the obvious lesson drawn from the earlier Perls on how to design an open language that enables unlimited evolution driven by its users that isn't stymied by the contradictory need for stability. &gt; Unlike P5, which is more or less start as an ad-hoc system with very open principle and eventually evolves into the form today; P6, it was a conscious design effort from the beginning, with many ideology, big, way off the ground goals (e.g. language for the next century). Do you think you may have thoroughly misunderstood P6? It is deliberately eclectic, *eschewing* ideology *even more than P5 did*. Can you provide an example of what makes you think otherwise? The "language for the next century" notion came from Paul Graham's comment that it was impossible to predict the future of Perl because it eschewed ideology and was mutating without much constraint. A big point of P6 was to take that further, with a 3 layer metaprogrammable design. &gt; So while on the linguistic level, it seems exactly what I am proposing, at practical level, I find it every bit wrong. (I admit I am biased, and by saying that, you are welcome to point that out to me and I'll be listening.) I can buy the (not) practical argument in principle. It was a gamble to try redo Perl. Larry said as much. He decided it needed to outlive him so he said it would have to be a community redo and he refused to impose one particular way of looking at things and doing things (ideology) because that is the opposite of what Perl is about. One upshot was that its design phase, getting it roughly right, was prolonged. Another is that the implementation phase, getting it performant, will be prolonged. And in 2019, from a practical perspective, well, P6 isn't practical for a lot of use cases unless it leans on other languages such as writing P6 code that uses P5 modules. The jury is out on what will happen in the 2020s. P6 gets significantly faster each year. Its Unicode redo is increasingly important -- there will be more Indian than US devs within 5 years. We shall see.
&gt; So I could have gone in the other direction and emphasized that there aren't clear boundaries and perhaps say "it's all just metaprogramming". Would that have helped? I rather doubt it. I understand that I may seem like talking this and then that, but I am doing that so that I describe both sides of my (same) thinking. Only then the description is complete. It is a process of establishing common ground -- if I don't describe both perspective and to see you nod, I would I know that we have common ground? -- In fact, this is the problem of online communication: we each have our own agenda and one never can sure about the extent or even meaning of the nodding or replying (against). While I am not simply taking your nodding as yes (quickly), you probably are taking what I am replying as against what you were saying (not exactly, more of clarifying). Let's say we have the common ground on the 3-layer view of programming, what we are still differing? I guess there is still this "I dislike P6 very much". Well, that is loaded and complicated, but I am ok to talk about just that. (I am more interested in establishing common rather than arguing on different especially the subjective part though). You are right that I could've misunderstood P6. I only hear it in news and talks now and then, and only tried P6 now and then (after certain talk or discussion). I got my opinion of each time I trying it and each time putting the talks to my background of trying. I admit I never dug too deep for each of my trial. So my opinion could be shallow and changed -- but it won't simply due to talk, it has to come from my own trying. I probably will give it another try later (due to our talk). 
It appears we are establishing the common ground. I guess the next step is for me to dig in to a technical level. I am going to `nqp` a try. I guess I need to understand nqp before I can understand P6, just as I need to understand the C layer of Perl 5 -- which is how C works, therefor I never had the barrier -- to understand Perl 5. Can you be reached for feedback or questions when I get to the technical level (of either nqp or P6)?
&gt; I understand that I may seem like talking this and then that, but I am doing that so that I describe both sides of my (same) thinking. Right. The same with me. :) I think pretty much *everything* you've written is on point. (I think you may have misunderstood Larry and Damian's work but then again maybe I give them more credit than they're due and you've acknowledged it's just your current view of them.) &gt; Only then the description is complete. It is a process of establishing common ground Right. As I wrote, with added *emphasis*: &gt; *I wrote what I wrote to see if we could find common ground* rather than you thinking you're over there and I am over here and we don't hear each other. So it's unfortunate *if* you're interpreting my decision to emphasize the words "natural", "meta", and "target" and there being 3 layers as me not getting the overall point. But *perhaps you just aren't sure and just wish to clarify*. &gt; you probably are taking what I am replying as against what you were saying (not exactly, more of clarifying). I note you've chosen to reflect my wording. So I think we're on the same page. &gt; Let's say we have the common ground on the 3-layer view of programming, what we are still differing? Right. That's indeed what's interesting to me at this point. &gt; I guess there is still this "I dislike P6 very much". Well, I'm tempted to just accept that as an impassable barrier for now. I'm 95% inclined to think us discussing P5 possibilities will be more interesting and potentially fruitful. While I pursued discussion of P6 that was more about establishing common ground and open minded consideration of things. &gt; I probably will give [P6] another try later (due to our talk). Perhaps surprisingly I will now recommend you leave it at that, i.e. just be open to trying it *one day* but probably not this year. It's still slow. The slang mechanism is still unofficial. Your focus on MyDef makes sense and P6 has so many other things to sort out that it isn't currently *focused* on the 3 layer problem which will be a drag on any enjoyments you might try when exploring P6. On the other hand I think both you and Perl could gain from giving Damian's work a second look. In particular I suggest you explore mst's babble, as linked by /u/grinnz elsewhere in our exchange, which builds on Damian's work and shows some of its potential. While babble is ostensibly about being able to write modern Perl and run it on old perls, it also takes the 3 layer approach and you could explore building on babble to create a new generation of MyDef. At the very least it ought to be interesting and, I think, blog post worthy...
You can reddit PM me. Let me close by drawing your attention to my concluding sentences in my last comment regarding where you might take this conversation regarding P6 and P5. My suggestion was that you ignore P6 (and nqp) for now and poke around mst's babble. That said, feel free to PM me no matter what you decide to do or not do. Thanks for this exchange.
&gt;&gt; I guess there is still this "I dislike P6 very much". &gt; &gt; I'm 95% inclined to think us discussing P5 possibilities will be more interesting and potentially fruitful. While I pursued discussion of P6 that was more about establishing common ground and open minded consideration of things. I see. In the 3-layered picture, different layer has different focus. While the top layer is about presentation, the middle layer is about flexibility, the bottom layer should focus on efficiency and accuracy. Since I am treating P5 at the bottom layer, I naturally consider all efforts of P5 (or P6) that not focusing on efficiency and accuracy as a wrong direction, therefore, I disliked them equally. Now I understand the P5/P6 effort you described is more of a second layer nature and the effort is to leave the bottom layer stable and performant? If so, I will give Damian's talk and the babble module another look. &gt; It's still slow. &gt; I suspected so. Performance has to be a first goal of design. When the complicated infrastructure get established, the performance has to work around the infrastructure. My empirical reading is that it is too late for P6 to fix that now since it had many design choices fixed in already. ---------------------------------------- It is pleasure talking with you. 
&gt; presentation ... flexibility ... "metal" That's a nice formulation (I replaced 'efficiency and accuracy' with "metal" to be more concise). &gt; Now I understand the P5/P6 effort you described is more of a second layer nature and the effort is to leave the bottom layer stable and performant? Damian's Keyword::Declare and mst's Babble are about the meta layer, and are written in Perl 5, but they use a regular perl, the binary that runs everything, to do their things. The P6 stuff is how P6 was designed from the start in the early 2000s. &gt;&gt; [P6 is] still slow. &gt; I suspected so. Performance has to be a first goal of design. It was/is. (Do you really think so little of Larry Wall?) Both the language and the compiler stack are designed to close in on C and have been from the start. &gt; My empirical reading is that it is too late for P6 to fix that now since it had many design choices fixed in already. How can design choices that allow the language and compiler to approach the speed of C be a problem? Surely folk just need to do the work? The overall priority was to build optimizability in but to delay actual optimization until after the design was proven correct. These phases have overlapped of course but optimization has only moved center stage in recent years. In the meantime Rakudo has been significantly increasing in speed every year for a decade. One of the reasons I suggested you skip P6 for at least a year is that the regex/grammar engine is due to speed up a lot this year, perhaps an order of magnitude for some grammars. Unless you really have no respect for Larry Wall, don't write P6 off. When he announced P6 in 2000 he implied it would take 20 years to get it into shape. He's roughly on track.
When I was at Lazard, we routinely taught Perl to good developers we'd hire.
&gt;http://www.modernperlbooks.com/mt/2011/01/how-to-identify-a-good-perl-programmer.html &gt; &gt;https://stackoverflow.com/a/2119732 I have contacted the blog host.
&gt; (Do you really think so little of Larry Wall?) Not at all. I respect Larry Wall for what he created. Perl 5 is a unicorn in all programming language with a unique philosophy. The philosophy is "there is more than one way to do it". Or in my word, respect that a language is a mean to an end, not an end to itself. However, when I talk about P6 (P5 for that matter), I tend to focus on the object itself, whatever my assessment to the object doesn't automatically transfer to its creator or any of the particular involvers. Nobody is supposed to be perfect, Larry Wall included. Perl 6 is a failure. It probably is not a failure if it was a pet project, but with a large community behind Perl, it is a failure. There was too much of a drum-roll for the Perl6 20 years ago, and Larry's mistake is not to correct that (every year is an opportunity and every year he fails). Even that, I do not disrespect Larry Wall. It is more a curse of success, and won't diminish what he had contributed to programming. &gt; How can design choices that allow the language and compiler to approach the speed of C be a problem. I often get annoyed by this "speed of C" thing. If the goal is to get to the speed of C, the mean is to use C. Therefore, that "speed of C" is just a meaningless straw-man. Perl 6 have a set of mis-guided design goals. At this page: https://perl6.org/archive/faq.html lists a set of features that nearly all of them puts certain means as an end and I don't care any of them. There is no silver bullet. Each mean is often a compromise and have to be judged by the problem they are solving. By listing them as design goal detached from a problem statement, well, it is problematic. When P6 started, my impression is people complain it can't do proper OOP (at a time when every thing has to be OOP). However, Larry was never an OOP believer. So he naturally made the objective that the new Perl should do every thing good, OOP included, and he didn't doubt that he can (why would he). I think that is doomed. Again, this opinion is based the philosophy that silver bullet simply does not exist, rather an opinion on either the respect or trust toward Larry Wall. Any one who tries to make an silver bullet I will have the same opinion until they deliver (even then...).
I care
Many thanks to /u/daxim for fixing this!
You might have better luck in /r/rakudo.
Judging by going to oreilly.com, which has no mention of their ever having being a publisher, and no mention of what books if any they currently publish, it is difficult to guess what they *do* other than provide "training." They seem to be in the process of vanishing entirely.
https://github.com/Perl-Toolchain-Gang/toolchain-site/blob/master/lancaster-consensus.md#automating-pause-id-registration Perl ecosystem changes tend to take a long time due to lack of resources/interest - see also the various delays and planned-but-not-yet-complete changes on core sites such as perldoc.perl.org, search.cpan.org and blogs.perl.org for example. Might help to volunteer if you're interested in implementing/helping, though! (note that you're not completely blocked without a PAUSE account - commands such as `cpanm https://github.com/author/module/tarball/master` will at least let you work from a github account)
He says you shouldn't start a sentence with his name. I think that's too much to ask but still. 
&gt; anywhere from a few days to a few weeks That's a worst case estimate. The current situation is: 34 requests since 2019, of which 22 were granted: 11 on the same day, 2 on the next day, 2 within two days, 2 within three days, 3 within four days, 1 within six days, 1 within seven days. &gt; pypi, npm, or crates.io You mention centralised services, which [CPAN](https://github.com/neilb/history-of-cpan/blob/master/history.md) (where your uploads through PAUSE end up) is not. This makes abuse a much bigger problem. * There is no good way to delete stuff once it is [mirrored](http://mirrors.cpan.org), which ranges from instantly to a few hours. * A good chunk of admins do not own the infrastructure, some organisation merely connives the use of their resources. Imagine the upload of cheese pizza into your company's/university's ftp space and the scandal is perfect. So what do you do when you cannot afford to be sorry rather than safe? You better vet uploaders as good as you can to nip potential abuse in the bud.
The practical answer is that automation was tried for a couple weeks, but despite the captcha, a large amount of spam accounts started uploading nonsense to CPAN. So I think that experiment was put on hold for now.
What happened to the ones not granted? Were they simply not legit submissions by programmers?
🤔 &lt;https://www.nntp.perl.org/group/perl.modules/2019/01/msg99694.html&gt;
if you're considering relying on a module, look at the date of the last update of the module, check if there's outstanding bugs, look at how many cpan modules rely on it (the reverse dependencies link on it's metacpan page). further research would be to search stackoverflow for related questions and github for non-cpan related projects relying on it.
This is why we cannot have nice things. 
It's usually very fast. Don't worry about it, just do the thing, and wait a day or two. Once you have an account, you never have to wait again...you can publish things right away (well, within the bounds of how long it takes for indexing and whatever else). npm has a lot more contributors and packages, but also a lot more mess, including significant security problems in recent history. I'm not saying CPAN is better, but there are reasonable arguments for going a little slower and having contributors be a little more closely vetted.
I don't have experience with the module, but I can say that a definite con is the complexity of making use of shared memory (there are several notes in the documentation regarding this). This would make me consider a different approach first regardless of the stability of the module.
Looking up a diffrent way to approach this issue, thanks for some feedback :)
Just to add to this, we recently had to do a bunch of work on MetaCPAN to make it easier to delete CPAN uploads that have been removed from PAUSE. We can do it now, but it's still a manual process. When someone uploads garbage to PAUSE there are cascading effects and real people have to deal with them. It's a big of a drag that you don't just immediately get your account, but if people could behave themselves better, we'd be better placed to automate this.
&gt; npm has a lot more contributors and packages, but also a lot more mess, including significant security problems in recent history. I Yes, that was my thought. It could be that one of the reasons CPAN has been relatively free of issues over the years is that you need to convince another human being that you're really a human being before you get access. 
Or with some explanation so one can learn: `for` loops will eagerly create a full list of the entirety of `STDIN` when you use `&lt;&gt;` inside the round brackets of the loop statement. If `STDIN` never closes you're going to be waiting there a while and use a lot of RAM. However, if you instead used `while (my $line = &lt;STDIN&gt;) {}` that gets just a single line at a time from STDIN both in execution and in memory. This is a super common mistake almost anyone new to Perl makes, and is especially common from people learning on Bioinformatics courses in my experience. Which are more generally taught by people who have a thinner grasp on language semantics, lecturers frequently have a primary background in biology rather than computer science or software is the usual culprit everyone suffers from. Easiest way to see this is to try both of these commands in a shell. The following will print nothing and just hang until you ctrl+c (but will grow in memory): `yes | perl -e 'for (&lt;STDIN&gt;) {print}'` But this will print everything out as it goes: `yes | perl -e 'while (&lt;STDIN&gt;) {print}'`
I used it in a Perl app for Raspbian on a Raspberry Pi, and it worked faultlessly.
Cool I solved it by running a fork and return the data to the parent instead of sharing memory.
What's up with these Raku posts in /r/perl lately?
It's not a new thing - I would prefer to go to /r/perl6 for Raku news and discussion, but the subreddit moderators that are left here are mostly absent at this point, so there's little point in discussing it.
In fact, I'd say a "rebranding" is exactly *not* what Perl 6 is. That implies surface changes while the underlying product is largely unchanged. Even if you consider Perl 6 to be the same language, it's different in many ways from top to bottom, and it's more different under the hood than it looks on the surface.
Apologies for all the brokenness over the last few days.
Any specific Raku posts you have in mind? I didn't see any?
While you're at it, might be a good idea to have versions in the changelog.
Yes. I'm pretty sure the Changes file is still in the format I inherited many years ago. It's auto-generated from Git. I should really invest the time to turn it into something more useful (I think the same is probably true of most of my CPAN modules).
We are not absent. We're just not that heavy handed. I'd prefer to separate the two topics, but that's just me.
That would require changing the motto of this reddit, which as far as I know, is still "The Perl Programming Language, including both Perl 5 and Perl 6." Or am I missing something? 
That would be the idea, yes. It's an outdated "motto" either way, since it refers to two programming languages as one. I would also like to see a link to /r/perl6, though since new-reddit ignores the old sidebar content, we would also need a sidebar widget to be added to show the info for those users.
By "mostly", I was referring to the quantity of people in the moderator list, not the moderation presence which is quite sufficient for the traffic. It is difficult to have any discussion about subreddit rules and policy without knowing where the buck stops.
Its a pretty small community... just keep hanging out here and figure out who does what (just like you're doing), stuff starts to go smoother. In the meantime maybe do your development on github and release when you can? Thanks for contributing! 
&gt; Wonder why I did that? Perhaps you got pressured by bricas to adopt his unilateral idea of how a changes file must look like? The time frame fits.
Except the .46 changelog mostly matches bricas' format, while .47 is just a complete mystery compatible with nothing whatsoever.
The last one was the previous weekly 10 days ago.
I write webapps in perl using Mojolicious (a first-class web backend framework). I also do some chemistry analysis stuff using PerlMol. At my previous job I wrote a library in perl for doing backend support of a Java servlet-based product, for our tech support guys to easily write scripts against
Web applications for my team's network management tasks (configuration repository, IPAM, switch management).
Web applications, home automation system, workflow automation using inotify, complete radio timeshifting system (from parsing schedules through scheduling recordings to actually *doing* the recordings. In fact, pretty much anything that doesn't suit a simple shell script and doesn't have to be written in other languages (such as Android apps or javascript for in-browser work).
A ton of backend distributed systems stuff; email filtering and processing, web proxies, job systems, various kinds of reports, various kinds of web services, etc.
A lot of glue/automation/log analysis/sysadmin
I do ETL systems. Formerly for financial analysis, now for data conversion from legacy systems to our web app. In my personal time, I largely build web apps using Mojolicious and ETL with Minion / Beam::Runner.
I'm a DBA, so I use Perl to automate a lot of database administration tasks. We have to integrate with a lot of third parties, which usually involves SFTPing a CSV file of data extracted from the database daily or hourly. For example, we use a third party emergency text notification service. When I was tasked with automating the user phone number import, I wrote a Perl script to run a SQL query to get the phone numbers, format it in the CSV format expected, and SFTP it to the third party server. I could have probably achieved this with just SQL and Bash, but this is where Perl and CPAN (thank you, Text::CSV) really shines.
web apps, data syncs between systems with jenkins as the scheduler, anything to make my life easier at work 
I've written a midi controlled home audio system (music, spoken word and CCTV monitoring components) using it. I like wrapping distributed libraries in XS (flac, fluidsynth etc) for specific functions. 
Perl is my go-to for anything command line. I’ve started a couple personal projects on Perl. I’m writing a C `sizeof` calculator in Perl, and I’m writing a time-tracker in Perl as well. At work, we’re also using Perl for a web server and for a Rapid Application Development framework.
I write stuff in perl that can't be easily written in anything else. That's a lot of stuff. If you're looking for an advantage perl has over most other dynamic languages, you could think of it as a fast, full-featured regular expression engine with full unicode support. 
Most anything involving working with textual data that's too complicated for a small shell script that uses sed, awk, jq, etc.
Doesn't look like it. As for CPAN: "The CPAN module automates or at least simplifies the make and install of perl modules and extensions. It includes some primitive searching capabilities and knows how to use LWP, HTTP::Tiny, Net::FTP and certain external download clients to fetch distributions from the net." Net::FTP is built in and it can also use curl or wget if it doesn't have LWP or HTTP::Tiny available.
Most stuff involving big scale e-commerce from devops to application
Take something like HTTP::Tiny and distribute it alongside your code.
Most of my professional career has been writing Perl. Most of that work has been leveraging mod_perl. I've written applications that defined their own wire protocol or implemented other systems' wire protocol using custom Apache connection handlers. One of these implemented a go VoIP call processing platform with Asterisk. One provided a search platform that could distribution queries across multiple data sets with different levels of fail-over. As a personal project I wrote a podcast capturing/publishing platform to "DVR" radio programs streamed over the internet. But "Perl is just a scripting language."
[Yes](https://perldoc.pl/HTTP::Tiny#get%7Chead%7Cput%7Cpost%7Cdelete)
Good question! I was just looking for something to fetch http/s headers. Too bad something not in core, but at least there's some small modules to use.
I'd like to know more about your radio time shifting app. I wrote one that just relied on manual scheduling cron jobs and then rolled a podcast feed around it. My framework is available on [GitHub](https://github.com/codon/podcast) 
I'll try `HTTP::Tiny`, thanks! Am I missing something, it's definitely **not** listed in this core module list under `H` https://perldoc.perl.org/index-modules-H.html
I have used File::Fetch before, it's in core but is very bare-bones. If you only want the contents of the file and nothing else, it'll work. Anything more than that and File::Fetch won't help you.
`File::Fetch` looks interesting. It's a wrapper around a bunch of programs or modules. I didn't know this was an option, thanks!
perldoc.perl.org has [many issues](https://github.com/jonallen/perldoc.perl.org/issues). This is among the many reasons I created https://perldoc.pl.
Link to /r/perl6 added. I don't particularly like the motto, but I'm not particularly keen to change it either (although it is quite easy to do so). The feedback I've gotten personally is that Perl 5 people don't want mixed content. It's why I have separate twitter feeds for my posts about either.
That's not what I've said. 
I don't go apeshit over it.
&gt; Sentences should not start with brian d foy if you normally capitalize the first word of a sentence. Recast the sentence so that it begins with a capital letter. 
Control software for satellite ground systems and ETL-type systems. 
Haven't been able to get this working locally with httpie using: * localhost * 127.0.0.1 * ::1 * My two LAN IPs Also haven't been able to get it working with a phone. Here's the plack response: 192.168.0.4 - - [07/Feb/2019:23:37:19 -0800] "POST / HTTP/1.1" 403 31 "-" "Microbrowser/1.1 PolycomSoundPointIP-SPIP_335-UA/4.1.0.84959 Type/Application" That's a phone making a connection to the plackapp, with the plackapp having 192.168.0.4 listed, but still being rejected as 403. )-&gt;finalize unless '192.168.0.4' eq $req-&gt;{REMOTE_ADDR}; I haven't see anything but the forbidden message. No obligation to help find what I'm overlooking.
HTTP::Tiny has been in the [Perl core since 5.14.0](http://perlpunks.de/corelist/version?module=HTTP%3A%3ATiny).
* several web applications (from CGI, PSGI, as well as CGI::Application). * web hosting control panel (not unlike cPanel, which also happens to be written in Perl). * cryptocurrency arbitraging application. * command-line scripts, from doing automation, processing/munging data, displaying remote API call results, etc. * one-liners, mostly to massage data or perform some automation. * various modules to support the above. 
I've use IO::Socket::INET in the past for simple requests; use IO::Socket::INET; my $client = IO::Socket::INET -&gt; new( 'PeerAddr' =&gt; '127.0.0.1', 'PeerPort' =&gt; 80, 'Proto' =&gt; 'tcp' ) or die; $client -&gt; print( "GET /stuff.html HTTP/1.0\r\n\r\n" ); my( $line, $len, $status ); for ( ;; ) { $line = $client -&gt; getline(); $line =~ s/[\r\n]+//; if ( ! $line ) { last } elsif ( $line =~ /^Content-Length: (\d+)/ ) { $len = $1; } elsif ( $line =~ /^HTTP.+? (\d{3})/ ) { $status = $1; } } $status &gt;= 200 &amp;&amp; $status &lt; 300 or die $status; my $body; if ( $len ) { $client -&gt; read( $body, $len ); } else { local $/; $/ = undef; $body = &lt;$client&gt;; } print $body;
BTW, to check if a module is core: % corelist HTTP::Tiny To see list of core modules for a particular perl version: % corelist -v 5.14.0 // or you can also see this POD on metacpan.org: https://metacpan.org/pod/release/PERLANCAR/Module-CoreList-List-0.001/lib/Module/CoreList/List/v5_14_0.pod 
Try to keep up :) HTTP::Tiny has been in core since 5.14.0, released 7.5 years ago.
It's a bit of convoluted mess that's grown over about ten years, but it works. There's a script that downloads a week's worth of schedule pages from the BBC website for each of the stations I'm interested in, then parses them for programme details (start time/duration/description/etc) and spits them into a SQLite database. This bit's horrible because every now and then the BBC redesigns its schedule pages and I have to rush to reverse-engineer them again. Then when the schedules have been extracted, programmes I want to listen to regularly are automatically set up for recording and each station gets a web page with the week's schedule from which I can select more programmes for recording (or just see what's on today). Recording is handled by another script which dynamically inserts the necessary module for getting the stream (occasionally from the web but mainly from an RTL-SDR tuner that's plugged into a USB port, tuned to the local DAB multiplex). And it's all triggered by the atd daemon; the only thing I ever use at jobs for. When I originally wrote it (for a Terratec DR-Box1 DAB tuner I bought 17 years ago) I had thoughts of open-sourcing the code, but it got so specialised for my system and so crap in parts that I gave up on that idea. Especially as DAB tuners that plug into computers died out until RTL-SDR appeared.
How do you as the recorded programs? Do you have things connected to a media center? Or do you just browse a directory and listen through a some player on you desktop?
I listen to them all through audacious, with my sound-card wired to the home audio system. I like audacious because it's got a very small system footprint (no mucking about with big libraries, etc) and with the legacy skin it just takes up a small corner of my screen.
&gt; and doesn't have to be written in other languages (such as Java for Android apps or javascript for in-browser work). Actually, there used to be ActivePerl with ~ActiveScript~ [PerlScript](http://docs.activestate.com/activeperl/5.22/perl/Components/Windows/PerlScript.html#what_is_perlscript) that would allow HTML scripts to be written in Perl. Instead of infamous JavaScript. 
That seems rather complicated, given that HTTP client libraries exist :-)
Don’t tell me, tell https://perldoc.perl.org/index-modules-H.html which does not list it as a core module. Also, while 7.5 years seems like a long time, I left my last job 18 months ago, and when I did, they were still running 5.8.8 on production systems
What's in `$req-&gt;{REMOTE_ADDR}`? You still haven't checked and told me. &gt; No obligation to help find what I'm overlooking. If it is going to take you again four days to reply, then I'm going to ignore this thread.
&gt; they were still running 5.8.8 on production systems The curse of CentOS 5 :-/
Sorry, but that is the **Perl 6 Weekly**. Nothing to do with Raku, as far as I am concerned. As I already stated before, I will not be reporting anything about Raku in the Perl 6 Weekly. Raku deserves its own channels, not to be contaminated by the bad reputation that the word "Perl" has.
In my day job, I'm part of a team maintaining a Catalyst app which drives a financial services web site. In my spare time, I write and maintain various things. Mostly CPAN modules, but also a few web sites written in Dancer.
True, but if you're limited to core libraries (like the OP and I have been), you'e using a simple static API and your alternative is HTTP::Tiny (which may end up using command line utilities), it may be less complicated to roll you own solution with a couple of dozen lines :)
Not entirely sure whats triggered this response. My point was more its low density posting with a link to the one thing that summarises Perl 6 changes. Which feels like something /r/perl would be interested in seeing.
Using this script to get REMOTE_ADDR: https://ptpb.pw/wqZK HTTP/1.0 200 OK Content-Length: 30 Content-Type: text/plain Date: Fri, 08 Feb 2019 15:45:10 GMT Server: HTTP::Server::PSGI Hello stranger from 127.0.0.1! plackup contains 127.0.0.1: https://ptpb.pw/j4UJ
Indeed it has... Apparently the documentation for core modules on perl.org is not correct. Thank you.
`HTTP::Tiny` is indeed a core module. It just wasn't on the list at perl.org. Weird.
Do we know who runs the docs on perl.org? Seems like that's something the should **definitely** be fixed.
I knew there was a command like `corelist` but I couldn't remember what it was. I was thinking it was `perlcore`, but no luck. Do we know who runs the docs at perl.org, seems like we should get that list updated.
If only there was contact information at the bottom of every page :-)
I'll try contacting the perldoc guy and see if he's willing to update the docs. If not maybe he'll give control to someone else.
Looks like the problem might go deeper than that. It's not listed on [MetaCPAN either](https://metacpan.org/release/perl).
It's upstream CPAN, not developed as part of the Perl core, so it won't be part of the list on MetaCPAN. The "perl" distribution isn't the authoritative source for the "HTTP::Tiny" module.
You are free to try of course, but efforts to this end have so far been fruitless.
Ok. But it looks like the Perldoc site is using the same logic as MetaCPAN to determine what modules it considers part of the Perl distribution. And that's obviously causing confusion.
I wrote [Tetris as a way to learn perl](https://github.com/evanandrewrose/perltris) about a week ago.
Glancing through the code in [Mojo::UserAgent::_form()](https://metacpan.org/source/Mojo::UserAgent::Transactor#L171) (which looks to be what `Mojo::UserAgent-&gt;post()` calls), there is an override in there that sets `application/x-www-form-urlencoded`. You'd want to step through with the debugger to be sure. If possible, I'd use LWP::UserAgent instead. It tends not to have these sorts of unexpected "convenience" features.
It isn't. For example perldoc.perl.org lists App::Prove but this is similarly not included in the metacpan list. It's important to note that perldoc.perl.org is *supposed* to be showing all core modules, but metacpan makes no such claim - it already special cases a lot of things for the `perl` distribution, but it has a certain algorithm to find and index modules, documentation, and other files in CPAN distributions for display.
I'm not sure where you're seeing that post would call that. That function is only called by the [form generator](https://metacpan.org/pod/Mojo::UserAgent::Transactor#form) which the code we've been shown is not using.
Try setting the MOJO_CLIENT_DEBUG=1 env variable so that the raw request headers are printed when the request is sent. And make sure you are calling what you think you are calling, and that none of the "fluff" you stripped is actually the problem.
I am interested in seeing it in the subreddit where it is relevant.
Please don't create additional confusion based on interpretations you invented.
The `post()` method calls `Mojo::UserAgent::Transactor-&gt;tx()`, which in turn calls `generator()`, which potentially goes into this method. I'm not 100% sure it will actually make it there, but since it's overriding the content-type with this value, it seemed a good place to look.
It will not, because there is no generator used (this is activated by passing multiple arguments after the URL or headers).
Russian-language AI mind-modules in Strawberry Perl Five: **[RuAdjective](http://ai.neocities.org/RuAdjective.html)**; **[RuAdverb](http://ai.neocities.org/RuAdverb.html)**; **[RuIndicative](http://ai.neocities.org/RuIndicative.html)**; **[RuNounPhrase](http://ai.neocities.org/RuNounPhrase.html)**; **[RuParser](http://ai.neocities.org/RuParser.html)**; **[RuPrep](http://ai.neocities.org/RuPrep.html)**; **[RuPronoun](http://ai.neocities.org/RuPronoun.html)**; **[RuThink](http://ai.neocities.org/RuThink.html)**; **[RuVerbGen](http://ai.neocities.org/RuVerbGen.html)**; **[RuVerbPhrase](http://ai.neocities.org/RuVerbPhrase.html)**.
Thanks for the replies. Here's additional information after enabling MOJO\_CLIENT\_DEBUG: POST /api/m2m/v1/session/login HTTP/1.1\x0d Content_Type: application/json; charset=UTF-8\x0d Content-Length: 63\x0d Accept-Encoding: gzip\x0d Host: [removed]\x0d Authorization: Bearer notsolongstring\x0d User-Agent: Mojolicious (Perl)\x0d \x0d { "username": "[removed]", "password": "[removed]" } -- Client &gt;&gt;&gt; Server (https://[removed]/api/m2m/v1/session/login) -- Client &lt;&lt;&lt; Server (https://[removed]/api/m2m/v1/session/login) HTTP/1.1 400 Bad Request\x0d Access-Control-Allow-Headers: authorization,Access-Control-Allow-Origin,Content-Type,SOAPAction,TokenB\x0d Access-Control-Allow-Methods: POST\x0d Access-Control-Allow-Origin: *\x0d Content-Type: application/json; charset=UTF-8\x0d Date: Fri, 08 Feb 2019 21:41:33 GMT\x0d Server: nginx\x0d Content-Length: 140\x0d \x0d -- Client &lt;&lt;&lt; Server (https://[removed]/api/m2m/v1/session/login) {"errorCode":"REQUEST_FAILED.UnexpectedError","errorMessage":"Content type 'application/x-www-form-urlencoded;charset=UTF-8' not supported"} It does look like I'm trying to send what I think I'm trying to send... I think. For what it's worth, an older version of this module is working fine with LWP, I'm trying to convert everything to Mojo where I can. &amp;#x200B;
&gt;Content\_Type As Grinnz noted, that seems wrong. Seems like it should be Content-Type. &amp;#x200B;
Yes, you are not sending a Content-Type header. The format is precise. Despite HTTP::Headers accepting basically anything, the rest of the world doesn't.
Any good Perl programmer knows not to ignore the post-conditional... 
I sat down to debug my code and found a bug. It should be [`$req-&gt;address`](http://p3rl.org/Plack::Request#address). I confused the type of the object and thus called the wrong attribute and never noticed because I initially only tested and ran the XML part of the code. Normally I would feel shameful and apologise, but today I feel pretty indifferent. The reason is that I asked twice to check `$req-&gt;{REMOTE_ADDR}` but did not get the truthful and straight-forward answer from you that the expression is undefined/empty string – that's being uncoöperative. The expression was literally the first thing I looked at, and when I noticed it's undefined then it became blindingly obvious I had the wrong object/wrong attribute. The lesson for me is to use strict and warnings even for the smallest programs, this would have revealed the bug immediately. The lesson for you is when you participate in trouble-shooting, don't deviate from the protocol. You can offer your own observations, but only ever in addition to, not in stead of the requested info.
"The Perl Programming Language, including both Perl 5 and Perl 6." Ergo, posting when there's a new Perl 6 Weekly is relevant.
Eh, I don't think **I** came up with "raku". Which is the source of all confusion, and made Perl even more the laughing stock of the programming community: there are many more than ways to screw yourself up.
But I didn't: "which is, of course, what everybody does". 
The source of all confusion is that a programming language named Perl 6 is not the same as a programming language named Perl.
OP (warrenonedge) is a spam account using [multiple layers of redirection](https://old.reddit.com/r/TheseFuckingAccounts/comments/ahm59f/confuego116_referral_link_spammer_masking_spam/) to hide their referral link spam. Here's the real URL: https://www.humblebundle.com/books/programming-cookbooks They use multiple accounts to evade subreddit bans.
Thanks, just bought directly from humblebundle
You’re doing it right, but I highly recommend [SQL::Abstract](https://metacpan.org/pod/SQL::Abstract) which handles this and a slew of other details very elegantly. 
join(',', ('?')x@binds)
If I wasn’t using a library to build the SQL for me I’d probably use something like this. join ‘, ‘, (‘?’) x @bind; I am on my phone so I can’t test it and I can’t remember if x has higher precedence than comma. But I don’t think you need extra brackets in there. 
If I understand you correctly these are the three layers: 1. base programming language 2. transformation layer (meta layer) 3. user code written in a DSL That is a useful way to think about it, but in Perl6 those are all one layer. --- As an example: Let's say I want a DSL with a postfix operator for finding the factorial of an integer. The operator is going to be `!`. I am starting by designing layer #3. I want it to look like this: say 5!; Working my way downward, I need to transform that to something like: say [*]( 1..5 ); So I write a Slang (which is level #2), which will be used like this: use Slang::Factorial; say 5!; The module that handles the Slang could look something like this: **`Slang/Factorial.pm6`** use v6.d; role Slang::Factorial::Grammar { token postfix:sym&lt;!&gt; { &lt;O( %('prec', 'x=', 'assoc', 'unary', 'dba', 'autoincrement') )&gt; } } role Slang::Factorial::Actions { … # NYI } sub EXPORT(|) { $*LANG.define_slang( 'MAIN', %*LANG&lt;MAIN&gt; but Slang::Factorial::Grammar, $*LANG.actions but Slang::Factorial::Actions ); {} } (Note that the above doesn't work, but it is similar to how it is currently supposed to work) That part about `%*LANG&lt;MAIN&gt; but Slang::Factorial::Grammar` creates a new parser based on the existing Perl6 parser combined with the `Slang::Factorial::Grammar` role. So this folds layer #2 into layer #1. --- Of course even if the above worked, it would be a little daft to write it that way. Perl6 is advanced enough to take care of level #2 for you in most cases by just defining a properly named subroutine. **`Slang/Factorial.pm6`** use v6.d; unit module Slang::Factorial; # in layer #1 our sub postfix:«!» ( UInt $n ) is export { # add layer #2 [*] 1..$n } # in layer #3 The `postfix:«!»` tells layer #1 (Perl6) to add layer #2 (transformation). After that point the compiler is using a new parser which includes that operator. It was basically written at layer #3. (DSL) That's what I meant by saying they are all one layer in Perl6.
Yes, I use SQL::Abstract or DBIx::Class.
Nobody cared on your first 5 accounts, and they won't care on this one either. More spam from fake lawyer and admitted pedophile ltgerome/vevnicc/mikeeusa/mikeeusa0/gameroflibre. Report the account as spam [here](https://reddit.com/report) and he'll eventually give up. He's already been through at least 4 other accounts
You need the parentheses to make a list of `'?'` and not a string of `'???'`. 
Geez. Talk about a #triggered #incel #beta. 
The parentheses for the x operator yes, but not the ones for join.
Exactly. What was trying to say is that what I wrote should work as is, and if it doesn't, then add some extra parentheses in there.
It seems like you were trying to translate this Perl6 code to Perl5: 0, 1, * + * ... * Only you didn't do that. That should create a one-shot sequence. You can only get a value out of it once, and you can only move forward. (Unless you do something to cache it.) my $seq = 0, 1, * + * ... *; for $seq&lt;&gt; { last if $_ &gt; 144; .say } for $seq&lt;&gt; { # Error: The iterator of this Seq is already in use/consumed by another Seq .say } A sequence in Perl6 is basically a simple wrapper around an iterator. --- This is how it should work: use v5.12; sub fibonacci_iterator_factory { my @a = (0,1); sub { push @a, $a[0] + $a[1]; shift @a; } } my $iterator = fibonacci_iterator_factory(); for (1..10) { say $iterator-&gt;(); } Actually since `* + *` and `...` are functions, it should be more like this: (most operators are functions in Perl6) use v5.12; sub iterator_factory { my ($g_c, $gen, $e_c, $end, @initial) = @_; sub { # return empty list if it should stop return if state $stop; state @gen; state @end; my $next; if (@initial) { $next = shift @initial; } else { $next = $gen-&gt;(@gen); } if ($g_c){ push @gen, $next; shift @gen if @gen &gt; $g_c; } if ($e_c){ push @end, $next; shift @end if @end &gt; $e_c; } if ($end-&gt;(@end)) { $stop = 1; # clean up some memory undef(@initial); undef(@gen); undef(@end); undef($g_c); undef($gen); undef($e_c); undef($end); } return $next; } } { # 0, 1, * + * ... * my $iterator = iterator_factory( 2, # generator needs two arguments sub { $_[0] + $_[1] }, # generator 0, # ending condition needs zero arguments sub {0}, # does not end 0, 1 # seed it with two values ); for (1..10) { say $iterator-&gt;(); } } { # 0, 1, * + * ... 34 my $iterator = iterator_factory( 2, sub { $_[0] + $_[1] }, 1, sub { $_[0] == 34 }, 0, 1 ); while (!!( ($_) = $iterator-&gt;() )) { say } }
You've posted this everywhere you can. People, check his post history, report for spam, and move on. Oh, and here's a little something if you still think he's an okay fellow: https://np.reddit.com/r/opensource/comments/am6xhj/host_agrees_to_dmca_takedown_of_gpld_work_after/efm2bd5/ Oh and btw this guy, mikeeusa, LtGerome, GamerofLibre, and Vevnicc are the same person, a spammer. (Oh, and thanks for the shoutout, the GPL is non-revokable after I clone the repository)
Alright, you know what? I'm tired of this shit spewing from you every waking hour of the day. Yes I am. So here's my response to your post: https://old.reddit.com/r/freesoftware/comments/al4rjr/lkml_dmca_takedown_request_to_github_regarding/ https://old.reddit.com/r/COPYRIGHT/comments/al501e/lkml_dmca_takedown_request_to_github_regarding/ https://old.reddit.com/r/linuxmint/comments/alc274/lkml_dmca_takedown_request_to_github_regarding/ https://old.reddit.com/r/devops/comments/alc8pr/dmca_takedown_request_to_github_regarding/ https://old.reddit.com/r/github/comments/alceii/dmca_takedown_request_to_github_regarding/ https://old.reddit.com/r/Ubuntu/comments/alcju8/lkml_dmca_takedown_request_to_github_regarding/ https://old.reddit.com/r/technews/comments/alcmpr/lkml_dmca_takedown_request_to_github_regarding/ https://old.reddit.com/r/opensource/comments/alcpr4/gpl_revocation_opensource_author_sends_dmca/ https://old.reddit.com/r/programming/comments/alcssa/gpl_revocation_vs_a_john_doe_dmca_takedown/ https://old.reddit.com/r/linux/comments/alczpl/opensource_author_sends_dmca_takedown_request_to/ https://old.reddit.com/r/tech/comments/ald4o6/opensource_author_sends_dmca_takedown_request_to/ https://old.reddit.com/r/linux_gaming/comments/aliku3/lkml_dmca_takedown_request_to_github_regarding/ https://old.reddit.com/r/slashdot/comments/aljb72/lkml_dmca_takedown_request_to_github_regarding/ https://old.reddit.com/r/IBM/comments/ami2f6/host_agrees_to_dmca_takedown_of_gpld_work_after/ https://old.reddit.com/r/voidlinux/comments/amlxdi/host_agrees_to_dmca_takedown_of_gpld_work_after/ Tell me, how does this have anything to do with IBM? Linux gaming? It's a 10 year old casino project that nobody uses, and if anything, it's *you* who is Chicken Little here, making a mountain out of a molehill because you can't stand being wrong. You're a pedophile who can't stand being wrong and insults everyone if they try to offer a counterargument, since you're so closed-minded. To [quote you](https://www.reddit.com/r/opensource/comments/am6xhj/host_agrees_to_dmca_takedown_of_gpld_work_after/efm2bd5/): &gt; I HATE that you scum banned men from marrying cute young girls forever ago. Motherfucker, you're insane, and you're going to learn that today. Not only did you assume that I'm white (I'm not), you also assumed that I'm catholic (I'm not), and that I give a shit about anything you say. You're wrong. You're so wrong that I'm going to make sure that everyone else knows that you're wrong too. In that same post I just referenced, you asked someone for what city/state they lived in. Gee, that seems like the smart thing to do. To give a pedophile keyboard-warrior who gets angry and calls someone a "woman-worshiping white FAGGOTs" my address would only make my day. Fuck off with your less-than-subtle tactics at doxxing people, we can see through it. Btw [here](https://www.reddit.com/r/opensource/comments/am6xhj/host_agrees_to_dmca_takedown_of_gpld_work_after/efmf7w0/)'s where you're assuming that I'm a catholic white man. For all you know on the internet, I could be the exact opposite, an atheist Latina woman (I'm not though), and let's face it, you'd have responded the same way, finding some way to condescend me and try to hit me where you think it'd hurt. &gt; Wishful thinking on your pro-women's rights pro-women-control-of-opensource (which men built) part? You FUCKING PIECE OF FILTH. ([Source](https://www.reddit.com/r/opensource/comments/am6xhj/host_agrees_to_dmca_takedown_of_gpld_work_after/efm2bd5/)) Okay wow. Let's look at the [FSF's members](https://www.fsf.org/about/staff-and-board). You know, the ones who practically *made* the GPL that you keep ranting about because you're so insecure and can't handle being wrong on the internet. &gt; Jeanne Rasata, Assistant to the President Oh wow, look, a woman. I guess she's secretly a man, since there's *no way* that a woman could have possibly contributed to open source! &gt; Molly de Blanc, Campaigns Manager Same thing. So many crossdressers on the FSF, must be a trend. &gt; Dana Morgenstein, Outreach &amp; Communications Coordinator Gee, with a name like "Dana", he must have really wanted to trick us into thinking that there are women on the FSF, and in powerful positions that deal with how the world sees them! Oh, and the most ironic one of all: &gt; Kat Walsh &gt; &gt; Kat Walsh is a copyright, internet policy, and technology lawyer. She was most recently at Creative Commons, where she was one of the drafters of version 4.0 of the CC license suite, and previously worked for the American Library Association in their information technology policy office. Kat came to the free software community through free culture. An early Wikipedian and advocate for free cultural works, she was on the Wikimedia Foundation board of trustees from 2006-2013 (Chair 2012-13), where she advised on strategic, policy, and legal issues, and currently serves on its advisory board. She is also on the board of the Xiph.org Foundation. Kat holds a J.D. from George Mason University School of Law and a B.A. from Stetson University; she is a member of the Virginia State Bar and the US Patent Bar. With your misogynistic views, of course you forgot that the laywer, the one who would have been most likely to work on the GPL itself is a *woman*. You're backing a woman's views. *How scary*. Why don't you contact her if you're having issues with the GPL? I'm sure she'd be happy to help as long as you don't realize just how much a piece of filth you are, a stain on the earth that you've become. If you claim to be a lawyer, I want to make sure that you're never my lawyer. /u/LtGerome or /u/Vevnicc, if you're ever doing any kind of law in California, let me know. I want to stay as far away from you as I could possibly be (and yes, I know that you're going to try to use the fact that I live in California against me. Go ahead, do your best).
Some thoughts about my behavior recently: I've been very misogynistic lately and I'm sorry about that. It's stupid on my part to think that posting on dozens of subreddits at a time and calling people slurs (as well as admitting to being a pedophile) would help anything progress. I've also lied about being a lawyer and what-not, and I've done stupid things. "JohnDoe", /u/comphacker, Leigh Honeywell, Alex "Skud" Bayley, and the entire Geek Feminist collective, you guys have my blessing to take my code and use it as you like. To quote YHWH: &gt; There is neither Jew nor Greek, there is neither slave nor free, there is no male and female, for you are all one in Christ Jesus. ~ Galatians 3:28
https://unix.stackexchange.com/questions/41252/how-to-start-a-perl-webserver-with-systemd
very simplest: just fork twice. exit(0) if( fork or fork ); Then close or redirect STDIN, STDOUT, and STDERR. 
If on a systemd system it's certainly simplest to have systemd manage the daemon aspect. You need very little configuration to run a standard process as a daemon.
You can still daemonize in that way, but check out [Mojo::Server::daemonize](https://metacpan.org/source/SRI/Mojolicious-8.12/lib/Mojo/Server.pm#L28-39) where it's written a little more modern.
Why would a learning perl second edition book be desired at the point?
Does MySQL support arrays nowadays? In Postgres you're able to rewrite the IN clause to something like this: ``` run_query('SELECT * FROM x WHERE y = ANY(?)', undef, ['a', 'b', 'c']); ```
Easiest way?(on a *nix system): if you really just want to start it and forget it: `nohup /path/to/script.pl &amp;` and you should be free to disconnect. For a slighty better experience use GNU/screen or tmux, run the script, disconnect. Then you can reconnect to the same session to look in on it from any other ssh session. 
Beware that by default, [systemd kills nohup-ed processes when the user logs out](https://news.ycombinator.com/item?id=19023885).
Let me add that to the list of things systemd breaks. 
Come on now, we all know that it's not systemd breaking it, it was init doing it wrong &lt;grin&gt;.
I have used [Ubic](https://metacpan.org/pod/distribution/Ubic/lib/Ubic/Manual/Intro.pod) as a service manager
Getting to know the operators is only the first step. The next step is learning the helpful exceptions and additional behaviors that break the function's behavior. I'm talking about things like split " " having a special white space removing meaning, where no other string does, or that using the ? as the match pattern delimiter behaves differently from every other delimiter choice allowed by Perl. Today, if you must learn Perl for some reason, perhaps your effort would be better spent on learning Perl6. Perhaps you are tasked with taking up maintenance of something written in Perl5, in case you have no such options. In any case, you're already learning bad habits such as using the glob strings such as F, whereas every other perl programmer will be using lexical handle names, e.g. open(my ($fh), "&lt;", etc). You should use more modern Perl reference to learn the language from.
so how does one do the equiv of nohup /path/to/prog-to-keep-running-after-logout &amp; with systemd ?
In fact, you can write simpler code: `while (&lt;F&gt;) { print }` And for many people (like me), this is beautiful!
I haven't tried any of this. prophylaxis: https://news.ycombinator.com/item?id=19023986 enable-linger set-linger: https://github.com/systemd/systemd/issues/8486 alias `nohup` to `systemd-run --scope …`: https://news.ycombinator.com/item?id=19032356 https://github.com/tmux/tmux/issues/428
Or: print while &lt;F&gt;; (But I'd recommend moving away from bareword filehandles.)
30 years of knowledge and experience in The Wrong Way is nothing compared to the who of one developer. 
Why are you learning Perl if it's so painful for you? And how are you learning Perl? Your sources seem to be teaching you bad habits. Firstly, there's far too much code in your first example. A Perl programmer would write: while (&lt;F&gt;) { print; } Or even just: print while &lt;F&gt;; And, secondly, we stopped recommending bareword filehandles a very long time ago. These days, you'd use a scalar variable for your filehandle: while (&lt;$fh&gt;) { print; } It sounds like you're on a course where no-one cares about Perl or bothers to keep up to date with it. To be honest, courses like that do more harm than good.
This is not a great advert for the quality of the teaching at http://www.unsw.edu.au/
As they say, a bad workman always blames his tools.
Ahem.. ```print &lt;F&gt;;```
Why are you learning Perl 4 idioms? If you have an instructor, get a new instructor. If you are using a "Learn Perl in _X_ Days" manual, stop. Find resources that were at least updated to be consistent with Perl practices from 10 years ago, like always `use strict;` and airways `use warnings;`. 
Well sure - if you don't mind reading all of the data from the file before printing any of it out :-)
&gt; Today, if you must learn Perl for some reason, perhaps your effort would be better spent on learning Perl6. I don't know why you would say that. There is still plenty of Perl 5 being used in the industry. There is (to a first approximation, at least) no Perl 6 being used in the industry.
Certainly less conventional than the other responses, but I advocate Dockerization. Docker provides your script with services like auto-restart in addition to containerization/isolation, and a long-running processes in a docker container are essentially automatically daemonized
Brother in turmoil, I hear you. Your cries are understood and heard - I have been there and sometimes find myself back in that neighborhood. I started learning perl about 4 years ago due to taking a job that required me to program in perl and nothing else. Talk about a trial by fire. On the job training was, "Here's the O'Reilly book. read." When I am trying to understand something and I struggle because I am confused or overloaded my natural instinct is to thrash about. I'll say things like your original post, usually with a few thousand more "fucks" thrown in. I don't like that I do it, but it happens. Perl turned me into a toddler and kept me there for a good long time. I still go to that place from time to time after having learned something new (I'm thinking about you unary - operator) but it is far less frequent than earlier in my learning process. I will say this: Perl people try to help. I appreciate all of the help that was sent my way. However. It's easy to forget what it was like before you understood the basics of perl, and there are SO MANY basics you have to understand before you can even understand the help that is being offered. So ask your questions to the perl community - I feel confident you will receive many offers of help. If you don't understand the help you've been offered it can be a learning experience (that might be painful) and you might even learn the help offered is not applicable to your problem, but it will show you how not to do it, and possibly how to do something else. There are still many concepts perl handles that I don't have a mental grasp on and I don't know when I will understand them. The perl community uses terms and ideas that are still foreign to me. As an example, I've read in several perl books, including the o'reilly programming perl book, that arrays are bad - use hashes. I am not just being pedantic when I say a hash is an array. It is an associative array and that is just that. How often is that brought up in any of the books or help so that someone coming from a different programming language might help make that connection? Rare. But it's there. You'll be admonished for saying it, but a hash is an array. Anyway, man I feel you. I'm there with you sometimes. Perhaps one way we differ though is I actually love perl. Now that I have the basics down and I feel more comfortable with the language I really don't see that I have the need for any others. I hope you make it to this place in the perl-learning mindset. We will still visit this seedy street of language-bashing, I feel confident. But fear not, though it is dark and shadowy, we are not alone. We are being heard by others in the shadows. I believe they are nodding their heads, taking a slow drink, and silently rubbing their chins from the protection of the shadows on this street. We're here man. Let it out. It will get better. There's more than one way to do it. 
While that maxim is true, I believe in this case it is too broad. OP isn't a bad workman, he's a new carpenter, so to speak. It takes a journeyman carpenter exactly 2 hammer strikes to sink a 16d nail into a piece of wood. A beginning carpenter helper will think see that he doesn't do that so he buys the same hammer as the journeyman. He then realizes it isn't just the tool but how it is used. He's not a bad carpenter. He's learning -- he's a new carpenter.
I'd do the same as you, other than I'd use `chop` to get rid of the last comma. 
Are you sure you even need to run it daemon mode? Proc::PID::File + a crontab entry can do the trick if you just need to run something on a regular basis. 
And as a new carpenter, he should learn to STFU until he knows what he's doing! :)
I don't think it does unfortunately :/
Thank you! This seems like the way to do it :)
I upvoted form twice, since it is the simplest ignoring any additional data. This approach assumes that fork will work properly in Windows - which it may or may not depending on your perl version. Newer versions tend to fare better here. IMHO you need to provide more info to get a better answer. Some of the other responses touch on this. Do you need to to know if it is running? Do you need to kill it? Should only one instance run at a time? ... And lastly, Powell had been around a long time. Just because advice is old doesn't mean it is wrong. The TIMTOWDIness if perl almost insures that there will be multiple solutions. Some may suit your needs better than others. As long as it does - use it! Good luck, lbe 
Thanks! I'll take a look. A lot of times I get frustrated with SQL generators, because then I have to learn how those work in addition to SQL, especially for more complex queries. However, maybe it's worth the time to learn how this works since I write a lot of SQL from Perl.
Cool! I didn't know about [chop](https://perldoc.perl.org/functions/chop.html). Thanks!
&gt;Then close or redirect STDIN, STDOUT, and STDERR. And chdir to /. 
While it's likely wasted breath, I'll just say that every language will look like garbage before you've learned it. Also, `&lt;F&gt;` can be written `readline(F)`, and it's recommended not to use bareword filehandles, so you can avoid both of those oddities. There are [good tutorials](http://perl-tutorial.org/) out there, if you go into them with an open mind you'll find yourself understanding much more.
&gt; Today, if you must learn Perl for some reason, perhaps your effort would be better spent on learning Perl6. If I was to recommend learning an entirely different language, node/JS or python would probably be more fruitful.
If you are on linux; # grep '#!/usr/bin/perl' /usr/bin/*
At work, I use a Perl script to manipulate and prepare large numerical listings for our database server. The script only had to be written once and I’m the only one that uses it.
https://formulae.brew.sh/formula/ipcalc
I think the IMDB website is written in Perl. At least it was back in the day.
booking.com runs their backend on Perl, I believe. And I know an ad tech company that uses Perl for their backend.
Significant chunks of Amazon run on Perl.
The **[ghost](https://ai.neocities.org/perlmind.txt)**.pl AI in **[English](http://ai.neocities.org/EnVerbPhrase.html)** and in **[Russian](http://ai.neocities.org/RuVerbPhrase.html)**.runs on **[Perl](http://strawberryperl.com)**.
Many of linux utils. You can query your package manager for packages that //depends// on Perl. Git, a package manager, tools like `dch`...
There are a lot of software involving perl, completely or partially. Have a look at https://github.com/topics/perl
[Bugzilla](https://www.bugzilla.org/), [ddclient](https://sourceforge.net/p/ddclient/wiki/Home/), [SpamAssassin](https://spamassassin.apache.org/), [autoconf](https://www.gnu.org/software/autoconf/), [irssi](https://irssi.org/)
&gt; If I understand you correctly these are the three layers: &gt; &gt; base programming language &gt; &gt; transformation layer (meta layer) &gt; &gt; user code written in a DSL &gt; &gt; That is a useful way to think about it, but in Perl6 those are all one layer. &gt; Likely we are not at the same page. The 3-layers of programming are all at programmer's realm -- vs. programming language designer's realm and library/cpan-module realm. The programmer constructs his code at all three layer the same time. The bottom layer is the non-ambiguous layer; the middle layer is the implicit layer; the top layer is the presentation layer. Let me use an natural language example: you tell your son to "go to school". Now the three words are the presentation layer. However, the picture/meaning in your mind when you saying "go to school" is your son wrapping up breakfast, checking school bags, putting on shoes and jacket, walking out of the door, taking the school bus or riding the bike. These are the bottom layer. How would you and your son and your rest of the household your meaning when all they heard and all you said is "go to school"? There is this implicit convention layer that you build up over the time. For the first few time, you probably need actually walk your son through the process as you saying "go to school". At some point, you no longer need explain this implicit layer but it is available when ever your son fail to interpret correctly or any new relative/friend who raises question. That is the middle layer. As you see, you, the programmer, work at all these three layer. The English committee -- university professor, dictionary editor, language police -- only provide the tools and parts and provides the ultimate facility to spell out the bottom layer, but they do not control your program, even at the bottom layer. They do have some influence on your middle layer -- usually people say "go to school" more or less means the same thing -- but ultimately the middle layer is completely defined and controlled by you, household and application specifically. Then as to the top layer, it is context dependent and ambiguous by nature. Programming language and DSL and custom syntax and new keywords that in most current conversation context are not context dependent and ambiguous, which means they do not reflect my top layer -- or the way we use natural language exactly. &gt; but in Perl6 those are all one layer. Typical compilers or implementation of programming languages all have many layers, none of them are the layers I was talking about. I am talking about the layers strictly on the programmer side. 
Many commercial websites. Most famously [booking.com](https://booking.com) but also significant chunks of other big sites (though few tout their use of Perl). Many open source projects covering a wide range of application. [Openhub](https://blog.openhub.net/about/) is "an online community and public directory of free and open source software (FOSS), offering analytics and search services for discovering, evaluating, tracking, and comparing open source code and projects.". You can see projects they track that use Perl by using their various search options such as [a search for all projects they track that involve perl](https://www.openhub.net/p?ref=homepage&amp;query=perl). (Some of the projects that Openhub tracks -- in all languages but more so older languages like Perl -- are stable or dead. But their monthly commit activity graphs reflect the latest state of play for the projects they track. They show that Perl's *relative* share among the languages used in all the projects they track about halved for the 5 years from 2009 thru 2013 and then remained roughly stable for the last 5 years, i.e. 2014 thru 2018. Here's an aggregate chart comparing [C#, Go, Haskell, Perl, Rust, and Scala](https://www.openhub.net/languages/compare?utf8=%E2%9C%93&amp;measure=commits&amp;language_name%5B%5D=csharp&amp;language_name%5B%5D=golang&amp;language_name%5B%5D=perl&amp;language_name%5B%5D=haskell&amp;language_name%5B%5D=rust&amp;language_name%5B%5D=scala&amp;language_name%5B%5D=-1&amp;commit=Update) over the last decade. In the same timespan Python's share has gone through the roof from twice as much share of open source projects as Perl 10 years ago to 10 times as much share today. Here's Openhub's chart comparing [C, Perl, PHP and Python](https://www.openhub.net/languages/compare?utf8=%E2%9C%93&amp;measure=commits&amp;language_name%5B%5D=objective_j&amp;language_name%5B%5D=c&amp;language_name%5B%5D=perl&amp;language_name%5B%5D=php&amp;language_name%5B%5D=python&amp;language_name%5B%5D=-1&amp;commit=Update) (I included Objective-J to set a near zero baseline).
cPanel used for shared and reseller webhosting is written in perl. 
I used to work for a web host and, IIRC, cPanel is written in Java, not Perl.
You are 100% incorrect. cPanel is written entirely in Perl.
cPanel is written in Perl https://forums.cpanel.net/threads/in-what-programming-language-is-based-cpanel.248071/
[ack](https://beyondgrep.com), the grep-like search tool for source code.
a) yes b) no c) no d) no The pattern just has to match *anywhere within the line*. If there are multiple matches possible, the leftmost one wins; if there are multiple matches possible at that position, the longest one wins. So in `2nd 3rd` the pattern `[a-z].*[a-z]` matches `nd 3rd` because that is the leftmost longest substring that both starts and ends with a character in `[a-z]`. And then that substring gets replaced with the empty string because that's what's in the right part of the `s///`. 
[duckduckgo.com](https://duckduckgo.com) runs on perl. &amp;#x200B;
[duckduckgo.com](https://duckduckgo.com) runs on perl. &amp;#x200B;
 (this is the result of a very simple backtracking algorithm). Got it, makes sense now! cheers
ZipRecruiter runs on perl
Because Perl5 is so quirky. I think Perl6 is more regular in nature, so it would be easier and more satisfying to master. I'm assuming learning Perl5 isn't just for employment, and to be honest I wouldn't learn Perl to gain employment today, it is clearly a language on its way out of the door.
Regexes work left to right in every sense. Quantifiers that can match a variable amount of characters will try to match as much as possible by default, or as little as possible with the `?` (non-greedy) modifier. Alternatively the `+` (possessive) modifier will prevent backtracking. So this regex will look for the first character that matches `[a-z]`, then try matching `.*` with as many characters as it can (the entire rest of the string), then try to match the next character with `[a-z]`. It can't because there's no characters left, so it backtracks to match one less character with `.*` and so on until it finds a match. If it doesn't, it backtracks to the initial `[a-z]` and tries the second character in the string it matches, and so on, until it exhausts all possibilities. If the `.*` had the non-greedy modifier applied (`.*?`), it would try the smallest amount of characters it could match first, which in this case is the empty string, and work forward from there. If it had the possessive modifier applied (`.*+`), it would match as much as it could at that position and never backtrack to try less (thus the pattern could not match, because it would always match the rest of the string). The `perlre` documentation goes into detail on the regex engine, particularly the sections on [quantifiers](https://perldoc.pl/perlre#Quantifiers) and [backtracking](https://perldoc.pl/perlre#Backtracking).
I do it differently. Avoid passing ID lists in SQL where possible, replace an ID list with the query that returned the ID list in question. This will achieve two things: firstly, it teaches you how to model things in a way that is tractable relationally, and generally gives higher performance. Surprisingly, many databases have terrible performance for looking up rows by ID, they just process the construct as a sequence of individual unrelated row fetches, which gets slow when the number of ?s increase to hundreds or thousands. Some databases even resort to just doing a table scan on the source table once the number of ?s pass a fixed threshold. In some situations this advice is not applicable, like maybe you presented a list of results to user and the user literally selected by hand some subset of those presented rows for further processing. ID lists can be the right tool for that job.
On a different theme ... [Frozen Bubble](http://www.frozen-bubble.org/) is an arcade-style game written in Perl using the [SDL](https://metacpan.org/release/SDL) (Simple DirectMedia Layer) library for graphics, sound, and user input etc.
And on a completely different note, [Tau Station](https://taustation.space/), a free-to-play narrative sci-fi MMORPG runs on Perl. [Watch our trailer here, if you're curious](https://www.youtube.com/watch?v=RZ5ocaGjaNs).
but how much referral commission can one earn from a $1 book anyway? :-)
Netflix used to!
BBC iPlayer was built using Perl too. 
I don't think your ex would be very happy to read this. She must be beautiful if Perl looks like her, but you are blind to that beauty. 
What are these "many" and "some" databases? 
Not sure what the benefit would here.
I write my books (fiction and poetry) in Kaun text and then process them with a program I write to generate DOC/PDF/EPUB/MOBI versions. This way I control the style perfectly and avoid file corruption and bloat. (My program interfaces with other free tools after processing; I certainly didn't write a PDF or an EPUB filter.) 
This is great, saved -- thanks mate
They say the same thing about $1 Viagra spam. All it takes is one person to click buy and you made a profit.
*Woah!* It's your **8th Cakeday** quintus_horatius! ^(hug)
But please don't read the source code. It's some of the worst Perl in existence :-)
I used to work on websites running the open-source e-commerce package [Interchange](http://interchange.rtfm.info/index.html), which is entirely Perl (OK, a little Javascript on the front-end).
I work there!
Me too!
Love to see more cool stuff leveraging libffi.
Your middle layer creates a DSL that is the top layer. It's just a very limited form of DSL. It's roughly the same as a Perl5 source filter. $call define_sequence fib: 0, 1, a0+a1 Is roughly equivalent to this Perl6 code: define_sequence (my &amp;fib), 0, 1, * + *; `define_sequence` could be a source filter like you created, or it could be a macro which does exactly the same thing but on the AST. or it could even be a function: sub define_sequence( &amp;name is raw, **@args ){ my &amp;code = @args.pop; my $seq = (|@args, &amp;code ... *).cache; &amp;name = sub ( UInt $index ){ $seq[$index] } } I would call all of them a DSL. If given enough time and tuits I could even make it so that the following would work in Perl5 without your middle layer. define_sequence "fib", 0, 1, "a0+a1" --- You know what else could be considered a DSL? Every module that imports a subroutine into your namespace. Again it is a very limited form of DSL, but it still has all of the hallmarks of a DSL. It changes what is considered valid code in the language. --- I would absolutely argue that the Perl5 module `Moo` is a DSL, and all it really does is import functions into your namespace. --- So there a various ways to create a DSL - add functions - preprocessor / source filter / your middle layer - interact with the compiler (Keyword::Declare) - modify the parser Perl6 basically combines all of those different ways into one. --- &gt; One always need to _learn_ a DSL to use the DSL. Yes you need to learn other peoples functions in order to use them. How is that different if the function is `fib(…)` or `… fib`? sub postfix:&lt;fib&gt; ( UInt $n ){ (0, 1,*+* ... *).cache[$n] } say 10fib; sub fib ( UInt $n ){ (0, 1,*+* ... *).cache[$n] } say 10.&amp;fib; say fib 10; say postfix:&lt;fib&gt; 10; --- If your middle layer was good enough people would eventually only work at the top level. At which point it doesn't matter how it works under the hood. Frankly if I liked your middle layer enough to use it with Perl5 I would turn it into a source filter. I created [something similar](https://github.com/tsee/Games-Lacuna-Client/blob/master/data/build_types.pl) using a Template-Toolkit2 [file](https://github.com/tsee/Games-Lacuna-Client/blob/master/data/Types.tt2), which generates Perl5 [code](https://github.com/tsee/Games-Lacuna-Client/blob/master/lib/Games/Lacuna/Client/Types.pm). - layer #1 Perl5 - layer #2 TT2 file - layer #3 Yaml data file You know what? Nobody should ever look at the generated code unless they are trying to change the TT2 generation code. If there were a way to create a Slang in Perl5 that didn't make it slower every time you loaded the module, you can better believe that I would have used it because it would be nicer than trying to write Perl5 code with TT2. The resulting Perl5 file is an artifact that I don't care about, and would prefer if it didn't exist. Guess why. Someone already hand edited the file rather than the data files, even though it clearly says not to at the top of the file. I don't see any benefit to keeping them as 3 separate layers if you design the middle layer so that it is easy to understand the bottom layer by looking at the top layer.
Only criticism I have is the single use of system().
&gt;&gt; One always need to learn a DSL to use the DSL. &gt; &gt; Yes you need to learn other peoples functions in order to use them. You ignored my example. Let's say I visit your house, I hear you tell your son to "go to school", and I get the idea, and I go home start using "go to school" in my house. I did not learn whether "go to school" requires finishing breakfast or not; I did not learn which school did you son go to; ... etc. But that doesn't prevent me start using it. So if your DSL requires learning, then your DSL is not my DSL. In fact, it is you that insist to call my top-layer DSL (that is fine, but please don't insist my meaning). &gt; You know what? &gt; Nobody should ever look at the generated code unless they are trying to change the TT2 generation code. I emphasized that my 3 layers are all on programmer side, but you ignored it. In my analogy, seeing your son's actual action including talking back is the bottom layer that ultimately defines the meaning of your words. If you insist that one can throw away the bottom layer, then you don't really need the middle layer (since it is rolled into the compilers), then you, as a programmer, don't really have 3 layers at disposals. Your model is not the same as my model. It is fine if you insist that you only need 1 layer for programming. I am saying that having 3 layers gives you unprecedented power. For example, you can just say "go to school" to your son, and refine to the bottom layer via the middle layer. 
webmin
If you don't like that, there are other ways which have been added to Perl. open my $fh, '&lt;', 'example'; while ( my $line = $fh-&gt;getline() ) { print $line; } I don't see what the problem you have with `push @lines, $line` Is it just because the parens are optional? push( @lines, $line ) --- Also you should always have this at the top of your Perl programs until you know exactly why they are recommended: use strict; use warnings; Note that `use v5.12` or later turns on `strict` mode so you can shorten that to: use v5.12; use warnings; Since you are learning, it might be a good idea to turn on `autodie` as well.
Your 3 layers has less power than Perl6's one layer. In Perl6 I can directly interact with the abstract syntax tree. Which means I can do things that wouldn't normally be allowed in the language. Your code must eventually return Perl5 code, meaning you are limited to what Perl5 can do. Sure you could eventually come up with ways to work around it because Perl5 is Turing complete, but it wouldn't be easy. --- Your `go to school` example shows that even in your not-a-DSL-DSL you must “learn it” to “use it”. (Assume that your coworker made the middle layer.) --- You also seem to ignore the fact that if anyone changes the bottom layer directly either those changes get overwritten the next time you run the middle layer, or your middle layer has to be more complex to handle that. Also you can't combine more than one such layer without risking collisions. Perl6 does not have any such problem because your additions get parsed alongside everything else. Also Perl6 restricts changes to the current lexical scope, is your middle layer powerful enough to do that? my $a = 5; { sub postfix:&lt;!&gt; ( UInt $n ) { [*] 2..$n } say $a!; # 120 } say $a!; # ERROR --- Also if you really want to see it as 3 layers, ask the compiler to output the AST.
That's funny. Some time ago I wrote part of my toolchain in Python. Then I more or less had to re-learn Perl, because it is used in my production environment. After a year or so I wanted to do a few changes in the Python tools.... And lo and behold, those Python scripts looked just like a lot of line noise. I guess any language can look horrible to untrained eye. And don't get me started on JAVA and Groovy. My eyes bleed anytime I see source code in Groovy, let alone Java. Perl is complex and has steep learning curve. And provides a lot of power. And with great power comes great responsibility.
Been years and years since I've used it, but it's written in perl: http://www.webmin.com Still very active, last commit from today: https://github.com/webmin/webmin
Oh nice! Was looking to do this for internal keyboard as well. Might use this a me a starting point.
&gt; Your 3 layers has less power than Perl6's one layer. &gt; Perl 6 could be my bottom layer. Every time I trying to explain that MyDef is not a programming language, it is difficult to get that idea through. &gt; Your go to school example shows that even in your not-a-DSL-DSL you must “learn it” to “use it”. (Assume that your coworker made the middle layer.) Coworkers can make part of the top layer as well, and of course we need communication. The 3 layers (the one that I am referring to) are integral part of authoring programs. There is no such thing as different person responsible for different layer. With "go to school", both your son and you are cooperating on the middle layer to get the bottom layer correct. Neither you nor your son can work independently on the middle layer. &gt; You also seem to ignore the fact that if anyone changes the bottom layer directly either those changes get overwritten the next time you run the middle layer, or your middle layer has to be more complex to handle that. The bottom layer is for unambiguous communication or verification as well as for debugging. The code is not persistent and never propagate back up to top layer. The top layer + middle layer determines the bottom layer. Think this way, your final program is uniquely specified by the bottom layer and provides an unambiguous layer for communication and verification. Your top layer is for higher level communication and often ambiguous and context dependent -- as our communication in natural language shows, it is highly efficient and fits how our brain works. The bottom layer, of course, fits how machine works. The middle layer is not for communication, but for bridging the two layers. In practice, if the top layer communicates the abstract idea well they don't need look at your middle layer at all. All they need is to check your bottom layer for verification (of their understanding). 
Is this so that the cat can use it? 
Thanks! In this situation I have a list of 'types' that is just an array in my class, and not results I'm getting from a query. But I will keep this in mind!
If “MyDef is not a programming language” then it is absolutely less powerful than the features built-in to Perl6. The top layer should be unambiguous communication. If it isn't, it is time to go back to the drawing board because it isn't good enough yet. If the top layer is unambiguous, there is no need to see what the bottom layer looks like. If the top layer syntax for controlling MyDef isn't in any way a programming language, then it is even less useful than I thought it was. I mean I thought it might be useful for Perl5, but I certainly don't now. A higher level syntax for Perl5 would be handy, but you keep insisting that it isn't even as powerful as the simplest of source filters which creates a DSL. If it isn't a DSL, or allow you to define a DSL, it sounds like it is adding extra complexity for very little benefit. Also if I said “go to school” then I don't care how the child gets there only that they do. I don't care how a Perl5 source filter works, only that it does. I don't care how Keyword::Declare works, only that it does. I don't care how defining an operator in Perl6 modifies the parser, only that it does. (Actually it copies the parser, and modifies that copy.)
What is this space-vim?
&gt; only in perl is this valid logical syntax &gt; &gt; "while ($line = &lt;F&gt;)" { print $line; } Um, no, that's a syntax error: &gt; $ perl -ce '"while ($line = &lt;F&gt;" { print $line; }' &gt; syntax error at -e line 1, near ""while ($line = &lt;F&gt;" { "
&gt;WHAT THE EVER LOVING FUCK? Without any clear warning of the dangers involved: What is your issue?
People think that downloading scripts from the web and piping them into bash is riskier than downloading other software and running it without checking the source first.
This is just a way to install SpaceVim, you can checkout the github, and clone the repo, run install script after read the content. &amp;#x200B; [https://github.com/SpaceVim/SpaceVim](https://github.com/SpaceVim/SpaceVim)
Right, I know. Still, you asked what the issue with "curl ... | bash" was.
&gt; if I said “go to school” then I don't care how the child gets there only that they do. Certainly you would care which school does your child go to and how he/she gets there -- you may not have that experience yet to understand. That is the bottom layer, it describes or specifies the exact execution of your program. At top layer though, all these details comes at different shade and the very top is simply "go to school". I think what you trying to express is that you don't care about the middle layer that how your child gets from "go to school" to all the details including which school to go to and the manner and safety of getting there, as long as your child gets these details unmistakably. 
Seriously? You don't know the dangers of piping a shell script off the internet?
You could have phrased it a lot better. 
Presumably you're referring to https://www.idontplaydarts.com/2016/04/detecting-curl-pipe-bash-server-side/ - in which case you might also want to direct your attention to prominent Perl sites such as https://perlbrew.pl/ and anyone foolish enough to run a CPAN client locally.
Yeah, I was never a fan of perlbrew's installer, nor with their failure to warn of the obvious dangers.
Not everyone capitalizes the first words of sentences. But note that what I said is still not what you said I said. There was more information in my statement.
Fair enough, but I don't think any style guide calls for recasting a sentence to avoid a capital letter, which is why I said it was too much to ask. 
The MoarVM backend eliminates many function calls automatically, by inlining. It is actually more likely to produce faster code if you write many small subroutines. In Perl6 on MoarVM it is more performant to write operators as functions than to do the transformation that MyDef does. If you write it as a operator function then the compiler knows what you are doing and can optimize it. It is even possible to write plugins for the optimizer in NQP especially for some Perl6 functionality that gets added. MyDef is likely to defeat such optimizations because it is outside of the parser. With Perl6 “I build contexts, abstracting details into different parts, most critically I keep logics from entangling while not making comprises at the bottom layer.” Perl6 has “… builtin facilities [that] are [awesome] for such refactoring as they often [make] changes [to] the bottom layer” at my whim. If I want it to work differently I make it work differently. --- Guess what, those features that you are afraid of are the exact same ones used to make Perl6 itself. The infix addition operator `+` is actually a set of 27 multi subs. say &amp;infix:&lt;+&gt;.candidates.elems; # 27 So if you add two numbers together you get the “function call overhead” that you so despise. Moreso even since it calls the proto sub which has to figure out which multi to actually call. say 5 + 7; say infix:&lt;+&gt;( 5, 7 ); That was a bit of a fib, because Perl6 can figure out to use the one that takes two Ints, and edit the bytecode to call it directly. my &amp;temp = BEGIN &amp;infix:&lt;+&gt;.cando(\(5,7)).head; say temp(5,7); Since it knows exactly which function to call, it can get inlined. `infix:&lt;+&gt;` is marked `is pure` so it really just replaces the value with the result. Any operator that I write gets used in exactly the same way as “builtin” operators. It is a bit of a mistake to call them builtin operators, because they kinda aren't. They are really just user operators that come standard. --- If you think MyDef is better, which one of these would it most likely produce: for ^20 { say 'hi' } loop ( my int $i = 0; $i &lt; 20 ; ++$i ) { say 'hi' } Actually forget answering that, which one is faster? Last month the second one was a bit faster, today the first one is about the same speed. What's worse is that the second one has potential for spooky action at a distance. I think the best way to write that is actually: say('hi') xx 20; --- If you use the features in Perl6, your Perl6 code is going to be faster than if you do some transformation on top of it. You will also be able to use the features that enforce correctness. If you use a tool to produce Perl6, you have to learn Perl6 and that tool. If you use Perl6 and Perl6 then you have to learn Perl6. Why would I use your tool to produce code that is at best not slower? --- Also if a child isn't responsible enough to figure out how to get to school safely then they aren't responsible enough for me to tell them to “go to school”.
Mine does.
Well, I think it is too much to ask. 
Every style book I’ve read (when I was getting my degree in journalism) said to not start a sentence with a lower-case letter (such as the AP Style Guide, and IIRC, Chicago Manual of Style). Now, AP (last I saw) does allow changing the capitalization (so “Brian d foy wrote”) is acceptable when possible, and Chicago allows using the lower case to begin a sentence in some cases, but **almost all** editors will tell you that the best solution is to avoid the problem by recasting the sentence. This is why Apple has frustrated so many journalists since the introduction of the iMac. Even though Apple offers an exception, that exception does not overrule the newsroom, and the newsroom style trumps any external style manual, whether it is AP Style or the suggestion of the owner of the trademark. Note that *necessarily inherent* in any style guide is that the rules are optional unless explicitly stated otherwise; that said, this “rule” was *explicitly* optional all along anyway, due to the word “should,” not to mention the part you cut out: &gt;*I merely make a suggestion based on most reasonable style guides that prefer not to break the sentence-style capitalization in these cases. Recasting the sentence avoids the problem.* &amp;#x200B;
Dude, you have achieved the rare distinction of being pedantic and sloppy at the same time. Let me be pedantic and precise in order to further clarify what I mean. First of all, I am a journalist too, but in my case I am a Spanish speaker, so I get the point about style guides making pronouncements about things like "iPhones" starting sentences. That kind of thing doesn't happen as naturally in Spanish because we need to put the article first ("Los iPhones") so it's very, very uncommon for the trademark to start the sentence... unless it's a company name. for example, "eHarmony". (That's the way you write, right?) To summarize, I get the need for journalists to walk around words like "iPhones" in English speaking countries. Having said that, there are two points in your comment where you are misrepresenting what I said or what I meant. &gt; this “rule” was explicitly optional all along anyway, due to the word “should,” not to mention the part you cut out You point this out as if I had been somewhat sleazy about it. In fact I was very much not. If you reread my comment _including the part you have left out yourself_ you'll find this: &gt; **it's true that you make it clear that it's a suggestion, but still** I've emphasized it this time so that you can find it. The second part where you've been sloppy is in the comparison between brian's suggestion and a newsroom style guide. While I get the need for style guides and I've found myself bound to them while working on newsrooms, you are completely missing the point that in this case brian d foy **is not analogous to the newsroom you work in, but to Apple**. i.e. he as the owner of the name can make any suggestions he wants, but your boss at the newspaper will have the last say in how you need to write those names. The AP style guide can make you reword your sentences so that you never use "iPhones" at the beginning; but if _Apple_ asked this of you, *it would be too much to ask*, which is exactly what I'm saying about brian's suggestion. 
Do you need '-base'? use Type::Library -base -declare =&gt; qw/Char/; "get\_type" is a method defined in Type::Library. '-base' makes Foo a child of class of Type::Library.
So then I get this issue: &amp;#x200B; Can't locate object method "add_type" via package "Moose::Meta::Class" at /home/parumoo/perl5/perlbrew/perls/perl-5.28.0/lib/site_perl/5.28.0/Moo/HandleMoose/FakeMetaClass.pm line 16. &amp;#x200B; Which I wonder if there are issues because I'm also using `Moo`, but now it's trying to extend Type::Library?
It looks like moving: &amp;#x200B; use Type::Library -base, -declare =&gt; qw/Char/; &amp;#x200B; Above `use Moo` makes this work. Although I don't really want this type to be exportable by people using my module. I wanted to refer to it as a bare word within my package, but maybe the right thing to do is just use it anonymously.
The `Char` created by `Type::Library` via the `-declare` option is not an actual type. It's an object to be used with the utilities in `Type::Utils`. The actual type object is created by `Type::Utils::declare` and is both inserted into your type library's exports (if you used the `-base` option to `Type::Library`) and returned, as you've discovered. If you moved your type definitions into a separate module, then you could obviously use `Char` in your class as a bare word, but that won't get you the clean namespace that you desire, as `Char` is a subref installed into your class' namespace. To avoid that, you can use the fully qualified type name or use [namespace::clean](https://metacpan.org/pod/namespace::clean). Here's some code that shows what happens to the namespace. (The code is designed to be run as a single file; if you split it into separate files you can remove the `BEGIN` blocks and the munging of `%INC:` ``` use 5.010; use strict; use warnings; package MyLibrary; use Type::Library -base, -declare =&gt; qw/Char/; use Type::Utils qw/declare as where message/; use Types::Common::String qw/StrLength/; use FindBin '$RealScript'; BEGIN { # record that this package has been loaded, so Perl doesn't try to find # it in the filesystem when it's used later on in this file $INC{'MyLibrary.pm'} = $RealScript; # this needs to be in a BEGIN block so that it creates the Char type # before package Foo gets compiled, else the Char reference there will # bomb out declare Char, as StrLength [ 1, 1 ], message { 'Char must be a Str of length 1' }; } package Foo; use Moo; use MyLibrary -types; has char =&gt; ( is =&gt; 'ro', isa =&gt; Char, ); package Bar; use Moo; use MyLibrary; has char =&gt; ( is =&gt; 'ro', isa =&gt; MyLibrary::Char, ); package Baz; use Moo; use MyLibrary -types; use namespace::clean; has char =&gt; ( is =&gt; 'ro', isa =&gt; MyLibrary::Char, ); package main; use Data::Dumper; my $foo = Foo-&gt;new( char =&gt; 'a' ); say $foo-&gt;char; say Data::Dumper-&gt;Dump( [ $Foo::{Char}, $Bar::{Char}, $Baz::{Char} ], [qw( Foo::Char Bar::Char Baz::Char )] ); ``` And the output is: ``` a $Foo::Char = *Foo::Char; $Bar::Char = undef; $Baz::Char = undef; ```
You could also do something like this in your code: ``` use Type::Library; use constant Char =&gt; declare 'Char', as StrLength[1, 1], message { 'Char must be a Str of length 1' }; ``` and get a bareword, but you'd still need to clean it out of your `Foo` namespace. One more option (not tested, but should work) would be to use (constant::lexical)[https://metacpan.org/pod/constant::lexical] instead of `constant`. 
[constant::lexical](https://metacpan.org/pod/constant::lexical) to the rescue! ``` package Foo; use Moo; use Type::Library; use Type::Utils qw/declare as where message/; use Types::Common::String qw/StrLength/; use constant::lexical Char =&gt; declare 'Char', as StrLength[1, 1], message { 'Char must be a Str of length 1' }; has char =&gt; ( is =&gt; 'ro', isa =&gt; Char, ); package main; use Modern::Perl; my $foo = Foo-&gt;new(char =&gt; 'a'); say $foo-&gt;char; ``` With the output: ``` a ```
Thank you for the detailed responses! This is all great :) &amp;#x200B; So it seems like since `Type::Utils` only installs it into your packages exports or returns the type object, in my situation it was probably intended that a type object would just be assigned to a variable? &amp;#x200B; That seems like the right thing for me to do, so I think I'll do that. Thanks again for the detailed post! I really learned a lot and I appreciate it :)
That's definitely the easiest way to do it if you want to use the DSL provided by `Type::Utils`. I should note that `Type::Library` isn't needed at all, as you're not building one. I've removed it from the above code for future clarity. You can simplify things much further though, if you don't mind using the `Type::Tiny` API directly: ``` use Types::Common::String qw/StrLength/; my $Char = StrLength( [ 1, 1 ] ) -&gt;create_child_type( message =&gt; sub { 'Char must be a Str of length 1' } ); ``` 
Ah, that's much nicer! I can't think of a reason I wouldn't use this, and it removes a bunch of imports, which is great. Thanks! :)
What exactly do you mean by "I do not have access to a server"? Where will your code run? There's various ways to send email, but you could start by looking at Email::Sender / Email::Sender::Simple - start by reading https://metacpan.org/pod/Email::Sender::Manual::QuickStart There is, of course, more than one way to do it.
I am not sure what you mean by email over ftp, but cpan has a number of modules for it (like Email::Sender) If it is Linux, you could likely skip the module and just use sendmail What is this this ticketing system? You mentioned not having a server. 
Linux environment... Not a server... Are you trying to use Perl to send email from an Android device? Is this homework?
Avoid [triple backtick](http://redd.it/9cyuvb) for code formatting, it's broken for a portion of users, including me. Indentation works always.
"Just use sendmail" has a poor failure mode, wouldn't recommend.
Yeah I am unsure about the "send email over FTP" part too. It sounds like an assignment rather than an actual real world project TBH and there seems to be some misunderstanding about email protocols. 
Modules in the `Email::*` will be your best bet - in particular, (`Email::Sender`)[https://metacpan.org/pod/Email::Sender] or (`Email::Stuffer`)[https://metacpan.org/pod/Email::Stuffer].
Drop messages directly into the maildir of users? I dunno, that's all I got.
The project is a ticketing system that requires me to send a ticket to the technician. I am trying to figure out the best way to incorporate an email in perl. What I meant by not having access to a server, is that I am currently running Linux from my VM and don’t have access to file/web/email server. 