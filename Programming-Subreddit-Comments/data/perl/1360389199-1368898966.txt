You're welcome. :)
Some dialect of BASIC?
&gt; What if I follow a data directed style of programming and want to extract my matcher and substitutions from data structures? In Perl I can't, because of the queer way regexes are implemented. Why did you think you can't? You can! The world is your oyster. :) https://gist.github.com/wchristian/4745052 use strictures 1; use 5.010; my $t = "ab"; my $r1 = qr/a/; my $r2 = qr/b/; my $s1 = "1"; my $s2 = "2"; $t =~ s/$r1/$s1/; $t =~ s/$r2/$s2/; say $t; __END__ 12
&gt; You just declared that you can't, so I can't help you there. Sure you can. People have a habit of proclaiming their opinions and ideas as fact, and it is only nice to show them how reality is formatted if it is easily recognizable that their inner reflection harshly deviates from it. I've done so in a post neighboring this one to save you the work. :)
There are three kinds of projects: * Green field development. * Resystemization * Incremental improvement Unfortunately all of the perl 6 efforts are falling into the resystemization area. These rarely succeed and when they do it is rarely because they meet their original goals. 
This is sad to see Parrot and Perl6 devolving into such a train wreck. Maybe an RPython implementation would be easier after all.
Is it correct to say that the project was just too ambitious? I can't quite piece together the why of it all. What I seem to see is that the people were chasing a moving target. And bootstrapping a whole new compiler + language + vm is a big task. The mystery to me, though, is why it didn't fly, with talent of that magnitude. Those people have built lots and lots of other things, so why this one in particular didn't fly remains a mystery to me.
For many years I stuck with Perl because I saw Ruby and Python as sidegrades. Nifty, but no compelling reason to switch. These days I'm messing with Go and it is surprisingly awesome. I think something like Go (or maybe Rust, when they get around to specifying it) are the future. Go is not flashy but it addresses real world problems rather than just playing around with syntax: effortless deployment (static binary distribution, no lib::local or perlbrew mess), real integration with source control for package import, fast compilation and fast execution. 
#3 and #4 are much easier to parse in the case of multiple inheritance. #3 matches the syntax used by Moose (and some Sub::Exporter things too I think).
Not every package with a parent class is an instantiable module.
Talent does not make one immune to having the perfect being the enemy of the good.
Many people will disagree with me, but I believe the biggest problem remains that the pressure to produce and support a working product is less important to the current developers than their desire to do other things. It's really not fair for me to speculate about what they feel, but perhaps they'd rather produce something which they believe is "complete" than something that is generally "useful and usable by regular people". (Alternately, I'm being petty and bitter and should give them the benefit of the doubt and wait just a little bit longer.) When Parrot started to get serious about producing a mature product in 2009, it didn't lead to more users and only seemed to frustrate Rakudo all the more. I can't entirely blame the Rakudo developers for that frustration. Maybe that's not fair to suppose. The intent of Rakudo Star was to produce a useful and usable and supportable product, but it certainly hasn't met my needs, even two and a half years later--and I thought I would be an *ideal* early adopter.
&gt; effortless deployment (static binary distribution, no lib::local or perlbrew mess) That kind of statement only makes sense when you have a wide range of third party libraries available. Does Go have that?
No, not quite on the level of CPAN, but the standard library is quite good, and more work is being published every day. Also, Go interoperates with C pretty effortlessly, so dynamic linking with local C libraries can fill a lot of gaps. EDIT: Also, this was just posted to HN: https://gist.github.com/freeformz/4746274
Good riddance. The file IO is broken. The network functions are broken. Threading is nonexistent. It's slower than IE6. It pulls the rug out from under Rakudo so often that all their monthly releases since the middle of last year have ranged from subtly to unusably broken. And this is only the shit Rakudo end users have to put up with. Remember, the only reason this VM even exists? Don't pretend those toy languages they've been pissing around with are significant. You (yes you, specifically) wanna know why Rakudo is getting nowhere? It's because it has to work around this piece of crap all the time! Parrot is *completely fucked*. I almost want to go back to PHP at this point, at least *they* could figure out how to write a working VM. They keep their bitching to their own mailing lists too.
Is the standard library equivalent to Perl core? Because right now you seem to be telling me that Go does not even remotely have anything similar to CPAN; which, if true, would make any comparison based on deployment pointless. Also, speaking of deployment: If i develop on debian, how easy a time will i have preparing a Go program for deployment on windows? Right now in Perl all i need to do is make sure my tests aren't dumb.
Perl 6 has specs for file IO, networking, and threading now?
Alright, while your view on what CPAN is or is not is quite naive, i got a good idea of what Go can do now. (I'm throwing you a bone by skipping the talk about testing.) However, the crucial question is still open: Is there actually a wide array of third-party libraries that are used by the majority of Go developers? To make this more clear: In Perl the percentage of programs that do NOT make use of a third-party libraries is far below 1%. Are Go programs similar? The cross-compilation thing is all kinds of baller though. :)
If Perl 6 can't do I/O, networking, or threading, then it seems like it isn't worth much, regardless of whether these things are in the spec or not.
Go does not have CPAN Testers, no. Go does have built-in testing out-of-the-box, which includes benchmarking tools and embedded dual-purposes example tests (examples for documentation that basically verify themselves). I don't think the third party environment for Go is as expansive as CPAN, but it's a young language. Here is a pseudo search.cpan.org for Go: http://godoc.org/ A sore point: the Go regular expression engine is extremely primitive (and slow). It also does not have a heredoc operator.
Yes, the IO refactor integration wasn't particularly well-executed, at least to some extent due to the fact that no one makes sure that Rakudo and Parrot stay in sync. Rakudo doesn't build on latest Parrot? Just downgrade and move on. For your particular example, the issue might have been fixed [on the same day your gist was created](https://github.com/parrot/parrot/commit/1d6430d658d010aeaedd6f9943403827d4237f06), but I cannot verify as on my machine, Rakudo HEAD doesn't build on Parrot HEAD.
So, might the list be somewhat not inaccurately paraphrased as: first system, second system, third system?
I would certainly hope that a project would not hold back on fixing a significant bug simply because the guy reporting it is being a jerk...
I don't know, is niecza really promising? And it still rely on a technology which is hostage of Microsoft goodwill, hardly something I'd want anything I'm working on to depend upon.
I'm not usually a bastard to this extent. But I'm completely burned out on restraining myself when replying to whiny assholes who don't know when to take a hint and *shut up*. The same two users crop up Every Single Time anything positive about Perl 6 gets mentioned on reddit: chromatic and shevegen. If this shitty attitude is what everyone else got out of him before he “silently stopped contributing” (bullshit, if you're going to leave then *leave* and stop being a hemorrhoid on every public channel you can find) then no wonder Parrot lost most of its other devs.
I try to spend my spare time in enjoyable ways. I think I am not so alone in this. 
This is nice. Thanks for making it.
&gt; shevegen What you do with shevegen is pick the useful bits of his posts, reply to them in a manner that is positive and otherwise ignore him. He doesn't actually hate anything, he just enjoy making people's lives hard by posting intentional and obvious troll comments. Heck, usually he even crafts them in such a way that any decently aware person can quickly dismantle them and gain positive publicity from it. TL;DR: Don't take it personal, he's a professional troll.
Why focus on niecza? Would you confuse the state of Perl 6 and Java if Rakudo ran on the JVM?
The Parrot Foundation is shutting down and looking for another organization to take on the copyright and code--and then Allison and I had a discussion the other day asking "Does the project even *matter* anymore?"
**Reystemization?** It's convenient to put things in boxes for the sake of discussion, but reality is more messy. Are you aware of ways in which Perl 6 projects are greenfield? Incremental improvement? **Parrot is not Perl 6.** The Parrot relationship to Perl 6 is like that of a car engine project to a car project. At the start both projects thought that the new engine could, should and would be a great fit for the new car. That said, the car project (Perl 6) designed and implemented engine related subsystems in such a way that other engines should work too. Thus, for example, Rakudo Perl 6 will almost certainly be running on the JVM this year, perhaps this spring.
Would you find a Go backend for Perl 6 interesting? Edit: swarley is writing a Go backend for nqp which is a short hop from porting Rakudo to a Go backend which in turn is a short hop from mixing Perl 6 and Go.
Are you talking about Parrot or Parrot + Perl 6?
I see. Thanks for explaining. 
&gt; almost certainly ... this year. Um, hooray?
&gt; Can you see why I am impressed by the car project's dedication to what can work over what is fun? No. If I were evaluating this project, I'd look at it and say "I'd sure like to drive that car, but instead of getting one model out the door so that it can transport me safely from point A to point B, the designers are going to spend the next couple of years making sure that they can swap out whatever pieces of the car that they like," I'll spend the next couple of years driving some other car instead. Or, *as it actually happened in my case*, I just won't go from point A to point B.
&gt; Is it correct to say that the project was just too ambitious? I can't quite piece together the why of it all. My understanding of the problem is that, although the Parrot project began with the goal of being the main back-end for Perl 6, as time passed the goals changed. Instead of being the VM for Perl 6, the folks working on it broadened Parrot's goals, such that it would be a multi-language VM. This may have been because Parrot devs saw that Perl 6 was taking a while to fully design. Or maybe they saw things about the Perl 6 language which they didn't like. Or maybe they were seeing interest from implementors of other languages. I don't know the history here. Parrot and Rakudo drifted apart. And communication between the projects became strained. And you know the rest. Parrot is still the current back-end for Rakudo (with support for the JVM currently being *added* to Rakudo). It seems to me that there's still a chance for Parrot to refocus on exclusively supporting Rakudo, and be successful at that. In fact, as we speak, folks are looking into how Parrot might do that. We'll have to see. 
&gt; ... as time passed the goals changed. Yes and no. Remember Ponie? One of the earliest goals for Parrot was to run both Perl 5 *and* Perl 6 code. The name Parrot even came from an April Fool's joke about merging Python and Perl. As time went on, some Parrot developers gave up on Perl 6 and new developers arrived who cared about other languages which weren't Perl 6. &gt; I don't know the history here. There was no single ultimate vision for Parrot which trumped all other goals, just like there's no single ultimate vision for a Perl 6 implementation.
&gt; There was no single ultimate vision for Parrot which trumped all other goals, just like there's no single ultimate vision for a Perl 6 implementation. Well, suppose that the ultimate vision for Parrot became: * complete focus on being what Rakudo needs * slim down Parrot (jettison extra features irrelevant to supporting Rakudo) * begin work on some sort of "good enough" interop with Perl 5 (not like Ponie, but some way to use an external Perl 5 interpreter, maybe something like Blizkost?) * get C lib interop together If those goals trumped all others, do you think Parrot would have a future in Perl 6? Do you think the project would gain contributors? (Have a look at today's #parrot logs; it appears those goals are being considered as a possibility). 
Okay, but wouldn't your regex match 'alsdfkad asdlfkj asdlkjfweoj asldfk' just as well as 'the quick brown fox jumps over the lazy dog'? OP defines non-gibberish as 'words (without spaces in between)', and it seems like 'thequickbrownfox' would meet that definition. From my understanding of regex, \W only matches characters that are permitted for use in words, not characters that are actually in a readable word in the string being tested. If I'm wrong, of course, please enlighten me.
&gt; If those goals trumped all others, do you think Parrot would have a future in Perl 6? I don't, no. Edit to add: The belief that Parrot is the source of Rakudo's performance problems and instability is almost a matter of dogma now. When I was profiling and optimizing (and fixing bugs in both sides) back in 2010, it looked like about 50/50. Some of that was the mismatch between what Parrot provided and what Rakudo wanted, but that's a far different question. Certainly Parrot's bytecode is a terrible format, the calling conventions are optimized for the slowest path, and the considerable overhead of switching between managed code and C code loses a lot of speed, but a lot of the code generated by Rakudo would have run pretty poorly on almost any VM. In particular, one important part of the Rakudo parser was code that would have brought any register allocator of which I'm aware to its knees. It doesn't matter how good your O(n) performance is when n exceeds a certain point.
I think you probably need to look at some kind of API, google comes to mind. Aside from that the old crack password check utility would let you compile dictionary indexes, but I'm not sure if there's a module wrapped around that available.
I don't think you're answering the question that was asked. The OP presumably wants a string like "xyzaardvark" to match, but not "dlkhjfsdiqjp". `\W` and `\b` are completely irrelevant for this. 
Yes, this is my intention. So that "thequickbrownfox" would be flagged as containing words, but "haidjkecbaownfsx" would not. Ideally something such as "tbequickbronnfox" would also be flagged as containing words, but the strings that I'll be dealing with will be ~500 characters so hopefully there will be an easy distinction between containing some words and gibberish.
This is pretty sweet. Can we have a peak at the source? And do I -have- to login with twitter?
You're putting words in my mouth. I chose the word "immediately" with great care.
Fair enough; so the *amount of time* it takes to fix a bug is based on whether the person is being a jerk rather than on its significance.
Entirely understandable. :-)
Sure :)
&gt; Rakudo Perl 6 will almost certainly be running on the JVM this year I'll put it on my calendar. 
[Here you go](https://github.com/berekuk/play-perl). Multi-auth with account linking, a-la metacpan, is [in the plans](https://github.com/berekuk/play-perl/issues/7). I don't know when it will happen, though, there are so many other features to be done!
Awesome. Thanks
Upvote for the suggestion of [n-grams](http://en.wikipedia.org/wiki/N-gram), with [trigrams](http://search.cpan.org/dist/String-Trigram/Trigram.pm) being a good starting point. I remember a blog post about using trigrams to recognize whether two strings could be the same name, possibly with the words reordered.
I can think of a few approaches to this problem, some more expensive than others. The best first step would be to analyze the data you do have and look for characteristics common to good and bad text. Standard English speech will consist of, on average about %38 vowels (a,e,i,o,u). Letters randomly chosen from the alphabet would be less than %20 vowels. Either 'A' or 'E' should be about %20 of the characters you encounter. If this is true of all of the good text you encounter and none of the garbage text, then vowel frequency alone is a good test. If you need to be more thorough make a list of 100 (or 500, or 1000) most common English words (you should skip words of less than 3 letters to avoid false positives). Then loop through that list and increment a counter when index($text,$word) returns a non-negative value. I suspect your good text should score much higher than garbage text.
Considering that OP mentioned his input text is about 500 chars, words like ("the", "and", "that", "have", "with", "for", "not", "you") are so common, that search for incidents of those words in your text may be enough. If your garbage text is truly random it will not contain those sequences anywhere near as often as regular English text.
I commented on this in the article, but I'll put this here too. Something that causes a visible error like this is not what people normally refer to as "data loss". In fact, if you use that definition then hard disks can have data loss because if it's full, otherwise valid data will cause an error. Data loss for programmers is usually when a system tells you it took your data but then drops it under certain circumstances. Yes, this is a limit of SQLite, but it's not "data loss". 
I ended up downvoting this thread. He's just wasting time -- not looking for community review. It's an amateur script without a build system that calls external bins, and patches providing input about more mature methods are denied.
I'm not sure I buy into the last paragraph. I think for more cases than not, SQLite is a great choice. MySQL is overkill for many uses. How many Wordpress(yes I know PHP) blogs actually need MySQL or Postgres? 
"He's not doing what I told him to do, downvote"
? eh, regardless of what I tell him to do, I don't expect him to publish a single-file script and come here and simply not look for advice.
Death Valley, California or Purgatory City, Colorado? I kid...
I've been keeping an eye on RethinkDB, but it's still a few years away from being usable.
I'd suggest that if you're wanting a database that multiple processes are going to update, then SQLite is the wrong solution. It's a lightweight tool that's perfect for standalone applications that only need to store their own data, but if you're going to want concurrent access (or at least concurrent **write** access) across a number of processes then it's the wrong tool.
It's probably not a big issue for blogs. They do writes for new blog entries and comments, but there's *a lot* more reads than writes.
Is it a requirement to be a university town? It would seem so.
2011 was done without any university involvement.
This is true. Howerver, newer versions of SQLite(I think 3.6? maybe) introduced optional write ahead logging so that readers don't block writers and vice versa. Keep in mind one of the beautiful aspects of SQLite is that it is simply a library. Introduce a heavy database system and that is another game all together. On that "simple" line of reasoning, a heavy-write library such as LevelDB is often a good choice if writes outnumber reads. But blogs these days are often just tumblr/github pages, often static(Jekyll or similar) and with externally hosted comments(Disqus) managed via javascript.. 
Any town large enough to have a decent convention center or medium-to-large convention hotel will work nicely for YAPC. As far as these kinds of events go YAPC::NA is relatively tiny, less than 1K attendees on average. However any town large enough to support meeting spaces for 500 people will usually have a decent sized unvieristy in it as well. That said I have thought about writing bids for tourist destinations that are more remote than others. Glacier National Park in Montanna would be a beautiful location, they have hotels that work well as retreats that I *think* (I haven't done the actual research yet) would accomodate a YAPC. The same is true for Yosemite and several of the national parks, especially the older ones that pre-date the National Park Service when they had to earn their living as tourist desinations. Any more you can purchase the AV equiment for a YAPC for less than $2k which means that any venue where you can hold 4-5 concurrent talks and house ~500 people will work for a YAPC::NA. Be creative!
Perhaps we can get a discount on a Carnival cruise ship with a disabled engine. At least then we'd have a captive audience as well. 
Having been a small part of the planning for YAPC::NA 2012, I can't imagine how it would work without somebody close to the venue. The planning team is all volunteers, after all. I think a remote tourist destination would be awesome. I'm just not sure how it would work logistically.
Please, please no more US. Let's have a YAPC::NA in Canada or Mexico. Preferably Canada because it is in the middle of the god damn summer. Ugh, why Austin, TX? WHY? Don't people remember the swamp ass from Houston in 2007?
Well, put in a proposal, then. TPF only goes off the proposals they get.
Have a look at http://search.cpan.org/~rschupp/PAR-Packer-1.014/lib/pp.pm
Oooh, interesting as that is it isn't quite what I'm after, thanks! :) I want to get all my module and its dependencies together in a tarball that I can distribute, and then people can download it and do whatever it is that's normal for perl apps to do here. I guess, as with modules, it's to run `perl Makefile.PL; make ; make test ; make run` or similar, but the plan is to end up with 'normal' Perl scripts in /usr/sbin and a normal Perl module installed to wherever is generally viewed as the right place to put it.
I'm not a Perl 6 specialist; I know that pugs is basically dead, so remain Rakudo and Niecza. I don't know of any other compiler. Not that I care much at this point.
Maybe you're looking for something like Shipwright? http://search.cpan.org/dist/Shipwright/
Fascinating! I've never seen nor heard of Shipwright before and it has been out over 4 years. How time consuming are the vessels to build? And sizewise? Here's a blog post about when version 1.0 was released: http://blog.bestpractical.com/2008/02/shipwright-our.html
I was going to suggest a trie as an alternate implementation, but RE2 is essentially building one anyways with that simple word list, and is doing it a hell of a lot faster than pure perl.
Yeah, in reality I'll mostly ship it around at work as a deb, but I was so sure I'd seen a 'standard' way of creating a tarball that it seemed the most sensible way to order the repo. If there isn't such a de-facto standard, then I'll just script the deb creation as it is. 
I was the lead organizer for Asheville (YAPC::NA 2011). Nobody on the organizing team lived in or near Asheville. It is do-able you just have to rely upon your venue event staff more and be incredibly prepared to hit the ground running.
What he said! There is no reason you can't put in a bid from Amsterdam!
If your CLI program is in ./bin/myscript, ExtUtils::MakeMaker, add &gt; EXE_FILES =&gt; [qw( bin/myscript )], to Makefile.PL. That won't necessarily send it to /usr/bin, you need to check where your perl is configured to install executables. But this is what I use for a package I currently maintain at work. It also has the benefit of doing the "right thing" if you want to install it under perlbrew (w/o root priv).
When I built an application for Debian/Ubuntu using Perl I ran into the same sort of issues. Most of the Module -&gt; .deb type of automation/instructions were for making a `libfoo-bar-perl.deb` library type package that didn't handle (or I couldn't figure out how to do..) things for applications like adding .desktop entries for the menus, putting icons in the right place, or placing config files in /etc. So I sorta rolled my own maybe slightly broken .deb package (all the stuff under a debian directory needed for dpkg to build a .deb). I'm not sure I remember how to actually build a working .deb anymore, but the Module::Build configuration went like this: my $builder = Module::Build-&gt;new( # other M::B stuff etc_files =&gt; { 'contrib/selfcontrol.sh' =&gt; 'etc/init.d/selfcontrol', 'contrib/keep' =&gt; 'etc/selfcontrol/.keep', }, # similar for gnome_files ); $builder-&gt;install_path(etc =&gt; '/etc'); $builder-&gt;add_build_element('etc'); # same for gnome stuff $builder-&gt;create_build_script(); That would let `perl Build.PL; ./Build test; ./Build install` place those files that lived in the `contrib` directory to specific places in the filesystem. So you'd put your script in a `sbin` directory (not `bin` where the install step would place it wherever Perl is configured to install scripts), and just add the appropriate 'sbin_files' section to Build.PL. You could also just make a regular Module::Build script, place your script in `bin` and install with `./Build install --install_path script=/usr/sbin` to override the default script install path.
I can see you don't know Perl 6. But I also see troll behavior that might be an innocent accident. Here's my last post in this thread branch. 1. Unless you want to look dumb in the tech world, don't confuse the state of JavaScript and of Java even if you hear that JavaScript runs on the JVM. 2. Neither this reddit (which is about **Parrot** -- note the title) nor confusing Parrot and Perl 6 has anything to do with Perl 6 or Parrot. It's just a basic misunderstanding.
I would add - Perl is about the only language around that treats me like a responsible adult and allows me to use 'goto' if I so choose. As an old C programmer, it's nice to be able to easily use references ("pointers") to construct data structures.
Sigh...the only message that article effectively advocates is that perl programmers live in caves.
I subscribed to the paper edition of Dr Dobbs Journal in late 90's/early '00s. It used to have good articles. This article is definitely not one of them and looks like it has been rehashed from 1995. There are more specific, modern reasons where Perl shines compared to other languages. I'll list several here. * variable scoping (Python doesn't have lexicals, JS only recently, none of Python/JS/Ruby/PHP has local [dynamically scoped] or state variables). * strict mode (Python/PHP/Ruby doesn't have strict mode, JS only recently). * tainting mode (only Ruby provides something similar). * phasers (BEGIN/UNITCHECK/INIT phases), allowing you to do cool stuffs during compilation/pre-execution. None of Python/JS/Ruby/PHP has this. * some advanced regex features like code/conditional/subpattern/recursivity in regex, making stuffs like Regexp::Grammar possible. * the most advanced/complete Unicode support among programming languages; What else?
Stupid sexy Flanders.
Lots of other languages offer goto, even PHP and BASIC. Perl doesn't have pointers. References in Perl (and most other higher-level programming languages) are not equivalent to pointers, since they do not facilitate pointer arithmetics.
From the software developer's perspective maybe. From a systems administrator's perspective, Perl provides a fully featured shell interface within its programming environment without the need to import a single module for most common tasks. For this reason Perl has a place in the modern world for a long time to come, regardless of how many people are searching google for Perl related topics.
There has been a YAPC in Toronto and another in Montreal though I am not sure if the latter was sponsored through the TPF. Talk with Dan, all things are possible when you're talking about a $20,000 dollar event.
Thank you; I know very little about perl and had not been impressed by the article, so it was nice to hear more about the relatively special features that Perl --- i.e., you gave me some new terms to Google. :-)
I fully agree. I work with, and enjoy writing perl nearly every day. But this is weak advocacy that sells the language, tool chain and community far short.
Not something that will set perl aside forever, but I feel it's worthwhile learning for much the same reason vi/vim is worth a basic understanding. It is available on most systems without me having to install it.
take a look https://www.youtube.com/watch?v=oZ5xTI1QRTA
Wow, hadn't heard of Slaughter but it looks awesome.
An simple option not mentioned yet: you can just distribute your program along with a list of modules which the user must install first.
Thanks. That was some of what I hoped to see in the article. I'm trying hard to like Perl, cuz my job is largely supporting an old Perl app. But I'm not finding it easy (to like Perl). The article suggested why it might have made sense to use Perl back when my app was written. But it only rekindled my desire to port it to something easier on my eyeballs.
There is no technical reason that requires bumping the major version number in order to "drop the baggage". Why can't P5P just announce that 5.20 will be the new "major version" and 5.18.x will have long-term support for those that want backwards compatibility?
Exactly.
If all you need is packaging small applications in debs, you might be interested in https://github.com/komarov/debosh
My impression from these articles is that Larry has abandoned Perl 5. I have no problem with that; he should work on what interests him. However, P5P has become as polarized as congress and equally as functional. Perl 5 needs a new Benevolent Dictator who can make these kinds of decisions without a lot of arguing and bike-shedding.
Perl 5's Benevolent Dictator is the set of people who are willing to do the work. The arguing and bike-shedding comes largely from a disjoint set.
&gt; Are there any fundamental issues with using perl to take in huge formatted text files and filter/alter them? Since perl has been backronymed as "practical extraction and report language", I'd said this is the task that it is best suited to do. But yeah, more details would be necessary to help you. 
I agree that it has become polarized, but functionality??? Functionality comes with the language itself, and does not depend on the state of the community. Perl 5 is perfectly functional as it is. 
Oh man, I misread you. I read "p5p" as "p5", this is, "Perl 5". Please forget my objection. I thought you were talking about the language itself.
Well, there's no *technical* reason, but there's a *social* reason. Historically Perl 5 has had a very strong commitment to backwards compatibility, so trying to get that changed now is very, very difficult. Also, there is the very reasonable expectation in the wider world that backwards compatibility breakage would be accompanied by a major version # change. 
The year.month thing doesn't really work for languages, IMO. Every Ubuntu release is a *huge* change since all the packages have been updated, whereas the difference between Perl 5.18 and 5.20 is way, way smaller. And we'd still need a way to indicate that a given release breaks backwards compatibility, so the problem I wrote about isn't solved by year.month naming at all.
I think the debate about the version # all by itself misses the point, which is why I wrote [a blog post about the future of Perl 5](http://blog.urth.org/2013/02/12/the-future-of-perl-5/). Also, at this point appeals to Larry on Perl *5* ring very hollow to me. Larry has not been involved in Perl 5 for years and years, so I'm not too concerned with his statements about it any more.
No, I probably shouldn't have implied that overcoming the social reason would be *easy*. I'm just not convinced that starting a fork with a new name is the *easier* solution. But then it also depends on the type of changes. Changing the dereference operator is a whole different ball game from "strict by default", for example.
I loved the Toronto and Montreal YAPCs, and would be thrilled to return to either city. I'd also love a YAPC Quebec City of YAPC Vancouver. You know what to do ;) 
I guess what I don't understand is if you want to do BIG changes, why not work on Perl 6? Sure, it is a bit of a mess at the moment but you are talking about *a lot* of work either way.
If you can read and implement the best practices set out in this (pretty freakin' awesome) text: http://shop.oreilly.com/product/9781565922204.do then you get to call yourself advanced. In fact, if you can get through this entire text: http://shop.oreilly.com/product/9780596102067.do you get my personal 'advanced' sticker of approval.
Perl 6 is a huge jump, full of very experimental stuff. Perl 5++ could be a more modest jump, bringing Perl 5 into the modern age. Basically, what I'd like to see is some sort of Perl 5 and Ruby mashup, so ... * Meta-programming and MOP built-in * All built-in types are objects, all built-in subs are methods (but still callable as subs) * Make it easy to pass block params (this is something Ruby does nicely) * Built-in async support - something simple and message passing based would be ideal - even better if this could be done with threads and without * Subroutine signatures (with types) * C interface that isn't XS * A grammar separate from the implementation so we can have even better tools that aren't insanely hard to maintain (I'm talking about you, PerlTidy and PPI). Yes, Perl 6 has all this (except maybe the message passing?) but it also has tons of other things that mean it's going to be a while before we get it. In other words, I want [Moe](http://moeorganization.github.com/moe-web/).
&gt; Every Ubuntu release is a huge change since all the packages have been updated, whereas the difference between Perl 5.18 and 5.20 is way, way smaller. That's not the point. The point is managing the image externally. The point is to signal Modern Perl. It can't stay Perl 5 any more since people outside of the community think of what they saw in 1999 and 2002 when they hear that. That's not what Perl is today. Even if we don't like the look of Perl 2014 we can still use that naming convention as a tool. Because the point also is to get away from the 5 vs 6 trap. Using the year is a brilliant dodge. Here's the evolution: * Perl 5.18 (and Perl 6) * Perl 2013.x * Perl 2014.x * Perl 15.x * Perl 16.x If we're cheeky we can just skip the transition step and go straight for 13.
Again, just bumping the major version leaves us in the position of having *no way* to signal backwards compatibility breakage, meaning we're stuck in the same position that we are now. I'm all for doing marketing *too*, simply bumping the major version without including substantial changes is a transparent ploy that will quickly be dismissed.
I dislike like year.month version - it's harder to pronounce, and it's not elegant. 
Firefox and Chrome did it.
Read the file in line by line, using a while loop, not a for loop. For() loops secretly read in the whole file in the background, and dole it out line by line, so you need whacks of memory. while() loops really do load small subsets of the file at a time. Instead of using a pipeline of programs, why not implement the various transformations as modules, and use a configuration file to determine the order in which they are applied to the input, one line at a time. Modules may need to maintain state of what has been seen. 
Interesting books, will give them a try, thanks. 
Do these people have the power to decide to break backwards compatibility or change Perl's revision number scheme? From the comments on Ovid's post and what the article here said, it sounds as though Larry is against either. Is that authoritative?
&gt; Do these people have the power to decide to break backwards compatibility... Yes. It happens with every release. There's now a deprecation policy, and some things (misfeatures, outdated code, unnecessary core libraries) get deprecated and eventually removed. &gt; ... or change Perl's revision number scheme? I suppose so, but I find it unlikely that Perl 5 will ever not have "Perl 5" in its name.
Understanding multiple levels of nested references. Unfortunately a very unintuitive feature of Perl.
A perl developer becomes advanced when they can type regex like its their first language and you get referencing/de-referencingright the first time :P
I would add [Higher-Order Perl](http://hop.perl.plover.com/book/) though that might be the step above 'Advanced'.
All right, that's good to know, thank you. I'm going to gather what I know about the old program and consolidate it into a coherent several lines. 
That's great to know, I'm newer to Perl and the for loop thing is not something I knew. I'll definitely keep that in mind
Maybe Perl 5.yyyy.mm 
Complete facility with references and objects. The ability to use regexes effectively — and to know when not to use them. Knowledge of anonymous functions and closures and when they come in handy. Knowledge of some of the more obscure but painful pitfalls and how to avoid them — unwanted autovivification, indirect method calls, circular references, and other stuff. The ability to answer questions about someone else's code by reading the source, when the docs aren't enough. Enough internals knowledge that if you have to use Devel::Peek or B::Concise to debug a problem, you might have some idea what you're looking at. What XS is, what an SV, AV, HV, CV, or GV is, what an "op" is, and why JSON::XS quotes your numbers sometimes but not other times. If you can read Higher Order Perl, know what most of the words mean, and learn something that sticks with you, you're an advanced programmer. If you can read Higher Order Perl and absorb the whole thing the first time through, you're superhuman.
How can you call something a monstrosity when you don't know Perl that well? Are you a new programmer taking over from some senior programmer that is no longer around? Perhaps using some Java knowledge you have into it and trying to apply it to Perl? Perl and processing text files is one of its huge strong suits. I recommend just doing it all manually, as it doesn't seem that you understand the language you're trying to refactor. I'd fully recommend not messing with the "bash/perl pipeline monstrosity" unless you absolutely have to, especially if it works as it is. At least not until you have your Perl skills up-to-par. You may do more harm than good, and honestly waste company time. Good luck!
...eventually Perl faded into obscurity alongside other long-dead languages; it's swansong an incoherent babble about version numbers and benevolent dictators amid plaintive cries for a long-imagined but never realized dream of a modern rewrite of the original, and last (usable) implementation of the language. Few noticed, fewer cared. ~ History of Computing in the 21st Century
So long, and thanks for all the fish.
Backward compatibility is currently mostly irrelevant in browsers. But, that does answer the marketing concern. I have no idea what version of Chrome I'm running, and only have vague notions of what version of Firefox (I guessed 14, turns out it's 18.01). Obviously what matters is real forward movement, not the numbers following the project name.
I think that they an call the next version Perl 6, and send the former 'Perl 6' squatters to find themselves a new name. But the problem with the Perl core is not the name, but that p5p are very conservative, and the lack of man power to change and improve things. The whole perl5 project, as I see it, is on maintenance mode. Fixing bugs, adding a new function, ad so on. the power to change things dramatically (such as adding different threading model, new object model and such) simply does not exists anymore. So my point is, if you want different things, use a different language. Perl is not going anywhere. I will continue to use it, just be aware of its shortcoming. 
TIL I'm an "advanced" Perl developer despite never being able to read my own code more than a month after I wrote it. Yay! :)
That's because it's so advanced!
Yes, I'm saying that if Perl 5 is going to have a future it wlil be as a new language with a different name that draws heavily on Perl 5. But the name change is only necessary because of the version number mess we're stuck with now.
Woohoo! Advanced Perl Expert from day one!
Except... you know... :)
Keep in mind that Perl 6, while it's a great language, is a *different* language and it's not guaranteed to gain market share. I would love to see it get some traction, but there's a big difference between the powerful, successful and widely used language we currently have versus a more powerful but little-used language we'd like to see become popular. There are plenty of great programming languages out there which simply don't gain widespread adoption. We can't know if Perl 6 will be successful or not. We *already* know that Perl 5 is successful. Without a clear upgrade path from Perl 5 to Perl 6, these two languages are guaranteed to go separate paths. The issue, therefore, is that some people see a brick wall blocking Perl 5's path. We can't upgrade to Perl 6 and we don't see a clean way of making the major changes to Perl 5. I don't think that renaming to Perl 7 is a good idea (and I regret that I've reignited this debate with that particularly ill-thought example), but I do think there's a problem and I don't see any good solutions to it.
What about when you get pissed off at remembering whether you wrote it as a hash or a hash ref, get pissed, and swear to yourself to only use references from then on?
[It's not stupid!](https://www.youtube.com/watch?v=inR02pEesCQ)
To be honest I'd ignore the older Perl books these days -- a lot of them have lost their relevance since the release of newer versions, and commonplace but non-core extensions like Moose, DBIC, Catalyst etc. These days I'd be more inclined to point people at Perl Best Practices, Modern Perl, or something specific on Moose, DBIC or Catalyst. Ninja edit: http://perlhacks.com/2013/02/perl-books-2/ has more thoughts on the same line
I still like the YYYY.MM meme. Perl 2014.01 (or whatever) could be announced waaaaay before hand to be breaking stuff. Those in the Perl would now would understand that and those coming in with that version wouldn't really care. The social issue goes away with that and Perl 5.XX goes into maintenance mode.
That's not true. We announce and announce and announce that Perl 2014.01 *will* break backwards compatibility and if you don't want that, stay on Perl 5.XX. That solves the social issue because those *in* the Perl world now will know and those coming in at the new version change won't care. I agree with jplindstrom totally.
Sure, we don't know if Perl 6 will be successful but at least it exists. I don't see any reason to think that Perl7/Moe/Whatever will be successful either; you are just splintering the community, again.
Personally, I don't like the plus signs in the name. Would prefer "Perly", "Perl5i" (I realize there's already a Perl5i :) ), or the like. (Heh. "Moe, Larry, and Perly".) 
My point is, why not just call it Perl 6? It is not like Rakudo or Niecza implement 100% of the spec.
"Perl yyyy.mm" doesn't work because it co-opts the name "Perl" for itself (thus snubbing Perl 6). "Perl 5.yyyy.mm" could work though, IMO. 
Perl 5+i.
i have that first book, i'm reading bits here and there but the style seems to have changed from the examples i'm finding online these days. I've noticed higher order perl i'd check that out probably. Also a handy quick and easy to read/use as a reference book i've found was "effective perl programming" 
Beginner is when you don't know anything. Intermediate is when you think you're advanced, and advanced is when you know just how much you don't know. :)
&gt; I think the debate about the version # all by itself misses the point I don't think anyone's debating numbering on its own. My point was only that the numbering is not going to change, so discussing that as a tactic to solve problems is a waste of time that obscures the real issues that people want to address. I'm not at all discounting anyone's concerns, only the magic bullet of changing version numbers.
I thought part of the discussion was how to make a major change when we can't increment the major version number because Larry won't let it go. It's not a perfect solution, but it does sidestep the initial hurdle. We could just rename it to Perl++ instead :P
Or bump the current Perl 6 stuff to Perl 7.
I'd argue that basic understanding of profiling, debugging and the symbol table are important..
In short, yes, the canonical way to distribute an application in Perl is as a standard module distribution that happens to install a script. Ideally, most of the code is actually *in* modules, and the script looks something like #!perl use My::App; My::App-&gt;run; 
I don't think Jifty ever caught on strongly outside of Best Practical, and I don't think *they* write anything new with it these days. Gantry is deader. Neither one has been updated for PSGI, which I consider to be a pretty big fault these days. My preferences run to Web::Simple for small stuff and Catalyst for the big. Dancer isn't bad, but it just doesn't suit *me*.
It's breaking my back button.
That's neat. A good way to make Play Perl even more appealing is removing the exclusive twitter requirement. 
Oh, nevemind, if you're talking specifically about /welcome page, I know what's going on. Thanks, I'll fix it.
I believe I've just fixed this.
The bar we started having regular meeting in shut down last month. We are working on another and should have it by the second Monday in March. If you wanna meet up for a drink or whatever before that let me know and we can find someplace :)
Also we're in #orlando on irc.perl.org 
Wow, that's one best Perl talk in years. Perl really lacks decent aficionados. 
Wait, that's your conclusion? One might conclude just the opposite.
This talk is awesome. This guys is (nerdy but) awesome. Perl needs more ppl like this. Perl needs more aficionados. That's my conclusion. TLDR: Good, need more.
I would say that Rakudo is pretty much feature complete (with a few caveats), aside from concurrency. The primary obstacles are: * Performance tweaks (it's almost there and the JVM may solve that) * Libraries * Minor fixes here and there
Hi Ovid, I love Perl. I love Perl 6. I know enough to know 6.0.0 is going to happen. I agree with Damian's "extraordinary language" comment. But I felt uncomfortable when I read your portrayal of the status of Perl 6. So **I'm going to play devil's advocate here.** I'll start with **speed**. In [this recent exchange](http://brave.neckbeard.ca/r/perl/comments/12vtbw/i_know_python_very_well_is_there_any_reason_i/c716bke) harbud3, who is not anti-Perl 6, measured Rakudo as being something in the order of **100x slower**. At that time (3 months ago) **#perl6ers agreed**. I've been watching closely enough for long enough to be confident Rakudo is going to catch up and overtake the Pumpkin Perl binary for many things in, say, 3 years, and perhaps for selected benchmarks this year. But the "now 4x slower" and "was 20x slower" comments in your blog post shocked me. If you're right, well, wow, in a very good way. But I think you've missed a zero. Please, please take a breather and don't let it get you down if you find I'm right, but please double check. I think that, when the time is right (I get the sense you might be thinking that's now or soon) the module/library writers will kick in en masse. I would guess that time to be 2014, perhaps the last half. There are currently about 100 or so modules, many of them trivial. Unless there's an influx of Perl 6 writers, I'd be very surprised if there were more than 1,000 modules by the end of 2013. (I'm ignoring Zavolaj which is Perl 6's elegant FFI solution.) Other than speed and libraries, you mention just "Minor fixes here and there". I agree that the remaining work to get to a 6.0.0, compared to the huge amount of work of the last 12 years, is *relatively* minor. But **some remaining fixes are major** (NFG and Buf stuff, while exactly the right thing, does not look likely to be a piece of cake) and there is still a heck of a lot of minor fixes to do. Unless something remarkable happens (such as another dozen Perl 5 heavy hitters jumping in to help for a year or two), **I find it very hard to imagine Perl 6 being anything other than bleeding edge for most folk for the next 18 months and quite plausibly 3 years**. It would be awesome if there was an influx of help, or at least a respectful, details oriented discussion in the Perl community about getting to 6.0.0, and planning for an optional future reunification of Perl 5 (Pumpkin Perl?) and Perl 6. But I'm definitely with chromatic on the need to not oversell the current status of Perl 6.
Hi raiph, The benchmark comments were from discussions I had at FOSDEM, plus I ran that article past several Perl6 folks and no one commented on the timing. That being said, I can (sadly) replicate the benchmarks you link to. Even accounting for startup time, Perl 6 winds up being far slower. I'm going to try to track down the folks I chatted with and try to find out the misunderstandings, but for now it looks like I goofed. As for the "Minor fixes here and there", I meant "minor" from the standpoint of the vast majority of devs who won't use the features that are being worked on. For example, "shaped arrays": they're absolutely lovely, but they're not a blocker. "precedence and associativity of new operators": again, awesome, awesome idea, but marginal from the standpoint of the average dev and thus not a blocker. So I think your points are mostly quite valid and I should probably write a follow-up blog post citing your issues. Thanks for the feedback!
I'll be so happy when systemd replaces cron. I've seen so many hacked together batch systems based around cron, and they tend to be very fragile. 
How does systemd change that?
systemd can already run job X at time Y. Additionally you can use it for dependency management: start ssh after networking. If systemd moves to replace cron (don't know if it's confirmed yet), scheduled jobs will get dependency management capabilities. So scenarios like: * database job runs at 16:00, reporting job runs at 17:00, if the database job runs late, tough * database job runs at 16:00, reporting job runs at 16:00, but checks for a "job done" file or some other fs based locking mechanism * database job runs at 16:00, reporting job runs at 16:00, but polls the database every minute to see if it's allowed to actually run ...get replaced with proper job dependencies. This makes systems easier to support because they don't all have some different batch management scheme. There are a ton of other benefits to having systemd manage your process groups, so read [Lennart's blog](http://0pointer.de/blog/projects/why.html)
Note to Perl developers: Please don't make your code rely on systemd. -Thanks from the rest of the computing world(to include sane Linux distributions)!
Fwiw Geoff Broadwell (japhb on #perl6) recently created [perl6-bench](https://github.com/japhb/perl6-bench) for comparing versions of Perl 6 with each other and with Perl 5. I don't think anyone has done much of anything with it yet, and I know Geoff would appreciate someone taking it out for a spin. Please ignore the following if it does not sound like fun, but I'm excited about you spending some of your time to assess Perl 6. I'm imagining something like the following series of blog posts: * how to set perl6-bench up; * initial benchmark results; * a round up of sixer's reactions, others' reactions, any others using perl6-bench; * fresh round of benchmark results published just before [yapcna](http://yapcna.org); * third round, in 2014, on one year anniversary of initial benchmarks; * another round up of sixer's reactions and others' reactions; I agree about shaped arrays and glitches related to new operators and indeed many of the loose ends. The average dev won't care. But they may well care about the painful immaturity in areas such as sockets and signals. And getting NFG done is central to Rakudo's string and buf handling story going from a weakness to a selling point. In August 2009 I wrote "as hard to stomach as it may be, the story remains, even though they've taken a decade to get this far, they may well take ... five [years] to get to Perl 6.0.0 and a generally robust status. All, of course, imo." I still think that's about right. Imo Rakudo is not yet ready for the mass of folk whose focus is getting things done, and, unless there's a change in how folk get involved in Perl 6 in the meantime I don't see it being ready for them till some time in 2015.
&gt; I cant seem to find anything by googling. [Really?](http://lmgtfy.com/?q=perl+hash+map) There are probably thousands of websites showing you how to use hashes in Perl. If you gave some more information on what you were specifically trying to do someone might be able to provide even more specific help.
http://thaps.blogspot.fr/2006/01/perl-bigram-count.html
He/she isn't asking about hashes. They're asking about this: http://anbuwrites.wordpress.com/2010/09/ I think. I don't see one offhand. Here are some graphing modules: http://search.cpan.org/~bwarfield/GDGraph-1.44/Graph.pm http://search.cpan.org/~tjenness/Graphics-PLplot-0.03/PLplot.pm Various things will render graphs. Search CPAN for "graphviz" for modules that interface to that graph plotting package. http://d3js.org/ looks nice but is for JS.
Refreshing change from all the "Perl is dead" babble we hear so frequently.
Well reasoned response. Thank you. Do you personally see embedded, desktop and server Linux systems as all having the same requirement or distinct in their need to manage processes? In other words, do you think systemd is one size fits all? I create embedded distros and also virtualized distros that derive no benefit from systemd. Lennart has been a polarizing figure and his inflexibility for anything not in his realm of "normal use cases" is quite disturbing. Hence, many fear the entanglement and further infection to user-land code that a systemd requirement hints at. Systemd works for some...don't make it a requirement for all.
&gt; He/she isn't asking about hashes. They're asking about this I'm no Java expert, but I fail to see how a Perl hash is fundamentally different from a Java HashMap. To the rest of your comment, I don't see anything the OP stated that indicated anything regarding a graphical module to display a particular data structure. What the OP did say was: &gt; Trying to find a data structure to do bi gram counts I stand by my response that a hash is the most obvious and correct data structure to use to store this type of data. As /u/natmaka has already shown, others have used this exact method in the past as well for what appears to be the exact sort of problem the OP is trying to solve. What else the OP may or may not be wanting help on is impossible to determine at this point because of the lack of any detailed or well defined questions.
I think desktops and servers have fairly similar requirements---embedded always seems very custom. I'm less familiar with embedded systems (outside of some tinkering), so forgive my ignorance around that environment. That said, I don't think sysvinit and cron are a good fit either. Most service start/stop scripts are very similar; encapsulating those similarities in configuration rather than code (bash) is a good practice. Bugs and fragility in process management in an embedded environment is more dangerous than server/desktop because of its lack of accessibility. I also understand that for embedded environments, what has worked for 30+ years is known and safe. It's reasonable to be conservative in an environment where software cannot fail---it's why 2.6 is still around. systemd is new, and I expect it to be vetted on the enterprise server market before it can court embedded devices. I think a lot of the concern is about Linux moving in a different direction from BSD and SysV, and thus older *NIX operating systems. To some extent this is necessary to make full use of the kernel's capabilities, which are fundamentally unique to Linux. I think it's a necessary step to modernize these foundation components like X -&gt; wayland/weston, init -&gt; systemd, and in a broader (and fuzzier) sense, sequential -&gt; massively parallel. 
You could start with this; https://metacpan.org/module/Hash::Map
To everyone who's downvoting the OP .. please stop. Downvotes should be used to hide posts that don't add to the conversation (trolling, off topic, abuse), not to indicate disagreement with a reasonably stated point of view.
Sounds good. I will argue that I think the servers have different requirements. One of my distros is virtualized and meant to be operated in a server environment. I gain nothing from the mission statement on the front page apart from what I have now. As an example simply from the view of starting up...I have 400ms boot times with only udev and devtmpfs because I know what the hardware is going to be. These are servers meant to be disposable and spun up on-demand. Systemd is fast but actually slows me down. I have no problem with the mission statement IF everyone respects the last sentence and not make it a requirement. -- systemd is a system and service manager for Linux, compatible with SysV and LSB init scripts. systemd provides aggressive parallelization capabilities, uses socket and D-Bus activation for starting services, offers on-demand starting of daemons, keeps track of processes using Linux control groups, supports snapshotting and restoring of the system state, maintains mount and automount points and implements an elaborate transactional dependency-based service control logic. It can work as a drop-in replacement for sysvinit. --- Now if you have a modern replacement for ncurses....I am all ears!
What you're looking for is a histogram, and it's [something you can do with the basic hash](http://www.perl.com/pub/2006/11/02/all-about-hashes.html).
To clarify, I am talking about what you originally said, Also natmaka posted something kind of usefully but not what I was looking for exactly. His essentially is a script on how to count the number of bi grams, I need to check if a word is a bigram, save it and then for the next line check again, if it is new make a new one if not (duplicate) increase a counter variable to the bigram. 
TIM TOWTDI; what you say will work. However, it's a very common problem to run one or more jobs when another completes. This is the sort of thing that a job scheduling system (like cron) should do, but it doesn't. Instead everyone implements simple batch management logic, like you describe. This will work in the case of a single job, and can be made to work for multiple jobs. However, what you end up with is a nest of somewhat unmaintained perl/bash/? scripts that provide some subset of features of a full batch management system. In most cases your core business isn't creating a stable, reliable, full-featured batch system---it's to get your jobs to generate the right output as soon as possible, with tweaks to the system as it fails. It makes sense to have a core component that does the heavy lifting and provides a standard interface and set of tools to rerun jobs, see job status, monitor progress, etc. A component that is the same across hosts and across projects.
I think people need to stop treating production systems like toys. If you are going to automate something you ought to do the due diligence to make sure it runs properly, emails the correct address any errors, and doesn't depend on anything that isn't capable of being depended upon. People need to THINK when implementing automation, and the attitude of letting it all sort itself out leads to a sticky mess. Every step to automate should be documented properly in a wiki or something else. The documentation should include who implemented it, what it does, why it is necessary, and should be linked to anything it depends on, or depends on it. I agree that many things should remain out of cron, because there is no real centralized control for it, but sometimes you need something to run at regular intervals. The simplicity of cron makes it attractive for 'quick fixes', which ends up in quickly out of date documentation.
There's a substantial gap between "treating production as a toy" and "time to market demands imperfect solutions". If anything, this reinforces the need for a production-scale batch management system out-of-the-box on Linux systems. Manually maintained documentation will always lag reality. As much as possible, you need to have configuration that is effectively self-documenting. Human readable, concise, with tools available to visualize relationships between jobs. [SysVinit scripts](http://0pointer.de/blog/projects/systemd-for-admins-3.html) are pretty legible in systemd, I imagine scheduled jobs will have a similar format.
Well, they already have a lot of Perl code in there as I discovered recently browsing the new release.
&gt; I need to check if a word is a bigram This statement needs to be explained further. My understanding of a [bigram](http://en.wikipedia.org/wiki/Bigram) is that it is a two-letter sequence, not a "word" (at least in the linguistic sense). If you expect people to help you with specific algorithms and implementations you should define clearly what you are trying to accomplish, preferably with an example set of inputs and desired output. Furthermore, it really feels like you are trying to get someone here to do your homework for you (literally or figuratively). You have been provided more than enough information already to at least make an attempt on your own. It's additionally frustrating for those trying to help you that you appear unwilling to perform even the most basic of searches for information on your own first.
Except someone coded it foreach my $employee (@employees) { unless ( $employee-&gt;salary &gt;= $threshold ) { increase_salary( $employee, 3_000 ); } } So they're fucked anyway. *Edit*: Fixed double reverse of comparison.
That is the exact same thing.
D'oh, you're right. I double reversed the comparison. Thanks, fixed.
how about something 'sane': foreach my $employee (@employees) { if ($employee-&gt;is_salaried) { if ($employee-&gt;salary and $employee-&gt;salary &lt; $threshold) { increase_salary($employee,3000); } } } but then again, it really seems that your increase_salary function should do some sanity checks of its own.
I don't see the purpose of using a module to prevent bad programming. As the blog states, a warning would be thrown in both cases, so assuming one develops properly, this should never be an issue. Additionally, it goes an a gripe about how it misinterprets business logic. This is the primary role of a developer though, to accurately code business logic. I just can't see a practical use of this. Explicitly requiring the value be set is easy to read and accomplishes the same task. This on the other hand requires documentation look up and is redundant. If you don't know the language you are writing, well than maybe you should write in something else. To further beat a dead horse, if you are using Moose and declaring an attribute, there are plenty of other ways to handle this in the attributes builder or default. Or even better, just put the fucking employee eligibility verification in the damn increase salary sub. 
A long time ago I found that if I used examples with variables like `$foo` and `$bar`, people would complain that they needed a "real" example to help me use the idea. Then I found that when I would take the trouble to create a "real" example, people would go guns-a-blazin' after the example and ignore the idea I'm trying to illustrate. Fortunately, this is a well-crafted example for a well-known problem and you have (no offense :) fallen into the trap. What does `$employee-&gt;is_salaried` mean? Well, it means "does this employee have a salary or not". In the case of a new employee whose salary is not yet in the system, they very much *are* salaried, it's just that their salary is unknown (hey, that sounds familiar). The cognitive problem arises because with things like SQL's `NULL` and Perl's `undef`, the former has the semantics of "unknown" and the latter tends to evaluates as "none" and two have very distinct meanings and should have distinct impacts on the code. So, to illustrate, should the following two lines of code *really* imply the same thing? if ( $ceo-&gt;is_salaried ) { ... } if ( $volunteer-&gt;is_salaried ) { ... } No, they should not. The CEO of course is salaried, regardless of whether or not you know the salary, while the volunteer is not salaried. However, while the semantics of "none" can often be handled by the semantics of "unknown", the reverse is not true (read that sentence a few times if it doesn't make sense because it's why SQL's `NULL` works, but sometimes lead to false negatives when `undef` leads to false positives). Thus, an `unknown` keyword which responds appropriately to the operators is appropriate. This is why SQL's `NULL`, while confusing to some, has been so successful: SELECT * FROM employees WHERE salary &lt; 40000; As you can see, that SQL statement has effectively the same meaning as our for loop. Or, if we had three-value logic in Perl 6, we could use a list comprehension: my @employees = ( $_ if $_.salary &lt; $threshold for @employees ); In other words, you get clear, declarative code and you get to skip the scaffolding required to work around language limitations.
&gt; I don't see the purpose of using a module to prevent bad programming. Oh god, I do! That's one of the main reasons I tell newer OO programmers to use Moose. Good design doesn't eliminate bad programming, but it should certainly minimize it where it can. However, `Unknown::Values` isn't there to prevent bad programming on the part of the programmer; it addresses the problem that **both** the behavior and meaning of `undef` in Perl are overloaded. `undef` might evaluate to: * false * zero * empty string Further, *by design*, it doesn't always generate a warning when you coerce its value: $ perl -Mstrict -Mwarnings -E 'my $foo; say ++$foo' 1 $ perl -Mstrict -Mwarnings -E 'my $foo; say $foo + 1' Use of uninitialized value $foo in addition (+) at -e line 1. 1 So why might that value be undefined? It might be because: * It's not applicable (volunteers don't have salaries) * It's not known (new employee whose salary is not yet implemented) * It's not available (the 'salary service' is down) * It's restricted (you don't have permissions) So `undef` conflates all of these meanings and more, and adds in several different behaviors, depending upon context, and may or may not issue a warning. In many cases, that's not a reasonable default. In SQL, a different approach was taken to say "if I don't have a value, I will logically treat it as unknown". Though there are cases where this doesn't work, it's often more correct than a false/zero/empty string coercion. So the meaning of `unknown` is not overloaded. The meaning of `undef` is overloaded. I thought we, as programmers, learned a long time ago, that overloading the meaning of something was usually a bad idea? For example, look at C code which returns -1 for an illegal account balance transfer and now has to handle the business rule of "negative account balances allowed". Oops. Or look at Perl when we thought that having an arrayref with a hashref as the first value would magically be a "special" array and we managed to confuse years of programmers with mysterious "pseudo-hash" warnings. SQL isn't perfect, but in this case, the semantics of NULL are at least far more predictable. That's not true for `undef`.
$employee-&gt;is_salaried is meant to be a boolean of whether the employee is salaried or not. If the employee is a new employee, I would expect $employee-&gt;is_salaried to be 1.
&gt; If the employee is a new employee, I would expect $employee-&gt;is_salaried to be 1. To me, `is_salaried` in is a predicate allowing me to ask if an employee has a salary. * If they're hourly, they do not have a salary. * If they're volunteers, they do not have a salary. * If they're unpaid interns, they do not have a salary. * If they're contractors, they do not have a salary. * If they're the CEO, they do have a salary. * If they're management, do they have a salary. Even if you filter our everyone in the above list who you do not consider an employee, we clearly have "employees" for whom `$employee-&gt;is_salaried` would return false. If `is_salaried` returns true, it doesn't mean that you know the salary at run time. [As I wrote above](http://www.reddit.com/r/perl/comments/18uc1c/how_to_handle_unknown_values_in_perl_threevalue/c8id7al), there are several reasons why you might not know that salary: * It's not applicable (volunteers don't have salaries) * It's not known (new employee whose salary is not yet implemented) * It's not available (the 'salary service' is down) * It's restricted (you don't have permissions) So *if* employees can have a salary that is not known as runtime, the combination of "defined" and "is salaried" can have four possibilities, but `is_salaried` is a boolean, dropping two possibilities on the floor. By specifically asserting an `unknown` category, as they do in SQL, you can handle cases of missing information. It's not always the right thing to do, but `undef` is a huge source of bugs. [See my earlier response about it](http://www.reddit.com/r/perl/comments/18uc1c/how_to_handle_unknown_values_in_perl_threevalue/c8id7al).
I would just like to point out that in my original write-up, I speculated at one point that the threshold might also be undef. Your code will fall foul of the same bug.
My point is that if comparisons with unknown always return false, you're fucked either way. What should happen is that if you do a comparison with unknown the code should `die`.
eh. i just thought i'd have another set of eyes look at it. i'm not asking someone to finish it for me. just explain why it doesn't save the updated values.
All of your volunteers now feel marginalized and have quit. Grats!
Actually, I don't think we're that far off in our reasoning. The comparison I've created with `unknown` is semantically correct. However, when you try to use the `unknown` value for anything else, you get an exception and a stack track (such as if you add or subtract a value from it). Thus, `unknown` allows semantically correct comparisons and prevents silently corrupting your data.
Are we talking past each other here? Please explain how my example would work without corrupting data.
Hmm, maybe we are talking past each other. If so, I apologize. For your example, it *can't* work without corrupting data if we accept the existence of undef values. Rather than try to guess what you mean, I'll consider use cases. Consider: foreach my $employee (@employees) { unless ( $employee-&gt;salary &gt;= $threshold ) { increase_salary( $employee, 3_000 ); } } 1. If the employee salary and threshold are both defined, the code works as expected. 2. If threshold is undefined, every non-negative salary is eligible for an increase. 3. If salary is undefined, that particular salary is eligible for an increase. 4. If salary and threshold are both undefined, case 2 holds. So for the bad cases with undefined values, we get to `increase_salary()` and presumably we eventually get to this: $employee-&gt;salary( $employee-&gt;salary + $increase ); For case 3 and 4, we now have a corrupted salary. For case 2, we *may* have a corrupted salary. So what happens with my new `unknown` type? Well, it's pretty much the same logic as above ... *except* ... trying to add the `$increase` to `undef` results in a possible warning, but adding it to `unknown` is a fatal error and a stack trace. Thus, `undef` values can easily lead to corrupt data. `unknown` values often skip the corrupting portions of the code and even when they don't (as in your example), they throw a stack trace rather than allow someone to do anything other than compare them. This is not an accident, it's by design. `unknown` values throw exceptions rather than coerce. They, unlike `undef`, are explicitly designed for comparison. They may not always be the right answer, but for most things I've walked through so far, they're more likely to protect data than `undef` values are.
Very well, my example was meant to be using an `unknown` salary, as per your example using `Unknown::Values`. It's nice that trying to increase an `unknown` salary will `die`, but what about if the `if` or `unless` makes a decision based upon a comparison with an `unknown` value that returns `false`, and doesn't result in trying to manipulate an `unknown` causing a stacktrace. My point is that i think that having comparisons with `unknown` return `false` is a design bug, because there is not guarantee that `false` is more correct than `true`. Comparing to `unknown` should `die` instead. 
Oh man are we bikeshedding or what? As for the undef issue: I prefer to just not allow it in cases where I do not expect it via Moose attribs. As for the actual bug in the example code: I don't think it has anything to do with undef. The pay increment logic is correct, but the query is utterly wrong. Employee type and status are not encoded within the salary field. Any attempt to munge out the correct employees from the set of all employees by this single field will be, at best, a hack or, at worst, flat out wrong. Transient bugs like service unavailability or permissions issues should just terminate with an uncaught exception.
I just read your function again and noticed that you have a second check for salary: foreach my $employee (@employees) { if ($employee-&gt;is_salaried) { if ($employee-&gt;salary and $employee-&gt;salary &lt; $threshold) { increase_salary($employee,3000); } } } That code is still wrong because the second `if` statement needs to be `if (defined $employee-&gt;salary ...` because we don't know that a salary of zero is necessarily incorrect, while we do know that an undefined salary is incorrect. I think that again shows how fragile `undef` is. `unknown` allows you to make that check (it's recommended), but if you fail to do so, it will throw an exception if you do something bad with the `unknown` data.
By the way, you wouldn't happen to be using SSH along with Expect. If so, make sure to manually SSH to host as the user the cron job is running as. This has slapped me in the face more than once. Hope this helps.
It may be the terminal on the other end that's the problem. If you can get as far as logging on, try sending an "export term=vt100" before anything else. Also, I generally find setting both $expect-&gt;raw_pty(1) , and "stty raw" on the remote end helps.
everybody's saying term=vt100 or Term=vt100... Try TERM=vt100 just in case.
Along the same lines, does the cron user have a ~/.ssh/known_hosts with a key for the remote system? Check `man ssh_config` for StrictHostKeyCheking and maybe su to the cron user and try the ssh command as them. I haven't had to mess with the raw_pty stuff for anything I do, another good thing is to enable `$Expect::Log_Stdout` and `$Expect::Debug` before creating the Expect object and capturing the output somewhere. edit: rereading halfprogrammer's comment and I glazed over the SSH as cron job user bit.
Are you sure the script is executable (+x), and that cron knows about the relevant paths you need to execute the script?
I don't have an answer for you, but in my experience, 90% of the time something runs fine manually but fails from cron, the problem has been that of a different environment. Try dumping %ENV when running from cron and compare with when not running from cron and see what's different. Also, make sure the output from your script is directed somewhere that you can examine it. 
The trick to cron is you have to make your ENV declarations in the crontab itself, at the top. So you might have something like this in your crontab: SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root HOME=/ # run-parts 01 * * * * root run-parts /etc/cron.hourly 02 4 * * * root run-parts /etc/cron.daily 22 4 * * 0 root run-parts /etc/cron.weekly 42 4 1 * * root run-parts /etc/cron.monthly Just experiment with placing relevant pieces of your user ENV (which you can get with the 'env' command) into the crontab until it works.
Also, setting up [private keys](http://www.ece.uci.edu/~chou/ssh-key.html) can save a lot of Expect code and make things more secure as you are not storing credentials in an expect script.
&gt; Perl is Perl. Perl 5 is distinctly different from Perl 6; and i've been told in job interviews: "We look forward to start using Perl 6, because it will be so much faster than Perl 5." The problem is that the world believes as you do, Perl is Perl, but the reality does not bear that out. :) &gt; Inventing silly or stupid names is not going to gain popularity. Did you read the [original blog post](http://shadow.cat/blog/matt-s-trout/names-and-numbers)? The people responsible for releasing new Perl versions have historically been called pumpking because they were considered to be the ones holding a stuffed pumpkin toy, which marked them as the people with the right and ability to do this kind of thing. There's nothing invented or silly about this, just a nod to real Perl history. :)
As an aid to software development this sounds like it would be useful but not challenging. This also evokes the story of Linus and the Great Pumpkin.
Moe was actually named after the stooge. Stevan said in his announcement talk that he asked Larry first if he could name it 'Larry', but Mr. Wall was uncomfortable with that. Moe was picked as a second choice because it evokes similar issues with Mo.pm that Mousse.pm causes with Moose ... 
Hell, I'm just angry at the whole thing :) I love Perl and I hate when something bad happens to it. Maybe the name change/beautification/overload is necessary, I don't know, but I hope it's for good. 
I didn't know that. I instantly switched to angry mode seeing the name. Ok, now it's cool I guess...
This was a really useful real-world example. Full of the false starts and blind alleys that real troubleshooting leads to.
Understandable, and i think you for calming down. Keep in mind everyone working in Perl wants to do good for Perl. :)
A lot of names are silly. See the codenames for most Linux Distro version.
True, BUT draw this out to its logical conclusion... All Perl 5 related websites, blogs and marketing materials will be orange themed! Doesn't this scare you a bit? What image does the name Python conjure up in your head? What about Ruby? Now Pumpkin... A large, orange, bulbous gourd. Awesome.
I think it'll just be treated as a more unique identifier as opposed to a re-branding. You're right, that would be awful
I kind of like the "original perl" idea. Maybe we need to pull out the pitchforks and get perl 6 renamed which makes more sense to me considering it's NOT perl 6....
OG Perl. Seriously though, part of the idea is to get a neutral name that is new and connected to Perl culture. "Original Perl" is too much "the lady doth protest too much". As for Perl 6, please read all of mst's posts, he adresses that at length. :)
Yeah I figured it was in there somewhere but when faced with the long list of comments and only a few sips into my coffee this morning I didn't read through everything being discussed. At the end of the day, I think it's a pointless exercise. It's introducing yet another confusion that we'll have to explain. "Pumpkin perl? Is that new" "No, it's perl 5 renamed" "So perl 6 is still better?" "Well... " yadda yadda yadda Does it really solve that?
Well, frankly. The exchange would probably be more like this: "Pumpkin perl? Is that new?" "Yes. You're used perl 5.8.6, which was released almost ten years ago. This Perl has had many improvements since then and even does some of the things Perl 6 was meant to do." Keep in mind that this rename is not for the benefit of people who're inside the Perl community, but people who've never even heard of p5p. Also, it Perl to have an incrementing major version number. &gt; Yeah I figured it was in there somewhere but when faced with the long list of comments and only a few sips into my coffee this morning I didn't read through everything being discussed. No need to read the comments. There were three blog posts made by mst, those are important to read.
You could be right and I guess only time will tell if it has a positive impact as it appears that the powers at be are on board. I still don't see the benefits and I think most people outside of the hardcore perl community will still be confused between perl 6 and Pumpkin perl and/or just see it as a new flavour like Strawberry perl. One bonus is that this has stirred debate and discussion. It's nice to see perl getting some attention that isn't surrounded by death or decline. 
If you don't understand where the pumpkin comes from, read: http://shadow.cat/blog/matt-s-trout/names-and-numbers/
&gt; What image does the name Python conjure up in your head? A badly drawn cartoon snake. &gt; What about Ruby? Clip art.
Well I guess I am referring to what the names conjure up for people without intimate knowledge of each language/community. If the name is the public face of the language/community you have to consider what it means to a complete outsider. 
I get where the name comes from. In fact it just adds to my argument that it is silly, considering the source is basically a pun. While I understand that that puns are an important part of perl culture, inside jokes are usually not inviting to outsiders... I want perl taken seriously. It is a serious, stable, 'production ready' language that should not be taken lightly. A name should reflect that. 
Well, i'd suggest you take that up with mst and have a good solid suggestion in your backhand. :) So far i've only seen objectively worse suggestions.
Not having a better idea does not invalidate an objection. In fact I think keeping things as they are now is better than going with the 'best of bad' names. 
Given the idiocy regarding Perl i've experienced from employers firsthand ("we're hoping to use Perl 6 soon, since it'll be so much faster than Perl 5!") i can only disagree.
&gt; It is a serious, stable, 'production ready' language that should not be taken lightly. A name should reflect that. FWICT, Perl has always made it its business to appeal more to hackers than to corporations. And the Perl community in general is pretty well known for not taking itself too seriously. Also, note that trying to get all Perl 5 programmers to agree on a name is like herding cats. ;) "Pumpkin" may be about as close as you're likely to get wrt everyone agreeing. :) 
Some of us don't really care what outsiders think and just want Perl 5 to be more awesome. It is not really clear yet, from what mst has said, whether changing the name will help that goal.
But that is the heart of the problem. If Perl 6 is a different language why name it perl? And make its version number an iteration of perl 5? To quote Office Space "Why should I change? He's the one who sucks.".
Excellent. Thanks so much for the feedback. I'll start doing trial and error investigation and let everyone know what happened. Thanks again Perl-Folk! edit: exploring a suggestion of C_1_s_c_0's [helped me locate and fix the issue](http://www.reddit.com/r/perl/comments/18wtk0/i_have_difficulty_using_expect_in_perl_run_by_cron/c8j7lx0).
Perl 6 should be renamed. Why is this not obvious?! 
To be fair, Damian did tout increased speed as a virtue of Perl 6 for many years before it actually came out in any usable form.
I wonder also if you might be confusing [Moe](http://i.imgur.com/GycjrmP.gif) with [Barney](http://i.imgur.com/p9zlc8S.png). Not that either of them would really make a good mascot for Perl.
Because it is not an option. 1. Larry owns the name 'Perl' and he says no. 2. At this point it would probably be too confusing anyway.
It may be obvious, but it's not going to happen.
Well, maybe I'll start my own from-scratch web browser project, with zero code taken from Firefox, and I'll name it "FirefoxPlus." I'll build up a lot of hype about it, but not have a fully working version for 10 years. On top of that, I'll whittle away Firefox's (original) mindshare in the process by confusing everybody while FirefoxPlus continues to not be ready, and in fact, is nothing at all like Firefox. Why should people download or contribute to Firefox when FirefoxPlus is just around the corner?! Yeah it sucks now and doesn't do anything yet, but just you wait! Yeah, that'd be a dick move. 
It will help in keeping Perl's reputation from scaring away newbies. I hope I don't need to explain how that actively helps make Perl awesome. :)
Yeah, eventually it probably even *will* be faster if they can get their stuff together. However that was said to me in 2011. :)
Actually, please do explain it. New users don't pay fees to the Perl Foundation to support development nor are they likely to contribute to the core themselves.
Actually they can contribute to the core. There is a whole bunch of tasks that can be done which other p5p hackers don't have the time for, but which need done anyhow. More importantly though they are an influx of fresh blood that will eventually contribute to core and also make it easier for companies to recruit perl devs, which means perl will be chosen more, which means eventually some companies will want changes in core and will pay for them.
Thanks for this tip. Adding some ENV to the beginning of the crontab allowed things to work. Specifically, I had to add a line like this one: PERL5LIB=/home/me/perl5/... Intuitively, it makes sense because cron needs to now where to look for the Expect module info. Thanks again for the pointer.
I'd be pissed at Mozilla Foundation if they did that, is what I'm saying'. 
I second the pitchforks motion. 
You are totally free to be pissed at Larry but it is no longer productive to argue about renaming Perl 6. Which is why most people have moved on to working on less "obvious" solutions.
Agreed. The person with the paint brush in his hand gets to choose what colour the bikeshed is painted. That said, I wonder if "Modern Perl" would be a better choice, given that it's already well established as a name for "new" Perl.
As a career Catalyst developer, I suggest Mojolicious for big stuff. Catalyst is just really slowing down. It has a lot of inconsistencies and quirks that'll probably never be resolved.
I'd rather see perl5 become 'perl' and perl6 become 'perl++' or something.
The distinction is important because perl6 shouldn't have to support things in perl5, and perl5 doesn't do things perl6 does. I'm cool with perl (perl5) and perl++ (perl6).
OG Perl has a nice ring to it... *updates resume*
Well, I'd probably suggest commenting out most of what's in the "foreach $a" loop block, and get it to print which $file it's going to unlink and then open?
I'll spare the syntax scolding... looking at this, I'm guessing it deletes SOME of the files it opens, but not all? If that's the case, try this: if ($a =~ s/(.*)$FindTxt(.*)/$ReplaceTxt/g) { unlink $file; open OUTFILE, $file; print OUTFILE $a; close OUTFILE; } The order of the statements looks like it was doing this: 1. Delete the file. 2. Open a new file with the same name. 3. If the string matches what we're looking for, replace it and print to the new file. 4. Close the new file. So, yeah, I'm guessing it was just deleting everything it touched, whether it warranted having text replaced or not. If that doesn't fix it, could you provide a little more context? Thanks, and good luck. ------------------------------------------------------------------------------------------- *Edit:* This should help you debug: foreach my $file (@files) { open FILEIN, "&lt;$file"; foreach my $a (&lt;FILEIN&gt;) { # unlink $file; open OUTFILE, "&gt;$file.new"; if($a =~ s/(.*)$FindTxt(.*)/$ReplaceTxt/g) { print OUTFILE $a; close OUTFILE; } } } Now see what .new files are being created and, in turn, what old files aren't -- and then it's just a matter of finding out why that's happening. Also, strict+warnings. Just do it. Again, good luck.
now it doesn't run! it tells me operator missing. Scalar found where operator expected at ./cleanup_hr_docs.pl line 14, near "*)$FindTxt" (Missing operator before $FindTxt?) syntax error at ./cleanup_hr_docs.pl line 14, near "if($a =~ s/(" 
What, exactly, did you comment out?
I was using the wrong kinda comment brace. I've changed it to this and it is still deleting all the files now foreach $a (&lt;FILE&gt;) { unlink $file; #open OUTFILE, $file; #if($a =~ s/(.*)$FindTxt(.*)/$ReplaceTxt/g) # { # print OUTFILE $a; #close OUTFILE; # } i think it is the unlink that deletes the folders too.. a co-worker thinks its a null pointer or something when it tries to close
Well... [unlink deletes things](http://perldoc.perl.org/functions/unlink.html) so I'm not really sure what the problem is. Do you want this to delete, or not delete, files?
i don't want to delete it. its supposed to rewrite the doc, which is what the "s/password/pxaxsxsxwxoxrxd/g" does. it used to work, until i changed the replacement text. now its deleting everything from the folder
Yeah, this is poorly coded, and doesn't do what you've outlined that you want it to do. Let's start with the things that are wrong: 1. You are attempting to unlink (delete) a file you have open for reading. 2. You never close the FILE you have open. 3. You open a file with the same name as the one you have open for reading, for writing. 4. You only replace the contents of the file if the search and replace finds anything. 5. You only close the OUTFILE handle if that same search/replace finds anything. 6. You repeat the delete/open/write cycle for each *line* of the source file. 7. When you actually find $FindTxt *anywhere* in a line, you replace the entire line with $Replacetxt. 8. You retain, Using parentheses, the text before and after $FindTxt, but don't do anything with the retained information, which doesn't cause bad *behavior* per se but does add to confusion as to what it's supposed to do. 9. You use the 'g' modifier on the regular expression, which if it matches will match the entire line, which makes the 'g' irrelevant (since 'g' says to keep searching, but you've created a RegEx which will match the whole line) this leads me to believe you *don't* want to match the entire line in your RegEx Now I'm *guessing* here, but what I *think* you want, is to open each file from a list, read the contents, and then perform a search and replace, then dump the altered contents to disk, if that's what you want you should do this: { local $/ = undef; # remove line seperators so &lt;&gt; operators read the whole file # at a time, local makes it so it only works in this block foreach $file (@files) { open FILE, $file; $a = &lt;FILE&gt;; close FILE; if($a =~ s/$FindTxt/$ReplaceTxt/g) { open OUTFILE, $file; print OUTFILE $a; close OUTFILE; } } } If you want to replace the entire line rather than just the part that matches $FindTxt, then the if should look like this: if($a =~ s/.*$FindTxt.*/$ReplaceTxt/g)
This doesn't run either, lol. I think it's a long day for us both :) This prints like 200 times. requires explicit package name at ./cleanup_hr_docs.pl
#What your script is doing There are several problems with this code. Let's go through it line by line: &gt;`foreach $file (@files){` Ths iterates through an array (`@files`), naming each element (which is presumably a file name) `$file`. Easy enough. Since the interpreter didn't scream at you for not prefixing `$file` with `my`, though, I can tell that you don't have `strict` enabled. If you're not writing a quick, throwaway one-liner, you should almost always `use strict` and `use warnings`. If this script going awry means that it is clobbering files in other departments, `strict` should be enabled. &gt;`open FILE, $file;` This opens a file handle -- through which the file itself can be read from or written to -- named `FILE`. So now you have `$file`, which is an element of `@files`, and you have a file handle named `FILE` pointing at the file with name `$file`. You may want to rename some variables, here; maybe indicate what you'll be doing with the `FILE` handle, such as `open IN_HANDLE, $file`. Also, this line indicates that this script was probably written a while ago. It's frowned upon, to say the least, to use the two-argument version of `open()`; if a user passes in a filename like `&gt;foo`, then `foo` will be truncated. Additionally, you should (if your perl interpreter isn't a throwback to the dark ages) use a lexical file handle so that it doesn't pollute your global namespace. So you would end up with something like the following: open my $in_handle, q{&lt;}, $file Anway, back to the code: &gt;`foreach $a (&lt;FILE&gt;)` &gt;`{` This iterates over each line in file pointed to by the file handle `FILE`, and stores that line in `$a`. The usual idiom is `while ($a = &lt;FILE&gt;)`. I have a suspicion that, because the `foreach` loop expects a list argument and `&lt;&gt;` reads into an array in list context, you're slurping the entire file into an array and iterating over each line. Possibly perl optimises this out. This next part is where it gets weird: &gt;`unlink $file;` You just deleted the file that you're reading from! This actually works, at least when I tested it on my GNU/Linux system, but what if you ever run this script on a Windows machine that doesn't handle file operations on open files gracefully? I don't know, but I suspect bad things. If `foreach` is actually forcing `&lt;FILE&gt;` to slurp the entire file into an array, then this doesn't matter (except if your script crashes and you lose the file). I'm sure someone here knows if perl slurps the file in this context. &gt;`open OUTFILE, $file;` Now you're writing back out to the same file that you were reading from, adding insult to injury. Fine, though; it works on my system. &gt;`if($a =~ s/(.*)$FindTxt(.*)/$ReplaceTxt/g)` This `if` statement then takes the current line (`$a`) and, if it has the text matching whatever is in the variable `$FindTxt`, replaces *everything on that line* with `$ReplaceTxt`. The `/g` flag seems to indicate that you want to do this multiple times, but `.*` is greedy and will replace *everything* on that line. Also, you're using capturing groups ( `(.*)` ) but not using backreferences. So, basically, I don't know what you're trying to do with that regex, but what is going to happen is the following: * If `$a` contains `$FindTxt`, then the entire line is replaced by `$ReplaceTxt`. Then, control is passed to the inner body of the `if` statement, which will print `$a` -- which at this point just contains `$ReplaceTxt` to `OUTFILE`. **Except**, you seem to have opened `OUTFILE` without a mode specifier. Which means either you are relying on the variable `$file` to be prepended with a mode specifier (which is really, *really* bad practice) or you just opened `OUTFILE` in the default mode. Which I'm pretty sure is read-only, at which point your script crashes. If, via some really silly magic, you have managed to open `OUTFILE` in append mode, which is the only mode that makes sense, you will append `$ReplaceTxt` to it. If it's in "write" ( `&gt;` ) mode, you just nuked the file and replaced it with `$ReplaceTxt`. If it's read-only, your script crashes. I'm almost certain none of that is what you want. * If, however, the `s///` command did not match anything, then nothing is replaced and `s///` returns 0. Your if statement is then not entered into and *nothing happens*. You just discard the entire line. #In summary I have no idea what you're trying to do. Please let us know what the script is actually supposed to do. As general advice, I will say the following: * Always put `use strict;` and `use warnings;` at the top of your scripts. There are good reasons not to do this sometimes, but they are rare. This isn't one of those times. * Use the three-argument version of `open`. This avoids the ambiguity of the file modes that I talked about above, and closes a bunch of security problems. * Don't unlink a file that you're reading! Ignoring what happens if the OS you're on doesn't like that, if the script crashes halfway through processing that file then you're boned. This is probably what's happening, possibly because you're trying to write to a read-only file handle. Use a temporary file and copy it over when you're sure the processing is done.
first of all, I didn't write this "poorly coded" script. i'm just the only guy here that has does any coding(some javascript and basical HTML). the unlink delete is ok becuase it is opened right after? ohhh, so if I close the file after the 'unlink' it won't delete it? i thought this just opens a file link that i'm going to write back to. I just tried to add your example but i get the same messages as @aburgers did. "requires explicit package name at ./cleanup_hr_docs.pl" I think it's just the complier warning messages that "use warnings" is saying, cause it isn't deleting the files now, but it's also not re-writing the file with the new text. I think you're on to something. 
Wow! Thanks so much for this. It's very helpful and starting to make more sense. I have added warnings and strict, it now prints a bunch of stuff that I'm trying to google. how do i call the three-argument open? do I have to download a new perl library? so it must be the unlink. then the script dies and the file doesn't get created again. how do i just write the file without deleting it first? then it should be fail-safe right? i'm going to be perl pro by the time i'm done with this lol
oh yeah. this script just changes text in files. if it finds a certain word in the file it changes it. 
I'd recommend, then, writing a new file, **then** deleting the old file and replacing it: use File::Copy qw(move); ... (perform operations, create $new_file) unlink $old_file; move($new_file, $old_file); Hope that helps. It seems like you're very new to perl, so I'd like to point you towards a great read: [Modern Perl](http://modernperlbooks.com/books/modern_perl/). If you haven't already, however, I'd recommend flipping through [Learning Perl](http://www.amazon.com/Learning-Perl-Randal-L-Schwartz/dp/1449303587/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1361497328&amp;sr=1-1&amp;keywords=learning+perl+6th+edition) first. Good luck, and welcome to the language.
Rather than unlink the file, can't you use sed? Since you are rewriting the code, just do a system call to sed with the appropriate regex.
Lemme know, I'll be there too.
Oh, thank you. I do sense that Catalyst is the "industrial" option and it feels big. I have read two Catalyst books and I can't keep the whole thing in my head, which is a flag. On the other hand, I've noticed others pick up Catalyst and just crank with it. Personally, I've not been able to do that because I need to comprehend the whole thing (just a personal quirk). So I will check out Mojolicious, thank you!
Thanks for all the help @aburger! I just downloaded that Modern Perl book. Seems like good book. I've learned that perl isn't very good with Linux or working with files (look at all these issues it's having with my script). @smtfreak came through with a great suggestion about "sed"(its a Stream Editor). Which is a perfect solution to my problem. Everything is working now YAY :) I just had to put this in the foreach and delete(unlink:p) the other lines $newfile = $file . ".changed "; system( "sed s/$FindTxt/$ReplaceTxt/g $file &gt;&gt; $newfile") ; system("rm $file"); $newoldfile = $file; system("cp $newfile $newoldfile"); Perl should really have a way to do the above code without system calls :(
 #!/usr/bin/perl use strict; use warnings; use File::Copy qw(move); foreach my $file (@files) { open my $input, "&lt;", "$file"; open my $output, "&gt;", "$file.new"; while (my $line = &lt;$input&gt;) { $line =~ s/$FindTxt/$ReplaceTxt/g; print $output "$line"; } close $input; close $output; unlink $file; move("$file.new", "$file"); } Something like that, anyway. ---------------------------------------------------------------------- *Edit:* PS: perl is great with files, and even better with linux. It seems you've inherited bad code and, trust me, we've all been there. The more fluid you get with the language, the more you will love it. After all, all code is only as good as the person writing it, and you're very new to the language. Fret not -- you'll get there. Stick with it.
 foreach my $file (@files) { # open the file originally for reading into memory (not always a great idea) # but it appears that this is the expected behavior, from what you've shared if (open FILE,'&lt;',$file) { my @lines = &lt;FILE&gt;; close FILE; # open the file, again, truncating it. if (open FILE,'&gt;',$file) { foreach my $line (@lines) { # /e is needed to evaluate '$FindTxt' $line =~ s/$FindTxt/$ReplaceTxt/ge; print FILE $line; } close FILE; } else { print STDERR "Unable to open file: $file; $!\n"; # exit / return, maybe? } } else { print STDERR "Unable to open file for read: $file; $!\n"; # exit/return? } }
It seems that you don't need system calls for that. I recommend strongly the reading of the [Ovid's Beginning Perl chapter about files](http://ofps.oreilly.com/titles/9781118013847/files_and_directories.html) (and especially writing files section).
OP is trolling /r/perl.
Please don't feed the troll.
Guys, please stop feeding this troll.
No. No new Perl library needed. Made me laugh.
perl++ becomes qerl )
The rename would be the first step. Baby steps. :) 
&gt; Except that mst isn't proposing any technical changes as part of the rename. Sure, hence my footnote &gt; Convincing people to start cutting legacy crap out of the language will be a lot harder than convincing them to accept a silly new name. Thats not really the issue I'm addressing (nor, I believe, the one mst is addressing). At the moment perl has a marketing problem. The average person that might be otherwise interested in such things think either 5.6/5.8 perl or perl6 when they hear the word perl, when this shouldn't be the case. Modern perl looks nothing like those two and they are only tangentially related via a shared history. I believe this fixes that, for some definitions of "fixes" 
&gt; In short, I am against dropping 'Perl' from the name. Right. mst's plan doesn't call for dropping the name "Perl". The idea is that you'd refer to it as "Pumpkin Perl". And when folks ask what that means, you could say, "Well, it's the flavor of Perl which will very probably start breaking backcompat with venerable Perl 5.x to modernize it. You can still use 5.x, but new users are getting pointed to the more modern Pumpkin Perl". That's my impression anyway. 
&gt;No he doesn't. It's actually trying to open it for reading again. But the filename is gone from the filesystem, so this won't work. That's what I thought, but `print`ing to a read-only file handle will cause the program to crash. For the sake of argument I assumed that some dark magic was going on with the two-argument `open` and `$file`. &gt;I recommend using the -i command line switch instead. (see [1] perldoc perlrun) Thanks, I didn't even know that switch existed! Sounds like another feature for one-shot throwaway programs, though. I know I'd be a bit surprised to see `#!/usr/bin/perl -i` at the top of a script.
Very useful. A couple of years ago, I had a memory leak in a daemon written with POE. I tried various modules to find the leak, and drowned in TMI (too much information). In the end, I gave up. Dodging the issue, I did a partial rewrite of my daemon and thankfully the leak was gone. With the tip presented here, I might have found it.
Not exactly a switch, but this is as close as you can get now I believe. perlbrew install-cpanm perlbrew list-modules | perlbrew exec --with &lt;new perl&gt; cpanm If you want to review the module list first and edit what gets installed you can do: perlbrew install-cpanm perlbrew use &lt;old perl&gt; perlbrew list-modules &gt; modules.txt &lt;edit modules.txt&gt; cat modules.txt | perlbrew exec --with &lt;new perl&gt; cpanm I've done this a few times with mixed results. It has always eventually worked, but I've sometimes had to go back and manually install various modules because of problems that are way beyond the control of perlbrew.
Aiui: P5P have already made the technical changes to be signaled with a new name. They spent the last N years making them. The rename is to do just one relatively simple thing (a cosmetic rename) to achieve two specific branding objectives: catch up with today and prepare for a future of two Perl 5 paths, one 100% backward compatible, the other less than 100% backward compatible.
Install perlbrew, don't bugger about with the system perl - you'll end up regretting it. Edit: I replaced system perl on osx once, everything was great for a while ...long dull story with lots of pain... then I backed up my documents, reformatted and got everything back to normal
First and foremost, DO NOT upgrade the system level Perl. 5.12 is pretty modern and should be fine but it is actually still nice to have a Perl install separate from the system, even if they were the same version. Or at least use local::lib. perlbrew is still a handy way to install perl, even if you don't plan on using multiple versions. Then again, [this](http://www.cpan.org/src/README.html) is not really hard either: wget http://www.cpan.org/src/5.0/perl-5.16.2.tar.gz tar -xzf perl-5.16.2.tar.gz cd perl-5.16.2 ./Configure -des -Dprefix=$HOME/localperl make make test make install
This. A thousand times, this. For everything else you need that's not included (e.g., MySQL for DBI::mysql), use [homebrew](http://mxcl.github.com/homebrew/). 
Also, on top of everything else here, don't name a variable $a or $b. As per perldoc perlvar: &gt; $a $b Special package variables when using sort(), see "sort" in perlfunc. In general, a single-letter variable name is considered bad style (with a few well-known exceptions like $i, $j, $k for loop iterators or $x, $y, $z for coordinates), not only in perl, but in general programming.
I like to give people the benefit of the doubt and try to be helpful regardless, but you're probably right on this one. 
I agree. Use perlbrew. That way, if Apple pushes out an update to the system Perl, you'll still be good to go and won't lose all your work.
Agreed. Use perlbrew, macports, homebrew, fink (is that still around?), or just build your own from source and put it in /usr/local, but do not fool around with the system perl!
 sudo cpan App::perlbrew perlbrew install --switch stable Done :)
Agree, while I like the idea, Pumpkin/Pumpkin Perl just doesn't have a ring to it. I suggest "Evo Perl" (or Perl Evo). That is the evolutionary version of perl, in contrast to Perl 6, which would be the revolutionary version.
Why not have it both ways? Rename Perl 6 to Perl 10, or Perl X, then we can have 7, 8, and 9. 
Yes. Don't mess with the system perl on pretty much any OS. Perlbrew, or roll your own. 
Why do we need to rename what has been 'perl' for years, now? I understand perl4 was different enough from perl5 to warrant re-naming, but we're beyond that now. Perl6 could be named 'Pumpkin Perl' without confusing much of anything, where calling perl5 something new kinda screws it all up. I'm a proponent (and probably alone) of perl6 becoming 'perl++'
You can always run Configure with PREFIX=/usr/local and then play PATH and PERL5LIB games.
Never replace the system version of Perl, python, etc ... Some system tool may be relying on characteristics of the specific version. "Replacements" belong in /usr/local or /opt/local/ or your user directory. If you're the only user, it hardly matters wich one you use/
How old? A longshot, but around version 5 or so the NetSNMP stuff was borked for a while. (I had to go back to libsnmp-0.4.2.5 for a while). The problem was in the walk/bulkwalk/table type of code (single set/get was fine) and the effect was empty OIDs in the result. The net-snmp binaries still worked fine, only the Perl binding was borked.
[MacPorts](http://www.macports.org) is your friend. Install it using the friendly directions on the website, then pull down your favorite perl with (e.g.) "sudo port install perl5.16". It'll go into /opt/local/bin instead of overwriting the system perl. The disadvantage is you're not building from scratch, so you don't get to tweak the build like you do when you build from the source distro. The advantage is that you don't have to do that. There is another advantage, which is that macports has a lot of good things in it. 
Defintely perlbrew to get perl automatically installed. Once this is done, grab cpanminus with curl -L http://cpanmin.us | perl - App::cpanminus and every module install is as simple as 'cpanm DBD::mysql' 
You aren't alone in wanting a rename of Perl6. It isn't going to happen though. Zero chance of Larry Wall doing that. I hate the "Pumpking Perl" name as well. I think it should keep "Perl" and go with a YYYY.MM naming like "This is Perl release 2013.04". Perl5 stays locked into backward compatibility for fear of breaking whatever. "Perl YYYY.MM" is more free to change things.
&gt; Does "startup" qualify as page load, or when I fire up the app with plack or FCGI? The latter. To give a contrapoint to the dependency thing: Not depending on ANYTHING but what's in core means Mojolicious needs to reinvent every perl module known to man. That can be dangerous. Maybe the reinvention doesn't address an issue of complexity long seen to in module whose creation lays back many years. Maybe it can be slower, since it needs to be pure perl only. However it can also be advantageous. Maybe the resulting module has a nicer API, or simply doesn't have some weird bugs existing in legacy solutions mainly for reasons of compatibility. There is no right answer here, and which you need depends on what you wish to do and who or what is limiting you.
&gt; "Perl YYYY.MM" is more free to change things. I don't understand why people keep saying this. Deprecation notices have started to flow again. Core modules have been kicked out of the core. Some language features are starting to be removed. The process is slow and deliberate--which is good--but the numbering has nothing to do with that.
Perlbrew will do that for you. It's very nice.
&gt; Pumpkin Perl can have pragmas that break compatibility provided these are optional. Like Perl 5 already has?
What's wrong with Perl++, exactly?
I'd rather have easy to maintain and a full stack solution instead of hacking it together on my own. Speed is easy to fix, and mistakes made at the beginning and initial design is a huge pain years later. Years from now, you'll be glad you went with a more complete stack, especially one as awesome as Moose, Catalyst, dbix::class (or whatever orm), and TT (or whatever templating solution). I've learned the hard way.
Don't worry about startup time as long as you are running in some persistent environment (like FCGI or Plack.) Personally, I &lt;3 starman. As long as your moose objects are all properly written, you use namespace::autoclean, you make sure to make_immutable, Moose isn't going to be your bottleneck. Follow Moose::Manual::BestPractices and you'll be set. Once the parent process has "compiled" all of the Moose objects in memory, you will not experience any more slowdown. Don't get in the trap of making and discarding 1000s (or 100,000s of objects) with every request though. Just because Moose makes it easy, doesn't make it right :)
Confusing Perl module names: Net::SNMP - Pure Perl module, has nothing to do with net-snmp SNMP - net-snmp client stuff (get/set/walk/etc) NetSNMP::* - net-snmp server/daemon stuff I had a script using SNMP module from the 4.2 days that just stopped working when moving to the SNMP module from the 5.0 release. Yet the snmpget/walk binaries from the same release had no problems. The 5.0 release of ucd-snmp/net-snmp (not sure if they had changed the name yet) just had buggy Perl bindings to the libsnmp.so libraries. The buggyness was in the walk/bulkwalk/gettable code path. So, in my mind, Perl + older net-snmp + walk/bulkwalk is just a broken thing. I didn't know enough XS to dig any deeper. If your agent is working with get/getnext and having problems with walk, you probably should grab the latest release of the net-snmp library source and build it (the SNMP, NetSNMP::* modules are included in the source) yourself. You should also try using tcpdump/wireshark or some other packet capture software that does packet decoding for SNMP and check the traffic between your client code and agent to see where things are going wrong. You might want to pare down your agent to a minimal failing bit that you can post somewhere. It's hard to tell exactly where your troubles lie. 
What perl defaults are you talking about? I'm so lost.
Yes. That's precisely my point. That is, aiui, Pumpkin Perl is just an alternate name for the Perl 5 maintained by the Pumpking.
The most common one would be that 'use strict' should be enabled by default.
Wait, what? This is all just to avoid having 'use strict;' at the top of your program?
Well, that was just one example. Others might include: use warnigns; use IO::File; use auotdie; use feature 'say'; use Carp;
'5yy' done.
Lol. Are you kidding with that first example? 1. using 'map' to do transformations and 'for' is for generic iteration seems to make more sense to me 2. 'map' *is* parallelizable making it faster than 'for' 3. Anyone stating 'for' being "cleaner" or more easy to read in this example is just dead wrong. So, in conclusion.. Thanks, but no thanks really
Oh man, well played. For a while there i thought you were really just a quick-judging idiot. Thanks for being clear about being a troll! :)
nah, i've just read the whole modern perl book i the last 2 days... lol
Pumpkin Perl is a terrible name. This is exactly why Perl is the butt of every shootout.
Modern is a terrible prefix because it will age with time. What do you do when people start writing bad, crufty "Modern Perl"?
And where are they today?
Super awesome! I love perl brew!
Quite reasonably out there. Ubuntu and Debian stuff.
perlbrew offers the 'perlbrew install-cpanm' command that handles this, too.
That's only part of the herculean effort to bring these lines to your new script, you still need the 'p', too! Seriously, though, I don't think I understand what the fuss is about here, either. This is both explicit, easy to read, and leaves no head scratching whatsoever about what's included in your script.
You can sign in with email (using Mozilla Persona) now.
Look at some projects that use scripting to scrape data from web-resources, or try to do something yourself and write about the process.
CPAN has a huge number of modules for interacting with various services and interfaces via the internet.
Which bits of the Internet exactly? WWW::Mechanize is nice for automating certain web tasks that would normally be done by a human being.
What he said. Running your browser through a proxy you build is a quick and deeply reliable way to log what requests need to be made to automate something like a UAT process or health check, btw. And if all else fails, there's always the venerable LWP module.
...and if you're using something like mod_perl, you can also script the web proxy, to do funky logging etc.
These are both very broad topics. Scripting can be used from server-side management to client-side interaction with a server. Could you be a little more specific?
&gt; little Need to be a lot more specific I think :) EDIT: Happy cake day :)
Visual regex debuggers focused on Perl programmers: * https://metacpan.org/module/Regexp::Debugger (http://www.youtube.com/watch?v=zcSFIUiMgAs) * https://perl6advent.wordpress.com/2012/12/05/a-perl-6-debugger/ (visually debugs both P5 and P6 regexes)
You can use `LWP::Simple::getstore( $url, 'filename.pdf' );` Of course that only gets you the PDFs, I'm not sure if you want to read the PDFs
I am really wondering here: Which of the downvoters think this should not be posted in this sub-reddit, and which simply disagree? :)
I noticed that. It looks like it it automatically anchoring the regex to the start/end of the string. /.*r./ and /.*ry/ both matched. It definitely is not perfect, but it is still a useful tool.
Thanks so much. I figured it out, using your suggestion of looking at the packets. Realized that the agent library was actually calling it's own request function many times, completely messing up what the walk was supposed to be like. This was the result of registering ALL OIDs in my "register" function, not just the root ones. The Perl agent docs don't state just root - but the c library function at http://www.net-snmp.org/dev/agent/structnetsnmp__handler__registration__s.html made it clear. Thanks again! Edit: Darnit, nope. Walks work, but Get's don't anymore when I just register the Root OIDs :( I think this module has some problems... :/
I totally agree.
Probably because there is still so much talk about breaking backward compatibility.
You can use [poppler utils](http://poppler.freedesktop.org/) pdftotext program to get the text then run regexp's on the result: my $text = `pdftotext -layout -q -eol unix file.pdf -`; $text =~ /foobarbazquux/; 
Well it is for a scripting class, we focus mainly on perl. It should probably be client side, I have to do a presentation too, so being able to build a lab around it would be nice. Happy Cake Day.
&gt; What actually happened was that the original author of the patch, who'd been utterly excited at YAPC::NA that year to start taking tribal knowledge from the IRC and associated perl communities and bring it to the wider world of perl users had his motivation completely crushed and hasn't tried to contribute again since - and several other potential perldoc contributors have taken one look at that thread and decided they don't want to try in the first place. This looks rather too close to what Schwern was getting at in the YAPC::NA 2012 keynote: that we've built a system that works for thick-skinned developers and nobody else.
"scripting" is still awfully vague. 
If you just want to fetch the files, I'm enjoying WWW::Mechanize as a higher level version of LWP at the minute -- well worth a look, and the docs are relatively straightforward... https://metacpan.org/module/WWW::Mechanize
No, it seems you don't read it because you should know that [TIMTOWTDI](http://c2.com/cgi/wiki?ThereIsMoreThanOneWayToDoIt).
@sebf, @mithaldu was "trying" to provide a "cleaner" way to do it. Yes, but there's only one "right" way.. 
No idea what system you're on so I will suggest a cross-platform solution. **NOTE**: *move* will overwrite the destination if there is a conflict use File::Copy; foreach my $filename ( &lt;"*.XYZ"&gt; ){ my $new_name = # Do what you need to here to make the new filename move( $filename, $new_name ); } Edit: Can't tell the exact string manipulation without more specifics on file naming.
And nary a foul-mouthed word in sight. That's impressive, right?
Well, this is more server side but perl can be used to create cgi scripts. When the client connects to the server and requests the page the cgi script is ran on the server and literally prints the html to the client. This cam be used to create more dynamic of webpages.
It's pretty much an intro class, I have only been using Perl for 6 weeks now. So vague is all I know. I just wanted some starting points or leads, and since we are using Perl I figured this would be the best place to start. I can use any scripting language I want, If there are any other suggestions. But I think that would just make it more vague. 
[vidir](http://man.cx/vidir) :%s/\/dd/\/file_ 'vidir' is written in Perl, so you're sort of doing it in Perl.
Thanks for the support!
The current release supports exact matches only. find() and findAll() type matches will be supported before it comes out of beta.
Yup. See comment above.
*easier to read* (stupid mobile)
Yes, in list assignment you can assign more than one value and regexes in list context return all of the captures. The code would look like this: if (my ($area, $prefix, $line) = $str =~ m/([0-9]{3})[^0-9]*([0-9]{3})[^0-9]*([0-9]{4})/) { # $area, $prefix, $line are only visible in here }
You want to rename the files? [File::Rename](http://search.cpan.org/dist/File-Rename/) (module and command line script). This ought to work: rename 's/^dd(\d+)/sprintf q(file_%d), $1/e' dd*.XYZ (On Windows, replace the single quotes with double quotes)
Okay, you are twenty lines from the regex, what is `$1` again? Heck, what was it supposed to mean in the first place (i.e. is it self documenting)? What does this code print? perl -le '$_="abc"; /(.)/; /(e)/; print $1' The only safe and sensible places to use `$1` and its brethren are in a substitution or immediately after a match.
I second this, it's very nice!
Great blog post. Maintaining a positive community is so critical. Rule of thumb: If someone's being publicly gruff (intentionally or not), it's worthwhile to pop in and diffuse the situation :), rather than letting it lie. 
So, you'd like to rename those dd\* files en masse? If so, have a look at this: my @filenames = qw/dd004.xyz dd005.xyz dd018.xyz/; for my $fn (@filenames) { my ($digits) = $fn =~ m/dd(\d+)\.xyz/; $digits =~ s/^0+//; say "$fn --&gt; file_$digits.xyz"; } To actually rename the files (instead of just printing them out, as I've done above), use the `rename` function. 
You had my hopes up for a moment. One other thing to factor in is the difference between v1 walks and v2c/v3 bulkwalks. The v1 bulkwalk is really a wrapper around the v1 walk. The true bulkwalks pack multiple OIDs in the same response where the v1 plain walk basically just does getnext in a loop (fetching next OID until outside of tree). My suspicion with my old problem was some sort of bugginess in the Perl/net-snmp interface with the multiple OID packing/unpacking used in the bulkwalk. That is the get/getnext/walk all kept working while the bulkwalk was broken after an upgrade. So in your testing (if you haven't already) keep in mind the differences in the v1 vs v2 walk/bulkwalk. You may be able to get one but not the other to work. I'd love to hear if you get this working (and see the code :P). I've meant several times to build a agent to use in testing but I just haven't ever gotten around to it. I just test against real devices that are within arms reach in case I bork something...
Have been using NetSNMP::agent for various plugins and modules, and it seems to work fine (in AgentX mode) But now I've been trying to write a full fledged simulator with something like 20k+ OIDs registered at once on custom port. And the module really struggles with it, like I said either walks or gets don't work depending how I register the OIDs! So I gave up on the NetSNMP::agent module for this purpose. Today started writing one through network layer. And it's nearly done. This is not actually the most targeted use of my time for current task but I find it fun. :) Forgot to mention, the main application is v2c. Just reread your suggestions about bulkwalk/walks, I wasn't really aware of the differences between them, insightful. Now I'm wondering what else I'm not aware of, that will be needed, and if I'll have time to finish this thing. I think tomorrow I'll have to abandon this for the time being and come up with something else... but thanks for all your help!
Wait a second, that means that the match can return in both list context and scalar context, simultaneously? weird.
Yes, indirect method calls are pretty. But they're also broken. When you're putting code into production, which one do you care about more?
I cannot even count how many times a bug in my code, or code of a coworker exploded at random because of this unnecessary parsing behavior. I can however count how many times the behavior was useful or necessary: 0.
I guess that Pumpkin Perl rename really was a great idea if it has already brought in all these new core hackers. And it hasn't even happened yet! BTW, [for anyone else who was unclear](https://en.wikipedia.org/wiki/Subject%E2%80%93verb%E2%80%93object).
There is an important distinction between parents yelling at you to get out from in front of the bus and your parents yelling at you because you did not get the borders of the bathroom towels lined up exactly right.
To be generous many of the comments are perhaps given with irony and sarcastic humor in their intent but they are frequently taken as direct and hostile criticism from leadership onto junior team members.
Ahem. Not perl, but this is better done in the shell; zsh here: dima@shorty:~$ ls dd* dd001.XYZ dd0010.XYZ dd00100.XYZ dd002.XYZ dd003.XYZ dima@shorty:~$ zmv -n -W 'dd(*).XYZ' 'file_$((*)).XYZ' mv -- dd001.XYZ file_1.XYZ mv -- dd0010.XYZ file_10.XYZ mv -- dd00100.XYZ file_100.XYZ mv -- dd002.XYZ file_2.XYZ mv -- dd003.XYZ file_3.XYZ The -n does 'dry run'
Is there a good text link anywhere?
I think it should be noted that CGI is nowadays still useful as a development setup and for debugging.
This doesn't include the detailed explanations, but basically its the same information as in the 1.6000 entry of [the Changes file](https://github.com/miyagawa/cpanminus/blob/master/Changes): 1.6000 Tue Feb 26 09:50:57 PST 2013 [Major Changes since 1.5] - Support fixed version search with @version and ~"version range" - MetaCPAN and BackPAN search using MetaCPAN API - --dev to install developer releases - Install via git:// URL (with @branch, tag or commit) - Better MYMETA version range and cpanfile support - No fallback to search.cpan.org, which means you can't install from command names 
Thanks, I'm at the office now and I can't really watch videos. Big help.
Awesome module. Simple to use and really provides tons of information. I'm very impressed.
Plack is still far better for dev and debug with all the handy [middleware tools](https://metacpan.org/module/Plack::Middleware::StackTrace) it gives you. Also, consistency in your setup from dev to prod will pay off in the long run.
"profile the data in 10 tables" doesn't make any sense. You don't profile data and you don't profile database tables. You profile code. As someone else mentioned you can us Devel::NYTProf to profile Perl code but most database applications have their bottleneck in actual SQL queries, so that won't be where you find you biggest gains. In order to speed up your actual SQL queries you'll need to know which ones are causing the problems and then go from there. And it's different for each database system. I'm not very familiar with SQL profiling on SQL Server but I assume there's some tools you can us for that. And in my experience, most of the gains are going to be in adding indexes to the right columns (and sometimes removing them).
But the point that mst is trying to make is that there is never any level of immediacy in these discussions. All of his example discussions are happening in mailing lists, blog posts, rt, etc., in preparation of some perl or module change. So the heart of the issue (as I read it) is that community members are replying as if the question is, "Hey, is it a good idea for me to step in front of this bus?" But the question is actually, "Hey, is it a good idea for me to walk in front of a bus a few weeks/months from now?" So the response should not be "GET AWAY FROM THE STREET!!!" It should be, "Buses are heavy and bodies are fragile, so I don't think this is a great plan. However, with a crosswalk and a pedestrian crossing sign..."
You also profile data. I'm looking for any Perl based tools to profile data like Informatica's Data Profiling Tool or Talend Data Quality too
Wow, i tried to word this politely, but your understanding of this matter is flawed at a base level. First off, there's not the question of Plack or CGI. Of course in anything modern you use Plack, and then deploy as either PSGI, CGI, FCGI, mod_perl or CLI. There's no exclusivity here. Furthermore, consistency between test and prod is a must, yes. However in dev it is extremely valuable to be able to use many kinds of deployments, since every deployment type has its specific advantages and disadvantages. And that is exactly why you use Plack, and when it helps you, deploy in dev with the server configured to talk to your app in CGI. I hope you'll not take this as a personal attack and instead understand it as the concise explanation of a complex matter i intend this post to be.
So, when you say use Plack and then deploy as CGI I believe you mean something like: Browser =&gt; Apache (eg) =&gt; CGI =&gt; Plack =&gt; Your Code VS: Browser =&gt; HTTP::Server::PSGI =&gt; Plack =&gt; Your Code Can you explain to me what advantage you see in that extra CGI layer?
Probably very few (if any) shared hosting provides Plack support, but as I can have a full VPS for $20/month or less I feel this is is not such a big problem. Of course I understand the shared hosts are even cheaper.
You understand it correctly. Two things: For one i don't need to rely on forking to reload my libs, which is nice, since i dev on a platform that doesn't have fork. For the other i can easily add the -d switch to my scripts, hit the browser and have it connect to the remote debug facility in komodo IDE. Plus, i'll need to have apache in there anyhow for most things, so i'll get all the .htaccess stuff in dev as well.
Plack is pure perl, so you can just copy it along with your app.
It will tell you how long you spend in DBI methods making queries but not which queries are causing the problems. Surprise, your database application makes a lot of database calls! Not a lot of help there really.
If you are using DBI to access your database, then you should use DBI::Profile to generate profiling data on all calls to your database. An easy way to gather this data is to use DBI::ProfileDumper to generate profile dumps and then run dbiprof over the dump files to generate reports on your longest running queries or most called queries. All this in bundled with DBI so it's all there for you to use... And although I have never done it, you can use DBI::LDAP to connect to your ldap source and my guess is that you can get profile data in the same way.
Plack doesn't need to be "supported" by hosting services. If your app targets Plack (or PSGI, more precisely), Plack::Handler::CGI will run it in a vanilla CGI environment. Same as FCGI, mod_perl1 and 2. No code changes required.
From your example I don't know what you are after. But it can be helpfull to look at complex data structues with the Data::Dumper module. If you can post a more complete example I can take a look.
Are you a wizard? That worked. So... what you did there was ... take a reference of... which part? EDIT: It must be a reference of the hash stored at $hashRef{key}[0]. This makes sense, but it makes me wonder why it isn’t the same as: my %finalHash = $hashRef{key}[0];
No, it can only return in one of void, scalar, or list contexts just like everything else. What is happening here is that the if statement is seeing the return of the list assignment operator. from perldoc perlop &gt; Similarly, a list assignment in list context produces the list of lvalues assigned to, and **a list assignment in scalar context returns the number of elements produced by the expression on the right hand side of the assignment**. The match operator in list context returns an empty list if the regex doesn't match. Since there are no elements on the RHS, the list assignment returns 0 which is false.
I suppose I ought to do that. I sort of get it, but I must have some confusion.
NYTProf is amazing for what is does, but it is really not the best way to profile your database calls. Not sure why you guys are downvoting mpeters. It may tell you that DBI::execute was called 500 times and took an average of 50ms per call. You can drill down to find the exact places where execute was called to find the SQL lines in question, but it is not really giving you the info you need. The DBI Profiler will profile each different query you send to the database. Tell you how many times each query was called and how long each query took to execute. Who really cares how many times execute was called, you should care what queries were executed and how many times. Personally I use both NYTProf and DBI's profiling tools in combination when I need to optimize my code. They serve different purposes but complement each other.
so, maybe i'm just *special*, but the example you gave makes perfect sense to me, it's "a" (there's no possibility of more than one match the way it was written). i can see this one being a *little* more confusing: perl -le '$_="abc"; /(.)/; /(b)/; print $1' i do see where you're coming from in the self-documenting aspect, but i just tend to assign $1 to a local variable shortly after matching, and using the variable throughout the rest of the relevant routine.
You were trying to access the reference itself as if it were a hash. $hashRef{key} does not exist because $hashRef is not a hash, so can't have any keys. It's a reference to a hash. You need to de-reference by using the double-dollar: $$hashRef{key}
Why don't you try and respond without the attitude! Yes you can use NYTProf to do this, but there are other, better ways to figure out which SQL statements are causing you problems in an application. Especially if you are dealing with a very large application. What if the same SQL statement is called from multiple places in your code. When using an ORM, this is quite possible. NYTProf may not highlight that this query is a problem because the calls are spread out across your code. However, an SQL profiler (which as I said is built into DBI) will show you that this same query is called many times and is causing you issues. The original question was to profile the 'data', and you keep talking about profiling the code. As I've said already, you can figure out what SQL calls are being called the most and which ones are taking the longest without ever needing to search through your code. Once you have your list of SQL queries, you can create some indexes for the long running queries, or rewrite them to optimize them. If it turns out that the same query is being called too many times, then you can go to your code and try and change things. And hey, you could use NYTProf for that. You might actually become a better programmer if you at least consider the suggestions that other people provide instead of just snidely disregarding them... 
Offtopic: He links to [a certain bug](https://rt.cpan.org/Public/Bug/Display.html?id=79504). Could someone enlighten me what this bug is about? All I see is basic info and a discussion without apparent start point. But I don't see the bug description, or patch source code (if it has that), or anything that would help make sense of it.
or $hashRef-&gt;{key} which is how I prefer to write it.
My point is that a regex that doesn't match doesn't set `$1`, `$2`, etc. (leaving them set to whatever happened to be in there) Examine this code: $_ = "abc"; my ($first) = /(.)/; my ($dee) = /(d)/; You always get the captures (or lack of captures) from the regex you are runnning. Now let's use `$1`: /(.)/; my $first = $1; /(d)/; my $dee = $1; Oops, `$dee` has `"a"` in it (a capture from a completely different match). The capture variables are only safe to reference inside an if statement: my $first; if (/(.)/) { $first = $1; } my $dee; if (/(d)/) { $dee = $1; } or my $first = /(.)/ ? $1 : undef; my $dee = /(d)/ ? $1 : undef; If you are going to "assign $1 to a local variable shortly after matching", why not just do it when you match? What is the value you are getting from using `$1`?
People are giving good advice but I'd like to add my tuppence: Firstly, unless you _need_ the hash, stick with the reference, when you do this: my %hash = %$hashref You are collapsing the hash into a list and then making a _new_ hash with the contents, just stick with the hashref, unless you really need a shallow copy. Also the clearest way to deref is with '-&gt;' $finalhashref = $hashref-&gt;{key}-&gt;[0]
Sure, probably clearer to people not thinking in Perl yet - TMTOWTDI and all that :-)
&gt; Of course almost no one writes plain Plack/PSGI code Is this really true? I found that Dancer off the shelf didn't let me customize things how I wanted, and Catalyst &amp; friends were too big and heavy for my needs, so I just wrote my own PSGI app directly. It wasn't very hard, and the request-handling bits of the code are quite short (maybe 50 lines tops) -- I was able to get on to writing the meat of the application quite quickly.
The bug is attached to a module called [strictures](https://metacpan.org/module/strictures) which is like 'use strict' except stricter. As I understand it, it attempts to be even more stricter when being run in the context of a module author's development environment. The bug is complaining that this gets triggered when it shouldn't. Because Moo uses strictures, if you want to use Moo, you also end up with this super-strict mode.
I'd second the pointer towards Data::Dumper -- not just for diagnosing specific problems, but frankly, because my brain just would not wrap around complex nesting of array-refs and hash-refs until I started seeing the output of Dumper()
chromatic: With p5p perl the parser does know the type and structure of the context. Because the parser is dynamic. Those who argue that this causes buggy behaviour don't understand perl well enough. It's fragile if you code in a fragile matter, relying on load order. But we deal with a dynamic language, so load order matters. So parsing order matters. Giving up language extensibility because people do not understand dynamic languages is my problem. You extend the language by defining methods. Maybe a bit by defining functions with prototypes. But the prototype syntax is not managable. One should able to define a language with macros (not evaluating its arguments, rewrite at parse-time). This would be the easier choice to replace indirect method syntax. But then the parser needs to gets reflection and need to get extensible (adding and changing rules). I gave up waiting on this. So we have to defined indirect method syntax.
Indirect method are not broken. Broken is the code if you break it. When you put code into production do not rely on load-order changes or go to a static language.
If my code breaks because the internals of a library I downloaded off of the CPAN have changed with regard to the order it loads its dependencies, something's rotten, and that has *nothing* to do with whether I understand dynamic languages as well as you do. Pushing the burden of understanding onto users to defend a broken mechanism is actively hostile. You're right that Perl 6 kept indirect object notation for a reason. Perl 6 also added the invocant colon syntax so that the invocant is *never* ambiguous in any of the eight ways it can be ambiguous in Perl 5.
"Avoid writing bugs" is unhelpful. "Try to avoid using code anywhere in your entire stack, especially the parts outside of your control which exposes bugs due to action at a distance" is also unhelpful. "Avoid using this syntactic construct because it's fragile and subject to action at a distance" is helpful.
 I tend to leave the curly-braces in place (perhaps more than necessary): my $hashRef = \%someHash %{$hashRef} == %someHash #true $someHash{'key'} = 'value'; $someHash{'key'} == ${$hashRef}{'key'} #true ${$hashRef}{'key'} == $$hashRef{'key} #true So you have a hash containing a reference to an array, with that array containing a hash reference. Building that up: my %innerHash; $innerHash{innerKey} = 'innerValue'; my $innerHashRef = \%innerHash my @array; $array[0] = $innerHashRef; $array[1] = 'someString'; # stick something else in the array, just for fun my $arrayRef = \@array; my %outerHash; $outerHash{outerKey} = $arrayRef; And now to reference into this unholy mess ( ;) ) print $outerHash{outerKey}, "\n"; #ARRAY(0xF00) - the array ref print @{ $outerHash{outerKey} }; # HASH(0xBAA)someString - the literal contents of the array (all slammed together by print) print ${ $outerHash{outerkey} }[0] #HASH(0xBAA) - just the hash reference print %{ ${ $outerHash{outerkey} }[0] } #innerKeyinnerValue - the literal contents of the inner hash (again, all slammed together) print ${ ${ $outerHash{outerkey} }[0] }{innerKey} #innerValue - the innermost value, extracted Or, more readably: print $outerHashRef, "\n"; #HASH(0x1234) print %{$outerHashRef}, "\n"; #outerKeyARRAY(0xF00) - the literal contents of the outer hash print %$outerHashRef, "\n"; #the same as the last; showing that the parens are not necessary print $$outerHashRef{outerKey}, "\n"; #ARRAY(0xF00) - just the array ref print @{ $$outerHashRef{outerKey} }, "\n"; #HASH(0xBAA)someString - the literal contents of the array print $$outerHashRef{outerKey}[0], "\n"; #HASH(0xBAA) - grabbing the first element of the array print %{ $$outerHashRef{outerKey}[0] }, "\n"; #innerKeyinnerValue - having a peek at the contents of the hash print $$outerHashRef{outerKey}[0]{innerKey}, "\n"; #innerValue - weaselling our way right into the center 
I'm learning it now, while slowly building a tool for myself. How did you learn it and what did you build?
What exactly does it mean to you to "profile data"?
Well, have you tried debugging the script? What is `$members` being set to? Is that value correct? If it is, why is the string matching not working? If it's not, why is it not correct? Why is string equality being used to check GIDs? Why is the username being lowercased but then compared case-sensitively in the regex? And so on. Stylistically speaking, the Modern Perl movement would have a lot to say about this: - lack of `use warnings;` and `use strict;` - function prototypes are generally not needed and should not be used unless you're trying to emulate builtin functions, especially since: - that `&amp;` in front of each function call should not be there, as it's not necessary and it disables any prototype checking - consider using 3-arg open and lexical file handles, check return values, etc. 
Well, I reviewed the podcasts, and the other materials. Perl is already my go-to language, so this was just "contemporary web framework in perl" The man pages, ( a.k.a. online docs ) are your friend.
`-&gt;` are unnecessary past the first one, though. $finalhashref = $hashref-&gt;{key}[0]
Data profiling is the examination and enumeration of of a column of data that precedes data cleansing. The purpose is to characterize the data to find and list all unique values, mins, maxs, data of the wrong type, find unusual punctuation or ctrl chars etcs. please also see : http://en.wikipedia.org/wiki/Data_profiling 
Why are you lowercasing the username? If the new usernames aren't actually all lowercase, that may be the problem. As some additional general advise, additionally to what Rhomboid is suggesting, instead of $result = 0; if (condition) { $result = 1; } return $result; you could just do return condition; 
You can pass an array of bind variables to execute. Include in that list whatever you need to. Untested example below: my @values = (1, 2); if ($x) { $extraFields .= ', X'; $extraValues .= ', ?'; push @values, 3; } my $query = "INSERT INTO sometable (A, B $extraFields) VALUES (?, ? $extraValues )" $sth = $dbh-&gt;prepare($query); $sth-&gt;execute(@values);
FWIW - A "list of scalars" is essentially an "array" (at least in the context you mean).
Yes and that's not it at all. I need to do some data quality tests and wondered if anyone knew of any perl work to do this. I do not want to profile the performance of any perl code. thanks 
you're right, guess I didn't explain myself correctly
Thanks! indeed, that's what I ended up doing, I didn't knew it was possible I didn't saw that as a valid parameter for execute in the DBI API.
You just need to make damn sure you have complete control of what gets assigned to $extraFields and $extraValues, because that's a one-way ticket to a SQL injection if you're blindly including unsanitized data directly into your query.
[pdf copy](http://ge.tt/8kwmGpZ/v/0) I can upload elsewhere if this doesn't work. (all the simple fileshare sites I used to know seem to have quit public sharing or have gone over to pornware.)
For future reference: https://metacpan.org/module/DBI#execute $rv = $sth-&gt;execute or die $sth-&gt;errstr; $rv = $sth-&gt;execute(@bind_values) or die $sth-&gt;errstr; Here's a great article on this kind of stuff that will show you how to simplify/generalize your code: http://www.perl.com/pub/2001/03/dbiokay.html Placeholders: my $fields = join(', ', @fields); my $places = join(', ', ('?') x @fields); $sql = "INSERT into $table ($fields) values ($places)"; $sth = $dbh-&gt;prepare($sql); $sth-&gt;execute(@formdata{@fields}); $sth-&gt;finish();
everything i clicked on was the "edit me" boilerplate. do the links to the files go up while they're still being edited? 
Speaking of this, if anyone has a good pdf of the Good, Bad, Ugly slides I would appreciate that too.
Yea it seems people create a new file and then just write something and don't save their changes. Yep. It creates the file first then displays it in the editor.
you're asking to get exploited: IPC::Open2 still works for process execution you can use an eval and split any string that you're filtering again I can see your source your method of doing run probably allows a user to shell out and do whatever they want is the daemon running as root? you're *really* asking for trouble if so. (everything in /home/limiteduser/PerlExecutor seems to be chowned root:root) the userland on this box gives me *way* to many ways to break your security model
Can you give me more detail on this. Maybe email me please? gideon [at] cpan [dot] org. I did this as a learning project, so I would like to learn how to fix this. I'm sure the PerlExecutor daemon isn't running as root but I will double check. I created a new user called "limiteduser" and I run the daemon on this. Would you know of any other way to block security calls? Safe.pm is pretty limiting, the author of codepad.org uses ptrace in a executor written in Haskell so I've been looking at that.
Still the same 5 they've had for a year?
this looks right. https://dheeb.files.wordpress.com/2011/07/gbu.pdf
I simplified my code a little bit... There are some values in the %hash already and I need to extend/override some keys/values in those hash by the $href. You are right with the dereference, thanks a lot... EDIT: grammar
"The keys of a hash are returned in an apparently random order. The actual random order is subject to change in future versions of Perl, but it is guaranteed to be the same order as either the values or each function produces (given that the hash has not been modified)" Source: http://perldoc.perl.org/functions/keys.html --- However if you need to create a copy of a hash why not just copy it? my %hash = %$href;
I needed to insert the %$href into the %hash. Could be done also as: my %newhash = (%hash,%$href);
flamey misread your post. So /[+-]?\d+$/ matches numbers with a + or - sign at the end. That's what the $ sign means--it means after the last digit must be the end of the string. The ^ in your regex is the opposite--it means "must match the start". So if the start of the string matches that, and the end of the string matches that, that means the entire string is a series of digits (\d+) with a + or - in front ([+-]?).
On a side note, the perl built-in hex() function would allow you to do the conversion directly. $ perldoc -f hex $ perl -lwe 'print hex shift' 0x10 16 $ perl -lwe 'print hex shift' A50FB 676091 # Has sections on recognising and converting numbers $ perldoc perlfaq4 # See also Scalar::Util::looks_like_number() $ perldoc Scalar::Util 
It just so happens that I saw the hex() function a few minutes after I finished coding what I had. It was a nice little quick intro having to code the function on my own.
Ok. I looked at it and had no idea what it did at all, but tossed it in the code and it worked haha. I just hate putting something in without knowing what it does and not trying to find out.
I wonder if you'd get a different key() order for two hashes if they were created in different orders, or one had extra keys deleted etc. I don't know how perl hashes allocate space, nor deal with collisions, but I there is a chance that two identical hashes could have different internal iterators. The following code (under perl 5, version 12, subversion 4 (v5.12.4) built for darwin-thread-multi-2level) which creates two identical hashes, but in different order gives a mismatch in the order of keys() my (%hash, $href); my $num = 10; for (1..$num) { # Created in numeric order. $hash{$_} = 0 } my $hash_str = join ":", keys %hash; for (1..$num) { # Created in reverse numeric order. $href-&gt;{ $num - $_ || $num} = 0 } my $href_str = join ":", keys %$href; if ( $hash_str eq $href_str ) { print "keys() match\n"; } else { print "keys() don't match\n"; print "$hash_str\n$href_str\n"; }
:-) Get used to that experience, it's very common in Perl! One of the biggest things to unlearn when you pick up Perl is the temptation to think nobody could possibly have written appropriate infrastructure for what you need. Perl has been pretty heavily hacktimized for most common tasks, so if you find yourself doing something long and awkward, better than 9 times out of 10 there's a better way in the language itself or on CPAN. 
&gt; Because by dereferencing the $href twice, you will get 2 different hashes This is the part that's completely wrong, and makes the rest wrong. `%$href` is the same hash every time you write it (well, unless you re-assign `$href` of course). How could it not be?
I only ever consider web developers for interview if they have a handlebar mustache that is at least half as manly as Larry's; and that includes the ladies.
`/^[+-]?\d+$/` tests your entire string. No need to do this character by character. Perl is not C! Besides: the ASCII code of "0" is 48, not 55.
// defines a regular expression. ^ means beginning of line ^* [] is a character class, meaning match any character defined here - could be a list of characters or ranges , eg a-zA-Z would define all letters. ? Means optionally match the preceding \d defines a number \+ means “one or more” $ means end of line ^* So, the whole regex reads as “match the beginning if the ljne , followed by an optional +/-, followed by one or more digits, followed by the end of the line. ^* note - if the regex had an 's' modifier it would mean beginning and end of string rather than line,
&gt; I needed to find away to determine if each digit was a character or number Use `looks_like_number` subroutine from `Scalar::Util`. From the manual: looks_like_number EXPR Returns true if perl thinks EXPR is a number. See ""looks_like_number"" in perlapi. A quick test: #!/usr/bin/env perl use 5.012; use warnings; use Scalar::Util 'looks_like_number'; my $input = "FFAA33"; # split every character in $input and test it with looks_like_number for my $probably_a_digit ( split //, $input ) { if ( looks_like_number( $probably_a_digit ) ) { say "$probably_a_digit is a digit"; } else { say "$probably_a_digit is a not a digit"; } } Use [grep](http://perldoc.perl.org/functions/grep.html) to filter them out: my @char = grep { looks_like_number( $_ ) } split //, $input; 
`perldoc perlre`, bro. Read it now and pull it out again every week or so for the rest of your life, 'cause you'll be using it that often.
&gt; So /[+-]?\d+$/ matches numbers with a + or - sign at the end. I had to read this two or three times to realise what you meant -- at first I thought the + after the \d had confused you. You mean "an optional + or - at the beginning", right?
C will be faster. Pure Perl will be easier to develop and more portable. Unless you have an existing C library to bind to, you'll probably want to go with Pure Perl. Perhaps looking at some of the existing PP DBD modules would be helpful. [DBD::Google](https://metacpan.org/module/DBD::Google), for example. I wonder, though, if there might be a simpler solution to your problem, not knowing what your problem actually is. Have you looked at modules like Metabase or KiokuDB? Otherwise, you'd probably have better luck on the DBI mailing list.
I think I will end up sticking to pure perl and if someone else has the gumption they can write it in C. I could write a rest object but the issue is speed. Instead of connecting directly to the db I am now connecting to an API. I think my next step is the mailing list. It is just a daunting place.
I think I meant the number is "at the end [of the string]".
Ah, that'd do it!
I've no idea how to get Apache/mod_perl running under Windows, but would using PSGI be a viable alternative for you?
sadly not
+1, all build tools required for compilation should be included in your Strawberry Perl distribution. Not so long time ago I've got similar case and found only one set of existing mod_perl binaries for SP 5.16 [here](http://people.apache.org/~stevehay/) but you'd better compile it by yourself (I didn't try it on Apache 2.4 on 64 bits).
 $DB::single &gt; Will be true if the API will stop at the next statement. from: [Perl Programming Documentation , DB - programmatic interface to the Perl debugging API](http://perldoc.perl.org/DB.html) might be a valid flag to check whether you're debugging or not. But I guess there must be a more handsome way of doing this.
While $DB::single is awesome, it's not normally used to be read, but is written to and causes the debugger to stop at the next opportunity. Its presence is also not guaranteed and it will usually only be around when the perl 5 core debugger library is loaded, which it wouldn't when you're profiling with Devel::NYTProf, for example.
So if $\^P is non-zero, the application is in debug mode? 
That seems to be a more handsome way to go!
Yup. :)
This worked for me. Thanks 
Great article. Now can we get a version written for managers? :D
If anyone is able to build this successfully, I hope they post it online. I know I could definitely use this. 
Bummer :-( Good luck though! BTW, there seem to be some Windows notes on the mod_perl site: http://perl.apache.org/docs/2.0/os/win32/install.html but I've only ever used mod_perl on Linux; no idea what it's like on Windows. If it's any help, we've been using Apache/mod_perl on our main websites for many years, but recently I've found it's getting hairier to maintain, such as not getting more recent releases of Apache and mod_perl to compile properly (we use a bit of custom config and whatnot). I'm switching some of our newer projects to an NGINX front-end proxy with PSGI/Plack Starman back-ends; it seems ok.
Building mod_perl using Strawberry Perl + MinGW is difficult task. Only officially supported (and documented) way to build mod_perl under Windows requires ActivePerl and Visual C++.
ok, this makes sense. especially that second example. thanks for the great explanation :)
Also "We’ve got a great line up of Master Class Training for YAPC this year. Trainers include, Gabor Szabo, Michael Schwern, John “genehack” Anderson, Dave Rolsky, and Stevan Little. There will be classes given both before and after YAPC. [Get the most out of YAPC by signing up for Training](http://blog.yapcna.org/post/44314925087/get-the-most-out-of-yapc-by-signing-up-for-training)."
I think this is a cool idea
I guess you asked on IRC? So it will be ported? This would be great :)
Gnarley Barley on South Orange at 7pm tonight!
Fish on Fire wins! Around the corner from Gnarley Barley at Daetwyler and McCoy!
&gt; I'm assuming this is an array indexing problem? No, it's a "you called `$sth-&gt;fetchrow_array()` the first time and threw away the result" problem.
Sorry i didn't get round to replying to your PM, been very busy. The problem is you're using an incorrect way of checking the results, which is "fetching" the first result from the query and discarding it `if (defined $sth-&gt;fetchrow_array()){` There isn't really a method for safely checking the amount of rows returned. You're options are: * Perform 2 queries, one to check the expected size and the other to fetch the results * Iterate over the results as you are doing with the while loop and keep a counter, if the counter is 0 at the end of the while loop then you have zero results. --- my $sth_count = $dbh-&gt;prepare("SELECT COUNT(*) FROM table"); my $sth = $dbh-&gt;prepare("SELECT * FROM table"); $sth_count-&gt;execute(); my ($count) = @{$sth-&gt;fetch()}; if($count &lt; 1){ print "NO RESULTS\n"; }else{ $sth-&gt;execute(); # Iterate sty results here } **This method isn't recommend for multiple access/realtime/critical systems as there is a potential race condition between checking the resultset size and iterating the results. --- my $sth-&gt;execute(); my $counter = 0; while( my $row = $sth-&gt;fetch()){ $counter++; # Do something with $row; } if ($counter == 0){ print "No Results founds\n"; } 
And the first resolution from tonight's meeting is to figure out the location for next month more than 4 hrs ahead of time. 
This. I would have loved to come. 
I work with that author. :) Smart guy; builds systems.
I'm surprised that there are considerable users who's using 5.8.3
considerable? That's only 0.8% - maybe you took the color wrong for 5.8.8? Click the graph and hover over it to see which color represents which versions.
RHEL 4.
@miyagawa I was guessing that users of 5.8.3 is more less. @average-drifter indeed. Additional: I noticed big blue is not 5.8.3 just now.
Fascinating. I personally do not try and make my cpan modules compatible with pre-5.10 perl. It's been a long time, and I am addicted to the // operator. This data, to me, suggests that we probably can't get away with that for modules in heavy use, but it's probably fine for more specialty modules.
Not to my knowledge. JavaScript is pretty much the only option, and at best you can get something to compile to it. To be honest, it's really not that bad these days. I hated JavaScript with a passion after my experiences with it before. Started using JQuery and such recently and it's a lot nicer than it used to be. 
Is there a demo video?
me too, and me three :) // is a godsend. as well as named captures.
http://perl-begin.org exists and is funded by the Perl Foundation.
Is there a conclusion that comes after that statement? Are you suggesting that perl101.org doesn't need to exist because perl-begin.org exists?
That is what I would infer from his/her post.
Its really easy to use. Just install, and follow the instructions on how to start it up. It'll tell you a URL when you launch it from the command line. You go to that URL. That's it. 
I'm a sucker for cookbooks when learning a new language. A quick poke around perl101.org makes me like it because it's simple and really dives into basic things you might want to do when you start programming perl. The perl-begin site seems like a manual when you first go there. The sidebar is more like a table of contents for a book than a beginners resource. I suppose they could begin at the beginning, read the "Home", "About", "News", or "Links". or they could be sensible and start with "Online Tutorials" but they would again face a wall of text. One thing both sites could use is a very prominent search bar at the top, encouraging users to drop all of their braincells and just type what really brought them here. Fuzzytext, autocompletion, whatever is optional. Having said all this, I don't have cycles to spare for improving perl101.org, but I don't think it should disappear. It seems like a valuable resource, and as long as the information isn't outdated it doesn't hurt anything. Unless it's getting hammered and costs tons to run.
Wikifying it might make it easier to grow the content as well. Then it requires more management though. 
It doesn't cost tons to run. It costs me the $10/year for the domain name. That said, it's sad to see it just sit pretty much untouched for a couple of years. I don't want to go the wiki route because that's just a nightmare of editorial slop.
~~what about crowdsourcing it and~~ putting some ads on there? 10$/year should be reachable edit: just saw your comment further down about wiki route, i take it that's not viable either. 
Pardon my ignorance but what does // do?
What about popping it in a public repository if no-one comes forward who wants to take over the whole thing? Obviously still requires some management but could (?) be easier than a wiki. Edit: apologies, I've just seen that there is already a github account. 
The money isn't the issue. I don't mean to brag, but I can afford $10/year. The issue is that there's no one driving it. No one is adding content, no one is making noise, etc. It's effectively crowdsourced and people have indeed contributed, but it needs new blood.
If there was a plugin/browser combination that would enable you to do this it would be pretty useless as other users would be required to have the same browser/plugin combo. If this isn't a problem for you then this could mean that you are just creating something to be used by yourself. If this is the case you could just create an interface for your application using wxWidgets or some other framework.
A bit ironic that the script uses pratices that can potentially become security bugs themselves.
Could you elaborate?
writing bulletproof code is hard. Off hand here are a few problems I'm spotting just playing spot the error. * Opens a file for writing without checking for an existing file * lots of global variables (including that filehandle) * RandUserRange modifies some global variables it isn't called with (arguably those globals should be initialized when they are created.. even if you're leaving them global. At least you wouldn't have a chance of inadvertently using them without initialization) * mix of '.' append, semicolon and commas in @url initialization makes it hard to read (and could be done in a readable way without trying hard) * mix of camelCase and all lowercase variables. No consistency or marking if it's a method or variable or reference. $i is a global variable (usually not a smart idea since it's reused often and without careful checking you won't know if it's been left at 0 or some random number) There are some other nitpicks but I'm not going to fault the guy too much. Most of the time people writing POC code are "get it done" people, not 'strict for strict's sake!' people. The code is sloppy in ways that make it nasty in a 1000 line file, but for a small POC it's fine. 
2-argument open can sometimes become an issue. Not in this case perhaps, but it's not considered a good practice: see http://modernperlbooks.com/mt/2010/04/three-arg-open-migrating-to-modern-perl.html
It's the defined-or operator. It lets you type: $a //= 0; instead of: $a = defined($a) ? $a : 0; You'll be surprised how often you write something like this. Perl has always had ||, the // completes the quinella.
is the input just a flat file? there are more sophisticated ways, but you could just cut the input file into a manageable pieces and load them one at a time.
Opening a file does not cause anything to be read into memory, it just causes the file to be available for reading. The usual way to open and process a file a line at a time without loading it all into memory is this: use warnings; use strict; my $filename = "foobar.txt"; open my $fh, '&lt;', $filename or die "can't open $filename: $!" while(my $line = &lt;$fh&gt;) { # do something with $line } # $fh automatically closes the file when it goes out of scope, no need to close($fh) If however you write something like: my @lines = &lt;$fh&gt;; or: for my $line (&lt;$fh&gt;) { ... } ...then it's going to have to read everything first before anything can happen. You generally want to avoid that unless you really need the whole file in memory at once for some reason. 
Thanks. Any good way of keeping track of its progress instead of just printing an autoincrementing value?
The variable `$.` (also known as `$NR` and `$INPUT_LINE_NUMBER` if you `use English;`) holds the current line number of the last accessed file handle. 
Is this genomics? I often split my files based on chromosome and operate on things one file/chromosome at a time. So if you're doing some kind of comparison then you'll just compare the chr1 file with the other chr1 file.
(Where a 'line' is defined by the stuff between the value in `$/`)
Yes! I was planning on running a script through and splitting them by chromosome first. Edit: grammar
Ooo, thank you.
I'd just like to follow up on [PenultimateTry's](http://www.reddit.com/r/perl/comments/1acwj8/bioinformatics_help/c8wb2sg) comment with a link to [Bio::SeqIO](http://www.bioperl.org/wiki/Module:Bio::SeqIO). After reading some of your later comments it looks like the sam file is tab delimited but could also be in a bin format. SeqIO looks to natively support tab delimited files and will do the heavy lifting for you with a built in cursor function. 
I'm a protein structure/homology modelling person, I'm afraid, so I've not heard of Galaxy. From the docs that you linked, `Bio::DB::Sam` claims to be compatible with the `Bio::SeqFeatureI` interface, which is probably the closest you'll get to a standard for dealing with sequences or sequence features (BioPerl is sorta-kinda similar to [BioPython](http://www.biopython.org/) and [BioRuby](http://bioruby.org/), so it's not a complete loss if you switch to a different language later. Whether it's a good idea to translate perl idioms to python and ruby is up to you...). My spirit has not yet been broken by the general quality of academic software, so I'm going to implore: please use an existing library if you can! I hate digging through the code of the poor bastards preceding me that reinvented the parser and saying (or shouting, with added obscenities) "What is this? Why does this comment just say 'florb the gnarbs'? What are gnarbs? Why do they need to be florbed, but only on a Tuesday? If I florb them on a Wednesday, why do perl versions before 5.14 die?"
`Bio::SeqIO` is pretty nice! It felt kind of clunky the first time I used it, when I was only working with nice and simple FASTA files. It's a lifesaver when you get onto the more...*fancy* formats. Since a cursory reading of the `Bio::DB::Sam` seems to indicate that alignments are relevant, I shall point out that bioperl comes with `Bio::AlignIO`, as well as `Bio::SeqIO`. Maybe not relevant in this case, but it might save some poor sod the pain of finding that their lovely parser code that handles all the edge cases is completely unnecessary.
Thanks, I'll check it out.
I'm not sure. I'm just trying to help her out with what she needs. I assume it isn't doable in Galaxy as she asked for me to do it separately.
Needs more obfuscation.
Scrolling on that website hurt my eyes
That was so obscure I didn't get it :-( 
http://en.wikipedia.org/wiki/Just_another_Perl_hacker http://www.cpan.org/misc/japh
That's the joke! :D
Punctuation sir, my god.
I actually resolved this, I just used ua::UserAgent and opened a file for reading instead. I don't like it, but it works. I figured I'd use curl because I know libcurl is installed by default on OS X and I didn't want to use any external dependencies if possible, although I'm probably going to add the Log::Log4Perl module now! Thanks anyway!
I work with tab delimited files every day. Here's how I do it: open(INFILE, $filename) || die "ERROR: Could not open $filename. $!"; @lin=&lt;INFILE&gt;; # read whole file into array chomp(@lin); if ($#lin&lt;0) { $s="ERROR: no lines were found in $filename."; writeerr($s); exit; } $lpos=0; while ($lpos &lt;= $#lin) { # do stuff $lpos++; } close(INFILE); Occasionally Excel will put a bunch of blank lines at the end of the TD file. 
Yes! 
If you just want to grab a file and save it to disk, https://metacpan.org/module/LWP::Simple is probably what you want.
Sometimes you can use the form http://username:password@website.com to do authentication, just for the record. 
Interesting, I didn't know that graft had been "replaced" by replace.
Yup, here's Junio saying as much: http://git.661346.n2.nabble.com/BUG-Cannot-push-some-grafted-branches-tp7572814p7572915.html
I've found that going off of inference is perilous.
perl5 or perl6?
The class was in perl 5, but he's been talking a lot about 6 since that is a large part of what he's been working on. edit: perl 5 isn't going away, and is currently faster then perl 6, but perl 5's optimizations are near the ceiling, while perl 6's optimizations are near the floor, and is getting faster. He just compared perl 6 to the lord of the rings, vs the hobbit being perl 5. Perl 6 is the sassy younger sister that thinks it knows everything, and perl 5 is the older sister that actually knows how the world works.
 Ask him what mistakes were made w regards to Perl 6 If he had it to do all over again, what would he change.
Asked my question already :/. He's spoken to this to some extent though. He said he sees Perl6 as an experiment... perl 5 was stable enough, and there was no company selling it, that the perl 6 community was free to try to fix the whole system instead of trying to interate. experiments could fail, but they'd still have learned a lot. 
Perl 6 is the answer he gave for this question Regarding perl 5, btw. 
Why was -I- the one who asked about OO in perl6, I figured someone else would've asked.
Difference in multiples? I think that is perfectly Ok to use perl to deal with sam files and I personally hate bioperl/python. I haven't touched perl in a while because i prefer python but this will be simple to parse while (&lt;fh&gt;){ chomp; if ($_ =~ /^#/){ next; } else { my @cols = split ("\t"); # now if she wants counts of mapped # reads I would build a hash. She # will need to deal with ambiguous reads # Regardless all your fields will be in # cols so you can filter on MAPQ or # whatever. } }
"I have a Perl class?"
"Can you take Guido in a fist fight? Why haven't you?"
"Why are you talking to my Perl class?"
Love that description. In fact maybe there's our answer to this whole "Should we rename Perl" hoohah that's going on at the moment. Instead of MST's suggestion of "Pumpkin Perl" maybe it should be "Sassy Perl" :)
What changes (if any) happened to the Benevolent Dictator for Life model between the early days of Perl 5 and Perl 6 that lead to the differences in the lifecycles of the software? (Perl 5 being fairly widely used in its heyday, while Perl 6 has been unable to get off the ground as far as widespread use is concerned)
If you're allowed, use [bioperl](http://www.bioperl.org/wiki/Main_Page). See `Bio::SeqIO` for reading sequences. There are also modules for running BLAST or other bioinformatics tools. If you don't want to (or are not allowed to) use bioperl, you can probably get away with just calling `system "blastn "-query ... -db ... -out ..."`. To be honest, this assignment is a bit strange. The default output format for NCBI's BLAST tools is a human-readable format subject to change. The modern (BLAST+) versions can use different output formats, including CSV and XML. So, realistically, you shouldn't be parsing the report file. Anyway, the steps you've given are fairly explicit. For step 2, you just need to take each sequence, output it to `seq.fasta` (a sequence name and the actual sequence), run BLAST, call `ParseBlastOutput` and store the results. If you want some untested pseudocode I wrote without more than a cursory glance at your actual assignment: for(@seqs){ #Write seq.fasta open my $fas_out, q{&gt;} "seq.fasta"; print {$fas_out} "&gt;$sequence_name\n"; print {$fas_out} "$sequence; close $fas_out; #Run BLAST system "blastn -query seq.fasta ..."; #Parse output file $evalues = ParseBlastOutput(...); #Process evalues } Edit: I should probably have made it more clear that you should assign `$sequence` from `$_` in the `for` loop. `$sequence_name` can either be on a for-sequence basis or just some arbitrary string.
It's 2am here too, mate :) You seem to have everything down. You just need to tie it together. I've just supplied boilerplate and pseudocode, but it might help you in the right direction.
I guess people get these ideas because they hear this kind of facts about Easter (e.g.: Easter very rarely occurs on March 22: last time was in 1818 and next time is 2285; it also rarely occurs on April 25) and they don't realize that Easter is a much more complicated beast than the rest of the calendar. Although even the simple naming of the week days does reveal some strange surprises: for example that the 13th of a month falls ever so slightly more frequently on a Friday than any other day (688 times in 400 years versus 687 for Wednesday and Sunday, 685 for Monday and Tuesday, and 684 for Thursday and Saturday).
You might want to look [here] (http://www.bioperl.org/wiki/HOWTO:Beginners) especially the part about [blast](http://www.bioperl.org/wiki/HOWTO:Beginners#BLAST) 
&gt;ORMs. DBIx::Class is wonderful. It's awesome. Until it's not Exactly. That's why I like Rose::DB::Object. It's not like magic, it's transparent enough, but you can understand it and manage it.
clone, patch, pull request.
[Ars](http://arstechnica.com/staff/2013/03/donglegate-is-classic-overreaction-and-everyone-pays/) has a good summary of the event which likely triggered this cover-your-ass-athon.
How about this insanity is totally unnecessary and doesn't help anybody? 99.9% of all people behave properly anyways - this one guy who's a moron at some conference can be easily called out IF IT ACTUALLY happens. I don't need a code of conduct, it doesn't improve anything. If anything, the recent PyCon incident shows how _completely_ out of proportion this blows and how completely utterly useless their code of conduct has been. And adding every niche - like "oh gee we haven't thought about public shaming before and now it suddenly happened" AFTER the fact is completely useless too. I really don't know who's supposed to feel better with these kinds of codes - but I as a woman certainly don't. And I don't want this kind of belittleling, paternalistic protectionist treatment. I will say something if something happens and I'm absolutely confident that I will have help when needed. Or am I going to shove down the code in someone's throat to protect me or quote it angrily or what's it supposed to accomplish IF anything happens? Please keep this shit out of this community. And I'm not the only woman who thinks like this. I don't need no stinkin' code. 
I think that's already covered. It states "Refrain from demeaning ... behavior" and I think demeaning includes public shaming. I'm curious why RsrchBoy created this repo and what rblackwe intends this reddit post to be about. Does anyone know of online discussion of problems with the YAPC::NA 2013 Code of Conduct (not just codes of conduct in general)? (Link?)
1. Don't be a dick. 2. Don't assume the other person is being a dick. If you need more code of conduct than that, you've already failed.
s/you/we/g
Agree. There should be no need for a code of conduct for adults in public professional settings any more than there should be special laws for behavior in red-seated movie theaters showing a comedies Tuesdays. I understand the organizers may need some gesture to avoid liability if someone ever does something stupid at a conference but such gestures are hollow. We've all been to kindergarten and we all know how to act. Furthermore, many attendees are representing their companies and have higher powers to answer if they screw up.
It's been a while, but I remember Uri G behaving pretty horribly at one of the Chicago YAPC's. What do you do when the *organizers* make you want to flee?
YAPC::NA 2012 [had a code of conduct](http://beta.webgui.org/conference/code-of-conduct). So did [2011](http://www.yapc2011.us/yn2011/conduct.html). This isn't new.
I feel like the whole of such a document could be: 1. **Don't be a dick.** \_\_END__
This rather presupposes visitors to those two sites are representative of all Perl developers. Perhaps a more accurate title would be "The distribution around the world of Perl Weekly and Perl Maven readers".
Agree agree. Codes of conduct like this are a sop to insecurity, and an example of legislative abuse. Organizational rules are a pretty blunt instrument: they're incapable of fixing certain types of problem, and incur pretty large costs. One sees rules like this a lot in collegiate settings, where concerned and "enlightened" white knights try to protect young "oppressed" introverts who recoil on encountering the real world. But - surprise! - dealing with opposing or even offensive points of view is different from oppression, and trying to fix it with rules is itself oppressive. Better to drop the entire thing. If you must include a code of conduct, I like ew73's suggestion best. You could amend it to "Don't be an ass" if you don't want a gender-specific slur. Edit: how very P.C. Please, if you're going to downvote, be courteous enough to explain why.
Indeed I think it would be much more useful if I could get per capita - at least for countries. I have not seen this in Google Analytics.
BioPerl is nice but the last thing you want to do is load a genome file into object memory.
&gt;When in an elevator, stare silently at the door. I can only assume that you're referring to the [Rebecca Watson Elevator Incident](http://en.wikipedia.org/wiki/Rebecca_Watson#Elevator_incident), aka "Elevatorgate", and it's associated drama. Let me first say that I think the drama was overblown. The behavior that occurred there should have been a private matter between two adults. There is no reason that an incident like this needs to be publicized absent some sort of unwanted physical contact. That said, conferences are not your dating pool. Act like a professional. Would you ask out someone at work? Probably not. So don't do it at a conference. Problem solved.
There is a long discussion on the YAPC mailing list--not sure if that's archived anywhere public. But it basically all comes out of that recent incident at PyCon. One of the complexities is that the YAPC code of conduct as it stands was already vetted by a lawyer. It's not a simple matter to get new additions straightened out, and certainly won't happen in time for YAPC::NA this year.
If you can get away with it, [Inline::C](http://search.cpan.org/~sisyphus/Inline-0.52/C/C.pod) is by far the quickest and dirtiest way to get started. The [I::C::Cookbook](http://search.cpan.org/~sisyphus/Inline-0.52/C/C-Cookbook.pod) docs are also pretty good if you can find something close to what you want and steal it. You'll probably end up with half a dozen tabs for `perldoc perlxs`, `perlguts`, `perlapi` regardless of route. [`perlxstut`](http://perldoc.perl.org/perlxstut.html) is (from what I recall of when I tried to do some XS things) not too bad, although has some gaps for things you probably want to do.
In addition to shobble: You'll probably be able to get some help in #p5p on irc.perl.org
[SWIG](http://www.swig.org/Doc1.3/Perl5.html#Perl5_nn32) is a good place to start. But beware the steep learning curve!
You probably mean [Tk](http://search.cpan.org/~srezic/Tk-804.030/)? It's not bad, I've used it once before. I also like [WxPerl](http://search.cpan.org/dist/Wx/), a wrapper around WxWidgets.
Su-Shee is kind of ignorant. Perl sucks and so does Su-Shee.
Tk is very mature and if you just need a simple click-here GUI, it's absolutely enough. I wouldn't bother to put more work into it. Alternatives are Gtk2.x and Gtk3.x bindings or Qt. But honestly.. for a "go" button, Tk is just fine. :)
\o/ Yes, I totally suck. And I'm so ignorant that I use all languages equally. ;) Also, I'm pretty stupid, let's not forget that. ;) And [ ] _______________ (your favorite insult here) 
Writing documentation is kind of like washing dishes after a nice meal; nobody wants to do it, but it needs to be done.
For something simple as this, how about dialog/zenity? https://metacpan.org/module/KCK/UI-Dialog-1.08/lib/UI/Dialog.pod#fselect
Tk is very simple and good; recent Perls include Tkx instead (same thing, different wrapper). You'll find an excellent tutorial here: http://www.tkdocs.com/tutorial/ with the advantage that if you pick "Perl" in the language dropdown, all the examples will be ni Perl, so you don't have to "learn" Tcl at the same time. 
the guy i learned perl from always said "it's not done until you finish the perldoc". i really like this attitude, and try to apply it to everything i do.
That's quite possibly the simplest and most accurate description of documentation I think I've seen. 
I've worked with perl, php, and javascript quite regularly. I haven't needed to use CPAN since 2001. I didn't even realize it was still around. Those rare times I need a module, the OS has a package for it. What is pip and why is this so important? I haven't heard that one.
... and your code can't be moved to anything else. That's my point. 
That doesn't sound like a point at all and makes no sense. The great thing about scripting languages is that they're portable
I have found Tk to be very easy to pick up quickly for making simple GUIs. It also seems to work well cross-platform. I've used it on Windows, Mac OS X and Linux.
You say you don't use CPAN modules. You say you use the package on "the OS". So your code isn't portable to other OSs. Which bit don't you get?
You do realize that the OS modules use the exact same packages as CPAN? It's simply a different installation method, and one far more convenient for those of us that have access to it. The code is very much portable
What are you talking about? You *do* use CPAN modules now? 
This simple? Print and readline...
Wxperl, though zenity would probably do. Also, perl 5.8.8, you do know it's not the beginning of 2006 anymore...
If you have a distro package use that, since yourl perl is 7 years old you'll probably need an equally old wxperl, but I don't know redhat well enough to say if they have a package or not. Sorry Cpan is an installer for perl modules, as far as i know it doesn't list what's installed or not, and if you want to install with cpan you'll probably have to install the normal wx libraries via red hats package manager first, as wxperl is a wrapper around normal wx
He meant he didn't need to use CPAN.pm. That is different from search.cpan.org :)
He installs modules with apt-get install libtest-most-perl not cpan Test::Most It's the same package in either case.
CPAN sucks, Perl sucks, Su-Shee sucks, you suck. Learn Python FTW
Seriously, are there enough Perl webpages, meta webpages, and meta meta webpages?
I agree. Can we say web page debt. Who's going to maintain these pet things when their owners die or no longer want to maintain them (perl101.org HELLLLLLO).
**my $pre = $frags{$enz}{'pre'};** What exactly are you trying to do here? {'pre'} doesn't exist in that hash.
 $frags{$enz}{'pre'} That doesn't reflect your structure. This looks like what you're trying to do? my %frags = (); $frags{'a'}-&gt;{pre} = 'foo'; $frags{'b'}-&gt;{pre} = 'bar'; foreach my $enz ( keys %frags ) { my $thing = $frags{$enz}-&gt;{pre}; print $thing,$/; } # prints 'foo' and 'bar' or maybe this: my %frags = (); $frags{'a'}{pre} = 'foo'; $frags{'b'}{pre} = 'bar'; foreach my $enz ( keys %frags ) { my $thing = $frags{$enz}{pre}; print $thing,$/; } 
$enz is going to be your keys, aka 'a', 'b'. So you can drop the {'pre'} also remember that the "my $pre" is a variable that for 1, will be over written each loop, and 2, if you are using strict will only have scope of that foreach loop. Edit: fuck that formatting http://pastebin.com/kZvmhtnm
I don't think anyone can really understand what you're trying to do from that section of script, but you're *still* trying to do something much more complicated than you need to. After this line: %frags = ( 'pre' =&gt; $1, 'post' =&gt; $2); you have a really simple hash with two keys and each key having one value. There's no reason in the world to go through your keys with any `foreach` loop. You have *two* keys! And you don't need to access them using this syntax: $frags{$enz}{'pre'} you just need this: $frags{'pre'}
If that's all you want to do, why do you even need a hash? Why not just use split? @frags = split /'/, $test;
This is kind of the main reason why even though I've been using Perl for a long time, and have been eyeing Ruby (what with Perl being it's Spiritual Liege and all that), I just can't seem to get away from using Perl in projects because it does everything I need it to do. I would like to get on to Ruby for some stuff though, it does look a little nicer in some respects. Edit: can't spell
when it is running from the console, are there any error messages / warnings?
Well, at a first glance, you don't appear to be using Gtk at all. Aside from 'use Gtk2', the only references to Gtk2 are Gtk2::Pango::Cairo for some drawing, I suppose. How is the main window created? $mw = MainWindow-&gt;new(-title =&gt; "HaploPainter V.$self-&gt;{GLOB}{VERSION}"); MainWindow? Let's look at the comment above: # Main Tk Window with Canvas and bindings So, the code appears to be using Tk instead of Gtk for almost everything. Let's look at the beginning again: use Tk; use Tk::BrowseEntry; use Tk::DialogBox; use Tk::LabFrame; use Tk::NoteBook; use Tk ':variables'; Tk is not Gtk. It's a different toolkit; looks differently, works a bit differently, and you seem to have written your program using Tk rather than Gtk. This is also why you can uncomment 'use Gtk2' without anything changing: you're barely using it (or not using it at all). PS: In the future, give people easy access to your code so they can look at it. A file somewhere on sourceforge where I have to search for it and download it doesn't qualify. Consider using github gists: https://gist.github.com/tadzik/5269686
&gt; at a first glance, you don't appear to be using Gtk at all. The code appears to be using Tk instead of Gtk for almost everything. Tk is not Gtk. It's a different toolkit; looks differently, works a bit differently, and you seem to have written your program using Tk rather than Gtk. Well, that explains a lot (Just to be clear, this isn't my code). I just looked through the documentation again and there's no mention of GTK as the graphical toolkit used. In fact, aside from the dependencies part, it's only mentioned once: &gt; HaploPainter uses Cairo and Pango for the creation of exported image formats. All of the precompiled libraries you will need are included in the GTK+ package So you're absolutely right: GTK2, specifically its Pango and Cairo components, are only used to render exported images. I guess I read over that part and just assumed that GTK would be the toolkit due to the listed dependencies. Naturally this means that the issues I am describing are completely unrelated to GTK and all my troubleshooting attempts were likely pointless. Thanks to you, however, I was able to find a [related discussion on perlmonks.org](http://www.perlmonks.org/bare/?node_id=887926). The OP there had the same issue with different popup menu behaviours on different platforms. As far as I can tell he wasn't able to solve it (or at least not the root of the issue), but I could be wrong. I looked through the code and found the relevant binding that invokes the context menu on line 299: $canvas-&gt;CanvasBind('&lt;3&gt;' =&gt; [ \&amp;ShowContextMenue, $menu, Ev('x'), Ev('y') ]); I suppose the creator of the script would be the right person to ask this but: Do you have any idea why the behaviour of this binding would differ between Windows and Linux? &gt; In the future, give people easy access to your code so they can look at it. A file somewhere on sourceforge where I have to search for it and download it doesn't qualify. Consider using github gists. Duly noted! Thank you for your answer, at last some clarity!
Ah, yes, Unity... I've had my own fair share of problems with that DE. Unfortunately it's not the component to blame this time: I have been happily running a mix of XFCE/LXDE on Openbox for more than half a year. Since you've already downloaded the script: Can you tell me if the context menu of the canvas works for you? Does it require you to hold down the right mouse button to remain visible or can you just click once and have it show up until you select an option or click somewhere else?
You're welcome :) I have no idea whatsoever of Tk and its behaviour on Windows. I suppose the &lt;3&gt; thing may not be so cross-platform after all: maybe it's &lt;2&gt; on Linux, or you need some additional X11 settings, as indicated in the perlmonks discussion?
The OP over at perlmonks had a slightly different problem. In his case the context menu didn't show up properly even when holding down the RMB. Turns out he was using the two-finger tap on his touchpad instead of a proper mouse. He was able to troubleshoot this by messing with the mouse settings on OSX. But this just led him to the point where I am, i.e. the context menu only showing up when holding down the RMB. I was able to troubleshoot some of my issues with Haplopainter by hacking the script a bit, modifying the window geometry settings and replacing `&lt;3&gt;` in the snippet above with `&lt;ButtonRelease-3&gt;`. It's the other way around now: The context menu stays open until I click on the menu bar. This is far from perfect, of course, but definitely an improvement over the previous behaviour. I think that the app is now more or less in a usable state and that's all I wanted. It's astounding really how far a few pointers in the right direction and some Google-Fu can get you! Still, if there are any Perl Tk experts out there who have some spare time, please feel free to chime in!
Yes, I know, [tsjr was kind enough to point this out to me](http://www.reddit.com/r/perl/comments/1b85mw/help_why_doesnt_this_perl_script_render_a_gtk_gui/c94jvpz). That fact somehow completely went over my head. Right now I am struggling with the [strange context menu behaviour](http://www.reddit.com/r/perl/comments/1b85mw/help_why_doesnt_this_perl_script_render_a_gtk_gui/c94kag5). Any chance you could take a look at the [source code](https://gist.github.com/tadzik/5269686) to see what might be causing this? Only if you're in the mood for it, of course.
http://i.imgur.com/xaBA0Sq.jpg http://sunray22b.net/media.htm
It's been a while, so bear with me on the details, but the general approach for binding events in Tk is: 1. Bind an event to the button press -- Either `&lt;ButtonPress-3&gt;` or simply `&lt;3&gt;` should work. This event should be a "show the menu" function. 2. Bind a similar event to `&lt;ButtonRelease-3&gt;` whose job is 'hide the context menu'. Alternatively -- and think about the apps you're familiar with, you bind the context menu appearing to the _release_ of the right mouse button (ButtonRelease), and bind an event to hide the context menu when any other button is _pressed_. 
Thanks for the suggestion! I wasn't able to find a call to 'hide the context menu' in the code but I was able to troubleshoot the problem by a.) binding "show the menu" to `&lt;ButtonRelease-3&gt;` and b.) deleting `$menu-&gt;grabRelease();`. I have no clue why that works, but it does. Thank you, everyone, for your help!
&gt;What is pip and why is this so important? I haven't heard that one. Pip is "A tool for installing and managing Python packages" either from downloaded source, or remotely from PyPI (the Python package index) https://pypi.python.org/pypi/pip https://pypi.python.org/pypi Not sure what the nature of his complaint was - either the package he wanted was not available on PyPI, or it was not configured to be installable via pip. 
Please don't post your questions in a paste site. Post them here in reddit so that we can all see them without having to go elsewhere for it.
This wasn't a question - it was a demonstration of Perl
Congrats on picking Perl as your next language. I can highly recommend chromatic's Modern Perl which is available as a free download at: http://onyxneon.com/books/modern_perl/ Stick with Perl 5 because Perl 6 isn't going to be production-ready (and even more important: widely used) for another 5-10 years, if ever. It's more or less a big programming language research project. If you want to solve problems and get things done, Perl 5 won't disappoint you. Enjoy! ;-)
Thank you. I thought no one would respond because it's been a while since I posted this. Thanks.
People would just rather make a new one than use the things the already work. Then again, what do you really expect from a perl community?
So cute.
Are there many such mainstream non-compiled languages providing eval out of the box :)
Something like this I guess. my @words; while(my $inp = &lt;&gt;) { chomp($inp); push @words, split(/\s/, $inp); } my $last = ''; foreach my $w (reverse sort @words) { if ($w ne $last) { print "$w\n"; $last = $w; } }
Piece of cake: #!/usr/bin/perl my %LINES; #I'll put the lines in a hash, to eliminate duplicates while (my $line=&lt;STDIN&gt;) { chomp($line); #chop the \n $LINES{$line}=1; } #reverse alphabetical sort of the keys of the hash foreach my $line (sort {$b cmp $a} keys %LINES) { print $line."\n"; } Hashes, lists and regexes make me love Perl. It's so simple to use.
Beginners avert your eyes. Golfing is hazardous to your health and your mom will not approve. I couldn't resist. @x{(split)} = 1 for &lt;&gt;; print join "\n", reverse sort keys %x, ""; 
Well, he tried to with that ($w ne $last) clause, but my spidey senses tell me that he meant to put "$last = $w;" outside the clause instead of inside it.
your spidey senses are right ;)
Perl is not C. Make use of its unique syntax. You should rarely, if ever have to write a C-style for-loop.
If someone makes some changes and a pull request, would that help? I found a few places that could probably be improved on, but I am not sure if that is the direction you wanted to take the site. For example, I'd like to add a perlbrew section to ["Where to get Perl?"](http://perl101.org/how-to-get-perl.html) Note: I realize I am commenting on a nearly three week old post. I apologize for the delay. tl;dr: Will you accept new contributors rather than a maintainer? 
Yes, new contributors will be great. There's a Google Group called "perl101-talk" that has been going for a while. I'm not sure that perlbrew is something that "every Perl programmer should know", which is how I'm trying to limit it. In fact, I may just remove the "Where to get Perl" page entirely, based on the assumption that people who are using it have it.
Using sort and map: #!/usr/bin/perl my %uniq_sort; my @r_sorted = sort { $b cmp $a } @ARGV; map { $uniq_sort{$_} = 1 } @r_sorted; map{ print $_, "\n" } keys %uniq_sort;
 @x{(split)}=1 for&lt;&gt;;print$_,$/for reverse sort keys%x Gogo golf it down :)
this isn't quite what the op asked but you can reverse sort an array and make it print like that, at least that's what i would do especially cause you're working with lines you entered in STDInput and not millions of data records
&gt; very minimal external dependencies Now THAT's what I'm talking about. It's possible my apps might be used on a second site. 
cat $file | sort -r | uniq
 undef $/; @x{(split /\s+/, &lt;&gt; )} =1; $,="\n"; print sort reverse keys %x;
/r/commandline is *that* way
All those pipes aren't really needed, are they? $ sort -ru $file I mean, I'm not a fan of overloading sort w/ a command line option for uniqing, but if it's there, why not use it? And since sort will take a filename, the cat does???
wouldn't just be: print(join(reverse(split(join(&lt;&gt;," ")," ")),"\n"))
No, because OP's problem asked to sort and remove duplicates.
You're right. I read the instructions wrong. I hat it when that happens.
You're right.
The call to scalar() is redundant and not idiomatic.
Right you are. I always used it for clarity, but it's rather obvious I guess.
I program Perl since 1999 and I had no idea. Nice.
It's a tutorial thread. I don't comment that line in my code.
I used chomp. &gt; **chomp** - This safer version of **chop** removes any trailing string that corresponds to the current value of $/ (also known as $INPUT_RECORD_SEPARATOR in the English module) In the comment, I used English.
Is this any better? #!/usr/bin/perl use strict; use warnings; use English qw/ -no-match-vars/; my ($n,$m); while (&lt;&gt;) { # perl -n: read lines off stdin my @F = split(/\t|\n/, $ARG); # perl -aF: split input line $n = @F-1 if (!$n); # length of input (assumed constant) # put each col of input into corr. row of arrayref-of-arrayrefs $m for my $i (0..$n) { push @{${$m}[$i]}, $F[$i]; } } # join cols of each row with "\t" &amp; append "\n"; print array END { print map { join( "\t", @$ARG, "\n" ) } @$m; }
Here are a few commonly employed solutions: - no session at all, or session read-only. If you know you don't need session, or don't need to manipulate it, you can in theory indicate this to your web framework and improve concurrency. (This can be important for download activities where your backend script can be tied for a long time when writing to a slow client, though you should in reality use a spoonfeeding proxy such as nginx.) - split processing of the request to the fast and slow part, if possible. For instance, only allow mutations of the session while processing the backend code, but then unlock session during template processing. While not a solution, more a mitigation, it's still very useful. The solution proposed in the article such as using a tie to bind hash directly to state in database table makes sessions more complicated to understand, though it is true that performing atomically updating operations in separate methods solves the problem in some cases. There are a few problems I can see: - more code, and a potential to do things incorrectly despite it looks innocuous ($session{foo}++ is wrong -- this is a fetch and store, and therefore has a race) - latency for database access (your session hash will be slow to read from) - transactions: if your database locks rows after a modification, then you will potentially get deadlocks between requests accessing the same session unless your access pattern to the keys avoids deadlocks. It is also very easy to inadvertently serialize access to a session, for instance by maintaining an automatically updating "last request time" timestamp, which will always hit the database lock anyway. The alternative of no locking (multiple versioning concurrency) is even worse, because that allows requests to unpredictably fail at commit time.
use Mojo::DOM! ➤ cat &gt; x.html ..... from your file.... ^D ➤ perl -lE'use Mojo::DOM; use File::Slurp; my $d = Mojo::DOM-&gt;new(scalar read_file("x.html")); $d-&gt;find(".match_details_cell")-&gt;each(sub { say $_-&gt;find("a") })' &lt;a href="/champions/thresh"&gt;&lt;/a&gt; https://metacpan.org/module/Mojo::DOM Comes from http://mojolicio.us/, and only needs perl (no other modules!) to work.
Bit of a nitpick here: &gt; Python is still suffering from that initial churn that you get with a relatively new language. Python was first released in 1991. That's four years after Perl's 1987 release, but I still would not call Python a new language. Maybe it seems that way because Perl was popular before Python was? 
s/File::Slurp/IO::All/g You can thank me later. :)
Wget grep cut
Fantastic, this is definitely on track with what I want to accomplish. Could you walk me through a little further on gathering the plain-text between the *div style* tags? For example, **Normal 5v5**, **Win**, **2 days ago** -- those fields.
http://search.cpan.org/~cjm/HTML-Tree-5.03/lib/HTML/Tree/Scanning.pod
I thank you now, not later. [It looks quite interesting](https://metacpan.org/release/IO-All), and [it's on Debian/Ubuntu](http://packages.debian.org/search?suite=default&amp;section=all&amp;arch=any&amp;searchon=all&amp;keywords=libio-all) already.
Writing scrapers is 90% of my job, and they all use Mechanize and https://metacpan.org/module/HTML::TreeBuilder. The look_down method of HTML::Element objects does the job really nicely
**Who cares in this day and age? Seriously.** Language development has moved way beyond both Perl and Python these days. Instead of living in the past and fighting this tired battle, marvel at the explosion of creativity in contemporary language design. **[ALTJS.ORG](http://altjs.org/)**
&gt; ... marvel at the explosion of creativity in contemporary language design. The winner is the JavaScript framework with more than a dozen users.
You should consider the one **[audreyt](https://twitter.com/audreyt/status/276144551536783361)** uses. 
Try [pQuery](http://search.cpan.org/perldoc?pQuery), which lets you use jQuery type selectors to grab content.
I really wish Mojo::UserAgent supported the `file:` schema so that it could be easy to test scraping scripts against local copies of documents. i.e: perl -MMojo::UserAgent -E 'say Mojo::UserAgent-&gt;new-&gt;get($ARGV[0])-&gt;res-&gt;dom' http://example.com vs wget -O example.com.html http://example.com perl -MMojo::UserAgent -E 'say Mojo::UserAgent-&gt;new-&gt;get($ARGV[0])-&gt;res-&gt;dom' file:///$PWD/example.com.html I've written my own little helper-tools type module to collect useful bits of code and have a wrapper that handles this: $dom = mojo_dom('http://www.example.com'); # via HTTP(S) $dom = mojo_dom('file:///path_to_file'); # via local file $dom = mojo_dom('file://localhost/path_to_file'); # via local file $dom = mojo_dom('path/to/file'); # no scheme is also local file but it would be nice if Mojo::UserAgent were a bit more clever. :)
Always refreshing to see someone interested in Perl despite what appears to be a prevalence of negativity these days (particularly in the web development world). Perl is an outstanding language and in this man's personal opinion you've made an excellent choice. As already mentioned, the result of the unfortunate naming conventions for Perl 5 and 6 don't really do you or any other newly introduced individuals with the language much good. Perl 6 is a work in progress and you are best served spending your time looking at Perl 5. It's also worth noting that just because 5 is one less than 6 doesn't mean that it's a deprecated version of the language. Perl 5 is still very active and the current version was release in March of this year. To be completely clear: It's best to think of Perl 5 and 6 as entirely separate languages (because they are) that share some amount of similarity in syntax and philosophy. It would be better if their names denoted that difference more clearly, but we're a little pregnant on the matter at this point. My personal opinion on paying for tutorials is to exhaust your free and low cost resources first. The already mentioned [Modern Perl](http://modernperlbooks.com/books/modern_perl/) being one good example. Odds are you don't need to spend a dime (though there are books, like the one already mentioned, that you really should support if/when you have the chance and means to do so). Honestly, the best way to learn this (or any language, really) is to set forth some small projects/scripts you think feel reasonable to accomplish (and potentially useful to you) and take a stab at creating them. Start small and work your way up from there. Every time you're tackling something new give it some thought, make some small attempts, and seek help in finding the best way to go about it. Feel free to seek help along the way as you need it (but I'd always start with some intelligent searching for existing answers before asking a question that may have been answered dozens or hundreds of times in the past already). There's a lot of knowledge out there and plenty of resources to seek help from. One last note: [CPAN is your friend](https://metacpan.org/). While I strongly advise learning the language and doing things yourself (or at least making small attempts to) when you're first introducing yourself to programming tasks, ultimately you're going to want to tap into the hard earned efforts of the community, and CPAN is going to have the necessary tools available to do just about anything you could ever dream of. In closing: Good luck, and congratulations on choosing Perl (it's a great choice)!
Wow. Thanks so much.
best post ever
Perhaps he meant a relatively-recently popular language? Perl got popular in the mid-90s, PHP from late 90s to early 00s, Ruby/Rails from 05 or so, Python (via Django et al) soon after Rails. So yeah, lots of people think Python is "new". 
I'll be there. I'll be the guy in the clothes.
Thanks for the poke in the right direction, this helped me greatly in hammering this out over the weekend. Cheers! 
http://p3rl.org/App::FatPacker
You haven't showed yet!
Good read.
DateTime is awesome, but I very rarely use it. I can't think of the last time I had to deal with "real" dates that required the kind of heavy-lifting correctness that DateTime provides (or DateManip for that matter). But on a daily basis I have to deal with trivial date/time handling like reading and writing ISO-8601 timestamp to and from databases, HTTP headers (cookie expiry times, etc), web pages ("Last login 36 minutes ago") and file modification times (and other general Unix epoch &lt;-&gt; date/time conversions) For that "simple stuff", I wrote [Badger::Timestamp](http://badgerpower.com/docs/Badger/Timestamp.html). It's small (~200 lines of code), very fast and extremely useful. Very much in the "simpler is sometimes better" school of thinking.
So what's the huge value add on Kelp over, say, Dancer? I read your "Why Kelp?", but what's the real value-add? The stuff that I would want to have more control over in an ideal world is the stuff that Kelp's handling anyway... or so it seems.
Took me more than five minutes to read, but was definitely worth the additional info and brush up. Bookmarked!
This looks like mojo wth
Very clean. Very nice. A much needed approach to many over-engineered solutions that are available today.
Simpler is generally better.
Thanks for your comment. I am not requiring or expecting anyone to use Kelp. It was not created to be a threat to anyone or anything. Everything is voluntary/free/open source/at will/if you feel like it.
This looks excellent! (If you removed the stripper comment, I could have people at work read this.) Anyway, great work.
I'm glad you like it. I removed the above mentioned comment, so the documentation is now fully business friendly. Kelp should find its way to CPAN by the end of the week, but in the meantime, you and your co-workers can view it on Github - https://github.com/naturalist/kelp
I know that, I didn't mean anything by it, anyway is free to work on anything they want as far as I'm concerned. But I'm gonna stick to catalyst
Well worth the read, thanks for that. 
Thanks for the comments, unfortunately my /r/programming post is stuck in a mod queue or something. Shame since I think a lot of people could benefit from the article :)
That's perfectly fine, but why? If you're going to mention it twice, may we hear the reason? Not disagreeing, just want to know. For example, maybe you're building larger apps and don't need to rapidly prototype, or...? The opposite (let's use Kelp or Mojolicious or Dancer2 rather than Catalyst) is for speed of development, in order to bang out something in five minutes (e.g. a single-file app in Mojolicious::Lite). Or you want to use WebSockets, or in the case of Dancer, you have just a couple days to build and debug a web service. Or in the case of Kelp, the fact that it's a thin layer over Plack is a novel and interesting advantage if you really love Plack, for example.
Thanks I needed a good laugh. These day I just use what every one else uses at work. As for the Java guys the stuff just works. The frameworks have been around for a while. There is plenty free/open source stuff you can just pull into your project and more importantly a enterprise can go out and get 100 java resume just like that.
HTML::TreeBuilder. Mojo::DOM would do, but I have something against installing a whole web framework just to work with a little html.... And if I'm totally honest, I have something against the Mojo folks reinventing everything when half of it is already on cpan in one form or another /rant
Hrm. I'm in Houston, I may be able to make that. That's probably why they chose Austin.
I'm sorry if this is a stupid question, but how do I install this? Is it available through CPAN? Thank's for your time.
If you want the full tempest in the teapot, head on over to [PerlMonks](http://perlmonks.org/?node_id=1026502). It's probably not worth your time.
I thought they said it was sold out? EDIT: Nevermind, somehow I was reading a [blog post from last year](http://blog.yapcna.org/post/22122208465/yapc-na-sold-out).
Are you trying to do a closure? That seems a bit advanced for a novice but without a copy of the Camel book it is hard to know what you are getting at. Otherwise, the easiest solution would be to move the my $n outside of the sub. Then you'll also have to fix the == on your if. my $n; sub greet { $n += 1; if ($n == 1) { Putting the my inside the sub means it gets a new value each time the sub is run.
 if ($n = 1) { should probably be if ($n == 1) { add this in after your use strict line: use warnings; and it will tell you helpful stuff, like point this error out to you. i also just noticed, you are using "my $n += 1"...that is creating a new local variable each time greet() is called, so it's always going to be one (undef + 1 == 1). it always says hello to Dave, yes? there's a better solution to this problem, you should try a different approach.
OK, I found a copy online. They are expecting you to use a 'state' defined variable as explained in section 4.11. You should also probably review section 3.1.
Thanks! That's exactly what I needed.
Perfect. I suppose I need to get in the habit of turning on warnings. Thanks.
i played around with http://code.google.com/p/android-scripting/ a while back, might be worth a look
Been using SL4A for a long time and it's generally excellent. Perl support is a bit poor though due to a lack of some common modules. Python support is much more complete if you know perl *and* python.
Welcome to Perl! Since it looks like nobody's said this to you already, let me tell you that ~~the~~ my copy (d'oh!) of the camel book is a bit dated. But that's Ok! It's still great, but you have to be wary because there are new ways to do things that the camel book doesn't teach. For example, you will want to call your subroutines like: greet(); or: greet; Using the ampersand (&amp;) means you are doing one of two things that you probably don't want to do. You can read about what the ampersand in front of the subroutine call does in [perlsub](http://perldoc.perl.org/perlsub.html). For Perl books and tutorials, see: * http://perl-tutorial.org/ * http://learn.perl.org/ * http://books.perl.org/onlinebooks * http://perl-begin.org/tutorials/ * http://learn.perl.org/library/beginning_perl/ * http://www.onyxneon.com/books/modern_perl/ Modern Perl isn't exactly for a beginner but it's good stuff. Additionally, Perl lists hold scalar values. When you reference a particular value, you want to write something like $myarray[0] (instead of @myarray[0]). Finally, here's the payoff. Here's a Perlish way to do what you want to do. I hope it makes things clearer. #!/usr/bin/env perl use strict; use warnings; use feature qw/say/; # This is how to do what you want using a closure. # You can look up closures on Wikipedia, or look in perlsub. # Search for the text "Persistent variables with closures". { my $last_visitor = undef; sub greet { my ($name) = @_; say "Hello, $name!"; if ($last_visitor) { say "You just missed $last_visitor!"; } $last_visitor = $name; } } # This uses recursion and that ampersand thing I mentioned earlier; # it's pretty silly. Try to see if you can figure out how I did it. sub predictive_greet { my $name = shift; say "Hello, $name!"; return unless @_; say "You're going to see ${_[0]} next!"; &amp;predictive_greet; # This statement makes the subroutine "tail-recursive". } my @names = qw/Dave Jay Conan Jimmy Craig Johnny/; map {greet $_} @names; say "Now let's go the other way!"; predictive_greet @names; EDIT: formatting.
Did somebody steal your mojo?
Hi. This is not a stupid question at all. Kelp is not available on CPAN yet, so installing is a little tricky. You have to clone the repository on your local computer, run `dzil build`, then install the tar.gz file via cpamn. Or, you can wait until Friday evening, when I'll publish it on CPAN and then you can install it from there. EDIT: Kelp is available on CPAN now. You can install if from there.
For those curious about Perl 6 on Android, from [#perl6 recently](http://irclog.perlgeek.de/perl6/2013-03-15#i_6591198): pmurias: * how hard would it be to port [nqp-jvm](http://6guts.wordpress.com/2013/02/17/nqp-on-jvm-gets-grammars-multiple-dispatch/) to android? jnthn: * I guess you'd have to turn the bytecode into stuff for Dalvik... * There's a tool for taht. * Not quite sure what happens next :) * "Try It To See" :) * I'd be curious how it works out
That is how the question is written, actually.
Hasn't it rather bitrotten by now? It seems it hasn't moved at all in years. Even if it still works with the new versions of Android, I imagine it doesn't interface any of the new API's. It would be really nice if someone resurrected the project.
I'm curious what you make of [Perl 6's Unicode related elements](http://www.google.com/cse?cx=005089285939400490688%3Athhniwrkcma&amp;ie=UTF-8&amp;q=unicode+OR+nfg&amp;sa=Search&amp;hl=en&amp;siteurl=www.google.com%2Fcse%2Fhome%3Fcx%3D005089285939400490688%3Athhniwrkcma%26hl%3Den&amp;ref=&amp;ss=4009j1719309j15#gsc.tab=0&amp;gsc.q=unicode%20OR%20nfg&amp;gsc.page=1).
I downvoted this because you posted a link to (your own) short blog entry pointing to the real content, tinita's blog post. This is commonly known as blog spam. Not that the original blog post was uninteresting...
D'oh! Thanks. I have edited my original comment to reflect that it is in fact *my* particular copy of the camel book that is out of date. ;) Do you have a copy of the book? I am curious as to whether the examples in that chapter actually show subroutines being called like that or if OP just gleaned that from one of the ~~black terrors~~ gloriously hideous tutorials festering on the web.
The book he's using is actually Learning Perl, not Programming Perl (the camel book). Of course, both have a ~~camel~~camelid on the cover. And yes, Learning Perl 5th edition does use the &amp; syntax in its first example.
&gt;The book he's using is actually Learning Perl, not Programming Perl (the camel book). Of course, both have a camel on the cover. http://shop.oreilly.com/product/0636920018452.do I've always seen the book with a llama as the colophon. Has there been some different edition that I am not aware of?
No, of course that is a llama. I was mistaken. They are both Camelids though. Which is what I meant to say. Yeah, that's it.
 my $s=do{local(@ARGV,$/)='test.html';&lt;&gt;});#no one will thank me 
App::Fatpacker. Note must only depend on pure perl modules. 
Ah that's awesome news. I will definitely be installing it soon. I'm really impressed with the framework. It seems like it can be very powerful. I've been a big Dancer fan since its release, but this seems to be even better. I am excited start building with it. I really like the ability to dynamically add routes and the smart return types. The dynamic routes feature is significant too because it allows one to easily define routes for static pages without having to do some sort of fallback route to catch them. Just one loop and all your static pages are complete. Nice work.
$data-&gt;{'item'} holds the arrayref. @{$data-&gt;{'item'}} *IS* the arrayref but dereferenced (e.g. the array itself). So your code should be: foreach (@{$data-&gt;{'item'}}) { print $_-&gt;{'subitem1'}.' '.$-&gt;{'subitem2'}.' '.$_-&gt;{'subitme3'}."\n"; # BTW, 'subitme3' is misspelled in your example. }
The posts made already should be sufficient to parse what you've got. However, as a bit of extra advice, you can use the 'ref' function to figure out what an item in your structure is at runtime. For example, ref($data-&gt;{item}) will return ARRAY since $data-&gt;{item} contains an arrayref. From there, it's not too hard to write a function that dumps all the data in the structure: #!/usr/bin/perl use strict; use warnings; our $data = { item =&gt; [ { subitem1 =&gt; 'value1', subitem2 =&gt; 'value2', subitem3 =&gt; 'value3' }, { 'subitem1' =&gt; 'value4', 'subitem2' =&gt; 'value5', 'subitem3' =&gt; 'value6' } ] }; sub mydumper($;$); sub mydumper($;$) { my ($item, $path) = @_; $path = '' if ! defined $path; if (ref($item) eq 'ARRAY') { for (my $i=0; $i&lt;@$item; ++$i) { mydumper($item-&gt;[$i], $path . "[$i]"); } } elsif (ref($item) eq 'HASH') { for my $k (sort keys %$item) { mydumper($item-&gt;{$k}, $path . "{$k}"); } } elsif (ref($item) eq '') { print "$path = $item\n"; } else { die "Can't handle unknown ref type: " . ref($item); } } mydumper($data, '$data-&gt;'); When run, this outputs: $data-&gt;{item}[0]{subitem1} = value1 $data-&gt;{item}[0]{subitem2} = value2 $data-&gt;{item}[0]{subitem3} = value3 $data-&gt;{item}[1]{subitem1} = value4 $data-&gt;{item}[1]{subitem2} = value5 $data-&gt;{item}[1]{subitem3} = value6 Keep in mind that this was just a quick and dirty example. It assumes you've only got arrayrefs, hashrefs, and plain (i.e. not a reference) scalars in your structure. It also won't show you parts of the structure that exist but don't contain any scalars. But depending on what you're doing, you might find this to be a useful supplement to what's already been posted. Edit: Fixed code indentation
It looks like you're already using Data::Dumper which is great. You can also use it to examine portions of your data structure by calling Dumper($data-&gt;{item}). This lets you see what happens level-by-level.
When dealing with complex data structures, I find the perl debugger is a good way to play around and see how things should be referenced. Example session: [em@jethro Downloads]$ perl -d -e "print 'heh';" Loading DB routines from perl5db.pl version 1.33 Editor support available. Enter h or `h h' for help, or `man perldebug' for more help. main::(-e:1): print 'heh'; DB&lt;1&gt; $VAR1 = {'item' =&gt; [{'subitem1' =&gt; 'value1', 'subitem2' =&gt; 'value2', 'subitme3' =&gt; 'value3'}, {'subitem1' =&gt; 'value4', 'subitem2' =&gt; 'value5', 'subitme3' =&gt; 'value6'}]}; DB&lt;2&gt; x $VAR1 0 HASH(0x8c30a80) 'item' =&gt; ARRAY(0x8c30a40) 0 HASH(0x8975488) 'subitem1' =&gt; 'value1' 'subitem2' =&gt; 'value2' 'subitme3' =&gt; 'value3' 1 HASH(0x8c309f0) 'subitem1' =&gt; 'value4' 'subitem2' =&gt; 'value5' 'subitme3' =&gt; 'value6' DB&lt;3&gt; x $VAR1-&gt;{item} 0 ARRAY(0x8c30a40) 0 HASH(0x8975488) 'subitem1' =&gt; 'value1' 'subitem2' =&gt; 'value2' 'subitme3' =&gt; 'value3' 1 HASH(0x8c309f0) 'subitem1' =&gt; 'value4' 'subitem2' =&gt; 'value5' 'subitme3' =&gt; 'value6' DB&lt;4&gt; x $VAR1-&gt;{itgem}-&gt;[0] 0 undef DB&lt;5&gt; x $VAR1-&gt;{item}-&gt;[0] 0 HASH(0x8975488) 'subitem1' =&gt; 'value1' 'subitem2' =&gt; 'value2' 'subitme3' =&gt; 'value3' DB&lt;6&gt; x $VAR1-&gt;{item}-&gt;[0]-&gt;{subitem1} 0 'value1' DB&lt;7&gt; 
Thanks for excellent advice. One quick question &gt; First rule of refactoring legacy code is to write the missing tests. Can you recommend a good unit testing library?
Test::Simple is good if you don't know how to write tests yet. Test::More is good after you learn how to write tests.
Learn how to use Moose well, including roles and lazy builders. This has made a massive difference to me (but only useful if you're a fan of OO of course). On package management - a lot of CPAN modules are in the Debian/Ubuntu repos. You can also easily roll your own with dh_makeperl
&gt; Learn how to use Moose well, including roles and lazy builders. This is a good idea, but probably not a realistic first step when refactoring terrible old code.
1. Buy Perl Best Practices. 2. Read Perl Best Practices. 3. Add "use warnings;" and "use strict;" to the top of everything you touch. 4. Watch *Dexter* for ideas on what to do with your predecessors. Edit: Also, beware of code that is "accidentally correct", e.g.: if ($a_string == "lightsout") { # This'll teach 'em! unlink "/etc/passwd"; } Because the comparison above uses "==" (numeric equals) instead of "eq", the condition will never be true. Fixing the bug in the comparison may cause you to encounter an even worse bug.
OK, some more things to look out for: * [Why you should never do a ground-up rewrite of an old system](http://www.joelonsoftware.com/articles/fog0000000069.html) * [How to go about it when you decide to do it anyway](http://onstartups.com/tabid/3339/bid/97052/Screw-You-Joel-Spolsky-We-re-Rewriting-It-From-Scratch.aspx) * This is in the second link above but it's worth reinforcing. Legacy applications often follow the [Big Ball of Mud](http://www.laputan.org/mud/) anti-pattern and there is a temptation to try and rewrite the whole application at once rather than try and untangle it. This is faster, but the guaranteed failure (for the reasons in the articles above) makes that moot. What does work is to pull bits off of the ball of mud one by one and turn them into [atomic (PDF)](http://www.jucs.org/jucs_11_5/on_atomicity_and_software/Kienzle_J.pdf) (testable) services. Rinse and repeat until there is no mud left and you have a nice service oriented architecture (SOA) in place. Now just some further random thoughts based on my experience with legacy Perl: * If the system isn't in version control, that is step 1 * If you don't have a dev/test/stage environment that is identical to the deployment environment, that is step 2 (If you are Linux based, look at [puppet](https://puppetlabs.com/puppet/what-is-puppet/) and [vagrant](http://www.vagrantup.com/about.html)). Watch [Apollo 13](http://www.thinkbrownstone.com/blog/2011/10/26/divergent-thinking-vs-convergent-thinking/) again if you or your management don't think this is important. * Add logging to every sub in every program and module in the application (performance allowing). If it isn't in the logs, it likely isn't being used and can be removed. There's not much more frustrating than spending time refactoring code that is never used. Start to get proud of your 'lines of code deleted' metric. CPAN modules you should consider making use of: Testing and profiling * [Test::More](https://metacpan.org/module/Test::More) * [Test::Exception](https://metacpan.org/module/Test::Exception) * [Test::MockObject](https://metacpan.org/module/Test::MockObject) * [Devel::Cover](https://metacpan.org/module/Devel::Cover) * [Devel::NYTProf](https://metacpan.org/module/Devel::NYTProf) Logging * [Log::Log4perl](https://metacpan.org/module/Log::Log4perl) * [Log::Dispatch](https://metacpan.org/module/Log::Dispatch) Various ([use Modern::Perl](https://metacpan.org/module/Modern::Perl) gives you some of these) * [autodie](https://metacpan.org/module/autodie) - die automatically when built-ins fail * [Try::Tiny](https://metacpan.org/module/Try::Tiny) - exception handling * [Template](https://metacpan.org/release/Template-Toolkit) - The [Template Toolkit](http://template-toolkit.org/) * [List::Util](https://metacpan.org/module/List::Util) and [List::MoreUtils](https://metacpan.org/module/List::MoreUtils) - list munging * [DateTime](https://metacpan.org/module/DateTime) - **never roll your own date code** * [Data::Dumper](https://metacpan.org/module/Data::Dumper)/[Data::Printer](https://metacpan.org/module/Data::Printer) - see what's in your data structures * [File::Temp](https://metacpan.org/module/File::Temp) - **never create your own temporary files/directories** * [Params::Check::Faster](https://metacpan.org/module/Params::Check::Faster) - subroutine argument checking * [Regexp::Common](https://metacpan.org/module/Regexp::Common) - common regular expressions where someone else has thought of and tested all the edge cases Finally, for OO, I recommend learning and using [Moose](http://www.slideshare.net/davorg/introduction-to-oo-perl-with-moose) and/or [Moo](http://www.youtube.com/watch?v=MzTWTLaUZrg), but as noted elsewhere, this is more something to look at further down the road. Good luck! 
Try hashing it with SHA
If $a_string numerically evaluates to 0, that will *always* be true. Even if it's just another random string.
Re dependencies: Try creating a "Bundle" module, in the cpan shell.
If that legacy code is monolithic (e.g., one or a series of big .pl files), the first order of business would be to start splitting it into proper .pm modules, without adding any new features. Just carefully abstract out certain code into modules. If the code is not yet OO, but procedural (as legacy code often is), take a serious look at first factoring into modules (keeping it procedural) for the sake of moving incrementally. Do the smallest thing that could work (i.e., move code into modules) rather than introducing OO (which is redesign and could be your phase 2). Once it's all into modules, writing tests becomes possible, as you really can't test a big hunk of monolithic code. As for the bug you mentioned, that is the most preventable of bugs with use strict / use warnings, as others have noted. Using an uninitialized variable triggers a warning, and you can treat all warnings as flaws as far as I'm concerned.
Woah, woah, *3* spaces! Are you nuts? How can you even read code without 4 spaces per indent?
Well the streaming FTP part is simple: curl ftp://ftp-mouse.sanger.ac.uk/current_snps/mgp.v3.snps.rsIDdbSNPv137.vcf.gz | gunzip - | perl ... But for the rest you probably need to ask an expert in Bioperl or VCFtools.
`$ echo "Try hashing it with SHA" &gt; /tmp/thiws.txt; openssl dgst -sha -hex -c /tmp/thiws.txt` `SHA(/tmp/thiws.txt)= 85:38:ae:3b:6c:81:6d:13:37:c1:ba:9d:79:4c:d4:93:74:e1:5f:ac` `$ ` 
2 spaces, brah. 2. I like Ruby, too. 
Cheers mate.
No offence taken. I'm not sure why I even use Data::Dumper any more. Probably 15 years of muscle memory. I'd love to hear more about your successes turning around legacy code with Moose. I've tended to introduce it a bit later in the process, after I've got environments sorted out, and particularly after getting past the point where the perl version and module dependencies are under my control rather than those of sysadmins. 
Just sent this email to them. If it isn't to much work I want to write the code for a Catalyst Benchmark. Help and proofreading would be highly appreciated. Hello, I just saw your benchmark blog and would like to have Perl Frameworks included. How can I help? cheers
I just like catalyst, and I don't find it's that much work to set up. Though I am planning on splitting my app in two, backend and frontend, so I was thinking of dancer or web::simple for the frontend, but I might give kelp a try. But I might also use catalyst. I guess I'll toss a coin lol.
plack app for starman: https://github.com/pfig/FrameworkBenchmarks/pull/4/files
My favorite part of that benchmark suite is the use of random numbers to select database records. Who needs repeatability in the empirical process?
It's Rude or rude, never RUDE. This is /perl you know...
I'm so sorry. You asked for a guide, and all you got was names of modules. There's an excellent blog post about App::FatPacker (and its associated script, fatpack) here though: http://www.perladvent.org/2012/2012-12-14.html
Perhaps I'm lost, but why post here? 
Well, you could make a temporary RUDE with [aliased](https://metacpan.org/module/aliased). :)
Camomile tea?
&gt; By default all text files are searched, not just files with types that ack recognizes. Kudos for finally removing that huge misfeature. The "all" and "no really, I mean all" options were a clear indicator that the default was wrong. EDIT: as for the website change, perhaps you could meditate upon [this](http://perl.plover.com/yak/12views/samples/notes.html#sl-39).
I would follow @perlbuzz on Twitter if I didn't curate it myself.
&gt; AFAICT most of the software out there for handling this sort of stuff is written in ruby (vagrant, chef, FPM) with lots of support for rpm, deb, python &amp; php, but very little support for perl (read: cpan support!). dh-make-perl does a very good job bridging the gap between cpan and .deb. If that is your only serious weakness, you might consider going the deb-based management route and use dh-make-perl to distribute the cpan modules you're missing.
I know this is the perl subreddit, but when it comes to search I like [The Silver Searcher](https://github.com/ggreer/the_silver_searcher) **Edit** I'm not deleting this egg on my face so that you can downvote it! I thought I was helping to promote filtering commands. This is nothing short of being the pooper at a party.
Thanks for all the hard work, Andy and Rob. I was excited about this when you guys gave the YAPC lightning talk last year.
ack is amazing. when i found it my life has changed :)
That's great. It's one of the many non-ack tools on the ["More Tools" page on beyondgrep.com](http://beyondgrep.com/more-tools/). I don't care what you use, so long as it makes you happy and productive.
 \&gt;_&lt; are you Andy or Rob?
No, it does not run on anything that runs Perl. In this RHEL5 machine at work, I'm stuck with ack 1.96 because 2.0 wants a newer version of a module.
I think it should be used more often in function calls wherever two parameters are related, like: push @array =&gt; 'foo';
I suppose it would have been nice to introduce labels. outer_loop: for my $i (0 .. $#array) { for my $j (0 .. $#{$array[$i]}) { next outer_loop if $i == $j; ...; } }
Your Perl is at least 5.8.8, yes? We're on it: https://github.com/petdance/ack2/issues/225
Ha sorry, I'm a tool and hope I learned my lesson. 
Yikes. I'm a fan of the fat comma but that one does not read well to me.
:-) Thanks.
I haven't used it myself but Shipwright is one to look at. https://metacpan.org/module/Shipwright
Seems like the arrow should go the other direction in that case.
Thank you all for the help. I received a great answer when I asked on stackoverflow &gt;my $fails = 0; while (!($MySocket=new IO::Socket::INET-&gt;new( PeerPort=&gt;$port,Proto=&gt;'tcp',PeerAddr=&gt;$IP))) { die ($E) if ++$fails == 3; sleep(10); }
Would they have this tool for rpm or would you use deb-&gt;rpm?
Meh, I always quote barewords. It's just my style I guess. One day I'll run Perl::Critic through my code and I'll see what that has to say about my idiosyncrasies
I respectfully disagree - I like being able to easily search JUST source files without getting results from readmes, various assets, etc. I guess I'll just keep -k in my .ackrc
For me, the fat arrow reads as the english *to* or *into*. The sentence *push these array values into string foo* doesn't make much sense. In contrast, bless $self =&gt; $class; # bless myself into the class copy $source =&gt; $target; # copy the source to the target kill 9 =&gt; @pids; # send signal № 9 to these PIDs tie $var =&gt; $class; # tie this variable to the class # open my $handle =&gt; $file; # would read nice, but 3-arg open is a must read naturally. I'd say that `=&gt;` can make code much more readable, but only when it points in the right direction. This is not the case for many builtins (e.g. `index`, `pack`, `printf`, `shift`, `push`) It could also be argued that “`=&gt;`” is a more visible distinction than “`,`” and could thus separate parts of different meaning, e.g. # The AST of a Lisp-like language [LAMBDA =&gt; [qw/a b/] =&gt; [APPLY =&gt; [VAR =&gt; '·'] =&gt; [CONST =&gt; 2], [APPLY =&gt; [VAR =&gt; '+'] =&gt; [VAR =&gt; 'a'], [VAR =&gt; 'b']]]] and something positive could be said about the method argument unpacking syntax my($self =&gt; @other_args) = @_;
There is cpan2rpm which does this for rpm. I hope to help the fpm maintainer add support for perl in his next release: https://github.com/jordansissel/fpm/issues/74#issuecomment-16699349 which would give us cpan2(rpm|deb|tarball|etc)
PBP is pretty outdated now. e.g. Class::Std? ugh! _Modern Perl_ and _Essential Perl_ are much better.
This looks like it's been fixed in the [Github repo](https://github.com/petdance/ack2), but hasn't made it into the CPAN distribution yet.
Probably Monday morning I'll put out 2.04.
I don't really know anything about AI, however, a cursory search turned up a [thread on PerlMonks](http://www.perlmonks.org/?node_id=123590) about the subject. There are some useful comments, however, the most useful is probably the link to the perl AI mailing list: perl-ai@perl.org Good luck.
Thanks!
Previously used both debian packaging and capistrano with perl, both worked well. You might want to look at http://rexify.org/ which provides a good looking alternative to chef, etc
You might also want to look at http://perlchef.com/ if you like chef - there is a fair ammount of work gone into chef support for perl within the perl community including several TPF grants http://news.perlfoundation.org/2012/08/cooking-perl-with-chef---grant-4.html
Edit: The workshop will be held via IRC (not email). Edit: Carl has now blogged [about the workshop](http://strangelyconsistent.org/blog/the-masakism-workshop). [Carl Mäsak](http://strangelyconsistent.org/about) teaches Perl as part of [his $dayjob](http://edument.se/english/consultants/name/carl-masak). He is hosting this free [4 hour online coding workshop](https://gist.github.com/masak/5431185) (via IRC) on Wednesday, May 1st 2013. The start is in the morning in the US, at night time in Asia. Topics will cover functional programming, object orientation, grammars, operators, DSLs, various problem domains, syntax, and semantics. The common theme, however, is principles of coding that promote simplicity, readability, and elegance.
[Test::Class](https://metacpan.org/module/Test::Class) is really good for organizing tests, a great tutorial for which can be found [here](http://www.modernperlbooks.com/mt/2009/03/organizing-test-suites-with-testclass.html) A problem with Test::Class is that you can't make Moosey Test::Class tests, /u/OvidPerl has put together [Test::Class::Moose](https://metacpan.org/module/Test::Class::Moose) which, despite being in its infancy, is really rather good. As is warned in it's documentation it is alpha currently, so possibly not something to dive into for the work you are describing, but I'd keep an eye on it for future use
You should try posting this in r/programming too. :) And thanks for the publicity work, i would've missed this without you. :D
/r/programming 
I just thought this was such an interesting subroutine. I modified it a little so that it returns an array of lists. # from http://www.perlmonks.org/?node_id=87538 # Description: Converts a list of numbers to a string of ranges: (1,2,3,5,8,9,10,11) to "1-3,5,8-11". # input: an array of numbers # output: an array of lists (or a list of lists) sub num2range { local $_ = join ',' =&gt; sort { $a &lt;=&gt; $b } @_; s/(?&lt;!\d)(\d+)(?:,((??{$++1})))+(?!\d)/$1-$+/g; # string to array of lists my @arr; for(split /,/,$_){ my($first,$last)=split /\-/,$_; $last=$first if(!$last); push(@arr,[$first..$last]); } return @arr if(wantarray); return \@arr; # returns a list if an array is not requested } 
Would actually like something that goes the other way. I've got something, but it's not perfect. I can post when I get to work tomorrow. Using for parsing Cisco configs.
Interesting as a thought exercise but I would punch anyone I found putting something like this in my codebase. Perl has enough trouble with the "write only" crowd of perl haters. These things need to stop or at least w/out explicitly calling it out as an exercise never to actually see the light of production code v
At least it's wrapped up in a subroutine where it's in its own small, contained bit of evil.
Taking the simplest perl5 approach, I think your whole expression will match zero, one, or two "=" chars. If zero, $1 won't be set. If one or two, $1 will contain them. Reading left to right, the =? either matches or doesn't. Outside, ()? either matches or doesn't.
Aye, the difference between * and + is a ?
An odd way of phrasing it, but yes. '?' is 'zero or one'
From the comments on perlmonks - this is actually over a decade old when that kind of thing was very popular. What frightens the hell out of me is the 2011 post - "I've been using this for awhile". Crazy town. This is neither legible nor fast. Why is anyone actually using it? Sigh.
Alternate ways to achieve something similar that *might* be easier to understand: ={0,2} (={1,2})?
It's awkward a project is being crowd sourced to serve the interests of very large companies. I've never needed to run my own repository, but if i did that video didn't make it all that clean how Pinto would be an improvement over just a CPAN mirror. Nor, do I understand how it would be different over merely specifying the exact version to install w/ `local::lib`. Using `local::lib`, set `PERL_MB_OPT` and `PERL_MM_OPT` and `PERL5LIB`, per [the docs](https://metacpan.org/module/local::lib) to something relative to the script (or w/ the script name). In `node` we use `node_modules` for NPM. Then use `cpanm` or whatever CPAN-front end variant you want to install the specific versions you want to that location. Lastly, set up the environment to pull from it, `use local::lib "./perl_modules"` so your repo has priority. Or, even better -- imho -- simply distribute with [App::FatPacker](https://metacpan.org/module/App::FatPacker) like cpanm.pl itself. All of that aside, it's nice to see something Perl that gets crowd sourced. Even if it isn't all that interesting for me. Next, a replacement for POE!
I use the Perl binary from SL4A on Android 4.x on my Touchpad, but mostly just for standalone hacking on things like codegolf challenges; not scripting the OS, so the APIs haven't been an issue. No real issues for simple stuff.
&gt; It's awkward a project is being crowd sourced to serve the interests of very large companies. I don't understand "awkward" in that sentence. Can you explain more?
This will cause the default binmode to be `:encoding(utf8)` when you open a file. Note that that's the "loose" UTF-8 mode -- you probably want to use `:encoding(UTF-8)` which is the strict UTF-8 mode. I should also mention that perl 5.8.8 probably has bugs that could bite you... consider upgrading.
Merging UTF-8 and non-UTF-8 data in Perl (and no doubt most if not all other languages) is a nightmare. I think what you need to do is make sure you re-encode the ASCII data as UTF-8. Have a look at the [utf8](http://search.cpan.org/~rjbs/perl-5.16.3/lib/utf8.pm) documentation for a few tips. If my understanding is correct (quite possibly not) handling UTF-8 strings can also be problematic if the source code of your Perl script is in ASCII, so make sure your environment's right and the script's written in UTF-8.
If you haven't yet, be sure to read [perluniintro](http://perldoc.perl.org/perluniintro.html) and [perlunicode](http://perldoc.perl.org/perlunicode.html).
Wow. I've never done any UTF8 before, so this is going to be a huge learning curve, and none of my Perl scripts are actually saved in UTF8, they are all ascii. 
Add "our @a;" after the "use strict;" line ? 
Just declare `my @a;` in a BEGIN block after `use strict;` But really, you just exceeded the complexity that should be using `-lap` -- I recommend rewriting the loop yourself. In particular, it might help you re-think why are you using `-a`? (hint: you're not using autosplit)
&gt; However every character in SS1 has 2 bytes, the first byte being null for normal ASCII characters. That sounds like it's UTF-16, not UTF-8. UTF-8 is identical with ASCII in the ASCII range, and encodes Unicode code points with more bytes after 127. Actually, UTF-16 [isn't always two bytes](http://en.wikipedia.org/wiki/Comparison_of_Unicode_encodings#Eight-bit_environments), either, [if you use certain characters](http://en.wikipedia.org/wiki/Plane_(\Unicode\)#Supplementary_Multilingual_Plane).
Don't worry about it. For one thing, ASCII is the first 127 characters of UTF-8, so a script "saved in ascii" is already valid UTF-8. The "use utf8;" declaration tells Perl that your script itself may contain characters above 127, but that doesn't affect how it processes data. The way to think about Unicode processing in Perl is that you "decode" incoming UTF-8 data to Perl's internal string format, and "encode" outgoing data to UTF-8 as you save or print it. Since ASCII is a subset of UTF-8, you can safely set your default binmode to UTF-8 if you are reading files in those encodings. mikedoherty's suggestions should see you right.
Chicken!!
Alternately, just refer explicitly to the `@a` global in the `main` package, ie: push @::a, $. if /OK/; END { print "line numbers: ", join ',', @::a; } 
Do the script sources contain non-Ascii (AKA "accented") characters? If no, if they're Ascii only, then there is no difference between Ascii or UTF-8, or ISO-Latin-1, or any other single byte ISO-8859 encoding. Personally, I do think that using any accented characters, as is, in a Perl script is a terrible idea, and easily avoided.
"`my @a`" in a BEGIN block: just no. I's still a block. But yeah, why use strict if you want to use the -p shortcut, or vice versa? The combination doesn't make sense. It's more sensible to put in an explicit `while(&lt;&gt;){}` loop.
There are 97 contributors to the project, I'd be curious to know how many of those contributors will benefit from this work, except in the abstract sense that *we all benefit from open-source*. That said, I don't entirely understand what it is he is creating, or how it could help me.
Why are you doing this on RedHat 5.5? It sounds like you have used Windows (Excel) to export spreadsheet tabs to TAB delimited files, copied them to an old RedHat box with an ancient Perl to do the munging. You'd be better off installing one of the Windows flavored Perls (Citrus Perl, Strawberry Perl, etc) on your Windows machine so that you have a **much** more recent Perl (5.14 or 5.16). You have a few other things to consider. Your 'ascii' file is probably *not* an 'ascii' file. It's more likely some other 8-bit encoding like latin-1, iso-8859, cp1250, etc. whatever the default 8bit codepage Excel used when you exported it. Does it have any bytes greater than 127 (0x7F)? If it does then you'll have to figure out what encoding it actually uses. Your 'unicode' file with 2 bytes per character is UTF-16, either BigEndian or LittleEndian with or without a ByteOrderMarker (BOM). I totally forget which one Windows uses. You may or may not ever be able to actually see the characters in a terminal on RedHat 5.5. First you'll have to use a terminal that supports UTF8, second you'll have to have the appropriate fonts installed and configured. The encodings and actual terminal/fonts on old RedHat is probably the hardest part you'll have to deal with. The actual Perl part is pretty easy. Here is `foo.csv`, a simple one row tab delimited file in utf8 encoding: $ cat foo.csv a b ¶ ° $ xxd foo.csv 0000000: 6109 6209 c2b6 09c2 b00a a.b....... Here it is in latin-1 encoding (a common 8-bit encoding) $ xxd foo.csv.l1 0000000: 6109 6209 b609 b00a a.b..... Here it is in UTF16-BE with no BOM $ xxd foo.csv.be 0000000: 0061 0009 0062 0009 00b6 0009 00b0 000a .a...b.......... Here is simple Perl that reads the latin-1 and the utf16-be and appends the two lines together and outputs utf8. #!/usr/bin/perl use strict; use warnings; binmode STDOUT, ':utf8'; open my $latin, '&lt;:encoding(latin-1)', 'foo.csv.l1' or die "$!"; open my $utf16, '&lt;:encoding(UTF16BE)', 'foo.csv.be' or die "$!"; my $row1 = &lt;$latin&gt;; chomp $row1; my $row2 = &lt;$utf16&gt;; chomp $row2; my @cols1 = split "\t", $row1; my @cols2 = split "\t", $row2; print join("\t", @cols1, @cols2), $/; and the output: $ perl foo.pl a b ¶ ° a b ¶ ° This is pretty horrid Perl, but the idea is that once you know your encodings, everything is simple. You open your files (using the proper encoding), read them and munge them as you would any other data. Choose the encoding you want for your output and save/print the data just like you would if you weren't worrying about encodings. If your RedHat has `iconv` installed, it may be easier to convert both files to UTF-8 first, then process them with Perl (setting utf8 encoding on your in/out filehandles) and then convert the final utf8 output to utf16 (assuming you're going to send them back to the Windows box). Just from my many trials and tribulations of munging files in a myriad of encodings, it's usually easier to convert them all to utf8 first and work with those instead. I made those different encoding files with `iconv`: $ iconv -f utf8 -t latin1 &lt;foo.csv &gt;foo.csv.l1 $ iconv -f utf8 -t utf16be &lt;foo.csv &gt;foo.csv.be $ iconv -f utf8 -t ascii &lt;foo.csv &gt;foo.csv.ascii iconv: illegal input sequence at position 4 Note that since the ° and ¶ are 8-bit (in latin-1 encoding) they are not **ascii**. So check your 'ascii' file to make sure it's really ascii, or convert it to utf8 as well.
If you want to understand this better, you can read [Chapter 9 of my Perl book here](http://ofps.oreilly.com/titles/9781118013847/files_and_directories.html). That's the "files and directories" chapter and it has a reasonably decent introduction to Unicode. It should tell you most of what you need to know (note that the chapter is a rough draft and there are changes in the final text, but it should be fine for your needs).
Sorry, I meant our, but my fingers didn't cooperate.
Curiously. Why do you need to declare for a one liner? I only really use them for quick and dirty tasks and leave all formality at the door. Not saying there isn't a reason. Just curious what yours is.
1. Install [perlbrew](http://perlbrew.pl/) 1. Install and switch to the latest Perl via perlbrew: `perlbrew install perl-5.16.3 &amp;&amp; perlbrew switch perl-5.16.3` 1. Rejoice that you have the latest and best Unicode support in Perl (without mucking with the system-installed Perl) 1. Read this documentation on `perlunicode`: http://search.cpan.org/~rjbs/perl-5.16.3/pod/perlunicode.pod
Formatting is your friend: my $fails = 0; while ( !( $MySocket = new IO::Socket::INET-&gt;new( PeerPort =&gt; $port, Proto =&gt; 'tcp', PeerAddr =&gt; $IP ) ) ) { die($E) if ++$fails == 3; sleep(10); } 
Sounds good, I'll have finished travelling soon, might have to get involved, if I have time. Gotta find a job, house and all that first!
What am I looking at?
Every time you push with git it updates and reports your test coverage
日本語のsubredditはないのかな？ 残念だけどほとんどの人は日本語が読めないからここで日本語のリンクを共有してもdownvoteされてしまうと思うよ？
That's a good question. I've never seen non-English content in other subs. Is Reddit only for English speakers? Are there other subs specifically for non-English discussion?
Google translate does a decent job if you can grok its attempts to translate technical blog-posty type of things. https://metacpan.org/module/Devel::Cover::Report::Coveralls is a new module that came out of the Perl QA Hackathon 2013 Satellite Tokyo http://memo.fushihara.net/post/48086316824/coveralls-perl-project that lets you use the http://coveralls.io service with Perl projects on GitHub + TravisCL so you can get a pretty Web 2.0 dohickey that tracks your test coverage to go with your TravisCL dohickey that tracks your test results. I'm all for the occasional non-english post, this subredit is not so active that it matters and for the most part the code snippets speak for themselves.
Sorry about the link not responding. I have daily followed these ilbot driven logs of Freenode IRC channels for years with only a couple hiccups for a few hours each in that time. But now they've been down for over a day. "They" are working on it.
I was hoping for something more than the static+speed vs dynamic+slow argument there. This is an unfortunately transparent advertorial for Kelp, which while it looks like a really nice little framework, is not competing with Go, but with Dancer. What the author needs to do is show reasons why this is the best tool for Perl web development, and why Perl is still a good choice vs other dynamic languages. 
Regex that will test for primes: /^(II+)\1+$/ Note that it actually tests for composites, so a non match indicates prime.
References are pretty important in perl, most of the time if you're passing a hash or an array as a parameter to a sub you're making a mistake, unless you understand about [list context](http://perl5maven.com/scalar-and-list-context-in-perl) and how arrays and hashes flatten in list context.
Nobody's mentioned this yet: **exists** might be appropriate in the sub without examining the value itself. die unless exists $map{$key}; return $map{$key}; The distinction is that when you use **exists**, "The element is not autovivified if it doesn't exist." 
Here, learn some more: http://modernperlbooks.com/books/modern_perl/ ;) You're using a lot of "old style" perl. 
Mostly because it "grew" from something smaller. Plus, what I'm doing is pretty much what the -lapoptions are designed to do -- a a shortcut, if you will. I expect that, by the time I'm done, I'll just add the 3-5 lines to explicitly implement the loop for clarity. 
instead of requiring above a specific version (and a very recent one at that, say was in 5.10), you can use the feature import: use feature qw/say/;
Nice bedtime story.
What install method that is already a standard part of Perl 5.8.8 do you recommend. I seem to have problems with ~~ppm~~ cpan. 
cpan
From my own experience, [Excel::Writer::XLSX](https://metacpan.org/release/Excel-Writer-XLSX) seems to be the best developed option for writing XLSX files. Not sure about parsing. I find that ActiveState's installer (ppm) is best used for modules with xs dependencies (links to C libraries). Since compiling C code on Windows takes some setup, it's nice that ActiveState provides precompiled versions. But pure Perl modules don't really need that. You can try "perl -MCPAN -e shell", go through the configuration, and then type "install Excel::Writer::XLSX" to install the module above. If nothing else works, you can always download the tarball and copy the contents of 'lib/' into an `@INC` directory.
There's literally no reason not to. I use DBIx::Class in my deployed products and it's fantastic. It uses Moose (EDIT: Not true, see below @ jimbobhickville), meaning that you take a startup penalty, but it's not that large, so if you have a long running product (like a Catalyst-based web app, say), it's nothing. You can do some incredibly useful things, like built-in incrementally filtering a resultset based on criteria, which only ever actually talks to the database at the point where you need the data, and makes everything generally much cleaner. For example, in my app, I have a shop that sells gift cards: $shop is a DBIx::Class object that has_many cards. &gt;my $query = $shop-&gt;cards; Here we filter by owner, if it's specified. No queries are actually performed as of yet. &gt;$query = $query-&gt;search({ current_owner_email =&gt; $c-&gt;req-&gt;param('query') }) if ($c-&gt;req-&gt;param('type") eq 'owner'); Perform other filtering that you want, in any way; nothing will be actually be queried at this point, generally. &gt;... Still, let's get the total listing of cards so we can paginate properly: Makes a SQL COUNT call: &gt;my $total_cards = $query-&gt;count; Start on the first page, or the specified one. &gt;my $page = $c-&gt;req-&gt;param('page') || 1; &gt;my $max_per_page = 20; &gt;my $total_pages = ceil($total_cards / $max_per_page); Perform the select statement, only getting the data we need, filtered. &gt;my @cards = $query-&gt;search({}, { rows =&gt; $max_per_page, page =&gt; $page})-&gt;all; Now you get back an array of at most 20 objects representing your schema of a Card, on the specified page. Also, the nice thing about it is, that you can get down to the level of abstraction that you want; for example, if you don't want to have full object inflation, because you're working with a lot of data, quickly, you don't have to have it, you can simply query data by column number. 
Does DBIC use Moose now? The last time I looked, it didn't--but if you use an extension (like the schema builder?), you might see that the resulting schema classes it builds use Moose.
The only reason to avoid any ORM is when you're doing speed-related things. It's just a simple fact that doing things simpler is usually faster. A raw `$dbh-&gt;do('INSERT INTO..');` is going to be faster than `$schema-&gt;resultsource(..)-&gt;create({..});`. When you're doing 1 or 100 iterations, it's usually worth the sanity when coding to use an ORM. When you've got 2,000,000 iterations, you just added 10 minutes to your code's runtime. 
DBIC now *supports* having your classes use Moose, but doesn't require it, and S::L doesn't generate classes that use it by default.
DBIx::Class doesn't use Moose, but it does have a nasty startup penalty due to its use of Class::C3 in older Perls. Newer perls don't have nearly as big a hit, due to using the builtin mro pragma, but there's still a hit with each class detecting whether to use mro or C3 and the corresponding logic. I don't know if they've fixed this in newer versions or not.
I don't understand what your example with mocha does, and I barely understand what "honing in on specific tests" means. Maybe you should try to ask a clearer question. From what I gather, you want to know how to run just part of your test suite? `prove t/feature/*.t` will run all the tests in the "feature" directory. `prove t/whatever.t` will run just that test file. As far as I know, there's no way to run less than a whole test script (a single subtest, for example).
Yes, that's what I was looking for. The Test::More docs say how to write tests, but they don't say how to run them with `prove`.
&gt;As far as I know, there's no way to run less than a whole test script (a single subtest, for example). I've used prove's '::' functionality for this: $ prove -l -v t/foo/bar.t :: my_desired_subset This isn't a general-purpose solution: `bar.t` has to be instrumented such that it groks `@ARGV` and does what you want. But it sure can be useful when you have a long or slow set of tests. See `perldoc prove`, search in-page for **Arguments**
Excel files are just rows of Comma Separated Variables, No? What more is needed than split and join? I deal with them that way all the time. What am I missing?
Is this just clever for the sake of being clever? What's wrong with this? my @matches; if (@matches = $log_string =~ m/^($ip)\s-\s (.*?)\s \[(.*?)\]\s "(.*?)"\s (\d+)\s (\d+)\s "(.*?)"\s "(.*?)"$/x) { my $deparsed = { }; my $c = 0; ... for (@field_list) { $deparsed-&gt;{ $_ } = $matches[++$c]; } return $deparsed; } 
Look at the Fennec module on cpan. It lets you write blocks of tests inside test files, you can tell it to only run specific blocks via name or line number.
You can use Fennec to break your tests into blocks and run specific blocks independantly.
Named capture groups can do it more clearly: if ($log_string =~ m/^(?&lt;ip&gt;$ip)\s-\s (?&lt;remote_user&gt;.*?)\s \[(?&lt;time&gt;.*?)\]\s "(?&lt;request&gt;.*?)"\s (?&lt;status&gt;\d+)\s (?&lt;bytes_send&gt;\d+)\s "(?&lt;referer&gt;.*?)"\s "(?&lt;user_agent&gt;.*?)"$/x) { return { %+ }; } Code is from memory, check "man perlre" to double-check it, but that's the drift of it. Edit: Will need perl 5.10.0 or later I think. But you should be using a version of perl from the past 5 years, right? Right? :)
Tell that to those still on CentOS 5 servers. Fortunately, there's perlbrew. 
Don't do this. Don't do this. Don't do this. Don't do this. Don't do this. Please. 
do not want
sometimes i use similiar trick to call constructed methods: `map { $_ =&gt; $object-&gt;${\($_.'_count')} } qw(red green blue)`
&gt; Excel files are just rows of Comma Separated Variables, No? No, an XLS/XLSX file is a binary file with information for formatting, fonts, colors, shading, maybe even graphs, and multiple tabs. A file with comma separated values is a text file with no other formatting information. 
Among the many simpler and better alternatives (still using older-style match-number variables ) would be to assign all 8 at the same time : @deparsed{@field_list} = ($1, $2, $3, $4, $5, $6, $7, $8 );
[Why it's stupid to use a variable as a variable name](http://perl.plover.com/varvarname.html)
Still running 5.8.4 on over 2000 production servers. :(
Awesome, this is what I was looking for minus the memory watching part -- but I think I can manage to wrangle that in given this. Thanks! 
Either this or a batch queuing system.
It's easy to clean a pile of shit.
I agree, in principle, it is always possible to improve performance. in this case, the code operates on a 3-d domain using fourier transforms, sometimes the domain may be data dense, so sparse methods won't always be effective. timeliness of execution is not critical, but i just want things to chug along while i am focusing on other work. if this were mission critical or production code, i would spend more effort on improving the efficiency. 
I've had good luck with Spreadsheet::WriteExcel for this - used this on Linux with Perl 5.8. Haven't used it on Windows I'm afraid. Still worth a look though. http://search.cpan.org/perldoc?Spreadsheet%3A%3AWriteExcel
If I type 11 to 19, it's the same as 10... STDIN is only taking the first digit in these instances. If I do 20 it's as if I typed "2" but for some reason "9" is seen as "90"?
$count_to = &lt;STDIN&gt;; chomp $count_to; \# &lt;-- ok this fixed the issue with "9" c:\strawberry&gt;count.pl count_to is current_count is count to what #? 9 count_to is now 9 current_count is now 1 count is now 1 count is now 2 count is now 3 count is now 4 count is now 5 count is now 6 count is now 7 count is now 8 done count_to is now 9 current_count is now 9 c:\strawberry&gt; Still having issues with double-digit #s having only the first digit recognized.
no problem will fix that now
cool! that fixed it! I didn't know when to use &lt; or &gt; instead of lt or gt, or that there was really a difference.
thank you microwavecookietime, raiph! upvotes for all of you. I'm here to learn and learning has happened. :)
lol! good eye! that was my dyslexia jumping in and me typing too quickly. interesting to see that didn't have any effect... probably because /usr/bin/perl doesn't exist in Windows. :-)
Yeah, I don't think Windows pays it any mind at all. Of course, it's a unix thing and you don't even need it on unix if you execute the perl command yourself. Had you left it out, I wouldn't have said a word. But for some reason I noticed that.
Back? It would also be nice if it had a real changelog.
Why use Curl when there is the super awesome [LWP](https://metacpan.org/module/LWP)?
Actually, why not using the best of two worlds? :) http://blogs.perl.org/users/stas/2012/11/libcurl-as-lwp-backend-or-all-your-protocol-are-belong-to-us.html
Ah, that makes sense. Good job then. :)
Have a look at Mojolicious::Lite. It ships with a wonderfully complete testing suite that requires zero configuration. Quite nice, really. 
In conjunction with my Dancer app, or as a replacement for Dancer? I'm confused. (If "replacement", sorry -- that's not up to me in this case.)
My apologies, I did mean as a replacement. Devel::Cover is good for deep testing. It'll find logic branches that your tests don't cover and point them out to you.
You need to "See /root/.cpanm/build.log for details."
&gt; See /root/.cpanm/build.log for details. Post the contents of that file as well. That contains all the details and without them we can't tell what's what. cpanm is handy because it hides most of the installation noise so you don't have to see it, but when there are problems, as you've found here, you'll have to go look in the log files and do some detective work.
Done. Put pastebin link in original post. 
Done. Put pastebin link in original post. 
do you have build tools installed? The log you posted doesn't really give a good reason to be failing.
What's that? I normally don't install modules as we try to keep a vanilla installation, as we have one other (remote) machine at another office which sometimes runs the scripts I make. 
From the log you pasted: &gt; ! Installing Digest::Perl::MD5 failed. See /root/.cpanm/build.log for details. So it's failing installing Digest::Perl::MD5. Try installing that by itself, and assuming it fails, look at *that* log file and see what fails.
On the other side, the *critical leak* was there for 2 years... So, the meaning of the "Net::Curl is back" announcement is that it will be maintained again. By yours truly.
it depends on what OS you're running but basically you need gcc installed to compile PM's into their XS counterparts. If you're running debian its apt-get install build-tools, if you're running RHEL its yum install "Development Tools"
libcurl is a nice one-size-fit-all bundle. Here I'm just annotating the libcurl advantages over the bare LWP cited in the [LWP::Protocol::Net::Curl docs](https://metacpan.org/module/LWP::Protocol::Net::Curl): * support ftp/ftps/http/https/sftp/scp protocols out-of-box - for HTTPS, LWP requires LWP::Protocol::https with it's long dependency chain. Ditto for SFTP. FTPS/SCP have no LWP::Protocol::* implementations at all; * support SOCKS4/5 proxy out-of-box - LWP support for the SOCKS proxy is tricky, at best; * connection persistence and DNS cache - while LWP::ConnCache is a part of libwww-perl distribution, it is considered *experimental* and disabled by default; * lightning-fast HTTP compression - HTTP::Message handles that really well under LWP, but it requires the whole resource to be downloaded to be decoded in-RAM. libcurl supports streaming decoding.
It looks like your script is working okay but the input file has bad data in it (e.g. an extra tab on the Scottsdale line and presumably missing initial tabs for the CA lines). As a workaround, you could changing this: chomp; my @Fld = split('\t', $_); to this: chomp; s/^\t+/\t/; my @Fld = split('\t', $_); unshift @Fld, '' if $Fld[0] =~ /^[A-Z]{2}$/; Oh, and you'll also need to come up with a hack to fix the header line since it doesn't have fields for both the city and state. Maybe just skip that line in the input and output a hardcoded header containing the proper fields.
I started a project recently on RedHat and my first thing to do was install perlbrew and install the lastest Perl (5.16.3). Since you are using a Unix-like environment it super easy to setup newer versions of Perl with Perlbrew. I also made it so I could share the install with others using [Perlbrew root](http://gugod.org/2010/12/a-shared-perlbrew-root-for-multiple-users/).
Break it down to pieces. In my experience, installing a whole module tree with cpan can fail where, if you install smaller set of dependencies first, it may succeed. Sometimes it's all you need to do, weird but true - I suspect a memory problem, or cpan deleting temporary files prematurely. And if it fails because of a failed test, you can still force installation.
At least in the transcript, I didn't see anything about sabotaging Perl's OO documentation.
That would be a string. Notice the single quotes, that means '@' is not treated as a sigil. You are looking at a literal text string '@@WORKSPACE@@', also works liek this: "\@\@WORKSPACE\@\@"; I suspect it is part of some templating system. The program is probably building a template, and later something will come in and replace @@WORKSPACE@@ in a large string with a value.
It looks like during a product build, make goes in and replaces these @@VALUE@@ definitions with system specific strings, paths, etc.
The Class::C3 hit is a *very* old side-effect of the pure-perl 5.8 implementation. These days if you are on 5.8 and a compiler is detected then Class::C3::XS is installed, and on 5.10+ there is nothing even close to "detecting whether to use mro or C3". There is a startup penalty if you have many result classes (i.e. tables/sources in the schema), because we do not yet lazy-load stuff. However this has nothing to do with mro/@ISA checks, it has to do with loading many modules. If you do not believe me try `perl -MDateTime -e1` for size ;)
I'll have to find my old NYTProf output from when I was doing research on this, but I can say your points don't jive with what I saw. Yes, using Class::C3::XS on 5.8.8 was insanely slow (about 16s to compile all of our code), and that dropped to about 4s when moving to 5.14 thanks to the mro pragma. But of that remaining 4s, a healthy chunk was still related to Class::C3, even though it wasn't using it. I was honestly surprised by that, which is why it stuck with me. Maybe I misread something, who knows.
And Skynet is one step closer. Now seriously, this needs to become easily extensible now that there's people out there rolling out homemade 3d-printed drones
Very awesome! Thanks for sharing that. The flips are impressive :)
I just figured out that if I use: use strict; It will bork out in strawberry if my dyslexia kicks in. :-)
thanks!
Look at the tr operator.
In this article chromatic used: die "No test method test_$name\n" unless my $func = __PACKAGE__-&gt;can( 'test_' . $name ); $func-&gt;(); I know that declaring a variable inside an condition is bad practice and lead to bugs: my $var = 5 if condition; but here he declared the var in the condition side. is it OK? maybe because the code will die if the condition is not true, so $func will not be used, which make this code OK. your thoughts? 
Yes, your analysis is correct. The declaration and assignment are not conditional. The conditional depends on the *evaluated value of the assignment*. The assignment always happens first, and only then does the conditional test happen.
Another solution : my $from = join ("", 'a'..'z'); my $FROM = uc $from; my $to = join ("", reverse 'a'..'z'); my $TO = uc $to; my $s = 'Blergh, I'm afraid of evals'; eval "\$s =~ tr/${from}${FROM}/${to}${TO}/, 1" or die($@); print $s."\n";
Why use the hash as pointer on an array? Also, you don't need `map` to initialize it. And as you are using v5.10 at least (`say`), then the `//` operator can replace the ternary+exists. my %encrypt; @encrypt{@unencrypted} = @encrypted; say join ', ', map { $encrypt{uc $_} // $_ } split(//, $string); 
`tr` substitute a character to a character. It won't replace "Z" with "26". But the `s` operator could be used: my $pattern = '([' . join('', @unencrypted) . '])'; $string =~ s/$pattern/$encrypt{$1}/go;
This isn't encryption it's obfuscation. Big difference. Please don't think that any text treated in this way will be encrypted.
I'm sorry, I've just never learned the difference between the two.
You might also want to x-post that to [jobs.perl.org: The Perl Job site](http://jobs.perl.org/).
Linking to the HTML to be served raw?
Looks normal to me.
Does it look like this? http://awesomescreenshot.com/0d91a1s98d
That looks like metacpan!?
Do you perhaps have a browser addon or something that redirects cpansearch.perl.org to metacpan? Otherwise, maybe it is some mirror redirect going on.
Sounds as if it might be interesting, but as soon as I follow the link to [http://mojolicio.us/](http://mojolicio.us/) to find out, I'm hit by stupid blocks of (I assume) code with such low contrast that I have absolutely no way of understanding if it's going to be of any use to me. What kind of wanker thinks nearly black text on a black background works?
We're sorry to hear that you have trouble reading the site. I don't believe we have ever heard this concern before. In fact we are often complemented on the look of our site. In the meantime, you are welcome to read the documentation on other CPAN sites, for example here https://metacpan.org/module/Mojolicious::Guides starting with Mojolicious::Guides, which is the starting point for all of the documentation. The one page that isn't so available from those sites is that landing page, which is the project's readme file. This is visible on our GitHub landing page or at https://github.com/kraih/mojo/blob/master/README.md
Congrats! Can't wait to take it for a spin.
Are you talking about source comments? Are you visually impared? I have some relatives who would have a hard time as well but most people will have no issue.
Ah, exactly. I use the suggested metacpan /etc/hosts trick.
I also have minor readability issues with the Mojolicious site's code. It's really a combination of age and contrast. The low contrast themes are great when staring at an editor all day, but when embedded in a web page with a surrounding white background things get hard to read. Like I have my contrast down a bit to avoid the eye-burn of browsing "professional black on white" webpages, then a page with code styled in a low contrast theme becomes hard to read. It's a toss-up, turn down brightness so the white doesn't blind and the code is unreadable. Turn up the brightness enough to read the code and the white background is blinding. It's a hard balancing act when your eyes start to get old. A little more contrast in the code style and/or a less bright surrounding page around the code sections on the Mojolicious site would be nice.
Nothing wrong with my vision. [This is how it looks in my browser](http://www.web-brewer.co.uk/mojo-screenshot.jpeg)
[screenshot](http://www.web-brewer.co.uk/mojo-screenshot.jpeg) Almost (but not quite) as bad if I use Opera instead of Firefox.
Something strange then. [screenshot](http://www.web-brewer.co.uk/mojo-screenshot.jpeg) Almost (but not quite) as bad if I use Opera.
[Don't reckon there's anything wrong with the display](http://www.web-brewer.co.uk/mojo-screenshot.jpeg)
I felt the same way, then I got the cataracts fixed. Now the contrast issues are all fixed. 
For someone who just got introduced to the whole PSGI thing, the amount of frameworks available is kind of daunting. I've seen tons of praise for Mojolicious, but lots of rebuke in favor of Dancer/Dancer2 as well. However, most of what I've read is old, useless, and inaccurate information circa 2011. Can someone point me in the direction of some clear-cut pros/cons and legitimate arguments for the various frameworks to find out what might suit me best? At this point I have the impression that if you've ever touched Template Toolkit and Plack, any of the frameworks will be easy enough to understand and work around their various quirks. After jumping into all of this last week, I'm getting a bit of [this vibe] (http://webcache.googleusercontent.com/search?q=cache:6n6UOXrlXloJ:su-shee.tumblr.com/post/46416661551/i-fucking-hate-you-all-all-of-you-equally+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us).
The answer depends on what you want to build. What do you want to build?
You almost have to take pic with camera as screenshot won't convey your contrast settings. On my pc and nexus tablet the code is easily read. I can turn contrast down to recommended levels for a game and it becomes difficult. I suspect you may have contrast a bit lower than I do and possibly daylight (typically absent for me) 
Linux and fonts...
Really appreciate this. Thanks!
Cool! Just started with perl, find it very expressive. *installing on perlbrew*
Nice
I do love that perl gives you so much power to do whatever you want, even if its shoot you(and anyone who ever maintains your future code) in the foot, but... no if $] &gt;= 5.018, 'warnings', "experimental::feature_name"; is that really the type of code we want in official documentation? 
Here's a link to the [perldelta](https://metacpan.org/module/RJBS/perl-5.18.0/pod/perldelta.pod#NAME) describing the changes since 5.16.
`perlbrew install -j 8 -v http://cpan.metacpan.org/authors/id/R/RJ/RJBS/perl-5.18.0.tar.bz2`
That part made me sad. I really like the idea of smart matching :( To me they were perfect for making 'get'/'find' functions that can be called with damn near any type of argument and still have it work.