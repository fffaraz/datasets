That seems to make sense, sounds like it would be worth learning. 
This might be a stupid question, but do you actually want to keep adding elements onto @controlArray and @sampleArray? Are you sure you don't want to actually declare those variables inside the for loop (so that they are empty at the beginning of each iteration)? The way it's written now, those arrays will become incredibly massive, and use a huge amount of CPU.
Which is why I pointed to it. R is pretty horrible for complex tasks that need extensive coding, but this case doesn't and with BioConductor, most MA analysis is one step,
I remember first learning R and using some loops (because what language doesn't use loops, right?!). IT was SOOOOOOO slow. Then I learned I could do functions on an entire matrix at a time and then it was smooth sailing. (Well, other than the fact that factors/levels kept getting in my way for a while.)
Without trying to sound like an ass (though, I'm afraid I'm about to): You're writing C code and making /usr/bin/perl parse it. Perl is not C, and the ideas of "fast" in C are not always fast in Perl. You read the entire file into memory, one line at a time. Why? * Do you need the entire file? Use File::Slurp. It's faster than a while() loop. * If you don't need the entire file, why not do your parsing inside the while() loop? You seem to be doing things like iterating over an array to see how many items it has. Why? So you can, later, use the C-style `for(;;)` loop? Stop that. Use `for my $thingy ( @list_of_thingies ) { }`; there's almost no chance you need the C-style stuff. Stop using `&amp;foo(..)` to call subroutines. It's not what you want, I guarantee it, and when you do `&amp;foo`, (See [perldoc perlsub](http://perldoc.perl.org/perlsub.html) for reference) you're going to be confused. On top of that, subroutines in Perl are expensive; are you sure you need to do it at all? As others have mentioned, you may be running out of memory. You should also point NYTProf at this script. [Here](http://www.slideshare.net/bobcatfish/profiling-with-develnytprof) is a quick overview on how to use it. 
Couple things: * You should profile the code and see what the bottle necks are. Is it using a lot of RAM? Is it CPU bound? * Do you REALLY need to slurp the whole file into RAM at the start or can you process it line by line? * Look into memory mapping the file with Sys::MMap or File::MMap or the like * Look into PDL http://pdl.perl.org/ if you're doing this sort of thing a lot.
yes! C is not perl. Also, there are little things you should clean up, like using `die "\nUse: perl microarray.pl &lt;Input datafile.txt&gt;" unless @ARGV == 1;` instead of that horrid initial if-statement. 
I've been using GTK for building desktop apps in Perl. It's easy to get simple apps written quickly but powerful enough to build complex applications. 
&gt; To start off, stop instantiating useless vars in your loops when $_ would suffice. Sometimes this is a good idea, but sometimes it isn't. It's only worth doing this kind of micro-optimisation if you've already demonstrated (by profiling) that the loop in question is a bottleneck. Otherwise, write your code for maximum clarity.
&gt; The code seems to run really quickly for the first 1000 or so, but slows down rapidly after that. Yeah, that's exactly what you'd expect to see if you're, say, repeatedly iterating over a growing array :-)
&gt; The comment above was not meant to be rude Nonetheless, it was. &gt; Profiling a fundamentally broken approach to a problem is not helpful, nor is trying to rework that broken approach. And yet, with a few simple changes, unkz was able to make the script run in less than a second. I'm certainly not arguing against the importance of having a clear understanding of the problem (though I find that clarity usually comes from writing tests and code, rather than sitting and thinking hard). But saying "go to your room and think about what you've done!" doesn't help anyone either.
You seem to know what you're talking about, but I respectfully disagree. $_ is just as readable as $i, and is good practice. of course he could always `for my $foo (etc)` but I honestly don't see the sense in it. I suppose it's semantics, really.
&gt;And yet, with a few simple changes, unkz was able to make the script run in less than a second. There's more to this than that. The OP is using this for scientific work. When it comes time to publish the group will briefly look at the code and decide to not make it available. Because of the baroque nature of the code there are still places for bugs, so this component of the work will not be peer reviewed. Do you remember the big kerfuffle about some climate scientists not releasing code? This may be small examples, but it is what leads to the generalised practice. &gt;I find that clarity usually comes from writing tests and code, rather than sitting and thinking hard That is a false dichotomy. Reworking broken code often results in the desire o reincorporate past effort - this is often wrong. Further, the OP has had their first go. Now they need to do the real implementation. &gt;"go to your room and think about what you've done!" Your interpretation. That was not what was intended. Don't be so precious.
To how many files are you splitting? If it's a reasonably small number (say, &lt; 50), I would: open each output file, keep handles in an array, say @handles open input file an array for buffering lines, @buffer or something array iterator, say $i = 0 loop on each input line if (/^&gt;/) { if anything in @buffer, write to to $handles[$i] clear @buffer increment $i, wrap to 0 if &gt; $#handles } put line in @buffer The idea being cycle through output files, one record going into each.
If you are working in a linux environment, you could use the split command. The problem with this solution is that you may split a sequence between two files. Another more complex solution could be done using the tail and head commands.
In principle this solution works. Personally, I won't use this solution because you'll have to parse the whole file(s). I remember working with FASTA files of about 30GB or more, therefore I would prefer a solution that does not imply parsing the whole file.
If you absolutely must preprocess the data on a single node, you could probably put something together using sysread()/syswrite() and regexp/pos() to locate the "&gt;" characters. It'd let you minimize the memory copies and maximize the data read/write rates. Depending on your cluster setup, the best way to do it could be to assign an offset to each node on the cluster, and have each node seek to that point in the file, then search for the next marker. Then have that node start at that point in the file. For example, if you have 2 nodes and a 1000 byte file, you start node 1 at offset 0 and node 2 at offset 500. Then you just ensure that node 1 reads up until the first sequence at or after offset 500 to prevent overlaps. This would be great if you are already on a shared network filesystem sort of setup, or possibly better if you are on a distributed file storage mechanism so that each node already has a copy of the data.
split would be great to generate most of the files, with a small postprocessing step to copy all the data from the head of each output file that doesn't contain "&gt;" to the tail of the previous file to deal with improperly split segments. Since FASTA ignores whitespace, the copied data at the head of the files could be overwritten with newlines with no effect. This might be the optimal single-node solution.
here, this works pretty well: #!/usr/bin/perl die "usage: splitFasta.pl inputFile.fasta chunkSize\n" unless ($ARGV[1]); open (FA, $ARGV[0]); @fileName = split (/\./,$ARGV[0]); $entryCounter = 0; $faCounter = 0; while (&lt;FA&gt;) { $line = $_; if ($line =~ /\&gt;/) { if ($entryCounter % $ARGV[1] == 0) { ++$faCounter; $chunkFilename = "$fileName[0]\_$faCounter\.$fileName[1]"; close CURCHUNK if ($faCounter &gt; 1); open (CURCHUNK, "&gt;$chunkFilename") or die $!; print "$chunkFilename\n"; } ++$entryCounter; } print CURCHUNK $line; } close CURCHUNK; close FA; it'll break if your input FASTA filename has any periods in it (before the .fasta) but otherwise it should be pretty solid.
This does seem like a good idea... i want to run it 16way 16 ... i was planning on splitting the files to 10 or so smaller runs and parallelizing that way
This seems to split the large fasta set into smaller sets with a specified number of sequences in them. I want to split the large FASTA dataset into a SPECIFIC number of files (like 10).
No, it's called *being an asshole*. It's not 1990 any more, we should stop doing this shit and making excuses for the socially inept. **Edit** I now accept that dx_xb was not being deliberately hostile, just tone-deaf. Which is much more forgivable, but not much better for our reputation as a beginner-friendly community, and we shouldn't tolerate it. Judging by the downvotes, people agree with me - I'm delighted to see that.
&gt; When it comes time to publish the group will briefly look at the code and decide to not make it available. You're not a scientist, are you? I've seen much worse code than this in an academic context. "The code is messy" is almost never the reason for not releasing scientific code.
&gt; $_ is just as readable as $i, and is good practice. Sure, but a more meaningful name (for a loop variable that isn't just an index) can often help readability. TMTOWTDI.
*has no idea what TMTOWTDI means. also, readability for non-perl users ;)
BioPerl reads a full sequence in to ram for each call to -&gt;next_seq. Depending on the structure of the fasta file that you are reading and the number of sequences in it you can run into all kinds of interesting problems here. For example in our data sets it's not uncommon for a fasta file to have a sequence that is larger than ram. In such cases system performance is going suck because the system starts swapping. I'd start exploring the number of sequences in the file using something like: grep -c '^&gt;|^;' filename.fasta Then get a feel for the average size of the sequences by dividing the count by the file size. Think about how that relates to the amount of available ram.
&gt;You're not a scientist, are you? Academic bioinformatician. &gt;I've seen much worse code than this in an academic context. If I had a student that wrote that I wouldn't let them release it. I would however make them rewrite something that validated any results it generated and release that. [The notion that academic software is particularly worse than commercial or floss software is foolish position to take (have you looked at the openssh source? or noticed how unstable Windows has been for the past 20 years)](http://www.nature.com/news/2010/101013/full/467753a.html). &gt;"The code is messy" is almost never the reason for not releasing scientific code. Not a valid reason, no. But poor quality software is more often not released than good because people are (justifiably) embarrassed. Nice try at attempting to undermine an argument by attacking the person though.
To fix the problem with it breaking upon use of an input file with a period, I recommend using [File::Basename](http://perldoc.perl.org/File/Basename.html)... use File::Basename; my ($file_name, $file_path, $file_suffix) = fileparse(ARGV[0], (".fa", ".fasta")); #inside the loop, specify output filenames with: my $chunkFilename = $file_path . $file_name . "." . $faCounter . $file_suffix; Also, you shouldn't need to escape the underscore and period characters.
There's More Than One Way To Do It. It's the Perl motto :-)
Oh god!!! Too many!
Ho yes, at least there was pugs, written in Haskell. 
Wow! Please don't apologize - that was an amazing response. Thank you for taking the time to explain everything with such detail. You seem like a regex guru, at least based on this post - is this something you do day-to-day, or have done for years, or just a skill you happened to have picked up? I would love to know how you got to where you are now.
Term::ReadLine
A valid point, and I do have plans to add command line options. I'm making this more for less tech savvy coworkers who react better to plain English prompts rather than trying to figure out command arguments.
yes, that's what portability means, to write stuff for each platform and each vendor. (writing portable code can be boring as hell). anyway.. only Debian, Ubuntu and perhaps Arch are important distributions so you can descope anything else, that makes the job easier. HTH !!!
RDBMS systems such as MySQL and Postgres have bulk loading utilities. Optionally, what I used to do (as a hack) when doing data reloads was parse the input file, one record at a time, and convert it to an appropriate INSERT statement, and then save it to an intermediate file. The run the commandline SQL client on that.
If you're doing anything serious, and you don't have a reason to not use Moose, use Moose. If you want a good explanation, get chromatic's [book](http://www.onyxneon.com/books/modern_perl/index.html) (free to download, but you want to buy it). 
Look for O'Reilly's "Perl Cookbook". It's good stuff, though not free. Also good: Learning Perl, by Randal Schwartz. Avoid at all costs: Matt's Script Archive. 
Why do you automatically dismiss CPAN? You don't have to download anything, there is a source link on every page to view the source of the current module. I've learned heaps of useful things by looking at how CPAN modules are implemented. 
[github](https://github.com), search for perl projects...
Like a swan from the duckling, I have made your comment... *art* http://i.imgur.com/pO0r4.jpg ...Courtesy of the instant_reddart bot
I think that could run into problems with CDATA sections. Perhaps use [HTML::Restrict](https://metacpan.org/module/HTML::Restrict)?
Little tools in Perl are maybe my favorite things to do. My current project is an app framework. It's quite small and yet I've still been working on it for some time and get held up when I realize I have some kind of design decision to make. Little tools are refreshingly straightforward. And using them is sort of a little thrill every time.
`die ("\nUse: perl microarray.pl &lt;Input datafile.txt&gt;") unless @ARGV = 1;` for the love of god stop wrapping your argument checks in if loops if you're not checking for anything complicated. EDIT: also, you could clean up the fldscore setup a little better. Great tho. Glad to see Grep is popular with the kids still.
I was speaking to the synopsis block of code for the modules which doesn't provide any context. I actually didn't know until this comment that I could view the source of the module; never really occurred to me. However, the source of most modules is still way above my head. I'm still learning the basics, so a program that ties several basics together is more what I'm looking for.
&gt; I'm not in it to win - I do this because I learn and because sometimes others learn from me. Likewise - but sometimes people infuriate me and I can't let go. &gt; It would have been obvious what the required scope was for the arrays. In general the OP demonstrates a poor understanding of scoping issues, so I don't think this follows. &gt; You are iterating over the same data twice, unnecessarily- the grep and summarisation can happen in the read loop. Aha - perhaps you missed [the comment where I explain why I did it that way](http://www.reddit.com/r/perl/comments/qk261/stepbystep_cleanup_of_madclowndiseases_microarray/c3y7cef), or the [branch in which I make the program run line-by-line](https://github.com/pozorvlak/microarray/tree/by_line). It makes basically no difference to the speed, but it does save some memory and a few lines. I still don't like mixing in the parsing logic with the filtering logic, but it would be worth it if the files were large enough. And, as I said before, it was basically trivial to alter the algorithm to work line-by-line after doing some more cleanup - much easier than rewriting it from scratch. &gt; not understanding the value of letting go of old code is a real failing in a programmer I find that version control helps a lot here :-) &gt; bad design often entrains itself. Indeed, but this is not one of those cases. &gt; I disagree that the advice is bad Any advice about fixing performance problems that does not start "profile your code" is bad. &gt; the notion of rudeness is your interpretation - perhaps you would have felt happier if I had put a smiley at the end of the sentence? Not really. You don't seem to understand that rudeness is not a function of your intent. I accept that you weren't trying to be rude, and I'm sorry that I said you were: nevertheless, your words could easily be taken as hostile and belittling (and were so interpreted by most people who read them, judging by the downvotes and the "tough love" comments). Try to put yourself in the position of a beginning programmer who's spent a lot of time and effort writing a program. Your advice is "throw it away and try again"? Well, great, that's going to make them feel valued. You could have made your point more clearly by, for instance, saying "Treat this one as a prototype and start again; you can apply the lessons you learned from this one without being imprisoned by your design mistakes". I'd still be disagreeing with you, but at least I wouldn't be calling you rude. It's the difference between "What you've done is a useful step along the way" and "What you've done is worthless". The reason we as an industry make a big deal about egoless programming is that it's *hard* to separate yourself from your code, even if you know you ought to be doing it.
I missed a point in my previous comment. If I had been presented the code you have at the tip of your repo, I would have said just refactor the loops - the difference being how long the refactor would take. How long did you spend doing revisions? A rewrite would have been 15-30 minutes. &gt;Aha - perhaps you missed the comment where I explain why I did it that way, or the branch in which I make the program run line-by-line. It makes basically no difference to the speed, but it does save some memory and a few lines. I still don't like mixing in the parsing logic with the filtering logic, but it would be worth it if the files were large enough. The link you provided to the thread went to the the repo, so yes, I missed that comment. I can understand the desire to separate the two parts, but it's generally not appropriate in bioinformatics. The MA sets may be small (on the order of 1e5-1e6 lines), but sets can be 1e8 lines. Generally slurping is seen as bad practice for this reason and for managing community resources. &gt;I find that version control helps a lot here :-) I agree. Things can be thrown away without the negative emotional impact. &gt;Indeed, but this is not one of those cases. In your case, no. You have well argued (though in the context of bioinformatics, wrong) justification for your approach. In the case of a less adept coder (the OP may satisfy this definition), that is less likely to be the case - the less adept coder would likely continue to use an incorrect approach without justification just because it was already written. &gt;Any advice about fixing performance problems that does not start "profile your code" is bad. Most advice that takes no bearing from context is bad. &gt;nevertheless, your words could easily be taken as hostile and belittling (and were so interpreted by most people who read them, judging by the downvotes). Surely you've noticed the hive mind. If there is some doubt about the intent of a comment, redditors more often than not vote with the votes. Arguing ad populum on reddit is not worthy. &gt;Your advice is "throw it away and try again"? Well, great, that's going to make them feel valued. And if you look at the whole post, you'll see my [comment to the OP](http://www.reddit.com/r/perl/comments/qf9do/why_is_this_perl_code_painfully_slow/c3x8j14) with specific advice and reasoning. &gt;You don't seem to understand that rudeness is not a function of your intent. No. The *interpretation* of rudeness is not a function of intent - rudeness is most definitely a function of intent, or lack of intent (callousness). I neither intended to be rude, nor was I callously disregarding the impact of my comment. As you mention, ego enters into the picture when dealing with intellectual endeavour, and significantly, people's bases for interpretation differ (as you are probably aware, communication is a Hard Problem - re-read some epistemology). If I am to play it safe, I must give no comment, because someone may suffer a slight. That is the same as telling Johnny that Granny is sleeping. I can guarantee you that the OP, at least weekly, has heard more ego crushing advice from their supervisors and colleagues. In molecular biology the most commonly given advice is "Do it again.": there there is no source control, there are no macros and everything takes twice as long as you expect (even when you take that into account) - and personal involvement in the project is arguably stronger.
You can write daemons in Perl. If your program takes a while to start up, sleeping can ameliorate that. Any decent operating system should let your program sleep without eating many resources--unless your program is very memory heavy.
Is there a resource difference between writing a perl daemon and just running and indefinite perl script? Or are those basically one in the same?
It's the same thing. I think you're putting too much weight on the semantics. A daemon is just a process, detached from interactive input, running until told otherwise. Looping forever is the norm.
I just submitted a pull request that includes wafflepirates' suggestion, although I opted for '==' instead of the assignment operator ;)
While I can appreciate keeping 'separate stages of processing separate', and actually find the master branch much more readable than 'by_line', there's no reason not to do the filtering as a part of your file reading loop. Aside from creating an extra unnecessary array which buys you nothing (as you allude to in your commit message), you're also doing an entire extra iteration over the data array after you've just finished doing so once already (to create the array). This is a bit silly and actually harms readability IMO. ...Pull request, submitted ;)
I run Perl daemons that routinely run for *years* (typically matching uptime of the machine, even Solaris sometimes needs a reboot for patches). Some talk to databases (DBI) and routers (Expect/SSH), some tail log files on one machine and send RPC reqests to another daemon on another machine to take some action. Most of them have been chugging along without incident, starting and stoping with the sytem rc scripts for 7-10 years now.
I've never quite understood what Moose was. It's like... scotch-taping some form of OO into perl, a language that doesn't really support OO concepts, right? But perl does apparently allow libraries to re-write the basic rules... so that's... a good thing... somehow.
If I remove a test for what a method does, I can't imagine caring what `can_ok` will do.
Perl really does support OO concepts pretty well, it just doesn't come with them inbuilt. The issue is that while coding you tend to repeat yourself a lot because you have to write accessors manually. Moose is there to automate that. You would do good to look at RJBS' excellent [Moose is Perl](http://rjbs.manxome.org/talks/moose/Moose.pdf) talk (pdf), because it demonstrates that really well.
I'm going to pull back and ask the annoying question -- what are you trying to do, and why do you think you want to do it this way? There are certainly ways to create global variables based on string names, but I can't see a way that that would lead to clear, understandable code.
God, tell me about it. Working on replacing a 12 year old codebase where it's been partially "refactored" by sophmore programmers several times over. Additionally, I wish that anyone who learned to program got some kind of subliminal hook put in that would make them shoot themselves in the head if they thought that an EAV database schema applied to their web app. 
I believe the module PadWalker might be able to do what you want. I'm afraid I can't provide an example. Disclaimer: Doing this kind of thing is USUALLY inadvisable, but if you know what you're doing go right ahead!
It looks like you want to obtain something that requires a functional paradigm. I suggest giving a look at this great book: "Higher Order Perl" by Mark Jason Dominus.
[google: perl get name of variable](http://stackoverflow.com/questions/5199860/get-variable-name-as-string-in-perl)
I am looking at a data file and I want to look at two lines at once. the lines do not have the same number of items. It's either 5 or 6. I am processing the first line while looking at the second line because I need the data in the second line. I feed the first line into $line_a and start the while loop on the next line. ..beating my brain for the most efficient way to do this.. 
That module is perfect! That should be enough to get me started. I have a question though... This is more just "prettifying" but how do I get the script set in such a way that I could issue regular commands without knowing the path? *e.g.* service my_daemon start
Create a datastructure. Use a variable as a hash key to lookup and store the string. [Autovivification](http://en.wikipedia.org/wiki/Autovivification) is your friend. *EDIT* - [PaulMdx](http://www.reddit.com/r/perl/comments/qlrbi/get_variable_name_as_string/c3ykgzh) gives a good example of this. Also, you can slurp the file into an array and iterate by array index to make it easier, if you always know that you need two lines next to each other. I may have completely misunderstood what you need but (totally untested): #!/usr/bin/env perl use strict; use warnings; use Data::Dumper; sub slurp { my $filepath = shift; local *F; open F, "&lt;", $filepath or die "Cannot open $filepath: $!"; my (@contents); while (&lt;F&gt;) { s/#.*$//; # Remove comments next unless /\S/; # Skip blank lines push( @contents, $_ ); } return @contents; } my @data = slurp("path to file"); my $results = {}; for my $i ( 0 .. $#data ) { # If it's any odd numbered element then skip, because we're doing even and # even + 1 as a pair. next if $i % 2 != 0; my $fifthword = $1 if $data[$i] =~ /^(\b.+\b){4}(.+)\b$/; my $sixthword = $1 if $data[ $i + 1 ] =~ /^(\b.+\b){5}(.+)\b$/; # Store it $results-&gt;{"$fifthword"} = $sixthword; } print Dumper $results; 
Okay, now we're getting somewhere. I'm sure you're about to get a bunch of ideas, but in this kind of case, I usually ask myself: What more do I know about the data, other than it's on lines? Is there any way I can create a way to group it that doesn't require I think about it in terms of lines? i.e. if they are pairs of lines, can I figure out a way to process a pair of lines at a time? I don't know enough about the data to offer advice here. * If it's always going to be looking at the previous line, then simply create two line array refs (or hashes, if you can give the columns names, that would be far clearer). Then just before reading the next line, put the current array/hashref into "$prev", and read the next line, and process it into a hash or array or whatever. * You should, generally, be using hashes for giving names to things wherever possible. And you should ALWAYS use data structures to give data-derived names to things, NEVER stuff in your program's namespace. Down that road lies register_globals madness. More details would allow us to give you more advice, especially on the structure of the data. Edit: Fundamentally, you're describing a mismatch on how the data exists physically and how you're processing it. You are processing it like it's "one record per line", but clearly (if you need more than a line at a time) one "record" spans more than one physical line. I would, generally, encourage you to find a way to process the file in such a way that you can extract "one record" at a time before doing any processing on it.
I really like that book!
Unfortunately not... You could push all lines in to one and process as you exit each chunk (the "Flop"). It's great for processing chunks of multiline text... [Here a good post](http://www.perlmonks.org/?node_id=525392) from Perlmonks about it.
Don't understand what you're asking about has to do with what you want. Anyway $$var is a variable whose name is $var. $var = "foo"; $foo = 4; $$var is 4. As to what you're asking about... $prevline = &lt;&gt;; while (&lt;&gt;) { # dostuff $prevline = $_; }
Yes, Master.
Ubuntu and Fedora use something called Upstart, and you can find a few good tutorials online if you search. (I haven't had much luck with Upstart for Plack servers, but I didn't try too hard.)
If your use case is simple enough then PadWalker is the way to go. But it looks to me like the OP is trying to do something with variable names that is better to do with a data structure. Say a hash of hashes for example ed: spelling
I mentioned PadWalker before the OP mentioned what his problem was. PadWalker seemed to be what he wanted at the time. Now that I know what his problem is, PadWalker seems like a poor choice.
Install PuTTY and wrap the pscp cmdline utility. Have done this in perl &amp; python
 1) if perl is not installed - install it cygwin, activeperl, or citrusperl are all options 2) run cpan to install Net::SCP::Expect (go to cpan.org and lookup module for more info and how to use it)
You're right, the "ref($class)" portion is the unusual part, and not particularly useful. $object-&gt;new is something a prototype based object system might do (like JavaScript I think?). Doesn't really apply well to Perl. It makes more sense in languages where either classes don't exist at all or are static and cannot be modified at runtime.
use scp, not winscp
Net::SSH2 is a good module for ssh/scp. You can use it instead of winscp. It is included into Strawberry Perl.
This was my problem, even though I had put the absolute path to the winscp file, but not to the script file, or the key file. Once I did this it worked. Thank you.
putty download page: http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html
I'm glad to see PSGI/Plack get more attention! Tutorials like this are cool. The real-world usage I've seen is for people to start with something like Dancer and Starman and then extend the project with Plack::Builder and the numerous middlewares[1]. Do you intend to do a followup? [1]: https://metacpan.org/search?q=Plack%3A%3AMiddleware 
Yes, I'll do more PSGI/Plack writing in between the parts of the beginner and advanced tutorials.
I think the usual suggestion is "friends and family first". So contact people you know and trust already and show it to them first. At least those who are in your target audience anyway. 
Do you know if anyone is doing a Plack book?
I know about this http://www.modernperlbooks.com/mt/2011/05/the-little-book-of-plack.html but I am not sure if there are any specific plans. What would you expect to be in a Plack book?
Working on it, but found myself bogged down in other work for the time being.
uhh lol is that what u meant? 
What does the chomp function do?
Lol by very new to Perl, I mean I have no idea what anything past arrays, scalars and subroutines mean. :P
Then let's go through this, one step at a time. I'm going to start with a simple program and slowly make it more complicated. For *very* short scripts, you can just run Perl from the command-line instead of having to create a file and run the script from that. This is what huf is doing here. To run the script, just write the line in the command line or terminal, press enter to run it, then enter a bunch of numbers (pressing enter after each one); to finish, press Control-D (or Control-Z on Windows) and it should display the average. ## `perl -E ''` This is the default, empty program. If you run it, it should do nothing. Which is good, because we haven't told perl to do anything! Let's try adding some code: ## `perl -E 'say "avg: ";'` This program should print `avg: ` and nothing else. The 'say' function, which you might have not heard of, is the same as the 'print' function but printing a new line at the end (you don't have to use the `'\n`' like you might have been doing already - I don't know which tutorial you've been using). The 'say' function isn't available by default, but using the `-E` flag enables it. ## `perl -E '@x = &lt;&gt;; say "avg: "';` When you run this program, it should just sit there, because it's waiting for you to input a number! So enter some numbers, pressing return after each one, then hit Control-D (or Control-Z on Windows). Then it should say `avg: `, as before, but it doesn't calculate it yet. The `&lt;&gt;` part might be confusing, so I'll explain. You say you understand arrays, so I'll go with that. It assigns into the array `@x`, but instead of using a pre-defined value, it uses the list of numbers that you enter. `&lt;&gt;` is shorthand for 'anything the person enters as input'. ## `perl -MList::Util=sum -E '@x = &lt;&gt;; say "avg: "';` This does the same as before - we don't print the average yet. Perl doesn't have a default sum function, but it does have one in the module List::Util. The `-M` means "import a module", which is followed by the name of the module we want. The equals sign specifies which functions we want, which right now is only `sum`. ## `perl -MList::Util=sum -E '@x = &lt;&gt;; say "avg: ", sum(@x);'` We're almost there! This prints the sum, rather than the average, of the numbers. We use a comma after `say` to print another thing. ## `perl -MList::Util=sum -E '@x = &lt;&gt;; say "avg: ", sum(@x)/@x;'` To get the average, you divide the sum by the length of the array, and that's what's happening here. But why does `@x` suddenly mean "the length of `@x`"? This bit's the trickiest, and you must know about contexts. Basically, Perl allows you to be fast-and-loose about what you mean sometimes. It's the same design as why you don't need to turn the strings into integers as you would do in other languages - Perl assumes that if you're treating it as a number, it *is* a number. It's the same thing going on here. `@x` is an array. But you can't divide a scalar by an array, you can only divide a scalar by a number. So Perl uses the array *in numeric context*, and converting an entire array into a single scalar means getting its length. In English, it's like saying "divide the sum by the numbers" instead of "divide the sum by how many numbers there are". So that's the code. It's not that complicated, really. Be sure to ask for help if you're still stuck!
This is why I love Reddit, I get the best human to human advice for free... And people dont call me dumb :P
Yes, right you are. Fixed!
It's not possible to satisfy the requirement if the number of variables is not known. I'd 'push' the numbers into array and then sort like above person said. 
As Rhomboid said, using List::Util is the easiest option, but here is a more "done by yourself" way of doing it: Get the numbers from wherever you are specified to (standard input, as arguments of the program, hardcoded in it, etc...) on an array and then do a numeric sort on the list. You can then print the first and the last elements of that list. You don't need to create a separate variable for each value as perl already gives you a variable for each element of every list in your program, for example, if you have an array named @numbers, its first element gets stored in $numbers[0], the second one in $numbers[1] and so on... (Hint: you could access the last one without the need to know the number of elements on the list by using $numbers[-1] or $numbers[ $#numbers ] )
You need to put quotes around "Barack Obama" on Line 7. Without them, perl thinks that you're trying to run a function called `Barack` on a package called `Obama`, then compare `$x` to the result of that. Also, in Perl, you need to use `eq` instead of `==` when comparing strings instead of numbers, because two numbers can have two different representations (such as 3 and 03) yet still be equal to each other. You'll get a warning from perl if you don't do this. Also also, you should `chomp $x` after you get the input from the user, to remove the newline at the end. Here's a paste with all that: http://pastebin.com/f5xsDSVD
You talk in code! 
When you hit reply, on the bottom-right corner of the text box is a link called "formatting help." The pertinent part: Lines starting with four spaces are treated like code. The first thing that you should do is tell us all where this class is so that we can avoid it. Then, you can just unroll the for loop I wrote: #!/usr/bin/perl use strict; use warnings; my $var1 = int(rand(21)); my $var2 = int(rand(21)); my $var3 = int(rand(21)); my $var4 = int(rand(21)); my $var5 = int(rand(21)); my $smallest = $var1; my $largest = $var1; $smallest = $var2 if ($var2 &lt; $smallest); $smallest = $var3 if ($var3 &lt; $smallest); $smallest = $var4 if ($var4 &lt; $smallest); $smallest = $var5 if ($var5 &lt; $smallest); $largest = $var2 if ($var2 &gt; $largest); $largest = $var3 if ($var3 &gt; $largest); $largest = $var4 if ($var4 &gt; $largest); $largest = $var5 if ($var5 &gt; $largest); print "\$var1 = $var1\n"; print "\$var2 = $var2\n"; print "\$var3 = $var3\n"; print "\$var4 = $var4\n"; print "\$var5 = $var5\n"; print "\n"; print "largest: $largest smallest: $smallest\n"; % perl test.pl $var1 = 17 $var2 = 11 $var3 = 2 $var4 = 8 $var5 = 14 largest: 17 smallest: 2 Finally, don't use $a and $b as variable names. Perl gives special exemptions to $a and $b so that they can be used as values in a sort() operation. For example, you can use them without first predeclaring them with my(), even under use strict;. You will end up in a situation where you forget to declare variables and end up with the strange behavior of $a and $b working, but $c, $d, and $anything $else not.
Thanks Kip, I'll review those resources. I do not want to hardcode the filenames and I do not want to process the additional *.xml files yet (possibly in the future though). For now it would be sufficient just to print the list of files that match that glob. Here's what my parsing call looks like from the main program: my $p = XML::SAX::ParserFactory-&gt;parser(Handler =&gt; $handler, Source =&gt; {SystemId =&gt; $fullPath}); my $trnDestHash = $p-&gt;parse(); I've made my own parser class as well which is very simple, it just prints itself via Data::Dumper and calls $self-&gt;SUPER::parse so the program continues to work. Ideally all I'd need to be able to do is pass the parser's "Source" value to my handler but I'm not sure how to do this. EDIT: formatted code nicely
The easiest and simplest thing to do would be to copy everything down from the first "print" statement, to a couple lines below the last statement. Just change the variable name to keep the answers separate (makes it easier to save them all to disk or e-mail them or something later on). Kinda like this; http://pastebin.com/vuBj8c2Z Tip; make sure you have a line or two between each section, so you can visually separate the different pieces of your code. This becomes very important when you have many sections!
thanks!
You're welcome. Let us know how it works out.
Look in the source of their own website: holophrasticenterprises.com 1000+ lines of garbage for a static front page.
They must also hate having decent pay. $40k/year is a fresh-out-of-school salary (and not a very good one; mine was higher than that, *15 years ago*).
Bonus! "Interestingly flexible hours", which I suspect means "Whenever I want you to work, and that's going to be a lot at all times of the day and night"
Can't tell if serious...
Wow. That is "special". Also (and I'm no web dev), but I thought using a table for layout went out with frames?
This dude is serious. He's the same guy that "has a really great idea" but "just needs you to code it," but don't worry, he'll make millions and you'll get paid then because he's paying you NOW but in SHARES OF THE COMPANY. No, of course not actual stock. He's got an excel sheet he made and gives you shares instead of a paycheck every 2 weeks.
&gt;never document code (it's legible, that's the point) Oh God.
This will not work as intended for negative numbers.
There's a recession on, I don't know if you heard about it...
&gt; Pipelines includes dozens of sub-syntax languages of natures similar to regular expressions, so if you can parse a regular expression in your head, cryptic as it may be, pipelines becomes crazy easy. Really, this guy *has* to be a troll.
&gt; Table layouts are pretty much out. Don't tell that to e.g. Google News. &gt; I don't know of any major sites using them. That just means you don't pay attention, not that you are an authority. 
For a simple front page with just a logo on it, that's surely a lot of JavaScript in there. 
Check Ubic on CPAN
Meh, so many companies operate like that. I've worked in 3 different companies on 3 different large projects. All of them had the sand general feel. No OO, minimum reuse, lots of home grown modules, no CPAN usage, etc... Where's all the good stuff? :)
What worries me most is that author's style of writing may be unique and easily identified within the company. Unless he wrote like that on purpose. 
UUID.xs:5:23: error: uuid/uuid.h: No such file or directory This is the key error, you are missing the development libraries for generating uuids. I'm assuming you're on debian or ubuntu, so install apt-file, do an apt-file update, and then: $ apt-file search uuid/uuid.h uuid-dev: /usr/include/uuid/uuid.h Install uuid-dev, your problems will be solved.
Alright...so right after typing up that command I found the problem (I swear, I've been staring at this thing for hours) the makefile was pointed at /usr/local/include and the uuid.h was in /usr/include one simple link and it fixed all the problems. Thanks for the brain wave!
Yah, it's a dependency for VMWare's vSphere Perl SDK 
Thankyou. I learnt something today.... ;-)
No, it does not.
Why in the world would you not just try it and find out for yourself instead of asking? $ perl -E 'say join " ", sort (1234, 1234, 1222, 1222)' 1222 1222 1234 1234 If what you are trying to accomplish is to remove duplicates, then [read `perldoc perlfaq4`](http://perldoc.perl.org/perlfaq4.html#How-can-I-remove-duplicate-elements-from-a-list-or-array%3f).
Thanks. I actually wanted to show dupes. The error was mine and has been fixed in my code. Silly customers give us all kinds of dupe part numbers. And I need to watch for these and report them. 
Aren't I supposed to hate you?
My personal fave compact sorting algorithm is quicksort: `sub quicksort { ! @_ ? () : ( quicksort( grep { $_ &lt; $_[0] } @_[1..$#_]), $_[0], quicksort(grep { $_ &gt;= $_[0] } @_[1..$#_]) ); }` Not as short as yours, but it's damn powerful.
I like this a lot, it's logically identical to one I saw in [lisp](http://swisspig.net/r/post/blog-200603301157).
Feel free, it's a large, comfy bandwagon. ;)
As is already mentioned elsewhere in the thread, you should not bless the object again unless the class you're subclassing is doing something unconventional, like hard coding its class name to itself. Your test passes. What if you remove the line: bless $obj, $this; # and then bless it to our current class! The test still passes. Why? Because LWP::UserAgent does bless {}, $class and not bless {}, "LWP::UserAgent" so when new is called as *your subclass*, it gets the correct class name from the method call.
About 960: Pixel-based web design is terrible because it means people with visual disabilities (or a desktop display with a DPI above 90) will have to deal with your site looking terrible or being downright broken.
&gt;one simple link I wouldn't arbitrarily link things around if I were you...
[Template::Plugin::Table](http://search.cpan.org/~abw/Template-Toolkit/lib/Template/Plugin/Table.pm)
BTW, a tip. You actually don't have to say: use Foo; use base 'Foo'; as 'base' will require the module for you, so you only have to say: use base 'Foo'; 
 $ perl -e'package Bar; use base "Foo"' Base class package "Foo" is empty. (Perhaps you need to 'use' the module which defines that package first, or make that module available in @INC (...). The error message could have better wording, but I wouldn't call it screwy. Also, if Foo exists but has a syntax error: $ cat Foo.pm package Foo; = $ perl -I. -e'package Bar; use base "Foo"' syntax error at Foo.pm line 2, near "=" Compilation failed in require at (eval 2) line 2. ...propagated at /usr/share/perl/5.14/base.pm line 93. BEGIN failed--compilation aborted at -e line 1. Not too bad either, methinks. 
the first one's entirely misleading.
Very close with Lisp :P I'm not sure if it's original, but for me, it's based on Haskell quicksort, which Haskell does very well (pardon the procedural, haskellites): `quicksort [] = [] ` `quicksort (x:xs) = quicksort [n | n &lt;- xs, n &lt;= x] ++ [x] ++ quicksort [n | n &lt;- xs, n &gt; x]` The functional type capabilities of Perl are amazing.
Using the CPAN, install List::MoreUtils. Then: use List::MoreUtils qw( uniq ); @a = uniq( sort( @b ) );
Assuming the superclass constructor is properly written.
It's good that you use warnings and use strict ... then you have pay attention to the messages. * You haven't declared the variables (missing the 'my'). chomp (my $x = &lt;&gt;); and similarly for the others. * You need a semi-colon after the calculation line. * '\^' is the bitwise exclusive-or operator in Perl( ie, 8 ^ 3 -&gt; 11), you want '**' for exponentiation. There's some tutorial information at cpan.org, as well as info on all the available modules. http://onyxneon.com/books/modern_perl/ is an excellent book available online as well as on paper. http://www.perlmonks.org is a good resource as well as here.
To round the cents, change the last line to printf("In $z years you will have %.2f dollars\n", $a);
Good point. I tend to forget that 'parent' is now the recommended one to use. 
compare this with your link http://pastebin.com/td6DwQTw
That's a valid question. When we upgraded Perl last time to 5.8.8, the sprintf function worked completely differently, and broke all my Perl scripts. We deal with prices a lot, and the sprintf no longer rounded, it now truncates. That means I had to rewrite all my scripts. So I am VERY concerned when anything changes on our system that might impact our Perl installation. Thus I thought our sysadmin had updated a library, or maybe even our Perl, and forgotten to tell me. So I thought Perl started working differently. It turns out it was a problem with my code and it has been fixed. 
you've kind of missed his point.. he was asking for something very precise, which would just require you to fork his script or whatever and fix a few characters, instead you've given him a lot more than he can chew.. these are newbies, did you really forget what you wanted when you were first learning perl yourself ?
you got cluttered up in minutiae and forgot to actually answer his questions. I'm sorry to say this but some people forget how it was when they were newbies.
[Modern Perl](http://www.onyxneon.com/books/modern_perl/index.html), assuming the environment she's looking to has an actual recent version of perl (some of us still work on RHEL5 boxes, which are at 5.8.something, yay progress). That will teach perl, it assumes a basic knowledge of programming. It will get you up to speed on modern perl facilities, such as Moose for OO, etc. Is she inheriting a codebase, or starting something from scratch? Is it in a particular field which may have it's own stuff (i.e. bioperl)?
I think in some ways [Modern Perl](http://www.onyxneon.com/books/modern_perl) is the successor to PBP.
Take a look at [PerlCritic](http://search.cpan.org/dist/Perl-Critic/). It implements the best practices in 'Perl Best Practices' as well as a bunch of other suggestions. There is an [online version](http://www.perlcritic.org/) where you can upload a file and it'll critique the file. You can customize the critique level and even turn specific practices on or off depending on how fussy you are about 'bad code/practices'. The author mentioned in a presentation at the LA-PM (Los Angeles Perl Mongers group) that he personally doesn't agree with all the suggestions in the 'Best Practices' book, but the core is useful. The author has some slides from a [PerlCritic presentation](http://www.slideshare.net/joshua.mcadams/an-introduction-to-perl-critic) available. 
[How to get started with Perl](http://www.reddit.com/r/perl/comments/pmwjt/how_to_get_started_with_perl/) [Beginning Perl](http://learn.perl.org/books/beginning-perl/) [Learn Perl in about 2 hours 30 minutes](http://qntm.org/files/perl/perl.html) (this one needs a little programming background for a beginner) [Perl Intro](http://perldoc.perl.org/perlintro.html) [Perl 5 By Example](http://www.webbasedprogramming.com/Perl-5-By-Example/)
I agree on a content level, but I liked the format of the book immensely. It was a collection of "if you're doing this sort of thing, you should be doing it one of these ways, and here's why", rather than a traditional explanation of a language.
PBP is mostly as valid as it ever was â€” but if you think it's right 100% of the time then you still need to grow up as a developer. I'd say the hit rate is about 50-60% (and of course it's not the same 50% for everyone). Just pretend Class::Std doesn't exist, and ignore everything the book has to say about it. :)
Perl TK is probably going to be the easiest way to do this in Perl. You could also look at something like wxPerl, but for something this simple, TK is the way to go. GD isn't designed to write GUIs in, it's intended to manipulate graphic files. What code do you have so far? Edit1: Doing a once-over of the documentation for Perl TK shows that most widgets implement the [Tk::options](http://search.cpan.org/~ni-s/Tk-804.027/pod/options.pod) stuff, which allows changing of attributes. Edit2: You'd want to look into using Tk::after to setup a repeating event which scans the CPUs, to call a Tk::Callback, which would then be responsible for changing the colour of the labels. Or something like that. I've never worked with it, just a couple of minutes browsing the docs. If you're still having trouble, post your code.
Okay, you're not understanding what MainLoop does, then. Once you call MainLoop, it only leaves that when your program quits. i.e. MainLoop already encapsulates the while(1) logic you did there. You need to setup everything via events/callbacks, and (in your case) a timed repeating event is what you need. See my other comment. GUI programming is event-driven. The program responds to events with callbacks.
It's a bit out of date in places, but there's a [PBP Module Recommendation Commentary](https://www.socialtext.net/perl5/pbp_module_recommendation_commentary) that you might find useful. If you ignore the bits about which modules to use, the book itself is still incredibly valuable.
Be advised that doing calculations involving real money with floating point numbers is a big huge giant no-no as floating point values are approximations of numbers, not actual values. If you're using real money, I suggest doing calculations with cents or fractions of cents as your "ones" position, not dollars. Ex: represent $1 as 100 as cents or 10000 as hundredths of cents. Once all of your calculations are done, you can then divide by 100 or 10000 in these examples to get your value.
In Tk, use $mw-&gt;update() to manually refresh the GUI instead of MainLoop, this way you can run your own event loop (or a while(1)). If you put the output of each widget(i.e Label) into a variable, you can use that variable to configure() the widget later to change its settings (make sure to use $mw-&gt;update() for changes to take effect)
True, it is a different format, but there is nothing else that comes close to PBP. I though there was a rumor of a revision, but I don't know anything concrete.
Not really. He just hid the error. The small inconsistencies are still there, and given enough time they will corrupt the values you're computing. Think like the pennies thing from Office Space. [This article](http://blog.udby.com/archives/13) talks a little about it.
So the inconsistency is just that it is rounded off? I don't really understand...
&gt;how do I deal with that? Hey, I'm just pointing out the error. If you're a student, you don't need to worry about it. When you're done with all of your calculations, you should just round off like I show you above. How do financial apps handle that? Hopefully, better than you do. But I wouldn't be surprised if they do the way you've been doing it. 
http://pastebin.com/UjuBJEFJ Did I do this right... I get no errors, but the same results when I test it both ways. Am I not seeing this because I am presenting it with the wrong situations, or did I misplace the code?
oh derp 
There, much more elegant. package Addition; use Carp; use Lingua::EN::Words2Nums; sub AUTOLOAD { (my $name = $AUTOLOAD) =~ s/^.*:://; unless ($name =~ /^ComputeSumOf(\w+?)(?:And\w+)+$/) { croak "Usage: $_[0]::ComputeSumOf###And###[And###]..\n"; } my $num = words2nums($1); my $sum = ($num)?$num:0; while ($name =~ /And(\w+?)(?=And|$)/g) { $num = words2nums($1); $sum += ($num)?$num:0; } *$AUTOLOAD = sub { $sum }; goto &amp;$AUTOLOAD; } 1; 
Sure? Make it into an array and then compare a right way around one and normal (iterate through it using a for loop).... unless im missing something
Use `substr` with a negative offset to compare characters.
I think his professor wants him to figure it out with math, which is, to answer your question, entirely possible. If I remember correctly, you have to be creative with how you use the modulo operator. It's not that your professor wants to over-complicate, I suppose he wants to show that not everything has to be done with data structures. 
Can you use `index` or `chop`?
One solution might be to use the 'pos' function in a while loop as described here: http://perldoc.perl.org/perlrequick.html#More-matching 
oh okay well no big deal, it doesnt have to be all that accurate 
http://www.perlmonks.org/?node_id=880426 but what about code like towards the bottom of this article? Would that help?
It's as accurate as it's ever going to be. The inaccuracies that we've been hunting are so utterly small that they wouldn't affect a calculation as small as yours at the precision you're looking at. I've been trying to hint that you didn't need this solution. It's close enough to do it the way you had it. If you don't see any difference when you do it one way versus the other, it's confirmed.
There you go, loop around `chop` and compare. You should be able to figure out the algorithm from there.
...well okay man, as you can see this wasn't really for my math class, it was to better my knowledge of Perl but if u are getting bored of this I can just look somewhere else
Chromatic is doing your homework. *Chromatic* /facepalm But seriously, a loop using substr to compare characters at different offsets inside the string is way easier than chop IMO, especially conceptually. Edit: And seriously.. Chromatic.. stop doing this lazy slob's homework and go be amazing.
Your next step is learning about the [nitty-gritty details](http://steve.hollasch.net/cgindex/coding/ieeefloat.html) of the [IEEE Standard for Floating-Point Arithmetic](http://en.wikipedia.org/wiki/IEEE_754-2008). Good luck
I don't really understand your constraints. Why can't you use arrays? It's not very easy to help you with such a vague question.
&gt; ... stop doing this lazy slob's homework and go be amazing. I should, but see the post about "your professor must hate you"? It must be possible to teach people how to run marathons without tying their shoelaces together and setting their jogging shorts on fire.
First time I've seen multiline commenting in Perl. Why isn't that standard?
That last subroutine is whack - here's what I've come up with, sub create_Out { my $name = shift; my $age = shift; for ( $i = 0 ; $i &lt;= scalar(@$name) ; $i++ ) { push( @output, $name-&gt;[$i] . "\t" . $age-&gt;[$i] ); } return @output; } 
Thanks, so can you explain the $name = shift, and the use of scalar(@$name)? So far these have not been covered in the class. We've covered shift and unshift but as a way of working with arrays.
$$#name should be $#$name. $name is the array reference, then you use $# to get the length of the array. I would suggest 'scalar @$name' as it's more clear (once you know that "scalar @array" returns the length of the array). Also, I would suggest changing this: push(@output, "$$name[$i]\t$$age[$i]"); I prefer the more modern and readable $name-&gt;[$i]
I thought that to, so I changed it before asking Reddit. I got an error on that line when I didn't have it as $$#name.
The line: for ($i = 0;$i&lt;=$$#name;$i++) is your problem, and more specifically "$$#name"; what you want is: for ($i = 0;$i&lt;=$#{$name};$i++) because you want to get the highest index of the array pointed to by the arrayref stored in $name. As your code stands, perl is (i'm guessing) parsing the '#' symbol as the start of an end-of-line comment, which means your opening 'for' never gets closed off properly. 
$# is not the length of the array. it's the highest index. foo &lt; scalar(@array) is never clearer than leaving scalar off... learn contexts.
shift takes the first value of the @_ array, in this case, which is usually the case, if you don't explicitly state what array you're working with. Saying something like, $name, $age = @_; wasn't working for me. Perhaps you mean, ($name, $age) = @_; Calling an array in a scalar content returns the number of elements in that array. $name is a reference to an array, putting a, "@" before the name of the reference de-references it. 
scalar(@array) is sometimes correct. adding a redundant scalar() to an expression already clearly in scalar context (the right-operand of a &lt;=) just makes the code more verbose. code that uses more to express the same thing is harder to read, as there's more of it to read. that is all.
That makes sense.
&gt; BTW I'm not sure the following will work, either: That bit should work fine. $$ref[$i] is the same as $ref-&gt;[$i]
You really should try to do things more perl-ish :) Others have already told you not to pre-declare global vars. See perldof -f open for a good way to use 'open'. OR Completely drop the whole file-stuff -- you are reading a single file and writing a single file, so why not do it with stdin/stdout? Also: Hashes might be useful. use strict; use warnings; use diagnostics; # great for beginners! my $curr_name; my %age; while (&lt;&gt;) { $curr_name = $1 if /Name:\s+\w+\s+(\w+)/; $age{$curr_name} = $1 if /Age:\s+(\d+)/; } for my $name (keys %age) { printf "%s\t%s\n", $name, $age{$name}; } hth :) 
In the old days, you'd use shift to get your arguments. Perl best practices generally say you should grab your parameters with @_ in non-trivial subroutines nowadays. It's "safer" or something. The only exception is objects with predefined opening parameters (normally $self... $self,$context in Catalyst). The idea is that you don't want to destroy the commandline arguments you may theoretically need to pass to another method: sub foo { my ($blah,$something) = @_; bar(@_); } However... as you'll see, this is not a very well-embraced best practice, and top developers still argue over it. Perlcritic will, however, kick your ass over it by default. (And perlcritic doesn't even like the $self=shift version)
You may find [PerlMonks](http://perlmonks.org) useful.
Thanks, yeah, I gathered that from some of the other commenters. I'm not used to the old array dereferencing syntax so it looked odd to me.
 Looks like everyone else has answered this already. Maybe I'm the only one that does this: &gt; open(IN, "&lt;$file") || die "Could no open file. Error is: $!" open(IN, "&lt;$file") || die "Could no open file. Error is: $!"**;** 
&gt; Maybe I'm the only one that does this: Doesn't matter in this case; just a matter of personal preference. The block-ending curly brace terminates the statement just as well as the semicolon does. (I usually write the semicolon, unless I'm writing a one-line method.)
About 960 - the web is not print media, so don't think in absolute pixels unless you have complete control of the client device.
&gt; I read this expecting some sort of gotcha. It's coming in the next post. &gt; On top of that, perl has always supported polymorphism between hashes and arrays with assignment and access. It's only adding 'use strict' that disables this functionality. Can you give an example? I can't think of what you might mean.
This is ingy being funny. "orz" is an emoticon signifying kneeling down and putting your head to the floor in admission of total failure. Sometimes you have stuff in your code that you know is total failure, but keep around for some reason or another. So, to admit what it is, you use orz. (Also, please read the code and test cases next time when a perl git repo is linked.)
lol gotcha. Meta perl humor &lt;3
Sure, here are a few examples. Assignment of a hash by defining as a list. Polymorphic because odd numbered commas acts differently between a hash and an array: my %hash = ( 'key1', 'value1', 'key2', 'value2' ); print $hash{key1} . "\n"; That is you wouldn't expect to do this on array assignment: my @array = ( '0', 'value1', '1', 'value2' ); Nor this: my @array = ( '0' =&gt; 'value1', '1' =&gt; 'value2' ); And get this: ('value1', 'value2'). In both cases, you get an array that looks like this: (0, 'value1', 1, 'value2'), making the ',' and '=&gt;' polymorphic. Above hash functioning as a list (polymorphic because when doing this with an array indexes aren't present, only values): foreach (%hash) { print $_ . "\n"; } EDIT: Removed miscellaneous code that wasn't relevant to the point, added explanations as to why the use is polymorphic. EDIT 2: Thinking about it more -- especially with the foreach example -- I would argue that the new use of each that you describe is not polymorphic but instead consistent.
&gt; Polymorphic because odd numbered commas acts differently between a hash and an array.... The assignment operator is polymorphic, not the comma. All of these create the same lists: 0 .. 10; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10; 0 =&gt; 1, 2 =&gt; 3, 4 =&gt; 5, 6 =&gt; 7, 8 =&gt; 9 =&gt; 10; ... and so on. &gt; Above hash functioning as a list... I say `for` always imposes list context, no matter what its operands (an aggregate, an expression, a scalar, a list). I'm still not sure what any of this has to do with `strict` though. &gt; I would argue that the new use of each that you describe is not polymorphic but instead consistent. That's a fair argument, but it's problematic as of 5.14, which I'll show in the next couple of posts on my site.
&gt; The assignment operator is polymorphic, not the comma. I made a mistake on the specifics, but overall agree I agree it's the = that is polymorphic. &gt; I say for always imposes list context, no matter what its operands (an aggregate, an expression, a scalar, a list). Right, but the list context between an array and a hash are different. As I previously stated, the array only includes its values while the hash includes it's keys and values. To be consistent, foreach on %hash should be equivalent to foreach (values(%hash)). &gt; I'm still not sure what any of this has to do with strict though. On that I'm mistaken. I was remembering another behavior that strict has (preventing coercion of array references into hash references). &gt; it's problematic as of 5.14, which I'll show in the next couple of posts on my site While it's your site, I would argue that you should have presented the entirety of the argument in one post, not fragmented it into multiple posts or alternatively ended on questions about where the issue can lead a developer. In this way, you keep the reader interested.
&gt; To be consistent, foreach on %hash should be equivalent to foreach (values(%hash)). It's not as easy as that. `for` doesn't do anything special to a hash; it imposes list context. Should a hash evaluated in list context produce only its values? If so, you break: %copy = %original; The same goes for a hash in list context evaluating to only its keys. You could go the Smalltalk approach and add methods to hashes and arrays to perform cloning, shallow copying, and assignment, but then you miss Perl's pervasive list processing. The question of consistency is always complicated--it's about what you want to be consistent and where.
Interactive calculation. Finally something that resembles the capabilities of HP calculators.
&gt; No, you get an array that looks like ('value1', 'value2'). Maybe you should have tried running that snippet first: use Data::Dumper; my @array = ( '0' =&gt; 'value1', '1' =&gt; 'value2' ); print Dumper(@array); Output: $VAR1 = '0'; $VAR2 = 'value1'; $VAR3 = '1'; $VAR4 = 'value2'; In PHP you would get an array of 2 values. &gt; [Your other stuff +] Hashes and arrays are different - why shouldn't you expect the constructor to behave differently? The whole point I'm making -- that is that polymorphism already exists in perl between lists and hashes. In the OP's link, he makes the claim that the new behavior of 'each' introduces polymorphism between the two. I'm stating that it's been there all along.
you are completely misunderstanding the relationship of arrays, hashes and lists. stop it.
You are completely misunderstanding my point. The OP understood my point a while ago.
&gt; In the OP's link, he makes the claim that the new behavior of 'each' introduces polymorphism between [lists and hashes]. Not at all. I wrote that `each` is no longer a monomorphic operator with regard to its single operand. That has *nothing* to do with how you construct hashes or arrays and absolutely nothing to do with lists. (`each` takes a single operand, so it has nothing to do with lists.) &gt; In PHP you would get an array of 2 values. Sure, but I'm not talking about PHP or Lua here because they're irrelevant.
I conceded that a long time ago [here](http://www.reddit.com/r/perl/comments/r3sbc/inadvertent_inconsistencies_each_in_perl_512/c42qkk6) -- that is that it is actually the = operator that is polymorphic.
He didn't trust his operating system to keep the filesystem coherent.
Remmy states that *"No, seriously, the compiler uses heuristic rules because the syntax is too ambiguous"*, this is essentially like saying Perl uses common::sense to compile the Perl code. First of all, is Remmy right? I did some quick Googling, but didn't find anything that spelled it out for me (I'm at work after all). If this is the case, how does the Perl interpreter accomplish this? I'm intrigued.
interesting... i feel like i'm analyzing the lord of the rings or something here.
Unless you know how it works.
Google [kupdated "5 seconds"](https://startpage.com/do/search?q=kupdated%20%225%20seconds%22). Possibly the guy encountered some weird buffering issue at one point in his job related to that, and then rather than understanding the problem and the right way of solving it, just kept doing the wrong thing out of habit and fear of breaking things. Kind of like how I've waded through so much DBI code that uses $sth-&gt;finish *everywhere*. (Hint: You don't need to call that method unless you're actually going to reuse that statement handle -- and no, overwriting it with a new call to $dbh-&gt;prepare doesn't count as reusing it).
I'm not sure how or why, but Perl corrupts your soul and you can never go back. Oh, the detail that everything works like a list is fucking awesome, example: my @array = ('house', 'good', 'fuck', 'yeah'); my %hash = @array; this causes %hash to be { 'house' =&gt; 'good', 'fuck' =&gt; 'yeah' } it's more awesome than I can make it sound though :(
Ever since I started using Perl, the commands "perl (-e|-ne|-pe|-lane) " have snuck their way permanently into my command-line toolset. Powerful (and fun) stuff.
I think one of Perl's strengths is how it demystifies some highbrow programming concepts. Features which seem impenetrably dense when you read about them in other languages are right on the surface of Perl, and you may be using them already without knowing the names. Object == namespace. Closure == scope. Web applications operate by taking strings as input and return strings as output, and Perl's strong string processing abilities make it a natural fit for this sort of thing. Plus its speed in getting something up and running as a proof-of-concept keeps development fun for me.
Obviously, the guy increases the number of seconds every time there's a new smartass telling him he should remove those sleep()s. I would do the same just to mess things around a bit without apparent reason :) 
&gt; It's insanely awesome that It's also awesome how inconsistent Perl can be. For example, sort() can take SUBNAME for it's operations, but map() and grep() can't. I don't know what's the reason behind this, but I don't like it.
That's more or less my story, except I came from a linguist background :)
Sane (not UCS2) Unicode support.
Larry?
For newbies, it might be a killer feature. That's fine. I'll take the clunky syntax until Perl gets a real MOP on which MOOSE might be built. And why do people always forget about [The Perl Data Language](http://pdl.perl.org)?? For me the true killer feature is that there is ONE interpreter and that it from the syntax on down, is tied to Unix. 
It's one of the few languages where you can (and I do, every day) write one-liners, short sysadmin scripts and enterprisey modules with unit tests and argument validation. There's a module for everything on CPAN. It's got one of the best testing ecosystems around. A brilliant community. Moose. Great unicode support. And so on...
Perl was designed to supersede older unix tools like sed, awk and sh, therefore, Perl is very good for text processing and shell scripts. 
Well, map and grep also take an EXPR, which sort doesn't. Other than the comma, what's the difference here? sub timestwo { $_*2; } my @r = map timestwo, (4,5,6); If you need to pass $_ lexically for some reason, sub timestwo($) { $_[0]*2; } my @r = map timestwo($_), (4,5,6); The only difference being how variables are passed, which is fine in this context. With `sort`, if you are customizing it, you are probably going to be using special-purpose subroutines, which is why it does a special thing when `sort`'s subroutine has a prototype of `($$)`. map and grep are much more general, so making that kind of assumption (that you are going to be writing special purpose subroutines to call map and grep with on a regular basis) is premature. I can't think of many times when it would be useful to pull out map or grep logic into it's own subroutine declaration. With map, you can also do `map divide(1,$_), @list`, which you can't do (nor would you want to do) with the subroutine call of sort. TL;DR - sort *does a different thing* than map or grep, and it's semantics optimize *it's* common use case. They might be similar, but they're also different.
Well, I agree with your conslusions, but a lot of syntax in Perl is used for a lot of different things ("{...}" as code block or anonymous hash, for example). As for the comma, you sometimes tend to forget comma, so why use it at all? (OTOH, comma is needed when we pass code block to map, and not subref.) I'm saying for similar usage patterns, things tend to be similar in Perl, except for this with "map/grep vs. sort" thing.
The comma is needed because an EXPR is not a subroutine name. Without the comma, what does this mean? my @r = map wtf (4,5,6); With map and grep, since you can put an arbitrary perl expression there, and are not just limited to a subroutine name, that parses as `map wtf(4,5,6);` and results in a "too few arguments to map" syntax error. sort does something much more limited than map or grep does. You can't expect things that do different things to have the same interface. map: apply code or expression to each element of a list, using the result to create a new list. grep: apply code or expression to each element of a list, returning the elements for which the code or expression was true. sort: sort list, taking an optional piece of code to do the comparison, applying it to pairs of elements of the list, and conforming to a very specific interface (either have a prototype of ($$), or explicitly refer to package globals $a and $b in that code, and returning &lt;0, 1 or &gt;0). Why would you expect these things to have the same interface? ___ Edit: Where are you getting this subroutine reference/subref thing from? The code that that guy above posted -- `my @saints = map &amp;flagellate, @sinners;`? `&amp;flagellate` is not a subref in perl. The `&amp;` isn't necessary in that call, `map flagellate, @sinners;` would work fine (assuming that inside `flagellate`, something is operating on $_). That's not a subroutine reference being passed at all, it's an expression that is getting evaluated. `flagellate()` is getting called once per element, with `$_` getting set to that element.
The community, the community, the community.
Why do you need the MOP to be built into Perl?
Also perl -pie, for filtering with a backup. Because who doesn't like pie?
You should look into IO::File, once I started using it, I never went back to "open".
&gt; Why would you expect these things to have the same interface? Why not? I mentioned in another comment: it's the same usage pattern: "perl_func optional_func_name @some_data". What happens under the hood is not of the concern here. map/grep vs. sort are radically different in how they handle user data, of course, but the reason this version would be nicer is the syntax consistency and nice "functional programming approach". After all we don't call other functions differently on different data they accept. 
There is something about Perl that just seems intuitive. If I felt that something should work a certain way; before picking up the manual, I would try it. It is surprising how often it would work. I have developed a bit of a English to Perl converter in my internal monolog. Example: $_ is the variable that contains the result of the previous line, whatever that is. But I always think of $_ as the English word "it". So I'm debugging, and I want to see the result of a line, I just "print it". print "$_ \n";
No, it's not the same usage pattern. map: arbitrary code operating on each list element, returning new element, called n times. grep: arbitrary code operating on each list element, returning boolean, called n times. sort: comparison operating on two elements, returning -1, 0, +1, called up to n log n times. How are these the same thing? &gt; "functional programming approach" Buzzwords are not useful as a touchstone for good language design. The nice thing about perl is that it takes common use cases and makes them easy and simple to do. So you can say things like `sort backwards @list;` -- because the kind of thing that `sort` does is so constrained, you can optimize it's semantics for common use cases. This is why Perl is so nice. The common things are easy, and the rare things are possible. Trying to hammer misguided consistency into the picture will only make things less clear. &gt; After all we don't call other functions differently on different data they accept. I can't figure out what that's supposed to mean. Numerous tools in perl have different syntax depending on what you pass them. Even basic things like print/say. use Path::Class qw(file); my $x = "string"; my $y = file("string.txt"); my $z = $y-&gt;open("&gt;"); say $x; say "$x"; # same thing say $y; say "$y"; # same thing, probably not useful say $z; say "$z"; # same thing say $z, $x; # works, probably not what you want say "$z", $x; # same as above say $z $x; # probably what you're after say "$z" $x; # boom, syntax error 
Plenty of things kill perl for me.
Curly then?
I don't know that Moose is a necessity, but I don't think OOP is a necessity in general. I'm interested in your reasons why.
https://metacpan.org/module/English
Not saying it needs to built in, just redesigned to make things like Moose more efficient.
&gt; Edit: Where are you getting this subroutine reference/subref thing from? I'm sorry, I typed too fast without real thinking. 
yeah, Moose can kill.
Because the first argument is arbitrary perl expression, perl needs to know when that expression ends. What would you do in the case I posted above? sub wtf { "wtf$_\n"; } my @result = map wtf (1,2,3); Since there are no `{ }`'s, it's clear to perl this isn't a BLOCK. So it's an EXPR. Where does the EXPR (an arbitrary perl expression) end and the LIST begin? 
wantarray, not wantsarray. I personally consider this practice an abomination.
yes. but you have to be extra-accurate not to shoot yourself in the foot with something like if ($h{}{})
Everything has its trade-offs. It's easy to jump in with Perl, you can do things. You can have the stuff done. But often you have to know what you are doing, double-check your understanding using small tests, know what not to do. You continue learning new things using Perl everyday. And that's fun.
Why is that trouble? `sort`'s subroutine/block is also optional, whereas it's not optional for map or grep. Is that also trouble?
I agree. Saying Moose is a killer feature is a bit overkill. Perl is multi-paradigm; OOP is just a single paradigm. If you include Moose, you basically have to include all other paradigm enabling technologies.
Ever since I learned Perl I dropped out of high school, got a job as a programmer, quit that job and got a better one in NYC. I'd say that's a killer feature.
I agree. The fact that Perl, despite being ridiculed and pronounced dead, have inspired many other languages, including Ruby and PHP, is a testimony of its power and usefulness. 
Perl used to be the "it" language back in the early- and mid-1990s, when there were few competitors. The landscape is significantly different now that we have other (more!) popular and arguably equally powerful alternatives like Python, Ruby, the .NET languages, and so on. Many of the features listed in this discussion, like: * powerful regular expressions * hashes * topical variable ($_) * one-liners (-e, -le, -p, -s, -n, -i, etc) * huge repository of libraries * list assignment * map/grep/sort * large community have been pretty much duplicated; some even become standard feature. And some other so-called killer features of Perl listed are not very useful to me, like: * scalar/list context (source of some subtle bugs and confusion for beginners) HOWEVER, here are the areas where I think Perl still has some edge in: * Regular expressions. While many RE features (like non-greedy matching, named captures, look-ahead/-behind, etc) have become standard, Perl continues to explore new features, including: recursive matching, code assertion, expressions, allowing things like Regexp::Grammars. These features are not common yet in other languages. * CPAN. While Python and Ruby are catching up fast in number of modules/distributions, CPAN enforces more naming standard and uniformity. There exist more infrastructure and tools surrounding CPAN, like CPAN Testers, RT, metacpan.org, BackPAN, Dist::Zilla, that make CPAN all the more useful. There are no equivalents for something like CPAN Testers in Python and Ruby, I believe. In short, Perl is an ugly but practical language which encourages brevity, expressiveness, reuse, modularity. Some languages maybe are prettier, stricter, more popular nowadays, but Perl gets the job done, quietly without much fuss. It has enough quirks (due to its age) but are consistent and flexible enough. Try it, after a while you'll love it. 
Yea but once you consider all the quirks together its really quite symphonic.
If you really want to do that, [go right ahead](http://perldoc.perl.org/Tie/RefHash.html). 
...and yeah, he's a piece of work for sure. Wow. Well, he won't be trying to recruit me, at least (build/SCM engineer...).
you'd have to do scalar @horses not $horses ;)
No problem, it happens to the best of us.
Web Archive has snapshots of his site: http://web.archive.org/web/20070325154029/http://www.holophrasticenterprises.com/completed.html This is one of the sites running on his "Pipelines". The source is a thing of beauty: http://www.gstconferences.com/ The funniest part: Most of the Javascript and CSS he inlines on the frontpage is inline in EVERY page of that website. Each page is about 160 kbyte to download, just for resources which could easily be shared.
If I hit caps-lock before I fall asleep with my arm across the top row of keys, I wake up with perfectly functioning code!
The guy just keeps digging himself a bigger hole in the comments, yikes. He has absolutely no clue what he's doing.
He's still writing '80s-style Perl, so let him have his joke from 1988.
eval. Oh gods, eval. Check this crazy shit out: http://poe.perl.org/?POE_Cookbook/Dynamic_Loading I have event loop style perl daemons, where I can swap out 99.9% of the code, while it's running. Add new code, bug fixes, live patching. I've got CLI environs where I can suck in live data sets into ram, and add/edit the code to process it interactively, without ever (intentionally) stopping the process.
For one extra byte on the calling side you could have skipped all that and wrote `my ($a) = param;` instead. The function itself would be optimised into an inline list constant too without all that code in the way.
This is my favorite: while(&lt;&gt;) { # do stuff; }
threads::shared ...the fact that we can still run 5.8 in production 
I wrote a review of Chapter 15 on my blog about a year ago - http://blog.urth.org/2011/03/reviewing-perl-best-practices-chapter-15-objects.html I was considering doing some reviews of other chapters, but as always, I'm suffering from a tuit shortage.
Thanks - sorry for the (major) mistake. I've corrected the post
thanks - sorry for replying to your good advice with some incorrect additions - I've corrected my post!
I mean, c'mon - this is perl! :). But I'd bet it results in some debugging mysteries.
Explain the insulting salary range then.
Consistent behavior across platforms. Try that w/ sed or awk.
&gt; I frequently wonder if the NoSQL movement isn't really about people who don't get how to write SQL. However, it seems to work, and the different engines have clear benefits for various situations. It's true. NoSQL does have some spectacular performance and other benefits in some small set of use cases. Sadly, the people that love the nosql stuff seem to think the set of use cases is "whenever I see an Oracle installation!"
well, if, "uname" is, ;TRUNCATE tabl You'd probably be pretty screwed. 
I see. I did omit them at first, since they would be redundant, but I added them here anyway. Point taken. Sidenote, I know some SQL, enough to inject simple things to see if they will break my code, I thought that was enough for my simple example here. I will look into more complicated SQL once I'm better with perl ( which could be a while from now..)
That resulted in a wrong username error, did not erase my test table
Here's how to not get injected. http://bobby-tables.com/perl.html
Dear god yes. I tried to use python once, but I had to maintain 2 different versions due to libraries I needed not being backwards compatible. With that kind of administrative nightmare I'll probably never leave perl voluntarily.
Probably not. DBI doesn't run the second query. 
You could give [Data::UUID](http://search.cpan.org/~rjbs/Data-UUID-1.217/UUID.pm) a try.
&gt; but I can't figure out how to make sure it will never be created again. Store the created IDs in a table.
Use a UUID. Seriously. If you need IDs, use a UUID. Always.
An iterative version might look like this: #!/usr/bin/env perl use strict; use warnings; chomp( my $input = &lt;&gt; ); my $result = $input--; while ( $input &gt; 1 ) { $result *= $input--; } print $result; 
Personally, I tend to prefer modules that are frequently maintained, over those that maybe haven't been updated for a long time; it depends though.
[CPAN Testers](http://matrix.cpantesters.org/?dist=Test-TCP-1.15)
naaw im learning casually
You might get some extra points for doing it like this use strict; use warnings; my $factHash= {0 =&gt; 1}; sub factorial { my $int=shift; $int= 0 if $int &lt;= 0; if (!defined($factHash-&gt;{$int})) { $factHash-&gt;{$int}= ($int * factorial($int - 1)); } return $factHash-&gt;{$int}; } you could even throw away the $int= 0 if $int &lt;= 0; line. That is just professional programmer's paranoia showing
can I have an explaination of my $result = $input--; while ( $input &gt; 1 ) { $result *= $input--; I don't really get all of it... 
Lots of good points made. I also tend to go with the one that works for me. It's an in depth process. ;)
I've thought of this but there's no way to make sure it's unique.
those tutorials are mostly old and out dated.
Did you look at those google results? The very first result is http://perl-tutorial.org , a site that has the mission to inform seekers of which perl tutorials are currently up-to-date.
Wait a few months for daylight savings time to end!
Wow, why are we both being down voted? UUIDs are a good idea. The chance of two people receiving unique ID is also abysmally low if you MD5 their username and epoch time of request. It's certainly not the best idea I know but it's a simple solution.
The [MetaCPAN leaderboard](https://metacpan.org/favorite/leaderboard) might also be something worth checking out.
Unix time! 
Sometimes there are real advantages in not following certain "best practices". What are the advantages of not using a version control system?
You were downvoted because it's bad advice. Coming up with a half-assed solution yourself that "might be good enough" is Bad when the work is already done for you. In your example: Epoch time is 1 second resolution. You have now limited a single username to not creating more than one session per second. If that username is in use by more than one person (i.e. a company account), it will blow up if two people log in at the same second from different browsers. That kind of stupid bug that you'll spend 2 days tracking down is why trying to invent your own scheme for this kind of thing is a waste of time, both your time as a programmer, and everyone else's time when it fucks up.
thanks...I dont know what HTH LOL and A/S/L are but I hope they aren't mean
This is actually a really hard problem. I have been toying with it since around 2007 when I started Task::Kensho which tries to build a kitchen-sink Perl distribution. Several people here have mentioned several attempts at solving, as well as several tools that as a by product provide useful information. Unfortunately in my experience these tools are flawed beyond utility. Things like the MetaCPAN leader board and the Perl reviews site are both open to severe gaming without a lot more manual curation than the community seems ready to provide. While tools like CPAN testers has a lot of noise in the quality signals because of its primary goals. Additionally to the difficulty in producing good tools, the actual problem domain is hard. The things that I consider quality markers in a distribution other people don't, and things that they may consider mandatory are things I not motivated by. That is to say honest opinions differ on how to define quality, and there is no single simple way to rectify that. The answer I think is to figure out how to get the proper level of human curation for different major opinions on module quality. This is what I started with Task::Kensho but a community is a hard project *too*.
Less overhead for one thing. And if you are the only person working on a project, most of the "advantages" of source control quickly become overhead.
Do you mean if I have it split like this: @arr = ('VAR', '$HOME/dir'); $ENV{$arr[0]} = $arr[1]; Then %ENV has 'VAR' =&gt; '/home/mylittlefnord/dir'? **Edit** Just tried this, and it didn't work.
Sorry, I thought those were lines of a shell script. Aside from the question of why you're reading in a shell script and attempting to parse it's variables... There are two basic approaches you can take. Attempt to re-implement the shell's variable substitution scheme yourself (taking into account variants like ${HOME}, which are valid in bourne shell-derived shells), or simply farm it out to the shell to do. The latter is much easier, and the best solution is situation-dependent. You could open up a pipe to a shell process, feed it lines, and after each line send it either an echo command, or the command 'set | grep "\^VAR="', etc. If you want to re-implement the variable substitution logic yourself, there isn't going to be an easy magic way to do it. You're going to have to parse the line to see if there's something that looks like $([\w_]+), and then replace it with $ENV{$1}, with all the hidden assumptions and stuff that that's going to entail.
Okay, if the format is a well known format that just *looks like* a shell script, doesn't have all the weird crap that a real shell script has, and is basically a subset of the sh syntax, then it's easy. $line =~ s/\$(\w+)/$ENV{$1}/g; It all depends on what that input format actually is. If it's an actual shell script, with all the support for all the weird stuff that can be in an arbitrary shell script, you're better off using a shell to interpret it. If it's just a simple format that's a strict subset of shell variable assignment syntax, it's easy.
Yeah I threw something similar together. I'll post it later after I tighten it up.
I was specifically responding to &gt; Then use the date and time. As far as I know, they never repeat. &gt;&gt; Wait a few months for daylight savings time to end! Unix time doesn't change for DST or timezones or any of the funny things we do to to our calendar and time. I understand the advantage of using a UUID across multiple machines. Also, UUID's are not the end-all-be-all of IDs. Something like https://github.com/twitter/snowflake is also an option. However, for simplicity's sake UUID's are the easiest. 
Try: use lib 'C:/strawberry/perl/lib';
UTF-8 is a horrible headache to keep track of in Perl 5. So don't, and keep all that charset-mangling code at the I/O boundary where it's probably already done for you in another module.
Now it says. Server error! The server encountered an internal error and was unable to complete your request. Error message: Attempt to reload WebService/Browshot.pm aborted. Compilation failed in require at C:/xampp/htdocs/phpbrow/test.pl line 3. BEGIN failed--compilation aborted at C:/xampp/htdocs/phpbrow/test.pl line 3. , If you think this is a server error, please contact the webmaster. 
$_ is the default variable, too, so your print $_; could be written as simply print; Which I think's even better :) Especially since with 5.10 you can do say; (say's like a print, but it puts a newline on the end. Many times my `print;` ends up being `print "$_\n";` to make it more readable.
They're not normally referred to 'aliases' but as 'special variables', so you may find more info if you search on that. Here's a good place to start: http://perldoc.perl.org/perlvar.html
'cpan WebService::Browshot' from your command line to install browshot
I used that command line to install browshot. It works fine from the command line but when trying to execute from a website it does not work.
Does xampp have it's own perl?
Still says error line 3.
Some notes: in the "Decoded Text" box the downgrade operation can fail (i.e. if the string contains code-points outside of the latin1 range.) in the "Encoded Text" box the downgrade operation may need to be performed in order to interact correctly with some XS extensions.
~~Well, your browser will parse the file from there, but you won't have a CGI infrastructure underlying the service of the file so perl execution probably won't work unless there is some kind of windows magic involved.~~ ~~I'm pretty sure you need to stand up a web server and do this from within that.~~ Edit: Ok I just took a closer look at your screenshots and this *is* within an Apache server, so that's not an issue. I would recommend you just start troubleshooting. Start with a Hello World script and work your way up from there. Some things to pay attention to will be what your environmental variables are and once again file permissions. Did you ever verify that the entire strawberry/perl/lib/ directory structure, with the Webservice subdirectory and Browshot.pm file, was public read? (both directories AND files must be public read). If the script doesn't have the permission to read that file then it won't be able to load the module.
I suppose that Apache uses Perl installed with xampp. This means that you need to install any cpan module there. Or configure Apache to use Srawberry.
I don't understand why this works from the perl command line but on the apache server it doesn't. Here is a screenshot of the permissions. [http://imgur.com/jHMSK](http://imgur.com/jHMSK) When I uncheck that read only box it reverts back to read only for some reason. I repeated these permission steps for the strawberry folder / perl folder / lib folder / and webservice folder. Browshot uses the JSON libary and URI::Encode library. Do I need to set permission on those folders also? Also, how come when I use cpan JSON it installs the perl script into c:/strawberry/cpan/build ? This code below prints this "Hello from ActivePerl CGI!" &gt;#!C:/Strawberry/perl/bin/perl.exe # previous line added to support Apache 1/2 # please adjust to your own Perl path! use strict; use CGI; my $page = new CGI; my $msg = "Hello from ActivePerl CGI!"; # print header and start the markup output print $page-&gt;header( "text/html" ),$page-&gt;start_html( $msg ); print $page-&gt;h2($msg); print $page-&gt;end_html; # end code
Personally I use something a bit more plain. MyMod.pm: package MyMod; use strict; use warnings; sub GetMsg { return 'Hello world'; } 1; test_MyMod.pl: #!/usr/bin/perl use strict; use warnings; use MyMod; print MyMod::GetMsg(), "\n";
Can you pastebin the whole script as it currently reads? http://pastebin.com/ Looking at your original screenshot, you just needed to remove the '/WebService' from the path on line 2, but I don't know what changes you've made now.
[test.pl](http://pastebin.com/TshSUdbG) [browshot.pm](http://pastebin.com/0kSX9Fh5) I changed perls. Now I am using active perl and my perl path is c:/perl instead of c:/strawberry. Still only works from command line. I think chorny and cisco are right about it being xampp using its own perl instead of the one I want it to use. I don't understand why this is the case if on the first line of test.pl I indicate the path for the perl directory I wish to use. When looking how to change the perl module in xampp it looks very complicated ;(. Everytime I edit the httpd.conf file the webserver refuses to boot.
Probably easier to use our @EXPORT = qw(add multiply); instead of our @EXPORT_OK = qw(add multiply); Which would then mean the script itself only needed to use use My::Math; I'm sure there's a point at which the code's big enough that only selectively importing has some value (maybe someone with a more in-depth knowledge than me could say when) but I reckon for something small it isn't worth the bother. Unless you're writing pretty big libraries as modules, there's a good chance any script using the module's going to use all or most of the exported subroutines anyway.
yeah if i go to my gmail and type in 1234567890@vtext.com it works fine
Gmail is misbehaving somehow, it's not setting the recipient despite accepting it. $VAR1 = { 'addr' =&gt; '1234567890@vtext.com' }; $VAR1 = { 'num' =&gt; \'250', 'txt' =&gt; \'2.1.5 OK i7sm15473027igq.11' }; It's accepting it (250), but if you look in the outbox of your gmail account, you'll see a message that lacks a recipient. This is on gmail's end, it doesn't like that address for whatever reason, but accepts it anyway.
exactly! the thing is, if you do it for an att number, gmail accepts the address but then sends them a message, but if you do it for a verizon it messes up
I also favour brevity and simplicity. However, I would never go as far as to remove `use strict` and `use warnings` from my code. That's just asking for trouble. 
Nevertheless: NEVER use -i without backup. Had my *ss bitten enough times in the past. 
I'm not sure you can figure the odds that way You buy 1 ticket your odd are 1 in 175711536, that leaves 175711535 numbers you didn't pick. Buy another ticket your odds are 1 in 175711535, not 1 in 87855768.
It's bad style (people will point and laugh, and maybe even call you names) to use strict and warnings but then not use "my" variables. You're using the globals $a and $b which are magically predeclared for sort(). If you're going to use $a and $b, "my" them, and use the block scoped version.
It seems like that, but according to probability it is correct. Probability vs. combinatorics is where you're getting hung up I think.
My immediate guess was that `$str2 = reverse($str1);` reverses the order of characters in the string (DWIM). Reading `perldoc -f reverse` confirms. Even works with list arguments: `$str = reverse($strA, $strB,...);` 
People write bad code like this because they tried this once and it failed: $ perl -E 'say reverse "string"' string They mumble something under their breath about how it must only work on lists, so they create a list from the string, reverse that list, and then implicitly join it back together, which appears to work: $ perl -E 'say reverse split //, "string"' gnirts They get it in their head that this is how you have to use reverse. But their original problem was that they used `print` or `say` which provide list context, and `reverse()` works differently in list context. They should have forced scalar context: $ perl -E 'say scalar reverse "string"' gnirts And ironically, assigning to a scalar is another way to provide scalar context (obviously), and so if they had tried their original version with an assignment instead of a `say`, it would have worked there too: $ perl -E '$reversed = reverse "string"; say $reversed' gnirts So the moral of the story is they're doing things that are wrong and less efficient because they didn't understand the original problem that they were faced with. Perhaps the author is making a metacommentary on why context-sensitive functions are dangerous.
Thanks a bunch :) Edit: it worked! i'm sure you knew it would but for me it was very exciting, thanks again for helping me get off the ground.
&gt;You buy 1 ticket your odd are 1 in 175711536 That's a probability, not an odds. EDIT: Your _second_ ticket has a 1 in 175711535 probability (not odds!) of winning, iff (that's if-and-only-if) your _first_ ticket has no probability of winning; for example, if you know it has all the wrong numbers already or however Mega Millions works, then it can't possibly win. But you don't know that. All you know is that you have 2 tickets out of the total possible of 175711536 tickets, so you have a 2/175711536 = 1/87855768 probability of winning.
... I did use my didn't I?
 my $b = (175711536 / $a); and chomp (my $a = &lt;&gt;); thats what u mean by 'my' right?
I didnt realize that was still left in. I was trying a different method and my brain just decided to work $x in for some reason. But I got rid of it thanks!
No need to say sorry. We're all learning.
Hmm, I checked the lin kwhen u posted that and they were there and I didn't make any edits, but i'm also pretty certain that you are being sarcasic so I will end this comment here.
what is this I don't even...
Well, Im sorry to say but the real world is different from the internet and I, personally have the control to keep them separate, so I have no qualms shortening a word.
Suit yourself.
Similarly hash slices are pretty rad too. 
If you're going to continue to lie to yourself and others, there is nothing I can do or say that will help you learn to program Perl.
Is Renzo Piano related to Lorenzo Music?
&gt; This is perl, v5.10.0 built for x86_64-linux [...]
These were Debian Stable and Debian Testing by the way. I was being sarcastic, I don't get the bug.
The bug manifests with 5.10.0.
I'm pretty sure comments don't run through the compiler, so never worry about having too many comments. It's not slowing your script down any. Code readability is important though. A good read if you're interested in "doing it right" is a book called "Perl Best Practices". I really liked the sections on code commenting / formatting.
I wasn't trying to lie, I genuinely looked without editing it and saw that the 'my's were in there and I was not trying to start a conflict, so please I don't really want any of this, I'd be willing to just give up this silly thing if you are...
When you're ready, level up to an ORM like DBIx::Class. Whole new head trip!
Easy. Doing this for a second company right now. Pure perl will "prove" in $WORKSPACE simply. If you have database access, you have a little more fun, but about as much as you have with tests in general. As mentioned, TAP::Formatter::JUnit is nice and gives you purty graphs. You might want to separate out real code tests from "scaffold tests" like test coverage, benchmarking and Test::Perl::Critic. For your front end guys, running selenium tests in CI is also really helpful. And if you code to branches, set up CI for branches too!
It's a pity it's not serious enough to backport.
Uh, it was backported. Perl 5.10.1 has it fixed. :)
Oh, duh. I thought this was another "Everyone should be using 5.12" article but the OP gist is talking about a maintenance release, which I assume is 5.10.1 :)
yes they are, though they don't come out naturally to me yet
You can only (afaik) share data between threads by using one of the following modules threads::shared Thread::Queue For all perl threading related questions you can't go wrong with the official [perl thread tutorial](http://perldoc.perl.org/perlthrtut.html) What are you doing that requires data shared between threads? Edit: example #!/usr/bin/perl use threads; use threads::shared; use Test::Simple tests =&gt; 2 ; my @threads ; my $a :shared = 1; my $b = 1; push( @threads, threads-&gt;create(sub { $a++; $b++; }) ); push( @threads, threads-&gt;create(sub { $a++; $b++; }) ); $_-&gt;join for @threads ; ok($a == 3, 'foo was incremented by both threads - it was shared') ; ok($b == 1, 'bar unmodified as not shared') ; 
Yeah I ususally have to look them up, and I'm almost a veteran. 
Ah, Thanks! Let me give this a go. The reason why I'm wanting to fork()/thread() is because I have an open file handle to an external program that actually loads and play's MP3s. Unfortunately that file handle requires constant supervision or the external program becomes unresponsive :/.
&gt; is possible to multiply a given string by a variable amount, within a string substitution. Yes. One way is to use the 'x' operator to multiply a string and if you want to do so within a substitution then use the "e" modifier which means the substitution performed is really code (even calls to subs). while(&lt;&gt;) { s/(\S*)\s(\d+)/$1 x $2/e; print; } Example input: "foo 3", Output "foofoofoo" &gt; could I have made a substitution that matches numbers only if they do not have brackets around them? Why not just put a conditional around the substitution? while(&lt;&gt;) { if ( ! /\[\d+\]/ ) { # skip [%d] s/\d+//; # replace \d } print; } Edit: Upon further reflection. You asked for "a" substitution, so (using look ahead and look behind) what about the following. It's a little bit looser than what you asked for but should be sufficient. # preserves [\d+] and [\d+ and \d+] but removes all other \d+ while(&lt;&gt;) { s/(?&lt;![\[\d])\d+(?![\d\]])//g; print; } This works and does exactly what you asked but it isn't elegant # preserves [\d+] but removes all other \d while(&lt;&gt;) { s/(?:(\[\d+\])|\d+)/defined($1) ? $1 : ''/ge; print; }
There is Sphere online judge, http://spoj.pl. This lets you implement the functions in many languages and also compares you to others
I'm not threading graph generation - I'm threading rrd population to many (around 100) rrd files. Obviously RRD population is generally IO bound by the disk, however I'm populating from a database. My thinking was having multiple threads querying the DB at once and populating RRDs should give me a bit more performance than sequentially querying and updating
Use processes instead of threads, you can manage them yourself with fork and a sigchld handler, but there are also many frameworks to make your life easy. The penalty is a bit more memory use and more connections, but performance is likely to be better if anything.
Personally i prefer this shorter version: #!/usr/bin/env perl use utf8; # so literals and identifiers can be in UTF-8 use v5.12; # or later to get "unicode_strings" feature use strictures; # quote strings, declare variables, fatal warnings use open qw(:std :utf8); # undeclared streams in UTF-8 use charnames qw(:full :short); # unneeded in v5.16
This is guaranteed to work with the forth coming examples and other cookbook code?
Yeah, it only shortcuts the warning fatalization and makes all of them fatal.
Moving to forks did it - thanks!
Thank you, your rhomboidy goodness. I will give it a try. Actually, I'm passing in the string to search for into the csh script. So is this going to work if I put it into a c-shell script? #/bin/csh perl -nE 's/\s+$//, say if /$1/' input.txt where $1 is the first parameter passed in to the csh script.
Shell variables do not expand inside of single-quoted strings, so that's always going to be the literal value `/$1/` which will never match. To have the variable expand, you need to exit from the string, expand the variable, and then continue the string: perl -nE 's/\s+$//, say if /'$1'/' input.txt However, if `$1` contains a space this will do the wrong thing; you really want all variables to expand inside of double quotes, which keeps them as single words by preventing word splitting: perl -nE 's/\s+$//, say if /'"$1"'/' input.txt Or, you could use double quotes for the whole thing, but then you have the problem that you need a literal `$` in the perl fragment, and in csh there's no way to get a literal `$` in a double-quote context, so you'd have to escape out, switch to a single-quote context for the `$`, then end the single quote context and switch back to double-quote context: perl -nE "s/\s+"'$'"//, say if /$1/" input.txt This would also be problematic if you needed double quotes in the perl fragment. Fortunately perl provides an alternative form of double quote context (`qq`) which you could use in that case. But there's another problem here: that `$1` is being expanded into the context of a regular expression. Regular expressions have their own syntax, for example `.` does not mean a period but "any character." If you are writing this script to search for plain keywords, then you probably want to escape any regular expression metacharacters, which perl lets you do with `quotemeta()` or the `\Q` and `\E` operators. perl -nE 's/\s+$//, say if /\Q'"$1"'\E/' input.txt Whether or not you need this is up to you. It's not generally a good idea to allow user-supplied input into a perl regex unquoted, because perl regexes have extreme power and can include embedded bits of perl code. 
If there were one, it could probably be condensed to -1 lines.
Best I can do: Did you hear a guy got fired at a perl conference? Handing out ID badges he asked if a woman wanted a perl necklace with that. Incidentally, I had no idea what a pearl necklace was.
Have fun meeting with HR!
Thank you. Odd that I never was notified of your replies. Also -E is not valid for Perl 5.8.8. So I used -e: perl -ne 's/\s+$//, say if /'"$1"'/' $filename &gt;&gt; temp.txt Which still doesn't work. Why am I using the subsitution thing s///? I just want to match a string. Shouldn't I use m//? 
Awesome thanks!
What you need to do, if you want to follow this through instead of using either Parallel::ForkManager or a thread pool that's already been written, is poll for finished threads with `threads::list`. Something like: do { if (my @joinable = threads::list(threads::joinable)) { # possibly do something useful with the result here $_-&gt;join for @joinable; $running -= @joinable; } } while ($running &gt;= $MAX_THREADS); 
Nice thanks! I will play with this with my pre fork manager code.
I don't think you really want to start 5k threads. I would use a Thread::Queue and have a fixed number of threads each pull tasks from the Queue until it's empty. It would be easier to just use xargs though: ls |xargs -P20 -n1 -i rsync {} user@host:/tmp
Thank you! This works. My problem is one of my datafiles had like 50-80 extra tabs at the end of each line (thanks Excel) and was making messy output from the more command. Yes, my input file was a tab-delimited file exported from Excel. Very common in my job. 
Okay, if you have *actual data* that suggests running more rsyncs in parallel does indeed increase performance, then disregard my other post. The part about threading still stands - you're not sharing memory between any of the rsync processes, so threading is overkill. Just fork each one and be done with it. Besides managing forks is easier than managing threads (in Perl).
I am open to other ways. A push in the right direction would be great. This code is ruining my day. By the way, I removed the second "OUT" instance and now it opens, sits for a minute, and closes without ever writing to the log (Not that it was before)
Well your print statements don't actually print to that descriptor, they just print to screen (stdout). You have to say 'print OUT "text";'. But if you must. Let me write it out real quick, no testing, no debugging, no compiling, so excuse typo's. use IO::Socket::INET; my $file = 'iplist1.txt'; my @ips = (); open(my $IO, $file) or die "Unable to open $file: $!"; push @ips chomp($_) while(&lt;$IO&gt;); close $IO; open(my $LOG, '&gt;&gt;logfile.txt') or die "Unable to write to logfile: $!"; foreach my $i (@ips) { my $socket = new IO::Socket::INET ( PeerHost =&gt; $i, PeerPort =&gt; 81, Proto =&gt; 'tcp' ); if($socket) { print $LOG "$i:success\n"; } else { print $LOG "$i:failure\n"; } } close $LOG; 
Yes, this is pretty much what I'd do, too. Only your line push @ips chomp($_) while(&lt;$IO&gt;); is pretty far off the mark. what you mean is while(&lt;$IO&gt;) { chomp($_); push @ips, $_; } 
Ya know, this being /r/perl I didn't even put thought towards a non-perl solution.
I didn't forget about 1 line loops, but the return value of chomp is the number of characters removed. However I *do* like your last version. I've never thought of using chomp on the whole array. This is quite elegant :) BTW, if we're nitpicking: use 3 argument open ;) 
Anyone interested in the DBI module should read the docs available on the [DBI CPAN page](http://search.cpan.org/~timb/DBI/DBI.pm). It's also a good idea to read the docs for the DBD module for the database (i.e. MySQL, PostgresQL, Oracle, CSV, etc) you are using. Not all database drivers support all features available in DBI.
Not sure why you need to telnet to the port. Here's one I've been using for ages: #!/usr/bin/perl -w # # portping - ping a TCP port on a server, ssh by default. # Perl, Unix/Linux/Windows... # # This program works by trying to establish a TCP connection, no ICMP # is used. This can be useful in senarios where everything but ssh # has been blocked by firewalls. # # 23-Jan-2006, ver 0.65 # # USAGE: portping [-h] | hostname [port] # # -h # print help # hostname # host to TCP ping # port # port number to use (default is 22) # eg, # portping mars # try TCP port 22 (ssh) on mars # portping mars 21 # try TCP port 21 on mars # # There are currently no advanced options for port scanning or different # TCP flags, as there are many existing freeware tools to do this. # portping is designed to be a simple handy perl script. # # # SEE ALSO: nmap (port scanner), hping2 (super ping) # # COPYRIGHT: Copyright (c) 2004 Brendan Gregg. # # 25-Mar-2004 Brendan Gregg Created this. # 23-Jan-2006 " " Tweaked style. use strict; use IO::Socket; # # Command line arguments # my $host = defined $ARGV[0] ? $ARGV[0] : ""; usage() if $host =~ /^(-h|--help|)$/; my $port = defined $ARGV[1] ? $ARGV[1] : 22; # default port # # Try to connect # my $remote = IO::Socket::INET-&gt;new( Proto =&gt; "tcp", PeerAddr =&gt; $host, PeerPort =&gt; $port, Timeout =&gt; 8, ); # # Print response # if ($remote) { print "$host is alive\n"; close $remote; exit 0; } else { print "$host failed\n"; exit 1; } # usage - print usage message and exit # sub usage { print STDERR "USAGE: portping [-h] | hostname [port]\n"; print STDERR " eg, portping mars # try port 22 (ssh) on mars\n"; print STDERR " portping mars 21 # try port 21 on mars\n"; exit 1; }
Also this: http://cpansearch.perl.org/src/TIMB/DBI_AdvancedTalk_2004/index.htm
I've done the same thing for monitoring a load of machines. I don't do the checking for an existing error in the appender. I drop a unique file for the alert in a temp dir and check for that and it's age before calling $logger-&gt;warn() or whatever. 
I'd leave the job of monitoring log files to Nagios. 
I would suggest swatch. It's written in perl and is used specifically to watch logfiles and trigger on lines that match things. It does duplication checking and things like that so it might have everything you need covered. This also allows you to break your process into multiple logical units. You have a monitoring daemon that just monitors, and an alerting daemon (swatch) that just alerts.
Hmmm...isn't that INSERT going to fail because he defined "pw" as NOT NULL and doesn't pass that in with the INSERT stmt? The UPDATE will also fail because the field is "pw" and not "password".
Yeah, maybe a custom filter that just maintains an MD5 hash for each recent event would work.
&gt; ... the best programming related book I've ever bought. Wow, thanks!
I thought that Conway's Perl Best Practices is the best programming related book...but then I read Effective Perl Programming and now there is a battle inside my head for the first place.
Yes, and it's been for quite a while.
I'd heard people talking about Cucumber but I hadn't taken a look at it before - now I see just how ridiculous it is. No wonder I'm drawn to Perl, with its refreshing (and apparently uncommon) down-to-earth approach to things!
To be fair, the implementation and focus of Cucumber are ridiculous. The BDD approach of "organize of your tests in terms of behaviors" is good advice.
Perl 5 was Larry's vision alone, and it was implemented on top of Perl 4, a code base he and the implementers knew quite well. Perl 6, on the other hand, was designed by anarcho-committee and it's being implemented from scratch mostly without reference to the Perl 5 source by a number of interested volunteer parties. By design, it's more modular than any interpreted language I know of. There are no public timelines, no set of publicly-interpretable milestones, and no pressure to complete the project. Larry gave Perl 6 a long row to hoe, no ox, and no switch. And that's how it'll be until someone comes along and donates a diesel tiller.
&gt; Perl 5 was Larry's vision alone, ... Perl 6, on the other hand, was designed by anarcho-committee At first, yes. But my understanding is that Larry eventually resumed design leadership duties of the commune. So, right there it sounds like that's one of the things that prolonged the Perl 6 development timeline. There was a plot a while back -- I think Audrey Tang made it -- showing highs and lows of the Perl 6 development timeline. The Perl 6 community needs an updated one of these. It would explain to everyone the blind alleys that have soaked up development time over Perl 6 history. &gt; And that's how it'll be until someone comes along and donates a diesel tiller. Not sure I buy this. Perl 6 has some talented and prolific developers implementing it. 
Cucumber is used for integration tests and is designed to be read by non developers as test cases. The methodology is outside-in development - BDD (Behavioural Driven Development) The example provided in this site's example, would be better written in Rspec (unit testing) as describe "The thing you are testing" do it "does something wonderful" do As an ex Perl developer, Ruby and its tools (Cucumber, RSpec, SASS, HAML), not to mention how nice Ruby is to develop with, make web development a much nicer experience. When I look at Perl now, I really don't think I could ever go back to it. 
&gt; *Perl 6 has some talented and prolific developers* ***who have day jobs*** *implementing it.* Maybe I'm talking out my ass on that one. I sit here ready to be disproven. I will know that Perl 6 has gotten serious about Perl 6 when I see a timeline that has "feature complete" and "first bugfix release" on it, for any of the Perl 6 engines. I mean, give a man or a woman a project without a deadline *with teeth*, and he or she will have no incentive to make the hard decisions that are necessary for an actual release. Personally, I don't expect to see the first bugfix release until 2025.
&gt; To complain that it is not serious is an insult to the people who have been working on it. I wanted to deploy a real product to real customers based on Rakudo Star's first release in April 2010. Two years later, it's not appreciably closer. I was happy to be an early adopter, but for my purposes it's still not a real product.
&gt; Still though, what sorts of hard decisions do you think Perl 6 leadership is failing to make? To start, the decision to create a timeline that contains a stable, production-ready release. 
&gt; By the way, I have Good Newsâ„¢! Perl 6 is in a state usable by someone such as yourself! Perl 5 has received many backported features from 6 Well, in the first place, why would I want to use backported features and not write Perl-6-qua-Perl-6? Seems to be defeating the purpose, unless Perl 6 has solved all of Perl 5's performance issues. In the second place, there is no standalone implementation of Perl 6 that is as stable and production-ready as, say, Perl 5.004. &gt; what exactly do you expect to get out of Perl 6 anyway? I expect to get the same thing I got from Perl 5 over Perl 4, namely, the easy things stayed easy, the hard things got easier, and many impossible things got just hard. I'll bet you've heard that one before, though. &gt; Sorry if I'm being overly sarcastic but when you insult the developers I think you are being a little oversensitive here.
The ol' "meritocracy" argument, eh? You need to earn yr right to have an opinion on Perl 6, or at least to express it publicly. This might be valid if FLOSS were a democracy, but it's not. I don't actually have a say in the direction, administration, or philosophy of Perl. My opinion is just that. If you see something worthwhile in it, then run with it. If not, then why spend so much time arguing about it, if you truly believe in meritocracy? I don't really give a shit if you don't care about my opinion, because I'm not going to hold back on yr account. I do, however, wish these kinds of discussions could stick more to the facts of the matter, rather than arguing over who is being rude and whose feelings are being hurt, blah blah blah. We're all big boys now, right?
&gt; ... he can complain all he wants because he put in a genuine investment and got burned. I think anyone who believed that Rakudo Star would be a "useful and usable subset of Perl 6" *two years after its initial release date* has the right to feel disappointed and misled, as well as the right to wonder just what its developers have been doing in the meantime.
I still think performance is an issue. Not so much when you write simple scripts, but module loading is dog slow and takes the fun out of developing bigger programs. Another thing that's certainly lacking is documentation. Finally, there's a big problem with perception. Even people who are really interested in Perl 6 haven't yet realized that the specification and also the compilers have reached a certain level of maturity. There are areas that won't change anymore (the basic controll structures, variable declarations, most scoping rules, many OO features etc.), but this fact hasn't reached many people. Probably because it wasn't announced officially anywhere. And probably because too many people, especially on the perl6-language mailing list, are still attached to the idea that Perl 6 can be fundamentally re-shaped by their ideas.
I left Perl 3 years ago. And what do you mean, what did I use? Which version of Perl? I think I got to 5.10. And over the last 3 years, I've kept my eye on Perl's developments and have played with Perl 6 but I still can't imagine going back. This is only my opinion, it's funny how people get upset about others' opinions. I see you get an upvote by asking me your question thus defending Perl. It is sad if we can't critique other languages without getting downvoted and what not. I'm not saying Perl is a bad language, not at all, and I've done very well as a Perl developer, but for me it was time to move on. As for tools, in my 13 year career as a Perl developer, I think you can imagine I've use a wide range of them (Embperl, AxKit (developed a good website with that) and associated technologies, all the way to Catalyst with associated technologies (templating systems and ORMs). I know Perl is starting to develop drivers for the Cucumber DSL but I really do feel the momentum is with Ruby/Rails with regards to web development. Again, just my opinion. Surely I'm entitled to that. And programming in a pure OO language is so nice. edit: You have no idea how much I miss CPAN. 
You should have a look at autobox::Core - you can write Perl like Ruby, read the code from left to right, and more
Neither defensiveness nor attack intended; I was just curious. I've tried to use Cucumber and RSpec and found them tedious and ineffective. De gustibus non est disputandum.
&gt; Even people who are really interested in Perl 6 haven't yet realized that the specification and also the compilers have reached a certain level of maturity. Including hash flattening rules?
Then don't use Cucumber. The tool has a specific functionality and I wouldn't use in your example. In your example, I would use RSpec or Test::Unit. There's no hard and fast rule when to use either, it's a matter of taste/style but as I said, for your example, I certainly wouldn't use Cucumber. You could also use RSpec for your integration tests (using the same web drivers as Cucumber), if you wanted. I prefer Cucumber for integration tests even for projects I work on alone.
&gt; Why do people take it so personally? Read carefully: *I understand the following concern*. Note that I do not claim this belief myself. Some people believe that Perl 6 kneecapped and hamstrung Perl 5 and continues to do so by neither shipping something usable nor getting out of the way.
&gt; But do people really want a backwards-incompatible revision of Perl 5? I do, and the Perl 6 RFCs show that even as far back as August 2000 other people did. The other problem is one of *perception*. How do you argue with someone who says "Why should I use Perl 5? I thought Perl 6 was supposed to replace it *twelve years ago*. It's dead."
&gt; C with Classes took 13 years to become C++. Maybe you're thinking that thirteen years passed between the introduction of C (1969 or 1970) and the renaming of C with Classes to C++. (Or maybe you're thinking that it took 12 years for Cfront to die out.) C with Classes became C++ in *four* years (1979 - 1983). The first C++ book came out within six years (1985). Around the same time, the first commercial implementation came out. Within 12 years of Bjarne's first work, the official language standard was underway.
&gt; Is a number all that's standing in the way? Not in the sense that renaming Perl 6 would solve anything right now.
Last time I checked, angle brackets were the short form of qw(): my @a = &lt;a b c&gt;; You can also do double angles for variable interpolation (think single versus double quotes). my @b = &lt;&lt;$a $b $c&gt;&gt;; qw hasn't gone away, either, according to [Synopsis 2](http://www.perlcabal.org/syn/S02.html#Angle_quotes_%28quote_words%29).
The blog post is good, but you shouldn't try to judge how clean a language is from this kind of blog post. There are some few features that look a bit more verbose or even less clean in Perl 6 than in Perl 5, but since other, nicer idioms are available for doing common tasks, you won't need them often at all. A "here's how you do Perl 5 stuff in Perl 6" blog post usually won't express the new, clean idioms very well. Instead take a look at http://rosettacode.org/wiki/Category:Perl_6 which has examples of problems solved in Perl 6, along with slutions in other languages. It should give you a better idea of how the language feels.
Completely loaded question! I was wondering what it is about Perl, design-wise, that makes it perform so poorly against other languages? Obviously, it wasn't built to compete head to head with C but I was wondering if there was room for improvement (whether or not you think such charts are a good idea).
Why do you say it's slow? All the major dynamic languages (Perl, Python, PHP, Ruby) score in the same approximate ballpark on most tests, with a couple of outliers. That's just the nature of dynamic scripting languages. Edit: direct comparisons: - [Perl vs. Python](http://shootout.alioth.debian.org/u32/benchmark.php?test=all&amp;lang=perl&amp;lang2=python3) - a wash in speed, Perl wins in memory. - [Perl vs. Ruby](http://shootout.alioth.debian.org/u32/benchmark.php?test=all&amp;lang=perl&amp;lang2=yarv) - a wash in both memory and speed - [Perl vs. PHP](http://shootout.alioth.debian.org/u32/benchmark.php?test=all&amp;lang=perl&amp;lang2=php) - a wash in memory, perhaps a slight speed advantage to PHP 
Thanks as always Dugen. I will try to get on tonight, been doing SOW's for work.
I want to thank 'avuserow' for the comment regarding &lt;&gt; as qw. I'm going to update my post. Cheers!
They're bundled, compiled code. If you have a goood [FFI](http://en.wikipedia.org/wiki/Foreign_function_interface), you *might* be able to call them
You may also have some luck with the Inline modules. A quick guess would suggest maybe [Inline::MonoCS](https://metacpan.org/module/Inline::MonoCS) may work, or simple Inline::C. 
The naked diamond operator will check @ARGV for files over which to work, only looking at standard input if @ARGV is empty. An element on @ARGV that isn't a filename will generate an error when &lt;&gt; tries to open it. &lt;STDIN&gt; explicitly reads only from standard input.
I'm not new to perl and even I didn't know that! UPVOTES FOR ALL!
To elaborate, as dannywoodz has said, &lt;&gt; will consume all the files passed as arguments. This is exactly like unix command line commands works. For example: &gt; sort file1 file2 read all the lines in file1 and file2 &gt; sort read the lines from STDIN Using "&lt;&gt;" in you Perl script you can emulate this behavior with minimal effort.
&gt; To elaborate, as dannywoodz has said, &lt;&gt; will consume all the files passed as arguments. Not just as arguments! The fact that it operates on `@ARGV` and not the arguments that also get copied into `@ARGV` is really useful, for in your sort example, why not make it a function? sub sortmany { local @ARGV = @_; sort &lt;&gt; } Or maybe you want a multi-file slurp: sub cat { local @ARGV = @_; local $/; &lt;&gt; } 
 getopts('sgh:', \%args); Is telling getopts to expect a value after h (because of the colon in your getopts after h). If you './script -h' the value after h is null, which populates %arg like so $arg{h} = undef So your if statement is evaluating the undef to false and not executing the code within it. For -s getopts is not expecting a value to follow it, so if the script is called with -s it just sets the value of s in %args to 1. $arg{s} = 1 Which in the if evaluation would equate to true. The population performed by getopts can be seen in action using Data::Dumper - [example](https://gist.github.com/2376376) *edit - reworded some guff
Change: getopts('sgh:', \%args); To: getopts('sgh', \%args); If you want help to be a bool like s and g. h: tells GetOpts that h requires an argument. You may also want to look at Getopt::Long if you want more control over input. EDIT: When I started typing my response there were no replies. I got distracted and fact_hunt provided a better answer before me. 
This may not be the best way to do it but I'd make the following changes: Original: if (($args{s} == "rectangle") || ($args{s} == "re")){ New: if( ($args{s} eq "rectangle") or ($args{s} eq "re") ){ '==' is numeric comparison; any string evaluated in numeric comparison evaluates to true, that is the right hand side of each comparison is true, any string could be in those "". The if statement you have will (almost) always evaluate to true; as it is saying essentially 'if anything is true' Using numeric comparison when you need string comparison and vice versa will lead to problems! *edit formatting
Thank you so much kind sir for your help.
For the same reason, I include unique identifiers in error messages: Your transaction could not be processed due to a charge card error. [E103] This makes tracking them down a bit easier for me. 
Just re-discovered this accidentally yesterday. I've been used to using -- to abort getopt and find this to be a simpler solution.
 Listen to this man!
Makes my head hurt. 
I've been guilty of doing that string concatenation thing on more than one occasion. I'd use perl5 heredocs all the time if they had the perl6 "virtual left margin" feature; without it they're pretty unwieldy to use for stuff where they're output verbatim.
Use [Mail::RFC822](http://www.ex-parrot.com/pdw/Mail-RFC822-Address/Mail-RFC822-Address.html)... uses the same obnoxious regex internally, but much simpler to implement. use Mail::RFC822::Address qw(valid validlist); if (valid("pdw@ex-parrot.com")) { print "That's a valid address\n"; } if (validlist("pdw@ex-parrot.com, other@elsewhere.com")) { print "That's a valid list of addresses\n"; }
IMO, the ugliness of Heredocs is a very high price to pay for this benefit. 
&gt; how is this an argument for anything in this case? You asked how `$#` is magic. In my example, I tried to show the same, for *some* value of magic (in the sense that the value of `$#` is affected by an unintended or unknown modification of `$[`). Whether it's usage is deprecated or not is irrelevant.
I'm biased... I've written patches for Email::Valid. Thankfully I didn't have to even look at that regex though :)
Good to be teaching someone the language and the testing at once but, even though this is a very basic example, shouldn't there be something about how to separate test and code? A large part of good code is code that can be maintained etc
Thanks. I'll change my example to have a binary.pl which defines the function. And then a binary.t like below. Is this ok? require "binary.pl"; use Test::More; is( binary(0), 0, "0 : 0" ); is( binary(1), 1, "1 : 1" ); is( binary(2), 10, "2 : 10" ); is( binary(3), 11, "3 : 11" ); is( binary(4), 100, "4 : 100" ); is( binary(5), 101, "5 : 101" ); is( binary(6), 110, "6 : 110" ); is( binary(7), 111, "7 : 111" ); is( binary(37), 100101, "37 : 100101" ); 
Why YAML::XS and not a smaller dependency like YAML::Tiny?
Is the strict module on your box still?
Thanks for the reply. I'm not sure how to go about verifying. I performed a find / -name 'strict' and nothing came back. I'm running Ubuntu 10.4 LTS.
Sounds like you somehow lost the strict module which probably lived in /usr/share/perl/5.10/strict.pm. This is a core Perl module and in theory this type of problem shouldn't happen(tm). What is your OS and version? Try the command `locate strict.pm` to see if the locate database has an idea where it was/should be and then check that strict.pm is really there and has sane permissions. My cross-fingers and hope it works fix for something like this would be to re-install the latest Perl packages from /var/cache/apt/archives/perl* and if that didn't work try the older versions. This is from my Debian sid so the versions are 5.14.2 instead of 5.10.x but the general idea should be the same. $ cd /var/cache/apt/archives $ ls perl*5.14* perl_5.14.2-5_amd64.deb perl-doc_5.14.2-5_all.deb perl_5.14.2-6_amd64.deb perl-doc_5.14.2-6_all.deb perl_5.14.2-7_amd64.deb perl-doc_5.14.2-7_all.deb perl_5.14.2-9_amd64.deb perl-doc_5.14.2-9_all.deb perl-base_5.14.2-5_amd64.deb perl-modules_5.14.2-5_all.deb perl-base_5.14.2-6_amd64.deb perl-modules_5.14.2-6_all.deb perl-base_5.14.2-7_amd64.deb perl-modules_5.14.2-7_all.deb perl-base_5.14.2-9_amd64.deb perl-modules_5.14.2-9_all.deb $ dpkg -i perl_5.14.2-9_amd64.deb perl-base_5.14.2-9_amd64.deb perl-doc_5.14.2-9_all.deb perl-modules_5.14.2-9_all.deb That is pick the latest set of Perl (ver, base, doc, modules) packages that you have cached from previous apt runs, and re-install them. If it doesn't work go back to a previous version (i.e. 5.14.2-7). Cross your fingers and that should at least get Perl back to working enough for apt-get to work again. Then I would check your distro forums for problems and such. Like did this breakage happen just after apt-get updated Perl? If this fixes the problem and you apt-get update,upgrade again does Perl break again? Maybe you just fat-fingered an rm command and deleted some important Perl modules by accident (or some other program did).
In which case I'd say follow the advice of zengargoyle, paying particular attention to the finger crossing part
Seems like apt-get had to have broken it. I am using Ubtuntu 10.4 LTS. When I do $ cd /var/cache/apt/archives $ ls perl*5.10* The only file in that folder is, perl-doc_5.10.1-8ubuntu2.1_all.deb
i supposed that YAML::XS works faster
If essential system files are randomly disappearing, you may want to confirm you don't have any kind of nasty filesystem corruption happening.
For future reference, questions like this are better asked on stackoverflow.com since it's a dedicated Q&amp;A site, gets more eyeballs than /r/perl and you can post something with multiple tags (in this case "perl" and "ubuntu") so that multiple communities can help out. In this particular case, I'd check to see if for some reason strict.pm was put into another package. Some distributions try to make the core perl package as small as possible, even moving core essential modules into a different package.
http://easybuddy.blogspot.com/2012/01/run-perl-script-as-windows-service.html
This is not a question for stackoverflow.com, try superuser.com.
There's also [sprunge.us](http://sprunge.us) (uses `curl` too).
Well, duh! &gt;&gt;Iâ€™ve made a Perl almost-clone of sprunge.us
I ignored all text on the page outside of the code block, as any good programmer would do.
 no strict 'refs'; my @modules = qw(foo bar); foreach (@modules) { print ${$_.'::variable'}; # prints the namespace variable, requires no strict refs $_-&gt;function(); # calls the namespace function }
Regarding your second question, even though an array of pairs is possible â€“ see this example: % perl -MData::Dumper -E '@a=([1, 2], [3, 4], [5, 6]); say Dumper \@a' $VAR1 = [ [ 1, 2 ], [ 3, 4 ], [ 5, 6 ] ]; â€“ I think it would actually be a much simpler solution to just use two arrays, one for the A values and one for the B values.
First of all, `$i_max` is never defined anywhere, so things like `foreach $i(1..$i_max)` run zero times. But even if we pretend that these loops did run, a scalar variable can hold only one value: foreach $i(1..$i_max) { # calculate $x1 and $x2 $error = abs($x1) + abs($x2); } This overwrites the value stored in `$error` each time through the loop, which means essentially that all your calculations except the `$i` = `$i_max` one are discarded. And similarly here: for ($i=0; $i&lt;$i_max; $i++) { if ($error &lt; $error_best) { $error_best = $error; $lambda_best = $lambda; $cro_best = $cro; This is just running the same code over and over; none of these variables ever change, so this loop does nothing. (Even assuming that `$i_max` had some value.) Edit: Also, as far as I can tell, nothing in your inner calculations depends on `$t` or `$i`, so this is just thrashing over and over computing the same thing repeatedly. 
A set of tools that I have used for some time embodies this idea pretty well. http://www.isi.edu/~johnh/SOFTWARE/FSDB/index.html Its a set of command line tools for doing "data base stuff" on delimited text files. The cool thing about it and about debugging stuff that is processed with this is that each tool adds a "provenience" to the data file as it is processed. So you can look at a data file and understand how it got to be the way it is. 
That... is a horrible way of avoiding adding one line to the dependencies.
The design phase for HTML 4 did not take 12 years.
For the convenience of not using a dependency, everyone everywhere using generated code has the privilege of manually updating everything. Talk about your negative externalities.
We're all going to turn away and now and pretend you didn't say that. And I'm going to pretend I didn't laugh. I wonder how many Perl devs are even old enough to get that joke :)
(links about the auto-golfer? (non-perl-hacker so apologize if its widely known))
Yup. If you aren't making your job easier to do over time, you're doing it wrong. Very wrong.
No, it makes the code smaller. :)
There are young Perl developers?
And thus sacrifices maintainability for the sake of saving a few bytes, which are cheap. Oh, and copy&amp;paste simply isn't a good way to organize code reuse.
Acme::Golf::HoleInOne sounds like a really good idea. 
&gt; If I want terrible generated code that abuses undocumented and unintentional features of the parser Actually, no, it won't do that. Think of it more as a reverse Perl::Tidy. I guess a more fitting name would be Perl::Minify, but that doesn't quite carry the ring of ::Golf.
I guess so, since I have no idea what Ovid is talking about
Thanks for this help, I have the french version of Modern Perl, and the difference is not shown. I'll use Moose and `package` as you suggested !
Sounds like your version of cpanm was the system version, and not the perlbrew version. I would say do a 'perl -V' to make sure you're using the perlbrew version of Perl, then an old-fashioned 'perl -MCPAN -e shell'. From there, 'install Modern::Perl' - it will go into your perlbrew @INC and leave the system stuff alone.
According to the latest [Perl Survey](http://survey.perlfoundation.org/Data-PerlSurvey-2010/R/), 40% of respondents were between 30 and 39 years of age. I don't know the demographics for other programming languages, though most people seem to estimate them (from what I've seen) around 25 to 35 years old. Side note: I was programming COBOL when I was thirty and I was one of the youngest programmers in the company.
Thanks for your input. According to `perl -V`, I'm definitely using the perlbrew version and it is pointing to perlbrew libraries. Both `cpan` and `cpanm` are the perlbrew versions: $ which cpan ~/perl5/perlbrew/perls/perl-5.14.2/bin/cpan $ which cpanm ~/perl5/perlbrew/bin/cpanm However, trying to intall Modern::Perl using either method results in: `Modern::Perl is up to date. (1.20120130)`. A reinstall completes successfully, but still results in the original error: `Feature bundle "5.14" is not supported by Perl 5.12.3 at /Library/Perl/5.12/Modern/Perl.pm line 41` 
OK. In progress. I'll report back when completed. thanks.
Having read through bits of the French version, I can assure you that it's not the same thing as chromatic's [Modern Perl](http://modernperlbooks.com/books/modern_perl/) (which you can download for free from his site if you can't afford it).
WOOHOO! Thanks, that worked!
Ya, it looks like my problem stemmed from installing cpanm before Perl 5.14.2. Switching the order fixed everything. P.S. Thanks for `Modern::Perl`!
We've figured out the problem, but I've used your suggestions to prove to myself that all is well. Thanks!
Nice ! I'll take a look. The french version I have is released by Pearson as _"Perl Moderne, le guide de survie"_. This book's quite good as a memo but is not at all an introduction to Perl (and _Programming Perl_'writting style looks weird for a french guy ;)). I'll try to read _Modern Perl_ as it seems to be a really good introduction to this language. Thanks
Not everyone has access to Moose.
I bless you to return to your valuable teachings.
Thank you, very nicely explained. 
You're saying that chomp(...) implies an automatic loop over the whole file? It doesn't work that way when I run it. The whitespace around IN in that line also messes with the interpreter (Activestate). What I get is a the first line of the file with all the whitespace stripped out (once I fix &lt;IN&gt;).
 my $query = &lt;FH&gt;; # $query will contain the last line in the file since it is overwritten as the file loops Where does the file "loop" ?
As others pointed out the whole file doesn't get slurped. Though it would if $query was @query. My mistake.
Thanks for the correction. 
Are you just being pedantic or what? The file is read in line by line which any layman can interpret as a loop. Sorry I'm not using the ISO standard lexicon in a forum.
There is no loop. That only and exactly reads one line from the file: the first line.
Where is this code from? It wouldn't happen to be from a job application questionaire, would it?
To answer my own question, I know Perl 6 is NOT Earl(y) Grey. I find Earl Grey gets bitter if you steep it for more than 20 seconds or so. To me Perl 6 is more like, say, Ginger tea, something that becomes more nutritious and delicious the longer it steeps...
Oh goodie, another fundamental component gets a rewrite (AST -&gt; QAST) explained as "a key part of our work towards getting Rakudo up and running on an extra back end." What do you call tea that's poured into multiple cups without ever finishing brewing? Hot water.
I'm somewhat amused that one of the authors of [Perl Moderne](http://perlmoderne.fr/), Damien Krotkine, is one of my colleagues and I worked with another one, Phillipe Bruhat, at my last job. I think Perl is a small world in France :)
For the convenience of other readers I'll quote jnthn and pmichaud more fully on QAST: jnthn: "I had a design session with pmichaud++ on QAST, the successor to our current AST. The new nodes will integrate far better with 6model and bounded serialization, give us better native type handling and be much more memory efficient due to being able to use natively typed attributes in them. This is also a key part of our work towards getting Rakudo up and running on an extra back end." And from [pmichaud's blog post about the Oslo hackathon](http://pmthium.com/2012/04/22/oslo-perl-6-patterns-hackathon-days-1-2/): "jnthn++ and I were able to spend some much needed time plotting out the next moves for the AST implementation, currently called QAST. QAST is part of the nqp implementation, and is the successor to PAST (part of the Parrot repository). Some of the refactors weâ€™ll be able to make in QAST look like they will enable huge improvements in speed, readbility, and writability of compilers in NQP."
Im sorry for last night I was a bit drunk watchig UFC and acted like an asshole to you. You are completely right.
Acceptable to whom? I'm not paying anyone to work on it. I don't understand spending so much time and effort making sure software that's difficult to install and almost impossible to keep anything running from month to month runs equally poorly on multiple backends instead of making it run well on one backend. &gt; ... the memory bloat this also addresses is a total non-issue. Getting away from recursive descent parsing (like I suggested a couple of years ago) or addressing any of a dozen suggestions I posted on the wiki a couple of years ago would also help.
Yes, I think too. You know, I started with python but perl seems to be a really nice language allowing elegant programming. This is cool.
It's easy to miss when sober, since `while (&lt;WHATEVER&gt;)` is such a common pattern in Perl.
That's encouraging, I can't get any young developers I know interested in Perl. It's all PHP, Python and Ruby for them.
&gt; You've just shot down something I presume everyone using or trying to use Rakudo today wants. I don't believe everyone using or trying to use Rakudo today wants every core component of Rakudo rewritten every 18 months just as it's in danger of becoming useful. I'm fairly certain no one in late 2010 wanted Rakudo to grind to a halt throughout 2011 for the nom transition. I'm convinced that this has does nothing to address the fact you can't rely on Rakudo as a product for end users unless you're willing to idle on IRC at least once a week and stick close to HEAD of whatever the master branch is these days. &gt; This is presumably a fair point. Presumably so. After all, I *measured* it. Repeatedly. Such that several of the Rakudo optimizations since then have been independent rediscoveries of things I'd been saying for months or years.
More variants for reds? Certainly. I think it'll need some panda improvements first though; a Perl 6 Test::Harness would be nice (volunteers? :)) Publish under some sensemaking place? Sure, once it'll be something more than a quick and dirty hack :) Blog about it? Absolutely. I'm planning to write a blog post about the hackathon today. If you want to contribute to the new project, the code that generates the website is at https://github.com/tadzik/panda/blob/master/bin/masstest
No, it's from a class. It was given by the prof., and I want to know what it's doing.
Could you define the structure of the "template.xyz" file? or better yet, just post the first couple lines of it.
Stick a while loop around your chomp and the rest of it that deals with he input from the file. That's why you're only getting the first line.
Could skip performing all those additions each time like so, though I'm sure someone else will come up with something better than this: #!/usr/bin/perl use strict; use warnings; use Data::Dumper; my %list ; my @value = qw(158322647 136908437 121408443 120786530 121183174 119454666 112628884 113367096 105695468 104301732 107282960 91131021 84229982 84628243 85276403 81720984 75148791 65999195 64044783 71992748 71573501 61379134 52465632 62685898 42879707 51680135 45402893 46248750 515028681) ; for( my $i = 0 ; $i&lt; $#value ; $i++ ){ $list{$i + 1} = ( $list{$i} || 0) + $value[$i] ; } print Dumper(\%list) ;
Much better! Uninitialised values warnings though, unless: my %list ; my $i ; for (@value) { $list{ ++$i } = ( $list{ $i } || 0 ) + $_; }
I find it interesting that you still haven't answered the question which parts to work on you find acceptable.
Ladies and gentlemen I believe we have a winner
works well however $list{1} should equal 0
I'm wondering what this is for. It seems like an array would serve you better on the output than a hash since the hash is numbered. If you throw away the requirement of the hash and the starting from one instead of 0 as your index, the code becomes simpler but might be harder for you to reference when outputting (depending on what you're doing with this) After doing some tests, it looks like some of the people attempting to do this got the offset wrong anyway (1=158322647 instead of 2=158322647) my (@list, $sum); @list = map { $sum += $_ } @value; So, print $list[0] = 158322647, $list[1] = 295231084 If you explicitly need the offset for some reason you could do something like this: my @value = qw(0 0 158322647 136908437 121408443 120786530 121183174 119454666 112628884 113367096 105695468 104301732 107282960 91131021 84229982 84628243 85276403 81720984 75148791 65999195 64044783 71992748 71573501 61379134 52465632 62685898 42879707 51680135 45402893 46248750 515028681) ; Which should work even if you keep the list as a hash table.
I think chromatic was implying that focusing on getting Rakudo running really well on one backend is good, and having it run poorly on multiple backends is not. smosher used the word "acceptable", not chromatic. It doesn't matter what chromatic thinks is acceptable, since people work on what they want to work on. I think it's a question of focus. Either the Perl 6 team is focused on one single backend and practical concerns (like getting a fast and usable Perl 6 release out the door so people can start using it for real work), or they're focused on exploration, design tweaking, and research (which is, of course, a great deal of fun). Nothing wrong with either choice. To each his own. But if the community is expecting a focus on practical matters, and the Perl 6 team is instead focused on exploration, then there's going to be misunderstandings. One option: if the Perl 6 team thinks Parrot has a future, then fork it, bring it under the Perl 6 banner, drop support for other languages, and invite current Parrot devs to join in - with the understanding that the Perl 6 Parrot is exclusively focused on being **the** Rakudo backend. Another option: If the Perl 6 team thinks Parrot does *not* have a future, then drop it and begin work on porting to some other (existing!) backend. 
Other people have already answered this, but I just want to mention this: $list{29}=$value[0]+$value[1]+$value[2]+$value[3]+$value[4]+$value[5]+$value[6]+$value[7]+$value[8]+$value[9]+$value[10]+$value[11]+$value[12]+$value[13]+$value[14]+$value[15]+$value[16]+$value[17]+$value[18]+$value[19]+$value[20]+$value[21]+$value[22]+$value[23]+$value[24]+$value[25]+$value[26]+$value[27]; is the same as: use List::Util qw(sum); $list{29} = sum $value[0..27]; If you haven't used Perl modules before then now would be a good time to start.
General rule: If you write something repetitive, it's "wrong". (Where "wrong" means "there is a better way to do that".)
Lol. The beauty is, you can include the look of disappointment right in your code. So, you can satisfy your itch just by *having* error handling in your code! No need to trigger it to achieve satisfaction.
Yo, I don't understand 90% of this.
And I'd even say: $list{29} = $list{28} + $value[27]; which will be *much* more efficient than your code, and which ought to give the OP a clue. 
Hey fabreston, There isn't a single Perl 6 team. Just as folk work on what they want to work on, they also join whatever team(s) they choose to join. Someone could suggest sorear and friends stop working on Niecza, but sorear is not going to work on one of the other compilers, so you'd just lose sorear and Niecza. A similar story applies to fglock and friends developing the perlitos, audrey et al and PUGS, and jnthn et al and Rakudo. &gt; exploration, design tweaking, and research No one is going to stop anyone exploring things and doing research. Tweaking the design is a whole different thing. To the extent it's happening, it's almost exclusively to fix things that need fixing -- features that looked great on paper but turn out to be wrong or impractical when the compiler teams try to implement them -- or adding things that need to be added -- such as fleshing out concurrency features. Finally, I think it's worth taking a closer look at the compiler team that uses Parrot as its back-end, namely Rakudo. While the Rakudo team is focused on Parrot as their back-end, practical concerns have forced them to look at their options, including the two you suggest. The strategy they adopted in 2011 was two fold. First, to try persuade the Parrot devs to focus on Rakudo's needs -- in effect to become part of the Rakudo project. Aiui they succeeded and current Parrot devs now explicitly consider Perl 6 in general and Rakudo in particular to be the only "client" that really matters for the foreseeable future for Parrot. Second, to rewrite the parts of the Rakudo/Parrot combination that were killing performance. For example, 6model, which Parrot devs have said they plan to back-port into Parrot. These rewrites will hopefully be completed later this year, at least on the Rakudo side of things. 
One of the few times I've seen a legit "use utf8;". 
&gt; Just as folk work on what they want to work on, they also join whatever team(s) they choose to join. We agree on this. But there's another factor to consider: people also tend to follow the lead of the core Perl 6 team. &gt; Someone could suggest $name stop working on $alternative_implementation ... It's not about individuals. It's about what sort of atmosphere you create, which determines what comes out of it on average. And note, I'm not saying that the Perl 6 atmosphere is bad, per se. It's great, but it's clearly focused on exploration, research, further language design, and solving interesting problems in novel ways. Unfortunatly, although fun, that focus does not lead very directly to a fast and usable Perl 6 release. &gt; Aiui they succeeded and current Parrot devs now explicitly consider Perl 6 in general and Rakudo in particular to be the only "client" that really matters for the foreseeable future for Parrot. ralph, you quoted jnthn elsewhere writing, "This is also a key part of our work towards getting Rakudo up and running on an extra back end." Why focus on an additional backend if Parrot is dedicated to Rakudo? Anyway, my point is that, fwict, the core Perl 6 team appears to still be focused on things other than practicality. And that means people who want to use it to get things done today are going to be looking elsewhere. And at some point, people stop being interested at all and just start thinking of Perl 6 as being forever in the exploratory development phase. 
&gt; I could give you a list of what I *wish* Perl 6 developers would focus on, This is what smosher is asking for. &gt; but I've done that before, multiple times, ... Well, perhaps then a link would satisfy those who are interested. 
&gt; I'm not saying that the Perl 6 atmosphere is bad, per se. It's great, but it's clearly focused on exploration, research, further language design, and solving interesting problems in novel ways. Unfortunatly, although fun, that focus does not lead very directly to a fast and usable Perl 6 release. Although this myth is understandable (why else would Perl 6 have taken so long? how else do you explain #perl6 comfort with -Ofun?), it is a myth which is hurting Perl 6. I rebutted it in my prior comment and feel disappointed that you chose to repeat it, pretty much as if I had said nothing. &gt; Why focus on an additional backend if Parrot is dedicated to Rakudo? Exactly! The hope is that [whiteknight's vision](http://whiteknight.github.com/2011/09/10/dust_settles) will pan out and Rakudo won't be left high and dry. That's probably why the Rakudo devs are NOT focused on switching the backend! That said, as they finish the rewrites triggered by 6model, they are naturally doing the work that enables extra back ends. Doing anything else would be absurd. If you still find this confusing, despite having read the post by whiteknight which I just linked, especially the part about 6model, well, please at least realize that "the core Perl 6 team appears to still be focused on things other than practicality" is about appearances, not reality.
whoa, That certainly makes it a lot easier than plain bash!
 ( 0.484 / 0.060 ) = 8.06666666 1.131 * 8.066666666 = 9.12 Both the IO test and the Storable operation are slower by the same factor on the prod machine. `prtdiag` should give you the underlying CPU speed underneath the sun4v virtual CPU. 
That makes sense. A single threaded operation is of course going to be faster on one 2.8GHz core of a higher end 4-core CPU than on 1 1GHz core of a 64-core server. 
I agree with that - but nearly x10 the difference?
Unfortunately I really don't see those changes happening. Instead I'm toying around with other ideas on how to store this huge chunk of data into smaller bits and de-normalize it. 90% of the data is not relevant to the part that's visibly slow, you just don't know which parts are relevant at the time of page loading. My other thought is to write a daemon that keeps this giant structure in memory at all times and write a communication layer to pull individual chunks out of so the file is more or less only read at daemon startup and written when changes are made.
&gt; ... it is a myth which is hurting Perl 6. Stop blaming people who aren't working on Perl 6 for the failures of Perl 6. &gt; I rebutted it in my prior comment.... Nonsense. You told an interesting story with chunky elements of truthiness swimming in a boundless sea of #perl6 party lines. Rakudo Star was to come out *two years ago*. It was to provide a useful and usable subset of Perl 6 for early adopters. Almost two years after its release, it's still neither of those. I know the #perl6 party line is "Oh, we had to rewrite several core components to improve speed" but there've been one or two *funded* developers doing almost all of that work and in that time there have been no substantial documentation improvements, no substantial packaging improvements, several rewrites of the module installer, and several cycles of invention, lack of adoption, bitrotting, bitrot rescuing, and abandonment of ecosystem components including the packaging system, external modules, and bridges to external systems such as Perl 5 and shared libraries. You can set your watch by three things: * a core component gets semi deprecated and abandoned in favor of a rewrite promised to save the world and be the last big rewrite, this time we promise * a proof of concept ecosystem piece appears, gets hailed as a great marketing point checkoff, then bitrots after a couple of releases * someone notices an artificial milestone (number of tests passing, speedup on a benchmark, clever name of the new hotness component) and gets huffy when people who'd like to use Perl 6 for practical purposes say "Why should we care about that?" But maybe I'm the only person who wanted to use Rakudo Star for something practical, who had real customers,who wanted to get real things done with programs that keep running month after month without having to track git HEAD all the time and idle on IRC to see what's broken now. ... but maybe your definition of "practical" includes "faffing about with macros and junctions" or "We're not writing our own VM, wink wink, just laying the groundwork so that someone can do it, but if someone were to do it, here's a proof of concept you could use, wink wink" rather than "Real users can write real programs that won't break on upgrades" or even "Let's try to keep the test suite passing 100%."
&gt; My other thought is to write a daemon that keeps this giant structure in memory at all times and write a communication layer to pull individual chunks out of so the file is more or less only read at daemon startup and written when changes are made. You've just described a database server.
I would guess that something like MySQL + memcached is what you should be looking at instead of Storable.
Unfortunately getting a mysql or oracle instance here is more of a pain in the ass than it's worth for this particular problem. I've also had issues coming up with a good schema for this type of data. Basically, we have X number of servers. Each server has N propertie pairs. Like "city". The number of different properties is variable, it can grow and shrink, and the data of the properties is also variable, might be a number, might be text, might be a date.
So basically, a key value store? Maybe BDB or gdbm or something similar would do the trick. Lots of easy interfaces using tied hashes available that should already be installed on your machine. 
Okay, so *any* third party servers are out of the question, or does the red tape only specifically affect RDBMS instances? Or is it okay, as long as you don't call it a DB infront of certain people? Also, regarding the schema of the data, if the data is only going to ever be looked up by a unique ID (server name, ID, whatever), then you can use an object DB or a key-value store, or something like that. The problem with those plans comes when something else needs to query the DB on other fields in the structure, or do anything other than a simple lookup on a key -- then comes the pain.
Okay, so something like Mongo is out of the question then? i.e. if it looks like a database sever, the DBAs take it over -- or do they only handle relational DB servers, and wouldn't touch a NoSQL document store? There really isn't a better solution than *some kind* of database server. It doesn't have to be an SQL RDBMS to be a database server, but something that will listen on a socket and respond to requests is going to be needed. Especially if the data is going to be updated periodically. If you have to write that yourself, you have to (yay politics), but I just forsee someone else 10 years from now cursing another homegrown database system ;-) 
They should handle that fine -- that's not really a large amount of data these days. Note that NoSQL is a very wide term -- it's a statement of what something is *not*. They can use very different technology under the hood. [This](http://www.mongodb.org/display/DOCS/Comparing+Mongo+DB+and+Couch+DB) is an (older) comparison of two NoSQL stores. Comparing them vs relational DBs isn't always a 1 to 1 mapping -- but [lots can be stored in them](http://blog.wordnik.com/b-is-for-billion).
What the hell kind of sysadmin would reject a script and prefer to do it manually?!
&gt; in [the last couple years] there have been no substantial documentation improvements That's not true. The Perl 6 equivalent of Perl 5's bible, *Programming Perl*, is [Official Perl 6 Documentation](http://perlcabal.org/syn/). While the index and Overview pages haven't changed much in 2 years, try comparing the other chapters. For example [the current S02](http://perlcabal.org/syn/S02.html) vs [the last archive.org snapshot of S02](http://web.archive.org/web/20090209223527/http://perlcabal.org/syn/S02.html). Almost all the changes, including the new look, sub-heads, and 350 content commits have happened in the last 2 years. I think the [over 400 Rosettacode examples](http://rosettacode.org/wiki/Category:Perl_6) count as doc, and most of those have been added in the last 2 years. The last 300 or so commits to the Perl 6 Book have been applied in the last 2 years. Parts of the Tablets, such as [the Tablets index](http://tablets.perl6.org/appendix-a-index.html) are shaping up. I don't think Perl 6 has a good doc story yet -- perhaps tadzik's recent integration of pod6 parsing into the Rakudo compiler is going to be a breakthrough on that front -- but **there have been substantial improvements over the last 2 years to move Perl 6 doc in the right direction**.
&gt; no substantial packaging improvements, several rewrites of the module installer, and several cycles of invention, lack of adoption, bitrotting, bitrot rescuing, and abandonment of ecosystem components including the packaging system, external modules, and bridges to external systems such as Perl 5 and shared libraries. I don't see what you see. I see what Larry calls whirlpool dev, and a nice evolution of the ecosystem. I don't see how the external lib bridge [Zavolaj](https://github.com/jnthn/zavolaj) could be much sweeter. While [the Perl 5 bridge blizkost](https://github.com/jnthn/blizkost) is weak and hasn't improved much since it was started, it hasn't bitrotted either. It awaits someone with Perl 5 guts knowledge and tuits to help out. Plans are afoot to cross link tadzik's nice [module smoker](http://tjs.azalayah.net/new.html) with http://modules.perl6.org. 
Sorry for the confusion. BS works fine in linux, and various linux editors. BS doesn't work in Perl debugger.
Yes. Perl Debugger is displaying \^? when I hit backspace.
I know. It's still terminal bullshit. (And it's still not related to perl specifically, any command line utility that doesn't set it's own terminal handling settings will exhibit this behaviour). If you're seeing \^? instead of \^H, then see if there's an option in your terminal to send backspaces as \^H (that's what it's called in OSX's terminal app). This is what happens to me when I mess around with my terminal settings: -bash-3.2$ cat type shit here then hit backspace^H^H^H^H^H^H^H^H type shit here then hit backspace -bash-3.2$ You should see \^? there instead of \^H, but same shit. Most applications which grab the terminal adjust the terminal settings. Some, especially those that are typically run by other programs (like debuggers) do not touch the terminal settings, so if they aren't set right to begin with, you get crap like this happening. As a test, does Ctrl-H work as a backspace in the debugger?
`stty erase ^H` tells your terminal to expect \^H as a backspace character. Your terminal emulator is *sending* it \^? when you hit backspace. Most terminal-using programs can deal with both. But if a program starts and doesn't do whateverthefuck it is that actually needs to happen to do that, you get this.
&gt; EDIT: I'll have to get back to you on the Exceed settings. I have a linux program running and it might take 8 hrs or more. That has to finish before I fiddle with my client settings, because when I change the client settings, the Xserver will reboot and close all my Linux windows. Which is a "Bad Thing". Ah, I didn't realize this was an X session, thought it was over ssh. Once you get the chance, you can also just try `stty erase ^?` (which should be done with this series of keystrokes: `stty erase [Ctrl-V][Backspace]`) -- that should set the terminal so it's expecting whatever the terminal is sending as backspace. You might want to look into tmux or screen. Putting an 8 hour job at the mercy of a network connection would be unreliable for me.
I can't. I have to use an Xterminal via Exceed. It's company policy. I did your stty command above at the command line. It didn't work in the Perl debugger. Does this have to be done in the .cshrc and then I source the .cshrc? Because I don't know how to enter the backspace key in nedit for the stty command.
This. =)
&gt; You are ignoring.... You selectively quoted me and attempted to knock down a strawman. Quit it.
Moritz' post also mentions that he ate Vietnamese food and generally had a good time. While eating food and having a good time is useful and commendable, it also shows something about what the current focus of the team is &lt;/sarcasm&gt; Why are *you* focusing on the hacking dojo instead of the work on Postgresql, SQLite and MySQL backends for MiniDBI or his face-to-face discussions with the other core developers (which is probably one of the most important, perhaps even *the* most important feature of such an event)?
I had a similar problem and resolved it by adding *stty erase \^?* to my .zshrc 
Whenever you offer technical help on a public forum, you are not just writing for the person asking the question, you are also writing for everyone in the next 5-10 years who will encounter the thread on a google search.
I see no `use strict;`. I think you may be onto something.
Haha I wish. Sorry about that, I meant to fix that typo and forgot. On my PerlMonks post, the author of the backend package actually responded and said he would add in the pass phrase functionality this weekend so I assume my original assumption about the backend package not being able to handle the argument was correct.
This is unrelated to your (now quite answered) question, but seriously consider using a newer perl. If you aren't all sysadmin-y and have opinions on installing perl on your system, google 'perlbrew'. It's the easiest thing ever. Might as well take advantage of the last decade of active development on perl!
From one of his other posts it sounds like company policy forces him to use ancient/bad software.
Do you think Perl 6 would finish faster if all the core hackers didn't eat during the two days of the hackathon? Or if the food hadn't been Vietnamese? Or that not having a good time would make us more productive? Or that the generally good time was not spend discussing things with the other core developers? Of all the critic I have heard of the Perl 6 development process, this is the most bizarre I've ever heard. 
I'm not quite sure if I should feel honoured of insulted that the irony wasn't obvious enough on its own. Anyway, I hope the &lt;/sarcasm&gt; tag clears things up...
And now you're going to stick with perl 5.8.8 forever?
&gt; One example is sprintf now truncates numbers, instead of rounds them. When did sprintf in Perl round numbers?
I ran the script using the sample data, redirected output with the shell, and got the expected output (no unexpected line breaks). By the way, why are you redirecting the output instead of printing to the file from the script? 
When I run that program with that input, I get this: A B C D E F A 0 4 5 5 9 10 B 4 0 4 6 8 10 C 5 4 0 4 7 10 D 5 6 4 0 4 6 E 9 8 7 4 0 4 F 10 10 10 6 4 0 I don't see any line breaks. Is this test case supposed to exhibit the problem? Is there maybe anything different between it and case that's causing the error? FYI, you can make your read loop a little simpler by using slice assignment: while(&lt;FH&gt;) { my %pointHash; @pointHash{@keys} = (split)[0, 2..4]; push @points, \%pointHash; } The `chomp` is not necessary as `split` with no arguments splits on whitespace.
Very possible. My other guess was that one version was a 32-bit Perl and the other a 64-bit Perl and the difference in precision accounted for the difference in results.
I feel the opposite: hard coding filenames in a script is the noob way, using redirection is the more flexible way, because then you can reuse your script for different purposes without having to modify it every time. Anyway, to answer your question, in modern perl it's preferred to use the 3 argument form of `open` along with lexical file handles. The second argument is the mode, which is `&lt;` for input or `&gt;` for output. Lexical file handles work just like the old-style except without the possibility for name clashes (since they aren't global variables) and they automatically close when they go out of scope. # reading open my $fh, '&lt;', $filename or die "error: $!"; my $line = &lt;$fh&gt;; # writing open my $fh, '&gt;', $filename or die "error: $!"; print $fh "Foobar\n"; But like I said, I prefer to have scripts read from `STDIN` and write to `STDOUT`. 
When I run the script with that input, [this is what I get](http://pastebin.com/raw.php?i=epT7u8nZ). There's no line breaks. I agree with the other person that this is probably an artifact of whatever you're using to view the file. 
That output is identical to my output, but unless you click on "raw", you're seeing it wrapped to the width of the screen. Those line breaks aren't in the file though. Turn off word wrap in notepad and you should see it fine. (But I don't recommend using Notepad for anything. There are plenty of real text editors out there that are free.) 
I'd argue that it depends on the context. For example, I always use a static filename for logging events. In the case here, it would make sense to write to a file if you are doing `./script &gt; output.txt` more than half the time. The times when you don't need the file you could do `./script ; cat output.txt ; rm output.txt`. Of course the reverse is also true; if you just want to see the output as STDOUT most of the time, it makes more sense not to write to a file. If it's a toss-up, you could always write to STDOUT and a file.
"Bad" may be an unfair characterization. I worked on the project because I wanted to use it productively sooner rather than later. I stopped working on the project because I believe the project management decisions emphasize having fun and doing interesting things and seeing what might happen eventually over delivering a useful and usable product for end users. (Okay, I was also tired of cleaning up messes other people made and taking the blame for their mistakes. That's all I'm ever going to say about that too.)
ahem.... I've used notepad to generate quite a lot of code in my lifetime. I do not think there is anything unreal about notepads ability to edit text. 
I submitted a pull request on GitHub with some minor changes. Should help readability for someone who didn't write the script. My favorite features: * Extremely well-organized (Makefile and README!) * Good documentation * Succinct all around And dude, don't worry about your English. It's the lingua franca of the internet and we're all trying our best. ;)
Perl version 5.4 sprintf("%.2f",$x) used to round floating point numbers. Now Perl 5.8.8 sprintf truncates numbers. 
Thanks for the response, but I might need to solve the problem as described in the OP. 
&gt; Look who *wrote* that code sometime. History of rewrites. I'm curious what you're getting at. Where should I look? I picked [oo.c](https://github.com/parrot/parrot/commits/master/src/oo.c) as a starting point, but browsing its history shows little evidence of rewrites, so I'm guessing I'm not looking where I would need to look. Btw, even if I knew where to look, I don't understand what I'd be looking for and why it would be relevant. Aiui the problem in 2010 is that a rewrite was needed and wasn't happening; why would the presence or lack of prior rewrites make any difference?
&gt; I'm curious what you're getting at. 6model is Rakudo's fourth or fifth object model, by my count. &gt; Aiui the problem in 2010 is that a rewrite was needed and wasn't happening Multiple Parrot developers were ready and willing to revamp Parrot's object model to help Rakudo. By my count, at least three. &gt; ... why would the presence or lack of prior rewrites make any difference? At some point, you start to believe that the [CADT Model](http://www.jwz.org/doc/cadt.html) is in effect.
That's because splitting on a number makes no sense at all. Perl will turn it into a number, then split it on that, which will make it into the string "16". You need to split on a string or a regexp, so either split /\020/ split /\x10/ split "\020" split "\x10" 
Crosspost at http://www.perlmonks.org/?node_id=967985
Interesting idea. I'll probably take a look at that soon. Thanks !
Merged ! Thanks !
Not sure why all of my comments are getting downvoted...I thought it was a legitimate post/question. the author of the Net_SSH2 backend package has already updated (super awesome guy btw) the code to handle the passphrase argument and can be found here [Net SFTP Foreign Backend Net_SSH2] (https://metacpan.org/release/SALVA/Net-SFTP-Foreign-Backend-Net_SSH2-0.09). With the update, the above test script works. I fixed the typo in the code as well so if anyone would like to use it, you should be able to copy it and insert your variables and it should work, although I copied most of it off of random post on different sites. 
Wow, lots in here for me to ruminate on. Many thanks.
He's talking about RHEL5, which is still officially at 5.8.8. `screen` is in RHEL5, so it's a simple matter of installing the (supported) RPM from the OS vendor. *I'm* currently stuck using 5.8.8 in production on RHEL5, and we are able to have screen installed on all of our production boxes (because it's a supported part of RHEL5), so yes, he should have access to it. Now, his company politics may get in the way, but asking for a supported RPM to be installed from the distribution he said his company uses is not "ignorance".
&gt; Now, his company **politics** may get in the way... What exactly do you think company **poilcy** is?
I meant what I said. I would very much doubt that installing a supported RPM from their OS vendor is against company **policy**. It is, however, often the case that developers aren't given any ability to get things installed in production easily because of **politics**.
Like I said, ignorance.
Are you attempting to claim that organizational politics never enters into bullshit like this?
Doesn't even need perl for what he's attempting. Using `bash`, it's echo What DC? read HOST echo What is the hosts console IP? read IPADDR ssh -t console-$HOST.myhostname.com /usr/local/bin/consoletool $IPADDR if [ $? != 0 ] then ssh -t console-$HOST.myhostname.com /usr/local/aes/cons-utils/consoletool $IPADDR fi 
I like your attitude. On behalf of those 5-10 years down the line, thank you.
Yes this does need to be interactive.
And your response actually helps a lot, I will read more into Net:SSH for sure.
Okay, I don't want to go off on a tear about "when you ask for help, please provide as many details as are relevant", but I'm getting to that point. You didn't indicate what kind of programs you are trying to run -- if they are terminal programs (that need a tty), or if they are simply batch scripts. You didn't indicate if the user needs to enter a password or not, or if you have ssh keys setup. (Net::SSH can't work with password authentication, you need Net::SSH::Perl or Net::SSH::Expect, so it would matter). Regardless, see the bash script I posted in my other comment. There's no point getting perl involved in something that's just command execution from the shell. 
Just a few notes. The -w on #!/usr/bin/perl -w is redundant with 'use warnings;'. That's fine. I like to write out 'use warnings;'. With strict on, you have to declare your variables (keep it on!): chomp( my $data_center = &lt;STDIN&gt; ); Note the extra 'my'. Then you have a deadlock going on. You've run system, and you want the connection open, but it doesn't finish and return until after the connection has closed. By then, it's too late to ask the user about other things, like the host console IP. Ask that before you run system(), or don't launch off to a whole other program (ssh) (others are suggesting Net::SSH). It would be possible to rig up one big command to run with system: ssh user@whereever -e '/usr/local/bin/consoletool $ipaddress' Getting the quoting right on stuff like that can be tricky. http://perlmonks.org was created for asking questions like this, by the way. #perl-help on irc.perl.org (using your favorite IRC client) can be good, too. You may find it hard to keep a thread running on Reddit and continue to get feedback as you make changes.
There's a difference between needing the language and wanting to learn more about it thus using it for all your scripts.
Theres a lot of consistency in it unlike php, so things often work how i expect them to instead of me having to look up parameter orders or other such things. It's also really really easy to write 'quick hacks', which make it a must have for system administration. Thats not to say its all good of course, parts of it are (IMO) horrid, like the reference system, how many modules you need to do relatively simple things, etc. But that too is a double edged sword -- There are so many awesome modules that completely change everything, like Moose or DBIX::Class.
Off the top of my head 1) System Administration and Automation : Sooner or later, when dealing with computers you would want to automate things. Usually people choose bash for that sort of task, but perl will do too ! php *simply* can't be used for this. Eg I) https://github.com/symkat/Daemon-Control can write init scripts for you. Eg II) you can use perl operators qx/cmd arg1 arg2/, system("cmd","arg1","arg2") to execute various external commands One simple usecase for the above is, when you are restarting a web server, you want to remove earlier log files. You can do it manually, you can do it by bash, or you can use Perl ! Confused about stin, stderr, stdout ?? IPC::Open3 to the rescue ! Eg III) Do you need remote system adiminstration ? Net::SSH is just godsent. I have found many uses for File::ChangeNotify, so I'll just put it here. 2) Text : 'Nuff said. On a side note, the recent versions of perl come with extensive utf8 support. Perl has the best regex implementation. Perl offers the best string quoting operators, q{ } , qq{ }, qw ( ) , &lt;&lt; 'EOD', &lt;&lt; "EOD" 3) Web Robot programming, IRC bot programming. Checkout LWP, WWW::Mechanize. I'm not an expert on IRC bot programming, but it can be done and it can be done *well*. 4) A philosophy of programming: There is more than one way to do it =&gt; Be Creative Extreme Programming =&gt; Test the fuck out of your code POD =&gt; Document your code so that others can read it. 5) CPAN : Big number of modules number of well tested modules ^ to do most of the common tasks. Checkout Task::Kensho One killer feature of cpan is, it comes with a ticketing system ... so you can check the bug reports and contact the author if you find anything funny with the cpan module. 6) Multiple Programming Paradigms : I) Shell scripting: ^ II) General Purpose programming in the sense of C/ C++, Data structures, Algorithms, Games(Perl::SDL), GUI Apps(Perl has tk bindings,wx) IV) Functional programming. Let me just say it. Python and Ruby suck if you want to learn functional programming. Python has lambda which just caters to a single expression, and ruby has proc, lambda, blocks. Perl has just "sub" and a whole book -&gt; Higher Order Perl dedicated to functional programming style. IV) Modular Programming. Perl takes a huge advantage of modular programming. See CPAN to get a sense of the how. V) Event oriented programming / Network Programming : Checkout Any::Event VI) Object Oriented Programming Perl initially just had a simple way of doing object orientation. People always hated it. Specifically people who were looking for Java style OOP hated it and continue to bitch about it. But you know what ? It's really not _that_ bad once you get to know it and use compostion instead of inheritance. But now, Perl has Moose. Moose truly brings the power of lisp to the perl programmers, except for macros ofcourse. (Perl6 is dealing with the cognitive dissonance of implmenting lisp macros in a language with *rich syntax* right now. Hope it succeeds :) --------------------------------- I learnt perl in 2007 summer by a mostly ad-hoc approach of reading the manuals and reading a pirated edition of Learning Perl. I'm glad I did it because, the all-encompassing-post-modern-mish-mash-kitchen-sink that perl is, made me a better programmer.
1) what usually take me 30 mins to write in c, would probably take &lt;10 in perl. 2) CPAN &gt;I would love to hear about why you use perl and what kind of things you use it for. **Everything**, here we use it for small utility scripts to very large complex systems. Learning Perl is a good place to start but it can be a bit basic. I'd recommend taking a look at [Modern Perl](http://onyxneon.com/books/modern_perl/) after for better examples of how perl is really used. 
So is COBOL, but many large companies still use it quite a bit.
So, despite them being the same, you felt the need to start a semantic pissing match about me using one over the other.... why?
 $ perl -e 'print sprintf("%.2f\n", 1.2345); print sprintf("%.2f\n", 1.2355);' 1.23 1.24 $ perl -v This is perl, v5.8.8 built for x86_64-linux-thread-multi 
Perl is a melting pot of ideas, but most remarkably, the ideas work together in endless novel ways. For example, you have "closures" from Lisp, which are code references that keep their stack frame alive, variables and all, as long as a reference to that bit of code exists. This lets you compose complex pieces of logic at run time without resorting to eval'ing code or making a trip to the compiler. You also have the standard dynamic language idea of a package (which constitutes a class) being populated from code references. Well, it turns out that you can use closures to build a package, and implement a class in terms of closures. It's this kind of "hey, that actually worked" stuff combined with all of the ideas rolled up in Perl that makes hackers love it. Any reference can be an "blessed" into being an object. Blessing a reference associates the data (pointed to by the reference) with a package (which contains the code that implements the methods). Packages themselves can have references taken to them. So you can bless packages into themselves to make one-off objects, perhaps composed from closures. Whee! Many other things can have references taken to them as well, including regular expressions and file handles. Long ago, the language designers that they wanted "to grow CPAN and the community, not the Perl core", so every chance they got, rather than adding something to the language itself, they added hooks to the language to make it possible to do things as a module. As a result, modules can temporarily take over parsing, such as with Devel::Declare, so you can add entire new bits of syntax to the language. The autobox module on CPAN makes the primitive types appear to be objects (as in newer versions of Java), so you can do 3-&gt;print; or other things. It's not just that these things exist, but the potential for creating new, fun things using the hooks. The bytecode of the running program is exposed via an object-oriented face using the bundled B module. You can recursively traverse and inspect the compiled bytecode of the running program. But if you install the B::Generate module from CPAN, that API gets extended with mutators, and you can then use the same OO interface to modify the bytecode of the running program. There's tons of room for doing nerdy CS research things with this and other open-ended hooks. Regular expressions are good, but that's half of the story. Perl stole ideas from the awk text parsing language. Regular expressions are closely integrated with other language features. One regular expression can do some matching, then perhaps you want to throw in some conditionals and then resume matching where you left off with one of a few other regular expressions. You can look at a string and find out where matching left off. You can compose regular expressions from other regular expressions and pass around references to them. You can take them apart and inspect compiled regular expressions and do various other things with the regex debugger. "Perl compatible regular expressions" (PCRE) is years out of date. Perl's regexes now allow fully recursive regular expresses. Mostly, as you develop competency at Perl and continue to learn it, you'll repeatedly be struck by this feeling of "holy shit, really smart people created this". Forth, Scheme, and a few other languages induced the same feeling in me. If you already know other languages, the book _Learning Perl_ might be a bit slow and shallow for you, though it is an excellent book. It half teaches programming ideas while teaching Perl basics. _Programming Perl_ might be more your speed. Larry Wall shows a lot of cleverness and fun loving hackery in his own Perl book there, and it's a more thorough introduction to all of the stuff in Perl. There are tons of good books. _Higher Order Perl_ shows how to do Lisp-hackery stuff in Perl. _Perl for System Administration_ is a great Perl intro that deals with a lot of the harder stuff that other books gloss over, such as network servers and IO without deadlock and dealing with buffering and interfacing with other programs and the system. There are lots of stinkers, but there are also too many good books to count. Shameless plug: I wrote _Perl 6 Now: The Core Ideas Illustrated with Perl 5_, that shows the origins in Perl 5, or else back-ported versions, of things elevated to first class status in Perl 6 (work correctly, core, interacts well with all of the other features). It's full of all sorts of hackery. _Modern Perl_ is a concise course on the syntax and most common idioms of Perl and it's available freely online. Oh yeah, one other thing: when working in other languages, almost everything is a function, or it is an API method on some object, or something. In Perl, what you're trying to do might be an API method on a module included in the standard library (perldoc perlmodlib). It might be an idiomatic combination of a couple of features such as a mix of operators and built-in functions (then it's documented in perldoc perlfaq). It might be an operator (and documented in perldoc perlop) or a built in function (and documented in perldoc perlfunc). There's no cure but to skim all of those documents once and get an idea of where things are for when you have to go looking for them. Then everything else is either on CPAN (search.cpan.org) or not invented yet =)
What is the difference between composition vs. inheritence? I looked here: http://c2.com/cgi/wiki?CompositionInsteadOfInheritance and it seems that it's basically the difference between creating a new class based on another one (inheritence) and creating a new class that just uses another class (composition). Is that about right?
It comes down to "is a" versus "has a". Some cases are handled better by saying "this new thing is like this old thing, except it does this differently." Others are handled better by saying, "this object has these subparts, reusable elsewhere." Composition allows you to build up more complex behavior from small subunits; inheritance lets you take larger existing things and alter them slightly to get the new behavior you want. Edit: damned phone...
Wow, thank you soooo much.. you have know idea how much I love to read, these book suggestions are to be investigated immediately. I do have another question.. I am embarassed to admit that I have not yet learned regex. What would you recommend after I have decided to take on perl? I bought O'Reilly's Regular Expressions Cookbook and couldn't get past the 3rd chapter as it seems to be more of a reference. I assume it will be just like anything else and I will just need to jump in and start doing it. Would you say to learn regex before perl? My only dilemma is that I bought the domain name 'www.myfirstandlastname.com' and that was to be my next project and I wanted to use use perl. I was going to make it fun and create a small app out of it where visitors can ask me anything and leave their question anonymously and then I would come back and answer it later but I don't think I'll find much need to manipulate strings with this one.. thank you again. and to everyone else.
 #!/usr/bin/perl use 5.014; use strict; use warnings; use autodie; my $filename = './list.txt'; my $magic_value = 'X'; my $data = []; open (my $read_handle, '&lt;', $filename); while (my $line = &lt;$read_handle&gt;) { chomp $line; my ($key, $value) = split (' ', $line); die unless $key and $value; push $data, [$key, $value] } my $result; for my $key_one (0 .. $#$data) { my $value_one = $data-&gt;[$key_one]-&gt;[1]; for my $key_two (0 .. $#$data) { my $value_two = $data-&gt;[$key_two]-&gt;[1]; my $combined = $value_one.$value_two; push @{ $result-&gt;{$data-&gt;[$key_one]-&gt;[0]} }, $combined.' '.($combined =~ /$magic_value/ ? 0 : 2); } } print ((' 'x7).join ('', (map {sprintf '%-7s', $_-&gt;[0]} @{ $data }))."\n"); for my $key (0 .. $#$data) { my $value = $data-&gt;[$key]-&gt;[0]; print $value.' '.(join ('', map {sprintf '%7s', $_} @{ $result-&gt;{ $value } }))."\n"; } $ ./matrix.pl A B C D E F G H I J K L A XX 0 XY 0 XZ 0 XX 0 XX 0 XP 0 XQ 0 XW 0 XX 0 XY 0 XV 0 XR 0 B YX 0 YY 2 YZ 2 YX 0 YX 0 YP 2 YQ 2 YW 2 YX 0 YY 2 YV 2 YR 2 C ZX 0 ZY 2 ZZ 2 ZX 0 ZX 0 ZP 2 ZQ 2 ZW 2 ZX 0 ZY 2 ZV 2 ZR 2 D XX 0 XY 0 XZ 0 XX 0 XX 0 XP 0 XQ 0 XW 0 XX 0 XY 0 XV 0 XR 0 E XX 0 XY 0 XZ 0 XX 0 XX 0 XP 0 XQ 0 XW 0 XX 0 XY 0 XV 0 XR 0 F PX 0 PY 2 PZ 2 PX 0 PX 0 PP 2 PQ 2 PW 2 PX 0 PY 2 PV 2 PR 2 G QX 0 QY 2 QZ 2 QX 0 QX 0 QP 2 QQ 2 QW 2 QX 0 QY 2 QV 2 QR 2 H WX 0 WY 2 WZ 2 WX 0 WX 0 WP 2 WQ 2 WW 2 WX 0 WY 2 WV 2 WR 2 I XX 0 XY 0 XZ 0 XX 0 XX 0 XP 0 XQ 0 XW 0 XX 0 XY 0 XV 0 XR 0 J YX 0 YY 2 YZ 2 YX 0 YX 0 YP 2 YQ 2 YW 2 YX 0 YY 2 YV 2 YR 2 K VX 0 VY 2 VZ 2 VX 0 VX 0 VP 2 VQ 2 VW 2 VX 0 VY 2 VV 2 VR 2 L RX 0 RY 2 RZ 2 RX 0 RX 0 RP 2 RQ 2 RW 2 RX 0 RY 2 RV 2 RR 2 $ cat list.txt A X B Y C Z D X E X F P G Q H W I X J Y K V L R 
(good-natured heckling, please take it as such... I don't expect to persuade you) You go through all that, then bust out with $_, *and* in a postfix loop? ...and that indent style? Is that the "hipster" indent, because [the styles](http://en.wikipedia.org/wiki/Indent_style) used by everyone else are too mainstream?
You're quite welcome! Re: Learning regexes, I wouldn't make a goal to go out get really good it and then write big, gnarly regexes. Regex is best used in moderation. perldoc perlretut (bundled with perl or available on perldoc.org... http://perldoc.perl.org/perlretut.html) might be helpful. Practice with real data helps. Help on IRC chat helps. For more involved parsing tasks, there are other modules, such as Parse::RecDescent. Regexes for common tasks are already written in Regexp::Common on CPAN. The (correct) regex for parsing email addresses is famously gnarly. Don't use regex to parse HTML (unless you really know what you're doing). There are HTML parsers and XML parsers for tasks like that. There are parsers for various log formats, for CSV, and many other things. Every now and then, you will come across some loosely structured data, though. If memory serves, _Programming Perl_ ha a chapter. 
Let me give a some of my prespectives on why compostion is &gt; inheritance. 1) It's simple. 2) No diamond problem, No ZOMG multiple inheritance ! A Salmon *is a* Fish ! You will hear people say. Fuck them. A Salmon *has some* Fish kinda traits inside him ! 3) Dynamic languages like perl make compostion a breeze to use because you can just use *duck typing* and be done ! In typed languages you need all the --interface polymorphism-- crap. 4) Composition actually offers greater encapsulation than inheritance. Think about it. Compostion is greater than private, protected, friend, enemy all bullshit put togother. 5) Delegation &gt; Inheritance. In a language that does not support delegation natively, compostion is a very very dumb and cheap way to do it. 6) ||||||||||||||||||||#Music is composed# |||||||||||||||||||||||||| 7) Code-Reuse on a granular level is just not possible with inheritance. With inheritance, your inheritance tree just keeps going on and on and on and on. Where does it end ? With Compostion, there is a sort of peer-to-peer approach to code-reuse. tl;dr The 4 motherfuckers of GOF explicitly stated that Composition &gt; Inheritance. 
It was my first thought as well, and I was looking forward to some kind of filthy hack to make it happen. That said, if you can't manage even basic politeness, I'm not surprised the blog author pulled your comment.
I like the helix looking one. :)
My favourite from that list Abigail's prime number detector, which I've always admired: perl -wle 'print "Prime" if (1 x shift) !~ /^1?$|^(11+?)\1+$/' Highly inefficient, but equally elegant. 
IRC can be weird. The #perl-help channel on irc.perl.org is generally pretty helpful. The proper etiquette is just ask your question. If it's about code you're working, on use a nopaste service to share the code. Then wait. Sometimes it can take a little while to get an answer. Just leave your client connected. People will use your nick when they answer you and your client (if it doesn't suck) will alert you to this somehow (Pidgin does a good job with this, I find). If you don't get an answer in 30-60 minutes, it's ok to repost the question. New people may have joined the channel since you last asked. More often that is probably going to get annoying.
Indeed. There's also [#perl on Freenode](irc://irc.freenode.net/perl) with some clueful and helpful people willing to help answer questions. For quick and easy access through your browser if you don't have an IRC client installed or configured, you could try [Freenode's web chat client](http://webchat.freenode.net/) or [Mibbit](http://www.mibbit.com/) among others.
[older thread](http://redd.it/qxv1m) Modern Perl - [html](http://modernperlbooks.com/books/modern_perl/chapter_00.html) / [pdf](http://onyxneon.com/books/modern_perl/modern_perl_letter.pdf)
Maybe something like this could do the trick. use strict; use File::Copy; while (&lt;*&gt;) { my ($filename, $extension) = $_ =~ /^(.+)(\..+?)$/; next if !$extension or !$filename; next if $extension !~ /^\.(?:mkv|avi|mov)$/; my $newname = $filename; $newname =~ s/(crap|words)//g; $newname =~ s/[._-]/ /g; $newname =~ s/^(the)\s+(.+)/$2, $1/i; my $folder = substr $newname, 0, 1; move($filename, "$folder/$newname") || print "error $!\n"; } Edit: Now that I think about it, this could potentially move folders with a dot in their name.
Perl on Windows is fine, even great, and for things like that is as good as it is on *nix platforms. most modules are cross-platform, and plus there are Windows-specific modules. Search CPAN/MetaCPAN for modules to work with files (getting list, traversing through directories recursively, etc.). you'd need to know Perl's hashes and arrays, read up on references in Perl (and de-referencing). and you'll definitely want to know some (at least basic) regexes for this.
I've actually used that code before just to blow the minds of people reading my work later ;)
Thanks for the tips I was thinking I will make a folder with test cases, probably tell the script to only select .txt files, and then make a bunch of test case files and see how the renaming goes.
NP - testing is good :)
You can install cygwin on windows to get most of the command-line functionality on Windows. I use it all the time on my windows machine. 
I'm all about learning new languages, but make sure you're not [reinventing the wheel](http://www.therenamer.com/) first, unless you're just doing this to learn/for fun :) It's not hard to have it [automatically start](http://lifehacker.com/5595586/set-up-a-fully-automated-torrent+seeding-media-center) when uTorrent (or whatever) finishes a download.
Yeah, already stated that I was doing this as a learning project in my post
You need to "chomp" the input to race/name/etc. The newline at the end is making the strings not 'eq'. For example: chomp($temp = &lt;STDIN&gt;) By the way, you may want to use regexes to check input instead of eq. You also assign a lot of things to "undef" when you really don't have to, not a big deal. Since you seem a little new to Perl I highly recommend: use strict; use warnings; 
chomp $temp; Right after reading it from STDIN.
Use [`perltidy`](https://metacpan.org/module/perltidy) on your code if you want others to look at it. [Result](http://pastebin.com/u3SSWctz). $temp = &lt;STDIN&gt;; `$temp` now contains a line, including the newline. That means it will never match any of your tests. To remove the newline: chomp($temp = &lt;STDIN&gt;); 
Honestly, I've always felt like the perldoc [perlrun](http://perldoc.perl.org/perlrun.html) is better. This page always read like a list of cool things that can be done with Perl one-liners, as opposed to telling me how to leverage Perl to do what I want to do.
I wouldn't necessarily call awk and sed normal CLI commands. They are essentially their own languages and when you use them, it is the equivalent of a perl one-liner. 
Eventually you may run into Larry Wall's original problem, that all these do not operate identically on all systems. In that case perl (or anything else these days) is an excellent replacement.
The data dumper did help with some later changes, but it just seems less redundant if you use a subroutine to apply assign the values of %abilMod and apply the changes to the character's attributes after rolling them. Plus I'm too lazy to type all of that. But the only real problem I had when actually debugging was not using chomp().
Will someone explain the difference between &lt;STDIN&gt; and just &lt;&gt; ? I know they are both user input but what is the difference, if there is any?
Does putting open FILE, "&gt;blah.txt"; tell Perl to save the output in blah.txt?
The gibberish is the binary image your code creates. Redirect it into a file and use some tool in order to view it.
Not in a terminal, no. You will need to print it to a file ("filename.png") and use a graphics tool like Photoshop to open that file. Terminals are character based, and are not designed to display graphics - they only show letters &amp; numbers.
You can render images on the fly in web pages by having your image tag point to the program that renders your image so your example would work like this: &lt;img src="myprogam.pl"&gt; and then you would print the image data to stdout - after setting the content-type header. Not what you asked but FYI.
Only if the `open` succeeds and you print to the `FILE` filehandle.
Nice! I had a bunch of functions I wrote in perl a long time ago for little projects, but never formally made it a package or published it. Thanks for putting this out there. 
awesome ! care to cpan it ? :)
What is a filehandle? 
I've never tried print it like that but I use: while((my $key, my $value) = each %herpaderp){ print FILE "$key:\t$charAtt{$key}\n"; } close FILE; But no, if the file doesn't already exist, it will make one. But only if writing onto it. 
No problem. I'm also new to Perl so it's nice to help out a fellow noob. :) $key is the name of the hash element like %herpaderp = ('derp' =&gt; 1) $key is 'derp' the first time the while-loop goes around and $value is 1. 
Why is $value always 1?
Just look at any of the [other reddit bots](http://goo.gl/mHyvH) for an example. There's lots of automation on reddit, but most are written in python. 
Unless this new module is backwards-compatible with yours, replacing [WWW::Reddit](https://metacpan.org/module/WWW::Reddit) with this might be unwise, as it could cause existing code using WWW::Reddit to break when WWW::Reddit is 'upgraded'. Personally, if this gets released to CPAN, I think just releasing a new version of WWW::Reddit with a deprecation notice pointing to this module would be the way to go (assuming you plan to deprecate WWW::Reddit; that's how I read your comment, apologies if my assumption is wrong).
That's a good point, but it's already been uploaded. Is there a process for moving to another namespace? On the other hand, this isn't a web service. It's an API wrapper. My code isn't the API (any more than all modules provide an API), but it models the Reddit API.
Thanks for your concern, but I think your point is moot. Any code currently using my WWW::Reddit module is already broken. The site has changed a lot in the last several years, and my module has not been updated to reflect that. 
Hehe, fair enough then - yeah, in that case it's not likely to really matter too much :)
No. Test count is a silly metric.
I prefer F. If you haven't read it yet, I highly recommend [Perl Best Practices](http://shop.oreilly.com/product/9780596001735.do). It is seven years old now, but almost everything in it is still applicable (except for OO.) There's a very good chapter about this type of basic code formatting. You should also look into using [perltidy](https://metacpan.org/module/perltidy). It's very configurable, so you can have it format code to your exact preferred style.
Ya, like I said, `F` was my original first choice but then `D` keeps trying to steal the show with its sleekness. In all my other formatting decisions, I always put my closing bracket properly aligned on its own line. Why am I second guessing myself? OMG, am I having a midlife crisis??
The first line of D is just a bit too busy for me, with the assignment of the new object and the first argument as well. I just like to do one thing per line, maybe I take it further than most, but newlines are pretty cheap these days ;)
The current Rakudo Star (aka "R*") release is, as you likely already know, "for early-adopters" (as the release announcement states). Currently, the core team appears to be focused on getting the implementations to converge with the specs &amp; tests (which may include updating the language-design/specs/tests as needed). I don't really know what the criteria is for discerning when those things are close enough together such that R* can go from "for early adopters" to "for everyday use". The [compiler feature comparison matrix](http://perl6.org/compilers/features) indicates how far along the major implementations are. Perhaps when the Rakudo column is "green" enough, the focus will shift from design &amp; implementation to making Perl 6 practical for everyday use. 
Still no threads...
D, or F if D causes long lines 
I prefer E ..mostly because that's how I'd write it as I coded - many of these formats are sort of after coding is done/perl tidy type stuff. Also, I'd point out - I generally have a trailing *,* even on the last line to prevent errors when adding more data later(but that habit can come back to bite me in things like Javascript!)
F), but with a trailing, last comma
&gt; Perhaps when the Rakudo column is "green" enough, the focus will shift from design &amp; implementation to making Perl 6 practical for everyday use. If history is any guide, the focus will shift to porting everything to a different backend instead of making something practical.
F, because the aligned arguments are easy to scan with my eyes, and it's not super-wide on the screen so I can skip over it quickly if I don't care about looking at it.
F, if only only so that commenting out lines, or adding new lines is dead simple. Also, I would always add a comma after the last value.
F, the other ways just look messy to me. I'm very much used to F, that's how I've been taught so I'm sure I'm biased :)
It isn't isn't always.$value is the value that's assigned to $key.
E is my favorite. Anything above E makes me cringe. There is no reason for there to be so much white space on the following lines. It also doesn't seem practical. Assume someone comes along with soft emulation, every additional space becomes an extra character. There is never a reason to not micro optimize so I feel anything beyond E is not only ugly, but redundant. Additionally, extending the length of the line makes code comparisons more difficult as the code may go beyond the split of your screen. I'm not anal about it, but it's nice to get into the whole 80 character line to facilitate terminal editing groove. 
I agree, if they're not cuddled it would just piss me off. 
I just res-tagged you as `Militant Cuddler`
For me, it is all of them. In PERL at least. I have different widths for different syntaxes. I'm not sure if you already know about it, but if not, I'd recommend checking out this text editor. It's super configurable and intuitive. http://www.sublimetext.com/2
Can you configure perltidy to do it for you?
That's a nice way to put it. 
The specification test suite doesn't always run every test on every implementation. Some test don't parse, and some tests have infinite loops and other unwanted behavior. The test files contain fudging markers to indicate that certain tests shouldn't run on certain implementations. When a test passes--on purpose--on an implementation, someone unfudges that test so that it can continue to run on that implementation.
D or F are both fine, except that D (and the others) don't need the space before the closing paren (unless you're using a space after the opening paren), nor does D need multiple spaces between the longest argument key and the following "=&gt;". Why are there multiple spaces there? A and C don't even seem like real options. It's like you needed more options and made up some ugly ones?
until0 summed it up pretty well, but I just wanted to add that for me it is about having a visually smaller document, if I can keep a script onto one "page", it helps me to understand it quicker if that makes any sense. I have a crappy memory so if I have to keep scrolling up/down left/right it will throw me a bit :s
Soft tab emulation? And I'm a die hard Vim user if that helps; I could set it up just haven't gotten round/used to it yet.
Or learn to decode png by eye!
D
F, with a trailing comma after "dna". Makes it trivial to add or delete arguments without needing to modify any other line.
I'm still on the 2nd edition :) Don't know if I should get the newer edition for more updated reference material.
If your reason to not micro optimize is that inability to acknowledge the impractical from the practical, then you shouldn't be a programmer. It goes without saying that two letter variables and multiple statements on the same line pose much greater dilemmas than the little optimization that will arise. For general purposes, there is always a reason for micro optimization. To not promote efficiency due to the possibility that *someone* will misunderstand the concept is a poor choice. We are programmers, we have a lot of responsibility; practicality is one of the most important. With that being said, there truly is never a reason to not micro optimize. Additionally optimization is not always in the performance of the code, but can also be applied to the performance of the workers. The bottom line is that the extra white space is just redundant; one of the biggest programming sins. Especially since the extra white space is just redundant. (^ See what I mean? It's just annoying....)
&gt; If history is any guide, the focus will shift to porting everything to a different backend instead of making something practical. I know you were hurt in some way by the effects of the nom refactor. (For outsiders: "nom" stands for "New Object Model", and was jnthn's name for the branch that introduced a meta-object protocol into Rakudo.) On behalf of the Rakudo developers, I'm sorry about that. I had downstream code in production too that broke, and I had to handle that in various ways. It's not fun. You're right that we can always focus on "making something practical", and creating a polished product more than we currently do. It should be our constant goal. The nom refactor took a longer time and became wider in scope than originally planned. Maybe for example the MOP bits could've been separated from the lists bits. Maybe that would've smoothed the migration path somewhat. I dunno. I'm not the project leader. But to claim that we shouldn't have focused on that, or to dismiss it as "porting everything to a different backend", makes no sense whatsoever. Niecza overtook Rakudo in terms of passing spectests earlier this year in its steady progress towards a full implementation. Now Rakudo is ahead again, and making great advances all the time. The reason Rakudo can do that is that the nom refactor was made in 2011, which unlocked a number of things that are now suddenly possible. So the focus wasn't so much on "making something practical" as it was "we need to fix X to get to Y", for various values of Y. Having said this, I'm always willing to listen to feedback on how we can make things more practical and more of a product.
Your gracious apology has made my morning.
The prof is using very old coding style, and doesn't show the error if the open fails. Using bareword filehandles is old style. Better would be this: my $filename = $ARGV[0]; open( my $fh, '&lt;', $filename ) or die "Unable to open $filename: $!"; chomp( my $query = &lt;$fh&gt; ); close( $fh ); $query =~ s/\s+//q;
Ah, I see what you mean. When the test is written but should not be run, it's "fudged" (marked: "don't run this"). But when an implementation is ready to have that test run with the rest of the tests, it's "un-fudged". Thanks, chromatic.
&gt; Having said this, I'm always willing to listen to feedback on how we can make things more practical and more of a product. Two suggestions: 1. Currently, a lot of questions from new users get answered on #perl6, but that info is ephemeral --- it evaporates and gets asked again a day or a week later. Suggestion: in addition to answering, add that info into the [new wiki](http://wiki.perl6.org/), and start pointing users there for info. Start a culture of documenting useful and practical morsels of categorized info there. Not only will it be useful to new users, but it may also be the seed that leads to the growth of some user docs. 2. Try to standardize. I've asked in the past about things like "What version number format should I use?" and "What filename extension (.pm or .pm6) should I use?" and no one seemed to want to say, "do it like *$this*". As they say, "thereâ€™s more than one way to do it, but sometimes consistency is not a bad thing either".
http://emacswiki.org/emacs/AlignCommands
I figured out something pretty useful if anyone's interested - http://pastebin.com/kEpTmjMk Questions welcome
This? $seq_obj = Bio::Seq-&gt;new( -seq =&gt; "aaaatgggggggggggccccgtt", -display_id =&gt; "#12345", -desc =&gt; "example 1", -alphabet =&gt; "dna" );
E
I haven't worried about that in my career. I do use a while() loop rather than a for() loop to avoid creating (additional) huge data structures. Frankly, if you're running out of memory because of the size of a result set, you should be rethinking your query strategy, anyway.
This, exactly. Fiddle with the WHERE clause in your query ( you do have one, right? ) to reduce the volume of records returned if memory use is of concern.
Nope, F all the way. Because of line-based version control systems.
Sometimes it works very well. Sometimes it works... less well.
E makes it less likely than F that Iâ€™ll look at the wrong value if the arrow is far from the key. Thus, my personal preference goes to E + final comma.
Maybe brian d foy had something to do with the book being more readable. Your description convinced me to buy the new edition.
MySQL isn't the only one. DBD::Pg also fetches the entire resultset, whether you want to or not. Oracle and Sybase do it right. Not sure about others.
Nope, was referring to exactly that. So fetchrow must be some ghetto emulated thing because when I do a trace I see that subsequent fetchrow's don't do anything, leading me to believe it just fetches everything in one fell swoop. Still curious as to the actual implementation of how it stores the data and then when it inflates it, short of reading the whole driver.
Already tried. I suspect there must be values unique to the XS space...
Re: "how is it stored and where?... What shape is it? Is it compressed/encoded?", most if not all of the DBD drivers are Perl that use XS (perldoc perlxs) to link to the client libraries distributed with the database. These client libraries are (always or almost always) written in C. Whereas Perl has scalars, hashes, arrays, stashes, globs, etc, etc, C has integers of various sizes, floats, characters, bits, arrays (which may be multidimensional) built out of those things, and "structs" built out of those things. You can create your own types by naming structs you create. Header files (.h files) in the C source code generally define these structures. The client library speaks to the server in a protocol defined by those structures, and the query results are generally stored in memory in these structures. As far as where it is stored, "in memory". The client library, when it gets data back from the database server, uses malloc() (or a similar function) to request a chunk of memory by the operating system to that process. If you use Devel::Peek's Dump() function a Perl variable, you'll see a lot of memory addresses (generally printed out as hex numbers) contain different parts of things. If you're good at reading Perl data structures (such as what get dumped with Devel::Peek), and you're good at reading C data structures as defined by .h files (which is hard, since you can really only guess how structures will actually get laid out in memory), you can use the PeekPoke perl module to inspect and manipulate this memory. That's mostly theoretical though, as it's a lot easier (and less error prone) to just write XS that uses the library that knows how to manipulate the structures. It looks like a good place to start in MySQL's source is include/mysql_com.h, if you want specific answers as to how the data is represented in memory. 
You, sir, win the prize for the most targetted and detailed answer!
Thanks for the feedback. People are working actively on documentation. (lichtkind++, uvtc++.) It's a big task, but we're moving forward on that. Packaging and deployment are also taking small steps. (tadzik++, pmichaud++.) Forward compatibility [came up recently](http://irclog.perlgeek.de/perl6/2012-05-04#i_5542668) on #perl6. In neither of these areas we are excellent yet, but they are a focus. &gt; How am I to respond to words you're trying to put into my mouth? Misrepresenting you wasn't my intent. Let me re-phrase and quote you directly. I occasionally get frustrated at your framing the nom refactor as a "debacle". What I tried to express in my reply to you was how the nom branch to me seems like the *right* refactor at the right moment -- it sits at the foundation at literally all Rakudo's current focus. It needed doing. No-one denies that it took a long time and was wide in scope and a bit disruptive. Your coming afterwards and saying &gt;&gt;&gt; If history is any guide, the focus will shift to porting everything to a different backend instead of making something practical. feels snarky, unnecessary, unfair, and serves to demoralize core Rakudo developers, including me. Is this your intent? &gt;&gt; Niecza overtook Rakudo in terms of passing spectests earlier this year in its steady progress towards a full implementation. &gt; So what? The spectest count doesn't reflect whether any implementation is a stable, practical product for users. Right, but I was illustrating progress along a dimension that is still a major focus: amount of the Perl 6 specification implemented. Niecza has been making impressive, sometimes almost Pugs-like, advances in implementing features in the past year, rivalling even the five-year-old Rakudo. What's significant isn't the exact number of spectests passed, it's the general trends of Niecza overtaking Rakudo, and then as the nom branch took hold, Rakudo overtaking again. And none of this has to do with "practical product". I even stated as much. I wrote 'So the focus wasn't so much on "making something practical" as it was "we need to fix X to get to Y", for various values of Y.' Your saying 'So what?' and repeating *your* original point won't assist you in understanding my point.
&gt; I occasionally get frustrated at your framing the nom refactor as a "debacle". How would you frame blowing past the original estimate, leaving users in the lurch, missing releases, and finally releasing with known regressions? &gt; Is this your intent? I'm not going to debate the tone argument. Show me a Perl 6 implementation that takes the needs of users seriously--that makes and meets promises to do so--and I'll change my tune. If you feel demoralized that some loudmouth on the Internet criticizes what you're working on as misguided and ineffective, then prove to me that I was wrong (especially in the risks I explained in December 2010) or prove to me that I have become and will remain wrong. Don't tell me that, two years later, Rakudo Star has met its goals.
Cuddle please, with extra vertical whitespace added before the closing brace of the "if" if necessary (usually because the "if" paragraph is too full).
Maybe D if there are only a couple arguments; otherwise F with a trailing comma and less leading whitespace (I use 3 because 2 seems too little and 4 seems too much).
The more (clear) logic you can fit in some vertical real estate, the bigger picture the of the program you can get. So, don't use too much vertical space.
perltidy is a pretty flexible tool. You can configure it just about any way you want. Still worth mentioning, though. Figure out what makes you happy in perltidy and then just run that regularly (and always before committing code) and you're pretty well set.
The trick is just using the right tools. I put together a set of perltidy options that matches what works for me, and now I never have to worry about style. Any code which isn't perfect will get run through perltidy regularly anyway, and always before committing. Now all my code is consistent and regular, with no additional time or effort needed to maintain it.
It doesn't exactly directly address this point, but I'd also recommend reading the perlstyle guide (perldoc perlstyle). Most Perl code you'll find in books tends to follow the style guide, as does most of the Perl code you'll find from well known and well experienced Perl coders in the Perl community.
Newest Perl I'm dealing with is 5.10 (RHEL6) and sadly the other end is about the 15 year-old range. Perl 5.005 haunting me from the ugly corner of our platform.
Perlmonks needs an overhaul. It looks like the old slashdot from the 1990s. There is nothing wrong with have a visually pleasing site, it is not selling out, marketing isn't a bad thing. As for the PM content, it is mostly misses instead of hits. When I try to find things on there the content is usually out of date or incomplete for subject matter that is above intermediate Perl usage. Is there any known reasons as to why perlmonks is not evolving with the times?
&gt; Is there any known reasons as to why perlmonks is not evolving with the times? No one's done the work.
That's almost tautological. There's some management philosophy about [asking five "why" questions](http://en.wikipedia.org/wiki/5_Whys) for every problem you encounter in order to get to the root cause, and I guess the root question is, why does the perlmonks community not hold modern aesthetics in high enough regard that someone feels motivated to volunteer to fix it? Or is the code even open to someone who wants to volunteer? A little clicking on the site got me [here](http://perlmonks.org/?node=gods), which implies that only the gods can alter the appearance of the site. Am I correct?
&gt; That's almost tautological. It's not. Plenty of people have volunteered over the years. None have delivered. &gt; why does the perlmonks community not hold modern aesthetics in high enough regard &gt; I guess the root question is, why does the perlmonks community not hold modern aesthetics in high enough regard that someone feels motivated to volunteer to fix it? Did you mean for this to sound condescending and insulting? (I really don't think that's how Five Whys works.) &gt; Am I correct? Someone would have to do the work. No one has.
$bar ||= $foo[0];
I know how to use this operator in scalar context. I am forced to define my variables in list context since I am dealing with a function which returns multiple items in a list. 
$bar ||= function()[0] perhaps? I guess it really depends on the actual context vs this example.
What are you actually trying to do? What are the possible values of $bar?
I'm calling findvalues from HTML::TreeBuilder::XPath to build a hash of address info from pages I crawl (returns undef if nothing is found): ($addr{street}) = $tree-&gt;findvalues($xpath); ($addr{city}) = $tree-&gt;findvalues($xpath); ($addr{state}) = $tree-&gt;findvalues($xpath); ($addr{zip}) = $tree-&gt;findvalues($xpath); However, with this particular crawler I want to make sure the hash info isn't already defined. So right now I've just been using 'unless', but I was just curious to find out if there was something like ||= I could use when defining a variable in list context. I can define arrays for each findvalues call and just do ||= $foo[0], but that's a lot of extra code.
So something like this? ($addr{street}) = $tree-&gt;findvalues($xpath) unless defined $addr{street}; which can be shortened using 'defined-or': ($addr{street}) //= $tree-&gt;findvalues($xpath); What I'm not sure is how it handles list context?
This kind of thinking is dangerous, because it leads to some odd results when $bar == 0 or $bar eq "", even though you hypothetically expect that never to happen. Consider using *defined* with the unless statement.
Yes, CentOS 5 is what I log into for my dev server at work.
 $bar //= $foo[0]; It will protect you from `$bar` being falsish but defined.
Unfortunately we don't all have the ability to change the dev stack our organisations use.
 or like: $bar or ($bar) = @foo;
No, because 'unless' is neither equivalent to the ||= operator, nor list-context.
For those unaware of what these modules do, they're source code transmogrifiers that convert your Perl programs into [works of art](https://metacpan.org/module/Acme::Bleach) or [a blank page.](https://metacpan.org/module/Acme::EyeDrops)
I ran Bleach once then realised I didn't know how to get my script back to normal and I didn't have a backup. I had to email Damian. 
No, then it will be 24k of 30k.
Depending on the context it might be very prudent to to specify that one is talking about US-Americans, as opposed to the anyone from Northern America or America itself. In the case of the article he points towards the US-American Geometry taught in schools, which might well be different in other countries in America. (In fact, from reading about it, i know it is.) Specifying that brings across to the reader that he doesn't mean the entire discipline as practiced world-wide, or as practiced in a wide region he kind of knows, but a very specific branch of it. Also, to correct your example with Europe: The practice of calling US-Americans "Americans" would in Europe be the same as referring to Germans as "Europeans" exclusively, just because they have the biggest GDP there.
Fair enough, thanks and I apologize for over-interpreting your words.
That's a good point, but it's something I tried to cover in my original post. There is no difference between "US-American" and "American", or rather that "American" doesn't by itself refer to the continents. There are 2 different continents, North America and South America. Even saying that someone is "from [the Americas](http://en.wikipedia.org/wiki/Americas)" if you really needed to refer to both with a short word would give enough context that you were referring to geography and not nations. That was what my example about "Eurasians" was about, not about what nation was biggest and baddest on the continent. One almost never has to refer to the inhabitants of two separate continents side-by-side and even when they do have to, it's already possible without trying to change the meaning of existing words (and in this case there are already short words to use as well). In the case of the article, is there any way to plausibly and honestly mistake "what we Americans call 'geometry'" as referring to dozens of different nations and some 900 million people spread from the Arctic to the Antarctic? I wouldn't even mention it if it wasn't for the fact that I've interacted with quite a few people over the years who are just a *bit* anti-American, and who use the term "USian" pejoratively much like an overzealous fellow from /r/atheism might refer to a "Xian" or an anti-Semite might talk about "that Jew banker", and the reasoning is always that they've felt those imperialistic bastards at the U.S. of A. have stolen their rightful (and exclusive) term. So when I see it elsewhere I never know what to think. chromatic has commented elsewhere that I'm reading way too much into it (which means I thought wrong ;), so I'll drop it... I already feel bad hijacking the comment thread this much.
See the [Perl 5.16.0 delta](http://search.cpan.org/%7Erjbs/perl-5.16.0/pod/perldelta.pod).
I really dig that SUB key word, for writing anonymous recursive subs. Stolen from perl6 I believe :)
Yes, though it's &amp;?ROUTINE in Perl 6. And you usually don't need it in Perl 6. The reason you sometimes want that in Perl 5 is that variables aren't visible until after the statement they are declared in: my $x = sub { # $x not visible here }; As a workaround, you had to write my $x; $x = sub { # $x visible here }; In Perl 6, this was never an issue, because variables are visible immediately.
Perl Monks has a design? Sorry, I had to. No, no rendering issues here in FF12.
OMG, we're walking with giants here. Scott, I had no idea someone like you exists on reddit. After 10 years of Perl programming, I feel like a beginner. Your post made my day.
how is this new in 5.16? I've been using anonymous routine references in 5.8.8.
Come back in another 10 years. It's going to take a long time until we have the same level of suport we have in p5 CPAN.
Trolololol
'unicode_eval' and 'evalbytes'?
&gt; There is no difference between "US-American" and "American", or rather that "American" doesn't by itself refer to the continents. There are 2 different continents, North America and South America. Actually, this is cultural, and for many people, America is one continent.
Yeay!
That label is Percentage Growth, and it's still above zero, so before people panic: This data (which I have no idea if it's useful) suggests that perl jobs are growing, just at a slower rate. So it's still not that bad.
And it doesn't mean a lot unless you compare it other languages since it could be an industry slowing of employment (which given the state of the economy wouldn't be a surprise).
&gt; state of the economy Of course, that explains it. The growth of other dynamic languages has suffered as well, starting in 2011: http://www.indeed.com/trendgraph/jobgraph.png?q=perl,python,ruby,php&amp;relative=1
A quality engineer will work well with any language. Just sayin'.
It only shows percentage growth since Jan '05. If there were 1,000 Ruby jobs in 2005-01, then there were 25,000 in 2012-01. It's possible there could have been 10,000 Python jobs then, corresponding to 65,000 now.
&gt; It might still be growing, but this is still making me uncertain about my job security in Perl, and also happy that I'm hoping to move to something with [2] healthy growth in the future. This is really the hallmark of a quality engineer. You shouldn't be bound by language what-so-ever. 
Okay, let's [compare](http://www.indeed.com/jobtrends?q=perl%2C+haskell&amp;l=) Perl to Haskell. Hmmm. But you could always peruse the [Haskell](http://www.indeed.com/q-Haskell-jobs.html) job listings. Ahh. 
Thanks. Can I request a tiny office with a really comfy chair. I don't need windows. I like feeling cozy like I did in the womb. 
Omg! In that case, I'll bring in my cot and work 24/7!!
I'm a bit puzzled as to why concurrency is such a big issue in a new language. I'm a Perl5 programmer on and off work, but I am a bit disappointed with concurrency in p5, I know the alternatives, I know the whole discussion threads vs event-loops vs coroutines vs continuations etc, but I am still not satisfied about threads in p5(Of course, that's not a showstopper for me since I always find alternatives, but .. that's not the point). Anyway, I was thinking.. couldn't people just study what was done in Python or Ruby or Java or any other language that has some OSS implementation and just make it work in Perl6 ? It seems like time is flying by and p6 still doesn't have concurrency figured out yet. Why ? (I think that concurrency is the missing piece of the puzzle in p6, and if that gets done, it's just a matter of time before the compiler gets more optimized and the community starts writing lots of modules for it)
As a person who's followed the project for a long time but at a great distance, it appears to me that Parrot is kind of a millstone around the project's neck. I'm doubtful it will ever be performant on that platform. The Niecza project seems to bear that out. Am I mistaken, or did essentially one guy build a much faster implementation that covers nearly the same amount of the language in a fraction of the time that Parrot/Rakudo has been in development? I know it sounds like I'm just spreading FUD, but if I'm wrong, I would really like know.
In most cases someone who has only worked in one language for most of their career, even if it's a long one, has less valuable experience than someone who has changed gears a few times. Those who are amazing a a particular language over others are typically, though, much better than your average engineer in ANY language or framework. The Perl engineers I've met who would fit the 'monk' description typically have a long storied career of at minimum a few decades. Everyone else I've worked with who had only worked in one particular language have ranged from absolutely terrible to work with to mediocre. tldr - I'll take depth over breadth any day of the week when I'm hiring engineers to work beside me.
Getting threads right is non-trivial, especially with a high-level dynamic language. The simple question of what semantics the system should have doesn't even have one obviously correct answer. 
While you might just be trolling I didn't say I was actually moving yet. Being on a tiny team now is not at all the right time to move. I was more just pointing out that the direction of functional languages (Haskell naturally being my favourite) is why I see my career going, and it's comforting to see other big parts of the industry moving in that way too.
While parrot's poor performance is not the only problem, it does make up a big part of the problem. Mostly the missing of a JIT compiler and the calling conventions that produce way too many GC-able objects. Niecza doesn't miss out too much speed due to CPS emulation, the things that make it slow are mostly the regex engine.
Well, excuse me if I'm wrong but concurrency is something people do since the advent of threads, perhaps even before that, since forks, which is a long time ago. Saying that &gt; the world is moving toward a greater diversity of hardware, much of it multi-core, and software is something which has been iterated many years now. I mean just look at the C++ or Java or C people, threads are natural to them, it's something that their language supports for a long time now and it's not like in 2012 "people have started switching to multi-cores and concurrent models", I mean we have multi-cores for some time now and threads as well. what you meantioned about various data structures delivering safe concurrency is already in Java or C++ as thread-safe data structures, and most classic data structures have a thread-safe analog. I agree with you, but I have some concerns on the nuance of novelty you seem to bestow on the words "multi-core" or "concurrency". 
&gt; I'm doubtful it will ever be performant on that platform. One response to this common concern is that it doesn't matter. The Rakudo team has a path on to other VMs. Another response is that I am confident Parrot will eventually come up to snuff anyway even though the path there has included a rough patch. &gt; The Niecza project seems to bear that out. Am I mistaken, or did essentially one guy build a much faster implementation that covers nearly the same amount of the language in a fraction of the time that Parrot/Rakudo has been in development? Yes and no. Yes, sorear wrote Niecza in about 2 years whereas Rakudo's been under development for about 5 years. But Rakudo is generally more complete and since the Rakudo team landed the new object model branch (which was primarily about speed even if some think it was about portability) Rakudo has begun to catch up or overtake Niecza.
Maybe something like this...? foo.cgi use CGI; use XML::XSLT; my $q = new CGI; my %styles = (by_name=&gt;'byname.xsl',by_price=&gt;'byprice.xml'); my $xslt = XML::XSLT-&gt;new ($styles{$q-&gt;param("sort")}); print $q-&gt;header(),$xslt-&gt;serve("phones.xml"); $xslt-&gt;dispose(); Then in your html, &lt;a href="foo.cgi?sort=name"&gt;Sort by name&lt;/a&gt; &lt;a href="foo.cgi?sort=price"&gt;Sort by price&lt;/a&gt; Edit: This is of course skeleton code - you'll of course want to sanitise parameters and maybe use a more "modern" CGI module or whatever in real life...
I wish I knew what this did and how to properly use it :P when I send this through the web server I just get a print out of the code back :/ is there a text/cgi type I should be using?
Make sure your web-server is configured to accept CGI Perl code!
Yeah I don't know how to do this part xD again I don't know if the way I'm doing it is common, but this is what I have: sub lookup_file { my $url = shift; my $path = $DOCUMENT_ROOT . $url; # turn into a path $path =~ s/\?.*$//; # get rid of query $path =~ s/\#.*$//; # get rid of fragment $path .= 'index.html' if $url=~m!/$!; # get index.html if path ends in / return if $path =~ m!/\.\./!; # don't allow relative paths (..) return (undef,'directory',undef) if -d $path; # oops! a directory my $type = 'text/plain'; # default MIME type $type = 'text/html' if $path =~ /\.html?$/i; # HTML file? $type = 'text/html' if $path =~ /\.php?$/i; # HTML file? $type = 'text/xml' if $path =~ /\.ictml?$/i; # ICTML file? $type = 'text/html' if $path =~ /\.pl?$/i; # perl file? $type = 'text/css' if $path =~ /\.css?$/i; # CSS file? $type = 'image/png' if $path =~ /\.png?$/i; # PNG? $type = 'text/html' if $path =~ /\.xsl?$/i; # XSL file? $type = 'image/gif' if $path =~ /\.gif$/i; # GIF? $type = 'image/jpeg' if $path =~ /\.jpe?g$/i; # JPEG? return unless my $length = (stat(_))[7]; # file size return unless my $fh = IO::File-&gt;new($path,"&lt;");# try to open file return ($fh,$type,$length); } and it doesn't look like it likes the cgi file. Since now I have found a couple of ways to do what I'm looking for, either through javascript or php, but I don't know how to make the webserver accept either of them (although I think php files were working, just didn't really know how to use the code I was shown)
Ok. What you have there looks like a minimal web server example that serves static files. (Nastily, I may add) . Ideally, you should be running a proper server like Apache that knows how to handle CGI, and run scripts. You *can* do this yourself, but it's a fair amount of research and work.
I saw on w3c that they recommend doing it through js. I don't know a hell of a lot, but enough to know what everything is doing. The code they recommended using is: &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Whatdroid - Which Android is right for me?&lt;/title&gt; &lt;link rel="stylesheet" media="all" href="styles.css" /&gt; &lt;script&gt; function loadXMLDoc(dname) { if (window.XMLHttpRequest) { xhttp=new XMLHttpRequest(); } else { xhttp=new ActiveXObject("Microsoft.XMLHTTP"); } xhttp.open("GET",dname,false); xhttp.send(""); return xhttp.responseXML; } function displayResult() { xml=loadXMLDoc("maindata.ictml"); xsl=loadXMLDoc("samsung.xsl"); // code for IE if (window.ActiveXObject) { ex=xml.transformNode(xsl); document.getElementById("example").innerHTML=ex; } // code for Mozilla, Firefox, Opera, etc. else if (document.implementation &amp;&amp; document.implementation.createDocument) { xsltProcessor=new XSLTProcessor(); xsltProcessor.importStylesheet(xsl); resultDocument = xsltProcessor.transformToFragment(xml,document); document.getElementById("example").appendChild(resultDocument); } } &lt;/script&gt; &lt;/head&gt; &lt;body onload="displayResult()" &gt; &lt;div id="example" /&gt; &lt;/body&gt; &lt;/html&gt; Though it's just not displaying anything once it has loaded
From here-on in, your browser debugger is your friend.
If that's your entire page you don't even need the JS. Have the XSL generate the entire XHTML document in the browser.
Yes, there are many types of concurrency, but apparently, threads pose the most problems to a team developing a language. I'm not quite sure why this is.. It doesn't seem like such a big deal..
Threads often have complicated locking schemes for shared memory. Implementing concurrency via message passing (such as Erlang does) and not shared memory makes locking related bugs go away.
Mostly because we know what happened with concurrency in Python and Ruby and Java, and we know they're all terrible. Threads share too much, and fork() doesn't share enough. The trick is to find a sophisticated middle ground.
Are you serious? It should be obvious that just exposing POSIX threads cannot be the answer for an interpreter/virtual-machine based implementation. Also, are you disputing that it would worthwhile to look into higher-level concurrency abstraction that just threads with shared memory and DIY locking? Languages specializing on such higher-level abstractions, like Erlang and Clojure, are doing quite well.
PCRE is not "the old regex engine". It's a separate library that mimics Perl's regexes (but not completely) for use in other projects that want to emulate Perl's regexes.
&gt; Mostly the missing of a JIT compiler and the calling conventions that produce way too many GC-able objects. Parrot's calling conventions have problems, but PIR and Winxed code can beat Perl 5 on several benchmarks. One of Rakudo's biggest problems with regard to Parrot's calling conventions was (I don't know if it still is) using exceptions pervasively for control flow. Another of Rakudo's problems is that what it wanted from Parrot's lexical model Parrot didn't provide. I spent at least year asking Rakudo developers to make a list of the features they wanted from Parrot's lexical model. At least two of us (and maybe three or four) were ready to revise Parrot to meet their needs. It didn't happen while I worked on Parrot.
Even if you just try to wrap pthreads, the problem still isn't trivial. Consider simply adding two numbers. Perl 6 is dynamic, so the "add(Int, Int)" method can be redefined at any time. That means that each call has to do a lookup to see what code to run. That lookup table is shared data, and needs to be protected by locks. Suddenly we can only add numbers in one thread at a time. Now, clearly that isn't the code that we actually want to write, but coming up with the right way to deal with this has a surprising number of gotchas. Most reasonable solutions involve changing the language semantics. But until you decide what higher level parallelism abstractions you want, you can't decide which low-level semantics you really need. 
"Exposing real pre-emptive threading with shared mutable data structures to application programmers is wrong". (From http://www.tbray.org/ongoing/When/200x/2009/09/27/Concur-dot-next) Do you agree?
Right. Star releases typically come out a few days after a monthly Rakudo compiler release but add modules etc. So in most cases most users are better off waiting for the subsequent Star release.
Star releases are monthly again? Except for last month?
They skipped March (so there were releases in jan, feb, april, may).
Interestingly, Larry Wall's original intention was to create a C obfuscator, and thus Perl was born. Edit: It's a joke.
You thought you were on Slashdot?
Neat. :) Is the source on github?
Any community with a sense of humor.
My favourite discovery lately is Moo and Mo when Moose is too much of a Pig.
Of course I wasn't trolling; I was just demonstrating that saying you are worried about job security in Perl then talking about moving to Haskell is rather silly, when there are orders of magnitude more Perl jobs. I wasn't saying anything about Haskell as a language. I like functional programming too (although my favourite is [Racket](http://racket-lang.org/)), and I wish there was more heterogeneity of languages out there in the 'real world'. If you can find a Haskell job, well done and I hope you enjoy it!
I've just started looking into Moose. What do you mean that it can be a pig? And what is the difference between Moose and Moo/Mo?
It's obfuscated though...
I like the one with the parrot. Because it's dead, you see. Funny, because it's dead.
Large/complex Moose classes and relations add a compile-time cost to process startup. This generally isn't a problem for long-running processes like webserver or batch processes, but can slow down development if you're in a tight change-&gt;test loop. Edit: Plus installing Moose gets you about 70 new modules, with about 20 further dependencies.
Using a `do` block to slurp a file. my $contents = do { local $/; open my ($fh), '&lt;', $filename; &lt;$fh&gt;; }; Been reading *Effective Perl Programming 2e* and realizing how much I had been letting my Perl knowledge stagnate. It's both depressing and invigorating.
That's also one of my favourite idioms. I'm starting to use it more and more for stuff where I need to do a bit of work to get a single value that'll be used in my main program, but I want the work to be in a small lexical scope so it is all reclaimed.
That parentheses are called round brackets
Did you make that Moose class immutable?
Perl used to be big. :| What happened?
Really cool to see such a useful module getting active development again.
/facepalm
That's not bad looking Perl for a first go. See my reply to sOMa for a couple of points. Some other minor things (you did say to fill you with knowledge!): Don't use call a subroutine like this: &amp;print_help; Do it like this: print_help(); The rule of thumb is not to use the &amp; format unless you know what the difference between those forms is :-) I'd have written lines 21-26 more like this: my $cmdipargs = ""; while ( my ( $key, $value ) = each(%inputs) ) { $cmdipargs .= "$key $value "; } my $returnip1 = `$chkcmd -H $hostaddr1 $cmdipargs`; my $returnip2 = `$chkcmd -H $hostaddr2 $cmdipargs`; Not vastly different, just a tad shorter. Note also the use of the .= operator for concatenation. I'm sure your if..then..else blocks could be shortened significantly too. I *think* you could replace lines 34-132 with the following, but I've not tested it in any way.: my $status1_value = $state{$statusip1[0]}; my $status2_value = $state{$statusip2[0]}; if (not defined $status1_value or not defined $status2_value) { // Equivalent of your "shouldn't be here" blocks. // You'd want to make sure you get suitable exit value in this case. } else { my $best_status = $status1_value &lt; $status2_value ? $status1_value : $status2_value; print "$statusip1[0] - $statusip1[2]$status1_value $statusip2[2]$status2_value\n"; exit $best_status; } Another minor thing; you could write your print_help subroutine using a "heredoc" instead of 2 separate strings, which isn't vastly different in your case, but gets more useful the longer your messages are: sub print_help { print &lt;&lt;END check_2ips - Checks 2 IP Addresses - if 1 is up, returns status OK Usage: $0 /path/to/nagios/plugin [nagios plugin arguments] END exit(0); } NB: the word "END" mustn't have any whitespace to the left or it won't be recognized as the heredoc end marker. If you've got any more questions, please ask! I love Perl, but my current job has me writing in C# (which is nice, but it's not Perl), so it's nice to keep my hand in.
&gt; "You need to switch $inputs = {} with my %inputs = {}, but my %inputs will do." It's lucky you didn't write that. "my %inputs = {};" would give a warning ("reference found where even-sized list expected") and create a single entry in %inputs where the key is a stringified version of an empty hash-ref and the value is undef. But I know you really meant "my %inputs = ()". :-) 
An additional comment: I wouldn't bother enclosing the main part of the program in that long `else` block, because you have an `exit(0)` inside the `print_help()` subroutine. That is, you could just as well write it like this: if ( $chkcmd eq "--help" or $chkcmd eq "-h" ) { &amp;print_help; } my %inputs; # and so on... Some people disapprove of this sort of thing and call it a "dirty exit", but I don't agree with them. However, if it bothers you, you could move the `exit(0)` to be inside the `if` statement instead of inside of `print_help()`. That would make the exit more explicit.
Will you be happy with Linux or iOS instead?
Instead of a comfy chair or instead or perl? Or is this a trick question? ...because, I am already reasonably happy with Linux and iOS.
Agree agree! For several reasons. Chromatic makes the point that perl is rock-solid in maintaining behavior. But in addition to that solidity, perl reduces cognitive load on the developer by doing smart things in edge cases. Cognitive load on developers is the bane of reliability. By providing good abstraction isolation (e.g. polymorphous typing allows numbers to behave more like, well, numbers than any of the fixed types do), perl reduces cognitive load, allowing more reliability in the code that I write. That's why I used Perl two years ago to control all data acquisition tasks in a sounding rocket payload that flew into space. By reliably hiding the complexities of operating system interface and related stuff, Perl allowed us to focus on the algorithms and interfaces between our instrument-control and data-acquisition modules. It worked like a champ, and development/test time for the core of the software was reduced from an estimated 9 man-months to under 9 weeks, and led to successful operation in flight. 
I totally misread that as two colons, not one. I said to myself, "I have to check out this Perl::Reliability module. I wonder what it does."
It would be cool if there were built in profiles so you could just add a switch to the .perltidyrc to get the style you wanted: -allman -pbp -kandr 
That doesn't do it though.... I actually have no idea what that does. All of the braces, brackets, and parenthesis are still on the same line. EDIT: it does appear to put a brace on the next line. Can it also do parenthesis?
You might also check into using [Mouse](http://search.cpan.org/~gfuji/Mouse-0.97/lib/Mouse.pm) with [Any::Moose](http://search.cpan.org/~sartak/Any-Moose-0.18/lib/Any/Moose.pm). Mouse is much faster than Moose and is almost completely compatible. Sometimes though if you need Moose's extra debugging and introspection you can easily swap Moose in using Any::Moose.
The one thing that sold me was roles. But nowadays you can use roles without Moose. 
You are understanding it wrong. You are retrieving `http://geo.craigslist.org/` server-side, and then conveying the result to the user. Since that request always comes from your server, it will never report the location of the user. It sounds like what you want to do is make the user's browser do the connection and then get the headers, but that's not possible. The browser security model (same origin policy) explicitly prevents this. Think about it -- if what you are trying to do were possible, then any site could steal the user's login information for any other site and hijack all their accounts. 
Thanks a lot.
You've received plenty fine answers that explain that the performance difference you observed is mainly an artifact of unfamiliarity with Moose, but there's one very visceral thing i'd like to point out: * Your class MyTest has 8 lines. * Your class MyTest2 has 19 lines. That doesn't only mean that YOU have to type more, it also means that everyone else has to read more to be sure to understand what your class does. And this is only for an extremely barebones class. With complex classes you're bound to get a ridiculous amount of delta between a pure implementation and a Moose implementation. And that is **why you should use Moose: Because it has great syntax**. And if you don't like the specific implementation, you can get either: * Mouse, which is an XS-accelerated Moose; or * Moo, which is a pure perl Moose without the meta introspection; or * Mo, which is a pure perl minimalist implementation of the most basic pieces of sugar.
There are options for how parens work as well. However, I don't think they work quite like brackets and I wouldn't want them to nor does I think the Allman style.
Blog post: http://blogs.perl.org/users/jeff_ober/2012/06/simplified-error-cleanup-with-filtercleanup.html
Why wasn't it just WebService::Reddit?
Now, for how it works: `system()` is a function to pass a command to the operating system shell. "Clear" and "cls" are commands that **cl**ear the **s**creen on linux and Windows respectively. As a preference, I wouldn't do it this way, especially if you're using some of the more advanced output stuff. But for a simple "Clear the screen" command, it works pretty well. [There's a list of other ways this can be done on perlmonks.org](http://www.perlmonks.org/?node_id=18774). [They also give an explanation of why you might not want to use my way](http://www.perlmonks.org/?node=How%20do%20I%20clear%20the%20screen%3F)
So sleep 'time'
When you want to learn the parameters of a builtin function, use [perldoc](http://perldoc.perl.org/functions/sleep.html).
Oh thank you!!
You're mis-understanding the use of the crypt function. crypt() is a one way hashing function. That means that anything you put in is not recoverable. This is usually what you want to 'encrypt' passwords with. It outputs the hashed value so comparing it to a plaintext version isn't going to work. Based on the perl man pages, the arguments to crypt are: crypt PLAINTEXT,SALT This means that you pass in the plaintext password followed by a salting value. For this sample, let's just pass in the salting value of 'foo'. Look up salting values on wikipedia for more information about that. What we want to do is compare the encrypted value in our system to the password that is passed in. Instead of the $pwd being set equal to test, it needs to be set equal to the already hashed value of our password. This keeps it 'secure' in our source code so someone can't sniff the right password. You can see a working example here: http://pastebin.ca/2157657 Now that this is working, you want to notice that the encrypted value of the password 'test' ALWAYS will be 'foy6TgL.HboTE' whenever the salt is set to 'foo'. This is bad in case your database is compromised since every instance of duplicate passwords will easily be seen. Most people use a salting value such as the first few characters of the password, or the username, to make sure that every single user that has the password of 'test' doesn't have the same value in the database. If you're doing anything high security, don't use crypt() and instead look into Crypt::SaltedHash with the SHA-1 algorithm. This ensures that the salting value is random and that multiple users with the same password can't easily be recovered. This also makes rainbow table attacks pretty much useless.
&gt; 3) You're comparing a result of crypt($plaintext, $salt) to $salt, which &gt; makes.. about zero sense whatsoever. This actually does make sense in the context of traditional unix-style passwords where the first two bytes of the hashed password is the salt. For example, look at the first two characters of each line when you run perl -le 'print crypt("foo", $_) for "aa" .. "az";' It's the salt. Also, it's good practice to always use a salt when hashing passwords to make attacks using rainbow tables harder.
So the only was to gain access to the rest of the code is to enter the alphanumeric string that is equal to $crypt_password?
and if i just wanted a raw password I could do this right? #!/usr/bin/perl use 5.014; use strict; use warnings; use autodie; # password is testpass my $target = 'test'; say 'Enter passphrase:'; chomp (my $input = &lt;STDIN&gt;); if($input eq $target) { say '[+] Access Granted!'; } else { say '[!] Access Denied'; exit; } print "OK\n";
Yes, but it's bad security and starting out that can start a dangerous precedent that never gets changed out. It's ok for testing though.
Yes. Hashing the password is the safer way to handle it. That means you have to compare the hashes of the passwords and not the passwords directly.
&gt; http://perl-tutorial.org/ -- seems to not be maintained ... if i can get access to it, I can update it a bit. There hasn't been a lot happening with new tutorials lately, so there wasn't much need to change anything. If you have changes you'd like to make, please just go ahead. You can log in with any openid service or make an account with the wiki itself. Also, could you please tell me how you got the impression that it was: - unmaintained and - not editable by the public? If i can do anything to change these impressions on first-time visitors i'd like to do it.
alright!
Alright, sorry for being so naive, but what exactly does it mean to 'compare the hashes of the passwords'? Also, what does setting $salt equal to 'foo' do?
Well, since you said "plzz" and "thkx"... I'll make sure to steadfastly ignore you. 
step 1: create a hash of the password (using crypt or preferably a more modern hash function like SHA-256) step 2: store the hash somewhere associated with the username step 3: at a latter date get the username and password from someone requesting access step 4: create a hash from the password that same way as step 1 step 5: compare the hashes with the eq operator (i.e. $stored_hash eq $new_hash) step 6: grant access if the hashes are equal. The purpose of a salt is to make it harder to use a brute force attack. You may want to read more about salts here: http://en.wikipedia.org/wiki/Salt_(cryptography) 
How would I print the hash, is the problem I have.
you need to catch the result of `sha256_hex`: my $hash = sha256_hex($test); say "The hash is $hash"; The SHA-256 hashing function does not include a salt for you, so your code should look more like: #!/usr/bin/perl use 5.014; use strict; use warnings; use autodie; use Digest::SHA qw[sha256_hex]; my $plaintext = 'test'; my $salt = "some salt value"; my $stored_hash = sha256_hex("$salt$plaintext"); chomp(my $password = &lt;&gt;); my $new_hash = sha256_hex("$salt$password"); say $stored_hash eq $new_hash ? "good" : "bad"; NOTE: storing the password directly in the program is bad form, it is better to store the hashed value (in this case, e8934218539cf227b7a55758c530f40c53b23cf0afea72bdf53f9ea18b465ee4)
sure, you could create a coderef for each operator, and pass the operands as arguments: my $sum = sub { return $_[0] + $_[1] if not defined $_[2]; # Note: __SUB__ requires perl5.16.0 return __SUB__-&gt;($_[0] + $_[1], $_[2 .. -1]); }; my $lessthan = sub { return $_[0] &lt; $_[1] }; ...; But WHY... this is an obscure thing to do, and your problem can almost certainly be solved another way. Why do you think you want to structure your code this way? 
I'm a fairly junior programmer, so please excuse me if my question is stupid :P I just feel if I'm running this multiple times. If it is to use user input, it would be through CGI app. I would prefer to be able to have those couple of lines rather than: if ($operator eq '&gt;') { if ($totalCost &gt; $amount) { print "blah"; } } elsif ($operator eq '&lt;') { if ($totalCost &lt; $amount) { print "blah"; } } elsif ($operator eq '&gt;=') { if ($totalCost &gt;= $amount) { print "blah"; } } and so on. thanks for your reply
 my %operators = ( '&gt;' =&gt; sub { $_[0] &gt; $_[1] }, '&lt;' =&gt; sub { $_[0] &lt; $_[1] }, '&gt;=' =&gt; sub { $_[0] &gt;= $_[1] } ); if($operators{$operator}($totalCost, $amount)) { print "blah"; }
If you have a limited number of alternatives to handle, create a hash my %OPS = ( '&lt;' =&gt; sub { return $_-&gt;[0] &lt; $_ -&gt;[1] }, '==' =&gt; sub { return $_-&gt;[0] == $_ -&gt;[1] }, '&gt;' =&gt; sub { return $_-&gt;[0] &gt; $_ -&gt;[1] }, ); die "Unknown operator '$operator'." unless exists $OPS{$operator}; return $OPS{$operator}-&gt;($op1, $op2); If you have a large number of cases to handle, you might consider building a statement and putting it into an eval{} ... but first you have to "untaint" it from user input, eliminate the possibility of a malicious just-fired employee using it to delete files or damage data bases ... or of an innocent slip of the finger causing the same harm 
That looks great, thanks!
&gt; I understand, the user input would most likely be from a dropdown menu in a CGI app though. You can send any user input you want to any HTTP server. It's trivial. You can never trust the client.
Thanks a lot for the insight. That makes a lot of sense! :D Now i'll have to see how to get it in though, because all of the HTML is generated statically. :/
A bit late, but please take this advice anyhow: Tutorialspoint is terribly out-dated and provides information on Perl 5.1, where we're already up to Perl 5.16. Anything you'll learn there will be positively dangerous in current times. Please have a look through http://perl-tutorial.org to find better written and more up-to-date tutorials. :)
Hey, since I posted this, I have a much better understanding of hashes and whatnot. What I don't understand, is how in the sweet tits that you found the hash of $input w/o the salt. #!/usr/bin/perl use 5.014; use strict; use warnings; use autodie; use Digest::SHA qw[sha256_hex]; my $oldhash = '6a7b936e1015f6a7117cb203ee6ef872bef8e52d0a2783b8e9ad620ea7be89ab'; my $salt = 'chocolate'; chomp (my $userpwd = &lt;STDIN&gt;); if(sha256_hex("$salt$userpwd") eq $oldhash) { print "Access Granted!\n"; } else { print "Access Denied!\n"; } is my script, but I don't know how you could leave the salt out and still find the hash.
&gt; I don't know how you could leave the salt out and still find the hash. I just did not bother using salt at all. It's purely optional, to make a hash rainbowtable-resistant and thus a bit more secure. Hashing function (the sha256_hex) accepts a string and returns a hash of that string (as you can see in documentation here https://metacpan.org/module/Digest::SHA ). Whether or not to add salt to your string is up to you.
Perl's parser considers `$ =` and `$=` the same thing. You can also write `my $ foo`.
Thanks to a "mis-spent" youth coding up 6510 assembler on a Vic-20, I can still read ASCII-encoded text, although I'm way slower than Perl! I got as far as "I found a ", then gave up and just read the reply with the answer. 
It is possible to make your program usable by other people without giving them access to the source code - using CGI or any other network interface.
The title says consecutive number so I think it means detecting the numbers in "asdf1234" etc. That said a limit of two numbers seems low to me. I can't think of cute way to do it but /(01|12|..|89|90)/ isn't that long and on the plus side it is highly readable.
Sorry I meant two consecutive, like password2345 or password2222
Do you have more of the code in your program? ...To me this looks more like a joke. 
You could match two consecutive identical digits (as in password22) using backreferences, like this: (\d)\1 Runs of numbers like 12, 34... I'd probably match as kinnu suggested. Alternatively, just match any string of digits with `(\d+)`, and then examine `$1 ` to see if it consists of duplicated digits or runs of digits. Something along the lines of my @digits = split(//, $1); do { if ($digits[0] == digits[1]-1 or $digits[0] == digits[1]+1) { # Do whatever } shift(@digits); } while ( scalar(@digits) &gt; 1 )
Password strength checkers can be a real pain for users. Make sure you build in contingencies so that a strong password is not marked as weak because of a single silly rule like '2 consecutive numbers'. For example, I think SH$34Visw@ is a pretty good password, but it fails your consecutive numbers check. What I have done in the past is when a password fails a test, I remove the offending characters and retest the password to see if a shorter version of the same password can be considered a strong password. In this case it would check if SH$Visw@ is still a strong password and it would allow the original password even though it failed one of the tests.
Just an FYI about consecutive character sequences.... it's actually a good thing for password strength. I've done quite a bit of research into this area, nothing exhaustive, but while consecutive characters may not increase the entropy of the string, they do not decrease, and actually since the extra character is lengthening the string the entropy goes up..... but here is why the password strength increases, and it has nothing to do with math. The most common form of password compromise is over-the-shoulder eavesdropping.... typing a single character twice quickly is very extremely difficult to detect with the eye. That is why crack lib has a feature to forgive consecutive numbers, but only once in a string.
I thought so too, but I checked it out via google just to make sure. That is the correct URL.
Have you checked this [site](http://www.bribes.org/perl/ppm64dir.html) and configured as it says? I get #Pkgs = 89
[inotify maybe?](http://stackoverflow.com/questions/5316178/watching-multiple-files-with-inotify-in-perl)
It sounds to me that you're looking for a publish/subscribe framework. AnyEvent is an event loop abstraction library; it allows you to use timers, signal handlers, and asynchronous I/O. I think you're looking for something like Object::Event.
What is the URL you are trying?
I'm not sure if I have the same problem you do, or if I just feel like your frustration is similar to mine. My first suggestion is to check out Mojolicious since they claim to be a next generation framework. My problem is that having used framework systems in other languages, I don't like the way people promote Mojolicious coding. Many people talk about MVC in one file, or small web apps all in one file. Which is nice for readability but not good for code separation and enforcing MVC. I can't find anything that will generate an MVC structure from an existing schema, so starting an app seems to be a gigantic pain. Plus if you look at some Mojolicious examples it seems gross: http://marcus.nordaaker.com/slides-from-my-mojolicious-presentation/ That's not to say it isn't a good approach, I just haven't found an example I can really dig yet. Hopefully you'll get a response with something that meets your needs.
POE? Do people still use that? I have had good experiences with it, I wrote a behavior based 'bot catcher that sits in front of apache that's been working great for &gt; 3 years.
Would [DBIx::Class::DeploymentHandler::HandlesDeploy](https://metacpan.org/module/DBIx::Class::DeploymentHandler::HandlesDeploy) or [DBIx::Class::Schema::PopulateMore](https://metacpan.org/module/DBIx::Class::Schema::PopulateMore) be of any help? 
POE is definitely alive and well, although I think rcaputo has started focusing more on his next-gen framework, Reflex (which I'm told is what POE would have been if Moose had been around when POE was first started).
The bone head,JFDI way is to use string eval. Tt's dangerous from a code injection point of view but it is also expedient. So assess your user base and take it from there.
While learning how to do this the manual, hard way (Well, the real hard way would be to use raw DBI stuff, but whatever), if your end goal is a web application, take a look at [Catalyst](http://www.catalystframework.org/). It's much more similar to Django and RoR, though, probably more powerful than either. I'm not a fan of the model Django uses for the request/response stack.. thingerjiggy. In fact, if you've got an existing schema, the various Catalyst helper scripts will generate a working model for you: &gt; `script/myapp_create.pl model SomeDB DBIC::Schema MyApp::Schema create=static dbi:SQLite:/path/to/some.db` And so on. &gt; But so far, the only tutorials I've found (and the answers from other people) are to create the database first, then generate the schema; this is unacceptable, primarily because the site then become reliant on that specific database, but also because this (in my mind) is backwards. This isn't backwards. This is forcing you to think about what sort of data you are storing and creating a relational database to handle it properly. If you're storing shit willy-nilly, you perhaps want a NoSQL solution, like CouchDB or MongoDB instead. But, because I'm a nice guy, I'll point you at the answer to your question. DBIx::Class::Schema has a `deploy`method intended to create your tables and whatnots for you, based on the loaded schema. See: https://metacpan.org/module/DBIx::Class::Schema#deploy
Thanks for the reply. Indeed, my end goal is a Catalyst Web App. It was recommended that I figure out the DB stuff first since that's the part that I don't understand and will cause issues; also the DB should operate independently of my Web App so I can perform unit testing on the DB directly. &gt; This isn't backwards. This is forcing you to think about what sort of data you are storing and creating a relational database to handle it properly. I don't understand how designing the DB in SQL then generating Perl code is "proper", and writing Perl code to describe the DB then using Perl code to create the tables, etc. is "willy-nilly". I definitely do want to define my DB and relationships, but I'd like to do so in a script able and easily repeatable fashion, such that running a "deploy" script handles the DB configuration. I'd really like to design my database without mucking around in the database itself. Honestly, I have looked at NoSQL, but don't know enough about SQL/Databases to make an educated informed decision. So I stick with what I [hardly] know. Thanks for the link to the deploy docs. I am using the deploy method to deploy my database, which seems to work, the problem I am running into is when I attempt to load data. The errors don't seem to turn up any useful information on Google either. Again, thanks for the reply.
I also liked building a site in mojolicious. 
It sounds like you may be after something like: https://metacpan.org/module/DBIx::Class::Migration::Tutorial (though I confess I haven't actually had a chance to use it yet).
Ok, thanks. I'll give it a shot.
Awesome! Thanks for the link, I think I'll buy the book, it's only $35.
Ok, I'll give that a shot. Thanks.
Not a problem. You would want to customize you database when you need your application to be efficient. If you are expecting a small amount of traffic and your web app isn't very complex, then you probably will never run into database bottlenecks. However, if you want to design an application to support a lot of traffic, you are going to want to take the time to plan what kind of tables you will store your data in and what relationships those tables will have to one another. IMHO writing an application before you think about how you are going to store the data and what that data is going to be, is putting the cart before the horse.
...in this case, [\[Git::Describe\]](http://metacpan.org/module/Dist::Zilla::Plugin::Git::Describe) (thanks, rjbs!) My core dist.ini now includes: [InstallGuide] [MetaConfig] [MetaJSON] [Git::Describe] [PkgVersion] [NoTabsTests] [EOLTests] [Test::Compile] [Test::DistManifest] [Test::MinimumVersion] [Test::CPAN::Changes] [Test::ChangesHasContent] [PodSyntaxTests] [PodCoverageTests] [Test::Pod::LinkCheck] [Test::Pod::No404s] [Test::CheckDeps] :version = 0.005 fatal = 1 [Git::Remote::Check] remote_branch = master [Git::Check] allow_dirty = [Git::CheckFor::CorrectBranch] :version = 0.004 release_branch = master release_branch = stable [NextRelease] format = %-9v %{yyyy-MM-dd HH:mm:ss ZZZZ}d [Git::Commit] allow-dirty = Changes commit_msg = %N-%v%t%n%n%c [Git::Tag] tag_message = v%v%t [Git::Push] [InstallRelease] install_command = cpanm . [Clean] 
You need to make a pluginbundle sometime. Then you can just rerelease all your stuff without even changing anything. :D
also hop on #dbix-class on irc.perl.org where people are generally helpful - populate is quite powerful, but it's not necessarily easy to interrogate the docs if you start doing relatively exotic database-stuff where you start to need to give the Result class definitions' metadata a real beating.
ok, so work on it piece by piece.
I think from the glob perldoc page this is what's happening: If non-empty braces are the only wildcard characters used in the glob, no filenames are matched, but potentially many strings are returned. For example, this produces nine strings, one for each pairing of fruits and colors: @many = glob "{apple,tomato,cherry}={green,yellow,red}"; I can't offhand find a way to do this with glob. I think your -e check is the best solution when you aren't using wildcards. 
Thanks! This does the trick! I changed the line to push @listing,bsd_glob("/sftp/Mob/unzipped/$mobyesterday.*",NOCHECK); and now it works as I expect.
That's what I thought too, but apparently this turns off the normal behaviour.
I'm stupid :(. 'use strict' should be the first thing I do when I start a new script, which I neglected to do.
This is odd, someone at the Phoenix.pm meeting last night was talking about glob. Same dude? I've never used it, so I have no real relevant comment, just sayin hi if you're the same guy. And now you have to figure out who I am...
sorry I had some trouble linking it :P
The problem is that on line 36, you're specifically opening the file for *appending*, but then trying to read from it. 
I don't think this is needed. ~~Does the OP having use strict; and use warnings;?~~ **Edit:** OP does have these. I (stupidly) didn't look at the code beforehand.
I think you're spot on here.
It's been a while since I've done any significant work in Perl, unfortunately. First thing that comes to mind: it doesn't look like you're catching any errors that might occur in your `open()` call. You can do so like this: open(...) or die $!; Also, I can't remember: are you allowed to re-use filehandles like that? Might be worth double checking.
use gist.github.com or pastebin.com. the syntax on reddit to link something is &gt; [ link_text ] ( http://actual_link ) (of course without the spaces betwee square and round brackets )
I wrote [Modern Perl](http://onyxneon.com/books/modern_perl/index.html) for that.
someone on this subreddit told me to use that site because pastebin is "ad-ridden crap' his words not mine
Yeah when I was writing this I was thinking, "Man, isn't this what subroutines are for? Meh." So yeah I will look into that :) thanks! EDIT: Now that I think about it this will be version 0.5, I will try to condense the code to thew bare mininmum next time with subroutines and whatnot
doesnt something like; if ($condition1 eq $condition2) ? good : bad; work too? I saw this somewhere, idk if the code is spot on
No. Drop the *if* and you've got a proper ?: expression. Interesting side note, you can also use ?: expressions to do conditional assignments: my $str; $str = ($x &gt; $y) ? "X is greater than Y" : "X is not greater than Y"; print $str;
Awesome!
wat?
Oh, okay
This isn't a bug, it's standard behaviour: glob just expands potential filenames, it doesn't check for existence... except for when you use a wildcard, where it needs to look at the filesystem to see what the wildcard can expand to. ie: The magic that checks the filesystem is a side-effect of the way wildcards work, rather than a general behaviour of glob() itself. Others have suggested bsd_glob(), but personally I'd just stick with -e to make it explicit that you're checking for file existence too.
I may have been wrong (I've seen somebody do this before, so I thought it might apply here) but as you'd already shown the user the contents of the 'database' earlier, I assumed that the only reason you were reading-and-printing it all again was that you wanted to "get to the end" of the file, so you could then append data. If that *is* the case, then all I'm saying is you don't need to do this - that's what "append" does for you - it adds data to the end of an existing file. As for the 3 argument open (and lexical file handles and suchlike) , see any modern perl tutorial or book, like the one by our own [mr chromatic](http://modernperlbooks.com/mt/index.html).
1. No i was opening to make it so the appender (if that is a word) can see what is displayed before he/she starts typing, I understand the idea of appending. 2. SHIT! I just bought 2 perl books ([this](http://www.amazon.com/dp/0596000278/?tag=stackoverfl08-20) and [this](http://www.amazon.com/dp/0596520107/?tag=stackoverfl08-20))
I would probably forgo trying to do it via apt or any other distro package manager. They tend not to get updated to all the latest versions and they'll miss out on the more obscure modules you'll end up using sooner or later. You can kinda get away with it on Gentoo, but even there, I found it to be just another piece that can go wrong. Instead, use `sudo perl -MCPAN -e shell` like everybody else.
http://www.cpan.org/
Aptitude has almost all the useful stuff in CPAN. Using 'apt-cache search Module::Name' might help find the name that the package system gave it. 
When I have root access, my practice has generally been this: have 2 totally separate Perl's on your system: * the system Perl that comes with your OS, and * the one you install yourself from source (off in its very own /opt/perl-x.y.z directory) For the system Perl, *only* install modules via your OS package manager (for example, `apt-get`). Never use something like cpanm with your system Perl. With your own hand-installed Perl, only use something like cpanm to install modules --- not your OS package manager. If you're new to Perl 5, for now stick to just using the system Perl and installing your modules via `apt-get`. Search for modules like so: `apt-cache search whatever`. Note that deb package names of Perl modules will look like `libfoo-bar-perl` (which would correspond to the Foo::Bar Perl 5 module). Ah, also, you asked specifically about `aptitude` ... Although for a while it appeared that the aptitude tool might replace apt-get, I don't think that has been the case. I suggest using the combination of apt-cache for searching for and getting info on various packages, and apt-get for managing their installation and removal. Also, if you don't have root access on the machine, but would still like to install modules into your home directory using cpanm, I think [local::lib](http://search.cpan.org/dist/local-lib/) is used for that purpose, though I haven't used it myself. Another option for you --- if you don't have root access --- is to install your own Perl into ~/opt/perl-x.y.z, then install cpanm into that Perl, and use that cpanm to install modules into your own Perl's site_perl dir. *Edit*: Finally, as pointed out by mithaldu and illusori, there is a tool called "perlbrew" which installs your very own Perl for you. I've never used perlbrew --- the Perl 5 install procedure is pretty straightforward, so I haven't felt the need to use other tools to manage it for me. 
The general recommendation is to not do that to the perl installed by your package manager, since mixing stuff managed by the package manager and stuff managed by cpan may not end well. Instead, consider installing a new perl that you manage yourself (it isn't that hard) in `/usr/local` or `/opt` or `$HOME`. [Perlbrew](http://perlbrew.pl) can help you with that.
most current installations of perl have cpanm: $ cpanm Module::Name::Here Might need to run as root. You can also try perlbrew for your own installation of perl in your home directory. 
Being that you are learning, use perlbrew. What it will do is install perl into your home directory and allow you to screw it up all you want and not hurt your system install. I am sure at some point in time the scripts you write will need to be deployed and at that point in time you can either install from apt or you can use dh-make-perl (for those not in apt-get). perlbrew may seem overkill, but its nice to be able to play and understand whats going on without worrying about killing anything.
At this stage, anything will do
Data::Dumper automagically exports "Dumper" into your namespace. Not all modules do that. See: https://metacpan.org/source/SMUELLER/Data-Dumper-2.131/Dumper.pm#L24 - That's the line where Data::Dumper Exports the Dumper subroutine.
Since Data::Dumper is used before your print statement, perl "knows" about the subroutines that Data::Dumper exports. So the DWIM part of perl's parser guesses that you intend to call Dumper rather than write to a filehandle called Dumper. perl's DWIM (Do What I Mean) features are a mixed bag. Also methods are just subroutines.
Subroutines called as a function do not need parentheses as long as they are declared before you use them. Data::Dumper exports Dumper() when used thus declaring it. Any statement after that using Dumper() mau omit parentheses. subs called as methods always need parentheses when used with arguments, but do not require them when no arguments are provided. Also sometimes there is ambiguity in the parser that would require parens, example: 'Dumper BareWord' may be interpreted as BareWord-&gt;Dumper(). In this case adding parens is necessary to disambiguate.
Looks like a good time to buy some Perl stock to me!
Yeah, should definitely be Dumper \@array ; 
huh, like as a best practice thing? I've never used Dumper that way, but I mostly use it for $hash_refs anyways
Right, right. Worth mentioning. Sort of under "clarity" but sort of not. 
Why not use 'git bundle' and FTP just that one file?
My advice: use [perltidy](http://perltidy.sourceforge.net/). Not meant to be hypercritical, but some of the use of whitespace is kind of sloppy. Specifically, use 4-space tabs (replacing the tab character with spaces), consistent spacing around brackets, and try to keep linewidth under 80 (some places, with tabs included, it seems to be over 100). These are my tab options in vim set expandtab set shiftwidth=4 set tabstop=4 set smarttab Then I use `:retab` to replace tabs with spaces. Edit: for those who don't seem to think this is a good suggestion, http://perldoc.perl.org/perlstyle.html
Just a little quibble - 80 character lines are a little old-fashioned and don't make as much sense given the massive wide-format monitors we all have now. A limit of 100 or 120 characters may be more appropriate, especially if you like using verbose "self-documenting" variable and function names.
It's funny that Windows uses cls, but they use dir for directory listing, instead of ls.
Excessively-long lines aren't usually readable, and you'll often want to have several files open side-by-side in split windows / multiple terminals / whatever, so 80 chars is still a good limit to follow, IMO. When I'm working, I usually have Terminator taking up the full screen, split into various terminal windows within it, usually in 3 columns. Works well for me, wouldn't work nearly as well with wider code. Editing HTML is one time I sometimes find longer lines useful, though.
It must be just me, but I have never been able to understand why the consensus seems to be that using spaces is better than using tabs. Could somebody care to explain why ?
The general argument for spaces is that they are absolute. They always display the same way. The general argument for tabs is that they are flexible. They allow you to display the same file with different styles of indentation (I like 8 spaces; you like 4; with tabs we are both happy). The problem with tabs comes when you use them for alignment and not indentation. Changing the tab size misaligns code. This is why the hybrid approach is my favorite: tabs represent nesting levels, spaces are used to line up code.
As pointed out, excessively long lines are harder to read. However, they're also often a code smell of trying to pack too much logic into a single statement.
Some of us really, really like opening multiple columns of code side-by-side. 80-character lines make that much easier.
Sounds reasonable, is more or less what I am already doing anyway.
Thanks for the great advice (and a link and vim settings)! I will put in the todo's to refactor the code and conform it to 4-space tabs and better whitespace consistency.
let my tabs alone!
So, I guess you like scrolling a lot? $fields-&gt;{some_variable}{some_other_variable} = $source-&gt;{more_variables}{here_to_come} if $fields-&gt;{some_variable}{line_breaks}; 
I just tried to view one of the streams, but it requires Silverlight of all things &amp;#3232;\_&amp;#3232;
The streams, as well as professional camera men, are provided by the venue itself, so we gotta take what we get.
Install Moonlight for Chrome/Firefox and you're good to go. 
Yes, although the details of when and where are still to be worked out. UW is only making them available until the end of the conference.
My vim wraps long lines, take a look at :help wrap. I find it much easier to read than arbitrarily inserted line breaks.
There is no reason to remove the use strict/warnings. You should always use those, imho. It promotes cleaner code.
No, I will buy it too. I love being able to see the content. But love more holding the dead tree in my hands. If I ever get a kindle (or equiv) I would get the mobile version as well. Thanks!
I tend not to buy too many paper books these days (running out of room on the bookshelf, and they are also impractical for travel), but I would gladly pay for a pdf version. Is there one available? (I didn't see it on the website.)
I just bought that book....oops.
This is a pre-release. O'Reilly does (some) early release ebooks, but I don't think Wrox does. Once it's released, it should be available as a pdf.
Thank you for posting this. I'd love an HTML/EPUB dump of this. Was hoping to see one in this comment thread tonight, but I suppose that's what the weekend's for.
Perl 5.16.0 is now released; Chapter 1 should be updated to mention this.
You could also check out the script: https://github.com/robinsmidsrod/yapcna-streams/blob/master/yapcna-streams.pl, which will open selected room stream with vlc. Pretty useful!
I think so. There have been formatting changes to accomodate the electronic editions, but I don't know offhand what they'll be. I'm just focused on finishing it right now.
1) I'd suggest suggest using LWP::UserAgent even though I haven't used WWW::Mechanize at all. 2) Not really. You could just check if the response was successful. 3) As long as you know where to submit your data, the html is irrelevant.
WWW::Mechanize
A PDF of the handout I gave attendees can be downloaded at this URL: http://perl.scaffidi.net/TEPHT-List2.pdf?attredirects=0
I liked it. Maybe it's the ADD in me...
You might want to make this the link, and kill the slides. 229 slides...
You should probably use lexical filehandles and the 3-parameter form of `open`. #!/usr/bin/perl use strict; use warnings; use autodie; open my $in, '&lt;', $ARGV[0]; open my $out, '&gt;', 'Ecoli_proteins_with_GO.txt'; my %data; while (&lt;$in&gt;) { chomp; my @line = split /\t/; my ($id, $go) = @line[1, 4]; push @{$data{$id}}, $go; } for my $k (sort keys %data) { print {$out} "$k\t", join(q{,}, @{$data{$k}}), "\n"; }
What's the advantage of this? 
http://stackoverflow.com/a/1479771 http://me.veekun.com/blog/2011/04/13/perl-worst-practices/
Y U NO POST EARLIER? I just bought 'Learning Perl' by Schwartz, foy and Pheonix :(
Please don't build a spam bot, or you will be hunted down an shot. 
First of all, thanks for all the help! But I don't get the point about Mechanize not processing JavaScript. Does that matter? I mean, if I'm only checking for an http 200 packet, where does it come into the picture?