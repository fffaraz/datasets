You can't access local variables without initialization, and you can't call methods like that in class scope. While it's true that you can call extension methods on `null` references, it's not the answer to this question. `A a; a.M();` has left `a` uninitialized, so it can't be accessed.
It‚Äôs a bit more nuanced than that, actually. 
Tasks often cause context switches as well, which are just as expensive. It‚Äôs the price of creating a new thread which is quite high and can be avoided. 
Ah true story. As I mentioned value objects would work (which they do). I assumed that the puzzle was there would be no default value created (which would exclude the obvious answer of struct). But I forgot that a reference variable still needs to be initialized. (I just assumed a reference variable in that format would be given a default value which is null, just like a value object would be) I'll use the excuse of "I wrote it on the train so couldn't check what I said before I submitted it" Lame excuse I know.
C++
I mean, it‚Äôs still just compiler rewrites so..
Actually this program accepts the picture through open dialog. What topics should I learn to be able to design the program I want.
I like [SharpLab](https://sharplab.io/) better.
How come you didn't have to initialize the variable?
It requires a specific kind of `struct`.
Most structs have to be initialized too. Can you figure out under which situation they don't have to be?
All structs that you write are forced to NOT have a empty default constructor, but the CLR supports those. My guess would be, some structs (DateTime) have a special empty default Constructor.
Yup, that's the answer I was looking for.
&gt; My guess would be, some structs (DateTime) have a special empty default Constructor. Nope, `DateTime` does not have any special constructors. You can verify that by looking at the result of: typeof(DateTime).GetConstructors(Instance | Public | NonPublic) .Where(c =&gt; !c.GetParameters().Any())
Hangfire is more background task running, where Quartz is more scheduling. Hangfire also has taken a number of steps to play as nicely with being hosted in a web process as possible, where Quartz is meant to be hosted in its own service (although you can host it in process). Quartz jobs can also be persisted to a data store.
You've pretty much got it. So far as what to Dispose - you generally look at the heavy weight objects owned by your class (i.e not strings, etc.) to see if they implement IDisposable, then call Dispose() on them. There are exceptions though - some of those classes prefer that you call a Close() method (just how MSFT wrote them) so call that instead. You shouldn't have to dispose them in reverse order of creation, but it can't hurt that you order your code that way (this may just be me being overcautious). 
When you await an IOCP backed async method, the thread that the async operation is part of can be returned to the pool until the work of the IO/async operation completes and continues back up on a thread pool thread. The number of active threads at any point is greatly diminished.
Right? There are passable implementations, dirty implementations, barely contained dumpster fires... The list goes on.
Upvote for Hangfire.Console. 
Depends on the implementation. Does it guarantee ordering of the async elements, or first complete first served? Either way, async enumerables would be a nice feature.
Don't let these buzzkills bring you down. You should be proud that you took the initiative to learn and clearly spent sometime trying to make this work. I get the impression that you accomplished your goals, which is always the point. Would your application pass any professional peer/security review? Of course not! But that was never your intention, it was to learn. In the future if (when) you encounter a situation where you need to protect data you'll be able to draw from your experience here. Nice work! 
Ok mr genius
Just make sure you remove that finalizer in each implementation if it's not explicitly needed for unmanaged resources. Otherwise, your objects are going to survive for an extra garbage collection while the finalizer is called.
Agreed. Don't access the same connection from multiple threads, make sure that you having a using block or are calling Dispose() on all connections, commands, data readers, and any other object that is disposable, and your issues will go away. If you are trying to access the same connection from multiple threads because you are worried about overhead of connecting to the database, then don't. Connection pooling, which is built in to nearly every RDBMS client and almost always enabled by default, will help a lot in that arena.
I was able to get Hangfire.Console working with MemoryStorage in .NET Core. If running into roadblocks let me know and I'll compare it to what I've set up.
You can also use it for managed objects explicitly set not to be GC'ed, right?
Use Task.Delay not Thread.Sleep
If you only need the disposable object for the duration of a single method, sure, but if you need it for the lifetime of your own object you need to dispose it manually. Of course you may place your own object implementing `IDisposable` in a using block.
Not sure what you mean exactly. The purpose of the disposable pattern is deterministically cleaning up resources independently of garbage collection.
Sounds like I didn't read OP's post fully. Not sure what he is trying to do 
Thank you very much for pointing me in the right direction. I will definitely look into implementing the OtpKeyProv plugin. So, in layman's terms, is PBKDF2 basically designed to be much slower than SHA256 to prevent bruteforcing?
It's just easier to do it that way, for the same reasons handwriting C# code is easier that handwriting CIL code. And having the C# sources is actually useful for debugging. Cell does not have a debugger yet, and sometimes one just has to step into the generated code with the C# debugger. Would targeting CIL directly provide any benefits, anyway? You're right about the licence files, it felt like a rather minor issue at this stage and it just slipped my mind. I'll add them soon. 
Thank you very much for the positive reinforcement. This was the first project I have ever started in c# so I was expecting to not receive that positive of feedback. Without having any offsite storage to send data to I just used a local database to store the keys to just work on practicing encryption. I guess since I'm not dealing with exporting data offsite yet, the best case I could see is to export the keys to a separate file where the user could store it on a flash drive or something and keep separate from the encrypted data.
The guidelines from Microsoft from a few years ago was for server applications to start twice as many worker threads as there are CPU cores. Obviously things have changed since then... If you're not wanting to use Task/Async, look into the socket async methods (not the same thing, even though they have the same name). They're basically wrappers around the I/O Completion Ports used by the operating system, so they're pretty low-level. The coding effort will be high, but they're performant. Allocate your receive and transmit buffers when the program starts and never free them to avoid memory issues. 
Ahh. The depths of my ignorance on this matter can't be overstated. Always look forward to your comments. :)
We use Hangfire a lot at my work. Hangfire + Serilog + Topshelf are a great combination. With the SQL job provider the Hangfire server polls for new jobs by default every 15 seconds. There is a paid package that uses Redis pub-sub to communicate with the server so tasks start near instantaneously. I've never used the Redis package as the latency hasn't been a problem for us. 
&gt; Would targeting CIL directly provide any benefits, anyway? It would remove an entire layer of parsing an additional AST, gathering the semantic information and emitting the result. Basically compiling once, instead of twice.
I'm starting to do the same. I've had nothing but pain with EF Core. (Well technically I'm using Dapper for materialization and parts of Tortuga Chain for SQL generation. But I still count that as using Dapper.)
What about the "longer than a few sec, shorter than a few min" range? Verboten? üòÅ
Thread stack size can be made as big/small as needed. Where did you come up with a sec+ to run?! That's quite improbable.
I'm interested in writing my own language for educational purposes. I have a novice level understanding on how to write a compiler. In college I studied programming languages and theory of automata for my CS degree. Could you provide me with a few resources that you found useful, possibly a few tips, and, if I haven't asked too much already, could you tell me where in your source code I can find the "most important" examples on how to write a compiler? Thanks!
The disposable interface is used for the Using Pattern. You can implement the disposable interface and call dispose on your own... but you could have just as easily created a dispose method without the interface and done the same thing. The benefit from the disposable interface is when the object it automatically disposed at the end of a using block. using (StreamWriter wtr = new StreamWriter(New FileStream(file)){ // &lt;do stuff with the stream writer&gt; } //The stream writer is now disposed outside the using block 
ORM lite here, in the era of document style persistence these things aren't really needed and just create overhead when my data is in a json blob. 
The company is using TFS and want to "optimize" the wey they do it, truste me I've been trying to understand this way to, but they want my code to be able to run, fetch the information (files) from the TFS and copy said files into my local machine, without the normal and common way, but using the XML as an appconfig, so in case they want to get files from other folder within TFS they just have to change the XML path. I'm still trying to comprehend why, but that's what I got asked for. We're doing Escrow
TFS is definetly not designed to allow you to pull files without it being a checkout... you can try using TF.exe (TFS Command line tool) but I am pretty sure you'll run into issues if you aren't pulling it into a workspace... I am not 100% certain... but I wouldn't even be surprised if TFS stores the files as binary data in the database rather then as actual files on a file system... 
I don't even understand why would you want to do this, I mean you can click on get newest version, literally, you can get the files you need with 3 clicks! and I've been googling, u tube and looking for a way almost for a week and not even one guys uses this method. So far from what I've read, they want to use an XML file as an app.config, where the path for the server lies, then read it through VS, and I assume use the "System.IO.Path.combine" (!!!?) to fetch the files into my local PC to proceed to zipped it and have it ready for customers. That's what I assumed.... 
make a nuget package and use that? you also dont have to upload to the official nuget repo, you can host your own https://docs.microsoft.com/en-us/nuget/hosting-packages/overview
Never happens, at least for the kinds of applications I write.
as i said i also want to use it for work. so adding a potentially unaccessible nuget package is a nono. also doesnt work for my open source projects cause then people cloning it cant get the code =/
Do they even have a timeline to be mostly feature-equivalent to EF.Net?
&gt; in the era of document style persistence So you mean the 1970's? My roommate writes banking software. They desperately want to upgrade to 1980's era relational database technology, but they're stuck on the document model and can't afford the rewrite. 
I wonder if you can make like a seperate git branch or repo or something that is like SVN's "externals" - http://svnbook.red-bean.com/nightly/en/svn.advanced.externals.html Maybe some other git user can help me here, I'm a git pleb, use SVN at work so know way more about SVN than git
Nope. But they do have some interesting plans on supporting NoSQL databases.
there are subrepositories, but again, they are hardwired into the repo then, and have to be accessible from whereever the main repo is cloned. so not possible to use a private one, and i would also have to throw everything together in a single repo (i do a lot of different things with c#, so i dont want game related stuff that might even reference a game engine in a program that analyzes video files or manages distributed computing)
What I've done I guess for that use case is make snippets/gists and upload those and update them when I want Mainly for Extension methods I write and stuff for work and for later personal use still kinda copy hell, but at least you can get a URL to edit/update then use that https://docs.gitlab.com/ee/user/snippets.html
Software design principles matter here :-P. Separation of concerns applies at the assembly level just as much as it does at the class level. Actually, it may be *more* important at the assembly level. &amp;nbsp; Anyway, are you using VS? VS has a **Shared Project** template. Any project that references a shared project compiles the source code in the shared project. With assembly references, the unit that is consumed is the assembly itself -- however, with a shared project, the units that are consumed are the *source* files. Basically, this allows you to put source code in a separate project that *still gets compiled as if you added it to the assembly project*. &amp;nbsp; There are some limitations. The namespace used in the shared project can't be changed. Use google for more information about shared projects and what you can or cannot do. &amp;nbsp; Anyway, I mentioned software design. You should clearly define the scope and purpose of an assembly and use interfaces for segregation and inversion of control. Take logging for example. Create a library project called something like `MyApp.Api`. The scope of this library is basically "this is how to communicate with my app". Add an interface called `IMyAppLogger` that does all the logging you want. Create another library called `MyApp.Adapters.NLog` that references the api library. Create a class using the **adapter pattern** that adapts NLog to your `IMyAppLogger` interface. Reference the api and nlog adapter libraries in your main app. Your entire app should only be using the `IMyAppLogger` interface for logging. However, in the startup, you will do something like this: IMyAppLogger logger = new NLogAdapter(); Besides that one line, everything else should only see `IMyAppLogger`. When you want to swap out a logging framework, create a new adapter for the new logging framework and change that *single line*. Voila. &amp;nbsp; If you have an assembly that contains all your favorite code that you want shared and all the code crosses more than one domain (i.e logging, rendering, analytics, business logic, extensions, etc) then your assembly is already breaking the separation of concerns principle.
So how did the rest of the interview go?
If we're looking for *anyone*, VRAGE, the engine behind Space Engineers (and other games) from Keen Software House, is written mostly (96.8% according to Github) in C#: http://www.keenswh.com/vrage.html
I can't help you with the sharing between private and work code, but you can include files into your project as a "linked" file. Linked files are not copied into your project, so you can have a single location you share the file for multiple projects/solutions. Then if you update the code, all projects get the update.
If you have the syntax node for the call, you can ask the SemanticInfo API to tell you the symbol(s) it is bound to. From the method symbol you can see the parameter information.
would only work if i make all that work public as seperate libraries, which i dont intend for all of it
do those snippets have the ability to define dependencies to other snippets?
when they are linked i cant put them in sourcecontrol =/
no
Swallowing an exception is not *always* bad, but it's a good rule to do it as little as possible. In my project, i do swallow some exceptions. If you cancel a oracle SQL query, it will throw 2 exceptions. In this specific case, sql queries get 2 minutes max to run, if it takes longer, they get canceled. It's handled (logged + entries receive some information that it's data might be out of date), then just swallowed because it's expected to do so. If you (re)throw an exception in a hangfire job, it will be thrown on the fail queue and requeued later. And since i don't want the entire job to fail due to something that is basically treated as a warning, i decided to swallow the exception. But exceptions (hue) do happen on this rule. ^^^I ^^^never ^^^used ^^^the ^^^word ^^^swallow ^^^so ^^^much
Didn't seem to work for me, no log entries appeared. But do share, it might be of use to someone :D
this sounds like more work than copying XD i get the advantages of this approach, but it still requires a lot of manual work to get it working for all the projects. and splitting it up is also hard. for example i need logging targets for AWS, so to keep aws out of all other projects i would need another project/solution just for aws logging stuff. and its similar with a lot of other things. how do other people manage this? or do they just wing it by copying? :P the shared project thing sounds nice, but being able to change the namespace would be nice... i wonder if it were feasible to write a visual studio plugin that can reference files and copy them over if they changed. 
dang =/
I haven't done this yet, but you can host your own Nuget repo and point VS to that repo so you can control who gets access to your libraries. At the very least you should break everything into seperate projects to create libraries.
It's called "snippets", you can edit them freely.
Can you post the code where you're trying to parse it? (not all of it -- just the relevant portion)
It's not from an interview, that would be a terrible interview question.
/r/iamverysmart
Ok, so if Displacement textbox is empty, you'll blow up on the first time you try and parse it. So your test down below to check for null -- you won't even make it that far. Now is a good time to build your debugger skills. Put a breakpoint on that first line and run the program again. Execution should stop when it gets to the breakpoint and you can mouse hover, etc. to inspect variables. And single-step until you get to the place things blow up. 
You could only have gotten the same error if you tried to use d before assigning a value. The code I posted will never throw a null reference exception. The code I posted IS the example of the quote you replied with. d will either be the text in the text box or 0. It will never be null.
I guess any alternative is fine as long as they are kept up to date. RoslynPad is just the one that I happened to be using so I'm comfortable recommending it.
Is there anything in particular with that loop that's confusing you?
I edited my response to add the out keyword, sorry for the omission. That should solve your issue.
[This is my new line of code](http://prntscr.com/il42hm) but the [error](http://prntscr.com/il431c) remains the same. Sorry but I really suck at coding and just wish I could solve this and not waste your time
Very easy to read writing style I was disapointed when I got to the end.
Can you elaborate a little bit more on this implementation thank you! 
Why does all this core stuff feel like reinventing the wheel? View and group by support, really? Been a .NET (web) developer for over 10 years now and I'm still not convinced why I should switch over to .NET core in the first place. Just don't see the need to nor have I ever needed to write applications that can run on a Mac or Linux machine and news like this, albeit positive, really shouts 'premature' and 'empty' as far as I'm concerned.
Of course the error remains the same, the changed kind is never reached as the highlighted like already kills the program. You need to use TryParse up there
.NET Core removes a lot of legacy cruft and bad design decisions found in .NET and ASP.NET, offering cleaner code and better performance. It's definitely worth considering even when hosting on IIS. EF Core: total dumpster fire. Even compared to EF classic, which I was never impressed with.
Why would you want to use "var" instead of "int" in this case? I understand that some developers have taken to "var" whole hog and while I don't generally agree with them I can understand their argument. But in this case "var" is less clear than "int" and there's no savings in typing.
* j starts at 1 * the loop continues until j is equal to i. * increment j by 1 at the start of each loop iteration instead of after (j++ would increment j at the end of the loop iteration). 
``` d = float.Parse(...) //First line if (!float.TryParse(..., out d)) { d = 0; } //Line within the if ``` The comment above gave you the second variant but it's currently not even invoked, as the you should've replaced the first occurrence (where visual studio shows you the error
I would also turn you toward Inversion of Control (IoC) and Dependency Injection (DI). It's a major piece to your puzzle. 
Same error again. [Here's the current code](http://prntscr.com/il4n2w)
THe first line! üòî if (!float.TryParse(..., out d)) { d = 0; } if (!float.TryParse(..., out iv)) { iv = 0; }
I'm sorry I'm so confused. Is this how you meant [it](http://prntscr.com/il4t12)? Although now my output for my calculation is zero but no more errors haha
no prob, we use a actor model system called microsoft orleans as our core system framework, some of the the actors (or grains as orleans calls them) have states. We take those states and serialize them to json and save the blob in the database. This allows us to write a storage provider which is very simple, basically, create a table for every class that implements a state. These tables have when the state was created, an id of the grain that state belongs too, and the state itself in json format. (we can also do timestamp of the states so we can replay the states as events over the grain but let's keep it simple right now) Our core ORM only has to map three columns from the database and can all be done with generics cause all the columns are the same for all data. Then chain it together with a Json serializer and you can easily get a instance from persistence with minimal work. Now i know what you're saying, but we need to run sql reports on our data! Well we have that covered too, we use an ETL server which can take those json documents and create the tabular data for reporting in a different database, so our transnational data isn't getting hit by reporting. Though there is a trade off of not getting 'up to date' data, but it's only an hour or two behind. It runs on a schedule and will query all tables for any transactions which are new, if it finds a new piece of data (or document) it uses SSIS which has a pretty nice etl configuration, to map that data using a mapping class you write. Our core implementation of persistance is the same concept as using like MOngo or other cloud db's out there, you get the json data from the service and then you deserialize into your goodness. We just have to store that document here inhouse cause our CTO is scared of the cloud (I build health and ben admin systems so we have alot of personal data).
You've always got `out d` but apart from that
Hmm, you might be able to do something like layering your private git repos on top of your work repos, or something similar. So at work you pull down your changes for your private stuff, then commit them to your work repo, and vice versa. Id have to think more on how to really do that nicely.
You could hardlink the file. So modifying a file to one repo modify the other. It would be a bitch to setup tho.
The server needs to run the pipeline at least once after the cookie is created in order for the context to update. If you check before the redirect and after a redirect you should see the user identity name only after a redirect.
Install R# and it'll probably refactor your code to that whenever you run cleanup, if you use the default settings.
https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/var
`Dictionary&lt;string, List&lt;string&gt;&gt; foo = new Dictionary&lt;string, List&lt;string&gt;&gt;();` -versus- `var foo = new Dictionary&lt;string, List&lt;string&gt;&gt;();` that is all. `var` != `dynamic`
I went from: 1) I'll never use it, explicit code is good! 2) OK it looks neater, I'm using it all the time! 3) Oh, Sometimes it obfuscates the code. Use it all the time, except not when it obfuscates code... 
"var" doesnt magically make the type weak, I think what you meant was making it dynamically type you can use `dynamic` to get a "weakly" typed variable in C# any dev should know the difference between statically and dynamically typed languages - here is a good summary: https://stackoverflow.com/a/2696369
A good rule of thumb is to only use it on `new` expressions, since you already have the type anyway.
Same here, except that whenever it does obfuscate the code I stop to ask why. Usually it means something else in my API is unnecessarily complex or just plain clumsy.
Or when the assignment and/or name makes it clear what type of object you'll end up with. `var currentUser = userManager.GetUserById(context.userId)` for example.
To ruin the life of another engineer reading your code
Why do you keep creating new posts about the same things? Go back to your previous post and read my answer, where I tell you how to step through your loops, open the locals window and see what the values are, better yet, print out their values and see what's happening
*Technically* you can store them in `object` variables or pass them to generic methods as inferred parameters. It'd rarely be useful (or sensible) outside of a few corner cases, of course.
&gt; how do other people manage this? It seems like you're going out of your way to avoid using NuGet packages. (The way other people manage this) If it needs to be private, it's pretty easy to set up a private feed with authentication. If it's an open-source project then NuGet.org will work fine.
What do you mean by document model ? MongoDb also follows document structures and it's a 21st or maybe 22nd century's tech !
It came into existence with .NET 3.0 to support LINQ and anonymous types. It is impossible to put anything on the left with anonymous types. 
In addition to what others have pointed out, if you use var then later change the type, you don‚Äôt have to update every reference in your code. 
I really think asp.net core does DI right. The built in framework does exactly what I need to create and manage controllers. Most DI I saw was with WPF/Silverlight, where frameworks weren't necessary and often turned into a shitshow.
Prior to the introduction of relational databases, most databases used a hierarchical database model. It wasn't JSON or XML, but it basically the same thing in layout, limitations, and performance characteristics. Relational databases solve a lot of problems that nosql databases like MongoDB have such as data consistency/duplication and an inability to query the data in multiple ways without a significant performance hit. When in the 90's people started mixing document tables with relational tables (a.k.a. lob/blob storage), a lot of arguments were had. And even today we debate the merits if storing files in the database. Fast forward to the NoSQL movement, which was led by people who were mostly ignorant as to why we went to relational models in the first place. Now were seeing MongoDB slowly become a relational database step by step.
Pretty much the same for me, but I also don't use var if I am retrieving an object from a method like this: var kids = person.GetKids(); Even if the method name or variable hints at the return type, I'd still do this: IEnumerable&lt;Kid&gt; kids = person.GetKids(); IMHO, the latter example is more readable, though it really only saves me and others the *inconvenience* of having to hover over the method to see what it is returning via intellisense lol.
I switched over to asp net core 2 from mvc3. Took me 3 months to rewrite my solution but I learned a lot doing it and so really happy with it so far. Ef core leaves a lot to be desired but I've worked around it just fine. Not doing anything performance critical enough that I need to stress over it and I'll revisit it when it gets further developed. The DI aspects of core were worth the switch alone.
That'd be a breaking change and I prooooooooooobably want to know where the breaks happened lol.
The keyword `var` isn't dynamic typing. When you use `var`, you are telling the compiler to infer the type for you. Ultimately, it is just syntax sugar for most uses though it is required for some things like anonymous types.
It's not the performance that bothers me about EF core. It's random bad behavior like when I tell it to delete something and it sets the FK to null instead. Or if I modify class A, then class B will stop loading because of malformed SQL. Note that B doesn't reference A. And it's damn near impossible to predict what will be loaded into an object unless you make a new DB context with each and every query.
Depends on what you are going for. I went to Visual Studio Live Las Vegas. I had a great time, and got exposed to some new concepts and did some networking, but the value of the conference sessions for their cost was pretty low. I could have locked myself in a room and watched videos and read blog posts and learned more on my own in a day than I did with a week at the conference.
Check out the GAC. Global Assembly Cache. It's an area in Windows where you can globally register a DLL and any application on that machine can use it. I've seen plenty of articles that say it's a bad idea to use it, but it serves us well where I work. We have a very complex system of databases housing all employee information, and have to tap into various DB's to see who has access to what, and it has all of their personal information. So we made a library, it has our user model, as well as a few others, then we added various handy services, db factories, our custom encryption routines, etc... And we load it into the GAC on all of our web servers. So we just include it into any app we write, and when we publish it up to a web server, it uses the library in that server's GAC. If we need to change any of our central code, we just update it on each server. Way better than having to touch every app. You just have to be careful at managing version numbers and only add features, fix bugs, etc... Never remove a feature. If you want to change the parameters of a function, just add an overload function, don't change or remove the original. I'm sure people have shot themselves in the foot by using the GAC, but we've been using it for years and it serves us well. Another cool thing, is our library pulls some of its configuration from web.config, and we put relevant information in the root level web.config of each server. So, our development, test, and production servers are all running the exact same compiled copy of the library, but the web.config of each server environment automatically points every app on it to the appropriate databases. It's a pretty slick system, we put a lot of thought into it.
Kinda sounds like you're using mssql. If you have server cycles to spare, you might want to look into database snapshots (since 2005), could save you some time, offer faster data and save a license cost.
All of the Core stuff is all about moving from Win32/64 native onto cross-platform (including the much smaller Win32/64 images without GUI). I don't know why it's so hard for EF7 to just move over, I don't know. However I know that in 7 releases (+ some interims with large feature creep) the codebase can become absolute shite. However rewriting a library to replace a library written over 10 years usually takes another 10 years.
I'm 100% with you there. It doesn't do any harm, I suppose, but I find it confusing. It would make me ask "why isn't that just an int?" Code that makes you wonder why isn't good code. In my opinion.
The failed MERGE updates are killing me. Sure the affected objects are there in exception, but *why* it suddenly doesn't want to update it.
Not always. If it is, then you'll still know where the break happened.
I'm not a zealot too much when it comes to this stuff but personally I think the fact that `kids` is plural already indicates that I'm dealing with an enumerable of some kind. I personally think that what the code does is more important than the types involved, so for clarity's sake I prefer this: var kids = person.GetKids(); var taxDue = GetDefaultTaxDue(person); foreach (var kid in kids) { var applicableBenefits = kid.GetApplicableBenefits(); if (applicableBenefis.Contains(ChildBenefit.Disability)) { var disabilityAllowance = TaxCalculator.GetDisabilityAllowance(person, kid); taxDue = disabilityAllowance.Apply(taxDue); } if (applicableBenefits.Contains(ChildBenefit.TaxCredit)) { var reducedTaxCoefficient = TaxCalculator.GetTaxCoefficient(person, _currentTaxYear); taxDue *= reducedTaxCoefficient; } } To this: IEnumerable&lt;kid&gt; kids = person.GetKids(); decimal taxDue = GetDefaultTaxDue(person); foreach (var kid in kids) { IEnumerable&lt;ChildBenefit&gt; applicableBenefits = kid.GetApplicableBenefits(); if (applicableBenefis.Contains(ChildBenefit.Disability)) { ITaxAllowance disabilityAllowance = TaxCalculator.GetDisabilityAllowance(person, kid); taxDue = disabilityAllowance.Apply(taxDue); } if (applicableBenefits.Contains(ChildBenefit.TaxCredit)) { decimal reducedTaxCoefficient = TaxCalculator.GetTaxCoefficient(person, _currentTaxYear); taxDue *= reducedTaxCoefficient; } } ... Nine times out of ten, anyway.
I am hoping you dropped this /s
Actually I used to create dynamic languages, and we didn't use var *or* the type declaration. You could just say something like &gt; foo = TypeName(); and it would be fine. Also dynamic has nothing to do with it: you are talking about strongly typed versus weakly typed, but regardless, the specific grammar doesn't mean much. In our languages you could declare your variables or not (it was always a separate statement), and it didn't matter, strong/weak typing was a compiler parameter and was separate from grammar.
What
Its because people are lazy.
`new Dictionary&lt;string, List&lt;string&gt;&gt;();` is unnecessary, you could've used `new Dictionary&lt;&gt;();`
`dynamic` is a keyword in C# to allow you to bypass the compile time checks, which is what /r/mcnerdius was referring to. He was stating that `var` is just syntactic sugar and that types are still strongly enforced when using `var`, while `dynamic` types are not strongly enforced. See https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/dynamic
I'll tell you why. The internals of EF are a clusterfuck and no wants to touch them. So they started over from scratch. Twice if you can't great provider rewrite between the EF core 1 and 2. And I've lost track of how many times they basically restarted EF on the old series. In my opinion, EF's basic design is fundamentally flawed and there's no good way to actually implement it. They should be exposing the power of the database like SQL alchemy, not trying to hide it through these abstractions and caching layers.
I agree with you. Expressive variable names &gt; types most of the time for me. 
That would be a third option, but it doesn't help demonstrate that `var` can be used to remove redundancy.
That's funny, because at first I thought you were pointing out how much better the second one is. Because it's 10x as readable. The use of var makes everything blurb together when you don't know what is happening, all the variables lose any distinctiveness upfront. I have to use contextual information to figure out what I'm dealing with. Suddenly that multiplication at the end there had me second guessing, and then wondering what primitive I was dealing with, and I mean, I had to go back through it even though I was at the end! Without your second example, I wouldn't actually ever know for sure. I need intellisense or to go to one of those methods to figure it out. There is nothing more clear in your first example. I can not only read what the code does better in the second, it's faster too because I'm not having to decipher the variables at the same time. Knowing the types immediately upfront enables me to know what the code is doing much quicker. You hid information from me. There is no way it's going to make it more readable.
It's much easier to refactor. You should always work on improving your code and naming convensions. Renaming an object will result in a lot of renaming changes even where the specific object is only passed through. Using "var" also minimize usings in your C# file. :) Most people not using "var" say that they prefer to see the type when reading code. I prefer not to and in stead concentrate on writing readable, well structures code to begin with.
Well, that's why I'm a programmer to begin with. Can't stand non-automated work.
You type var i = 0L Not that id actually recommend doing that
&gt; The default Entity Framework is to set null the foreign key on a dependent entity when the principal entity is deleted. Yea, even when it knows the fucking column is non-nullable and there's no way it could possibly work. Well that's a bit of a lie. Because sometimes it will work fine for months, then start doing that with no apparent change in the code. I hate EF.
Might as well use `dynamic` then.
In software, laziness is good. DRYness is good too (Don't Repeat Yourself). var prevents repetition.
My preference is to use var everywhere in production code but in my BDD/TDD code I explicitly use the types to ensure my tests are correct and to make my expected behaviour clear
Would you mind pointing me towards the exact methods to use? What I'm trying at the moment is: - On the SyntaxTree, I'm calling `tree.GetRoot().FindToken(position)` - This gives me a `SyntaxToken`. I'm then using its `Parent` property to get its parent `SyntaxNode`. This seems to be working, but I'm not confident that the node I've got is the node that the semantic model needs. - Then, I'm calling different methods on the semantic model, passing in the token. `GetSymbolInfo()` returns `null` for the Symbol, and the `CandidateSymbols` has a length of 0. `GetDeclaredSymbol` returns `null`. I can't seem to find a method that returns me any symbol information, and I'm not sure if I'm using the wrong methods on the semantic model, or if I'm using the wrong token. For context, just for testing purposes, the script that I'm testing this on is: using System; Console.WriteLine("Blah blah blah"); The position that I'm using points to part way through the "Blah blah blah" literal, and the token I'm receiving from the syntax tree is a `StringLiteralToken` with the correct value of "Blah blah blah", so I'm confident that I've at least got the right token. Thank you!
I personally find the types unnecessary noise when what I usually want to do is assess the algorithm, while ignoring the implementation details. Nonetheless like I said before I'm no zealot and I don't force my preference on others.
Why is this answer and similar at the bottom, when it's clearly the correct one? 
Woohoo, I think I've got it! Leaving my code here, in case it helps anyone else, or in case anyone wants to comment on it: IEnumerable&lt;ISymbol&gt; overloads; var semanticModel = compilation.GetSemanticModel(syntaxTree); var theToken = syntaxTree.GetRoot().FindToken(position); var theNode = theToken.Parent; while (!theNode.IsKind(Microsoft.CodeAnalysis.CSharp.SyntaxKind.InvocationExpression)) { theNode = theNode.Parent; if (theNode == null) break; // There isn't an InvocationExpression in this branch of the tree } if (theNode == null) { overloads = null; } else { var symbolInfo = semanticModel.GetSymbolInfo(theNode); var symbol = symbolInfo.Symbol; var containingType = symbol.ContainingType; overloads = containingType.GetMembers(symbol.Name); }
No need to buy ReSharper just for the linting. We use Stylecop analyzers with great results. https://github.com/DotNetAnalyzers/StyleCopAnalyzers/blob/master/README.md
what? have you tried it?
He's talking about the C# `dynamic` keyword.
Official Microsoft convention is to use var when the type is obvious from the right term, otherwise you write the type explicitly.
Most oss projects distro on git and nuget. The build just publishes to nuget. If you really wanted to you can also bundle source and symbols in a nuget package. its just not done often so you need to reference some esoteric msbuild docs. 
In long term we also want to get a Code Coverage and performance measuring etc. so it would probably be ReSharper Ultimate with dotDover and so on. I will give Stylecop a try, thanks for the hint!
Normally serialization and model classes are shared between client and server. its the libraries for data access that are different.
&gt; Because it's 10x as readable. Subjective. There's way more noise now, detracting from the focus of the code.
You are mixing two different aspects of typing! On the one hand there is the *quality* of the type system, "measured" only by the two extremes *strong* vs *weak*. On the other hand there is the aspect of the time, when the typing is (primarily) evaluated. There we decide between *static* and *dynamic*. The important thing to know is, that both paradigms are *not* related! So you can have static weak typed languages and strong dynamic ones (like C and Python for example). Imho one should be very carefully to don't mix up both aspects; especially if one provides an answer to a typing question üòâ
Yes. GitHub. Many of the Microsoft projects are there. Here's a relatively new one which demonstrates so neat techniques in code, architecture, and infrastructure: https://github.com/dotnet-architecture/eShopOnContainers
SonarLint is pretty smart. PVS Studio is amaze-balls, and has a free trial.
Doesn't have to be, it depends on what breaking means. If only "source level compatibility" is needed, it doesn't have to break anything.
Isn't that how every conference is?
I use var always so... yeah it doesn't save characters with int, but it's consistent for me to use var when I can.
Makes things easier to write. Syntactic sugar. 
Correctly using var won't ruin your code - it will make it more clean, more readable as it removes a LOT of unnecessary cluttering. For example: Dictionary&lt;int, LongClassName&gt; dataHolderDic = new Dictionary&lt;int, LongClassName&gt;(knowArray.Lenght); Or var dataHolderDic = new Dictionary&lt;int, LongClassName&gt;(knowArray.Lenght); Means the same, but the second is cleaner, easier to read. The type is already there, it makes no sense to write it out again. Obviously abusing this feature results in an unreadable code, but this is pretty much true for everything.
`Dictionary&lt;string, List&lt;string&gt;&gt; foo = new Dictionary&lt;&gt;();` works just fine.
in C#?
This has changed very little since I first did it in VB6.
It doesn't matter how the files are stored, TFS abstracts that away for you. It does mean that you can't use a simple file copy -- you have to ask TFS for the files. But no, you do not need to know any of the TFS internals. [Example[(https://stackoverflow.com/questions/3762812/scripting-tfs-command-line-for-get-latest-version-check-out-and-check-in-progr)]
to be honest, it sounds like you "want your cake and to eat it too".
you left out all the drinking and eating i assume is going on! haha
But you wrote it like "ThingA / ThingB" which reads like both are rather synonyms or alternatives than different kind of properties. So you didn't meant it, but your answer wasn't clear enough though.
Yes, but billing them as a 'valuable learning experience' is kind of a stretch.
You should create a class library or shared project for the client and server. All the code shared between client and server goes into that project. Then you just reference the project from the client/server project. If I understood your question correctly.
Thank you, I will look into shared projects. Also, du har ett fantastiskt username.
ELI5: "var" is like telling: "Hey compiler, I am too lazy to write the whole type name, do it for me please." so `var dict = new Dictionary&lt;string,string&gt;();` basically becomes `Dictionary&lt;string,string&gt; dict = new Dictionary&lt;string,string&gt;();`... As others said you should use it responsibly, where the type is clear at first sight as above. 
I just ran the code and checked the User.Identity.Name after a login but before the redirect. I also deleted the cookie to recreate the problem I'm having. So the cookie gets created on the PasswordSignIn call but the user identity is still showing the network login. After redirect it's still not showing the proper username. I'm not sure what you mean by pipeline. &gt;the pipeline you create is run per request &gt;The server needs to run the pipeline at least once after the cookie is created How do I run "the pipeline" after the cookie is created? What you are saying makes sense though. I feel like something needs to be run again so the cookie works because once I stop my code and re-run it, it all works properly. 
Haha, thanks :) Just send me a message if you need further help.
You going to learn or network? Bit of both? Bring some business cards sure, everyone else always has them. Don't get too drunk... or at least don't be the first one visibly drunk. Listen to people and nod sagely.
Ding ding! I've been working in C# since it was in beta, and Node.js for a couple of years. The lack of typing has illustrated the value of clear API calls, and that if you need to depend on the declaration of the variable to infer type, your code is not clear.
Well put - if anyone needed evidence of the Ted Neward quote ‚ÄúORM is the vietnam of our industry‚Äù they can point to EF with ample justification.
Don't hit on the few women that will be there.
The pipeline is what is setup when Configure is called in the startup.cs class. The configure method is called once which sets up the request pipeline to run once per request. The startup class has two methods: Configure and ConfigureServices. Just to check, you are calling services.AddAuthentication in the configure services method and app.UseAuthentication() in the configure method? Here is an example linked to from the Microsoft documentation: https://github.com/aspnet/Docs/blob/master/aspnetcore/security/authentication/cookie/sample/Startup.cs
var is also used for Anonymous Type: var person = new {Name = "John", Lastname = "Doe"}; 
Official? All of Microsoft?
OP was asking how to retrieve the files from a TFS repository without using TFS. 
Download: https://getbootstrap.com/docs/4.0/getting-started/download/#compiled-css-and-js CDN: https://getbootstrap.com/docs/4.0/getting-started/download/#bootstrapcdn There is no "chosen" package manager for ASP.NET Core. The bower stuff that is installed with the project templates is just an example of how things could be set up. 
You should post it to /r/programming. They love it when someone develop his own language and yours is worth the attention.
I just followed the example in the PluralSight course I took. I don't have a Configure or ConfigureServices (although I could probably add those). [assembly: OwinStartup(typeof(MachineInspections.Startup))] namespace MyNameSpace { public class Startup { public void Configuration(IAppBuilder app) { This is the default method I get when adding an OWIN Startup Class. All the app.CreatePerOwinContex calls are in this method. I'll change my Configuration call to Configure and add a ConfigureServices method and move the cookie authentication to that area and I'll report what happens. thanks again for the help.
I did Webpack with npm for the first time to get Bootstrap 4, and holy shit that was complicated. But if you want the source Sass files, that (npm) has become the de facto way of getting front end frameworks of any kind. If you're still looking at going this route, I may still have some relevant articles that I found helpful.
I made an update to the comment above, I accidentally linked to .NET core documentation. Have you tried to use the default templates generated by visual studio? If you click "File &gt; New &gt; Project" and click "Web &gt; ASP.NET Web Application (.NET Framework)" and finally select MVC and From "Change Authentication" select "Individual User Accounts" the template that is generated has all the boiler plate code that you will need. If you don't have visual studio I can upload the default template to a git repo and link it here.
You can use Code snippets("few lines"), Item templates ("one class") and Project Templates("multiple classes"). [Item and Project Templates](https://msdn.microsoft.com/en-us/library/ms247121.aspx) and [Code snippets](https://msdn.microsoft.com/en-us/library/ms165394.aspx) 
Now try adding some angular on that shit pile.
i dont feel like its a good idea to put custom repos into work related things. but yes i probably have to split it up in a lot of small things
Cool, I'll try that out. thanks.
will look into those two. already using DI kinda, but probably not in the intended way
maybe i can put single csprojs into repos and then use them as submodules in git... i can just add them to the solution then
exactly, looking for a way to kinda do that but without the bitch part
I just did my first project with Webpack, Vue, and various other js libraries, and holy shit. I think I spent more time trying to get all of that worked out, than I did actually working on the site.
You should talk to your manager about creating shared projects for the business and adding them to your companies code repo. You can literally creat/add them as you go so you wouldn't need some massive effort to split everything out. Just replace old references in code with the references in the libs you create as you go along.
i could use nuget if it were just for my own projects, but i cant use them for work
&gt; only add features, fix bugs, etc... Never remove a feature that sounds like what happened to the win32 api XD. bad idea. for deployment on work i use apt and ofc have configuration files
yeah i will probably have to put every piece of code into submodules... which is alot more pain than just having it directly in the repo (pulling recursively etc)
nuget wouldnt work for me cause i cant use it for work then
i dont see whats wrong with that :P i just want to spend less time on this and more time with actually making progress
Y'all are right. You know, for whatever reason, I was only thinking of this kind of scenario: var person = personRepo.GetPerson(42); where `GetPerson()` returns a `Person` object but then we change the return type of `GetPerson()` to `IPerson` which may or may not have the same members as `Person`. In this instance it may be a breaking change if the public API of the interface doesn't match the public api of the concrete `Person`. Of course, this isn't the only scenario so I am not sure why I zoomed in on it lol.
a) how would i keep those shared projects updated b) im a freelancer, my "manager" and place of work change every few months
Removed: Rule 5.
Microsoft's C# Coding Conventions [See here](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/inside-a-program/coding-conventions#implicitly-typed-local-variables)
I'd say it's much more than that, seeing that you can't do anonymous typing without var.
Is the "..." part where you decided to stop reading to make an argument completely explained by the "..." part? Having to figure things out on a later line by context takes more time. Just like you said, I have to read on into the "for-loop" to determine it. The "for-loop" does not show everything, either, because it doesn't show what it contains. I have to read on to determine that as well. All of this takes more time and more thought. Yes, it can be done. But it is less readable. It is less clear. &gt; I would go mot of the times even further and eliminate the temporal variable at all And it would be more readable for it. Because I wouldn't need to figure out on later lines that it's an ienumerable, the immediate context is clear. I still have to figure out var kid, but it's one less thing. &gt; are all about the contracs - not the concrete types. And if I know the concrete type, I know the contract. You can't gain a full familiarity with the code if all you have is vars. Over time, reading a project, you'll gain familiarity with types and what they do. Say goodbye to that with var. It becomes that var could do *that*? Huh, okay. Nobody not drinking the var cool-aid thinking var is more understanding, or that knowing types are "noise". Nothing about var changes the actual code and nothing about var gives you a better understanding about abstraction.
Even then I'm more likely to write `var someInterface = (ISomeInterface)foo` rather than `ISomeInterface var = foo`.
I don't have much to recommend in term of learning resources, a search in Google or Amazon will probably give you better suggestions that I can offer. It's been a long time since I went through the learning phase of writing a compiler, and I learned mostly from scattered resources on the Internet. The only book I remembered using was "The Definitive ANTLR Reference" which is where I learned enough about parsing to write my own parsing library (but then again, you probably won't need to write your own parsing library...). In terms of languages and tools, I would strongly recommending using a functional language to implement your compiler, it will save you a lot of effort (yes, I know I'm not supposed to say this in the C# subreddit, but...). Myself, I would probably use Haskell with the Parsec library for parsing. I don't recommend using the Cell source code as a guide to implementing your own compiler: I've done my best to keep the code clean and organized, but Cell is a complex language to implement, and if you need an example to start from, it would be better to look for a compiler for a very simple language, ideally one that is not even meant for actual industrial use. And remember that the Cell compiler is written in Cell itself, not exactly a mainstream and well-known language... Let me know if there's something more specific you need to know. 
Yeah unfortunately that's the price of choosing text over library, but it shouldn't be such pain to update them in your projects. :-) ... You could even create some powershell script to automate this. But I wouldn't be so crazy with it. I've created ItemTemplate with micro benchmarking class ( warming run action -&gt; GC.Collect -&gt; start timer -&gt; run action few times -&gt; stop timer) and it's pretty helpful :) 
It's not an excuse. It's a reason. The second example is noisier than the first, I don't need to see type info so explicitly, particularly with generic types extending the length of lines beyond the short(er) terse statements of function. I'm not going to reply to you anymore, fyi. You don't get to call someone else's opinion "an excuse" like your opinion is fact, when it isn't. Some prefer tersity, some prefer full declarations. It _is_ subjective because it depends on who you ask. So you can fuck off.
FWIW Resharper out-of-the-box comes with two related inspections: to not use var for simple types and conversely use var for complex types, just like you said. So it seems to be the common practice.
Assuming you already have the Hangfire dashboard working, in the `Startup.cs` you'll bootstrap everything. Here are what I think are the relevant lines from my working implementation: `public IConfiguration Configuration { get; }` public Startup(IHostingEnvironment env) { var builder = new ConfigurationBuilder() ...other stuff... .AddEnvironmentVariables(); Configuration = builder.Build(); } public void ConfigureServices(IServiceCollection services) { ...other stuff... services.AddHangfire(config =&gt; { config.UseMemoryStorage(); config.UseConsole(); }); ...other stuff... } public void Configure(IApplicationBuilder app) { ...other stuff... app.UseHangfireDashboard("/dashboard"); app.UseHangfireServer(); ...other stuff... }
Dynamic makes work harder for me. I want to be lazy and do the least work possible.
use a bower. bower is like a nuget packages, but special for static files.
What do you think about using F# for the compiler?
&gt; but i cant use them for work Why not? Private NuGet feeds are precisely for internal packages at work.
You could take a look at [FNA](https://fna-xna.github.io) 
You can build NuGet Source packages, although they are most suitable for small pieces of static code. These would be accessible for changes, but they would have to be manually merged/repeated on updates unless the changes only consists of partial class additions or extension methods. https://nikcodes.com/2013/10/23/packaging-source-code-with-nuget/ Private Git repositories with forks, consumed as submodules, may be a better approach. That creates some cumbersome updating procedures though (update/merge the submodule repo, commit the changed submodule commit pointer ) Anyway, I have problems with the whole premise of the thing you are trying to solve. As a customer I would be sceptical of some contractor introducing his private frameworks as a dependencies in my applications (and in general of any framework with few active contributors), especially if they require non-standard/non-trivial update mechanisms and/or non-public repositories.
Thanks for understanding this.
You can when A has no fields, right? I can't think of any other scenario.
Then why is the code in there in the first place? Whenever I make a class library I only put code that is going gonna used in it. If I want to add anything I‚Äôll do with from outside of the library or extend it.
Make a class library for you own code. Stop copying your code for work. I'm surprised nobody has brought it up yet, that is a very bad idea. You don't own that code anymore, it's now theirs. You open yourself to legal troubles in the future, because now it looks like you stole their code. If it's for work, you remake it and ideally do so with a slightly different implementation. You also can't touch your own code on the clock, or even on any of you're employers resources. Further beyond that, many employers have an IP transfer agreement that says they own whatever code you do even on your off-time. This is all to show you just much of a precarious position you're in. Be careful.
Gardening, cats, non-Rubik's brand cubes
&gt; In my opinion, EF's basic design is fundamentally flawed and there's no good way to actually implement it. To me, this would have been a good reason to simply port EF to .Core and then design a new tool with a new name.
I have apps in both app stores: For Android it's mostly Java, but I have some newer code in Kotlin. For iOS most of what I've done is Swift, but I maintain some older code in Objective-C. For various work projects I also have some old code written in PHP, and some ancient Power Basic.
I think they should have kept the original Linq to SQL and just added more database providers. But that's not how that team rolls.
Yep, that's exactly it. (And it has to be a `struct`.)
now try and get typescript to work with all of it. What a shit show.
You can use ParcelJS, https://parceljs.org/, it is simpler than Webpack, Zero Config, and as powerful. Frontend can be easy
If you're not interested in engines try sfml or sdl2. I believe they both have bindings. Depending on your knowledge one of the people behind .net core Eric Mellino has a framework on GitHub called Veldrid that uses .net core. It's has a couple examples but it's not super well documented. https://github.com/mellinoe/veldrid Alternatively there is CocosSharp, but I think that's on top of monogame.
I'm not sure I understand the link. Did the same people who killed LinqToSql create EF.Net and EF.Core? 
You could use Unity.
Been meaning to learn at least one functional language, I've liked F# and Clojure so far. Node.js is my goto for small projects and prototypes since it's so easy to quickly get something running
Running, fitness (and gaining weight), this one girl, I swim a bit and I like just generally being busy. 
why would you not just use an Observable?
Ruby on Rails! Haven‚Äôt touched .NET at home since I started working with it. 
It hasn't been for awhile. For example, Xenko is pure C#: https://xenko.com/
You might consider taking a look at a conference like KCDC (http://kcdc.info).. It is very affordable, has a history of great speakers (many that also speak at the "bigger" conferences like VS Live and Dev Intersections), and has plenty of networking (with all the drinking and eating) to go around. They are in their 10th year and are projecting close to 2k attendees last I heard.
3D-printing among other things
 But using Observable will allow you to work with any Promise/Observable based library as well, and even though yes the api is different than linqs, for nearly everything there is a 1:1 mapping, even if named differently. And you don't have to import the entirety of rxjs, you import by operator, and the rest will get tree-shaked
Cigars, sci-fi, and kpop. 
There's one for comments that I occasionally use, but not on a _"regular basis"_ (because, why would I comment my code, right?), that's useful for quickly enabling/disabling some code. When making multi-line comments with `/* */`, if you prefix the last `*/` with a standard `//` comment, you can quickly comment/recomment the whole block. For example: /* if (shouldDoTheThing) TotallyDoTheThing(); //do some other stuff OtherStuff(); //*/ Now this code is commented out. But if you add a single slash to the opening line: //* if (shouldDoTheThing) TotallyDoTheThing(); //do some other stuff OtherStuff(); //*/ Now you have converted the comment _block_ to just two single-line comments (`//*` and `//*/`), and the code is uncommented/re-enabled. To recomment out the code, just delete the preceding `/`.
Well, there were few key points that convinced me to make the library: * Performance and RAM usage: native `.filter`, `.map`, etc consume A LOT of RAM, which is very sad. Other libs like Promise/Observable based ones provide a nice integration between libs but the performance is few times slower because of this. * LinQ api: When working with C# + TypeScript, this is very handy. * ES5 and no dependencies: other libraries have multiple dependencies and maaany of them dont even work in ES5 * Nice typings: typings for RxJS and similars don't work properly with `strict` TypeScript compiler options * Writing it: this was the nicest thing of all of them. This project made me a better programmer in terms that I needed to familiarize myself with LinQ internals to design the whole architecture and adapt the design to TypeScript. I also learned Mocha testing (100% coverage of unit+integration tests). Totally worth. Thanks for the support btw haha I like when questions are asked
Yep. LinqToSql was written written by an independent team when the ADO.NET crew couldn't get their act together. Later the ADO.NET team took control of LinqToSql and subsequently killed it in favor of their EF project.
The game engine?
var in C# is like happiness in life. Not strictly necessary.
&gt; Strictly implementing microsoft's official linq definition As a not-really-a-front-end-dev this is a big deal for me. I sent a link to my not-just-a-front-end-dev colleague and his comment was "that's sweet" 
[Yarn](https://yarnpkg.com) is pretty easy to work with. And it looks like there's also a [sass-bootstrap](https://www.npmjs.com/package/sass-bootstrap) package for version 4 with npm.
If it works as an extension method, I'll write it as an extension method; I prefer extension methods to public methods on classes when I can get away with it, especially when I can write the extension method against an interface rather than a specific class. I find it makes testing and debugging a lot easier when almost all of my methods are pure functions of their arguments.
I use (and like) this approach to polymorphism a lot: interfaces with extension methods. It‚Äôs really nice to be able to easily ‚Äúappend‚Äù functionality to a class without using inheritance. Sometimes I even do it with interfaces with single properties: my and engine has IPosition, IScale, IRotation, IColor, etc. Might seem a bit tedious, but when I‚Äôm ripping through work and I add a new component and I want it to have a bunch of tween functions and helper code... bam it‚Äôs done. I also really like to be able to ‚Äúfind all references to this function‚Äù in the code editor, which works great for extension functions.
Why is it a big deal for you? With this, you can even get questions from LinQ stackoverflow and use them in TypeScript. The idea behind this library is allowing "only c#" programmers to feel confortable in TypeScript world (and performance boost ofc)
Cool!
&gt; a big deal for me I mean that I really like that. As a C# dev, the example looks like real code ;) 
I have this bit a code that I'm constantly adding to new projects. It replaces the base object class and allows me to do: instance.Extend&lt;SomeComponent&gt;(); and then call this in a method: public void SomeMethod(string a, int b) { ... this.Components(a, b); ... } which will use duck typing on SomeComponent to call SomeComponent.SomeMethod(string, int). The nice thing about it is that it doesn't use reflection and it doesn't allocate after the initial setup.
oh nice then!
Honestly, Web Pages in Core is a quite nice middleground if your app is not super complicated.
I'm kind of a foody. I watch too much Netflix and I'm always working on some side project. Mostly some game development. Oh. And listening to podcasts to fall asleep... 
&gt; it seems like they spent a lot of time on micro-optimizations Yep. That is very much intentional. 
Did you not read the first sentence? &gt; It seems like Bootstrap has chosen not to distribute Bootstrap 4 via Bower anymore
&gt; I could have locked myself in a room and watched videos I was just going to mention that. Unless you want to ask questions of a particular speaker, what you really should be doing at a MS conference is hang out on the floor talking to people. MS employees, vendors, and just random folk. There's nothing wrong with catching a session or two, but with everything released the next day on Channel 9 that's not what you should be spending your time on.
Thank you! I don‚Äôt see an agenda yet but definitely with considering as it‚Äôs within reasonable driving distance.
To migrate out of silverlight?
Huge!
might not always be available though
I don't think a point can really get very complex.
Before I release an app I put all my classes and other objects into a single .cs file. Then in that file I put all lines into a single line. It had been shown to improve the compiled performance. It can take ages so I made a utility to do it automatically. 
I've seen the same technique expressed this way in the code base I work on. &gt;if(0 ==1) { &gt; doSomeStuff(); &gt;} Just change one character and the code is re-enabled AND depending on your language / tools, this will be picked up when looking for references.
This is not so much of a trick, but whenever I create a new class, I add a common comment to the constructor so that when I come across it later I instantly know that I created it.
Why would that work in C#? In an interpreted language like JavaScript maybe, but there is no reason why that would improve performance in a language like C#.
Bower is basically dead Npm via non or yarn is the preferred method to install most libraries these days
Im not following what you mean. Extend must use the SomeComponent type to do something, but not sure how it is relating to your second example?
Beer, brewing, gardening, I have been getting into python for work but I really don't like it much.
Oh... well, I missed that. It makes a lot more sense now!
This is dope, I've been needing something like this for a personal project I'm working on. Thanks so much for coming up with this!
Author here: If you have any questions, please feel free to post them here :)
Was going to ask why the thumbnail was the steel alphabet for iron, but I just saw your name--so carry on.
Haha yout got it. I should probably change it now that I'm releasing things, but Mistborn still holds a special place in my heart.
Ah I figured it was something like that. How do you not use reflection though?
It uses reflection when it's setup and then it just caches the delegate.
You may enjoy Bridge.NET
Yea, I've been thinking of posting a version of it to GitHub. I might do that this weekend.
Maybe put a few `try/catch` blocks in so you can remove the need for 8000 log statements.
I think one of C#'s greatest attributes is that in most cases there already is a defined design pattern for whatever you're trying to do. That's a good thing, and other languages don't necessarily have that luxury. 
Interesting. I'll definitely have to give that a try. Thanks!
This comment chain is just proof that we're crying out for some kind of traits or mixins. Can't come soon enough imo.
I cook, collect whiskey, play video games, read, work on one of my cars, and travel.
I've seen people use it as a framework. Create a single scene with a single object and a single behavior and just do everything from code.
f#/.net core
 try { DoSomething(); } catch (Exception e) { if (Debugger.IsAttached()) Debugger.Break(); } 
I use var always, if someone want to know the type, the IDE can tell you.
DataTables haven‚Äôt changed that much and this is likely a red herring. The issue is probably your connection to the Oracle DB. Isolate that and make sure it works. Do you need firewall rules so the new server can connect to the DB server?
&gt; It has been shown to improve the compiled performance. ... link? Because that sounds completely preposterous. 
Shhh... everybody be quiet and observe the elusive JavaScript developer in its natural habitat 
the ! is used with nullable types.
I have to assume you're right cuz I never used it.
Why?
Windows 7/10.
W10 because it works, I know it, and I don't have time to fanny about fixing other desktop environments that in my past experience always need fixing. *Ahem*
Private T cache; Private T getResult(){} Public T GetResult() =&gt; cache ?? (cache = getResult ());
As someone who makes a living making b2b ecommerce applications you definitely want to store it on the server. I can't really think of a good reason you wouldn't want to. 1. Cart is always saved 2. Cart is accessible from multiple access points 3. You don't have to worry about size at all and let me tell you no matter how improbably you deem a scenario there will be exceptions several times a week if your app has any kind of volume. High purchasing customers are not the ones you want to scare off. 
Mac and windows 10 on parallels. I only use Windows for visual studio, SQL and iis. I mostly use my Mac side for everything else, like chome, slack, and vscode for angular apps.
No, I mean, the "value of the conference sessions for their cost was pretty low" seems to be pretty true for most conferences I've ever attended. And I TRY to learn what I can, it's just a crapshoot. 
Very useful in situations when you are querying a database and don't need every field. For example, listing all the blog posts available for consumption: var posts = dbContext.Posts.Select(p =&gt; new { p.Title, p.CreatedDate, p.Url }).ToList(); 
When I see code smells, I like to know if I'm to blame without having to spend all my time looking in source control history. Basically, I type ctor tab and it just happens so I don't have to think about it. 
Other than C#/.Net stuff. I am a big fan of Microsoft Azure. Cool new things to explore. Not only that I think it leverage the skill set of C#/.Net developer with Azure Function Apps, LogicApps &amp; etc. 
It's just a snide dig at linux desktop :) I'll be diplomatic and say this: Linux on the desktop is a [kit car](https://en.wikipedia.org/wiki/Kit_car) whereas Windows is a [Ford Galaxy](https://upload.wikimedia.org/wikipedia/commons/d/d7/Ford_Galaxy_front_20080331.jpg). Yes the former is faster and cooler-looking when its assembled, but I just need to drive to work and I don't have time to mess around with the internals. :P
This is why I program on Win10, carry an iPhone in my pocket and buy KTM dirt bikes.
Oh you are going to love this.. http://upgrade-bootstrap.bootply.com/
We started using MediatR (+ Ninject) for tracking major lifecycle events where we continually were getting additional business requirements. I liked how it broke down our existing logic into a handful of handlers per event (greater test ability) and decoupled any new features from the existing core logic (less open-closed principle violations)
Game dev: Windows 10. Home use: Windows 10. Realistically, if you‚Äôre using any modern languages, even C++, you really only have small bits of OS specific parts in your system. Let‚Äôs say you‚Äôre wanna building something for iOS? You layer it easily through headers to prevent the ObjectiveC from leaking into everything else. Working on Windows? Later your code so your code the same way so your headers only expose platform agnostic C/C++ and hide all the C++/Cx bits from leaking. Realistically: most application code, certainly more than 90%, can be written in a platform agnostic manner.
I have been lacking in c# development as of late, but doing gnu c++ on windows is just a pain in the ass. I very quickly fell in love with Debian on my T440. 
If you‚Äôre working multiplatform, regardless of what it is, you‚Äôre gonna want to have your target platform available for testing/building. I prefer VM, but that‚Äôs mostly because I‚Äôm lazy and I hate swapping my monitor sources or using VNC to attach to a different box. There‚Äôs no wrong way, though.
Observables are asynchronous, though. I don't think this is the same thing.
True. Right now I'm doing some work that's going to get deployed to an RPi, and trying to get my debugging environment nice ( so I can use the integrated debugger in vscode) has probably taken 4 hours. 
This is why the /s is always important.
If the debugger is attached you can already break when an uncaught exception is thrown. These tricks actually make debugging harder because when you break you‚Äôre not in the context of the code that threw. I used to work in a codebase where code like this made issues really hard to debug. A better pattern is this: if (!Debugger.IsAttached()) { try { DoSomething(); } catch (Exception e) { // Log or do something to report the error } } else { DoSomething(); // let the debugger break automatically if this throws } 
Observables are only asynchronus if you subscribe as an observer... that would the same as saying FirstOrDefaultAsync() in EF isn't LinQ
It's not too popular, but I replace factory interfaces and classes with Func&lt;T&gt; or Func&lt;T,T1...TN&gt; instances. The name of the parameter, field or property gives enough context as to the intent. And you eliminate one interface and a number of classes. This also allows one of my favorite DI container tricks (from Unity, but you can configure SimpleInjector to do it). If a injection constructor has a parameter that is a Func&lt;T&gt; or Func&lt;T,T1...TN&gt; where T is a type that is registered with the container, the container will inject a function that uses the container that built the dependency to create an instance of the dependency in the function. It makes it really easy to lazy load dependencies without having to inject the container itself. Once you get used to it, it's hard to go back. 
What brings this over the many existing LINQ JS implementations?
For Windows / .NET / Android, and all personal use; Windows 10 (need the latest for programming / testing, and 10 is just rock solid for me). For iOS / Swift work, I have a MBP, and use MacOS. 
Nice, it would be awesome to have some performance comparison with lodashs chain methods. Then there would be an even better reason to ditch it
Mac OS with Win10 running in VMware for C# and SQL. Everything else (docker, git, browsing, and all other languages) on the Mac
If you have access to VS Pro, Codelens will do this for you automatically without having to write anything. If you don't, I humbly suggest you get familiar with "git blame" or the equivalent for your VCS of choice. It's a generally a simple one liner to answer the question you're asking here, and it can also be used for a lot of other things.
That better be followed with a null check.
Have you tried this alternative? private Lazy&lt;T&gt; cache = new Lazy&lt;T&gt;(()=&gt;...); public T GetResult() =&gt; cache.Value; It doesn't change much in this example but there are two potential big advantages. 1. It's a System class that clearly states your intent, without anyone having to reason about whether to call getResult or GetResult from an internal function. (Or simply making a typo and calling the wrong one.) 2. It has additional constructors that can help you deal with exceptions and thread safety in sensible ways--dealing with that in custom code becomes more complicated and is easy to get wrong. 
Win 10 because I'm a C# .NET dev for work and I frequently work from home and we're still targeting 4.5, no plans on changing over to core. Personal projects, I'll use C# .NET Core on Win 10, Mac, or Debian based distro (whatever flavor I'm using at the time, currently a plain copy of Debian, older version Jessie ). Android is Win 10 with Android Studio or Xamarin depending on what I am trying to accomplish. I would like to run Linux only, but VS is solid and non-programming activities are not quite ready for a full transition (hoping Vulkan takes off!).
As a C# guy you probably want to look into type hinting and PyCharm. Examples: ``` def this_is_a_function(it_wants_an_int: int) -&gt; str return "It returns a string" ```
Mostly collections (list, dictionary, stack, etc), deferred execution, proper typescript definitions when using strict null checks (also implementation is done in ts) and tests. I went through all the most popular libraries and checked the bugs and problems they are usually having and I made tests for them in my version. 100% coverage currently with 100% tests passing!
I tried to answer this in other's questions
Yes, never changes never gets complex, only if computer graphics gets a major upgrade hardwarewise.
What else would you do with an observable if not subscribe to it? Just composing them doesn't count. Eventually you have to do something with it. I know, I know. You can _technically_ use observables synchronously if you can guarantee that your inputs are always things like arrays. But you still have to subscribe in some form or fashion to do something with the final results. And `FirstOrDefaultAsync()` isn't the same thing. `FirstOrDefaultAsync()` makes perfect sense, if you're using EF or something similar which is going to make an asynchronous / network call. If you're just using Linq to objects, it's probably unnecessary. And the library linked here looks like the equivalent of Linq to objects.
I know, but it's still definitely a usable choice. I use it because I don't like having to boot into windows. There are places where it's obvious it was derived from Xamarin Studio, and by extension Monodevelop, and it definitely has its kinks. But it's making progress as well.
Windows 10 for work, MacOS for hobbying on my [game engine](https://github.com/Wolfos/WolfEngine). Windows works for C#, but for C++ it's less than ideal.
Just for developing you can use sqlserver 2017 in a docker container, works great for me.
Thanks for the answer. That‚Äôs my scenario as well but with different libraries for the mediator and the events dispatcher. My question is, why not use native .net events for this? Would it become more coupled at some point? 
Thanks :) I changed the way assets are referenced to avoid running into "numbering" conflicts essentially. In Gamemaker, all assets are given an ID at *compile* time, which is ok, because there is no real way to reference that asset from another assembly. However, suppose you write two projects in TaffyScript independant from one another. Each one will have an object with id 0, 1, etc. Now consider you have a c# project that consumes both libraries. There is no way for any of the three projects to differentiate between which object comes from which library. Hence, assets are referred to by their names. Note, that at least you don't have to quote them; instead they will get translated into a string constant by the compiler. One possible alternative would be to use something like GUID's but I still can't shake the feeling of a conflict. I didn't want any sort of undefined behavior. To help mitigate some of the problem with names, I introduced a namespace system to separate a project into pieces to avoid other types of naming conflicts. Still not nearly a perfect solution, but I was unable to come up with a better solution that didn't involve a major rewrite and refocus of the language.
I‚Äôm able to connect to the database through sqlplus on the server, and the line before the DataTable starts also runs a query using the same database connection but that seems to complete okay
Gross. public "instance_create" and "instance_destroy" methods? Here is syntax that is a billion times better: let instance = new InstanceName() destroy instance // or even instance.destroy() Why are constructors events rather than methods you can supply arguments to? I would *never* use this language, for any reason. **Especially** not game making. 
Windows 10 for personal use and misc stuff. Server 2016 on an esxi VM for most dev work. A host of various OSs for building and testing on VMs.
.Net events can cause memory leaks if you don't unsubscribe, it's a life cycle thing. I haven't looked at Mediatr but I would guess it uses weakreferences somewhere to ensure references aren't held which prevent dead objects being collected. (Bit of a guess). With .Net events you're also required to change the public interface of the class which might introduce incompatibilities or the need to redeploy more widely. Finally the .Net event system is just syntactic sugar around a delegate really. If you want to raise the event asynchronously or fire the listeners concurrently (rather than sequentially) or deal with one handler raising an exception, there's a significant amount of boiler plate that then lives inside the classes raising the events. With something like Mediatr all that code can reside inside Mediatr.
VS can be configured to break as soon as the exception is raised, not just on uncaught. You can also configure it to break only on your code (i.e. not on framework or reference code exceptions) and a bunch of other things. It's extremely useful.
This is a nightmare for version control. You should really try and avoid ever using /* */ style comments. It's too easy to merge and lose or duplicate one end. It also makes it difficult to see on a merge what is now commented and/or uncommented.
I usually keep "catch on throw" on. If it's something I really can't fix (it's usually some 3rd party lib) then I disable that exception from catching on throw. It's a good incentive to keep away from exception-driven flow as well.
Why not use #if IMCLEARLYAPREPROCESSORDIRECTIVEWITHANAMEYOUCANREAD Then set a #define either at the project level or the code file level. It just makes it obvious that this isn't a stupid error and it will have a name that actually means something.
Lol I agree that the syntax is pretty wonky. If I were to take full creative freedom of course I would use any number of other methods to create instances (though probably something similar to c#). However, the language was meant to be as similar to Gamemaker Language as possible, and so it uses the same syntax. And from my anecdotal experience, people tend to like GML, so unfortunately the syntax stayed the same. So hopefully at least some people might be content with using it for games. Despite that, it is still definitely something to look into. Eventually, events are going to be callable as instance methods, but that wasn't a key feature for the first major release. When that functionality is changed, I'll look into creating a better method to call constructors. Probably something like: var inst = new instance_name(); Again, I agree with you in sentiment. I appreciate any constructive criticism that can be used to continue making the language better. However, much of your post is definitely not constructive. I feel like you have good intentions, just really mean execution lol. 
Is CodeLens in Pro now? it used to only be in Enterprise/Ultimate (I use Ultimate so don't see what happens in Pro). Great change if it is!
Started a recent side project in Core 2 and being a JB sub, decided to give Rider a go. Wholy moley it's a nice IDE for my Mac
Windows 10 on Work and Home Desktops and my Surface Pro (I also have Visual Studio 2017 on macOS on a Macbook but I use that much less frequently since I got the Surface). 
Yep, we have 2017 Pro and it has CodeLens.
Cool, thanks :)
Weight lifting, reading, socialising with alcohol, gaming, volunteering with organisations. Big into the new EU GDPR at the moment, very interesting to me. 
* electronics (guitar pedals, synthesizers, circuit bending) * movies/music/tv * hiking/surfing/biking/skateboarding/snowboarding/climbing * got a switch recently, so getting back into video games * marijuanan, usually with all the above
Martial arts, auto detailing, and I'm slightly audiophilic.
Fair enough.
Windows 10, it works pretty well and is much more polished than previous Windows versions. I get that a lot of stuff still feels unfinished as they move away from Win32 and push UWP for Windows Core OS.
Depends on what I'm building - for 99% of things I'll use Windows because I'm comfortable with it and there's a lot of support for everything out there. I might dev on Linux if I'm writing a service or something (depending on my mood) just to feel like a cool kid. 
WebForms... I mean, wtf Microsoft? What were you thinking?
Looks like Blazor users, will get away without using JS anymore, so yes kind of. It will however use JS under the hood, sometimes to communicate with the DOM and other apis, as this is currently not supported in web assembly. 
Man, I can only hope. It would be sweet to use one (great) language throughout, but already have a foreboding premonition of people trying to put business logic in the client because "it's so easy now!".
Its fine to put business logic in the client, as long as you aren't duplicating too much effort and as long as all of the validations are also strongly enforced on the server as well.
Validation, sure; I meant *business logic*, like "if he's a premium customer, which would mean he's had over a million in purchases, I'll just fetch his purchase history from the server, add all the amounts" *business logic*. Someone would do this, I guarantee it.
It won't replace it but the libraries that come out of this will most likely be incredible.
How have I missed this!? Thank you so much.
&gt; s the "..." part where you decided to stop reading to make an argument completely explained by the "..." part? Not at all! &gt; Having to figure things out on a later line by context takes more time. Just like you said, I have to read on into the "for-loop" to determine it. The "for-loop" does not show everything, either, because it doesn't show what it contains. I have to read on to determine that as well. No! You simply do not understand, that by reading through the code from top to bottom, you build up a mental model of it. In the first line, you realize that there is an object called ``kids``, which is gotton by a method call. There is *nothing* more you need to know to understand that line! That's really all you need. And yes, as the name should be carefully chosen to be *expressive* and *intention* revealing, you can assume, that there could be arbitrary amount of ``Kid`` objects being hold within this object. You don't need any special type information at all, to understand that! In the next line you recognize, that the author iterates through this object; by this you know, that it is iterable. Great! You know that the object must support ``IEnumerable`` by just seeing the ``foreach`` loop; the loop construct just implies this perfectly, without any type you need to know. So now you understand, that you have an object with some items of kids in it and that there is an iteration over this collection for handling each ``kid``-object in some sort. And that's how you can go further and further. The compiler has to know much more, as he must make sure, that the objects supports all the relevant API (interfaces). But you don't need that to know, to understand what's going on. If you need to decide about an optimization, then you could need the concrete *type* information. But then you can easily get it via the IDE. For the most cases in reading, the information is simply not necessary. &gt; And if I know the concrete type, I know the contract. Have you ever tried to type the *type* of some crazy ``lambda``-expression in C++? Or an heavy ``rvalue`` iterator-pointer-template-monster expression? There is a *good* reason to introduce ``auto`` for C++11... üòé You *could* know all the contracts if your a genius or better have a mimetic brain. In reality you *assume* some aspects for some well known types. But you make strong assumptions, based upon the context. If the context is too limited yet, you might focus on the *wrong* things, as only the further API-calls reveal the *real* subset of the possible interfaces, which are really used (or usable!). You know, people like you have imho too low experience with different programming paradigms and languages supporting them. Your argumentation is too focused upon *one* aspect of the language, you are probably the most familiar with. You are in your comfort zone and gets feared by newer capabilities of this language or further evolutions. So you try the best to argue against something, that seems to be inevitable to you, like *human regocnizable* type descriptions. In reality those are primarily important for the compiler (and the IDE) - not the human developer. For the latter the naming is important to understand what's going on; you understand the code by reading *words* you understand, not by the types you read. Dynamically typed languages don't even have any *type* information visible in their source code at all - based upon your argumentation I won't be able to understand (or at least have a much harder time to master it) the written code. On the other hand all stytic typed languages with *no* support for type deduction (so the type can be omitted in the source code, like Java until version 10 probably), are much easier to read an understand. Hm... the reality shows, that you can write **shitty readable code in any language** - so if that's the case, to write or not to write the *type* seem not to be helpfull at all üòâ Last but not least: Imagine the following code from above: IEnumerable&lt;hij&gt; hijk = abcdef.GetHijk(); decimal lmnOpq = GetDefaultlmnOpq(abcdef); foreach (var hij in hijk) { IEnumerable&lt;HijkRstuvw&gt; acghploGthrsfddfg = hij.GetacghploGthrsfddfg(); if (acghploGthrsfddfg.Contains(HijkRstuvw.Jsfasffsf)) { ITaxAllowance awertzghSdvvbgtd = KlopGfrapdfe.GetawertzghSdvvbgtd(abcdef, hij); lmnOpq = awertzghSdvvbgtd.Apply(lmnOpq); } if (acghploGthrsfddfg.Contains(HijkRstuvw.Mkpdofhfd)) { decimal qhlkduuiuFrewCvdgrrs = KlopGfrapdfe.GetGhszDlkfjde(abcdef, _dsadhjaGzuKrde); lmnOpq *= qhlkduuiuFrewCvdgrrs; } } Now you have all the types - can you understand anything? üòà
Then, as suggested in another comment, put in a try/catch block and log the stack trace on error. 
Man was I hoping it would support IE8 just so I didn't have to do it myself. Congrats for your work! 
Nice! 
Did you do this on company time or did you just do it for "fun"? How much time do you think you invested in this? I'm quite interested in doing some open source projects myself, but I can't find any time to think anything through for the moment. 
Eventually we will need a better language for the browser, maybe c# will be it. This is still only experimental and MS has a habit of dropping UI stuff. Silverlight 2 (via plugin) allowed the use of C# in the browser in 2008, where is it now? If Blazor still exists in 5 years, it will take another 5 to 10 years after that.
I mean, we already have Xamarin to run C# on mobile devices and Mono or .NET Core for Linux and Mac. Web would be just another target.
Im not sure, try navigating here from IE8 pls: http://blog.codeisc.com/linq-collections/mocha
Windows for programming : Visual Studio 
Probably not blazor specifically, but I think web assembly will have a massive impact on how we develop for the web and could change everything. 
Blazor itself won't replace JS. However, given time, you'll be able to write a full web application using it without the need for JS. Will JS or other back-end stack developers abandon their current stack for C# to use it? Definitely not en masse. Other languages will spring up their own WebAssembly frameworks. Make whatever predictions you wish as to how well suited .NET is to compete with other languages once they do the same, but don't count on JS going away. You'll just never have to use it if you don't want to. 
Thanks. Tried this this morning and it seems to have issues connecting to the database. Got the following error returned on conn.Open() so I‚Äôll have to do some googling now: ‚ÄúAttempt to load Oracle client libraries threw BadImageFormatException. This problem will occur when running in 64 bit mode with the 32 bit Oracle client components installed.‚Äù
I prefer Bridge.NET myself. But there are different approaches. DouCode and Bridge.NET compile the C# source into JavaScript, but Blazor uses the resulting IL instead.
Rider on Ubuntu 16.04 
&gt; when javascript rules the roost We're using JavaScript on the web because we're forced to. The scripting language of the web is JavaScript (VBScript died a long time ago). Of course, with stuff like transpilers and WebAssembly things are changing and people are using non-JS languages more.
Please do watch this video for an early demo of just how sweet this is going to be: https://www.youtube.com/watch?v=MiLAE6HMr10&amp;feature=youtu.be&amp;t=1875 
For years I developed web code, with Java, and I used MacOS because it was easier, and I could write it on MacOS and deploy anywhere I wanted, and I could show it off on Mac, Windows, and Linux all at the same time on one laptop when a client got pushy about it. Some years ago I switched to developing web applications on Windows 7 because an employer demanded it. A year or two after that I stopped using MacOS and iPhone at home, due to customer service issues with Apple and the machines being too unreliable. I now use Windows 10 and Android at home, and I'm not presently working but when I do I plan to do my development on Windows 10. I'm sure employers are going to try to get me to use Windows 7, and I'm going to tell them bluntly why it's always a bad idea to use out-of-date software. 
That's awesome. I can't really do it right now, because I don't really have free time, but mostly because I don't know Typescript at all yet. I'll start learning it next month
Wow I am completely baffled by this. I'm gonna follow this very closely.
Windows 10 (primary) + Bash on Windows (when needed)
Looks like IE8 isn't supported, but IE9 is :( http://kangax.github.io/compat-table/es5/
Windows 10 &amp; Visual Studio for everything work related. Arch + Python at home. 
The best part of it is when you set them up at the project level, you can make them for specific *targets* of that project. So your Dev, UAT, and Production build targets can all have their target names defined. I have a project that uses an #if/#elseif/#else block with those project-level per-target definitions to swap out URL's for dev/UAT/prod servers. There's no need to go back and edit anything for a specific build, it just happens automatically as you change the target and rebuild.
&gt; IMO, the uncaught exception handling of VS is worthless in mature enterprise applications because all exceptions get caught eventually. That‚Äôs the problem, though. If a debugger is attached then an unexpected exception should not be caught in some generic place. That‚Äôs where it‚Äôs better to use the pattern I showed: only wrap the call in try/catch when the debugger is *not* attached, and otherwise never catch. I‚Äôll leave aside the debate over whether it ever makes sense to blindly catch an unexpected exception and ignore it just to avoid crashing. The point here is that if you‚Äôre going to do that then at least skip the try/catch when a debugger is attached so that you can use the debugger effectively. 
Web isn't a new target either though. There was activex, embedded .net, silverlight, etc.
I really like the idea of Blazor but I don't know if it could or even should become ubiquitous. I do hope that one day JS is replaced. It's a terrible language. But it seems very unlikely that Blazor will be the tech that does it. I would expect, if there is any real overhaul that sees JS given a diminished role in the web, that it would be replaced by a more diverse and language agnostic system, and not a specific language.
Unfortunately Windows 10. It's like a good car with a shitty body kit, interior, dashboard, and controls glued on
&gt; but majority of those devs aren't going to be using C# lol what? That's not accurate at all. What do you think ASP.NET applications are written in? "Full stack" developers in the (enormous) Microsoft ecosystem 100% already know a .NET language. Bank on it.
Makes sense, so would something like VBScript/Active Scripting fit the definition of web target?
&gt; And they've become obsolete because they had too many security flaws. That's not the case for Silverlight.
This is the C# section so don't be too surprised if the majority of people here say Windows.
&gt; Not at all! Yes, it was. You cherry-picked a sentence, ignored what was said, then literally reiterated what I said and pretended it was an argument against me. I said: &gt; I have to use contextual information to figure out what I'm dealing with. You stated as an argument against me: &gt; But you see what's going on! The for-loop shows everything Which is contextual information on a different line. You didn't deal with what I said. And it's now a common theme, because you've gone on another tirade, without actually dealing with anything. &gt; You simply do not understand, that by reading through the code from top to bottom, you build up a mental model of it. And you can build the mental model of it faster and easier when you have type information, instead of having to figure out the type information as you go in addition to the behavior. You didn't argue with me on any of this. You simply uttered the basics without understanding the point being made. I never said it was not possible to do, I never said you can't. I said with usage of var, **it's less readable and harder to do**. This is a **relative** statement. It means compared to not using var everywhere. So if your argument makes no distinctiveness on how var makes things more clear or just as clear, then you're not dealing with the point. You're not making an argument against me. Which is what your post does. Irrelevant points on how to determine what a var is. You didn't deal with the problematic issues of the decimal. You could be hiding a pretty nasty bug there. It's important to know that variable is a decimal. &gt; There is a good reason to introduce auto for C++11... There is a good reason for var in C# too. That reason is to not use it for everything. It was for anonymous types and expressions. People have the same problem in C++, they took auto, which had distinct purpose, and want to use it everywhere to the detriment of readability. &gt; In reality you assume some aspects for some well known types. "You're too stupid to know what a type does!" &gt; as only the further API-calls reveal the real subset of the possible interfaces So, exactly how var works per default. This is the relative part of the argument you don't get. At worse, you're back to the same situation you have with var. There is only gains to be had by knowing the type. You also ignore familiarity. &gt; You know, people like you have imho too low experience with different programming paradigms and languages supporting them. I have a lot more experience than you, guaranteed. &gt; Your argumentation is too focused upon one aspect of the language **The argument is about one aspect of the language.** &gt; newer capabilities of this language Var is over a decade old. A DECADE old. And var, again, does not change the behavior of the code. It is syntactical sugar. I'm not arguing against var in totality, that you shouldn't ever use it. It has important usages. Using it everywhere though, is what we call an abuse of a feature. &gt; like human regocnizable type descriptions. In reality those are primarily important for the compiler (and the IDE) - not the human developer. **No, no no**. This is how YOU show you have little experience. Code is all about human reading. Yes, it gets run by the compiler, but humans have to maintain it. Code is written once, and read many times. And types are important to a developer, because it's the contract being used. Which was your own argument you had just a little while ago, which you ditched. &gt; you understand the code by reading words you understand, not by the types you read. Imagine this, genius, good developers can understand the types and thus have easier time reading the rest of the code. &gt; Dynamically typed languages don't even have any type information visible in their source code at all - based upon your argumentation I won't be able to understand (or at least have a much harder time to master it) the written code. You quickly start with the strawman: Never said you can't understand it, period. It shows you aren't reading. Your little concession proves you understand you have a strawman. That's right! People do have a harder time reading dynamic typed languages. This is a common cited issue. Harder to read, harder to maintain. Does this mean you can't use them or whatever other strawman you want to create? No. &gt; Hm... the reality shows, that you can write shitty readable code in any language - so if that's the case, to write or not to write the type seem not to be helpfull at all That doesn't follow at all. "But, but, I can screw with all the names in functions and variables and that proves... something!" But once again, you miss the point, and you miss that the argument is relative. Can I understand what you wrote better than if did the same thing but swapped all the types for vars? YES!
Did you see this? https://www.reddit.com/r/dotnet/comments/81fsk8/i_wrote_a_relational_linq_provider_for_net/
Does this work with mvc? It‚Äôs going to need stuff like signalr support
It is a really compelling solution, and when Microsoft controls all aspects of the product there tooling always is the best from my experience. It'll be interesting to see which direction they go with it, my guess its ultimate success will depend on the deployment size of the entire app. From what I've read/listened to they are trying both AOT and interpreter approaches to see what gives the best results. Having dealt with Xamarin AOT, my guess the interpreted approach will be most compact as things like generics and linq really balloon up the AOT size. 
Sorry. I was enraged. If the people want this GML syntax then... go for it, I suppose.
As far as I can tell, that just means you need to install the 64-bit ODP.NET driver. Of course, I'm not sure how strict versioning is for that. Oracle has a second .NET driver set called ODAC, but as far as I can tell, that's targeted at Entity Framework.
No, that's very interesting. Thanks for pointing it out.
foreach is the standard way of processing collections that support it. Under the covers it does a "move next" kind of loop but it hides that from you. Using the currentItem property is not necessary in the foreach and if that's the only use of that property, it could be removed from the class. In other words, you can just do foreach (bar item in foo.collection)
Definitely. In the mean time, javascript is the bytecode.
Lots of cool stuff happening in the space. Check out [Retyped](https://retyped.com). 
EF Core isn't relevant to C#? As for quality, doesn't the up vote rate speak for itself?
I give up! You won. Congrats. 
And this API would be on a server somewhere, yes?
Sounds about right. Found out what the issue was now. Had a try catch around the oracle connection and it was throwing the error on conn.Open() as mentioned above. The server is 64 bit and the oracle install is 32 bit. There was an option in Visual Studio in the Solution preferences to "Prefer 32-bit". Ticked this, built and the service started fine!
This is the third submission by you to your content/website in three days, so it's starting to be a bit spammish. This impacts leniency when considering the submission. With regard to the below rule explanations, no single one of them for this submission, in isolation, would be sufficient to remove the post. All three combined in view of the third submission in a day, is enough to remove it. Regarding Rule 3: Yes, EF Core is relevant to C#. But the submission itself is light on C# content, and seems to be more related to NoSQL databases and/or Azure Cosmos DB and support for those. Regarding Rule 6: A significant portion of your submissions is to your own content. Regarding Rule 7: This submission is relatively light on content, and reads a bit like blogspam; in that it's regurgitating information reported on at other sources. As the site reports, the _"estimated reading time"_ is _"1 minute"._ &gt; As for quality, doesn't the up vote rate speak for itself? On my side, it's showing an upvote rate of 4 over a period of over 2 hours before it was removed. I know /r/csharp is not the model subreddit for high upvoted posts, but a rate of 2 votes per hour I do not believe "speaks for itself". You should also be aware that users are fairly flagging your posts as spam. Normally we disagree and do not remove the submissions as, compared against more prolific/obvious spammers, you do actually take part in Reddit outside your own submissions regularly, and your submissions usually are of pretty decent quality. I would suggest that you keep carrying on, but try to increase/improve the content on the submissions and/or be aware of submission frequency as to not rub readers the wrong way.
Understood, thank you.
np. By the way, I had a typo, which normally I wouldn't bother raising it to your attention I think changes the meaning of the sentence pretty significantly. I had accidentally written: &gt; You should also be aware that users are fairly flagging your posts as spam. When I meant to write: &gt; You should also be aware that users are fairly ***regularly*** flagging your posts as spam. In that, I'm stating that they are often being flagged as spam; I'm not trying to pass judgment on the users as to whether or not the flagging is "fair".
LOL. I read that as "fairly regularly flagging" and didn't even notice the missing word.
I think if Blazor + Avalonia every came to fruition, that would be a game changing combination.
 somefunc(){ foo=new foo(); //Populate foo.collection bar current; try{ foreach(bar item in foo.collection) { current = item; item.process(); // may throw exceptions } } catch(Exception ex){ Throw new exception($"There was an exception when processing {current.ToString()}"); } } This is still better than building your own iterator (as many others have stated foreach is just a more readable way of doing exactly what you described)
it's a strange world when MS is rebranding GTK apps
I saw the same talk by him at NDC London. The blazor stuff was great, but the whole talk was definitely worth a watch if you have the time. 
Blazor is compiled C#, running in a VM, that was written in C and compiled to WASM all running in a browser. So it is in essence, I high level language running in WASM.
At work, Windows 7. At home, Linux Mint. It's not that I prefer the OS, but it's what runs on my "hobby" PC. It's in the basement where I A) won't be interrupted or distracted and B) I smoke weed so it doesn't bother my wife and cats. MonoDevelop meets all my needs but Intellisense (or whatever equivalent MonoDevelop has) is *really* slow. I suspect this is because my PC is ancient, not any flaw with MonoDevelop. We have another PC running Windows 10 but my wife and I both use it so there's always a chance she would want to do something on it while I'm coding. 
No, just leave Javascript alone already. I can do whatever I want in Javascript (and jQuery, which is my lightweight framework of choice) because I bothered to learn it. Stop inventing frameworks, let alone replacements for it and pretend like it's the new Egg of Columbus. 
This is an amazing project, thank you for bringing it to my attention!!!!
Eh. People did the same (poor quality) in JavaScript. A while ago, maybe 10 years, i interviewed a guy for a web developer job (was actually php but meh), and asked a question about how he would implement pagination. The answer was to the effect of pulling the entire list down and using js to choose what to show. I furthered the question for what if you had a lot of records, say, a million... Hinting that I wanted a server side solution. His answer : still do it client side.. 
Thanks for the input... but I might want to clarify a couple bits... I didn't design this method, I found it pre-existing in the code base and my first reaction was "Code Horror!" but I when I tried to figure out why it was so bad... I couldn't come up with any strong specific reasons other then it really looks weird/wrong/nonstandard... Second, the example code is just example code... it's just the barest snippets of the actual code. If I were to have had written it, I'd likey have done something similiar to what @enlogen suggested This codebase isn't 'mine'... I'm just looking into it b/c the person who does have responsibility for it wasn't available... I say this and my initial reaction was to send an email to the guy that was responsible for the code pointing out how I would have done it (The only reason I considered the .MoveNext() is because the bar being processed at the time of exception is lost when the loop/try/catch falls out of scope and that is a difference in object lifetime which could potentially cause issues further down the line)... for example, if outside the loop and outside the try catch it was being used for some reason. but as I was writing the email I couldn't think of any specific good reason to not like it... so I figured I'd ask here just to make sure that it wasn't just my own bias that made me dislike this approach... I'm not going to email someone about their code if they use string a="A"; a+="B"; a+="C"; vs String a=String.Concat("A","B","C"); Certainly, the "Better" way is string.concat... but it would be mere Micro-optimization... this wouldn't even be optimization necessarily, just imporoved readability... but it's only improved readability if it is actually easier to read and not just the fact that I hadn't seen it done this way before... but improved readability is more important then micro-optimizations and long as it isn't a determent to optimization. Thanks for the feedback.
Okay, so I watched the video and I'm not impressed. 15 years ago I had code where you could write everything once and it would make the client do everything for you, only it would also generate your entire UI for you, so none of this messy mucking about in HTML. It could even send all the mouse moves and clicks to the server if you wanted, so implementing drag and drop was as simple as adding a "draggable=true" or "droparea=true" paramater to the object. It made the AJAX happen for you as if by magic. Every server-side object had its own way of representing itself in HTML (which you could override but there was a default) and you would just throw the object at the web server, and it would display it. Then you could call the "refresh" function on the object, and it would send AJAX commands to the browser to refresh the display. Then 3 years ago I re-wrote a lot of it in C#, so I could build web applications in C# and have it make all the HTML in C# and not have to muck about in Razor. It didn't auto-generate the UI yet, but I was getting to that. You could code once and then drop it into your choice of ASP.NET or MVC and it would work just fine and look identical, so no more being tied to either templating system. It *is* slick how he brought the compiler into it so it will recompile quickly. 
And it is :) ... WebAssembly *is* that language. It's just a compiler target, which many languages can compile to
The really interesting part will be frameworks that skip HTML and CSS and implement their own rendering layer on WebGL.
&gt; where is it now? The death of Silverlight happened before Microsoft made any decisions to pull the plug. There was significant competition between browser vendors, JavaScript and security became a focus for those vendors, and extensions became more wide-spread; other languages popped up to make working with JavaScript tolerable; and it all culminated into killing native plugins in the browser.
Create a project template in VS. Include all your common reusable classes or put them in a Nuget package. Host it locally or load from disk/network share.
There are several other APIs which can be used. Canvas and SVG are the most common.
It's still far too new for production, in my opinion. I think we should all hold our breaths a bit longer.
No, I haven't. I'm only using it as a hobby. However, from what I've seen, the crew responds very quickly their issues on GitHub and their forum.
Obviously if your code has one method it doesn't really matter. The main issue with using a lot of static methods is that you cannot use much polymorphism with static methods which makes it harder to compose them. Also it makes testing more complicated. 
But aren't they both also ultimately part of the DOM? Canvas is a DOM element. SVG has its own DOM subset.
I am being shown but I‚Äôm not being given an explanation as to why those chose that design.
Care to explain a bit more in depth in regards to polymorphism? As in what parts of the concept would not be able to be used? Is it just overriding?
üòÅüòÅüòÅ Fair enough. [Did you read the documentation?](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/static-classes-and-static-class-members) It says what static class is useful for.
Yes, but it doesn‚Äôt really help with my current situation. I would just like to know when it is appropriate to be marking things static.
I think, the answer to that follows from the documentation, second paragraph. No?
So if it doesn‚Äôt store any information and it‚Äôs only aim/role is to calculate something or run a task make it static?
You laugh but [until 2016](https://github.com/v8/v8/commit/0702ea3000df8235c8bfcf1e99a948ba38964ee3#diff-64e6fce9a2a9948942eb00c7c1cb75f2) Chrome's JS engine would take comments into account when deciding whether to inline/optimize a method... so you could actually hurt performance by a lot for having a comment that's too long in your code.
Well, now... The conclusion is easy to make, is it not? Why even ask? Also, why are you asking me, an anonymous person on reddit? Surely the documentation, which is written by experts on the subject, reviewed and read by many others (who could have contributed to make it better, and probably did) explains better than me (or anybody else here)? 
I would have to see the code to be sure. Though in C# if any methods do not access ‚Äúthis‚Äù it should be fine. Most seasoned developers will and should divert new developers from static until they understand object oriented programming. To often we see people wanting to create global access to items in things like singletons, or other static references. Once a developer reaches maturity, having static methods here and there (like one in about every 5 classes or so) are fine as long as it is not breaking oop. So without seeing the code it is to hard to tell.
It seems like your question is really three questions: When do you use static classes? When do you use static methods? When do you use static members? All three have different use cases. Also, it really depends on context. Static Classes: Since static classes can only ever contain other static "things", static classes are most commonly used to hold utility-like methods/members. For example, a method used to complete the square of some given equation could be stored in a static class as it's always the same and doesn't require a state. You could also store things like strings that will always be the same in these classes. Static Methods: When contained in a non-static class, these are normally some type of helper method. One of the most common things I have seen in practice for this are static FromID() methods used to retrieve an object stored in the database from it's ID where the return type is the type of the containing class. For example: public class Account { public static Account FromID(Session session, long I'd) {} } Static Members: In addition to the use case stated in static classes, a couple common of uses for static members that I have seen are for singletons, and for static state. Static state would be described as the applications state - an example would be storing in runtime the number of logged in users. I think the question you asked is difficult to answer because there are so many situations for when to use static. The answer is not a precise definition because it depends on the scenario. I would suggest looking into polymorphism if you don't understand what it is as that should help you to realize how to make the decision of when to use static, and when to use instances.
Real pathetic act you're putting on. Do you always do this when you don't get your way, or when you find yourself wrong?
But for my console I don‚Äôt need to initialize any variables. The only variables in the class are inside of the Run method which are only used for parsing the command. I don‚Äôt know why I was given grief.
What are you talking about?
&gt;If there is no object, the ‚ÄòO‚Äô in **O**OP is not even possible. I couldn‚Äôt stop myself from chuckling. All I‚Äôm trying to get at is that I like to code the best way possible, and the reason o feel insecure is because I know that my way is incorrect and would like to do it in an OOP manner.
Why did you chuckle? It's a trivial observation: no object =&gt; no **O**OP possible. Not true?
Yes but they have distinct API surfaces.
**If** you had many of these, they may have had some structure that could have been modeled by a some use of classes. A typical console application, for example, is like so: * process command line to gather what needs to be done * do that something An abstraction of that is, for example (pseudocode): interface IAction Run() Main(args) IAction action = Process(args) action.Run() where there are different IAction implementations. Process creates an appropriate action, Main runs it. Example actions: "show help", "explain what's wrong with args" (if anything is), do X, do Y... I am **not** saying you should have done the above, just inventing an example.
That's amazing, but I am comfused how will this tackle AJAX and js interop?
Static is bad for multithreading too. 
eh? No it's not..
This is what i meant https://social.msdn.microsoft.com/Forums/en-US/c3cc953f-4659-44b2-8107-3e25d23fb02a/static-methods-in-multithreading-environment?forum=csharplanguage
Ah :)
What would be the best way of calling a method without reflection though?
You seem to be looking for us to tell you that you should not have been given grief about it. Please allow me to summarize what everyone is saying to you: There are good reasons why making static methods and static classes is appropriate in some circumstances, and not in others. Without knowing your specific requirements *as they were given to you* and seeing your specific code, there's no way for us to determine from what you have said whether you should have or should not have been given grief about it. 
New stuff is fun and all, but nothing's going to *replace* good old Javascript, or HTML or CSS for that matter. People need to stop acting like it's the most terrible language in the world and it's so extremely hard to do certain stuff in it. It isn't.
Yes, you can get the invocationlist from the event and invoke each within an error handler. This is the traditional way of dealing with one failure bringing down the chain or executing them asynchronously, again with error handling. I use extension methods for this. Winforms is tied to an event loop and has thread affinity which is a bit different. The event loop here is not using C# events it's a historical name. Thread affinity means all operations that affect the UI must occur on the UI thread. To further complicate things, Winforms was from the era of the [Event based asynchronous pattern EBAP](https://docs.microsoft.com/en-us/dotnet/standard/asynchronous-programming-patterns/event-based-asynchronous-pattern-eap) which was the second asynchronous pattern widely adopted by the .NET framework. Early winforms was around from the beginning so very early Winforms code used the APM and predates generics and iterators! Thank god for progress :) The EBAP uses a convention of C# .NET events to marshal code back to the UI thread. You will have seen the pattern in the BackgroundWorker and one of the Timer implementations. So again, it's using events but it's just a convention.
If you're fine with a low-level library, check out OpenTK. 
You can‚Äôt override static methods is what he‚Äôs getting at. 
They sound like old school C# developers who predate extension methods. It happens sometimes. People just stop learning because they're content that what they know works. People wrote software that worked 20 years ago, so it's not a ridiculous mindset. It is a problem if they can't communicate the full vision of their approach. If they can't explain clearly why they think it's wrong, they're also poor communicators. That's more damaging to you. We would have to see your code to know if there is any particular problem with your use of statics, but it doesn't sound terrible. Like everything though, static can be used inappropriately. 
You seem incapable of distinguishing opinions from facts. Using facts to reason an opinion, does not turn the opinion in to a fact. Honestly you sound like a huge dick. I don‚Äôt blame the other guy for telling you to get fucked. 
There is no spoon. No Javascript needed.
But it is needed. Without easy js interop, blazer can't be used in current projects. Without ajax, blazer has to introduce new concepts which will significantly raise the barrier for entry.
Extension methods, completely deterministic functions that don't depend on any infrastructure. The deterministic functions have a down side in that you're then relying on real implementations when it comes to testing. 
Sorry I read that but don't understand how to transfer it to my code 
This.
The whole frontend community works in JS and thus the whole ecosystem is based on that. I very much doubt that blazor will be popular except for small experimental internal sites at some companies. In general for any real system it's not very useful to have such tight coupling between the backend and frontend, since most companies want to expand into various mobile apps (sometimes several for one BE model).. Also I find that the frontend frameworks are pretty damn nice these days, which almost makes up for the shittyness of JS (and with typescript it does!).. Source: I work for a SaaS company. 
Just from reading the thread. I think you need to use AsJson&lt;players&gt;()
RemindMe! 1 day "c# exercises" 
I will be messaging you on [**2018-03-04 12:23:41 UTC**](http://www.wolframalpha.com/input/?i=2018-03-04 12:23:41 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/csharp/comments/81p0bo/any_resources_for_multithreadingasync_exercises/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/csharp/comments/81p0bo/any_resources_for_multithreadingasync_exercises/]%0A%0ARemindMe! 1 day ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Razer Game booster. Even if you‚Äôre not running a game it will do what you‚Äôre looking for.
The thing is it is simpler with non static instance. Each instance has its own state and they will not mess with each other.
The error now shows as `Compiler Error Message: CS0029: Cannot implicitly convert type 'unirest_net.http.HttpResponse&lt;Webpages_Tables.players&gt;' to 'System.Threading.Tasks.Task&lt;unirest_net.http.HttpResponse&lt;Webpages_Tables.players&gt;&gt;'` I have pasted what I currently have on the page, is this what you meant by list of players? https://pastebin.com/MRDwb0aD 
try the dining philosophers problem? https://en.wikipedia.org/wiki/Dining_philosophers_problem there should be many implementations out there
I‚Äôm not on my computer right now so I can‚Äôt really provide an example, but you should look into using LINQ for getting data from your DB rather than a reader and a while loop. It‚Äôs quite handy and a bit more readable. 
I do understand what you're saying; statics are accessible across multiple instances and each of those instances may be operating in a different thread. So it's more likely that a static will highlight a thread safety issue with your code. However, an instance is not bound to a thread, it can be operated upon by multiple threads, so the same thread safety concerns are applicable. 
If you want us to tell you if using static is good or bad, we need context. Other commenters are literally just guessing. You need to post an example of your code for a definitive answer. 
&gt; But the reason I did this was because whenever I wanted to run a command from within the game or the console I didn‚Äôt want to have to make a new instance of that class every time which saves writing some code whenever and wherever I use it. I Think this is the big thing to talk about, this is a lot broader than whether your use of statics is correct or not, this shows a bit of a flawed approach to creating software in terms of long term maintenance. If you're optimising for the amount of keystrokes you need to make at the time of writing the code, but in time saved now you end up potentially creating additional cost at a later date, because the codebase has grown, your global static code is now used all over, and it becomes impossible to change without breaking a lot of code or having to put in a lot of manual effort to clean things up. Using instances of classes creates more flexible code because you can change types at runtime to modify their behaviour. You can change the behaviour of your software by writing new code instead of having to crack open and change existing code. Bonus points if your class gets passed in as a parameter instead of being new'ed up in place. Have you ever looked at code you wrote a year ago and been mad at yourself for the way that you solved the problem? If you use statics in places that you don't absolutely need to, you will end up with a codebase that's a tightly coupled and takes a mountain of effort to maintain. Be very very careful with the use of static, it is very easy to do far more harm than good with it. Now, I'm not going to say that your specific usage is that terrible because I can't see the requirements or the code, but what I can see is the reasoning you've explained for using it, and that reasoning is absolutely incorrect. Do not use statics to save yourself time typing.
Use reader.GetString(0) to get first value of the record from select statement if it is a string. you have to k ow the type.. If you want to use it by the columnname, use GetOrdinal first. also you may need to check if the value is DBNull.Value or you may get crashes. This is more painful than EF or Dapper, but it is the most performant.
Change the type on response to HttpResponse&lt;players&gt; response Or you could just use var 
There is no reflection in the example above. That is a virtual method call.
Hey thx for the help, i managed to get the values with : while(reader.Read()){ tb1.AppendText (""+reader.GetValue(1)); //the index is the collum index I dont know anything about LINQ but ill give it a shot, puh and i thought im done with basics ;-) 
http://www.albahari.com/threading/ is a great resource for understanding the fundamentals
I believe you'll find your error is the classes you have set up to deserialize the data to do not match the structure of the data being returned. When I copied the example output of that api call and in Visual Studio "Edit-&gt;Paste Special-&gt;JSON as Classes" it gives me a similar, but different class structure. This Paste Special functionality makes it a lot easier to have the correct data structures with which to deserialize the output. also as u/JustRamblin mentioned, try using var. This will allow you to step through in debug mode to inspect the value being returned and make adjustments accordingly.
If I'm understanding you correctly, ReadLine reads multiple characters (ie. A whole word, sentence, or even paragraph), where ReadKey only reads one character.
Your comment does not make sense at all. He cannot even compile the code, but you suggest that the error is a runtime one. Also how does var allow you to debug? Var is just a "shortcut" so that you don't write the type by hand. The type is automatically determined by the compiler at compile time.
+1
Heh. Did you watch the video? You would not use it in an existing project. You would start afresh with version 2.0 and never look back to the bad old days of Javascript.
Since you have control over the class you're pulling data from to populate that info ... I would just add an Id column with a type of int, and put the [Key] attribute on it from the DataAnnotations namespace. When adding your values (New York, London, etc) put a unique value in there to make it look like a primary key. https://msdn.microsoft.com/en-us/library/system.componentmodel.dataannotations(v=vs.110).aspx
Yeah man, I have crapload of stuff bookmarked to read but I'm looking for as simple practical exercises/tasks mostly.
works perfectly, although i have the run time error now `Unable to cast object of type 'System.IO.MemoryStream' to type 'players'.` Sorry and thanks for the help
Removed: Rule 4.
I will let in on a little secret. **Without js interop, blazor won't get any traction at all.** It does not matter how great it is, there are shit tons of js library and quality ones at that. abandoning the entire ecosystem for a bleeding edge tech, is not a smart idea.
It's useful in Unity because any static class or class with a static method/variable will not be destroyed between scenes or with scene reloads (since it's not an instance).
the reader you have used here is reading in an entire row of data. you are on the right track tho. intead of going reader.ToSting() you should try reader[colname].GetValue() to get the value of every column in that row
Try: var response = I think your asJson method is changing the return type and you need to update what tyoe you are expecting as well.
I'd say give it a try. You should understand the MVC pattern beforehand, but otherwise I don't think theres much of an issue in creating a simple app.
you cant output the readers content tostring unless the reader supports that (like the textreader). You need to extract the records from the reader. Or you could make your life easier and more like what we do in the real world by using Entity Framework.
That is exactly the answer I was looking for! Thank you!
A newcomer comes! What does he bring to the table? Insults. &gt; I don't blame the other guy for telling you to get fucked. I mean, he specifically tried to make it personal from square one and refused to deal with a single point brought up, because at worse, he didn't like my opinion. He searched for some random excuse to get out, literally getting upset at the word "excuse". It's perhaps the most petty and inane thing I've heard. But, I guess that behavior is all okay in your eyes, why, and who's surprised really? Because you did the same thing this post. &gt; Using facts to reason an opinion, does not turn the opinion in to a fact. Yeah, those facts are how var hurts readability here. Yes, sometimes the usage of var vs types comes down to style, and opinions are then what we have. Sometimes var in fact actually helps readability in some situations. But this time, it is a fact that var hurts readability, because of the issues I brought up. Now, nobody can deal with the issues I brought up, and nobody can seem to back up a single point about why using var here would be readable other than blanket claims about noise and it somehow magically hurts, but gosh darn it I must be in the wrong and I must be a huge dick for not immediately relenting to others.
It‚Äôs okay, you still don‚Äôt get it.
What a *darn* shame.. *** ^^Darn ^^Counter: ^^475346
No, I get it. You're working on a strawman that I think you should never use var. So that you can dismiss my argument that the example here is factually less readable, which I backed up. Then, because you don't like that, and you can't actually deal with anything brought up here, you just want to insult me over it all. If you guys had actual arguments, you'd use them. But you don't, and you're upset about that, so you resort to ad hominems to avoid hurting your ego admitting you're in the wrong. That is very typical behavior. It's funny you guys don't see how transparent and common that is, though.
I don't know of any actual Exercises offhand. However, one sort of task that can be done as an exercise is implementing your own `TaskScheduler` if you want some practice in/around Task based multithreading. I can give you an interesting task on that tangent that I've never bothered to turn into a lesson/exercise/code sample. I have seen this pattern (And ramifications) in production environments however: - [Consider this Limited Concurrency task scheduler ](https://msdn.microsoft.com/en-us/library/system.threading.tasks.taskscheduler(v=vs.110\).aspx) - Consider this implementation: http://share.linqpad.net/o6hutc.linq What Happens when each of the different calls runs? Can you do something about the especially problematic method? (you can, but it's ugly.) Most of what I've learned from thread pools and multithreading has been by looking at code from robust multithreaded projects. Akka.NET uses thread pools in their dispatcher implementations, as does DotNetty, and I believe MassTransit.
this is not america, this is asia that i am working for. its a) on the other side of the globe and b) they arent dicks like americans that would take ownership of code that your didnt write for them
the thing is i want to reuse code, not write a new library for every project that i will ever make
thats why i want the files to be in their repositories, not in nuget or something else. but i guess i will fork my code then into a library on their premise and use that. i of course have to ask my client first if that is ok
For WebGL, you generally end up with a very simple HTML page containing a single Canvas element.
yup guess thats the way i have to go, i see many repositories ahead @~@
I mean, sure, depends upon which area of Asia you are in, and if it allows IP theft. But you have a misconception here: When you copy your code over for them, it becomes code you wrote for them. They have ownership of that. Their claim is you wrote that code for them. I don't see any reason to risk it to save yourself some time at work.
I'm revisiting a Library Management System project I built with ASP.NET Core 2.0. Currently working on getting code coverage setup with OpenCover and publishing to Coveralls. I created a YouTube series documenting the build last year: https://www.youtube.com/watch?v=WTVcLFTgDqs&amp;t=76s
No joy I'm afraid, still the same result. I've managed to get it working by adding the following two properties to the `City` class: public City Self { get { return this; } } public string Description { get { return ToString(); } } That way, I can use `Self` as the `ValueMember`, and `Description` as the `DisplayMember`. It's a lot more elegant than the previous ways I found of doing it, but I still can't help but think there must be a better way.
I would say so, but you will also need to understand what is MVC and how MVC projects are structured. Things like Javascript and CSS you can learn along the way.
I can't find the specific resource now but search for stuff by Stephen Toub, he was hugely responsible for a lot of elements of modern TPL and has written a ton on its use.
this is a skill you are going to have to develop yourself. there are not nice examples or sample projects written against the northwinddb for most stuff. as a matter of fact for most things the examples suck, and the sample projects do not handle any extra scenarios. You might find some stuff if you dig around on github. good luck
Try developing async or parallelised versions of regular algorithms and containers.
The thread that was running when InnerMethod() was called is the one waiting for Result. From [MSDN](https://msdn.microsoft.com/en-us/library/hh524395\(v=vs.120\).aspx): "The Result property is a blocking property. If you try to access it before its task is finished, the thread that's currently active is blocked until the task completes and the value is available. In most cases, you should access the value by using Await or await instead of accessing the property directly." ConfigureAwait(false) is like saying 'don't necessarily save the current context to schedule the continuation'. Because I *think* SomethingAsync() could still scheduled the continuation on Method()'s thread even with ConfigureAwait(false) if it runs fast enough. So, I think the answer is: if you ever wait on async code there is a chance to deadlock.
&gt;So, I think the answer is: if you ever wait on async code there is a chance to deadlock. ConfigureAwait(false) avoids deadlock, 100% of the time, 100% sure. I wasn't asking if ConfigureAwait(false) prevents the deadlock, that is a fact. 
I'm not sure I follow your naming of threads. Here's what happens (usually): 1. `Method()` is called on thread A (depending on where you call it from) 2. `InnerMethod()` is called [still on Thread A] 3. `SomethingAsync()` is called [Thread A] 4. `SomethingAsync()` begins doing "something" and returns a `Task` object to `InnerMethod()` [Thread A] 5. `InnerMethod()` sets up a continuation on the task returned by `SomethingAsync()` [Thread A] 6. `InnerMethod()` returns a new `Task` object to `Method()` [Thread A] 7. `Method()` calls the `Result` getter and blocks [Thread A] 8. `SomethingAsync()` completes and signals its task 9. `InnerMethod()` is continued on arbitrary thread B 10. `InnerMethod()` signals its task completed [Thread B] 11. `Method()` receives the value of the `Result` property [Thread A] 
As others replied, the action is executed on another thread with `ConfigureAwait(false)`. There are other implications (Especially in Pre-Core ASP.NET) that wind up leading to the adage 'Async all the way down'. It's worth noting there's other ways around executing an async operation. [This Gem of code](https://github.com/akkadotnet/akka.net/blob/dev/src/core/Akka/Util/Internal/SynchronizationContextManager.cs) is used Here [such that the call can be safely done either synchronously or asynchronously.](https://github.com/akkadotnet/akka.net/blob/3b78f75ce98007361de44154d13af5e60fe58b99/src/core/Akka/Actor/Futures.cs#L103). It essentially detaches the context but then reattaches it after the continuations execute. 
What an awesome explanation. I wasn't sure if 11 was going to be executed on Thread B, but now I understand it. Thanks a lot for the detailed explanation.
That doesn‚Äôt make sense. In order for a script to function it must be on a game object if it‚Äôs not a derived class. You must specify in code to not destroy on load. So what do you mean?
I feel like this is actually reasoning why you should know how MVC is meant to be structured...
Nice. So if I'm forced for whatever reason to block an async call, I can use this library, call await SynchronizationContextManager.RemoveContext; (before any awaits) and the I can safely block the async call. Am I right?
Yes, basic HTML/5 should help also. Basic JS is a plus also but not a req. Follow some 'Walkthroughs', boring but informative.
Are you against using OAuth2 or OpenID? Do you need to roll your own access auth system? I you are not sure you're capable of making a secure system and don't have time to make sure... maybe run with an existing option. I'd suggest website &gt; API &gt; DBServer as the basic model if you must though. You'll have more options to change if and when you learn more.
At the very least it makes blocking calls worry-free within ASP.NET. I've never tried it in a win forms app. Note how in the example, the non-async methods are calling this async method with no other trickery. There may be different drawbacks to this method vs `ConfigureAwait(false)`, but I haven't yet ran into any.
When we make business object classes that are called through web services, we always mark them static to prevent anyone from trying to store class local data. We have sets of business object webservers and they have to be stateless. 
I‚Äôm confused. Let‚Äôs say I have an empty game object with a script. The script contains a static class and static members. When loading a scene that empty game object is destroyed along with its components. Unless in your script before loading you specify not to destroy that game object on load.
Always use ssl. You can keep your creds in your web.config (presuming you're writing a web application) and encrypt it. You could even keep it on a separate server. Heck, make just one for credentils if you want. Make sure your sql server is hardened, particularly, disable/rename admin accts and disable sql's ability to browse the network. Make sure your code is injection proof. Always use parameterized stored procs, don't write sql statements in code. Always use secondary accounts for anything with minimal access/permissions - this limits the footprint if compromised. Write a good encryption/decryption class if you want to get fancy, use it like salt and pepper. Just some fyi imo.
If a class isn‚Äôt derived from MonoBehaviour, it doesn‚Äôt need to be attached to a GameObject to work properly.
I would use it for green-field projects, so it would certainly get *some* traction.
I'm not against using one of the tools you mentioned, but having my own system would be later for other goals (licence management, ...).
How would a web application look like for a problem like this? I'd give a query string for a website (xy.com/login.php?usr=aaa&amp;pw=bbb) and wait for an answer?
"shared network folders" are a technology built into Windows that isn't standard on other OSes. There is a Linux 'port' called Samba, but you're going to have to figure out how to PInvoke the C samba libraries yourself... not pleasant. What I would recommend is use a drive mapping on Linux with [cifs-tools](https://www.howtogeek.com/176471/how-to-share-files-between-windows-and-linux/). This will create a folder somewhere like `/mnt/my-share/` that you simply write/read with System.IO and let the OS handle the protocol. Another option would be to switch to a file access protocol like SFTP, but that won't always be feasible.
Figured it out myself, but *thank you* for the clue that led to my solution: NetworkCredential testCreds = new NetworkCredential("user", "password"); CredentialCache testCache = new CredentialCache(); testCache.Add(new Uri("\\\\192.168.5.5"), "Basic", testCreds); File.Create("\\\\192.168.5.5\\testfolder\\test.txt"); Other objects like DirectoryInfo, FileInfo, etc, work great. Thanks!
That's one of several ways you could accomplish this however, encrypt/decrypt everything in your query string and use ssl. You could do this with cookies too. You could do this with the session. You could do this with an asp.net membership account with stored fields for username and password - so the user never actually submits their true credentials, only the asp membership creds. Still, more ways of course... 
Hm, I hadn't considered this... I'm doing all my dev/testing on windows... but Your drive mapping workaround just sounds perfect, and is likely what I'll do when I test on linux. You guys made my night, much appreciated.
Np my dude, that's exactly what i meant. Great job! 
Ah, sorry, I was just re-reading your first reply, and I misunderstood it. The application would be a desktop application, which would connect to a server to authenticate.
For real? What does "var" have to do with runtime errors?
I believe you can extend the asp membership library/implementation to extend to AD. so your login, reset, forgot, validate, etc. methods all point to AD. Once validated, the uid and pwd could still be applied to your network credentials object and proceed from there. 
Well, then I totally should get some information about them. Thanks!
There's nothing wrong with having your DB connection string in code/config file, unless your project files are shared with someone who shouldn't know it.
Does not look like good solution at all. Now if you want to move your app and data to some other place you have to update that config file. Why not have data file instead of that config file then?
(shrugs) I setup Ubuntu Gnome on the laptop and desktop almost three years ago and have not had to fiddle. Even upgraded to the latest release. I have a Win7 VM that I keep around for the 2x-3x per year that a client pays me to boot it up and do work that can't be done in Linux.
Coherence mode is cool, but I found I prefer to keepy workspaces separate. I tried VMware for a bit but was really sad that when you interacted with a windows screen, it would switch all the screens to windows workspaces, it didn't allow for mixing workspaces. As for your git repos,I've gotten it working before with me repos on the Mac side and hitting them from vs on my windows side. But sometimes vs would get angry about having source on a shared drive, especially when working with xamarin. 
Yeah, the issue with the git repos for me was I originally kept them in the macOS side. And either MSBuild or VS would get complainy about the repo. That may have been fixed in VS2017 -- but at the moment it causes me no pain because git bash + GitKraken works fine. I just had to make my Win VM larger when I rebuilt it a few months ago. I like Coherence because I setup my workspaces so that I have 7 workspaces. And I have some of the Windows programs set to always display on a specific workspace. I also don't have to remember how to swap between windows in the macOS way vs the Windows way. Workspaces: 1. EMail / Slack / MS Teams / GMail 2. Git issues / kanban board 3. Browser windows for the build service, the exception logging service, or if I'm checking something in a QA / production site. 4. The reference browsers (how to do X, notes on what I'm working on this instant). Plus SSMS from Windows is set to always open on this desktop. 5. Visual Studio / Code windows, also the default screen for any Windows stuff 6. GitKraken / git bash windows 7. Misc stuff I do a lot of three-finger swipe left/right. Upper-left corner is my alternate 'show all desktops' method. I also find it really easy to find stuff because I have things categorized by screen. Still, sometimes I have to use Tabli to find an open Chrome tab that I know is somewhere.
I'm not sure who said it was bad idea to have database credentials in code (app.config probably), but they where wrong. Maybe you misunderstood them? They might have meant that never have database credentials client side? Client side (mobile app, desktop app, browser, etc) should never ever access database directly, only through secured api. Also don't try to reinvent the wheel by doing authentication yourself, it's a bad bad idea. Create your api (server side) with something battle tested like ASP.NET. After reading comments here about OAuth2 and OpenID. If you ever need to use them I want to let you know that never use OAuth2 if you can use OpenID. Some people think OAuth2 is authentication protocol but it's not, it's an authorization protocol and it's extremely hard to secure.
You have an object of OleDbDataReader and you call .ToString() on it. You seem to expect that ToString gives you *data* from the *columns* in your reader. The documentation **does not** say that will happen, does it?
Oh and remember to use SSL (https) with ASP.NET. You can get free SSL certificates from Let's Encrypt
Jus FYI: You can prefix a string with @ to disable escape of backslashes. That way you can avoid awkward path literals. 
The math class is pretty much 100% Pure functions. You pass in some arguments, and you get a number in the return value. There are no side effects, it doesn't print anything to screen, it doesn't touch any external dependencies like the file system, network etc, it doesn't manipulate any other bits of software. It's just a parameter goes in and a number comes out. More importantly, if I'm writing a class, Foo, and I'm writing unit tests for Foo to prove it works correctly, and Foo needs to use the Math class - it wouldn't make sense for me to want to write a test in a way that I could isolate Foo from Math, the Math functions being so simple that Foo wouldn't make sense to test without it. So no, what Microsoft have done with the Math class isn't a problem. &gt; I assumed that anything that does not implement any class variables or methods should be static, if it is just a single task then it should also be static. This reasoning is incorrect, and far too broad. You need to think about what the code is trying to do, not how it's implemented. If you try hard enough, you can make any class not have member variables. And every method is really just 'one task' at whatever level of abstraction you're working at. 'WriteLogFile()' is just one task. I can pass in a file path and the data to write as arguments, and now it doesn't need any class variables, but this still is not a good candidate to be marked static, because it calls out to the filesystem, and now any code that uses this becomes tied to the filesystem. What if in some cases I wanted to send my logs over the network? If this is static I have to go and change the code inside the 'WriteLogFile' method, or I need to change every bit of code that uses this static class. Other code becomes tied to the implementation of WriteLogFile, you've created a hard dependency between two classes by making things static where you didn't need to. The static keyword will make your code rigid and difficult to change, it limits your options. I've seen whole programs where every method was static, and you end up with procedural C style code where every method is global. It's an absolute nightmare, but don't just take my word for it, write something like this and see for yourself. Write it, and then try to maintain it and make changes, you will enter a world of pain. Working on codebases like this was what really opened my eyes to how bad it can possibly get, so maybe it'll be helpful for you too. You arguments suggest that you seem to think that marking things as static is in some way an optimisation, when the reality is it takes options away from you. I suggest you spend some time reading and understanding [SOLID principles](https://en.wikipedia.org/wiki/SOLID_(object-oriented_design)), `static` gets in the way of O, L and D. Sorry, I've gone off on a few tangents there, hope this helps.
&gt; The "smart solution" you come up with today will have you scratching your head in ten years, when you need to edit the code, wondering what the hell you were thinking. THIS!
I‚Äôm on mobile here, so it‚Äôs hard for me to read all your code samples. One thing that strikes me, though, is that the current code has a side effect - it changes CurrentItem. That‚Äôs usually a bad thing, I think we all agree. But if you ‚Äúfix‚Äù it, and there‚Äôs something else that relies on that side-effect, you‚Äôve just broken it. Of course this is exactly why side-effects are bad, and I‚Äôd never suggest keeping it as is if you‚Äôve got the option to change it. But just a warning, before changing it, to do a full code review and check if anything that‚Äôs using CurrentItem might rely on that side-effect, and then to test it thoroughly afterwards.
To add one more thing to already great info in other comments, static members may not get GC'd ever throughout the life of the application. So, avoid unnecessary heavy idle heavy objects in static members.
It probably isn't the most terrible language in the world, but that doesn't mean it is a good language either. The truth is the reason why you see so many people trying to "improve" or move away from Javascript is because it isn't very good. 
Ahh, that's good to know on ConfigureAwait(false) forces a context switch. &gt; I wasn't asking if ConfigureAwait(false) prevents the deadlock, that's a fact. True, but I answered your question in my first line: &gt; The thread that was running when InnerMethod() was called is the one waiting for Result.
Guess I'll have to learn how ASP.NET works. I'll look into JWT aswell.
I've literally never used events inside an ASP.NET MVC app.
I‚Äôve used filesystemwatcher in the past and always ended up replacing it with a timer sweep or something since it‚Äôs incredibly unreliable at triggering the events you‚Äôre listening for.
No.
Use this. You'll probably have to copy paste the code and use it or build a nuget package for easier install. https://github.com/dotnet/corefxlab/tree/master/src/System.IO.FileSystem.Watcher.Polling
https://github.com/dotnet/corefxlab/tree/master/src/System.IO.FileSystem.Watcher.Polling
I kinda succeed writing the code to perform the desired function however, i'm struggling to do the same in "coddingames.com" when there is already code given and I need to add something for everything to work. The code is: using System; using System.Linq; using System.IO; using System.Text; using System.Collections; using System.Collections.Generic; /** * Auto-generated code below aims at helping you parse * the standard input according to the problem statement. **/ class Solution { static void Main(string[] args) { int n = int.Parse(Console.ReadLine()); // the number of temperatures to analyse string[] inputs = Console.ReadLine().Split(' '); for (int i = 0; i &lt; n; i++) { int t = int.Parse(inputs[i]); // a temperature expressed as an integer ranging from -273 to 5526 } // Write an action using Console.WriteLine() // To debug: Console.Error.WriteLine("Debug messages..."); Console.WriteLine("result"); } } The part that confuses me is how does the input work with an array which is not defined before the loop. Any help on this?
Why use events inside MVC? It kinda defeats the purpose of the framework. MVC handles requests via http request (typically) Events are for winform apps that don‚Äôt send requests over http. 
Are you talking about the pattern named MVC, or the Microsoft product named MVC (which does pretty much follow the pattern - but you don't need to write any of the reference links as it does it for you)
 if (foo is ISomeInterface someInterface) { // no need to null check
F# has better type inference and zero lifes ruined.
What if you want to use Rx? 
with the async/await keywords?
why? type inference is really good.
Yea, I do like that syntax. Those I worry some times that people will skip the `else` clause and turn it into a "do X or fail silently" function. I've already seen that with the `null` checks.
This and if you're using it within Docker on a Windows system with host -&gt; container mounted volumes, you won't receive any events due to the nature of mounted volumes in Docker for Windows. I know this specific scenario isn't super likely but it's forced me to write a timer-sweep instead. 
I'm not too familiar with F# what is it? Is it only specific things or can it do everything C# can
I often use both. The FileSystemWatcher can trigger a sweep more frequently than the timer, but I don't rely on it to determine what has actually changed.
i find it hard to get get my head around the difference between using a reader a using LINQ, because i lack about the "magic" behind Database querys. I just learned c#, then wpf, then SQL (all just basics) and then i started to combine all. Im not sure where to start learning LINQ
You just need the EF [provider for access](https://github.com/bubibubi/JetEntityFrameworkProvider).
I think you are missunderstanding something. The used language doesnt mean that your source code is "secured". What do you want to achive?
I want to hide my source code. This is impossible in some languages and near possible in others (C, C#, C++ for example).
You cant "really" hide what your program is doing. You can make it more diffucult to reverse engineer it https://en.m.wikipedia.org/wiki/Obfuscation_(software)
Non-Mobile link: https://en.wikipedia.org/wiki/Obfuscation_(software) *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^156009
Your needs seem very specific and way beyond your apparent understanding of the framework and perhaps even programming. What is it that you are trying to achieve? Do you intend to rewrite your Python code in C#? Why all the secrecy?
Well certain languages are really easy to decompile (e.g. Java) and some aren't even compiled so are extremely easy to get the source code from (e.g. Python). My original question still stands.
I don't think hiding source code is all that specific. I have written the program in Python and I will be translating it into C#. It is a paid service and it is a market in which people constantly try and 'crack' your software and release your source code, which would decrease revenue.
Tells us your real problem why it should be "secure" in such a way, not what you think you have to do :)
It is a paid service and it is a market in which people constantly try and 'crack' your software and release your source code, which would decrease revenue. What is the best way to prevent reverse engineering in C#?
OK well what is the best method of obfuscation for C#?
Dont know. But you can never be safe that code cant be reverse engineerd. You might net to have e.g. some server side licensing
So how can I hide my code? From the conversations I've had with people on similar subreddits it seems as though the current advice is it is totally impossible and there is no point in trying, which obviously isn't true as you can't get the source code of every application on your computer.
Is there a better language to do it with?
The model I've used most recently is to monitor the events and throw them into a queue. When a file gets created, throw an entry in there. When subsequent updates come for the same file in a brief amount of time, throw those away because the item is already queued. After a short period of time, process the items in the queue against whatever data store you're using. This has worked flawlessly over the past few months on a system I'm running. 
F# is another .net language. 
You can attach a debugger and debug the assembly. The CPU still has to run something that it knows how to do. Meaning your problem is inherently impossible to solve. If you really need to stop hackers/crackers from getting the source code then you shouldn't even give them that information to begin with. Use a server/online architecture for you app and use encryption.
Using a language that compiles directly to machine code (e.g. C++) and maybe using an obfuscation tool at least raises the difficulty. Ultimately, if you want your code to run on your customers' computer, they need to have the code in some form. There is no way around that. Skilled reverse engineers will always be able get around any 'protections' if they care enough, even huge gaming companies that spend millions on this stuff generally only manage to delay them for weeks or months at best. If you are so worried about keeping the internals of your code secret, consider creating some kind of web application/SaaS solution instead.
Are you talking about cross-platform? Surely I can run C# software on Mac? I think a server will be too expensive for the start :(
You aren‚Äôt returning a value of type T, you are returning a value of type Potion.
Do you know of any obfuscation tools? I guess I will have to just hope for the best as I am a single developer so it will be too expensive to buy a server and process everything the user does. OK well I would like to use Selenium which I don't think is compatible with C++ unfortunately :(
But what's different about it. What is the purpose of it. Is the syntax like C#
Everybody needs to learn to read and understand the documentation, otherwise they‚Äôre typing random stuff until it works. So read.
No I mean run all the important code on a server so that the client program is useless and only has an UI to display the information from the server. It's more expensive but also hides your important code completely.
Oh ok, well I wouldn't really know where to get started with this. Is there a framework that makes it easy to use with Python code? How much do you think I'll need to spend on a server?
Your method should return a T but you are returning potion. You aren't using generics correctly at all. You need to do some more reading on them.
So how do I keep the interface how it is, but allow myself to return whatever type I want? I don't understand what the point of generics are if I can't return anything.
C# doesn't get compiled into machine code but pretty readable intermediate code. You should look into obfuscation. If you write for the Mono framework then your code should run on Windows, macOS and Linux but you will find that there are fewer features (libraries) available compared to tje .Net Framework.
OK well what about storing the Python code on a server and then the only thing stored on the user's PC is the UI. How could I go about doing that and what sort of pricing am I looking at? Sorry for such a general question but I really have no idea.
I'm leaning towards storing my Python code on a server. Meaning the user only has the UI installed and I serve them the code from my server. Is this going to be expensive and/or difficult?
It differs per framework and the tooling you have for the language. I've got little experience with Python so you'd be better off looking around online. You have to keep in mind that if you're working alone on this program it might not be worth it to spend a lot on security and instead just get your app functional. All things come at a price/time investment.
Yeah, I appreciate I'm asking Python questions on a C# subreddit. You're right, I might just have to settle with what I have.
Ok, so my book doesn't cover that. What are some good books, tutorials, resources that can explain this better? any recommendations?
Sorry I'm asking a Python related question on a C# subreddit. I was planning on using Tkinter or htmlPY for the GUI. The code is about 300 lines (I know that is still very general but hopefully it can give you an idea). Although I am using some fairly large packages such as Selenium.
You can rent a basic VM with a public static IP address on DigitalOcean for $5/month, there's no need to buy an actual physical computer.
Where does C# come into play? If you just want to run your Python code in the .NET Framework or Mono then you should look into IronPython.
Well I made a most on r/learnpython asking how to hide my code and they said it was useless and I should write it in a different language. They suggested C# since it is compatible with Selenium. Does IronPython drag-and-drop work on Mono (i.e. Mac/Windows) too?
This guy you replied to helped you out by creating an example and you failed to thank him. Good luck with your programming education
Sorry I realise this is a C# subreddit but do you know of any tutorials for setting something like this up with existing Python code? It sounds like it would be quite difficult.
I haven't been a learner in a while so I can't help much there. I would normally just Google c# generics tutorials and find one that worked for me. If you have any specific questions after reading up feel free to contact me.
Don't get me wrong, I like the simplicity of type inference. But explicit typing leads to more readable code. There are obvious cases like var list = new List&lt;int&gt;(); Thats easy to read. But if you're getting it from a method or something like this: var list = ListClass.GetList(); Its easier to read this quickly so you dont have to look at the function to figure out what the return type is. List&lt;int&gt; list = ListClass.GetList();
To use it, instantiate it like you would in any other C# program (MyClass mc = new MyClass(); for example). Access to MonoBehaviour objects could be achieved with a singleton pattern, or if that‚Äôs not an option you could pass them as parameter to your methods.
`List&lt;T&gt;` is one of the most basic examples of how generics are useful. With `List&lt;T&gt;` we can create `var stringList = new List&lt;string&gt;()` or `var intList = new List&lt;int&gt;()` which would allow me to do `stringList.Add("foo")` or `intList.Add(1)`. Without generics, we would have to create a separate implementation of `List` for each individual type (`IntList`, `StringList`, etc.) which would be extremely tedious and repetitive. An example of a generic you might create yourself could be `PagedList&lt;T&gt;`. You don't care about the type of `T`, but you want a generic API for creating a paged list of `T` objects. 
Now you are the one name calling. I made a simple statement of fact and then wished you well in your endeavors. Btw, I've been working with c# since nearly its inception. Feel free to shoot me any questions you might have about the language or or the .Net environment.
Haven‚Äôt seen the concept of a datafile. I‚Äôll google around a little. The plan with the config file was as following: 1) load the config file with a try and catch. If it fails it creates a new one 2) load the database from the path that is in the config with a try and catch. If it fails you get an open file dialog asking for the location of the database and update the location in the config file
If you‚Äôre familiar with Autofac, look in to CQRS within your MVC projects. This way your controllers can just import an IDispatcher interface for example and dispatch events. https://weblogs.asp.net/shijuvarghese/cqrs-commands-command-handlers-and-command-dispatcher
I'll never write a class with a name like "ListClass".
Sorry to say, I've not read or heard of any great books on the subject. That said, I've been on Greg Young's course, and built a couple of systems using the concepts, so I can hopefully give some decent advice. Firstly, I'd recommend looking through [Greg's 'simplest possible thing's codebase on github. ](https://github.com/gregoryyoung/m-r) It's a great codebase because it avoids death by abstraction, and also demonstrates clearly how a domain is saved and loaded from a series of events. My second tip would be to plug the above codebase in to Greg's eventstore. At this point you're probably thinking in some kind of groupie of Greg's - which is only about 5% true - he's a clever guy, and CQRS is some clever shit, but there's a good reason: if you make sure you plug the readmodel concept info eventstore's projections, you'll have a crystal clear understanding of how to separate your reads from your writes, and the power and simplicity separating the two provides. Hope the above helps. 
An event is essentially a message that is sent to any component that cares about that message, whereas a message bus is more targeted (and requires a good deal more infrastructure). Can you explain why you think it is so bad?
Example?
Bro you're being a dick so he has withdrawn from the thread. Get over it and move on.
Why not use something like sqlite? You could store an empty database file in your resources and dump that out to file if a database doesn't exist.
So, how am I supposed to use it? Copy `build.cmd` and/or `build.sh` to my project?
Yes, the information they've given you is dodgy, but you can sort of see what they're getting at. You can see in the code that they've started with a CreateCopy method that returns Object, this is similar to Clone. It's still not entirely clear why they want this method to be generic specifically. I say that because, if Potion and Monster are derived from Item, it makes more sense to me to make IRepeatable just have an "Item CreateCopy();" method. This comes down to why we have inheritance and interfaces. You can override existing behaviour: BallBase is the base class of all balls, TennisBall : BallBase is still a ball, and does ball things, but you might override its size, weight, bounciness, etc. Second you can extend behaviour: MammalBase is the base of all mammals, but Bat would require a Fly() method because, well, bats can fly. The second example highlights a potential problem. If you've written code that does stuff with Mammals, it's not going to know that bats can fly. You would have to have special cases to check whether it's a bat and then make it fly as necessary. That's bad design really. People have literally written whole books about this, so I'm not going to do it justice in a single post, but that's the basics anyway. So, we can make IRepeatable generic by adding &lt;T&gt; to it. We can add a generic method by adding &lt;T&gt; to its name. In this case, from your latest pastebin, it seems they are going with IRepeatable&lt;T&gt;. This is a bit of a weird design as you don't get anything from it really. Code that operates on the return value of both CreateCopy methods has to work on common bases, i.e. Item or Object. If it's going to be called in places that know about the specifics of being a Monster or a Potion, then it doesn't need to be generic either... Anyway, you end up with this sort of thing: public interface IRepeatable&lt;T&gt; { T CreateCopy(); } public class Monster : Item, IRepeatable&lt;Monster&gt; { public Monster CreateCopy() { return new Monster(); } } public class Potion : Item, IRepeatable&lt;Potion&gt; { public string Name { get; set; } public Potion CreateCopy() { return new Potion {Name = Name}; } } public abstract class Item { } public class DoStuff { public void Ble() { var p = new Potion(); var m = new Monster(); Item i = p.CreateCopy(); } } The DoStuff class at the end was purely to show that potion.CreateCopy, while returning a Potion can be assigned to Item i. I left all the Monster code out, except for the CreateCopy method and just return a new Monster. You get the idea though. I don't get the feeling they're giving you enough information to make good decisions here, but stick with it, perhaps they're just introducing you to the basic language concepts and will flesh out the whys and hows and don'ts later. 
Well assuming you need to access Cart in more than 1 action, that logic would need to be replicated each place. Removing the concern from the action itself makes it cleaner and more easily unit testable. You could of course put it somewhere else than in a model binder.
Another ad hominem poster appears! Notice how the conversation stopped days ago? Right, so why are you starting it back up? He could stop responding as he wished, and did so. He spent his last two posts using underhanded insults and sarcasm. Did you not notice? So if I dare to respond to that, I'm the dick? I believe you did, but you turn a blind eye towards one side in bias, because you don't like the arguments I presented earlier.
https://github.com/CenterDevice/MiniFSWatcher
I think regex would probably work. Try this: https://stackoverflow.com/questions/25287177/match-pattern-anywhere-in-string 
Thank you for the reply. I wrote some code based on the assignment, but not necessarily following the assignment requirements. Mostly as a way to learn, try some new things, and hopefully get better. How does this code look: https://pastebin.com/ut2PasFQ -- I know it's not much code, but...?
https://github.com/yck1509/ConfuserEx is probably the best free option right now.
You created an interface but you're not really using it anywhere. In your code that would use and manipulate an Item, it should be written to do that against anything that implements your interface. That way, someday you'll create a new implementation of your interface and that code will happily keep on plugging with it.
For completeness sake, and since I haven't seen it mentioned here before: There is a generic constraint `where T: new()` to require a parameterless contructor. This allows you to call `var foo = new T();`
Where are you seeing performance problems? When querying read stores? The volume of events being distributed? Are you doing distributed transactions updating across more than one source database in a transaction?
Ahh, a stream key grabber
Exactly. In your Inventory class, line 52 should be an array of IItemInterface. Lines like line 64 should accept IItemInterface as an argument rather than Item. In short, the interface is a contract. It's saying that any object that implements me is welcome in the code that consumes me. So tomorrow you can whip up a TaxableItem that implements IItemInterface and it will work great in that consuming class.
It will make sense if you keep experimenting with them. It just saves you from writing the same code multiple times for different types. The compiler literally just takes your generic function and creates N versions for each type you use it with (sometimes less than N when it knows it can) 
&gt; In short, the interface is a contract. It's saying that any object that implements me is welcome in the code that consumes me. So tomorrow you can whip up a TaxableItem that implements IItemInterface and it will work great in that consuming class This is a really important concept to keep in mind. /u/KarbonDioxide you might see people say "program to interfaces, not implementations" and this is what is meant by it. 
You are correct but interface is also very useful in Dependency injection. It is useful in unit testing and you don't have to create new insurance of your class every time you want to use the methods.
IÔ∏è only use C# for Monobehaviors in Unity but are interfaces in C# the same as Java?
Alright, thank you. I've updated the rest of the code I wrote and uploaded it to the original post. I haven't put in what you mentioned yet. I wanna understand it better before implementing it. Thanks for all the suggestions and help. I'm currently working on learning more about interfaces.
I honestly have no clue. I've only ever written JavaScript, sorry.
I went ahead and uploaded the rest of my code. Please feel free to critique the rest of it. I welcome any and all suggestions, criticisms, and other knowledge or experience that will help me to become a better, more competent programmer. Thanks to everyone who has already posted! I really appreciate the feedback and am looking into everything that was said and starting to implement most of it. I just wanna understand it before doing so.
 private string _itemName; private string _itemDescription; public string itemName { get { return _itemName; } set { _itemName = value; } } public string itemDescription { get { return _itemDescription; } set { _itemDescription = value; } } Honestly, if you aren't doing anything special with the backing fields, you can use the shorthand for this public string ItemName {get;set;} public string ItemDescription {get;set;} For the constructor parameters, use the name of the property/field you are assigning it to so there isn't any misinterpretation as to what you are doing with it, as not everyone looks at the source code and tempName isn't correct as the name isn't temporary if its being used to assign to the item. &gt;amespace Test_Project should be namespace, but it just a spelling mistake that wouldn't compile If item is supposed to be the base class of all items and IItemInterface is also, you might as well make Item an abstract class and get rid of IItemInterface, as well as the generic since it doesn't seem to be used. For the following: private static int _inventorySize = 20; public static int InventorySize { get { return _inventorySize; } } You might as well make this a single constant? &gt; public const int INVENTORY_SIZE = 20; For AddItemToInventory there is no failure condition, so if you can't add the item to the inventory, do nothing? How do they know they can't add to the inventory before calling add to make sure you aren't removing the item from the game after the method is called? In showInventoryContents Console.WriteLine("Slot {0}", (i + 1) + ": " + _inventoryContents[i].itemName); Can be reduced to Console.WriteLine($"Slot {(i+1)}:{_inventoryContents[i].itemName}"); $"" is shorthand for a FormattableString. Same applies to the other console write. The Potion class _healAmount/HealAmount can have the same done to them as the ItemName and ItemDescription. You may want to have AddItemToInventory return the Inventory, this way to can use "Fluent Design" and have newInventory.AddItemToInventory(newPotion); newInventory.AddItemToInventory(newPotion); newInventory.AddItemToInventory(newPotion); newInventory.AddItemToInventory(newPotion); newInventory.AddItemToInventory(newPotion); Become newInventory.AddItemToInventory(newPotion) .AddItemToInventory(newPotion) .AddItemToInventory(newPotion) .AddItemToInventory(newPotion) .AddItemToInventory(newPotion); You also probably don't want the same newPotion to be added to the inventory multiple times, but by using CopyItem on it to make sure it is a different potion, but you will need to make sure each item implements an override to CopyItem, by making the CopyItem in Item virtual. 
Dependency injection is one of the most important concept to understand if you want to work as a .net developer. Good luck to you. 
Wow. Thank you so much for that really detailed response. It's super late here, and I need to head to bed, but one thing stood out to me. I though I was doing a deep copy, but you said it was only a shallow copy. What did you mean by maintain it? Can you show me an example of that?
Thank you so much as well for this insanely detailed response. I'm about to head to bed, but I will read over it throughout the week (I won't have much free-time with school), and fix everything and I can't wait to learn and get better. Thank you again for taking the time to write a response so detailed!
In this case it looks like shallow and deep in the same time. By maintaining it I mean you have to add to the method whenever you add a new property. It's error prone, because someone else can come along in one year and not realize you implemented a clone. A deep clone is usually implemented by using serialization, so you cannot miss new added properties. https://stackoverflow.com/questions/129389/how-do-you-do-a-deep-copy-of-an-object-in-net-c-specifically For shallow vs deep clones, you can read more into these interfaces and methods https://msdn.microsoft.com/en-us/library/system.icloneable(v=vs.110).aspx https://msdn.microsoft.com/en-us/library/system.object.memberwiseclone(v=vs.110).aspx I personally don't like cloning, because it's so error prone. If you really need to deep clone, use a serializer. 
Not C#, but trivial to use via the command line and of great quality: [Pandoc](https://pandoc.org/).
You can also use Task.Run(async () =&gt; await ...).Result instead, since it by default run the lambda on a new thread with no context.
[removed]
&gt; how does the input work with an array which's lenght is not defined before the loop It is defined before the loop. The `Split(' ')` function creates the loop, thereby setting the `Length` property.
Whoa, this makes me extremely happy. I'm in no way a professional developer and I've come up with this exact solution in my application. It works flawlessly and my impostor syndrome just got a little smaller :)
For /u/PM_ME_YOUR_GISTS the link to the ddd-cqrs-es Slack is: http://ddd-cqrs-es.herokuapp.com/ 
I think it's better to comment your Classes, rather than explain each variable/methods used within them. Classnames should be an consise identifier for an object-type, and methods should be single-responsibility with a self-explaining name. I would explain: * The Inventory contains a record of Items the player has, and has an *upgradeable?* amount of slots to store items in. * Every Inventory is a [Composite aggregation](https://www.uml-diagrams.org/composition.html) on a Player. (Or do chests also have inventories?) * It is public because it is accessed directly, rather than via methods on Player. * Can you also explain why items are stored in a Private Item[], or a List&lt;Item&gt;? They can contain Item objects and objects that [Inherit](https://www.uml-diagrams.org/generalization.html) from Item. At least this should explain the presence of a variable for inventorySize, and how it relates to the amount of item-slots. Also I think the comment at AddItemToInventory didnt add anything the name didn't already explain.
That's the course, though I attended it in person. The content will be the same though, I'm sure. No probs for the pointers! Hope you get on with it OK. It's definitely an extra string on your bow to be able to think about solving a problem in a quite different way. 
Sort the Datasource the way u want
What if the datasource is readonly (I'm reading from WMI)
I would have used a Dictionary or a list rather than an array to get rid of some of the loops but that‚Äôs just personal preference 
The data may be readonly, but the sort order wouldn't be. You'd need to tell the container how to do a custom sort so you can set your order how you'd like.
Guys, guys! Stop! You are making no sense to me! I told you I have almost no experience in distributed architecture patterns and their implementations! ;-) But seriously I 've got so many questions for you that I don't know even where to begin... Help me to understand if I get the concept correctly. First, my understanding is that microservices give you high scalability and some architectural advantages like high cohesion, loose coupling and small, encapsulated easy and fast to deploy and independent services built around concepts like DDD bounded contexts and aggregates, that can be developed and deployed independently of one another. I get that some medium to large projects can take advantage of that. But, I've got this feeling that microservices are definitely not for every project. I feel when there are high temporal fluctuations of usability and performance needs, as well as high-reliability needs, and the high disproportion in database reads and writes, the microservices are the option to consider. Otherwise, they are not so great. And the reasons are (as I see this) eventual consistency versus transactional consistency or the performance hit (sometimes very noticeable, and you acknowledged in your answer that it's indeed very problematic) in distributed systems vs monolith application, to name the few. I mean the bottom line is that I've got this feeling I should NOT go to a green-field project and say "I'm gonna do microservices!". I guess microservices became popular when companies like AirBnB, Amazon or Netflix started to implement and write about the good experience and success they had. But I think that they weren't successful because they had implemented microservices but they implemented microservices because they were so successful. The more I read about this topic the more I can see that microservices are no silver bullet by any means. But I want to understand that topic to make informed choices in the future. So to the more concrete questions of mine: 1. Do you think in medium to large applications especially those more data-centric with the steady numbers of users (like the most LOB apps I've been working on), advantages of microservices still outweigh the disadvantages? Or is this situation when we exchange one set of problems for another set of problems with the real zero or very minimal net gain? 2. As for the DDD, CQRS, and EventSourcing. I understand these are very connected with(in) the Microservices but are very distinct and independent of each other concepts. I mean I don't have to do microservices to enjoy advantages of DDD or CQRS pattern. Am I getting this right? 3. The least understood concept for me right now is the EventSourcing. I mean I think I get the high-level concept of exchanging messages between objects (aggregates? services?) and using some kind of central "place" for dispatching those messages. Is it what "event bus" is? Some kind of queue where we store messages and act on them asynchronously? Can I treat everything like some kind of pub/sub pattern with the intermediate abstraction layer that introduces asynchrony and decouples source of a message (publisher?) from a place where we act on it (subscriber?). And how about that vocabulary of "event bus" and "message bus" (whats the difference?), "tasks", and ... "sagas"? I'm confused. And there are probably many more concepts I don't know yet about... I haven't found yet the book or article that would explain it to me in theory as well as with some good examples. Do you know any? I think that's enough for now... Thanks. 
We're all impostors, baal. Some of us are just better at faking it than others ;)
Yeah, I'll definitely check out Greg's workshops. Thanks. &gt; We‚Äôve seen that to have proper event sourced aggregates you need to have very well defined bounded contexts. And getting these wrong in the beginning can lead to headaches later on. I know too little on the subject to know why would that be the case or problem. I don't even know what do you mean saying "proper event sourced aggregates". What are the features of those? And why is this so important? Is it because without well and proper defined bounded contexts your messages would "leak" between contexts? Is that the case? How do I spot it? &gt; Some recommended reading: DDD by Vaughn Vernon (the big red book) Do you mean "Implementing Domain-Driven Design"? Yeah, I've got both this and Eric Evan's books on my bookshelf but haven't read them yet. Just riffled through the pages. I've heard "the blue book" is somewhat hard to digest, so I wonder if I should start with the "red book". Which one would you recommend I go first? Thanks.
A foreach will work on an array too, so there is zero need to switch to a List _solely for that reason_. However there are plenty of other good reasons to use List instead. 
Your absolutely on the money with regards to your gut feel on microservices. They come with advantages but also a bunch of trade offs and complexity which you allude to. Unfortunately, they're the fad there days and only the advantages ever get looked into. I wrote more here [microservices siren song](https://blog.rraghur.in/2017/06/16/the-microservices-siren-song/) Now to your other questions: &gt;Do you think in medium to large applications especially those more data-centric with the steady numbers of users (like the most LOB apps I've been working on), advantages of microservices still outweigh the disadvantages? Or is this situation when we exchange one set of problems for another set of problems with the real zero or very minimal net gain Microservices isn't the destination..A well designed system is. In fact you focus on applying DDD and have well thought out BCs, is trivial to split the system to real services later on along those boundaries. &gt;Do you think in medium to large applications especially those more data-centric with the steady numbers of users (like the most LOB apps I've been working on), advantages of ms ujoy advantages of DDD or CQRS pattern. Am I getting this right? Absolutely. You can apply DDD, Cqrs and Es independent of whether there are actually multiple services or a single monolith. Also you can apply cqrs/es fully synchronously if you feel so and later make them async. Se did something like that with lokad. 3. Events are facts that something 'happened' to an aggregate (user created, password reset, item added, item removed, etc) They are generated by your aggregates in response to commands. ES is about storing events and replaying them to reach the final state of the aggregate. Having a log of all past events is incredibly powerful. You can query the event log arbitrarily.. Say 'give me all users who have reset their passwords atleast twice' You can also easily delete your entire read store and rebuild it later if you want a new structure on the read side. It becomes really easy to introduce new features while taking care of historical data.. you just need to hook up the handler and replay events for ex: let's say you introduce billing later and every time a user IS created a billing profile must be created. You can just hook in to the user created event and replay all past events and voila you're good. Or you want to introduce full text search... Hook up a handler that subscribes to events it needs and writes to elastic search and replay all events. ES does have additional complexity though.. So keep that in mind. Events vs messages: messaging is an implementation detail. Messages can be arbitrary and need not be a state change.. User logged in may not be a state change and you may not want that in your event store but still a perfectly valid message to notify a logging system maybe. Just making things up here. BTW your bounded context represents a transactional boundary... If other domains need to respond to events in one domain, they need to subscribe to them to respond and here enters eventual consistency. Usual book recommendations.. Eric Evans and Vaughn Vernon implementing DDD book... But try to build a side project.. helps with learning more. 
I have updated README with more information: https://github.com/wieslawsoltes/Cake.CoreCLR.Runner/blob/master/README.md
This stackoverflow should help, you'll need to recast each of your items to a icomparable object for it to work. Linq will do that for you. https://stackoverflow.com/questions/33647064/sorting-a-listbox-relative-to-another private class ListBoxItem&lt;T&gt; : IComparable&lt;ListBoxItem&lt;T&gt;&gt; where T : IComparable&lt;T&gt; { private T item; internal ListBoxItem(T item) { this.item = item; } // this makes possible to cast a string to a ListBoxItem&lt;string&gt;, for example public static implicit operator ListBoxItem&lt;T&gt;(T item) { return new ListBoxItem&lt;T&gt;(item); } public override string ToString() { return item.ToString(); } public int CompareTo(ListBoxItem&lt;T&gt; other) { return item.CompareTo(other.item); // here you can catch the comparison } } public Form1() { InitializeComponent(); var items = new List&lt;ListBoxItem&lt;string&gt;&gt; { "Banana", "Apple"}; items.Sort(); listBox1.DataSource = items; } 
What JS interop would you need exactly? C# already has a good standard library, and 1000s of NuGet packages on top of that. What JS libraries are going to be required if everything can be done in C#?
You forgot to check naming conventions.
Honestly, Eric Evans' blue book is a little difficult to read, but I'd recommend starting that before Vaughn's Implementing DDD as the latter book references topics in the former. The downside is that the blue book was written before domain events really became a 'thing', so it's not directly related to event sourcing as such. It does cover all the pre-requisites that you really should know if you want to start modelling your domain with events though. I'd say if you're pretty hot on aggregates, bounded contexts, context mapping and the like, then jump straight into IDDD as that does have a more modern take on things.
Its on the build steps panel, in the project properties dialog in VS. Im not sure that answers your question, however, Im not sure what you asked for.
This is actually the ideal solution if you need near-realtime probably. Granted, I stopped using the FileSystemWatcher class in the jump between Windows 7 &amp; 8 due to the fact that all of my existing code was 100% broken in Windows 8. I believe they have fixed the issue I was running into in a later .NET release, but I just never went back.
Please use xmldoc
Look up **Test-Driven Development** as well. With TDD, you'll quickly see just some of the most important aspects of **Dependency Injection**. For a quick DI example, suppose you have this logging class: public class Logger { private TextFormatter Formatter { get; set; } public Logger() { Formatter = new TextFormatter(); } } When unit testing, the `Logger` class has a *dependency* on the `TextFormatter`, so when we test, we are actually having to test both the `Logger` class and the `TextFormatter` class which isn't a unit test at that point -- it is more of an integration test. Furthermore, we have to read the code in order to discover this dependency. Although the above example contains very few lines of code, discovering dependencies in this manner can quickly become difficult in larger classes. Finally, the `Logger` class can't change its formatter without having to change the `Logger` class' implementation -- this means it isn't very *extendable*. We can solve this by *injecting* an `ILogFormatter` object via the constructor: public class Logger { private ILogFormatter Formatter { get; set; } public Logger (ILogFormatter formatter) { Formatter = formatter; } } Now, our dependencies are clearly listed in the constructor, I can pass in any formatter I want so long as it implements `ILogFormatter`, and during unit testing, I can *mock* the formatter (i.e create a "dummy" formatter) so that I am truly only testing the `Logger` class. I can use the class like this now: var logger1 = new Logger(new TextFormatter()); var logger2 = new Logger(new XmlFormatter()); var logger3 = new Logger(new JsonFormatter()); //etc. And there we go -- DI in a nutshell. &amp;nbsp; You should google **S.O.L.I.D** programming principles. These principles are incredibly important in OOP languages. The **D** stands for "Dependency Injection", btw.
 var nums = new List&lt;int&gt;() {1, 2, 3}; nums.Insert(0,3); // nums contains 3, 1, 2, 3 If you wanted to remove the three at the end, you could simply just remove it first by calling nums.Remove(3); first before you insert. If you have duplicates in your list, then you might want to be a little smarter about how you remove them (Remove only removes the first instance of the item it finds that matches). 
Dictionary&lt;string,Dictionary&lt;string,string&gt;&gt;
&gt; `Dictionary&lt;string,Dictionary&lt;string,object&gt;&gt;` Let's not jump ahead of the spec here :P
You can compile Python to an exe. http://www.py2exe.org/index.cgi/Tutorial
If I understand you correctly, you want to implement an indexer. Look here: https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/indexers/index
But its still here ;) :P
The first Dictionary would return a type of Dictionary&lt;string, string&gt;. What I'd like, is for it to return a different object type. So I suppose what I'm looking for is how to implement the ["Key"] part of an object. So if I have: Foo&lt;string, BarObject&gt; How do I implement BarObject yar = Foo["key"]; 
Thanks but py2exe is easily reverse engineered unfortunately.
Visual Studio crashes occasionally when I switch git branch on a particularly large project I work on. That and it takes an age to open it. Both reasons my primary is now Rider. I still use Visual Studio for some stuff.
then do Dictionary&lt;string,Dictionary&lt;string, BarObject&gt;
Ok, thanks for confirming I'm not missing something more obvious!
That will cover "After Build", but I don't recall any way to indicate that you want something to run "Before Clean". There is one "Before Build", but that may not work for him. VS is surprisingly inflexible when it comes to calling MSBuild targets. 
 You can AOT-compile .net and mono code and it will be a normal executable, not JIT-compiled. Can't do that with .net Core. That said... The more it is important to keep the code secret, the more impossible it is to do that. üòÅ No, seriously... Native (C or C++) code can be turned into C sources easily, [there's tools to do that]( https://www.hex-rays.com/products/decompiler/). Sure, no decompiler gives you your exact code back, but they all give **a very clear** view of what the code does, in [insert language here] source. What are you trying to achieve by "hiding" your code, BTW?
Think like a "section" and "key" type of thing for INI files. (Not actually using INI files, but that's as close as it gets). So: var foo = File["section"]["key"]; Would give the value. "Sections" and "Keys" will have custom attributes, too, so using a generic dictionary won't work.
Indexer! That's what I was missing! Thanks! 
JObject from JSON.Net?
What about something like this; you'll need to add in the means to populate the structure and work out how you want to handle non-existent keys. class Program { static void Main(string[] args) { Document document = new Document(); string text = document["Foo"]["Bar"].Text; } } class Document { private Dictionary&lt;string, Section&gt; sections = new Dictionary&lt;string, Section&gt;(); /// &lt;summary&gt; /// Indexer to get section by key /// &lt;/summary&gt; public Section this[string key] =&gt; sections[key]; } class Section { private Dictionary&lt;string, Value&gt; values = new Dictionary&lt;string, Value&gt;(); public SomeType SomeOtherAttribute { get; } /// &lt;summary&gt; /// Indexer to get value by key /// &lt;/summary&gt; public Value this[string key] =&gt; values[key]; } class Value { public AnotherType SomeAttribute { get; } public string Text { get; } }
It also works with the community edition in Visual Studio 2017. Source: I'm using it.
IMHO it is not an issue at all, most functional languages uses type inference everywhere, Haskell, F#, etc. and zero issues. Most people that said that a code is more readable using explicit types are people that are used to languages without good type inference. The IDE/editor has enough tools for inspecting types. 
Release a 'cracked' version of the application on pirate sites with key changes to make your software a [pain in the ass to use](http://www.greenheartgames.com/2013/04/29/what-happens-when-pirates-play-a-game-development-simulator-and-then-go-bankrupt-because-of-piracy/)
&gt; This is impossible Concise summary. With the advent of fuzzing humans don't even need to reverse engineer your application to figure out how it works.
&gt; I've hit a brick wall when trying to do the same on Windows using its Visual Studio. What is the exact problem? MSBuild format is cross platform. If you can add a target before other target, you can do it on windows too. https://msdn.microsoft.com/en-US/library/ms366724.aspx
Link is 404
That's strange. I can open it
I can open it, too
Will for sure check this out shortly in the future.
Thank you, Nick. I hope you will find it useful. Any comment or idea is always appreciated. All the best.
I had the update just before I posted it. 
No it's not, as it is now an assembly. This plus obfuscation will make it even more difficult as everyone has already stated. 
Also getting 404 here
I'll be sure to leave feedback once I get into it.
The update wasn't showing up for me in the notifications tab inside visual studio. I had to run the Visual Studio Installer in order for it to begin downloading/installing.
C# and Java are some of the easier languages to decompile, so you're much better off writing it in native languages like C/C++/Rust if you really want to hide your source code. Dnspy make it exceedingly easy to reverse engineer applications and there are some developers like me who can comfortably write and read IL code which is the language that C# get compiled to.
What about this? https://github.com/4w4k3/rePy2exe
Would be amazing if this reaches the level of Qt
It allowes visual studio and other to display your explanations for the methods/vars/props when you type them
wat
Msbuild is cross platform, but any shell commands you put into actions might not be. 
You can follow along here: http://www.blackwasp.co.uk/csharpsimpleclass.aspx
Banned: Rule 5.
This is awesome, so many new features. I particularly like the idea of being able to debug into external code using ILSpy. 
I am watching the Blazor project with great interest, as I like C# a lot, but in the meantime, the closest you can get to C# on the web is Google's Dart language, which was heavily influenced by C#. So that's what I'm using for web apps until Blazor becomes a reality.
Thanks a lot! I've only gotten a very brief introduction to methods and classes so I only used static methods up until now and I didn't know I could reference something with the "this" expression. I thought I had to do something with bool or if-statements so it was hard to figure out with just the knowledge I had. :P This was exactly what I needed, and now I know where to go from here. Thanks for taking the time to help me!
Thanks, I would've missed that feature otherwise. That is legitimately cool.
As somebody who tries to stay on the Desktop/Client side of things, this is pretty helpful. I often would *like* to spin up this stack but just didn't know how. Thanks for the guide! 
&gt;This is awesome, so many new features. Would be even more awesome if they actually worked. My vs2017 experience has been constant crashes, broken features and slow performance. I'm happy I'm using community edition and my boss buys professional for work, there is no way I would pay for vs2017.
What you're looking for is to execute an External Command which calls upon a shell to execute a script of your choice. I have written up a small guide for you using *powershell* because I'm on Windows, but you can replace it with whatever scripting language you want and whatever shell you want.
.
I‚Äôm getting it as well. Must be a CDN problem. 
Not for me.
&gt; Why does the Solution explorer or whatever it‚Äôs called not show things that are on the file system? Huh? It totally does? I was too lazy to look for a modern image; but Solution explorer has had this forever. https://i.stack.imgur.com/NmkhK.png
Did not know about that button, cool. Still, I hate that it‚Äôs necessary. .sln files are an opaque mess of XML and GUIDs. A lot of times a coworker will commit something that will add or remove multiple lines of the .sln file and we will have no idea why. As a programmer I want to know how every piece works because when something breaks I need to be able to figure out why. And with .sln files I have no idea how they work or how to fix them if they get broken. 
Use an ExpandoObject, they are dynamic objects that you can turtle all the way down... 
&gt; Why does the Source Control Viewer show files as changed but when I view the diff they‚Äôre identical? Because TFVC is terrible. It works as expected in Git. In TFS you check out files, and VS shows you whether the file is checked out, not that they have changes
The variable `j` is captured in the lambda you pass to the thread, there is only one `j` that all the threads read *when they are executed*. Thread scheduling is unpredictable, sometimes no thread will execute in the moment the variable is 25/50, and sometimes multiple will. This might make it a bit more clear what's going on: for (int j = 1; j &lt;= 100; j++) { int local = j; // unique per iteration Thread t = new Thread(() =&gt; Console.WriteLine($"Thread {local,3} sees j={j,3}")); t.Start(); }
You are very welcome. Thank you for the reading and commenting also. I appreciate it a lot. I hope you will find a helpful stuff in this series.
First of all, thank you very much for reading and leaving a comment. If you have any new idea or any question, please do not hesitate to write a comment. One more time, thank you a lot.
Thanks for your reply. Would you be able to provide some more detail on how I would go about putting my logic server side? My software requires internet for its core functionality anyway.
Update is showingn 992 Mb download for me :?.. that's huge -but now I'm worried if it doesn't crap out. I had to run the installer as well for it to pick up the update
It was 3.54 GB for me :o
I think you misunderstand the audience of Visual Studio versus that of Visual Studio Code. 
In VS 2017, there is a button to switch to Folder View. 
Sln files are mostly just a list of project paths and project guids. Doesnt contain much. "*.*proj" files are usually the messy ones, with their randomly grouped propertygroups and unordened msbuild tasks and various build variables. But there is order to the insanity, if you read it carefully. Lot of the duplicate xml is because of build configurations. There is also some checks in there for if you have various build tools (for example it checks if you have nuget.exe or if you have typescript compiler and handles it if you dont). And if you want to "include everything in a folder" in your project, you can replace all the content include tags with one content include="*.*" tag. Would have been nice with a "clean and sort" tool for the project files.
[2.34GB here.](https://i.imgur.com/MmT4CmR.png)
The find in files feature could sorely need an update. It is my most used tool, but i still hate using it. Mostly want search configuration sets so that i can, with a quick keyboard combo, switch between searching in "my solution, cs and vb files" and "current project, ts and js files" and various other commonly used search configurations. And to be able to group, sort and filter the result, and change how much of the surrounding code is in the result preview would be nice. And to ignore certain folders or files from search even if they are in the solution file. The new ctrl+g tool helps a bit, being able to go directly to a symbol or method or type if i remember the name.
Great, Visual studio is getting better and better with each release. Same other C# and Net Core. 
How many of your issues have you reported using the built-in feedback tool? They're pretty responsive with crashes... I've reported things broken in preview releases that get fixed before the next release.
&gt;Still, I hate that it‚Äôs necessary This way I see the files my CI will see. Build will ignore files it doesn't know about, so seeing them there is just dangerous. Just install the extension that warns you when you have files not included in the project.
Yep, we replaced dirty jquery, RxJs and lodash with this lib in the project. Currently using TS + React + LinqCollections Getting this to my team was one of the motivations for doing the lib
&gt;For instance why do Find All results show up as plain text? Because you're asking it to do a dumb text search. That's what Find All means. You want find all references? &gt;Why does Ctrl+T suck so much compared to Sublime or VSCode‚Äôs Ctrl+P? Because you're not using Ctrl-, &gt;Why can‚Äôt I delete / rename Typescript files while my web app is running? Yeah, this one is a bit odd. If you "Run" instead of "Debug" you should be able to. &gt;Why does the Source Control Viewer show files as changed but when I view the diff they‚Äôre identical? If you're using Git, it literally just calls Git, so that's nothing to do with VS. If you're using TFVC, don't, again, nothing to do with VS. &gt;Why do I have to select a template when I create a new file? I just want a blank file with the file extension of my choice. You don't have to?
&gt; Now I see a lot of people talking about DI in the context of controlling lifetime of objects Doesn't `using` serve the same purpose?
It can be used, it just depends if the object in question has an IDisposable implementaiton
Say you have five different services that you want to use throughout this request. They each take 200ms to start up, so you only want to start them once, and then use them everywhere. However, they depend on the current request so you can't create them on startup. Are you suggesting: using (var one = new ServiceOne()) using (var two = new ServiceTwo()) using (var three = new ServiceThree()) using (var four = new ServiceFour()) using (var five = new ServiceFive()) { } in every action? 
DI *can* control the lifetime of your objects, yes. With the using statement, you control it yourself. Maybe you have a more specific example to ask questions about? ASP.NET Core comes with Dependency Injection, so you can choose to use theirs, or use a third-party library. 
I can't ask anything specific. I just need to understand that whole DI thing and how to use it, because between reading Adam Freeman and talking to actual developers turns out I've been writing my code wrong all this time. The link you gave is about Core and for some reason it mentions the workd 'Serivce' quite a lot. What is a service?
I edited my comment, please take a look. Ok, so why do you need to understand the whole DI thing? It sounds to me like you should take the basic ASP.NET core tutorial or something, and learn what a WebApi (for example) consist of. 
We use DI at work for swapping out different encryption implementations. Lets say you have a service that needs to be encrypted, but you want that service to have different ways of encrypting. First you define an interface which describes what the encryption service does: IEncryptionService string Encrypt() string Decrypt() This is a broad description of the encryption service does. We have written our implementation yet. In an implementation we could have dozens of different ways of encrypting, AES, 3DES, SSL etc etc. But they all have one thing in common, they Encrypt() and Decrypt(). So during the development process we are creating an application that is going to use encryption, but we don't know what type. So in order to satisfy the application requirements we just give it our interface. It tells the application that, no matter what happens you'll always get these methods. It's a promise that any object passed as IEncrytionService will HAVE (ie implement) the items described by the interface. So another team can happily code away without having to worry about encryption because IEncryptionService promises it will be taken care of. So the time comes to run the application, we need an encryption service. The Encryption dev team have completed their code so the app dev team simply INJECT it into their application. Because their code is expecting IEncryptionService and the encryption team are providing an implementation it is accepted by the app. It doesn't matter how the encryption works as long as it's following the rules set out by the interface. And that's the beauty, we are disconnecting two concerns. One is the application and the other is encryption. We are injecting the encryption service into the app rather than building it into it. We can happily swap between different types of encryption by just providing the code responsible for it. This can be done in different ways, using a dependency injector like Unity or CastleWindsor or simply using reflection to scan assemblies and creating instances of them. DI is just a way of separating and decoupling concerns. Each concern is it's own single unit, which is where Unit Testing comes in. Each is testable. All that is needed is an Interface that describes each units rules. Hope this makes sense.
I like a quote I find on wikipedia: &gt;When you go and get things out of the refrigerator for yourself, you can cause problems. You might leave the door open, you might get something Mommy or Daddy doesn't want you to have. You might even be looking for something we don't even have or which has expired. &gt;What you should be doing is stating a need, "I need something to drink with lunch," and then we will make sure you have something when you sit down to eat. E.g. you shouldn't be "newing" up services (middleware, all your business logic), you should be asking for them.
Noobs, only 70 mb for me https://imgur.com/RE7cj6W
I am working on a ASP.NET MVC app that interacts with Telegram webhooks and API and I though my knowledge is not enough, so I went for something more 'formal' and downloaded a book, which turned out to be very confusing, because, while it shows the same basic examples as contoso university website in MSDN guides, the actual implementation is weird and hard to understand. Then I went to some C# related chats, and people are talking about services and repositories (damned if I know what kind of magic turns simply DbContext into IRepository). I merely wanted to git gud and not invent a rectangular wheel, but I just can't wrap my head around this madness. Like, in ASP.NET MVC I always have my DbContexts as controller's field and easily refer to it. Others are 'injecting' it by adding DbContext to controller's constructor parameter and using one of the multitude gimmick libraries to actually create in instance of DbContext whenver the instance of that controller is needed. Who's right here? Which approach is better?
This part I understand well, I used interfaces long before I heard the term 'dependency injection'. What I don't understand is all those services - whatever those are - and when I should use DI vs having some config class I can always refer to, or maybe a collection of different interface implementations I choose from based on argument, etc.
A service is just an abstraction of some logic. You should use DI to separate our your 'concerns'. So, if you use Entity Framework for example, that is a service that you can inject into your application, or like in my example Encryption. Units of logic (work) that can be asked for, rather than constructed on demand. It's all down to separation of concerns.
Theres no magic that is turning a DbContext into a repository. They probably have a repository class. Normally, you would have a layer between the DbContext and your Controller class, which you could call a repository. So you have an extra folder, beside your Controllers-folder, and your Models-folder, which you call 'Repositories' or something. [See this example](https://github.com/abel-masila/Asp.net-Core-Backend-Service-Demo/tree/master/BackendCore) So, all the magic DI does is create an instance of the repository class in your controller. It doesn't sound like your application is using any DI. Do you want to implement it?
I'm going to use an analogy You go into McDonalds and you want to order a burger. There are dozens of different types of burger in McDonalds. So you pick one, a BigMac. This is an implementation of IBurger. I know you already get this but let me continue... In order to get your BigMac you must talk to the guy behind the till. He is the service. So you say * Hey can I have a BigMac please The service says, sure. You provide him with cash (a parameter) and he gives you a BigMac. Behind the scenes though are multiple areas of concern. The service is just the tip of the ice berg. But you, as a consumer of IBurger do not care what happens, so long as you get what you ask for. Behind the till guy, is a bunch of other services. There are friers, people who deal with drinks, people who deal with burgers, others who deal with the refrigeration. They are all services in their own right. Some of them could be replaced with more qualified staff. They are injectable into the McDonalds staff. They all do their own thing but they come together as a whole. The whole being McDonalds Kitchen service. But your (an application) don't give a second thought to the poor saps behind the counter, so long as you get your IBurger implementation. They can be swapped out. The entire kitchen could be replaced. All DI is about, is keep the services inject-able and testable. So these services are constructed at the application start (or on demand if you so wish) and they provide you with what you need. This gets away from constantly 'constructing' new objects and provides an abstract way of getting those objects in a controlled manner. Afterall you can't just wander into the kitchen and make your self a burger, it's done by those services.
Looks like all this time I only cared about separation of concerns, while paying little attention to properly coupling my services, because HelloWorld.sln doesn't need much testing and I am too lazy for them anyways. Thanks.
Your controllers should not contain "business" logic. Controllers aren't responsible for how things happen, they just receive web requests and pass them on to the correct service. The service will respond in some way, then the controller packages up that response and displays it to the user. "Services" are the names for the well defined tasks that your **application** can do. E.g. I have a "ReportService" and an "ReviewService". My actions then look something like: [HttpPost] public ActionResult UpdateSession(int reviewID, ReviewSessionEditModel reviewSession) { _reviewService.UpdateSession(reviewID, reviewSession); return RedirectToAction(nameof(Review), new { reviewID }); } But where does my reviewService come from? Well, before DI it looked like this: public class ReviewsController { private ReviewService _reviewService; private ReportService _reportService; protected override void Initialize(RequestContext requestContext) { base.Initialize(requestContext); DataAccessKey accessKey= (DataAccessKey )HttpContext.Application["accessKey"]; _reviewService = new ReviewService(GetCurrentUser(), accessKey); _reportService = new ReportService(GetCurrentUser(), accessKey); } } Which is messy, because I'm having to manually fetch all the things my services need in **every controller**. After DI it looks like: public class ReviewsController { private ReviewService _reviewService; private ReportService _reportService; public ReviewsController(ReviewService reviewService, ReportService reportService ) { _reviewService = reviewService; _reportService = reportService ; } } Which is much simpler, however, it looks like magic. The missing part is I have (in one place). container.Register&lt;DataAccessKey &gt;(() =&gt; container.GetInstance&lt;HttpContextBase&gt;().Application["DataAccessKey "] as DataAccessKey , Lifestyle.Singleton); container.Register&lt;ReviewService&gt;(Lifestyle.Scoped); container.Register&lt;ReportService&gt;(Lifestyle.Scoped); So i defined it once, and everywhere gets the same.
DI is all about decoupling. Ensuring each service is a single entity that can operate on it's own. A bunch of services coming together to create a whole is how the entire application is constructed. In my example, each staff member is independent. Each is testable. But they come together as a team.
There's a lot of reasons for that. For example when I build a news website, I wanted a method that gave me the most popular articles the last 30 days. So I made a method in my ArticlesRepository called GetMostPopular(). I can now reuse the code I have written for retreiving the most popular articles multiple places. For example, I also wanted to show the most popular on my front page, so I am able to use the method from my HomeController too. I hope that makes sense. I think you should read up on some best practices, follow some get started tutorials, and lookup some similar projects on Github. [ASP.NET - Writing Clean Code in ASP.NET Core with Dependency Injection](https://msdn.microsoft.com/en-us/magazine/mt703433.aspx). They talk about why its good practice to use the repository pattern. [ASP.NET MVC with Unity (Dependency Injection)](https://www.codeproject.com/Articles/786332/ASP-NET-MVC-with-Unity-Dependency-Injection). Tutorial.
This makes sense, but I don't know what that `containter` is and what if, say, it was a WPF application, would it still be applicable? The idea of having 'nothing' at the beginning except for, maybe, some factory and instances of all necessary class instances created at runtime 'on demand' is a bit alien to me.
This looks really good for someone like me, first job in C# and wanting to look into a web development framework like Angular. Is there a reason why'd you need VS &amp; VS Code? Why use Angular over, say, MVC? Please update the series! I will be waiting for them.
Container is just an object the library I use (SimpleInjector) has which lets me "register" constructors. &gt; it was a WPF application, would it still be applicable? Yes, although it would be simpler. It's just an alternative to having static "singleton" classes you fetch. It wouldn't be on-demand really, more like "lazy", where they're made the first time something needs them then reused for the rest of the application. &gt;instances of all necessary class instances created at runtime 'on demand' is a bit alien to me Well, in my case, it has to be after the request happened. How can I safely create a database connection when I don't know who the user is? Instead of having every method on my database class ask for the current user I just make it so that you have to know the user *before you can even create* the database class.
Seeing how many different DI libraries are there, it seems like there is a way to detect when the instance of some class is being created so everything necessary for contructor is created too. How does it work?
Hi Horoblast. Thank you so much for your interest in this series and for leaving this comment. I am going to try to answer all of your questions: 1) I don't need to use VS &amp; VS Code, I like to use it that way. This allows me to separate the concerns between server and client side. Pls don't get me wrong, I am not saying this is the best or only way, I am just saying this is the cleanest way to write and separate client side from the server side. 2)Angular is the fantastic framework for writing the SPA's (single page applications), I wanted to learn it so much, thus the post with it. 3)As the title says it would be deployed on the IIS(Windows environment) and on the Linux environment. So there is no chance to run IIS on Linux because IIS is strictly Windows feature. 4)This complete series is written in the .NET Core 2.0. Thank you for your suggestion, I have fixed it on the site. 5)Every new post is going live on Monday every week until I have a resource to write about :D :D I hope my answer was helpful to you. All the best.
For ASP.NET MVC the DI libraries often have a helper which hooks into the ASP.NET MVC pipeline. Basically when a controller is made there is a point at which you can manually step it and construct it yourself. They just do that, step in, look for a constructor, find the classes you've registered, and then use them to create the controller. If you can't integrate into the pipeline (e.g. a console app) you have to manually call the container and ask `Container.Get&lt;ReviewService&gt;()` or something.
I am very interested in this as well. I run a lot of virtualization and emulation and I am also very interested in Threadripper. 
If you wanted to go that route, then here's the basic setup: * ASP.NET Web API, with actions that you invoke through a web request, and mark anything that requires a logged-in user with AuthorizeAttribute. * ASP.NET Identity Framework, so that you can login, register, password reset, authenticate (using AuthorizeAttribute), e.t.c. with the API * Identity will use a database in some form. By default it's a local database within the web project, but I prefer to point it to a remote SQL Server instance * A client-side project to call the API. You would send the username and password, receive a bearer token, and send that token on each request to authenticate with Identity Framework, and if authenticated the API will execute your secret code and send a result in JSON/XML format. Your client-side project can be in any language. You can make the server side in Python, and I do have experience with Python myself, but Python is not at all cohesive in this area. In .NET Microsoft makes ASP.NET MVC and ASP.NET Web API, which are really great and cover all the bases. You would have to look for a third-party Python stack to cover this, and an authentication framework.
:D
Oh yes. That was so annoying. Had to close the file and open it again al the time.
Never had an AMD CPU, but in the light of Spectre/Meltdown issues, I'd rather go something that's less vulnerabilities to begin with.
Remember that any time something is captured by a lambda, it is captured by reference.
AMD is also vulnerable to Spectre.
You don't need the "this." within the method body, unless there is a name clash - instance variables are already injected into the context of the method body.
Yes, but not all variants, and not to Meltdown. I'd rather not wait for Intel to climb down from their high horse to deal with the issues.
Intel has dealt with Meltdown, as have Microsoft. The real issue with Meltdown is that you also need a motherboard BIOS and many people with not-so-new boards won't get them. Now Intel and AMD need to deal with Spectre.
The (kernel) mitigations for Meltdown and Spectre (KPTI, fence insertion, and retpoline) do not require any firmware updates.
&gt;Have a browse of Mark's excellent blog too. If you DO use a container (you don't have to, you can manually compose the composition root yourself) you should also NOT use the service locator anti-pattern: http://blog.ploeh.dk/2010/08/30/Dontcallthecontainer;itllcallyou/ That's a weird blog post. It talks about "there is never any reason to query the container" but then finishes by querying the container? You have to query a container at least once, otherwise your application would never use the container...
You're missing the bigger picture. Yes, the one place (http://blog.ploeh.dk/2014/06/10/pure-di/) you should do it is the composition root (http://blog.ploeh.dk/2011/07/28/CompositionRoot/) but you might not need to if you're using a framework like ASP.NET where it can hook in automatically. http://blog.ploeh.dk/2012/11/06/WhentouseaDIContainer/
See also Dependency Injection with Mark Seemann https://www.infoq.com/articles/DI-Mark-Seemann
Beyond that, services shouldn't be disposable if at all possible. A lot of lifetime and multi-threading problems disappear if you make your services stateless and have then create/dispose connections as needed within a method.
Ah, you replied to the wrong post. :) But since I'm here: What he meant by "run instead of debug" is "Run without debugging" in the Debug menu (if i remember correctly). It compiles once and starts the IIS Express server, but doesn't stay in debugging after build is done.
&gt; ASP.NET - Writing Clean Code in ASP.NET Core with Dependency Injection. They talk about why its good practice to use the repository pattern. That is not an example of clean code. Passing around a single DBContext for the life of a request is just asking for trouble. You can use DI with a repository, but you should be injecting a connection string, not a live connection.
I understand the bigger picture, it's what I do, it's just a weird blog post. I think it fails to make the point it's trying to make and just confuses matters even more. Because in the end, you **do** call the container. Either you or your pipeline.
I mixed up my Meltdown and Spectre there, but there are BIOS updates to fix Spectre, as outlined by Dell: http://www.dell.com/support/contents/us/en/04/article/product-support/self-support-knowledgebase/software-and-downloads/support-for-meltdown-and-spectre Dell has released BIOS updates for Spectre V2, and Spectre V1 and Meltdown V3 should be fixed by OS and "software" patches. There are BIOS patches from other vendors which I assume apply the same fixes.
I find that DI frameworks are more trouble than they're work in WPF. Usually its better to just create all of the long-lived services on startup (composition root) and go from there. In ASP.NET MVC/WebAPI, they are vital because you don't control the creation of controllers. 
Android emulation using HAXM will not work on AMD CPUs on Windows, but may work on Linux
I added some examples.
Why MySQL? 
This still is the definitive resource for grasping the whole picture. I would even recommend this to none dotNet devs! 
&gt;The project publishing experience has been updated. Has anyone seen screenshots of the "publishing experience" changes? I'm still using VS 2015 because I always use preview and don't like saving the password. 
&gt; Because you're asking it to do a dumb text search. That's what Find All means. You want find all references? What I mean is that the Find All results are just a big block of text, unlike Visual Studio Code which groups the results by the file they were found in in a tree view that allows you to expand / collapse files. &gt; Because you're not using Ctrl-, It still sucks. If I slightly misspell something with Ctrl-, it doesn't find what I'm looking for, but Ctrl-P in VSCode does. And the results are a mix of filenames and references in code, so if I want to just type the name of a file and go to it, often I have to press the down arrow to go past tons of results that are just references to the thing I'm looking for. 
Timer's have an `Enabled` property (anything inheriting from `Control` has this property). Using `Timer.Enabled = false;` will prevent the timer event from firing. Is that what you need?
Whoops, thanks. And that fixed it for me. Still it seems odd that this behavior is there in the first place.
Don't abuse regex for your dirty needs, sir.
Yeah me too. I've pre-ordered the second edition and get regular chapters emailed to me while it's being written. I've not had a proper look yet but apparently it has a lot more SOLID and patterns in it too while being used with DI which is great.
neat
OK, good to know. I didn't actually read throught any of these though, I was just trying to show what DI is and how it's being used, and assumed they were of decent quality.
I would guess it's there to prevent you getting out of sync with your debugger in languages that don't support hot-swapping.
It's actually really hard to find good examples of DI frameworks. I suspect the main reason is that people develop start with bad APIs. Especially when it comes to managing disposable resources. But the real kicker is that DI is incredibly boring. If you do design your services correctly, then DI becomes nothing more than a fancy way of calling simple constructors. And that makes it hard to justify the framework they're promoting. 
It's good to note than Windows 10 Pro or greater operate as a hyper-v instance. 
My experience with uninstalling resharper 10years ago made all my Visual Studio experiences excellent. 
Hello MiesL. I could always answer you: and why not? :D But here it is: It is free of charge. It is very similar to SQL(if this was the main reason for your question), it is fully supported by Linux (and I needed that for this complete series as you may notice in the title), and I have always worked with SQL as my DB part, so I decided to try something new. Trust me it is a great change. Thank you for leaving a comment mate.
Copy it into a System.Data.DataTable, then sort its default view.
Is anyone having issues with Ankh? Gah, I hate having to use SVN.
They've also made working with csproj files much easier and you can add/edit sln with a really easy to use CLI.
Hi MiesL. I couldn't agree more with you about NoSQL db-s. I didn't know that this was the subject of your question. As I said I wanted to try something different than MSSQL and I haven't work a lot with the NoSQL db-s. But thank you for pointing this out, it is a great idea. I really appreciate it. And this is my doubt, I am not sure how much are the NoSql db-s efficient and stable for the big projects and a large amount of data (again this is my question, not the point). Thank you again for the suggestion.
You can "use" it if your subscription runs out, BUT you can't deploy binaries internally/externally if you don't have a current subscription... This isn't obvious if you read their terms - you really need to dig in to find it.
And emulators?
I've ran Windows 7 x64 as a hyper-v guest as well.
Sure, they also seem to provide a free license to small shops, will see if ours falls within the limits.
`^([A-Za-z0-9]{5}-?){5}$` should do it, regardless. Worst case you'll have to `String.Trim('-')` your matches or test them for a trailing hyphen. This will get you the "good enough" case without needing to do masochistic regex contortions.
It's an official extension...
Seems unnecessary. Just start with some dumb api and refactor it from there, since you are new to ASP.NET also you arent really "learning" ASP.NET Core, you are ASP.NET Core 2 MVC development
I‚Äôm glad people finally realise it‚Äôs a relic. Haha. There are some things .... but fir that price. Nah. 
Thanks for your reply. That is very helpful but unfortunately I need it to work on both Mac and Windows. Could I do something similar that would work on both? Using Mono perhaps?
You think it's worth taking the risk with buying the CPU and hoping a fix will be rolled out soon?
"in this very quick tutorial" dude it took you half an hour
&gt; you're starting to get into pretty niche searching here No I'm not. Grepping for a string is one of the oldest tricks in the book. I can't tell you how many times I've seen something in the UI and searched for the string in the code to find where it's coming from. Maybe I should use a separate tool to do search? That's your answer? 
Start here: https://gist.github.com/jboner/2841832
Will that "stop" the timer and then resume when enabled again or? Like if the timer is set at 10 seconds and 5 seconds have passed when you enable = false the tiimer, once you enabled it again, does it start from 0 or from 5?
Really old series, and the blog/website/project is dead, but [this guy screencasting](https://www.youtube.com/playlist?list=PLpBzqAJhzCLct58wYqQv31CaN-j9nesC6) his initial creation of [Funq](https://archive.codeplex.com/?p=funq) is what helped get the whole DI/IoC and Container concepts clicking in my head. I still use the simplified/modified Funq-esque library I built following this screencast in production today. Unfortunately, the associated blog/site describing the process along with the screencast is long gone. Definitely not a "very quick tutorial" (about 3 hours), but it's what worked for me 5 years ago.
It seems like a lot of the example code in this article contradicts the rules being laid out by the author. Example: If you're advocating a program throws the most specific exception type it can, the very first example of the article should throw `System.ArgumentNullException` instead of `System.ArgumentException`. The example of catching a generic exception to rethrow something more specific is also rather ugly: static int GetValueFromArray(int[] array, int index) { try { return array[index]; } catch (System.IndexOutOfRangeException ex) { throw new ArgumentException("Index is out of range", "index", ex); } } Try/catch shouldn't ever be used to retrieve values from an array. It's also debatable whether this method should throw `ArgumentException` when `index` is invalid or `IndexOutOfRangeException`. This example all around feels pretty bad for making the point. static int GetValueFromArray(int[] array, int index) { if(array == null) throw new ArgumentNullException("Value cannot be null.", nameof(array)); if(index &lt; 0 || index &gt;= array.Length) throw new ArgumentException("Index is out of range", nameof(index)); return array[index]; } I realize this is just an example but that shouldn't exempt it from following good practices, especially ones the author is trying to highlight. The portion of the article on `finally` blocks is also incorrectly using `FileStream`. Streams implement `IDisposable` and should be used inside of a `using` block or handled in a try/catch/finally properly. The [official docs on `using`](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/using-statement) go into further detail about this. I think a lot of the points being made here about exceptions are pretty accurate, but the examples definitely could use some revising.
It seems like a lot of the example code in this article contradicts the rules being laid out by the author. Example: If you're advocating a program throws the most specific exception type it can, the very first example of the article should throw `System.ArgumentNullException` instead of `System.ArgumentException`. The example of catching a generic exception to rethrow something more specific is also rather ugly: static int GetValueFromArray(int[] array, int index) { try { return array[index]; } catch (System.IndexOutOfRangeException ex) { throw new ArgumentException("Index is out of range", "index", ex); } } Try/catch shouldn't ever be used to retrieve values from an array. It's also debatable whether this method should throw `ArgumentException` when `index` is invalid or `IndexOutOfRangeException`. This example all around feels pretty bad for making the point. static int GetValueFromArray(int[] array, int index) { if(array == null) throw new ArgumentNullException("Value cannot be null.", nameof(array)); if(index &lt; 0 || index &gt;= array.Length) throw new ArgumentException("Index is out of range", nameof(index)); return array[index]; } I realize this is just an example but that shouldn't exempt it from following good practices, especially ones the author is trying to highlight. The portion of the article on `finally` blocks is also incorrectly using `FileStream`. Streams implement `IDisposable` and should be used inside of a `using` block or handled in a try/catch/finally properly. The [official docs on `using`](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/using-statement) go into further detail about this. I think a lot of the points being made here about exceptions are pretty accurate, but the examples definitely could use some revising.
There are two operating systems here - the server OS and the client OS. The server OS runs the Web API, and the client OS runs the application that connects to it. It could be the Python application you have, or the .NET version you were planning to make. If you develop the Web API using ASP.NET Core Web API, then you can host it on Windows as well as some Unix operating systems. Your Python client application should be compatible with many operating systems, and the same would be true of a .NET client application using .NET Core or Mono. If you use Mono, you can use most of Windows.Forms to build a GUI and it will work cross-platform. If you use .NET Core, you could try an Electron or Avalonia front-end. 
Oh ok, so it doesn't matter which I use then? I'd like to build this with .NET &amp; Python then, but I still have... no idea how. I don't know how to set up a server to do something like this. I don't know how to develop a Web API. I don't know how to make the GUI and I don't know how to make them communicate. I'm sorry if this is too much to explain, if you don't want to show me how I can actually go about doing this then that's perfectly fine. Do you know of anyone who has documented doing this? Perhaps a guide or something? Learning about how it is going to work is great but really I just want to start building it. Thanks for your time.
It's a decent article. Some nitpicks. &gt; Throw Exception For Exceptional Cases I really wish that stopped. What is "exceptional"? It doesn't mean much, if anything. The rule really should be "throw when you can't do what you're supposed to do here". That's practically always, one [sic!] exception being stuff like various "find" methods (but then, the .net "tryFind" idiom applies). &gt; Do Not Use Exceptions To Change The Flow Of The Program The example is too short to be informative and flow change is trivial either way. `bool ValidateProductViewModel` is suboptimal because it hides information about what is wrong. Version with an exception can be used to log what went wrong. `bool` variant could do that by itself, but that gives it a strange extra responsibility ("validate and log problem; return validation result") &gt; Make Sure To Clean Up Any Side Effect If Exception Thrown This example is quite bad. [Exception safety guarantees](https://en.m.wikipedia.org/wiki/Exception_safety) are at play, in particular, the so-called strong exception safety guarantee needs to apply to `Deposit` function itself and MakeDeposit has no reason to exist. (.NET people tend to know less of exception safety IMO). &gt; Finally The Finally Block This example should be one if * using `using` * looking like this: `var fileinfo = new FileInfo("C:\\file.txt") var file = fileinfo.OpenWrite(); try { file.WriteByte(0xF); } finally { file.Close(); }` The `if` in finally is made possible through poor coding, it is not necessary.
Non-Mobile link: https://en.wikipedia.org/wiki/Exception_safety *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^156767
So you're trying to make this super secretive app that no one can ever decompile yet you don't know much about programming. No one will put the effort in decompiling an app if its not big. Either give up on the secretiveness or put your code server side. Having your code decompiled won't affect you much btw. Games are cracked literally all the time and they're still in business. You'll be fine.
love me that ReSharper test runner tho
go be gay somewhere else
epic comeback dude XD
That's a bummer. Maybe getting a cheapo android device would work out.
I think you have misunderstood. I'm no longer even considering trying to hide the source code on the user's computer, as I've stated above. Also, I am not trying to make my app super secretive, I am mainly looking to prevent people from editing out the license check and re-selling my software. I have no idea why you'd say I don't know much about programming. My code is complex, I just have absolutely no experience in this area. Hence why I am asking for help... on a help subreddit... Again, the post you commented on is literally me saying I want to do it server side. It's my decision and I don't think I'll be "fine". Thanks though.
Great idea. But how would you allow constructor injection with that container? My assumption is that you would need some extra code. I could be wrong though.
Yes, Venkat has great guides on C#, ASP.NET MVC &amp; Web API, SQL Server, and more: https://www.youtube.com/user/kudvenkat/playlists You first need to decide whether you will host on a Linux or Windows server. Linux servers are cheaper, which will sway a lot of people. Personally I still host everything on Windows because it's what I know. If you want to host on Linux and develop the API with .NET, then you will need to use .NET Core. If you host on Windows, you can use .NET Framework or .NET Core, it doesn't matter. Most of what you find in the ASP.NET MVC and Web API tutorials will be applicable to the ASP.NET Core versions, but there will be some dead zones, and for those dead zones the Microsoft documentation can be quite good. ASP.NET Core is great and it is faster than the older stack, but personally I'm not using it again until their APIs stabilize. There were large changes from ASP.NET Core 1 -&gt; 2, and personally I will wait until such large, breaking changes stop occuring before I invest more time into it. SQL Server now works on Linux also, though I'm not sure to what capacity. You can run SQL Server 2017 Express on Linux or Windows for free. The Express edition misses some tooling and imposes a 10GB maximum database size. The tooling you get is still considerably better than any of the completely-free alternatives. To get your servers, you would provision them from a provider like Microsoft Azure or Amazon Web Services. Amazon gives you an entire year free with EC2 t2.micro and RDS t2.micro instances, and a lot more too. You can use these to host your web application and database respectively. There are a lot more things you need to take into account with this sort of stuff so you will need to look into all the charges e.g. bandwidth, disk IOPS. Google the AWS free tier to find out more. Further to this, you may want to attach a domain name to your web service, e.g. www.example.com, and for this you would need to buy the domain name from a registrar and learn a little bit about DNS records, the zone file and hosting a website on a server using IIS on Windows, or some other web server for Linux. So it is a fair bit of stuff, but learn to make the web api, then learn to host it, and then you can provision a server to host it in the real world.
You can sometimes get the best of both worlds, nice convenience + good performance with libraries like (mine): https://github.com/jackmott/LinqFaster It does not do lazy evaluation, but provides some convenience functions to work around that in some cases (like WhereSelect, and SelectWhere, for example). Also it provides SIMD, Parallel, and SIMD+Parallel version when applicable. 
That's absolutely fantastic, thank you! I will probably go with Windows too, if you think Core is unstable then perhaps I will choose Framework - I'll have to do some more research into that. I will need a database so that's great, thanks. I'm on AWS Free Tier right now and I selected Create a Virtual Machine. Is there any chance you could help me decide which option is the best for my uses? It's asking me to select from 35 options such as &gt;Microsoft Windows Server 2016 Base - ami-16370073 &gt;Microsoft Windows Server 2016 Base Nano - ami-873d0ae2 etc. Should I just go with the first one? I picked EC2 because I'd like to get the code running before I setup a database (it won't be needed until I deploy). Yes that is definitely something I will look into Thanks again!
That's a very good question without a good answer. Looking at my APIs, I see places where I wish I choose the opposite for both cases in roughly equal proportions. 
Yes, the first option is more "fragile" in that if you change how it works you'd have to change the parameters. But if you extend that idea to the extreme, then we should just use objects everywhere. That way we can change anything any time we want without having to change any code. I think you can see why that's not a good idea :) Functions should be as tight as possible. If this function only operates on (or uses) the user name then it should only get the user name. It shouldn't get the whole object just in case it might need the other properties at some undetermined future date. "Just in case" programming violates YAGNI (You Ain't Gonna Need It). Unit testing the first case is simple: you don't have to worry about the function fucking around with other properties of the object because it doesn't GET the object. Unit testing the second case is almost impossible because it has so many more things it can do. If you need another option in the future (to select user by first name) then that's what overloads are for.
&gt; But if you extend that idea to the extreme, then we should just use objects everywhere. That way we can change anything any time we want without having to change any code. &gt; &gt; I think you can see why that's not a good idea :) I agree and that's been one of my biggest argument for option 1 in our discussions. So it's fun to read someone with the same feelings. 
Yeah, we came into this discussion after I saw a method taking in a whole object and then just using a single property. My mind went just went - why (especially since I didn't have the whole object)? So I wanted to change it but he where more against it.
That's my go-to argument any time somebody wants to make their code "as flexible as possible". Obviously flexibility is good. And since we spend most of our career maintaining code, it's good to have code that is easily changed and adapted. But not at the expense of turning the whole code base into an amorphous goo. Some structure is always going to be required. It's always better (in my opinion) to start with tight, restrictive code and loosen it when required. As opposed to starting with loose code and having to tighten it up when the users find creative ways to break it.
It was just an example for this thread but for we can say that the method select the user inside a GUI (maybe to show detailed information). Regarding my other comment we're currently still discussing if we should change the method to just take the required simple parameter. The workarounds would be pretty ugly I think.
Core is a bit unstable with the breaking changes, but it works well. I noticed that my website became faster when upgrading it from .NET Framework 4.-something to .NET Core 1.1. It's just that there are very lengthy upgrade guides when the new changes come in, because so much stuff is broken and needs to be re-worked. It should stabilize eventually. I think you should go for "Microsoft Windows Server 2016 Base". This is Amazon's regular Server 2016 image and includes the Windows UI. Nano server is very stripped down, and you may not even recognize it as Windows. You may be interested in it at some point if you decide to learn how to manage Windows entirely through the command line.
A dictionary could be used as a local caching layer to provide very fast results with the trade-off being the data can be stale. Imagine you run a website with baseball statistics and you have ever single stat in a huge database. Maybe some popular lists are 'who has the most strike-outs by year?'. Well, that might take a little while to compute with raw data, but once you have it you could cache those results since they are unlikely to change much between computations.
Well speed is actually very important to me, so perhaps I will opt for Core. There are some things I am a bit confused about though. My software is automation software that will open up many headless browsers with Selenium and perform a task. If I set this up as an API and request it using a .NET Core GUI, won't the headless browsers run on my server and not on their computer? I need to be able to run Selenium browsers on my user's computer as I will be transferring cookies to a 'headed' browser so they can see the finished result if they choose. If they will indeed run on my server then I may need to re-think this a bit. I was thinking I could store the setup of the automation on my server as well as the license check, and then the functions that actually run the Selenium on their computer along with the GUI. Is this sensible? And is it achievable through the same methods? Thank you I will choose that one!
Good advice *however* sometimes I make an exception for 'stringly typed' objects like the username example above. If you're working with multiple representations (email addr, username, domain (e.g. domain\user)) the consumer may get confused which one needs to be passed in if there isn't a wrapper object like `Username` that is returned from `User.Username` and can't be mixed with `User.Email`.
It is case by case. We definitely need more details to what is going on, but usually you want to follow encapsulation and loose coupling. So, in this case, what do I mean? Do you want to force the caller to know and have the full User class, before they can call the behavior? Do you want to have that restriction? Probably not. No need to couple it there. What happens when the User is provided, while having the same username, has different details? Is that important? The caller might get behavior they weren't expecting. Just by the signature, what I'm imagining is that there is a list of Users in the class. When you pass the name in, it chooses it for other functions to work on or something. Or, perhaps it makes a call to the database and grabs that User. In these cases, you probably want to use the username. But what if this was more like a setter situation? Then you'd want the full User class. But personally, I'd change the design of the code to make the object take in the User at construction and not allow it to be changed. Or, if you were using many different properties of the User for just the method then you'd want to pass in the User. Even further, an extra option you have is to put the Select method on the User class itself, if it made sense. I doubt it does in this situation, but that's something to keep in mind. One more way of thinking about this, I bet thinking about how you'd test this would solve the issue. I think the first one would be far easier to test, which is a good clue as to which is the better one to use.
As seen on TV must have X easy payments of Y part.
If the stuff you're doing with Selenium is what you want to protect, then you will need to do it server-side and communicate the results back to the client. If that's not the part you need to protect, then you can do it on the client. If the whole point of your software is to automate the client's web browser, then it could be the case that you can send some HTML to the server, then the server decides what should be done with it and sends those commands back to the client. If you're opening web browsers on the server then this will drastically increase your memory requirements.
"... ships from Canada, all prices in US dollars" 
Is it possible that something is being cached from the LINQ side that makes the traditional code run faster? What if you run the traditional code first instead?
Good point. And of course there are always exceptions to everything. Our jobs would be a lot easier if everything was straightforward :)
You can't know the future, so any choice you make may appear to be the wrong one at some point. For example, if you use the one that takes a user instead of a string, then you will have some issues if you start using UserViewModel instead of user.
&gt;or an extension for VS that does it better JUST LIKE IN VSCODE. Dear god man, are you trying to be as obtuse as possible?
My objective is to prevent people from viewing my source code, copying and pasting it and then re-selling my software. I think that the best way to do this is via a license key check. However, if they can view my code then they can just edit out the license check. What I would also like to do is run some code on my server which will check some stuff and send it back to their computer which will then run the Selenium browsers based on what I have sent them. This way, if they remove the license key check then they remove some functionality of the software. Should I still follow all of your previous advice if this is what I'd like to do? Also, will this make it run quite a lot slower than just running it fully on their computer? Thanks. 
To be more specific, I will do some web scraping on my server and categorise some of that data and send that information to the user and the software on their computer will then run Selenium which will call from that data.
You have to be careful running tests like these. So I ran your first example. 43ms to 31ms. My computer is apparently a bit faster, and perhaps it's .NET Core, but the LINQ performance is better too. Then I simply changed the type of 'numbers' from int[] to IEnumerable&lt;int&gt;, no other changes, it's still an int[] internally, and the result is: 47 ms to 74 ms. Suddenly, the Linq result is actually faster than the traditional, by quite a bit even. For me, anyways. Guess what happens when I change the data type from an array to just an IEnumerable? Nearly the same time taken (both slow, though for that scenario, 344 ms to 323 ms). Measuring these things are tricky. Not only do small tweaks like the above change the results, but you didn't check for the JIT optimizing the behavior at some points, giving one side an advantage. It can do that. ... But what I really want to talk about, that isn't covered here, is the pitfalls of premature optimization. It is very likely that many developers are going to use IEnumerable&lt;int&gt;. They read your blog, think why, I need performance here, and they switch to traditional. And oops! Slower and you're missing the benefits of linq. We're talking some pretty insignificant differences in performance here. It is doubtful it's worth optimizing, you're likely facing much bigger bottlenecks somewhere else. And until you actually have the solution in place, then actually bench-marking it, the reality is you often don't actually know if the performance is better. You can be surprised at the actual results. I know I've been a few times. Don't optimize for performance, until you know you're in a spot to actually measure it. Likely at that point, you also know if you should care about squeaking out at best such minor improvements.
And to do this could I not just simply send a request to the VM I just setup to run a certain .py file and run the specified function within that .py file with specified parameters, and then return the result? That sounds quite simple to me.
Change `Object` to `Func&lt;Object&gt;`: var container = new Dictionary&lt;Type, Func&lt;Object&gt;&gt;(); container[MyType] = () =&gt; new MyType((MyDependantType)container[MyDependantType]()); MyType myTypeInstance = (MyType)container[MyType](); This is the absolute, most rock-bottom, basic constructor injection for the container. Wrapper API wraps all this, provides type sanity, and other bells and whistles.
I'm not the author of this article or site, just thought it was interesting and shared it
Generally speaking I find that when some says "we're doing X because it is more flexible" the truth is the exact opposite. For example, in this case option 1 is more flexible for the caller because it can source the username from anywhere, not just a user object.
I use Win 10 for anything .NET related. All else coding-wise I use MacOS. Obviously I could use .NET Core with MacOS but I simply like Visual Studio.
So if I have ten parameters in my class constructor, I would need all those functions written out. Maybe I'm reading it wrong, but that code seems difficult to maintain. 
so CQRS is a thing that you want to do for a lot of reasons, but " I'm looking to learn a bit before starting with a fun side project" is not one that many people would classify as a great way to be introduced to it. If you're up on software patterns, one you might want to look into ( sort of a 1/2 way point between where you are and a full CQRS implmentation) look into a mediator pattern. http://www.dofactory.com/net/mediator-design-pattern If you couple this with a solid IoC container and generics, you can cleanly do most of what you're thinking CQRS will do for you without a lot of the baggage it can come with. FWIW, I would never build an application without CQRS and event sourcing unless I had a real solid reason not to. My typical pattern for API's: 1) Update comes in as a request ( in the form of a single parameter that is an event like ItemAddedToCartEvent), then put on a queue -&gt;an acceptance result is returned 2) the updates happen on a web job or similar system -&gt; event handlers call commands to do updates to source of truth and rebuild view models ( typically different handlers to maintain SRP) 3) once all the handlers have finished either socket.IO or SignalR call made to the client to query for updates, or giving them the updates directly 4) queries (Also the API, with a deterministic URL that can be cached appropriately) only hit view models stored in something like Redis or Mongo, never the RDBMS 5) if the data is fairly static, we also push the output to something CDN-ish ALL that is what makes a healthy CQRS system, not the code structuring. If you want to do all of those things and you want to devote a few months to getting it right, then you should give it a go, otherwise it's probably out of the scope you're looking for right now. 
Ended up editing the post. I solved the errors I was getting, but I still have an issue with a duplicate triplet coming back and I'm not quite sure how to fix that. I also don't really get this part of the code: IList&lt;IList&lt;int&gt;&gt; solutions = new List&lt;IList&lt;int&gt;&gt;(); I get that it's a list that contains a list of integers, but I don't really get it... if that makes sense?
I don't know if you're allowed to use LINQ, but it has the ability to remove duplicates. And yes, List&lt;List&lt;int&gt;&gt; is a list of a list of integers. 
I actually haven't learned LINQ yet. I plan to learn it in the newxt week or so, but do you know a way I can do it without using LINQ?
You'd have to sort each individual list (so the integers are in the same order). Then sort the containing list. Then loop through it and remove duplicates.
May I ask what are the requirements or the scale of your applications that you benefit from such a complex solution? Is this something you studied and implemented 'for fun &amp; learning' and now become fond of it and use it in your applications or was there a real requirement to use such a solution?
What is it giving a duplicate with ‚Äî What are the inputs?
Performance wise you're just passing a reference to a place in memory so both are equally efficient, it's just the dereference point that is different. Clarity wise I name input variables to match what I am going to be using them for. That way when you read the method signature you have a decent idea if what it does and what you are passing. Anything I can do in your code to reduce additional documentation is a good thing. Personally I would go for the explicit separate inputs and not the class because then you can name the inputs to help clarify what they are being used for.
Well, _yeah._ The `Dictionary` usage here is kind of an example of reducing it the most fundamental concept of the containers/injection. Some lookup by type/class/interface, a factory method to instantiate that type, and a way to inject the dependencies. I wouldn't suggest anyone use _this as-is_; we create APIs on top of it to simplify/abstract the concepts or add additional functionality. A single/simple layer of API on top of this concept might look like: var c = new Container(); c.Register(() =&gt; new MyDependentType()); //MyDependentType implementation has no dependencies c.Register(() =&gt; new MyType(c.Get&lt;MyDependentType&gt;())); //MyType implementation doesn't care about MyDependentType implementation/dependencies MyType myTypeInstance = c.Get&lt;MyType&gt;(); //we don't care about MyType implementation/dependencies Another implementation of the API might automagically-wire dependencies using reflection to inspect available constructors and call them intelligently (or throw exceptions for ambiguities). var c = new Container(); MyType myTypeInstance = c.Get&lt;MyType&gt;(); //magic, reflection, checking types in the AppDomain, etc. Another implementation might look at XML configurations: var c = new Container(myXmlStream); //parse XML, reflection, wiring, checking types exist, etc. MyType myTypeInstance = c.Get&lt;MyType&gt;(); The various IoC frameworks have pros and cons. One where you explicitly register constructors and types might afford you some compile-time safety when wiring dependencies but requires a bit more work wiring up. One doing everything automagically might "just work" at the expense of less configurability or failure at runtime. One using XML configurations might afford you more ability to dynamically change your application without recompilation but perhaps prone to typos or painful to refactor type names. But ultimately, it basically boils down to our type lookup, factory methods, and dependency/implementation injection. This `Dictionary&lt;Type, Func&lt;Object&gt;&gt;` represents a bare minimum using a very small amount of C# features and wrapping APIs. Again, I want to stress that I wouldn't suggest anyone _actually do this_ in isolation. But if you want to learn how to make your own DI framework, this might be a basic concept you start with then wrap or replace with your own classes/API/stuff.
If you want to request that the VM run a file, then this could be possible, though I'm not sure how. However, you would need login details for the VM. That means the client has access to your VM. I'm not sure how you would handle that. It may even be possible for the client to download the file. Your WEB API could execute a Python file. 
If the client has the ability to run this code, and it's only conditional on the response from the server, then a hacker could edit the response from the server, or perhaps move the check entirely. If the code is on their machine and they just remove the license key check, that wouldn't remove any other code that's on there. If you use a web server to run the code, then the speed of doing that vs. running locally depends on the power of the server and the network speed. It could be better or worse, depending.
So first thing: I build very large / complex / high throughput applications all day long ( financial sector) - so I had real need to learn. It does work very well in a small application though, it's just hard to justify learning unless you're a gear head. I learned because we had to - there was no way to keep up the requirements coming our way without this change to decouple the reads and the writes without open heart surgery for weeks of downtime, so we backed into the solution. It was a few years later that I realized it had a formal name. I kept spending time trying to explain to people that caching and pre-aggregation are not the same thing, and then I found out that all people care about is that it works, and works well. This does work well. That said: The requirement is ( and typically will be) around three things: scalability, tracability / reporting, and DATA DATA DATA. Data is the new bacon - hot, sizzling, juicy data - and everyone wants their share of the data. For a small startup I'd use it becuase we can quantify the hard decisions easier. For a large company it gives the tools to really analyze to squeeze an extra 1% in profit where that could be tens of millions of dollars. If you don't love data that's ok too - I can guarantee there's someone you work with that does. Form the scalability side, there's a lot of ways to handle the problem ( assuming you build for $1bn from the start) - this is just one of them. It happens to be my favorite way, since it's changes the way you talk / discuss your system to a series of events and not as database reads/ updates. If you can learn to build you application to handle eventual consistency ( and 99.999% of the applications out there can be as responsive as a HFT trading system,so yes your application can do it) you get an almost infinitely scalable system if you have the scratch to stand up servers. Example: message handlers overloaded? With this type of core system in place you can examine where the bottleneck is and just spin up new servers to handle the events. Or is it purely system overload on the web / query side? Add more servers there. Back end database is slow? no one gives a shit becuase no one is reading from it except for reporting, they can wait. For the tracability and reporting First tracability - when you record the events separately (to something like [event store](https://eventstore.org/)) you get the added bonus of playback - both in forward and reverse ( or just time travel back to the latest aggregate snapshot) if you wanted to engineer it that way. This is hugely valuable, but extra work in both system design and in terminology. You can't play back to the beginning of time ( way out of scope for this conversation) but you can get a good chunk of the past within your grasp for analysis. Let's say for kicks with a medium size application and you choose to time travel instead of reverse the flow. You could keep the events in raw form for 6 months without any real data retention issues around size ( storage costs falling like a rock that may be an under estimation). Once a week you crete an aggregate rollup from that week, it becoms the new starting point. Bug comes in, you stand up a debug handler that starts at the aggregate, plays to the bug. You find the bug, fix the bug, then one server at a time ( in the case of say a redis server) you take it offline, and replay. Assuming you have this rolling 1-2 weeks window, you just make sure that you can solve any major bug that needs specific data within the 6 month timeframw. the other part of the tracability /recording is that since you have your aggregates, and you have your events, you create a new event handler ( fresh new implementation, like "bob in accounting needs a new excel output from a nightly set of data"), add it to the pool and teach it how to handle the aggregate first. It runs the aggregates, feeds the data in, and then it reads the events until it catches up. Once that happens, it behaves like every other event handler in the system. Of course that's a complex topic in itself, but it's perfectly doable with some planning. On the reporting side, it's a more clear example: cached viewmodels are optimally suited for something like Mongo / Redis / DocumentDB / whatever else your O(1) object database is really good at. that same store is the worst possible way to give your business team data they can run analytical processes on. give them what they want - something like that looks like an excel spreadsheet that they can understand and work with. Your web site hates SQL, your marketing team / finance team hates Mongo. Don't compromise and don't design your table schema to fit performance goals, make it for reporting. It's now your source of truth and it doens't need to conform to anything other than exactly what it's great for - holding the data in the most reasonable way posible. Normalize the shit out of it, OR DON'T - it's your call and it no longer has anything to do with scalability. The other reporting piece is that say you have this rolling 6 month window of data, and your CMO comes rolling in asking why an A/B test passed, made it into the main stream, and then sales dropped. Armed with data you can replay what happened and do a real root/cause analysis on the problem, not guessing games and finger pointing. Want to know how many people added a winter coat to their cart, then deleted it in the last month vs. this month when the items were on sale? You have the data in front of you. All make sense? I feel like I'm hitting all the points, but I may not be answering your question directly. let me know if you care to know more, or if your eyes just glazed over :)
That is called caching and yes it is magnitudes faster than querying the database directly every time. Thats what it is though, caching, its not a replacement for the database. You are trading memory, and more complexity, to deal with data locally rather than have to wait for the multitude of network operations that have to happen to get you that data in real time.
Thank you all kindly.
You must be new to the industry if you don't know what Tech Recruiters are Mainly its for non-us targets.
Or just properly document it, including property comments that are shown via intellisense. Take a look at the RFCs for domain names and email addresses before taking on enforcing those formats. Compared to just adding: /// &lt;summary&gt; /// Description for SomeMethod.&lt;/summary&gt; /// &lt;param name="s"&gt; Parameter description for s goes here.&lt;/param&gt; /// &lt;seealso cref="System.String"&gt; /// You can use the cref attribute on any tag to reference a type or member /// and the compiler will check that the reference exists. &lt;/seealso&gt;
This is why I always look at how I would solve a problem and then do the exact opposite. 
Its not more fragile. It needs to change _exactly_ when it needs different data. And the compiler tells you (how friendly of it!). Passing User in is a little sloppy when what you really want is the name. Youre basically saying, "Hey, we might need to do _anything_ with this function, have fun!". I mean, if languages had better syntactic sugar, Id be passing around things as interfaces much of the time. 
after the first example I already know he doesn't know what he is doing. you don't do .where(a...).count() you do .count (...). otherwise he is looping through multiple times here. he doesn't realize the subtlness.
It‚Äôs decent. The instructor gets straight to the point and from what I remember he doesn‚Äôt demonstrate a lot. But the theoretical part is decent.
Didn't Udemy get outed recently for stealing tutorial content from youtube?
Don't forget a possible cache miss.
I found this video very helpful: https://youtu.be/aIkpVzqLuhA Was a great intro to building .NET core APIs, including setting up the routing to controllers, building controllers/repositories, and generally how the projects are setup. 
The timer resets whenever you enable it. 
Exactly, my company revenue falls within the limits so we'll check if we can adopt it.
But trying to enforce a specific format inn the interface makes this even harder. In effect, you're saying "this is too hard to document right, so just do it in code"
How many parameters must a function take before you use an object? I think if it‚Äôs more than 3, I‚Äôll create a request object to pass the parameters.
Thank you video maker. You said in the very first 15 seconds that it's very specifically a Dependency Injection container. Sure, it's also IoC, but a lot of things are IoC that *aren't* DI.
This doesn't really answer any of your questions but I would HIGHLY recommend checking out Amazon lightsail for hosting if you are willing to install asp by your self. (You can use let's encrypt for ssl). Otherwise I would recommend using php + pdo for fairly robust + secure database interfacing. (Pdo auto prepares and sanitizes SQL statements)
If you already have the user... what use is the SelectUser method? It would just return user. In _general_ though scalar arguments are a bitch to support and you end up with lots of function overloads with different sets, when you could have a single method that took a class
This whole example could use more clarity. The only suggestion for what select user would do is to display a user. In that case not passing one in if you had one is wasteful. And the implementation offered above of throwing away a user, then finding them by user name, then displaying the user is even more wasteful, you'd want to have the opposite implementation. If you have function overloads for different scalar parameters, you can probably wrap them in a class or a struct. If you have a class, you should probably consider extracting an interface, and binding to an interface instead of a concrete class. _Especially_ when I see a User parameter, I'm predicting problems from not binding to an IUser parameter instead
Thank you for your feedback. I agree with your point in general, but if I want to think about every aspect of exception handling in every example and mix them, it could potentially take away from that actual point that I was trying to make. For example the GetValueFromArray method that you've changed could not be used for "catch generic exception and throw specific one" part. Isolating the concept before explaining it is a natural thing to do when introducing an idea.
That really seems like you're solving the problem of consumers not reading the documentation there. IMO any of these would be preferable, - rename the function to SelectUserByUsername, or - accepting multiple arguments with default null, e.g. SelectUser(string username = null, string emailAddress = null), or - do nothing
What are you going to do when your library is used at the company where "name" commonly means "name of your imaginary friend when you were five years old"? Your function's expectations are a closed set and easy to document, whereas user misbehavior can be unbounded.
Input parameters should be as generic as possible, while the return should be specific as possible. This maximizes the scenarios in which the method can be used with ease. It is also confusing to take in more than what is needed to perform an operation, because it implies to the caller they need to be concerned with the other properties. If I pass an object into a method I'm not familiar with, I'm going to need to dive into the method body to understand how its using the properties of the object I passed in if it is not well commented in the summary. Once I've determined it took that entire object in, but only used the one property, I will be quite annoyed with the time I wasted. If it had only taken a single `string username` it would have been self explanatory. Also it returning a void leads me to believe that perhaps the method will retrieve the user and then modify the object I passed in, filling in the user properties, which is not a good pattern in my opinion. So again I have to dive into the method body to determine whether it actually does that or not. In this case, a User is too specific. A string is more generic. Consider all the cases where we might have a UserId and want to leverage this method: We already have a User object, it's easy to adapt it to just the string: `var user = SelectUser(Session.User.UserName);` We only have a string in a business method: `public void AssignUserRole(Role requestedRole, string userName) { // first retrieve user var user = SelectUser(userName); //... }` We have some other object containing a UserName `var userRelatedTo = SelectUser(roleAssignment.UserName);` If I had to use the other version, I'd have to do this everytime: `var userRelatedTo = SelectUser(new User { UserName = roleAssignment.UserName});` So adapting a User object to just the string property is easy, but adapting the string to a User object is more cumbersome. I'll reply with the example of why return values should be as specific as possible.
Well, since you've been coding for 5 years, I think this may be too basic for you, but this course covers a lot of things. https://www.pluralsight.com/paths/csharp
Oh very nice!
Returns should be specific because it's easy to cast a specific object to a more generic one, but not the other way around. Let's say you login and they set the user on session: public class User : UserBase { } class UserBase : IUser { public string UserName {get;set;} public int UserID {get;set;} } public class IUser string UserName {get;set;} int UserID {get;set;} } //... public User SelectUser(string userName) { ... } //... during login, depending on caller's need one of these may be needed: User user = SelectUser(username); IUser user = SelectUser(username); UserBase user = SelectUser(username); Depending on what the caller is trying to accomplish, they may only reference IUser types and cannot declare a `User`for some reason in order to keep their code generic, or the caller may have some other object they are required to build where a property is declared as a specific `User` or `UserBase`. Because SelectUser returns the most specific type of `User`, then all of these casts are safe. So returning the most specific type allows the return to be used safely in all possible cases where any base type or interface is needed. If we instead returned the most generic type of IUser, then only `IUser user = SelectUser(username);` would be valid, and all other casts would be downcasts which don't guarantee a successful cast since we can't make assumption about the concrete type. For example, say I need to retrieve the user, and then pass it on to another method: `public void DeleteUser(User userToDelete)` If SelectUser is declared: `public IUser SelectUser(string userName)` Now I have a problem: IUser user = SelectUser(Request.UserName); DeleteUser(user); // cannot cast IUser to User (I could use a downcast but we can't guarantee success without making unsafe assumptions) We wouldn't have this problem if `DeleteUser` followed other guideline for parameters and only required an IUser instead of User, but sometimes a method absolutely needs properties in the derived or concrete type that aren't in any combination of base types or interfaces. Now imagine there was a very specific class: public class WindowsUser : UserBase { public string WindowsAuthId {get;set;} public List&lt;Claim&gt; Claims {get;set;} } public class LinuxUser : User { public Guid LinuxId {get;set;} public int AccessFlags {get;set;} } Let's say `SelectUser` can return either a `WindowsUser` or `LinuxUser` depending on username match? Which type should it declare as its return? My guideline was "most specific type" and both are more specific than `User`. Really the rule of thumb here is "most specific type common to all possible return types". Notice WindowsUser inherits UserBase, which means it is NOT as User. LinuxUser inherits from User, which means it is both a User and UserBase. They are also both IUser. So the most specific type which they have in common is `UserBase`. Therefore `SelectUser` should return a `UserBase` as that's the most specific type it can guarantee all possible concrete types it might return have in common. If I had a method `public WindowsUser ValidateWindowsAccount(string userName)` and it **always** returned a WindowsUser, then we can safely return that as the type. Again this maximizes flexibility. Windows specific code that works with the WindowsUser type and needs access to it's properties will be able to use the specific type, but more generic code can safely cast from WindowsUser to any base type of interface as needed. 
Starting tight definitely sounds right to me. If no side effect is planned (usually bad anyway!) I would always use what is needed if it can be passed by value to prevent accidental mutation. And then maybe call the method `SelectUserByUsername` and add a separate `SelectUserByFirstName` when needed. That way calling code gets mor readable.
You can use asp.net core2 mvc. You can use sql server express. You can use the regular aspnet mvc also if you want to try that. 
The question is, what are you operating on? In your example, you aren't operating on a user. Your selecting one, passing a user object just feels wrong in this context. Maybe a cut down object called: `UserSelectionCritetia` or rename your method to make it more obvious which criteria you are selecting on. After all, why would you need to select a user, if you already had one to pass in?
I'd preferably create or have User as a immutable data container. This way, I'm won't break the User and if the needs it, can have access to other data when needed. No need to add a new parameter then update every method reference just because X requires Y. 
I have the same idea... Look at the presentation in my profile... 
If this is the only processing you‚Äôre going to do, it‚Äôs better to not do it in parallel at all. There is a non-trivial cost for doing things in parallel and using a concurrent collection. 
a well-written Parallel.For? Can you show me a example? That will be great
Test the performance, yourself. ConsoleApplication1 is my favorite app. Use the Stopwatch class to time lots of iterations (a hundred thousand? several million?) of each technique, then compare. Unless the code for processing each item is _much_ slower than newing up an object and adding it to the list, I would just use the extension method equivalent of your LINQ query syntax (though go ahead and use your LINQ query syntax if you prefer): var shipmentDetails = concurrentPass .Select(x =&gt; new ShipmentDetail { ShipmentId = shipmentId, Status = "Z" }) .ToList();
Ah.. SpacialCircumstances said otherwise.. need more people to give their opinions
Jon Skeets ¬´C# in Depth¬ª should be perfect. 
IMO you should't be doing Parallel.Foreach at all if you are only reading the data. Foreach loop will be just as fast if not faster. Parallel.Foreach will give you an advantage if you are doing something with each row's data that takes time. For example: you are reading a value from the row, passing that value to an API call, parsing the response and saving it to a remote database and this takes say 3 seconds, then foreach will be slower than Parallel.Foreach. And even in this case there are better ways than using Parallel.Foreach...
Dunno whats your purpose of doing the app, but if its only for learning experience, I would recommend using SQLite. I just used it for a job showcase app and its really easy to set it up and use. I also used asp.net core with angular on frontend.
The CLR via .NET
Or take a look at [BenchmarkDotNet](https://github.com/dotnet/BenchmarkDotNet).
What's the schema of the Person table? You may have used something like varchar(MAX) instead of char(11) which given your 11 character requirement would be the most suitable choice of datatype.
First, wrap things in a try catch block, so you'll at least have some chance of logging the exception in a way where you can debug it, even if it means dumping a quick text file or something. Second... `args[0]` Did you set up the service to start with arguments? If args is null or a zero length array, then there's your issue right there.
Clean your build? 
Already tried that, didn't work sadly
It's a randomized design. That usually happens when a user doesn't set a profile pic.
But that's so _old_
They are both right and both wrong. The wall clock time of the parallel operation might be faster (I have my doubts about it, because there is some ConcurrentBag overhead), but it might have negative effects on the throughput of your entire application/system to use extra threads. It could starve your threadpool and cause delays as new OS threads are spun up, and the context switching could eventually ruin the overall throughput...if you don't already understand how many threads your system is using and the load that it needs to handle and its current thread usage characteristics.
It just string in .edmx ADO.NET Data Model diagram
Are you unable to internet? A quick Google search on "Parallel.For example" will literally give you just that.
Well the simplest LINQ statement works fine too 99.9% of the time. You typically don't want to be translating large collections of objects in a tight loop where performance matters, eventually the GC would become more of an issue than the looping construct.
&gt;We're talking some pretty insignificant differences in performance here. Every extremely simple things can be orders of magnitude slower using linq (or IEnumerable!). For example, on my i7 desktop, using BenchmarkDotNet which accounts for JIT warmup and does repeated tests, the simple task of summing an array of 100,00 numbers: * Linq: 541us, 48bytes allocated * Imperative Loop: 53us, 0 bytes allocated * Imperative Loop with System.Numerics SIMD: 9.7us, 0 bytes allocated * Imperative Loop, with System.Numerics + Parallel: 3.7us, 1.1kb allocated So we can see that the basic Linq Sum() operation is two orders of magnitude slower than what the hardware is capable of. This misquoting of Knuth about optimization, these lazy attitudes about performance, are why every day everyone has to use annoyingly slow software. Sometimes yes, Linq provides enough code simplification, with little enough performance penalty (or none at all!) that it is the smart thing to do. Otherwise, just use a loop! Just use arrays or List&lt;T&gt;, they are fast, they are simple. Don't turn to IEnumerable without good reason and just throw away time and battery life. Don't just shrug and say "well this function isn't a bottleneck so I won't worry about it", you have to think carefully about whether that function *also* affect others functions in the program as a whole. If you are allocating the GC has to deal with that later, if you are pointer hopping all over the place you are affecting the CPU caches and slowing down other things are you too. You don't have to optimize for performance all of the time but at least get the clowns out of the car. 
What does better for performance mean? Fastest time to complete the work? Least CPU to complete the work? Least blocking against other work? Least garbage collection triggered? Least memory used? You can't optimize performance in a vacuum
Mine isn't really about trading books, it was just an example. The subject matter is different :)
I have a feeling that Office caches the file somewhere. This so post might help: https://stackoverflow.com/questions/41211065/location-of-dlls-and-other-files-when-a-vsto-addin-project-is-built-in-visual-st To definitively find out where Excel is loading it from, launch Excel and use Process Explorer to view the Excel process's loaded dlls. Should show you where Excel is getting your dll.
Yes, I want to do a web api so I have the option to make a mobile app in Xamarin later should I wish
Half black on white, half white on black makes it really hard for me to read. 
I feel like I could give a semi-accurate answer, but admittedly, there are holes in my understanding that I've filled in with assumptions. Did you ever come to an accurate answer?
OK. Have you seen my presentation? 
I think one of my machines is running ConsoleApplication15 and WebApplication5 but it all depends on the context.
At this point you can _almost_ say 'you should never have a non-readonly struct'.
I haven't. I looked at your profile, but didn't find the presentation. Happen to have a direct link?
Oh i saw another bullet point that said website. I believe in core a mvc site is the same as a web api site
I think MSSQL is the easiest to work with, at least in my limited experience. There are a lot of built-in tools in VS via SSDT that make working with SQL Server *really* easy. Admittedly, I have only used MySQL and SQLite a few times each but both seemed harder to work with **efficiently** than with MSSQL, but they still performed their primary purpose, for the most part, fine. With MSSQL, though, you get all the little goodies that come with it. NoSQL databases are a different beast altogether and fill a different niche than RDMS so IMHO no real comparison can be done. &amp;nbsp; As a side note, I hate Lua and JS. Breaks my heart that JS has such a large marketshare on web apps. &amp;nbsp; Also, with SSDT, you can create a SQL project that allows you to manage your database directly via T-SQL. You can add table, stored procedures, functions, triggers, and index objects (and more) and the table object has a built-in designer. You can also easily manage pre and post deployment scripts. The consumable of a SQL project is a .dacpac file which, when published against a target database, will automatically 1) create a DB with the correct schema if the target DB does not exist 2) automatically upgrade the target DB to match the correct schema (the migration script is generated dynamically) and 3) *version* your database (the version is stored in a system table. Good shit.
 This isn't really the case... you have 8 tables you're joining to, you don't want to join to all 8 tables on the same query, ESPECIALLY if they're outer joins for instance. This is where dictionary collection from a database is insanely faster than just querying the database (which happens a lot in bigger software). You have the value have a collection of whatever object off of the primary key of the next table, and you only have to pull the values that actually exist instead of massive overhead from the DB, it will hold smaller cache and execution plans, and can better optimize smaller queries. And I get what you're trying to say, but the point isn't "random" access to that list, it's key'd access to the content.
I realize you have a framework you want people to use. But aggressively pushing like this to everybody causes me less likely to use it, not more. You're talking to me now not over milliseconds anymore, you're talking to me over microseconds. One millionths of seconds. You do that, while ignoring that I changed the performance of examples in the article by simply changing the container type (even just the reference to it), and it could make an imperative loop in actually slower than Linq. I don't know your exact code, but you didn't even bother to do the things I pointed out and compared with them. So why are you pointing out that you can make Ling slower, without actually dealing with any of the points I brought up regarding it? You are literally trying to argue over microseconds with me. And not just that, over specifically engineered test cases that are not actual production code. Knuth is not being misquoted here. &gt; Just use arrays or List&lt;T&gt;, they are fast, they are simple. Sure, if that variable is local. But here's where the real world differs from your test, the data is almost never defined in the same method. It comes from another method, which is returning IEnumerable, which is the best practice. Feel free to research why. In the real world, not storing results into intermediate arrays and such and just using Linq can have big savings. Or, it might not, and turning it into an array does. If you're trying to prematurely optimize, you're stuck. If you're properly allowing callers to make such decisions, they can do a toArray. Your premature optimizations here can drastically hurt performance magnitudes more than just microseconds. Microseconds are not what is slowing down the program to begin with. Again, there are probably far bigger bottlenecks actually causing real slowdowns. You don't know what is actually causing performance issues until you actually have the code set and can run proper tests over the code actually being used. Your tests are not reflective of actual code.
Thank you for the detailed post! One thing is that I'll be using VS on both Windows and Mac. I guess I'm going to be limiting myself technology wise if I do that. I could always install Windows 10 on the MacBook if needed, as I don't really care what OS I run, provided it suits my project. 
I'd rather let the compiler ensure the right pattern was being used instead of relying on the Dumb Human to read the documentation.
Diagram in the article looks wrong to me. UWP is shown in .NET Core column. Hmmm. 
Oh yeah, now it all makes sense! 
As far as I know that is correct. At least that's where Scott Hanselman (https://www.hanselman.com/blog/AnUpdateOnASPNETCore10RC2.aspx) and C-Sharpcorner.com (http://www.c-sharpcorner.com/article/difference-between-net-framework-and-net-core/) put it.
Interesting. I'm using a MacBook Pro, with Windows 10 in a Parallels virtual machine. The MacBook has a resolution of 2560x1600, and (interestingly, I hadn't noticed this before but it seems to work except for this!) the Windows VM has a resolution of 2880x1800, with a custom scaling factor set! I wonder if it's anything to do with the VM, or to do with the custom scaling factor? I'm in the office next week, which has more "standard" hardware, so I'll try to reproduce it there and see what happens. Thanks for checking it out though!
Yeah, I noticed that as well and fixed it. As far as the inputs they're completely random, and usually we have about 2000+ test cases that the code needs to pass. I just need to make sure that they don't show up in my output more than once. e.g. {{0, 1, 1}, {1, 0, 1}} --These are considered the same.
Yeah, probably something to do with broken scaling.
I like the idea as long as you can't "break" the "in" modifier like you can with a const_cast&lt;T&gt; in C++.
I looked at it again and again and it just does not make sense to me. There are no UWP/.Net Core project types in Visual Studio and no explicit documentation about such frankenmonster anywhere. Either it is a dead fork, early .NET standard experiment or some hakish way to compile .net core natively and then use it in UWP. 
 I don't think you're understanding. You still do SQL queries. You save those results into a dictionary to be used in further SQL queries. Also... dictionaries are MUCH faster than SQL queries, there is no transport time, no transactions, and it's a complete memory based operation. And... outer joins are incredibly expensive when your outer join is a smaller dataset. You're still transmitting all of that over the line. And finally, no, an outer join will NEVER be more effecient than an inner join. https://stackoverflow.com/questions/2726657/inner-join-vs-left-join-performance-in-sql-server
It's a shame that leetcode doesn't support Unit Tests. That would be a great addition to this code. You could do some simple Test Cases to remove the fear of red flags.
Ah yes - that‚Äôll happen. There are multiple things that can be done. Sorting the source, additionally removing duplicates from the source, sorting the results and then deduplicating .. etc. 
A short, not exhaustive, list of valid email addresses: - email@example.com - firstname.lastname@example.com - email@subdomain.example.com - firstname+lastname@example.com - email@123.123.123.123 - email@[123.123.123.123] - ‚Äúemail‚Äù@example.com - 1234567890@example.com - email@example-one.com - _______@example.com - email@example.name - email@example.museum - email@example.co.jp - firstname-lastname@example.com - much.‚Äúmore\ unusual‚Äù@example.com - very.unusual.‚Äú@‚Äù.unusual.com@example.com - very.‚Äú(),:;&lt;&gt;[]‚Äù.VERY.‚Äúvery@\\ "very‚Äù.unusual@strange.example.com If you use a validation library, all of these are valid entries. If the code needs a specific format, then the possible formats might have to be restricted. If the User ID is name@domain format, that needs to be parsed in accordance with the system requirements. And if I'm coding against your component, I'm going to hunt you down and smack you with a large game fish if you've coded a restriction without documenting it. And since you're documenting it, that's the primary interface necessary: User ID ( name@domain format. Ex: john@ourcompany.com ) is worth far more than some regex that's going to throw an exception if it gets the wrong format. 
i'm no expert, and i might have gotten a few things wrong, but this is how i would edit it. void Main() { Console.WriteLine(999.ToRoman()); //nice extension method syntax } public static class Solution { //static class, no instance behaviour required-&gt; extension method possible private static readonly Dictionary&lt;int, string&gt; intToRoman = new Dictionary&lt;int, string&gt;{ //static readonly, initialized once and with Dictionary initializer (more readable imo) {1, "I"}, {4, "IV"}, {5, "V"}, {9, "IX"}, {10, "X"}, {40, "XL"}, {50, "L"}, {90, "XC"}, {100, "C"}, {400, "CD"}, {500, "D"}, {900, "CM"}, {1000, "M"}, }; public static string ToRoman(this int num) { //'this' keyword to make this an extension method string romanValue = string.Empty; if (!intToRoman.TryGetValue(num, out romanValue)) //TryGetValue to shorten things up and access the collection only once { return FindValues(num, intToRoman); } return romanValue; } private static string FindValues(int i, Dictionary&lt;int, string&gt; d) { var result = new StringBuilder(); // stringbuilder might be overkill, but it prevents new immutable strings creation with every concatination while (i &gt;= 1) { //i didn't really get what the foreach loop was good for, maybe i'm wrong here, but it seems to work without it ..? if (d.ContainsKey(i) == true) { result.Append(d[i]); i -= i; } else { int max = FindGreatestValueLessThanTarget(i, d); // this method should do only what it says it does, so no string manipulation i -= max; result.Append(d[max]); } } return result.ToString(); //creates the result out of all cached parts } private static int FindGreatestValueLessThanTarget(int target, Dictionary&lt;int, string&gt; d) //LINQ makes life easier (/u/mmodrow) =&gt; d.Keys .Cast&lt;int&gt;() //only to use IEnumerable&lt;T&gt; methods .Where(x =&gt; x &lt;= target) //only values &lt;= target .Max(); //max value of them } Pascal Case for method names, static class to use it as an extension method, private modifier to hide unnecessary members/methods, no ref string manipulation (confusing) and and a few personal readabillity changes. Maybe i messed something up, but thats not the point, i just wanted to show the possibilities you have.
That link has no fewer than two examples that contradict your statement. One related to a bad index causing the inner join to be less efficient than it could be, and one related to the fact that outer joined tables can be dropped entirely from the query in some circumstances.
I actally did this problem myself a while back. Here's the solution I came up with. I wanted to solve it using a recursive solution though, to practice that so it's interesting to see how they differ: https://gist.githubusercontent.com/jamietwells/fc17014c7cc3dbe1a1514cf583811adc/raw/a1b66118dc4f881baec66dd78873eddc44faa250/roman-numeral.cs Concerning your solution, there are places where I would do things differently but a lot is down to personal preference. I'll go through line by line. Line 6: I would use `var` instead of `Dictionary&lt;int, string&gt;`. I often say this but I really do think that `var` should be used in 99% of cases. It's neater and makes refactoring easier. Line 7 through 19: I would initialise this using the Dictionary Initialisation syntax. See here: https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/how-to-initialize-a-dictionary-with-a-collection-initializer Line 6 through 19: I would extract to be a readonly private field. Every method wants to access it and doesn't want to modify the contents. Line 21: Use var. Line 23: `== true` is redundant. Lines 26, 28 the brackets are redundant, I would remove them. especially since this conforms to the if statement above. Line 23 to 29: I would change the findValues to not pass the string by reference and have it instead return the value, then change the return statement to be: `return intToRoman.ContainsKey(num) ? intToRoman[num] : findValues(num, romanValue);` Line 31 through 48: Quite difficult to read since no readable variable names. s should be built up using the StringBuilder class, not appended to the string. Line 37: Redundant `== true` Line 51: prefer `var` I dislike parameters being passed by reference, not so bad with private methods, but I usually see it as a code smell. Something probably needs to be extracted to another class or some other design change should be made. It can lead to difficulties in maintaing large code bases when methods alter their parameters so is not something I would reccomend implementing when practicing solving problems.
I think it is worth mentioning that .NET Core is also multi platform in the sense that it can run on different operating systems than Windows as well. I have created a few console applications and ASP.NET sites/APIs that I have used on a Linux server without any problems.
Thanks for bringing this up. I will look into this and update the post &amp; diagram if necessary.
I second the question about `args[0]`. It could also be that the connection string is malformed and causing the data access library to choke. If the command parser always splits on spaces, regardless of whether you put quotes around the arguments or not, your program has to put quoted args back together on its own. For example, if you have "Data Source=foo;Initial Catalog=bar;User ID=baz;Password=asdf" as your connection string passed in as a command line parameter, you might have ended up with 4 values in args[]: * "Data * Source=foo;Initial * Catalog=bar;User * ID=baz;Password=asdf"
So first you'd probably want to move your collection outside of the method, as a private static readonly collection. It shouldn't ever change, and you don't need to generate it every time the method is called. Next, now while a dictionary is fine and dandy, it's not working for you most of the time here. You spend a lot of time to find the biggest value to use, then repeat that over and over. Instead, switch it to an array with a tuple (value tuples if you're using the latest framework versions), and order it from largest to smallest. Now, you can sequentially work through it with a foreach loop. Next, you should use a StringBuilder instead of a string here. In this case you're dealing with such small strings performance might not matter, but since you're new I want you to get the concept. Concatenating strings in a loop can really hurt performance, because you're creating a bunch of temporary string instances. Along these lines, you should absolutely avoid using "ref" as much as possible. You want functions to have little to no side effects. That means it should change the state of anything not internal to its own method. What do we end up with? Something like this (ignoring the collection declaration): public string IntToRoman(int num) { StringBuilder result = new StringBuilder(); foreach(var pair in intToRoman) { while(pair.Item1 &gt; num) { result.Append(pair.Item2); num -= pair.Item1; } } return result.ToString(); } Pretty short and clean, right? The biggest takeaway is simply this: pick your collection type carefully and make it work for you.
Did you clean both the solution and the dll project? I find to do a full clean I have to set the config to Debug, right-click the solution and clean it, and then right-click on the project and do another clean. Switch to Release config and repeat. I also get compiler errors in WPF due to caches, which are only resolved by closing VS 2017 and re-opening it. Lastly, do you use any third-party tools? If so, do they have different design time and runtime licenses that you need to account for?
Through unsafe code, all things are possible. You can break `in`, in the all the same way you can break `readonly` (or something like `string`). You just need to use unsafe code (either via the `unsafe` keyword or the `System.Runtime.CompilerServices.Unsafe` static class).
There are a few things I would do differently. **Stylistically** First off, C# is _not_ Javascript. I would start getting into the habit of newlining your brackets. It makes it much easier to read and 99.9% off your C#/.NET coworkers will hate you if you don't use the (basically) uniform C# style. Secondly I would work on your variable names. Some of them are pretty vague and confusing (`i`, `d`, etc). Thirdly your casing conventions are off, all methods (regardless of private/public) should be `PascalCased` (meaning starts with a capital, and each subsequent word is a capital). Methods like `findGreatestValueLessThanTarget()` should be `FindGreatestValueLessThanTarget()`. **On to more technical things** Currently your solution _always_ initializes a new Dictionary _every single time_ the method is called. This is a pretty inefficient solution since Roman Numeral rules haven't changed since they were created thousands of years ago. What is another name for things that don't change? _Static_ Consider moving your Dictionary into a static class member. You can initialize the values of the Dictionary without needing to be in a method: private static Dictionary&lt;int, string&gt; _romanNumeralLookup = new Dictionary&lt;int, string&gt;() { { 1, "I" }, { 4, "IV" }, { 5, "V" }, { 9, "IX" }, { 10, "X" }, { 40, "XL" }, { 50, "L" }, { 90, "XC" }, { 100, "C" }, { 400, "CD" }, { 500, "D" }, { 900, "CM" }, { 1000, "M" } }; Using a static Dictionary will not only prevent unnecessary memory allocation, but it will make your other methods simpler (you wont need to pass by ref back and forth). This brings us to another point. Passing by ref is typically pretty rare from my experience. If a bunch of methods in the same class need the same data source, thats a clear indicator you need a property or a class member. Next, as others have said using: if(intToRoman.ContainsKey(num) == true) Is redundant. An if statement expects a boolean expression. A simple true/false value _is a boolean expression), so your code could just be: if(intToRoman.ContainsKey(num)) Back to the topic of `static`, you could even make your entire class static. The only downside is you could not abstract this out into an interface (so no abstraction/dependency injection/etc), but this is pretty clearly a utility class so its likely fine to be static. This is a benefit because you could run this code without requiring an instance of the class. Last thing is your `findGreatestValueLessThanTarget()` method. You have a `Console.WriteLine()` in there. I am not sure if this is just leftover debug code or not, but typically your class and methods should have one responsibility. `findGreatestValueLessThanTarget()` should only "find the greatest value less than target". If you want that value written to the Console you should have a method that calls this class and writes the values to the Console. This point is a little harder to explain over a textbox but I hope that makes sense. I made an attempt at the problem to see how I would solve it to compare to your solution. If you are interested, the paste bin is [here](https://pastebin.com/bxi2HQbL) 
The statement should actually be: &gt; you should never pass a non-readonly struct implicitly as `in` parameter For: ``` int DoAggregate(in FairlyLargeStruct largeStruct) { int result = 0; foreach (int n in _data) result += n + largeStruct.N; return result; } ``` Doing `return DoAggregate(new FairlyLargeStruct(42));` or even: ``` var x = new FairlyLargeStruct(42); return DoAggregate(x); ``` May cause a copy. While doing: ``` var x = new FairlyLargeStruct(42); return DoAggregate(in x); ``` Should force the compiler to elide the copy, as you have explicitly opted into passing it by reference.
Yes, not sure why the comment is so near the top, it's a fundemental principal of LINQ that the queries evaluate lazily. Especially crazy to acuse the author of not knowing what they're talking about!
use Interlocked.Increment to safely increment the number of files processes. https://msdn.microsoft.com/en-us/library/dd78zt0c(v=vs.110).aspx Since you are closing the Word.Application somewhere, yes you are going to need to create a new one, or re-use the original without closing it.
I don‚Äôt know how I was dumb enough to forget that haha. I‚Äôll edit in a bit. 
I read your answer, no glazing over :) The thing is I was expecting such an answer in a way. I'm also in fin-tech building considerable sized (everything is relative) applications, however we do just fine with a, should I say, traditional approach where only the data or the record itself in the database is as you say the truth. There is probably one key difference, from your answer I'm assuming you do a lot with 'data in time', I lack a better wording. Data in time for me would be a Ledger where a series of events leads to a current state, so I see your point in replayability back and forth. Need to know how this guy went from 10.000,00 to 5.000,00? just roll the events to that state. We don't work with data in time so much, there was one product I remember which was a savings account where we needed exactly this replayability, I solved it completely in SQL, no code whatsoever, but thinking about it now I might be tempted to try and implement an event store for this. Based on my personal opinion and experience we never had any need to split Read and Write operations because of performance, so this aspect of CQRS is a bit moot for me. So, I guess for the things we currently do I don't see a need for an event store and CQRS, that was why I asked the question to get some perspective how this is used in a production environment rather than just being a buzzword.
The main exception I make is for arrays. Having arrays of mutable structs with a few related fields is much more performant than arrays of classes, and much easier to deal with at allocation/creation time.
Getting trained/experience in SharePoint is a "good choice" in that there might be quite a few "enterprise" level jobs out there that use SharePoint. Lots of big companies and various levels of governments use SharePoint. That said, it might _not_ be considered a "good choice" in that the only thing worse than being a SharePoint user is being a SharePoint administrator. Other than that, not sure if I can provide good advice from a _career perspective_ on the subject. You could try giving /r/cscareerquestions a shot; they might have more/better advice on the subject.
I do feel that SharePoint would involve exactly the things you mentioned. Maybe a government position would make for an easier life? As they keep people for maintenance instead of real work at least around here. But getting cushy in the beginning of my career would be really bad. I will look if I can find a better education or worst case I will transition after 1 year of SharePoint work. Or who knows maybe I can get hired to a normal workplace with my sharepoint education. I will crosspost this to cscareerquestions
Thank you very much for the fast response! This really cleared it up for me.
`IComparable&lt;T&gt;` is most useful as a generic constraint (rather than directly using it as a parameter type), e.g. public T Max&lt;T&gt;(T a, T b) where T : IComparable&lt;T&gt; { if (a.CompareTo(b) &gt;= 0) return a; else return b; }
Yeh, it was a big ahah moment for me when I saw the rule for the first time. When I read about it I remember the author also pointed out this rule was something established in C++ programming as a good general recommendation.
That is really interesting, thank you for bringing it up!
Read this https://support.microsoft.com/en-us/help/257757/considerations-for-server-side-automation-of-office TLDR: Your solution will not work cause the office interop classes were not designed for this. One thing you could do is pull down a batch of documents locally and then do your processing. If you read up on the TPL library there are ways to do this in parallel. 
Just installed the UWP dev tools on my machine to check it out and you seem to be onto something. There are neither obvious references to .NET Core nor .NET Framework in the default project VisualStudio creates. That is definitely something I have to further look into and fix the post about. Thank you for bringing it up!
Tried a reboot? Sometimes stuff gets stuck in memory.
I agree that SharePoint could lead to a nice job and you would learn .NET which is in demand, BUT...... Administrating/DEVing Sharepoint is the bane of my existence. Nothing and I mean nothing, is fun or exciting about it. In a month or so I get to go [OfficeSpace](http://gph.is/2d7hw2H) on our Sharepoint server and it is the only reason that I have to live for. 
SharePoint developers are always in demand. Personally I wouldn't do it because I hate SharePoint development. But that just means there's one more slot at my company for people who are willing to actually learn it.
&gt; For example, you could create a class that wraps a private int ID; field. And you would like to have it implement IComparable&lt;int&gt; to directly compare it to other integer IDs. Please don't. This will confuse people maintaining the code months or years after. There no sane reason to implement IComparable&lt;not the same class&gt;.
Those "friends" turned out to be jerks. They were lazy and never worked. :) I'm actually really fond of `ConsoleApplication27` on my work computer.
ya, you got it - it's as much about business needs as data, but quite often is used for performance reasons. Event Store = Ledger - quick books ( or any ERP system) do all of this already, it's a generalization that happened organically out of the accounting concepts. I postulate that every aspect of data storage in an application is " over time" as you put it - it's a matter of how much you care about the fequency of the aggregation. With a typical RDBMS system you are effectively taking an aggregate snapshot at every transaction and throwing away the event. We don't look at it that way, but let'd take a shopping cart example for a second, in the form of an add and delete method. Two basic ways to approach the "nouns" and "verbs": 1) Create a service ICartService with methods Add(ProductId,CustomerID,Quantity) and Remove(ProductId,CustomerId). Those methods update the database, and when you're done you query for the shopping cart details and updater your UI with the full set of data from the cart. 2) you throw an event ProductAddedToCartEvent{ProductId,CustomerID,,Quantity,Date} ProductRemovedFromCart{ProductId,CustomerId,Date} - then write an event handler for the corresponding event. Now here's why I like option #2 - Single Responsibility Principal. Where the magic of IoC starts to play ( if you're not using IoC that's a whole different issue) is that you can scan and close generic types - you write a second event handler that does another action (say updating a cached view model), and the first handler is not touched, and no major regression is needed on it. Then you write a decorator around the grouping of handlers to do a third action when everything is complete. With a similar decorator pattern, you can then add instrumentation to every event handler, and no one has to know that it's there, it just works. We are in Azure, so we use Azure logging, and log performance stats as well as running aggregates of handler types and whether they were successful, warning, error, or exception. A separate process picks up those aggregations, pulls the stack trace of errors, and creates a link to github, creates an issue, writes the line number and error message to the description ( only once per hour)notifying the support team. Another great side effect is that you start to care less about code standards, more about architectural patterns. It doesn't matter how many tabs, curly brackets, or whatever your pet peeve is - instead you write system level static analysis on adherence to expectations. Every command must have a handler. Every handler must have a test. Every test must have an assertion. It gives both more overarching control, and more autonomy to your developers. We have 18,000 tests that are executed at build time, it takes 2 minutes to run and it keeps everyone honest. One last thing - if you're doing UI work you might find this interesting. Someone who I know through the local meetups in Austin wrote an an open course Roslyn based typescript bridge to a CQRS systrm. If you create a new command or query, it will update and generate your API for you, and it'd compatible w/ Swagger in .net Core. We do a lot of Angular and AngularJS (multiple projects, some older than others) - there's a mediator pattern in that same project built to work in Typescript. It extends the whole pattern to the UI, and lends itself well to testing using Jasmine or Protractor, or whatever else kids are using these days. .Net dev updated the API? point to the new endpoint, regenerate your CQRS file and check for compilations in your typescript. Compile time checking of Angular's integration with your API. I suppose that's something I didn't give enough weight to the first response- it's not just distribution of workloads on servers, but team productivity. Once you set it all up, it speeds up workflow for your team. Anyway, something to think about! 
so based on everyone's input, parallel isn't really good for my case. I shall stick with LINQ or foreach. Thanks everyone for their input
Your first choice was published 16 years ago; how relevant is it today? It‚Äôs also worth noting that the 4th edition of C# in Depth will be published this fall and will focus on versions 5-7 of the language. An early access version is available now with all but the first 4 chapters. It comes with the ebook version of the 3rd edition as well. (If you look around the web you should be able to find a 40% off coupon code for Manning.) The details are here: https://www.manning.com/books/c-sharp-in-depth-fourth-edition