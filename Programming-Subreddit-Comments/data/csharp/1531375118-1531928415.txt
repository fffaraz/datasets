&gt; We are not anti-pattern like what Dapper did. Can you elaborate on that?
How stable is this library? Looking at the code on GitHub, I can't find any tests. Dapper has an extensive suite of unit and performance tests.
Thank you for this concern. That's the reason why the library was still on Beta5 right now. The code is now being used for regression testing, and our team is using it right now in some small projects. Dapper is still the one we used in Production until we stabilized this library. It will not take long to stabilize this as we are very active in development. We are now writing the Unit Testing and Regression Testing on this one. Thank you for this comment. For now, the library is on Beta and if any bug comes, please report it directly here.
Not proclaiming to be an expert on the topic but I am writing an application myself that is using spellchecking and I utilize the Interior.Word add-on with a custom dictionary for terms and word that are specific to the text I'm checking. Does it work? Yes. Is there a better way? Probably.
I just tried this string r5 = ""; double t3 = 0; var sw3 = new Stopwatch(); sw3.Start(); var query4 = from kh in db.CodeDeviceKeyholes join linked in db.LinkedKeyholes on kh.ID equals linked.ID into counts select new { kh, counts.ToList().Count }; r5 += query4.Count().ToString(); sw3.Stop(); t3 += sw3.ElapsedMilliseconds; it shows 4ms now; so it 50 times faster
Thanks! I will use it!
no. So if I complete them in orded in my OP post, I get 200 ms for the first one, 650ms for the second one and 4 ms for the LondonPilot one. But If I switch first and second ~800 ms for second and first and 11 ms for the last. Jesus Christ, what is going on?? I think I force the execuiton of the request by doing something like this: query.Count().ToString(); which I write right after the query. Maybe I am wrong? 
I am fairly new to designing SQL tables. I did the following: the first table entity has unique ID (in form of GUID) and some columns; the second table also has unique ID (in form of GUID), other columns and a column which "reference" the first table in form of Foreign Key. Like that: CREATE TABLE "tbCodeDeviceKeyholeImages" ( "ID" uuid NOT NULL, "CodeDeviceID" uuid NOT NULL, "Image" bytea, "Markers" text, "CodeDeviceName" text, "BlankTypeID" uuid, CONSTRAINT "ImageKeyHolePrimaryID" PRIMARY KEY ("ID") ) and CREATE TABLE "tbLinkedKeyholes" ( "ID" uuid NOT NULL, "KeyholeID" uuid NOT NULL, "Image" bytea, "Markers" text, "Name" text, CONSTRAINT id_unique PRIMARY KEY ("ID"), CONSTRAINT khid_equals FOREIGN KEY ("KeyholeID") REFERENCES "tbCodeDeviceKeyholeImages" ("ID") MATCH SIMPLE ON UPDATE NO ACTION ON DELETE NO ACTION ) I was just following examples which was made by somebody before me. Is this schema wrong? 
Do you need a separate license for word add on or is it included in the visual studio. 
&gt; Principles: &gt; We will never ever do try-catch inside the library Why?
Thanks for reading the documents. We will make sure that library would do as expected based on the user's activity. That's true that you can never see try-catch-finally block there. We are sending back the exception to the developers. We cannot see any scenario why swallowing the exceptions or composing a new one. However, we have the scenario of validations (of like PrimaryKey validation) and throw the error back to the developer if the PrimaryKey is missing. In some some scenario like calling of &lt;connection|repository&gt;.&lt;Delete|Query&gt;(primaryKey), there are some validations. We have a lot of debate on our case here in the company, but in the end, this would help the developers figure out the exception. Example. In DTO class, you added a field named "FirstName", where as in the database you actually have "FName". Upon running the operation, the ADO.Net would return a "field exception" and we are not swallowing it, instead, we are just letting the runtime show that exception back to the caller. I hope you get our point here.
What you have isn't necessarily wrong, but it's not well-suited for the particular query you're trying to perform. Depending on how much data we're talking about, that might not actually be that big of a deal, and there's a cost to having additional indexes in both disk space of disk space and write speed, so it's a bit of a balancing act deciding what to include and what to omit. But in this case, I would make two suggestions. 1) Add this line after your second create table: CREATE NONCLUSTERED INDEX IX_tbLinkedKeyholes_KeyholeID ON tbLinkedKeyholes(KeyholeID) I'm not familiar with this flavor of SQL, but that syntax ought to work. This will address the grouping on your foreign key issue and should solve your speed problem. The name "IX_tbLinkedKeyholes_KeyholeID" can be changed to whatever you like, but the more descriptive, the better. Basically, this index works as a cheat sheet for KeyholeID, with each KeyholeID value listed in order along with a link to the parent row. This lets the database engine quickly count up how many of each KeyholeID there is without having to scan the whole table and hunt around for each value. With nonclustered indexes, you can also include extra fields on the cheat sheet if needed, but since you're just counting that won't be useful for this. 2) uuid is expensive in pretty much every aspect. Each uuid is 16 bytes apiece and since each value is completely random, data gets shuffled around a lot when new rows are added if it's on the primary key, which can lead to fragmentation and a significant performance impact unless you maintain it frequently. The main purpose of a uuid is for when you have to assign an ID to a piece of data and you don't have an opportunity to consult the table for what the next available keys are, so it picks a very large, very random number to minimize the chance that that key is taken. For most purposes, if you don't have anything more meaningful, you'll typically define ID to be an identity field, which should look something like: "ID" int NOT NULL identity(1,1), This tells the table that each time a new row is inserted, a new value is assigned to ID, starting at 1 and incrementing by 1 for each subsequent row. When used with Entity Framework, the identity field will be updated on the entity once it's written to the table.
Looks very nice. Are type mappings on property level (Customer.FullName as nvarchar vs Customer.Email as varchar) possible? Composite keys?
Thank you for reading the documentation. No, the type mappings are only working on the Type level, not property level and is only one way. Meaning, the CLR .Net Type will be converted to desired DbType if you specify the type mapping properly. ``` TypeMapper.AddMap(new TypeMap(typeof(Decimal), DbType.Double)); ``` In the case above, all DTO class property with ``System.Decimal`` CLR .Net Type will be converted to ``System.Data.DbType.Double`` data type prior the execution of the actual ADO.Net SqlCommand Execute&lt;Methods&gt;. I will take note of the property-level type-mapping, this is a bit old school and would impact the performance of the library. But we will think of it. Documentation: https://repodb.readthedocs.io/en/latest/pages/typemapping.html
I have read this and will get back to you with correct explanation. We need to be accurate on our answer here.
One-way means, only from .Net application to DB. Not from DB to .Net application. Just FYI.
XAML came after Windows Forms, so give up the idea of XAML. You can view the "code behind" and the designer at the same time and place the windows in Visual studio to be one above the other, but the code is generated, so you have to be careful about how and what you change because it "may" get overwritten. In Solution explorer, create a new Winforms project, you'll see Form1.cs. Open the form in the designer and drag a button onto it. Unfold the item in Solution explorer and you'll see Form1.Designer.cs under Form1.cs. This is where the code that is generated goes, so you can see how the controls are added and placed. If you open the "Windows forms generated code" section you'll see some C# with the button, it's location, size, etc. You can edit all these things, but there's no XAML, it's all code. As you gain experience you'll rely less on the designer. Back when I did Winforms, most of the stuff I did involved setting up the basic layout in the designer and then everything pretty and functional happened in my own custom control code. But there is no XAML, the designer is just a graphical view of C# code. As an aside, you can actually do WPF in the exact same way. Have an empty XAML and then use C# code to add controls. I wouldn't recommend that in most cases, XAML was a huge step forward.
Have you measured the size of the 50,000 contacts? Where are they being stored? A database or do you have a server "endpoint" you're querying? Do you have to worry about several users updating the contacts and other users expecting to receive those updates automagically? A drop down could work if you stick with paging, a slider would probably be better imo with a label indicating the current page. But try loading all 50000 into memory and see how much space they take, it might not be as much as you think. WPF can be quite clever about being data bound to a large ObservableCollection for example and only rendering the visible bit. So we tend to let it do the heavy lifting where viable. 
&gt; I don't have the ability to alter the web service implementation on my end, so I can't make it async async/await doesn't change the networking protocol. If you change the webservice client on your end to using *Async methods, it's not going to affect the API. Also, you might want to checkout [`TaskCompletionSource`](https://docs.microsoft.com/en-gb/dotnet/api/system.threading.tasks.taskcompletionsource-1?view=netframework-4.7.2), which can be a "shim" between sync and async code.
No. Windows Forms doesn't support XAML. You're stuck with the Windows Forms editor.
It looks really nice. I'm (very slowly) doing a rewrite of our main (mobile unfriendly and webforms based) website and could see myself switching from Dapper to this as it has a bunch of things I always missed with Dapper or I had to do in a roundabout way. But one thing seems to be missing (or I can't find it): Objects with other objects as properties or a list of other objects. Something you'd solve in dapper with `QueryMultiple` or `Query&lt;T1,T2,T1&gt;` Is there anything like this available in RepoDb? Or planned?
I tried to run the standalone exe as 64 bit and it works just fine, so it must be something that doesn't work in 32 bit mode. I tried to run Veldrid's NeoDemo in 32 bit mode, and it also experiences problems. It's not the same problem, instead i get this: Unhandled exception at 0x0FD9372E (coreclr.dll) in dotnet.exe: 0xC0000005: Access violation writing location 0x0FD9380E. The call stack points to this function: https://github.com/dotnet/coreclr/blob/3fb4483277c7b12841b9ea7672bccdc6f23d3d52/src/vm/stubhelpers.cpp#L1011 Complete call stack: https://pastebin.com/hzr5C2LG The Veldrid codebase is completely unmodified aside from the ImGui renderable code and the menu code being disabled in the NeoDemo program. I ran it with the 32 bit dotnet executable and used the 32 bit SDL2 library provided in the Veldrid repository. u/ironstrife i will create an issue about this on the Veldrid issue tracker.
It's because you're doing all the work on the same thread. This way your program has to finish the CopyAll()-function, before it can do something else. In your case updating the label. This is why you have to offload heavy processing to another thread, so the UI doesn't get blocked. Microsoft has a good article about this: https://docs.microsoft.com/en-us/windows/uwp/debug-test-perf/keep-the-ui-thread-responsive It's written specific for WPF, but it also applies to your situation. Let me know if you have any more questions!
`IQueryable` isn't slow by itself. It should only be slightly slower than your expression tree implementation. It's up to you what parts of the `IQueryable` ecosystem are supported and if the SQL statements aren't living up to your standard: Just fix the translation (from the expression tree to SQL) in your library. `IQueryable` is just there to build an expression tree and it depends on you what you do with it.
Hi @CWagner, thank you for your kind words and interest. In RepoDb, we have implemented it differently. We have modelized our approach same as EF or NH. We called it RecursiveQuery (this is very very fast compared to EF and Dapper's Recursive Query approach). This is the newest feature we introduced at Beta4 and Beta5 (RecursiveQuery, RecursionDepth, and Cyclomatic StackOverflow Complexity). See below our samples. Your models. ``` public class Customer : DataEntity { public int Id { get; set; } public string FirstName { get; set; } ... public IEnumerable&lt;Order&gt; Orders { get; set; } } public class Order : DataEntity { public int Id { get; set; } public int Quantity { get; set; } public double Price { get; set; } public int CustomerId { get; set; } } ``` In the **Query** operation, you can just set the **recursive** parameter to **true** when querying the data. See below. ``` using (var connection = new SqlConnection(ConnectionString)) { connection.Query&lt;Customer&gt;(new { Id = 1023 }, recursive: true); } ``` The code above query the customer with Id = 1023 and its corresponding orders. If your criteria returns multiple rows, each customer row will contains its orders. **Note**: This is **very very fast** to the point that we made **15 seconds of Dapper and EF down to 2 seconds in RepoDb** when compared to the legacy approach recursive-data-retrieval. We have made a different logical approach in RepoDb and this is the thing that we are advantage actually. Video: https://www.youtube.com/watch?v=dv1jCZcqBEE
Ah, so it does this automatically? I'm guessing it can handle multiple variables in a single string?
Does it do streaming well? As in, processing a billion records, but not run out of memory by only loading in memory what you're processing. Weirdly enough, dapper doesn't really do that well w/o extensions, but if you configure EF right, it can actually manage that with some decent performance.
No streaming included on the implementation. I will discuss this with my fellow architects. But, one thing we can share, it is a batching approach of querying the data from the database (where we limits the iterations) by utilizing the query tree expression (**IN** operation) of the library. Then, bringing back to the client all the **affected** data and process everything in memory via IL.
I am personally not using EF anymore after the problem they give us on the weird SQL Statements if we're joining multiple entities. I might be bias on this, but they impose to create sub queries that eat-ups a lot of memory and slow down the performance. We will not gonna compete with IQueryable, but we will maximize the use of Dynamics in RepoDb. That's all the reason why Dapper was created. IMO
Many thanks for your comment! The problem is I have to maintain my version of postgresql (8.3) to ensure backwards compatibility with old devices. I tried to use the latest one (10-something), and it downloads images from bytea columns incorrectly. 8.3 does not have identity field. I found info about that index though and will try to implement it. 
Two possible ways you could approach this: 1. What (small) problems do you experience yourself that could be fixed with a small software tool? The "scratch your own itch" approach. This is good for learning. 2. If you want to build something that you might want to sell at some point, first do a bit of research on pains your audience is experiencing. Reddit is a great source of pain. Plenty of "painspiration" here.
&gt; Have you measured the size of the 50,000 contacts? Nope. Not really sure how I would and I actually don't understand why I should. Could you clarify? &gt; Where are they being stored? A database or do you have a server "endpoint" you're querying? SQL Server LocalDb. &gt; Do you have to worry about several users updating the contacts and other users expecting to receive those updates automagically? No, each installation of the software manages its own list of contacts. Only commonality between every installation is the remote database where leads data is stored. Each lead, therefore, is linked to a "SoftwareId" GUID that gets saved at install into the client's system registry. &gt; A drop down could work if you stick with paging, a slider would probably be better imo with a label indicating the current page. A slider? I have a label indicating the current page... Slider looks like there's potential there. I like the idea :) It would still rely on the standard paging logic right? Only thing is I believe paging on the slider would still have to be done on the property change, right? I'm currently loading by buttons because I can do it async that way... Something I don't believe is possible on property changes... &gt; But try loading all 50000 into memory and see how much space they take, it might not be as much as you think. Now I'm understanding the measurement question :)
Be very careful how you batch. A lot "naïeve" approaches (offset/fetch next, skip) use index-scans, which perform pretty terrible at scale. Maybe make it configurable? The optimal strategy often depends on how your keys are distributed and how the table is indexed.
EF just utilizes `IQueryable` (and the produced expression trees), but `IQueryable` != "EF" and `IQueryable` != "SQL statements produced by EF". You don't need to compete with `IQueryable` (which is just the standard way to create expression trees), but you may (should/will?) compete with EF and its butt-ugly SQL statements. The dynamic expressions in your documentation seem very unintuitive and nothing that I'd like to use, but that's just my preference.
FYI: On reddit you make codeblocks the old way, 4 spaces indentation. Thanks, I'll play around with this :)
Oh and a follow-up question: Is it possible to `order by` the subquery? 
I did see this doc! Okay, so using this as a reference, I've appended my copyAll to this: public static async void CopyAllAsync(DirectoryInfo source, DirectoryInfo target, Label ProgresserLabel) { Directory.CreateDirectory(target.FullName); // Copy each file into the new directory. await System.Threading.Tasks.Task.Run(() =&gt; ComputeNextMove(source, target, ProgresserLabel)); ProgresserLabel.Visible = true; ProgresserLabel.Text = fi.Name; I had to change it to async because it needs to be async in order for the await operator to work. And my 'computenextmove' is this public static void ComputeNextMove(DirectoryInfo source, DirectoryInfo target, Label ProgresserLabel) { foreach (FileInfo fi in source.GetFiles()) { Console.WriteLine(@"Copying {0}\{1}", target.FullName, fi.Name); fi.CopyTo(Path.Combine(target.FullName, fi.Name), true); } } So, I have two questions. 1. when I run this, the await doesn't seem to wait for the foreach loop to finish. It just ploughs on while it's running. What do I do to sort that? Ideally I just want to free up the main thread so the UI can update while the ComputeNextMove thread runs it's course. After it's done, then the thread is closed, and the main thread continues. 2. Where do I put the label update? I can't put it outside of ComputeNextMove because fi.Name (which is what I want to use) is defined in the static void, which is a problem I had before. And I can't put it in ComputeNextMove because it's back to square one again, and the UI update will be on the same thread as the one doing the work. Sorry for my ignorance if these are all obvious questions!
Something like Facebook's [DataLoader](https://github.com/facebook/dataloader)? Instead of doing 1 `Customers LEFT JOIN Orders` query and manually splitting or 1+N queries you're doing an 1+1 query (`SELECT FROM Customer... , SELECT FROM Orders WHERE CustomerID IN (1, 2, 3...)`?
&gt;What about things like mocks? If you start adding functionality to default interfaces that are supposed to be DI'd, you can no longer mock that interface for it to return what you expect, it's already a default implementation. Can you elaborate on that? Interface implementations are virtual by default, and that can only be changed by using the sealed or private keyword as per the current proposal. I think that would be the only way to restrict mocking a specific interface method.
Yeah, " Like why use one pattern over another, what is clean code and how can you write it, and what are some security mistakes that many coders make, on a conceptual level. " sounds like theory to me :)
Basically, yeah - C# happened because Microsoft wanted to do things with Java that Sun wouldn’t allow or wouldn’t do or disagreed with. It’s basically Java with a bunch of things developers wished Java did 
This is absolutely correct, but we are batching it at 256. Right now you can see the value of the batch at the (https://github.com/mikependon/RepoDb/blob/master/RepoDb/RepoDb/Constant.cs). Thinking if I can expose a class named RecursionManager to process the configuration based on the business scenario you needs.
If you are only creating that class only once anyway I don't understand why you need static fields at all. If you are using dependency injection then singletons are usually used instead of anything static. If you are going with static field route you should use static constructor for static fields. Initializing static fields in normal constructor isn't thread safe. I'm not sure how you are populating your data but loading files or connecting to database in constructor is bad practice. Constructors should be fast, use static factory methods instead for slow construction. They also support async await unlike constructors. I wasn't advocating to use Lazy&lt;T&gt; in tight loops. You just use Lazy's Value property once to load value in local variable before your loop. You should really look how Lazy&lt;T&gt; works. It's initialization is by default also thread safe. That means it's initialized only once even if multiple threads are calling Value property simultaneously.
RepoDb supports ordering on the current entity level only, and not on the recursive entities. Meaning, if we have the ``Customer`` object as the parent entity, the ordering will only affects the ``Customer`` result. See below the sample. ``` using (var connection = new SqlConnection(ConnectionString)) { var orderBy = OrderField.Parse(new { CreatedDate = Order.Ascending }); var customers = connection.Query&lt;Customer&gt;(top: 100, orderBy: orderBy); customers.ToList().ForEach(customer =&gt; { // Process each customer here }); } ``` Documentation: https://repodb.readthedocs.io/en/latest/pages/repositoryoperations.html#ordering-the-result
This is a critical point to me. Couldn't risk my production code and my business on a library without a proper test code coverage.
As someone used to write production code with TDD this sounds sub optimal. How will you validate and trust future pull requests from external developers? It sounds a lot of work to check they don't introduce unexpected behaviors. Also, you told you will be adding tests as a second step. I bet you will try to make them pass. But, if there's a bug in the code, you risk to write a green test confirming the bug, don't you? How could you protect from this?
This is a very good response. Yes, that's true. The ORM only works on the client side, one should know about optimizing the database itself (let say indexing the proper keys, data files, partitioning, column store, etc etc). RepoDb would assume that every "Id" field is indexed properly in the database, if not then you can add an attribute of your **PrimaryKey** field in your DTO class. But RepoDb is intelligent enough on identifying the **PrimaryKey**, I have documented it here (https://repodb.readthedocs.io/en/latest/pages/attributes.html). The recursive query is dynamic with this attribute called **[Foreign]**, though I am not campaigning to use the attributes in RepoDb (as I hate attribute), but we cannot skip this one. You can maximize this attribute to make sure the correct index-seeking activity in the database. Sample code below: ``` public class Customer : DataEntity { public int Id { get; set; } public string FirstName { get; set; } ... [Foreign("Id", "CustomerId")] // You can change your setting public IEnumerable&lt;Order&gt; Orders { get; set; } } public class Order : DataEntity { public int Id { get; set; } public int Quantity { get; set; } public double Price { get; set; } public int CustomerId { get; set; } [Foreign("CustomerId", "Id")] public IEnumerable&lt;Customer&gt; Customer { get; set; } // Including the parent (traverse activity), could effect Cyclomatic Stackoverflow Complexity (which we also resolved) } ``` Hope this explanation helps!
Whatever ItemsControl-derived control you are using, be sure to enable virtualization on it. This will prevent WPF from creating all items within that control upon load and it will only create them when they are close to being visible by the user. So if you have all 50,000 records in memory, you don't want WPF to create 50,000 textboxes, you want it to just create ones that are visible. This could be causing your problem.
Thank you @FubarCoder, we appreciate all the feedback and we respect it. This helps us a lot to improve our ways. But with **RepoDb**, just FYI, it has speed-up our process in development, structuring, patterns (Repository) and the best performance we can gain. Again, you can still use Linq in IEnumerable after retrieving the data from the database in fast manner. **RepoDb** will address the performance and simplicity of use, if we have not leveraged the IQueryable, maybe because used into **Dapper** already which does the same thing, maximizing the **dynamics** and by preventing the SQL Injection attacks. Thanks again.
Our Solution Architect is pushing me stabilized this as an Application Architect. That's the reason why I cannot place a final release right now, we are still in Beta5 as of writing this as we are still start to protect the code and scenario via Unit Test. But we are also targeting the Regression Test and not just Unit Test. We will update it here once we have done such scenarios. Thank for your inputs.
Never mind dude, I got it! I'll edit my original post to show how I did it. 
&gt;if I had to guess it's mainly because default parameters weren't originally part of .NET and many non-.NET languages do not have similar code constructs, so people are doing what they're familiar with. For "final" applications with nobody downstream that depends on you, use as many default parameters as you want. For libraries, it's more complicated. Default parameter values are compiled into the **caller**'s code, because that's kinda how it has to be in order to make those "niche" use cases work. A consequence of compiling them into the caller is that you can't change the default value of the parameter in a later update unless everybody downstream recompiles. You also can't add more default parameters to an existing method in a later version without breaking binary compatibility (but you can do this with an overload just fine). There are few instances where I advocate for using default parameters on visible methods in a library. The only situation I've come across so far is `CancellationToken cancellationToken = default` on new methods that support cancellation and have never been released before, since there's realistically no other token that will ever make sense as a compiled-in default.
Love this idea... Unfortunately, here's the client: &gt; I would prefer the ability to select the page I want to go to and then click load. I just don't have time to sit and load 50 pages to get to page 50
One advantage to #2 that I don't see mentioned in this thread: "find all references" is, IMO, **much** more useful when you go with #2 than with #1. This is based on my experience with vanilla VS2017; I don't recall if R# or CodeRush had better versions of "find all references" that would make this better.
Get a count of items so you can calculate the number of pages, then only retrieve/render details for the current page 
We do it like this: * On start : Get total entries count, set `currentPage = 1` * Have a TextBox that, on pressing Enter, sets `currentPage = INPUT` * get total entries count, validate if page exists, show Page * If Invalid page, redirect to last page (if &gt; total) It kinda looks like `&lt;&lt; | &lt; | 50 | &gt; | &gt;&gt;` Since it is a Desktop Application and most of our clients data is on their own servers, the database load is not significant (we have clients with sizes of 50 ppl up to 1000 ppl)
We will surely do before we even move to “RC” library. There could be one more “Beta” or “Beta5” is the last “Beta”. Rest assured we will write Unit Test, Regression Test and will share it to everyone. We do not want to get blamed and by being in “Beta” for now is our protection. But everyone can play around this library already or use it in small and non-critical applications.
I will be the first person to beat the person to deceive this library when it comes to implementing the Unit/Regression Testing. We will never do that as we are to use this in the future on our Production apps as well. I will also share the Unit/Regression Testing that we writen so everyone can have a say whether it is a shallow or deep testing methods.
Along with what /u/locuester said, nullable types aren't tricks, either :-P.
I used to create console applications when I was in college -- they were object oriented, they pulled and put information to several employees according to if they were salaried, hourly or temporary. However, I am open to learning new things and see how they work. I just want to get some practice going. Thank you.
I might start to do that. I just want to "translate" programs into GUIs. However, I will take your advice as well. Thanks.
Second this. And even if tests are on the todo, it's a little troubling that it wasn't just a part of the process to begin with. Adding tests after the fact is not TDD, and the results will not be sufficient.
Better to use DateTime.UtcNow, because [DateTime.Now](https://DateTime.Now) uses the CurrentCulture to transform it, and it is a LOT faster for many calls. Note: [DateTime.Now](https://DateTime.Now) should only be used for displaying Data in the wanted Culture. For anything Database/Storing/Variables it is encuraged to use DateTime.UtcNow or even DateTimeOffset. &gt; These uses for [DateTimeOffset](https://docs.microsoft.com/de-de/dotnet/api/system.datetimeoffset) values are much more common than those for [DateTime](https://docs.microsoft.com/de-de/dotnet/api/system.datetime) values. As a result, [DateTimeOffset](https://docs.microsoft.com/de-de/dotnet/api/system.datetimeoffset) should be considered the default date and time type for application development. 
SyncFusion’s Succinctly series (they have their own app) can be a great way to get an overview of a few new technologies for those familiar with C# already, or to read up on things like security or neural networks.
Good for you. For some people technology is a hobby, not just work.
I cannot reason out on here, we have a skeleton project for testing and you can see it at the repository at github. I am just lazy enough to code it first, than to develop the feature and do the on-the-fly testing and created a small test project to test each operation. But in the end, we are testing this on a small project we have, of like implementing Regression Testing scenarios for our client and does not required Production Deployment. Thanks for pushing this, now I know how to prioritize things up.
I use EF primarily at work and I know where you're coming from. However, it's the drivers fault for bad queries. We especially see a lot of poor queries (queries including sub queries) while using Oracle's MySql driver's which are the standard MySql driver's for EF, especially when using navigation properties and sorting. We do not see these same issues with the MSSQL driver when using MSSQL, nor in the devart driver for MySql. I still thinks there's a big place for this repository, though. Standard EF is bad at doing bulk operations since it wants to pull data into memory first a lot of the time. Bulk deletes are especially an issue. We find ourselves needing to use ExecuteSql() in order to have any performant bulk delete which is a big problem. And we don't want to have to pay for software such as devart or EntityFramework-Plus just to extend functionality that should already be there.
Microsoft Office Word and Visual Studio are different products. To use any microsoft office word integration with software will require a CAL license per user of the final product.
lol was this your homework assignment? ;)
Not sure if this suits your needs but there is a IsDesignMode for controls that I believe let's you render a default template. https://msdn.microsoft.com/en-us/library/system.componentmodel.designerproperties.getisindesignmode.aspx and https://msdn.microsoft.com/en-us/library/ms171820.aspx
If Avro is purely json, then I believe you can edit &gt; paste special &gt; json as class (with webessentials extension for visualstudio). Otherwise, give this a shot: http://json2csharp.com 
Your library does not handle any reconnection attempts internally? 
I can pretty much guarantee you that the developers working on the project 5 years from now will hate you for choosing someone's pet project as your orm when it's long outdated and unmaintained.
No....
String interpolation will not work. You will have to use string.Format() and likely paired with a dictionary: var d = new Dictionary&lt;string, string&gt;() { {"a1", "{0} bar {1}"}, }; var s = string.Format(d["a1"], "foo", "baz"); // s: "foo bar baz" 
Sounds like this is a Data Mapper and not a full blown ORM. I'll read the docs and check.
Is the one in Blend better? At the time when I did some silverlight, people used blend for doing visual/wysywig design.
I attended a talk last year with an ex-microsoft guy who had worked in a bunch of areas in the company and he said blend used a different, and better, designer.
Confirm it's not a network/compute resource issue and work backwards from there. What does the browser/webclient profiling show (f12 on browser)? What does the nginx/apache/iis log show? Set breakpoints in the source code around the "slow" areas and step through the code and look at the evaluation times in the diagnostic tools
Interpolation looks much simpler than your suggestion. Could you explain why yours is better?
a) I plan to have the whole thing somewhat pluggable so that exchanging it would completely happen in the data project that returns DTOs. b) The current code "grew organically" since 1996 and is an utter mess of direct ADO.NET, IDataReaders, DataTables and EF scattered all over the whole project. If RepoDb stops being developed right now at Beta5 I'd still be better off than I am now. c) With my current development speed, I won't get anywhere close to being done in the next 2 years and have enough time to evaluate the RepoDb development.
It is a direct plug-and-play. Yes, it does not do any reconnection attempt currently. The developer itself is the who is controlling the **connection** object. But, I think, I can only include this feature in the BaseRepository/DbRepository class where the ConnectionPersistency = ConnectionPersistency.Instance. I will take note of this.
There's no XAML in WinForms, but you can add controls programmatically. Create control -&gt; Give it attributes -&gt; this.Controls.Add() it.
I don't have any problem using "this". IMHO, both ways are ok.
You guys just do not know that your small words has big impact on a developer like me. Never it will happen that RepoDb development will stop. So many people tried to criticize this in early stage, and I had to swallow it all. I'll make this library runs 40&amp;#37; much faster than it is today. I will use this on my new role as an Application Architect on my company. Thanks and 2 thumbs up!
I will not pinpoint, new thing comes out with some development and improvements. Maybe I just liked working with ORM and is eager to improve the dynamic fast-switching approach between massive and lightweight ORM operations.
Yes, but it requires a lot of effort to make your custom controls compatible with a designer. I usually don't bother and write everything in raw XAML.
Because string interpolation is compiled to string.Format(). You could use string interpolation but it'll have to be a Func or a separate method.
What are the specs of clients running the app? 50k records is not much unless you need to load binary data like images. You want to page the UI since loading into the control and creating 50k elements will slow WPF but the back end query can happen pretty quick and 50k records of the handfull of vital info is in a user record is not that big. Your biggest hit in WPF land is always the rendering of controls and binding during initial render. You need to be very sloppy with LINQ to beat WPF there.
Nope you just have the static designer and bindings to events. Its why this type of app was replaced with the more flexible and developer friendly WPF. You can still do MVVM or MVC patten if you want, it does tend to make your code more sane looking. You just dont have data binding so you have to do that in your "codebehind".
The designer does suck, but there are things you can do in code, e.g. IsDesignMode that can improve the experience. If you weren't aware, WPF (mostly) allows live editing when in debug mode, i.e. start debugging your application, then change a grid proportion, and the live application will update along with the code change.
The c# spec defines a property of methods called signature. Adding a default parameter alters the signature. Within the newly compiled assembly all the existing call sites are desugared and invoke the new method. The existing assembly which have dependency on the new assembly will have binding errors because they are trying to bind to a method with an invalid signature.
You should maybe try look into virtualizing lists which could allow the performance benefits while still allowing a simpler interface.
I think it's pretty important to prevent ambiguity in your code. Private fields should pretty much be the only things that hold state in an object, they should at no point be confused with parameters.
Try .Net 4.6.2 instead. It's the first version of .net to use TLS as a default for http connections. It would rule that it as an issue.
Just FYI, PayPal seems to have changed several other things about their API (which was already super janky) without notifying anyone or documenting the changes in their patch notes. For me, they also changed their CORS settings and payment type options. Just mentioning it because it might not be specifically a TLS problem - the IPN message might be getting blocked or something and then the page only refreshes after the client polls the server for a result... It depends what product you're using. Anyway, don't trust that PayPal's documentation is accurate or up to date. They don't put much effort into developer support.
Is there any way of doing it without using Microsoft Word (buying license not feasible) ?
Well, I was trying to find a way to be able to be able to rebuild my app at any time I wanted with VS then be able to easily execute it as if it was fully deployed. However it seems that's not possible. So I ended up doing this: Creating a Bat File so i can have the console output and be able to execute it from desktop very easily, then in this bat file execute a powershell script to actually run the dotnet application. Bat File: @ECHO OFF Powershell.exe -executionpolicy remotesigned -File [directory] Powershell Script: cd [directory] dotnet run I knew i could have done this all along and it's simple but i wanted to find a more clean and not very like roundabout way to accomplish this in the way I wanted to.
I write everything in XAML because I find it easier, especially since dynamic controls can't even be displayed in a viewer (I'd just be empty!)
:) You've got it :) You can still do it async with a slider, it's actually a good thing to learn. [There's a little article here which talks about async with cancellation](https://blogs.msdn.microsoft.com/dotnet/2012/06/06/async-in-4-5-enabling-progress-and-cancellation-in-async-apis/) and you might also want to look at RX, but I can't find a reference as I'm travelling! Yep, the slider idea is sort of preferable in one way in that you can slide it from page 1 to page n and it becomes a bit more natural than having to find the page in a drop down. What you want to do is not make the call to the DB until the slider has stopped moving for say 500ms. You then want to be able to cancel the previous async call (or disregard it depending on what it's doing) if the user decides to start moving again. If your UI is quick, you can actually have it page in as the user moves the slider which can make for a really nice experience. Do experiment with the in memory idea though if you get a chance. It's always the silkiest experience, but it depends on the memory cost. You may not need the entire record in memory, have select fields that need to be immediately visible in the list, and only load the full details when you need to. Good luck :)
&gt;As I'm going to programm addons for SAP, I need to use Windows Forms, cause that's what SAP uses. Are you sure? WinForms and WPF have some limited interop ability (you can host one inside the other, though in practice, there's a lot of caveats). If you're trying to embed some SAP control inside your app, or vice versa embed a control of yours inside the SAP app, that interop might be enough. And if you don't interact with SAP's UI at all, it shouldn't matter if you use WinForms or WPF. &gt;Is there a way to get somthing like this in Windows Forms? I want to see the window and the XAML code for this window simultaneously. WinForms doesn't work with XAML or a similar concept. It has no declarative UI language. Instead, the designer uses code-generation to serialize — i.e. upon save — (this ends up in a special method `InitializeComponent`, which is typically moved to a `separate *.designer.cs` file in .NET 2.0 and newer), and code _execution_ (it calls that method) to deserialize — i.e. upon initting the designer the next time. It's kinda clunky, has funny (and some not-so-funny) bugs, and basically doesn't scale to complex controls. You want to keep your forms simple and move stuff to separate user controls. But also, it doesn't support _abstract_ user controls; the designer has weird bugs when you try to do that. It also generates a ton of _superfluous_ code; it isn't very smart about knowing which properties it has to set on new controls. And, unfortunately, it occasionally yields redundant "changes" (that don't actually change anything meaningful) in your version control. Sorry about that rant. It's… fine, really. Just don't build huge complex stuff with it. Instead, look at how InitializeComponent works and init your controls yourself — it can be as simple as: var label = new Label(); label.AutoSize = true; label.Location = new Point(10, 10); label.Text = "Foo"; this.Controls.Add(label); Much cleaner, shorter, and you've explicitly described your intent.
Try adding the following into your code before making your web service call: `ServicePointManager.SecurityProtocol |= SecurityProtocolType.Tls11 | SecurityProtocolType.Tls12;`
Try a tool like Fiddler, Wireshark, whatever to see if the TLS 1.2 handshake actually looks right. &gt;I currently have a very dated 3.5 site. .NET 3.5 _does not support_ TLS 1.2 out of the box, but [there's a patch for that](https://support.microsoft.com/en-us/help/3154518/support-for-tls-system-default-versions-included-in-the-net-framework). Really, though, you're in for a world of pain. Upgrade it to .NET 4.x.
Just take any console based tool you currently use and write a c# GUI Wrapper. Look into System.Diagnostics.Process it can be as simple as Process.Start("File.txt") to taking control of the input and output streams to provide feed back. 
Reviewing the 4.7 [changeset](https://github.com/Microsoft/dotnet/blob/master/releases/net47/dotnet47-changes.md) it looks like that's the one that uses the underlying operating system TLS version. The 4.6.2 [changeset](https://github.com/Microsoft/dotnet/blob/master/releases/net462/dotnet462-changes.md) added some suppport in ClickOnce apps - but I don't see any other TLS changes within that. https://docs.microsoft.com/en-us/dotnet/framework/whats-new/ If I'm missing something here just let me know - dealing with TLS issues these past few months (thanks PCI DSS!) has been insane haha. I've been pushing to get more people onto 4.7 for the SystemDefault addition.
One way I design in wpf and it’s probably not the best by far is I run the app the design the xaml while running so I can move controls around the way I need them set up. Doubt that helps much but we use a lot of skins that are stored and changed so the controls on the screen are blank no images added to the project for build. So I add all the controls to the page then add the code to load the images from a skin and move the controls around at runtime to get things where I want them.
What if there is a composite foreign key?
So is `IUserStore&lt;TUser&gt;` actual problem? Why can't you just do two user stores both implementing `IUserStore&lt;IUser&gt;` ? Actual user store wouldn't be using generics. Something like `class MongoUserStore : IUserStore&lt;IUser&gt;` and `class MySqlUserStore : IUserStore&lt;IUser&gt;`
So I just updated it to 4.6. No probs. I added in: ServicePointManager.SecurityProtocol = SecurityProtocolType.Tls12; i pushed. and it worked. but then I realized the i used the wrong web config. I pushed the correct one and its slow again. So, I did a line by line compare and the part where it slows down is when I do the mail settings (which worked prior to going to tls 1.2). If I remove that entry in mail settings...its lightning fast...but I can't figure out why.
So I just updated it to 4.6. No probs. I added in: ServicePointManager.SecurityProtocol = SecurityProtocolType.Tls12; i pushed. and it worked. but then I realized the i used the wrong web config. I pushed the correct one and its slow again. So, I did a line by line compare and the part where it slows down is when I do the mail settings (which worked prior to going to tls 1.2). If I remove that entry in mail settings...its lightning fast...but I can't figure out why.
So I just updated it to 4.6. No probs. I added in: ServicePointManager.SecurityProtocol = SecurityProtocolType.Tls12; i pushed. and it worked. but then I realized the i used the wrong web config. I pushed the correct one and its slow again. So, I did a line by line compare and the part where it slows down is when I do the mail settings (which worked prior to going to tls 1.2). If I remove that entry in mail settings...its lightning fast...but I can't figure out why.
check this out : https://stackoverflow.com/a/3540895/2047029 
Delete the componentcache folders also
So I just updated it to 4.6. No probs. in the page load, I added in: ServicePointManager.SecurityProtocol = SecurityProtocolType.Tls12; i pushed. and it worked. but then I realized the i used the wrong web config. I pushed the correct one and its slow again. So, I did a line by line compare and the part where it slows down is when I do the mail settings (which worked prior to going to tls 1.2). If I remove that entry in mail settings...its lightning fast...but I can't figure out why.
how would i do that without getting an extension, i would need to elevate the extension software but i do not have access to that
just deleted the folder, but the toolbox is still empty, thanks for the suggestion tho!
Here you go https://www.matteopozzani.com/visual-studio-cache-cleanup/ Also, this may sound silly, but you aren’t somehow filtering the tools are you?
Thanks, I did not know that. So, what if I just leave it dynamic, and initialize it at declaration? I’ve changed the example.
go figure, i was just looking at that page, in my general section of toolbox there's nothing there. 
For the thing that's suppose to replace WinForms, it's not even 1/10th as good as WinForms. Every few years I touch it again and it looks like it hasn't got any better.
I absolutely hate it. I am not going to claim to be a WPF expert, but from a full stack dev perspective it's absolutely much more complicated, at the very least. I am not even talking about MVVM. I am talking about virtualization and other considerations that make everything complicated. We have Telerik controls that don't work as well as controls we had from Infragistics 15 years ago on winforms. Freaking thing sucks IMHO.
You get those performance benefits if you just load static field, instance field or basically anything to local variable. If you want to get most out of performance then `List&lt;T&gt;` is probably littlebit slower than using array directly, but nicer to use. Also arrays supports ref return, if plan to store big structs inside your list it will help. You should benchmark with BenchmarkDotNet anyway if performance critical to you. If you only want that data to be initialized when something is calling your method you can have `private readonly Lazy&lt;List&lt;MyType&gt;&gt; _myList` field. In constructor you initialize it with `_myList = new Lazy&lt;List&lt;MyType&gt;&gt;(CreateMyList);` and CreateMyList is method in same class like this `private List&lt;MyType&gt; CreateMyList()' It seems to me that you are coming to C# from some other language, these coding style links are useful https://github.com/dotnet/corefx/blob/master/Documentation/coding-guidelines/coding-style.md https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/inside-a-program/coding-conventions
Can you post the performance code comparing Dapper to RepoDb? Without knowing how you are calling Dapper, the numbers for benchmark timings themselves are not useful.
In almost every case where I've seen someone use mutable static state, they're doing it as a back channel way to prevent having to pass around parameters, or a context object, or some other proper mechanism. Even the .Net API avoids it at all costs. Very few people ever call \`Application.Run\` more than once in their UI programs. However, all of the .Net internal code that registers the ambient state for the UI context (the message pump, synchronization context, etc) is all thread-local state, not static proper. Because of this, if you design your UI around context objects instead of static state, you can instantiate your top-level UI more than once per process/appdomain. This aids re-use, debugging, and testing. Microsoft knew this, which is why the don't use static state for recalling the UI context between objects, even though you never pass it around. Static state should only ever be used for things that are truly process-global, and that kind of state is often rare. People think they have it, in reality, they're just being shortsighted with how their code is going to be used. I understand I'm being harsh. Given how frequently I see people abuse static state when they ask questions like this, I feel like its the sort of thing that deserves a bit of push-back. 
Is the mail server UTD? Email by standard can be slow btw so you may want to push it off into some sort of async task. But that's something for you think about knowing zero about your code base.
I think I also condisidered that, if the concerns is just an ordering of execution, then you can copy RepoDb’s code before Dapper’s code. Or, run the Console app the 2nd time? I think that would equalize the scenario you mentioned. IMHO Then, at Insert (option #3), iteration of Insert is also a big deal as I can see RepoDb is much faster, and so Dapper at some point. Almost equal, but when it comes to BulkInsert, I guess RepoDb is much faster 90% over Dapper’s normal insert if you are inserting a something like 5k rows. Though we cannot ise this as comparisson unless you write your manual way of bulk-insert.
I have never included the recursive query performance comparisson, but I have a recursive approach test process that had made the 15 secs in Dapper down to 2.5 secs in RepoDb, unless you write so many codes in Dapper. I will do a series of testing on this one against Dapper’s mutiple type query.
This one is not yet supported as of the moment.
There are a few free spellchecking libraries out there. I haven't looked too far into it but a quick search for "C# Spell Check Library" gave me multiple options. From there you should be able to research them and find the one that suits your needs. As for the medical terms, my guess is that you'll have to create a custom dictionary anyway.
I enjoy idea of recursive query, but seems to be useful only in basic examples. In case of more complicated queries dapper multimapping still is the winner. I will do some benchmark in free time.
Part of our “principle” is not to do complex joins query. Have you seen our multiple mapping? It is far different from Dapper, but we have auch kind of enabler feature for a very complex business scenario.
I find default parameters most useful as a refactoring tool. It's an easy way to add a parameter to a method safely until you're ready to change all references to it. Overloading is the only option in cases where you need to segregate access with an interface. Though I think both are something to be used sparingly as public methods. They lead to unnecessary ambiguity In a lot of instances, but are really useful when used correctly
I have also given up on EF. Well I am actually using it as a micro-orm for now because it's still in use in some places (it's fine for VERY selective queries, using the clustered index etc). But far too often relatively simple queries are too slow. I prefer to drop down to stored procedures and using a dacpac instead of EF migrations now. The amount of control you get over your database increases significantly and EF just can't match it for scale.
I dont even bother. Just XAML and I use the designer as a visual output window
I agree, as a .net developer by trade for over 12 years I've had the same experience. From my perspective, the only thing about XAML that's inherently better than WinForms is that MS focused its active development toward the former and not the latter. 
There was a project years ago mind you, that popped up on CodeProject where a guy had written an xml layout engine for winforms. Shortly after that XAML and WPF came out so it didn’t get much traction. I’m sure you could dig it up, but it would be questionable at this stage. 
This is a non-issue when the server's not using 1.2. And it's not even trying to email anything. But when that tag is in the web.config, it takes forever. Even more interesting. If I use Gmail as the SMTP it takes 20 seconds for the page to load. If I use Amazon AWS email with SSL it takes over a minute.
I am pretty sure this is not true with 2017 at least. I remember reading that blend uses xdesproc under the hood and the xaml designer now uses the same process. Microsoft has made huge improvements in the designer with 2017.
Because overall wpf and XAML based UIs were a terrible idea feom the start. I always get downvoted for staying that very obvious facts from the purists. I do EA for a large private equity group so I see tons of companies implementations In due diligence and follow ups. Wpf is almost always a huge shitshow.
It sucks because they don't care about wpf that much anymore, UWP is the future
You need design time data, u can use a data source file or have a dummy viewmodel file to generate or any other way. There are many ways but it depends on how you’ve structured your view to initiate. Remember the visualizer will try to instantiate the view class.
Does this not answer your question? https://msdn.microsoft.com/en-us/library/system.net.sockets.tcpclient(v=vs.110).aspx
Removed: Rule 4.
If you didn't not send your mails over https before, it could be the certificate lookup that adds some time. It needs to check the servers certificate store to validate the remote certificate. You can add a custom servercertificatevalidationcallback method to the system.net.servicepointmanager. 
I'd suggest trying instead.... `ServicePointManager.SecurityProtocol += SecurityProtocolType.Tls12;` or `ServicePointManager.SecurityProtocol = ServicePointManager.SecurityProtocol | SecurityProtocolType.Tls12;` This will allow TLS 1.2 to run alongside your existing protocols. *Some* endpoints will take offense to this, but most will properly negotiate.
I'm still using 2015, but I have noticed Blend being a little better at rendering 'complex' xaml. Maybe I'll have more success with 2017.
I've been using WPF since it came out (anyone remember WinFX?). It has a steep learning curve, but once you become comfortable with it's design you can see the absolute brilliance in it. I wish MS would improve the performance of it, but other than that, it's still better than anything else out there.
WinForms is conceptually simple, but doesn't work well with high DPI screens without a hell of a lot of developer care. Most developers can't be assed to give that much care. It also had zero chance of being the One UI Framework To Rule Them All for mobile devices and XBox and all of that. Something other than a squares and pixels mindset was necessary. At the time XML and lots of features seemed appropriate. In hindsight, I really wish they'd stuck to something that scaled up linearly in complexity. Simple stuff is not simple in XAML.
It beats the pants off of Android UX design, and if you wrote HTML by hand back in the day, WPF XAML is very easy to pick up and even do well.
Great, now go green Microsoft to get their shit together and make a good UI designer for the replacement, it's been more than a decade and it's fucking pathetic.
I would recommend firing up fiddler and watching the request-response sequence, you can see if the server issues a redirect, you can see if the SSL port connection is even attempted, it will give you more to go on, because that does sound weird.
I hated blend. It's so much easier to just use WPF and write some XAML. You can always use a 3rd party GUI tool as well, but i don't know how great those are.
Does the SMTP server you are using allow tls 1.2 over port 25 and not something like 587 or 2525 etc.? may seem silly but I have over looked port issues before. 
I'd recommend at least considering carefully what extension points you provide to allow other developers to integrate their own connection resiliency. Having patched a three older .Net ORM's to handle smoothly reconnecting the experience has ranged from hair pulling to just kill me instead. Reconnecting is essential on AWS and Azure, and I would assume any SQL Platform-as-a-Service (whereas you can often just get away without on bare metal, co-located boxes).
I've written a few programs in WPF and it personally feels like, at best, a lateral change. XAML has a lot of noise behind it about abstracting away the interface but when you get down to it it's really just replacing one type of code for another. At some point it seemed like we spent more time learning how to use these specialized abstractions that were supposed to make development simpler, and ended up having to spend more time working around design limitations of those abstractions. For example, where before we might have written code-behind in WinForms to say populate and manage a Data Grid View, That's no longer "correct"; with WPF, we instead create Data Templates for the Grid that references the data bound control and appropriately converts properties that need to be converted or formatted using custom converter implementations. To me it sort of just felt like replacing one form of busywork with another. Instead of responding to cell-enter events and updating say an information control to describe the cell data, now we "simply" bind the informational control to the Current cell of that grid and then have a DataTemplate(s) which properly defines the content of that informational control based on the bound cell. For example where before you might have a Inventory Item listing, and you handled cell enter events by updating an informational display about the item on the row, With WPF, you create the informational control(s) and the appropriate data template and bind the Current Row of the grid to those controls. Considering the limitations of the visual designer, it seems like fundamentally just replacing what used to be written with C# code-behind with XAML. And it's not really that much simpler. it's all about separating the presentation from any logic. But I think at a certain point we should have asked ourselves at what point that becomes counter-productive. Should we really be so abstracted from the data we are presented in the view that we need to construct a shitload of "adapter" classes that are part of another middle tier of interfaces so they can communicate? Seems like making work to me. One thing I do like about it, however, is that it tends to make a lot of things more flexible- this is specifically because usually you can put whatever you want in the content of controls, which makes for some pretty nifty UI, allowing you to have lists of more "rich" information without worrying about Handle limitations like you would if you put a bunch of User Controls inside of a TableLayoutPanel or something. The list could show summary information like a "normal" WinForms Listview and then when you select an item it expands and gives you more detailed information and/or additional functions to work with it. That is the part I like the most about WPF/XAML over Windows Forms. (And of course you can define different Data Templates as well, so could respond to certain things immediately in the application- eg. a checkbox could change the displayed information instantly. With WinForms the trick was knowing where and what to change and what events to handle. With WPF it's mostly figuring out what somewhat opaque properties you should bind to what bound members of some other control and what Templates you should define. 
I don't mean to disparage you personally, it's just good business sense. If someone's going to use your library in their project - and the ORM is generally not just a small piece that's easily replaced - they should go in fully assuming that they alone are entirely responsible for all future maintenance of your ORM. There's just no reason at all to expect otherwise, sorry. Look back at SubSonic, for example. Was all the rage for a while, written by someone who was at the time a fairly notable and known personality in the .Net developer community. The library was abandoned incomplete and littered with bugs. Despite it's apparent popularity at the time, no community has continued it's development. Last opinion, your Query Group Expressions are *super* wordy. Seems like all you get out of that is dynamically combining and/or/not and that doesn't seem worth all the verbose boilerplate. There's more succinct ways you could the same thing I'm sure.
This is a very good advice, and I will take note of your wordings here. Thank you. For the static query expressions, I kinda agree, but the alternative is by using dynamic instead. Though I am considering the following before. - QueryGroup = Qg - QueryField = Qf - Operation = Op - Conjunction = Cj - Equal = Eq - LessThan = Lt - LessThanOrEqual = Ltoe ... But it is kinda critical for the developers to optimize the codes specially for dynamic query tree expressions. We are considering this in the future without affecting the communities code implementation.
I’m not looking at it right now but when this happens to me I go to the toolbox and Right click on the window. select add items and it usually refreshes the toolbox.
Or... they could have stuck with and improved winform a which is a very good technology. 
If your other parts are anything like this one, the down votes are probably because you don't give *any* evidence to back up your claims.
XAML is awesome... said no one, ever. 
I did actually.. I *know* the redirect is happening. and then a soap client has an allowautoredirection=true option to allow it or not I was wondering if perhaps it had anything to do with wanting to do some sort of cheap authentication w/ http before https but it doesn't really add up why it would record the url as http in the instance
Same here .NET since day 1 (actually used J++ on an app prior). I don’t bother with WPF at all. It’s a huge learning curve in the enterprise business app world and provides no benefit. I’m hoping someone says something to the contrary to make me take another look. 
UWP xaml borrows heavily from WPF so there's that.
It’s a very mature technology anyway. 
Thanks, i'll look that up. 
Well, I much prefer it to WinForms. Yes, there's a steep learning curve, but it's so much easier to make dynamic windows in WPF. Plus MVVM is nice for separation of rendering logic. Data preparation in VM, layout in XAML, and behaviors for special cases.
Have you tried to compare your lib with others in this way? [https://weblogs.asp.net/fbouma/net-micro-orm-fetch-benchmark-results-and-the-fine-details](https://weblogs.asp.net/fbouma/net-micro-orm-fetch-benchmark-results-and-the-fine-details) [https://github.com/FransBouma/RawDataAccessBencher](https://github.com/FransBouma/RawDataAccessBencher)
Yeah, I suspect the linked33.id column would not benefit from being the primary key like in the first query.
Be it evolution or not, it has stopped being actively developed.
u/understandthings100 seems to be a machine learning bot: https://www.reddit.com/r/IWantToLearn/comments/8iyd9p/i_want_to_learn_how_to_communicate_well/
Those things were rarer than chicken lips or unicorns. I was a sysadmin. My boss (who owned the company) wanted a new laptop, so I went shopping. I found an ad for those, we discussed what we were willing to pay, and I called suppliers. I found two available in the whole country. One was black and white with 2MB RAM available overnight, the other color with 4MB available in 2 weeks. I asked the boss, because he was a guy who liked things right away, but he wanted a color machine. He said buy both, he'd use the B&amp;W until the color machine came in, then I could give the B&amp;W machine to a consultant. Okay. I did that. He loved the B&amp;W machine and was eager for the color machine to arrive. Then the color machine did arrive, while he was away on a business trip, so I set it up and had it ready to go for his next trip. However, right at this time they hired a new consultant, and just as he returned she had to leave on business. I offered to get his files off of the B&amp;W machine right away so she could take that, and then he could have the color machine as planned, but he said to send her out with the color machine and they'd switch after her business trip. She is a type that I have since learned to be terrified of. Roughly the size of a bull and less careful than one, puts on a big pretense of being dainty without putting any effort into actually being careful of her surroundings, and wearing a Chanel tweed jacket. Folks, if you ever have to do business with a large matronly woman in a Chanel tweed jacket, run screaming. If she also reeks of Chanel #5, \*teleport\* out of the office to get away from her. I had the Aero (which is actually a tiny delicate thing and cost $10,000 at the time) ready for her in a bag when she arrived in my office to collect it. she took the bag and WHAMMed it down onto the table and RIPPED the top open to look at it. I tried to explain (in a hurry since I could see she was very ham handed with stuff) that you used the latch to *gently* open the screen, but she more or less told me to shut up and RIPped the screen open. I thought then and there "this will not be okay," but then she ran out the door with it before I could get in touch with the boss to say "danger Will Robinson!". A week later she PLOPped into my office guest chair WHAMmed it onto my desk, and said this machine was garbage, it had broken the first day. She RIPped the case open (permanently ruining it in the process) and showed me... she had completely ripped the screen off its hinges. The $10,000 laptop was now in two pieces, and since she had casually tossed the screen in the case, it had banged around for a week and was now all scratched up. She demanded another color Aero, and threw a tantrum when I said (truthfully) that I didn't have one. She ran to my boss and demanded I be fired for incompetence and being rude to her. My boss freaked out and demanded I give her what she wanted. I told him (truthfully) that I didn't have it. He demanded I get one. I called every supplier in the country, none of them had one in stock and nobody knew when they'd be getting more - apparently they were very popular and had sold out instantly. I reported this back to the boss. He was again frantic, he said she was very lucrative and that we *must* make her happy, so he gave me his B&amp;W aero ($5,000) and told me to get his files off it and give it to her for the business trip she'd be leaving on the next day. I told him she was very indelicate with the machine and suggested we give her the office loaner laptop (which was a little old but was built like a tank, was very reliable and near indestructible), but he refused. Okay, his company, his wallet. So she got the B&amp;W one, after screaming at me again for 15 minutes about how unacceptable it was that this was a \*black and white\* machine. (I tried to tell her this was supposed to be her machine in the first place, that the color machine was supposed to be for the owner, but she basically told me to shut up and stormed out.) A week later, WHAM, onto my table, she'd ripped the screen off another one. Another demand for the new color machine. (Compaq told me it'd be 3 months to have it repaired, and nobody had a new one for sale yet.) Another tantrum when I told her no can do, I can't one for months. She again ran to my boss and demanded I be fired. The boss was frantic again. Again he demanded I make her happy. Again he demanded I call every supplier. Again he was upset with the news that I already had, without luck. Again he said she was \*very\* lucrative and we had to make her happy. I told him she had just destroyed $15,000 of computers in 2 weeks, and he turned sheet white - she wasn't \*that\* lucrative. He reluctantly agreed I could give her the loaner laptop (the tank - built like one, slow as one, weighed as much as one), but suggested I not give it to her until right before she walked out the door. I have it to her at 4:59pm. She started to scream at me but I pointed to a clock and she grabbed it furiously and ran out the door. Sure enough, a week later she'd scuffed up the bag but the computer was fine, she returned it to me and demanded a new aero. Threw a tantrum when I told her (calmly, but truthfully and firmly) that this wasn't happening because there were no aeros available in the whole country. The boss later told me that she'd been calling and throwing a tantrum at him on the phone about it every day. It came out she'd acted unprofessional in front of our biggest client and they'd called to say they don't ever want to see her again, so she was fired. She never did make enough profit to make up for the Aeros she'd destroyed. They weren't back from repair yet when I left the company. 
You wanna know what the most absurd thing is about all of this? The data in question is paging in a DevExpress WPF DataGrid which appears to do its own visualization and definitely has its own paging controls. That's not good enough for the client though apparently... How many hours I've thrown into paging this data...
This statement is false. 
We have not tried comparing RepoDb with other library, we used our own performance benchmark tool that includes the 'Query', 'Insert', 'BulkInsert' operations. It is good to try and create a graphical representation of the performance comparison soon. Thank you for this. 
Man, this comment would have saved my life earlier tonight. I couldn't get a column header centered for anything. 
To be honest I just close the designer, write only xaml and change it at runtime if I need to tweak visuals. I think that WPF would have been great if it didn't need so much boilerplate. The whole binding/converter thing can get really ridiculous. Extensions like Bindables.Fody and CalcBinding makes it a bit less tedious to use
3 vars and calculs
Use TimeSpan.FromMinutes(1625) then use the format method to display it.
hh = (1625 / 60) which is 27 mn = (1625 % 60) which is 5
I think I'd do it like this: var ts = TimeSpan.FromMinutes(1625); var hours = (int)Math.Floor(ts.TotalHours); var result = $"{hours}:{ts.Minutes:00}:{ts.Seconds:00}";
 String result = (minutes/60).ToString("D2")+":"+(minutes%60).ToString("D2")+":00";
Are the both tables in the database or in memory? If one is in the database and one in memory then EF will do weird queries. I had a problem with this a few years back - had an array of object in memory and a database table. When I joined them in dev, everything worked great. When it hit production and a 40gb table, a single query took down the machine. Either do everything in memory (not recommended) or everything in the database - do NOT mix them in queries without determining if it is safe. 
Another aproach : var ts = TimeSpan.FromMinutes(1625); var result = $"{(int)ts.TotalHours}:{ts:mm}:{ts:ss}";
Is this for an assignment? If so, how long have you been programming for, and at what level? The most upvoted answer uses TimeSpan.FromMinutes(), and it's absolutely fine. However, if this is an exercise for an assignment, and especially if you're only just learning to program, it's possible that the aim of the exercise is to get you thinking about how to do basic math. In that case, using TimeSpace.FromMinutes(), although correct, wouldn't be achieving what the assignment is setting out to achieve. In this case, you need to think about how you'd solve this yourself, then reproduce it. In this case, 1625 divided by 60 gives you an answer of 27 remainder 5. You would write this in code as follows: int totalMinutes = 1625; int hours = totalMinutes / 60; int minutes = totalMinutes % 60; int seconds = 0; // A whole number of minutes will never include any seconds string result = $"{hours:00}:{minutes:00}:{seconds:00}"; 
Can you provide the format string that would show an hours value greater than 24? https://docs.microsoft.com/en-us/dotnet/standard/base-types/custom-timespan-format-strings https://stackoverflow.com/questions/3505230/format-timespan-greater-than-24-hour
 var ts = TimeSpan.FromMinutes(1625); Console.WriteLine($"{Math.Round(ts.TotalHours):00}:{ts.Minutes:00}:{ts.Seconds:00}"); this will work, but I'm almost positive you are asking us to do your homework and that your teacher wants you to use math to do this rather than the TimeSpan class
&gt; I do find it strange that 4 random strangers don't value whitespace as much as I do. I have a somewhat-fiddly set of formatting conventions I like to follow that, I think, makes my code more readable, but which isn't well supported by the IDE's code formatting options. I can get 90%-ish that way, but there's still stuff I wind up having to go adjust manually, especially if I use a tool to reformat the whole file or block. (In my case, it's mainly to do with braces, but the specifics don't matter.) *From personal experience*, the value this adds is really close to nil, and I would always advise that you try to accommodate your style of formatting to what your IDE can support. If possible, try to follow the default options Visual Studio has set up: it will take the least amount of day-to-day effort to maintain, and is most likely what your employer would be using, anyway.
Not that I particularly like your solution, but I wish a downvoter would comment on why they downvoted. It looks ok to me.
I'm assuming because it's hard to read at a glance, compared to the other solutions provided. But I agree. Giving a comment, especially in a post like this when where "learning" is the objective, would be greatly appreciated.
There ain’t no apecifier for TotalHours, but you could do this: &gt; string.Format("{0}hr {1:mm}mn {1:ss}sec", (int)t.TotalHours, t);
I suggest to use String.Format() for such concatenations.
Look at @pX\_ or @AndreiAbabei answers. Using the TotalHours property is what you need
Me too, but the UI specialist I worked with used it when he needed to use a designer.
I'd perhaps mention the usage of the `{var:00}` syntax, as someone learning the language may not be aware of custom string formatting OP: it formats a number to 2 digits, ignoring decimals. Eg 27.0833.... becomes 27
Exactly. I think the point is that you can't just use a simple format string for this. I understand the logic behind the h and hh options, but why they didn't add H and HH for TotalHours is beyond me.
Wait there’s a method for that? That would’ve made life so much easier. God damnit I’m an idiot.
Math.Floor is redundant with the cast to int.
The golden wet-dream of those Microsoft people: no programmer should deal with the UI part - programmers write the code-behind and designers draw the elements in Blend. In reality, it's programmers solving 90% of the difficulty of figuring out the correct chain of arcane XAML tags, properties, bindings and nested "{}" inside property values. Awesome!
If you're trying to get the OP thinking the worst thing to do is give the answer.
Yeah, it is, but this is a little more explicit. On the other hand, leaving out the Math.Floor means it will work fine for negative values too, so that could be more beneficial.
yeah... I did not see the 27h at first :P. The format stuff is more for normal datetime than timespan
Sorry working to much. UTD is just short for up to date. If you are running an old version it may have issues with tls 1.2 same as dot net. I'd hit it with a profiler see what's taking so much time. It might be something you're not expecting. Always best to measure. 
&gt; might get asked how you would select the largest k item in an list of integers, which you could solve using a max heap &gt;Caveat: I've never actually been hired by Google probably because you should have used a min heap
String Interpolation for the win! Yes it does all that.
Yeah, OP is almost positively a student, and neither the upvoted answer, or this, are both a bit over-helpful. I only say that because to coach this person through, and educate along the way, is much more beneficial (which /u/LondonPilot actually alluded to in their post). The chunk in their post from "However..." to "...achieve." is perfect, but the rest is, kindly, a bit too gifted-with-a-bow (in my opinion). :-D
The NodaTime package has a more useful `Duration` type than TimeSpan turns out to be. using System; using NodaTime; namespace scratch { class Program { static void Main(string[] args) { Console.WriteLine(Format(1625)); } private static string Format(int minutes) { var unit = Duration.FromMinutes(minutes); return $"{unit.TotalHours:0}:{unit.Minutes:00}:{unit.Seconds:00}"; } } } That won't get you credit on any homework assignments, but in a workplace it means you won't have to worry about whether your own calculations introduce floating point error.
Yep, I'd tend to agree - I shouldn't really have given the solution.
In my business services, I actually define the methods to do all the work. I DI a Repository layer that gets called by those methods. I use EntityFramework and you can create a new context in each method, but I prefer to do is inject the Repository layer in the service constructor. I also create an interface for my Repository layer that includes all the properties (DbSet) in my EF DbContext. Also adding a SaveChanges method definition in the interface. 
Me too thanks
Removed: Rule 4.
I've edited the original post to leave some of the work for OP to figure out. Not sure if OP has already seen the answer, in which case this comes too late, but you never know...!
Your statements about IQueryable are enough for me to not consider your library.
Thank you throwaway\_lunchtime. We appreciate your feedback. We hope to improve our ways in maximizing dynamics.
If you are working with EF, please don't wrap it in additional abstraction. EF already implements the repository pattern. You said it's a document processing system? What sort of state are you maintaining? How does it receive requests? Generally, we tend to work with microservices (MSA.) We use [Autofac](https://autofac.org/) for dependency injection, and RabbitMQ as the messaging technology. You can use these techniques with a larger application, as long as you follow this design: each "request" (message from RMQ, or web request, or some other requested interaction that has a single input, output, and unifying context) needs to be its own "lifetime scope." Your "request handler" (Controller/Consumer/Business Object) will have a lifetime scope. It will have any relevant configuration and any necessary services as parameters. You'll use Autofac (or whatever DI tool you want) inject these by resolving this object on a per-request basis inside a new lifetime scope that is created for each request. All dependencies created inside this lifetime scope will be disposed of when you are finished with the request. Since I don't know how your document processing works, I'm going to use this as an example: we receive a file with an account and write it to the database. `using Autofac;` `using System;` `using System.Collections.Generic;` `using System.Linq;` `namespace SampleThing` `{` `internal class Program` `{` `static void Main(string[] args)` `{` `IContainer container = BuildContainer();` `// Here is where we would wire up something to` `// receive requests. It might be a message bus,` `// it might be a WebApi controller (which has` `// an autofac implementation that will DI for` `// you with request-based scopes), or you might` `// be using Quarts to fire timer-based events` `// (which also has an Autofac implementation),` `// or you might just be monitoring for Windows` `// events. In any case,` `string file = RequestReceived();` `// If you are using something with a per-request` `// autofac implementation, this is handled for you` `using (ILifetimeScope scope = container.BeginLifetimeScope())` `{` `// Begin the actual request processing` `var requestHandler = scope.Resolve&lt;Presentation&gt;();` `requestHandler.ProcessRequest(file);` `// Dependencies will be disposed of with the scope` `}` `}` `private static string RequestReceived()` `{` `return "An event will deliver this";` `}` `private static IContainer BuildContainer()` `{` `ContainerBuilder builder = new ContainerBuilder();` `builder` `.RegisterType&lt;SampleContext&gt;()` `.As&lt;SampleContext&gt;()` `// For WebApi, you can use InstancePerRequest()` `.InstancePerLifetimeScope();` `// For WebApi, this would be a controller` `// and you wouldn't be configuring it` `// here` `builder` `.RegisterType&lt;Presentation&gt;()` `.As&lt;Presentation&gt;()` `.InstancePerLifetimeScope();` `return` [`builder.Build`](https://builder.Build)`();` `}` `}` `public class Presentation` `{` `private SampleContext context;` `public Presentation(SampleContext context)` `{` `this.context = context;` `}` `public void ProcessRequest(string file)` `{` `var accounts = file` `.Split('\n')` `.Select(line =&gt; ConvertToAccount(line));` `PersistAccounts(accounts);` `}` `/// &lt;summary&gt;` `/// Parse line into an account` `/// &lt;/summary&gt;` `/// &lt;param name="line"&gt;&lt;/param&gt;` `/// &lt;returns&gt;&lt;/returns&gt;` `private Account ConvertToAccount(string line)` `{` `throw new NotImplementedException();` `}` `private void PersistAccounts(IEnumerable&lt;Account&gt; accounts)` `{` `context.Accounts.AddRange(accounts);` `context.SaveChanges();` `}` `}` `}`
Have you tried using stretch align too for centering? :P
Likely so...
exactly what we've done at my company! Makes for easier unit testing!
I feel like we're the only people still using SQL Server Service Broker
I can safely say you are not... 
Since no one else asked, what file type are you focused to? It will only show items in the toolbox if you're focused on a file that can consume it.
I have used Linq2DB ORM. It was the fastest lib for ORM, that is why I am interested in comparing with this lib. Also do you plan to add "baseline" - same Query,Insert/BulkInsert but implemented with standard DataReader to understand ORM overhead?
Isn't IQueryable supposed to be performant? I just read [this](https://stackoverflow.com/questions/1578778/using-iqueryable-with-linq)
Isn't it a bit more tricky to unit test the service layer if you don't abstract DbContext behind some simple interface?
IDbSet over DbSet in the context and you should be fine.
DbContext, unless you're creating them by hand, is already mockable. At least, since EF... 5?
Can you post your code somewhere like pastebin and think put the link here 
I don't think that the code itself is the problem, I showed it to my friend, who is proficient in csharp (has a job), and he said that the code looks fine.
May I *strongly* suggest adhering to the Single Responsibility Principle and not making your objects do two or more things. Entity Framework takes care of the details of storage and lets you concentrate on the details of your application. It makes testing easier, too.
There should be a separate project that handles the database. And a third project that holds the interfaces. So let's say you have the following code: IClassARepository repo = new ClassARepositoryOracle() ClassA a = repo.GetById(123) IClassARepository, ClassA should be in project 1. ClassARepositoryOracle should be in project 2,and the above code in the main app. Also, ideally the code above shouldn't be familiar with ClassARepositoryOracle, and just get the interface via injection. ClassARepositoryOracle will be responsible to implement the databases connection and the only layer to actually know and access the database. 
Right click the output window and make sure Program Output is ticked.
What do you mean by 'output window'? If you mean the console, if I right click it, the console immediately closes.
Probably simplest/easiest to just roll a couple of classes. For example: class Episode { public string FilePath; } class Show { public string ShowName; public List&lt;Episode&gt; Episodes; public int NumberOfEpisodes =&gt; Episodes.Count; } Iterate through all the files, parse out the show name and build a list of `Show` objects, each containing a list of `Episode` objects (which is really just a file path). Then it becomes trivially easy to find all shows below/above your count threshold: var largeShows = shows.Where(show =&gt; show.NumberOfEpisodes &gt; 2); var smallShows = shows.Where(show =&gt; show.NumberOfEpisodes &lt;= 2); Then you can iterate the episodes and do what you want: foreach(var show in largeShows) { foreach(var episode in show.Episodes) { MoveEpisode(show, episode); } }
Thanks for the reply! From what I understand though, EF will not work well with Informix or poorly designed databases (unfortunately I'm dealing with both). Are you suggesting that I still use EF and somehow get it to work with all of the different databases? And have a class to just get the information, one to save, one to delete, etc? Do you have any examples or books that you could recommend about how I could go about with integrating EF? I tried watching a few videos on YouTube but it was very confusing getting the DbContext part wrapped around my head as it didn't seem explained well in any of the material I viewed. Thanks again!
Thanks! So you think I should actually have three projects in this project? I was using folders instead but the project probably makes more sense considering code reuse. And in this other project (let's say called "Repository"), I create generic classes to access all of the data in other projects? So back to the person example I'd have one class called GetPersonByNameInformix() : IRepository and then use the repository design pattern to create the person? This is the first I've come across this method. Do you have any examples or references with more details? Thanks again for the help!
What you want is called active record and is in general considered not as good as having dumb entities. You may achieve it but you will be fighting EF along the way.
Dude, nice!
Do you start the correct application? Maybe one of your others is marked as start element
If you have multiple projects are sure you are running one that is a console application? Is it selected with "Set as StartUp Project"
Yes it is a good design. You can see a demo of how to easily inject services [here](https://github.com/leaderanalytics/AdaptiveClient.EntityFramework.Zamagon).
It's: single responsibility / ORM / EF / Native code -&gt; Repository Pattern -&gt; Business Process -&gt; UI / API You will combine the multiple responsibility in the Business Process layer.
Thank-you, that's a very helpful reply. By accumulating the NumberOfEpisodes *within* the list of files and titles, I won't have to apply one collection against another, as you've shown. Thanks very much for writing such a long, clear, and helpful response!
Next 2 books for you to read: [Patterns of Enterprise Application Architecture](https://www.amazon.com/Patterns-Enterprise-Application-Architecture-Martin/dp/0321127420) then [Enterprise Integration Patterns](https://www.amazon.com/Enterprise-Integration-Patterns-Designing-Deploying/dp/0321200683/ref=pd_bxgy_14_img_2/140-7886017-9361621?_encoding=UTF8&amp;pd_rd_i=0321200683&amp;pd_rd_r=04680fb1-86d3-11e8-88c9-b521805f7331&amp;pd_rd_w=hlopV&amp;pd_rd_wg=The0y&amp;pf_rd_i=desktop-dp-sims&amp;pf_rd_m=ATVPDKIKX0DER&amp;pf_rd_p=3914568618330124508&amp;pf_rd_r=H5C7YQY05WNVCR2GV57K&amp;pf_rd_s=desktop-dp-sims&amp;pf_rd_t=40701&amp;psc=1&amp;refRID=H5C7YQY05WNVCR2GV57K&amp;dpID=51eqtvacK7L&amp;preST=_SX218_BO1,204,203,200_QL40_&amp;dpSrc=detail). If it’s truly a large scale project, you are asking the wrong questions at the wrong scale. Coding patterns+mistakes are easy to fix, but architecture mistakes kill projects and careers.
The name repository is typically part of domain driven design. It's not necessarily what you need. But the idea is the same: you need to have 3 basic layers in your application: the user interface, the business logic and the data acces. Each layer can be one project, several projects or they can all be in a single assembly. It really depends on how big your application is. Now, to answer your question, yes, the classic approach is that each class (entity) will have a parallel repository class. If your entities are similar, you can look for Generic Repository Pattern, and make sure you implement it across the board from the get go, without code duplications. Your business logic layer is only familiar with the interface of the data access and isn't aware of the implementation. This is achieved by using dependency injection (you get the interface via the constructor). 
If I would build anything large today, I would use Clean Architecture with Mediator Pattern (MediatR) to abstract UI. UI would send commands with MediatR and command handlers would be in Core project. Database and abstractions (interfaces) and models would be in Core project. Actual database access etc. implementations would be in Infrastructure project. This allows you to switch UI and database without touching Core project. More info https://www.dotnetrocks.com/?show=1538 https://github.com/ardalis/CleanArchitecture 
Lol, what *does* work well with poorly designed databases? Microsoft has pretty good training materials for EF, and StackOverflow is your friend. There's a lot of tutorials out there. The dbContext is the part that handles persistence for you; you don't have to write classes for that. Your business objects' job is to represent state.
 // Get the TV show name for all the episodes Dictionary&lt;string, string&gt; showsByShowName = new Dictionary&lt;string, string&gt;(); [...populate showsByShowName...] int minimumNumberOfEpisodes = 2; Dictionary&lt;string, List&lt;string&gt;&gt; EpisodesByShowName = showsByShowName.Aggregate( new Dictionary&lt;string, List&lt;string&gt;&gt;() (result, episodeShowNamePair) =&gt; { if(result.TryGetValue(episodeShowNamePair.Value, out var episodeList) { episodeList.Add(episodeShowNamePair.Key); result[episodeShowNamePair.Value] = episodeList; } else { result[episodeShowNamePair.Value] = new List&lt;string&gt;(){ episodeShowNamePair.Key }; } return result; }) .Where(showNameEpisodeListPair =&gt; showNameEpisodeListPair.Value.Count &gt;= minimumNumberOfEpisodes) .ToDictionary(kvp =&gt; kvp.Key, kvp =&gt; kvp.Value, StringComparer.InvariantCultureIgnoreCase); Result should be a dictionary with the names of shows with more than N episodes as keys and lists of that show's files as values.
It's an extremely large scale project. At least 3 big vb6 applications and 50+ c code all into one local desktop app ppl location. You're right, I probably should focus on the architecture before I actually start coding. I usually get excited and just want to make something to show the stakeholders but the reality is this is going to be a project that will take a few years and I should do it right. Thank you so much for your insight, I will be sure to get started on these books right away! Can't wait to learn some new things :)
Mostly, I didn't know if you wanted to add additional properties (season/episode) or if you wanted to record your destination path, or anything else of the sort. You could definitely just use a `List&lt;string&gt;`, especially for such a simple use case scenario. One benefit of wrapping it with a class is it forces you to be explicit about what the `string` represents. In this case, a file path (rather than episode name). It can also be called "Primitive Obsession": https://www.codeproject.com/Articles/890541/Functional-Csharp-Primitive-Obsession Definitely don't need to do it everywhere, I just figured in this case it could be a good example of it.
Good point! I think I'm starting to understand. I'm going to look into EF more as well as the overall application architecture, make a plan, then go from there. Thanks!
Jesus that syntax is ugly. Wouldn't it result in anonymous object spam?
Thanks for the reply. Yes, they are set as a console application and still the code doesn't work. 
Hi there and thanks for the reply. Could you elaborate what you mean? Just so that I can understand better, thanks.
Pro-tip: don’t choose and architecture and start writing big chunks of code right away. It usually takes about 3 iterations to get the architecture right. So start by defining your non-functional (ie: quality, performance, etc) requirements, choose a candidate architecture, do a little bit of coding, do a little bit of coding, do a little bit of testing, verify it actually meets requirements, then go back and validate the requirements were correct. Repeat incremental 3 times or so. Just like coding, when there are lots of unknowns it is much safer to build an architecture in several incremental iterations and evaluating after each iteration.
Downvotes because you come here asking for help and you are giving very little information about your problem. How would you answer to someone that asks, I have this code that doesn't print anything please help? Then someone asks for more information so he/she could help you better, your answer is that my buddy said my code is ok you don't need to see it. Why didn't you buddy help you to fix your problem then if he/she was so capable?
Right next to your run button there should be a project selected to start from, if you have multiple projects (eg multiple console applications) you need to tell your IDE what project to start from. There is a dropdown menu (at least in VS2017) and you need to select the desired project. Alternatively you need to right click your project and set it as start project. 
First rule of C#, put breakpoint to code that doesn't seem do anything and start in debug mode. That way you know for sure that code is actually run.
Ok, my bad. Here is the code for a particular class in pastebin, for a very simple hello world program: [https://pastebin.com/xvM3jDcM](https://pastebin.com/xvM3jDcM) (to anybody who can assist) Note that this is a part of the solution that has two projects, the solution that does not work. Again, sorry for being out of line, /u/SilenceInDarkness .
Yes I mean the same thing.
Thanks for your help. I selected the correct project as you described and I finally got an output to the console! 
I stopped because it kept breaking. Likely my bad code but I blamed it in the tech at the time. 
Great! :)
Are you just trying to encrypt the in-flight traffic of a diagnostic report? How big is the file? Why can't you use HTTPS / TLS 1.2?
If you have Resharper installed Visual Studio is very slow. Roslynator is nice free Resharper alternative that doesn't slowdown Visual Studio because it uses Roslyn.
Assuming that there's no bug in your implementation (e.g. accidentally using null keys or something), this is the way public key crypto is typically used and should be secure. However, it sounds like you're just reimplementing TLS, really. Do you actually need to encrypt the data "at rest", or is it going straight from the application over the net to the server anyway?
But I want paper! To signal to others in my office and when I commute on the plane that I know how to code le epik style
It's cool, simple mistake. You know now. 
You know what I mean 😁
I don't have control over our web services to implement a public facing service to receive the data over HTTPS. But we DO have an ftp server and I wanted to send the logs up securely over an insecure connection. This way, it's encrypted in transit, and if the FTP server is compromised, anything sitting there is still encrypted. I develop tools on my own to assist our support teams, though I'm not a developer by title. Most of my development efforts are aimed at filling gaps I see, and getting R&amp;D to say "Ah ha!" and adopt some of my tools over time.
The data is sent to an FTP server as I have no control over our web services. I also make enough changes to my tools over time that I don't want to lock myself into a framework for which I'd have to maneuver through too many other teams to change. Cool that I essentially recreated the process behind TLS, I didn't realize that was what I was doing!
Currently enjoying this and taking it slowly but doing at least a little every day. What do you recommend for after this book?
I did not know that! Although personally i dont test crud.
Yeah it's only really useful if you're treating EF as your repository and therefore your business logic is directly interacting with it. If not, there isn't really a lot of use in writing unit tests for it beyond increasing code coverage, since anything that's going to fail is going to be due to a problem with your connection to the database.
Adaptive Code via C#: Agile coding with design patterns and SOLID principles https://www.amazon.co.uk/dp/0735683204/ref=cm_sw_r_cp_api_KBssBb4KK2YX1 Absolutely revolutionised the way I approach coding and class design. I can’t pretend to know everything in this book but if you can atleast appreciate the approaches described you will subconsciously change the the way you approach things. This is probably the best ‘coding’ book I’ve bought as the principle lad lend themselves to almost any language/project. Hope you get as much from it as I have. Disclaimer: I am not affiliated in any way with this book. 
Out of interest my last project i used cores in memory database for some end to end testing. I was surprisingly good.
I'm not exactly sure since I'm not that experienced with C#/.NET but I believe your supposed to use the [BackgroundWorker](https://msdn.microsoft.com/en-us/library/system.componentmodel.backgroundworker(v=vs.110).aspx) to update the UI from another thread?
That's awesome, we haven't switched to Core yet, so I haven't gotten a chance to play with that. The only in-memory service testing I've used was the in-memory queue with MassTransit. I wish more external service libraries provided that level of testing support, it makes testing behaviors so much easier.
Looks like a solid foundation that will serve me well, thanks! Do you have anything you could recommend for projects and assignments, or is it better to go through books like these and just try to create things that come to mind as you go?
How through is in-memory test? Can you test for column overflow? Trying to write a null value? Invalid FK?
Examples from books are great but you’re a lot more likely to enjoy a project if it’s something you’re interested in and would find useful to have as an application in your personal life. When I was learning it was all about organising CD and DVD collections and making booking systems to lend them to your friends however I doubt that’s relevant now. If all else fails, make your own calculator app 👍🏻
Repository pattern with contexts respective to your DB Connections. 
I'm glad you said calculator, because I made a list of 8 small apps to make whenever I start coding properly and a calculator is number one haha. Thanks for the help!
No worries pal. Calculator is great because it’s very easy to write unit tests and verify that your code is performing as expected. Enjoy the journey, it’s never ending but can be very rewarding. 
I used it to do end to end testing instead of crud, although most of those problems would have got caught by the validation layer.. The only real limitation i came across is it cant test stored procedures (which i use to generate reports). Well that and trying to write the setup code as briefly as possible without obscuring it behind setup / teardown methods.
What gets me is its mostly been ignored which I find astounding. Its a bit of a game changer IMHO.
I'm sure I will! The direction is invaluable - thanks again.
Out of interest how old are you and where are you based? 
19, from the UK. 
Look into Bae Systems for software apprenticeships, great scheme with fantastic employment possibilities 👍🏻
FYI I’m based in East Yorkshire 
Ah, gotcha. If your messages are small enough (less than 1mb) you might want to try using a reliable message queue with broker (like Azure Service Bus) instead, as they were designed to solve this kind of problem safely, but it sounds like you are dealing with mid/large size logs?
\&gt; **X DO NOT** use underscores, hyphens, or any other nonalphanumeric characters. [https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/general-naming-conventions](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/general-naming-conventions)
Aha, no way! That's the apprenticeship I'm starting in eight weeks or so. Straight into Software Engineering and a Computer Science degree, I just want to learn some C# between now and when I start. 
There are better/newer ways to work with asynchronous and update the UI.
Maybe there's an easy way around it, but in my experience, there's only [one surefire way of fixing it.](http://www.artofwellbeing.com/wp-content/uploads/2015/09/Lots-of-coffee.jpg) I've learned that when it comes to API surfaces (beit XML/JSON serialization, REST, WCF, SOAP, whatever) that the public contracts trump your own internal naming/organizational protocols and practices. If you have to match an external/existing API, mirror that API _exactly_, then adapt within those methods to whatever internal practices or structures you want. Separation of concerns and all that. Maybe there's a specific workaround for WCF for you, but I'm not aware of it (but I'm not an expert either). Good luck!
We will surely do performance benchmark against raw ADO.net and other ORM library, we will post the result afterwards. We are creating a test now, and we are adding performance benchmark test suite out of it.
Wow that’s a small world. Where you going to be based? Warren, Yeovil or Brough?
Well, I apologize about IQueryable. It is been long since we stopped using it, and I might be bias with what I said earlier. I will personally play around with this IQueryable again and see if this really suit on this library.
No kidding, I feel like everyone here is from the US 95% of the time. Going to be based in Brough! I take it you've worked there?
Still there. Former software apprentice that started in 2008 graduated in 2010 as of already done a year of the uni course before I applied. Just moved into my first ‘tram leader’ role and have no plans to leave any time soon. First 2 years at college should be fairly straightforward, third year is a big step up so try and learn as much as you can when at work. I knew very little when I started but there are Plenty of guys around that are more than willing to help. I have no doubt you’ll be fine. Any questions then feel free to send me a pm. 
We have certain validations with regards to the anonymous object type composition on this query tree expression. You can see the code at **QueryGroup.Parse** and **QueryField.Parse (internal)**, and see how we handle it. On the other hand, we tried to make it more simple, by maximizing dynamics. We loved **Dapper** very much and we are used into this syntax already. They are very liked with each other. And you saying this, realizing that many developers are rooting for IQueryable. One thing to remember, we made it simple until to the point of composing SQL statement via **SqlDbStatementBuilder** (extensible). You can see how optimal generated SQL statement by plugging your own custom **ITrace** in **Query** operation. Thank you for this, and we will take a look with IQueryable soon.
Wow, I really appreciate that! Thank you. It's good to know people stay on in the long-term like that. I'm trying to get as much in as I can before starting; do you think it's smarter to focus on C# or on CS in general? 
Yes, this is secure. You can use FIPS certified implementations for added assurance the algos were written correctly.
For now I would focus on one language. C# is a good starting point as once you understand the constructs of one language you can then use that knowledge to understand other languages you may be working with. In one apprentice rotation you will start with doing a C course which is really basic and then move onto a c# course before being introduced to actual ‘work’ . if you already know some c# then that’s holds you in good stead, although don’t worry if you know absolutely nothing and no prior knowledge is assumed. If it were me starting over, I would carry on my pursuit of c# and getting to know how to use visual studio and how structure code with classes and namespaces and projects, maybe understand what interfaces are and why to use them, and how to unit test code as that will probably make up a lot of the things you will do in the first couple of years. For the teams that work with .net and c# everybody uses visual studio so download the community edition of that and familiarise yourself. But please don’t spend your whole summer learning as you will get taught and helped through all that stuff. Though the fact that you are asking questions about what and how to learn is definitely encouraging. 
So if you catch those errors in your validation layer (and presumably test there also), what value is added by in-memory testing? I mean, what do you expect to not break when you write the in-memory db? I'm sorry to ask - I just can't understand why to do it.
What you described is basically a PKCS7:CMS approach (see EnvelopedCms class)
I would start with telling your management you need a server-side component, and develop APIs for manipulating data. Then, develop client app(s) to consume said APIs. This will let you not worry about number of db connections and put you in control of scalability (e.g. if the deployment will get to 10k users etc)
I could also link a project style guide that supports my point of view, but I reckon it'd convince you about as much as yours convinced me.
Yea ok, I’m not really well versed in this. Sorry. Could you provide an example for OP?
I'm going to assume you want to use this as an avenue for learning how to properly implement crypto. The steps I'm describing are probably unnecessary for your use case, but will bring you closer to using crypto properly. You're off to a pretty good start. You're probably using AES-256-CBC (default in .NET), so confidentiality is guaranteed. But authenticity and data integrity are not. This leaves you open to some improbable but possible cryptographic attacks. You should be using an authenticated block ciher mode of operation like GCM. However, I know from experience that the stock .NET crypto libraries don't actually offer GCM. So you'll want to make a couple of modifications to your protocol. 1. Encrypt then MAC. Your receiving client should verify the MAC before processing the received data in any way. 2. Since you already have a sort of PKI in place, you might as well sign the MAC immediately after generating it. The signature should be verified prior to processing the data in any way. This'll ensure the message was received by a legitimate sender, and that the data is exactly the same data the sender intended to send (hasn't been tampered with in any way). Implementing these measures will make your protocol fairly strong. The biggest weakness at this point is the RSA key. If someone were to compromise your private key, they could decrypt every message ever destined for the owner of that key. To eliminate that vulnerability, you should implement a key agreement algorithm that provides forward secrecy. I'm personally a big fan of the Diffie-Hellman key exchange, as it's easy to use once you wrap your head around how it works. Super easy to implement from scratch, too. If you go the extra mile to add a proper key agreement algorithm, you can get rid of your RSA keys in favor of something that's only useful for signing. ECDSA keys will be generally faster to use, and you'll end up with a slightly smaller final payload. Those are some best practices you should follow whenever you're designing a cryptographic protocol. I'm sure I've missed something, if anyone else would like to chime in.
I wrote this to help solve an issue I had where I wanted to be able to send a file with potentially sensitive information over an insecure connection.
What worked was defining my Dictionary like this: // Show title -v List of show files --v Dictionary&lt;string, List&lt;string&gt;&gt; showsByShowName = new Dictionary&lt;string, List&lt;string&gt;&gt;(); Then I can filter based on the number of episodes for a given show like this: // Remove all of the shows that don't have at least &lt;n&gt; episodes showsByShowName = showsByShowName.Where(s =&gt; s.Value.Count() &gt; minimumNumberOfEpisodes).ToDictionary(s =&gt; s.Key, s =&gt; s.Value); Thanks SO much for your help! - DRP
We are not here to do your homework 
you arent thanks for the productive comment douche bag you ever hear of trying to teach your self something? I was given code and an example thats it trying to figure out bubble sort is easier for some than others
So google it, go read a book on algorithms slowly. Don't just throw down some completely illegible code on reddit and expect someone to magically decipher it and explain where exactly you're going wrong. If you're teaching it to yourself then go do that. Read more books. Start with something simpler. You can probably get help with specific c# issues here (I can't see it against the rules) but nobody's here to teach you programming. Especially if you're gonna be an asshole.
i will delete post and move on no worth arguing but there is a better way to respond to posts than the prior person and giving some type of advice like you have is still more productive i wont thank you as you are an asshole as well 
Its a good question. So an example is I use it for end to end test of a payroll system. So the test case was passing in employee hours, which generated a payroll, calculated their wages, holidays and tax etc... Then asserted that a payslip was correct. While I had unit tests around each individual engine such as the PayCalculatorEngine, the TaxEngine the PayslipGenerator etc.. At the end of the day they didn't test that it all plugged together and then the right data went into the datastore. So being able to test the whole thing plugged together imho added value and was worth the cost of maintaining the tests.
Essentially, your describing the action of a progress bar, but instead of updating the progress bar, you're updating a text box. It's been a while for me, so details might have changed, but essentially you will hand your worker thread a callback function that will write to the text box during each loop. Also, you will nerd to allow your worker thread to read a cancel token so that the user can stop the operation. This is how I used to do this with a worker thread class. I'd have to research the current Task based async syntax, but there will be a similar way to hand the thread some sort of method or lambda that will execute after each loop and also a way to terminate the task before the loop completes. 
Value types do not have any header by themselves. Their size and layout depends on the struct layout, typically it's the sum of the field sizes plus padding for alignment. The value from the type handle is either meaningless or probably only relevant for boxed value types (which are heap allocated and do have headers like any reference type).
I may be utterly wrong. The reason why you getting 24 bytes is using value type in typeof boxes it and the header for object type as you said is 24 bytes.
I have no idea, I’m afraid. But I wonder if you could explain where the number 24 comes from? The way I read that table, you have 8 bytes for the header, and 8 bytes for a pointer to the method table. Then you have fields, which presumably might be zero if there are no fields? So I’m sure I’m missing something, but that looks like 16 bytes to me. I’d honestly never considered looking into this area before reading your post, so I shall be following it with interest hoping to learn something!
Value types do not need method table pointer as exact type is known at compile time unless such type is boxed and method pointer table is present (like for any other object). You can get size of umanaged type by using sizeof operator. You can also get an idea how particular fields are laid out in memory using this trick: public struct MyStruct { public short s1; public int i1; public int i2; } MyStruct myStruct = new MyStruct { s1 = 0x1111, i1 = 0x22222222, i2 = 0x33333333 }; byte* arr = (byte*)&amp;myStruct; for (int i = 0; i &lt; sizeof(MyStruct); i++) { Console.WriteLine($"{i.ToString(),2}: 0x{arr[i]:X}"); } Output: 0: 0x11 1: 0x11 2: 0x0 3: 0x0 4: 0x22 5: 0x22 6: 0x22 7: 0x22 8: 0x33 9: 0x33 10: 0x33 11: 0x33 So we have 2 bytes, then 2 bytes of padding, and then 2x4 bytes. Btw. I have never seen this: Marshal.ReadInt32(typeof(T).TypeHandle.Value, 4) I presume it reads some internal type structure. Do you have some documentation about it? What other information could be obtained by this way?
Marshall is for managed/unmanaged transitions and doesn’t tell you the correct sizes. 
Marshal.ReadInt32(typeof(T).TypeHandle.Value, 4) It reads a field from a type's MethodTable. Specifically the base size DWORD. TypeHandle.Value is a pointer to the MethodTable. I have it mapped out [here](https://github.com/Decimation/RazorCLR/blob/master/RazorCLR/Runtime/MethodTable.cs)
This is really reassuring; I wont be completely sacrificing my summer but I'm more than happy to chip away daily at things like the yellow book while I'm enjoying it. Already use Visual Studio! It certainly seems like this apprenticeship invests into it's employees a lot and I'm really looking forward to it. Another thing I've been curious about though - with doing programming at work on a daily, did you stop doing it at home for enjoyment or do you still make your own side projects and such? 
According to object.h in the Core CLR GitHub: // // The generational GC requires that every object be at least 12 bytes // in size. #define MIN_OBJECT_SIZE (2*TARGET_POINTER_SIZE + OBJHEADER_SIZE) Which (on 64-bit) evaluates to 2 * 8 + 8 (2 * IntPtr.Size + IntPtr.Size) == 24. The code above says the GC requires a minimum of 12 (24 on 64-bit) bytes for an object but I don't know why. I initially assumed it included the size of the pointer on the stack (which would be IntPtr.Size) but I guess don't know what the other IntPtr.Size (8) bytes are.
The above code I posted isn't `Marshal.SizeOf`.
I don’t know that this is specified anywhere if you don’t use the StructLayout attributes to do so. If you do then obviously it depends on the attributes you’ve set.
No. Only the initial setup of the test infrastructure is somewhat harder meaning instead of 30 minutes you will spend 3 hours setting it up for EF6. For EF Core you will probably spend 1 hour
What are you using it for? Where has the author referenced it in his comment? Is using that a bad thing? I will be using ServiceBrokerListener library from GitHub for a .net core Microservice app to retrieve database changes. Is service broker a hit and miss thing?. If yes, any alternative you suggest? Thanks
Use `sizeof(T)`, not the method you're using for correct results
I never really programmed outside of work or even outside of university projects anyway as I wasn’t from a IT or computing background. I don’t think many people do as once they’ve done between 8 and 10 hours at work it’s nice to get away from it. 
I love Dapper for its minimalism, but certainly not for its syntax. C# is a static language first and using LINQlike syntax is much more natural than anonymous objects that make it look like bad JS. Plus you get intellisense when using statics. 
[Your own code](https://github.com/Decimation/RazorCLR/blob/8a9fdb179fbb04700f0d5ba7a703d0f806a5507b/RazorCLR/Runtime/MethodTable.cs#L168) says (emphasis mine): &gt; Base size of instance of this class **when allocated on the heap** So this only applies to value types when they're boxed. One way to see this is [by using SharpLab's `Inspect.Stack` and `Inspect.Heap` methods](https://sharplab.io/#v2:EYLgtghgzgLgpgJwDQxAgrgOwD4AEBMABLgIwDsAsAFADe1hDxJAbMQCxMAcAFAJT2M6VRiMIBJTFAAOcAMYwAdAGUYEWQGtumOAHdCSvrwDcA0eMkz5CgBJwIUrbv2GTwxgF9qnqtVgZ5+tRCIgCWmDCEEK6h4YTAru5AA=). (Note that the parameter of `Inspect.Heap` is `object`, which means it will box any value type.)
&gt; using value type in typeof boxes it That doesn't really make sense. When you write `typeof(T)`, there is nothing to box.
I am afraid to reply because this could trigger a heat or a debate, and it is very common known topic for a "debate" when it comes to structuring the approach all throughout the development. Let me express my opinion. I find writing SQL Statement a bad practice for .Net developers, that is why there a what we called "Repository" to abstract the separation of concern in the Data Access Layers. It reduce the simplicity and common-grounds of the implementation specially if you're working on multiple projects that targeting the same structure designs. We have removed the persistency layer of the simplicity here. Imagine the effort if you are writing SQLs in just a simple Query, Delete etc. Imagine the effort as well if you are to write a customized or dynamic repository in your project and start-over on that area the persistency of your data-access activities. We need to consider or make the design more pluggable, that even on this layer, we need to have an easy-to-use and easy-to-change components. That's why, being on a big ORM like EF and NH is very good when it comes to this persistency as they removed most (if not all) complexities in the programming paradigm. Though, it is a different story why we did not use this ORMs. On the other hand, I am also aware that business scenarios and problems could not be solved by just ORM itself. ORM is just an ORM, as its stands on its name. It does not say, I will solve your problem, but only to map an object. I hope you get my point here. And I guess, this is the reason why Dapper was loved by many because of its "simplicity" and the most is "performance". What I am trying to say is, you somehow need to write SQL statement to solve complex problem. There are pros and cons on here, and that's the reason why I also developed RepoDb and I campaigning this (fast-switching-approach) of the library whether you are to use the lightweight or massive operations. For me, lightweight is to write SQL and massive is to use ORM features. That's how I undertand things up on ORM. I want RepoDb to live in between Dapper (super lightweight) and Entity Framework (big ORM), where developers can just switch to any approach and give more dynamics on their development activity. But of course, I personally cannot compromise the performance. No debate please and thanks.
Ok thanks. Method table exists for every type, even for primitives like System.Int32. In such case this field also contains 24, so it's definitely size of boxed value type.
You need to fix your formatting. It's very hard to read your examples.
I am still using the '\`\`\`' the old approach, just indented it properly. Thanks
Mark as async the asynchronous method and receive a IProgress&lt;T&gt; as parameter. In the call you can use the Progress class (it implement the IProgress interface).
https://www.aspnetspell.com/ it has a med dictionary I believe, as the editor of choice, I think you should go with rich edit box as it does pretty much what ms word does in terms of simple text formatting. 
He did not, he referenced RabbitMQ. When queues became popular it was sort of between SQL Server Service Broker and MSMQ for a short while, we decided to go with SQL at the time. It seems that trend lasted about 5 minutes until all these other solutions like RabbitMQ became goto solutions. If I were starting over I would go with whatever it is the cool kids use.
Okay, I will use service broker for notifications then, rabbit make for queries, thanks
Thanks for letting us know.
Unless you are very careful unsafe code can cause massive problems. But it's in there for a reason and if it's the only solution just use it correctly and it will be fine.
If your talking about windows it's just vs. If your talking about mac say vs for Mac. People will assume windows unless you specify.
Use Task.Factory.StartNew to create a task that does the long-running stuff, and use the .ContinueWith() method of that task (passing in TaskScheduler.FromCurrentSynchronizationContext() as the scheduler to specify to start the continuation on the UI thread) to create a task that will display the results when the long-running task completes.
If you are interested please in using c# for game development, then you would probably use the Unity engine which uses Mono. So I think that would be cross platform, but im not sure. For desktop applications, I'm not sure if there would be a good cross platform solution using c# yet. Maybe WPF or WinForms support .NET Core, which would be nice but I'm not sure if that exists yet. Overall if you're debating learning C# or Java I would definitely go with C#. I've worked with both in the professional environment and C# as a language is just so much nicer and the tooling built around it just blow the Java environment out of the water. 
Given the rise of Net Core and cross platform support and the existence of Mono, I don't see any downsides to learning C# compared to Java on linux. Especially given the new Visual Studio Code IDE works cross platform as well.
Just leaving a comment to pin this thread so I can listen to this podcast tonight.
There is no production ready .net solution for desktop app on linux and no official cross platform desktop solution was announced, so I'd recommend using java. For game development there is unity and to some extent godot and few other engines have various levels support.
That's fair enough and I can imagine that'll be the case for most people! I started trying to do my own projects today and I'm loving it, but I actually think I learn better from the book funnily enough. At least, I understand it clearer, but practical cements the techniques. 
Thankfully I've found out that the way that I feared would cause the program to lag really badly actually doesn't make it lag at all.
Haha this is what I'm talking about. Read your answer and compare it to the other 2 above. My tiny and limited mind is in distress now once again :(
So you are dismissing what this fellow is saying in the link I pasted in my OP: [https://imgur.com/a/SadPBlH](https://imgur.com/a/SadPBlH)?
fyi -- every thread and comment also has a 'save' link
IIRC Xamarin works on .NET Core / Linux. WPF doesn't support Core but OP could try [Avalonia (in beta phase)](https://github.com/AvaloniaUI/Avalonia). Please note hat I have never used any of the two so I can't give any specific information.
[https://github.com/AvaloniaUI/Avalonia](https://github.com/AvaloniaUI/Avalonia) [http://www.mono-project.com/docs/gui/](http://www.mono-project.com/docs/gui/) [https://github.com/jsuarezruiz/forms-gtk-progress](https://github.com/jsuarezruiz/forms-gtk-progress)
Learn both.
Unfortunately there's no stable cross-platform UI library that I know of for C#, though there are bindings for GTK (GtkSharp) and Cocoa (can't remember what it's called but it seems to be built in to Visual Studio for Mac). Java may have strong cross-platform support but .NET isn't far behind.
Yup that guy doesn't know what he is talking about if he thinks net core only has so so support.
No offense but UI desktop clients are dead. If your not making web applications at this point your in the past. If your doing game development there is Unity which works everywhere.
Avalonia is far from production ready, same desktop versions of xamarin forms. As for various mono toolkits - winforms tech is by many considered obsolete already and gtksharp is far from being acively worked on. I'm not saying it's impossible to write crossplatform app with ui with c#, but I would not dare to use it in production.
***Java*** is multi-platform and there's a lot of educational material even for multi-platform programming. There's also plenty (although not all good) UI libraries available. It's broadly used in commercial applications but to a lesser extend in games. ***C#*** is a language that is multi-platform. However, it's heavily dependent on frameworks and those haven't been adapted yet. ***Mono*** is a layer between C#, DotNet and the Linux and MacOS environment. It can run some, but not all frameworks on those platforms and it's what's used in *Unity.* It can run big chunks of the DotNet framework on other platforms. ***DotNet*** is the main framework you'll use in C#. It's been developed by Microsoft and it's the foundation of any project and interaction with the system etc. DotNet (IE DotNet 4.6) is exclusive to Windows. ***DotNet Core*** is a rebuilt from the ground up multi-platform implementation of the important parts of the DotNet framework. It's in rapid development but not widely adopted yet and there's no UI components. Thus far it's a revolution for web development for it's platform flexibility and raw speed. It's a lot faster than Mono or DotNet. It's a well documented but also changing framework. **Opinion time** I don't think you should be doing game development on Linux with Java or C# *yet*. I think you're well off teaching yourself C# with DotNet Core but starting with console applications &amp; web API's like we all did. When you can program one language switching isn't as big of a deal anymore and C# is readable, clean and extensive whereas Java can be restrictive in features. When you're getting comfortable coding (and don't need such extensive explanations of the basics anymore) you can start looking into Unity. It'll be C# but in an environment that asks a bit more of you as a programmer (threading, 3D, performance, etc). Python is - even though you don't want to hear it - a very great start to learning how code actually works. C# (and Java to an extend) add a lot of features and abstractions that make stuff really easy to do (especially collection manipulation) but using those abstractions is hardly a way to learn how to code. Python will have you doing a lot of things yourself in an easy to understand, multi-platform console environment. It's real easy to pick up and will make learning C# a ton easier which is for beginners a bit like diving into the deep end of the pool. TL;DR: Get PyCharm, find some exercises and learn the basics. Then, after a month or two (and not having given up yet) you can dip your toes in DotNet Core console apps. After that, maybe some DotNet Core WebAPI stuff as that teaches some nice architectural stuff. Only after that I'd recommend Unity. Cross-platform on Linux is a bitch. 
&gt; tooling built around it just blow the Java environment out of the water. I also work with both. Unless we are speaking about VS 2017 Enterprise here, no they don't. VS Community and Professional don't offer the same refactoring capabilities, code coverage, live server profiling, database integration tools as provided by the common Java IDEs trio without additional plugins. 
&gt; No offense but UI desktop clients are dead. If your not making web applications at this point your in the past. That's not really relevant as OPs requirement is to write a desktop app (assuming with UI). Agree on the unity part, which is why I mentioned it in the first post.
&gt;winforms tech is by many considered obsolete already Winforms is not "obsolete", or at least it is not "unusable". You can write practically any desktop application with Winforms, at least as good or complete as Linux desktop applications. There are a lot of third party controls, and I guess a lot works with mono.
Try to use EF 6 or ADO.NET with Oracle on Linux.
UI desktops are alive and kicking in the enterprise space, factories and life sciences. Not everyone works in industries with browsers connected to internet.
Not even Java developers are voluntarily touching anything Oracle related anymore. You list non-arguments...
The answer depends on who you ask. I am a developer, I have been in the position to choose the language for a larger project, and I am a teacher for game programming. As a single developer I'd say use C#, but as someone working in a team I'd say use Java. The main difference between the two languages is the attitude towards introducing new features. Where Java went the conservative way and tried to stick to the bare minimum C# went the opposite direction and added everything it could. And language features are a little bit like guns: if I am alone in the wilderness I feel better with a gun, but if I am in a city I feel safer with nobody owning a gun. It's similar with language features: if I am the only developer (and that includes "future me", meaning it's not only a one-person project but also one that doesn't take longer than a couple of months) I enjoy the power that C# gives me, but if I will be confronted with other people's code (again including my own code that I can't remember writing) then it has proven beneficial to use a language that forces you to stick to a commonly known set of core features. As a teacher I say start with Java and learn C# later. Of all my students the ones that started with Java were those that had the best understanding of "clean code" whereas those that started with C# had much larger issues with that. As a game programmer I'd say forget about Java. Minecraft is the exception that proves the rule. The number of frameworks or engines that uses Java is very low. If you had asked about server development then Java would have had a significant advantage over C# (albeit not quite as clearly as C#'s advantage over Java when it comes to game programming). So bottom line: since you asked about "learning" a language the downside is pretty clear: it takes much longer to learn C# than to learn Java (I am only referring to the language itself, not to the libraries you would typically use), and if all you learn is C# you will have a hard time identifying the advantages and disadvantages of different solutions. 
&gt; Winforms is not "obsolete", or at least it is not "unusable" Obsolete doesn't mean unusable and I haven't said it was obsolete, I said it was considered obsolete by many. Last time I checked it was (and probably will be for long) still supported tech and it is even coming to .NET Core 3.0 in form of windows only compatibility pack.
Well it's subject on which many people look differently. To be honest you should probably learn both (and more) and just use the right tool for the job. As I've said in the first comment - I don't consider there being cross platform production ready .net solution for desktop apps, so you will not see me writing cross platform desktop app in c#, but there are people who disagree. Java is far ahead in that regard (but still not ideal to be completely honest). For games unity (which uses c#) is great - there are a lot of courses and tutorials and it seems there is no such solution using java. 
Any framework has things that are not compatible listing a niche case with very specific libraries and saying it doesn't work well is not really an argument. If you said there is no support at all for oracle or a wide swath of databases then maybe that is an argument but not a specific case. Every programming languages have things that they are not great at even java.
Hi, c# on Linux is "good" with mono but don't expect to get tons of support libraries and a smooth user experience like on windows. Java would probably be nicer to develop with because it's sort of built with cross-platform tooling in mind? Either way it depends on what you are building, good luck!
When VMWare ESXI is dropping desktop clients and going to web based interfaces you have to wonder how long desktop clients have to live. I am not saying they are dead now I am saying their future is dead. If your building a new app there is no point doing it desktop based unless you are deploying to old hardware which is probably windows. In that case C# is still the way to go.
Your absolutely right. If the OP want's desktop then maybe he is targeting old environments which are usually windows and thus C# should work best.
WPF is impossible to port, because it is heavily based on Windows API
C# is better for making games for following reasons - Has value types - Has real generics - Lot of games released with XNA/Monogame and Unity. Xenko engine might be big in future as well. - Cross platform games, even game consoles. I don't think Java runs on any game console. Ok maybe OUYA :) - Other engines like CryEngine added C# to be competitive - Lot of game companies here in Finland write their internal tools with C#. For UI in Linux maybe Java might be better there. But if I had to do cross platform desktop UI today, I probably do UI with Electron then run ASP.NET Core with it. Something similar to https://github.com/ElectronNET/Electron.NET It's been many years since I've used Java but back then after using C# Java felt like very big downgrade. I bet same applies today, does it currently even have something similar to LINQ or async/await? If I would ever have to go back using JVM and I could choose language to use, I would choose Kotlin over Java in a heartbeat. Plus Oracle suing Google because of Java really doesn't really help Java's future.
I can't quite grasp what you mean with the 'FromCurrentSynchronizationContext()', could you mock up a quick example on how to use it in this context?
Well then, guess I’ve just won half the battle against Cobra :)
Java and .NET developer here. I would use Oracle databases and PL/SQL over any other RDMS alternative, with the exception being MS SQL Server. You don't know Java developers.
I wasn't specifically talking about IDEs. I had more Nuget vs Maven or Gradel in mind. Might be a bit of an apples to oranges comparison, but Nuget just has a much more polished feel than both of them and is much more intuitive. 
Tell that to the European companies eagerly searching for developers doing native desktop and mobile applications for green field applications. It has been my major source of income the last four years, and there is no end in sight.
With a tinier portion of open source packages, comparatively with what is available on Maven central.
&gt; Plus Oracle suing Google because of Java really doesn't really help Java's future. It hardly made a difference when Sun did it the first time, and they would have done it a second time, if they had the money. Google could have bought Sun, but they thought they would get away with it, instead of like what happened with Microsoft and J++.
Mono is/was an independent implementation of c# and parts of the .Net framework for use on Linux and over the years sort of morphed into a cross platform way of dealing with smartphones with Xamarin I think you need to separate what you want to do with the best approach. While C# obviously works well for Windows desktop apps neither of your 2 choices are very good on Linux. Yes Java offers GUI libraries but they don’t work well from a user perspective and learning them aren’t going to benefit you in the long run If you really want to do Desktop development on Linux you really need to either go for one of the existing frameworks (gtk or qt) or go the new cross platform way (electron/JavaScript). The existing frameworks all offer access from c++ or Python 
Are you thinking of WinForms? That's mostly Windows GDI. I thought WPF did it's own rendering.
Granted
I'm not native English speaker and maybe that's why I have hard time understanding your reply. Does it mean that you really think Oracle suing Google didn't hurt Java's future? Or where you even replying to what you quoted?
Python has tons of abstractions as well. If you don't want those, use C. Seems like it's better to start with a statically typed language IMO.
Oracle charging for Java security updates is a bigger deal IMO.
Yeah let's not have OP start with C. To be a language you need features and Python has them but there's no Linq. That's what I'm warning of. For whatever typing is concerned your first month of coding is probably going to be string manipulations and number operations (or maybe mild interaction with a lib) so I'd argue typing isn't of importance. Single dev, single file, single day but do learn about `type()`. 
This is madness.
I'd argue Python's [list comprehensions](http://www.pythonforbeginners.com/basics/list-comprehensions-in-python) are pretty LInQ-like, albeit not as powerful. Starting with a REPL does seem like it would help, so Python has that going for it. I suppose you could start with C# interactive, but that seems a bit weird.
Neither you nor the other commenter represent more than yourself, so we can't say what Java developers as a whole think.
But now that i think about it, Microsoft provides a lot of Nuget packages and companies seem much more willing to let their developers use officially supported packages rather than 3rd party stuff. I've had a company tell me I couldn't use 3rd party libraries without going through this giant approval process, even though it was the communities generally accepted way of doing this and the package had millions of downloads. Microsoft has been doing a great job of supporting their development environments. 
Many do. What's the reason, not trusting every browser? How do you trust desktop framework then?
I agree. I've been a C# developer for years, and a few years ago I had to briefly switch to Java due to the nature of the project. I always embrace changing it up and using languages that I'm not as familiar with; in this case, I couldn't wrap it up and get back to .Net fast enough. Java seems...weaker. Less flexible. Less graceful. And a hell of a lot more boilerplate. 
If you really are just starting out, I don't think it makes that much difference which language you start with. If you get good enough to write any kind of gaming app from scratch, then you'll be good enough to be also pick up other languages easily. And learning multiple languages will actually just make you a better developer in your "main" language. I've dabbled in just about every popular language out there at this point. I've learned ***how to learn*** just about any new language. That's really the best skill you can pick up. Then language choice becomes way less relevant. And your tool set for developing solutions is wide open. Which is way more fun.
Yeah I am not sure about that. Obviously I am not in Europe so I can't really tell but I think your statement about "No one wants a browser controlling their air gaped laboratory robots" shows that fundamentally you don't understand how this tech works or why web based interfaces are on the rise. At least in the states there are tons of web based interfaces controlling robots. Also its not the browser controlling the robot it's the backend server that the browser site communicates with that is controlling things.
It doesn't matter, they are so similar. Please do not reply to this talking about linq or structs or reified generics, I know.
I would say with .Net core I would highly recommend c# over java.
While a number of replies were not helpful at all and didn't answer my specific question. I really appreciate everyone's responses trying to help me. But honestly speaking? I didn't come out with a lot. I think from what I have gathered so far is that C# is doable but not ideal for Linux. Which makes my choice even harder because now, do I stick with a language that is sub-optimal and might be challenging for me or go with the one that I don't prefer? Oh well. 
Why try those on Linux when you have .Net Core? Your not even making fair and accurate comparisons here. EF Core 2 is missing some features, but it's not anywhere near your claim of being 50%. Perhaps you have heard of Dapper? Why not use that instead of the heavy weight ORM? Core is a huge improvement to .Net that's also cross platform. Have you actually used it before? There is almost no difference between it and .net framework for day to day development.
Google did it because it wasn't wrong...
Im interested
You're going to be facing a lot of challenges from what I can guess of your situation. Many of those challenges aren't even going to be technical. I think you've gotten some good feedback so far. Let me add to that. You've been thrust into a software solution architect position without having much experience. That tells me your company most likely isn't a software shop and the project is probably in-house software. As such, whoever it is that you report to probably isn't going to care much about your technical problems. Sooner or later someone is only going to care about your progress. That is going to make it difficult to put down mature architecture up front. I also feel I should caution you about trying too hard to come up with a good architecture in your situation. You may end up suffering from analysis paralysis; don't let yourself get so worried about making the wrong choices that you become crippled to build anything at all. Next, your time is like money. You'll need to budget your time and where to spend it. For best results in a company that only cares about progress, you'll probably want to allocate the bulk of your time on functional progress (the stuff the user sees and cares about) and a smaller portion of your time on technical progress (the under the hood stuff the user isn't likely to notice but makes you happier and makes you more productive). You should make sure to prioritize *all* of your work, just like how you prioritize spending money. You should try to understand *value* of what your development options are. Value is essentially benefit/cost. If there is little benefit and high cost, you probably shouldn't make it a priority (even if it sounds fun). The cost part of the equation is generally easy since the most significant contributor to cost is your time (and there is only so much of you to go around). The benefit part of the equation can be measured in many ways. What pain does it solve? How frequently will the user use it? Will user error be reduced eliminated such that it might prevent future costly expenses (such as loss of data, public embarrassment, etc). At my company we often practice what we call "pain driven development". We focus on the areas that cause the most pain. That brings us to estimation. Estimating is hard. Personally, I'm not a big fan of estimating. What you really want is risk management. Sooner or later someone is going to ask you where things are at and how longs things are going to take. You should always be ready to answer these questions. You should always have a version of your project that runs *at all times*. It's really shitty when someone asks to see it and you can't run it. It doesn't look good at all. Risk management isn't an easy topic to talk about and there is lots of material on the subject. I really like the chapters about risk management in the book Rapid Development by Steve McConnell. Know what your low risk, medium risk and high risk items are (how much do you understand the problem and how likely is it you are going to get it partly/wholely wrong). Try to minimize the amount of high risk items your project has. Budget your time knowing that some items will come in quicker than you expected, some items will come in longer than expected, and every project outright has a tragedy at some point. Being prepared for these things can save your project from an executive nightmare. You should generally try to avoid using your job as a playground to try out new SDKs or technologies. An item that is high risk because it is a known problem but it is complicated is usually a necessary item. An item that is high risk because you don't know the problem or uses technologies you don't understand is something you should either avoid or get help on it. Sometimes it might be necessary to admit you can't do it all. See if you can hire someone with the expertise in the problem area to reduce the risk. If you are truly interested in learning the new SDK or technology, consider investing your personal time into it and write experimental projects to prove the technology before introducing it into your main project. When it comes to design for the software, my preferred approach is to focus on the *end* problem you are trying to solve (which in a lot of cases is reporting). Start with the thing the user wants and work backwards from there. For example, the user might want a report of some data; that report will likely dictate the data model; the data model will likely dictate the data entry flow; that will dictate the user interface. I use a product called ReSharper, an add-on for Visual Studio, that makes "flowing backwards" fast and easy, although the latest versions of Visual Studio can now do some of those things now. My comment is too long so I'm going to break it up into two parts.
Part 2 As I mentioned earlier, you may not be able to come up with *the prime architecture* right now. You can read all the books you want but it takes experience to be a good software architect. Here are some things that might help you get there. * Fail fast. The shortest option is almost always the best/right option but it has the added advantage that if it isn't the best/right option it also was the easiest to prove. In some cases, you may have something that will take weeks to build. Find the things you are the most uncertain about and prove them as soon as you can. You can easily avoid weeks of failure by targeting the things you are most uncertain about first. Sometimes that means making a shitty program test harness just to make sure the concept you want to try is going to hold up. * Build to unit test. Some people even practice test driven development (TDD) although it'll likely slow you down until you get practiced at it. TDD isn't strictly necessary though. What matters is that you think about how you would unit test a part of the code you are writing. That will help you write it *loosely coupled* (ties in with single responsibility) which might just be the most important thing you can do in any good software architecture. * Build to an interface, not an implementation. I usually design and write my code starting from the end. I write the line of code that produces the result I want, putting in symbols/variables for things I don't know I need yet. Usually those variable get typed as interfaces and then as I need methods I add them to the interface. The interface becomes a dependency that can be implemented later when I'm ready. This ties in neatly with the *Interface Segregation Principle* (see [SOLID](https://en.wikipedia.org/wiki/SOLID)). * As other people have said, try to avoid "newing" up objects inside of another object as this increases tight coupling and makes testing and future maintenance a nightmare. Either supply these dependencies in through the constructor of your object, or supply a factory method/object or an object provider to the constructor. * Try to eliminate "tramp data" - the act of passing parameters several method calls deep to get a parameter from the top to the bottom. This ends up forcing "middle" methods to know details that are irrelevant to them and can make refactoring difficult. A couple of solutions to this problem are to pass around a context object (consider using interface segregation principle with this for best results) or to make parameters something that can be exchanged with dependencies instead of passed to methods. * To make dependency management easier, consider using a dependency injection framework. There are many of them out there. Unless your software is performance critical, I would advise using a framework that is well documented or is simple to use. I prefer to use the Microsoft.Extensions.DependencyInjection.Abstractions NuGet package for dependency resolution because it's simple and allows for you to swap out the dependency injection provider later on if you think you chose poorly. It does restrict away some of the extra capabilities some other frameworks provide though (such as named dependencies). I don't think there is a one size fits all solution to this problem. * Get familiar with good software design principles and practices. [DevIQ](https://deviq.com/category/principles/) has a good collection of them but sadly I think the sorting/paging is broken on the site. It might take you a bit of sleuthing to read them all. Don't just read the principles and practices either. You need to practice them. Find ways how they can solve problems for you. Try to understand how these will make "future you" not mad at "past you". Also, too much of anything is a bad thing. People who grow into architects often end up going through a phase where *everything* is needlessly over-engineered. Which brings me to my next point. * Always write code like someone else is going to have to read it later. That someone else will probably be you three months after you stop looking at it and you won't remember what you did. If you can't read the code and follow what is going on, that's a problem. If you absolutely have to write something that looks confusing or unusual, make sure to leave a comment explaining ***WHY*** you did it (not what you did). * If you are going to write any documentation or comments in your code be aware that it is going to get stale. The best way to avoid stale documentation is to avoid writing it. Write documentation that is **important**. Avoid writing documentation for things anyone could just figure out by reading the code. Keep high level documentation that tells you *where to start looking* and then you can read the code the rest of the way. Always focus on the "why" you did this, "why" you would use this, and how everything fits together. * Avoid writing something that someone else has already written. This is the best way to go almost all the time. If you absolutely have to rewrite something or reinvent something, make sure it's because your solving a problem *worth* solving. Maybe this point should be further up in my list. Remember, you have a time budget to work with. * It's generally a good practice to encapsulate logical divisions in your software in layers. View layer (what the user sees), view controller layer (to put the data into a form the view can work with, and to take the user input and put it into a form the other layers can work with), business/services layer (to perform business processing and apply business rules to data as it flows back and forth through this layer, or to perform technical processing not database related), data layer (provides a programmer centric interface to data storage and performs some data validation). What you do in the database itself can be a mixed bag of arguments if you get into conversations about it but I strongly support the idea that only data constraints belong in the database and business logic should be in the software. I'll finish up with some comments on your question about database SDKs. I personally hate Entity Framework and other persistence frameworks but they can save you a lot of time if you use them for what they are good at and make sure you don't try to use them for what they are bad at.Entity Framework (and other persistence frameworks) are usually absolutely terrible at working with large sets of data. If you're just building some simple screens with forms then Entity Framework will work good for you but if you have to do large volumes of inserts and updates you're going to find persistence frameworks hard to work with.Persistence frameworks also have some hidden gotchas to watch out for. They almost always have a "context" of objects. If you work with objects from more than one context at a time then shit is going to get real ugly fast yo. The errors you get from these frameworks can be pretty confusing and sometimes point you in the wrong direction for solving the problem. I have spent days tracking down a problem I thought was in the database only to eventually find out it was something I was doing in code.What persistence frameworks are really good at doing is helping you make changes to data objects through some very complicated and long method call graphs and only writing out the changes to those data objects at the end. Each method can touch the object(s) it needs, potentially being touch by many methods, and then only getting saved once.This can also be accomplished with a good implementation of the repository pattern too but it is more work. Some people encapsulate a persistence framework behind a repository pattern. I personally think that is redundant, error prone and confusing but that could start some theological debates on the subject.If you want an alternative to a persistence framework that does work well with all kinds of databases, consider using Dapper. It's just an "object mapper" but does some of the best parts that people often use a persistence framework almost exclusively for and that encapsulates very nicely behind a repository pattern.I've exhausted all my thoughts on this subject for now. I hope you find some/all of this useful. Good luck! 
I wanted to throw in one more part about *technical debt* and *technical investment* because I think they are important subjects for long term development. Think about technical debt and technical investment like money debt and money investment. Too much debt and you'll go bankrupt; too much investment and you wont actually spend anything on what matters. Furthermore, debt can be good. You'll probably borrow money to buy a car or a house. If you didn't, you might not get the car or house you want. Investment works like it should sound. It costs a lot to get off the ground and you usually don't see results for a long time but eventually it works for you. Technical debt is basically writing things shitty. You know it's garbage. It disgusts you when you write it but you have to get shit done. Sometimes it is necessary; you simply don't know how to do it right. It's better to start with garbage than nothing at all. Software development usually has roller-coaster of panic, stress inducing crunch cycles where shit has to get done "now, now, now" and then lulls of time where, I dunno, maybe there are fires somewhere else in the company and no-one is looking at you; all of a sudden you have time on your hands. The crunch cycles will be where you end up borrowing from the mob-boss. It's dirty money and if you don't pay it back, he'll break your legs. The slow times are your time to invest or pay back debt. Don't waste those times. Too much technical debt will kill your project. You should make room in your time budget to pay down technical debt. I usually pad my regular functional development with an extra day to make *something, anything* just a little bit better. And use *the boy-scout rule*; always leave things as good or better than the way you found it. If you software development only has one never ending crunch cycle, GTFO. Seriously. Start looking for another job because your current job is just setting you up for failure and misery. Just like money, balance your expenditures, debts and investments for the best results.
&gt; C#, Visual Basic, and C++ compilers apply the Sequential layout value to structures by default. https://msdn.microsoft.com/en-us/library/system.runtime.interopservices.structlayoutattribute(v=vs.110).aspx
I actually used to work at nventive and was on the platform team that built Uno! 
Windows Forms actually is "cross-platform"; I don't know the extent of it but it was enough for me to run a rather complex WinForms application via Mono on Linux a while back. The main limiting factor is of course that a lot of applications that use WinForms and thus the standard Win32 controls also expand or use additional features through P/Invoke., either directly, through libraries, or through add-on controls. With WPF I think the "binding" is less Win32 itself and more to DirectX, since it does everything via DirectWrite. I expect that would then need to be ported to OpenGL. Even a very good port would need to be tested for each program, I think; while it might be less extensive in WPF a lot of WPF applications do also use P/Invoke to utilize certain features. 
https://stackoverflow.com/questions/4331262/task-continuation-on-ui-thread has a good minimal example. More specific to UI though would be: private void MouseClickEvent(object sender, MouseClickEventArgs e) { CPUIntensiveTaskResult result; Task.Factory .StartNew(() =&gt; { result = this.DoCPUIntensiveTask(e); }) .ContinueWith(() =&gt; { this.DisplayOnUI(result); }, TaskScheduler.FromCurrentSynchronizationContext()); } I think... }
Oh really? Anything in particular I missed in the article?
Oh really? Anything in particular I missed in the article?
WOW! You were pretty much dead on in EVERYTHING you wrote. That really is some amazing insight and I really do appreciate you taking the time to give me this incredible advice. I will definitely look into all of you have mentioned and sincerely take it to heart when this project really gets underway. Again, thank you so much! You rock! 
awesome but i love Flutter for make some app native :)
Hell yeah -- https://xkcd.com/1053/
Yes, use Google!
Meanwhile, I just passed on a $65/hour contract gig because it involves using Oracle with .Net. I'll use just about any other major RDBMS with .Net, but Oracle is a massive pain in the ass, and not just from the perspective of coding with it. Using Oracle by itself is just a pain compared to most other solutions.
I’ve only ever worked with Ms-SQL and Postgres in .net, what makes Oracle a PITA, besides their insane licensing labyrinth?
When you say games, what are you looking to do, 2d platformers, interactive fiction, 3d games, something else? For desktop applications, if you want to use core, you have few options at this very moment, but Avalonia looks very promising. Overall, C# is completely fine on Linux based OSes in my experience, 
*"note they recommend using Firefox or Edge for the best results"* The fact that they have to say this raises a red flag about the ease of deployment cross platform....
I think it’s actually in relation to web assembly not the platform itself. 
In my experience at least, it seems to be a reliance on Oracle to provide the support necessary to get anything done with their platform. I was on a contract gig with a major telcom in a branch office, and was helping them transition from VB.NET and WebForms to C# and ASP.NET MVC. We needed an Oracle provided library to get shit to work cleanly (read: as/about as nicely as if you were working with MS-SQL), but tracking down the exact library was a pain, so much so the developer charged with the task requested the wrong one to be white listed by IT for inclusion on their install list. We didn't have admin rights to install stuff on our machines, everything had to be pushed to us by the main IT department. Well this library didn't work so we identified the right one, but IT refused to consider it because they felt we'd wasted their time already with the wrong one. Absolutely wouldn't have been an issue if they were on MS-SQL. This was back in 2015/2016, so maybe that's changed by now. On top of that, Oracle does some things their own way that's pretty dumb in most cases. For example, auto incrementing something like an ID value in a table. MS-SQL makes that easy with the Identity keyword, MySQL has AUTO_INCREMENT, and even Access, *fucking Access*, has AUTOINCREMENT which is basically the same as MS-SQL's Identity. Wanna do that with Oracle? You have to create what's called a Sequence, name it, set its properties (min value, starting value, increment value, and a cache value), and then call that named sequence piece as part of your query. It's not like MS-SQL where you don't even have to provide the ID value, it just figures that out for you so long as you set up the column to use the Identity feature/property. Small potatoes I suppose, but annoying enough that it just felt like Oracle made me do extra work that other RDBMS systems don't. I believe more recent versions of Oracle have something like Identity now, but at this point I don't really care. Plus there's all the bullshit with Oracle suing Google over the Java API, so in general Oracle can go screw as far as I'm concerned.
I'm confused on your description. Are you saying you are passing in an object to a custom or control's constructor? And you want the object passed in to be put in a list (contained in the custom control?)? And you want this item to be displayed using a DataTemplate? If you use an ObservableCollection&lt;T&gt;, bind your ItemsControl (or ListBox) to that collection, and have a DataTemplate for that type of object without a Key parameter named, it will automatically use that object's datatemplate to display the object and automatically update the ListBox with that item.
You can use a `while` loop: while(true){ randomNumber = ... Also, rather than just `while(true)` which will loop indefinitely, you could also use a variable to hold some basic representation of the game state. For example: bool correctAnswer = false; while(!correctAnswer){ ... if(randomNumber &gt; 50){ Console.WriteLine("Correct!"); correct = true; } }
https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/iteration-statements
You could put your switch inside a while loop that runs until the right answer is given. Like this: bool rightAnswer = false; string inputGuess = ""; while (!rightAnswer) { inputGuess = Console.ReadLine().ToLower(); switch (inputGuess) { // Have the same stuff in here, except that after getting // it right, with the "Correct" message, go: rightAnswer = true; } } The while loop will repeat as long as rightAnswer has not been set to true. So it will let them enter guess after guess after guess until they get it right and rightAnswer becomes true. After you come out of the loop it can only be because the answer was right and you would put maybe another ReadLine there and a prompt to press enter to exit or whatever.
I have a ListBox with its ItemSource set to an observable collection. I want to use the custom element I made, that takes the type that's located in the collection, as the ItemBox's DataTemplate. // DataTemplate public class View { public View(Data data) { } } // Data public class Data { } // Source class Source { public ObservableCollection&lt;Data&gt; Data = new ObservableCollection&lt;Data&gt;(); }
Sounds promising. Now I know what framework to pick up and inevitability abandon for my next unfinished side project. 
WPF hides its implementation details better than Windows Forms ever did, and Windows Forms works reasonably well. I think the issue is the amount of work required.
&gt; I would use Oracle databases and PL/SQL over any other RDMS alternative Seriously? Why? It silently commits transactions if you have DDL in them, and it lacks a UUID datatype. The database/schema/user thing is pants on head.
It looks like you already made up your decision before you even posted. If I took a count of the affirmative posts in here they would far out number the negative posts. So your comment of not coming out with a lot and not being ideal for linux is just disingenuous. Good luck! 
This isn't true, it does matter what language start with. For most languages it doesn't really matter that much but if you start with functional language like F# you will have hard time moving to object oriented or procedural language like Java, C#, JavaScript, C, C++, Go or Python. Same is also true other way around.
its a C question, not C#
I don’t know how but if my proof of concept works I loose interest. 
Too real 
Add a label called start or whatever and once you need to jump to it just type goto start;
Because you are missing the big picture of PL/SQL tooling, cluster support, distributed transactions, graphical tooling for database modelling and quality of language drivers for C++ (proper C++ instead of C), Java and .NET.
Because as external consultant, one gets to use what the internal devs are currently using and they won't migrate to whatever an external dev says unless there is a sound business opinion to change their current way of working.
That was my point.
Using old Oracle versions? Auto increment fields are supported since Oracle 11g.
You don't have to pay for security updates when using OpenJDK. Sun also did the same with their closed source EOL JDKs.
Yeah, right. Microsoft wrong, Google (favourite tech company), wasn't wrong.
Quoting Gosling here, [James Gosling: The Success of Java](https://www.youtube.com/watch?v=8BsaOqBD-Uo) [James Gosling: Oracle vs Google](https://www.youtube.com/watch?v=JQ7xVO9lqD0&amp;t=8s)
No it shows the experience of some of the work I got payed to deliver this last couple of years. Using a browser is definitely not the way to meet the hard real time constraints of such environments.
So Sun did it before? That does sound equally bad as well. Charging for security updates, how can that ever be defended?
Again you are replying without really replying to what I wrote.
Easy, don't want to pay? Use OpenJDK or upgrade to an actual up to date version. If you insist in using something like Java 1.4 in 2018, then well...
You are the one not bothering to understand. With my Java developer hat on, I want to be able to use whatever library I feel like from Maven central on my Android projects, instead what Google did to Java prevents me from doing that, as I get to search for libraries written to Android Java subset.
&gt; and the tooling built around it just blow the Java environment out of the water. LOL, nice joke
Nuget is a joke compared to Maven central, are you a troll ?
Do you understand what they said, or you being naive on purpose ?
If you really want to do games, I mean ones that you are actually going to sell some day, then C# is a no brainer. But if you want to be a programmer living by programming, then making games to do that is very hard, maybe even extremely hard. Creating other software will pay your bills better. Not sure where you live but at least in Europe Microsoft has big foot hold and making software with C# is really high demand here. I think most people in game business use Windows operating system even if actual finished product is running on Linux. IDE situation for Java on Linux might be better, but I've been using JetBrains Rider on Windows and it's pretty awesome, someways better than Visual Studio 2017. It should work similarly on Linux. For Linux computing Microsoft is really putting their weight to get C# running well on cloud and on Linux on general. I don't think there is any GUI from Microsoft planned for Linux. Maybe Xamarin Forms will someday work in Linux who knows. Creating web services/sites with lite IDE Visual Studio Code should be good experience. I think creating 2D games using Monogame might work with it as well. Monogame runs on Windows, OSX, Linux, Xbox One, PS4, Nintendo Switch, Android and IOS. Maybe other platforms as well. I suggest learning C# first because it's more advanced and then learning Java and see if you can live with lesser language. I have some Java programmer friends that are moving away from Java, well actually their companies are moving to JetBrains Kotlin language that runs on JVM (Java Virtual Machine). So you can use same libraries etc. with Kotlin. They have been bashing Java for ages but only have good things to say about Kotlin. Good luck to you! 
How is your experience with Flutter?
async await does not do locking for you. I had a bit of extra info, but basically that's all you need to know :)
It's just an example I wrote to "simulate" why locking is required, but would it be possible to fix the problem without using lock ?
Thank you for the help!
Thanks for the help. Just curious why you're being downvoted. I wonder if there is something that people don't like about 'goto'.
As soon as you have parallel execution paths you need to synchronize access.
There is no magic fix to using non-thread-safe collections like `List&lt;T&gt;` in multithreaded code. The only way is to prevent concurrent access, e.g. with the `lock` statement. A possible alternative is using [concurrent collections](https://docs.microsoft.com/en-us/dotnet/standard/collections/thread-safe/) which are designed for multithreaded access. There is no one-to-one equivalent to `List&lt;T&gt;` however. Another option is designing your code in a way that the work is performed in multiple threads, but the results are added to the collection on a single thread that awaits the others.
var joinedtable = context.customers .Include(u =&gt; u.ContactDetails) .Select (x =&gt; new YourViewModel { Name = x.Name, Contacts = x.ContactDetails. } .ToList(); 
No problem, I don't get it either but oh well 😛
I guess he is being downvoted because using 'goto' is considered a bad practice.
!RemindMe 6 hours
I will be messaging you on [**2018-07-15 18:59:33 UTC**](http://www.wolframalpha.com/input/?i=2018-07-15 18:59:33 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/csharp/comments/8yxqnq/cross_platform_mobile_apps_with_net_and_uno/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/csharp/comments/8yxqnq/cross_platform_mobile_apps_with_net_and_uno/]%0A%0ARemindMe! 6 hours) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
I think there isn't nothing wrong to use Windows while you are developing with C#, as it's the language you already chosen as the best for your purposes. It's not a sin to leave Linux while working with Microsoft technologies, by the way... Forget all this Windows x Linux bullshit and do what it's best to reach your goals!
!RemindMe 1 year
In general, `goto` is extremely bad practice and _rapidly_ reduces readability of code. It should never be considered as a first option, or second. OP clearly just needs a while or do-while loop here. Restraint needs to be used in programming. Don't throw a nuclear grenade to open a door when you could just twist the handle.
Not at all. There are people that say there are absolutely no disadvantages to using C# in my case. While others say that .net core is not suitable for me because it can not make GUI applications. But then there is mono and Avalonia which are all quite confusing because I don't know if they are stable or not. Which affirms what I said earlier that either I go with sub-optimal path of C# or Java. Once again, I still appreciate all your answers. They still helped me know a lot more and go deeper into this subject.
Thank you very much! That is a really helpful answer. I do agree with you about the gaming part. While I would love to work in that field. My priority was making desktop applications and learn a language that would help a potential future in the gaming industry. So I don't need to focus on gaming at all right now. I will take it step by step because no language is truly perfect and can do everything. Which brings me to the second sad fact which is rider not being free. It sounds amazing and I always read good things about it. However, I can't afford it nor am I student who can qualify to get it for free. So "I don't think there is any GUI from Microsoft planned for Linux" means I don't have a lot of choices. Java is the only one left for me. Am I correct?
How about you actually write something that relates to what you are replying to and not write something unrelated? It feels like trolling.
Online, non browser games like in the MMO genre. It's just a dream that I aspire to reach but I think it's wise for me to put that aside for now and firstly start out with desktop applications and take it step by step as I just mentioned below. Is C# truly fine for creating GUI applications on Linux?
I know this will probably sound silly to all of you but my ultimate goal is to expand in on the Linux platform as much as I can. To aid in more cross platform accessibility.
I wonder why you got down voted? I think the only statement I disagree with is "it takes much longer to learn C# than to learn Java" but otherwise, you were on point with your advises. At least from what little knowledge I have.
Still I think your confusing things and you really don't know what your talking about. Even webassembly is a web application running in browser. A huge number of apps running on mobile are now web based applications converted to native using tools. Look at Xamarin, React Native, Native Script, Cordova, etc. These areas are not getting smaller but increasing. Saying there are nice demos at JSConf and that there is not actual apps being delivered is just wrong. Spotify, VSCode, Discord, VMware, Grafana, and many others are not small apps they are complex apps built using web technologies to drive the user interface display. 
Web Assembly: Uno: (Check) Yes Xamarin.Forms: (Squiggle) Yes It’s the same answer, but you give Xamarin.Forms a squiggle instead of a check to make Uno look better. That’s pretty damming of a bias blog post. 
Sure, you can use Monitor or ReaderWriterLockSlim, but you need to manage locks. Even things like ConcurrentDictionary only provide atomicity for certain operations. The async await revolution relies a little on changing behaviours, so things like mutable state are anathema. Where you do need mutability, and it happens a lot, then you need to be proactive in managing it. That's a really blunt answer, and this is a really tough topic to get your head around at first, so feel free to ask more questions :) 
What does “Edit &amp; Continue” mean? Flutter and React Native’s hot-reload feature is incredible. It allows you to see your code updates running on in the app in real-time without needing to re-compile/deploy the app to a device/simulator. Does “Edit &amp; Continue” offer that level of productivity? Or is it similar to Xamarin.Forms’ XAML Previewer, which allows you to see XAML updates in real-time, but doesn’t incorporate any C# code-behind changes. 
The nice demos remark at JSConf was regarding what it takes to deliver user interfaces for industrial applications in factory automation. I wasn't talking about Spotify and friends. Xamarin and React Native are a tiny market of the overall applications in the mobile space. Go check how good it worked out for Air BnB and Udemity. The fashion trend is already fading away.
It is worthless to explain when there isn't any willingness to learn. 
Why would you use rider? Use VS Code which is free and runs great on linux. Honestly if you telling the truth in your post you should use C#. There is no reason to use Java. There is no future in native desktop development. Look at apps like Spotify, web based. Even games like PUBG use a web based interface. Blizzard's Battle.Net launcher web based. Unless its graphically intensive UI based apps are going towards thin web based interfaces with backend servers. If you want to prepare for the future Java is not going to help you. No one is going to want your Swing experience from Java because Swing apps look like crap. Just look at Eclipse does anyone think that app looks decent? Compare that to something like VS Code which everyone is using now a days its web based with backend servers written in C# and other languages. Unity is used all over the place and if your at all interested in applying your work to gaming eventually I would learn some web, C# and unity. Either that or C++/C. Learning Java is going to get you anywhere. 
If you replace main with something like: static void Main(string[] args) { Task.Run(async () =&gt; { List&lt;Task&gt; tasks = new List&lt;Task&gt;(); for (int i = 0; i &lt; 100; i++) { tasks.Add(TestThread(i)); } await Task.WhenAll(tasks); }).GetAwaiter().GetResult(); } Then everything will run on one thread and you don't need any synchronization. Most real world apps are going to have more than one thread, in which case things aren't this simple.
I don't understand this dedication to Native GUI applications. Now a days most modern applications are not native. Spotify, Discord, Slack, VSCode, Grafana, Skype, etc. All of these apps are not native apps, but web based with backend servers. If you actually believe at all that gaming is more important than desktop clients you would do C#. If you believed that modern desktop development was more important than old ass Java apps, then you would do C#. If you are interested in the easiest possible path to learn skills in making old looking native desktop clients you would do java. In all other cases the answer is clearly no.
Yea, as with every chart like this, you should take it with a grain of salt. I mean, whos going to highlight what a competitor would do better than the advertised company? All these charts from the companies site will always be swayed one way. But the rest made me wanna try it just to see how simple it really is. Xamarin.Forms is still kinda bad in my experience recently 
What’s changed to make it worse recently? I’ve been developing apps in Xamarin.Forms for the past 3 years, and it is infinitely better today than it was then. 
Industrial Applications in factory automation that is awfully specific. I will go check out Air BnB and Udemity. My cursory knowledge of industry has me thinking that maybe for those areas its not ready but thats more of a time thing. I think the fact that most other areas are going that way will force them to eventually go that way as well. Maybe its not industrial applications but you look at things like Prometheus, Kubernetes, VMWare, Hyper-v, Azure, AWS. Applications dealing with industry level monitoring and control of datacenters and server clusters, and most of them are moving towards web applications. 
&gt;It’s the same answer How so? Uno is obviously producing hybrid web apps running through webassembly, Xamarin.Forms is mobile native (cross compiled or not) and not running through webassembly or otherwise a hybrid web app.
My apologies for my lack of knowledge. This whole time I thought that the only way to make GUI applications was through the native way. Web based to me sounded like it had to run through a browser. But building up on what you stated. That means I have to create a server for each application I make? Is that even doable for someone like me?
&gt; How so? Both answers are “Yes”
I'm not really familiar with Java GUI offerings. Lot of UI is moving to web so companies do less desktop apps in general. Companies that still write cross platform desktop apps that also run in Linux seem to be using something like Electron or similar. That means they are actually writing them in JavaScript or something that transpiles to JavaScript like TypeScript. TypeScript is pretty awesome if you need to write something for JavaScript platform. Even Google is using it Angular 2+ and Vue.js 3 is moving to it as well. I hate to say it but I think JavaScript world is probably best choice for cross platform desktop apps if Linux must be supported. As an example Visual Studio Code is created with Electron. I think Electron supports WebAssembly so I think it's possible to write performance needing part of code with some other language. You could also do UI with Electron and run it side by side with ASP.NET Core and use C# for everything that is not UI. See this project https://github.com/ElectronNET/Electron.NET . If Linux support is not needed then Xamarin Forms might be a good choice as well.
Aren't you adding unnecessary delay &amp; cost by using S3? Couldn't the initial API call for sending the image trigger a Lambda-function which uploads the image directly to Rekognition?
Its a shame that I couldn't get it to work...
Its not his comparison, its the comparison from their homepage.
Edit and continue means you can be running your application and make edits to the code without needing to hotload or recompile. Its been a standard feature of visual studio for 10+ years now.
It really depends on what you’re defining GUI to be, if you’re okay with having either an electron.net based or straightforward honest browser based front end, core is good to go today, I have things in production at my company that use asp.net core and a browser front end as well as daemons that run in .net core on Linux machines. If you need, or just want, a native UI things get sticky with .netcore and a little annoying with mono. Mono already has a fully functional c# wrapper for GTK2/3 but then you’re working with GTK. If you have experience with that toolkit and are okay with it, more power to ya, if you don’t and don’t have experience with Qt, go for it. I’m not sure about how well, if at all, GTK# runs on core, but there is the option to use Avalonia which is a XAML based approach inspired by WPF. Avalonia isn’t 100% stable yet but it’s very promising. Now, there is another option for desktop applications that I basically have never heard suggested by anyone, but you could write an application in asp.net core, just a bunch of api controllers, then write a JS or TypeScript client, and use that in a QML based Qt application. The application would spin up the backend process to listen to localhost on some port, then fire up the QML document and from the user’s perspective it’s just a native application. Somewhat like the idea behind Electron, but without the overhead of running Node AND Chrome at the same time, and you get all of the work the Qt team put into making QML very snappy. tl;dr: it, like soooo many things related to computing and programming, depends. 
Removed: Rule 3.
This is a really good question. In short: what you suggest can be done, so it is an absolutely valid approach. The Amazon.Rekognition.Model.Image type that I pass to the DetectLabelsAsync method has a Bytes property which can contain the image as binary directly. - So instead of using S3Object by using the Bytes property we can do the same without S3. (see here: https://docs.aws.amazon.com/rekognition/latest/dg/API_Image.html) 2 things I’d add to this: -You have to deal with passing binaries to your lambda -More importantly Rekognition only supports max 5MB images through the Bytes property. By using S3Object as image source this limit is 15MB (see here: https://docs.aws.amazon.com/rekognition/latest/dg/limits.html ) In fact you can use Rekognition directly from an iOS or UWP app, so you don’t even need a lambda here. So yes, you can definitely optimize things. And another side note: My goal with this video was to show how .NET and AWS work together, so I wanted to target a scenario that uses multiple AWS services. Thanks for your comment! 
After reading your reply more carefully I noticed that you would want to create desktop apps for gaming industry. I was in gaming industry very long time ago. I still meet people who still work there from time to time and I know that their tools are created with C# and use Windows GUI. So they are only running them in Windows, here in Finland anyway. If you really want to go that path I would start creating Windows only desktop apps. Example embedding in-house 3d engine to Electron app might not be that easy.
Upvoted for AWS. It's good for .NET developers to walk outside MS and know that are more tools to work with.
Thank you very much everyone. I can't possibly appreciate all the feedback and input your poured into my knowledge-lacking post from a beginner like me. I'm in your debt. I have chosen the the C# path and I'm quite confident it is the future. While that will be my main focus, I will still strive to go beyond and learn more after that. Obviously that is not going to happen anytime soon as I still have a long way to firstly get a good grasp of this language. Thank you once again!
Yep, and thats sad. Pathetic that people resort to downvoting instead of explaining why you shouldn't use 'goto'. Sure it might not be the best way of doing stuff, but it is a solution that matched OP's needs.
Common misconception. Server sounds like a big daunting word but its just a console app/process with some web endpoints. In 10 seconds flat you can have one up.
Hey, you definitely succeeded on that goal! It was a nice scenario and I'm a big fan of the show too. That 5/15 MB difference is pretty big, plus having the bucket will be nice for historical reasons - that data may be valuable in the future. And the demo acted very snappy regardless... Another idea about the architecture: couldn't you have achieved the same demo but done in one API call? I believe you call AWS once to upload to S3 and again to invoke the Lambda? This also forces you to have the API keys embedded right? What if you used API gateway with a Lambda that both stores on S3, and invokes the Rekognition-lambda, and returns either true/false. You'd be down to a single API call without the security concerns?
You act like karma is valuable. Also, goto absolutely doesn't work in this scenario, so your solution is wrong. Nobody is obligated to argue with you over basic stuff.
I have a couple of Windows Phone apps I might port to UWP and use this to bring it to other platforms. Shouldn't be that big of an investment although my apps are using the old WP UI patterns so reformatting the UI will require some work but if I can ship them on iOS and Android it will be worth it
I would like to quote Stephen Cleary Guidelines for Lock-free Programming Don't https://blog.stephencleary.com/2014/02/guidelines-for-lock-free-programming.html Instead try to minimize time inside lock.
:shrug:. I replied to your comment about not understanding why people would downvote and I was downvoted. Maybe it's "safer" if you care about votes to just downvote the person. Maybe people would be more willing to tell you what's wrong if you upvoted them for disagreeing with them but explaining why?
Good to know. That’s how Hot Reload works on Flutter and React Native. 
All stuff for VC pumping money into startups, most of our customers run their own IT stacks.
Maybe because xaramin forms running in we webassembly is coming but not here yet?
[removed]
You only need the program.exe Regards.
If you build it as a class library targeting the proper version of .Net Standard you'll be fine. For version compatibility, consult https://docs.microsoft.com/en-us/dotnet/standard/net-standard
You will need Program.exe If you need the conifguration files, include Program.exe.config Obvisuly, the target PC will need to have the target .Net Framework and Wpf
You _probably_ only need `Program.exe`, but possibly also `Program.exe.config`, depending on whether the configuration information inside is essential. As your program grows in complexity, there will probably be `.dll` files you'll also need. Even without any `.dll` files in your `bin`, your friend may not have the right framework or you may have referenced code that is in your GAC but not everyone's GAC. You need to make sure everyone has the right framework version (or consider downgrading yours to increase compatibility) and the right dependencies (or consider shipping your dependencies alongside the app). You never need any `.pdb` files; they're for debugging information (but you may sometimes want to deploy them, too). There's never any point in deploying the `.vshost.*` files; they're only for your local debugger.
Thanks for your help. I took a peek in the config file and it just says the .net version, so I can't imagine that's vital. I assume most windows PCs will have some form of .NET installed, or does everyone need to install it?
Thanks.
Thanks.
This is very likely a timing thing that is harder to catch while you are debugging. Writing to standard out also gives the alternate thread just enough time to instantiate game. Maybe you can consider using async / await instead of a while loop?
What exactly are you trying to achieve here?
It depends on the type of edit. When editing the code behind you must pause and continue. XAML can be modified without stopping.
Thanks for the nice words! :) Yes, with API Gateway you can achieve that. When you create a project you can select the “AWS Serverless Application” template, that automatically configures API gateway with CloudFormation for your app (in the video I go with the “AWS Lambda Project” template). So API Gateway + HTTP is also a good architecture for doing this, and yes, that would be only a single call. 
Optimizations. In release mode it sees that you never change the `game` variable inside the loop, so it caches the value and never rereads it from main memory. Adding a `Thread.MemoryBarrier()` to the loop just before the read and after the line where you write to the variable should fix the problem. However, using a real lock would be safer.
100% agree. Thanks for the upvote! 
Mark game as [volatile](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/volatile) The compiler assumes it's not going to change and isn't checking it.
I'm thinking a semaphore would be better in this case. Yes it will block a thread, but it's a bit clearer as to what's happening.
I'm trying to create the Form on a different thread than the main game process
Maybe I'm just inexperienced, but what makes that more clear?
async/await wont work because `Application.Run()` is blocking
Blocking in a separate thread. You await that thread's return in your UI thread. 
You're welcome. Thanks for the video.
A lock doesn't seem to work because I cant ensure that the new thread locks first.
Looks like that works thanks.
Ohhh, you only want to await Game construction, not the entire Application.Run(). I misunderstood. 
It doesn't return until the window closes. Or am I misunderstanding?
yes, tho I feel like there may be a better way than this for me to do this, but I don't know.
You can have an async Main now. No need for the Task.Run anymore.
Can you call these two lines in your main thread? Application.EnableVisualStyles(); game = new MeteoraWindow(new MeteoraTriangleView(), 1920, 1080);
no, because WinForms doesn't allow me to run a form that was created on a different thread.
I didn’t make the comparison chart? If you went to Unos website you’d actually see that they’re the creators of the chart not me
You need .exe and .exe.config plus .dll files.
It’s actually not “obviously” that at all. If you went to their website they show the whole systems android and iOS components are based on Xamarin.Forms and so they’re about as native as the Xamarin.Forms apps are. 
If you have any further questions about Uno I would go to their website and view their docs or contact them on twitter as they’re quick to respond in my experience. I’m not a developer on the library btw, just someone who was intrigued in the product and wrote an article. 
If you don’t want the program to crash or misbehave if people have a too old version of .NET, you might also want to keep the program.exe.config.
It’s vital in the sense that it ensures that the program won’t attempt to run on older versions. It otherwise will. 
Oh should rather create game processes on different threads, or tasks. 
Technically just the EXE but that is making a massive assumption as to what version of what dependinces that person has. Provided you are using the most basic .NET features and no 3rd party libraries you should be fine. Otherwise you may need to bundle copies of the libraries you are using. 
What you have there, is a Heisenbug
I've had nothing but compatibility issues with .net core. Maybe I'm doing something wrong, but it's sandboxed nature has prevented me from using anything third party, and even MS capabilities are limited. Can't interact with hardware, can't interact with the filesystem outside of the installation directory and then only in frustratingly limited ways. They'd added stuff for 2.0, but that does nothing for my apps already in production.
If, let's say, your program compiles against .NET Framework 4.6.2, computers with 4.6.1 or older won't be able to run it.
That's UWP rather than .NET Core specifically?
You're absolutely right. I was conflating the two.
Why’re u starting the game in a separate thread only to wait for it to begin on the main thread. This feels needlessly complicated. S.N. Love the tohsaka in glasses thumbnail image.
Any reason why you're creating your window in a new thread? Sounds like a very weird thing to do. Usually in these scenarios your Main only invokes the window, and then in the window you listen for an event (like Load) to invoke all the logic.
Someone solved your issue but i dont like it. Is there a reason you aren't using monogane? 
I'm writing my own game engine
I've tried that but then the main loop will block the load event, and I've run into other threading issues when I have game logic on another thread, It was easier to move window logic to a new thread than everything else.
I name it game, but it's only the window that holds the vulkan surface, not much else happens on that thread. Also thx :)
&gt; Heisenbug First time I've heard this term, now I know what to call it.
I still think you're solving this the wrong way, though. Of course, it may be more difficult to help you with that here in the comments.
that may be how it ends up being, also to support multi-threading. Since I'm writing this game engine myself it's all evolving as I learn the nature of the vulkan api.
It very much will change, because I also want multi-threaded game/rendering logic, which this doesn't allow me to do. But for now this is a good enough solution for testing the implementation of my engine.
Mono is on the way out. dotnet core is the future. I coukd write a long explanation but i advise looking up dotnet standard. Every framework is required to meet standard. So you know it will be available. 
Thank you. Sorry if this noobie question, but If I read correctly, you are making a list of viewmodels with that code? And in terms of architecture, you would file that in a dataaccess class?
I am beginning to think your delusional. VS Community is great and definitely blows Eclipse, NetBeans out of the water. Refactoring as of 2017 has been pulled out of the tool and given to the community. You can now install nuget packages that offer roslyn refactoring with an easy as one click. Code Coverage is available via opensource extensions. 
Wow just wow. If your doing any kind of professional IT Stack and not using VMWare, Hyper-V, Kubernetes, or similar tools than you are not a professional company.
This is personal opinion, but I think this is really clear: Original code: thread.Start(); while (true) { //Console.Write(game); if (game != null) break; } New code: thread.Start(); _GameCreated.WaitOne(); 
 while (true) { //Console.Write(game); lock (gameSyncLock){ if (game != null) break; } } Application.EnableVisualStyles(); lock (gameSyncLock){ game = new MeteoraWindow(new MeteoraTriangleView(), 1920, 1080); } Application.Run(game); game.Dispose();
FYI: Using volatile is equivalent to using Thread.MemoryBarrier() whenever you access the variable. 
For the stopping one node before, you check if current is equal to end and then return path, but you don’t add current to path until the end. This means path is missing the last node. You should probably just add current to path right before returning.
Now that I look closer, it seems that there are a lot of places that don’t make sense in your code, for example, there shouldn’t be a single path, A* works by having every node store the best previous node and updating the best previous node every time you find a better one. Then, at the end, you walk backwards following each previous node to reconstruct the path. Also, you get the G score but never use it. The idea is that each node has an F score which is the F score of the previous node plus the true cost to the current node. Then by comparing the G score + F score to the previous value, you can see if this new previous is better than the last previous. I would recommend reading the algorithm again and maybe finding an easy to understand explanation.
i like that framework, i'm begginer with it.
I feel dot net will probably still stay bunch in a much smaller form solely due to being (from what I see) the best solution for Gui stuff using c#. I would love to be proven wrong thoigh. 
On mobile so it’s hard to read your code, but have you looked into ConcurrentBag?
Very true. 
[removed]
For this kind of thing I recommend looking into an `AutoResetEvent` or a `ManualResetEvent`. They're inherently threadsafe and designed for exactly this situation.
Removed: Rule 4.
The main thing they forgot is the reverse card, which is a pretty important feature. How are we supposed to defend ourselves when the compiler hits us with that Draw 4 without it? Major oversight, 0/10.
Sorry sir, i'm new user.
Will do
As others have said for your simplified example, the .exe and .exe.config files are generally the two out of your list required to successfully run the application. I figured it might help you to know what the other files are and why they're not required. (These are simplified answers, others should feel free to jump in and add detail) .PDB - this is a program database used to hold symbol tables and other information used by the debugger to quickly index the application. It's generated when you compile and it's not needed for release mode operation. .VSHOST.* - Visual Studio generally doesn't crash when your program dies throwing a catastrophic exception because the actual program "hosting" the instance of your application and attaching the debugger is the vshost system. This also is not needed for release mode operation. As you add complexity to your project and solution, more and more files will be added to your output bin/debug or bin/release folders. This is where application publishing becomes important. The publish systems will pick out all of the correct dependent files and package them neatly for whatever distribution method you're designing. There's no need to reinvent the wheel or do it yourself. 
This sounds like an object finalizer/destructor is running (upon `GC.Collect()`) that is causing the crash. Finalizers usually call Dispose() internally, so it's possible that a finalizer is hitting a code path that hits bad unmanaged memory after Dispose has already dealt with it, or something along those lines. If I were debugging this, I would be breakpointing the finalizers in the underlying library.
Until the UI packs come out
2.0 really did open it up, luckily we wait for any production released until now, so i feel like we dodged a lot of heart ache 
so that's where i went wrong, i put the second lock around the whole while loop. thx for the help
I don't see any reason why changing reference should cause nullreference or accessviolation. When you access it it's stays the same or already moved.
/u/joelving is right to suggest you target the proper version of .NET Standard. Here's how it works out, I always say "brief" but it's never brief. I like typing it out because it took me a couple of months to comprehend it. There are *implementations* and *interfaces* of .NET. There have been multiples of each, and things got really confusing. They'll be a lot easier going forwards. To be clear, an "interface" of .NET is just like a list of APIs that any tools must implement to be "a .NET implementation". An implementation implements *at least* as much as the interface it promises, usually more. This is why it's confusing. ".NET Standard" is the newest interface. There are three implementations. * .NET Framework is Microsoft's Windows-only implementation. It is the oldest .NET implementation, and only certain relatively new versions implement .NET Standard. * Mono is an open-source every-platform implementation. It implements .NET Standard. * .NET Core is Microsoft's every-platform implementation, the final phase of "Embrace, Extend, Extinguish" aimed at Mono they promised they'd never do. If you target an *implementation*, in general you don't expect your code to be compatible with other implementations. There are narrow exceptions, for example, Mono is fine with running a big subset of .NET Framework applications. But it'd take pages to explain why. If you target an *interface*, like .NET Standard, then ALL of the implementations HAVE to run that code. Otherwise they are lying about implementing the interface. So if you are writing a library today, it makes sense to target .NET Standard if you can. That way all of the relatively current implementations can consume your library safely. The elephant in the room here is "Well, some versions of .NET Standard might not be supported on a platform like Xamarin.iOS." That's a deeper, harder can of worms to describe. But it's easier than PCLs, which require you to inspect a matrix of something like 80 different profiles to figure out which one best suits your needs, and you ultimately end up supporting about 12 of them. 
Anywhere I can read more about this? It seems like a strange optimisation to make when it is explicitly re accessing the variable.
&gt; Mono is on the way out I don't see Xamarin going anytime soon.
It's a complex topic, but this is a good starting point: &gt; Memory Operation Reordering According to ECMA-334, when a thread reads a memory location in C# that was written to by a different thread, the reader might see a stale value. This problem is illustrated in Figure 1. https://msdn.microsoft.com/magazine/jj863136 (I'm actually going to re-read that tomorrow because there are a lot of details I've forgotten.) 
Actually, for this /u/crozone has a slightly better solution. A semaphore is used when you want N possible threads sharing the same resource. The xResetEvent is more explicitly about events. https://www.reddit.com/r/csharp/comments/8z4m4n/am_i_being_stupid_or_is_this_a_bug/e2glb5v/
Part 2: https://msdn.microsoft.com/en-us/magazine/jj883956.aspx
Mono.NET is the project, xamarin is the company and framework. They will likely consult dotnet core for future iterations.
Yes, await each Task sequentially instead of running them all simultaneously on separate threads. Also use Task.Run instead of ThreadPool.QueueUserWorkItem, unless you have a very good reason you shouldn't have any knowledge of ThreadPool or Threads.
The default synchronization context just throws it on the the ThreadPool, which by default has a very large thread limit, so you should expect these to still run concurrently and but thread-unsafe.
ConcurrentBag is definitely the easiest solution, and one I'd use as it avoids locks.
Yep. I also have an [async version](https://github.com/crozone/AsyncResetEvents) if you need it.
Yeah, it is very confusing, *and also* harmful. Sadly, I do not have a voice in that matter, as aforementioned app is already in prod, in 4.x. How can I make sure that code under mono/core can be introduced to existing framework app w/o having to re-rewrite it from scratch? This assertion would enable me to work on it more than 1h/day.
Really?! VS Community might be great, but you haven't been using Java IDEs apparently. 
Welcome to the real world of professional software outside startup's distortion field.
It will take years to move the Mono-specific features to .NET Core. As an example, Mono has mature support for AOT due to running on iOS. Some recent stuff like Blazor also uses Mono. Eventually, Mono will probably get deprecated in favor of .NET Core. But to call it “on its way out” seems quite premature. 
I mean it is on it's way out though. No one said it was dying tomorrow or a month from now, simply that it is very clear that in the not-so-distant feature it will no longer be in service.
We found the underlying cause, the Veldrid OpenGL bindings were using the wrong calling convention in 32 bit mode (should be StdCall, was CDecl).
Monogame is not an engine it's a framework to build your engine top of.
Well, the GC is extremely complex and probably also very different between runtimes, so this is just based on my limited understanding. That being said, the GC only runs at all when there is memory pressure, it doesn't compact gen 0, and automatic compaction depends on a fragmentation heuristic. So in simple test code that doesn't allocate or collect a lot of non-ephemeral objects, compaction may not occur. To reliably see compaction you'd want to allocate a lot of objects before your test object, make sure the objects survive till gen 2, and then force a GC. Also, this should never cause an NRE since the reference itself doesn't become null even if it's pointing to invalid memory, and it doesn't necessarily cause an access violation because the GC typically will hang on to that memory and it still belongs to your process. You'd probably just get garbage data when reading fields of the moved object or weird problems when invoking methods via an invalid method table.
The GC won't compact until it needs to. So try to make something that fills up and fragments the heap and see if you then run into problems.
If GC moves the object in memory the previously obtained pointer doesn't contain the correct address anymore. Accessing that invalid pointer will cause NullReferenceExceptions or AccessViolationExceptions.
Gvgg
The day *volatile* solves anything is a bad day ...
Though I seldom use unsafe ,but I have a few guesses. Correct me if I'm wrong - If your method returns an IntPtr Actually IntPtr is a handle. Which means it sits between the virtual memory address and the variable application see. GC is aware of IntPtr and it will update the value 'inside' the IntPtr during compact phase. Which means memory compact/ relocation is transparent for application code - If your method returns a pointer AFAIK There's no way you can get the actual virtual memory address of a reference without GC's aware, unless you do something like `char* ptr = 0`, but again ,that's not actual virtual memory address. When you use `fixed` or `stackalloc` statements to get the memory addresses, GC won't compact them. I think this method may get access violation if you try to use the pointer after GC moves `str`, but still, I could be wrong. public static char* AddressOfStringData(ref string str) { fixed (char* x = str) { return x; } } Another aspect to think about is the LOH(Large object heap). If my memory is accurate, GC won't compact LOH unless you explicitly ask it to do. Some references - [https://github.com/dotnet/coreclr/blob/master/Documentation/botr/garbage-collection.md](https://github.com/dotnet/coreclr/blob/master/Documentation/botr/garbage-collection.md) - [https://stackoverflow.com/questions/8743972/return-a-fixed-pointer-in-c-sharp] (https://stackoverflow.com/questions/8743972/return-a-fixed-pointer-in-c-sharp) If you find out answer, please post it here. I'm also curious.
AFAIK this is what happens: * You start on the main thread. * You ask the thread pool to execute TestThread multiple times on multiple threads. * On each thread pool thread you call AddRemoveFromList in an infinite loop. * On each thread pool thread you add and remove items to/from the list (concurrently to the other threads). * You wait for an already finished task (Task.Yield). Things I don't understand right now: * Task.Yield does something with the current context but I cannot see a context switch here, so it does probably nothing. * AddRemoveFromList is marked async and returns a task. There might happen some unwrapping of tasks by the compiler but this is too complicated for me and I never get it right. 
Hi samplecovariance, Are you using Xamarin.iOS?
This is correct. I've used AR in Rails extensively as well as EF in .net. Pattern wise, the two approach things from two completely different angles. Either go with AR or with repositories. Curious - WHY do you want to mix the two?
30 year veteran of it industry. Listed in historical order indicating current working proficiency. Basic, assembly, C, c++, java. Lots of XML and XSLT. Currently working in dotnet backend (webapi and mvc) along with front end with javascript, and angular and the requisite CSS, HTML that comes with that. Have clibed from junior programmer through lead and then up through architect and senior architect. These later jobs were too far away from the coding that I love in meetings. I've struggle with making sure managers give me the correct ratio of meetings to coding, but when it gets to be too many meetings I usually have to bail after giving them a chance to correct it. I enjoy my current job but would leave it for one closer to my location or with a larger amount of work from home.
The GC only adjusts managed references, not `IntPtr`s. It couldn't, really, the `IntPtr` may represent anything including Win32 handles or an address in another processes' address space that just happens to match the address of a managed object in the current process. You're not *supposed* to obtain references to unpinned objects (or anything other than unmanaged types, really), but you can with various methods including the `CompilerServices.Unsafe` package, `GCHandle` and many others.
That's not going to work because your DataTemplate 'View' isn't a DataTemplate. You should create your DataTemplate in XAML, unless you're doing some fancy stuff like so: &lt;ListBox ItemsSource="{Binding Data}"&gt; &lt;ListBox.ItemTemplate&gt; &lt;DataTemplate&gt; &lt;StackPanel Orientation="Horizontal"&gt; &lt;TextBlock Text="{Binding Name}" /&gt; &lt;TextBlock Text="{Binding Health}" /&gt; &lt;TextBlock Text="{Binding Mana}" /&gt; &lt;/StackPanel&gt; &lt;/DataTemplate&gt; &lt;/ListBox.ItemTemplate&gt; &lt;/ListBox&gt; public class Data { public string Name { get; set; } public int Health { get; set; } public int Mana { get; set; } }
Information Systems Engineering Student, Intern at a local software company, I have been using .Net for at least 5 years now, proficient in C#, WPF, ASP.NET Core API, EF Core, SQL. Have done a couple professional projects in WPF. I am looking for a remote job.
The GC can move objects as part of a garbage collection. It firsts marks all live objects, and then compacts the heap to get rid of the dead objects. Depending on what your heap looks like and how the compaction algorithm works, some objects might never actually be moved. Also when objects survive a GC, they get promoted to a higher generation, which is collected less frequently, making it even more unlikely for objects to be moved. Finally, large objects go on the Large Object Heap, which is normally never compacted. But just because you might not in practice see any of your objects being moved doesn't mean that it isn't necessary to assume that they will move. The GC is allowed to move objects and it *will* move objects when necessary, so you *must* write your code to deal with this if you want it to be correct by construction, rather than working by accident.
It's easy to just **say** "yes, references can get moved around, and this can cause issues if you allow a pointer to a managed object to leak outside of a scope in which that object is fixed, so don't do it". It's a bit more effort than I'd guessed to actually **show** it happen. I'd started with [this](https://gist.github.com/airbreather/f786a27497d819a41cba6b76227256b0), which does seem to trigger pretty quickly for an untenured object, and I got that working pretty quickly (the code here is **very** close to what it was when I'd started). It took me about 45 minutes of fiddling to make it happen with tenured objects. [But I got there in the end](https://gist.github.com/airbreather/42e0f54491b719de62a716467ac1ac45). That loop at the end usually terminates fairly quickly, tested with both `net471` and `netcoreapp2.1` target frameworks. This kind of situation is particularly dangerous, since unless the GC is releasing process memory back to the OS, I'm pretty sure that it'll try its best to just keep reusing the pages that it already has allocated to it, which means that your tainted pointers will very often point to "something" that's mapped to your process... it just won't always be pointing to the **same** thing.
An interesting fact (probably mentioned in the article) is that the x86 memory model is stronger than C#'s, which probably means there is tons of technically incorrect code out there, which can easily fail when executing on ARM, for example, which has a much weaker (and more typical, outside x86) memory model.
Sorry, I should word that better. I am newer with Forms and have a hard time with the structure and how things should be connected. Not that it has gotten worse for me, just that it isn't the friendliest to learn.
It's not on the blog is on the product webpage
If you want a very good source/help on implementing A* I would look no further than this site: http://theory.stanford.edu/~amitp/GameProgramming/index.html Most pages include interactive examples so it's really easy to grasp.
Shame Microsoft doesn't give a damn about it and instead keeps on backing the MacBook owning hipster crew and their 80mb package-40 second to load form apps. 
You may take a look at `int.TryParse(inputString, out choice)`. When it returns `true`, then the input could be successfully parsed as a number and its value is stored in `choice`.
For reference an `AutoResetEvent` version would look like this: static void Main(string[] args) { MeteoraWindow game = null; //Form AutoResetEvent gamecreated = new AutoResetEvent(false); var thread = new Thread(() =&gt; { Application.EnableVisualStyles(); game = new MeteoraWindow(new MeteoraTriangleView(), 1920, 1080); gamecreated.Set(); Application.Run(game); game.Dispose(); }); Console.Write("Creating window... "); thread.Start(); gamecreated.WaitOne(); Console.WriteLine("Done!"); Console.Write("Initializing... "); game.Init(); Console.WriteLine("Done!"); Console.WriteLine("Running Main Loop... "); game.DoMainLoop(); thread.Join(); }
Pls can you explain how I can insert it in the code? Thats the part i need to take under condition: if (choice &gt;= 0 &amp;&amp; choice &lt;= 8) { if (arr[choice] != 'X' &amp;&amp; arr[choice] != 'O') { if (player % 2 == 0) { arr[choice] = 'O'; player++; round++; } else { arr[choice] = 'X'; player++; round++; } } else { Console.WriteLine(); Console.WriteLine("Scelta non valida"); Thread.Sleep(2000); } } else { Console.WriteLine(); Console.WriteLine("Scelta non valida"); Thread.Sleep(2000); }
If you are editing that person's code, the best you can do is *try* running it on Mono/.NET Core and see how it goes. If you're just adding features, it would be best for you and that person to agree on an API for your work so you can write a .NET Standard DLL he can consume. That way you can work freely and it will be compatible.
You have 2 choices. A) The page reloads and the view refreshes B) You use AJAX to reload the partial view 
Hey Flex! Honestly, I am not sure.. I am very confused about Xamarin, but I don't think so. I am using the Storyboard and C#.. Xamarin uses syntax close to HTML, I think, and I haven't used any of that.
I think you are using Xamarin.iOS as you are using c# and the storyboard. The latter only being available in Xamarin.iOS. The HTML markup you mention is, in fact, XAML, and it's used in Xamarin.Forms.
I cannot find the code where you handle the user input? 
I gotcha. I am new to Visual Studio so I was really confused about all this so yeah, I am using Xamarin.iOS I put up a search bar and then I put in a UITableView. I created a new class for the search bar and the UITableView, but I really don't understand how to use it or create events for it.
Yeah, you're definitely using Xamarin.iOS. What are you trying to do exactly?
Well, we have an api that is essentially a list of food items. All that I am really trying to do is have the table show the list and the search will filter them with respect to their names. So there's this long list and as the person starts typing in "co" then it will filter out everything doesn't start with "co".. pretty much like what most search bars do nowadays. It filters as you type. The table's cell will show a button image of the product, the name of the item, and the price.
That's a scary thought. Though thankfully I've never actually had to write ARM code.
You need to google xamarin UITableView + UITableViewSource and work from there
Okay, thanks! I kept putting in like "search bar uitable c sharp"
You've experienced the common urge to prematurely optimise. My advice is get it written in the simplest most maintainable way. Then once it's complete benchmark to find places where optimization is need and do it. Basically get it working then optimise as required :)
It's an instruction that tells the compiler that "contents may change". It's not good or bad. 
https://codeshare.io/Gq3wYM Oh sorry it start around line 60
&gt;private HttpClient client = new HttpClient(); What other properties and fields on this class are initialized this way? These statements will be considered part of the constructor, I believe, so some other default-initialized variable may have a dependency on a local file.
use an ajax call to reload the partial.
Volatile tells the compiler to stop reordering instructions. Nothing more - it is not magically thread safe or anything. And therefore a solution where only a voilatile keyword is added is a *hack* and not a solution for already existing bad code
Okay, thanks!
I copied the algorithm directly into C#. The only place I *think* I may have gone wrong is in calculating G and F costs.
The reason I didn't do it that way before was because I think I did something else in a similar way and it ended up being really slow.
Google Sysinternals and download their free suite (They're part of MS now). ProcMon will show you every file access attempt including the failed ones. Also, wrap the ctor code in a try catch and log the exception It has a property which should be set to the filename. Take a look at Log4Net as an example, although there are plenty of other options.
Uh, aren't the smart compiler folk supposed to handle issues like this? This is SO far outside my expertise that I have to trust that there are experts doing a good job.
So if I compiled in 4.6.2 is that a computer running 4.6.1 won't run it full stop, or only if I use features introduced in 4.6.2, which won't be present in 4.6.1?
Yes and no. The runtime makes certain guarantees, but only if you play by its rules. For example, many ARM processors cannot handle unaligned memory access, e.g. reading a 4 byte integer from an address that is not a multiple of 4 bytes (this isn't entirely safe on x86 either, but not as severe). By default, the runtime will insert padding between fields to make sure every value always sits at an aligned address. But if you change the layout of a struct, or use unsafe pointers to read from unaligned addresses, you can break things. The only way for the compiler to fix this for you would be to insert expensive checks at every single read of a variable, which isn't really practical.
&gt;Consequently, in the reordered version of Init, another thread may observe _initialized=true and _data=0. It changes the behavior, how is that not a bug?
I'm using Vulkan
I'll try it, this looks like a more elegant solution anyway
Because it follows the behavior defined by the specification. 
It won't run, regardless of whether you take advantage of 4.6.2 or not.
Good question! All classes in .NET inherit from a class called Object which contains a few methods. Since you're inheriting from Object you have access to these methods and can provide your own implementation of them. One such method is called ToString(). In your card you can already call something like card.ToString(). However, since Object is a super generic class it doesn't know how to print out anything specific about FlashCard's so it just spits out something that's not very helpful. You can define your own behavior for ToString() that prints out what the question, answer, and userinput is in a well-formatted way. Check out an example [here](http://pasted.co/9bbc82b6).
 var inputString1 = "12345" var inputString2 = "a12345" inputString1.Any(character =&gt; char.IsLetter(character); // returns false inputString2.Any(character =&gt; char.IsLetter(character); // returns true You may also want to investigate what exactly the IsLetter method considers to be a letter and whether this suits your needs.
Here's another blog from this from around when the CLR was adding support for IA64 which has a vastly different memory model: https://blogs.msdn.microsoft.com/cbrumme/2003/05/17/memory-model/ 
How easy was it to calculate/predict your running costs for each option? 
Which line does it crash on?
Ok, thanks. So is there an option in Visual studio to build against a an older version of .NET framework, if you're not using features from the newer versions; or do you have to build against the latest version and have everyone update their framework, in order to run you program? 
It doesn't change the behaviour from a single thread's point of view. The compiler, CLR/JIT, and CPU are allowed to make whatever optimisations they like as long as program order is observed to be unaffected from a single thread's point of view. Once you have unsynchronized multi-threading in play, these optimizations may break your code.
Yes you would create a list of ViewModels. Not sure if I understand your question correctly, but I would have ViewModel in it's separate file.
I agree. It would be better for OP to learn basic multithreading concepts first rather than slapping a `volatile` on his field and calling it a day.
When it sets _initialized before _data, its no longer operating in the order the developer expressed and its state is a bit odd. At the end of the method state is ok. A bit of a Schrodinger's cat, without another thread peeking in, no one would ever know :) 
Thank you for the reply. A few questions: 1. When you WriteLine the ToString method, how does Console.WriteLine know to print the strings in that method? Is that because of the return line? I haven't messed with return that much, so they're a bit confusing to me. 2. On the same line, you say that the ToString method isn't required, but isn't that what's allowing these strings to be printed? Thanks.
&gt; When you WriteLine the ToString method, how does Console.WriteLine know to print the strings in that method? Is that because of the return line? I haven't messed with return that much, so they're a bit confusing to me. Notice that the return type of ToString is a string. When you call Console.WriteLine(**card.ToString()**); you'll end up with a string inside of Console.WriteLine() which is exactly what it's expecting. Hopefully I'm not misunderstanding your question. &gt; On the same line, you say that the ToString method isn't required, but isn't that what's allowing these strings to be printed? Yeah I wasn't very clear on that. Inside of Console.WriteLine() if it finds an object instead of a string, it'll automatically call ToString() on the object. 
Gotcha, you understood both of my questions. Also, a followup, how do I Console.WriteLine an item in a list? I Googled it, but all of the example I see are using a for loop to go through the entire list.
Are you not wanting to print out all the items in the list or are you just wanting some of them? 
Great question! We used the pricing calculators from each cloud to get a rough estimate of the costs based on the number of expected requests per month and GB of data involved. I'm not sure how accurate the estimates will be but it's at least a relative measure between the two. The one big outlier was the cost of Azure API Management (APIM). It isn't based on a consumption model. Its more like a VM you spin up. I think it started at $150 per month where AWS API Gateway was less than $10 for the traffic we needed.
For now, I just want to print out one, since there are already plenty of examples on how to print all of them. If I had a list called CardList, I believe I would do it like this: Console.WriteLine(CardList[0]); ?
Big tech company in Wales, ( Swansea, UK) is looking for graduates and senior full stack developer to join his large development team! The company offer an amazing office, great benefit package and flexible working hours. 
That's right. A more readable syntax would be to call .First() on the list. Console.WriteLine(CardList.First()); // Remember there is an implied call to ToString() here 
Oh okay, that makes sense. So here's the code I have currently. I've simplified it a lot, to make sure I understand everything before complicating it. I can't figure out why I'm unable to add Card.Question to a list: http://pasted.co/618b1014
One thing I'd recommend: **If** you want stack trace info in error logs to include filename and line numbers, include the PDB. If you don't care about line numbers, don't ever plan to read the logs, or aren't logging anything, then you don't need it.
Because you want to be adding the whole card to the list, not card.question ;)
Well the code given is always the canonical example when people are talking about reordering optimisations; but it's hard to see the *why* from such a small snippet (i.e. "*why* would the compiler bother to do that?" is not very clear). It makes a lot more sense once you realise that the compiler/JIT/CPU would be pretty much unable to make *any* obvious optimisation if they had to preserve coherency across multiple threads by default. Take the following example: public static void M() { for (var i = 0; i &lt; 1_000_000; ++i) { if (_myField == 3) { DoSomething(); } } } Having to go back to main memory to check the value of `_myField` being equal to `3` one million times would be a hugely expensive operation (especially as memory is the bottleneck in most CPU-bound applications). So, in the example above: * The CPU is allowed to check `_myField` once and cache the value in L1 or a register, * The compiler/JIT is allowed to rewrite the code to move the `if` check outside the `for` loop, thereby only checking the value once. This seems like an obvious "free win"; but if we suddenly say that `_myField` could be changed from another thread, then you can see why those optimisations would potentially break the code. The fact of the matter is that if the compiler/JIT/CPU had to assume that all fields could be changed from anywhere at any point, then they wouldn't be able to make most optimisations. Instead, they are allowed to assume that all code is single-threaded; and it's up to you as the programmer to explicitly indicate otherwise (with explicit synchronisations like `locks` or higher-abstractions such as `ManualResetEvent`/`ManualResetEventSlim`/`AutoResetEvent`/`Semaphore`/`async` and `await` etc.).
StructLayout.Sequential is the default. Not sure about FieldOffset.
C# yes, see .NET Core. GUI stuff, you can use ASP.NET Core for web sites, but not WPF or Winforms (native GUI apps). You can use Avalonia which is a XAML based cross platform UI framework I believe, but haven't used it myself.
Did you look at my code? I simplified it way down, just to kind of ease my way into using a list. Here's the code, but on Pastebin because when I used Pasted, Reddit was flagging my comments as spam. https://pastebin.com/0xyWurm7
I did. Your problem is line 19. Your list is expecting to contain objects of type FlashCard but you giving it Card.Question(which is a string) instead of Card (which is a FlashCard). It should work if you change line 19 to this: CardList.Add(Card); Just remember that since you haven't provided any behavior for ToString() it's going to use the default implementation from Object.
Ooooooh, that makes sense now. Thank you for the help, I really appreciate it. I think I have all the information I need to start working on it.
Sure thing. Good luck!
&gt; Having to go back to main memory to check the value of _myField being equal to 3 one million times would be a hugely expensive operation Worse than that, you would also have to ask all of the other CPUs to flush their write caches to main memory. 
From the docs. &gt; The volatile keyword indicates that a field might be modified by multiple threads that are executing at the same time. Fields that are declared volatile are not subject to compiler optimizations that assume access by a single thread. 
Others have already answered your question, so I would just like to say I felt the same way when I first learned about out of order executions and other optimizer tricks.
Why? 
Or C) Load all the results and paginate with JavaScript like [pagination.js](http://pagination.js.org/).
Yeah and it does it by using acquire and release fences on read/writes which in turn disables instruction reordering and local variable optimizations. But the main point I am trying to make here is that the volatile keyword isn't the right solution but the underlying bad code is. You almost never need the keyword. And as such it's more a code smell than a real feature...
The spec is pretty explicit about not guaranteeing much. The loop example someone posted is much better for understanding "why" than the seemingly random re-ordering of 2 simple value assignments.
 while (true) { //Console.Write(game); if (game != null) break; } if this is not smelling like cat food to you I don't know anymore ...
The spec isn't something most developers read. 
When I played with AWS Lambda I was not impressed by the cold-starts, which sometimes took up to 3 seconds for a simple function call. I was curious if Azure handles those better, or if it's just a cost of serverless architecture.
Because then my user model is locked in. I want to be able to define my model type on a per project basis without having to create new stores. If my model implements IUser and my model can be cast to IUser, i don't understand why IUserStore&lt;MyModel&gt; cant be cast to IUserStore&lt;IUser&gt; 
Do `ManualResetEvent`, `ManualResetEventSlim` or `AutoResetEvent` or others like them imply or enforce memory barriers? I was looking at the other thread and wrote it with a naive `AutoResetEvent` : https://www.reddit.com/r/csharp/comments/8z4m4n/am_i_being_stupid_or_is_this_a_bug/e2hax1k/ and posted but I cannot find any documentation that ensures the read of `game` in `game.Init()` will not possibly happen before the `.WaitOne();` from the event. I think to fix that code you must make `game` `volatile` or use a `Thread.MemoryBarrier();` between the `.WaitOne();` and `game.Init();` (and possibly between `game = ...` and the `.Set();` call) but I am not 100% sure. The short of it is that multithreaded code is very hard to get absolutely right even for those of us who have been writing C# for 10+ years. 
(I work for Microsoft) We're no better. Supposedly v2 (which is in public beta) will improve/address this at some point. However, short of allocating an App Service instance, I think this will always be an issue to some extent.
In line 60, you should do the following: \`\`\` var userInput = Console.ReadLine(); if (int.TryParse(userInput, out choice)) { \`\`\` and in line 118 the closing \`}\`.
Damn you, you sent me down the rabbit hole for this one ;D Before I started doing some googling I would've been 95% condifent in saying "Yes, those types all emit the correct barriers", because my experience with .NET concurrency types' design philosophy is to make everything a pit of success (same as everything else). Anyway, after looking around I'm gonna go ahead and say that I'm 99% condifent that is the case. `AutoResetEvent`/`ManualResetEvent` are built upon `WaitHandle`s, which themselves are the .NET wrapper around WINAPI [Synchronisation Objects](https://docs.microsoft.com/en-us/windows/desktop/sync/synchronization-objects) (`Slim` too, but it spins in user-mode first before deferring to the kernel; hence it being faster for low-contention scenarios). According to [Microsoft's documentation](https://docs.microsoft.com/en-gb/windows/desktop/Sync/synchronization-and-multiprocessor-issues): &gt; The following synchronization functions use the appropriate barriers to ensure memory ordering: &gt; * Functions that enter or leave critical sections &gt; * **Functions that signal synchronization objects** &gt; * Wait functions &gt; * Interlocked functions I also had a glance through the [reference source for WaitHandle](https://referencesource.microsoft.com/#mscorlib/system/threading/waithandle.cs,e10a1c3ea4cad280) and there does seem to be a fair smattering of `volatile`s but it's pretty dense code (a lot of attributes). To go to 100% certainty I'd have to sit down with it all for a day- I might actually do that when I finally get back to blogging (soon). :)
Because sooner or later he'll come across a problem that `volatile` won't solve and he'll have no idea what to do. Also, I don't like volatile anyway: [Sayonara Volatile](http://joeduffyblog.com/2010/12/04/sayonara-volatile/) has a good explanation why it's not so great.
*Well*, `Volatile.Read()`/`Volatile.Write()`, I think. At least in theory.
Ahhh that is what I thought. I think the problem was worse because I used C# which requires compilation? I wonder if it would have been better to use Node or Go. Probably the only time in my life I regretted using c#.
Compiled C# is significantly faster than every other language. Same on Lambda. [Blog article on Lambda](https://read.acloud.guru/comparing-aws-lambda-performance-of-node-js-python-java-c-and-go-29c1163c2581) 
How is user model locked in if everything is using `IUser` like in my example?
If you are unsure why not test it? Login to sql management studio, set your app running, run sp_who2, identify your apps spid and use this code: https://stackoverflow.com/questions/1038113/how-to-find-current-transaction-level However you are much better constructing your own views and procedures and setting it inside those and binding EF to those. 
I remember reading a comparison of languages on serverless platforms recently and c# pretty easily had the best performance on AWS/Azure. That was probably execution performance though not cold start; i'd still be surprised if it made much difference. I imagine almost all the time is spent finding/allocating/assigning a machine to run the code.
&gt; I imagine almost all the time is spent finding/allocating/assigning a machine to run the code. Ahh that makes sense actually, Especially considering the small-size of the functions. Thanks.
Unless you're doing something in bulk, serverless seems like a poop solution for a lot of problems - as in anything event-driven where the "event" is some user action. The cold-start times are just painful. We've had much success with Fargate + ALB. Does Azure have something similar?
&gt; The real problem is that programmers have spent far too much time worrying about efficiency in the wrong places and at the wrong times; premature optimization is the root of all evil (or at least most of it) in programming. There are at least a dozen ways to fix the OP's problem, however given that he didn't understand the interaction between the two threads, I chose to offer the easy to implement, easy to understand, "good enough" solution. Feel free to offer your own solution.
Ok and I guess multi-threaded Xenko Game Engine with Vulkan support wasn't enough for your needs? If you do engine yourself, it's probably quite hard to port your game to any game console. But if you don't plan to do that then it probably doesn't matter.
You can enable a cloudwatch event to call your lambda every five minutes or so to keep it warm. We do that for all initial landing lambdas.
Exactly what I wanted to try and explain, but couldn't put down so effectively.
Yeah that is what I did, but it felt a bit dirty lol
Works perfectly now :D Thanks a lot for help and apologized for my noobieness
What is the value of e.Key when you set a breakpoint and press the down key?
Assuming this is a GUI app of some sort (using a `TextBox`) are you sure you're reading any outputs to `Console.WriteLine`? Try putting a breakpoint and see what happens with your debugger. I'm not terribly positive about this, but perhaps also the events are being swallowed/handled/managed by the control. See what happens if you listen to the `PreviewKeyDown` event instead. This may even be preferable if you plan on implementing your own caret up/down management behaviour as (I think) listening to the `KeyDown` event will already be after the control has shifted the caret.
Hey, sorry to bug you again, but I can't seem to understand why I'm getting this error: CS0120. An object reference is required for the non-static field, method, or property 'FlashCard.question' data item selected Here's the link to my code: https://pastebin.com/AR4ez7F5
Can you link the actual code? That's just the error message.
Oh oops, sorry, have a lot of things on my clipboard. https://pastebin.com/Gk7Gg7Lk
Are you sure that this is the code that's generating that error message? I don't see where you error would be coming from. There is some questionable stuff going on in the Create() method but I don't see it being called.
Azure container instances and the aptly named Load Balancer. 
Yup positive. It's catching on the userinput = Console.ReadLine(); Also, what do you think is questionable?
This has nothing to do with premature optimization. It is just *bad code*. 
I was looking to get into using azure functions, but was really surprised that it didn't yet support .net core 2.1, which prevents me from referencing my project's other objects without being a big hassle. Hopefully they catch up there soon.
yea i have no intention to do any of that, don't even plan to support anything other than windows. This is only a learning project.
I know that feeling. You can detect it and terminate early though. 
You don't, use a grid control that supports it in javascript. Meaning you load multiple pages at once and the grid only displays only so much. It's actually inefficient to load tiny amounts because of the build up and tear down. For example it you only show 20 rows, it's less work on the server to load up 200 rows (10 pages) than to load 20 rows 10 times.
From @jeffhollan, Sr Program Manager, Azure Functions Tweet from June 6, 2018: “Exciting news - the latest release of the @AzureFunctions v2 runtime will be using .NET Core 2.1” https://github.com/Azure/azure-functions-host/releases/tag/v2.0.11843-alpha * Tweet source: https://twitter.com/jeffhollan/status/1004414851953905664?s=21 
I didn't see your solution anywhere in the thread.
C# can be precompiled as well. See this article: “Pre-compiled Azure Functions example” * https://samanthaneilen.github.io/2018/06/08/pre-compiled-azure-functions-example.html Excerpt: “There are multiple ways of creating a C# Azure Function: - Precompiled Azure Functions are created with a Visual Studio Azure Functions project - File based Azure Functions leverage the Azure Function CLI NPM package for development and do not require any specific editor to create.” Contrast that with this approach: “C# script Azure Functions example” * https://samanthaneilen.github.io/2018/07/14/csharp-script-azure-functions-example.html Excerpt: “These functions rely on C# script files (.csx) that are not compiled into a dll.” 
Replace n with "+n+"?
Ah the problem was your Create() method was marked static. Inside of a class's static method you can only interact with other parts of the class that are marked static as well. If you simply change the method declaration to "public void Create()" it will build. Regarding what seems questionable, I don't understand what the scope of FlashCard's responsibilities are. Judging by the name, each instance of the class should represent a single FlashCard. If this were the case, it would only have fields for storing the Question, Answer, and UserProvidedAnswer - and maybe a ToString() method for fancy output to the console. It would be the main method's responsibility to construct (and store in a list) multiple instances of these cards. Alternatively, your comment next to the class name and the fact that your latest code sample CardList within the FlashCard class makes me think that's not what you intended.
I think it is absurd that a reference can be assigned to a nonvolatile field before the constructor has been completed. The JRE is the same way. Apart from that the smart compiler guys can’t solve any of these issues for you. If you use synchronized blocks most of it is handled for you but you can still cause deadlocks. 
Check out this example to show what that first case might be like. https://pastebin.com/CRBAfhVj I didn't fill in any of the methods in FlashCard because I don't want to hand you a completed answer. Encountering stumbling blocks are an important part of learning. I did however fill out what the responsibilities of the main method could be. Notice how the set of responsibilities for the FlashCard class are all very self-contained and it's main's responsibility to construct instances of FlashCards and do meaningful things with them?
Weird, I could have swarn I tried removing static. Either way, the reason why things seemed all over the place was because I was trying to isolate what the problem actually was. Thanks for the help :).
It should be pointed out that figure 8 is also incorrect for the lazy initialization pattern. Yes it will always print 42 but multiple instances of the Boxing class may be created. You should always check for null again after entering the synchronized block. Or as suggested use Lazy&lt;T&gt;. 
It should also be noted that the assignment to a local variable is important because it skips the volatile read at the return statement. 
Seems like what you want is actually a dictionary, not an array
If a class with properties for each key and possibly an array of class objects
Cool, I will take a look at dictionary. Thanks a lot.
Yep, us too. I think the v2 runtime will go GA before the end of the calendar year.
Agreed functions/serverless are not for every use case. Yes, Azure has containers as a service and Kube as a service. They actually had those before AWS did. 
I think that is part of the current nature of serverless and Azure is the same. Although I know I've heard the Azure teams say they are making big investments in this area.
when you've begun to get a little experienced, this looks like Json and you might want to look at json.deserialization from newtonsoft.
I'd guess that the point of this homework assignment is to parse strings.
It is just taking a string as an argument. Any way of including a variable in a string will work. One of those ways is String.Format which you are already using. Personally I prefer $"//a[@href])[{n}]" 
Doesn't sound like a race honestly; sounds more like the thread(s) is(are) prematurely terminating execution for some reason; probably because they are attempting to do work on nothing because the first thread hasn't finished executing yet. The real question is: if steps 1, 2, and 3 have to happen sequentially and each step depends on the previous step, *what do you gain by threading?* Freeing up the UI thread on the app so it seems responsive? That just trades one set of problems for another, as you've seen. What you have is a long-running external operation (the Access engine doing the database work, which also involves filesystem IO), which is a classic case of waiting for results of an operation to become available. This is precisely what [async/await](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/async/) was added for (specifically pay note to the section on Threads). It allows the main thread of execution to do non-dependent things while it waits (*await*) for the results of external operations (*async* method, which returns a Task or Task&lt;T&gt;) OleDbCommand supports an asynchronous version of ExecuteNonQuery called [ExecuteNonQueryAsync](https://msdn.microsoft.com/en-us/library/system.data.oledb.oledbcommand.executenonqueryasync.aspx) which should be ideal for your situation. Asynchronous methods are not 
Are you making a new class? I think it’s under file or project but yea make a class then you can reference that class or it’s properties in the main program file the usual way. Check out derek banas [c# tutorial](https://www.youtube.com/playlist?list=PLGLfVvz_LVvRX6xK1oi0reKci6ignjdSa) he uses VS plus it’s super good 
Not sure if I'll be making a new class yet. Out of curiosity, can it only be done if you're making a new class? I was just going to store a few methods in a different cs file, just to keep it a bit organized.
Thanks for the reply. Did your answer get cut off? Unfortunately, I'm stuck with C#4.0 and VS2010, which locks me out of using async/await keywords. Do you think learning the old way of dealing with asynchronous programming is worth my time? Are there ways to ensure each ExecuteNonQuery runs successfully assuming all the work on the database is done with one thread? We use background threads to separate the GUI and backend for improved responsivity, as you said. 
Sounds like you want it to be a different class. I’m not even intermediate at this stuff yet so I could be wrong. But I think you should take the methods and the variables they need and put them in their own class. Think of a class as like a game character or an item Say you had a warrior They’d be class Warrior { Int health = 500; Int defense = 100; Int attack = 150; Void UseWeapon(Weapon weapon, int attack) { //whatever logic } } So it’s a place to store an idea or logic that does a certain thing in this case a warrior that uses a weapon which itself would be its own class Hope it helps!
Yeah I know what classes are, thanks. IDK though, why create a class if you don't necessarily need one, you know? I'll wait to see if someone else responds :).
Because it’s a way to store and access methods you want separate from your program file
Yes, you can change which runtime you are targeting in the project properties. Check [here](https://msdn.microsoft.com/en-us/library/bb398202.aspx) for instructions on setting or changing the targeted runtime.
I mean the G score is not a property of any node (I made a mistake in my initial comment), it is the current cost from the best path so far. I am just saying overall, it is very convoluted and uses global state and doesn’t seem to actually be implementing A*. I am not sure what you mean by copied the algorithm directly into C#. If you meant you followed a guide, then either the guide is wrong, or you implemented the guide incorrectly. Either way, it does not seem to operate on the principles of A*. One of the key parts of A* is for every node to store the best previous node. Only when the last node is the best possible F score would the path then be reconstructed by following the previous nodes backward from the end until the start is reached.
Yeah, strange, I must have submitted without putting the rest of it back in. What I was going to say was that asynchronous methods are not hard to use, and I was going to give a small example, but that all seems pointless now since you're stuck on C#4.0....why are you stuck on that?? Prior to async/await, I believe the preferred method of separating the GUI and background work threads in WinForms was to use the [BackgroundWorker class](https://msdn.microsoft.com/en-us/library/system.componentmodel.backgroundworker.aspx) because it managed threads for you automatically by borrowing threads from the thread pool rather than forcing the spawn of new threads manually. Basically, you launch the BGW and it offloads the long running task to the thread pool, and your event returns control to the UI thread. There's a tie-in event on BGW for OnWorkCompleted that you can then use to update the UI if necessary with the results, or if you're just doing something like writing a file to disk and ignoring it, you don't even need to tie in to the event.
You don't reference files, you reference types.
I'm stuck with a specific version of .NET framework to be compatible with a dependency. I think it's DevArt? 
Not likely unless, as I understand it, someone modified your SQL server installation. &gt;Entity Framework never implicitly introduces transactions on queries. It only introduces a local transaction on SaveChanges (unless an ambient System.Transactions.Transaction is detected, in which case the ambient transaction is used). &gt; &gt;The default isolation level of SQL Server is actually READ COMMITTED, and by default READ COMMITED uses shared locks on reads which can potentially cause lock contention, although locks are released when each statement is completed. It is possible to configure a SQL Server database to avoid locking on reads altogether even in READ COMMITTED isolation level by setting the READ\_COMMITTED\_SNAPSHOT option to ON. With this option, SQL Server resorts to row versioning and snapshots rather than shared locks to provide the same guarantees as the regular READ COMMITED isolation. There is more information about it in [this](http://msdn.microsoft.com/en-us/library/tcbchxcb(v=vs.110).aspx) page in the documentation of SQL Server. &gt; &gt;**Given SQL Server’s defaults and EF’s behavior, in most cases each individual EF query executes in its own auto-commit transaction** and SaveChanges runs inside a local transaction with READ COMMITED isolation. [https://blogs.msdn.microsoft.com/diego/2012/03/31/tips-to-avoid-deadlocks-in-entity-framework-applications/](https://blogs.msdn.microsoft.com/diego/2012/03/31/tips-to-avoid-deadlocks-in-entity-framework-applications/)
So I must do It with JS. Okay, so now should I prey to the God Of JavaScript or something? Google aint of much help.
Classes are types yea? Just for clarification cos I’m still unsure
Stopped using HAP ages ago soon as I found anglesharp. It's far easier and quicker to use. Sorry I can't help you but check out anglesharp
&gt; they expect a response Synchronous or async response? Serverless sounds like a pretty good solution for something like an email confirmation, which isn't expected to be 'instant' but still requires a response. If you need a synchronous response they are definitely the wrong tool for the job though.
From your comment about wanting to be a bit organized, one of the points of classes is to organize your code in a way that keeps similar functionality grouped and encapsulated. If you explained your program a bit more, how long is your one file, what types of methods are you creating that you want to organize, etc. Maybe I could be of more help explaining whether classes would be good for your situation or not, and how you could use classes effectively if they were applicable. That said, what you’re looking for is called a “partial class”. Look that up and you should be on your way to having one class span two files.
What is your data source? Localhost or another host? But most importantly, you are not supposed to directly connect to a Database in mobile, you make an API (possibly REST) to expose your data in a safe way to your app. The API should preferrably use tokens to authenticate requests.
My data source is Azure SQL. Yes I know that I am doing this in the wrong way, but right now this is the way I know how to do this :-) But my plan is to later use some kind of local datastore on the Phone, and sync that with my shared DB using an API that talks to my SQL.
I've never messed with this in EF6, but you should be able to manually set the isolation level like Database.ExecuteSqlCommand("SET TRANSACTION ISOLATION LEVEL READ COMMITTED"), which will override the default isolation level for the duration of the context connection or until it's replaced by something else.
how would change the implementation class on MongoUserStore for example?
As part of database configuration, you must set isolation level and recovery model. Read operations need not be encapsulated by transactions. Only write operations must be encapsulated by transactions, and only if the operation is not atomic. IAMA certified SQL Server Database Development professional, AMA.
I switched from AWS to Azure for a hobby project because AWS didn't support 2.1 and I just logically assumed that Azure would. Joke's on me. And now AWS supports 2.1, so back to that. Azure functions do not feel remotely ready to use sadly. 
If it's simple, go ahead and try it your new way and see if you like it. It's easy to get lost in the weeds and miss the elegant solution, and this will inform your decision-making the next time you encounter something similar. If it's complex or it's been a while since you've worked on it, be cautious. You won't remember everything you were thinking about at the time and it will be easy to open yourself up to dumb mistakes while you're getting back into the groove. Remember, everything *always* looks wrong to the outsider, even if it was once your own code. It could be wrong, or it could be better than you're giving it credit for. Do whatever you'll regret the least.
I'd use a timer. Quick and dirty example: using System.Timers; /* code */ Timer FiveMinuteTimer = new Timer(3000000); //5 minutes in ms FiveMinuteTimer.AutoReset = true; //will continue to trigger after the first time FiveMinuteTimer.Elapsed += PullFrameEventHandler; FiveMinuteTimer.Start(); /* code */ protected void PullFrameEventHandler(object sender, ElapsedEventArgs e) =&gt; pullFrame();
Is this on the same machine? As in you are publishing it on the same machine as you are debugging it? Do you run visual studio as the local user or do you fire it up as admin? Because it’s possible this is a permissions issue. 
From a user perspective, a complex query would be faster per 20 rows than say 20,000, 200,000 rows though...
Could you check if the Click-Once publishing included all DLLs needed?
Seems like that's the problem. I copied everything from the `&lt;project&gt;/bin/Release` folder into the folder where Click-Once is publishing to and now it works... Trick now I guess is how to know what files it needs and what files aren't being publishing.
&gt; Is this on the same machine? As in you are publishing it on the same machine as you are debugging it? Yes. &gt; Do you run visual studio as the local user or do you fire it up as admin? Because it’s possible this is a permissions issue. Local user.
I posted everything I know. This came out of Event Viewer so information is limited or at least, I don't know how to get more of it.
Have you tried use timespan object? [TimeSpan.FromMinute](https://msdn.microsoft.com/en-us/library/system.timespan.fromminutes.aspx)s()
There's just a const string that defines where the BaseAddress for the HttpClient.
For the error at row 70 and 79, you need to index the array with householdIncome[k] to get the value. The loop exit condition is looking for the string "No" or "N", not "no" or "n".
The do While wont escape because you'd need to append N or NO inside the Loop to the Variable moreInfo. Even if you press N while inside the loop it wont send it to the Variable right now, which is why it wont ever escape. Did you try to cast your int value on line 70 to a double value?
Are you 100% sure that the input file is the same on both systems? ReadToEnd() method shouldn't reinterpret newline characters. I've made this program to test it: using (var ms = new MemoryStream()) using (var sw = new StreamWriter(ms)) { sw.Write("Line1\n"); sw.Write("Line2\r\n"); sw.WriteLine("Line3"); sw.Write("End"); sw.Flush(); ms.Seek(0, SeekOrigin.Begin); using (var sr = new StreamReader(ms)) { var content = sr.ReadToEnd().Replace("\r", "-CR-").Replace("\n", "-LF-"); Console.WriteLine(content); Console.ReadLine(); }
You are right. The SQL files have different line breaks. Thanks
There's a lot to unpack here. I gather this is a homework assignment and you're learning. &gt;On line 70 I am getting an error, saying that operator '&gt;' cannot be applied to operands of type 'double[]' and 'int'. Console.WriteLine("What is the income of this family?"); Double[] householdIncome = new Double[10]; for (int count = 0; count &lt; 10; count++) { householdIncome[count] = Double.Parse(Console.ReadLine()); break; } What you're doing here is declaring an array with length 10 - that is you're declaring a collection that can hold 10 double values. With your for loop you're assigning a value to the double at index 0, then continuing on with the rest of your code. Later on (at line 70) you're trying to divide by that collection of doubles - not a specific double value. You could access the double you've assigned to by looking at `householdIncome[0]`, or, perhaps more practically, you could just use a single double rather than a collection Console.WriteLine("What is the income of this family?"); double householdIncome = Double.Parse(Console.ReadLine()); Note that this brittle - passing anything nonnumeric into the Console will cause an error. You can avoid that with something more like: double houseHoldIncome; while(Double.TryParse(Console.ReadLine(), out houseHoldIncome)) { Console.WriteLine("Please enter a numeric value"); } &gt; Lastly, my do while loop is not exiting. If the user enter no or n to exit, the loop continues and doesn't exit. There are a few problems here. Firstly, a do while loop will always complete at least once - the check is at the end rather than the start. You may wish to use a while loop instead. Secondly, string comparisons are *exact*. No != no. Converting the input to lowercase may be a good place to start - I leave it to you to learn how. Finally, (and most importantly), you only assign a value to `moreInfo` *before* entering the loop. While in the loop, you're not giving an opportunity to the user to change their answer, thus they loop without end. 
How would I cast it?
either (double)15782 or convert.ToDouble(15782) both should do the trick
Can you explain the practically using a single double instead?
As it is 6:30 AM, Im going to go to bed. I will look at it when I wake up tomorrow. Thank you for your help!
Removed: Rule 4.
Well, right now you're only actually using a single value in each array. For example: for (int i = 0; i &lt; 10; i++) { householdName[i] = Console.ReadLine(); break; } Assigns a value to the string at `householdName[0]`, and then `break;` terminates the loop. You're left with an array of ten strings, but only one of them holds any information. `householdName[1]` through `householdName[9]` will only have the default string value - `null`. You do the same for both `householdIncome` and `householdMembers`. In your `determineAssistance` method you try to iterate over those collections but in your current implementation there would be no need to do so. 
So I need to change to a while instead of a do while and remove the breaks in my statements, and that should help a lot of my problems, correct?
It depends on what behaviour you want really. Removing the breaks from those loops will read from the console 10 times each. If that's what you want - handling data in sets of 10 - then that would be the way to go. If you're aiming to do a single household then you don't want those for loops at all. I see above that it's very late for you, it ought to make more sense after you get some sleep.
I agree. Thanks and Ill get back to you.
https://www.infoq.com/news/2018/07/dev-spaces-aks-preview
Thanks Flexeerrr...Sorry if it was vague. I'm a little confused about things with my architecture. I use DevExpress' scaffolding wizard, it is a proponent of having one viewmodel with collections of entities rather than having collections of viewmodels with their own properties. I think there are pro's and cons to both ways, but I have never done it the collection of viewmodels way. (although to me it does seem more natural that way). I presume devexpress know what they are doing tho. Hope so. haha... But I shall not burden you with more confusion from my end :) Thank you kindly for your answer, it has me thinking about it.. John
So yo do this you should cache data offline. This could be in the form of json for the individual objects. You should also be using an API to access the database and not the database directly. 
I feel like I learned more from his background explanations than from his conclusions. Great article.
I read most of the initial C# spec because i found the .Net Beta a bit hard to work with, but that was a long time ago ;)
Classes are reference types, yes.
"He sh who" :P
I always knew the advice of overriding Equals and getting the hash for structs, but never knew the exact performance implications. I thought it was just to avoid boxing on the equals call. I never realized the default implementation was to use reflection and grab the first field. I understand why it exists, but that's terrible.
 //number of rows: var r = lines.Count; //number of columns (using System.Linq) var c = lines.Select(a =&gt; a.Length).Distinct().ToArray(); \^ this gives you an array of unique column lengths of individual lines. If there's more than one entry in that array, you might have a problem with your CSV. Finally - dispose your `StreamReader`s (using block is your friend)!
So your mongo user store needs to save and load different kind of user models depending on generics? Pretty odd requirement, but if you really need that do, use `class MongoUserStore&lt;TUser&gt; : IUserStore&lt;IUser&gt;` 
&gt; anglesharp How's the performance. I created a scraper with Selenium. When I switched to HAP, it ran so much faster that I thought I'd screwed up -- nearly 2 orders or magnitude.
Do people still use ReSharper or has it been obsoleted by these new VS revisions?
It seems to me this has less to do with structs and more to do with implementing Equals. These could have been classes instead and you likely would have had the same issue. I assume he is using Structs because he believes they are faster than classes, but that is only [half true](https://blogs.msdn.microsoft.com/ericlippert/2009/05/04/the-stack-is-an-implementation-detail-part-two/) and it really depends on how many and how big and how often the GC runs. In this case, the slow down was due to his allocations so I don't think it would have made a difference. 
... you didn't give it elevated permissions, right? RIGHT?
I still use Resharper because it provides a broad improvement over my development experience and I can install it and hit the ground running. Using the community extensions I noticed that there's a lot of overlap so the burden of configuration is yours. IntelliSense can get easily crowded with similar code fixes and Resharper offers a ton of hotkeys which I miss in extensions.
[Akavache](https://github.com/reactiveui/Akavache)
&gt; These could have been classes instead and you likely would have had the same issue. You would not. For classes, the framework uses reference equality by default, which doesn't have these issues (i.e. it's fast and doesn't cause collisions).
The best feature is the absolute performance bomb. 
You are in the C# subreddit asking how we decide whether to use C# and .NET as the server side API as opposed to Java... ok. If there is no existing server ecosystem of applications use whatever your team has the most expertise in. Otherwise, use what the server ecosystem tells you makes the most sense. If your app is backed by Windows servers with the MS tech stack available, use it. If 3/4 of your team are J2EE devs, it would probably be unproductive to tell them to learn .NET as they go. Use Java. If you're looking for a pro/con based set of opinions on the two technologies you aren't likely to get anything of value out of that exercise. Both are perfectly capable general purpose programming platforms with long and proven track records. Neither are going anywhere. Use which ever fits the domain of the problem and skill set of the devs best.
It sucks but I'm lucky enough to not work on huge solutions/projects so it's managable. ^\(at ^least ^keypresses ^are ^queued ^after ^the ^lag.)
Haha it’s a great tool but slows down so much I can’t handle it 
&gt; Use which ever fits the domain of the problem and skill set of the devs best. \^\^This. Also if its a new application and you do end up in the .Net camp, use .Net Core. It opens up so many better hosting solutions for you including containerization.
I haven't in years. R# started getting clunky and slowing down VS so I uninstalled it. I think VS covers 90% of my need.
Ooops...
If I had to do something like that I would probably use two nested foreach statements: int rc = 0; foreach(string[] row in lines) { int cc = 0; foreach(string record in row) { // do whatever Console.WriteLine("Value for (row {0}, col: {1}) is {2}", rc, cc, record); cc++; } rc++; } (the rc and cc counters are unnecessary and were added just for the Console output) Like that you can read both lists with a single number of columns or with different values, like: John;George;Paul;Ringo Joey;Johnny;Dee Dee;Tommy or Kirk;Spock;McCoy;Uhura;Scotty;Sulu;Chekov Picard;Riker;Data;Crusher;LaForge;Troi;Worf;Wesley If you prefer for loops you can use the properties Count and Length of the List and the array respectively to get their dimensions. If you have to ensure that all the rows have the same length you can use decPL's solution or check when reading and splitting the file. Hope it helps, oh and as it was pointed out by decPL, don't forget to close your stream! string filePath = @"My\File\Path\file.csv"; var lines = new List&lt;string[]&gt;(); using(StreamReader sr = new StreamReader(filePath)) { while (!sr.EndOfStream) { string[] line = sr.ReadLine().Split(';'); lines.Add(line); } }
So why use struts in this case? 
I probably need to re-evaluate using ReSharper.. if VS is going to build in all the features I use.. renaming, function signature changes, extracting methods, etc. Because ReSharper is DOGSHIT SLOW.
You can't find a direct solution, because the question you've asked doesn't quite make sense. A multidimensional array (i. e. `string[,]`) has a definable length and width, because all rows are, necessarily, the same size. A jagged array (i.e. `string[][]`) doesn't, because there's no guarantee that each row has the same number of elements; this is also true for a list of arrays, as you have, there. So, you'll need an outer loop to walk through the list of arrays, and an inner loop to walk through each array. Something like this: foreach (var row in lines) { foreach (var col in row) { // do stuff with col, here } } or for (var i = 0; i &lt; lines.Count; i++) { var row = lines[i]; for (var j = 0; j &lt; row.Length; j++) { var col = row[j]; // do stuff with col, here } } You can do similar things with LINQ, too lines.Select(row =&gt; row.Select(col =&gt; /* do stuff with col, here */ )); lines.Select((row, i) =&gt; row.Select((col, j) =&gt; /* do stuff with col, here, if you need the indices, too */ )); lines.SelectMany(row =&gt; row).Select(col =&gt; /* do stuff with col, here, if you don't care about rows */ )); lines.SelectMany(row =&gt; row, (row, col) =&gt; /* do stuff with col, here, if you care a little about rows */ ));
Yeah, I ended up using a breadth-first search lol
[removed]
+1 to Dogshit slow. I'm starting to think the 10 seconds of lag everytime I open the client is not justified by the productivity I gain from it at this point.
&gt;So why use structs in this case? The main point of the article is to show the pitfall but not to discuss when to use structs and why. If you'll look at Roslyn codebase you'll find 500 structs. The same is true for the project I'm working on. You may think that the GC is fast and you'll be right. In most cases. But before I've started a fight with allocations the time in GC for my app was 30% and then it went down to 5%. The difference for E2E time was drastic. And one of the reason was an excessive use of heap-allocated objects where the structs may be used. Stack is an implementation detail unless it's not. For many performance critical application this is not the case. But there are bunch of apps (most of them) where structs may be easily considered as a premature optimization (due to a number of caveats there).
Not sure if I got it right, are you looking for a way to change JSON, while keeping the property name in C# model? Or the way around ? If you’re using Newtonsoft.Json the JsonProperty attribute should do. So first I’d check what library is used for Json serialization in your app - likely to be placed in Global.asax.cs. However the attribute is not a only way to control mapping - might be overridden somewhere else, there are also custom converters, etc. (even though - don’t see a reason to use these, as the model seems to be quite a simple one) - might want to check if there are any cusom contract resolvers or serializers for that model - they could override attribute mapping. 
Using computers since 1982, on the Internet since 1988, on the Web since 1992, building web sites since 1996 and professionally so since 1998. Expert-level skills in HTML and CSS. Have been working on-and-off with Microsoft technologies since 2002. DotNet MVC 5 developer since 2015 (and supporting Web Forms projects that pre-date my tenure). Starting to poke my nose into DotNet Core since it hit v2. Have also touched upon WPF and UWP. Primarily C#, but also some F# and Python and a decent amount of PHP. Can do full hardware and software/OS support from consumer machines to servers and network devices. Also a decent administrator, not *just* systems/network but also databases. My current employment is awesome (hands down the best I have ever had), as it lets me chew through at least 3-6 greenfield projects a year with full and almost completely unrestrained creative/technical discretion on how to best get the job done. However, I am essentially by myself with zero additional support, which often leaves my hirsute posterior flapping in the wind and (at times) a distressingly high pucker factor. I am looking to test the waters, as while I am probably quite a bit more than a Junior dev at this point, I am suffering from no small degree of imposter syndrome and would seriously entertain the opportunity for employment at a quality firm that has well-rounded senior devs who love to mentor a thirsty person. My *ideal* position would be an in-office job where I get to meet my peers face to face and hack away at both code and theory together. I am tied to the south-central region of British Columbia (Okanagan valley and surrounding) due to familial obligations, but if your team is already geographically distributed then all-remote work is fine. I have no problem with starting out on the ground floor if that is what’s needed to get on board with the right team, as long as advancement is directly tied to meritocracy and opportunities are frequent.
Check the link below, it might be helpful https://www.c-sharpcorner.com/article/xamarin-android-create-login-with-web-api-using-azure-sql-server-part-two
It is likely. Otherwise cooperation between git clients running on linux and windows could be more problematic.
&gt;Not sure if I got it right, are you looking for a way to change JSON, while keeping the property name in C# model? Yes
I'm not really sure, what DevExpress is. Don't have time for that, i'm sorry, but I don't understand why wouldn't you be able to have a list of viewModels ( it's just a simple object, which purpose is to be displayed in the view ) https://docs.microsoft.com/en-us/aspnet/mvc/overview/older-versions/mvc-music-store/mvc-music-store-part-3
that's actually a list of arrays, not a multidimensional list. to get the number of items in a list you use the `Count` property, and in an array it's `Length`. to loop through all items you can do something like: for(int col = 0; col &lt; lines.Count; col++) { for(int row = 0; row &lt; lines[col].Length; row++){ Console.WriteLine(lines[col][row]); } }
&gt;Following the [initial announcement](https://go.microsoft.com/fwlink/?linkid=872708) of Visual Studio IntelliCode at Build 2018, we’re excited to report that the [Visual Studio IntelliCode Extension](https://go.microsoft.com/fwlink/?linkid=872707) has been updated to enable coding convention inference for C#, to help you and your team achieve more readable and consistent code. If you’re new to the Intellicode extension, it already provides AI-assisted IntelliSense suggestions, which you can read about in the [initial announcement](https://go.microsoft.com/fwlink/?linkid=872708). If you already have the extension installed, you may have automatically received this update. If not, you can get started now by [downloading the extension](https://go.microsoft.com/fwlink/?linkid=872707).
Selenium is a library for controlling headless browser so performance with that is not good if you want to do scraping but in certain situations it can avoid anti bot measures a bit easier as it parses JS. AngleSharp uses HttpClient under the hood but I prefer to write my own implementation of HttpClient and then just use Anglesharp for the angle bracket (html) processing. It is extremely fast, the only difference is it has full css selector and linq support so compared to HAP it is ridiculously easy to use. I would never go back to using HAP.
Now that's cool 👍
Honestly, I feel like this is more an issue with Visual Studio getting bogged down as a whole. It's gotten much worse in 2015 and 2017 without Resharper, and MSFT really needs to reconsider their direction with it a bit, imo.
 Yeah, they should make the app 16-bit, because 32 is too luxurious.
I have honestly never experienced Visual Studio as slow on my home desktop(I have on my 6 year old laptop). Perhaps I have just gotten used to the Android Studio experience(slow memory hog) too much.
I've been using it for years, but I might have to reevaluate if I can get all the functionality I need elsewhere. I know my company would be happy to not renew my license.
Please post a code sample.
I think there are very specific projects where resharoer is still beneficial. It seems to work best in very strictly structured mvc c# projects. I've never seen it perform particularly well outside of that environment though. I'd much rather have an inaccurate or in-optimal guess (the thing you want is 2nd on the list of options) from the built in intellisense than an intellisense that's bang on 99% of the time, but hangs my machine for 5 seconds every 50 characters. 
public void showResults(string text) { TextBlock objTextBlock= outgoing; outgoing.Text = text; 
I was kind of under the impression that VS already had all these style preference options. Is that part actually new, or just that it can now infer it from sample code?
Please, 8 bit or die.
Removed: Duplicate.
Mainly just use Roslynator in vs2017. Haven't used resharper in 2017, mainly due to it being a slug when used on monolith apps in vs2015. Haven't noticed a need for it either.
I think its now settings per project. To my knowledge it was only possible to change this settings gloablly before.
Forgot again :)
The "older videos" are usually webforms. Webforms was a technology Microsoft released in the original version of ASP .NET that simulated a desktop experience. You put form controls in your webform and it used a hidden field called a viewstate to compare the rendered version of the page with the posted version of the page and then fire events. This completely abstracted the need to know and understand the DOM and HTTP, which ultimately is a very bad thing for building scalable, standards-compliant web applications. Later on they moved to MVC which embraced more closely how HTTP actually works and how the client and server should interact. To be clear, you can still get keydown events and such but you need to use client side javascript and standard DOM events to get the effect, which is simultaneously more standards-compliant and more maintainable. TLDR; Webforms is bad, avoid it. // I've been doing .net programming since 2000-2001
Thank you so much for the response. That makes sense since the only KeyEventHandler I can find in the code behind uses System.Windows.Form.. as a prefix. I'm trying to achieve this without using any client side scripting, as that is part of the criteria for the project. But I'm finding more and more dead-ends without any kind of client side "event handling". 
https://i.imgur.com/0xRJoap.jpg
I'm assuming Dapper-Async 1.3.0 correlates with this: https://www.nuget.org/packages/Dapper-Async/ That's an unofficial fork, which was last updated 2012. I would stick with the official package: https://www.nuget.org/packages/Dapper/
Who set this "criteria"? Saying no client side code, on a project that runs on the client, is nonsense. I'm 90% sure that even the crappy keydown events in WebForms just injected javascript/vbscript into the webpage anyways.
It just does the same work twice. IIRC R# uses an own Compiler for their codefixes, while C# and plugins uses Roslyn. You can't disable Roslyn (AFAIK) while using R#, so both are compiling your code, check everything and offer you fixes. VS gets slower, but the costs are IMHO justified, I think you can't really blame it for being slow if you just disregard 50% of its calculations because you make them elsewhere. 
I finally just got my boss to buy it for me after having 2 years without it. It has a lot of improvements that VS still doesn't have.
&gt;just injected javascript/vbscript That's kind of what I figured, because there is js that is inseparable from the webpage. It is seen as a security issue, and it's not my place to contest this, but the customer might have to accept the inconvenience of not having certain capabilities or the page being responsive and intuitive. *Unless there is a means to achieve KeyPressed Events without scripts.* 
My fellow devs refuse to use R# and it drives me nuts reading their code. I may just need to commit this config file to the repo so it's forced upon them.
Dapper package contains async version of its API, so no need for the second package. Dapper-Async is obsolete and IMHO dates back when Dapper was distributed though source codes with Sync and Async versions.
One step closer to AI just writing the code for us.
😘
You can disable a lot of Roslyn features, and that's what Microsoft recommends when you're first hitting performance issues because Roslyn doesn't like large solutions:https://github.com/dotnet/roslyn/wiki/Performance-considerations-for-large-solutions. I'm pretty sure Resharper 2018 plays nicely with Roslyn code-analysis as well. The support is build into Rider already, so I would find it hard to believe that it's not also being used by Resharper. For our projects at least, having Resharper enabled has a minimal impact on performance of Visual Studio. I'm much more inclined to put pressure on Microsoft to shed their, somewhat, archaic argument against a 64 bit version of Visual Studio. 
This sounds like homework... is it homework? 
ReSharper has its own model, which is independent of Roslyn.
No, it’s not. I’m helping implement a back end to a project I’m not familiar with C# just yet, and was looking online to see if there was a faster way than going this by hand 
you can use [custom formatting strings](https://docs.microsoft.com/en-us/dotnet/standard/base-types/custom-date-and-time-format-strings). for example: `DateTime.Now.ToString("MM-dd-yyyy")` == `07-17-2018`
This does indeed sound a little homework-ish. You’re on the right track with DateTime. You want to parse the string with it, then later on look into date formatting.
Thank you. I’ll mess around with this at work tomorrow. I was trying to use ParseExact but it wasn’t working how I wanted to. I knew there’s a better way than just splitting the string like you do in js
I’m working on an MVC project at my internship, but haven’t worked with C# until like a week ago. I was trying to do this with ParseExact but I couldn’t get it 
Can you post the exact text of the exception, or a screenshot of the exception window? When I paste your code into VS, I don't have any issues. Also, what is the code for FlashCard's Create() method?
[Here's](https://pastebin.com/WJkq4nrb) the code for the Card class, which contains the create method. [Here's](https://imgur.com/a/kH8EuvL) the message I'm getting. Also, just to preface, I'm blind, so I'm not sure I took the screen shot at the right time, or even correctly. If it's not the right shot, I can wait for my girlfriend to get home and she can help me with it.
Looks like a DirectoryNotFoundException, which means it can't find the "D:\Documents\" directory.
Pretty cool. Presumably, you can use some conventions and ignore others? My feeling is that developers should be able to read other developers code without losing their shit if the other developer doesn't use the same bracing or spacing convention. I don't think teams need to be too Draconian about some of this stuff. 
Hmm, strange. I'll check it out then, didn't know it was something simple like that. Thanks for the help :).
So my team is growing again (we are in the process of hiring another c#developer as well) but have another opening. It's for a government contractor in silver spring, MD! Need someone with DNN experience that is down with creating custom modules from scratch in C#/asp.net. It's a junior level spot with lots of opportunity for growth in a mid level/senior level role if the candidate can prove themselves with a Web application redesign that we are doing. 
Only thing I miss from resharper is that cool feature that converts code to LINQ
It's also not a compiler.
Heey, I know linq now.
Look up the Roslyn compiler API.
I don't want to disappoint you, but you better read up on the CLR. C# has no header files and except for some AOT scenarios, it is compiled down to IL (intermediate language), that the JIT (just in time compiler) translates to machine code at runtime. IL can be bundled into assemblies. Usually this is done by having a project - all contained code is packaged as an assembly. There are lots of asterisks to this, but in general: a C# DLL is not a native DLL.
From which language are you interfacing with this SDK and on which platform?
Great info. Thanks for the comparison, esp about CSS
you can have a .editorconfig file at the solution level or even at a folder level. Great for enforcing spaces instead of tabs for indentation!
I have a coworker that has a lot of this: if (someCondition) DoSomething(); DoSomethingElse(); Drives me crazy! I'd rather see this: if (someCondition) { DoSomething(); } DoSomethingElse();
I'm getting conflicting information on whether double check locking is broken in .net as well (I'm assuming you've seen that paper on double check locking being busted in java). seems that some stuff says it works, some that you still need volatile on the field. what is the actual situation here? it seems like nobody actually knows. 
it is very confusing that volatile in c is ENTIRELY different than volatile in the jvm or clr. in c, it is basically "this is memory mapped, just do what i say and don't optimize". in the jvm and clr it's all memory barriers and rules about ordering writes and reads which is very abstract when you're dealing with a vm. it seems nobody actually knows what they do in the clr or jvm except maybe the people who implemented it and researchers. i know way too much random stuff about how the clr works, but still can't summarize volatile even though I've read the docs probably 30 times. tldr: just lock. 
Personally, I prefer: if (someCondition) DoSomething(); DoSomethingElse();
You could do it through session variables, query string, or cookies. Depends on how persistent you want it. Sounds like just a single shot so probably easiest way is via query string. {url}?referrer=mypage.aspx On pageload check for request.querystring[“referrer”] and set the text box text to that value (if it exists)
A couple of options for calling .NET code from native code: - write a C++/CLI wrapper - expose the .NET types via COM - host the .NET runtime in process (this is probably the least convenient one) - run the .NET code in a separate, managed process and use any kind of IPC
The problem with R# is that it's absolutely horrible on performance, and you can get the same effect with various Roslyn rule packs.
Nah that's cool. Didn't expect you to look into it. DevExpress are just a .net UI Control company. Like Telerik, etc...they been around for 20 years or so. I think they are popular amongst winform developers moreso than say wpf.... There no reason why I cant have a list of viewmodels, its just different to my existing architecture, and I like everything to be the same :) But yeah, that's all a complex subject so I won't take up any more of your time. Thanks heaps for your know how! 
if the condition is small enough: if (c) DoSomething(); DoSomethingElse(); 
I actually really prefer the first one and will eventually delete the extra lines if I see them in code like your second one. Only with single line if statements though. Single-line foreach statements seem weird.
Double check locking was broken in Java until a few versions back (maybe 1.6?) because even if the field was declared volatile it could still be assigned to before the constructor completed. The linked MSDN article says that this was also the case in C# until recently (i think it said 4.5.1?). 
It's easier to add additional lines when they're between braces. Don't want a junior dev doing something like this: if (someCondition) DoOneThing(); DoAnotherThing(); DoSomethingElse();
Yes! C#/VS finally gets linting... 
You mean tabs instead of spaces ;)
You should look up Apples huge if statement bug. Please do if (something) { dosomething(); } else { dosomethingelse(); }
[Developers Who Use Spaces Make More Money Than Those Who Use Tabs](https://stackoverflow.blog/2017/06/15/developers-use-spaces-make-money-use-tabs/)
You shouldn't be doing your dates as strings at all. You should be parameterizing your query and adding whatever date as a date, and the parameter should handle that formatting for you. 
Yes. Always use braces. Otherwise you're creating inevitable future bugs.
They said [in a blog post](https://blog.jetbrains.com/dotnet/2014/04/10/resharper-and-roslyn-qa/) that they wont support roslyn because the models are to different and they depend on features roslyn does not offer, and they want to maintain compatibility with older VS versions that dont support Roslyn. I cant say much about performance, but it feels that VS with R# is a lot more unresponisve and starts longer.
Apple's bug was that a line was duplicated, presumably due to a merge mistake. In C#, this can still happen _with_ braces, because you can put any statement in braces to declare a new local scope. if (something) { DoSomething(); } else { DoSomethingElse(); } { DoSomethingElse(); } // BUG!
That blog post is 4 years old, besides they've already built support for Roslyn into Rider. Still, I feel like the point is made when Microsoft tells you to disable substantial Roslyn features when vanilla VS gets sluggish.
&gt; but it doesn't work. Not to sound hostile as you're new to this but this is pretty much rule one of asking for programming help is not to say that. To get started: * It doesn't work how?, there should be an error message being thrown somewhere that tells you at least one problem when you run it * What have you tried already? * Look into the [dispose pattern](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/dispose-pattern), is there a reason your SQL functions need to be written like that? Also have a quick look through [c# coding conventions](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/inside-a-program/coding-conventions), not the be all and end all but worth reading into. Sorry for being vague; a) i don't know precisely whats wrong at a glance and b) just giving you a code snippet to copy paste doesn't help you understand what's going on.
it’s okay I understand. what i mean by it doesn’t work is that the data is still being written every second despite adding in a timer. 
Where are you creating your timer/how many timers are you creating? (i believe the timer is in the loop)
I created one timer inside the loop.
it's Cool 
Could you specify all those c# specific rules. Like there has to be a new line before the brace after a if? 
Was mostly a joke, but my main reason for tabs: So we have 4 spaces for C# 2 spaces for JS as common usage (eg: vue.js and others) So now my code all looks like crap when doing web stuff, or I can just use tabs and have 2 or 4 depending on my personal preference and the other members of the team can use 2 or 4 depending on their preferences. My main pet peeve though on spaces, is if I want to unindent I have to shift+tab instead of just hitting delete, as delete just deletes one space, not the whole indentation. Thats when I notice that its using spaces not tabs and it bugs me ;)
I wouldn't have the { DoSomethingElse(); } on its own line though, its inlined with it, or the braces are on their own line Eg: else { DoSomething(); } or else { DoSomething(); } so yes, you could have two else { DoSomething(); } else { DoSomething(); } or two { DoSomething(); DoSomething(); } But both are safe.
Perfect, thank you :)
&gt; I would hope to try to implement something on the client side as well to suggest names that have already been saved Something like "Code-Completion", where the user types in "ipho" and the Application shows all entries prioritizing the precision (think of it like Intellisense) ex. (Data is already in some sort of InMemory-List / cache) : * .StartsWith("IPho", StringComparison.Ordinal) * .StartsWith("ipho", StringComparison.OrdinalIgnoreCase) * .Contains("ipho", StringComparison.OrdinalIgnoreCase) IEnumerable&lt;string&gt; completionWords = WordMatches.Distinct().Take(50) // Do not show IPhone 3 times ex. (Data is in Database): User types in "ip", you query the database and get the first, say 50-100 matches, and display them to the user
well, that is the issue then. You take X People, create X Timers, and once any of them finishes, it will write its Data into the database. (Which is about X-Database Writes after 5 minutes) Also the data will be incorrect, because the variable "i" is scoped inside the for loop, which will complete after about 1ms, and have a value of Peope.Length (ex. 50), so after 5 minutes, all database entries will be for people.get(50) instead of the proper people.get(i)
What bigger issues do you see throughout the application if you rename the property? Personally I've found that ripping off the band-aid and making the names of your properties/classes line up with the real world a good idea as it reduces the potential for confusion, as you say the new people won't understand "Data Batch".
in WPF, updating textboxes (and most ui elements) must be done from the main thread, are you trying to update it from a background thread (perhaps a second thread / async Task that receives the messages?) In this case you should be getting an exception, but its possible its only crashing your background thread. In some other platforms the UI is updated in the main thread, which you may have blocked with a loop for receiving messages, in which case you'll need to allow the main thread to continue. Moving the receiving code to a secondary thread in this case would help.
https://docs.microsoft.com/en-us/visualstudio/ide/editorconfig-code-style-settings-reference#newline
I am aiming to gather 10 households information, determine if they require assitance, then print the results in a table like format. Kind of like: Name Income Members Assistance? Smith 125,000 5 No
All the updates to the WPf are done in the .xaml.cs file, i believe this is this the main place to do the updates? The other file runs the method inside .xaml.cs file that then updates the WPF, does that sound correct?
So the \*.xaml.cs is the location of the code, but the thread the code runs in is controlled by the application while it is running. How are you receiving the messages? Have you tried modifying your code to something like: `public void showResults(string text) { try { TextBlock objTextBlock = outgoing; outgoing.Text = text; } catch(Exception ex) { Console.WriteLine("An Error has occured: " + ex.Message); } }` to see if there is an error during setting the text?
there is no error that comes up, yes the server gets the message in, and sends it to .xaml.cs method that sets the text for the block
Sorry, of topic due this post and anyway, as I'm only on mobile it would be rather difficult to help you out. But I've looked at your post history and thought I would suggest you become fluent in single languages rather than knowibg little bits of multiple languages as you seem to switch every couple of months. Just some advice, you don't necessarily need to follow it.
It's all good, I am a college student and I have a base in all languages. Once I graduate I plan to dive in to just one and stick with it.
Ah, ok.
What's your prefered method of learning?
OP didn't say he wanted to call anything from native code.
Books and I'm taking a course in computer science
Alrighty, ignore my advice about only using a single double then. I don't want to give you too much help prematurely and kill your learning, but if there's something you're confused about feel free to ask. 
1) you're using || (or) in your while loop. This means that if you entered "no" , moreInforString != "no" returns a false, since moreInfoString is "no". But moreInforString != "n" return a true, since moreInfoString is "no". This is why it still get in your while loop. change || (or) into &amp;&amp; (and). 2) you have to use the for loop around all 3 statements, then you'll be able to fill it like you want. 3) determineAssistance(1.0, 1.0); would be an example, but since you don't know what you have to input, you simply can't do that. You have to change the function so that it doesn't take the doubles anymore and let them access the household members and income as a global variable. (private string\[\] householdName = new string\[10\]) 4) string assistanceNeeded == '';. You have to assign the string before you can use it. posting new code in a second :)
Before you posted your code, I went to work going step by step of what you said. I found your information very helpful! I had to mostly sorted out within the small time before you posted your code. Reading your advice gave me an AHA moment. I guess being a new coder, I get my mind stuck to one thing and can't see how I can fix it differently. Thank you!
Sure no problem, glad to be helpful. Sorry my explanation isn't that great, i'm not a native english speaker :p. Good of you to go step by step and checking everything! Good luck!
To not be a native English speaker, your English is remarkably good! Now I have to task myself with implementing an exit sequence and formatting my code! I am sure I can figure it out from here! I appreciate your help!
OP didn't say anything useful. But they implied they aren't using C# themselves and said they're looking for a .h file, so I assumed that's what they were going for.
Keep a normalized version of string columns in your tables, where you store the strings capitalized. For instance, if *ProductName* is the column where you keep the name of the product as "iPhone", have a *NormalizedProductName*, where you store it as "IPHONE". Then you can compare the criteria, after you capitalize them, against those columns first. Depending on the app logic and your schema, sometimes you may then want to compare the actual string to the original columns. This is the pattern Microsoft itself follows in the AspNet Identity tables it creates, if you follow user authentication and authorization using a DB for user storage.
This sum example is actually pretty real world scenario. It's just one of many methods you use to present the data for the api. It could also be for example correctly presenting the name from a customer object. So the steps you could take to test your api is to first write test on the repository. Preferably use a mock context filled with for example a list of 5 objects. Then the test could be on the repo.getallobjects which should return a list with 5 objects. From here you can expand the tests to more methods. I can't look up any tutorials at this point, but I hope this at least clears some things up for you. Good luck! 
Sorry for not answering, but why don't you use msbuild?
Can you include the client-side code for sending the message to the server and how you wired up the receiver? And, I'm not sure, but the way you're saying it, it sounds like the code you're using to set the textbox text is executing on the server. That code needs to execute in your WPF client.
Why do you create a local variable from `outgoing` to `objTextBlock` if you are still using `outgoing.Text`? Also this code does not really show anything, except that this code "should" work - if used in the correct place. Something like this would be a lot more helpful public void ReceiveCommandFromClient() { var asyncState = server.BeginReceive(OnReceived); // This command runs in a background Thread, so does the callback server.EndReceive(asyncState) // This should throw an exception, because "TextBlock outgoing" was accessed from a different thread. } public void OnReceived(string clientData) { // This will not reflect any changes showResults(clientData); } If that were your code, a simple solution would be (although not recommended, but i don't know anything about how your code looks like) public void OnReceived(string clientData) { Application.Dispatcher.BeginInvoke(() =&gt; { showResults(clientData); } }
I picked your solution and it simply works. I don't know why I was struggling so much. I feel kinda dumb now :) Thanks to everyone who replied!
Yeah I write this style. I find it's much easier to read, and I have a pathological hatred of braces also :D
Do you have any idea what is "best" json or SQLite in this case? I would think json is the simplest thing to do, but perhaps with SQLite its easier to synchronize the data with my SQL Database.
I have several vdproj projects and I think I cannot build vdprojs with msbuild. 
Thank you for your reply! Maybe I got the wrong example or explained it badly. What I intended is that the tons of tutorials that are out there are based on "let's test this super simple function just to see how you should use this testing framework" etc., but I wanted to know how someone who writes "enterprise" APIs is working when writing tests, or even better how he writes test driven classes and methods for an API. Your suggestion of testing the repository as a first thing is surely something to do, but what about testing the whole logic behind a controller action (an integration)? What steps should you take to write those tests? Thank you again for your suggestion, let's see if someone else has some other suggestions to write ;)
I can't wait to "Move type to &lt;expected-file-name&gt;.cs" all over our (otherwise pretty neat) codebase.
When talking unit tests you don't write a test to test the entire controller action. You test every little module to see if the one thing they are supposed to do, do good. So you are looking at the wrong tutorials as you have the wrong idea of what unit testing is. If you just want to test your api calls you could use a tool like postman to automatically test all your calls if that is what you are looking for.
Just a tip for your first issue, capitalize the input so you have less margin of error! So if the user types No, no, nO, N, n, it will still only come out as NO or N, which will lower the amount of stuff you have to check for!
Just found this, maybe that helps you - seems like just settings the value in the registry might work aswell. [https://github.com/it3xl/MSBuild-DevEnv-Build-Server-Workarounds/issues/1](https://github.com/it3xl/MSBuild-DevEnv-Build-Server-Workarounds/issues/1)
I already tried the solutions registered there, but didnt saw this : "You cannot call "DisableOutOfProcBuild.exe" if the CMD current directory (%CD%) points to another location." I'll definitely try to do this and will come back to update. thank you !
.net core would like to have a word with you and your windowed view.
You don't want too much code in your controllers. Say you have a controller with this action: AddEmployee([FromBody]EmployeeCreationDto employee) Now, after mapping your DTO to your business object (could be your entity) you want to do lots of things: * Add employee to your employees table with EF / your repository. * Create a user account in Active Directory. * Create a email account in Exchange. * Send an email to the department head. * Do some logging. You don't want to write all this code in your controller action. Instead, you write a bunch of testable classes: EmployeeService, ActiveDirectoryService, ExchangeService, EmailService... Your EmployeeService would look something like this: public class EmployeeService : IEmployeeService { private readonly IEmployeeRepository employeeRepository; private readonly IActiveDirectoryService activeDirectoryService; /* etc... */ public EmployeeService(IEmployeeRepository employeeRepository, IActiveDirectoryService activeDirectoryService /* etc... */) { this.employeeRepository = employeeRepository; this.activeDirectoryService = activeDirectoryService; } public async Task AddEmployeeAsync(Employee employee) { await employeeRepository.AddAsync(employee); await activeDirectoryService.CreateUserAsync(employee.FirstName, employee.LastName, employee.DepartmentId); // etc... } } Now your controller action is basically: 1. Validate your ModelState. ([I recommend using the ValidateModel ActionFilterAttribute from here](https://docs.microsoft.com/en-us/aspnet/web-api/overview/formats-and-model-binding/model-validation-in-aspnet-web-api)) 1. Map your DTO to your business object. 2. Call IEmployeeService.AddEmployeeAsync(). 3. Catch any Exceptions and handle them gracefully. 4. Do a return CreatedAtAction() or something similar. Most of the logic is now happening in the services. If written properly this should make testing much easier. I'm not sure how to test controllers though. That's not something I'm familiar with.
They should write it using microservices as saas or one up all that and just use functions for everything including hosting the site. Make sure to pick your no sql db and lots of queues.. You had a valid point, im just %$/÷ing with you.
ohh theres a lot of code, and it all works by formatting a message of a user and location, sending it using a http format and then waiting for the response, and breaking down the response to grab the right bits, https://pastebin.com/dqBSWtrv this is the GUI that works to send a message to the client, they are sort of independant. MainWindow window = new MainWindow(); window.showResults(incomingMessage); is the code the in the client that runs the WPF method 
That looks very useful. I will certainly try this.
&gt; MainWindow window = new MainWindow(); window.showResults(incomingMessage); You should be reusing the same `MainWindow` that's currently used in the application. This is creating a _new_, second `MainWindow`, which by default is hidden, which is why you don't see anything.
I'm sure they're loving to read yours!
You sir are a god, how would i get access to it without creating a new copy, how would i get a reference to the current window?
SOLUTION in OP
If you only expect there to be 1 `MainWindow` during the lifetime of the application, then the easiest might be to simply store a `static` reference to it: public partial class MainWindow : Window { public static MainWindow Instance { get; private set; } public MainWindow() { MainWindow.Instance = this; string[] args =Environment.GetCommandLineArgs(); ... }
The application would probably had been fine; it was the impact to the db and potential migration and merge conflicts I just didn't want to deal with.
THANK YOU JESUS, grabbing the instance and running the method in the other class worked perfectly, thanks for the great response!
If you feel the urge to beautify your code, you should have the affinity to use pastebin and not just throw this code here like that.
This is how we learn. I have never used/considered/heard of doing such. Thanks - I will do that now.
Very good attitude my friend! Never give up learning.
This is one of the most enlightening examples I ever seen, thanks. Now I have a good comprehension of how I should really write my code to make it testable. If you were trying to TDD this example, how would you begin? What could the code be like for the test? Thanks again, you were really helpful!
One thing I have found is having an bad attitude when someone points something out is to accept criticism or else help would be gone like a bag of weed at a Willie Nelson concert. [https://pastebin.com/funZt98X](https://pastebin.com/funZt98X)
I use Postman regularly to test my APIs when writing them, but I don’t use it as a test suite app (did I explain it good?). But I understand what you’re saying, basically I should test every single piece of line of code, and that’s why everyone explains it starting with the famous “sum method” I talked of before.
It looks like it does what you need it to do, so there's not much I know of to simplify it. I'd imagine someone here with more experience could find a way, though. If you're just looking to make it LOOK nicer, you could break the regex matching lambda out to a separate method.
- Check your formatting, the `if` should start at the same column as the opening brace. - Instead of `Regex.Match(..).Success` you can use `Regex.IsMatch(..)`. - What exactly is that regex checking for? You can move that to it's own dedicated function. - There's no need to make `distinctWords` a list, you can keep it an enumeration. - Regex is inappropiate for this use-case. If any of the words contains control characters for Regex you will have trouble. Instead use a `HashSet&lt;string&gt;` or something.
You could write your list initialization like this var distinctWords = wordsText. .Split(' ') .Distinct() .ToList(); At my phone atm, indentation might be a bit off, but the one method per line linq writing makes it more query like and readable imo.
1. Regex.IsMatch() would probably be preferable to Regex.Match() in this context. 2. You could wrap the repeated code up in a function. You could reduce the last assignment to something like `activities = activites.Where(x =&gt; Matches(regex, x.Text, x.Account.lastName, x.Account.firstName, x.Account.organization));`, which is a little cleaner. If you also leverage a params arg and Enumerable.Any(), your extra method ought to be pretty clean, too.
Exactly! Important here is that every method you make to test has only one function and then you'll be on your way. Best of luck!
&gt; I have a pathological hatred of braces Take up Python, my dude. 
To anyone who answered, I could have written it differently, different threading, List or whatever else, my aim was more to get rid of "Lock", not sure if that can be done completely without "Lock" but ConcurrentBag or different list types that are made for thread-safe is a start
I've stopped using R# around the same time that VS 2017 came out.
Convince them to try [Roslynator](https://github.com/JosefPihrt/Roslynator). It is basically the refactoring part of R# as a standalone extension.
I know what .NET core is capable of cross platform wise. We have several production apps running on core 2. "Where can I use .NET?" was not OP's question. 
That's not what this is. This is the extension auto-creating the linting config based off your existing code.
Only took a cursory glance, but this looks very nice!
Haha, yes... But I also have a pathological love of static typing ;D And performance heheh :)
I've been working in Python for about a year and a half now. I miss both of those things, every day. 
When building a regex from user input, you should use `Regex.Escape()` so you don't run into issues when a user enters special characters.
I don't think it's their dislike for R# in particular, but a general unwillingness to having their noses rubbed in their own code smells.
Having a go at implementing some of this; if (!String.IsNullOrEmpty(searchText)) { var distinctWords = searchText.Split(' ').Distinct(); var regex = $"({ String.Join("|", distinctWords) })"; activities = activities .Where(x =&gt; Test(x.Text, regex) || Test(x.Account.lastName, regex) || Test(x.Account.firstName, regex) || Test(x.Account.organization, regex)); } With the helper method; public bool Test(string target, string regex) =&gt; Regex.IsMatch(target, regex, RegexOptions.IgnoreCase); One thing I'd probably do is push the responsibility onto the object you are having to filter. Assuming the `activities` is a collection of `Activity` objects, I'd consider giving `Activity` a method that takes a sequence of search terms and returns whether the relevant fields contain that term. That would reduce this code to; if (!String.IsNullOrEmpty(searchText)) { var distinctWords = searchText.Split(' ').Distinct(); activities = activities .Where(activity =&gt; activity.ContainsAny(distinctWords)) } And now the `Activity` class takes responsibility for what it means to contain a particular search term. If you added new relevant fields you could add them to that `ContainsAny` method rather than having to change it anywhere you happened to search in your code.
Do I really have to worry about this if I'm never doing any equality checks on my structs(or putting them into a Dictionary or anything). Most of the time I use a struct is when I have a private method that might calculate something with two results and is only used within that class, eg: public class StructExample { public bool Connect(string connectionString) { var hostPort = ParseConnectionString(connectionString); // Connect w/ socket return true; } private HostPort ParseConnectionString(string connectionString) { string[] split = connectionString.Split(':'); string host = split[0]; int port = int.Parse(split[1]); return new HostPort { Host = host, Port = port }; } private struct HostPort { public int Port { get; set; } public string Host { get; set; } } }
So you are stating have some sort of action trigger when they input X amount of characters to query that database right then and there?
Have you ever used an IValueConverter? This is exactly what it’s for if you’re binding your textbox. I’m on my phone but can give some examples later if you need. 
I have not used a IValueConverter. Yeah man, could you please send an example when you can? I try to get around from data binding, I am not that good at it. 
I'm not too familiar with TDD myself, but you could start dividing your problem into domains and think about how you're going to arrange them into services. Say, your colleague is tasked with writing the EmailService. You don't want to wait for him to finish before you start writing your EmployeeService. What you and your colleague do is create an IEmailService interface that defines the behavior you want to use in your EmployeeService: bool SendWelcomeEmail(int employeeId); // returns true if successful, false otherwise. Now you create an interface for your EmployeeService and write some unit tests for it. What you don't want to do in your EmployeeServiceTests is test the EmailService. It has it own tests in EmailServiceTests and you don't want errors in EmailService to propagate to your EmployeeServiceTests. What you do want is use a fake EmailService that returns fake data. Here's where the interfaces come in handy. Because EmployeeService asks for IEmailService (the interface) in the constructor and not the concrete implementation, we can pass our fake without having to change EmployeeService itself. You could create another class FakeEmailService that implements IEmailService and returns fake data, but that's a lot of work. There are mocking frameworks that make this a lot easier. Personally I use [Moq](https://github.com/moq/moq4). With the fake ready, we can focus on testing the behavior of EmployeeService. Let's say our EmployeeService has a method AddEmployee that calls IEmailService.SendWelcomeMail(). If SendWelcomeMail() fails (returns false), we want to catch that and log it using our LoggingService. Our unit test could look like this: [TestMethod] public void Add_Employee_Should_Log_If_Welcome_Mail_Fails() { // 1. ARRANGE var employee = new Employee { FirstName = "frikyfriky", LastName = "11" }; // Create a fake EmailService that returns false when SendWelcomeMail is called. var emailServiceMock = new Mock&lt;IEmailService&gt;(); emailServiceMock .Setup(x =&gt; x.SendWelcomeMail(employee.FirstName, employee.LastName)) .Returns(false); // Create a fake LoggingService var loggingServiceMock = new Mock&lt;ILoggingService&gt;(); // 2. ACT var employeeService = new EmployeeService(emailServiceMock.Object, loggingServiceMock.Object); employeeService.AddEmployee(employee); // 3. ASSERT // Verify that LogError has been called once. loggingServiceMock.Verify(x =&gt; x.LogError(It.IsAny&lt;string&gt;()), Times.Exactly(1)); } We could create a second unit test that checks if we catch any exceptions that EmailService throws and log those. The only difference with our first unit test is how the emailServiceMock is setup: emailServiceMock .Setup(x =&gt; x.SendWelcomeMail(employee.FirstName, employee.LastName)) .Throws&lt;Exception&gt;(); Keep your unit tests short and simple. Don't try to test too many things in a single test.
Even if it was homework is their really a issue just him asking a question
Ohh, good! Just what I needed, thanks!
Yepp
Having known the pain, thank you. I will check it out.
Can we contact about the implementation of Mapbox, I'm interested. 
ok sweet thanks,
There are a number of places where you are taking a parameter of type `Type`, when instead you could take a generic type parameter. For instance, you could easily create a separate `WMIWatcher&lt;T&gt;`with a `public delegate void WMIEventHandler&lt;T&gt;(object sender, WMIEventArgs&lt;T&gt; args)` and `public event WMIEventHandler&lt;T&gt; WMIEventArrived`.