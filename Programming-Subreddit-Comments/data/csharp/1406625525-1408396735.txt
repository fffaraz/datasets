If you have knowledge of other OOP languages and maybe even a few scripting languages you could pick up C#pretty easily. The problem is that you can't really perform well if you only know C# as development will usually involve a lot of different languages. I don't think I'm wrong in saying that most C# development is done for the web, while the other C languages are used for desktop applications instead.
Even if you just started coding a few small projects at home, that's enough experience for the C# requirement. Now from there, you'll want to go into a particular field of programming if you want to specialize (asp.net, windows, mobile, etc). For a junior level position, you may not really even need to specialize if you can demonstrate somewhat good coding practices and have a decent understanding of how to properly manage project tasks.
Remember you're not just learning C# and ASP.net. You want to know javascript,html,css,jquery,sql,git,mssql,webapi. Throw in some software engineering practices, agile methodology(TDD/BDD), database design, OOP design patterns (IOC) and a few example projects you've completed yourself, and you should be right. Then maybe some hot topic of the month like AngularJs/Knockout coupled with some sexy C# async. 
Thanks for the reply! Yup I was looking at EAV initially. Currently the customer usues Magento, which uses EAV, and mainly the reason for this project is to drop Magento for that specific reason. Once you're getting to over 10-20k skus on Magento, well let's just say you "age" very quickly lol We have 200k, so that why I was looking at something that would be "better" performant than EAV. Although I think I might be able to optimize EAV in .NET specific ways. Gotta check that out
Thanks for the reply!! Yup that's someone how I have it now, I was just hoping there might be a better way. I basically have a List holding Attribute Classes, and a method for assigning a full attribute set
Thank for your reply!! Expando sounds interesting, I completely forgot about that one, thanks for the reminder :)
Thanks for the reply! We are currently using Magento (which is PHP), so I'm kind of trying to stay as far away from Dynamic as I can. Performance is just killer, especially on our specific situation (200k skus, with about 20-30 attributes each)
I'm thinking would something like this maybe be a perfect case for Roslyn? What's everyone opinions on this?
I have to disagree here. In the mid-west where I live it's nothing but .NET all day. Granted you need JS for web dev but overall the language is mature enough you rarely have to reach for another language due to .NET limitations. There are entire stacks written in it. I also disagree that C# is done for web. MVC IMO is great and can compete with any other modern web framework in terms of available functionality, stability, and availability. Also I don't think it's going away in the desktop arena either. With the release of Roslyn .NET compatibility and openness are becoming more a part of the .NET philosophy meaning we should seen better CLR implementations on linux in the near future. I don't think .NET is going anywhere. 
Check Microsoft Virtual Academy. THey have phenomenal stuff. If you're willing to be a big spender, @ $29/month :) Get yourself a Pluralsight membership. It is literally one of the best sites for .NET stuff, very comprehensive and covers 90% of material in .NET. Added bonus, Skeet teaches a bunch of courses :) Also look on youtube or Video for NDC talks, they have a lot of good conceptual stuff Lastly, look on MSDN, best resource ever, if you get stuck on something Stackoverflow or MSDN forum it, or ask here, we'll help :)
+1 for pluralsight. Worth every penny. Also, I think channel 9 usually has some pretty good stuff.
Oh ya forgot about that one, good stuff!!
Start a side project, you will learn much more!
Thank you for the suggestion! I actually already have an account on Microsoft virtual academy. Plural sight is way out of my price range (broke high schooler) I will keep it on mind for later on though. Thanks!
In that case check out https://www.dreamspark.com/ Free Microsoft Tools, software, and access to resources, plus a 90 day plural sight trial. AFAIK you can sign up as a High School student
My point being that a great programming tutorial shouldn't need to be up to date - by definition.
OK. Good idea
Well I think people misunderstood what you were saying :) I think you meant resources on concepts of programming, i.e. OOP tutorial or SICP books. THose are timeless and a lot of the foundation they teach is language agnostic and doesn't drastically change from 10+ years ago and now (certain caveats of course). However, if you're talking about tutorials for a specific language such as C# or C or whatever, in certain cases there have been drastic changes from even last point versions, so for that you really would need an up to date tutorial, maybe not for absolute beginner stuff like loops, variables, etc, but definitely for higher end stuff. For example if you were to learn about handling membership in ASP.NET a tutorial written for MVC4 will be absolutely irrelevant (except of course for certain points) to MVC5, and to someone new and unaware of those difference and having problems making it work in MVC5 it will very discouraging.
LOL priceless!!!
C# will keep improving, and Microsft is making leaps and bounds in terms of Mobile, and Cloud. In fact a lot of people think they are starting to back away from Desktop. You can see it happening now with Universal apps, and aggressive cloud strategies. I can absolutely see next step being taking universal apps and making them run or cross compile to Android/iOS
Oh how I regret the time I wasted trying to get EF and MySQL to play nicely together. Next time I am going to use Dapper or another micro-ORM. All I say for now is good luck.
I think you'd get an answer faster if you check/ask on the MathNet page.
I forgot to mention about it in my post, but I tried using a `List&lt;string&gt;`, gathering the data and exporting it in the end but I ended with the same result as when I am exporting the data to the file instantly.
Perhaps a Mutex will help here. You can lock a file down a file with a Mutex, write to it, then unlock it. Any write requests that take place while the thread with the mutex has the file locked will be queued until the mutex is unlocked. Of course this can mean that your separate threads will hang until the mutex is lifted. Perhaps you can redesign your code to use a messaging system along with a class (perhaps static) that can be c called to update the file?
I would accumulate your results in a ConcurrentDictionary, and in the work which you do on separate threads, make use of a counting variable. Once all the threads are complete, I'd write to the file (so all of the other stuff is done in memory, and then when you're done, write to the file) Here is some example code. In the first example, a ConcurrentQueue is being used, in the second, a ConcurrentDictionary is being used, then after the items are dealt with in threads, the output is sorted by the index class MainClass { public static void Main(string[] args) { const int MAX = 10; // this is the IEnumerable which is going to be iterated in parallel var enumerable = Enumerable.Range(0, MAX).AsParallel(); // with a queue var queue = new ConcurrentQueue&lt;string&gt;(); enumerable.ForAll(i =&gt; queue.Enqueue("This is number " + i)); File.WriteAllText("out-queue.txt", string.Join("\n", queue)); // with a dictionary var dict = new ConcurrentDictionary&lt;int, string&gt;(); enumerable.ForAll(i =&gt; dict[i] = "This is number " + i); File.WriteAllText("out-dict.txt", string.Join("\n", dict.OrderBy(i =&gt; i.Key).Select(i =&gt; i.Value))); } } The output for the queue (which is probably similar to what you're doing... where things enter arbitrarily) was: &gt; This is number 0 &gt; This is number 5 &gt; This is number 6 &gt; This is number 7 &gt; This is number 8 &gt; This is number 9 &gt; This is number 1 &gt; This is number 4 &gt; This is number 2 &gt; This is number 3 The output for the ConcurrentDictionary (which is probably what you want) was: &gt; This is number 0 &gt; This is number 1 &gt; This is number 2 &gt; This is number 3 &gt; This is number 4 &gt; This is number 5 &gt; This is number 6 &gt; This is number 7 &gt; This is number 8 &gt; This is number 9 The actual processing of the elements is done in parallel, and afterward, the data is sorted so that it can be printed in the manner you described. Could you give any additional details on what you're actually doing? In your implementation, the key for the dictionary should be whatever type of data you're building the string from. That's the best I can offer without more details on what you're trying to do.
There are a few reasons why I would not suggest this. First off, the lock will basically make a parallel process into a serial process. If OP wanted to do it in serial s/he would have probably just done it in a regular loop. Second off, this doesn't solve the problem. The threads will still, in general, not finish in any deterministic order. I mentioned in another post on the main thread, that (without knowing more about the problem,) I'd suggest using a concurrent dictionary, keeping track of what 'sortable' item is being processed (as the key), let them all run in parallel, then sort the dictionary by key and output at the end.
Sorry, I should have explained it better. I do not care about the order. The problem is that instead of `This is number 0` I get things like `hTihis iss nnmumbe1r 0` - all of the threads are writing at the same time. I must figure out some way to put each thread in a queue - first thread #1 writes, then #2, etc..
Same general idea. Accumulate the results in a concurrent data structure (such as concurrent queue, etc) then after all processing is done, do whatever else you need to do. 
Doing it like you do "by hand" is a bad idea. http://en.wikipedia.org/wiki/Matrix_exponential http://en.wikipedia.org/wiki/Pad%C3%A9_approximant The book Matrix Computations by Golub and Van Loan has a section on this and stability issues with the method.
I have smashed my head over and over again dealing this this. Best advice I can give you is make sure you have the latest connector for Mysql Install AND the MySql for visual studio package (it is a separate download, both are at Mysql.com) Also ensure this snippet is in your web.config: http://dev.mysql.com/doc/connector-net/en/connector-net-entityframework60.html Best of Luck! 
Here's an example. Whatever functions you're calling in parallel needs to return something which can later be assembled. In the example, each of these functions (Report1, Report2, etc) returns a string, and the result of each is stored in a concurrent data structure (a queue in this case, but any concurrent data structure will do). What you're seeing is called a **race condition**. One fundamental question: why are you assembling each report in a separate thread? Anyway, on to the working code: using System; using System.Linq; using System.Collections.Concurrent; using System.IO; namespace Shorp.Reddit.ReplyToSomeDude { class MainClass { public static void Main(string[] args) { // these are the things you want to do in parallel var functionsToRun = new Func&lt;string&gt;[]{ Report1, Report2, Report3, Report1, Report2, Report3 }; // set up a concurrent queue to hold the results var queue = new ConcurrentQueue&lt;string&gt;(); // run all things in parallel and enqueue the results functionsToRun.AsParallel().ForAll(report =&gt; queue.Enqueue(report())); // write everything in the queue File.WriteAllText("out-queue.txt", string.Join("\n", queue)); } static string Report1() { return "This is report 1"; } static string Report2() { return "This is report 2. It is different!"; } static string Report3() { return string.Join("", Enumerable.Range(0, 10).Select(i =&gt; i.ToString())); } } } And the output the time I ran it was... &gt; This is report 2. It is different! &gt; This is report 1 &gt; This is report 1 &gt; This is report 2. It is different! &gt; 0123456789 &gt; 0123456789
Dude above got it right.
Javascript, not Java, is the sexy language for web dev. Programming from the Client Side Object Model. C# is still relevant for developing the server side on the Microsoft Stack. While VB.NET is also supported, C# is the more popular language for web development and SharePoint development. 
So you would all suggest using the .NET connector itself and not the entity framework? I kinda don't wann to write SQL for all my programs that use a database, because it also needs things like transaction logic. I thought it would be an already solved problem. Is there any other good alternative for this than the entity framework? Thanks! 
You could have a writer thread that reads from a Queue. All the other threads write their results to the queue.
I've used entity framework with mysql before, but never generated the models from the database. Have you tried creating a few models in C# for the db and see if you can select, insert, update, delete those tables via EF code?
MVC or look into MVC WebServices to build a program that would be then hosted and able to be found on the internet so you can access it from anywhere. 
Yes, this is a correct answer. It's what we use at work and it is beautiful.
The solution we use at work is lock/mutex free (which it should be if you ever want it to be performant) and involves writing your log messages/text/whatever to a message queue on another thread; basically your last sentence, or what /u/Deep-Thought said. Spin up one thread with a queue&lt;message&gt; and on your other threads just push the message onto the queue. Unfortunately in practice making this actually thread-safe is quite hard so you'll need to do some reading about this kind of stuff first.
My personal advice about ClickOnce: **run** (away). Source: professional experience. Had the same problem, we never found a cause or fix for it. Changed all apps using it to a homegrown update solution.
I seriously doubt that converting a desktop app to a webapp is easier than porting it to Android.
I agree. And writing both a web service and Android app or a web app that can be consumed on OP's web browser on his cell could get a little complicated. But if OP is interested in learning, it's a worthwhile endeavor, I suppose. There are other options to making an Android app. OP could use PhoneGap or Xamarin or write a small web app. There's probably other options for developing an Android client that I'm unaware of.
If your threads are writing to the file at the same time and interposing messages over each other, then you need to lock on a proper object that all the threads lock on before writing to the file, OR you need to synchronize the threads some other way to coordinate the writes. Another way would be to have all the threads write to a thread safe collection (like ConcurrentQueue&lt;&gt;), and have a separate single thread that writes the collections contents to the file. You may need to post more code to see where the problem is.
This sounds like it'd easily come in under the free limit for Xamarin: www.xamarin.com Otherwise, use ServiceStack: www.servicestack.net . You can send and receive different serialised formats this way. It's incredibly easy to set up, much moreso than WebAPI or the other standard Microsoft-official web endpoint solutions, and still all C#. Otherwise, you could use Nancy : http://nancyfx.org/
But there are two parallel processes going on. Reading and writing. The vast majority of the work is in the reading process, so losing concurrency of the writing process is not necessarily a large hit.
Can you outline your strategy a bit? I'm assuming you have a skeleton executable with .DLLs to do all the heavy lifting, and the .DLLs are updated by the exe. Did you have vastly different production and debug architecture, or were you able to Visual Studio to step-through debug with .DLLs that were dynamically (heh) fetched at runtime?
This is a classic [producer-consumer problem](http://en.wikipedia.org/wiki/Producer%E2%80%93consumer_problem). Essentially what you have is multiple threads trying to write to the same resource (your file). You have a few different options on solving this depending on how you want your program to perform. Most of the other suggestions here wait for all the threads to finish doing their work before writing to a file. Those will probably work fine for what you need. However, if you would rather the file be written as soon as the "producer" threads generate the items, you can give this a try: ___ static Random rng = new Random(); static ConcurrentQueue&lt;string&gt; itemsToWrite = new ConcurrentQueue&lt;string&gt;(); static bool done = false; static void Main(string[] args) { Task consumerTask = new Task(ConsumerMethod); consumerTask.Start(); Parallel.For(0, 5, i =&gt; ProducerMethod(i)); done = true; //signal to ConsumerMethod to exit } //prints messages to file (almost) as fast as possible static void ConsumerMethod() { using (StreamWriter fileout = File.CreateText("report.txt")) { fileout.AutoFlush = true; while (done == false) { string itemToWrite; while (itemsToWrite.TryDequeue(out itemToWrite)) { fileout.WriteLine(itemToWrite); } Thread.Sleep(10); //sleep for 10 milliseconds } } } //adds messages to the queue to print to the file static void ProducerMethod(int id) { itemsToWrite.Enqueue(DateTime.Now + " Thread " + id + ": Started."); int sleepTime = rng.Next(2000, 5000); //2-5 seconds itemsToWrite.Enqueue(DateTime.Now + " Thread " + id + ": Working on report for " + sleepTime + " miliseconds..."); Thread.Sleep(sleepTime); itemsToWrite.Enqueue(DateTime.Now + " Thread " + id + ": Done!"); } ---- This is the contents of report.txt when I ran the program: ---- 7/29/2014 9:05:01 PM Thread 0: Started. 7/29/2014 9:05:01 PM Thread 1: Started. 7/29/2014 9:05:01 PM Thread 0: Sleeping for 3105 miliseconds... 7/29/2014 9:05:01 PM Thread 1: Sleeping for 3126 miliseconds... 7/29/2014 9:05:01 PM Thread 2: Started. 7/29/2014 9:05:01 PM Thread 2: Sleeping for 3012 miliseconds... 7/29/2014 9:05:01 PM Thread 3: Started. 7/29/2014 9:05:01 PM Thread 3: Sleeping for 4183 miliseconds... 7/29/2014 9:05:01 PM Thread 4: Started. 7/29/2014 9:05:01 PM Thread 4: Sleeping for 4034 miliseconds... 7/29/2014 9:05:04 PM Thread 2: Done! 7/29/2014 9:05:05 PM Thread 0: Done! 7/29/2014 9:05:05 PM Thread 1: Done! 7/29/2014 9:05:05 PM Thread 4: Done! ---- Basically, multiple ProducerMethods are executing at the same time. They are all producing messages that need to be added to the report.txt file. Instead of writing to the file directly, they enqueue the item. I'm also using the ConsumerMethod as a gatekeeper for what gets written to file. This ensures that only one thing can be written to the file at any given time. The ConsumerMethod constantly checks the queue to see if there is anything that needs to be written. If there's nothing to write, it just takes a little nap. Once all of the ProducerMethods are finished executing, the program signals to the ConsumerMethod that there won't be any more messages added to the queue and it is time to exit.
If you truly need live data you might look into the SignalR library, it is a way to push data to a receiving application. It would probably be best if the applications could talk to each other, when one is updated, it notifies the other to update it's data. Otherwise you could look into the SqlDependency class which lets you subscribe to changes in a MSSQL table which will fire an event in your application. Both of these take quite a bit of work to get going but your other option would be to poll the database periodically.
W..what? Well, I guess it depends on what tool chain you are comfortable with. It would take me weeks to put together an android app. I could have simple web service knocked and hosted in azure before I finish this beer ( if I drink it slowly ). If the core of the desktop app is all ready structured in simple CRUD terms then it should be straight forward to move wherever you want. 
this.Hide() after the game.Show()
I like it but might as well use a timer instead of using sleep. 
From each of the users I will need to send one string and 26 integers, I will have maximum of 8 groups of 24 users too. With a possible extra group of 40 which will send one string and 6 integers. Displayed will be 24 static images and one changeable image (depending on the data that comes in)
Thank you very much, I will definitely take a look at that.
Why a queue and sleep instead of a BlockingCollection
* For 1), try to re-produce the failure then check ClickOnce logs, Event Log messages etc. You can ramp up the ClickOnce log verbosity: http://msdn.microsoft.com/en-us/library/dd996997.aspx * As a possible answer to 2), I have seen **Squirrel** mentioned somewhere recently, but I haven't used it so I can't give it a personal recommendation. But could be worth a look: https://github.com/Squirrel Otherwise, another option is to create a per-user WiX installer, and then have some simple code in the client app to self-check for a new version of the MSI when it starts up. I can help provide some working example code for this.
I wouldn't use the File.AppendAllText call, I'd probably put together a thread-safe wrapper for a StreamWriter, locking every time I write to the file. I've never looked into the exact behavior of AppendAllText, I'd assume it would do an open, seek to end, write, flush/close, but leaving a streamwriter open seems like a better pattern. The seeking to the end of the file should be quick, but isn't free, and there could be some problem where the call gets a stale file length value so doesn't seek completely to the end?
First, did you look at existing ORMs so you don't have to re-invent the wheel? [Dapper](https://code.google.com/p/dapper-dot-net/), [nHibernate](http://www.nhforge.org/), [etc.](http://en.wikipedia.org/wiki/List_of_object-relational_mapping_software#.NET) If you still intend to roll your own: You should clean it up, move stuff like `typeof(T)`, `typeof(T).GetProperties()[i]`, etc., into variables so you don't have to re-type them and so you don't call expensive functions like GetProperties all the time. And the other problem is that GetProperties() does not guarantee to to return properties in a specific order, so trying to align columns against an arbitrary order of properties may not always work. [See this if you want to force an order](http://stackoverflow.com/questions/9062235/get-properties-in-order-of-declaration-using-reflection). A better solution would be to use column names and property names instead.
Before going down the reflection rabbit hole, are you sure you can't just use linq to sql with the object relational designer? Assuming not, first make sure you dispose your connection after use (`using` block). As for the reflection, you can't make any assumption about the order of the array returned by GetProperties, so assuming it index i of GetProperties would correspond to column i doesn't make too much sense. Also, you should watch out for array index out of bounds when indexing into those arrays. I might be mistaken here, but it looks like you want to return IEnumberable&lt;T&gt; or IList&lt;T&gt; instead of T?
A lot of folks are giving great advice on how to send the data, but you're gonna need a listener and an api first. How is the desktop app going to respond to your queries? What are your queries going to look like? Are they going to be JSON (highly recommended), XML, or some other format? If you're sending to a desktop app, are you sending directly to the PC which is running your app? If so, do you need to take into account non-static up addresses? When you send a query/some data, how will the app respond? Those are all rhetorical questions, ones that you should already have answers for, or planned answers for anyway.
Updated Code: public static List&lt;T&gt; dbToObj&lt;T&gt;(string path, string query) where T : new() { Console.WriteLine("&gt; Setting Object (" + typeof(T) + ") from Database ... "); OleDbConnection c = new OleDbConnection(@"Provider=Microsoft.ACE.OLEDB.12.0; Data Source=" + path + "; Persist Security Info=False;"); c.Open(); OleDbCommand command = new OleDbCommand(query, c); OleDbDataReader reader = command.ExecuteReader(); DataTable schemaTable = reader.GetSchemaTable(); List&lt;T&gt; t = new List&lt;T&gt;(); T temp = new T(); while (reader.Read()) { temp = new T(); string readerName, className; object readerType, classType; for (int i = 0; i &lt; schemaTable.Rows.Count; i++) { readerName = reader.GetName(i); readerType = reader.GetValue(i).GetType(); className = typeof(T).GetProperties()[i].Name; classType = typeof(T).GetProperties()[i].PropertyType; if (readerType.Equals(classType)) { if (readerName.Equals(className)) { typeof(T).GetProperty(className).SetValue(temp, reader.GetValue(i)); U.Message("Matched: reader(" + readerName + ") to Class(" + className + ")", ConsoleColor.DarkGreen); } else { U.ErrorMsg("Could not match property name: reader(" + readerName + ") to Class(" + className + ")"); } } else { U.ErrorMsg("Could not match type: reader(" + readerType+ ") to Class(" + classType + ")"); } } t.Add(temp); } c.Close(); Console.WriteLine("&lt; Done!"); return t; }
Reference for property order: http://msdn.microsoft.com/en-us/library/aky14axb(v=vs.110).aspx &gt; The GetProperties method does not return properties in a particular order, such as alphabetical or declaration order. Your code must not depend on the order in which properties are returned, because that order varies.
How is the data stored? Is it in application memory? Is it updated/inserted into a database?
I would use a single separate thread to write the data to the file. You could use a concurrent data structure to store the data and something like Rx to invoke the writer thread.
Uhh, I made a [QuadTree](http://github.com/Banane9/SharpQuadTrees) library a while ago, but I'm not sure if that's what you want/need. Give it a look :) You can declare a 2D array either with `[][]` (a jagged array/array of arrays) or `[,]` (a rectangle/matrix). The jagged array can contain variable numbers of items in the nested array (i.e. it looks jagged), while the other has the same number of items in every column and every row.
I'm currently working on a capstone project doing just this. The WCF service is easy enough to create, but configuring it, IIS, and Windows has been a huge pain. Working with Eclipse is never really a treat, either. I can't say that it hasn't been a hugely beneficial learning experience, though. 
I'm not familiar with WPF 3DViewport, but if you are working with 3D coordinates I think you need an implementation of an [Octree](http://en.wikipedia.org/wiki/Octree)
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Octree**](https://en.wikipedia.org/wiki/Octree): [](#sfw) --- &gt; &gt;An __octree__ is a [tree data structure](https://en.wikipedia.org/wiki/Tree_data_structure) in which each [internal node](https://en.wikipedia.org/wiki/Internal_node) has exactly eight [children](https://en.wikipedia.org/wiki/Child_node). Octrees are most often used to partition a three dimensional space by recursively subdividing it into eight octants. Octrees are the three-dimensional analog of [quadtrees](https://en.wikipedia.org/wiki/Quadtree). The name is formed from *oct* + *tree*, but note that it is normally written "*octree*" with only one "t". Octrees are often used in [3D graphics](https://en.wikipedia.org/wiki/3D_graphics) and 3D [game engines](https://en.wikipedia.org/wiki/Game_engine). &gt;==== &gt;[**Image**](https://i.imgur.com/xRYiYcM.png) [^(i)](https://commons.wikimedia.org/wiki/File:Octree2.svg) - *Left: Recursive subdivision of a cube into octants. Right: The corresponding octree.* --- ^Interesting: [^Linear ^octree](https://en.wikipedia.org/wiki/Linear_octree) ^| [^Sparse ^voxel ^octree](https://en.wikipedia.org/wiki/Sparse_voxel_octree) ^| [^Quadtree](https://en.wikipedia.org/wiki/Quadtree) ^| [^Caligari ^Corporation](https://en.wikipedia.org/wiki/Caligari_Corporation) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cjbv2wd) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cjbv2wd)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Currently the live data is in the application memory with it being stored in a serial file, currently not stored on a database of any sort.
Sorry, it was years ago.. I do not remember the details now. I *think* we had the apps check through a company vpn for an update, downloaded, and then ran a batch file which copy&amp;replaced &amp; reregistered any dlls, and relaunched. But I could be thinking of another project.. it was so long ago, sorry.
Is it even possible to do that in wpf3d efficiently? I mean, you can't even bind the viewport's children to a collection. How the hell do you want to do that? (Just curious, I'm building a wpf3d application at work right now)
For your server to receive data from the phone, implement Web API (REST) -- it's the next generation to WCF Web/Services. If you also want to receive data from the server, use Signal-R (this is only when the phone is "connected" to the webpage -- if you want to receive data when screen is off or you're in Ruzzle, you'll need to look into Google Push Services). Web API: http://www.asp.net/web-api Signal-R: http://signalr.net/ 
The OP stated his data source is MS Access. What would you suggest as an alternative to connect to it, then?
How is it that web services is not the top comment? 
It's cool to roll your own ORM. You're better for being able to accomplish it. But... Unless you have no time constraints at all where you can make your own complete, robust ORM, this will come back to bite you. I did something accomplishing the same thing as this on a recent project and the consequence was lots of wasted hours making it work in a big application, as well as the time it took to finally swap it out with entity framework or in some cases just sqlConnection/Commands.
&gt;Unfortunately in practice making this actually thread-safe is quite hard so you'll need to do some reading about this kind of stuff first. All he needs to do is call Queue.Synchronized http://msdn.microsoft.com/en-us/library/system.collections.queue.synchronized(v=vs.110).aspx 
Popped up in one of my feeds this morning. Seemed pretty interesting thought I would share. Mix of both simple and complex topics. Still a work in progress looks like he has about 1,148 items so far. I am not the creator of the content just thought I would share an interesting link.
Definitely a cool link I'll throw in as a bookmark. I'm a bit suspect of his memory leak "thing you should know", though. He seems to be really just showing a poor management of memory, not a real memory leak. I believe the example he gave would still be cleaned up at application exit, it would just linger till then. He never really lost the reference either, so it's not really a memory leak. Generally he seems to be good at offering fairly accurate surface explanations of many topics, though.
With your updated version, it's not bad. I'm also assuming since the data source is an access database that you're not looking for large amounts of throughput. So if it works for your needs, then go for it. However if you want to expand this beyond that use case, there are some notes that I have. First is that GetProperties, SetValue, etc. is slow. Like if it were a car coming at an old lady with a walker in the middle of a cross walk, she would have plenty of time moving out of the way. So you never really want to use those past the initialization phase in an ORM. Most ORMs go one of a couple routes to speed things up. First is the ExpandoObject approach. Basically instead of a static type, you get an ExpandoObject (or a list of ExpandoObjects) as a dynamic and that's it. I use a variation of this approach with a custom data type that can convert to a static type on demand. The second approach is the dynamically generated methods that copy the data from the reader/table to the resulting object. That used to be fairly difficult using IL to accomplish it, then came expression trees and that made it easier but it was a little slower most of the time so not that many people went that approach, but now that Roslyn is coming along, I would expect that will be the approach used in the future. The last approach is the "generate classes at compile time" approach. It's not that popular now but there use to be a couple early on that would take your project, scan for your model data, and spit out a modified version of the project that had the data access added... Sort of died out as no one really likes generated code in their code base. Plus you don't really need to do that when option 2 works just as well in terms of speed and is easier to set up.
Seems interesting and I'll give it a look. Though some of the information might be dated (in differences between C# and VB .net, VB now has Auto-Implemented Properties for example)
2,000, jesus. Saved :)
look at the head on that thing! eets like sputnik! eets got it's own orbit! 
Ah, I see what you are saying I think. Instead of my method you are saying to do var doc = XDocument.Load(item.GetXMLDocument(feed.SourceFormat)); var urls = doc.Elements("media:Content").Select(element =&gt; element.Attribute("url")); right?
Aaaaaand bookmarked thanks buddy :) 
C# code coming soon
&gt; would still be cleaned up at application exit That applies to pretty much anything but kernel-land applications, regardless of language. No matter how badly you leak memory, the OS will clean it up once your program crashes (unless critical system programs get an Out Of Memory error because of your application, of course).
Yeah. In user land a memory leak tends to refer to unreferenced allocated memory. He clearly has managed references to the objects still. I saw a better example of a guy who removed his reference but had a delegate set up. He lost the reference to the object but the memory was still used because that delegate still existed.
You can conceptually have a quadtree in 3d space, just imagine a 2d quadtree on the x,y (or x,z) plane, but turn rectangle bounding a 2d area into a rectangular prism extending from negative infinity to infinity along the third axis. This actually makes a lot of sense for applications where there's unlikely to be significant variation in "height".
Ughhh, I guess? What does `.GetXMLDocument` return? If It's a string you'll want to use `XDocument.Parse` :)
What I like about the title of this article is the fact that it shows the current dilemma that most new comers to a language face. People want to learn too quickly. Often, you'll see books with the title learn C# in 3 days, a week, or something among those lines. How can one learn C# in 3 days or even a week ? You might learn how to print something on the screen or how to write a simple method but know what makes C# the language that it is. It is the same problem with articles that have titles like: 10 things you should know about C#.. I know that nobody can't know all these 2000 things by heart, but it shows that to really become a true C# developer takes time and work!
If C# gets "static classes" in its list, VB should get "Modules"; also, I'd put "Case insensitivity" as a plus for VB. :)
`@Html.ActionLink("What", "Index", "Home", null, new { @class = isDsabled ? "disabled" : "active" })` It's not .NET 5, it's MVC 5. Two different things :P
I haven't used VB in years, but I feel like modules just add more global state. Isn't that a bad thing?
It depends on how you use them. Putting all your variables there is probably a bad idea. Functions you wish to use globally (for example, that's where you put ["extensions"](http://msdn.microsoft.com/en-us/library/bb384936.aspx)), that works. 
To answer the concerns listed: 1. It wouldn't. Just use the old syntax for that. 2. Why would it be different? 3. See 2.
It's not a memory leak because you can access his static list at any time, you never lose reference to it. That's the point of the `static` keyword. It would be a memory leak if the list was instantiated but any reference to it was not preserved when it left scope (which in C# will be caught by the garbage collector), meaning you now have an object allocated on the heap but no pointer to it. Do that enough times and you'll find your process appears to be consuming far more memory than it's actually utilizing thanks to orphaned (or 'leaked') objects.
He over-simplified, but managed applications can exhibit all of the behavior of leaking. E.g (forgive the pseudo-C#): void OnSomeImageClicked(MyImage sender, EventArgs args) { this.ActiveImage = MyImage; this.Resized += MyImage.OnResized; } void OnRefreshClicked() { this.ActiveImage = null; this.Images.Clear(); LoadImages(); } If you keep clicking images, and refreshing, the program will keep references to all of images that you clicked on, which is clearly undesirable - when the programmer wrote this.Images.Clear() the intention was to convey that they were no longer necessary. There is no meaningful codepath (the resize event firing isn't meaningful - the images aren't being used anywhere) where the memory is referenced, but it is still retained. Over time, you get the same behavior (from the user's perspective, which is really all that matters) as in a classic memory leak - the program's memory grows unboundedly, when the user performs certain actions. That the mechanic happens to be forgetting to remove a reference rather than forgetting to free is incidental. Edit: And yes, being a kernel developer for a major tech company, I have coded and do code plenty in unmanaged languages. 
Can't you just independently keep track of whats in the viewport, and then add and remove models yourself based on the camera view location? At least that's the approach I'm going with. 
This is a proper example of memory leaks in C#. This is why I had a problem with the example in OP's articles.
Thanks. Model3DGroup[,,] Model3DArray = new Model3DGroup[6,4,4]; Works great. Not sure why I couldn't figure that out myself. 
This is a C# forum, it can be assumed he is using .NET.
Yeah, which is why examples that show having a delegate lying around after removing references to the object that the delegate lives in are proper examples. 
That will hide it, not close it. A huge difference. 
Yeah, sounds like a good idea. The only thing I have is: isn't this computationally intensive? Because when you listen to the viewport camerachanged event, you get hundreds per second (I guess).
Oh my bad! I'm a C++ guy and subbed to most of the programming subs so I just didn't realise this was a sub-specific question. Your answer as above is indeed correct then.
Especially when checking often the performance counters are the way to go. They're designed for this kind of task. 
It has been fixed up no worries broski.
He (Sean Sexton) also does '2,000 Things you should know about WPF' [http://wpf.2000things.com/], which saves my sorry ass almost daily. I found about them from Alvin Ashcraft's Dew Drop daily newsletter, which is also highly recommended. 
Hint: If You want to have a code area by having 4 spaces in the beginning, it has to be surrounded by empty lines :)
i've been working in c# for 6 years and probably don't know 2000 things about it
Welcome to Stack Overflow. :-) 
It looks like it may be an absolute path C:\Users\[removed]\Documents\Visual Studio 2012\Projects\[project name]\[project name].sln where names in [] I have removed or changed. I was able to recreate the issue in a new project this morning. I created a new project and installed the MathNet.Numerics library. At that point everything worked as expected and I didn't get any errors when adding using MathNet.Numerics.Statistics I then closed the project/solution without saving and re-opened it. At that point, the above line of code no longer worked and threw the error mentioned in the OP. I also noticed when I good to the packages.config file, the first &lt;packages&gt; item is underlined in blue with the message "The 'packages' element is not declared." As for source control, I don't have the admin rights to even setup a local git repository. They keep things pretty locked down here and since my job isn't primarily in software development we don't have much help in that area. **Edit** - looks like right-clicking "References" and selecting add reference solved the problem. Still not sure what was messed up though..
&gt;MVC WebServices Web API?
Yes, forgive the addled brain of a parent with a new child. 
honestly, why write a blog post on this, it's a common mistake and already well documented on many places. Not to mention it's fixed by changing a single boolean value.
I don't think ibid. can be used like that, but otherwise I agree.
&gt; It might be faster to copy them to yours, do your work, and copy them back. It might. That's key. There are lots of things that influence the speed that have *nothing, zero* to do with the differences between c# and java. I suggest that you two collaborate to make sure that your programs are in fact doing the same work. If the java guy won't collaborate then it's a pointless "my language is better than your language" pissing content and you shouldn't play along with it, just note that lack of co-operation to the rest of your organisation. 
&gt; His machine does use a SSD, [Elsewhere in the comments](http://www.reddit.com/r/csharp/comments/2bii84/is_there_anything_in_c_ie_net_which_can_compete/cj5sdvc) you say that your machines are the same. Do you mean to say that they both have SSDs? If yours doesn't have an SSD then they *are not the same at all*, and yours is a far lower spec machine.
&gt; According to our devops group "devps group" ha ha ha http://continuousdelivery.com/2012/10/theres-no-such-thing-as-a-devops-team/
Yes, we both have SSDs.
How embarrassing. Edited.
Nice article. This is similar to what I am planning to do with Angular. Hopefully in Angular 2.0 this will be made easier. The following Angular 2.0 preview article explains where they want to go with this. http://blog.angularjs.org/2014/04/angular-and-durandal-converge.html?m=1 Please note the 'Dynamic View Composition' section.
Very cool list! I did have to adblock his image. That shit-eating grin on every page was starting to freak me out.
Anders gets bored and you get primary constructors. 
the shorter version.. var list = new list&lt;object&gt;(); while(true) list.Add(new object()); 
For Title, Order, Filterable you should look decorating your attributes with the [DisplayAttribute](http://msdn.microsoft.com/en-us/library/system.componentmodel.dataannotations.displayattribute\(v=vs.110\).aspx). Kendo Grid will automatically pick the properties up if you. Things such as editiable or hidden, (or others) I do not believe there are any attributes you can decorate with, you can create your own Attribute with the properties you need, but will require using reflection in your view. Here is an example attribute you could make. Just add additional properties you want to use. [AttributeUsage(AttributeTargets.Property | AttributeTargets.Field, AllowMultiple = false)] public class CustomAttribute : Attribute { public CustomAttribute([CallerLineNumber]int order = 0) { Order = order; Width = 200; Locked = false; } public int Order { get; set; } public int Width { get; set; } public bool Locked { get; set; } } The CallerLineNumberAttribute on the order basically orders my fields for me based on where they are in the source file if you wanted to use that. It won't play well if you are using partial classes to decorate attributes in many different places. Example of how you could decorate a property in your ViewModel: [Display(Name="Unique ID"), Custom(Locked = true, Width = 200)] public string ID { get; set; } This is how you could go about generating the columns in the View: .Columns(c =&gt; { c.AutoGenerate(false); foreach (var column in c.GetType().GetGenericArguments()[0].GetProperties() .Where(d =&gt; d.GetCustomAttribute&lt;CustomAttribute&gt;() != null) .OrderBy(g =&gt; g.GetCustomAttribute&lt;CustomAttribute&gt;().Order)) { var attr = column.GetCustomAttribute&lt;CustomAttribute&gt;(); c.Bound(column.Name).Width(attr.Width).Locked(attr.Locked); } }) In this example, the page will get only properties that were decorated with the CustomAttribute you created, order them by the order and loop through them. Then for each column it will bind it by the property name, set the width, and set their lock status. Attributes from the DisplayAttribute should be set by Kendo automatically, at least the column display name is. YMMV though.
The easiest way, not necessarily the best design: - Create 1 Form for the UI interaction. - Create a class to do the calculations. - Create your Database.cs class to manage the Connection and Requests to your Oracle Database. Your calculation class must be working while being unaware of the Database Class. And use it like this: public partial class MyForm { private DataBaseClass _database = new DataBaseClass(); private CalculationClass _calculation = new CalculationClass(); // Event handler for the Click event of the ConnectionButton private ConnectionButton_Click(object sender, EventArgs e) { _dataBase.Connect(); int someValue = _dataBase.GetSomeValue(); int someOtherValue = _dataBase.GetSomeOtherValue(); int result = _calculation.CalculTheResult(someValue, someOtherValue); myResultTextBox.Text = result.ToString(CultureInfo.InvarantCulture); } }
Yea, no need for those classes to know anything about your form...
I think you meant to write "wouldn't use"... It's kinda destroying the clarity of your comment :)
Hahaha, When I posted the link then saw it pop up as the preview image for the list have to admit it took me a little back. No offense to the blogger. 
Huh? I don't get it. Won't the GC remove unreferenced image memory?
Yes, no offense to him... but *that* grin is on-every-single-page.
It would not get rid of errors, it would only shift them to somewhere else. What makes you think the null is the actual culprit? You can completely develop without null nowadays already. 
Lots of good discussion about this issue at these links: [http://twistedoakstudios.com/blog/Post330_non-nullable-types-vs-c-fixing-the-billion-dollar-mistake](http://twistedoakstudios.com/blog/Post330_non-nullable-types-vs-c-fixing-the-billion-dollar-mistake) [http://cafe.elharo.com/programming/imagine-theres-no-null/](http://cafe.elharo.com/programming/imagine-theres-no-null/) [http://stackoverflow.com/questions/3393341/what-would-we-do-without-null](http://stackoverflow.com/questions/3393341/what-would-we-do-without-null) I remember reading somewhere that someone had actually created a branch of the C# compiler that disallowed nulls. I can't find a reference to that anywhere, though. 
Null references should go away. They cause too many problems in their current form and since almost no one actually uses C++ style pointers any more, it's not exactly an important feature. But you would need something to take its place as there are instances where you need a default value or something to signify an empty value. So that's why some people have suggested the [Null Object](http://en.wikipedia.org/wiki/Null_Object_pattern) pattern. There are a couple other options but you would need something like that in the language to compensate for the lack of null.
What's wrong with nulls? As a programmer and DBA I find them very usefull. In SQL tables and table types you can specify if you want them or not. If you use uninitialized variable - it is the mistake. And if it happen to be null instead of something more meaningful like random memory content converted to a value of some type - it's pretty easy to debug. VS for example will show you stacktrace - "voila, here, fix me!". Ok, .NET wouldn't allow you to read random memory locations, but it's fine for it to read default values for not nullable types if they are not local variables. However you might not wish to have zeros in some code fragments. Such bugs are a little harder to debug. You have to insert breakpoints yourself (assuming you know where to look). Null is also intuitive. Means no data. User hasn't entered the text at all, which differs if he specified the field to be an empty text. Can mean "keep the old / default value". It's up to programmer how to interpret this value. Removing support for nulls would be worse than removing the support for negative numbers :) You have not nullable types if you need them. What I strongly dislike about nulls is DBNull.Value - I keep forgetting about them. They should be implicitly converted to nulls for any nullable type. I can't even imagine what could go wrong with this.
[MVC Model](http://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller) [MVVM Model](http://en.wikipedia.org/wiki/Model_View_ViewModel) [MVP Model](http://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93presenter) [Multitier architecture](http://en.wikipedia.org/wiki/Multitier_architecture)
I assume you propose that any uninitialized variables that is a reference type would be initialized automatically with default values for all of its properties? How does that actually make anything better? It will only lead to allowing programmers to be more lazy.
This. Right. Here. Programmers don't get it as much as database guys do. Nulls are meaningful!
No - under the hood the Resized event has references to the images. Just because your code doesn't have references to an object, doesn't mean code you're using doesn't. 
I would suggest this approach but I would also suggest using some form of threading so that the UI doesn't hang.
Sure thing. To get the actual url you have to take the Value property of the attribute... Just append `.Value` to the closing bracket of `Attribute` so it's `.Attribute("url").Value`. Then you'll get an IEnumerable of strings :)
&gt; It will only lead to allowing programmers to be more lazy. Isn't that the real goal though? *I completly disagree and think nulls are important.
You are absolutely correct. Given your scenario, I would likewise recommend not reinventing the wheel and use performance counters. If you want higher resolution, such as per-process details you can look at the System.Diagnostics namespace. For example, you can monitor your own application's memory usage with: System.Diagnostics.Process.GetCurrentProcess().WorkingSet64 / 1048576.0 (depending on your resolution required... dividing by a MB will return the current MB's consumed.)
That's not a leak though. A leak doesn't mean that the memory footprint grows without bounds, it means that a piece of code executes that subsequently renders the application unable to free some allocated chunk of memory. Memory leaks can become a major problem when they occur in a looping construct which causes the amount of leaked memory to increase over time, but simply allocating memory inside a loop does not constitute a leak.
Typically data from a database is used to populate entities (e.g. Customers, Orders, Products, etc); this creates a logical object from perhaps disparate database tables/columns. This object would typically be bundled with business logic (e.g. Customer must be 18 or older, Order must contain at least one product, etc) to produce a "Model" for MVVM. Your form represents the "View" in MVVM, and a ViewModel object will handle your form's logic and wrap your model for easier consumption and a layer of abstraction for when things change. The ViewModel will also contain all the logic for your form so that your form can simply bind to properties on the VM and automatically enable/hide/resize controls. I'd recommend you read about MVVM and EF.
If I'm not mistaken, you haven't actually changed anything in the dataset. You might need to call assetTableAdapter.AcceptChanges() first. You can also set AcceptChangesDuringUpdate to true.
/u/tyler_1290 /u/EliGagerNorris
I'm sorry, I led you down the wrong path trying to answer off the top of my head :) I created a test project to replicate what you were doing and I couldn't duplicate the error. The steps I took on a fresh project in Visual Studio was: 0) Created a dummy access db with a simple table 1) Clicked on the Data Sources tab in VS and added a new Access DB file data source 2) Dragged the table from the data sources tab onto the windows form. 3) Added a CellEndEdit event and inserted the code: table1TableAdapter.Update(database1DataSet.Table1); You might not have used the data source wizard in your project though and from your description since you have the ability to insert and delete but not update, perhaps you are missing the update command in your table adapter? Did you manually build your table adapter or automatic?
I apologize in advance if I don't answer you directly. But you should look into the "as" or "is" operators and "IsAssignableFrom" method. You should be able to directly box your object if you've already determined its type. As for the ToShortDateString() I don't know of a way around this off of the top of my head. Maybe create your own class with either explicit or implicit operators to handle the conversion. 
This might be a shorter way: if(p.PropertyType is DateTime) query += p.GetValue(obj).ToString("d");
I've done something like that using Python, PyQt and also a NoSQL solution for persistence. Data was held in dictionaries. However keeping the UI in sync became more and more complex. Using WPF and MVVM I now highly apreciate the advantages of static typing and the data binding. You might consider using T4 to create your Model and ViewModel classes. This could be done at runtime, but if possible I would restrict creating user defined fields to certain situations (e.g. for business applications restrict this kind of configuration to architects), otherwise the users might easliy shoot themselves in their feet.
Shamless plug - I just posted this gentle introduction to how to use the ASP .NET Web API. The examples are based on .NET, but the concepts are portable. http://www.programmersranch.com/2014/08/asp-net-web-api-gentle-introduction.html
Regex and &lt;[^&gt;]*&gt; are your friends. Look up tag stripping. public static string StripHTML(string HTMLText) { Regex reg = new Regex("&lt;[^&gt;]+&gt;", RegexOptions.IgnoreCase); return reg.Replace(HTMLText, ""); } 
I can't do anything regarding HTML because what I'm looking for isn't in the HTML. 
I assume the code you supplied copies the HTML form a website? edit: No it does not.
Nope. It mimics ctrl + a and Ctrl + c
So what you're doing in those commands is copying just the text from the web page. It sounds like when the text is pasted you are expecting it to be formatted. Is this right?
The as operator, IIRC, will try to convert. If it fails you will receive a default instance. This might account for the default values. 
There is a utility called svcutil.exe, http://msdn.microsoft.com/en-us/library/aa347733(v=vs.110).aspx You can also host the wsdl on your local IIS and add a web or service reference to your project. Edit: there is an older tool to generate code off of the xsd, http://msdn.microsoft.com/en-us/library/x6c1kb0s(v=vs.110).aspx Honestly though the first two options are less of a headache. 
I was kind of hoping he would have explained why his C++ implementation worked but his C# suffered from performance issues.
Thanks, i have used the svcutil and generated a file from the wsdl and xsd's, can i use this as the basis of my service or is it only to be used as a mock service. (sorry I know that sounds stupid) 
OK thanks i am on the right path then
`as` operator will assign the default `null` value, but you cannot use on non-nullable value-types. (That is, only reference types or nullable value-types like `int?`) So you can't even use it for `DateTime` anyway; it won't even compile. In the case of the code though, since you're using a `PropertyInfo` object, and as /u/Mbkn has stated, you've already established that it's a `DateTime`, you can simply cast the result without calling `Convert.ToDateTime`: if(p.PropertyType == typeof(DateTime)) query += ((DateTime)p.GetValue(obj)).ToShortDateString(); Also, FYI this isn't "directly boxing your object"; it's actually _unboxing_. And "no" /u/shadetheartist, there is no `Date` class specifically without a matching `Time` component. I suppose the basic reason is that `DateTime` itself is simply wrapping a single `UInt64` value representing the number of "ticks" since 1/1/0001 12:00am. To store just the date itself didn't have too much meaning or significant storage/performance gains. (if you _really, really needed_ such a structure, you could roll your own, or use another 3rd party library like [Noda Time](http://nodatime.org/) which has one) In typical .NET usage, if you want _just_ the date and want to "strip" the time, there's the [`DateTime.Date` property](http://msdn.microsoft.com/en-us/library/system.datetime.date%28v=vs.110%29.aspx) which will give you the date with the time set to midnight (so you can essentially ignore it) But if you want to get the string representation of a `DateTime` in the format of "M/d/yyyy" you can use the `.ToShortDateString()` method. ***However***, doing so will use the _current culture_ of the application/computer executing the code. If you expect your code to run in another language/culture, it will format the output differently. For example, with German culture ("de-DE") it will output as "1.31.1899" with periods instead of slashes. To avoid this, you would want to use the [`.ToString(String, IFormatProvider)` method overload](http://msdn.microsoft.com/en-us/library/8tfzyc64%28v=vs.110%29.aspx) and pass in a specific culture, for example: ((DateTime)p.GetValue(obj)).ToString("M/d/yyyy", CultureInfo.InvariantCulture); And if you find this cumbersome and you're doing it frequently throughout your code, you can create an extension method to do this for you: public static class MyExtensions { public static string ToMSAccess(this DateTime date) { return date.ToString("M/d/yyyy", CultureInfo.InvariantCulture); } } Then the calling code would look like: if(p.PropertyType == typeof(DateTime)) query += ((DateTime)p.GetValue(obj)).ToMSAccess(); Finally, the "default value" for `DateTime` is `"0001-01-01 12:00:00 AM"`. If somewhere along the line you're mixing `"1/31/1899"` to `"1/1/2001"` I suggest you do some additional testing or debugging to validate your input data and conversions.
`p.GetValue(obj)` returns an `object` type. There is no `ToString(String format)` overload, so this won't compile. However, casting the result to `DateTime` first before invoking `ToString("d")` will work. EDIT: Also, the `if(p.PropertyType is DateTime)` won't work either. `PropertyType` _is_ `System.Type`, _not_ a `DateTime`. As such, it will _always_ resolve as `false`.
Thanks for the correction. Great write up btw. Should have pointed to the extension methods. Simpler than what I recommended.
Okay, so I'm not sure if you are trying to test a copy/paste function or what, so I don't know if you actually have to do a copy/paste, but as an alternative you SHOULD be able to get the InnerText from an HtmlElement you find on a page. If you do something like: HtmlElement element = webBrowser1.Document.GetElementById("elementID"); or HtmlElementCollection elems = webBrowser1.Document.GetElementsByTagName("BODY") You should be able to find an element that contains all the text that you want to parse. If you boil it down to a single HtmlElement, you can use the InnerText property of the element to get all the text without the HTML markup in it. Mind you though, for the 2nd solution with getting elements by tags, it will return an element collection, so you'll have to pull out the appropriate element from the collection. 
The table adapter has UpdateCommand. Here is the query it has: UPDATE Ammunition SET Caliber = ?, Quantity = ?, Brand = ?, Reloads = ?, PurchasePrice = ?, Notes = ?, Photo = ? WHERE (? = 1 AND Caliber IS NULL OR Caliber = ?) AND (? = 1 AND Quantity IS NULL OR Quantity = ?) AND (? = 1 AND Brand IS NULL OR Brand = ?) AND (? = 1 AND Reloads IS NULL OR Reloads = ?) AND (? = 1 AND PurchasePrice IS NULL OR PurchasePrice = ?) AND (? = 1 AND Notes IS NULL OR Notes = ?) AND (? = 1 AND Photo IS NULL OR Photo = ?) AND (ID = ?) I have a feeling that there is something majorly wrong with this statement....
Because you're copying the view that results from the html, you're not copying a normal string. What you're doing is already a huge messy hack, so another quick hack would be to just strip the newline characters. 
My first programming computer was a commodore 64. One of my favorite languages is C#. Damn.
Create a shortcut, and reference the executable out of your Bin/Debug folder
How would I go about doing that?
Sorry for the confusion, but what I hear you saying is to have a three tier architecture like the following; Asp.net site -&gt; App Server -&gt; DB Server. Is that correct?
Seeing more of your code would be helpful, but why not just pass a reference to the datagrid to the thread? [Example](http://stackoverflow.com/questions/3360555/how-to-pass-parameters-to-threadstart-method-in-thread) I'm not positive about WinForms but at least with WPF you cannot update UI elements from a thread that's not the UI thread. [Example](http://stackoverflow.com/questions/303116/system-windows-threading-dispatcher-and-winforms)
That's pretty typical. If you have the Asp.Net site as the only frontend to the resource (database), then you can get by without the App Server in the middle, but if you go that route, I strongly recommend you have a fully reified Data Access Layer api (treat it as a separate project) that sits at the bottom of your Asp.Net code stack.
Alright, so I passed a reference: public partial class QuickScanner : Form { public QuickScanner() { InitializeComponent(); JobProcessor.GetMyWindow(ref this.dataGridJobs); } Then in the threaded class: public static DataGridView JGrid; public static void GetMyWindow(ref DataGridView gr) { JGrid = gr; } And the method: JGrid.Rows.Add("1", "2", "3", "4"); But I get an error, *Cross-thread operation not valid: Control 'dataGridJobs' accessed from a thread other than the thread it was created on.*
Go to the Bin/Debug folder, right click on the exe, Select "Send To... ", Select "Desktop as Shortcut". That shortcut will always point to whatever exe is in the folder.
I believe the second example I gave should help with that. When accessing a UI element from a non-UI thread you will get this exception. So you'll need to either do a dataGridJobs.BeginInvoke() or maybe Dispatcher.Invoke(). Take a look at the second example from my previous post and see if that helps. 
Thank you!
This is a bit above my head, but I'll start reading about Invoke, thank you!
Thanks a lot. 
2nd Example worked like a charm. I had the first thread pass a ref to the second, then used: JGrid.Invoke(new Action(() =&gt; JGrid.Rows.Add("1","2","3","4"))); Which does exactly what I needed. Thank you for your help!
Glad it worked for you!
It could be a rich text versus text problem. When you copy/paste a website in IE, I'm pretty sure it's going to give you the rich text version of what it copied. If you're just outputting that to a string, that could be why it's different.
Seconded
*Finally* we have something that will show up in Google results for [null reference exceptions](http://i.imgur.com/NviIcSo.png)...
OP spams this all over Google+ communities as well.
In addition to sending a shortcut, can't you just press F5 to debug your application?
Good thought but when I copy it from the webbrowser1 and paste it anywhere it's the same. So the issue is webbrowser1
Thanks for trying but I can't do anything regarding HTML because what I'm looking for isn't in the HTML. 
Oh shit you're right. It's totally Internet Explorer that fucks up copy and pasting. So I went ahead and downloaded Awesomium which is apparently like a Chrome WebBrowser but I don't believe there's a way to copy/paste with that.
I mean this in the most polite way possible, but if you do not know how to create a shortcut, you may wish to learn some more basic computer skills before spending too much time learning a programming language. You are going to struggle a lot without fundamental knowledge of the OS like this.
The most programming I ever did on mine was probably printing how awesome I was in a GOTO loop :D I did play the shit out of some Karateka, though. 
Yep. This used to be an interview question we'd ask candidates at a place where we did a lot of Winform development. 
If the information is correct (even worded in a helpful way) then it is worthy of a blog post.
[Web scraping](http://en.wikipedia.org/wiki/Web_scraping)
Nowadays I would consider best practice as using an ORM, and hand-coding SQL in the business logic layer when necessary. This helps you avoid writing so much boilerplate SQL code, and also lets you do things like having unit tests and integration tests for your data layer. The true abstraction and isolation of the data layer happens with your data models at the application layer. The database is where data belongs, not business logic!
That's why he's explaining how to get rid of the html...
Guess he wants to run it without firing up VS
You'll have to use the Windows API and register a hook to the key press event, that should work for Alt+F4, etc. But Ctrl+Alt+Escape is a system level interrupt, so you can't stop that, I think 
The `async` keyword does indicate that the function is asynchronous and the `await` keyword can only be used in a function declared with `async`. Main is not async so you can't use it here (you need to do `var i = t.Result` in you last line instead). This might be your source of concern since the main thread is doing a blocking call. However, this is the only thread that has to block as long as you use async and await in doAsync. The reason that these keywords are useful is that they add language support for writing in a imperative way with Tasks. Any very few things in C# are not well thought out, especially the main feature to come out in .NET 4.5 (`async` and `await`).
No idea, I just read about capturing key Input in an article by a game developer :)
No. See the thing is, if I right click and show source I will NOT be able to find what I'm looking for.
Nothing but cranky developer who is mad that his favorite language wasn't chosen. 
Most arguments are valid but have nothing to do with the language. 
Depending on what happens in doAsync, you can use 2 threads. If doAsync starts work with Task.Run then that will be started immediately in background threads so when you call doWhileWorking in main thread, the other work will occur in parellel. When you then call "await t", main thread will yield the work until work from doAsync is completed. Your example isn't a good one though since in console apps since there is no other work to yield to so you don't end up getting any benefit from doAsync. Instead think about a case where you did the same code in a button click handler in a Windows app. In that case, when you call "await t", method will return the async Task to the caller (dispatcher in this case). So main thread can continue to execute other things, most likely other UI updates etc. This means that your app is responsive while the work in doAsync continues to happen in background. Once doAsync is completed, it will schedule the rest of the method after await to be executed on the main thread again.
When you mentioned overly complex queries, my first thought is that might indicate the database schema itself is an issue. Look into an ORM that suites your needs and use it. I can't recommend that enough. I can't count how many times I've re-invented the wheel here for no good reason. 
[Jon Skeet - Async 101](http://vimeo.com/37913054) gives a good explanation. It's worth watching and what made me finally get it, but it's an hour long. The important part for me is that it allows you to simplify your code (though it might not look that way when you're trying to figure it out). It allows you to write code that is easier to follow, like: do something quick do something else quick await do long running task do something with the result of this when it's done, while not blocking the caller without getting into a muddle of continuation tasks, etc.
This guy is just mad because he's stuck at some problem. I had my fare-share of "C# SUCKS!" moments as well because I couldn't find a solution. After couple of hour it usually turns out that there is some easy solution that I just didn't know of.
I haven't messed with async await enough yet to comment on that but as far as testing goes you should right click the .svc file and select view in browser. This will fire up an iisexpress.exe to host the service. From there go to the debug menu and select attach to process. Attach to iisexpress.exe. You should then be able to debug through your wcf. I assumed that this is what you are wanting to attempt. 
I think one of your points of confusion is thinking that not being able to use await inside a non-async function is a limitation. This is not the case because you can just as well do the following: class Program { static void Main() { MainAsync().Wait(); } static async Task MainAsync() { /* use await anywhere now */ } } In the code sample above you can now us async/await inside of MainAsync as well as in any of the functions it calls, and of the functions they call, etc. Here is the reason why you can't use the await inside of nonasync functions. Underneath, this async function: async Task&lt;int&gt; DoSomethingAsync() { A(); await BAsync(); C(); await DAsync(); return E(); } is conceptually transformed to Task DoSomethingAsync() { A(); return Task.Run(BAsync).ContinueWith(_ =&gt; { C(); return DAsync(); }).ContinueWith(E()); } So when you use await, all that is happening is that the method will be rewritten to return a Task&lt;TResult&gt; instead of just TResult. In a nonasync method though, you want the return type to be exactly TResult, not Task&lt;TResult&gt; because you want TResult to be produced synchronously. Another way to put it is that when we return from the function you want the result of the computation, rather than a promise (i.e. Task) for doing the computation. If you want to look at it in a different perspective, you can ask: why *can* async methods use await? What makes them special? And the reason as hinted above is that you can chain promises (Tasks). You have a task now, and you create a new task that will do extra work after the original task is done. In this way async/await exploits the compositionality of Tasks. The last point I want to touch upon is that when you are using Tasks, you don't need to worry about threads (well, until you want to look at performance optimizations in the last stages of your product development). In a simplification, there are really two types of threads - the Main thread and the thread pool threads. You start in the main thread, and once you run a task (maybe with Task.Run or DoSomethingAsync().Wait()), the task is going to run on a thread pool thread. Any tasks that this new task creates is also run on thread pool threads, and so forth. The number of thread pool threads is managed by the CLR, so all you need to do is create work (in the form of Tasks) and the CLR with assign the work to threads as optimally as possible. In my first code sample, all I'm doing is putting MainAsync() on a thread pool thread and suspending the Main thread until MainAsync() is finished.
You have suggested a method of testing I am not aware of as I have been running it in with the wcftestclient cmd and yes this looks more promising. I think my main sticking point at the moment is do I inherit the interface that was generated and work within that?
Nothing about async/await.
It's definitely a leak, just by a slightly different definition. The kernel prevents leaks at the process level, so all leaks are in the lifetime of the application. Whether the application loses actual track of the allocation, or, due to how the application is structured, doesn't release it anyway isn't relevant to the end result.
Still a memory leak. The end result is that memory is leaked until the application terminates. 
Ok this is where my knowledge of webservices is shite and I suspect I am going horribly wrong. I have been asked to build a web service so we can push data to the client. The client has provided me with a set of xsd's and a disco file, I have used svcutil to generate code, I have made all of the xsd's, wsdl and the (singular) cs files part of my project, then add a svc file on top of that? Do I implement the interface from the generated cs file or am I on the wrong track and they only provided this for testing purposes
First off https://csharpguidelines.codeplex.com/ is a greate resource to start with. Second I didn't go too in depth but the big thing that stood out to me was public void validateUserChoices(object sender, EventArgs args){ List&lt;string&gt; selctMonths = new List&lt;string&gt;(); // creates a list for selected months String[] monthArr = new String[12]; // creates an array so that the value of 'choosenMonths' is not changed monthArr = choosenMonths; // sets 'monthArr' equal to 'choosenMonths' foreach(String x in monthArr){ if(x != ""){ // if the month index('x') dosn't equal nothing it adds it to 'selctMonths' selctMonths.Add(x); } }hs' selctMonths.Add(x); } } The (x != "") should be if(!String.IsNullOrEmpty(x)) As a rule of thumb you should either set a default value for anything that can be null or validate all data that has a potential to be null. Second, this probably won't effect your project much: foreach(String x in usersMonths){ if(x == "January"){ fix.Put(janLabel, 7, labelHeightPlace); fix.Put(janTemp, 100, entryHeightPlace); entryHeightPlace += 30; labelHeightPlace += 30; } else if(x == "February"){ fix.Put(febLabel, 7, labelHeightPlace); fix.Put(febTemp, 100, entryHeightPlace); entryHeightPlace += 30; labelHeightPlace += 30; } Probably makes more sense to be in a switch/case/default statement instead of an if/elseif/else statement. On that note you should in most cases have a final else statement to handle values that don't exists or aren't what you are looking for, errors happen. Remember Garbage In Garbage Out. Same principle applies to switch statements have a default case for when the unexpected happens. Edit: On the note of try/catch statements, I'm typically not fond of using try catch statements that don't actually handle the exception. Given the fact that you do not even use the exception object when handling means you probably should put a try catch only around the main entry method to the application and let any other unhandled exception bubble up from there and remove all other try catches that aren't actually handled as the entry method try catch will capture all unhandled errors.
So web service to web service communication? If you plan on talking to the client side web service (???) with your web service then yes you will want to implement the client generated interface to communicate with the client. I suspect though I may be misunderstanding the design architecture here.
Thank you for the feedback, I changed the ' x == "" ', and added an else statement to the end of the if statement, also I got told that a rule of thumb was you shouldn't use switch/case/default statement if there were more than five cases. This may be a stupid question, but out of lets say 10, what would my code come under ?
First thing is to understand what an asynchronous function does and what it means. Then we can look at it in the context of async/await. Most of the time you are using an asynchronous function when something will take time to complete like I/O (writing to disk, making a network call, and so forth). But, while the operation is completing, your code does not need to be executing. So, you tell the asynchronous function to call you back (hence the name callback). Now here is the magical bit of asynchronous functions. While you are waiting, *there is no thread*. No thread at any level of the stack is being blocked. This means there are no resources getting wasted (CPU, RAM, etc.). None. There is nothing there. How is that possible? Well, what happens when making an asynchronous call is that your code calls into the asynchronous function with a callback. This will go through the various layers (base class library, operating system, etc.) who will all keep passing various callbacks until you get to the hardware interop layer. At the hardware interface, the operating system/driver will store the callback information the operating system gave it with an associated ID. How big that storage is depends on your architecture, but it is typically measured in bits. So then the hardware does its thing (using magnets to store bits, sending data halfway across the planet, whatever). While the hardware is doing it's thing, there are no threads waiting for it. Only that little bit of ID with a function pointer in a driver's memory is what keeps your program in mind. When the hardware is finished, it will send a hardware interrupt to the driver/operating system saying "Hey, operation 123 finished with this result!" at which point the driver/OS wakes up and calls the callback with the appropriate returned data. The OS will then make the callback into your program using whatever appropriate thread is available. By default, it asks for one from the thread pool. That is the essence of an asynchronous call. You ask for something to be done and then waste no resources while it is being done (no threads are ever blocked or ever waiting). And that is good because creating a Thread is one of the more expensive operations you can do short of I/O, and it consumes a lot of memory (~1 MB per thread). Before async/await, doing asynchronous operations was a major pain. Your code would look something like this. public class Name { Something thing = new Something(); private void DoIt() { this.thing.BeginOperation(this.OperationCallback, null); } private void OperationCallback(IAsyncResult result); { var value = this.thing.EndOperation(result) DoSomethingElse(value); } } The problem is that you get into what is called "callback hell" (credit the Javascript developers with the term). Doing anything highly asynchronous requires a bunch of callback functions all over the place and it is very hard to trace your code because you might make several asynchronous calls in a row. So just reading the logic becomes hard. Enter async/await. Async/await are keywords that make it much easier to write an asynchronous program. You can write it and think about it in a synchronous manner while the compiler magic makes it asynchronous. That same example can then be rewritten as it is below. It is greatly simplified and easy to read: public class Name { Something thing = new Something(); private async Task DoIt() { var value = await this.thing.OperationAsync(); DoSomethingElse(value); } } Now, you need to understand what is happening under the hood. The same thing with the callbacks and so forth is still happening. The difference is that the compiler is doing some magic in order to hide the complexity from you. The async keyword flags a method to be re-written by the compiler by turning it into a state machine. The await keyword says that this place marks the beginning and end of an asynchronous method, so every instance of the await keyword marks a change in the state machine. If you were to look at the code generated by the compiler for that async/await method, it would look something like what is below. Not exactly, because there are a lot of other things that need to go into it (exception handing, multi-threading, etc.), but it should give you an idea. public class Name { Something thing = new Something(); private IAsyncResult _DoIt_asyncResult; private int _DoIt_state = 0; private Task DoIt() { switch (_DoIt_state) { case 0: { this._DoIt_state = 1; this.thing.BeginOperation(this._DoIt_asyncCallback1, null); } case 1: { this._DoIt_state = 0; var value = this.thing.EndOperation(this._DoIt_asyncResult); DoSomethingElse(value); } } } private void _DoIt_asyncCallback1(IAsyncResult result) { this._DoIt_asyncResult = result; this.DoIt(); } } That is cool. But there are several side-effects that you NEED to be aware of. The thread that begins the async call is NOT (by default) the thread that finishes it. The thread that started it will exit the method and terminate (or return to waiting state if a UI thread). That is problematic in a console application because when the main thread terminates, the entire program terminates. So you actually need to block the main thread in a console application. That is why you call .Wait() or .Result. When writing a GUI application, this means that the UI thread may not be the one that finishes processing, but only the UI thread is allowed to change the UI. So you need to make sure to grab the current context when awaiting. But, the reason you are getting a compiler error is that Main simply is not async. It has not been written into a state machine, so when the await keyword comes up, there is no state machine for it to mutate. And you get a compiler error. The method re-write is also why async/await and the yield keywords cannot be used in the same method. Yield re-writes the method as well. Please let me know if you have any other questions or clarifications on this. I tried to simplify where I could, but I may have gone too far. Unfortunately understanding async/await requires understanding a lot about what goes on under the hood.
Sounds like a preference issue I've never ran into an instance where people thought huge if else statements were more readable than switch case statements. For school project 7-8, in the real world 4-5. I tried to avoid most of the readability issues that are addressed in that link that i provided. The catch statements would be what I would rail on you for at a company. For school though it is fine as is. It is a starting point for learning to CYOA, but there are better ways for handling this that will save your sanity later in life. The article that I've linked should address this as well. If not a quick Google search on C# exception handling will yield some pretty good resources. 
Is this a one time thing or something which has to be done commonly? If it's a one time thing, I might suggest doing it map reduce style (do you have free monthly azure credits on an msdn subscription)?
You may want to work on splitting up your methods into shorter submethods that can be composed into your final method. A method should do only one thing. Long methods often do more than one thing. Long, complicated methods makes it harder to reason about the method's correctness. A good rule of thumb is that a method should not be longer than seven statements. If it is longer than that, it is likely that the method is doing too many things and should be split up into submethods.
Yes. If this is the case then the interface is how the client intends for you to interact with their web service. The interface object was sort of hard for me to grasp when I was first learning about it but as I started learning about reflection and in particular MEF the light bulb clicked. Interfaces are some times referred to as contracts, as means of guaranteeing that what you implement is public and available for inheritance. That interface you will be using contains all of the public methods made available to you by the client service. So in this case the Client side might have a method called GetData() in there interface. The GetData() method has no implementation, meaning you will have to define what that method means either through inheritance or a Instantiate/Create type method that returns an implementation for the GetData() method. Why would you do this? Some processes in particular when using reflection, do not care what the actual implementation is for the GetData() method but only that it has an implementation to execute. Meaning one projects GetData() implementation could process a certain algorithm and another implementation could process a totally different algorithm as long as both followed the same method signature and expected return types.
This is an almost perfect example of when you would want to use a switch statement. I've never heard anyone suggest not using a switch based on the number of cases.
At first glance, two things come to mind. 1) I see a lot of duplicate code. Any time you find yourself copying and pasting, it's usually a good idea to take a second look. Most of your duplication could be eliminated through either creating more methods, or using lists and loops in the right places. 2) Instead of using strings for the months, I would strongly suggest looking into creating an enum. Let me know if you have any more questions, or if you post some updated code
When you're doing stuff like selecting months, getting data for a particular month and so forth, you have lots and lots of copy-pasted code. You need to rethink your approach - first of all, months aren't strings "January" "February" and so forth, treat them as numbers 0-11. When you want to write the word "January", make an array that links between the month's number and its name. Then you can shrink your code significantly - Instead of Label janLabel = new Label("January:"); Label febLabel = new Label("February:"); ... Label decLabel = new Label("December:"); You can make an array of Labels and write labelArr[i] = new Label(monthStrings[i]); in a loop and suddenly you shrink that bit of code by a factor of 4 or 5 and make it less error-prone. That's the big issue here - as a rule of thumb, if you write a piece of code more than three times, you're quite possibly doing it wrong.
Can you invest in MATLAB? Or is this not an in-house project?
I agree. Good example of when to use a switch statement. There are, however, people that would still prefer else ifs. I don't really get why one would, but some do. 
No, when running in 64-bit, the CLR can address all 2^(64) memory locations since around [2005](http://msdn.microsoft.com/en-us/library/ms973190.aspx). I think you might be talking about the 2^(32) byte limit on single object sizes, but this is not going to be an issue with 80k elements. Further, .NET 4.5 allows you to have [larger objects](http://msdn.microsoft.com/en-us/library/hh285054).
Code for how. Comments for why. 
Business rules are not always evident from code. 
Not my question, but thanks for that link. It was a great explanation.
Hey, I made a similar tool :) (I hate how vmware wastes ram with their stupid stuff) https://github.com/eried/ServiceLauncher
This is awesome! Congratulations to Xamarin. The entry price has been such a hurdle for so many people, myself included. 600 dollars to make an indie app for two platforms is a real and big investment. 50 bucks i can live with - even if its the same after a year. Will sign up for Xamarin iOS too - right now.
Try doing it on the GPU. It's fast as. I can't post you some code tomorrow (I'm on phone now), or messages me.
I've been doing some googling and I can't really find a good article about comparing Xamarin to Unity. Anyone care to chime in on that?
One is for games (Unity), the other is for anything (Xamarin). Xamarin offers native UI controls and API bindings.
I almost want to do school over again (nope, feeling passed) so I could ask for feedback like this... Great idea!
I've put the labels and entry's in an array, but have a problem with the entry's The loop creates the entry but when I try to handle the change of the entry it only sets the last value in the array. i.e. etrArr[i].Changed += (sender, args) =&gt; TempAdd(sender, args, i - 1); this only handles the last 'entry.Changed' in array and not the rest, so it would handle etr[11], but non of the rest, what am I doing wrong?
1 ) Unless the code for each month is autogenerated, I would highly suggest using an array to store objects for each month instead of (for example) janTemp, febTemp, etc. The less you duplicate code, the easier it is to add new code and refactor. 2) Method/class documentation is usually done in this way (where I work at least): http://msdn.microsoft.com/en-us/library/aa288481(v=vs.71).aspx. This is definitely a matter of preference, but I suspect that this style is pretty common in industry. 3) Based on my experience with windows forms, the current component should only call ShowAll/Show to its child components. So in your case, line 117 should be in Main. 4) On line 32, that 5 should be a 6. Use `Cities.Length` there instead. 5) Line 249 is not doing the right thing. You should [clone](http://msdn.microsoft.com/en-us/library/system.array.clone) the array instead of setting it equal directly. Following is how I would improve it. I had to remove comments due to reddit's post length restriction. It's almost 200 lines less that the original even before removing comments. using System; using System.Linq; using Gtk; using Pango; using System.Collections.Generic; class TempApp : Window { private static readonly string[] months = new[] { "January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December" }; private bool[] choosenMonths = new bool[months.Length]; // stores users choosen months private Dictionary&lt;String, Double[]&gt; locationTemps = new Dictionary&lt;String, Double[]&gt;(); // stores each locations temperatures private string usersLocation; // stores users choosen location private Entry displayAvrTempEntry; public TempApp() : base("Average Temperatures") { SetPosition(WindowPosition.Center); SetIconFromFile("/home/murraywatson/Documents/C#/nat 5/nat5_as/logo.jpg"); SetSizeRequest(600, 380); Resizable = false; DeleteEvent += delegate { Application.Quit(); }; var Cities = new []{ "Glasgow", "Edinburgh", "Aberdeen", "Dundee", "Perth", "Paisley" }; // array used to store locations for (int i = 0; i &lt; Cities.Length; i++) { locationTemps[Cities[i]] = new double[months.Length]; // appends each location to 'LocationTemps' and sets their value to 'defaultTemps' } var fix = new Fixed(); var citieLocations = new ComboBox(Cities); // ComboBox for locations citieLocations.Changed += choosenLocation; // calls 'choosenLocation' when the location is changed fix.Put(citieLocations, 15, 15); for (var i = 0; i &lt; months.Length; i++) { int temp = i; var cb = new CheckButton(months[i]); cb.Toggled += (sender, args) =&gt; cbCheckStateMonth(sender, args, temp); fix.Put(cb, 15, 55 + i * 25); } // creates a 'Button' which allows user to enter temperatures // :START Button enter_temps_butt = new Button("Enter Tempratues"); enter_temps_butt.SetSizeRequest(150, 60); enter_temps_butt.Clicked += validateUserChoices; fix.Put(enter_temps_butt, 205, 290); // :END // creates a 'Button' which gets the average temrature and displays it to the user // :START Button show_avr_temp_butt = new Button("Show Average temperature\nfor Selected Month"); show_avr_temp_butt.SetSizeRequest(200, 60); show_avr_temp_butt.Clicked += getAvrTemp; fix.Put(show_avr_temp_butt, 370, 290); // :END Label AvrTempDescLabel = new Label("Average temperature in centrigrade for selected months.\t "); //creates a label to tell the user what is displayed in the 'Entry' widget fix.Put(AvrTempDescLabel, 205, 105); // Creates an 'Entry' widget, which is used to display the average temperature' // :START displayAvrTempEntry = new Entry("Average Temperature"); displayAvrTempEntry.SetSizeRequest(200, 30); displayAvrTempEntry.IsEditable = false; fix.Put(displayAvrTempEntry, 205, 135); // :END Add(fix); // 'fix' is added to the window } public void cbCheckStateMonth(object sender, EventArgs args, int monthNo) { CheckButton cbState = (CheckButton)sender; // gets month 'CheckButton' state choosenMonths[monthNo] = cbState.Active; } public void choosenLocation(object sender, EventArgs args) { ComboBox selLoct = (ComboBox)sender; // gets selected locaiton usersLocation = selLoct.ActiveText; //sets 'userLocation' equal to the selected location } public void validateUserChoices(object sender, EventArgs args) { if (choosenMonths.Any(m =&gt; m) &amp;&amp; !string.IsNullOrEmpty(usersLocation)) { getTemps(choosenMonths, usersLocation); // calls 'getTemps' if the users choices are valid } else { errorDialogs("An error has occured", "To be able to enter temperatures you must\nhave choosen at least one month and a\nlocation.", "info_logo.png"); } } public void getTemps(bool[] usersMonths, String Location) { var winTemp = new Window("Enter temperatures"); // creates a new window winTemp.SetDefaultSize(400, 360); winTemp.SetPosition(WindowPosition.Center); winTemp.Resizable = false; var fix = new Fixed(); var enteredTemps = (double[])locationTemps[Location].Clone(); for (var i = 0; i &lt; usersMonths.Length; i++) { if (usersMonths[i]) { var label = new Label(months[i] + ":"); var entry = new Entry(); int temp = i; entry.Changed += (sender, args) =&gt; tempAdd(sender, args, temp, enteredTemps); fix.Put(label, 7, 7 + 30 * i); fix.Put(entry, 100, 3 + 30 * i); } } // creates button to add temperatures and close window // :START var addTempButton = new Button("Ok"); addTempButton.SetSizeRequest(100, 30); addTempButton.Clicked += delegate { locationTemps[Location] = enteredTemps; winTemp.Destroy(); }; // :END fix.Put(addTempButton, 100, 3 + months.Length * 30); // adds 'Ok' button to the window winTemp.Add(fix); // adds 'fix' to the window winTemp.ShowAll(); } public void tempAdd(object sender, EventArgs args, int monthNumber, double[] enteredTemps) { Entry temp = (Entry)sender; // gets value for the temperature entered double d; if (double.TryParse(temp.Text, out d)) { enteredTemps[monthNumber] = d; } else if (temp.Text != string.Empty &amp;&amp; temp.Text != "-") { temp.Text = string.Empty; // if the temperature entered is not numeric then an error is displayed errorDialogs("Invalid temperature", "Invalid temperature, Please ensure you\nhave only used numerical values.", "info_logo.png"); } } public void getAvrTemp(object sender, EventArgs args) { double average; if (string.IsNullOrEmpty(usersLocation)) { average = 0.0; } else { average = choosenMonths .Zip(locationTemps[usersLocation], (chosen, temp) =&gt; new { chosen, temp }) .Where(p =&gt; p.chosen) .Average(p =&gt; p.temp); } displayAvrTempEntry.Text = average.ToString(); // displays the average temp in 'displayAvrTempEntry' } public void errorDialogs(String title, String message, String image) { Window win = new Window(title); // creates window for the error dialog win.SetDefaultSize(430, 150); win.SetPosition(WindowPosition.Center); win.SetSizeRequest(430, 150); win.Resizable = false; Fixed fix = new Fixed(); Gdk.Pixbuf imageIcon = new Gdk.Pixbuf("/home/murraywatson/Documents/C#/nat 5/nat5_as/" + image); // gets image for error icon Image errorImage = new Image(imageIcon); // creates image for error errorImage.SetSizeRequest(80, 80); Pango.FontDescription fontdesc = Pango.FontDescription.FromString("verdana 10"); // changes the font for the error message Label msg = new Label(message); // creates label, which displays the error message msg.ModifyFont(fontdesc); // creates 'Ok' button, which closes the error dialog // :START Button okButton = new Button("Ok"); okButton.SetSizeRequest(100, 30); okButton.Clicked += delegate { win.Destroy(); }; // :END // 'fix' puts each widget on the window // :START fix.Put(errorImage, 20, 20); fix.Put(msg, 120, 33); fix.Put(okButton, 300, 100); // :END win.Add(fix); // adds 'fix' to window win.ShowAll(); } static void Main() { Application.Init(); // initializes applicaiton new TempApp().ShowAll(); // creates an instance of 'TempApp' Application.Run(); // runs the applicaiton } }
$50 per month is the same as $600 per year. I don't see what has changed. 
Why do you need to make up your own way to enumerate month names? DateTime and friends already do it for you, AND they localize them! static string GetMonthName(int monthId) { return new DateTime(1, monthId, 1).ToString("MMMM"); } There is also [System.Globalization.CultureInfo.CurrentCulture.DateTimeFormat.MonthGenitiveNames](http://msdn.microsoft.com/en-us/library/system.globalization.datetimeformatinfo.monthgenitivenames.aspx)
http://stackoverflow.com/questions/12861560/lambda-variable-capture-in-loop-what-happens-here
"month-to-month" vs. "per year" 
That is a very good point! It didn't even dawn on me to do it that way. 
I'm not an expert in unity, but its mostly for making games/simulations, etc. Xamarin is based on Mono, which was a port (or some open source thing) of .NET to UNIX. My understanding is you can use one code base in C# to make Android, iOS apps and windows apps.
I would list case insensitivity as a downside :-) 
I have to say, this has been the least buggy/cleanest C# github project I've looked over.. ever. Thank you!
I can give you $50 per month, but I can't afford the $600 one time payment. That's pretty much it. I wish MSDN accounts had a month to month deal.
I do describe Windbg and how to use it to diagnose many managed issues. It may not address your specific problem, but I think you'll still find it valuable.
$600 is a lot up front for something you may not be sure you really need. Being able to try it on a month to month subscription makes it easier to ease into it. If it ends up not being the right tool, you're not out $600.
Add only adds a single item to the collection. To add all of the items in the grabProxy result you could use something like this (untested) var items = grabProxy("http://proxylist.hidemyass.com/search-1300902#listable/"); foreach (var item in items) listBox1.Items.Add(item); 
Oh I see. That makes a lot more sense but now when I click button1, nothing shows up inside the listbox1
I think Unity actually uses the same Mono runtime. It is meant for games (started for 3D games but many are doing 2D games with it as well and you can use C# for game scripting as well)
Lower cost of entry. It's not even $50/month, you can concentrate on a single platform for a month or two, than move on to the next and only pay $25/month for the platform you need. And when you're done and release the app, you can stop paying for a while until it makes money or you want to do an update (this is assuming they keep this deal going, for now it's just a test and if they stop the deal and you stop paying, you can't start it up again) If you spend four months, release an app, and it's not successful, you just saved some money. The reality is you might figure out Xamarin is actually worth the cost and just keep paying
People have been asking for that since they changed the pricing model, doesn't look like they will budge on that
It's interesting that their plans page now shows monthly prices instead of the annual prices it used to show (and there's no annual option for indie, just month by month) maybe someone advised them that showing lower numbers even when customers have to pay annually makes the purchase easier (I'm not going to spend $1000 on a license, wait, $83 a month? that's not so bad, I spend more on starbucks...)
Or alternatively you could use AddRange to add a collection of objects. Haven't tested an array but it should work (on my phone). http://msdn.microsoft.com/en-us/library/z018s5az(v=vs.110).aspx
I think you pastebinned the wrong thing - I don't see button1 in that snippet.
&gt; Mono, which was a port (or some open source thing) of .NET to UNIX Mono is an open-source cross-platform implementation of .NET. Not only does it run on Windows, Linux, and OS X, but it also supports multiple architectures: x86 x86-64, ARM, MIPS, PowerPC, SPARC, S390, and IA-64 (Itanium). I don't believe it technically supports "Unix" as an umbrella of systems, as that would include stuff like HP-UX and AIX, but it certainly supports FreeBSD.
There are a bunch of issues: 1) Why not just create a GetByIndex(TKey key) instead of modifying the indexer? Otherwise, the IndexedDictionary is useless for `int` and confusing for the user. 2) Use `ElementAt` instead of `Skip(n).First()`. 3) You can achieve the exact same functionality by doing `Dictionary.ElementAt(n).Key`. I don't see why this indexed dictionary is so much more convenient. 4) Lastly, and most importantly, the indices of the Key are not guaranteed to be the same everytime. In fact, the order will completely change when a resizing happens. If you are using this in your code, you should really change it. If order matters, then use an [ordered dictionary](http://msdn.microsoft.com/en-us/library/system.collections.specialized.ordereddictionary).
Not bad, but keys should be sortable, thus `IComparable&lt;TK&gt;` should be a generic constraint. As it is, it's broken since key sort order is undefined in the general. Also, I can think of a case where I want to store integers as keys but not as the index (e.g. if my objects have `Int32` identifiers). The included special case code is too brittle for a general purpose indexable dictionary.
Exactly.
&gt; Xamarin is based on Mono Unity also uses Mono. Unity lets you write scripts in C# (Mono), UnityScript (which is similar to JavaScript), and Boo (which is similar to Python.) It lets you publish to iOS, Android, and Windows desktop. They seem pretty similar as far as I can tell. I wish Unity had the native UI stuff that Xamarin has, though. It would be nice to be able to write small native apps in C#.
Not really. You would still need to buy the full version of visual studio and it ain't cheap. What Microsoft should do is buy them out, then make the Android and WinPhone platforms free, with support in the free VS. Charge twice the normal price if you want to bulid IOS apps to increase the chance that great apps will be Android/Winphone only.
It's available to you. What do you think a fair price would be?
40 would be reasonable for a personal non-commercial license. I only write code as a hobby (ex-professional-dev-turned-pentester), so shelling out $1000 for it is out of the question.
40 is insanely cheap for tooling for Visual Studio. ReSharper is 104 (for a personal license) as a comparison. I think Xamarin are right to charge a premium for Visual Studio support, after all VS is expensive on its own. If you're a hobby programmer then whats the issue with using Xamarin Studio?
&gt; 40 is insanely cheap for tooling for Visual Studio. ReSharper is 104 (for a personal license) as a comparison. That's not a fair comparison at all. ReSharper is a complete overhaul of the frontend with all sorts of professional-grade productivity features. It's targeted at people who do lots of development and want to speed up their work. Wanting Mono support doesn't make you a hardcore dev; you might just want to write some code that's portable and use a familiar environment. &gt; after all VS is expensive on its own VS Professional 2013 is completely free via Microsoft DreamSpark for students that have a valid Windows 8 or 8.1 license. You can also get VS Express for free, though currently it doesn't support addons. &gt; If you're a hobby programmer then whats the issue with using Xamarin Studio? Because VS is vastly superior?
Cool. Thanks for the info. Would you use Unity to build a 'regular' business-type CRUD app for mobile? Or is it mostly for games?
Perhaps going other way with [Keyed Collection](http://msdn.microsoft.com/en-us/library/ms132438.aspx) instead of indexed dictionary could work for your use case.
Unity is a feature-packed 3D game-engine, and as such, is not designed to be used as a GUI app platform. Building a simple GUI app in unity is not only time consuming, it's also more expensive, as far as I know.
Cryptocurrency (Bitcoin etc) is a fast evolving space right now. Lots if things you can do there if you ask on the forums.
I'd worry that if Microsoft bought them that apple or google would start causing trouble. Xamarin seem to be doing a good job sitting in the middle of three big companies.
That made it much clearer. I guess i was trying to understand this based on my pre-assumptions, while the syntax is not that different, the way I was looking at it was. Sorry for the late response, was at a family function. Thanks
Sorry for the late reply.. Thanks, that simplified state machine example was extremely helpful.. I guess I just had to look at things from a different angle, It's not obvious until you understand it.
I'm using ADO.NET Entity framework and ASP.NET Scaffolding
**It is useless w/o VS support!**
Create an ASP.NET MVC project that allows the user to select a location and the website displays the average 'temprtues'. EDIT: I want Cardiff in there too buddy!
I don't think so, but even if you're right, Unity is still the wrong tool for said job. No matter how easy UNITY development is, it won't change the ease of GUI app development. It's using a spoon as a hammer.
I do this day-in-day-out, although I'm only targeting Linux/MacOS with it, not iOS/Android which is what they want money for.
You aren't downloading the page, you are trying to run the regex on a string that contains just a url, so no matches.
Make chess solely using the console
Easier said than done. It's hard to find problems unless you have them yourself
Create an editor for a game save file. I made one for Diablo ii. It's fun.
The major difference is unity is its own game engine that u design around while xamarin is for writing any kind of applications from scratch not just games
very true
Got code 18, thanks.
Tried a few codes, price didn't go down in my cart but then I realized my available credits were going up. I thought the codes weren't working. Think I grabbed a few codes by accident then, oops! Got the book and will give it a listen.
looks like you grabbed them all
Someone else may have. I stopped after I realized what was happening. Probably shouldn't have posted about it.
Do you use it? Is it any good/better?
LOL "Ok so the code should be ball basketball equals new ball newline opening bracket newline..."
i have the same thought but the good thing with audible is if you don't like it you can return it with no questions asked.
This. The GPU implementations of GEMM are pretty spectacular now even on budget hardware. I do think that OP should investigate a little further as to why the exception is being thrown before completely altering his/her workflow. Without any source code or example problem it is hard to give a quick turnkey solution.
[The road you're going down is a dark and scary one.](http://youtu.be/-5wpm-gesOY) Reconsider building it yourself. There are a number of calendar tools out there that you could leverage to build this system. 
I have a question about Xamarin Studio. Can I have it installed on two different laptops or are there limitations.
Look at languages like Swift or other languages with non-nullable types. It's about initializing stuff with default values. It's not easy to implement this in .NET, though, due to the CLI.
Why would you use NoSQL for that?
Thanks for this OP, even though I didn't manage to get one. All codes are gone, only 1 person had enough courtesy to say anything.
To be honest, I thought you wanted to calculate the number of days between power losses...
Approaching the problem with a functional mindset: public static IEnumerable&lt;DateTime&gt; DateRangeInclusive(DateTime from, DateTime to) { for (var date = from.Date; date &lt;= to.Date; date = date.AddDays(1)) yield return date; } public static IEnumerable&lt;DateTime&gt; GetHolidays() { yield return new DateTime(2008, 8, 7); } public static void CalculateNumberOfWeekdays() { DateTime startDate = new DateTime(2008, 8, 6); DateTime endDate = new DateTime(2008, 8, 13); var holidays = new HashSet&lt;DateTime&gt;(GetHolidays()); Func&lt;DateTime, bool&gt; notBlackout = date =&gt; date.DayOfWeek != DayOfWeek.Saturday &amp;&amp; date.DayOfWeek != DayOfWeek.Sunday &amp;&amp; !holidays.Contains(date); var dayCount = DateRangeInclusive(startDate, endDate).Count(notBlackout); Console.WriteLine(dayCount); } 
I'm on my phone, but I'd say adding an event may be what you're looking for. myObject.AnEvent += myObject_AnEvent; Then just add the code in the event. After the: myObject.AnEvent += You should be able to double tap Tab, and VS automatically adds the necessary code for the event. Edit: Just after clicking save I realised you can just call the event you're calling whit the other element. myElement.AnEvent += theOld_Event; theOld_Event(object sender, EventArgs e) { ... }
This is a personal aproach, so critics are accepted!, x-posted from programming and dotnet thanks to a comment.
I'd recommend avoiding a static dependency injection system. It results in the temptation to resolve interfaces at runtime, which can result in odd or inconsistent results deep within a call stack. Once you're in this position, it's very difficult to fix, because you have to refactor every point in the call stack, which can be even more difficult because of the presence of properties in C#. The best option is to instantiate the kernel like Ninject. If you need to create things at runtime, use the factory extensions, which allows runtime resolution without directly accessing the kernel (but still enforces dependency injection in all appropriate classes).
Appreciate it \^^
You've hit the nail on the head in terms of why Xamarin is worth $1000. Its the fact that you don't have to write the App 3 different times, with different tools and different languages. Any developer worth his / her salt should be able to earn the license fee back within half a week at the most. I paid for my Xamarin.iOS business license with a days work for a tradeshow. 
Its really not useless. I don't understand why some developers can't write code without VS 
Xamarin offers a 30 day refund. You can ask for a refund and then switch over to the monthly billing. 
Mainly because I want to learn how to write a MEAN application. I could also see the data being pretty nested and the schema completely changing if I were to add a second pos system. 
And here's what I've come up with. I'd say it's really dirty, but it works. If someone with more experience comes with a better answer, I'd say use their's! private void createLabels() { // Creating ten new labels. for (int i = 0; i &lt; 10; i++) { Label newLabel = new Label(); newLabel.Content = "label" + (i + 2).ToString(); // Here's what I was talking about previously, which you got working. newLabel.PreviewMouseDown += label1_PreviewMouseDown; // Add it to where you want to display it, mine is a StackPanel called stackPanel. stackPanel.Children.Add(newLabel); } And here's the actual event. private void label1_PreviewMouseDown(object sender, MouseButtonEventArgs e) { // Creating a temporary Label with the info from the clicked Label, // that being the sender, which we have to cast since it's just an object other wise. Label tempLabel = (Label)sender; // This was just for me to get some visual feedback, // you're free to do whatever you want to do. tempLabel.FontSize += 2; // Lastly I'm setting the sender (the clicked Label, in this case) // as the tempLabel we just altered. sender = tempLabel; }
I was thinking drunk blackouts
Wow. This is old and covered in every simple basics book about C#. 
That shit is really nasty! And a completely wrong approach. The label class has a `Target` property that should point to the textbox. 
I got it kind of working as it only creates one label but it does the function. The only other problem I have is how I'm going to save these labels in their position and how I'm actually going to GET them in the position.
Nice teaching article. Thanks for this. I am going to share it with some newbies. 
Coalescing is nice, but there's also GetValueOrDefault(T) if you want to chain things together.
Great, thanks! Now I can install it on my work laptop and my personal laptop. I'm going to sign up. 
Xamarin Studio on Mac is a really great tool (I've not used it on Windows). I honestly don't miss VS at all. I wish it was about 10 years ago when I first switched to OS X
The video perfectly describes every developer's mind when they start dealing with dates, times, and time zones
On this same note - if you right click a project in VS 2013 (not sure what versions support this) and click on Analyze -&gt; Code Metrics. You can get a few useful metrics. The one I find the most useful is Cyclomatic Complexity which tells you how many logical branches you have in a given method. The fewer the better. I'm not a huge fan of these metrics for whole program analysis but on an individual method level it can be pretty useful. The above solve method has a Cyclomatic Complexity of 31 which fits the intuition that it's overly complex and should be broken up.
This is a great idea for big projects (or ones that have the potential to become big). However, I wouldn't consider it effective to use it for small projects, as it may make the code more complex than it needs to be, with no actual added benefit. I would recommend the Unity library for doing dependency injection (I'm on mobile so excuse me for n or providing a proper link).
Here is a link to the unity library: https://unity.codeplex.com/ and to Ninject, the one that inspired the post http://www.ninject.org/
Fun fact about nullable value types - ever wonder how it's nullable and still a value type? .NET has a special struct behind the scenes that has a Value field and a HasValue boolean.
keep in mind that if you want to develop for iOS with VS from Windows, you are still gonna have to have a mac on your network. This takes two activations, 1 for the windows machine, and another one for the mac. This is even if you are running Windows virtually on a mac.
Forgive me for piggybacking your comment, but this one by Mads Torgersen is also great. (I happened to attend this one and it was great!) http://channel9.msdn.com/Events/Build/2012/3-011
I'm thinking about getting a macbook pro for xamarin development (android, iOS), is running visual studio virtually worth it or should I just stick with xamarin studio?
Integration into Team Foundation Server. I've got to be honest, our company just moved to use work items in TFS for tracking bugs as well as the software changes to fix those bugs. Now that we can do that and attach changesets to those items, I don't know why'd we switch to a third party application.
I can tolerate YouTrace - it's tolerable, and text and tag based. JIRA is horrible (oh my god the forms, and the configuration, and that terrible UI), TFS is horrible (if improving). Positive features? Web based, keyboard control, *very* simple, low on data entry and categorisation. API for dashboarding. GitHub (or equiv.) integration with hooks - the ability to close issues with commits. The best bug tracking stays out of the way.
IIRC jagged arrays actually require more memory to manage. I will look into it. &gt; I don't specifically do mat mult Other array manipulations (addition, reshaping, etc) run at a reasonable speed. The true bottleneck for me is multiplication as it is one of the most intensive operations I am completing.
I have added a small section describing the GetValueOrDefault() method.
Its for a discount system. For example stay 5 days get 1 day free. However there are blackout days that do not count for that duration. So if I stay 5 days, but one day is in a blackout day, I do not qualify.
I know. Luckily this is all calculated and used in one time zone. I'm building this in to an SDK for another application so I cant really leverage another system.
Tfs feels heavy and only works in windows. I like redmine with git integration. Visual studio 2013 has good support for git
nice. dl link http://www.visualstudio.com/en-us/downloads/download-visual-studio-vs#d-visual-studio-2013-update
Yeah, and my appartment is actually gonna cost a lot more than the full price when im done with the downpayments... Should have just bought it cash. 
&gt; IIRC jagged arrays actually require more memory to manage. I will look into it. More *total* memory or more *contiguous* memory? I've found it much easier to get bit by the latter than the former. I'll be curious to hear what you come up with. Must be some obvious bottleneck that would show up in a profiler, once you get the memory thing sorted. Could be interesting to do the same thing in a C++ project too. That's a benchmark I've wanted to do with my stuff for a while.
You can use TFS with Eclipse on other operating systems: http://www.microsoft.com/en-us/download/details.aspx?id=40785
Yeah I tried tfs everywhere last year on osx and found it not very intuitive... Maybe I wasn't using it right... But I still think git and redmine is pretty awesome. Much more lightweight than tfs
I have a similar setup: Windows 8.1 Pro,Visual Studio Ultimate 2013 CTP2,Resharper 8.2 Resharper works fine on my configuration. It could be due to version differences; eg if you are using a later or earlier CTP (or 2013 RTM) with a Resharper 8.1. It could also be a result of other Visual Studio versions you might have installed (I only have VS 2013, myself).
I actually dont even need to check for weekends. Only blackout days. But I will need to build a list of blackout days.
&gt; Menu Bar: All Caps Option I know people who will BE VERY HAPPY that this has been added
Gak, I didn't know that. So winforms is totally out in terms of learning C#
WPF is dead too so there's no decent .NET desktop API.
Of course XAML is the way to go. I'm not recommending WinForms. But, as far as I can see, WPF is in the same state WinForms is: legacy tool that's going to receive some bug fixes.
And the damn install decided to reset my Program Files location back to the C drive. Really wish the Visual Studio would realize that not every person wants their installation on their C:\ drive. 
It's been a registry key forever just added ui to change it
TFS is completely web based now and supports git as well.
Make a symlink on C:\ somewhere that points to a folder on your other drive.
This resource needs a lot of work. Not very well laid out for one thing.
Awesome. Don't you love it when software doesn't give a crap about what you want?
You're using Entity Framework, look up navigation properties and eager loading / lazy loading. Eager loading means you load the connected data immediately (1 query): ViewBag.bullshitTitles = nsc.NewsStories.Include(x =&gt; x.newsStoryTags).ToArray&lt;Models.NewsStory&gt;(); Lazy loading means the connected data is retrieved once the navigation property is accessed (1+n queries). For this your navigation property `newsStoryTags` must be virtual. It would be good to read some basic tutorials about the frameworks you use. 
Eh I'm pretty used to it now. 
I just love how a symbolic link is supposed to be transparent to the application using it. Yet Microsoft goes out of its way to fuck up this behavior with their products.
There's an entire WPF team working on it. Did you not see Build 2014?
This is my biggest peeve with VS, too many really useful tools are only in Ultimate, which is something like 13 grand per developer. I'm sorry, 'Ultimate' should go the same was as Vista Ultimate and the features send down the chain.
Why not just set the field as the initial value?
That's brilliant. I simply didn't want to start out with horrid habits, and make things more complicated as the project grows .. :) 
I am by no means an expert and have only recently starting delving into MVC. I can tell you my first project I kept methods in the class where it was called i.e. the controller. After reading up on it and later going in to make changes it just felt really sloppy to me. My controller was insanely big and convoluted. I ended up creating a helper class to hold methods for each model this made readability so much better. Also created a great place to store the common methods that will be used on multiple models and controllers.
This is how ruby on rails, another MVC style web framework, does things. Any methods not directly view or controller go into a helper class named after the model. In this insurance it would be a class called ADUsersHelper. These same methods can also be used in the view.
So is this the last big update before the next version?
Never used RoR but good to know. That is pretty much the way I do it in MVC now I usually create a helper folder and create a separate file for each model I would have probably named it same as you ADUsersHelper. Still cringe when I think of my first MVC project my controller was so bloated it was insane. 
I don't work for M$ so can't state anything for a fact but my guess would be no. I appears that they are trying harder to push things as they become available these days so I could imagine a few more updates coming out before VS14 goes final. 
You can solve that problem with `IndexOf` alone, do you have a better example?
Needed using System.Data.Entity; Now it works! Thanks again. There a quick and easy explanation as to why this is better/safer? Additionally I removed the abstract from the NewsStoryTags in the dbcontext in attempts to make things work. Will that negatively affect anything? public DbSet&lt;NewsStoryTag&gt; NewsStoryTags { get; set; }
Imagine you refactor your database, perhaps rename a table. Now... The string will be used on, but it is incorrect now - it has the old name. You will still get an exception during runtime, once you try to access this... But that is very late. With good integration tests this error will already appear during testing, but that is also still late. The option I mentioned uses a lambda - if the context is updated and the property does not exist anymore, your code won't even compile anymore until you fixed this. I think you meant virtual instead if abstract. Removing the virtual keyword will disable lazy loading of your navigation property. 
I think it's time you started learning the Repository and Service patterns. Your views and controllers should be lean, all of your real logic should be placed into service classes that are injected into your controllers. Like this: public class ADService { public List&lt;ADUser&gt; GetADUsers() { return; } } Inject this service into your controller, and then you would: return View(_adService.GetADUsers());
wow, I really missed that... thx, works perfectly now :)
Ahah, I see. See, *that's* a better use case! :D
This site looks like it's from the 90's.
Thanks for the excellent explanation! I'll be sure to use lambda for future development. Did mean virtual. Don't want lazy loading. :)
I haven't used it personally, but people really seem to like this: https://github.com/markrendle/Simple.Data Also, if you're not tied to sqlite, embedded RavenDB might work too. http://ravendb.net/learn
Dapper for relational stuff. https://code.google.com/p/dapper-dot-net/
Think of the model as a layer, not just as a data class. Keep the business logic out of the controller. Either put it in the model or some kind of associated class.
i've found code first entity framework to be straightforward. see [this example](http://code.msdn.microsoft.com/Demo-of-ADONET-POCO-with-140ad3ad) on how to get EF to play well with SQLITE, i think it just converts MS SQL to SQLITE. if you meant something else by 'doesn't play well' i won't be able to help. this step was key from the steps &gt; Download (http://files.cnblogs.com/timiil/SSDLToSQLite3.zip) and add the SSDLToSQLite3.tt t4 converter to %localappdata%\Microsoft\VCSExpress\10.0\Extensions\Microsoft\Entity Framework Tools\DBGen (you may need to create large part of this path). 
Seriously. And now they're pushing out yearly releases. Who's going to shell out $13k/yr for an IDE? Holy crap.
Yes. Using ReSharper with 2013.
being a student I got SQL Server 2014 for free, but have you considered SQL Express? http://www.microsoft.com/web/platform/database/free-database.aspx
[LINQ to SQL](http://msdn.microsoft.com/en-us/library/bb399408.aspx)? 
thanks :-)
That sort of misses the question, since I'm not looking for a "regular" SQL database - possibly except SQLite. If I were, I'd either go MySQL or Postgres.
Yup. Trending on /r/Programming right now: http://wozniak.ca/what-orms-have-taught-me-just-learn-sql 
Learning SQL is the most important thing! Don't get into an ORM until you understand SQL (though I love ORMs!). You can also use SQLite/ORM with [SQLite.Net](https://github.com/praeclarum/sqlite-net).
I did the same move, Java to c#. I think something on linq might be useful. Understand linq deeply includes a lot. Extension methods, enumerators etc. I read "c# in depth". C# original tried to be more static than Java. It has since evolved more.
There are quite a few good authors out there for .NET. I highly recommend Jon Skeet's C# In Depth books as they're wonderful and he's a very smart guy. He's a Java developer that works at Google (last I remember), but he's very deep in .NET as well; very intelligent and definitely knows what he's talking about MSDN is a good place to use as a reference source. StackOverflow is a great place for Q&amp;A (if you're a Java person, chances are you've been there before). I'll poke around my resources and see if I can't find something good.
Yes. It goes against their own UI guidelines, and their research team determined that ALL CAPS is much slower to read than Title Case http://www.microsoft.com/typography/ctfonts/WordRecognition.aspx The idea behind moving to upper case is stupid too. They designed the menu after [office 2013](http://www.brucebnews.com/wp-content/uploads/2013/02/office2013ribbon.jpg) which kind of works because of the ribbons. But because of the push to "unify their products" some manager must have pushed the UPPERCASE MENU SYSTEM DOWN ON VISUAL STUDIO, WHICH DOES NOT HAVE RIBBONS. So they made a PR post explaining the reasoning, which I think is just rationalizing the change to those who never asked for it in the first place. Everyone had a good laugh when a registry hack was discovered that simply disabled the uppercase mode, meaning that some engineer somewhere didn't like it, and disabled it lol.
You need ReSharper 8. It was available since VS 2013 Beta
I'm sure there's going to be another. Mads' last talk indicated a late 2014-early 2015 release. There will be a 2013.4 though, regardless.
2013 will install alongside 2012. They only recommend not installing side-by-side for pre-releases.
~~The biggest feature isn't even in this update: ASP.net vNext is useable in VS 2013!~~ Just checked with Mads. You'll have to do it via command line or VS 2014. :/
In this example sure, but in some cases there might be costs to initializing an object. This is basically the poor man's Lazy&lt;T&gt; pattern.
Ah OK, cool
I see. Didn't quite catch that first time through.
So to recap: Basically, we take what used to be concise, easy to ready code and took a GIANT SHIT all over it. And achieved basically nothing, except that now it will take about four times longer to fix any bugs we might have. Nice!
I'm going to go with this as a sensible option. XmlSerializer class can make the code really simple too. Although he didn't say whether he was working with dozens, 100's, or 1000's of objects.
Another vote for Dapper. You don't get the object-tree handling that EF gives you, but then, you don't get the pain that EF's object-tree handling gives you, either. 
Where do you see it say ASP.net vNext is useable in VS 2013 everywhere I look says its not compatible with VS 2013.
It has been at least a year since I have been solving this problem, but at the time, I solved it with http://ravendb.net/ and it worked very nicely. Of course SQL is much much better, because everyone says so.
That's what I was hoping to avoid in the first place. :)
I'm going to assume you'll be using Windows, hopefully 7 or 8. The only thing you really need to get going is Microsoft's official IDE, Visual Studio. The [Express](http://www.visualstudio.com/en-us/products/visual-studio-express-vs.aspx) edition is totally free, but you do have to register it for free after 30 days. You can write apps in C#, Visual Basic, and C++ in Express, and probably a few other languages that I'm forgetting. The installation should also give you everything you need to run .Net software as well. VS gives you everything you need - the IDE, debugger, and compiler - all in one package. You just need to write the code. If Windows isn't your OS of choice, [MonoDevelop](http://monodevelop.com/) is the best choice for most UNIX-likes, and OS X, too, I think. You won't be using the official .Net Framework, but rather Mono, an open source implementation of the framework that can run on other platforms. If GUI-based IDEs aren't your thing, take a look at [MCS](http://www.mono-project.com/CSharp_Compiler), Mono's official C# compiler on UNIX-likes and Macs, or [csc.exe](http://msdn.microsoft.com/en-us/library/78f4aasd.aspx), the official Microsoft compiler that is installed with every .Net Framework installation. CSC and MCS are the full compilers that VS and MonoDevelop use, so everything you can do in VS, you can do with Vim/Emacs+MSC, or your favorite Windows text editor + CSC. As for the language, C# and Java share a lot of similarity, but also have a lot of key differences. [Here's a good Wikipedia article on the differences](http://en.wikipedia.org/wiki/Comparison_of_C#_and_Java). Notably, you have access to unsigned (positive only) integers in C#, you can create value types (structures), and other differences.
I could, but the idea was to have something more database-like without having to code the layer between objects and a traditional RDBMS myself.
I understand SQL quite well. It's just that I don't particularly enjoy writing it, so for this project, I thought I'd try something else.
I've heard in one Microsoft video of late, that their alternative to WPF (HTML/JS) is mostly being ignored by developers, so they are sticking to WPF for the foreseeable future. Who knows, that might change though.
MVC / Web API isn't for desktop apps. 
EF with SQL CE, LocalDB, SQL Express [compare](http://blogs.msdn.com/b/jerrynixon/archive/2012/02/26/sql-express-v-localdb-v-sql-compact-edition.aspx) or one of the many tailored MS SQL DB offerings which fits your requirements. I really don't see how it could possibly get any easier than visually designing your entities and their properties if you really need a database... You might also consider XML or JSON serialization for simple object persistence (even easier - just mark up your existing objects with properties).
sorry, I thought you were talking about desktop API and how WPF was dead.
&gt; whether it is possible to write a program which will take an arbitrary regexp and contruct another which will act as it's negation against all possible input strings? This is solvable with regexp. Most (all?) modern regex parsers go well beyond regular expressions, such as back/forward referencing, recursion and BNF-like capabilities. [Examples here](http://stackoverflow.com/questions/4840988/the-recognizing-power-of-modern-regexes) and [here](http://www.regular-expressions.info/refrecurse.html)
Ok, I posted this challenge to another reddit commenter, but I'll post it to you as well. Produce a single statement regex that accomplishes the following. Matches all strings that contain "product" but not "service". Note: this is not starts with xyz, xyz can appear anywhere in the string. 
I've never understood this attitude. SQL is easy and writing a reflection method can handle all of the conversion of the result set generically.
 ^(?=.*?product)((?!service).)*$ [more here](http://www.regular-expressions.info/completelines.html)
Yep, that is correct. Step 2: In a single statment bla bla the following: Starts with "http" and contains either "product" and doesn't contain "service" or contains "google" and doesn't contain "filter" and ends with "jsp" When you start mixing logical operations regexes start to get incredibly complicated, if it is possible at all. Even if you can successfully write the regex, what is produced is very hard to maintain and could be accomplished more clearly if the logic is spelled out. FYI, the above in microscope would be: &gt; startswith("http") and (contains("product") and not contains("service")) or (contains("google") and not contains("filter") and endswith("jsp"))
I think WPF is dead, or at least at the same state WinForms is. I used WebForms as an example of how we get more information about the future of a web technology that is "legacy" (WebForms) than about the future of the current .NET desktop API (WPF). All we get is "don't worry bro some developers are still working on it".
If you've got lots of relationships, I think you'll get mixed results with an ORM. Like others have said, the time it'll take you to learn some SQL will serve you well for a long time.
Do you need the fields to be searchable, or simply want to save the data against an id? Saving the objects as serialized Json (see Newtonsoft.Json for the best serialiser) into a text properties field, then having an abstract, generic, base class to restore has help me many times. Something like: public abstract class JsonType&lt;T&gt; where T : JsonType&lt;T&gt; { public string Serialise() { OnSerialise(); return JsonConvert.SerializeObject(this); } public static T From(string serialised) { T t = JsonConvert.DeserializeObject&lt;T&gt;(serialised); t.OnDeserialise(); return t; } protected virtual void OnSerialise() { } protected virtual void OnDeserialise() { } } Then have your objects inherit this, and you can do /*INSERT*/MyData.Serilaise(); MyData fetched = MyData.From(fetchedSqlData);
This would give the warning: [Assignment in conditional expression is always constant; did you mean to use == instead of = ?](http://msdn.microsoft.com/en-us/library/c1sde1ax). You should definitely take a look at all your warnings and preferably set the option to treat all warnings as errors.
Petapoco is another great micro ORM. I've used it in a lot of projects.
Look at RavenDB. You *really need to read the directions*, but once you understand how to work with it, it's very easy to work with, and you can have a project up and running really fast. I've worked with EF, it has serious limitations that are making me really consider pulling it out of everything at my employer and replacing it with something else. I've worked with nhibernate, usually it works really well but when things go bad they go REALLY bad. RavenDB was a dream to work with.
Dapper is awesome. You still need to write SQL, but avoid all the lame mapping code. In the end hand written SQL will give you way better performance and control without having to fight an ORM. The performance hit you get by using dapper (or petapoco) is almost nonexistent.
Okay I want to tell you something that a lot of people wont tell you. If you aren't going to build a full fledged relational database, sometimes the best approach is to simply keep everything in RAM and serialize the objects to a big file. This will work even until your 'database' is a few gigs in size (given that the PC has that much ram). Don't overdesign. If you are going for a simple approach, use a simple approach!! If your project really requires a database, eventually you will bite the bullet and go for some RDBMS. For now, focus on functionality, rather than clever programming.
I'm actually a C# newbie, so I don't know the best way to serialize objects, but I'm sure you can easily find a solution. Every other programming language I've used has some straightforward marshalling functions
You had mentioned SQLite above, maybe give SQLite.net a try?
C:\Program Files\Microsoft SDKs\Windows\v6.0A\Bootstrapper\Packages\CrystalReports10_5 this is for vs2008,
thank you for your reply! But I have no idea what I should do with that path? 
This is a very simple example, so yes, it might be a little bit of overengineering, but the goal is to show how to use dependency injection. Later on the data manager could be mocked so it doesn't write on disk and you perform the checks inside an unit test. Anyway, thanks for the comment!
I thought you need to install the Crystal Reports Viewer locally. Long time ago for me i'm sorry :P http://www.businessobjects.com/forms/crystalreports/viewer/
Add it to your installer as a dependency 
Thank you. I've taken that advice and created a class, it makes things much easier to follow around as well. It's falling into place, ever so slowly :)
I'd have the list serialized to a Json file on close or whenever you want it to be saved, and in the initialization of the program simply check if there there is a deserializable file in the location you saved it in. If there is none, don't try to load it. Newtonsoft is great for this. Good luck!
So, I have an extension to the question if I may ... I have done the following in accordance with your suggestion : I created a class called ADUsersHelper. public static List&lt;ADUsers&gt; GetADUsers() { List&lt;ADUsers&gt; ActiveDirectoryUsers = new List&lt;ADUsers&gt;(); // populate the list return ActiveDirectoryUsers } Through my controller, ADController, It's now extremely lean :) public ActionResult Index() { return View(ADUsersHelper.GetADUsers()); } And that is then in the view ... @model IEnumerable&lt;SimplyMigrate.Models.ADUsers&gt; //HTML @foreach (var items in Model) { @items.emailAddress //for example. } Which is great, and works. What I would like to do, is have the Index View have an HTML table populated with the AD User detail once a button is clicked on the page. The issue I have isn't with the HTML table, it's that I cannot get my head around how to manage the button and the form in the View. What I am trying at the moment is is within my controller : public class ADController : Controller { public ActionResult Index() { return View(); } public List&lt;ADUsers&gt; GetADUserDetails() { return ADUsersHelper.GetADUsers(); } } and in my View : @using (Html.BeginForm("GetADUserDetails", "ad", FormMethod.Get)) // HTML for the form ... @foreach (var items in Model) { &lt;tr&gt; &lt;td&gt;@items.Email&lt;/td&gt; &lt;/tr&gt; } My @foreach loop is causing an error of : Object reference not set to an instance of an object This seems to be because Model in this instance is null. But I cannot quite understand why. I have a feeling the reason for this is the way I am using the method in the controller, but I cannot get my head around where this is falling over. I appreciate this is cheeky to ask, and I greatly appreciate anything you can tell me to get me headed in the right direction. 
I personally have great experience with FluentNHibernate, i wrote a small layer so that i can store any object i want with great ease. In the following snippet i show you how i get, modify and update an object to the database, and in case it didn't exist, we create it. Employee emp = Employees.Get("John").SingleOrDefault(); if (emp != null) { emp.LastName = "Doe"; emp.Update(); } else { emp = new Employee("John", "Doe", "etc"); emp.Save(); } Simply because Employee inherits IDatabaseRecord, and Fluent will map it for me(which i can override if needed). 
I just used SQLite together with EF6 for a word combination generator. It seemed to work fine to me, except for migrations, which I could live without. What is your problem with it?
very interesting. just to be clear these wouldn't be strictly date values, but would take the string.format options to parse the value (either, date, int, float etc.)
Sorry Charlie Winforms are not irrelevant. A lot of companies still use them and they use them because it works and its what they know. Rewrites suck because they take time and money and are just really a pain in the neck anyway. Just because you have a hot new technology it still needs to get adopted and it's not going to be adopted very quickly to people who use a proven technology. If it's not broken don't fix it!
I really wish Microsoft would either buy these guys or develop C# so that it would run on everything and you can write it in Visual Studio. It's really a pain in the neck to have to learn Java for android and C# or VB for desktops and have to merge the two. If your a hobbyist 25$ a month to play around with something is still too expensive. It would really drive developers to whatever platform if they could write code for any platform. Plus, Microsoft is gearing towards building one solution that runs on all devices. Microsoft is just missing a ton of money. The Crysis engine subscription is 9.90 a month, Unreal 4 Engine is 19 a month plus 5% profit.. 25$ seems high anyway just so I can write code for all devices. 
Can I ask why you want to reference things from the GAC at all?
I'm having issues finding it. I saw Mads do a demo, but I am confirming with him now. I could be wrong about vs2013 :/
I'd do it on my own. Just convert the image to b&amp;w, and then start looking for your patterns (analyze neighbouring pixels, etc). Your 2 shapes should be easy to differentiate. Not sure if it's overkill or not, but I think the time it takes to find a good library and then adapt it to your needs might take longer than doing this on your own (in this case).
Exactly. You can never make sure something's in there and which version it is, etc.
nice work, thank you!
I think you might be underestimating what's trivial for a human and what's trivial for a computer. Your problem falls into the category of Computer Vision and Machine Learning which is by no means a "primitive need"! Note: It's the "undefined" part that launches you into realm of challenging. If you could guarentee that the image was either X or O, then you have a binary classifier in a closed domain which would be pretty simple. From your description though, you are looking for a 3-class classification of handwriting in an infinite domain. The easiest way to start would be to segment the image based on connectedness (or however you are going to isolate an X, O, and "other"). From there, you could scale the object to a uniform size and take the difference from a reference template (subtract the intensity values between the source image and the image under test). In general, a handwritten X and a template X should produce a better match than a handwritten O and a template X. This is what I would consider a "brute force" approach. You could then classify based on a threshold. If neither the X or O difference meets that threshold, it's "other". It's by no means robust or efficient, but it's a starting point to understand the domain. Notably, tuning it to detect O versus Q is difficult! For a robust and general solution, I would explore common approaches to OCR in topics such as: * Neural Networks (Some of the latest and greatest advances in OCR are through deep neural networks) * Markov Models (The traditional approach to OCR) * LBP (Local Binary Patterns) * Haar Cascade (a simple way to detect objects in images robust against scale and translation) In addition, there are a number of other approaches that can detect circles and lines in images. The results of these could then be analyzed to classify them as X or O or other.
Isn't there Blend Express too?
Yeah that sucks! It took forever to get my company to upgrade from VS 2008/10 to VS 2013 and now it looks like all the good stuff is coming in VS 2014(Roslyn, ASP.net vNext, etc). Now I have to convince my company to upgrade again.
Sure. Usually this is references to assemblies of third party product installed in the GAC. My installer checks that this product is installed and i can be sure that this assemblies will be in the GAC. Actually this is the only case as I can guess :) But it's very often in my work.
Thank you for the feedback. I have included the link in the post.
You are absolutely right. This is why I have added warning at the end of the GAC Reference description.
Thank you for the feedback. I have included the ElementAt instead of Skip(n).First. I have been using this in production code for about a year and I have not hit any snags yet. I'll replace it with an ordered dictionary in the next round of updates. 
You can download Blend for Visual Studio 2013 with Visual Studio Express for Windows, Visual Studio Express for Windows Phone, and Visual Studio Professional 2013 and higher. http://www.microsoft.com/expression/eng/ 
I guarantee that you haven't included all the DLLs required by the project. Just google how to include them, there's an option somewhere. 
Oh god crystal reports. My work place use a legacy product of crystal reports from 2002... However for some of our internal projects we have to include msm modules into the setup. And I also believe there are redistributable packages on the SAP support pages. On holiday so can't help out to much!
Ankh SVN: https://ankhsvn.open.collab.net/ awesome VS plug-in for svn
Git + [SourceTree](http://www.sourcetreeapp.com/)
I've used both git and TFS, git GUI and git shell.. I prefer git shell because i type fast and I can get it done quicker than moving my mouse around to click things. TFS is nice, especially in VS2013. It has native integration with an agile project management interface where you can access via web or thru VS2013. I'd use git for open source, TFS for small team/private project
I'm using GIT repos hosted on visualstudio.com TFS. I switch between using the Github for Windows client and the VS Git Tools depending on whether I'm working on code or other files I have under version control. I use TFS Source Control professionally. It works well enough in a team environment. A few of us want to switch to GIT, but as TFS is good enough we're having a hard time justifying it.
My company is moving to TFS from Serena Version Manager. I feel like I'm the only one not freaking out about it. Looking forward to using TFS, though. EDIT: derp, so why? Management feels that TFS will integrate well with VS and offer the reporting, version branching, and reporting technologies they want.
I used the Visual Studio Tools for Git plugin for some time and the integration was nice, but I found the interface lacklustre. I use Sourcetree as an excellent GUI replacement for `git add -p`, `git log`/`gitk`, but default to command line Git for Windows for most operations.
Bog standard Git for Windows. Git Bash for the vast majority of operations, Git Gui for reviewing and committing larger commits (particularly if I want to stage hunks,) gitk for viewing history. I'm a big fan of zero IDE integration, though I didn't particularly mind the way Visual SVN did it back in my SVN days. (As an aside, GitHub for Windows has to be the canonical example of Metro Done Wrong.) On the OSX side, terminal for most general operations, GitX for viewing history, etc. (As another aside: On both platforms, SourceTree when I feel like fighting with UI inconsistencies, random pane resizing, etc.) (In case it helps, my background includes VSS back in the dark ages, SVN, TFS, Perforce, and, of course, Git. Git being my favorite, followed by SVN. The others can feel free to die in a fire, after the pain they've caused.)
TFS at my last job. VisualSVN with Tortoise at my current job, Git at home.
Both. They each suck, but for different reasons.
&gt; I was disappointed too that there didn't seem to be a TFS client separate to Visual Studio. TFS PowerTools. They let you do checkins, gets, etc. from Windows Explorer.
I've been doing a side-by-side since RTM with no problems. 
Oh wow, they used to charge. Good for them on opening up a bit, as I loved their product. 
No it's not normal. Yes you're wasting time. Why? Console applications and forms based applications are completely different, a windows form app is event driven, while a console application is sequential. So every time you do what you're doing you have to take a sequential process and think about how to make it event driven.
I'm using git with bitbucket hosting. As for the terminal / GUI it depends. Most often I have ConEmu opened for majority of things. When it comes to comparing differences between commits I use [Git extensions](http://bezensek.com/blog/2014/03/06/using-git-with-visual-studio/). And sometimes I even use SourceTree.
Huh? What's this *or* stuff? TFS is for ALM, and the underlying source control choice is up to you, right. TFVC or Git. Git in TFS. Shout out to [RadioTFS](http://www.radiotfs.com/).
TFS
TFS == TFVC in this case.
I do it sometimes to test out something different. Like, if want to try and figure out how someone else's web service works. Most "green field" type projects I do end up with some code for something in a scratchpad Console app, but I usually progress beyond that point VERY quickly. 
Yes, so long as you aren't developing something that is primarily a GUI/event driven application. I have many GUI applications that are just front ends to larger compute-intensive processes. In this case, why go through the overhead of a GUI when you're still working on the core logic? In some cases, depending on the project, I will develop a library with the logic, a console app with several test cases (like ghetto unit testing), and a GUI app to deliver to the client.
I agree, but only up to a point: if the goal is just to test a bit of code (a set of switch statements, or whatever), a small Console app is perfectly fine. I have a console project called "Test" that I use for this very thing, although I find myself not using it very often.
Mercurial, actually. It connects to git repositories, and has the best GUI in TortoiseHg.
I still don't see the point of doing this, if you want to test a small bit of code why not add a button to your form and put the code you want to test inside of the click handler?
Same. I use command line Git for the majority, Gitk to review history and simple changes, with KDiff3 as my difftool for reviewing bigger changes. I just never felt in control with the implementations of IDE integration I've tried and ended up checking and double checking the source control. I bit the bullet and spent a bit of time to learn the command line side of Git and I'm much happier with it. The bare basics that you need are pretty easy to pick up then learn more about the more advanced stuff as you need it. Once you start getting a real handle on it you gain a lot more flexibility I think. This is the article I used to get me started http://nvie.com/posts/a-successful-git-branching-model/
Just moved from being the TFS guru to a team using git. GIT is such a better source control system, but TFS's project tracking and customization has really gotten sophisticated in the TFS 2013. You get a lot better metrics and reporting from TFS out of the box, but git is definitely the way to go with larger teams. 
I tend to use it as a scratchpad of sorts, usually a simple 1 file console project where I'll just create a new method to play around with something simple. I do it that way as you can leave it there if you need to refer back to it without it cluttering up your main code, then delete it later when you're done. I don't do any cutting and pasting with it though. If I'm writing something I'm planning on using I'll do it in place. I just use it for figuring out syntax I'm not sure of or doing a quick check of some library functionality.
I think it's just what you get used to. I used WinMerge for a long time and similarly it never really changed much. The reason I initially switched to KDiff was it's directory diffing. I much preferred the way it did it over WinMerge and it worked very well for working with a bunch of code that wasn't yet under any source control. The 3 way diff comes in very handy some times too. KDiff isn't perfect by a long shot though and there are some things I'm still not keen on. I haven't tried Araxis as yet.
You should check out [linqpad](http://www.linqpad.net/). Totally changed my (development) life. Despite what it says on the tin, linqpad can do C#, F#, and VB.net without needing to touch LINQ.
Work: TFS Home: Was using Mercurial on an older Mac Mini with TortoiseHg and VisualHg for clients, but recently switched to hosted TFS at VisualStudio.com (free for 5 users). 
This is making the assumption that all GUI development is event driven and all console development is not. It's simply not true that "every time" you have to go out of your way to convert code to event driven when you use a GUI. GUIs add overhead both in resource usage and the auto-written back-end code that is overkill when testing ideas or learning new things. One beauty of C# (among many other languages) is that it is not one-size-fits-all. There are many ways to accomplish the same thing. Do what fits your style the best.
Sorry for making an overly broad generalization. I think it's safe to say that the vast majority of GUI applications are event driven, and the vast majority of console applications are sequential. It's kind of pointless to make a sequential windows forms application (precisely for the overhead issues you mentioned), and it's a bit of a pain in the ass to make a console application that behaves like an event driven one. I don't think the overhead of a GUI application is really a concern if the end goal is for your code to end up in a GUI application.
Svn or mercurial depending on team size.
Honestly... I think Git Extensions puts SourceTree to shame. I only use SourceTree on OSX because its probably the best free git ui there, but love using gitExtensions on windows
Visual Studio Online. Free for up to five users.
Sometimes it's just easier to do it this way. For example, let's say I'm at work, working with an ASP.Net MVC 4 project. I could hypothetically create a method in any number of classes and call that from the controller, but if I need specific data passed to it, then I need to be sure to make the call in the correct location. If something else in the project funks up because of this, I now have to spend time finding out what I forgot to add, or what it was expecting (which wasn't passed). Or, I could just create a console app, insert a few snippets, fill them out, run it, and have done with the bloody thing. Really though, I'm in agreement with you, as I'd rarely do this. But sometimes it's easier for me, in these rare cases, to separate the test bit from the project entirely. You have a point, though - which is why (again) i say that it's rare that I do this.
It would be better to write actual tests and tie your GUI methods into those.
Git + [posh-git](https://github.com/dahlbyk/posh-git)
We use TFS. The integration with TeamCity for continuous integration works well. We also use it for work item tracking (e.g., bugs, tasks, etc.) and source control.
Not sure I agree 100%. While this is a simple rule of thumb, and excessive abstraction can be confusing, it can also violate some OOP design principles like single responsibility, building for an interface instead of an implementation, and loosely coupled design. I guess it depends on how refined you want your approach. It will certainly work for a simple application, but if a controller connected to AD directly on a programming test for a job, it wouldn't look good.
Please excuse formatting issues, I've done the best I can with reddit's syntax.
What did you do to get it to connect to git? I didn't know this was a thing except thru kiln
TFS is project management tool first. Version things come as afterthought.
And, what do setPatientFirstName() etc etc do? That's where you need to set your stop point to examine what is happening. Are they just setter functions for private variables in your form code? Are you at any point calling {name of textbox}.Text = "value"; ? 
Sorry dude, wall of text, all I see is a MySQL query.
&gt;particularly if I want to stage hunks What's wrong with `git add -p`?
&gt;Why hasn't anyone mentioned Perforce? Probably on account of the fact that git exists.
&gt;Github for Windows, which is just a separate GUI for git. Worth pointing out that it's a separate **and awful** GUI for git. This not even mentioning the fact that you just shouldn't use a GUI for git.
Same here, this is a brilliant combination
 Same here, unfortunately. My last job used TFS, but personally I would like to use Git or Mercury.
Git and atlassian's stash. 
All mutator methods are functioning correctly, in that they are assigning values correctly, it is just that the strings in the variables it is assigning to the text boxes do not appear in the given textbox (whatever one that the mutator is assigning a variable to), and I am not sure why.
Are you calling textbox.Update() or textbox.Refresh() to redraw the box with a new value at any point?
No, I've never heard of those two methods before, till just now. Why would they work, and not the whole myTextBox.Text = "test"; thing? 
if you put a break point into the application can you step through where each text box is populated? is the text definitely getting put into the right variables?
My best guess (since missing code) is that your methods are not **static**. To solve it try to put a 'this.' infront of your textbox.text = value; This will point to the actual instance of your class. 
Git with SourceTree as my client. Sadly VS2013 doesn't handle git branches correctly, so I use a third-party client.
I've figured it out: It's to do with where my components are. Alright, so I have a blank form called "DataModule", and this is where all the behind-the-scenes database stuff occurs. I have my dataset, data adaptors and connection all setup on that form. Now, I used the following statement to test if (after I added a temporary TextBox to the DataModule form) data would appear. txtBoxTest.Text = reader["firstName"].ToString(); To my surprise, the record which I had selected (its first name), did appear. However, is there any way I can get this information to display the proper form using the statement above?
A number of deployment packages are available at: http://scn.sap.com/docs/DOC-7824
I'm kinda curious about this too..
We use Mercurial as well for the last 5 years. Less Visual Studio integration, but then we have a custom build system on top of Visual Studio anyway.
Useful when you depend on something that's installed in the GAC. If your product has an msi installer, you can merge the other (freely distributable) products installer merge files into yours, so everything gets correctly installed together, if needed.
Tick should be declared as an event instead of a field, to limit public access to += and -=. This is what events are for: to control public access. With the current code, anyone can assign null to the field. Also, if (Tick != null) Tick("HEARD IT"); isn't really thread-safe. Use var tick = Tick; if (tick != null) tick("HEARD IT");. Delegates are immutable, which is why this works (but the field isn't!).
Have you looked at the questions people pose in this sub, though?
In a perfect world, I would like to say that the communication wouldn't be masses of data, although would be frequent (for service health posting, status updates, etc). The vision is to keep the data transferred between the web application and the service to an absolute minimum I guess. I'll have a go through the article you sent and see how I get on :) Thank you for the response. 
100 services talking HTML to IIS is no different than serving up 100 browser requests. IIS won't even break a sweat doing that. 
There's the spirit of OOP design, and then there's actual work in the field. Sometimes they intersect, but not often. Most often it's, "get it done ASAP" with a phase of refinement afterwards.
Wouldn't SignalR work in parallel with WebApi? I haven't looked into SignalR much yet, but I thought it could be used with WebApi to make notifications from the server back to a client in a WebApi scenario.
You could definitely do that, like a hybrid communication channel. SignalR seems a bit better suited for small messages and notifications, so if you have larger messages, you could send those over Web API, and all the small notifications and such go over SignalR. But SignalR can also stand on its' own if none of the messages are large or have other requirements that would push you towards Web API.
Thank you.
SVN. ;_; At least there's http://www.visualsvn.com/
I love these additions. Both records (immutability) and pattern-matching can be very useful additions to C# I feel.
Yes but not Visual Studio Express for Desktop 2013 ... i.e. if you are developing WPF with the Express version of Visual Studio then you do not get Blend
Definitely. Also `record class` is a nice way to cut down boilerplate, since they seem to be effectively the same as [Scala's case classes](http://stackoverflow.com/a/2312936/1180426).
Git. I use git-tf to push/pull from tfs, but git locally. TFS is not (ever) my choice. Git allows a *lot* more control over your code, check-ins, etc. Git doesn't behave like a burning turd sack when I want to make copies of the codebase. It plays better with separate networks. All my eggs are not in one basket. Branching is easy and cheap in git, and saves a lot of frustration. And so on. 
OK. The issue has been fixed, but there is a small problem. To get the data to display in the form, just before the OleDbReader code, I had to call "this.Show()." Is there anyway that will allow me to refresh the form so that data can appear (and when the form is refreshed, will appear), rather than my having to do this?
Git. I use both SmartGit and the git command line, depending on which is faster for the task I'm doing. I use it because it's comfortable and is very widely supported.
Nothing at all. It's probably more about the way it changes how my brain looks at the code I am about to commit, not unlike how I tend towards the GUIs for doing larger pre-commit desk checks, whereas for most smaller changes I will stick to the console. Shifts my perspective a bit and helps make sure I do more than skim the code, I suppose.
My guess is that you are somehow initializing a new Form in your DataModule class, setting params for that and never showing it, rather than working with the original one. Are you trying to set the textbox of a form from another class, your DataModule? Did you pass a reference to the form to that module so it can properly change values? The code we'd need to help is where you actually have a string being added to the textbox, and any relevant code for the textbox and parent form. Step through your own code, make sure you're getting a result from the database and update with how you're setting the textbox and opening the form. Something isn't making sense. 
'buffer' (which is the first argument in the list) is fixed in the original background thread. But, 'buffer' is being overwritten as the original thread runs more. I would've thought that by passing the values to buffer_Alt, it would be in a different location and not an issue? I haven't locked anything down. The original variables need to be accessed by the original thread, and 'buffer' needs to be changed.
Game changer, to be sure.
The [hg-git](http://hg-git.github.io/) extension is really mature, and dead-simple to install with either pip or by simply cloning it somewhere.
May it be an unsafe access to the varIn[0] object? Arrays are reference types, hence the second line of the method might contain an error of referencing the original array  try explicitly and greedily copying it by appending, for instance, .Clone() after the cast.
I'll check it out!
Great discussion everyone, looks like I should try out linqpad.
Awesome, that seems to have worked! Thanks! I ended up having to clone it where I originally passed added the variable to my arguments: List&lt;object&gt; arg_ASyncDispFrames = new List&lt;object&gt;(); arg_ASyncDispFrames.Add(buffer.Clone()); arg_ASyncDispFrames.Add(recordsPerBuffer); arg_ASyncDispFrames.Add(postTriggerSamples); arg_ASyncDispFrames.Add(disp_Pic); That seems to have worked, but did you mean adding it in the cast in the background worker? float[] buffer_Alt = (float[])varIn[0]; I can't seem to do it there as it doesn't want to think of it as an array and treats it as an object. Just wondering out of curiosity/if it would be a better idea to clone at that point.
I may be mistaken but I believe that the watch window highlights values in red when they have changed (from what they were when the breakpoint was first hit) 
Glad it helped! As concerning placement of the fix... &gt; float[] buffer_Alt = (float[])varIn[0]; &gt; I can't seem to do it there as it doesn't want to think of it as an array and treats it as an object. Just wondering out of curiosity/if it would be a better idea to clone at that point. Yes, I was suggesting to do it here. You can't call a Clone() method on varIn[0] since it is of type Object, and Object doesn't contain this method (you can assign instance of a more specific type to a variable of a less specific type, assuming the same chain of inheritance). Try putting parens around the cast expression: ((float[])varIn[0]).Clone();
On the other hand, I've just found out (my bad, I know) that Clone() returns an Object, meaning that it would be syntactically correct to write, uh... float[] buffer_Alt = (float[])((float[])varIn[0]).Clone(); Okay, this is getting ridiculous, but I can't come up with something legitimate off top of my head right now, maybe only this: float[] buffer_Alt = new float[((float[])varIn[0]).Length]; ((float[])varIn[0]).CopyTo(buffer_Alt, 0); Okay *this isn't really better* plus I think it would hit the performance though, not sure. One of the obvious improvements of this snippet would be saving the array's length in a variable once, if the array is, ahem, of fixed length, and not recalculate it every time. The other obvious improvement is not to use this snippet, ever.
Refer to my comment below, in short, it would be correct to perform ^yet ^another cast to an array which gives us a resplendent float[] buffer_Alt = (float[])((float[])varIn[0]).Clone(); Sorry, I don't know how to simplify this syntax for a non-generic class further. 
If every VCS had a GUI as good as TortoiseHg, I wouldn't know what to do with myself.
Are you trying to wrap a web site into a client/server application? If so, a MUCH easier thing to do would be to just have people use their browsers. You can license based on user accounts/IP combination. If someone logs in via a separate IP, it would boot the other account off, preventing 2 people using the same account. This would be the absolute smallest footprint. Heck, you could package the whole thing up into a single install using iis express. 
I'll try it! But the other way seems cleaner so I'll stick with that. Thanks for all your help!! :)
I noticed this little tidbit that looks nice: if (c is Polar(var R, *)) Console.WriteLine(R); An out var that doesn't leak scope outside of the if, and an ignored out parameter as well.
Yep. Take a look at TDD (Test-Driven Development), as it sounds a good fit for you.
Don't let perfect be the enemy of the good.
That function is bad, and you should feel bad! ^^futurama ^^reference You should use StringBuilder if you're doing string concatenation in a loop like that.
I like this a lot - F#s bleed through into the core ecosystem is a reality. Spec seems sensible, anything that gets C# closer to sexy F# type providers ;)
Thanks, too bad it doesn't do anything useful!
This method is so horribly inefficient that it's really shameful to post this online. Please, first get at least one year of C# experience. 
And slowly but surely, C# morphs into F# while keeping the C# syntax.
This blog was posted about a week ago: http://csharp.2000things.com/ I've been a C# dev for quite some time, but I've been slowly reading 10 or so of them a day--a refresher never hurts. They are extremely short and easy to digest, but sometimes he gets a bit ahead of himself in code and comes back to it later. As for specific tutorials it really depends on what you're interested in learning/building. Do you want to create classic Windows desktop apps that can run on a wide variety of Windows releases? Then you likely want to look into Win Forms. Do you want to write desktop apps for Windows 7 and above? That would be learning about XAML. Also, Modern UI concepts for Windows 8/Windows Phone. Do you want to build a website? That would be MVC or ASP.Net. Really, just MVC these days. In addition to that you'll want to learn about LINQ/EntityFramework, since just about any app you build will likely need some form of data storage. Generally speaking, as with learning any new Language, Google and StackOverflow are your friends. 
What? It totally depends on the situation. If the two floats are the result of some complicated operation in which machine precision is problematic? Maybe use an epsilon. For the majority of cases the == operator is fine.
I use an extension method for this: public static class ExtensionMethods { public static bool IsApproximatelyEqualTo(this double initialValue, double value) { // Handle comparisons of floating point values that may not be exactly the same return (Math.Abs(initialValue - value) &lt; 0.00001); } } This way, I can write: if(variable1.IsApproximatelyEqualTo(variable2)) { // Do stuff } I think that makes it easy to read, and relays the intention accurately.
Good point :-) I want to introduce it to students who haven't come across them yet and would make examples of the more popular ones, leaving the others up to themselves to implement, when needed.
Thanks for that I guess I am the Simpleton :-) I had read somewhere very recently that said it was outdated. Its hard to know when trying to pick out the best what is currently used and what has been superceded, if any. 
F# is sexy for sure! I wonder when MS will let us developing Universal apps with it. If this happens I hope they let us use YAML instead of XAML.
Note that the provided solution falls apart when b is 0.
Anyways - some really good ones to learn that I use quite a bit: - Factories - Observer pattern - Command pattern - Flyweight - State Design Pattern - Immutable/Mutable design pattern. (Not sure if its considered a design pattern per se.) - Learn how to create loosely coupled code. Always program to interfaces. The "new" keyword is a big no for complex objects and instead you should be using a factory. - Learn about good and bad inheritance models. Make sure you are careful with the is-a (inherit), has-a (composition) and can-do (interface) models. Always prefer interfaces to inheritance if possible. Observers and Delegates are a a big plus C# has over java. They are inherit in the languages design. Still, knowing the pattern, how to use C#'s implementation of it and when to use it is important. For the love of christ - don't use singletons. Ever. Learn them only to recognize when you've made a singleton and need to rethink your solution. Why? There is no excuse for using them. They have two very large draw-backs: They introduce a global state, and that global state is programmed against as a concrete implementation. You can get the same effect as a singleton by using a service locator. This way you can get an _interface_ to implemented services. Service locators still introduce the problem of global state - which you can resolve by instead injecting your dependencies rather than referencing them via a global variable. Hence, there is really no excuse for using singletons (or service locators really... - but they're the lesser of the two evils.)
for teaching, the fact that some language features use a certain pattern doesn't mean you can't show a simple implementation of that same pattern or even explain it using the built in features
composition. because you should stay away from inheritance.
Yeah I wish but my company is really tight with the purse and doesn't like subscription stuff. The difference between 10,000(20x500) for standalone vs2013 and 24,000(20x1200) for MSDN was enough to make them go stand alone. 
Absolutely awesome reply. Thanks for taking the time to write some really good stuff :-)
Singleton is way overused. Singleton's in my opinion also lead to very bad code practices. That said it really depends on how you implement your singleton if you are using a Dependency Injection method for passing around you singleton that fine. If you have a class you just access from anywhere in your code base that is really bad idea.
No, I need windows services to be running on a bunch of machine to collect some information, and pass that information back to the MVC app. The MVC app will populate a SQL database with that information.
Is this snark, or has programming really gotten this fucked up?
Yea, the correct approach there should be a strong *it depends*.
Yea, I'd use /u/ScottInParaguay's like that too. But I still don't see how the floating points being more accurate towards zero would make any difference, seeing that the absolute difference should be pretty close to zero for them to be "approximately equal".
i have spent probably 3 full years fixing/finishing huge monstrocities of code, created by junior programmers. and the main mistakes they all make are: - apply design patterns for the sake of 'creating structured code' - use singletons or injection to make everything global - use base classes for shared code, for example: Window, WindowWithCloseButton, WindowWithCloseButtonAndMinimize Applying the wrong patterns or creating complex hierarchies of inheritance make code highly unmaintainable. What programmers should be learning is actually much simpler to learn yet harder to master. And that is to recognize 'things' that can be isolated and put into a black box. A great, advanced example of this is a tweening library. A simple example could be an abstraction of a die, or a number of dice. what i see a lot, is people failing to break up functionalities is smaller parts, but distributing them, illogically, over 3 layers of model view controller so: my advice: forget design patterns, focus on recognizing building blocks, taking the libraries you use as an example
*sigh*
Oh, I HATE design patterns because it seems that it's generally fresh grads that know the intimate details of them, yet can't see the forest through the trees. They are excellent for a short-hand on discussing the pros and cons of a particular approach, but are horribly hamstringing if followed religiously. Hell, most of the time the design pattern proponents will blather on for 5+ minutes. After they eventually get to the point I'll say, oh, you mean "blah blah blah"... "Um, yea." (so why did it take you 5 minutes to describe that?) Basically, I've had your same experience! Virtual awkward programmer hug, buddy! EDIT: We're using the decorator pattern at work... oh my WTF... It's is the dumbest, most confusing architecture I've ever seen. Why, I know it "works" but... why? Recursion for the fuck of it structured in such as way as to confuse the hell out of everyone. I love the coffee description on Wikipedia too. In certain specific edge cases, sure... when updating a generally flat database? Why!?
It depends from where you start. From scratch, I would recommend you to keep it simple. Find an beginner book, something like this : http://www.amazon.com/Programming-ultimate-learn-fundamentals-language/dp/1494208393/ref=sr_1_7?ie=UTF8&amp;qid=1407491266&amp;sr=8-7&amp;keywords=c%23 Start a project sufficiently simple and interesting from your point of view to not get unmotivated : A calculator, a notepad... whatever. And the most important, take notes about what you learn and don't forget that perseverance is the key when coding. 
Heh, we're not alone in this. I read a rather amusing article recently about anti-patterns, which describes the same issue.
Singletons are global state with a fancy name. Avoid them. You should avoid global state because the more information you have to hold in your head (or learn) to write, read, or maintain the code, the worse the code is. It may seem manageable in your 500 to 1,000 line applications you write when learning a language, but the more code you have, the exponentially worse this can and often does get. Global state is state that could be available to any bit or piece of your code (or someone else's! yuck) at any time. It's a way of passing hidden arguments into methods--you set the global value in the singleton in some code far off somewhere else, then when you call a function in a seemingly unrelated place, it reads that value again and its behavior changes. The chances of you as writer or consumer of the code knowing this behavioral quirk is made very small by the fact that the value that governs the change is stored in an out of the way place with no apparent link to its usage. Common outside-your-program sources of global state, such as the filesystem or databases (a database is a subset of filesystem manipulation mediated by a complex program, so these two aren't particularly far apart), can also be treated as in-program global state by being read into static objects and singletons, but often they actually aren't! This implicitly shows you how global state is abhorred by other programmers who are sage enough to write libraries that achieve wide adoption. It's often much better to read in that out-of-program global state into a limited context (say, some data structure that is scoped to a particular module or class) and manipulate it as if it were more restricted in scope by having properties on an instantiated class mediate access and manipulation.
Single responsibility is a pretty big one.
I agree that singletons should be used sparingly, but I wouldn't make a blanket statement like "avoid them". The iOS SDK has a few uses of singletons that make sense. First, the UIApplication sharedInstance singleton represents the one and only instance of UIApplication for the current process. You can't have more than one application in a process. That wouldn't make sense. A singleton clearly represents that limitation. Another example is UIMenuController (the thing that handles the cut/copy/paste menu in iOS). You can't have multiple of those on the screen at once. Again, the singleton makes that clear. NSNotificationCenter isn't quite a singleton, but it is typically used as if it were. It allows for subscribing to arbitrary notification events and posting those events so that you can decouple code. Most of the time you use the defaultCenter static instance (a global) because that ensures you are working on the same instance as all of the other code that is posting and subscribing to events. I generally agree that globals should be discouraged, but when you take that to an extreme then you lose some valuable patterns that actually do make code less coupled and more maintainable. It's better to understand the goal (clear, flexible APIs with low coupling) than to just stick blindly to a rule like "never use a singleton".
Good point (additional, optional parameter to set the acceptable accuracy). For the things I've written, that hard-coded value was always good enough. But that may not be true for every situation. One thing that's always been in the back of my mind is to pass in the number of significant digits as the parameter. I've just never gotten around to that.
As usual, it depends heavily on what you're really trying to do - It sounds like you're just trying to put a password on the "installer", that sound right? Once the user has put in the right password, how will you persistently store that information? Why do you need to check daily? Will the password expire at some point? How will you store that information?
You're nice. And by nice, I mean repulsive. 
If this is a case where you want to be able to generate keys that your software can validate, then you are looking for [DSA](http://en.wikipedia.org/wiki/Digital_Signature_Algorithm). You will have a private key that you use to create license keys, and in your software you have it validate against the global key. Fortunately C# has libraries so you don't have to do all the nitty gritty math yourself: [msdn](http://msdn.microsoft.com/en-us/library/system.security.cryptography.dsacryptoserviceprovider(v=vs.110\).aspx) Some initial googling for "DSA key generation in C#" has some good starting points for going about generating license keys using that library. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Digital Signature Algorithm**](https://en.wikipedia.org/wiki/Digital%20Signature%20Algorithm): [](#sfw) --- &gt; &gt;The __Digital Signature Algorithm__ (__DSA__) is a [Federal Information Processing Standard](https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard) for [digital signatures](https://en.wikipedia.org/wiki/Digital_signature). It was proposed by the [National Institute of Standards and Technology](https://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology) (NIST) in August 1991 for use in their __Digital Signature Standard__ (__DSS__) and adopted as FIPS 186 in 1993. Four revisions to the initial specification have been released: FIPS 186-1 in 1996, FIPS 186-2 in 2000, FIPS 186-3 in 2009, and FIPS 186-4 in 2013. &gt;DSA is covered by U.S. Patent 5,231,668, filed July 26, 1991 and attributed to David W. Kravitz, a former [NSA](https://en.wikipedia.org/wiki/National_Security_Agency) employee. This patent was given to "The United States of America as represented by the Secretary of Commerce, Washington, D.C.", and NIST has made this patent available worldwide [royalty-free](https://en.wikipedia.org/wiki/Royalty-free). [Claus P. Schnorr](https://en.wikipedia.org/wiki/Claus_P._Schnorr) claims that his U.S. Patent 4,995,082 (expired) covered DSA; this claim is disputed. DSA is a variant of the [ElGamal Signature Scheme](https://en.wikipedia.org/wiki/ElGamal_signature_scheme) &gt; --- ^Interesting: [^Schnorr ^signature](https://en.wikipedia.org/wiki/Schnorr_signature) ^| [^Elliptic ^Curve ^DSA](https://en.wikipedia.org/wiki/Elliptic_Curve_DSA) ^| [^Digital ^signature](https://en.wikipedia.org/wiki/Digital_signature) ^| [^ElGamal ^signature ^scheme](https://en.wikipedia.org/wiki/ElGamal_signature_scheme) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cjkjm0m) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cjkjm0m)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Changes look pretty cool. If C++ support gets rolled into it as well, ReSharper 9 is going to be awesome.
Couple of options below namespace Example { public static class ApiWrapper { //Option 1 public static IEnumerable&lt;Result&gt; GetResult() { return Foo.Instance.GetResults(); } //Option 2 private static Foo fooInstance = Foo.Instance; public static IEnumerable&lt;Result&gt; GetResult2() { return fooInstance.GetResults(); } } public sealed class Foo { private static volatile Foo instance; private static object syncRoot = new object(); public static Foo Instance { get { return instance ?? Foo.InitInstance(); } } private static Foo InitInstance() { lock (syncRoot) { if (instance == null) instance = new Foo(); } return instance; } private Foo() { //Init everything } public IEnumerable&lt;Result&gt; GetResults() { Result r = new Result() {X = 1, Whatever = "Example"}; var results = new List&lt;Result&gt; {r}; return results.AsEnumerable(); } } public class Result { public string Whatever { get; set; } public int X { get; set; } } } 
I don't want to get into an argument about what constitutes an objective opinion, because that doesn't exist by definition. The fact of the matter is that the singleton pattern works. You can't argue against that because it's a fact. Yes, there are places where it's a bad choice, especially as solution complexity grows, but not everything you'll write is going to be that complex. This is a well trodden holy war that I have no interest in.
Nope. http://blog.jetbrains.com/dotnet/2014/04/10/resharper-and-roslyn-qa/
I'm on a shitty thin client, and i have no admin privileges. We mostly do database development, but i do have to write some c# code on occasion. 
look into Dynamic IP Restrictions Extension for IIS 7.0 [link](http://www.iis.net/downloads/microsoft/dynamic-ip-restrictions)
I think they are just mentioning it in that it made development easier, but will not replace their core engine. Atleast thats what I took from it.
[Here](https://github.com/disruptor-net/Disruptor-net/blob/master/Disruptor/RingBuffer.cs) is the RingBuffer from Disruptor, for the more Enterprisey folks.
It's the Disruptor-pattern ring buffer by [LMAX](http://www.lmax.com/?ns_campaign=ukgenbrand&amp;ns_linkname=lmax&amp;ns_source=google&amp;ns_mchannel=ppc&amp;ns_fee=1&amp;gclid=CN3-m7HghMACFSQXwwodV54AtQ), ported from Java to .NET.
You'd have to make a loop to insert the string ("and") between each element, probably while outputting the result into a new array, and have that loop end when it gets to the end of the original array.
Singletons are global state - Objectively, yes. Singletons are accessed as concrete implementation - Objectively yes. Can you replace a singletons implementation? No. Not without refactoring one out. There is no room to subjectivity there. Whatever you have to do to justify your singleton ridden code. When the times comes to refactor it, you'll finally appreciate why you should've never started using them in the first place. As someone who has been on both sides of this argument, I can tell you that you will regret using them at some point in the future.
Hint: For the MSDN articles with brackets in them (...), you have to escape them with backslashes \\, otherwise Reddit doesn't format the link correctly :)
If I understand your desired output correctly you want [String.Join](http://msdn.microsoft.com/en-us/library/57a79xd0%28v=vs.110%29.aspx) like so: string[] array1 = { "test", "this", "stuff" }; string out = String.Join(" and ", array1); 
&gt; "Avoid" is not "never ever use." I used the word "avoid" because singletons tend to be abused in the way I outlined. Fair enough. &gt; I doubt that "it doesn't make sense to have more than one of these" implies "the one instance should be global." How else would you enforce that constraint?
I can't dive into the details, but we recently used a singleton as a configuration object for our post sharp logging attributes. We have the aspects and PostSharp code in a nuget package, the code that needs to be audited in another nuget package, and the code consuming the code that needs to be audited is one of many applications or workers. Because one cannot inject into attributes, yet we need to allow each application to configure certain things for our auditing aspects (such as the application the audit came from, and functions to determine certain things about the context at run time that is application dependent), we decided that a singleton configuration object that would only be mutated at runtime would be the best solution to the problem, with some reasonable defaults defined in the singleton itself within the aspects package. I do think their good uses are pretty rare, but they definitely exist, especially when DI/SL is not an option.
&gt; string[] array1 = { "test", "this", "stuff" }; string outString = String.Join(" and ", array1); FTFY ("out" is a keyword)
Haha thanks. I guess that's what I get for mostly writing plain old C these days.
That looks pretty neat, but diff use case for sure. Mine is designed to be simple and fast, disruptor looks complex but faster. I'm happy with not being quite as fast for now, though I might add concurrent I/O later. It's already pretty fast through use of copy-by-long unsafe methods (&gt;1GB/s).
Thanks, both of you. Every day I work in C# I'm excited to learn more and more about what I can do with it.
I love the idea of records. Far too often I see code that by all rights should be immutable but isn't just because of how tedious it is. *** I am concerned about ORM support though. I have no love of ORMs, but a lot of people do and as it currently stands the popular .NET ORMs have lousy support for this. Also serializers. I need to be able to convert records to and from SOAP-XML/JSON or I can't use them in a lot of places.
Never happen. C# would have to adopt far too many limitations for that.
I just use: Thread.CurrentThread.CurrentCulture.TextInfo.ToTitleCase(pString); I did enjoy the other posting about replacing with ignorecase. It shows a purposeful ignorance towards Regex.Replace. 
This is the scary bit: &gt; Will it be practical to use both ReSharper and Roslyn-based functionality in Visual Studio? and &gt; as its still uncertain whether we would be able to disable Roslyn-based features I don't want to have to choose between one or the other, I want both to work in the most sensible way.
Those are valid concerns, I assume that if they really go through with that draft, a wave of updates will begin. Seeing how you can both use case classes in ORMs and serializers/deserializers in Scala, I bet C# will follow. I only wonder how long it's going to take for the ecosystem to adapt...
Oh, definitely. It was more of a tongue-in-cheek reply, C# won't match any HM-based language, but they could add just a *little* bit more inference support. For example Scala's inference is far from perfect, but it still can do quite a lot.
&gt; OiskyPoPoisky Finally someone gets it! My router's firewall rules are set to always allow connections on the given port and forward it to the internal ip running the server. Like I said, this works for literally everything else *except* my program. As for allowing outside connections, is this some specific setting in Lidgren? I haven't seen anything mentioned on it, but it does seem most likely the problem is with the server itself. 
I have no idea about Lidgren, but when I tried to make a Streaming Server, I accidentally set the listener to only allow localhost at some Point and then later wondered why I couldn't connect from a different Computer... :D &gt; &gt;OiskyPoPoisky &gt; &gt;Finally someone gets it! Sure, I watched That :D
After much poking, I discovered I was only forwarding TCP connections and not UDP. Feel a little dumb, but it's fixed now.
You can use F# with Xamarin though. 
thought he said list of strings. probably shouldn't phone post lol
Immutable and Record are the same thing. And while the spec doesn't mention it, I would assume record structs are possible.
Here is the snippet from my library. /// &lt;summary&gt; /// &lt;para&gt; /// Returns a string with the &lt;paramref name="separator" /&gt; between each item of an /// &lt;paramref name="enumerable" /&gt;. /// &lt;/para&gt; /// &lt;/summary&gt; /// &lt;typeparam name="T"&gt;&lt;/typeparam&gt; /// &lt;param name="enumerable"&gt;&lt;/param&gt; /// &lt;param name="separator"&gt;&lt;/param&gt; /// &lt;param name="atTheEnd"&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; [DebuggerStepThrough] public static String ToStrings&lt;T&gt;( [NotNull] this IEnumerable&lt; T &gt; enumerable, [NotNull] String separator = ", ", String atTheEnd = null ) { if ( enumerable == null ) { throw new ArgumentNullException( "enumerable" ); } if ( separator == null ) { throw new ArgumentNullException( "separator" ); } string result; var list = enumerable as IList&lt; T &gt; ?? enumerable.ToList(); if ( String.IsNullOrEmpty( atTheEnd ) || list.Count &lt;= 2 ) { result = String.Join( separator, list ); } else { result = String.Join( separator, list.Take( list.Count - 2 ) ); while ( list.Count &gt; 2 ) { list.RemoveAt( 0 ); } result += separator; T item; if ( list.TakeFirst( out item ) ) { result += item; } result += atTheEnd; if ( list.TakeFirst( out item ) ) { result += item; } } return result; } 
Wouldn't you want to actually find out what the line size is (presumably of L1), and base it on that? Thanks for reminding me though, I'll add the power-of-two, it should help! Was distracted at the time. 
I spent quite some time looking for that, but could not find it. I ended up just finding a very concrete project of my own and jumped into it. That worked pretty well, in part thanks to what i learned from the JS course at Code A.
I heard that Pluralsight.com have some good stuff about the basics and advanced environments in the C# language. It is quite expensive but if you are a university student you should get it for free. Personally I do it old school and read physical books when I want to understand a new language :)
I had a account through an employer for a year and I thought it was pretty sweet. They are big into C# &amp; dotNet and have a lot of the latest language features and lots of patterns and abstract programming courses. Highly recommended. Its not that expensive at 29.99 a month for basic compared to other training materials I've seen that are that polished . Just get it for a month or two and cram. Also sometimes you can find discounts. 
&gt; Pluralsight.com Of course I can and do use articles/books/videos however I noticed I learn much better interactively.
Yep, pluralsight is the way to go, if you're a beginner or an intermediate. $29 gets you everything except the exercises and offline viewing option. Try it and see if you need the exercises files. If you do then just mail them that you want to upgrade to the $49.99 option and they will just charge you the difference. For a student, Microsoft dreamspark offers 3-month pluralsight free ($29.99 version)
Right. Pluralsight isn't interactive. Some of the presenters do a good job of making their videos and project files almost like a lesson plan but a lot are mainly demos or high level concepts. But they have a ton of content so you could start from learning VS IDE, C#, then LINQ, MVC, etc. and make your own learning track. For $30 - $50 a month I think its a great value. Man, if they would go the way of almost a Coursera course they would sweep up. 
Check out Microsoft Virtual Academy. There are video courses on everything, including C# from absolute beginner through to more complex, advanced stuff. It's free and covers not just C# but a lot of other stuff. Also, Channel 9, Microsoft's video station, has a ton of content, some of which is directly from Virtual Academy. LearningVisualStudio.net is also great (it's not free though), and the dude who runs that hosts the free tutorials on Virtual Academy. He's (Bob Tabor) very good at explaining the core concepts without assuming you know it already (which is a common error of people trying to explain something!).
I have a pluralsight subscription and add an interactive component to it. You have to click continue at the end of each module, so I take the opportunity to practice the concepts from that module in a test project. 
&gt; learn JS and PHP Hope you don't have to it... /r/lolphp
Bob Tabors site http://www.learnvisualstudio.net may be of interest to you. It's not strictly interactive, it's more the follow along at home video style. 
learnvisualstudio.com has a creat primer on C#. So does learnitfirst.com. I have taked both courses and they were both great.
I took his C# for Beginners class. I like how he keeps you engaged. 
I put my faith in Whitaker's C# crash course, its free and really understands how to teach the basics. http://rbwhitaker.wikidot.com/c-sharp-tutorials
By the end of those videos, I felt like Bob was my friend... I miss Bob :'(
C# course from Bob Tabor was the Best I have ever tried and I really enjoyed it. Now I am playing with these two on microsoftvirtualacademy : Programming in C# Jump Start and Twenty C# Questions Explained. Another good way to learn C# is browsing MSDN and also this site : http://code.msdn.microsoft.com/ :) There are some great code samples. ;)
Let me point you to my favourite, huge StackOverflow thread http://stackoverflow.com/questions/9033/hidden-features-of-c As you go through it, you'll stumble across new features and wow moments where you realize lots of cool tricks you didn't know, in addition to some stuff that just isn't relevant to you at the moment or you don't understand. Then you'll read it again a few months later and you'll find that some of the stuff you didn't understand or need previously teaches you even more cool new tricks based on what you've learnt since. Then again 6 months later, etc. It's a real goldmine I'd recommend anybody have a look at it if you've not seen it already (or if you have, have another look anyway!) There's cool new tricks in there whatever your level. I read through it every few months.
Yes, too many people start at too high of a level without ever teaching absolute fundamentals which are in my opinion actually harder to grasp, which is maybe why most tutorials and such skip them lol.
Seems like everyone here loves him lol. I'll absolutely check it out. Thank you.
Thank you.
Good luck :)
If you're going for the quickest upgrade path, VS 2008 express included a VB6-&gt;VB.Net migration tool. It won't leave your code in a compilable state, but it shouldn't take you long to fix the errors and tweak some stuff if your application isn't extremely complex. I was faced with the same decision as you a while back. Ended up starting down the WinForms road and changing to WPF after an extremely short amount of time due to our graphical/layout/customization needs. In order to prevent the spaghetti-code issue of events everywhere, we were already removing most code-behind into separate ViewModels, so rebinding to WPF view was absolutely painless. I've only got time to address couple things you mentioned. 1 - you can still accomplish MVVM architecture with WinForms. Binding to properties, commands... There is a gotcha, though. WinForms doesn't follow the INotifyPropertyChanged of your binding's parent objects, so you may have to manually rebind. 2 - For us, the combination of proprietary VB6 controls and drastic layout changes to rediculously cluttered forms 9made starting over in WPF almost a wash (as opposed to trying to modify the converted vb6 forms). Also, I'm about as fast in WPF as I am in WinForms. It really depends on your skillset. Check out the ReactiveUI framework - specifically the RoutedViewHost control and RoutingState object. Combined, they give me a really nice MDI application in WPF. 3 - I'm not a part of MS, and have no crystal ball. WPF has been updated every major version of the framework so far, so I can't imagine support will end in the next few years. Looks like the responses so far on your SO posting recommend WPF as well. Seems reasonable to me.
I don't have ReSharper, but my business license came with JustCode which is similar and I've had absolutely no complaints so far
Having written a whole lot of both, my vote is for wpf all day every day. It's impossible to fully separate the UI from he logic in winforms while it's a built in feature of wpf that you have to go out of your way to break. That said, if you know winforms and don't know wpf/xaml/MVVM and the speed of implementation is much more important than maintainability, you might have a good case for winforms. If I was the guy hat had to maintain your winforms solution, especially one that was a straight port of a vb6 application, I would end up spending a lot of time talking about how much of a moron you are. Wpf is not dead at all. Tons and tons of enterprise apps are built on it and they will live on for many years. That's Microsoft's bread and butter. They're not going to bone their most profitable customers. 
Although this maybe isn't the best example, imagine the class above was called ConsoleCellPhone instead. You may want to create another Cell Phone called TextFileCellPhone which instead of doing Console.WriteLine wrote text to a file. Within the Main method of MultipleInterfaces, you could replace the "new ConsoleCellPhone" with "new TextFileCellPhone" - the remainder of the class would continue to work as both follow the same interfaces - although the implementations differ. TBH, the example you are looking at probably isn't the best for explaining why interfaces are useful - there are far better examples out there. This may be more useful - http://programmers.stackexchange.com/questions/108240/why-are-interfaces-useful
Obviously I think you've been given some odd information about interfaces. Consider an interface to be a public contract in the type hierarchy, but not an object itself. For example, in C# everything inherits from System.Object, and as such they get ToString and GetType methods. For example: class BaseClass { } class DerivedOne : BaseClass { } class DerivedTwo : BaseClass { } interface ISample { } class DerivedThree : BaseClass, ISample { } class AnotherClass : ISample { } BaseClass instance = null; For instance, we can assign any instantiation of DerivedOne, DerivedTwo, or DerivedThree to this variable. AnotherClass has no relation to BaseClass, so it is invalid to assign it here. In the same way, you can't assign an instance of DerivedTwo into a variable typed as DerivedOne (since they are not related). However, an interface lets you deal with non-relations easier. ISample x = null; For example, we can assign any instance of DerivedThree or AnotherClass into this variable, even though DerivedThree and AnotherClass do not share a type relation. Similarly, you can define an interface that has some signature (in your example above, lets use Device). That means that anything that implements the interface needs a SwitchOn and SwitchOff method. Interfaces don't have implementations; they simply define the publicly available methods, properties, fields, etc. So your CellPhone object implements the interface, so it has the actual implementations of those methods defined in the interfaces. Now, as to WHY you use interfaces; typically they make managing your code easier in some respects. Let's use probably the most common interface that is used: IEnumerable&lt;T&gt;. There are lots of classes that implement this interface, for example Arrays, Lists, Dictionaries, etc. A List&lt;int&gt; implements IEnumerable&lt;int&gt;, just as much as int[]. Your code doesn't actually care if you use a List or array because it can consume it the same way, so the relationship in the type hierarchy isnt as important as the publicly available signatures. Imagine an interface like an API for your types; any type implementing the interface needs to implement these API methods. 
interfaces help your code be more extendable to different scenarios without duplicating a bunch of code. If something is a device, it CLEARLY has an on/off switch, so instead of coding on/off switches every time you create a class, you can instead just implement the interface for it- now you're only coding the parts of the on/off that are *different* or unique for your particular implementation). The interface consists of two methods: SwitchOn() and SwitchOff(). In your example you've created a CellPhone class that implements all the interfaces you've designed. But now your boss comes to you and says that you need to create a new device called a microwave that has no volume button. So now... public class microwave: Device, Pluggable { public void SwitchOn() { Console.WriteLine("Switching on"); } public void SwitchOff() { Console.WriteLine("Switching on"); } public void PlugIn() { Console.WriteLine("Plugging In"); } public void PlugOff() { Console.WriteLine("Plugging Off"); } }; You could create a new interface called "Tazer" for creating a device that tazes. Another interface for a device that has laser beams, another device for vibrations. You now have 6 possible interfaces. Depending on the way you define the implementation of these interfaces, you could have a huge variety of possible objects to create. The book "Head first into C#" has an *ok* description of interfaces, though if you can't acquire the chapter for free, I would stick with [google results](http://www.artima.com/objectsandjava/webuscript/PolymorphismInterfaces1.html)
Interfaces allow you to treat objects with commonalities without needing to extend an entire class. I think the example you found is a little difficult to understand the power of interfaces. Try something like below. The function TurnStuffOn doesn't need to know anything about cellphone or keyboard. All it needs to know is that the thing being passed in has a TurnOn function. This allows you to make functions/classes that tend to be cleaner and follow "code contracts" better. (doing this from phone, may not be perfect): Interface Device { void TurnOn(); void TurnOff(); } Public class Cellphone : public Device { Public void TurnOn(); // do implementation Public void TurnOff(); /// other class methods and properties } Public class keyboard : public Device { Public void TurnOn(); // do implementation Public void TurnOff(); /// other class stuff } Class MainExample { void turnThingsOn( IEnumerable&lt;Device&gt; stuff) { Foreach(Device D in stuff) { D.TurnOn; } } void example() { Cellphone [] cells = new Cellphone[]{ New Cellphone(), new cellphone()}; Keyboard k = new keyboard(); // without interfaces Foreach(Cellphone c in cells) { c.TurnOn; } k.TurnOn(); // using interfaces List&lt;Device&gt; dev_list = new List&lt;Device&gt;(); dev_list.AddRange(cells); dev_list.Add(k); turnThingsOn(dev_list); } } 
Here is a reply I posted a while ago to a question on how to use OOP features like interfaces and abstract classes: http://www.reddit.com/r/csharp/comments/20renb/help_with_inventory_system/cg78f6d
An interface simply defines a set of operations that you'd like to have available on applicable objects. For example: public interface IDrawable { void Draw(); } All this does in our program is say "some types can be drawn. Those types will at least provide a Draw() method.", and literally nothing more at this point. Then, you can implement IDrawable on any types (eg Circle, DogIcon, WelcomeMessage etc etc). The magic is then that you can just have a list of IDrawable objects somewhere, and draw them all, and you don't care what they really are. This example is a bit contrived and short; please forgive me, I'm on my phone! Edit: also, notice how the IDrawable types are otherwise unrelated, a WelcomeMessage shares little with a Circle or a DogIcon, but they can all be drawn, thanks to the interface. 
I'm not sure of the internals of it. It would certainly seem to make sense for it to break at face value. If you want to find out for sure test it - call it a few thousand times in a loop with a stopwatch. Make sure to run the release build as you can get fairly large differences in loop behaviour in debug builds and make sure your loop count is high enough to give a good answer (say enough for it to take 30 seconds). This should give you your answer or demonstrate if the difference is negligible.
Using a **for** should theoretically be faster (unless the CLR does some incredible optimization magic.) The main reason IEnumerable&lt;T&gt;.Any(...) is slower is because it's accessing the collection indirectly through an enumerator. IEnumerable&lt;T&gt;.Any() first creates a new IEnumerator&lt;T&gt; instance and then uses the IEnumerator&lt;T&gt;.Next() and IEnumerator&lt;T&gt;.Current members to iterate through the collection. The enumerator must then be garbage collected. The predicate passed to IEnumerable&lt;T&gt;.Any(...) must then be executed as a delegate. This is much slower than a normal method call for a couple of reasons. This predicate must be called on each item until the condition is met. Okay, I probably got a little carried away, but my point is that this is a **MUCH** more complex and roundabout way than simply accessing each element directly via the collection's indexer: var item = list[index]; if (&lt;condition using item&gt;) { } **Foreach** does use the enumerator in the same way, but it doesn't use the predicate delegate, so there's that I suppose. However, we are, of course, talking about micro-optimizations. You are never likely to see this as a performance bottleneck, or indeed hit, in a typical application. EDIT x2: Found it As for IEnumerable&lt;T&gt;.Any(..)'s implementation, check: http://referencesource.microsoft.com/#System.Core/System/Linq/Enumerable.cs#8788153112b7ffd0#references It does indeed return *true* on the first item. 
I'll give you a real world example of when to use interfaces. Say you have a client side of an app that needs to get its data from some sort of backend or service. The service is capable of using different types of databases like SQL, SQLite, Access, whatever. It has a database access layer implementation for each of those DB types. Each one of them inherits or implements an interface called IDatabaseAccessLayer. On your client side, you only have this interface and you couldn't care less what the implementation is. You just use the interface and access the data. Say you wanted to add another implementation of the IDatabaseAccessLayer interface. You implement it in the service and your client still works the same because all implementations conform to the interface's method signatures. The client might need minor to no code changes for this new access layer to work.
Thanks for the response! It was very educational. And I was never able to find that documentation, so thanks!
The capability and ease of reversing code in both .net and java make licensing and obfuscation a relatively useless task. The only true solution to this problem is to maintain your protected intellectual property as a service. Once you ship it there is no protecting it. 
Not sure? Read the documentation and check the source, but don't rely on some obscure measuring. 
This is definitely not **much** more complex. You said yourself that for each uses the same mechanics as Any. The only difference is the way you check for a condition, using a method or checking it directly. 
Imagine you just wanted silence and didn't give a damn about phone calls. Just grab everything that has a volume and turn it down. That's why interfaces matter.
As others have suggested, it certainly breaks when the first condition is met. The Linq extensions are pretty damn smart and .Any() has one simple job so it's not going to do it in a dumb way. The part that freaks me out is where you're worried about performance but I highly doubt this extension is creating any kind of a bottleneck for you. It's like trying to figure out how to save time by putting your shoes on faster... you'll spend way more time explaining why a grown ass man is wearing velcro shoes than you'll actually save by not having to tie them. Code it in the simplest, easiest to read way first, and if you later discover performance bottlenecks, isolate those, and optimize accordingly.
Interfaces are like an outline of a set of methods a class will need to have. If a class has a `Volume` interface, you know it'll have the `VolumeUp` and `VolumeDown` methods. 
Normally I'm pretty obsessive about performance but I would have to be in a pretty tight loop to even think about this one.
AFAIK linq will generally* be marginally slower than basic looping anyway. I thought linq in a lot of cases were more or less a wrapper and the actual work behind the scenes was pretty vanilla. Correct me if I'm wrong and I'll edit my statement. * keyword generally. 
Sort of, but not really. I made the tedious part of SQL selects easy without writing a black-box SQL generator and there's no mapping for insert/update/delete. A big advantage over an ORM is by using this method, it can actually map a single row to multiple objects if you design your database properly.
generally anything that uses lambdas is going to give a small performance hit but if you use it it correctly the hit is so small it wouldn't be noticeable in most situations i use .Any() over the alternative in 99% of cases as it is cleaner than writing a for/foreach loop for a simple case of does this exist 
 public static bool Any&lt;TSource&gt;(this IEnumerable&lt;TSource&gt; source) { if (source == null) throw Error.ArgumentNull("source"); using (IEnumerator&lt;TSource&gt; enumerator = source.GetEnumerator()) { if (enumerator.MoveNext()) return true; } return false; } Whoever told you to code out the foreach is an idiot and you should call them out for it. 
I wouldn't say WinForms is dead. It really depends on your target audience. Our flagship product is 70% Winforms, 20% Android and 10% Web, and we're still selling a healthy and accepted product, as our customers (logistics, courier, freight etc) companies want functionality rather than caring about the zeitgeist of the tech industry. We stuck with Winforms as it is a stable and mature product and perfect for a client side UI, although we are soon offering a lighter, and cheaper, web based one. I would, in fact, argue WPF died before it could get off the ground (but that is a subjective opinion)
Did you also want to get the first matching item? Because then using a foreach loop would be somewhat faster. Otherwise it's identical.
I really like this series. I am using it for my own app, so far I've been through part 1+2..
Well one way you could solve this is by creating a template for one "message". I am assuming that you want to add a little picture in the corner of a message that shows a user's avatar image, and you want to add borders to make it obvious what message belongs to which user. Create a user control, and add a border, picture box and textblock to it! When binding the list of messages (message can be a viewmodel, but whatever floats you boat) define the template the itemscontrol should use at the top like so: &lt;DataTemplate DataType="{x:Type my:ViewModel}"&gt; &lt;my:UserControl /&gt; &lt;/DataTemplate&gt; If you want more input let me know, but I have learned the most by doing, not by copying. And I know what you (or some others that might be reading this): no this is probably not the best way to solve this problem but then again, WPF is not the best tool for every situation. Also: you can use a web browser control, you can find plenty of examples on google.
Glad you like them :) 
Many Thanks for that. I think I'll be using a combination of both suggestions. After checking out Web API (a technology that I had missed) I decided to switch from WCF to Web API so I can get the add on for it and also use the IIS plugin for an additional layer.
The difference between LINQ to objects and raw loops is huge (factor 10-100). These are differences that are large enough to notice even outside of obviously CPU-bound code. You will need at least a few hundred thousand iterations for this to become noticeable, so it's not generally a very large effect, but it's certainly something I think about (I certainly have run into such calls in profiles while simply rendering webpages). 
"Runge Kutta in C#" would have been a better title
People keep saying "contract" or "rules" when talking about Interface-- but maybe the best way for you to wrap your head around an Interface file is that it's a list of requirements for a class. class MyNeatClass : MyInterface now says that MyNeatClass must fulfill all the requirements that I have laid out in MyInterface interface document. The best use I've ever had for this was in creating a host application that could consume plugin-DLLs on the fly. The plugins had to conform to that interface I made. I laid out an interface so that anyone else wanting to create plugins knew what my host application expected to see inside the plugin-DLL. It had to have specific properties and methods in it (so the host could use Reflection to load them and call and read properties and methods that it could comfortably know were there). This could also be met with using an abstract base class - but the whole argument of interface vs abstract classes is for some other thread.
&gt; Head first into C# [Here's the chapter.]( http://books.google.de/books?id=_cWDAAAAQBAJ&amp;lpg=PA1&amp;hl=de&amp;pg=PT578#v=onepage&amp;q&amp;f=false )
Good catch, it's been updated.
Try this: public DateTime FromUnixTime(long unixTime) { var epoch = new DateTime(1970, 1, 1, 0, 0, 0, DateTimeKind.Utc); return epoch.AddSeconds(unixTime); } http://stackoverflow.com/questions/2883576/how-do-you-convert-epoch-time-in-c 
http://stackoverflow.com/questions/23146639/noda-time-c-magic-to-parse-json-supposed-iso-8601-date-e-g-1396949418557 Does the answer on there help at all?
Right - the time is in UTC, you need to convert it to your local time zone using DateTime.ToLocalTime(). In dmoonfire's example: public DateTime FromUnixTime(long unixTime) { var epoch = new DateTime(1970, 1, 1, 0, 0, 0, DateTimeKind.Utc); return epoch.AddSeconds(unixTime).ToLocalTime(); }
Hah, well what with consumers realising that they don't need a PC after all - a tablet will do fine - and enterprise wanting robust general-purpose PaaS offerings, it seems a valid approach... not that I feel too excited by it, I must admit. Well other than Paint.NET, Samsung Kies and GitHub - no, you're dead right - I can't name anything else with certainty. Although I do hear there is not inconsiderable enterprise use. I must disagree with you, for the time being at least, on the "modern"-apps-being-a-replacement thing. Even with them coming to desktop, they really don't have the interactivity that desktop users expect - at least power users. They're like the new start page - completely juxtaposed with the desktop. And that's going to take time to rectify. I don't see client apps and Visual Studio being made metro any time soon... I was unaware of any significant XAML differences, other than using different controls. And the use of the new async stuff is because of the new Windows API, which should, if I've understood it correctly, be totally compatible with WPF. As I said before, WPF is purely a rendering engine and XAML parser with some custom controls - just another couple of .NET assemblies. Why put money into it? Good question. We'll probably see a steep decline in basic apps. But the desktop will be around for a while yet in enterprise and for power users. And they will need desktop-specific applications. And WPF could, and should, help fit that bill. Because Metro sure can't. I hope you're wrong too :/ :P
Started it and absolutely love it
Turn the fields into properties. public string Make { get; set; } public string Model { get; set; }
Oh, yeah, there is that. I guess the algorithm is the same as with any, but it returns the found item instead of true and the default instead of false. But then you have to test for the default value. I think foreach might be faster if you're embedding the logic you want to do with the item in the loop like... foreach(var item in collection) { if(item.Property == aValue) { doSomethingWith(item); break; } } but the gains would be really minimal, simply one testing for default. If, for some reason the default testing is really long then you can use the foreach loop, but making the comparison faster would be a smarter way.
There is no way Linq in general is that much worse than raw loops. You can shoot yourself in the foot pretty bad if you do something stupid with Linq (like anything else). When I've looked for performance gains by profiling Linq code against raw loops the difference is almost always negligible. Granted there is some extra boxing and allocations that happen but that won't create a "huge" difference. If your Linq expressions are a factor of 10-100 times slower then you're doing it wrong.
Who cares about tying your shoes when You can just slip into them :D
Out of curiosity, and don't take this the wrong way, but what level are you teaching that you're not familiar with design patterns? Singleton's can be good, and they can be bad, and if you don't know the 'why', are you sure you should be teaching students? 
Classes are something that I am unfamiliar with beyond the basic level and MVC. Until this year we didn't need to go beyond basic OOP, but as I have time I wanted to include in Design patterns. Its working out OK. 
I highly recommend momentjs. It's been a huge help with all sort of fun dates in javascript. http://momentjs.com/docs/#/parsing/unix-offset/
A bit of advice: always store your dates in UTC and convert them to local only while showing them in UI.
Or, as an alternative, you can store them in serialized `DateTimeOffset` type, including the date, time *and* time-zone. Then you can also freely convert to local :)
I'd just like to add that even though it's not really 'production ready' in all aspects, there's also [LinqOptimizer](http://nessos.github.io/LinqOptimizer/). The [performance](https://github.com/nessos/LinqOptimizer/wiki/Performance) stats are pretty impressive and I'm hoping it will include all the things they're listing in 'Future work' section, that would be *sweet*...
Na, always store in UTC. :) Because sometimes, you can't always have an offset, but you can always get UTC. And use ISO format if you have to transmit it in character format.
Related - wcf callbacks are awesome for chat apps.
Yes. I didn't use binding list when I tested, just List. When they are fields they did not work but when they were properties they did.
If you have a moment could you tell me why you made that suggestion?
Usually the standard collection type you use in WPF when you need change notification (i.e. when items are added or removed) is ObservableCollection unless you need all the additional features with the other types. I mention binding your items source because you can get rid of your code behind then. You will understand when you start getting more into MVVM. Here's a link somebody asked with a similar question on which collection to use. http://social.msdn.microsoft.com/Forums/vstudio/en-US/606c35ca-e0fd-49b4-9e3e-d8d72a26135c/observablecollectiont-vs-bindinglistt?forum=netfxbcl 
You need to bind your list box to the collection. Will post an example when i get to my laptop. 
Change the &lt;Grid&gt; into a &lt;Stackpanel&gt;
ObservableCollection/INotifyPropertyChanged is your friend. 
Using that argument you might as well pirate it, it's cheaper and you're still breaking the licensing agreement.
I paid for it. I wasn't reimbursed. Nobody else uses it. How exactly am I breaking the licensing agreement?
&gt; We newobj a new delegate instance which holds an IntPtr to the method to execute and the current execution context (local variables etc.) It should be noted that delegate calls are highly optimized by the JIT compiler, to end up with almost no overhead (the target method address is inserted inline). Also, all calls are callvirt at the IL level (when using C#), virtual or not. The JIT compiler devirtualizes when possible. Also also, delegate instances are often cached (at the IL level), although this is generally only done for lambdas. This means, bizarly, that Foo(bar) is slower than the eta-expanded form Foo(() =&gt; bar()). These cached instances are hoisted out of loops if possible, as well.
Yes, interface calls are quite slow unfortunately. Foreach uses one as well, but it's bit more complicated here since you don't actually need to be IEnumerable to be foreached, and it may call your methods directly if possible.
This is an exaggeration. Interface calls are slightly expensive, yes, but delegates are not, and their instances are often cached. Any doesn't even take a delegate parameter, for the simple case. Foreach may or may not be able to avoid interface calls, I haven't looked into it. For loops of course do, and if the container is an SZ-array, it will avoid method calls to access elements as well. But arrays aren't great to work with.
Yea, I didn't even look at the subreddit.
Premature micro optimization, especially on the cost of readability, are really bad. Period. 
definitely an interesting approach; looks like the constructor syntax from scala. 
&gt; For the time being only record classes are supported. In theory, record structs could be added using the same basic syntax and concepts. A couple of problems with record structs: * A record with all default values is probably not valid in most domains. * The syntactic advantage of `records` is in creating types with many read-only fields, but value types should only have a few small fields. 
&gt; For/Foreach difference was negligible for arrays. Not surprising since the C# compiler generates basically the same code when the compile-time type is an array 
Example please
Here it comes: case class Cartesian(x : Double, y : Double) then copying: val c1 = Cartesian(2,4) val c2 = c1.copy(y = 4) Seems that proposed C# copy syntax is closer to F#'s records: type Cartesian = { x : float; y : float } let c1 = { x = 2.0; y = 4.0 } let c2 = { c1 with y = 5.0 }
 You should check out my project that I created a while back: http://sourceforge.net/projects/csharpredditapi/ It will show you how to consume the Reddit API and if I remember correctly with a decent amount of comments. I even created a widget style bar in WPF to view Reddit at work, errr I mean on my home computer when I wasn't working. http://sourceforge.net/projects/redditwpf/ 
The concept is called a tri-state check box. The different states are true, false, unknown. If you want it to be in the false state by default make it that way.
 I really struggled with Interface's a lot when I first started programming. I can give you a real world example that got me over the hump. In a program that I wrote I have ( 3 ) objects, an object that can be a document, pdf or spreadsheet. Now, you can write a Switch statement that would suffice to enable control to each object. For instance: switch(object.getType()){ case Spreadsheet: Save(); break; case Document: Save(); break; case Pdf: Save(); break; } Like I said, this is fine and dandy, but if the object was contracted via an Interface this could easily be solved by: ((ICoolInterfaceName)object).Save(); An interface is really just a contract telling an object what it should and should not provide. 
 Do you have a snippet or something that would show unknown? 
 Only thing I could think of is if the value came from a database and it was DBNull or Null. Is that about right?
Thanks
Read the documentation: http://msdn.microsoft.com/en-us/library/system.windows.controls.primitives.togglebutton.ischecked(v=vs.110).aspx You can only set the CB to unknown/indeterminate programmatically. From the user's perspective unknown and false are the same. Also, you can change the behavior to only be true/false if you set IsThreeState to false.
Yes, or on a new form when you first open it, the user hasn't checked it, but the user also hasn't unchecked it. It most cases I find myself handling unknown the same way as unchecked... 
Hmmm.... I'm not sure how I feel about that. I think I'd rather force programmers to subclass if they want to add mutable properties. But, I also don't like subclassing from non-abstract classes.
I would start the login as a new thread in the mainform and if its succesfull abort it or smth. but thats my personal pref.
I an inclined to agree on #1 and am in full agreement about non-abstract classes.
Talking to coworkers?
And this is how it looks: http://i.imgur.com/vka7KoF.png
OK. I see where you are coming from.
Local user groups and meetups?
Nitpicking, this is really .NET and not C#. It's a method call to the standard library that does the work, not the language as such.
True. I guess what I really miss is the routine and being with other students.
I had to learn on the job on my own before... Just write out what you want to make.. a console app, a web site, a web forms app etc... Then start reading about how to make these things. Then start. Google specific issues as they arise. It's really not that hard, there's just a *lot* to look up.
&gt; there's just a lot to look up. You can say that again. I've spent at least as much time Googling (or Bing-ing) as I did when I was at university. I think my friend and his fiance are secretly annoyed at me for looking at my iPhone when I meet up with them.
I suppose I should.
Depending on the enumerable its prob better to check its length /count property anyway (providing it has one of course).
Try [rubber duck debugging](http://en.wikipedia.org/wiki/Rubber_duck_debugging). Sounds silly, but it works. Often when I put my problems into words I realize I understood the problem all along.
Sounds interesting. Thanks.
Senior coworkers fill the void. Google handles the rest. 
Looks at the image in the post above. I mean there's even an arrow pointing to it. "**Can be used on company hardware** if purchased privately." Here is the direct quote from [the license comparison page](http://www.jetbrains.com/idea/buy/license-matrix.jsp?_ga=1.32261050.580941046.1406811645) (the page you say you're getting your incorrect information from) for "Personal license" and "Available to:" &gt; Private individuals purchasing with their own funds. Cannot be purchased or reimbursed by companies. **Can be used on company hardware if purchased privately**
I see. Do you know why the casting, if enums have a default int type? &gt; Also, you can do bit field enums I recognize most of these words.
You can use Attributes to indicate the Enums are Flags which lets you combine one or more Enum values together like you've done. It's bitwise stuff; you were pretty spot on.
Also, did you know, the [Flags] attribute is just a convention? It's not actually necessary to be able to use bitwise ops on the enum constants! Edit: Having said that, I think the ToString() method checks for it and does something different accordingly.
Ok. I tried out the 'bitwise' stuff you suggested. enum Weekday { Monday, Tuesday, Wednesday, Thursday, Friday } public static void Main() { Weekday wd = new Weekday { }; wd = Weekday.Monday | Weekday.Tuesday; Console.WriteLine("My workdays are " + wd); } For the last line, I get: `My workdays are Tuesday` I prolly messed something up, but this is making more sense. Thank you, kindly.
They're doing the cast because if they just supplied the enum value to the Format string they'd just get the default implementation of .ToString, which for an Enum will give you the text for the value. So printing (int)Days.Mon gives you 1, and printing Days.Mon gives you Mon Edit: You get 1 because the default implementation of .ToString for an integer gives you the number. 
It's probably because Monday = 0 and Tuesday = 1 =&gt; 0 | 1 = 1 = Tuesday If you want to use things as bit flags generally you assign specific values to them (which don't actually make since in your week day scenario), but would look like this. [Flags] enum PhysicalAttributes { Blonde = 1, BlueEyes = 2, RedHair = 4, BrownEyes = 8, Skinny = 16; } var person1 = PhysicalAttributes.Blonde | PhysicalAttributes.BlueEyes; var person2 = PhysicalAttributes.Skinny | PhysicalAttributes.BlueEyes | PhysicalAttributes.RedHair; Then you can write something to test for the attribute bool IsBlonde(PhysicalAttributes attrib) { return attrib &amp; PhysicalAttributes.Blonde == PhysicalAttributes.Blonde; } IsBlonde(person1) is true; IsBlonde(person2) is false; 
&gt;You usually use them to create a custom - well defined and restricted - list of available options - where you need several possibilities, strings would cause too many code headaches through typo's etc - and you want that list to be VERY well defined, restricted, and controlled. This makes sense to me.
Since you mentioned before that you're just starting, it's important to note *why* the flags have the values they do. Note that they are all powers of 2. Since they are powers of two, each flag represents a single set bit in the number and that by "or-ing" them together, you can create a new number with all of the attributes that you or-ed into it.
ELI5? Never heard the term. As for immutable objects, that should be your default. When your objects are immutable, you know with 100% certainty that nothing changes them. You never have to search around to figure out what changed a given property, you know that the bad value came from the constructor. The same goes for public vs internal vs private. By default you make everything private so you can treat each class as a fully encapsulated mini-program. Then as you find a need, you make things internal or even public.
I briefly wondered about it. I appreciate you expanding on it. 
Thank you.
Rich Hickey explains it in this [video](https://www.youtube.com/watch?v=-6BsiVyC1kM); you're in for a treat.
ELI5 = Explain it to me like I'm 5. Also a popular [subreddit](http://www.reddit.com/r/explainlikeimfive).
I was just going to recommend this. I was going to post this block of code from my project: [Flags] public enum WeekDay { Monday = 1 &lt;&lt; 0, Tuesday = 1 &lt;&lt; 1, Wednesday = 1 &lt;&lt; 2, Thursday = 1 &lt;&lt; 3, Friday = 1 &lt;&lt; 4, Saturday = 1 &lt;&lt; 5, Sunday = 1 &lt;&lt; 6 }
I am not familiar with that notation. I imagine the number to the right of `&lt;&lt;` is the power. But then it just looks like you are raising `1` to those powers. The hex notation actually makes more sense to me. 
It's a bitshift. Take the binary value for '1': 00000001 Now, 'shift' all the numbers 4 times to the left: Friday = 1 &lt;&lt; 4; // Friday is 00010000 And, of course, 00010000 is equivalent to 0x10 which is equivalent to 16. And yes, psi- was right; the shifting method is better. My hexadecimal approach is an old habit that I should really relearn.
&gt;bitfields &gt;I recognize most of these words. Sorry, I had just woken up and neglected to explain these. Because enums are represented as ints, you can specify the integer representation of any given enum value. If you go by powers of two, each enum value represents one bit, and thus is treated like an individual flag. This allows you to do something like this: enum Burger { Nothing=0; Ketchup=1; Mustard=2; Pickles=4; Cheese=8; } Burger hamburger = Burger.Ketchup | Burger.Mustard | Burger.Pickles; Burger cheeseburger = hamburger | Burger.Cheese; Note the use of bitwise or ( | ). You use bitwise and (&amp;) to compare values: if (someburger &amp; Burger.Pickles == Burger.Pickles) Console.Out.WriteLine("I don't like pickles! "); 
You aren't calling your PowerSetofColors method in your Main method? It isn't getting run.
Why the hell is this being downvoted?
Got it. Thanks.
Just one Little Thing: If you're using an enum as a bit field, You should mark it with the `Flags` Attribute. [Flags] public enum Options { None = 0, One = 1, Two = 1 &lt;&lt; 1, Four = 1 &lt;&lt; 2, } Using bitshifts makes it easier to think about the bits as well. So instead of having to think of at which Position the 64 bit is, You can immediately see That It's the 7th bit if You look at `1 &lt;&lt; 6` :)
Well, he posted his KnownColor class up there, and he uses it correctly (as it wouldn't even compile otherwise), he just doesn't call it. But for yours You should really make the R, G, and B fields `readonly` or into `{ get; private set; }` properties, as mutable structs are bad (except in rare cases, for example the Enumerator struct Used by foreach Loops).
Thanks! I made both methods static and actually called the method and that worked! It's returning the combinations but giving me the type instead of the actual values: permutations.KnownColor permutations.KnownColor permutations.KnownColor,permutations.KnownColor permutations.KnownColor permutations.KnownColor,permutations.KnownColor permutations.KnownColor,permutations.KnownColor permutations.KnownColor,permutations.KnownColor,permutations.KnownColor permutations.KnownColor permutations.KnownColor,permutations.KnownColor permutations.KnownColor,permutations.KnownColor permutations.KnownColor,permutations.KnownColor,permutations.KnownColor permutations.KnownColor,permutations.KnownColor permutations.KnownColor,permutations.KnownColor,permutations.KnownColor permutations.KnownColor,permutations.KnownColor,permutations.KnownColor permutations.KnownColor,permutations.KnownColor,permutations.KnownColor,permutations.KnownColor 
Thank you for this explanation! This was helpful! 
wow, embarrassed ;) Learning every day! Thanks! 
I completely agree with you. Using abstractions for the states and inputs would be the best way to increase the reusability and extensibility. However, I decided to use the strings and chars for two reasons: 1. I wanted this to be as simple as possible. When people hear about automata in college it is most often presented in terms of string and language. So I believe that my solution might help people like that transition from mathematical models to a program more easily. Adding abstractions here might be too much. 2. It was just a fun little nightly exercise and I don't think I'll be using it any time soon. So I didn't want to complicate since I had no proof that abstractions were needed.
There's no implementation of "ToString()" on your KnownColor class. The default implementation just outputs the name of the class. You may be meaning to do clr.color instead of clr.ToString() EDIT: This whole line is a bit scary. Console.Write(string.Join(Environment.NewLine, result.Select(subset =&gt; string.Join(",", subset.Select(clr =&gt; clr.ToString()).ToArray())).ToArray())); Perhaps this would work better... foreach(var subset in result) { Console.WriteLine(string.Join(",", subset.Select(clr =&gt; clr.color))); } Functionally the same, but joining a string on enviornment.NewLine feels wrong to me for reasons I can't really qualify.
What's the "copy-by-long" method? I know there are a number of fast copy by pointer techniques.... Most things that I've read lately indicate that Buffer.BlockCopy has comparable speeds to the unsafe methods. Have you benchmarked the differences? Cool project by the way.
Cast byte array pointer to long array pointer, then iterate over it, copying as you go. Means you copy 8 bytes per iteration, and not 1. I've found the difference to be about 15% in favour of this approach (vs. Buffer.BlockCopy) for lengths between 64-1024 bytes, beyond that you get less difference. Buffer.BlockCopy still needs to fix the array in memory (as the unsafe version does), but it also then needs to do a system call. So you see, it makes sense it would be this way.
Possible? Most likely. Do I know how? Nope, sorry :/
Imo, if the rest of your game is native, it seems like the easiest way would be to just write the launcher in a native language as well.
I haven't touched Java in a long time, so I might be completely wrong, but aren't the layout managers runtime components? I ask because I'm curious what design-time stuff exactly you're trying to do. But whatever functionality you're trying to build into the IDE, I imagine it's possible, as there are a ton of extensibility points in Visual Studio. Look at the [Visual Studio 2013 SDK](http://www.microsoft.com/en-us/download/details.aspx?id=40758) and you'll probably find it. A bit of a word of caution, I've done some extensibility work in the past, and some of it makes sense, and some of it takes a while to wrap your head around. I don't know for sure, but if I had to guess I'd say that plugging into the designer is probably going to take a bit of time.
So you know, I added concurrent I/O just now. Not full concurrency, with many reads and writes at once, but you can read and write (one operation of each) at once. I'll add full concurrency later. It's already a big speed boost.
My guess is that KnownColor is an enum and is defined like: public enum KnownColor { Red, Green, Blue, Yellow }; http://msdn.microsoft.com/en-us/library/sbbt4032.aspx
You definitely might be right, but calling ToString() would return the string representation of the enum value, like it does in the sample code op linked. http://msdn.microsoft.com/en-us/library/16c1xs4z(v=vs.110).aspx
Thanks for the readonly tip. As for his posted KnownColor class. I think he wrote it like that himself to get the snippet in his link working, since KnownColor is not defined there. So i created a Version where you could initialize the list like it's done in the snippet. 
You are absolutely right there. If KnownColor doesn't have to have any functionality i think an enum would fit well. I just assumed KnownColor should have some more functionality later on.
I use the N-tier (3) design pattern. I typically put my principal context into the data layer as an abstract class. Then I have activedirectoryrepository that inherits from principal context. Mostly because we have a one way trust with multiple domains and I can use dependency injection to inject a domain and ou into the principal context class at runtime. Finally I extended an active directory user principal (and group) that lives in the domain layer. This lets me have the random attributes that the regular user principal doesn't have. 
I would just put the value in your model then you could just say &lt;% If(Model.isAdmin) { %&gt; html.button(whatevs) %&gt; } else { %&gt; blah &lt;% } %&gt;
Designers are a part of the framework and have nothing to do with visual studio. Visual studio is just a host. What is your goal? The nature of the question indicates you are barking up the wrong tree.
You can actually get a launcher up and running through Unity utilizing its version of Mono. You'll have to use something like GTK#, though. http://www.mono-project.com/docs/gui/gtksharp/
1. At first I implemented it like that. But then you couldn't represent some of the possible automata. Like you said, some of them don't make much sense (unreachable states, no finish states set,...). But the mathematical model allows that as well. With explicit declaration you also avoid mistakes you might make. For someone just starting it might be nice to see if he declared a transition to a non existing state or similar. You talk about efficiency later on but implementing states by looking at the transitions would be very inefficient! Usually there are quite a lot more transitions than states. So I would argue that the memory consumption of a list of states makes up for the increased efficiency. Sure it could be a one time step in constructor, then the performance loss in not to great. 2. I would guess that anyone that will understand my program will be able to do the needed modifications. The whole point of the example was a demonstration purpose. This is not intended to be used in a production environment. As such the printouts serve nicely. 3. That would complicate the example even more. Especially since this is only used as a demonstration. But I agree with you that that would be a nice improvement if we wanted to improve performance. For my example I believe the performance will not be an issue. So I went for clarity and simplicity. But I agree that probably set would be a better choice, since even mathematical model talks about sets. 4. Again I implemented it from the mathematical perspective. If you don't store the Q0 how to you know where to start from on repeated calls to Accpets function? In terms of mathematical perspective you will query the FSM multiple times. I didn't implement a generator of the language or something similar, but we would need the knowledge of the initial state for that as well. There can be outgoing transitions from the final state! Check the example automata I posted, both q0 and q2 are final states. And both have outgoing transitions. Sure you could probably design it so that there wouldn't be any, but again, this would add complexity to it. Matching the incoming tokens increases efficiency. We disregard invalid inputs before we even start to parse them. If we expect many wrong inputs this can save a lot of computation. If we always expect the right format of the input it can be omitted. I guess we are looking from different point of views. I view my solution as something a starter would take an play around with. It should be easy for him to start and it should notify him if he's trying to make something strange. But I agree that most of you considerations are valid if we wanted to optimize the FSM, or allow it to be useful in a more general way than just demonstrations.
Unfortunately this is not suitable: 1. Unity3D uses an extremely old version of Mono and therefore most libraries (Including the ones I use) just don't work with it. 2. I need to run some code *prior* the Unity3D launching. For example I need to check for bad driver versions under Linux before the Unity3D engine runs.
Ive done this, you end up with a native binary with no requirement to install Mono, however its complicated and I just woke up - posting as a marker to fill in later. Look up 'mkbundle' if you want a head start. Edit: Okay so there's two steps, the first is to use mkbundle to build an assembly with all the libraries in: mkbundle -c -o YOURASSEMBLYNAME.c -oo bundles.o --deps --static YOURASSEMBLYFILENAME.exe System.Data System.Web.dll ... This will produce a `YOURASSEMBLYNAME.c` file as output. You need to append the names of all the CLR DLLs used by your app. The next step is to compile the resulting C file, and build in the extra libraries: cc YOURASSEMBLYNAME.c bundles.o /usr/lib/libmono-2.0.a -lc -lrt -lm -ldl -I ./ -o YOURASSEMBLYNAME You need to change the path to libmono as appropriate. The output is `YOURASSEMBLYNAME` as an executable file, which should now run 'as is' on a system without Mono installed. IMPORTANT NOTE! If you do this, you *must* ship an unbundled version of your executable alongside the bundled one in order to comply with the licence terms for Mono. You have to do this on the actual target systems (using a real Linux machine/VM and a real Mac OS instance), you can't do it in Windows via Cygwin.
Ahh, I see :)
The information is mostly right... *but so many grammar problems*
Not to mention that it's not very useful for anyone /o\
Yea ... It's basically just the MSDN page with worse grammar...
Just wondering why exactly you need a launcher? Do the players need to sign into something before the game runs or set some options or something?
&gt;&gt;A static class can be used as a convenient container for sets of methods that just operate on input parameters and do not get or set any internal instance fields. &gt;That means you will make those classes as static class which contains some methods to do some task, without any requirement of storing or retrieving data. Yeaaah... nooo... that's not what that means... public static class DataStorage { public static void Store(object data) { //TODO: store the data } public static object Retrieve() { //TODO: load the data return new object(); } } It means that *whatever* your methods do (or values your static fields hold - but let's not confuse the issue with this just yet), they are only dependent on input parameters (and other static members - but let's not confuse the issue with this just yet).
Mkbundle also has licensing restrictions. I believe it is GPL so unless you are open sourcing you're app it probably won't work for you.
&gt; foreach(var subset in result) &gt; { &gt; Console.WriteLine(string.Join(",", subset.Select(clr =&gt; clr.color))); &gt; } Yes thank you! That works and is also much more clear to me written using Console.WriteLine. 
I'm just now getting back to this but I wanted to say thank you - this technique has made my life much easier =)
If you haven't, try posting your question to stack overflow as well. I don't know if this subreddit would be the most efficient place to get an answer.
Why don't you write a native runner around Mono in C/C++? http://www.mono-project.com/docs/advanced/embedding/
The task portion of your code is completely unnecessary in this context. Are you trying to use a task to learn about tasks? Otherwise it's some other bug in your code. A calling function will always block on a call to another function. bar() { WriteLine("1"); } foo() { bar(); WriteLine("2"); } baz() { foo(); WriteLine("3"); } If you call baz() you will always get 1 2 3 One really problematic thing is you seem to be modifying list1 as you are looping over it. You should probably create a list2 and after the loop do something like return list1.Concat(list2);
Sure! I reduced my # of Objects to just 4. This is the output I'm getting: 0 1 Object 1 1 5 1 2 Object 2 2 10 1 3 Object 3 3 60 1 3 Object 3 3 60 1 4 Object 4 4 80 1 4 Object 4 4 80 This is the output I expect: 0 1 Object 1 1 5 1 2 Object 2 2 10 0 3 Object 3 3 45 1 3 Object 3 3 60 0 4 Object 4 4 60 1 4 Object 4 4 80 The 2nd method is only receiving the SetID of Object 2 and passing a value of 20. So the results are coming back as all 1 and all multiplied by 20. 
Based on your code alone, your expected results do not match up. getA: list1 = 0:1,0:2,0:3,0:4,0:5 call to getB appended to list1 = 0:1,0:2,0:3,0:4,0:5,0:6,0:7,0:8,0:9,0:10 Now, you have 10 items in this list, which means when we move to the next item in list1 (0:2), you immediately set set ID = 1 so now list 1 is 0:1, 1:2, 0:3, etc. continuing this, you get 0:1, 1;2, 2:3, 3:4, 4:.... etc. So either your expected values are wrong or your code is wrong.
By using a Task, you're telling it to run in another thread. And then you're waiting on that thread to finish. But.. if you removed the Task stuff, you'd have a regular call that would run on your current thread. No need for to have a separate Wait call, and you'd get your data in order like you'd expect. 
Could you explain a little further the pattern you expect to be output? I see objectSetId flipping between 1 and 0, and am not sure why Objects 1 and 2 are only listed once, but Objects 3 and 4 appear twice. This strikes me as a problem solved by a couple foreach loops, each appending a new Example object to a list defined outside the loops, but the patterns (0,1,0,1) and (1,2,3,3,4,4) aren't clear to me...
I get too many redirects error.
I use Telerik's JustMock Lite so I have to use "wrappers" around static classes e.g., System.Configuration.ConfigurationManager. public interface IConfigurationManager { NameValueCollection AppSettings { get; } } public class ConfigurationManager : IConfigurationManager { public NameValueCollection AppSettings{ get { return System.Configuration.ConfigurationManager.AppSettings; } } } Then, in my test: IConfigurationManager _configurationManager = Mock.Create&lt;IConfigurationManager&gt;(); var appSettings = new NameValueCollection {{"SomeKey", "SomeValue"}}; Mock.Arrange(() =&gt; _configurationManager.AppSettings) .Returns(appSettings); I do the same for the System.IO.File class. Is there an easier way?
I'm just trying to learn the mechanics of lists and foreach and getting really mixed up by odd outcomes. I'm really pretty stumped. For instance say I change my getA method to contain a case statement like this: public List&lt;Example&gt; getA(int inputA, int inputB) { int i = 0; var list1 = exampleObject.Where(item =&gt; item.objectValue &lt;= 2).ToList(); List&lt;Example&gt; list3 = new List&lt;Example&gt;(); List&lt;Example&gt; list4 = new List&lt;Example&gt;(); foreach (var item in list1.ToList()) { item.objectSetID = i; item.result = inputA * item.objectValue; int valueToPass = inputB + item.result; switch( i ) { case 0: list3.AddRange(getB(valueToPass, 5)); break; case 1: list4.AddRange(getB(valueToPass, 10)); // this adds to range of list 4! break; } i++; } list1.AddRange(list3); // I'm adding list 3, not list 4 return list1; // I return list 1 there should be no setID of 10 in this list.. } Logically, to me this should mean case 0 gets met since i start with i = 0. I'm adding list3 to list1 and returning so I should see 5's in my results. I shouldn't see 10's because they are case 1 and added to list4, which I'm not adding to my range... this is the output: 0 1 Object 1 1 5 1 2 Object 2 2 10 10 3 Object 3 3 60 10 4 Object 4 4 80 Not only do I not get any 5's in my output how is it even possible to return 10's? I'm adding the results of case 1, which passes 10 to list4. I didn't add list4 to list1 so how does it get in there? I'm just confused. Is this a case of passing by values vs. references or do I need to set my lists null somehow between calls to the getB method? 
Heheh, I hope you aren't too frustrated by my lack of understanding but I'm happy to keep asking questions to help you figure this out. If it's not productive for you, no worries! If it's a recipe, what determines X? What determines valid combinations? In the full 10 object set, would you be hoping to match Object 1 with X of Object 3, X of Object 4 etc? When you ask for the list from example(int a, int b), what are you asking for? (ie in your original code, what do 5 and 10 represent?). I might guess that the 5 represents the number of Object Sets you'd like to end up with, but it seems like holding the Objects that are the "basis" for the recipe in the same list as the ingredients (?) is an odd approach, unless they're ingredients used by other "basis" Objects 
I think the easiest way is to purchase the full edition of JustMock (or Typemock), AFAIK both products only let you mock static methods in the full (paid) editions. 
If you make Example a struct instead of a class, do you get something closer to what you want? I think another problem you may be running into is that when you create your source list you are just referencing objects in the static list, not copies of those objects. So as you make a query and change them, when you make your second query you are getting references to objects that may have been modified. **Edit 1** But generally speaking your problem statement isn't very clear. I don't really understand what you are trying to accomplish. And for reference my suggestion to use a struct instead of a class is because they are passed by value and not by reference.
This looks great! I'll give it a go tonight and let you know. Thanks for taking the time mate.
Implying you should mock at all...
You need to set the HTML/CSS disabled property not the asp disabled property. You can do this using the styles properties of the asp check box control.
Sorry it's a day late. It took awhile to figure out the relationship between the is operator and pattern matching.
dont' thing there's a viable way to do this....to be honest your system-checking code should ideally be done oninit server-side rather than via javascript the checkbox is either enabled or it's not you COULD - i suppose - switch out the event handler depending on user privileges. One of them updates the DB, the other displays a dialogue saying "Nope!" and resets the CB. It's a nasty hack but the only way i can think of doing things your way. EDIT : i guess you could probably remove the disabled property in your javascript - change the value and then re-enable it .... but that's probably an even nastier hack than the one i already mentioned.
Whilst you are not wrong it would be nice to not require a C# installation on any platforms, if only for cleanliness.
Windows comes with .NET preinstalled, and your installer can list it as a prerequisite so it's installed automatically in the unlikely event that it is missing. 
Well sometimes you don't have a choice, which is why tools like Typemock and JustMock can exist. If you want to unit test legacy code, code you don't want to rewrite or code don't have any control over, mocking like this might be your only option. But for code you are writing from yourself, from scratch, I agree. It's much better to write it so that is can be unit tested in a more sane way.
No since bundling the mono version of all the libraries and runtime carries the same issue. There's no way around that requirement if you're using mono via bundling unless you buy a special licence from xamarin
I thought the licensing was only triggered in the event that one cannot update the mono version (Because its statically linked). If its dynamically linked and available in the same directory, eg we shipped the required mono libs with the native executable, then the licensing isn't an issue. Am I missing something there?
I see. Well this component of the video game will actually be open source, so this shouldn't be an issue.
Yea, I agree for things You can't Change of course... but if You can control it, it seems stupid to make testing it That complicated...
You might want to read up on some functional programming aspects, as there are quite a few new Features related to That coming in C#6. You can either use F#, if You want to stay with .NET, or You could look at others like Haskell and OCaml.
What is your end goal?
Basically learn as much as I can, but the idea is to focus on a more specific area, hence the options, since I feel like I could strengthen my knowledge on any of those right now
Well, I didn't make use of many of the C# 5 features (mostly async) but v6 looks very promising, I'm looking forward to it. I'd prefer staying with .NET for now, I've been considering F# because it implies an approach to functional programming while staying in the .NET ecosystem. The downside is that I'm pretty sure there is far more learning material using Haskell/OCaml than F#
Did anyone really expect that `+=` would be atomic?
Have you confirmed you can connect to that host and send. Maybe try [Sending an Email from Telnet](http://www.wikihow.com/Send-Email-Using-Telnet). If you can send by telnet using the same settings, your issue is with your powershell code, if not, the issue lies elsewhere (routing, firewalls, authentication, etc...)
Interlock.Increment() if you want that to be atomic
Right, never trust the client.
Atomic means it is indivisible, and we're talking on processor instruction level. Simple incrementing a memory location is not atomic - it consists of a read memory into register, increment register and write back into memory. So basically, you can assume practically no single line of code you write is atomic, unless you're writing in assembly or inferring what the compiler(s) is/are doing.
Thanks for the help, I'm double-checking all that right now.
Oh, yeah, it doesn't seem like anything would be, then. I mean even "x++;" has to find the address of x, read the value, add 1, then write the new value. And that's about the lowest overhead I could imagine for a single line. 
I'm a bit confused. Why can't you just launch the game, and have it do those checks in a nearly empty scene, before firing up any major pieces of the game?
Why would you assume any piece of code is atomic/threadsafe unless there are explicit mutex constructs around it? 
To me this seems more academic than something that I truly need to worry about. If it's thread safety I seek, I always lock around critical sections. The example with statics is nothing I would personally ever write.
A bunch of reasons. Stuff like making windows firewall rule changes requires admin elevation. It would be quite annoying to have that happen whilst in a fullscreen game. Unity3D runs on an extremely old version of Mono. Most modern C# libraries just don't work with it.
Nah man, I can vouch for "The Book of F#" being a good intro text and also "Programming F# 3.0". I'm a bit broke right now but am looking forward to purchasing "F# Deep Dives"
Saving
A bit expensive, bit it's reasonable for an upcoming book. I also saw The Book of F# as a good candidate, thanks for the recommendation
It is if you use Interlocked.Increment. 
You shouldn't be using locks across await calls. 
Are you referring to that "windows firewall: always allow access for this application" prompt? If so I don't see much of a problem in starting an empty scene, performing some checks, and leaving fullscreen mode to answer that prompt if necessary.
How many seconds are we talking about here, and just for the first launch of your game? Launching an empty Unity scene and leaving fullscreen mode does not take long at all. And for windows firewall isn't this just on first launch? I don't know how big your development team is but surely there are better features to spend this much time on. Or do you have a more serious example than the windows firewall whitelist? My initial alarm is fading.
Doesn't matter how many seconds it is. Its just not a good user experience. The major driver is the requirement of a modern mono (Unity3D is 3+ years behind) framework to run C# libraries that do things like UPnP Port Mapping and STUN/TURN for a smooth multiplayer experience.
You can't use lock in an async call. You can use an slim semaphore though http://msdn.microsoft.com/en-us/library/hh462723(v=vs.110).aspx
In IL it's 4 instructions.
It's not unexpected though, and the article states why.
I am not talking about await calls. I am yet to switch to .net 4.5 
I appear to have got it working for Linux. However machines without libgdiplus.so fail. How would you suggest I bundle these other libraries?
That's much more tricky. You have to compile libgdiplus from source, and modify the makefile so that it generates a static version of the library rather than a dynamically linked one, and then you can use -lgdiplus with cc to embed it. The alternative is to simply ship copies of libgdiplus.so/libgdiplus.dylib alongside the executable as separate files. Edit: Actually you might not have to do this, there's a libgdiplus-devel package for most systems that ship with a static version of the library. In which case just doing -lgdiplus (and adding libgdiplus.a) should sort you out.
As a quick test I added libgdiplus.so.0 to the same app directory and it found it, but then wanted a posix lib. Added that. Then finally it hurdled a stacktrace at me regarding some font functions that failed. I begin to understand why most game developers stay away from Linux. But I desperately want to make Linux a first class citizen. I was going to suggest that maybe it would be easier to force the user to install Mono 3.x. However I discovered tonight that some earlier distro's such as Ubuntu 12.x only install Mono 2.x by default. What a mess. Not sure how I should proceed at the moment.
I've just tried using -lgdiplus on one of my projects, went fine.
Can you show me the exact command you're using? I originally tried your cc arguments as above however it resulted in the following error: WFTOLauncherNative.c:1:39: fatal error: mono/metadata/mono-config.h: No such file or directory #include &lt;mono/metadata/mono-config.h&gt; ^ compilation terminated. So I instead I've been using the cc arguments provided by mkbundle: cc -lgdiplus -o WFTOLauncherNative.exe -Wall `pkg-config --cflags mono-2` WFTOLauncherNative.c `pkg-config --libs-only-L mono-2` -Wl,-Bstatic -lmono-2.0 -Wl,-Bdynamic `pkg-config --libs-only-l mono-2 | sed -e "s/\-lmono-2.0 //"` bundles.o /usr/lib/libmono-2.0.a Adding -lgdiplus as I did above appeared to do nothing and I haven't been able to find any documentation on this online either.
Did you install mono via your package manager, or compile from source? The exact command I use is the one I gave in my parent comment, aside from changing the assembly name its a copy-paste from my build script.
I know this doesn't answer your question, but you shouldn't put C# code in your razor templates. This code should go into your controller somewhere or into a separate emailer class. You can't test your code when you put it in a template and it breaks the separation of responsibilities in the MVC pattern.
Thank you, that worked :) 
Better do so soon. .NET 4 is hitting EOF pretty soon, so you'll have to be either current or on 3.5.
I'm sorry I'm not following. What exactly is about to happen to 4.0?
I'll post something on InfoQ Monday, but basically Microsoft is going to stop supporting it in 2015 or 2016. I need to check the date, but once that hits no more security patches, etc. 3.5 is OS bound and should have a longer lifespan, but I still need to look up the exact end date for the article.
Seems to me 4.0 apps should be able to execute on the latest 4.5.x build need be, without recompile.
There are a few breaking changes due to obscure security issues, but I've never seen them actually affect software in the wild.
&gt; We replaced our boilerplate code with a Lazy&lt;string&gt; instance. When creating this instance, we provide it with a lambda expression that will be used to compute the return value. Note that the lambda expression is not executed when the instance is created, it is only stored for later use. I think You meant `Lazy&lt;int&gt;` :D Nice Article :)
Good to know about. Thanks!
Great. I've been struggling to get away from my powershell crutch and get back to C# where everyone else plays... This is like waving crack in my face.
It is cool though I would have preferred that the library used the official verb list instead of custom ones.
`Lazy&lt;T&gt;` is thread-safe, your solution is not. It could be called multiple times, depending on `Calculate()` potentially expensive.
The title and the content differ a lot. You're asking about a general opinion of Entity Framework? Or how to solve your insertion issue? What exactly is your issue? Do your many-to-many relationships have a payload, or is it without payload? If it's without any payload then you won't get to access the join-table directly. Just add an element to the collection on one of the sides and EF will take care of it.
I've yet to find a situation it hasn't handled, complex or not. Whether it's worth it or whether you should use it is another story. But it will generate the code for even a super complex db operation.
Thanks. Do you have a link to an example so I can see it? I'm interested the general opinion of the Entity Framework. I was just using my issue with the many-to-many insertions as an example.
Like all ORMs, it is only appropriate for basic CRUD operations where performance isn't important. EDIT: Well I guess you could use EF in conjunction with stored procs. But at that point you just have a slow, clumsy version of auto-mapper. 
Thanks for that.
Ha! I've got a work queue table. I need to "claim" the ten oldest records by changing the AssignedTo column from null to a user. Finding these ten records, updating them, and returning them to the client is a single statement in SQL. How would you do it in EF? Query and then update? No, that's a race condition. Open an transaction, query, and then update? Say hello to a dead lock. Does EF even have the ability to acquire write locks on a set of records?
19 votes here. Only 1 star. Grim!
Ha! Use the right tool for the job. Your requirement clearly is no job for an ORM.
That's my objection to ORMs. Stuff that I consider to be fairly basic is damn near impossible with crappy pseudo-languages like C# or Java. Give me a real programming language like T-SQL any day.
Wow, this is really amazing shit.
Or Python + SQL Alchemy. Never used it myself, but I've never won a game of "bet you can't do this" with people who do.
Lazy is optionally thread-safe. Gotta study those settings very carefully or you might have an unpleasant surprise. Though now I'm wondering what the cost is for all of that internal locking. 
If you are using a mock, then it isn't a real unit test. 
&gt; Use the right tool for the job. 
To elaborate in this specific case you can use functions or stored procs with EF, and it generates a nice wrapper. You can also write raw SQL queries with EF, so there are a few options here. 
My past employer used nHibernate, my current employer uses Entity Framework. I dislike both for different reasons, but might use either under some circumstances. **EF Pros:** * It's easier to set up than nHibernate. * EF plays nicely with web applications because you can easily and quickly instantiate a separate context per user action, while nHibernate takes a while to instantiate so you really need to only have one connection per application, which will crash if any user action causes a database problem. **EF Cons:** * We are doing database-first, and we find that this is occasionally flaky, and easy to screw up. My impression, having worked with it since January, is that Microsoft designed it for entity-first, and then glommed on database-first as kind of an afterthought, and doesn't properly support database-first. If I had been around at the time the company chose to go with EF, and had known this, I would not have approved use of EF because of this. nHibernate does not have this problem, it handles database-first, model-first, or "you manually set up both the database and the entities and map them yourself", all smoothly. * EF doesn't handle "you manually set up both the database and the entities and map them yourself" at all. You can't do it. That's why my previous employer didn't go with EF. * EF is... touchy. I've learned that I can only make modifications to the EDMX if the solution it's part of is the only solution I've loaded in Visual Studio since I fired it up. If I started with one solution, then changed to another, it's no longer safe to edit EDMX files as they *will* get screwed up. Also, it's only safe to edit an EDMX immediately after I've compiled the solution without errors, because when I save the EDMX it will attempt to recompile, and if there are any errors the EDMX will become unfixably screwed up, and the only way to resolve it is to roll back all changes to the EF project in our version control system. So, I've had to become excessively careful about making changes to the entities, and I'm considering banning the junior developers entirely from making such changes. * When EF has an error, the actual error message you receive might or might not have anything to do with what went wrong. Of course, nHibernate has the same problem. * EF can't handle a database model that has a large number of tables. We pointed it at a database that has, if I recall correctly, about 450 tables, and had it generate a model. It churned for a while and produced entities, and in a strict technical sense, it works... but it takes FOREVER to instantiate the context before it will perform a database operation. We can't legitimately have web users wait for several *minutes* for EF to instantiate the context before it actually fetches their results. So, we're having to set up task-specific contexts that only have subsets of our data model, because there is apparently no solution to this. This is a pain in the ass, and again, if I'd been around when the company chose EF, I would have rejected EF as a choice for this reason too. * EF syntax for loading and saving and updating is a bit more verbose than nHibernate. In EF syntax there's a difference between saving a new object and updating an existing one, EF doesn't figure that out for you but nHibernate does, which means your logic has to pay attention to the difference if you're using EF. * EF seems to fail to deal well with re-saving objects that contain a list of other objects. I have to make my code loop through the list, examine each to determine if it's a save or update, and do the right thing. If I just tell it to update the parent object, EF doesn't properly save all the items in the contained list. This is yet another thing that would make me reject EF. **Advice** * When dealing with many-to-many relationships in EF, I give the linking table an identity primary key column, and make it an entity itself. So, if I want to join table foo to table bar as a many to many, I make a table foo_to_bar and add that to EF. Each foo and each bar has a collection of foo_to_bars. This isn't as bad as you think to deal with, because you can just use LINQ to access the list of objects you really want trivially, or you can even add a property to fetch it for you if desired. This also has the advantage that if I want to edit the linkages, I can use EF to directly edit the contents of foo_to_bar and be certain about what it's doing. * If you have the ability to choose the object persistence of your desire, don't go with EF or nHibernate, go with RavenDB. You need to think more about how you're going to structure your objects to deal well with the database, but once you have done so, it's a lot easier.
Ever try to call a stored proc that looks like this from EF? If (expression) SELECT A, B From X Else SELECT A, B From Y Doesn't work unless you explicitly map an object to it. *** Ever try to call a stored proc using async/await? Have fun rewriting the generated code by hand to call the right version. *** What do I write? myDispatcher.Procedure(name, args).AsModelCollection&lt;SomeClass&gt;().ExecAsync(); That's it. No EDMX models to fight with. No code generator that almost does the right thing. Just one line of code and the class I want it to populate. And that's assuming that I actually want model objects. If I'm just doing straight DTO work then I use... myDispatcher.Procedure(name, args).As[ Table | XML | JSON ]().ExecAsync(); 
When the apprentice asked the master if he should use a screw or a nail the master answered, "Use the right tool for the job." The apprentice picked up a hammer and stuck a might blow upon the master's head. As he looked at his hammer, now slick with blood, he sighed and said, "It seems that I've found the right tool."
Ive used it.. Dont care for it. With the push to decouple business logic and data operations, i find things like EF end up doing the exact opposite (despite best intentions). Not to mention, finding and fixing performance related issues can be a challenge. Basic CRUD work is fine, but if you find that you are using the entities all over the place, look out for tight coupling. Or if you find that getting the data you need is some mental gymnastics of lambda methods accessing iterators over some object arrays which contain collections of everything and anything, requiring prayers to the gods and an occasional chicken sacrifice - as opposed to a quick stored procedure call - then you may want to rethink the ORM. I just dont like a lot of baggage between me and the data Im trying to get to. I know many DBAs hate (and will even ban) the use of such things (ask them to run a profiler on some of the generated SQL code and you'll see why). I guess its not fair to blame the framework, just perhaps the improper usage of it.
I don't do database work, really, but we're using Entity 5.5 on my project at work. It has made generation of data layer code very simple and I love it. But again, I didn't write any of the stored procedures, we have someone else on the team handling most of that stuff. He seems annoyed by Entity at times and loves it at others. IIRC, we've only run into an issue with it once. It apparently doesn't support taking in a list of items/objects. So if I have a list of entities that I want to send back to the database, I have to call the stored proc one time for each item in the list. There are hacky ways around that, though. Overall, our team has been happy with it. And it has made the rewrite of our application so much easier than it would otherwise be.
In fact, Lazy is optionally not thread-safe, it is thread-safe by default. The cost for the internal locking is most likely not higher than the cost of running an expensive operation more than once, although this of course depends on how expensive the operation is.
You are correct, I corrected the typo. Thanks for the positive feedback!
Nor is the other lazy-loading technique in the post. Thread-safe would be... private readonly object calculatedSyncRoot = new object(); private int? calculated; public int Result { get { if (calculated == null) lock (calculatedSyncRoot) if (calculated == null) calculated = Calculate(); return calculated.GetValueOrDefault(); } } Lazy&lt;T&gt; has the drawback of only calling static members. For example, if Calculate() is an instance method, Lazy&lt;T&gt; won't be able to access it from a field initializer. You'd have to initialize calculated to an instance of Lazy&lt;T&gt; in the constructors. That's no fun. There should be another Lazy class with the following semantics but with the performance sorcery of System.Lazy&lt;T&gt;... class Lazy&lt;TContainingType, TValue&gt; { private readonly Func&lt;TContainingType, TValue&gt; valueFactory; public Lazy(Func&lt;TContainingType, TValue&gt; valueFactory) { this.valueFactory = valueFactory; } private readonly object syncRoot = new object(); private bool isLoaded; private TValue value; public TValue GetValue(TContainingType @this) { if (!isLoaded) lock (syncRoot) if (!isLoaded) { value = valueFactory(@this); isLoaded = true; } return value; } } Then you could do this... class Calculator { private int Calculate() { return 42 * this.someOtherMember; } private readonly Lazy&lt;Calculator, int&gt; calculated = new Lazy&lt;Calculator, int&gt;(x =&gt; x.Calculate()); public int Result { get { return calculated.GetValue(this); } } }
&gt; EF plays nicely with web applications because you can easily and quickly instantiate a separate context per user action, while nHibernate takes a while to instantiate so you really need to only have one connection per application, which will crash if any user action causes a database problem. Huh? This is not true at all. NHibernate sessions works pretty much like EF contexts. They are cheap to instantiate and you would typically use one per web request.
In practice, our experience was that they were not cheap to instantiate. It's possible that this was because of the quantity of classes we had mapped. 
&gt; EF doesn't handle "you manually set up both the database and the entities and map them yourself" This is flat out wrong. We use code first and map it to our database without EF's scaffolding. Since we can't modify the DB schema in production, we independently generate SQL scripts that we hand off to a DBA. Once it was set up, we've not had any issues with mapping. I believe we started off with Entity Framework Power Tools' "Reverse engineer code first", which generated entity classes and a separate mapping class using [fluent configuration](http://msdn.microsoft.com/en-us/data/jj591617.aspx). The pieces are all hooked up in the context. &gt; So, we're having to set up task-specific contexts That's actually the approach that was recommended to us by some Microsoft EF engineers my employer brought in for training. Are you *really* using all 450 tables in a single calculation? If we could re-do our own architecture, I'd probably set up a common library with the models+mappings for every table in our database and create a new context class in each project. That context will configure only the mappings that it needs (one line of code each) while the mappings can be managed independently.
&gt; I've yet to find a situation it hasn't handled How about inserting 40,000 records at once? Haha. Batch loading is probably not a good scenario for ORMs.
Its true that the SessionFactory is expensive to instantiate and should only be done once but it's false that NHibernate is expensive since the Session Context is as inexpensive as EF's DbContext
What's wrong with having a race condition if you know how to detect it? Read up on optimistic vs pessimistic concurrency. EF has several ways of handling optimistic concurrency such as rowversion column.
I personally love EF, and use it for any project where it fits. It has a strange learning curve, as you can get up and running very quickly, but it will take a long time to learn all the nuances and capabilities of it. In terms of limitations and problems, the only one that's ever been an issue for me is bulk inserts, but I just used a separate library that manages that and got away without having to write any DB access code. Pretty much every other problem i've had with it has been a case of me just needing to learn a little more about the framework. The question you have to ask is do you want to invest the time in writing custom DB access code or just learn to extend EF. If you work DB first, learn a little about how to manipulate the .tt files that EF uses, you can use them to do some really useful stuff.
There is just so much wrong in this post... * We are doing database-first, and we find that this is occasionally flaky, and easy to screw up. My impression, having worked with it since January, is that Microsoft designed it for entity-first, and then glommed on database-first as kind of an afterthought, and doesn't properly support database-first. If I had been around at the time the company chose to go with EF, and had known this, I would not have approved use of EF because of this. nHibernate does not have this problem, it handles database-first, model-first, or "you manually set up both the database and the entities and map them yourself", all smoothly. ***** Database first was actually designed before code first. EDMX designer is pretty weak over all though. * EF doesn't handle "you manually set up both the database and the entities and map them yourself" at all. You can't do it. That's why my previous employer didn't go with EF. ***** Yes it does, it's how I've used EF from day one. And it's very very good at it. * EF is... touchy. I've learned that I can only make modifications to the EDMX if the solution it's part of is the only solution I've loaded in Visual Studio since I fired it up. If I started with one solution, then changed to another, it's no longer safe to edit EDMX files as they *will* get screwed up. Also, it's only safe to edit an EDMX immediately after I've compiled the solution without errors, because when I save the EDMX it will attempt to recompile, and if there are any errors the EDMX will become unfixably screwed up, and the only way to resolve it is to roll back all changes to the EF project in our version control system. So, I've had to become excessively careful about making changes to the entities, and I'm considering banning the junior developers entirely from making such changes. **** Sounds like your manually editing the EDMX or have manual changes in it, I. that case yes this will get screwed up as it's not meant for you to tinker with, switch to code first and be done with it. * When EF has an error, the actual error message you receive might or might not have anything to do with what went wrong. Of course, nHibernate has the same problem. **** Inner -&gt; Inner -&gt; Inner Exception garbage, yep. * EF can't handle a database model that has a large number of tables. We pointed it at a database that has, if I recall correctly, about 450 tables, and had it generate a model. It churned for a while and produced entities, and in a strict technical sense, it works... but it takes FOREVER to instantiate the context before it will perform a database operation. We can't legitimately have web users wait for several *minutes* for EF to instantiate the context before it actually fetches their results. So, we're having to set up task-specific contexts that only have subsets of our data model, because there is apparently no solution to this. This is a pain in the ass, and again, if I'd been around when the company chose EF, I would have rejected EF as a choice for this reason too. ******What you are experiencing here is schema validation with the EDMX, I'm not sure you can disable it bit you might be able too, also maybe you should segment your application. I doubt you need to initialize all 450 tables for every request. * EF syntax for loading and saving and updating is a bit more verbose than nHibernate. In EF syntax there's a difference between saving a new object and updating an existing one, EF doesn't figure that out for you but nHibernate does, which means your logic has to pay attention to the difference if you're using EF. **** There's a switch for that, you can either send full updates or only what has changes defaults to full updates. * EF seems to fail to deal well with re-saving objects that contain a list of other objects. I have to make my code loop through the list, examine each to determine if it's a save or update, and do the right thing. If I just tell it to update the parent object, EF doesn't properly save all the items in the contained list. This is yet another thing that would make me reject EF. **** possible issue with disconnected objects or the objects are t flagged as modified. EF will save any modified entity within its unit of work. 
Hi! I remember you from a few weeks ago; I answered another parallelism question back then. You'll want to partition your data. [Here's an article](http://msdn.microsoft.com/en-us/library/dd997411(v=vs.110).aspx ) which briefly describes it along with the use if parallel linq (like I mentioned in the post from a few weeks ago). I'm traveling at the moment, but when I'm back I can give you an example if you'd like -- just reply and let me know.
Yeah, having done it both ways reverse-code-first is the way to go with Entity Framework. 
To you title question, that depends on how much you care about performance. If you care, write SQL. If you don't, I would use Linq. NHibernate and Entity are both very slow according to some recent benchmarks posted either here or on /r/programming. Note, however, that you need to use care to avoid creating race conditions with any ORM (or any select/update in SQL). Too often, I encounter shit like this: var obj = getSomethingWithOrm(someId); obj.counter++; obj.save(); Where the SQL would completely avoid it: update mytable set counter=counter+1 where id = someId
&gt; Database first was actually designed before code first. EDMX designer is pretty weak over all though. I said that was my *impression*. The reasons I got this impression are that it seems to work better code first, and that *every single one* of Microsoft's EF how-to examples is code first. &gt; Sounds like your manually editing the EDMX or have manual changes in it, I. that case yes this will get screwed up as it's not meant for you to tinker with, switch to code first and be done with it. We're not manually editing EDMX files, we use the visual editor, and the visual editor is *very skilled* at screwing up the EDMX files for us. One of my complaints about EF is that the EDMX files are so fantastically much more complicated than the equivalent mappings in Fluent nHibernate - enough so that I seriously can't be bothered to learn to edit them manually. Fluent nHibernate uses very short, easy to understand class files to perform the mappings. Switching to code first is *not an option*, because we have a large existing data model. &gt; Inner -&gt; Inner -&gt; Inner Exception garbage, yep. I was thinking more that sometimes the exception, when I finally dig through several levels of "inner", really doesn't say anything at all about what the programmer actually did wrong. For example, I saw one in which the programmer had forgotten to add a primary key column to the database table and was trying to add it to the EDMX. The error that appeared said there were compilation errors, but *there weren't*, there was no actual exception or compilation error, it just didn't add and screwed up the EDMX so we had to rollback from version control. &gt; What you are experiencing here is schema validation with the EDMX, I'm not sure you can disable it bit you might be able too, also maybe you should segment your application. I doubt you need to initialize all 450 tables for every request. Yes, I understand that completely. Yes, segmenting the application is what everyone recommends. My point is, we *shouldn't have to* disable schema validation or segment in order to get timely response with a large schema. Every *other* ORM I've worked with - and I'll mention that I've also written several ORMs over the years - has been able to deal with that number of tables in a schema in a timely manner. (For example, nHibernate validates the mappings for entities as you call on them so the validation occurs but is spread out.) Why does EF have to be so slow? We have a large and relatively highly integrated schema - why should we have to be jumping through the hoops of segmenting it? That's a waste of programmer time. &gt; There's a switch for that, you can either send full updates or only what has changes defaults to full updates. I think you may have misunderstood what I said, but I'll need to have a look at my code to refresh my memory of the syntax in question to be more specific. &gt; possible issue with disconnected objects or the objects are t flagged as modified. EF will save any modified entity within its unit of work. I have a foo. It has a list of bars. I pulled the foo out of the database, changed some bars, removed one, added two more. I tell EF to update foo. What I want to have happen is, it looks at all the list of bars and does the right thing, just like nHibernate would. What actually happens is, the changed bars don't get changed, the removed bars don't get removed, and the new bars don't get added. I have to iterate over the list and do the right thing... and I have to know to remove the one that was removed. I have observed this happening in front of me, I'm quite certain it behaves that way. 
Spend 4 hours digging half a ditch. Then toss a coin. Heads, you finish the job. Tails, you fill it back in and try again tomorrow. As a start I intend to have three instances of my application running against the server, one thread each. Already I see more than 50% of the calls deadlocking. That means a lot of wasted work being done on the database. All because EF can't add "with (UPDLOCK)" to a query. 
&gt; Database first was actually designed before code first. EDMX designer is pretty weak over all though. It was still an afterthought. Originally, the way you are supposed to use EF was model first. Database first was just a hack to get the initial model. For a long time you couldn't even update the model from the database without a third-party tool.
The sad part is that the SQL it generates isn't the problem. I'm actually CPU-bound on adding records to the damn in-memory collection.
According to some benchmarks, Dapper is actually faster than hand-rolled ADO.NET code. Not sure why, but it is something I intend to investigate.
I doubt that there is a way to properly use it. EF, and ORMs in general, are fundamentally based around naive data access patterns.
&gt;an inherent limit to the performance of async/await. I'd look at the task scheduler itself than async/await per se, the latter is just syntax sugar. The default task scheduler queues and executes continuations against threadpool threads. While the threadpool is ok, it isn't magical, it can be very slow to grow. It especially doesn't predict non-uniform work very well - e.g. mixing CPU and I/O intensive tasks can cause it both bottleneck as well as explosively grow. (I've debugged a good number of the latter in production servers) Personally I'd start with looking at a different task scheduler than default. I'd also start by dividing your workloads onto different schedulers. Long running IO vs. CPU intensive etc.
That explains it. &gt; With .NET Framework 4, the default setting for maxConcurrentRequestsPerCPU is 5000 which is a very large number and therefore will allow plenty of asynchronous requests to execute concurrently. For more information, see &lt;applicationPool&gt; Element (Web Settings) (http://go.microsoft.com/fwlink/?LinkID=205339). ref: http://msdn.microsoft.com/en-us/library/ee377050.aspx Sounds like he just needs to increase that value. (Assuming the back-end doing the I/O processing can handle it of course.)
If he is using async/await correctly, there should be no reason for the thread-pool to grow for I/O bound tasks.
That's my whole point. Even for a simple case like two operations inside a transaction, EF isn't the right tool.
You're simply wrong. I'll just leave it at that.
Agree - pure IO won't grow the pool, however you will almost certainly will have CPU intensive task as a continuation on the IO task. That continuation will occur on the thread pool thread unless override the default scheduler. You do that enough - 500rps is a healthy number, it'll grow the pool. I've picked apart several problems where the threadpool was rapidly passing thru &gt;10K threads - even a on a big machine - that's crippling. The dump showed a gamut of actions in process - IO, intensive parsing on an async response. There were over 800K tasks in the queue when I dumped the process. In reality many of those CPU intensive continuation tasks should have been pushed onto another task scheduler and it's own much smaller (#of CPUs) pool of threads. Like I said - the default scheduler ain't magic. It's average - it can't guess what your scheduling needs are, yet it's expected to be great for a mix of loads. Unfortunately the docs are scant at best, and the CLR team chose to ship alternate schedulers on Codeplex than in the box. (I suspect supportability was the issue)
Ok, how about an easier one. UPDATE Foo OUTPUT Inserted.A SET A = A + 1 WHERE B = 10 Show how you would do that in EF.
[Here's an article](http://msdn.microsoft.com/en-us/library/dd997411(v=vs.110\).aspx ) fixed that link
You don't want to split your URLs evenly amongst the available threads because if a thread finishes its allotment before the others it will end and be a wasted resource. /u/davidwhitney has it right: have your threads pop URLS from a concurrent queue
Dapper + SQL Bulk Extensions for bulk insert,update,delete is an insane speed demon
EF is TERRIBLE at bulk inserts, &amp; updates. It's performance when used on a simple system that inserts a LOT of data is just abysmal. In cases where you deal with a lot of objects, you don't necessarily want all those objects tracked and loaded in mem, so now you start turning off object tracking, using extensions to bypass some of the performance hits, adding something like SQL Bulk Extensions to handle other things, and eventually you've got a mismash system where EF isn't even doing it's intended job. I know a lot of guys that like EF, I am not one of them at all. I deal with huge datasets, performance is critical in my domain, and to do that I use a mix of simple tools to do each particular job correctly - querying is one tool, insert, update is another, and delete is a whole different topic for me (tomb-stoning). Use the right tool for the job, if EF meets your needs, great - but it's a tool not suited for every job. 
That's basically it. Fork a project you're interested in and start committing to your repo and send the original author pull requests. If they're interested in collaboration and find your contributions useful, they'll merge them in.
I would start by setting if there are any open issues to get started. It helps guide you and gives you a chance to see if you like how the code is organized, if the code style is compatible, and if you can live with the main persons quirks. Most of the time when I've gotten merge requests, it was to scratch an itch and then they moved on. Overall, be polite and start small.
Why would I want to do that? EF's auto-mapper is slower and less capable than the alternatives. And then there is the cost for the context itself, which I hear can become quite high when you have a large number of tables.
I see the crux of the problem. I asked you why would I want to use EF for raw SQL calls and you come back with a justification for the SQL. The very idea of not using an ORM is so alien to you that you can't even understand a question that asks you to justify its use.
Yeah show people the code. If your Pull requests are ignored, move on to another project. If they are rejected, make them good enough to be accepted. Once you prove yourself, you can have conversations about long term strategic changes.
Yeah, mostly it. Please don't go around pushing code. Discuss your changes before doing them, it's good for avoiding wasting your time, and also the time of the owner of the project. Unless you have very occasional fixes, of course. If you're doing a small bug fix, just go ahead and send the pull request :)
Thanks man, I'll look into it. :)
I'll create some sort of logic to make sure you can't put in a ridiculous score. :P Thanks!
10 stars now :D
There's always the option to record the moves and then check if it'd work. But depending on your game, that may or may not be hard to do.
Switching what to work on costs *some* time too. You can't straight up multiply.
You dequeue from a queue, you pop from a stack :)
I know. I **thought** I was being **funny**
Hey, just making it clear for the less experienced! :)
I disagree with this as a general statement. I review code as one of my primary job functions and will reject a pull request that doesn't follow standards, implements something in a way that isn't maintainable, doesn't have tests, isn't properly commented or documented. Those are all things that can easily be changed but they start with it not being accepted. It depend on the reason more than anything else. I love pull requests, but I don't fell it is the maintainers job to do all that for a request. I would second talking to the maintainer before starting, but I do consider an issue to be acceptable also.
I think you misunderstand me when I talk about strategic changes. If your making a simple tactical change, like fixing an obvious bug or implementing a small feature, yes add tests, follow coding standards, make your code maintainable and all that. Doing those things in a code base with standards, tests, etc is tactical. By strategic change I mean large features, implementing unit tests in code that has no unit tests, etc.
agreed, well said
&gt; You seem to be saying that you simultaneously do and don't use EF to generate your classes for you. 1. It wasn't Entity Framework itself, it was a VS code-generation plugin. 2. Once the existing set of tables (5-6, it was a small, new project) was generated, we never had to reach for the tool again. New tables are mapped more or less by copying an existing model/mapping and changing it to fit the table.
I looked through some of your repositories and so far all of them lacked unit tests. You do not value quality yourself.
This... so much this...
You can use stored procs and views with entity framework. You can even write direct sql if you want.
Im aware... but it does "beg the question"...if you can do SPs and direct SQL, why bother with EF at all? 
Not true, async IO is done using IO completion ports which are non-blocking. 
I have servers handling well over 7k requests/sec, so I doubt it's the async/await pattern. I'd suggest using perf/wpr to take a look at lock contention and context switching. Long-poll IO should be consuming barely any resources at all. 
You can always implement them and make a pull request.
Okay. I've finally managed to build a native executable including libgdiplus! Thanks PhonicUK! One more thing I'm hoping you can provide insight on: I built this executable on Ubuntu 14.04. It does not appear to work on Ubuntu 12.04 because: ./WFTOLauncherNative.exe: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.17' not found (required by ./WFTOLauncherNative.exe) I guess that makes sense: libc versions are different in older Linux distro's. But what do I do here? Google says its not recommended to statically link this lib, and I don't have a static .a lib to link anyway. Thoughts?
ConcurrentBag would be a good choice.
The current implementation just turns it into a thread if you specify that.
It's worth pointing out that Lazy's intermediate locking mode, LazyThreadSafetyMode.PublicationOnly, is the best performant thread safe option. It doesn't use locks, so it can't deadlock. It *may* call the initializer twice, just as is the case with e.g. ConcurrentDictionary's GetOrAdd, AddOrUpdate and similar.
Build a VM with an older version of glib? Something like CentOS 5
Without mocking, how do you unit test a method that calls out to the database or hits the disk? I'd say the opposite is true, if you want to do unit testing (i.e. test 1 unit of your code at a time), you need to have mocking, so that you can mock out all the dependencies that the single unit relies on.
Why improve something that not even the owner cares about?
Many projects prefer if you first create a GitHub issue for whatever it is you want to do, and the perhaps the maintainer(s) will tell you that they wont accept this feature anyways, or that its already done in some branch, or: &gt; What takes you hours might take me minutes simply because I have both domain knowledge and a perverse knowledge of Vim script so vast that many would consider it a symptom of mental illness. ([Tim Pope](https://github.com/tpope/vim-pathogen/blob/91e6378908721d20514bbe5d18d292a0a15faf0c/README.markdown#contributing)) (Having an issue number also makes it easier to track progress on the issue.)
As others have said: 1. file an issue against the project you're interested in contributing to 2. let the maintainer(s) know that you're interested in contributing that feature 3. ask if they have any comments or suggestions on how to go about doing it (sometimes devs have certain ways they envision a feature working and getting their input shows you want to work *with* them). 4. implement said feature, doing your best to keep with the coding style of the project 5. If the project has unit tests, try to add a unit test for whatever feature you just added (if you don't know how it should be done, ask) 6. send them a pull request Once you've established yourself as someone who submits reasonably good patches frequently enough, often maintainers will give you direct commit access. Edit: BTW, I'd love to get contributors to my [MimeKit](https://github.com/jstedfast/MimeKit) and [MailKit](https://github.com/jstedfast/MailKit) projects ;-)
IMHO, if you want third parties to contribute to your project, you really need to have unit tests because any third party that might be interested in contributing to your project will need a way to make sure that she didn't break anything. If you are just working on a project to scratch your own itch, not having unit tests is fine. I guess what I'm saying is that not having unit tests just doesn't scale very well once you start introducing third parties into the development of the project. When you have a single person or company, sure, they can do manual testing, but third party contributors that might just want to add a feature or two before disappearing into the void, manual testing is not really an option because they couldn't possibly know your manual testing procedures (and even if they did, manual testing procedures are probably laborious for any sizable project). On the other hand, if the project has a decent testing framework, they can probably figure out how to add at least some basic unit tests for the feature they just added, run the entire suite of unit tests and figure out if they broke anything. This is even more important if I'm just coming along to fix a bug in existing code.
Dapper uses IL generation. 
While WebClient still exists, the recommended library to use is [HttpClient](https://www.nuget.org/packages/Microsoft.Net.Http). It also has a method to read the content as a string.
If they're not, you still have a fork going and you can continue adding your own code to it.
Oh yeah, I completely agree. It can be done without but it is harder. Most of the OSS projects I've contributed didn't have unit tests. They had someone testing my code before accepting it. Unit tests just make it a *lot* easier to contribute code and reduce the back-and-forth cycles. I've also found that I have to remember a lot less of my code if I have tests to prove *I* didn't break something. That is why I'm behind tests now. :) Also, with a project without tests, it puts more work on the maintainer since they have to do the manual testing. I honestly wouldn't expect a contributor to do a full regression on their bug. Even if they did, I'd have to do a full test myself because verification is important. Tests means that I can be [lazy](http://threevirtues.com/) and not do as much myself. So, in that case, tests make me as a maintainer more comfortable accepting changes.
I've found the best mix between ease-of-development of EF and fast performance is to use EF for most queries (you can tune EF queries quite well with AsNoTracking() and optimize joins with .Include) and single object inserts/updates/delete. EF only gets really slow when you try to make a lot of updates to many different objects at once and rely on the change tracking to sort it out. Or trying to insert many rows (each one a separate DB trip). As soon as you need to bulk insert or run a very complex series of queries that would involve multiple trips to the DB with EF, then write a stored procedure and hook it up with Dapper or Insight Database (this library makes it very easy to wire up stored procs effortlessly). I also encourage designing your system in such a way so that you can replace slow EF with fast Dapper/Insight stored proc calls without impact to your main system. Also be sure to install MiniProfiler which allows you to very effortlessly analyze your query performances.
Agreed, I meant (and edited my comment as such) ignored, not rejected pull requests.
What is the "unit of functionality" you are testing when half of said unit doesn't actually exist?
In theory it can't generate IL that's faster than hand-rolled map code in C#. So there must be something more in the way its doing it such as the API choices.
The last time I wanted to use MIME related stuff, I needed a .eml reader. I don't know if MimeKit can read eml files but on nuget.org your project doesn't show for a search of "eml". Also I've seen you convinced the creator of the first project on the search result to use your library, it is certainly a good idea. 
Yep, it handles the .eml format (which is just raw MIME). I'll add it to the keywords the next time I upload a package, though, so it shows up when you search for eml (thanks!). Btw, what did you search for on nuget.org? If I search for "mimekit", it just shows MimeKit, MimeKitLite (which is just MimeKit w/o the crypto) and MailKit (which is my other library).
I searched for "eml" as I said. 
Its probably straightforward enough, im trying to figure out the minutes used for each month. The integers in the array aren't given to you. 
Can you provide more details about what you are having trouble with?
Yes, how to actually figure out how to do it. Am I trying to figure out the minutes from the array or the monthly cost? I'm a novice and programming really isn't my are. Its a required module of my computing course
Based on your picture, I would assume that they are providing the array/initial values for your program to read from. In a live exam, I would ask the professor because it seems ambiguous. If you're doing this for practice, I would suggest you make your program read in some values from the user and then do the calculations as requested. Sorry if that's not helpful. It seems like your instructions are missing some information.
Take the arrays and total up the minutes, then do the monthly calculations both ways and spit out the outputs. This is pretty basic stuff, if you have having an exact issue, ask away. 
* 1 mark for each valid table input --&gt; I guess that you may select minutes yourself, however the remaining cells must be consistent. Try to recreate the result form the row that is provided. How the program calculates the resulting values using the input(minutes) and parameters from: Tariff A and B.
I agree, the instructions aren't very clear and don't lay out exactly what is needed. If I received instructions like this on the job, I would have to go back to the customer for clarification. From what I take from the requirement, you have to take the users input 5 times and calculate the total for each tariff based upon their input. * Is 5 month total a running total (it's not stated)? If it's not in the contract (not stated), it doesn't get implemented...
One small problem I noticed was your rather intimidating READMEs. Especially on MimeKit, a giant list of RFC's probably shouldn't be your introduction. Might be time to start shifting some of that to either the Wiki or make your own small docs site with GitHub pages.
Either that, or the input values are elsewhere on the page (or a different page) and OP didn't capture them in their shot.
You can talk to reporters on news sites. For example, there's this asshole going by the name of 'grauenwolf' that runs InfoQ's .NET desk. I hear he hangs around reddit sometimes while he is waiting for indexes to rebuild.
&gt; Take the arrays and total up the minutes No. For example, take tariff A. If you use 250 minutes each of the 5 months ( = 1250 minutes), you'll come up to 8/month * 5 months = 40. But if you talk 0 minutes the first 4 months, then talk 1250 the last month, you'll pay 8/month * 5 months + 1000 minutes * 0.1/minute = 40 + 100 = 140.
haha, nice! I'll keep you in mind and give you a poke. I hadn't even thought of that since I'm not a business or anything. Thanks! 
That said, I love the examples and introduction to the library. I thought they were well written and very clear. Good job. ... I just haven't needed MIME parsing for a while.
"After January 12 of 2016".... isn't that near... And .NET 4.5.2 is backwards compatible to 4.0, 4.5 and 4.5.1, isn't it?
Thanks! I appreciate that... I spent a lot of time writing those docs ;-) 