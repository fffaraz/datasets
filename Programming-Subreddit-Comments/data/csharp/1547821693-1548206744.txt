The standard allows for intermediate results of floating point computations to be executed with increased precision (because x86 FPU has 80 bit floats). However the new JIT emits only SSE instructions to my knowledge, which don‚Äôt have this behaviour. 
The outer lock is the one with smaller ID of both locks, and the inner is the one with bigger ID of both logs. So: var smallest = [acc1.Id](https://acc1.Id) &lt; [acc2.Id](https://acc2.Id) ? acc1 : acc2;//smallest Id account var biggest = [acc1.Id](https://acc1.Id) &lt; [acc2.Id](https://acc2.Id) ? acc2 : acc1;//biggest Id account var task = [Task.Run](https://Task.Run)(() =&gt; { lock (smallest) { lock (biggest) {} } }); This means that the order of the parameters doesn't matter. To your last statement: Yes, I would lock the "same" account first but it's OK, the order doesn't matter. As long as it's inside both locks.
I could for increased accuracy, but the problem here is that I actually NEED to use the reduced accuracy floating point multiplication used in languages such as C++ and fortran (77) when multiplying two 32bit floating points. I need this because I need to exactly replicate the behavior of a seeded random number generator.
What are you using to build this on? If you're using V.S. set a break point at the action which I think is the save button click. Use f11 and walk through it until the error is created. You might just need to write a try catch to workaround that exception. 
Some great answers so far, I'd like to add to this thread. Many times I have seen servers with a single web app grind to a crawl because of poorly written, inefficient code. If you are being asked to make this setup more efficient software wise, the most likely two places to get immediate impact are by fixing poorly written sql (ahem, select * from... / not using SP) and loops that contain unnecessary heavy lifting of large objects. PS: A solid fix prob needs hardware fixes too, sometimes servers grow out of their skin.
Is this a replacement for Blend?
CH in mathematical terms means that \`a program in relation to its types\` is the same as \`a mathematical proof in relation to a mathematical theorem\`. If you write honest types then you can prove your code to be correct if it compiles (in similar way as you can prove Rust code not to have memory leaks). Sure, things can be stretched a bit and you can write bugs in F# just as you can write a memory leak in Rust, but in general, the code is extremely bug-free and easy to refactor, just as Rust code is extremely memory leak free compared to C or C++. Haskell uses CH and the merits of it are most nicely described by John Carmack (while learning Haskell, Carmack rewrote Wolfenstein in Haskell, and while doing it, he found out that Haskell doesn't even have a proper debugger; then he compares his experience to Lisp, which he also learned): [https://youtu.be/1PhArSujR\_A?t=14m8s](https://youtu.be/1PhArSujR_A?t=14m8s) HM on the other hand helps you not write types all over the place. Either you write types every time for all function parameters like in Kotlin (and you gain parametric polymorphism) or with HM you write Python-like code without types for each parameter, but then you can't have functions that take different parameters (i.e. you can't have multiple overloaded functions with same name). It turns out that HM is a statistically better choice (i.e. lower cost), because with Kotlin you'll have to write types for each function definition (even if it is not overloaded), whereas in F# you pay the price of extra naming only for overloaded functions which is a rare case compared to number all of functions written (and when you get used to it, it is even more sane and readable). In addition you gain parameterless function composition like: url |&gt; httpFetch &gt;&gt; parse &gt;&gt; validate &gt;&gt; extractResult.
This would be awesome if, as they said in the article, it allowed for more than JSON data bindings. I presume that is coming. I also would love to see this available on Linux and OS X (I assume it is not yet available since it did not mention it)
I don't even think GDI+ or the new cross platform bitmaps can even support anything close to that resolution. I also very much doubt BitmapSource will do it either. I'd experiment with MemoryMappedFile and dynamically loading data from the image into a bitmap's scan0 pointer. Seeing as you can't actually display 24k x 48k (if you can, I want your monitor and video card), I would start with subsampling the image to a reasonable resolution that can be displayed in full, say a 2000x1000 bitmap. Using the MemoryMappedFile and some UI controls to provide zooming and panning, you access the specific data in the MemoryMappedFile that corresponds to the viewport of the bitmap and dynamically move the memory around. No clue if this would work, but it is what I would try if I had your problem.
This is going to sound a little gross, but it is possible to execute inline ASM from C#. You mentioned it is for a random generator seed so I image this isn't a hot part of your code so performance isn't a concern. I imaging executing inline ASM in C# is not fast at all but it would give you the flexibility to execute F32 multiplication directly.
Hey, Thanks for the reply, I just had a breakthrough, I'm not sure if it's a bug in c# or what it is, but I will be editing the main post in the next few minutes if you'd like details.
Don‚Äôt ask why I made it. It seemed funny at the time and became less so when figuring out how to code it gave me a headache.
I think mastering an interview is the wrong approach. Yes you should be competent on the skills required for the position but in my experience hiring managers are going to continue to push you with hard questions until they stump you. They aren‚Äôt only interested in what you know. They‚Äôre interested in how you handle things you don‚Äôt know as well. Hope this helps, good luck!
Seems like a nice and lightweight way for designers to develop UI without the added ‚Äúweight‚Äù of Blend. It mentions it has some support for the code behind but I wonder if it encourages MVVM development. That‚Äôs what we really need.
If you share your code with where you're struggling and a particular issue, you'll get help here. 
Thanks for the answer) I am really interested in this topic.
In practice, the benefit is: IF you can rely on the compiler to catch all bugs, THEN you can develop a more offensive programming style. When you do refactoring in C#, you have to keep a ToDo list in your mind of all your pending changes that you need to resolve. There's apparently only 7 things you can keep in your mind at a time and if refactoring goes too deep, you might forget some of these, causing uexpected errors. So you're always afraid to forget something, or that there are cases not covered with unit/integration testing and you write code more defensively (more afraid, more validity checks in code, more unit tests). The functional domain modelling paradigm regarding errors is: "impossible is even better than testing" With a provably correct programming style and tooling, you just don't bother all that much. You change the code, things go all wrong, IDE is coloring everything red, and then you go and fix that stuff one by one and once the editor is happy, the code compiles and just runs without errors. (Yes, I know, it is hard to believe until you experience it yourself). It is often the case, that even though functional programming is often heavier on CPU and memory usage (especially garbage collection with immutable types), the end code is often faster, because the language makes it easier to get to optimal code. When the cost of refactoring is too high, one might prefer to live with sub-optimal code rather than risking breaking changes or unexpected runtime errors that previously weren't there. As cost of refactoring gets lower, optimal code is also more likely to appear. For the same reasons, you'll usually find much less technical debt on HM style FP software projects. Things get fixed faster.
The performance hit would most likely be minimal, and programming to an interface allows you additional flexibility. However, if you won't benefit from the additional flexibility, I would just use the concrete type. If the dictionary is an edge point (to your library, to the file system, etc), the interface can be beneficial for others to program to.
I currently have an IIS server with almost 200 web applications on it. Working great. Resource hog but working just fine. 
It's a little annoying that you have to use separate arrays rather than a single array of "Course" objects with the 3 properties. For the edit/delete operations you'll want to find the array index based on the id you have selected. The data being stored in Lists is convenient though, it's the exact API you need to make the buttons work, Add, RemoveAt, Clear, and the ability to assign via an index, it's all there for you.
This kills the Blazor.
What does caching (the CPU cache) have anything to do with caching the value in a register. Writing a value to memory from another thread can *never* "invalidate" a value that is in a register of another thread. To the compiler, *unless* `_instance` is volatile, there's nothing that can logically change its value between 1st and 2nd `if` and it's free to cache (in register!) both the value and/or the result of the 1st comparison. Boom. 
Restarting Visual Studio fixes it, but seriously, all I did was add two blank lines. The whole file looked like this.
My guess is that the large int constant is being interpreted as a specific non-int type which changes changes the operation semantics. I know you found a fix, but I‚Äôd still want to know *why* to avoid this in the future. I‚Äôd try specifying the constant‚Äôs type with f/d/M/L
Programming to an interface is generally what you want to do in most cases. What comes to mind is the dependency inversion principle, added maintainability and extensibility,LSP, testability etc. Interfaces make your life easier so that‚Äôs why it‚Äôs recommended. There may be more reasons I didn‚Äôt outline here but generally it‚Äôs a good thing. 
I think floating point computations are run with 64 bit on 64 bit systems, even when computing with 32bit types, since they're faster. If you compare your results with `double d = f * 2147480832; int j = (int)d:` then you'll see that it's the same result. I think it was only mono though which runs 32 bit computations in 64bit when on a 64bit system. Not sure tho anymore
In my opinion the main benefit of writing to Interfaces is when you are creating code that other people / teams will consume (a library). Once you publish your API and your customers have coded to that specification, you cannot change your method signatures in a future update without introducing breaking changes. If you are the sole maintainer of the code base, this pattern isn't as necessary as the refactoring tools in Visual Studio help you clean up changes like this quickly and easily.
If they all have individual app pools you can see in the task manger processes tab which is using the most resources
 Please tell me this will work on Linux and with Xamarin. I would actually give it another go if this works, this would be absolutely fantastic.
&gt; programming to an interface allows you additional flexibility. No it won't. It will make it less flexible because you are limited to just the methods on the interface, rather than all of the capabilities that the class offers.
Programming to interface will make refactoring easier. However, will you NEED to change from a Dictionary? Programming to an interface also means virtual dispatch, which (potentially) disallows RyuJIT from making optimizations. You would have to decide if these optimizations matter to you. How? By testing. There is another case, though. If you are exposing the Dictionary's functionality, then you could have any public methods/properties exposed via IDictionary. Then you could have the internal implementation as a concrete Dictionary, to get the optimizations. If you have to refactor, then you only have to worry about the internal implementation - consumers of the object are expecting an IDictionary anyway, so they don't care if it's actually a Dictionary or something else.
But it does increase the flexibility of behavior, since you can get different results using the same interface by using a different class that implements IDictionary
Its a Windows store app, so not for now :D
Yes, it's just demo code and he's using the Sleep as fake work. It's simply the mixing of the primitives I disapprove of. I would not expect to see someone writing task based code and using methods on Thread.
A lot of people don't understand what "programming to the interface" means. They see the `interface` keyword and think, "oh, I should use that everywhere". But that's completely wrong. To understand what the term means, you have to go back to the era of C and other languages like it. Back then you had two options for manipulating a data structure: 1. Use the functions provided by the library's API or Application Programming Interface - **Programming to the interface** 2. Use pointers to directly modify it - **Programming to the implementation** Programming to the implementation was bad because the internal design of the data structure may change over time. But you can (usually) trust the API functions to be updated to match. So as long as you programmed to the interface, you're safe. In modern Java or C# programming, the API is exposed through the use of public methods and properties. This forms the "public interface" that you are supposed to use. In these languages, "programming to the implementation" means using reflection to mess around with private fields. These fields may be altered between versions just like the internal layout of a C style data structure. *** So what about abstract interfaces declared with the `interface` keyword? Use it when you need to. If you actually need to support multiple implementations of `IDictionary`, then by all means use `IDictionary`. But if you know that you are always going to be using `Dictionary` then there is no reason to declare as an abstract interface. 
&gt; Once you publish your API and your customers have coded to that specification, you cannot change your method signatures in a future update without introducing breaking changes. That's also why you shouldn't be using interfaces in all cases. Lets say you have the choice between returning a `IList&lt;Customer&gt;` or a `CustomerCollection`. Later you discover a performance problem that can be solved by pre-calculating some data and exposing it via a `CustomerCollection.EliteCustomers` property. Lets see how our choices panned out... * `IList&lt;Customer&gt;` Now you have to change the return type, a breaking change, or add a matching extension method with a type check and fallback path * `CustomerCollection` - Just add the property. Being explicit dramatically reduces the chances of a breaking change in many situations. *** The general rule here is to be specific in what you return and liberal in what you accept. So use the smallest interface you can in your method parameters, but use the most descriptive type for your return values. There are occasional exceptions such as LINQ expressions, but this is still a good general rule to follow.
Years ago I had to load a gigantic image and the library that I used could not handle it. I looked at the code and the reason was the limitation of the c# array size. Since arrays were (are?) limited to 2146435071 elements it meant that if one pixel was represented by one array element the max square image that it could handle was roughly 46 000 by 46 000. I worked around this limitation by replacing c# arrays with my own "array" that internally split data into smaller segments. Speed penalty was imperceptible and I could load images of any size pretty much. 
You can reset the resharper cache... Choose Resharper -&gt; Options... -&gt; Environment -&gt; General then click Clear Caches
Enum?
&gt; you can get different results using the same interface If you are getting different results using the same interface, then whomever implemented that interface is doing something wrong. The whole point of an abstract interface is to say, "these unrelated classes behave the same way when used in this narrow way". 
Oh, bloody hell. That‚Äôs it! Thank you!
Removed: Rule 4.
Enumerations? \[Flags\] public enum MyEnum { AsSomeFlag = 1, AsSomeOtherFlag=2, AsSomeThirdFlag=4 } //For each of the flags.. bool HasSomeFlag(MyEnum e) { return e&amp;AsSomeFlag==AsSomeFlag; } bool SetSomeFlag(MyEnum e, bool set) { if (set) e=e|AsSomeFlag; else e=e|(e&amp;\~AsSomeFlag); } &amp;#x200B;
&gt; Programming to an interface also means virtual dispatch, which (potentially) disallows RyuJIT from making optimizations. I won't repeat my rant about misapplying that expression, but I do want to point out something interesting. In .NET Core they are starting to catch instances of programmers being stupid and can "devirtualize" calls made through interfaces. Last I checked that happens when you do silly things like `IDictionary x = new Dictionary(); x.Add(...)`. Eventually they may extend it to work with more interface calls like Java Hotspot does. Here are my notes on the topic. https://www.infoq.com/news/2017/12/Devirtualization
&gt; The whole point of an abstract interface is to say, "these unrelated classes behave the same way when used in this narrow way". Interfaces define ways of interacting with a class, not the behavior of those interactions. Obviously it would be wrong to create a dictionary with an Add() method that never adds values to the dictionary, but you can create a dictionary class that produces side effects (such as logging) or does additional validation on the input and see different (but still coherent and reasonable) behavior than the default dictionary class.
``` using static System.Console; struct Input{ public Input(string answer, int times = 0) { Answer = answer; Times = times; } ... public override bool Equals(object obj) { if (obj is Input input) return input.Times == this.Times &amp;&amp; input.Answer == this.Answer; return false; } } private Dictionary&lt;Input, Action&gt; _actions = new Dictinoary&lt;Input, Action&gt;{ { new Input("yes"), () =&gt; { WriteLine("Cool!"); ReadLine(); } }, { new Input("no"), () =&gt; { ... } } ... } // in main var input = new Input(answ, times); _actions[input](); // immediately invoke the action returned by the dictionary ```
I can still write procedural and OO code that is provably correct so this isn't super compelling to me. You could write essentially the same programs in Swift as you could in F#, it's more about coding style than about language features.
&gt; If you are exposing the Dictionary's functionality, then you could have any public methods/properties exposed via IDictionary. Then you could have the internal implementation as a concrete Dictionary, to get the optimizations. You can also do that with a strongly names class. In the .NET Framework Design Guidelines, they recommend returning classes such as `CustomerCollection` or `CustomerDictionary` so you can change the internal implementation as often as you like. (Also so you can add new methods, but I already covered that.)
Thank you, I‚Äôll try that.
I upvoted. Please post me on r/madlads.
Switch statement
I'll research that, thank you.
Because you don't know how to answer it? 
Removed: Rule 4. There's no built-in way in terms of sentence parsing, but perhaps something more rudimentary will work for you. You can search for your keyword using `String.IndexOf`: https://docs.microsoft.com/en-us/dotnet/api/system.string.indexof?view=netframework-4.7.2 You can split your text into sentences using `String.Split`: https://docs.microsoft.com/en-us/dotnet/api/system.string.split?view=netframework-4.7.2 For the splitting, you could put the different punctuations in (".?!") as separators. It wouldn't be perfect though, but maybe it's enough for you. Another option instead of getting the few sentences before/after, maybe just output the 500 characters before/after the find result.
&gt;I also see in the SO article that there seems to be some performance concerns in doing this. Calls to methods on an interface can't be inlined (which is where instead of inserting a call to a function, the compiler puts the code from that function into the function calling it directly). Inlining avoids the cost of a function call (which is relatively small), but it's premature optimization to avoid interfaces for that reason, since the benefits are really only noticeable when calls to that function are extremely frequent, and it's only possible on very small, simple functions anyway. https://mattwarren.org/2016/03/09/adventures-in-benchmarking-method-inlining/ has some good info. At my work, the only person I've ever seen mention method inlining is a guy whose job is to optimize the performance of critical sections of code that runs on tens of thousands of servers (or more). When you can start to save the cost of dozens of servers, then it's time to look into micro-optimizing your method inlining.
 void Main() { String[] InvalidResponses= new String[]{ "What? It was a yes-or-no question.\nI'll Ask again.", "Just answer my question as stated.\nYou get one more chance", "Nevermind, you're just not listening.\nBye." }; int wrongs=0; while(wrongs&lt;InvalidResponses.Count()) { Console.WriteLine("Do you like chicken mcnuggets? Yes or no?"); var line= Console.ReadLine(); if (String.Compare("Yes",line,true)==0){ Console.WriteLine("Cool"); Environment.Exit(0); } if (String.Compare("No",line,true)==0) { Console.WriteLine("Why?"); Console.ReadLine(); Console.WriteLine("Oh..."); Console.WriteLine("Ok by then"); Environment.Exit(0); } Console.WriteLine(InvalidResponses[wrongs]); wrongs++; } } 
Thank you very much.
Everyone has been very helpful. I‚Äôm not sure what to try or listen to.
&gt; Interfaces define ways of interacting with a class, True, but you are using an overly narrow definition of the word "interface". In addition to any *abstract* interfaces a class implements, it also has its *public* interface. &gt; not the behavior of those interactions. Not exactly right. If you believe in the "Liskov substitution principle" then it shouldn't be doing anything that would prevent a substitution. So you could add logging, but not additional validation and the latter could then throw exceptions when other dictionaries wouldn't.
I wouldn't rely on the solution you found, I wouldn't be at all surprised if it behaved differently when compiled as Release.
&gt; it's premature optimization to avoid interfaces for that reason, But is it really an "optimization" or is it just the default you should be using? It's not like it makes the code harder to read, which is what Knuth was worried about. Or to look at it another way, is insisting on using abstract interfaces everywhere a "premature generalization"?
Yes, it's still odd behavior though.
Right. The exception perhaps being tasks started with the LongRunning flag, which are just threads. 
Try it all! There is rarely only one way to code something. Try them all and see which you like best. Just a quick tip. When comparing strings, they are case sensitive. The safest way to compare strings is like `answ.Equals("yes", StringComparison.OrdinalIgnoreCase)` If you do this, you need to ensure that answ is not null first... StringComparison has other options, too.
OK
&gt;If you believe in the "Liskov substitution principle" then it shouldn't be doing anything that would prevent a substitution. Liskov applies to subclasses, but when two classes both implement the IDictionary interface, which is the subclass of the other? If C# were like Eiffel, where argument and return validation can be defined as part of the interface contract (so if C# interfaces acted like Eiffel class interfaces), then it would be obviously wrong to implement something that rejected input that would otherwise be valid under the interface's preconditions. But C# is not like Eiffel, and there's no guarantee that IDictionary's Add method accepts all the same input as Dictionary's Add method.
In addition to that, try to figure out what each piece of code does, and how. Because blindly copying code won't help you become better.
&gt; Or to look at it another way, is insisting on using abstract interfaces everywhere a "premature generalization"? That's a fair assessment; we don't make every method virtual just in case we want to be able to override it in some theoretical future derived class. I definitely don't think it's right to use interfaces everywhere you can just to open up the possibility of changing the implementation class later. My point is that performance concerns are not a sufficient reason to *avoid* using interfaces unless your need for optimization is significantly higher than that of most C# projects.
That‚Äôs a will do. :) thanks
Doesn't the long running flag just indicate to the thread pool that it might want to spin up a new thread? It's still under its control. I'm actually not sure but that's how I've explained it to others, so now I'm thinking I need to do a bit more research :) 
That's where the (potentially) comes in. From what I understand, there is no guarantee that RyuJIT will do that.
Yep. But still, it is a promising direction.
Agreed,
No I do not have that information memorized. Why would I want to memorize something like that when Google and reference books exist? The only purpose that question serves is to test a person's memorization of random programming facts. Memorizing programming facts is fine and dandy, but in an interview you aren't looking for the person with the best memory. You are looking for the person who can logically work through problems, and come up with a logically sound solution. I mean, maybe your specific job requires that kind of knowledge, but if that is the case your job is extremely niche and does not apply to the vast majority of programming jobs. This is especially true for entry level jobs which this person is going to be interviewing for. 
This looks interesting. I remember trying out Blender years ago, but couldn't get into it. I felt like it was made more for content developers than enterprise developers. At least to me it seemed like Microsoft was trying to entice Adobe Flash/Flex developers over to Silverlight. 
They are both subclasses of IDictionary. Remember, with the Liskov substitution principle the idea that an abstract interface was something different than a class didn't exist. Back then, an abstract interface was literally just an abstract class where all the methods were abstract. We have a distinction because of how the CLR and JVM are implemented. (And with default interface methods, that distinction is getting rather thin.)
Definitely not
You mad lad! And even after I specifically said not to! üòÇ
Thanks!
Triple back-ticks don't work here, you need to use 4 spaces. If using VS, select all of your code and hit tab to add the necessary spacing.
Why Ordinal instead of Invariant? 
From the [C# spec](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/language-specification/types#floating-point-types): &gt;Floating-point operations may be performed with higher precision than the result type of the operation. For example, some hardware architectures support an "extended" or "long double" floating-point type with greater range and precision than the double type, and implicitly perform all floating-point operations using this higher precision type. Only at excessive cost in performance can such hardware architectures be made to perform floating-point operations with less precision, and rather than require an implementation to forfeit both performance and precision, C# allows a higher precision type to be used for all floating-point operations. From the ECMA-335 CLR spec (which isn't authoritative for current CLR's but still a good starting point, I think?): &gt;Storage locations for floating-point numbers (statics, array elements, and fields of classes) are of fixed size. The supported storage sizes are `float32` and `float64`. Everywhere else (on the evaluation stack, as arguments, as return types, and as local variables) floating-point numbers are represented using an internal floating-point type. In each such instance, the nominal type of the variable or expression is either `float32` or `float64`, but its value can be represented internally with additional range and/or precision. The size of the internal floating-point representation is implementation-dependent, can vary, and shall have precision at least as great as that of the variable or expression being represented. [...] &gt;Rationale: This design allows the CLI to choose a platform-specific high-performance representation for floating-point numbers until they are placed in storage locations. For example, it might be able to leave floating-point variables in hardware registers that provide more precision than a user has requested. [...] The relevant 'culprits' here are presumably [x86's 80-bit extended precision](https://en.wikipedia.org/wiki/Extended_precision) floating points.
Dictionary is one of the most-used container classes in C#. Any engineer should absolutely know the performance characteristics of all the container classes. Also being able to figure out how to achieve those performance characteristics shows that someone understands basic data structures and algorithms and was paying attention in school. And no, there isn't a single right answer, but the discussion will reveal a lot about the person. You, for example, get defensive and angry when you get a problem that you don't know the answer to 
I guess it depends on your use case... If you're looking for an exact match aside from case, ordinal is what you want. Invariant does character expansion which could cause false positives if you're looking for an exact match rather than "effectively equal"
No, it's implemented like this in ThreadPoolTaskScheduler, which is the default task scheduler: [SecurityCritical] protected internal override void QueueTask(Task task) { if ((task.Options &amp; TaskCreationOptions.LongRunning) != TaskCreationOptions.None) { new Thread(s_longRunningThreadWork) { IsBackground = true }.Start(task); } else { bool forceGlobal = (task.Options &amp; TaskCreationOptions.PreferFairness) &gt; TaskCreationOptions.None; ThreadPool.UnsafeQueueCustomWorkItem(task, forceGlobal); } } 
Thanks.
I have a question. Although there are free online resources, do you think it would be helpful to buy a C# book?
Dafuq? Where does this weirdness end?
&gt; I can still write procedural and OO code that is provably correct Of course you can. You can also write *'functional'* code in C#. Or you can write manual memory management in C. Or you can write business line app graphical user interfaces in assembly. It is just that sometimes it does matter a bit, what kind of abstraction you use. It is also an extremely interesting phenomenon why people think that anything that they haven't experienced yet should probably be worthless. It is really hard to find a name for this phenomenon: neither is it just ignorance, nor Dunning-Kruger effect or something else.
So after more research I'm going to contradict what I said earlier: The presence of `lock` actually *does* cause the JIT to disable caching for items within its block. Which means that thread B will always go to main memory rather than cache the value of `_instance` once it enters the block.
Uncle Bobs "Clean architecture" is basically about dependency inversion. Great read. The best book I read about OO patterns in C# is "Apaptive Code" by Gary McLean Hall. A must read in my opinion. Also covers DI extensively, although in a more concise way. 
That's on my front page, congrats!
I should have looked at the source :) Thank you for that, you may have a cookie :)
Ah, yes. This is reasonable platform-specific behavior. I believe that current .NET will requires and uses SSE on x86, so it may be worth checking if this is actually an issue.
Int32.MaxValue generally, though you can specify them as other numeric types if you really want.
What tool or program are you trying to compile it with and what error do you get when you try?
No, when I do not know the answer to a problem, I admit as much, and do research to figure out the answer. I had never even heard the term "time complexities" before your post. So what did I do? I looked it up, and figured out what it was. That is how I came to the conclusion your question is horrible for an interview if your goal is to hire the best programmer. I mean sure, if your only goal is to hire the most knowledgeable programmer you might succeed, but that doesn't mean they are a good programmer. If you want the best programmer you should be asking questions about how they code, not how well they are able to repeat what their professor told them. The details of how Dictionary work can easily be looked up on an as needed basis. Breaking someone of writing poorly structured and logically thought out code is hard.
Yep, if you expect a failure, it's not exceptional. 
I ran into that parsing email addresses. At the time there was a Parse but not a TryParse method. 
...take my upvote and move on.
&gt; Also isn't it bad practice to use a Task synchronously Not necessarily. Consider this code: var total = list.AsParallel().Sum(x-&gt;x.OrderTotal).Result Here I am legitimately waiting for a Task to complete in a synchronous manner. Remember, Task was available for a wide variety of situations long before `await` came along. 
&gt; The presence of lock actually does cause the JIT to disable caching for items within its block. That's nice if you are actually using the `lock` keyword (which is a mutex). But if you are using some other type of lock such a s a spinlock or reader/writer lock then we've got a problem.
Several years ago, I had the opposite problem. I was so afraid of the performance costs of exceptions that I wrote a ton of code that returned booleans instead of throwing exceptions. The problem is that I did not evaluate my code to see whether my failures were _exceptional_. As a result, I ended up with too many places in code where I was not checking the failure condition, and it resulted in the code having tons of silent failures. I learned my lesson the hard way and reintroduced exceptions where appropriate. I was then able to see what was going wrong and handle the failures properly.
Hi! I am using Visual Studio Community 2017. I did the following: Open project\\solution redactiontool.sln Right click Redaction Tool, select build. Receive following build errors: [https://i.imgur.com/Vh0Ojb4.jpg](https://i.imgur.com/Vh0Ojb4.jpg) Unknown build error, "clr-namespace.TfsBuild;' mapping URI is not valid. (shown in jpg) The tag 'Activity' does not exist in XML namespace '[http://schemas.microsoft.com/netfx/2009/xaml/activities](http://schemas.microsoft.com/netfx/2009/xaml/activities)' &amp;#x200B;
&gt; Not entirely true. Here it's the only way as you can't await inside a lock. Correction, you can't wait inside a *mutex* lock. There are await friendly locks available. I believe this is the library my project uses: https://github.com/StephenCleary/AsyncEx
you can use `foo.HasFlag(flag)` instead.
Perhaps he is confusing it with the "double checked locking" bug. https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html 
I downvoted you to bring back absolute balance
A child of Thanos, I see. Well met!
You can either create a third interface the at inherits from both interfaces you need (and have your class implement that interface) or do runtime casting. There are no union types in C#. 
Correct.
Damn. I was hoping that you would say I was wrong.
If you don't know the performance characteristics of the Dictionary class then I'm not going to hire you as a C# programmer. If you had never heard of time complexity then you didn't get your degree in computer science or you slept through your classes and I'm not going to hire you. But then we were looking for back-end engineers who could write decent server code so our requirements were more stringent than throwing together some front-end hack where performance doesn't matter.
Have a new interface IFooBar If you have this sort of inheritance issue you probably have two separate implementations; If they have to work together, create a parent type, or compose with the Foo and Bar injected.
Really? How?
The third interface isn't really an option without making everything a mess... What is runtime casting?
What code did you use?
Numbers[x].forecolor=color.green;
Or worse, returning `IEnumerable&lt;Customer&gt;`. Now your consumer has to worry about possible side effects of enumerating the thing twice if your enumerable was created by a query rather than returning a concrete collection.
I hate that so much. In one library I worked on every one of several hundred methods did that. Half of them would require an expensive round-trip call to a separate server and then a database if I double enumerated. They were often very large too so I didn't want to call ToList on all of them and pay for the GC overhead.
No. If the return type of `GetItem()` implements both interfaces implicitly, you could simply declare the variable with `var`/the concrete type, but if the interfaces are implemented explicitly you'll probably just have to use one variable per interface. Generic constraints actually kind of do this, but that's probably not useful here: void M&lt;T&gt;(T obj) where T : IFoo, IBar { obj.FooMethod(); obj.BarMethod(); }
Definitely.
From [docs.microsoft.com](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/enum): *Every enumeration type has an underlying type, which can be any integral type except char. The default underlying type of enumeration elements is int. To declare an enum of another integral type, such as byte, use a colon after the identifier followed by the type, as shown in the following example.* `enum Day : byte {Sat=1, Sun, Mon, Tue, Wed, Thu, Fri};`
IFoo item = getItem(); // Do whatever IBar itemBar = item as IBar; if (itemBar != null) { // Do whatever with IBar }
It may depend on the specifics of the lock implementation. However, `lock` itself is a MemoryBarrier. Other mechanisms, such as semaphores, etc., I don't know. For what it's worth, there are dozens of articles about double-locking, and lock vs. volatile, that could fill volumes. However, everything I could find *from Microsoft employees and MVPs* (such as Jon Skeet) argued on the side of volatile not being necessary if you locked the write and protected it with a guarded read *inside* the lock.
This sounds like a design flaw. But technically you must address the interfaces seperately. 
Definetly. In a book you have a structure of topics related to each other. And you will learn step by step. Where as on the internet, you wont even knoe where to start learning.
Why did you take a photo instead of a screen shot ? 
 var i = getItem(); var item1 = i as IFoo; var item2 = i as IBar;
OK. I will, thank you.
I didn‚Äôt think of that when I took it.
So let me explain this again. For the JIT to be able to optimize away null reference checks, nullable reference types must be enforced at the CLR level. That would be a breaking change and would require a brand new CLR. As it is, the JIT cannot rely on C# 8's nullable/non-nullable annotations because they are in no way a guarantee. You could write a perfectly valid C# 8 program with NRT turned on, and at runtime set a non-nullable reference to null using reflection.
Removed: Rule 4. You'll need to include more code and the platform you're using (Console, WPF, ASP.NET, etc.). Ideally, try to produce a [Minimal, Complete, and Verifiable example](https://stackoverflow.com/help/mcve) from which we can reproduce the problem you're having and diagnose a solution.
Removed: Duplicate.
Can this be used as an interim tool for developing xaml while waiting for VS2019 to come out with .net core 3 support?
If you can change the type returned by getItem(), you can declare an interface that implements both: public interface IBaz : IFoo, IBar { } public class BazItem : IBaz { public void FooMethod(); public void BarMethod(); } IBaz item = getItem(); item.FooMethod(); item.BarMethod();
I upvoted
I did the same thing as eightvo, but with slightly different syntax, just to show what's possible. static void Main() { var retryMessages = new[] { "What? It was a yes-or-no question.\nI'll ask again.", "Just answer my question as stated.\nYou get one more chance.", "Nevermind, you're just not listening.\nBye.", }; foreach (var message in retryMessages) { Console.WriteLine("Do you like chicken mcnuggets? Yes or no?"); var response = Console.ReadLine().ToLower(); if (response == "yes") { Console.WriteLine("Cool!"); break; } if (response == "no") { Console.WriteLine("Why?"); Console.ReadLine(); Console.WriteLine("Oh...\nOK, bye then."); break; } Console.WriteLine(message); } } 
I‚Äôm impressed by how many ways there are so many ways to make the same method.
I agree, this is definitely a code smell. OP's code should be using getFoo() and getBar() and if it needs to be the same instance, that detail should be hidden from the code using Foo and Bar.
You have a leaky abstraction. Your method GetItem() returns IFoo that's all your code knows and all it should know. The implementation of that method can do as it pleases as long as it meets that requirement of returning an instance of IFoo it knows nothing of IBar. You are now assuming that GetItem returns something that is both IFoo and IBar, you are assuming too much and the details of your abstraction are leaking. What if someone changed GetItem to return a different IFoo that is not IBar then everything would break. Imo opinion your best creating a new interface or IFoobar that implements both Ifoo and Ibar. It's implementation could just wrap around an instance of each ibar and ifoo and pass the interface calls to the appropriate instance (there's a name for this pattern but ive forgotten it).
That's actually been heavily optimized in dotnet core iirc. It used to have an inefficient implementation, but I'm not sure if the changes we ever ported to the desktop CLR.
enum MyBetterBoolean { True: 0, False: 1, Other: 2 }
I am creating a UWP app. I am also trying to save a config file in that part of the code. I am using SharpConfig to manipulate my .cfg files. &amp;#x200B; I encounter the error when I am trying to save the file to the disk. user.SaveToFile(dest); So when I use the `SaveToFile()` I get the UnauthorizedAccessException Error. I have tried saving it to the folder where it launches, the desktop or to an another drive in my pc. But the problem still occurs &amp;#x200B;
Was there perhaps something different about how you were doing the logging, or text formatting in both cases? Because 13ms just to handle the exception overhead seems not possible. If the exceptions were causing critical functions to not get in-lined, then \*maybe\* that could explain the difference. &amp;#x200B;
r/unexpectedthanos
r/expectedthanos
Here's a sneak peek of /r/UnexpectedThanos using the [top posts](https://np.reddit.com/r/UnexpectedThanos/top/?sort=top&amp;t=all) of all time! \#1: [Thanos comes to us all in the end!](https://i.redd.it/jegcv3exle111.jpg) | [24 comments](https://np.reddit.com/r/UnexpectedThanos/comments/8nsq20/thanos_comes_to_us_all_in_the_end/) \#2: [Damn](https://i.redd.it/c4qks6mcl8z01.jpg) | [26 comments](https://np.reddit.com/r/UnexpectedThanos/comments/8l26op/damn/) \#3: [Perfectly Balanced](https://i.redd.it/g3tjvim9h9z01.jpg) | [22 comments](https://np.reddit.com/r/UnexpectedThanos/comments/8l3lnf/perfectly_balanced/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/afd0dd/blacklist/)
very well written article. there many Excel SDK which can be used. See if the below link helps: [https://zetexcel.com/](https://zetexcel.com/)
The well known Design Patterns book from the Gang of Four explicitly states to design to interfaces. I think this is where some people get the idea. They did not mean program to the Interface type, they mean it conceptually. Don't use an IDictionary instead of Dictionary because of that TutorialTeacher article/site. That is bad practice and I'd avoid that site altogether. Chances are, if you need to make a change in how your state is saved in a data structure, you will probably be changing the type(s) saved in the Dictionary or a Key/Value pair won't be a good fit anymore.
Would recommend Adaptive Code via C# too. It totally changed how productive I am. Clean Code was good for generally keeping code tidy too.
That's what I thought too, but even if I very liberally interpret his comment to be talking about double-checked locking... so what? What's his point?
This is bullshit. I used to believe it once upon a time but not anymore. Declare variables with the specific type. Declare method parameters with the interface (if the method is public, otherwise use it is pretty much the same and I use the specific type). Return types of public methods should probably be interfaces although I am too lazy to be bothered with this. I only put interfaces when I need the encapsulation for example if the method keeps the reference somewhere I return IReadOnlyDictionary while I keep the Dictionary internally.
ToList() all the things :)
Do you have overloads for getItem() such that it can return different interfaces? If yes, cast down to a base type (object if none) and test the reference using the is operator. if(retVal is IFoo) then cast retVal to IFoo and call your IFoo specific method. https://docs.microsoft.com/en-us/previous-versions/visualstudio/visual-studio-2012/scekt9xw(v=vs.110)
Way too vague. Do you have an online repository?
Great piece of wisdom here. You should write an article about it especially if you can somehow source the historical part.
Basically after selecting one radio button the other ones won't react 
Its hard to understand you. I'm guessing you need to subscribe to an Event. There is CheckChanged and DoubleClick that you could look at. In your callback you could check the CC #. https://docs.microsoft.com/en-us/dotnet/api/system.windows.forms.radiobutton.checkedchanged?view=netframework-4.7.2
Only one radio button can be selected at any given moment. They should not freeze though. Are you using WPF?
I mean yes, one radio button is selected but when I click on another one it doesn't do anything 
Not sure, hence the "confused" part of my comment.
I've been toying with the idea of doing a "back to the basics" series where I dig up the old archives. But I lost my notes over the years and would have to start my research over from scratch.
The Exception occurs when you save the file, but the code that saves the file isn't in your post. https://docs.microsoft.com/en-us/windows/uwp/files/quickstart-reading-and-writing-files
That said, it‚Äôs usually very simple to detect the type of card automatically based on the number format. 
Yes I know, I did that with regex. But every radio button has a different regex 
If you know how to validate the cards, why are you asking the user what card it is?
The user chooses what card he has such as visa Mastercard etc. All cards have different regex
Thought I'd run some tests, you're not wrong. [https://gist.github.com/brendanmckenzie/2075cd06f60db7eba2c89acc009e8a9a](https://gist.github.com/brendanmckenzie/2075cd06f60db7eba2c89acc009e8a9a) Results `Testing with exceptions` `Time elapsed: 3761ms` `Testing without exceptions` `Time elapsed: 24ms` &amp;#x200B;
Wtf
MVVM is used in client-side web as well as legacy desktop, both of which are very common in enterprise programming.
Edited my post, sorry
Here is all you need to know: 1) GC algorithm is generational, this means it only collects what it needs to and is very efficient. 2) Best practice is to let it do its job. 3) If it isn't working right (this is VERY rare), you can force collect with GC.Collect(...)
"Do not upvote" *Upvotes* *Reads post* 10/10, would post again. That's an enum, btw.
&gt; "Do not upvote" &gt; &gt; Upvotes Is that the key to gratuitous amounts of karma? Because I swear, I only wanted a quick and dirty answer and not this awesome Reddit karma-hug.
You should look at the MSIL that's being generated to understand what's going on, because that is odd and not behavior I would trust relying on without more understanding.
Fuck no, at least not in Australia... At all the jobs I have interviewed for and all the places I have been on the hiring board for the GC is very important. But I guess it might be different where you are from.
What is the knowledge that you expect from enterprise programmers about the CLR GC in Australia?
Lol, I guess that is the secret to success, reverse psychology is a hell of a thing! Happy Friday
My whole point is that you don‚Äôt need to waste the user‚Äôs time by asking them what kind of card it is. There are extraordinarily easy ways to tell this from the number itself. 
enum TheBestBoolean { True: 0, False: 1, Other: 2, Yes: 3, No: 4, Maybe: 4, So: 5, Wet: 6, Dry: 7, Light: 8, Dark: 9, Dank: 10, Normie: 11 } 
Don't tell me what to do!
Everything is hard to grok. Grasp first, then understand, then master, then grok.
The warning message is using the same logging facility, log4net. In the "before" version, the message was written in a catch clause. Now the message is written after checking for a marker value that indicates the date was text, not a recognizable date value. The try/catch structure is still there because there are other errors that can occur. The text formatting is slightly different, with one less substitution in the message, down from 3 to 2. The same number of messages are written. When the exception occurred, it was 4 levels down from where the exception was caught. I assume that has some impact on performance, but I don't know for sure. In the intervening levels, there was one try/finally block. It's possible that the issue was elsewhere but still solved by the change I made, but if so, it's pretty subtle.
You just covered like 5 different conversations I had this week
The overhead is obvious in your test case, too, but different (lower) than the results I described. I didn't do a benchmark.net-level test so my results indicated the problem without being highly accurate. I am not use the DateTime class as it would belch on most of the input I have to handle. For example, "from 1901 to 17 AUG 1903" and "11 FEB 1731/32" are both valid dates in the format I have to parse. The format handles inexact dates (bef/aft/circa), date ranges, "old style" dates when the year started on March 25 in some countries but on January 1 in other countries, etc.
One thing about evaluating performance is that you have to compare apples-to-apples. So, if your "before" code was supposed to detect errors and was not, and the "after" code was detecting the errors, then comparing the performance between before and after is not very useful. Further, if the code that didn't use exceptions was difficult to get right, then using an approach that is easier to get right is a good change. And lastly, if the performance of either approach was not an issue, then optimizing is not a good use of time, and code that seems performant but is not correct is a problem. In my case, the load time was way too slow (my users expect a second or two for most data files, not 3.6 minutes), so finding and solving the performance bottleneck was important. My change was relatively easy to implement, and the only tests that failed were the ones that expected an exception where the new code does not throw one. After adjusting those tests, good to go...
Double yep.
What functionality does this tool provide that Blend does not? 
I've seen R# do this since about version 2017. Not entirely sure, but I think it really started around the same time Roslyn was released.
I think I‚Äôm working on your code these days.
file:///C:/Users/user/Downloads/CSharpNotesForProfessionals.pdf
It was wrong either way. I had neither assessed how exceptional my errors ended up actually being nor measured the process to know whether optimization was even necessary. In the end, those errors ended being quite uncommon, so exceptions were the right way to go. Once I fixed it, it was actually nice seeing exactly what went wrong.
You probably are. My deepest apologies. :) I have repented of my ways.
Just the basics, common pitfalls and general idea of how it works under the hood. There are many C# developers to choose from I guess so they always like to see a strong understanding of the platform.
I'm actually toying around with creating my own programming language. I've read guides out there that suggest using exceptions to report lexing/parsing errors, but that actually doesn't make sense to me. There are far more incorrect programs in the world than correct ones. My compiler expects/wants to find the failures as fast as possible. :P
Hi All! App Developer here! Please report any bugs via Feedback Hub. And submit feature requests via UserVoice here: [https://aka.ms/XAMLStudio\_Feedback](https://aka.ms/XAMLStudio_Feedback) Thanks!
It only works with UWP XAML for now, but you can vote for Xamarin support on our UserVoice site here: [https://microsoftgarage.uservoice.com/forums/918727-xaml-studio/suggestions/36548311-can-we-get-this-for-xamarin-forms-xaml-too](https://microsoftgarage.uservoice.com/forums/918727-xaml-studio/suggestions/36548311-can-we-get-this-for-xamarin-forms-xaml-too) WPF support is this one: [https://microsoftgarage.uservoice.com/forums/918727-xaml-studio/suggestions/36549346-can-this-work-with-wpf-proper](https://microsoftgarage.uservoice.com/forums/918727-xaml-studio/suggestions/36549346-can-this-work-with-wpf-proper)
The methods that should be unit tested are those with complicated logic or conversions. You know, the calculations / decisions that have to handle boundary/edge cases, bad/strange input, things like that. Goal is to test behavior (looking only at the input/output values). The methods that don't need (or shouldn't be) tested are anything private or protected. Testing controller methods is an advanced topic. Your controller methods should be as simple as possible so as to not require testing within C#. If you have a controller method that is complicated, refactor that logic out to a service/helper class (or a static method in a pinch) and then unit test that thing.
What type of data bindings are you looking for, XML or something else? Please feel free to open a request on UserVoice with more details: [https://aka.ms/XAMLStudio\_Feedback](https://aka.ms/XAMLStudio_Feedback)
Yeah... asking a question that google would have found before he finished typing somehow qualifies as front page material.
XAML Studio is meant for rapid prototyping and it displays the result of your XAML as soon as you're done typing. It lets your interact with the result just as if it was running in your app. This is a bit different from live edit, as live edit has certain restrictions around how much you can swap out at a time, which bindings you can change, and what styles you can update. It's meant much more for fine tuning an end result, where XAML Studio is meant for the initial phase where you can rapidly change things out quickly and see what it'll look like and how it'll behave before finalizing it with VS or Blend and hooking up code. This is a quick overview article written by PoshTools which describes its feature set: [https://poshtools.com/2019/01/18/an-introduction-to-xaml-studio/](https://poshtools.com/2019/01/18/an-introduction-to-xaml-studio/) And this is an On .NET Video overview: [https://channel9.msdn.com/Shows/On-NET/Introducing-XAML-Studio](https://channel9.msdn.com/Shows/On-NET/Introducing-XAML-Studio) 
I've tested this with both netcore and net472 runtimes, looked at disassembly and I haven't managed to convince the compiler to cache the value in a register. &gt; The presence of lock actually does cause the JIT to disable caching for items treat all reads and writes as volatile within its block. Do you have a reference for that? Given that`lock` is dynamically scoped, how could the JIT generate code that always goes to memory given that code like `lock (m) DoSomething()`is commonly written? `DoSomething` may not get inlined and JIT could optimize its code.
Whaaa?....... 12 hours later. Whaaaa?
.NET Core will use WPF XAML where as XAML Studio is currently only for UWP XAML. However, .NET Core should support XAML Islands, so that would let you inject UWP XAML in a .NET Core app that way... :) You can vote for straight-WPF support on the UserVoice here: [https://microsoftgarage.uservoice.com/forums/918727-xaml-studio/suggestions/36549346-can-this-work-with-wpf-proper](https://microsoftgarage.uservoice.com/forums/918727-xaml-studio/suggestions/36549346-can-this-work-with-wpf-proper)
Look for a .sln file or .csproj and open it in visual studio. Why dont you read visual studio docs ? 
Best advice i can give is doing it yourself. Understand why ioc might be the choice. Without that it wont never occur to you taht you can use ioc to your advantage. If it does t click you are gonna introduce anti patterns into your code which is not wanted. Start by reading about: composition over inheritance. 
This is why the return type of functions should be the most descriptive type possible, which is usually a concrete type. "Accept interfaces and return classes" is a fundamental rule of good API design. 
Is it built on Electron?
Or, in newer versions of C#: if (item is IBar itembar) { //do something with itemBar }
Upvoting because fuck the system and I'm late.
You do realize you saw this 12 hours after it was posted, right?
&gt; asking a question that google would have found You have to ask the right question before Google will return the right answer, otherwise all you will get is useless garbage. That is the problem I had. How would *you* have described an enum without actually using the word in order to get a result back from Google? I tried for two days without getting a single article about enums until I gave up and posted here. Took less than 15 minutes before someone answered with the name I needed.
Nope, it's a UWP app built with C# and XAML. However, I do use the Monaco code editor that VS Code uses which is based on web technologies. I wrote a UWP Windows Runtime Component around Monaco so that it was easier to interface with C#.
The space in Equipmentframe viewmodel is what is making it all wrong, ita the c# compiler that does not understand what you want and after that evertyhing are errors
I'm at the end of a 12 month battle that we won, so buckle up and best of luck.
Although this comes with the risk of locking yourself more into a particular implementation, so it‚Äôs a balance. 
&gt; Hey guys I wanted to start independently learning IOC containers (and dependency injections as I think they go hand in hand) Dependency injection (DI) is the important concept. ‚ÄúIOC containers‚Äù is something that can make it easier to use DI, but they are not needed, especially not for smaller programs.
It doesn‚Äôt emit SSE on ARM. 
Well that makes sense, but ARM probably doesn't have this problem either though? I'm guessing the 80 bit nonsense is just Intel's mistake and no one else bothered repeating it.
Yeah, I don‚Äôt know how it works on ARM. The 80 bit floats are an x86 thing. From googling, ARM seems to have regular 32/64 and sometimes 16 bit floats internally. (By the way, googling ‚Äúarm floats‚Äù wasn‚Äôt helpful :p)
This reminds me that I need to put "Do not upvote" on all my posts to bank on that sweet karma.
Do you have proper SDK installed?
Uwp is win10 only
Then again, if you're not expecting a failure, you won't check for the exception either. I haven't really seen clear-cut guidelines on what failures count as truly exceptional (int.Parse comes to mind, where it's really not exceptional that a string shouldn't represent a valid int) and most of the time, it seems to me that exceptions are used due to the inability to easily report "either a result or an error".
Upvoted because of stupid title
This is likely due to an incorrectly registered DLL: [https://docs.microsoft.com/en-us/previous-versions/bb961987(v=vs.90)](https://docs.microsoft.com/en-us/previous-versions/bb961987(v=vs.90))
Some advice regarding strings: don't use "==" for comparison. For an example why, try running your program and typing "Yes" instead of "yes". The suggested way of comparing strings is using "string.Equals()". Look up the documentation for it on MSDN. In your case it would be something like: string.Equals (answer, "yes", StringComparison.OrdinalIgnoreCase); Or one of the other ignore case string comparison options. Use the method of off string, don't just do "answer. Equals". In this instance, it's not a problem, but it's better to get into the habit of it. Because what if the variable is null? You'd get an exception. I'd also suggest breaking your functionality out into separate methods. Basically, each time you have an opening brace {, take the content out and put it into a separate method. That will let you look at your program in a different way. Because honestly, in this example, you don't need the loop at all. The loop here is letting you leverage code reuse, but that's better served by using methods. I'd strongly suggest looking up the "Composed Method Pattern". Please reply if you have further questions on any of this.
If you're serious about learning C#, a good resource is "C# in Depth" by Jon Skeet, from Manning Publications. If you just want to learn programming in general, and you're serious about that, "CODE" by Charles Petzold is good for background on how computers really work. "Head First Design Patterns" is also an excellent book. If this will just be a hobby, I think the online resources would be more than sufficient. Look up programming challenges and see how other people solve them. Sites like /r/dailyprogrammer and AdventOfCode.com (they also have a subreddit where people will post their solutions). Look at other code. Especially if you can see different solutions for the same problem. Reading code is the best way to learn code.
What topics are you wanting to understand? Are you wanting a reference on the C# language, or programming concepts in general? If the C# language, honestly I find MSDN the best reference, and I don't really use a book. If you absolutely want a physical book, "C# in Depth" is _the_ reference, but kind of dense. The "C# Pocket Reference" is pretty good and much less dense. But again, all of that information is available on MSDN for free. For programming in general, that's a hugely broad topic. Do you want basics? Algorithms? Design patterns?
I like the book "Dependency Injection in .NET" from Manning Publications.
Oh I see where you are getting at. Thanks!
I wouldn't be surprised if the JIT just emits 32 bit instructions when you use `float` and 64 bit ones when you use `double` on ARM. That's what RyuJIT does for x86 and that's what the sensible thing is to do. The whole 'being allowed to use more precision' thing was really just because Intel introduced 80 bit floats on the CPU.
Didn‚Äôt I mention my goals in the second bold point? I don‚Äôt know much as a beginner and as I mentioned very little Python, but even though basics and fundamentals may seem a bit broad, that‚Äôs really all I know I want to learn. As for the C# in depth, I looked at it and it seems like a book for intermediates. I read a post about a guy who is starting a C# course and people said C# in depth wouldn‚Äôt be a good book I guess I‚Äôll see if MSDN would be good for me, however I was hoping for a physical side reference Thanks
Yes, those are your goals for programming, but there are a dozen ways to accomplish that. I was asking what you wanted out of a book to help you accomplish that. I.e. do you want a straight up reference book? Or something that teaches programming concepts in the context of C#? Both types of book would help you accomplish the goals you stated, but are very different books. Essentially I was trying to ask you how you learn: do you learn best from a guided course? Or do you learn best from doing things on your own? I'll restate the "C# Pocket Reference" for a physical reference if you want something less dense than "C# in Depth."
I'll restate the suggestion of the "C# Pocket Reference" if you want a physical, reference-only book.
Thanks, that is actually what I was looking for, unfortunately there are only 4 files in their tutorial. 2 .cs files, a .txt file, and app.config. The thing is, it seems like a serious project, and I don't really know what I am doing, so I am assuming there is something that I am missing. I appreciate you trying to help.
Do you understand how the parallel lists work in this assignment?
How about a student Class and if you like to add new student in your listbox you create a new student object. Like this: [https://pastebin.com/eaWFBLPv](https://pastebin.com/eaWFBLPv)
 Naw. You can change the implementation details all you want so long as you don't change the name of the class. That's what encapsulation is for. 
Yes but i need to know how to display the selected items in the listbox in the textboxes after adding them.
doubt that, since powershell and wbemtesting both work just fine. 
Do you test views? Seems kind of weird to say "does the view contain these strings in it somewhere?" My controllers are, usually, a simple "Ok, pull this data and put it in the model needed for the view". Very rarely do I have anything complex. The only *practical* things I can think of that shoud be tested would be "what if you're given an empty ID from the URL" or "what if the URL is gibberish" or "what if the URL is 100MB of binary data instead of an ID". &gt; bad/strange input Aren't these your controllers? For instance I have two kinds of ID's. a GUID (which should be guaranteed unique) and a short, human readable, ID custom picked so it can be visually unique as well as verbally easy to communicate over a phone. For instance, this is one of the first things entering into the controller (after checking to make sure it's not null, it's a number and not binary data, etc). `inventory` is a class / table (for context). if (id.Length == 36) { // GUID -- We use SingleOrDefault in case someone copy/pastes the URL wrong inventory = (from i in dbContext.Inventories where i.InventoryId == id.Trim() select i).SingleOrDefault(); if (inventory == null) { // return error; bad id TempData["UserMessage"] = new Models.MessageModel() { CssClassName = Models.MessageModel.CssClassType.Danger, Message = "Inventory Id (" + id + ") is not found! Perhaps a number is missed?", Title = "Error", EndPageProcessing = false }; return View(returnModel); } } else if (id.Length == 16 || id.ToUpper().StartsWith("EPIM")) { // Short UI -- We use SingleOrDefault in case someone copy/pastes the URL wrong inventory = (from i in dbContext.Inventories where i.ShortId == id.Trim() select i).SingleOrDefault(); if (inventory == null) { // return error; bad id TempData["UserMessage"] = new Models.MessageModel() { CssClassName = Models.MessageModel.CssClassType.Danger, Message = "Inventory Short Id (" + id + ") is not found! Perhaps a number is missed?", Title = "Error", EndPageProcessing = false }; return View(returnModel); } } Now that I'm looking into it, it looks like the smart thing to do is shovel it off into a class bound by an interface (not sure why an interface is usually found in these instances? Seems odd) and that handles sanity checking instead of the controller. Seems needlessly complex but perhaps it's like that because it may get more complex in the future and you're avoiding having to refactor? Does that sound about right?
Yes, but this precludes you from returning framework classes like HashSet&lt;T&gt; and similar.
It's a bit hacky, but you can use a ListView instead and set each ListViewItem's .Tag property to the corresponding Student object. Doing this, when the user selects an item in the ListView you can set the textbox values to that of (listViewWhatever.SelectedItems[0].Tag as Student).desiredValue
Do this in your selectedIndexChange event handler [https://pastebin.com/y3ntGGhQ](https://pastebin.com/y3ntGGhQ) &amp;#x200B;
Is there a good reason for rewriting this in C# or are you just trying to learn the syntax? I use both languages. I even sometimes call powershell scripts from C#. I think both languages have their strengths. 
just a project of mine, I wrote a whole gui in powershell/wpf and trying to redo it in C# just to get familiar with it. 
Cool, I didn't know you could do anything but CLI with powershell. 
you can do WPF and Windows Forms gui's very easily. check out poshgui.com
Console.SetCursorPosition() ?
I'll have to check that out. Advanced features is where most C# tutorials fail. 
Your class has no inheritance path other than Object. 
How do I fix this
Sounds good thanks and let me know your thoughts ;) 
Remove the call to the parent constructor or inherit from a class that has a public constructor that takes a string. 
By learning how OOP works. 
I copied this code of another program and it worked on that 
Add `: Exception` after your class definition. You should read more on polymorphism and maybe on the new C# features because you're not doing optimal work right now.
Works now thank u, I copied this off work I did earlier this week and I didn‚Äôt copy the class name and that‚Äôs why I got confused
Read the error message, silly.
Got it now, copied this from a other project but didn‚Äôt copy name was raging when I didn‚Äôt remember to Inherit the exception clsss
Use the snippet tool next time. 
There are a lot of comments in here about learning inheritance, object oriented programming, etc. When I got started at this, the needed product was staring us all in the face and I was the only person willing to get some egg on my mug to try to make it happen. And I did. But there was a lot of code in there that I didn't fully understand. Mostly in terms of methods, classes, interfaces, static, public, private, sealed, etc. I was dumb to that stuff but once I was in the class or the method, I could write the for loops and all that stuff that was needed. So it.. got done. There was an ungodly amount of trial and error though. What I'm getting at is, I get it. Sometimes, you have to ride the horse before you know how to take care of one. This happens a lot with programming. A person doesn't often decide she wants to program before knowing WHAT she wants to program, right? That said, based on what I see here, you will make your life easier now by not feeling sidetracked with truly understanding inheritance, OOP, and how all the dressing AROUND the logic works. Once you have your head around this stuff better, you'll shake your head at how much time you wasted right now on stuff like this. Go get a book, make a weekend of it. Honest, you'll be glad you did. Or try this. I watched these specific videos for free, I think you can too? Scott Allen is the guy that honestly pulled me out of the weeds. https://www.pluralsight.com/courses/csharp-fundamentals-csharp5
I generally don't test views -- that the job of a QA group or automated UAT (user acceptance testing). You can use a validation framework like FluentValidation to test request bodies. You could also setup two different controller actions, one that binds to an `int id` as the argument and the other bound to `Guid id` as the argument. Let the routing engine handle which is which. Not all helper classes require interfaces. But it can be useful in IoC scenarios where you want to test-stub / fake / mock the thing you injected in to return errors / specific data. Note: See also the unit-of-work pattern for controllers instead of using a repository layer. 
Fantastic, thanks for the info! I've begun re-writing the app and will begin trying these better practices. It's a personal app I plan on open sourcing later so I have free reign to do what I want and why not start over with better practices?
You need to post some code if you want us to be able to give any substantial advice.
The *.NET Framework Design Guidelines* (FDG) recommends not returning classes like that. Instead they want you to return `WidgetHashSet` which could be implemented using `HashSet&lt;Widget&gt;`. **** There is a problem with the FDG though. If your `WidgetHashSet` directly inherits from `HashSet&lt;Widget&gt;`, then you cannot later make it inherit from `SuperHashSet&lt;Widget&gt;` because it may be used in a place that references the original base class.
Guy is clearly a beguinner, come on. OP, your class, since you did not specify any inheritance, automatically inherits from Object, which cannot be constructed with a string parameter. Just add after your class name ": Exception", and it should now register as a children of the exception class
But what if it is doesn't? If you are expecting the IFoo object to always be a IBar and something changes later, you need a way to catch it. Which means a hard cast `(IBar)item`, which isn't type safe because we've got a runtime exception which should have been a compile time exception. It's a bad situation to be in no matter what we do.
I don't get the hostility. Sure its an easy fix, an experienced cs dev will immediately spot the problem, but a beguiner might not. 
Got it forgot to inherit the exception class and btw can u tell me how to import a image into a logo
Gotta be more precise, boy
Removed: Rule 4. You'll have to include the platform (WPF, Xamarin, ASP.NET, Unity, etc.) you're developing for and what you've attempted.
Visual studio 2015
That's the development environment. What kind of application are you making? What is the project type?
If you still need help let me know. 
I just signed up, I don't know what is this. Well, I'm gonna solve the darn thing, then. 
Ok, thx
Thx, again
CodeWars is similar but I prefer it because you don't spend half your time struggling with parsing stdin input. It also has more features in general like the ability to see other solutions in your language so you can learn better practices. Do note that once you are past the fundamentals, learning c# requires learning design patters which you can't learn on those sites.
Thanks, I'll check that out! I'm familiar with many of the fundamentals due to experience with Java, however I'd like to run through them again just to iron them out. That aside, bulk of practical application will be at home. Mainly just looking for something to help practice and learn new concepts at work.
YES! ... like VS and resharper are fighting each other then both deciding to gang up on me....spent hours going through the forums. Finally got them to play nicely again....makes me wonder if the value it adds is worth the annoyance. I still like it but no longer love it like I did.... got a little fat, out of shape, holding me back. 
Repl.it has a web ide, and allows for multiple file generation, there's also dotnetfiddle.net
I've only skimmed through the video, but please explain why do you have a utility method to my madness execute a delegate that's pointing at a method, instead of calling the method directly?
Yeah I know... never been a big fan of making these custom types, but it does make it more robust, of course. &gt; There is a problem with the FDG though. Hm yeah. So I guess you'd have to always only derive from their custom collection base classes.
I subscribed to you so I can check the video out on Monday as I don't have much time untill then. Can't wait to watch it :)
Documentation. Or Stack Overflow.
This post might help you https://social.msdn.microsoft.com/Forums/vstudio/en-US/e40388ff-30ce-448a-9ef9-17db8b26e62f/how-to-find-a-specific-file-by-traversing-hard-disk-using-c?forum=netfxbcl
.Net Core can have standalone executables. .Net Framework cannot unless you statically link against Mono.
Dotnet core doesn‚Äôt rely on the .net framework and I think it would compile to a single executable though I haven‚Äôt tried to confirm. 
Visual Studio is the most common But GitHub is important because it houses ***source code repositories*** using git. Almost all shops I have worked for in the last 6-7 years use git and a source code repo/server for source code management. So learn git... because when you work with a team of 12 people, you'll need to understand how to manage source code and the history of all your changes on a team. You will not be working alone, and need to be able to use tools to merge code from multiple developers into a single repository, manage the code conflicts that come from that so you have a repo that is a source of truth when you make builds of the application(s). That being said git (or any modern source code repo system) is good for single person development as it can be used to back out bad changes or work on branches of code when you are doing something, perhaps, experimental that will not affect your working source branches.
This, you can detect the card type from the number typed in, so don't even bother asking the user the card type, just get it from the card number.
Removed: Rule 4.
Here you go: https://rg3.github.io/youtube-dl/
I agree, this is invalid syntax and probably causing the compiler + resharper to go wild
Looks like you need to read the docs - it appears that this section tells you hold to generate the solution files https://github.com/IntelRealSense/librealsense/blob/master/wrappers/csharp/readme.md
Is there a third party source that will explain git a bit better so my brain doesn't lock up. Or knowing how to use it with visual studio
In C#?
Am making a game where u have to match items, so I have 16 labels in a tablelayoutpanel and I have 8 images and I want to randomise them into 2 labels. I got one label in them all atm, don‚Äôt know how to change the size of it tho and how to randomise them into different labels, can u help me please
you can make an exe, but you can't make a portable exe. With any language. You could compile the same code base, 3 times, to get windows/mac/linux executables though. &amp;#x200B;
[YoutubeExplode](https://github.com/Tyrrrz/YoutubeExplode) is the library that [YoutubeDownloader](https://github.com/Tyrrrz/YoutubeDownloader) uses
If not solved, yet: Create a Student Class. Create a list&lt;StudentClass&gt; and use it as BindingSource. Bind your fields to the BindingSource. &amp;#x200B;
Sorry for trying my best :/
https://agripongit.vincenttunru.com/
&gt;https://agripongit.vincenttunru.com/ Excellent, I like the responsive design of this tutorial, ty
Thank you very much!
Take a look at CoreRT https://github.com/dotnet/corert still a work in progress from what I can see, and a few limitations like no support for reflection. .Net Core 3 is planning single exe support but half of the talk on Github at the moment on how this will work seems to be discussing a extract to a directory and running the application which is just ridiculous if you ask me.
Yo dude i want to use unity to make games and stuff for fun, i know c# prrety well (only language i know, 2 years experience). My problam is that i am having hard time to start. You got any tips on where and how to start it?
What is the constraint violation? Duplicate key, or null value, etc? As an aside, learning SQL so that you can create stored procedures in the db and then calling them with SQL syntax and SqlCommand (ADO.NET) is the way to go performance wise and career wise. It is faster too. If you don't want to go that route, use Entity Framework. It will do the SQL work for you at the cost of performance, but that too has a ramp-up. Might as well learn SQL.
What app has this functionality? I'm curious about it. I think C/C++ would be the best choice as you would probably want to call a Win32 API or COM, but a managed API may be available (or COM interop). As an aside for Win7, you can use the WinKey+Arrow to move the active window. Up WinKey+up arrow will maximize and WinKey+Right/Left arrow will put it to the side, splitting the screen exactly like you asked. For Win10, the Snap feature needs to be enabled for this to work.
Cant wait to have some spare time to test and play with this bad boi. Kudos on the work, I always found network stuffs to be pain in the arse,at least in my case! 
On inserting T2 there is a conflict between T2.FK and T1.PK. I can not change the underlying database I only have to fill data into it. My SQL knowledge is sufficient to do everything I need to do manually (create and link rows, update and modify data,...), I¬¥m lacking knowledge in C#. Sometimes there are too much possibilities .. &amp;#x200B; I think I found what I was missing: [https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/adding-existing-constraints-to-a-dataset?view=netframework-4.5](https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/adding-existing-constraints-to-a-dataset?view=netframework-4.5) &amp;#x200B; &amp;#x200B;
Yes, and that why i answered that.
The exact constraint violation is that T1 is updated and *T1.PK* (Identiy) is set by the database on commiting the insert (On writing this I think I should have mentioned it before. Sorry. ). *T2.FK* still is 0. Therefore Updating T2 obviously fails. (*(**T2.Fk* == 2) != (*T1.PK* == nn)). &amp;#x200B; &amp;#x200B;
I'll definitely try that when I got some free time again. I will start by implementing it as you said and see where I can go from there. In fact I wasn't even sure where to really begin, but now I've at least got something to try! :) Thanks for that comment man
\#1 Add a method which does the job for him.
&gt; Don't use an IDictionary instead of Dictionary because of that TutorialTeacher article/site. That is bad practice and I'd avoid that site altogether. I'm in agreement with you. I had seen references to the Dictionary object in a few threads here, so I wanted to look it up. That was one of the first results, and it was good enough to show me the syntax and the general concept (a collection of key/value pairs), but I didn't really trust it for much beyond that. Hence this post.
No, if you do self-contained .NET Core apps, you end up with a directory containing several dozen DLLs and other support files. You could probably use something like 7-zip's sfx mode to make it a single self-contained file, though.
Thanks for the fantastic write-up, this was very informative.
Thats sounded quite condescending honnestly lmao
Learning how to parse stdin is one of the more useful things that you can learn from one of those websites though
It's where I mostly learned C# honestly. It's good for beginners to get a lot of practice in a short amount of time
You may find it much more straight forward to have CRUD methods that validate the data and then call appropriate sprocs/service methods without the having to map the DataTable PK's, FK's, constraints and so forth in .NET and the db. 
The particular functionality I described with moving to "virtual" monitor (i.e. rectangle of the grid you designed) where the mouse cursor is positioned - the DisplayFusion app does that. As for designing grids like these in general - more apps can do that; Actual Multiple Monitors for one and I believe there's quite a few others if you look at website like alternativeto. The Win7 aero snap is almost - almost - there, but unlike with Win10, you can't win+pgup which would move the window to a corner thus taking up a FHD area (1/4 UHD) out of a UHD screen. You can only take half of UHD. So no dice for me. Also ideally, the grid would be even more custom than that, i.e. not just 2 by 2, but any combination really, suited to your usual apps of choice (again those commercial and freeware apps can do that). C/C++ then huh? That's my first lead then :-)
Thanks for the nice comment man. Definitely let me know what you think later on, especially if you think something sucks, so I can try to actually improve it.
I saw a video where a guy showed they were working on exactly this sort of thing. He plugged in a usb, containing only an .exe file and it ran by itself. Can't find the video.
I already thought of going that way although I like the idea of creating only a few SQL-Statements instead of some hundred. Do you have any idea of how performance might be affected? I¬¥m mostly creating invoices with T1 as IncvoiceHeader, T2 as InvoicePosiition, T3 PartInformation for T2, T4 PaymentCondition for T1 and maybe some more. By adding 100 invoices I will have do some 1000 statements as each T has a bloody identity column as PK. &amp;#x200B; I think I¬¥ll give it a try on monday, with a fresh head
For Microsoft Windows stuff, look to the native API's first to learn how/what to do, then see if there are managed ways of doing it if you would like to use managed code. There are exceptions, like for Windows Shell Extensions always use native code (per MS recommendation). The native functions (Win32 API) that would offer the core (identify, resize &amp; move) functionality of what you want are here: https://docs.microsoft.com/en-us/windows/desktop/api/winuser/. It will be a lot of work, but it would be fun and the Win32 API comes with great power. 
There are a few tools out there like https://github.com/Fody/Costura and https://github.com/gluck/il-repack
Yes. See this wrapper: https://gitlab.com/BrianAllred/NYoutubeDL
Here's a stand-alone exe .Net app that can run on either Windows or OSX, though it does sound like Mono might need to be pre-installed on the Mac (not clear): https://github.com/ServiceStack/ServiceStack.Gap
Ah gotcha. Wasn‚Äôt sure how it would handle all the library references. It looks like the devs of dotnet core are working on it though. https://github.com/dotnet/coreclr/issues/20287
A lot more information about your scenario, what you've tried so far, and the result you're currently getting is needed for anyone to be able to help you.
So I go image.size=(100,100) and it gives me an error
I understand my friend as life gets busy. Basically most of my channel is about motivation so browse around as you will find many topics about what you are looking for. Recently I started to show more hands on videos but the majority are about business of games and motivation :)
If it is a small scale app, the perf impact of using .NET formulated SQL queries probably won't matter. The performance impact of letting .NET build the SQL queries for you would need to be measured on a case-by-case basis. If you are using SQL Server, SQL Server Management Studio comes with a tool that captures the statements being executed. You could run that and capture what query the framework uses and compare the perf of that with a query that you design. 
Also tried image1.height=100; And image1.width=100; and I got an error 
It isn't that straightforward to resize an image. That property you are trying to set image.Size is read only, that is why you get an error. I wrote a method to resize an image a while back and it worked for resizing a lot of images from an ebay auction. Some images didn't come out that great and I didn't look into why. Here is a starting point for you (remove the Log call in the catch): private Bitmap ShrinkImage(Bitmap image, int maxWidth, int maxHeight, string filePath) { Bitmap newImage = null; try { // A quality level of 0 corresponds to the greatest compression, and a quality level of 100 corresponds to the least compression. int quality = 100; int originalWidth = image.Width; int originalHeight = image.Height; float ratioX = (float)maxWidth / (float)originalWidth; float ratioY = (float)maxHeight / (float)originalHeight; float ratio = Math.Min(ratioX, ratioY); int newWidth = (int)(originalWidth * ratio); int newHeight = (int)(originalHeight * ratio); newImage = new Bitmap(newWidth, newHeight, PixelFormat.Format32bppRgb); using(Graphics graphics = Graphics.FromImage(newImage)) { graphics.CompositingQuality = CompositingQuality.HighQuality; graphics.InterpolationMode = InterpolationMode.HighQualityBicubic; graphics.SmoothingMode = SmoothingMode.HighQuality; graphics.DrawImage(image, 0, 0, newWidth, newHeight); } EncoderParameters paramList = image.GetEncoderParameterList(ImageFormat.Png.Guid); ImageCodecInfo imageCodecInfo = ImageCodecInfo.GetImageDecoders().SingleOrDefault(c =&gt; c.FormatID == ImageFormat.Png.Guid); System.Drawing.Imaging.Encoder compEnc = System.Drawing.Imaging.Encoder.Quality; EncoderParameters encoderParameters = new EncoderParameters(1); EncoderParameter compParam = new EncoderParameter(compEnc, quality); encoderParameters.Param[0] = compParam; newImage.Save(filePath, imageCodecInfo, encoderParameters); } catch(Exception ex) { Log.Instance.Exception(ex); } return newImage; }
Damn that‚Äôs confusing
I like the concept, I'll have to check this out later. 
Removed: Rule 4.
Removed: Rule 4.
I'm guessing you're trying to access/alter your GUI components from a background thread. You need to make sure you change your UI only from your application's main UI thread. For example: https://stackoverflow.com/questions/1423446/thread-control-invoke
Finally, someone I don't have to put the video speed up on :P 
Thank you for your nice comment :) 
I think thats just a normal .net EXE that needs a .net framework to run it (mono or whatever). Op is looking for a native executable. 
In my experimentation, with the example provided by u/brendanjmckenzie, the overhead of an exception is essentially nothing when **not running in the debugger**. When running in the debugger, I found exceptions would cause the debugger to spend something like 13-15 milliseconds per exception. I think the reminder you're giving is therefore wrong in the general use case, exceptions are not inherently expensive and shouldn't be avoided because of performance concerns.
One day I will use this feature without even realizing it.
&gt; I have an abstract class with a lot of derived classes. I would like to provide overloading of the + and - operators in the abstract class and I am missing something. That sounds very suspicious. Do all of these classes behave like numbers? If not, you are probably going in the wrong direction. 
&gt; It seems, if the language will support it, I can do this in the abstract class and have no other code repeated. Nope. You need to define them on each and every class. 
https://dotnetfiddle.net/KM5uvv You'll need to define an operation on the abstract type which can be implemented in a less-abstract type to be used as a base for actual implementation, and the intermediate type that results will need to be generic in a way that lets it make some assumptions about *its* children. What is it you're actually trying to *do*, though? u/grauenwolf is right, and this all whiffs of an x/y problem.
This is great stuff! When is the most common times you use this? Over say json or xml.
The 2 most common usages right now are for networking (all networking in my game is done through ceras) and as a sort of game db for objects (individually persisting monsters, items, spells,... Even though they all have many direct references to each other, so they can all easily go into their own file). Another thing is save files, which would simply take way too long to save/load in any text based format because they would be too big. With ceras save/load round-trip is done in milliseconds (vs Json which I used in the beginning, where a round-trip would have taken multiple seconds, sometimes 15 or more). As for Json and xml: I always use Json for any sort of config thing. Anything where I want to go in and manually change settings with a text editor. XML is too verbose for that, and ceras is completely irrelevant here because it's a binary serializer (can't edit anything, well, unless you want to use a hey editor haha). I also still use XML for anything that is hierarchical in some way. For example "frame" (as in UI in a game, custom windows) definitions and so on. Json would be bad for that. In the end comparing a binary and a text-based serializer is really comparing apples and oranges. They are made with completely different purposes in mind, trying to solve entirely different problems.
Curious how this measures up to protobuf. Also, if you also use this for persistence, how do you handle versioning of data?
I implemented automatic versioning support a while ago. Check out SchemaFormatter.cs It's embedding the schema data into the binary. (its an option you have to turn on) I even have plans to add more versioning modes for very advanced use cases. Like a way where you can manage the schema data yourself so it doesn't have to be embedded in the binary (just a 4byte hash is written as a header then). As for protobuf, I didn't test it. But it's not much slower than message pack (which is afaik the fastest). There are lots of massive improvements left to implement and I'm working on it every day so I'm somewhat optimistic I can compete with protobuf and so on eventually :) But anyway, as long as it's fast enough for what I'm doing at the moment it's fine because it does **so** much more than protobuf or message pack. 
Negative. Most of my viewmodels don't have the underscore, I was just trying to break up the view model label more so it would help keep me differentiate the files that I have open. The intellisense keeps telling me to change it. It knows what's up. Anyway, this had happened before I ever tried the underscore in the file name.
Yes, they behave like numbers. The intent is to have it be a smart unit, and have operations be hidden from the implementation. An example would be (in pseudocode) Length a = new Length(4,Length.Inches); Length b = new Length(4,Length.Meters); Length c = a + b; Area d = a x b; // Ill figure this one out later, but it is an example of what would be a nice feature Console.WriteLine(c); &amp;#x200B; In this way, the user is responsible for making sure the units are correct for entry, and otherwise only when necessary
&gt;Yes, they behave like numbers. The intent is to have it be a smart unit, and have operations be hidden from the implementation. An example would be (in pseudocode) &gt; &gt;Length a = new Length(4,Length.Inches); &gt; &gt;Length b = new Length(4,Length.Meters); &gt; &gt;Length c = a + b; &gt; &gt;Area d = a x b; // Ill figure this one out later, but it is an example of what would be a nice feature &gt; &gt;Console.WriteLine(c); &gt; &gt;In this way, the user is responsible for making sure the units are correct for entry, and otherwise only when necessary Copied my response above down here for you. In addition, one could do the following Console.WriteLine(a.Get(Length.Meters)); &amp;#x200B; I have some of this implemented already, its just the magnitude of the copy paste for each potential unit that drives me a bit crazy. Seems like it should be doable some other way.
So what you need is not a base class. These should be marked as `struct` or performance is going to stuck. For your shared code you could strongly consider a code generator combined with "partial classes". This can create your repetitive code like operator overloads. 
Thanks! I'll look into it and see what I can make work. What do you mean by code generator?
I'm pretty certain ceras is very vulnerable to remote execution exploits. The fact that you don't need to pre-specify known types to the serializer means it would be trivial to execute code on the receiving end. There's an inbox serializer which suffers from this problem too, BinaryFormatter. If you don‚Äôt 100% trust the remote host, then you shouldn't use BinaryFormatter or Ceras. If you do trust the remote host, then why not just use BinaryFormatter? It's about as compact a data format that you can get.
http://www.findbestwebhosting.com/web-hosting-blog/index.php/best-asp-net-code-generator
Can you elaborate on this? Why is it vulnerable?
Can you send an object that when called / constructed, hoovers up files from the target machine user dir and sends them to some remote server? There's lots of ways to exploit remote code execution.
By example: https://github.com/pwntester/ysoserial.net Via binary serialization, you can exploit certain classes in the .NET Framework to make them do arbitrary things, like launching processes or even executing arbitrary code embedded in the payload.
*THIS!!!!!!1* post should be titled, "Introducing a super easy way to get completely and utterly pwned, C# .NET edition"
Something like resharper would catch that no IFoo would ever be an IBar but you are right, (as far as I know) vanilla VS won‚Äôt, although it wouldn‚Äôt throw with that code either so you‚Äôd just have a redundant if. 
It seems to only be vulnerable if you use it poorly (as is most JSON serializers.) By using the generic deserialize methods, (deserialize&lt;T&gt;) the caller is in control of what the object turns into. So unless there's a flaw I am missing, that handles the known type issue. Don't deserialize object, dynamic, or types that contain lambdas, etc and you should be fine. 
Great response!
Okay, I have one class rewritten as a struct. Sigh... copy paste., copy paste.... I'll look at that code generator and see if it is easy enough to learn or if I just need to bite the bullet and make a bunch of classes manually. Thanks for the advice on struct vs class. I knew performance could be a problem, but I was hoping to ignore it. I know in the end I would have regretted doing it that way.
BSON?
Honestly, I find it easier to just create my own code generator each time I need one. If you know how to write to a text file, you know how to create a code generator. 
Hold your horse cowboy, how the heck do you resolve circular references?
Absolutely NOT. 
Check out Viasfora. It colour codes the brackets and braces.
Got it to work, all i needed was to write these simple lines lol, thnks all for your help &amp;#x200B; &amp;#x200B; `private void lstList_SelectedIndexChanged(object sender, EventArgs e)` `{` `int i = lstList.SelectedIndex;` `txtID.Text = ids[i].ToString();` `txtName.Text = names[i].ToString();` `txtCourse.Text = courses[i].ToString();` `}`
And only few geeks like me will tell stories about `$@` and `@$`. :)
Hi! Thanks for your work, but let me ask some questions. Sorry if they are stupid or obvious, but i just want to know: 1. What about working with streams? Does it handle them correct, may I send a file without loading it in memory? 2. What about .net core? Is it supported or do you have any plans to support it? Thanks 
You can launch any arbitrary binary on the remote host with any parameters you like. There are classes in the framework which you can get to launch any process you want via the mechanisms used by serialization, ie construction and property setters. So you start off by downloading a remote executable. Then you launch it. This allows you to do anything that the remote process is allowed to do. 
Oh boy... I hope you see the problem with that solution. Even if it‚Äôs works, it‚Äôs so wrong on so many levels. But it‚Äôs not your fault, because you have to use three unnecessary lists. 
Interesting. Which framework(s) support it? I've had to hack out my own versions of stuff like this, so it might be a good time to clean up some crap. 
yes &lt;TargetFrameworks&gt;net45;netstandard2.0;&lt;/TargetFrameworks&gt; &amp;#x200B;
Binary formatter has 7 key limitations: 1. If you upgrade the version of .NET on either end, then serialisation may break, as the BinaryFormatter output may change with the .NET version. 2. Binary formatter serialises objects to 2x to 15x the size of other methods, such as ProtoBuf: https://maxondev.com/serialization-performance-comparison-c-net-formats-frameworks-xmldatacontractserializer-xmlserializer-binaryformatter-json-newtonsoft-servicestack-text/ 3. BinaryFormatter is up to 15x slower compared to ProtoBuf: https://theburningmonk.com/2011/08/performance-test-binaryformatter-vs-protobuf-net/ 4. BinaryFormatter is ugly to use. And I believe it requires a parameterless constructor or else it will throw mysterious errors (need to provide a reference for that). 5. It cannot serialise Dictionary&lt;&gt; (reference required). So you have to convert that Dictionary to a custom object that it can serialise, then convert it back at the other end. Painful. 6. It struggles with nested classes. With ProtoBuf, this is transparent (reference required). 7. You are forever locked into .NET, because no other language can ever read the output of the program, e.g. Java, C or Python. It is for these 7 reasons (and more) that nobody has seriously considered using the C# BinaryFormatter anywhere at my workplaces over the last seven years. TL;DR Avoid BinarySerializer like the plague.
If you really dig into it it'll last you maybe two years at best, depending on where you are starting from. I probably spend ~80 hours a week working in C#. 40 in my job (Client work, so a lot of exposure to other people's codebases), then ~40 in my free time reading, writing, and learning. The problem now is that the only time I get to apply most of what I've acquired is in personal projects. And often those aren't large enough really justify some of the upfront boilerplate for a certain patterns and architectures that I want to try more...
Maybe you can answer this. In one of my code bases, I've written quite a few tests, that through reflection, test to make sure that certain classes and models are written do certain ways. Like ensuring certain attributes exist on properties of specific types, or that all the properties types and names between entities and dtos matchup...etc What would you call those types of tests? They're testing the logic, they're testing the code base instead.
Why you should only use the checked keyword when necessary. FTFY 
Can't open, Error 404
FTFY? What is that?
Try again now. I was running a wordpress update Unless I exploded everything
Fixed that for you
Oh, yeah i was using it like that to emphasize differently
[https://i.imgur.com/Feg6HDF.png](https://i.imgur.com/Feg6HDF.png)
Wow. Can you visit www.devsanon.com?
[https://i.imgur.com/53DchYN.png](https://i.imgur.com/53DchYN.png)
I don't get it. Everyone else can access it. Could it be a country issue?
:) 
A few points on the benchmark itself: - you should always make sure the code execution paths are JIT'd before you run the timed part of the benchmark. In other words "warm it up" by calling the code paths first, such as doing something like this before the first stopwatch: var q = multiplyChecked(1000, 222); var w = multiply(1000, 222); - It might be safer/clearer to run the same method each time, and changed whether the method call itself is wrapped in "checked", rather than two differing methods. i.e. checked { var q = multiply(1000, 222); } rather than var q = multiplyChecked(1000, 222); - You have to be careful interpreting the results of micro-benchmarks like this. Yes - checked might be slower, but this sort of benchmark massively over-emphasises it in most use cases. If only 1% of your total execution time is running this mathematical operation, then the impact on the performance is negligible and it may be the safety benefit outweighs the performance drop. That's not to say micro-benchmarks like this aren't useful, but they can mislead quite easily.
I do get your point. Which is why I stated, if your code is guaranteed to not overflow, don't use checked
I would like to use a hey editor, where can I get one?
Yes - I think it is fair enough advice, I was just pointing out some areas of caution around the benchmark itself.
404.. Boooooo
&gt; You have to be careful interpreting the results of micro-benchmarks like this. At the very least, put your microbenchmark in a proper test framework like BenchmarkDotNet, which will try to establish clean, fair testing conditions by running inside its own process, flushing GC, disabling optimizations, etc.
I don't know if you need an abstract class for that. That looks like something you could handle with a concrete class (Length) and an enum (UnitOfDistance).
You too? Wtf? Another guy told me that. It works for all the others. What country are you on?
Yes, I got that part and agreed. I had o comment on that :)
JSON cannot contain functions, so following your logic, I do not see how JSON deserializers could be used poorly?
`object.toString().replace("this.","&lt;change back later or something idk lol&gt;.");`
I dont know if it is helpful, but LiveChart has a such Timeline, that is used for their charts. You can see a example on their page (https://lvcharts.net) if you scroll down to the "Powerful" section.
The error is cleartext_not_permitted.
&gt;It should be noted that the vulnerability lies in the application performing unsafe deserialization Isn't this true with any deserialization?
If you have a class that somehow evals strings or json objects - you are vulnerable. Even if this class just exists in some assembly. Json.NET has unsafe feature of specifying types. There was a [Ruby YAML](https://www.sitepoint.com/anatomy-of-an-exploit-an-in-depth-look-at-the-rails-yaml-vulnerability/) exploit. It's just easier to find such classes in dynamic languages with complex markups than in .net, but it's not impossible for .net.
Oh, I think it's android 9 not allowing non Https sites?
The scope of checked is static, not dynamic, so wrapping multiply in checked won't work. https://blogs.msdn.microsoft.com/oldnewthing/20140815-00/?p=233
That's effectively saying "if your code is guaranteed to have zero bugs". In most cases, if my code has a bug, I'd much rather get an exception than the wrong result.
True, true. But for example if input comes from a slider with predefined values or under a specific contract etc etc, some things are guaranteed
You can use var `var superLongNamedClassObject = new SuperLongNamedClassObject();`
1. `var` lets you omit the type on the declaration and use the inferred type of the assigned value. That would reduce your line of code to `var superLongNamedClassObject = new SuperLongNamedClassObject();` 2. C# 8 has a proposed feature to allow you to omit the type of a constructor when the compiler can infer it from context. That would reduce your line of code to `SuperLongNamedClassObject superLongNamedClassObject = new();` Other than that, there are some tricks you pull with generics (`T Build() where T : new() =&gt; new T();`), but not that's actually worth doing, especially once C# 8 rolls around.
You can use the `var` keyword. `var myVar = new SuperLongNamedClassObject();` &amp;#x200B; It is strongly typed and makes code a bit cleaner. It should only be used in situations like this though, the type should be obvious when using var.
Without any Benchmark.Net data posted in the readme, I'm having to guess that Ceras is likely slower than most serializers, if only for the reason that it is difficult to write fast polymorphic serializers without using a lot of gymnastics. Ceras is going to be dominated by string serialization time, since it doesn't use an Encoder to track the string writing on splits, using a length check instead first (which is nearly as slow as the write itself). There is now also System.Buffers.Text, which is faster than the Encoder classes. That being said, BinaryFormatter is crazy slow (and not recommended for use anymore), so likely faster than that. I'm not a huge fan of the API, because it requires you to manage your own serialization buffers, which most people are going to do poorly. A better approach here would be to use ArrayPool&lt;byte&gt; and have the framework manage that. This vulnerability, while it exists, is a bit overblown. You cannot execute arbitrary code unless that code already exists on the remote host. Unlike what most people think of when they think remote execution (I've sent arbitrary bytes which end up directly as machine instructions executed on the host), this exploit requires the code to be executed to already exist on the host and also be compatible with one of the usable gadget chains that can be constructed. As an aside, I don't know when Ceras was originally created, but today I would recommend Span and very much discourage unsafe and fixed. That being said, lots of serialization libraries use unsafe and fixed well and properly, and have not made the switch to Span yet.
Just don't use Unity for 2D games
That could be a possibility.
I need to install Https to my site
I'll look at it when I get to work on Monday. I'm a developer, that hates computers. So I don't touch him at home on the weekends. on the weekends I do small engine repair and stuff.
BinaryFormatter can absolutely serialize Dictionary&lt;&gt;. It's not particularly good at it, like every other type, but it is supported and it does work.
That's an impressive platitude considering that's what this course is in. 
Pretty much nothing is fast as json serializer these days.
The class it deserializes into can contain functions. And with options like Mef, reflection etc one can use any class that is creatable to make an attack out of. However as long as you deserialize as known, fixed types that are safe, you won't have issues. It's when you embed the type information and say "deserialize this into whatever it should be" that you run into issues. This is all true for both JSON, and this binary serializer. 
Cool :)
Very good point - thank you (answer updated)
Don't have an exact answer for you, since I don't know Unity and I don't write games, but I would be setting breakpoints everywhere and running in debug mode to make sure the execution happens the way it should. The only thing I remember about calculating hits in my CS courses was calculating when one shape occupied the same space as another, but I assume the Unity libraries cover that for you?
Not related to your question, but learning Linq will help reduce large if/else trees like you have in Attack(). You can replace the foreach with something like this which will have the same result. foreach (var collider in hits.Select(hit =&gt; hit.collider) .OfType&lt;CapsuleCollider2D&gt;() .Where(collider =&gt; collider.tag == "Regular_Enemy") { collider.gameObject.GetComponent&lt;Enemy&gt;().TakeDamage(redDamage); }
You should handle the exception rather than just throwing. 3/5s of something throwing an exception warrants some logic to handle it
They do work... At least on new Reddit ymmv
if you are going to denounce it at least provide an alternative... or a why
I‚Äôve got to do this course I. C# and it‚Äôs due at the end of next week, but that is definitely something I will look at when I have this sorted 
It looks like C# 8 is adding support for something like this. MyCustomObect obj = new(); https://www.infoq.com/news/2019/01/c-sharp-targeted-type-new
It would be interesting to see how fast the unchecked multiply with the try catch is. As I understand that can also have some runtime impact.
That is not a bad idea. I will try that next time
In a perfect world, you would not care what IDictionary does beind the scenes. Add(key) should allow a Get(key) that equals the previous added result. That's the beauty of a interfaces it ensures a contract. Ordering a beer (IBeerServer.Order) could be a Bartender.Order or Amazon.Order Both provide you a beer, one is immediately and the other does a few round-trips before it reaches you.
Or, just use WCF
Nah use it everywhere. Especially when catching the return value from a function.
Animations should have a "By" property, skip the To entirely
I'm not all that familiar with Unity but I think I remember there being a "trigger" checkbox on the rigid body of the game object that needs to be checked for things to interact with each other.
Do you have the colliders attached to your enemies etc?
How would you pwn someone using the binaryformatter?
what's the best solution for this? array class?
No. Good deserializers only deserializers known permitted types. Abitrary deserialization = abitrary execution.
You could, but then you're sacrificing readability of code. It's just preference I guess. 
Sorry for the typo, fixed it now :) 
I'm not. The type of an object only improves readability when it matters, and usually it does not. It's more often than not a signal to anyone reading the code that the type of this object is irrelevant.
I see someone else already posted an answer for the second question. But for the first one: Working with files should be no problem, you can easily split the file in parts and send it that way. I realize that beginners might have a hard time imagining what I mean or will imagine it to be too complicated, so I will give some extra care to your question in the third part of the blog post (that I'm still working on). 
Hey, look into reference formatter cs. It's actually a bit intricate especially when deserializing things again. Maybe I'll write a separate blog post about it since it would take too long to explain it in a comment here. But you can just take a look at the source code. ReferenceFormatter&lt;&gt; is where you want to look. But let me tell you; there are a few more things in ceras that are a lot more complicated than this ;P (dynamic switching to different schematic formats while reading something with version tolerance for example, that one was a real head scratcher for a long time) Let me know if that cleared things up. If not, I will write a blog post about it if people are actually interested enough 
Pdb no. Config - it depends, but most probably the main one should be included. 
&gt; Without checked 318 975,7 &gt; With checked 2 070 000 Number gore. What the heck?
Doesn't have to be "release". Release is just a name for a set of build properties, one that happens to be a default created when a project is created. The real property you're looking for is whether optimizations are turned on. If you modified your debug config to turn on optimizations, then it would work just as well. I echo your note about running outside the debugger. If you really want to go nuts, you may want to ngen your program too.
Thanks!
Hey, That's pretty much an issue with all serializer in existence. Json.net can embed type names as well. But regardless, I guess you point still stands. Id like to see a working exploit though so I can come up with an solution. I have a hard time thinking of one / imagining how it would work. I'm not saying there isn't a way though! Like how would you actually execute code? If it is trivial please show me how, I'd really appreciate it. Binary formatter though... That one has to be a joke. It's hilariously slow. It also has pretty much no options / way to configure it. 
Too slow and too cumbersome to use for my taste. If wcf works fine for you, then thats great! However if you want to compare them, then I'd suggest to at least look at how ceras is different from what wcf does (disadvantages *and* advantages) 
Show me a working exploit please. I'd love to fix it :) 
Thanks for making that list, those are the reasons why I hate binary formatter as well. There is also the fact that it barely has any options which makes things pretty hard. 
I put spaces to separate the 100s thousands and milion
Hey using span is a good idea. I was thinking about it for a while, but I was worried that it might break compatibility to .net4.5 or unity. As for the api, id love to make it more accessible if possible. It was designed that way to ensure people can easily reuse the buffer. Any concrete ideas how to improve that? 
yeah, BoxCollider2D. I did just find a warrning message on the Unity software saying the CapsuleCollider2D wont function without an enabled 2D effector on this Game Object. I have no idea what that means
Properties let you control access (i. e. set can be private, even though the property is public), and hide implementation (e. g. calling the get or set of a property can trigger events notifying other objects of changes in this object's state).
PDB stands for "Program Database" and contains debug information about your application, so you don't need to include it. The config file probably doesn't have to be included. The easiest way to check is just to move the DLL and EXE file to a different directory without the config, and then see if it runs properly.
If one is immediate and the other not, then they should be different interfaces, the latter exposing asynchronous calls. 
If it's on azure you can do it pretty easily. Just use azure cdn and point your custom domain at it then enable https
It's not. I bought hosting and domain at godaddy
Fair enough. You could still point azure cdn at it but would need to re-point a CNAME record at the CDN instance
Not a very good article. States the obvious "safety checks are not free", acts like that's a surprise bad thing, and doesn't bother to show a disassembly or anything indicating *why* checked operations are more expensive.
Hmm, I haven't done a lot of 2d in Unity. But yeah, trying adding the effector
I really feel like that's what you should have been doing in your post, but I don't see anything about WCF.
There are actually a lot of differences between the two, and there is a strong case to use properties (besides just convention). The biggest difference between the two is that properties are effectively methods that don‚Äôt take arguments. This means that their inner implementation can be changed without requiring callers to be refactored. It also gives you, as the developer opportunities to _do_ or _record_ things when properties are accessed or set. Fields are simple pointers to objects in memory - when they are accessed directly, you have no actual control over their access. This difference also allows you to place breakpoints on property access, which you cannot do with a field. Properties also allow you to set independent access settings for the getter and setter. It‚Äôs a common pattern to have a public getter and a private setter. There is no way to accomplish this with fields, without taking the Java approach and writing public Get() and private Set() methods to provide access to your private field, at which point all you‚Äôve done is accomplished what properties already provide, with more code, and less readable syntax. This is getting more subjective, but properties also just _look nice_. They have first class support in the language and are the first things I look at when I look at an unfamiliar object. They support the property initializer syntax, which allows simple DTO classes to be written and populated very quickly. Many libraries assume that properties are the only fields that matter on capturing the state of an object, including many serializers. Some people only use properties for fields that have at least one public member, but I use them even for completely private members. It is extremely quick to create a private readonly property, which I do frequently. And you are one keyword away from exposing this kind of field publicly should you change your mind about access during development.
That was a meaty reply! Thanks for the detail
Looking for someone to assist in migrating a bunch of .Net 1.0 C# code into AWS Lambda. Lots of CRUD code, but some slightly more complex operations as well (orders, activating accounts, billing, etc). We don't want to reinvent this codebase in another language, but need to make it more accessible for more modern front-ends.
I can certainly do that for a next blog post :) What are the things you're actually looking for though? Ease of use? Performance? Or something else? &amp;#x200B; I definitely want to do more benchmarks and stuff soon. So, let me know what you think, and hopefully I can include what you want to know in the future.
I'd also investigate ilmerge.exe if you want to combine that exe and dll into one new exe.
What? Take a look at MsgPack, Protobuf, ... Json is pretty bad if you \*actually\* want performance. Also it'd probably be best to compare specific serializers, like [Json.net](https://Json.net) or so with each other, instead of the formats themselves (because they have no speed, they're abstract descriptions of how the format looks)
PDBs help a lot when things go wrong. Meaningful stacktraces with line numbers go a long way. We deploy PDBs along with binaries to our production servers and this has saved our asses quite a few times.
I've added better benchmarks onto my todo list! &amp;#x200B; Also, as for the buffer management, I'm not sure about the scenario you are thinking about. Usually you'd just keep the same buffer throughout the lifetime of the program, no?
Look I'm just telling you what metrics the authors of [json.net](https://json.net) proved [https://www.newtonsoft.com/json/help/html/Performance.htm](https://www.newtonsoft.com/json/help/html/Performance.htm)
Godot can make true 2D games. But, there is a lot of chance that /u/helsbellz care about the performance gain and prefer to learn unity, or programming. Unity will have more ressource to learn etc...
Yes, but a pedantic point. Obviously if you set all the properties of a different build configuration to those that are set by default for Release you'd end up with the same. The point is that, out of the box, you have two build configurations of which one has optimisations and one of which does not. Anyone who knows enough to edit the properties in their build configurations will understand the context of the point without me massively caveating it. And for those that don't.... just use Release.
Works for me on Android 9 using DuckDuckGo 
Thanks. Good idea.
I‚Äôll check it out.
Ah, okay, so there are some situations where you might include the pdb. Thanks.
Are you from EU? Typically people use , for thousands separator when speaking English. 12,345.67 -&gt; 12345 whole number, .67 decimal part.
A better solution you can see in the second post. 
Hey no problem man, I meant no offense. If you want to see how badly [Json.net](https://Json.net) does take a look at this page, there's a comparison graph \*\*right at the top\*\*: [https://github.com/neuecc/MessagePack-CSharp](https://github.com/neuecc/MessagePack-CSharp) &amp;#x200B; Also please note that I'm not trying to bash json here! Not at all!! I love json, take a look at my other response where I explain how Json is pretty much unreplaceable for some scenarios. Text-based and binary-based serializers are so different that you can't even really compare them. They are made for \*\*completely\*\* different purposes. &amp;#x200B; Hope my previous reply didn't come off as too offensive.
I dont actually know what that means, since this course video isnt telling me anything about it.
To clarify, I'm not arguing that exceptions should be used for control flow, but rather countering the argument from the original post that exceptions should be *avoided because of their performance penalties*.
I do believe it actually is in the C# guidelines to use var instead of specifying the type in a lot of situations
Maybe chrome on 9? Anyway, I still need my https
Yes. Which is why I put comma for decimal separator
I will re-measure the performance impact. Please note, however: 1 - I did not write that exceptions should be acoided because of performance penalties. 2 - The example is simpler than my code because there are less levels to unwind, and that will affect the results. However, your essential point about the debugger is right. Note that a user co plained about the speed of the ‚Äúbefore‚Äù code, so I suspect there will still be an impact, but probably far less.
No offense taken. I know I haven't kept up with latest programming stuff lately
Always include `.exe.config`, it may contain binding redirects, without which your program wouldn't work
Easily. See my other comment, [https://www.reddit.com/r/csharp/comments/ahqwb2/introducing\_a\_super\_easy\_way\_to\_send\_c\_net/eeibbm3](https://www.reddit.com/r/csharp/comments/ahqwb2/introducing_a_super_easy_way_to_send_c_net/eeibbm3)
That's not how security works. As the author of a serialization library, the onus is on YOU to prove that your library isn't vulnerable. 
You're taking this the wrong way dude, relax. I didn't even say my library is free of exploits. The only thing I want to do is help people with a better alternative, and you're right there are probably exploits in some way. But one man alone can't do everything. That's why I hoped that someone could help me and point out where exactly things are wrong. But it seems so far nobody can, **and that's OK**! I'm aware of the problem, and I will work on it, I'll learn and eventually fix it. It is not at all my intention to force some faulty thing onto people! I'm trying my best here, but I still have a lot to learn. Don't take me asking for an example as an insult; rather interpret it as a request for help. I hope that clears things up a bit. Also one last thing: Ceras has a `KnownTypes` property that you can use and a setting called `SealTypesWhenUsingKnownTypes` **which defaults to true.** That should protect against the vast majority of potential exploits (if there are even any), since it prevents creation of objects that are not in the KnownTypes list. So yes, I really am aware of the issue. The only thing you can really blame me for is not mentioning it even more, and after reading my opening post and the blog post you'll notice that I mentioned multiple times that it's just an example. I'm planning to elaborate on this issue and many others in Part 3. But maybe I should have only posted here once I've completed all parts? :/ Anyway, I hope that clears things up a bit. 
You know.. it's is really easy to write a serializer in C#. In fact, it only took me a week to write [https://github.com/izackp/AutoBuffer](https://github.com/izackp/AutoBuffer) which was quite fun. It seems both of ours is pretty similar though mine has way less features. I may steal the object recycling idea, could definitely be useful. I'll definitely keep an eye on it. The reason I wrote my own is because I wanted the smallest data possible during serialization. I'll have to experiment with yours if I find the free time. I also noticed this on your todo list: It would be really cool to support the "capacity-constructor" This is pretty simple you can check it out here: [https://github.com/izackp/AutoBuffer/blob/master/AutoBuffer.Deserialize.cs#L187](https://github.com/izackp/AutoBuffer/blob/master/AutoBuffer.Deserialize.cs#L187)
Click on the game object and then in the inspector add component and then search for the name
Interesting! Maybe we can work together or something if you want :) As for the capacity constructor, sorta got that planned through already. There are some issues with the reference serialization though, but I've got hat mostly solved. The only thing I need right now is some free time (and energy!) to start with all that. It's interesting that you also made your serializer because you wanted the smallest possible size. Maybe our projects can learn a trick or two from each other. But then again, Ceras needs to embed some extra information in order for reference-serialization to work correctly. But it does some pretty interesting optimization regarding that already (like completely emitting the type when the object type matches the field/property/indexer...) Also, you're probably using SetValue and the likes because they're fast, maybe take a look at SchemaDynamicFormatter.cs from Ceras to get some ideas to improve that (IF you even actually have need for that)
Sorry for sounding rude but these are the results... An inexperienced, confused programmer winding up on r/csharp with a question that has nothing to do with the C# language and would be better suited for a Unity-specific subreddit. What the other poster was getting at might have been a platitude, but it was not entirely meaningless: learning 2D game development in a fully-fledged, professional 3D game engine is pretty overkill, unless you really, _really_ need those 3D transitions and effects. Starting from scratch will not only help you get better at C# (or whatever language you end up using), but you'll also begin to understand how actual game engines work and finding solutions to your problems will get easier and easier. In contrast, when you're writing C# code on Unity you have to keep in mind (and understand) that: - You're not running on .NET, but on Mono. - You're not writing programs, but scripts. - You're not managing the game loop, Unity does it for you. - You're not designing and implementing the game's systems, just gluing them together (so you either understand them in the first place or you won't know what you're doing). [These](https://unity3d.com/learning-c-sharp-in-unity-for-beginners) tutorials teach you almost nothing about C#, only how to use it in order to write behavior scripts for Unity. In other words, they don't teach you how to be a programmer and how to acquire that mindset, which is what you need in order to debug your games and in order to ask the right kind of questions on the Internet. 
What would the name of this effector be? Since I‚Äôve already got a bubble collider on it 
Seeing the components attached to each gameobject would help. From only looking at the code, I see you're referencing a box collider in the enemy script, but you're checking for a capsule collider in the player script. Make sure that you're checking for the right collider. Another small thing is that instead of bitmasking the layer yourself, you can just call `LayerMask.GetMask("Enemy");` and just use that as the argument. I won't be able to figure it out with just the code, but you should start to learn how to debug. Put a debug.Writeline statement inside your if statement in the Attack function and see if the debug log shows anything.
I'd search for effector. https://docs.unity3d.com/Manual/Effectors2D.html
You don't. Properties are syntax sugar, you don't need them at all. Others have replied with good use cases for them. 
Even more similarities, we both emit type data lol. This is a pretty cool project you have going, but like you I'm also plagued with a lack of free time with other projects and goes. Though, I'll definitely take a thorough look at it sometime in the future. 
SOLID please :'(
In simple terms. consider properties a way for you as the developer to have control of what exactly happens when values are retrieved or set, whereas fields are purely a place to store data and nothing else.
In simple terms. consider properties a way for you as the developer to have control of what exactly happens when values are retrieved or set, whereas fields are purely a place to store data and nothing else. A field can only give someone exactly the value stored in the field of the instance of a class, while a property can go look up some completely separate resource, like a website, or an internal file. You can't validate data input to a field other than the data type, but properties allow you to verify that the incoming value conforms to the right criteria.
That's pretty cool man! That's an interesting looking game. You releasing for android/ios?
Not sure what you mean. I'm aware of the solid principles, but then again they're guidelines that (once you become experienced enough) know when to use and when not to use. But ok, lets assume there's a way things can be improved. How exactly would you clean things up? Maybe start by finding just one class or .cs file that would profit from it the most, and then outline some steps that *you* think would make sense. Maybe I can take that as an inspiration to apply it to the whole project? But then again, most classes are either (1) pretty well structured, or (2) have to do things in that way to maintain performance. The best example would be the type lookup stuff (like GetTypeMetaData() etc), that I originally had in an extra class, and then merged it into the main serializer. Anyway, I'm definitely open to improving the structure in the future, but only if it doesn't interfere with performance. :)
Ah yes, if the sender can decide what class it gets deserialized as, that would be a complete shit show potentially. Never even thought about that option.
Thanks man that game actually released already got iOS, appleTV, mac, and Android. This is a video I took after to contribute to the developer community by teaching them few things as I learned through the process.
I think I need to provide a preface for the rest of this comment. I work for Microsoft and am on the team which owns serving of BinaryFormatter. What I've written below is a correction of facts. I am not advocating that most people should use BinaryFormatter. There are a few places where it would be a good fit for new development, but they are very few and most should use alternatives for various reasons. I list a couple of reasons why someone might choose BinaryFormatter at the end. Having said that, there's quit a lot of corrections that need to be made about your comment. 1. This shouldn't be true. Sometimes mistakes happen though and they are corrected. I was involved with helping to fix a regression that happened in how the [CultureAwareComparer](https://referencesource.microsoft.com/#mscorlib/system/stringcomparer.cs,131) was serialized after they made a change which broke serialization. I helped the owning team make the correct fix. You should have the expectation that serialization of framework types doesn't break between version releases. If it does, it's a bug and will usually get fixed with urgency upon discovery. 2. I hadn't seen this. It's quite interesting although the author has missed a few things which could help the in-box serializers. For example, he's serializing to a Stream using DataContractSerializer. Instead, he should create a binary xml writer around that stream and serialize to that. It uses a dictionary which will shrink the output significantly. He should also pre-allocate the stream to be big enough for the output otherwise the stream is growing as you write more to it and that's adding noise to the measurements. BinaryFormatter attempts to represent the exact object structure which means duplicated strings will be duplicated in the output. I suspect the results would be quite a bit different if string interning was done. Although String.Intern is not a good idea for general use (it holds a reference to the string for the process lifetime, other similar mechanisms would be better) it would be easy to implement and I'd be interested to see if there's a size and time difference. I might experiment with this if I have time. 3. Another interesting blog post that I hope I have time to investigate further. I will say that ISerializable can produce bigger output as it outputs the key names used in the object data. 4. It does NOT need a parameterless constructor. It uses [FormatterServices.GetUninitializedObject](https://docs.microsoft.com/dotnet/api/system.runtime.serialization.formatterservices.getuninitializedobject?view=netframework-4.7.2) to create the instance then it populates all the internal fields. 5. Not true. I think you are thinking of XmlSerializer which can't serialize dictionaries. DataContractSerializer can though. 6. Absolutely not true. BinaryFormatter works very well with nested classes. CultureAwareComparer that I mentioned earlier is a nested class (the problems were due to an implementation change which modified the on-wire format and versioning was done incorrectly). 7. This is true. That's the same with any data format though. You need support for it on multiple platforms. When protobuf was first designed, it was an internal implementation to Google so it wasn't just platform restricted, it couldn't be used with people using the same platform outside of Google. Then they released the spec and other people implemented that spec. I don't see this as a downside though. When writing code, if you don't have interop as a goal, you don't limit yourself to only use things which interop. If interop across multiple languages is a goal, then obviously you choose a technology which achieves that goal. You should always choose the technology which fits your needs the best. If you want human readable output, then you should choose XML or maybe JSON (less structured so will be more difficult for a human to read some data, depends on your use case). So of your 7 reasons, 1, 4, 5 and 6 aren't true. 7 is simply a case that you pick the right technology for the job and if it doesn't fit, then don't use it. 2 and 3 are definitely interesting reasons. You have a lot of mis-information, it does the community a disservice to list so much negative things which are incorrect as people might believe you. Here are some reasons why you might want to use BinaryFormatter. 1. If you have a support contract with Microsoft, they will support you with any problems with BinaryFormatter. Is there someone you can pick the phone up and get expert support from for the other out of box serializers? What do you do when you are losing money because some of your software isn't working right and it's a problem with serialization and you don't have the in-house expertise to work out the solution? 2. Some organizations have a requirement not to use third party code. This can be for regulatory reasons such as security auditing. There has been more than one recent case of open source projects being hijacked by malicious parties and a malicious payload getting into the package management system. Some types of software (think government, financial, medical etc) can't take the risk of this happening. In which case you need to be very careful about which libraries you use and that will rule out third party serializers. As I said, BinaryFormatter isn't something you should generally use in new development unless there are specific reasons to do so, but it doesn't have most of the problems you listed.
I suggest you read my response to his comment as most of those reasons are incorrect.
Looking at the list of features, it says this: &gt; Ceras dynamically learns new/unknown types while serializing. New types are written once in compressed form, thus automatically becoming a known type. If this isn't the default, then this could be worded better. As soon as I read that, I read "exploitable".
https://github.com/YaccConstructor/QuickGraph I've personally rolled my own usually; but this came up with a quick google.
That's the problem with ceras. It can deserialize unknown types. It's one of it's listed features.
It's talking about deciding how to serialize/deserialize, not *what* to serialize/deserialize. As in the layout of types, etc. Having deep dived into Newtonsoft code a few times, there's a similar learn/cache step involved there as well. It certainly appears to have code paths that if used unwisely could be exploitable. But the code examples are all generics without the risk. Considering the most popular . Net serializer (Newtonsoft) contains similar potentially exploitable functionality, I don't hold it too much against this library. 
Ah, I didn't see that reply, I'll read them, thanks!
As soon as you allow the data stream to specify any class available at runtime to be deserialized, there are multiple ways to do arbitrary code execution. As soon as you can launch a process, it's game over. Even if you try and blacklist classes, people will find new paths to do the same thing. Another things you can do is delete arbitrary data. For example, if I can convince you to deserialize an instance of TempFileCollection, I can populate it with a list of files I want to delete. There's a Finalizer on the class which when garbage collected will delete all those files. Having any ability to bypass a known types mechanism will result in someone else owning your system if you accept data from untrusted sources.
Span is really only of use in .NET Core. If you decide to either deprecate .NET Framework support or fork your implementation, I suggest you wait for the UTF8 string support that's coming to .NET Core. In DataContractSerializer, it's typically 30% of CPU usage used for UTF8 encoding/decoding and that will almost disappear completely if using a UTF8 string class.
Hmm, you're right, at least partially. If one uses Ceras for networking, then they should definitely use "KnownTypes" and not use the learning thing. That being said, I'm still reworking that functionality to make it more secure. As for delegates: that's not intended to be used with networking of course. And it only serializes delegates to static functions (which, yes, could be problematic as well). All in all I'm working on improving those things. Not sure how to protect people against obvious misuse, but I think I can definitely reduce any pitfalls people might encounter. In part 3 of my guide (which is about optimization, problems and their solutions, security, ...) I'll make it known that this problem exists and people should be aware of it. If you have any suggestions how to do better please let me know. It's the first time I'm really trying to build something large for the public and it's not like I have any bad intentions like making stuff that is easily exploitable. Instead my primary goal is usability, making stuff where you can experiment quickly and try stuff, while still maintaining top performance. edit: Serializing delegates was actually a feature request by someone else who has no intention at all of using it for networking (he's using ceras as a save-state thing for his emulator, because it can deal with readonly fields). So maybe having some sort of "usage profile" would be an idea?? Like "ur using it for networking, in that case you have to use known types + preventing new types of being learned" or so? 
The json.net benchmarks "cheat" a little. They only serialize as far as a string. Converting a string to byte[] for writing to disk or across a network adds a LOT more overhead. Taking that into account, it often isn't even able to out perform DataContractJsonSerializer.
Take a look at this [repo](https://github.com/pwntester/ysoserial.net) that someone else has already posted. It provides examples how to exploit multiple existing serializers using various gadgets. It shouldn't be too hard to make an exploit runner for ceras based on that.
I see, that sounds really interesting. Thanks for making me aware of that! I'll probably have to research Span some more to really make an educated decision. Unity is recently more or less ontop of things regarding .net standard. If I don't get many people telling me to keep .net framework support (which will likely be the case) I think I'll really deprecate it eventually. 
1) hire literally any consulting company that can do the same thing ms does. I've gone through full Ms support. Was wasteful garbage. Ended up billing is a ludicrous amount and they fixed nothing. We were requesting help finding a memory leak. Turned out to be a bug within ado objects where in a very specific case related to fire house objects being reopened that it would or orphan connection objects and actually recreate a new connection object. I found it myself without their help, eventually.
&gt;And this is where it all falls apart. Even the C# compiler is aware that adding the checked keyword is adding a processing overhead, so why would you? Performance is not everything. In fact, I work in a field where *correctness* is everything and there this kind of stuff wouldn't fly. Because often (almost always in the industrial world) correctness is more important than speed. Also, it depends on the compiler and optimization level how much overhead this adds. 
are you saying you want to define the array contents in-line? if so, you can do this: string[] names = new[] { "Name0", "Tyrone", "Name2" };
It does seem that serializers are very dependent on application. I do have to say that in some of our software I did some benchmarks and we were using json.net and imo at least over the network it was slow, something like a thoroughput of only .1 Meg/s I was getting
Please do not do that.
thanks
You can, if the array has been previously declared.
if you're asking why you can't do this: public class Blah { string[] names = new string[3]; names[1] = "Tyrone"; } it's kind of just because that's how the language works and it's how most languages work that have classes. if you want to do stuff like that, you put it in a constructor.
How do you deal with misbracketed structures?
What is a misbracketed structure ? I never heard that word before ?
 Random rn = new Random(); imgarray[rn.Next(0, //Your array size in number)] = otherarray[rn.Next(0, //Your array size in number)]; &amp;#x200B;
Do I do this in a method or what?
https://www.microsoft.com/en-us/download/details.aspx?id=27224 Download all of these, then choose a different voice. My bet is TELE would be more robotic, but it's hard to say without trying it. https://docs.microsoft.com/en-us/dotnet/api/system.speech.synthesis.speechsynthesizer.selectvoice?view=netframework-4.7.2
well, try this if you want to randomize them all: public static void Randomize() { using (Random rn = new Random()) { foreach (var image in imgarray) { imgarray[rn.Next(0, imgarray.Length)] = otherarray[rn.Next(0, otherarray.Length)]; } } } &amp;#x200B;
Maybe he's asking what happens if you fuck up the JSON structure, miss a }, " or ] etc? I assume you'd test it before deploying changes or revert to the previous settings if it didn't pass muster. (I could be wrong in interpreting his question though)
Giving me an error with declaring the Random and otherarray doesn‚Äôt exist in this context 
Yeah I have an option in the game where I load the levels as I play and can reload them as I make changes, so yes you are totally correct that if something is misplaced it would break the level. The JSON deserializer will throw an exception and therefore the level won‚Äôt load. I use source control for everything so if I find an issue I keep track of the changes. 
&gt;But maybe I should have only posted here once I've completed all parts? Nah thanks for sharing it's a decent library, I was slowly working on something similar although your approach seems optimal, don't mind the overly dramatic/bitter users. It's clear you were seeking more details about the potential exploit.
Probably the safest way to tackle this security issue is whitelisting types. That is, your serializer should only create instances of types if the type in question has been explicitly declared safe by the consumer by putting it on the whitelist. &amp;#x200B; IMO whitelisting should be an OPT-OUT setting in every serializer which deals with polymorphism. This would prevent inexperienced consumers of the library from opening a security hole by accident. (E.g. I ran into this problem in regards to Newtonsoft.Json. It took me some effort and a decent amount of code to handle polymorphism reassuringly. But not everyone will do the homework even if they're aware of the problem!) &amp;#x200B;
You are totally right, and I think we're getting into a bit of a dilemma here. Serializers that are "hard" to use (where what hard means is obviously up to every individual) are less likely to get used / gain popularity. At least in my opinion. I always try the thing that seems to solve my problem in the simplest way. But on the other hand it's just not a good idea (in fact, a horrible idea) to leave that kind of pitfall to users. Sure one could argue that everyone is supposed to do their homework, but we already know that there are many who don't even if they know better. I think I subconsciously assumed only people of exactly my knowledge (or people who know even more than me) using the library. But you are right, it's not good as it is, that's for sure. I think the idea with the sort of "profiles" (like pre-sets of SerializerConfigs) would probably solve this nicely. It could enforce that people using it in a networking context will definitely be protected from those issues, while other (more experienced) users could use a sort of "custom" configuration (which would be exactly what I have right now).
No need for caveating. "turn on optimizations" is a short, precise, unambiguous sentence for conveying your intent. You'd figure that software developers would prefer precise intent..
Unfortunately "turn on optimizations" is not the only difference between "release" and "debug", what is generated in the pdb also is different. And loading pdb at runtime takes time as well. The post should also mention to not attach any debugger when doing benchmarking, might seem obvious but I have seen people missing that point.
When you‚Äôre working with arrays, the first index starts with 0. Try something like this string[] names = new string[3]; names[0] = ‚ÄúTyrone‚Äù; names[1] = ‚ÄúPerson1‚Äù; names[2] = ‚ÄúPerson2‚Äù; 
Arrays have to have a definite size. Without first declaring the size of the array, the computer does not know the amount of memory to use for the array or how to structure the array. If you don‚Äôt instantiate the array before declaring values, the computer doesn‚Äôt have any instructions on what to do with the value. names[1] = "Tyrone"; doesn‚Äôt work because the computer doesn‚Äôt know if it should save space for you to later add names[2] and it is very bad practice to assume that the computer will assume that you were assuming it would infer the existence of names[0], however obvious a leap that would be. So you instantiate the array clearly indicating its size (string[] names = new string [size];) and then assign values to the specific indexes of the array. You can technically begin assigning values on the same line as described, but that is a specific syntax issue. depending on the situation and how it is used in the code this could be seen as clunky or unreadable, but in other instances it could be very intuitive and save space.
This seems nice, but there seems to be very little documentation (or it is very hard to find).
I'm not familiar enough with your library yet to make specific suggestions, so I can share only some general ideas: I think it would be nice if there were a few security levels or profiles of which consumers can easily choose the right one for their use case. I think of something like this: * strict - all types instantiated by the serializer must be registered on the whitelist * relaxed - whitelist is enforced only when polymorphism is encountered (when the type to instantiate differs from the static type of the related field/property) * don't care - types are not checked, devil take the hindmost... Then we could have the "strict" or "relaxed" level/profile/whatever as the default behavior. I think "relaxed" level would be a good trade-off as it wouldn't require configuration if polymorphism isn't needed but it would allow instantiating only those types which are explicitly specified by the consumer either in the data model (or in the whitelist).
For the same reason you can't do: &amp;#x200B; `int i;` `i = 5;` &amp;#x200B; &amp;#x200B;
It's a preference thing. Some people prefer the explicit declaration style but I embraced var fully when I learned C#. Code is much easier for me to read when the variable names are neatly left-aligned and there aren't a bunch of distracting type names cluttering my left margins. I think of it a bit like audio or image compression vs raw. Most of the time you don't really notice the "missing" information.
Ditch the `using` block here. I don't think it's compatible with `Random`
Removed: Rule 4.
Which is why if your code could overflow you should use it, or you should use the compiler option
I would look at MonoGame, which is based off of XNA. I find it to be pretty straightforward for basic 2D drawing, though it lacks any GUI layout tools.
Yep - It's not a supported language at this time, but the buildpack language works great on the free hobby tier. So free is pretty good.
So are you making a game or program? In case of a game you can use mono related engines like unity3d or I believe cry engine. Of course you have options to write all UI from scratch but not with c#
It's a text-based video game. It's kinda like a visual novel, but much of the prose is procedural descriptions of things. I'm quite proficient in Unity3D, but I would prefer something more lightweight, and tailored more precisely to my needs. I basically just want to be able to draw text and GUI to the screen, and be able to gather input. In the future, I might want sound.
So you may use WPF as modern UI framework. For text based it should be enough. Then you may want to learn MVVM pattern to untie your game logic from it's appearance... 
I'm not sure if that's what I want, but I'll have to read more about it. Thank you!
&gt; Properties also allow you to set independent access settings for the getter and setter. It‚Äôs a common pattern to have a public getter and a private setter. There is no way to accomplish this with fields, without taking the Java approach and writing public Get() and private Set() methods to provide access to your private field, at which point all you‚Äôve done is accomplished what properties already provide, with more code, and less readable syntax. Properties are just a compiler trick to manage all the get and set methods behind the scenes.
Wpf/uwp would be easiest to go in that case. 
if you want a ready-to-use text based (or visual novel) game engine, you may search for those words on github or google. There are quite a few of them/ The first you should think, that game logic can be done without any interface at all. You can write logic, test it with only debug messages, and then make any UI, that fits your game. You even can make several and switch between them
Your second paragraph is pretty much my intent. I've already abstracted all of the code, so switching between different engines/wrappers should be very easy.
Merged
Maybe it's a bad advice but... You can try and learn asp.net MVC core if your logic is well tested and abstract. Then your interface will be a browser. In fact, you can share your game by hosting it and sharing a link to webpage. Other option is to release a game as Telegram bot. It's not hard at all to write a Telegram bot, and it have some good built in interaction tools. That's why we already have some good text based bot games on this platform. That suggestions are based upon thought about the ease of delivering a game to a player.
You rotter!
Keen to see what ImageSharp makes of it and if we can code a workaround. Thanks for sharing
How about this? https://github.com/SadConsole/SadConsole Gives you a lot of control over how the text looks (e.g. with animations, effects, complex UI elements, etc.), but it also has a particular "old-school" style. Disclaimer: I haven't used it myself, but have heard good things.
Dated, but still very useful.
Aaaahhh validating the data input is a good point.
ohhhhhhhhhhhhhhhhh .... I thought it meant "For That F*ck You"
Always use TryParse if you know that input may contain badly formatted data. Exceptions are for when you should not have badly formatted data, but may have it in exceptional situations as you say.
What's the question?
i need an array to work so need some help on it really every time i click button the year moves forward and the amount of people starved is calculated i need an array to store the starved for each year up to year 10 then display the average of these starved &amp;#x200B;
Still don't get what you want. Just make int array or list. What's the problem?
I don't know where to start or where to put it, I've got a code that my lecturer gave out with slideshow but can't get it to work 
I don't know where to start or where to put it, I've got a code that my lecturer gave out with slideshow but can't get it to work 
Wrong results The multiply method get's inlined, while the multiplyChecked is not because it contains a "hidden" throw statement. Also the Try/Catch **does** have a small impact on performance.
It's a bit hard to answer without context. What does the code look like? What is the shape of the data 9in term of classes, properties, etc.)?
This is the code I have so far // variables int year = 1; int arrivals = 0; int population = 100; int acres = 1000; int harvested = 0; int rats = 5; int trading = 18; int ratsAte = 0; int bushels = 2800; int bushelsHarvested = 0; int bushelsTrading = 0; int plague = 0; int starved = 0; private void btnAllocate_Click(object sender, EventArgs e) { // moves the game forward a year every time the allocate button is clicked year = year + 1; // random amount of people come to the city Random random = new Random(); arrivals = random.Next(1, 16); // plague that halfs the population Random random4 = new Random(); plague = random.Next(1, 21); if (plague == 1) { population = population / 2; MessageBox.Show("You were hit by a plague, half your population died"Ôøº; } else { plague = 0; } // working out the amount of people starved if (int.Parse(txtFeeding.Text) &lt; (22 * population / 2)) { MessageBox.Show("You starved " + population); } if (int.Parse(txtFeeding.Text) &gt;= (22 * population / 2) &amp;&amp; int.Parse(txtFeeding.Text) &lt; 20 * population) { starved = ((20 * population) - (int.Parse(txtFeeding.Text))) / 20; } // possibilty of rats Random random2 = new Random(); rats = random.Next(1, 11); if (rats == 5) { ratsAte = bushels * 10 / 100; lblRats.Text = "Rats ate " + ratsAte + " bushels."; } else { ratsAte = 0; lblRats.Text = "Rats ate 0 bushels"; } // new population total population = population + arrivals - plague - starved; // randomised number for trading Random random3 = new Random(); trading = random.Next(17, 27); // calculating the amount of acres that are left acres = acres + int.Parse(txtBuySell.Text); //randomised number of bushels harvested per acre Random random1 = new Random(); harvested = random.Next(1, 6); // calculates the amount of bushels harvested and stores it in a variable bushelsHarvested = harvested * int.Parse(txtSeed.Text); bushels = bushels + bushelsHarvested - ratsAte - int.Parse(txtFeeding.Text) - int.Parse(txtSeed.Text); // resets the textboxes txtBuySell.Text = ""; txtFeeding.Text = ""; txtSeed.Text = ""; // changing the lables to show the new information remaining labels lblBushels.Text = "You now have " + bushels; lblNewPeople.Text = arrivals + " people came to the city."; lblHarvest.Text = "You harvested " + harvested + " bushels per acre."; lblPopulation.Text = "The city population is now " + population; lblTrading.Text = "land is trading at" + trading + " bushels per acre."; lblYear.Text = "In Year " + year + ", " + starved + " people starved."; lblRemaining.Text = bushels + " Remaining"; } private void txtBuySell_Leave(object sender, EventArgs e) { // buy/sell calculation if (int.Parse(txtBuySell.Text) &lt; 0) { bushelsTrading = Math.Abs(int.Parse(txtBuySell.Text) * trading); } else if (int.Parse(txtBuySell.Text) &gt;= 0) { bushelsTrading = -int.Parse(txtBuySell.Text) * trading; } bushels = bushels + bushelsTrading; // calculating the amount of acres that are left acres = acres + int.Parse(txtBuySell.Text); lblAcres.Text = "The city now owns " + acres + " acres."; lblRemaining.Text = bushels + " Bushels Remaining"; } private void txtFeeding_Leave(object sender, EventArgs e) { // warning user they dont have enough bushels if (int.Parse(txtFeeding.Text) &gt; bushels) { MessageBox.Show("You do not have enough bushels in store"Ôøº; return; } lblRemaining.Text = (bushels - int.Parse(txtFeeding.Text)) + " Bushels Remaining"; } private void txtSeed_Leave(object sender, EventArgs e) { // tells user that they can not seed more than 10 seed per person if (int.Parse(txtSeed.Text) &gt; (10 * population)) { MessageBox.Show("You can only Plant a max of 10 seeds per person"Ôøº; return; } if (int.Parse(txtSeed.Text) &gt; acres) { MessageBox.Show("you can only plant a max of 1 bushel per acre"Ôøº; return; } lblRemaining.Text = (bushels - int.Parse(txtFeeding.Text)) + " Bushels Remaining";
For some reason I like `var obj = new MyCustomObject();` more.
No. _Do a Release build_ is a short, precise, unambiguous sentence for conveying your intent. "Turn on optimizations" is not only needlessly obtuse but also incomplete.
can you format the code and upload it to something like hastebin, pastebin or gist? It's hard to help otherwise. Also can you point out which parts of the code are relevant to the problem?
Yeah, nobody is going to read this terribly formatted code. I would like to help you, but I would not like to spend 10 minutes trying to format this first. Post it to [https://pastebin.com/](https://pastebin.com/) or so. But since you are not able to point to the general direction of your troubles, I suspect that you first just have to learn the basics. Go to the earlier lecture notes and re-study them. There is no sense in trying to shortcut your education.
https://hastebin.com/ijoxiduwaw.cs Couple things marked // array But basically anything with the variable starved Thanks for looking 
make a class that stores all the variables that you want, have a List&lt;T&gt; of that class, and during each allocation add a new insurance of that class with all the values you want.
A struct is a value type. That means you always get a **copy** of the value. When you use the indexer of the array you get a copy, then you modify that copy... and that's it. That's not making any sense, so the compiler prevents it. Instead you need to retrieve the element from the array, you modify that copy, then you re-assign the element in the array to overwrite the value. var element = array[index]; element.Property = newValue; array[index] = element;
 [https://hastebin.com/ijoxiduwaw.cs](https://hastebin.com/ijoxiduwaw.cs) 
You didn't even bother to run this code... there are literally emojis (:wink:)in it that got replaced somehow while copy pasting! Also I have no idea what you need help with. Writing "// array" in there is not much of a hint. People here are not going to do your homework!
will try and figure it out thanks
You can draw your own graphics in winfoms
Turn starved into an array and then at the end of your button click method store the values to the array using year as your index. Your year value is set to start at 1 so you will need to offset this when you store it. To declare the array: int[] starved = new int[10]; to assign to it something like starved[year-1] = starved_for_year (this doesn't exist, you will need a separate var in your method to calculate the starved). After this you should have an array that you can access that holds the starved per year. As others have pointed out here you could more easily use a list rather than an array. Also as general comments on the code your method on the click handler is far too long and it's not particularly easy to understand what is going on. It would make more sense to have some kind of object to track your years and associated results, etc and then I think a lot of this logic could be moved to that object where its applicable to do so. This is all assuming I've actually understood what you are trying to achieve, apologies if I have not. 
And you can notify listeners that a property has changed. This is standardized with the System.ComponentModel.INotifyPropertyChanged interface. You expose a PropertyChanged event, and then you use the set block of a property to raise the event so that other code can react to the change.
So you can control the acces on thos fields. It's basically syntactic sugar for getters and setters. an example: class Temperature { private double TempKelvin_Internal; public double TempKelvin { get { return TempKelvin_Internal; } set { if (value &lt; 0) throw new Exception("below zero kelvin does not exist!"); TempKelvin_Internal = value; } } public double TempCelsius { get { return TempKelvin - 273.15d; }; set { TempKelvin = value + 273.15d; }; } } 
[https://hastebin.com/ifajiveviz.cs](https://hastebin.com/ifajiveviz.cs) &amp;#x200B; tats what i have been trying so far but doesnt seem to work
Don‚Äôt ever concatenate SQL strings. Ever. Use parameters. They will save you when you have a ‚Äò in your data. They‚Äôll save you when someone does an SQL injection attempt. And they‚Äôll save you here. You just make the parameter to have the value of DBNull. 
change the otherarray to your other array's name remove the using block thats a optimizing tool or something like that
Ok, but lets say in this case, we're using the SQL string. How can I make a simple check to whether use the variable value or DBNull?
What do you expect this code to do? averageDeaths[0] = starved; averageDeaths[1] = starved; averageDeaths[2] = starved; averageDeaths[3] = starved; averageDeaths[4] = starved; averageDeaths[5] = starved; averageDeaths[6] = starved; averageDeaths[7] = starved; averageDeaths[8] = starved; averageDeaths[9] = starved; Again. Understand the basics first! There is no point in randomly trying to wiggle your way to a valid solution.
The code works up to a point. It's designed to store the amount of starved each year then add them up and work out the average but it doesn't do the last bit it just adds them up 
But what about those specific lines. Why did you write them? What did you expect to happen? What is "starved" for a value, and why are you storing it 10 times in the same array? If you were the computer, what would you do to calculate the correct result, when somebody pushed a button?
You‚Äôll use `null` if you want to set it to null in an SQL query
So I don't need those lines?
You tell me. You wrote them for some reason right? Programming is mainly 3 steps: 1. Understand the problem 2. Solve the problem as if you had to do it manually 3. Translate your solution into code so the computer understands it It doens't make sense to start fiddling random things in step 3, when you are still somewhere between 1 and 2. 
Nice! In case you're interested in that simpler way, you could write: return new string(Environment.NewLine, HowManyNewLines); as the contents of your method :)
This is a bit contrived but I think illustrates what you are trying to do: https://hastebin.com/unabotejas.cpp 
Giving me the error for the other array(I have it as correct name) ‚Äúcannot implicitly convert type ‚Äòsystem.windows.forms.Label‚Äô to ‚Äòsystem.drawing.image‚Äô
Does that assign the starved the particular numbers you entered there? If so I need it take the number from a a calculation that happens in the textleave event 
My solution is to never let it get to the parameter building stage if the input isn't valid. Instead, I alert the user that a value is required, if it is. If it isn't required, I just set that parameter to null. You might find it helpful to create some conversion extensions to handle string to date to avoid duplicating code all over the application. And, yes, as u/lekowski said, parameterize your queries properly, even SQL strings. It will save you a lot of grief, even in desktop apps. When I've been brought in on contract jobs to help solve mysterious errors, this is one of the first things I look for and usually find it.
Looks good, fine work.
Do you want to show an image on a label?
Then just assign to the appropriate array element. In the code you originally posted it seemed like you were setting starved based on a few different rules. When you calculate how many starved then assign it to the array element for the current year. When you then get to the end of the years your array should have all the values you need, the code I provided previously just illustrates how to assign to the array and then calculate the average from it. I would suggest taking the code I provided and adding it into a console application, set a breakpoint and understand how it is functioning and that should set you on the right track to adding it to your application. 
Yeah I‚Äôve got that working but I now want to randomise what image goes onto what label 
well, because I don't know how to show an image on a label I can't help you.
Ahaaaa!!! Super haha!!! Awesome man:) 
Agreed, but I think my affinity is based on familiarity rather than and abject dislike for the new syntax. I feel like it will grown on people 
I really am lost atm so will have to try do some more research 
&gt;Based on what you're seeing, do you believe there's any chance of this library ever catching on at all? Ok, so I'm not experienced enough to talk about C#/.NET code quality yet, but I just wanted to add that I'm definitely going to add Reddit.NET to my list of things to try out. Maybe I'll try it once it becomes a bit more stable. :)
Try ImGui.net: https://github.com/mellinoe/ImGui.NET Don't forget to give a tip to the developers (that library and the original one).
I can't help you much with this. But my advice would be to look for a framework to do this rather than rolling your own. There must be plenty of queue / pool ones out there.
We use separate "Add, Update, Delete" Methods and have a "AddOrUpdate"-Method, for when it's not important if it previously existed. (E.g. first write config-table for a user)
Sounds similar but I like the sound of the AddOrUpdate for simple scenarios, I've seen similar with Upsert I use Add when linking entities - for example: Create Employee Create Department Add Employee to Department 
i must admit, that was a bad example. However sometimes you have to comply to an existing interface, which only exposes a synchronous or asynchronous API. If you are lucky (/s), then someone might've created an "ISyncAndAsync"-interface, which gives makes you implement async and synchronous versions of your methods. How should one design a proper synchronous HTTP call, or an asynchronous HashSet-Lookup? &amp;#x200B; **tl:dr** People do stupid things with interfaces and dependencies and you can not always force good coding style on stuff that has been out there for decades &amp;#x200B;
Am i right that you mean stuff like in the following example? webClient.DownloadCompleted += (s, dcArgs) =&gt; // e.g. OnDownloadCompleted-Method { Console.WriteLine("Download Completed"); // Other stuff with dcArgs.Data; }; webClient.DownloadDataAsync(url); // BAD CODE - DON'T COPY int timeout = 10_000; // Seconds in milliseconds int timePassed = 0; while(true) { Thread.Sleep(10); timePassed += 10; if(timePassed &gt;= timeout) { webClient.Cancel(); } } If you can, don't use the EAP, but rather the TAP. (Task-based Asynchronous Pattern)
For asynchronous code you could also look at Rx and pipelines.
Microsoft tell me EAP is better than TAP so I‚Äôm trying to write some standard EAP classes, componentes. I need a good communication between classes. 
As someone who is still fairly new to C# this a cool tool to have. Thanks for putting in the work on this. 
I just googled them, sounds great. I‚Äôll read more about them. 
As /u/AngularBeginner said, it's not possible to get a *reference* from a standard indexer or property. But, if you were to use T\[\] instead, the compiler would let you do exactly what you want to achieve - the compiler emits *ldelema* instruction which returns a managed pointer to the value type - and so the struct instance is never copied (it's passed by reference). If you are using one of the latest C# versions (which allows `ref return`s), you could even wrap that T\[\] with your custom container class, but you need to make sure that your indexer returns by reference i.e. `public ref T this[int index] =&gt; ref _items[index];` [Here's a complete demo.](https://pastebin.com/jKcQerXu)
You could use CallerMemberName for this, I guess you could create a method that literally just returns the name of the method that called it. See: https://docs.microsoft.com/en-us/dotnet/api/system.runtime.compilerservices.callermembernameattribute?view=netframework-4.7.2
Thanks for detail explanation.
Thanks for detail explanation, I solved problem like you stated.
Would `MethodBase.GetCurrentMethod()` work for your purposes? https://docs.microsoft.com/en-us/dotnet/api/system.reflection.methodbase.getcurrentmethod?view=netframework-4.7.2
Could probably even toss this on `AnotherClass` as a convenience method, something like `AnotherClass.GetValueFromCaller()`
I had TONS of success using the asynchronous socket client/server. I hooked mine up with ssl as well. https://docs.microsoft.com/en-us/dotnet/framework/network-programming/socket-code-examples
How does this compare to Sandcastle Help File Builder?
"tests" - There's a range between "unit" (tests a single method) and "integration" (tests multiple layers, API calls, database calls, controllers). I strongly recommend [xUnit Test Patterns](https://www.amazon.com/xUnit-Test-Patterns-Refactoring-Code/dp/0131495054) as it covers testing concepts and is not just a "xUnit how-to".
Don't know what you mean by lightweight. But TCP operates on stream, so you have to implement some kind of message framing to extract messages. Also there's encoding to think about. byte order if you want to send numbers. Blocking on TCP operations is not good. So you need some king of multi threading. I recommend TAP. Besides, since the TCP protocol stack uses buffer internally, make sure to wrap every call to TCPClient in try catch. That said, my own TCP recipe is - Message framing: 4byte length + payload. Mostly JSON because XML sucks. Prohibited is also okay - I prefer asynchronous API to synchronous ones. Since network operations are naturally asynchronous, I expose asynchronous APIs Hope this helps 
This isn't really a c# issue. You'd likely have better luck on a unity specific sub.
That looks promising, thank you!
The problem you're trying to solve sounds like a perfect example of inheritance - a base class which represents the data that you always need to store, and derived classes which represent specialised versions for each customer. Regarding how to store data in a database, I highly recommend reading all three parts of [this blog](https://weblogs.asp.net/manavi/inheritance-mapping-strategies-with-entity-framework-code-first-ctp5-part-1-table-per-hierarchy-tph), which covers all the available options in incredible detail, including pros and cons of each option. It's tailored to EF, but will be applicable to any ORM.
I agree with using reflection to accomplish this `MethodBase.GetCurrentMethod().Name.Replace("get_", string.Empty)` `MethodBase.GetCurrentMethod().Name.Replace("set_", string.Empty)`
&gt;Microsoft tell me EAP is better than TAP Can you elaborate? It seems very unlikely to me that EAP would be recommended, unless it is for a specific use case. If you can, you should probably be using async/await.
I was really hoping to see the AAA pattern for the tests
This did it, thanks :)
&gt; There must be plenty of queue / pool ones out there. There's actually not that much around, from what I've found. The actual CLR ThreadPool source code is one of the best resources I've come across.
Be aware, if your method is optimized/inlined, I believe it may return an unexpected value (just as grabbing the stacktrace would). In such cases, you can add the `[MethodImpl(MethodImplOptions.NoInlining)]` attribute to the method, or use /u/Antilles34's solution which should be safe regardless of optimizations.
Sounds random to me. If it was not random the EXACT same thing would happen every time. Since sometimes it's one way, and sometimes another, then that's the definition of random. Also, be aware that computer "random" code is not truly random. This is why Lava Lamps are used by a cryptography company. Lastly, when creating your RANDOM object, make sure to place a SEED. I use DateTime.Now.Millisecond
Coordinators is irrelevant. It seems to be a pattern specific to iOS programming which isn't your case at all. Also, if you believe they should be named controllers (so do I), you should keep it this way. Also, if for example you have Controller.Foo, in your code base, you really should add the Controller suffix (FooController), it's a recognized practice to add the pattern name as a suffix in many instances, it just makes the code easier to understand by other developers (which should be your primary concern considering you're writing an API)
I will not. In fact, I'm turning off that stupid nullable reference type bullshit the instant it appears.
I saw the second part is out today. Can you post that here? I didn't want to take your karma.
How do I fix this 
ok, so you're a beginner, and that's fine, but when posting such a question we need details. eg: What EXACTLY do you want to fix? The code as you stated is in fact random. If you don't want a picture to be placed multiple times, then you need to remove it from the list after it has been selected. If the issue is something else, then please provide details on what you are attempting to achieve.
I havent used that for a while and have just downloaded it and immediately get an issue with new style project formats in the GUI and after 20 minutes I had not got anything built from it. But from what I can see: Live Documenter supports HTML Help 1 (complied help), mshc (Help Viewer 1 &amp; 2) and web which SFHB does also.. From memory SHFB also provided links to framework types in your docs which Live Documenter does not. SHFB supports MAML which Live Documenter doesnt. However Live Documenter is easier to use (I also remember SHFB being really slow but that may have changed.) 
Thanks, I'm glad it will help you out!
Many do, but tbh I didn't want to expend too much time on perfecting/optimizing the tests. You may notice that a number of them appear to have been a bit hastily written (205 endpoints!). I was actually hoping that I'd be able to farm most of that out to the OSS community. Making the tests better would be a great way for someone to become familiarized with the codebase, so I've been leaning toward that strategy. What do you think?
Heh thanks! Perhaps I should've taken a vote first.... In the previous thread, one user said that not renaming the controllers would be a "slap in the face" to many .NET devs, though I'm a bit vague on the specifics atm.
Great response!
Ok, good, I'll add the attribute. Thanks for the heads up! 
The feature is opt-in anyway.
Let's see... * No runtime cost * Minimal effort to update * Catches commonly occurring errors * Acts as machine readable documentation Yea, that sounds like a horrible idea. No one should use it.
try executing this in a new thread or as an asynchronous task to free up your main thread
Could you provide an example? :)
Your opinion is a valid one, but it might be a good idea to keep an open mind about these new features. I don't think you'll be able to turn it off since it'll become a language/compiler feature, not just an IDE feature. If you really don't want to deal with this in the future it might be a good idea to look at other languages since this is here to stay, and my prediction is that most languages will actually go this route though.
 I just read it again and I think I misunderstood it. Maybe I will switch to TAP. Thank you.
 I just read it again and I think I misunderstood it. Maybe I will switch to TAP. Thank you.
&gt;i [https://hastebin.com/oxeyafurim.coffeescript](https://hastebin.com/oxeyafurim.coffeescript) maybe something like this (Task is going to require a return value unless you're running it asynchronously) &amp;#x200B;
If you want to randomize your list order, you need to take track of already taken images, otherwise the same image might just show up again. There is several ways of doing this, if this is what you want. Can we have more informations ?
Just FYI, you don't want to use reddit in the name of your project, it's trademarked. Several people ran into this issue when designing apps.
I'd love to help and jump in on some testing
Side effects can make your code difficult to reason about and test. Unless you have a reason, prefer the first option over the second.
It's better to return a list. 
Yes this is what I want 
You can turn it off.
Var list = new List&lt;int&gt; { 1, 2, 3 }; Best way ü§£
So in the list I have 16 images (sports(, I 16 labels I want to randomise that each image goes into a label but using this code some images go into 3 labels and others none, it‚Äôs Different every time, I want it to be each image in a random label every time 
Emh...are you walking about winFoms,wpf or uwp?
you need to set up an event that updates the label when the attached property has changed this would go in the designer `this.MyText.TextChanged += new System.EventHandler(this.MyText_TextChanged);` and then you would open the panel's partial class and write a method to update the text [https://hastebin.com/iduqojenew.cs](https://hastebin.com/iduqojenew.cs)
RedditSharp has existed for years without an issue. Libraries aren't generally an issue. It's making apps with the Reddit that becomes a problem.
I already had it set up and working, but then started creating my panels now all of a sudden it's stopped 
Windows forms sorry
Since it's open source and increases the usage of Reddit, they might be less inclined to hate on it. But for sure, if it stays as [Reddit.Net](https://Reddit.Net) it should get a green light from Reddit's legal crew.
It bothers me so bad seeing a comment that says //Arrange One line of setup code //Act One line of code calling the function //Assert One line assert The comments are worthless and just take up space
I prefer separate CRUD methods. They align better with the HTTP verbs (like you said). And because there's less branching in them, they're easier to figure out what they're doing. 
I tend to just check the box that says to treat all warnings as errors, in the first place.
I am a super novice at C# (am mostly in C++ and C land), but in C# I've in the past done it as both you and /u/ormula suggested via creating the struct in place. public struct CombinedArgs { public int someid; public int otherid; public string username; public string password; } private static void FuncWithManyArgs(CombinedArgs someargs) {} FuncWithManyArgs(new CombinedArgs {someid = 1, otherid = 1, username = "aa", password = "bb"}); I could have sworn there was a cleaner way to make that struct when calling FuncWithManyArgs() but for the life of me for some reason I can't remember and googling doesn't give me anything.
My current solution at work has over 2000 warnings and 5000 messages.... I've been slowly going through them, but it's hard to justify spending time on them, instead features, to people making decisions :p
Given the simplified example, the first method is the better practice. But when a list may already have an item in it, then you could use the ref keyword passing the list by reference to say the method will be modifying the list. 
One technique I used in the past is to hide the time in feature development. If I need to touch a file for a feature, the first thing I do is fix the warnings in that file. Not only does this keep management from panicking, it naturally causes me to focus on warnings in frequently changed code.
&gt; No runtime cost ... or benefit. &gt; Minimal effort to update This is a great assumption on your part. &gt; Catches many, but not all, commonly occurring errors Null reference exceptions aren't actually that common **if** you understand references in the first place. &gt; Acts as machine readable documentation. By literally removing the readability of all legacy code? From now on, you will have to ask, "Is this code using the nullable references feature?" and then base your interpretation on that. IMHO, this is a terrible unneeded change. If C# started out with nullable reference types that would be fine, but the idea of changing that now is simply ridiculous.
It depends for us. We have a few upsert methods. But if something needs extra or different steps then we split it out. 
Isn't it going to be nice always having to wonder if code you look at from other people has the feature turned on? This is literally creating a branch in C# code definition. How is that good?
&gt; This is a great assumption on your part. No it's not. I've updated a few projects already to test how much effort it would be. &gt; Null reference exceptions aren't actually that common if you understand references in the first place. In that case, the effort required to make the update is even lower. Based on my experiments, the code that is hard to update is the code that doesn't handle nulls correctly in the first place.
Do you see any `?` appended to the type names? If no, then you can assume it's not turned on and the code will work as-is. If yes, well then its pretty damn obvious it is turned on.
And where I work at, we are still stuck in C#5 and winforms. Really makes me want to get us to update. And finally fix the thousands of messages of improperly named stuff (Like class names that begin with a lower case). 
So you only work on small codebases that you've written 100% by yourself. Got it. Good to know.
How does your tool handle marker interfaces? If I have XML documentation on the marker interface does it show up in any way on the classes that implement the interface?
If a language starts out with this feature and completely lacks a "null" concept, then that's fine. But nulls are useful, and breaking an existing language's syntax just to bubble-wrap it for the mouth-breathers is poor form.
First one. Pretty soon though you'll be subclassing List and then you can do tricky cute moves like { this.add(x); } which will make your friends jayruss. 
I've worked on projects where there were multiple 6 men teams all touching the same code base. And like you they were all terrified at the idea of checking the "treat warnings as errors" box because of the sheer amount of code that would have to be updated. A couple long weekends on my own and all of the warnings were fixed. It's not that hard to fix compiler warnings; you just have to not be a baby about it. *** It may be coincidental, but over the next couple of months the bug count coming across my desk (all runtime errors went to my team) dropped dramatically. 
My recommendation is to turn on code analysis at the highest level as you fix things. That way they can't reintroduce stupid stuff like improperly named classes. Just do it one rule at a time. If you turn all the rules at once, you'll get overwhelmed. 
&gt; If a language starts out with [nullable reference types] and completely lacks a "null" concept, then that's fine. You really don't understand what you're talking about, do you?
Yeah, that's what I'm trying to do, too. Unfortunately, lately there has been more new code added, than old changed.
I also covered that: "Also **potential** optimization speed. **If** the compiler "knows" a variable isn't null, it can skip adding any default null checks." I challenge you to find one instance where I said "This is how it will work." You can't. I said "This is how it can work."
Then I would suggest the "one rule at a time" approach I mentioned in my other comment. It's harder to hide, but if you aren't doing strict code reviews then you can work it into your other work. (And yes, I realize how stupid it sounds when I say you have to hide maintenance tasks.)
I am the lowest on the totem pole...
For async stuff I like to create small console apps that do something like interact with a threadsafe concurrent list. Sometimes inside of a full-bore application it can be really tough to debug or even understand. Having small lightweight examples floating around make it easier to grasp.
I mean, you don't need the comments. But it is nicer for readability in the future.
That doesn't necessarily mean anything. I was lowest on the totem pole and I just did it anyways because it needed to be done. I'm not saying that you necessarily should because I don't know your situation. I'm just saying that just doing it without asking permission worked out for me.
 That's a good way to learn but can you suggest me some async pattern documents? 
I think his point is that if anyone on the team is using it, everyone has to. It's not like Resharper or CodeMaid where each person can choose to use it or not.
The feature is to remove the ability to have "null" as a valid value by default. Any language that lacks that concept fits the definition (and can't *not* fit it). But your pedantry module wouldn't feel fulfilled without being a dick about something you don't agree with, so whatever.
&gt; No it's not. I've updated a few projects already to test how much effort it would be. He is somewhat correct about that part. We have over 200k files in our codebase, and we have a standard for every method in our code base. All methods have to look like &gt;public string SomeMethodSignature() &gt; &gt;{ &gt; &gt;string res = null; &gt; &gt;int myVariable; &gt; &gt; &gt; &gt; try &gt; &gt; { &gt; &gt;for (myVariable = 0; myVariable &lt; 1; myVariable++) &gt; &gt;{ &gt; &gt;res = $"{myVariable}"; &gt; &gt;} &gt; &gt; } &gt; &gt; catch (Exception e) { OurLogger.LogError(e); } &gt; &gt; return res; &gt; &gt;} &amp;#x200B; All variables have to be declared outside of the try catch and are not instantiated. &amp;#x200B; Plz no flame, I did not create this standard and we've argued over why it's bad 1000 times, but for us it would be changing every single method in our entire system. Going forward, I'm going to suggest new assemblies do this and use it as a pushing point, but it's not practical for our current.
Removed: Rule 4. Please try to create a [Minimal, Complete, and Verifiable example](https://stackoverflow.com/help/mcve) as there isn't much information provided to us to diagnose the issue, and it is possibly a result of unintended interactions within your developed application code.
How is it helpful?
Also, you may want to check out /r/learncsharp (it's great for asking questions and sharing progress when you're just starting out!)
Here's a sneak peek of /r/learncsharp using the [top posts](https://np.reddit.com/r/learncsharp/top/?sort=top&amp;t=year) of the year! \#1: [On-Going Series: Learn to Code in C#](https://np.reddit.com/r/learncsharp/comments/96p3uf/ongoing_series_learn_to_code_in_c/) \#2: [Is there any podcast, website or book you recommend to learn c# in 2018?](https://np.reddit.com/r/learncsharp/comments/8f3si6/is_there_any_podcast_website_or_book_you/) \#3: [What exactly is this whole .NET thing anyways?](https://np.reddit.com/r/learncsharp/comments/8ht28f/what_exactly_is_this_whole_net_thing_anyways/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/afd0dd/blacklist/)
Yeah, good point. Not the vibe I got from his comment though :)
thanks friend I will check this out on future projects. &amp;#x200B;
It seems you just need "communication" between classes. In which case plain old *events* would be enough, where a child class can notify a parent when anything changed. Also, i would create interfaces like "IReportAuthentication" if i need to pass a parent to a child object. But this heavily depends if you just need a single event or a full reference to the parent class Parent : IReportAuthentication { public event EventHandler&lt;AuthenticationEventArgs&gt; Authentication; private Child child; public Parent() { this.child = new Child(this); } } class Child { private readonly IReportAuthentication authenticationReporter; public Child(IReportAuthentication authenticationReporter) { authenticationReporter.Authentication += OnAuthentication; this.authenticationReporter = authenticationReporter; } public void OnAuthentication(...) { ... } } &amp;#x200B; You could also go the route of an event-bus, which would allow you to subscribe to any events that you are interested in and also publish any events/payloads to any consumer that previously subscribed.
&gt; breaking an existing language's syntax just to bubble-wrap it for the mouth-breathers is poor form. You manage to act elitist and complain about a feature that could make your job easier after a brief learning curve in one fell swoop. Come on man, this type of behavior has no place in this industry. 
That's a hard problem. This is exactly the kind of code base that would benefit from it the most because it misusing nulls all over the place. My recommend would be the same as yours, enforce it for new assemblies for now and then look at fixing the old assemblies later. You can even do it on a file by file basis using pragmas.
So in the list I have 16 images I 16 labels I want to randomise that each image goes into a label but using this code some images go into 3 labels and others none, it‚Äôs Different every time, I want it to be each image in a random label every time
&gt; ... or benefit. No, but a huge _developer_ benefit, because null mistakes can now be discovered at _compile time_. &gt;Null reference exceptions aren't actually that common if you understand references in the first place. And yet I see null reference exceptions happening even in Microsoft code. I guess they only have bozos for developers? &gt;From now on, you will have to ask, "Is this code using the nullable references feature?" and then base your interpretation on that. &gt; &gt;IMHO, this is a terrible unneeded change. If C# started out with nullable reference types that would be fine, but the idea of changing that now is simply ridiculous. You seem to be arguing both for and against the feature being opt-in. They made it opt-in precisely because they didn't start out with it. Otherwise, we wouldn't have this complication at all.
Keep in mind that you can opt-in to this feature (or opt-out from it) even on a file level.
Then remove the image from the list once it is added to a label. And while I am here, wtf are you using LABELS to hold pictures?! Use an Image control. So you'll want to pick a number between 0 and the number of items in that list, then place the image into the Image control by using the selected number as the index of the List. Then use the .RemoveAt(NUMBER) to remove that item before moving on to the next Image. (really, don't use labels)
This feature doesn't take null away. It just makes it more obvious when something can be null, and helps both you and the compiler discover developer mistakes.
Trying it atm ain‚Äôt working 
 I did not know about the file by file, and if you can use pragmas hopefully you can have an assembly file to reference the files so once EVERYTHING is moved you can just delete that file at once, that's good to know, thank you. Didn't know that was an option. &amp;#x200B; And yes, we have object reference exceptions all of the time, so 100% I agree it would be the biggest benefit to our code base :)
Again, just saying; "It aint working" is of NO help. Show your code, state what is/isn't happening.
Say I go that route of marking every method with a ? now all places that save the result now has to have ? added, now each place that that variable is saved needs to check if it has a value before using it, now I need to create logic of what to do when that variable doesn't have a variable... etc. There's a lot more to it than just marking it, we just need to fix our code base &amp;#x200B; But yes, I did not know you could do it on a file by file basis, that makes it much easier. I thought you could only turn it on or off in your csproj.
The syntax is `#nullable enable` and `#nullable disable` around the code you want to affect. I have to disable it when doing tricky stuff with generics.
Sorry I was going to but it won t let me reply again for 10 minutes so I tried sports.removeat(numbers) and it dint work and tried sports.removeat(randomlabel) didn‚Äôt work gave error cant convert system.rwndom into int 
&gt; Say I go that route of marking every method with a ? now all places that save the result now has to have ? added, now each place that that variable is saved needs to check if it has a value before using it, now I need to create logic of what to do when that variable doesn't have a variable... etc. There's a lot more to it than just marking it, we just need to fix our code base Sure, but really, you had to do that before. Not the annotations, but 1) the implicit assumptions, and 2) the explicit checks for null or not null where warranted. And if you do have such a check, the compiler will try to be smart about it: public static int GetLength(string? s) { if (s == null) return; return s.Length; // no warning, because you already checked for null } &gt;But yes, I did not know you could do it on a file by file basis, that makes it much easier. I thought you could only turn it on or off in your csproj. Technically, even _within_ a file, much like you can turn warnings on and off. However, the syntax is still subject to change, and I'm not sure if toggling it within the file is guaranteed to make it to the final version (which is still months away from shipping).
How is it not? I love seeing the delineation between the setup code, the code being tested, and the assertions.
&gt; I'm not sure if toggling it within the file is guaranteed to make it to the final version It better be or I can't use it. It would really suck to not have access to this feature because I've got one place where the generics don't allow for null checks. 
You do realize that Tony Hoare, the guy who invented null references, the guy who won a Turing award, calls it his Billion dollar mistake?
Really? You're seriously going to use *that* pathetic argument? Making me change hundreds of thousands of lines of code is not going to make my job easier. And the *only* reason this nuisance feature exists at all is because of people that don't want to be bothered to learn how to actually do the work. I'm all for making things better and easier. Just not at the expense of breaking things or making me do months of work just to get back to where things were before some massive breaking change. And *definitely* not at the expense of *useful functionality*. There's nothing elitist about not breaking things that already work just fine. If it's not working for *you*, then feel free to use the optional assistance. But don't expect me to put up with a gimped tool just because you think you know best.
I don't _think_ they'll remove it. But I did see them changing the syntax of `&lt;NullableReferenceTypes&gt;` again (it's apparently an enum now, not a bool), which might mean they haven't fully settled on the `#nullable` syntax yet either.
Oh really. When did that happen?
So? I'm not against nullable references. I'm against trying to shoehorn them into an already established language. All it's going to do is create a division in how people go about writing projects.
It should be PopularList, this isn't Java.
 Why does every new feature people consider to be shoehorned. I think it's incredibly ridiculous that every time some feature comes out (such as the new tuples), people always say it's being shoehorned. You're a programmer. We live in an environment that is ever changing. Things are going to change. Period. &amp;#x200B; These features are being thought out and being provided feedback from thousands of developers, and even open in the beta to give feedback before it becomes a full feature. It is not shoehorned.
You would not use the ref keyword for that. Lists are already reference types and can be modified by any method they are passed to. Using the ref keyword with a reference type allows the callee to modify the reference in use by the caller, for instance to alter the reference to point to a different list. That's a rare use case though; better to just return the new list explicitly.
No. Don't do this. The `ref` keyword has a very specific meaning, that is, that you pass the reference, being able to change what the variable points to.
It can be helpful if your codebase has a lot of junior developers on it since they may not be as familiar with the pattern. Having clearly delineated sections makes it clear which code falls under which category. That said, I don't typically add them (since I write our testing standards at work, I just include a blurb about this pattern and that it should be followed). I find line breaks to be sufficient for breaking up each section. It's mostly a style thing anyway, and as with all other subjective things such as that, it's far more important to have a single person dictate it once for a project then have that way enforced. Vs spending endless cycles fighting amongst the team to pick the "correct" way.
"Prohibited" ?
&gt; This is literally creating a branch in C# code definition. How is that good? It is, and it is a bad thing. But the designers of C# thought that this feature is so useful that effectively creating two dialects of C# is worth it. But note that the only difference between the two dialects is in warnings: you can copy and paste code between them and the code will still work the same.
I've been doing .net for 10+ years. I've never heard of the use of coordinators. Just did a bit of reading on it but I don't see the point in renaming them.
Any comments on interfaces are shown as documentation for the interface. Implementing types will not show the interfaces docs. 
&gt; Making me change hundreds of thousands of lines of code is not going to make my job easier. Regular reference types aren‚Äôt going anywhere. &gt; And the only reason this nuisance feature exists at all is because of people that don't want to be bothered to learn how to actually do the work. The only basis for your argument is that you don‚Äôt want to learn how to do your work with this feature. So, who‚Äôs wrong? &gt; But don't expect me to put up with a gimped tool just because you think you know best. That's rich. You're in a hell of a glass house throwing those rocks. Null reference exceptions have plagued .NET developers since the dawn of time. This is the closest we‚Äôve ever gotten to solving that problem at time of development. Perhaps you should read some of Microsoft‚Äôs tutorials and explanatory articles. I was trying to be polite earlier, but no. Shame on you for being obtuse and close minded. Give it a fair shot before you ring the death knell. 
&gt;The only basis for your argument is that you don‚Äôt want to learn how to do your work with this feature. So, who‚Äôs wrong? No, I *already know how to do my work*. My work is to write software that doesn't have errors (NRE's included). People that can't seem to do that without gimping nulls are the ones that still need to learn. I already learned. *That's the point.* NRE's aren't a "plague". They're a symptom of not writing good code. If it's widespread, then the need to *not suck* is widespread. Which, if you know anything at all about the world, you already know that to be true. I'm also not ringing any death knells. If you look back at my original comment, it was simply that I'm not going to use a feature that I consider to be a complete and utter waste of my time. Then the circle-jerk piled on with insults and flames, so I returned fire. Deal with it.
It's available as a NuGet package that targets .net standard so it should be available on all of the current major frameworks.
I've been very receptive of the recent additions to C#. What I'm not for is this attempt to change how something has always worked in C#. It doesn't make you code better, it makes you code differently. It's a core change to what a certain syntax *means*. The right way to enforce that a reference is not null is to check for null and then do something about it if it is. Trying to make C# pretend to work differently than it always has is ridiculous. Note: I would be fine if a new syntax was introduced to declare a reference as non-nullable. Many people have suggested something like "string! myString;" to denote actually non-nullable reference types. What I'm opposed to is a optional flag that changes *how code is interpreted*. If the optional feature fundamentally changes how you view the *same piece of code* then that feature is detrimental.
https://github.com/dotnet/project-system/issues/4058#issuecomment-448690684 &gt; true/false were not enough https://github.com/dotnet/project-system/pull/4422 Looks like `&lt;NullableReferenceTypes&gt;` is now `&lt;NullableContextOptions&gt;`. Not clear to me yet what the possible values are.
&gt; And the only reason this nuisance feature exists at all is because of people that don't want to be bothered to learn how to actually do the work. I know how `null` works, but I also make mistakes. A feature that makes it less likely that my code has a bug is a good thing. It has nothing to do with people not willing to learn. But even if it did, making the language easier to learn would still be a good thing: it means you have more time for other, more important things, than learning C# minutiae. &gt; some massive breaking change This feature was very carefully designed so that it's nowhere near a breaking change: 1. It's opt-in. You can even opt-in one file at a time. And there are also several levels of opt-in. 2. All it does is that it produces warnings. 3. If only some parts of your codebase use this feature, it still works fine (by making some variables "null-oblivious"). &gt; There's nothing elitist about not breaking things that already work just fine. The elitist part is when you resorted to name calling. And with this attitude, I think we would never have gotten `async`-`await`, lambdas, or even generics. (`ArrayList` works "just fine", no? And switching to some other type would be a lot of work.)
That's another thing and is why I call this feature shoe horned. The feature is simply, "lets pretend". Well that only works within your own code base and in that case, you ought to know what is or isn't able to be null. And if it is able to be null, then you still need code to handle it.
That sounds like the same excuses people make for not using strict type checks in VB.
 &gt; No, I already know how to do my work. My work is to write software that doesn't have errors (NRE's included). People that can't seem to do that without gimping nulls are the ones that still need to learn. I already learned. That's the point. Everyone needs to learn. Including you. You are not a perfect developer. I am not a perfect developer. We both write good and bad code. Nullable reference types are another tool in the toolbox that can improve the quality of our code. What's wrong with that? &gt; NRE's aren't a "plague". They're a symptom of not writing good code. If it's widespread, then the need to not suck is widespread. Which, if you know anything at all about the world, you already know that to be true. Yeah, everyone in the workplace sucks. I'm not disagreeing with that. We all have shit peers with cereal box qualifications. But code, especially at an enterprise level, is very complex and it becomes much easier to introduce NREs into the equation. Again, extra tool in the toolbox. Used right it's not a problem. &gt; If you look back at my original comment, it was simply that I'm not going to use a feature that I consider to be a complete and utter waste of my time. Then the circle-jerk piled on with insults and flames, so I returned fire. Deal with it. The problem is how you dismissed the feature. The way you are acting is very much "Well back in my day we wrote code differently and it was GOOD!" which is probably false and makes you seem like an overconfident hotshot developer who clearly knows better than the C# team. You don't. 
check [https://github.com/Azure/DotNetty](https://github.com/Azure/DotNetty) or [https://github.com/zeromq/netmq](https://github.com/zeromq/netmq)
&gt; Well that only works within your own code base It does not. You can annotate a library and when you do, it makes it much easier for you (and the compiler) to understand when it accepts or returns `null`.
Cheers :)
JamesWjRose is right, you need to remove items one at a time (be careful that some iterators won't work if you change the collection they are iterating on) &amp;#x200B; Send your code in the question (and not with a picture, write it for real) and maybe we'll be able to help you more.
I've recently been down this rabbit hole myself, working on a UI library that would be shared across multiple applications. There are a few web pages with metric-based performance comparisons between a few different ways of implementing resource dictionaries. The main take-away I got was to implement a SharedResourceDictionary class that keeps all resources as static properties instead of re-instantiating each resource dictionary each time a WPF element is created. In other words, you don't need a new instance of the same Brush for each object that uses that Brush but this is the default behavior of WPF. &amp;#x200B; See this blog article for more information: [http://drwpf.com/blog/category/resources/](http://drwpf.com/blog/category/resources/)
Fair enough on all points. But I can tell you for a fact that a targeted tool is *much* more useful than a blanket/global one. And because of that, it would've been far more useful to have a NonNullable&lt;T&gt;, and it would've been runtime-enforced (for a minor overhead) to boot, instead of the half-ass compiler-enforced garbage we got. I've really been wondering what the C# team was thinking, and some explanation is in order. Was it really just knee-jerk in reaction to bad developers, or did they *plan* this bad idea? It's not a complaint about having more tools. It's a complaint about using the compiler as a cudgel to break behaviors that skilled developers are used to just because it's difficult for beginners to grok. And you say it's optional, but what are the chances it remains that way? "New in C# 9.0: nulls are completely gone! Screw your old code! Screw useful functionality! We know best!" This is the fear, so I resist the actions that lead up to it.
I‚Äôm a .NET developer and have never heard a controller referred to as a coordinator That user sounds like a bit of a drama queen tbh: this is your project and your work, call things whatever you want. If someone‚Äôs enough of a princess that they‚Äôre going to see your hard work (given to them for free) as a ‚Äúslap in the face‚Äù then that‚Äôs their problem and they‚Äôre welcome to spend a few hundred hours writing their own project instead.... you don‚Äôt owe anybody anything 
&gt;And with this attitude, I think we would never have gotten async-await, lambdas, or even generics. (ArrayList works "just fine", no? And switching to some other type would be a lot of work.) That is a very fat strawman. Async/await is kinda clunky at times, but doesn't remove the ability to use delegates. It's mostly just syntactic sugar wrapped around delegates. Lambdas are something that should've been there from day one. Generics too. `ArrayList` indeed works fine... if you consider *casting* "fine", which I don't unless it's absolutely necessary to disambiguate a type, coerce something related to reflection, or used in an integration layer that forces the interpretation of a piece of data as a particular type when no other context is available. So, no, `ArrayList` is not fine. It's a steaming heap of crap done with minimal effort and rushed out the door because it took 3-4 years to build proper generics support into the CLR. Meanwhile, if `null` was such a problem, why wasn't it prioritized sooner? Surely band-aiding everyones' skinned-up knees from getting a NRE lodged in the spokes of their bicycles would've been a serious issue, right? But instead, this got greenlit, implemented, and approved for release fast enough to give everyone whiplash (and fast enough to avoid dissenting opinions or even alternative implementations) as soon as .Net started getting used by lots of new-blood developers on what can only be called an "open-source schedule". Do I like that .Net is available for cross-platform use? Yes. Is it a good thing to have the source opened up for public contributions and review? *Hell yes.* Do I appreciate a bunch of newbies coming in and telling us all that we're doing it wrong? Not so much. This shit divides and kills every open-source community that doesn't have a complete and utter bastard in charge of it. Linus... Theo... they serve a purpose, and that purpose is to put the kibosh on hasty decisions done by committee and sold to the masses by groupthink. Unfortunately, Microsoft failed to appoint a Bastard Sponsor From Hell. So here we are.
&gt; Meanwhile, if null was such a problem, why wasn't it prioritized sooner? Because it is a hard problem with no perfect solution. Eventually they gave up on trying for `perfect` and settled for `better than what we have now`. 
Got it working doesn‚Äôt matter
I'm not sure who suggested Coordinators, but Controllers def felt off. And not because they did different things, but because Controller is so ingrained with MVC. I'm not sure why he just didn't call them Things, because that's what Reddit calls them. And it's how [RedditSharp](https://github.com/CrustyJew/RedditSharp/blob/2.0-.Net-Core/RedditSharp/Things/Subreddit.cs) references them as well.
WTF? Seriously? Where the hell did you get the idiotic idea that nulls are ever going to be completely removed from C#? That makes absolutely no fucking sense. Even a newbie should be able to realize that even if it were possible, which it isn't, that such a change would require fundamentally rewriting countless APIs in the BCL alone. As I said before, you are panicking over nothing. 
it‚Äôs in the name. Umm. Oh. Model View Controller. Coordinator sounds more like Actor system. Maybe Orleans or Akka. Meh. Its in the game. ....name. ü§©
AAA is only relevant to unit testing. Not integration testing. A unit is small isolated piece of code with no dependencies or side effects. 1+1 is a unit. Starting a calculator is an integration test. 
&gt; I've been slowly going through them, but it's hard to justify spending time on them, instead features, to people making decisions :p And that's why Windows 10 is so buggy
~
You probably don't need to. The GC will likely handle it. What exactly do you mean to dispose/clean up?
The HTTP verbs serve a slightly different purpose - neither PUT or POST tells you exactly what to expect from an operation, just where they should be directed. Database operations are more tightly bound, you're asking for a very specific thing. The advantage of the ID=0 method is that you don't need to split your code for every operation (you don't have to know at every stage whether a particular object is new or old, and certainly don't need to query the database to see if it already exists), and it becomes particularly useful when you have more complex objects, where some parts may be new and some existing.
Some people don't understand change and that's why you have legacy software.
I'm a fan of the Arrange Act Assert comments. It helps highlight that you know what your doing and helps guide other developers on exactly what they should do. It also clearly delineates the code. While it makes less sense when there is only 3 lines in the test, this is often not the case so for the sake of consistency it makes sense to leave it in.
No you don't. Having a parameter that is `List&lt;T&gt;` is enough to indicate the list might be modified. If you want the counterpart to mean the collection won't be changed, use `IReadOnlyList&lt;T&gt;` as the parameter type instead.
For this I use https://www.sonarlint.org/ it changed my life. I would pay to oblige everyone I work with to comply to SonarLint hints!
i don't know what you mean regarding f#'s balance of oop and functional programming. i use both together, and it's seamless. aren't kotlin and swift primarily oop languages anyway?
If the type implements System.IDisposable, you can call the Dispose() method manually, or create the object in a `using()` block at an appropriate level in your code. If it doesn't, you probably need no consult the documentation for the library or API you're using, *but* it may be that you don't actually need to.
Does enabling nullable reference types (using String as an example) make existing `String` declarations accept/return objects of type`String?`, and existing `String!` declaraions accept/return objects of type `String`?
&gt; then it got greenlit, implemented, and approved for release fast enough to give everyone whiplash [The main GitHub issue about it](https://github.com/dotnet/csharplang/issues/36) has been created two years ago and the feature still hasn't been released, with 28 separate Language Design Meetings about it. I don't see how that could be considered rushing. &gt; Do I appreciate a bunch of newbies coming in and telling us all that we're doing it wrong? Not so much. I don't see any evidence that that's what is happening here. Do you have anything to back that up? &gt; they serve a purpose, and that purpose is to put the kibosh on hasty decisions done by committee and sold to the masses by groupthink As I understand it, previously, C# was designed by the Language Design Committee, who considered input about the language from various groups of programmers. Now ‚Ä¶ C# is designed by the Language Design Committee, who consider input about the language from various groups of programmers.
the garbage collector takes care of this but you can always create your own method for disposal with ~
I was running the tests directly from the CLI with `dotnet run` - not attaching it to a debugger.
I fail to see how this particular change is actually necessary. Like, I love string interpolation, tuples, inline functions, smart properties, and all the other cool *additions*... I just feel that their was an additive way to implement this without splitting code. Hell, you can even enforce it now by making a NotNull&lt;T&gt; class that has a constructor that requires a non-null reference.
Or even nicer: private IEnumerable&lt;int&gt; GetValues() { yield return 1; yield return 2; ... }
Right, which is why in your case you have an overhead of roughly 3us per exception caught (reasonable) compared to OPs 13ms which a considerable amount of overhead. From your benchmarks, exceptions are not a performance concern, but it seems OP is arguing that they *are* a performance concern.
Really nice work! Will be using this in some of my future projects; thank you for this nice solution. The only thing I have noticed is --&gt; when you export using the "Web Export: MSDN Lo Banwidth" option, the generated HTML pages have a footer with a hyperlink that points to a shady-looking SEO site in Arabic...see screenshot: https://i.imgur.com/QfKcrGt.png May want to update that link to your actual website.
&gt; Renamed "Models.Structures" to "Things". Why tho
Useless and wrong. You cannot manually invoke the destructor (~) and even if you wanted to implement it, it's only called whilt the GC is collecting the object - meaning the cleanup is already being done for you.
I wonder if you could get the compiler to inline that method call and basically have the compiler do OP's first example for him.
Another option, if you're worried about refactoring and not catching the hardcoded string, is to use `nameof(NameToPass)` instead - refactoring tools will rename this reference as well and if you happen to screw it up, your code won't compile.
How‚Äôs that compared to Resharper in C# ?
You are contradicting yourself. One time you say you don't want to "split code" (whatever that means) and one time you say you want to introduce a new type. A new type would be a breaking change which means you would not be able to update your library to use the new capabilities without asking all your customer to update their code using your library. The main and most important aspect in that feature is that it doesn't change the binaries at all. It is backward compatible. So people that don't want to benefit from it just don't opt-in. It doesn't create a shift at all, no more than the introduction of new keywords such as async/await or new use case of the ref keyword. And those changes were breaking (requiring runtime support). Here the csharp development team has chosen the less-impacting solution. It just requires support at the language level. I don't think your understand fully the advantages of that.
When I wrote "what does the code look like" I wasn't expected a dump of the code but more a high-level description of the problem at end, with maybe a simplified version of the main algorithm. Here it looks like you did take the time to reduce it to what the code is supposed to achieve, unburden by all the boilerplate.
I see what you did there and thought it was witty
This depends on a few factors. If the first method makes sense, then that method shouldn't be in the same class in the first place. If it doesn't make sense except to the current class, then maybe it makes some sense to use the second method, but is still suspect.
Just set the variable that points to the class to null or let it go out of scope.
Paging u/daedalus_structure for comment on this debate.
Popular demand. See the comments in the previous thread.
Xamarin 
Look into ClickOnce or Squirrel
Yes the Things are all the class representations of the various API JSON returns. The JSON deserializes directly to these objects.
In most places where I worked, people weren't allowed to introduce changes to the codebase they weren't suppose to introduce. 
I don't doubt that. But I have also worked in numerous places that trusted the developers. Or at least didn't watch them too closely. 
No, types in APIs and definitions from unadorned libraries exist in a third state and don‚Äôt produce warnings when used. There is an effort under way to enable external adorned definitions to be referenced by the compiler to add that information.
Yep, ClickOnce is especially easy to get started with since it‚Äôs an option when you publish the project in Visual Studio. Squirrel‚Äôs slogan is that it is the same as ClickOne, but that it works, but you will have to set more up in trade for more options, if you choose this.
I kind of understand that. If I was "cleaning up the code" for an entire day then it means I wasn't doing the tasks from the sprint. The tasks are selected into the sprint based on how much work the team can do, so any unplanned work impacts negatively on the entire team. 
I don‚Äôt know of great books for you but I can list some features to get familiar with: * structs vs classes. In c# structs are value types, important for controlling memory layout sometimes and avoiding go pressure when appropriate * span&lt;t&gt; a new feature giving you more power to avoid allocations * c# generics are quite nice, if you avoided templates in c++ you may like generics in c# just fine * .net core 3 will be introducing simd intrinsics which will be huge for game developers * linq is very convenient and good to learn about but it can be slow and create go pressure so often not good to use on anything that happens every frame * for each is a little slower on lists than a for loop * list in c# is like vector in c++
Sounds like your team is dysfunctional. A common occurrence for sprint based projects where they are in a constant rush and never stop to do clean up work, experimentation, or long term planning. I swear, SCRUM is one step above panic driven development in ways to destroy a group of competent developers. 
Checkout wyBuild and the oprn-source automaticaudter control.
Don‚Äôt use ClickOnce. There is a reason Squirrel was created. 
It seems to me like having the feature converting `String?` to `String` and `String` to `String!` on compilation would have been the simplest solution.
If you want to go the AWS route (maybe for the sake of learning, idk), you could consider this: 1) you‚Äôd have 2 programs. One is your winforms app, one is your update checker. The update checker just needs to be a small console app 2) place your program files (.exe, .dlls, etc) in S3, and deploy a microservice to handle the version checking 3 When the update checker opens, it calls the service, which sends back the updated files via a file stream if they need to be updated. Then, the files are saved into your winforms folder and the winforms .exe is called Unfortunately you‚Äôd have to manually update the s3 files and web service every time you built a new version, unless anyone has a better idea for this The truth is you should probably go with one of the tools listed above if you need it done quick and correctly, but I think if you are interested in more of a project or learning about AWS, this technique could be fun to try 
Thanks for including me as a contributor, even if I just did a glorified copy+paste :) One last suggestion for repo health would be to just push everything from develop to master, or make develop the default branch. You want the landing page of the repo to be informative, which it currently isn't without switching branches. 
Visual Studio. Build them with Xamarin. You can also develop iOS apps in the same project if you want. Some features will require device specific code, but it's very doable. 
ClickOnce is the simplest way, additionally you will need a web page where you can host your app. Read this guide, it's simple: [https://weblogs.asp.net/shahar/how-to-use-clickonce-to-deploy-your-applications](https://weblogs.asp.net/shahar/how-to-use-clickonce-to-deploy-your-applications) Once you have your app setup up, everytime you publish a new version of your app, it will be upoaded to your website and everytime an user opens the app it will update itself.
As far as a book goes, [C# in a Nutshell](http://www.albahari.com/nutshell/) is a great one for experienced developers looking to get up to speed on the language and framework's class libraries.
which is?
Read up on the IDisposable pattern. Also, GC will not know how to dispose of unmanaged objects such as a database connection or a file reader that makes io calls. 
Use TAP. Look into Stephen Cleary's blog. Old but gold article https://blog.stephencleary.com/2012/02/async-and-await.html 
Easier to read this wiki than explain. https://github.com/Squirrel/Squirrel.Windows/wiki
&gt; .net core 3 will be introducing simd intrinsics which will be huge for game developers Do you know if this is in the preview?
Sure, check this and thank you for your attention :) [https://www.reddit.com/r/csharp/comments/aijzc7/building\_microservices\_on\_net\_core\_part\_2\_shaping/](https://www.reddit.com/r/csharp/comments/aijzc7/building_microservices_on_net_core_part_2_shaping/)
.NET Framework already supports SIMD since RyuJIT introduction.
You should look into clickonce, if you want to own the deployment. If you already have some kind of SCCM setup, then you could also go MSI route. For both of them you will need to create some kind of template which store all the files information, download and shortcut locations, and actions to perform when user does something, etc.
It is already available on .NET Framework. https://blogs.msdn.microsoft.com/dotnet/2014/05/13/update-to-simd-support/ https://docs.microsoft.com/en-us/dotnet/standard/numerics
Check out [Onova](https://github.com/Tyrrrz/Onova)
This always reminds me how much of a hickland windows still is. There was system-wide update+upgrade for debian/redhat in what, '97 already? Sorry OP, this is not on you nor commenters, just hate this side of Windows ecosystem.
&gt; One last suggestion for repo health would be to just push everything from develop to master, or make develop the default branch. You want the landing page of the repo to be informative, which it currently isn't without switching branches. That's just a temporary problem that will go away once I put out the first stable release. I follow the [Gitflow](https://nvie.com/posts/a-successful-git-branching-model/) branching model in all of my Git repos. It a Gitflow-style repo, you only merge into master for stable releases. Feature branches merge into develop and develop merges into master. Once I'm ready to put out v1.0.0 (which should be very soon), I'll merge into master and the README will be updated. &gt; Thanks for including me as a contributor, even if I just did a glorified copy+paste :) No problem. Thanks for the contrib! You also cleaned up my markdown a bit, too, which was also helpful. If you take a look at the docs/contributors directory, you'll see a .md file with your name on it. Feel free to put whatever you wish in that file and do a pull request. Then you can link to it on the repo (after the next master merge) from your LinkedIn profile or whatever else. I was thinking that might be a good way to help motivate people to contribute. What do you think? 
I'm still confused about what's wrong with click once but thanks though
Thanks! If you already have your own App ID and refresh tokens, you can help by running the tests (see the previous thread or the README for instructions on that). I do have an App ID for the tests and example app, but I still need time to write the endpoint/form for giving out API refresh tokens to beta testers. I was planning on getting to that once we move on to beta, but that's on hold until we can find some sort of consensus on what to name the Controllers.
I'll give this a go too
I think that idea is a fantastic start and will work for most use-cases. I just wanted to share some additional ideas on how to better secure the patching process. I've used the same methodology that is stated above, with some additional steps in the past for modular desktop applications. In addition to the version checking, OP may want to add an additional layer of security which verifies on the client side that this is actually your code. For example, in a modular type application, you would want to verify that the file is digitally signed with your certificate, and that the hash of the binary matches the hash of the server-side file, and possibly some other form of verification such as file attributes (size, timestamp, etc). If not properly coded, .Net apps can be easily manipulated by, for example, a rogue dll that was either patched during the download process via some installed malware (yes, this is possible), or a direct replacement on the system, depending on whether the code was digitally signed initially. The sky is the limit for an attacker once that loophole has been discovered, and worst case, you may find that your code inadvertently has now infected your customer with something nasty like Remote Access Tools or the bane of all our existence, Crypto-Ransomware. The way we handled updates on the server was by building special packages which were deployed to the server. We even went as far as creating a custom packing application similar to creating an archive of all of the updates, which was encrypted before hitting the update server (S3 in this instance), then performing additional "pre-checks" before actually running the patch process. This could be done a bit more easily if you just use a regular zip library and come up with a secure process of retrieving the password to decrypt the file, such as an AES key appended to the end of zip archive (done server-side) that is used to encrypt the entire archive, then (again server-side) encrypt the AES key with a public RSA key that is machine-specific. This RSA key pair would be created server-side, with only the public key being sent and the private key being sent over SSL (thanks CryptoLocker :)). It's not foolproof and still has a degree of vulnerability, but this system should deter most people with even intermediate skill levels from being able to tamper with the update process. Obfuscation can help a great deal here as well, just don't use the open source ones without modifying them as there are ready-made DeObfuscation tools for many of these packages. Speaking of patching, OP may also want to look into patching the files rather than wholly replacing them. This saves significantly on bandwidth regardless of how large the file that needs to be patched is, as it will only download the changes. More info on patching [here](https://docs.microsoft.com/en-us/windows/desktop/msi/patching). In the past, I've built systems that handle all of these details and more, though I can't share some of the more interesting things we did as I am still under NDA. Additionally, this is not an easy task to get right, and requires a great deal of work vs some of the other fantastic ready-made solutions that have been suggested in this thread. All that said, if OP is not confident that they can properly implement this in a secure way, I wouldn't recommend reinventing the wheel. The use-case and prevalence of this application is certainly a factor this decision.
Follow up of https://altkomsoftware.pl/en/blog/building-microservices-on-net-core-1/ respectively https://www.reddit.com/r/csharp/comments/afwn38/building_microservices_on_net_core_part_1_the_plan/ 
Follow up of this https://old.reddit.com/r/csharp/comments/afwn38/building_microservices_on_net_core_part_1_the_plan/ respectivley https://altkomsoftware.pl/en/blog/building-microservices-on-net-core-1/
Here's where the argument for renaming them was the most strongly made: https://www.reddit.com/r/csharp/comments/a952u3/introducing_redditnet_an_oauthbased_fullfeatured/ecgmt23/ I would definitely appreciate any thoughts you might have on that. I've asked the user to come here and argue his case so we can hopefully get a healthy debate going on it. I agree that controllers is the better name but I also don't want to alienate a large segment of the dev community, so I think letting people debate the issue is the best strategy for resolving this right now. If the people who pressured me to rename them don't come forward and make their case, I'll just rename them back and call it good. But emotions could run a bit high on this one so I don't want to act too hasily either way.
Thanks for pointing that out. That has now been fixed. (someone else has bought the domain it used to be on.)
Thanks for making that point! I'd just assumed it was ok because RedditSharp has been around for so long without any problems. But I agree with the other users that this restriction seems to be targetted toward apps and not libraries. That said, I'll post over on r/redditdev and ask how I can go about making this kosher with their legal folks or whatever sometime before the first stable release.
\- What could be wrong if I update this 500k program? \- BOOM now you download 1.6 gigs of dependencies you never asked for.
&gt; My work is to write software that doesn‚Äôt have errors (NRE‚Äôs included). People that can‚Äôt seem to do that without gimping nulls are the ones that still need to learn. I already learned. Ah yes, the point at which a software developer thinks they know better than the compiler. Except‚Ä¶ [even the frigging compiler team makes this mistake](https://github.com/dotnet/roslyn/search?utf8=‚úì&amp;q=fix+nre&amp;type=Commits). If you think you‚Äôre the unicorn who never does, you should apply for a job there. &gt; NRE‚Äôs aren‚Äôt a ‚Äúplague‚Äù. They‚Äôre a symptom of not writing good code. No, they‚Äôre a symptom of early design decisions in .NET and C#.
That‚Äôs slow and awkward to write and consume. Why would you do this?
&gt; I hardly recommend trying to work with MediatR library. I think you meant "strongly"
Part 3 already available ? 
Yeah I'm still in the dark also, ClickOnce does me just fine so far.
I've admittedly only used it once, and not in production but it seemed like it does exactly as advertised... you make one click and it deals with stuff? what else is it supposed to do?
Straightforward, no plug in option: * Create a local config file with the application version number. * Have your application connect to a database and retrieve the current version number. * Compare version number in local config to the returned value &gt;&gt; If(LC != RV) Prompt for update. Wrap your application up in a shell that handles all of this and can open and close your application via its process handle and you're golden. 
Friends don't let Friends Right-Click -&gt; "Publish".
IDisposable is used where you need to explicitly clean up resources. This is usually for something like closing and flushing a stream writer where you need to instruct in the code how cleanup occurs. If it's something the garbage collector can handle without intervention, just let the GC do its job.
Have you tried Syncfusion [HTML to PDF in .NET using C#](https://www.syncfusion.com/pdf-framework/net/html-to-pdf). It is reliable and accurate. The result preserves exact layout of the original HTML document or webpage. [C# HTML to PDF example](https://www.syncfusion.com/kb/9143/how-to-convert-html-to-pdf-in-c-and-vb-net). &amp;#x200B;
Yeah, that's almost surely not what OP want. Finalizers in .NET is an advanced concept, not something for beginner programmers. Also, they are almost never needed.
It's not even called when GC is collecting the object. It's queued at that point. But that point may never come. 99.999% of programmers shouldn't write finalizers :)
Tbh, i tell my customers to use Chrome and set Destination to PDF. That way you get the precise page to PDF
You can use Syncfusion [.NET PDF library](https://www.syncfusion.com/pdf-framework/net) to merge PDF files with just few lines of code. &amp;#x200B; [C# example to merge PDF files](https://www.syncfusion.com/kb/9146/how-to-merge-pdf-files-in-c-vb-net) //Creates a PDF document PdfDocument finalDoc = new PdfDocument(); //Creates a string array of source files to be merged string[] source = { "file1.pdf", "file2.pdf" }; //Merge PDF documents PdfDocumentBase.Merge(finalDoc, source); //Save the document finalDoc.Save("Sample.pdf"); //Close the document finalDoc.Close(true);
The way I do it is to have the server track the latest version. Whenever this version changes, I update it through a web UI, which notifies all connected clients through SignalR. If you're not using SignalR, you can have the clients check when the app is opened, or periodically. App downloads the new installer, executes the installer, and quits itself. User has been told to click through the installer to complete the update. Much simpler than messing about with microservices and since I use proper installers, the app can easily be uninstalled by users, properly.
I did a weird thing, I kept a string on GitHub which I downloaded every time the program started, if the value was different to the program version, it would download the latest release from GitHub and restart, this worked because I had a light CLI and a library which actually did the work, the updater would update the library... It ain't stupid of it wolrs,
Did this with a text file on GitHub
The language has minor changes from C++, I think that you can focus on the platform internals. Best book here is ["CLR via C#"](https://www.oreilly.com/library/view/clr-via-c/9780735668737/) by Jeffrey Richter.
How does million on separate upgrader change this?
My working solution is now to: 1. For all Objects: call DataAdapter.Update for T1 2. SQL select (Read all PK) and Update my Objects representing T1 and T2 rows 3. call DataAdapter.Update for T2 4. SQL select T2.PK and Update my Objects representing T2 and T3 rows 5. ... and so on. Thanks for replying
maybe heartily?
Haha üòÇ sorry
I would go for the separation of concerns and inject a validation service into controller.
System.Numerics exposes a small fraction of available SIMD instructions in a convenient portable API. I'm pretty familiar with it, having built a couple libraries that leverage it (LinqFaster for C# and SIMDArray for F#) The usefulness is rather limited though as some key instructions are unavailable. With .NET core 3.0 they will be exposing all of them in raw form. They will be harder to use but much more powerful. 
Yeah there is a preview package you can use: https://mijailovic.net/2018/06/06/sha256-armv8/ https://blogs.msdn.microsoft.com/dotnet/2018/10/10/using-net-hardware-intrinsics-api-to-accelerate-machine-learning-scenarios/
Isnt this technically CQS and not CQRS?
Something linke this? public interface ILength { double Meters { get; set; } } public class LengthMeter : ILength { public double Meters { get; set; } public static LengthMeter operator+ (LengthMeter left, ILength right) { LengthMeter result = new LengthMeter(); result.Meters = left.Meters + right.Meters; return result; } } public class LengthInch : ILength { public double Inches { get; set; } public double Meters { get { return Inches * 39.37; } set { Inches = value / 39.37; } } public static LengthInch operator+ (LengthInch left, ILength right) { LengthInch result = new LengthInch(); result.Meters = left.Meters + right.Meters; return result; } }
Well, I'm assuming OP isn't actually hardcoding adding 1 to the list, becasue the best way would be to `return new List&lt;int&gt; { 1 }`, and actually wants to do something like: List&lt;T&gt; populateList&lt;T&gt;() { var newList = new List&lt;T&gt;(); foreach(var item in GetItems()) newList.Add(TransformItem&lt;T&gt;(item)); return newList; } which would be much neater as a yield: IEnumerable&lt;T&gt; populateList&lt;T&gt;() { foreach(var item in GetItems()) yield return TransformItem&lt;T&gt;(item); } 
Actually this Repository is already used via IoC in a Service used by a controller such as: DB =&gt; Repository =&gt; Service =&gt; Controller So what you suggest is: DB =&gt; Repository =&gt; Service =&gt; Validation =&gt; Controller
There are enough mediatr examples, but really need to some ‚ÄúSQRS from scratch‚Äù to understanding how it works in deep.
True. It's hard to know what OP is actually trying to accomplish here without more context.
Id rather name the method `EnumeratePopulatedIems()`, or something more meaningful (sorry not really creative right now), because "`PopulateList`" does not "populate a list" but rather enumerates an existing list and `yields` a transformed item
Yes, I'm just keeping OPs name and changing the implementation.
Yes, but your comment states otherwise for those that are new to .NET like the OP, namely that .NET doesn't support any form of SIMD at all.
Basically it's hard to do CI with ClickOnce because of the tooling and how strict it is.
Same goes for a network drive. I use click once and network drives at work
You haven't said exactly what this "label" class is. If it implements `IDisposable`, you should dispose it (most of the time). If not, you can let it go out of scope and the GC will reclaim it. Assuming `Label` is a class which implements `IDisposable`... - If your use of the Label only spans the scope of a single method, use a `using` block: void MyMethod() { using (var label = new Label()) { // Use label here... } // label gets disposed here. } - If your Label and your containing class have the same lifetime, your containing class will need to implement IDisposable - ideally with a Dispose pattern - and then dispose of it as described above. // Proper Dispose pattern: public class MyClass : IDisposable { private readonly Label myLabel; public MyClass() { this.myLabel = new Label(); } protected virtual void Dispose(bool disposing) { if (disposing) { // Dispose managed resources... this.myLabel.Dispose(); } // Dispose any unmanaged resources here... } public void Dispose() { this.Dispose(true); } } // Cheats method: // note *sealed* here public sealed class MyClass : IDisposable { private readonly Label myLabel; public MyClass() { this.myLabel = new Label(); } public void Dispose() { this.myLabel.Dispose(); } } - If Label lasts longer than the scope of your containing class, don't dispose of it. It's not your resource to manage.
Got me also xD
No, we're just starting to work on it.
It treats the returned string like it does today without the new feature and does not generate warnings when you assign it to a non-null variable or dereference it. I‚Äôm not sure yet how intellisense will denote the difference.
Brilliant. So we now have: - Nullable reference types - Non-nullable reference types - Non-nullable reference types that are nullable.
sorry, was just trying to provide some information
It's not a matter of not making the mistakes. It's a matter of not whining about it when the NRE comes up. *They're not hard to fix.* But most newbie developers can't seem to figure out how to find them. Get a stack trace. Look at the *few* lines of code where it's possible to get one. (If there are more than a few lines of code, *that's* the problem.) Look at where you're accessing methods, fields, or properties of something. Then look at where those "somethings" might be null. That's literally it. Wrap them in null checks, assign values to them, or handle the NRE's with a catch block (no, nevermind, *don't* do that one...), but there isn't really much else to it. Nulls are not a mistake. They're not a design flaw. They're not a *problem*. Nulls are a value state that should be accepted *and expected*. Be mindful of what you write and debug your code. Then they aren't an issue at all. It's not about knowing better than the compiler or the compiler team or the language designer. It's not about getting it perfect on the first try. It's about *not being bad at your job*.
I'm talking about the difference between an additive change versus a refactoring change. With how they implemented the new feature, when you enable it, the default is that all references are expressed as having the intent of never being null. Because the change alters how existing code is interpreted, I do not support it. It would have been better if using "!" after a reference type designated that the intended use of the reference to never be null. Then, you wouldn't need an option to turn it off and people can use the new feature by utilizing the new syntax. Again, what I don't support is the reinterpretation that the feature imposes on existing code. That kind of split is unacceptable in my honest opinion.
You should try out Actual Installer ([https://www.actualinstaller.com/](https://www.actualinstaller.com/)). They have a build in (very simple) Check for Updates. I put the update.txt on AWS. Your app calls their update exe at startup and I believe it compares versions and prompts the user if it's not a match. It might even be simpler than that. I prefer the user select check for updates. Love this installer. You'll want to set up a AWS S3 account. It's free. Make Public the files. 
CQS states that there can be only two kind of methods on a class: the ones that mutate state and return void and the ones that return state but do not change it. We do not have methods that do these two things at once. CQRS introduces separations between classes. In one class we have methods that only read data. In the other class we have methods that change the state. CQRS also enables us to have different models for mutating state and different models to support queries but IMO not requires this. Check this: [https://kalele.io/blog-posts/really-simple-cqrs/](https://kalele.io/blog-posts/really-simple-cqrs/)
So I wasn't trying to blow you off. Here's a full list of the different references I've looked at, with some inline comments: * [Threading in C#, part 4: Advanced Threading](http://www.albahari.com/threading/part4.aspx) * [ECMA .Net Standards](https://github.com/dotnet/coreclr/blob/master/Documentation/project-docs/dotnet-standards.md) (ECMA-335, partition I: Concepts &amp; Architecture, section 12) * [When is "volatile" used instead of "lock"?](https://bytes.com/topic/c-sharp/answers/649936-when-volatile-used-instead-lock) - extensive discussion by Jon Skeet and some MSFT guys about what the ECMA specification *means* vs what it *says*, etc. (The spec is vague on this point but Jon Skeet's argument is that, if lock's implementation doesn't use acquire/release semantics then it's broken.) * [What Every Dev Must Know About Multithreaded Apps](https://blogs.msdn.microsoft.com/vancem/2016/02/27/encore-presentation-what-every-dev-must-know-about-multithreaded-apps/) * [Understanding the Impact of Low-Lock Techniques in Multithreaded Apps](https://blogs.msdn.microsoft.com/vancem/2016/02/27/encore-presentation-understand-the-impact-of-low-lock-techniques-in-multithreaded-apps/) - specifically mentions double-check locking, states it's safe in the x86 and .NET Framework memory models but is not guaranteed by then-current ECMA; some of the code blocks and tables are missing from the PDF, but present in the CHM. * [Memory Barriers in .NET](https://afana.me/archive/2015/07/10/memory-barriers-in-dot-net.aspx/) - what do "acquire" and "release" semantics mean? 
We also prepare article "CQRS Intro for Developers" about how CQRS works in deep, regardless of language. Now you can check this article, from Vaughn Vernon: [https://kalele.io/blog-posts/really-simple-cqrs/](https://kalele.io/blog-posts/really-simple-cqrs/) 
Does this help? https://stackoverflow.com/questions/4682642/joining-godaddy-issued-spc-and-key-files-into-a-complete-pfx-cer-certifica For future reference, I highly recommend buying a Comodo authenticode cert from ksoftware.net. They're low cost and offer good customer service.
Well np, just... OP better not use it, in this case :p
I'm really interested in what you need to do for deployment of this. Going through the configuration of appsettings, different docker-compose files, start scripts, and kubernetes. Will you be going over these details?
The reason why the "!" syntax was not chosen has been documented and explain enough it the corresponding issues on GitHub. Not going to reproduce them here. The language team made a choice that the majority of people agree was the right one. Of course, you will always have a minority that is either uninformed or disagrees based on other opinions.
Basically if you use ClickOnce long enough with a wide enough audience it will fail you. For me personally that day was when our code signing certificate expired, my fault, but there was no way to correct it. Typically you don‚Äôt check expiration dates for code signing just that the keys match. ClickOnce wouldn‚Äôt update any longer leaving my 600,000 users on an essentially bricked version of my app. They fixed this issue in VS 2015 version, however it was too late for me. By the way, one thing I learned from this event is that you want the installer portion of the update to be external from your app and remotely download. This way you have the most control if things go wrong, because the logic to update exists on a remote endpoint. ClickOnce doesn‚Äôt offer this protection in their packaging. 
Jup, I've also used GoDaddy's code sign files. Remember I had trouble following their guide. And even when I converted it to a \*.pfx, I wasn't able to get Visual Studio to accept the certificate in the "Code signing" options in project settings. After research I ended up doing it another way. 1. Unzip both the \*.pem and the \*.spc file to a folder. 2. Right click on the .spc file and select "Install". When it asks you for where it should store it, select "Personal". When it is imported, you can find your sertificate in the computers certificate store (search your start menu for "Manage user certificates"). Check that it is marked "Code signature" and have a valid expiration date. 3. Find or download the tool "signtool.exe". [See here for where you can find it](https://stackoverflow.com/questions/31869552/how-to-install-signtool-exe-for-windows-10). 4. Run the command `signtool.exe sign /a /d "YourSolutionName" /tr http://tsa.starfieldtech.com /td SHA256 "FullPathToYourFile.exe"` If you are using Visual Studio, you can add that last step as a post-build event in your project file. I added it like this: &lt;PropertyGroup&gt; &lt;PostBuildEvent&gt;call "$(SolutionDir)lib\signtool.exe" sign /a /d "$(SolutionName)" /tr http://tsa.starfieldtech.com /td SHA256 "$(TargetPath)"&lt;/PostBuildEvent&gt; &lt;/PropertyGroup&gt; Quick summary of the options: * /a Does an automatic selection of the first and best code certificate it can find in Windows certificate store. I've not tried to use multiple code certificates yet, so don't know how to select a specific one. Check `signtool.exe /?` for details if you need that. * /d Adds a description to the signature. A description is required. Don't know why. * /tr The timestamp server to use. * /td Digest certificate for the timestamp server (no idea what exactly this is). With this I was able to sign both the \*.exe, a \*.dll file, and the final \*.msi file (that I created with a Wix project in the same solution), and they got accepted by Windows' UAC without problems. Hope this works for you.
Right. So are the coordinators supposed to be services? This looks like a service-ish pattern.
My company is looking to fill the following C# based positions: [https://careers.verisk.com/viewjob.html?optlink-view=view-63166 ](https://careers.verisk.com/viewjob.html?optlink-view=view-63166&amp;ERFormID=newjoblist&amp;ERFormCode=any) [https://careers.verisk.com/viewjob.html?optlink-view=view-63122](https://careers.verisk.com/viewjob.html?optlink-view=view-63122) [https://careers.verisk.com/viewjob.html?optlink-view=view-62070](https://careers.verisk.com/viewjob.html?optlink-view=view-62070) &amp;#x200B; And one dba position: [https://careers.verisk.com/viewjob.html?optlink-view=view-63152](https://careers.verisk.com/viewjob.html?optlink-view=view-63152) &amp;#x200B; PM me your resume if interested and let me know which position. &amp;#x200B;
Not exactly. You can put a null into any non-nullable reference variable. The compiler may warn you, it may not, but the runtime won't give a damn. Which means you still need to add things like null checks to your public parameters. 
So what I got from the discussion thread and "LowLock.pdf": * The experts couldn't agree on when or whether volatile is needed, even when using Interlocked. * ECMA standard has a weaker memory model (i.e. volatile is needed whenever there's potential sharing between threads), while .Net Framework 2.0 introduced a stronger memory model (confirming my observation that I couldn't get the compiler to cache values in registers in DCL experiment). * ECMA335 contains the following sentence: " For this purpose only volatile operations (including volatile reads) constitute visible side-effects." * ECMA335 guarantees that (among other things) volatile accesses, explicit atomic operations and lock acquire/release have cross-thread visibility. * ECMA335 on volatile: "An optimizing compiler that converts CIL to native code shall not remove any volatile operation, nor shall it coalesce multiple volatile operations into a single operation. " * With a bit of googling I couldn't find any definitive description of the .net core memory model; it's not even mentioned in the "Book of runtime" So, my getaway is: to be safe, or, rather, future-proof, volatile or Interlocked should be used in all code not using explicit locks. The code that .NET framework or CoreCLR generate is an implementation detail. So what's your takeaway?
&gt; It would have been better if using "!" after a reference type designated that the intended use of the reference to never be null. That would make it significantly harder to adopt this feature as the vast majority of variables are intended to be non nullable in a typical application. And it would be inconsistent with value types.
&gt; Do I appreciate a bunch of newbies coming in and telling us all that we're doing it wrong? I've been using .NET since it was in beta 2 nearly two decades ago. And I've been asking for this feature for nearly as long. 
The way they chose is inconsistent too though. What's worse is that it creates false expectations by using too similar syntax to nullable types.
IMHO, the hate on ClickOnce is somewhat exaggerated but there are valid complaints. FWIW, I've been using it for a decade w/o issues. It definitely helps that its on an enterprise app and I'm not pushing it to the general public and I've got a relatively bounded 1k user base. 
The coordinators are the controllers in a model-controller pattern. Shit everyone's right, the new name is confusing.
Yep. No one is denying that this isn't perfect, but after nearly two decades of talking about it this is the best idea we've got. And it's not done yet. Changes are still being made to the design.
It takes a long time, I think. It is better to spend time for improving the program
I'm not an expert on linux and I'm not trying to antagonize you or anything, but are you saying you can, at once, check for an update for all the programs you have on your machine? Even those that you didn't install from the repository but had to install manually?
That's also I point I should have covered. Don't name it "Things", it's the most generic name you could ever come up with. Ask yourself what should someone who knows nothing about your code expect to find under this namespace and name it this way :)
Yes for all repository -originated programs (and repositories can be individually hosted, I've done that personally on my server when I published programs), the same mechanism that looked for distro originated programs also checked the non-distro programs. Separately installed (compiled or binaries) programs have always been outside this method. However separately installed package could get into update cycle once it got into a repo or if you later added repo where a newer version were.
Can still use `String!` over `String` for method arguments, properties, and fields.
should you really inject a validator as opposed to just making it a static class? It feels really pointless lol...
Time-proven solutions for HTML-to-PDF conversion are wkhtmltopdf or phantomjs. This is command line tools (have builds for both Windows and Linux) that you can execute with System.Diagnostics.Process; or, you can use one of the existing wrappers like [NReco.PdfGenerator](https://www.nrecosite.com/pdf_generator_net.aspx) and generate PDF with 1 line of C# code.
Wow - didn't expect to get a response from Microsoft. Your corrections are indeed correct. My apologies, as this post was not entirely accurate.
I stand corrected.
Explain please
You probably shouldn't be doing CI with a desktop app anyway. CI is for server-side stuff. Do proper versioning and releases for anything that gets installed client-side. I guess you could do CI for your dev builds, but those shouldn't be set up as ClickOnce anyway. You don't set up ClickOnce for it until it goes into integration testing, which should at that point be "production but not really". IIRC, ClickOnce settings are per-build-target.
So true. Except for SSDT. That shit's *handy*.
It allows easier unit testing - I personally would inject
heres my repo fir ddd, cqrs, mediatr and fluent validation. Check out the video by JasonGT on clean code. cleanstartcore - https://github.com/jetstreamin/CleanStartCore Jasongt's Youtube video on clean code - https://youtu.be/_lwCVE_XgqI
does it? You need to mock the whole validation service and also add extra injections to your class which makes it less readable. It also doesn't really follow OOP logic - your valdator isn't really an object, its just encapsulated logic that provides pure functions with no side effects, which is the perfect use case for a static class.
To be clear, that wasn't an "official" response from Microsoft, but my personal response as someone who works on the team responsible for servicing BinaryFormatter.
Agile/Scrum ... Had some self-important person decide we should treat all errors as warnings, so 2 of of us fixed all the warnings in the code that we were responsible for in a couple hours. Most of the warnings were in the code that self-important person's group was responsible for. The guy claimed success, but when I ended up working on that codebase at a later time, I found that he himself had resolved most of the warnings with suppression rather than an actual fix. 
I still fail to see how you would unit test your controller effectively 
I still fail to see how you would unit test your controller effectively 
Code reviews are important for preventing that kind of crap.
I can't make any comment about your experience with support issues in other components, I can only speak of my own experience working on issues that have been escalated to me. If a bug is discovered in a component that I work on, the outcome (so far as my experience is anyway) has always been to either fix the problem or find a workaround for customers. A workaround is generally preferred as getting a fix released can take multiple months before it appears on Windows update and a workaround unblocks people quicker.
&gt;You probably shouldn't be doing CI with a desktop app anyway I'm referring to a pipeline of building and deploying which does versioning and release management. I shouldn't set up ClickOnce with customers' production signing certificates on a dev machine, for example.
C# 7 introduced non-nullable reference types in the form of `TypeName!`, which don't accept a null value. Or atleast there were supposed to have, it was one of the major touted features - but checking now, I'm getting syntax errors, so maybe I've misremembered horribly and they never added it, sorry for the confusion.
That was a previous iteration of the nullable reference type feature. It's mutated a bit, since.
No, but it does lead to an interesting idea. We could have the ! modifier on a parameter automatically add a null check. 
It doesn‚Äôt take a long time and it‚Äôs totally worth it. You can do so much with key generation like globally unique keys, database generated keys, or just your own plain algorithm which only took me 5 hours to make and can generate over 50,000,000 unique keys until they start colliding. You can make more possibilities by adding more key groups but I highly doubt an indie dev like myself will even get over a thousand sales. But it‚Äôs still very possible and easy to do.
&gt;1. Provide async only and let the consumer figure it out if they want to force synchronous calls. 1. Provide async with synchronous stubs that call the async methods and resolve the Tasks How do you do that and avoid the possibility of deadlocking? 
I agree, there's no real harm in using it. It's also really hard to articulate whether it's required or not. (Also note that in C# *all* writes are volatile, which is different from the Java memory model. Which would suggest that any write is included in the phrase "For this purpose only volatile operations ... constitute visible side-effects.", whether or not the variable is marked volatile.) FWIW, I found another one (former Microsoft Parallel Computing Team member): [Volatile keyword in C# - memory model explained](http://igoro.com/archive/volatile-keyword-in-c-memory-model-explained/), by way of [this StackOverflow question/answer](https://stackoverflow.com/questions/7833462/does-locking-ensure-reads-and-writes-are-flushed-from-caches-if-so-how).
var testData = someDataThatIsValid var result = StaticClass.Validate(testData) Assert.IsTrue(result) ? 
I'd avoid dynamic. 
Yeah, I went the simple route with my app as well. Have a file on the server with the latest version number and URL to download. Client calls that page, checks the version against itself and prompts the user. I actually made it a simple classic ASP file that also logs the IP, version the client reported, and somewhat unique identifier that I log to the database. Since my app is free, it's difficult to know how many people are running it, so this also gives me some basic metrics. The setup program (Inno Setup) sends a message to the app to shutdown if it's running (app uses a mutex that setup checks for), installs, and starts the app.
all architectures are different, so below don't assume you have to have a separate business logic layer or separate data layer etc. but the point below is valid nonetheless: **the HTTP terminology should stay where it's used, in the HTTP services/apis. your business/domain layer (and data layer) should know nothing about apis or http.** the same goes for references. if you are referencing some web stuff in your business logic project/lib, that is very bad. you are not only forcing consumers of your library to use those references but force them to use specific versions.
Whether or not .Result blocks doesn't depend on it having a return value. It will always block. Usually when I want to call an asynchronous function in a synchronous manner, I will use .GetAwaiter().GetResult(), and make sure that the code in the async function and its path will not cause a deadlock from doing this. It sounds like you may not be familiar with the differences between asynchronous and synchronous code. If that's the case, I recommend reading some of Stephen Cleary's "Concurrency in C# Cookbook".
Sorry i meant deadlock. Edited question
Right, well yes, you risk deadlocks when calling asynchronous code in a synchronous manner, such as when you use .Result, .Wait(), or .GetAwaiter().GetResult(). You need to verify, based on the starting synchronization context and the code that is in the execution path, whether a deadlock is possible. The best way to understand how this works is to read Stephen Cleary's blog posts, and some of his book if you want to learn more. He has a lot of posts, like this one: [https://blog.stephencleary.com/2012/07/dont-block-on-async-code.html](https://blog.stephencleary.com/2012/07/dont-block-on-async-code.html)
Is it my imagination, or is SQL actually just a functional language that functional language junkies refuse to accept?
Asynchronous code(async /await). Parallel programming using tasks look up TPL.. IoC ( inversion of control) .net has default dependecy injection libaries. Tupels, Func, lambdas. Someone mentioned a **foreach being slow in this thread well you can parallel.foreach**. Just be sure to read up on it / threadsafe and how to manage.. this shaved a lot off my pet project.. I was checking 176,400 strings and building lists.. 
honestly MSDN documention is great for the most part now. maybe start here; https://docs.microsoft.com/en-us/dotnet/csharp/index 
Why are you trying to call an `async`-style method without using `await`? That is a huge code smell to me. But from my experience, yes, it could deadlock. I was never able to identify the specific cause, but I had intermittent deadlocks in unit tests of my implementations of `AsyncLock`, `AsyncManualResetEvent`, and similar classes whenever they used `.Result`, `.Wait()`, or `.GetAwaiter().GetResult()`. The only way I was able to call `async` code synchronously without _ever_ seeing those deadlocks was by wrapping it in `Task.Run` (for example, `Task.Run(() =&gt; DoSomethingAsync()).Wait()`).
What you should do is go back to the original and use a single SemaphoreSlim, shared across each method that needs it, to ensure that those conflicting methods cannot be called concurrently. Semaphores are not re-entrant, so they work slightly differently, but it looks like that would be suitable for your use case. A re-entrant lock can be entered multiple times by the same thread, and is what the "lock" statement provides. A non-re-entrant lock prevents concurrent access to blocks of code, regardless of which thread is accessing them.
I'd like to throw my 2 cents in here... &amp;#x200B; I've worked on several projects with MediatR, and I'm increasingly convinced that the advantages it brings can be outweighed by the negatives of code comprehension being lost. &amp;#x200B; I'm all for clean code, but having no static analysis or IDE assistance to figure out where execution jumps to is really quite a bit of a deal breaker for me. &amp;#x200B; That said, I seem to be on the wrong side of popular opinion on this one. Somebody change my mind?
Read [this documentation](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/lock-statement) on the `lock` statement and controlling access to a shared resource. You've almost got the right idea, but you've overengineered it.
https://www.rikidev.com/networking-with-ceras-part-1/ That does everything you are looking for. Its easy to use and fast. 
Wait, so if I *lock* on a dedicated object, **any** *lock* statement using that object has to wait? Not just that one *lock* statement? Is that right?
Who?
Yes
You're basically made a decorator. And it's a pretty cool idea, though. And, as it is, it most likely would work. But, it's worth pointing out that [lambda expressions can lead to race conditions](https://blog.goyello.com/2014/01/21/threading-in-c-7-things-you-should-always-remember-about/) (see #3), depending on what is going on. So, for instance, when using Parallel.For, it's good practice to do: &amp;#x200B; Parallel.For(0, 1000, i =&gt; { int local = i; // use local instead of i. }); &amp;#x200B; As opposed to, &amp;#x200B; Parallel.For(0, 1000, i =&gt; { // only use i. }); &amp;#x200B; \&gt; Will this code make me cringe in a year? Is there a better way to achieve this? I would highly recommend you to stick to Tasks. A Task is not a thread, but instead you are saying that you want a piece of code to run while you do other things. This is typically asynchronous I/O, but CPU-bound work can also be submitted to a thread pool maintained by .NET. This thread pool can also scale to what CPU your program runs on.
This is not entirely accurate, and there's quite a range in between CQS and CQRS. CQRS has architectural and infrastructure implications and goes beyond just separating logic. CQRS implies: + the read and write side are able to be deployed and scaled independently of each other + the read and write side are able to and encouraged to have different representations and persistence mechanisms for the data + there is a one way connection from the write to the read side, generally through events, so that the read side can maintain consistent state While there's benefits from splitting the logic, from a microservice perspective, the benefits kick in once you can control the read and write side independently. Please don't conflate the mediator pattern with CQRS. Yes, they can be close, and the mediator pattern can be a step along the way to a CQRS architecture, but they are not one in the same. The mediator pattern is far more about decoupling the sender and the handler of a give message and doesn't require and separation between commands and queries.
```public class Buffer { private readonly StringBuilder _buffer = new StringBuilder(); private readonly object padLock = new object(); public string Buffer { get { lock (padLock) { return this._buffer.ToString(); } } } public void Write(string s) { lock (padLock) { this._buffer.Append(s); } } }```
Not me but my coworkers code. I saw that but i wasn't 100% sure so i tried to google. I know .result deadlocks so i was suspicious that .wait did the same. Had to ask to make sure.
A robot that unplugs your power cable whenever you turn the computer on .
Here's mine! I'll admit that if your reads and writes are pretty close to 1:1 then the extra overhead that comes with ReaderWriterLockSlim probably isn't worth it. class ConcurrentBuffer { private readonly StringBuilder _buffer = new StringBuilder(); private readonly ReaderWriterLockSlim _lock = new ReaderWriterLockSlim(); public string Buffer =&gt; GetBuffer(); public void Write(string s) { _lock.EnterWriteLock(); try { _buffer.Append(s); } finally { _lock.ExitWriteLock(); } } private string GetBuffer() { string buffer = null; try { _lock.EnterReadLock(); buffer = _buffer.ToString(); } finally { _lock.ExitReadLock(); } return buffer; } } 
A drone that is controlled by screaming, and or sound.
Michael Reeves. He's become pretty popular over his first video "The Robot That Shines a Laser in Your Eye" which was posted to /r/videos some time ago. &amp;#x200B; Basically silly dude who makes dumb machines.
Is there a real difference between a *Task* and a *Thread*? Both of the *Thread*s that I'm using are going to stay around for quite a while, they aren't exactly short-term.
This is a much better (and simpler) solution, thank you!
Thank you!
When you lock an object, no other thread can lock that same object until the first thread completely leaves the lock scope for that object. Other threads trying to lock that object will be put into a waiting state until a lock on the object is available. Locks are very important in multithreading but they can cause deadlocks, too. A good example is if one thread locks object A then object B while another thread locks object B then object A. Eventually, this design will most likely deadlock.
Could you avoid deadlocking by making sure that only one class will ever have access to the objects that you are locking onto?
Seconding comodo. Very good service and have renewed it since... sounding like a shill here but solid job.
No. Locking has nothing to do with classes. It's about concurrent access from multiple threads.
&gt;Widespread domain-specific declarative languages like SQL and Lex/Yacc use some elements of functional programming, especially in eschewing mutable values. https://en.wikipedia.org/wiki/Functional_programming
Deadlocks are possible when this happens: lock(lockA) { lock(lockB) { // Potential for deadlock. } }
Do you identify your objects like var iObj or var sObj perchance?
If you're locking multiple objects in multiple locations, you always need to lock all of them and always in the same order.
Not usually. I don't care for that either. Normally I know something about the type based on the name and context of the variable. For example, I might declare a timespan used for a polling interval as "var pollingInterval = Timespan.FromSeconds(10);" The exception is when I'm working with a winforms project perhaps. I like my controls to have a name like txtUsername for example.
I get you, if it's easy to understamd from the context it's cool, jus my opinion, but I deal with devs who write code like var o = GetTheThing(); "What the fuck is the thing you validate nothing? How am I supposed to know you handle this correctly, why do you do this to me!" is my thought process, I in actuality explain why it is better with more clarity but they don't get it because they understand it as they wrote it and know their intent. It won't be until they deal with others that they finally understand, 'var' and the advice to use it everywhere is killing me when it's advice they pick and choose from. Comments are also advice, but comments are effort apparently.
try this: `using System; using System.Threading; namespace InterlockedExchange_Example { class MyInterlockedExchangeExampleClass { //0 for false, 1 for true. private static int usingResource = 0; private const int numThreadIterations = 5; private const int numThreads = 10; static void Main() { Thread myThread; Random rnd = new Random(); for(int i = 0; i &lt; numThreads; i++) { myThread = new Thread(new ThreadStart(MyThreadProc)); myThread.Name = String.Format("Thread{0}", i + 1); //Wait a random amount of time before starting next thread. Thread.Sleep(rnd.Next(0, 1000)); myThread.Start(); } } private static void MyThreadProc() { for(int i = 0; i &lt; numThreadIterations; i++) { UseResource(); //Wait 1 second before next attempt. Thread.Sleep(1000); } } //A simple method that denies reentrancy. static bool UseResource() { //0 indicates that the method is not in use. if(0 == Interlocked.Exchange(ref usingResource, 1)) { Console.WriteLine("{0} acquired the lock", Thread.CurrentThread.Name); //Code to access a resource that is not thread safe would go here. //Simulate some work Thread.Sleep(500); Console.WriteLine("{0} exiting lock", Thread.CurrentThread.Name); //Release the lock Interlocked.Exchange(ref usingResource, 0); return true; } else { Console.WriteLine(" {0} was denied the lock", Thread.CurrentThread.Name); return false; } } } } ` Look up c# thread saftey best practices guide &amp; check out Interlock class : https://docs.microsoft.com/en-us/dotnet/api/system.threading.interlocked?view=netframework-4.7.2 This document explains it even further with best practice examples: https://docs.microsoft.com/en-us/dotnet/standard/threading/managed-threading-best-practices Hope it helps
`.GetAwaiter().GetResult()` has the same blocking issues and potential for deadlocking as `.Result`, `Task.Wait`, and friends. [This is the safest way to do sync-over-async](https://stackoverflow.com/questions/44814404/in-the-context-of-asp-net-why-doesnt-task-run-result-deadlock-when-callin).
threads are a lower order concept. When you spin up a thread you KNOW it's 1. Not in the thread pool. Completely separate. A task is more general. It's like making a promise to deliver a result of some kind. Thats my understand of the differences very briefly.
Haha I get it. Everyone has their own style and preference. The most important thing is consistency across the team. And when there's a conflict due to naming conventions or certain patterns, bringing it up to the group as something to consider changing going forward (and bringing old code up to the new standard whenever it next gets refactored). But I have never worked on any codebase with a team so I'm talking out of my ass for the most part.
Tasks are scheduled to run on a pool of Threads. They have some really nice features, such as the ability to await a some kind of long running piece of work while the thread is released to do other things. I don‚Äôt know if Tasks are right for your use case, and you still have to think about thread safety and locking, but they‚Äôre both simpler and more powerful than setting threads up by hand.
Tasks are intentionally barely defined jobs, and the system is free to manage them in ways you've never heard of
Can't this just be changed to: ``` public class Buffer { private readonly StringBuffer _buffer = new StringBuffer(); public string Buffer =&gt; this._buffer.ToString(); public void Write(string s) =&gt; this._buffer.Append(s); } ``` The difference between StringBuilder and StringBuffer is StringBuffer is thread safe (and therefore slower) correct?
Yes, it does. I didn't mean to imply otherwise. This is the same for all methods of synchronously calling an async method. The real solution is to not cause these problems inside the methods you're calling, or to go async all the way; though you're usually calling the async method synchronously because that's not possible. I like using GetAwaiter().GetResult() because it unwraps the exception, whereas .Result and .Wait() will throw AggregateException, which is not very convenient. &amp;#x200B;
I'm all for style... functional, safe and well coded style. Sadly that is not the case with all. Var is great, I use it often, but not great when in the hands of a novice. Perhaps public/group shaming is a recourse I may have to evaluate.
`_lock.EnterReadLock()` should be outside the `try...catch` block. It is an error to do it inside and can cause issues. Also it only works if the `ToString()` method of the `StringBuilder()` is guaranteed to be thread safe in every cases, which I don't think it is especially in case of a very big buffer (as internally `StringBuilder` will use a linked-list of other instances of `StringBuilder`, referred as "blocks").
New variable name for my lock objects! Can't believe I didn't think of padlock
If you must use async calls from a synchronous function, use Task.Run(() =&gt; asyncFuc()).Wait() This wont deadlock
&gt; Things To be fair, [reddit](https://github.com/reddit-archive/reddit/wiki/JSON#thing-reddit-base-class) came up with that one. Pretty generic indeed, but assuming one has read the reddit API docs, not too unexpected.
Oohhhhh, I didn't know about that. In that case I guess it kinda makes sense
Maybe it is a stupid idea but... why not use Reactive Extensions? public class Buffer { private readonly Subject&lt;string&gt; buffer = new Subject&lt;string&gt;(); private readonly object padlock = new object(); private readonly StringBuilder _buffer = new StringBuilder(); public IObservable&lt;string&gt; Buffer =&gt; buffer.AsObservable(); public void Write(string s) { lock(padlock) { _buffer.Append(s); buffer.OnNext(_buffer.ToString()); } } } Now, you can subscribe to changes in the second thread: var someBuffer = new Buffer(); // ... // ... someBuffer.Buffer.Subscribe(text =&gt; { /* here you can do what you cant with text */ }); // or use some operators: someBuffer.Buffer .Where(text =&gt; !string.IsNullOrEmpty(text)) .Select(text =&gt; $"The text is: {text}") .Subscribe(text =&gt; WriteLine(text)); Sorry if it is not helping at all.
Lots of fantastic info in this thread - saving this one!
Yes, it's much easier to reason about multi-threaded code (or any scenario really) when you limit the scope of interest. Hiding the object(s) being locked inside a single class is proper use of encapsulation. Having multiple other classes lock on a shared object is poor design and just asking for trouble.