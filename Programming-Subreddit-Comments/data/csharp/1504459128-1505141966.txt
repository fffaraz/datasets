This is what I usually use. You can be very expressive with xpath, but there's a minor learning curve. I like xpath because I can do very simple single/multiselect queries, and if needed, I can select specific nodes, only if they have a child node or attribute with a specific value. And SelectSingleNode will return null if nothing is found, or throw an exception if multiple nodes are found with that xpath query.
&gt; I'm scared that a class other than SelectManager will call a Selectable's Select method. This still confuses the shit out of me, honestly. But if Selectable.Select() can only be safely called from SelectManager, *then it should be implemented in SelectManager*. A delegate is the least-code way, here. Another way in addition to the ways I mentioned before... SelectManager passes *itself* in to the Select method. interface ISelectRecorder { void RecordSelection(ISelectedItem item); } class SelectManager : ISelectRecorder ... public void RecordSelection(ISelectedItem item) { this.SelectedItems.Add(item); } class Selectable : ISelectable { public void Select(ISelectRecorder recorder = null) { var item = this.DoSelect(); if (recorder != null) { recorder.RecordSelection(item); } }
If you were to create such an object to hold all "person" properties, you might want to override the ToString method instead of using your initial method. That way, the logic of how to convert a person into a string will always follow said object (and should the person object change, you won't have to go to another class to change the formatting logic)
&gt; Wouldn't they need to inherit from each other? Classes defined in the scope of another class are different than inheritance. &gt; Wouldn't I need SelectManager to do custom things with Selectable-private things? No. You just have the "private thing" be a parameter in the signature to the delegate. public void Select(Action&lt;Item&gt; recordSelection) { var item = this.PrivateDoSelection(); recordSelection?.(item); } &gt; For example, I need to invoke the events from Selectable when it's selected. I can only do this if I tell Selectable it's selected. I do this via the public method Select that's inside Selectable, but I'd only want this to be viewable by certain classes like SelectManager. This is all bass-ackwards, and that's your core problem. Try and rethink the problem in turns of message passing.
Thank you very much for your answer. Really informative. Do you have any recommendations in terms of books on C# itself, ASP NET, general programming? 
My question would be, what class is this static method a member of? It's likely that *that* class is doing too much. I woukd make a class that had all those properties and override the ToString() method of that class. Each of the 'objects' you're passing as parameters here should also be classes that override ToString(). Once you done this you can simply call thing.ToString(). The cool thing is that the class will automatically be converted to string appropriately. 
it will do soonish. [here's the roadmap for Xamarin.Forms](https://forums.xamarin.com/discussion/85747/xamarin-forms-feature-roadmap).
Avalonia
&gt; Right, but that doesn't let access to private methods from the class that it's nested in, right? It does. Give it a try. https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/nested-types &gt; How is it backwards? Right now, SelectManager informs a Selectable it's selected. If this is not correct, how else should you do it? If "informing" Selectable it's selected is destructive/unsafe, then you're doing something wrong. Are you rolling your own DataBinding or something?
&gt; To reply to your example, doesn't that couple the classes together? I'd argue that if an interface's method must only be called from one class that tight-coupling makes intend much clearer than keeping it abstract but enforcing the same rules as with tight-coupling. Interface doesn't look like a good choice for what you want.
&gt; To reply to your example, doesn't that couple the classes together? I would assume Selectable shouldn't know about the manager at all. In the case of delegates, it wouldn't have to know about SelectManager. Any class calling Select(Action&lt;Item&gt;) could pass in its own delegate, and Selectable trusts it to do the right thing when the delegate is called. &gt; The biggest problem with this is invoking the events in Selectable. WHY!?!?!? Why is the act of being selected destructive to the point where nobody else can call it? Why is Selectable firing events when selected, rather than some sort of Visitor saying, "oh, look, this appears to be IsSelected = true, therefore I'll render it differently"? Events are things that can happen at any time, asynchronously. Never use events for things that depend on prior state manipulations (other than the constructor).
&gt; I think my problem goes away. Well, it'll solve the immediate roadblock you have, but I still say there's a larger problem with your overall design if you need this at all.
On Linux, your options for GUI is limited mostly due to X11/Wayland dilemma in the first place. So you have few options that are cross-platform: 1. Create SDL2 Application and render using OpenGL/Skia (offers the most flexibility) 2. Learn P/Invoke and create [QT5](https://www.qt.io/) or [wxWidgets](https://www.wxwidgets.org/) GUI in C++ and have that program bootstrap C# CLR like Mono or CoreCLR for most of your logic by passing C# delegate as function pointers to C++. [Embedding mono](http://www.mono-project.com/docs/advanced/embedding/) 3. Use GTK by either using existing binding or creating your own binding library. Updated: As throwawaysomething94 mentioned, Avalonia is basically using GTK for windowing context and used their own mode of render on that window. You could give it a try if you like.
asm blocks are the purest of code blocks - diamonds in the rough. I squee when I find one.
&gt; Isn't this how most UI frameworks work? You mean those horrendously complex things that have thousands of man-hours behind them to get them to work right? They need that complexity, but it's an assload of complexity, and none of them have the requirement "things gonna go to shit if called from the wrong class".
So a couple of things to note: 1. Avoid using the .Wait() and .Result() methods whenever you are using async/await. This can cause deadlocks. Even using Task.Wait() or Task.WaitAll() or .GetAwaiter().GetResult() can all produce deadlocks. I would avoid them whenever possible. That makes it tricky for invoking an async method from the constructor. I have seen the factory pattern work well in these scenarios. 2. The way you currently have it set up, it really would never be "parallel". If you want true parallelism, you could use something like a Parallel.ForEach() method. Otherwise, what you likely want to do is concurrent calls. The reason you're not achieving the concurrent calls is because you're synchronously calling your async tasks. Meaning you are awaiting each task's completion before calling the next client.Get() method. What you really want to do is more like: static async Task RunAsync() { MyNamespaceClient client = new MyNamespaceClient(); List&lt;string&gt; urlList = new List&lt;string&gt;() { //urls }; var tasks = urlList.Select(x =&gt; client.Get(x).ContinueWith(n =&gt; Debug.WriteLine($"{x} - {n.Result?.Length ?? 0}"))); await Task.WhenAll(tasks); } 3. Depending on the type of HttpClient you are using, some have the ability to automatically follow redirects. For instance, Windows.Web.HttpClient can do this: readonly HttpClient client = new HttpClient(new HttpBaseProtocolFilter() { AllowAutoRedirect = true }); 
&gt; Something that is selectable would be assumed to have Selected and Deselected events, no? I don't see how that's disagreeable. Because events are asynchronous (logically, anyways) and you don't want to deal with asynchronous stuff unless you have to. The very fact that you're running into this "only safe to fire this event from this class" stuff should be evidence that Events are the wrong solution to your problem. If you have a public event, then *firing it should not be "disagreeable"* in the first place. You're thinking "Events are things that let you DoStuff after Thing happens". But you're overlooking the far simpler solution that *the next line of code* also lets you "DoStuff after Thing happens".
I don't think so. With C#, your best bet is Windows Forms through Mono, however it's the oldest official C# GUI framework so it is dated. Perhaps the successor to UWP will be cross-platform, but I think your short-term choices are limited. You could make an MVC site with an installer, and make the UI with HTML/CSS/JS, which posts to local controllers. I haven't tried it myself, and it may not fit everything you want, but some software e.g. CouchPotato does something like that. The only other thing I'd look into is Qt, but that is for C++. Radeon Settings came out really nice though: https://www.qt.io/case-amd/ It's quite expensive for a lone developer (thousands of $ per year). 
Or there is the option that everyone loves to hate: Electron.
Unity3D has a half decent UI system that can be ported to just about any platform.
its a little tool i started working on a few years and i now consider feature complete. do not expect well documented or unit tested code. posting this here to hear suggestions, criticism, improvements and other thoughts about it. (please submit issues etc on bitbuckt so i can keep track of it)
https://github.com/picoe/Eto I've used this one with success
Keep fieldlist and table name as parameters to prevent injection attacks. 
[JustA.ML](https://justa.ml) - Open source web app to be able to share text/code snippets, long URL or small files to other devices when I'm unable to install an app to the destination device or do not want to login to my email account and pushbullet is not an option! Tech stack: ASP.NET Core 2, SingnalR and LiteDb. Use cases: to send a long URL to my SmartTV browser or quickly send a small file to my friends laptop from my phone. Contributions are most welcome in [GitHub](https://github.com/mustakimali/JustA.ML)
I've been working with XML for 18 years. Learn the Linq way - it's reusable. 
Try GetKey instead of GetKeyDown GetKeyDown ownly triggers in the frame where you pressed the button, which probably doesn't happen in the same frame as your OnTriggerEnter. (Alternatively Make it a OnTriggerStay) 
I’m familiar with Linq, but mostly using it with Entity Framework, never with XML. But the learning curve will be small since I’ve used it before - good to know that it works well with XML.
Removed: Rule 4. Stating that it "doesn't work" isn't sufficient. Explain what you're trying to do, and what it's currently doing erroneously. Also remove irrelevant portions of your code (e.g., your empty `Update` method).
it worked, thx
I found and used 'HackHands' in the end guys. Was quite good!! Though you should all know. cheers
Removed: Spam.
Make stuff. Theory is valuable, but my greatest knowledge comes from practice.especially failure.
What exactly is the problem this tool was created to solve? I mean, Steam automatically downloads updates on its own and you can see its progress by just opening the Steam window or hovering over the tray icon, so I'm having trouble seeing why you'd need an external tool to watch it.
It's so you can do something after all downloads are finished, like shut down your computer or something.
Read up on the Value Object pattern.
I suspect your machine is trying to auto detect an http proxy. Make sure you don't have that box ticked in Internet Options-&gt;Connection
A web browser is cross platform :P
Let me put it this way: if you're working with Linq for XML and getting frustrated, rest assured that using the native XML assemblies are no easier. 
The last time I looked at avalonia the documentation was pretty sparse. Has that changed?
With ~60mb of overhead? Seems wasteful for a simple application. 
Have a look at signalr, I think it will suit your needs. Even works for non web apps
I know I'll probably be down voted into oblivion.... But JavaFX is another alternative. If Kotlin seems a more pleasant experience, try TornadoFX. Sadly, there's not much choice in C#... 
I've seen some examples somewhere before, I think. It sounds really cool in theory, but the JavaScript side seems a bit scary...
I just started as a c# junior, Mosh Hamedani has a great udemy course for learning asp.net and others on c#. Obviously wait til udemy does them cheap, don't pay the full price. Alongside that, practice makes perfect and showing people that you're keen to learn!
Huh, I see. You were right, it's actually really neat. Thanks a lot!
HTML. I'm not even kidding. Why the hell would anyone create a non-HTML GUI these days? Even for mobile, check out Ionic or other HTML-based UIs. Oh - you're writing a GAME? Fair enough.
Correct answer.
&gt; This tool will observe the Steam downloads and detect and execute an action, you can select, when all downloads are finished. from the readme
I understand the question perfectly. For others who may be confused, pretend instead the Selectable class had a property 'IsSelected'. Selectable has a need to store this info, but relies on another class, the 'Manager', to correctly populate this info. So now we add a public method, 'SetIsSelected' for the manager to call. Op's problem is this: he does not want any other class but the manager to ever call this method on the 'Selectable' class. His suggestion is an explicit interface to try and hide it from other callers. My answer: explicit interface is just an illusion, the design is no more secure than a public method. I would keep both classes in the same assembly, mark the method internal, and rely on convention rather than design to avoid others calling the method.
Sure thing :)
Constructive criticism: document and unit test code before considering something "feature complete." These are critical portions of open source projects. As it stands I have to compile your code fully on the trust that it does what you say it does, and handles errors sanely.
In C# internal is what should be used instead of C++'s friend. internal allows access to classes from the same assembly but the same assembly has the same author so you should be OK. If you need the manager class in another assembly .NET has the concept of a friend assembly.
Type safe method: https://dotnetfiddle.net/s33oPm To generate classes from an xml you can use Visual Studio special paste (something like that) or http://xmltocsharp.azurewebsites.net/
&gt;Why the hell would anyone create a non-HTML GUI these days? Because HTML isn't the end all, be all. You are now at the mercy of a third party to make sure their application (the browser) will not fuck up your properly coded application or reinterpret a spec to mean something else. I can't count how many times I have had to redo 300+ crystal reports because of how many times the chromium dev team has changed the way they read/print pdfs..
If there is only one SelectManager in this thread, you could get away with making SelectManager stateful, and have .Select check that the manager is in the correct state? Make the correct way to call the Select() method, is by passing it through the SelectManager. SelectManager.selecting(yourSelectable) Would then set the state before and after invoking yourSelectable, and if any other class attempted to select in the meantime throw an exception? If it needs to be re-entrant, you would possibly want to replace the statefullness with a stack of some kind. Otherwise if you just need support for multiple classes, maybe a map or a list would do? If you need to run additional code, .selecting could accept a lambda instead?
It is still pretty sparse when checking their documentation links in github. [The Avalonia Project](https://github.com/AvaloniaUI/Avalonia) [Tutorial directory](https://github.com/AvaloniaUI/Avalonia/tree/master/docs/tutorial) [Avalonia Architecture](https://github.com/AvaloniaUI/Avalonia/blob/master/docs/spec/architecture.md) [Blog Posts which was last updated in May](https://grokys.github.io/) It seems documentation is ranked very low on their priority list.
.... even with documentation and unit testing you're still having to trust that it does what he says it does. Geez, give the guy a break.
Just use Electron. Make a working build, and that's how you control chrome and its release schedule.
No thank you.. Electron is absolute shit imho if you are looking to develop anything that you want to have decent performance not to mention the fact its a resource hog. 
That's true, but every chrome/chromium app takes a lot of resources so.... But Electron is still really good because it's cross platform and there's no "it might render differently on a different platform"
WebSockets are 100% worth looking into. The .NET wrapper around WebSockets is known as SignalR. The benefit of SignalR over just WebSockets is that SignalR will use WebSockets if it's available, and fall back to other techniques if WebSockets aren't working in the browser/whatever combination you're using.
Ah I see what you are saying. At least in my situation, it was an access LoB application that our higher ups wanted converted to a web application. Our organization uses Chrome for their web browser which was the premise of what I was speaking about. Unfortunately, for us that type of solution isn't really available. I am not sure if it is just me, but, I absolutely hate how everyone is trying to move everything and anything to HTML/Javascript/CSS. It is like they are trying to cram a square peg in a round hole. On top of that I think that Javascript is a shit language to make as the "gold standard".. It is frustrating to say the least. But complaining doesn't really put money in my pocket so follow the trends I must I guess..
I 100% agree that JavaScript can be a pain sometimes, and it looks very ugly when u bring promises, lambdas and async into it. But there are so many things made for it that are so helpful and good, things like node, Electron, react... Anyways, Electron is good when you don't really have to worry too much about performances and that you want cross platform desktop apps. Otherwise, there are a lot of things u could use.
QTSharp works pretty well on Windows (I've made a couple simple programs so far). They are working to get it compiled with Mono for Linux support. https://github.com/ddobrev/QtSharp
Yeah I have a suggestion. Add documentation and unit tests 
Either you asked someone who has no contact with technical interviews or you should really reconsider the company. If their idea of junior developer is so undefined, there is the chance they will have so high expectations that what they really want is standard programmer or senior with junior salary. I do hope you have some alternatives because this kind of environment is very poor experience for someone who just starting.
&gt; I have seen the factory pattern work well in these scenarios. Can you elaborate on this?
There's about 4 of us that work on Avalonia in our free time. We know documentation is an issue, but because of time constraints documentation is a little lower priority as of now. We're really helpful in our gitter chatroom though.
I like that. It’s a little bit over-engineered for this situation (this is part of a lab on test driven development, so having this much XML-related code would detract from the TDD too much), but I’m definitely bookmarking this to study and store away for future reference.
What are the differences between the free and full versions? I didn't see a page anywhere that articulated the differences.
No. Only at end-of-input. 
No, that’s not possible. Edit: thanks for the downvote for precisely answering OPs question: "I'm wondering if there is a way to just run the command on the same process as the rest of the project." ;)
Under the assumption that the indexes don't matter and that number of occurrences doesn't matter ((3,2,1) with (1,2,3) = 3 overlaps and (1,1,1,2,3) with (3,2,1) also = 3 overlaps): HashSet&lt;int&gt; overlaps = new HashSet&lt;int&gt;(); foreach (int n1 in arrayOne) { foreach (int n2 in arrayTwo) { if (n1 == n2 &amp;&amp; !overlaps.Contains(n1)) { overlaps.Add(n1); } } } Console.WriteLine("The number of overlapping numbers are: " + overlaps.Count); Once again please note that there are probably much better ways of doing this. NINJA EDIT: formatting.
Hi there! You should create a .NET Standard class library with means it will be accessible from any .NET implementation (such as .NET Framework, .NET Core and Xamarin). Note that targeting the lowest version of .NET Standard as this will give your class library the greatest reach. Also make sure you use XML comments to document all your types and members. And if you want to expose your lib publicly, publish it as a Nuget package. Hope this helps
Add a `.Distinct()` call to your arrays in the two `foreach` loops. 
O-o I learned something new, didn't know about `.Distinct()`
That's a great idea, reminds me of my favorite psrts of NancyFx!
.... No, with proper documentation and well covered unit tests I could examine the code, it's intent, it's function, it's expected return, and its actual returns. I could do all of this before actually using the entire software by simply running the unit tests and looking at the code in any editor before using the full software itself where I'd have little to no insight into anything happening in the background. Also, I don't feel like I was unfair with my statement to the point where I'd have to "give the guy a break." He asked for criticism and stated to not expect either of those things in a project he's sharing in an open source manner on a place that is about learning programming. I didn't bash him, his idea, or his code.
This reminds me that I wanted to give Nuke.Build a try :-)
If you also want to go from O(N*M) to O(NlogN + MlogM) you should firstly sort both arrays and then when counting occurrences you could just an if statement to skip repeated numbers.
There's also [Typescript](https://stackoverflow.com/a/12694578/1277156) which is a much better option for mid to large scale projects. Imo HTML and CSS are probably one of the fastest and richest ways to create a UI right now. Especially because of frameworks like Bootstrap. You trade a bit of performance for flexibility. Edit: Added link to informative Stackoverflow post about Typescript
Anyone tested both? Haven't heard of Nuke.Build before, but looks nice on a quick glance.
The difference between the free and paid versions is [listed here.](http://moonstarsky.com/learn/free-vs-professional-license/)
Great! Awesome answer, just what I was seeking to find. Thanks so much my friend, if I had money I would gift you gold! 
 var intersect = arrayOne.Intersect(arrayTwo).ToList(); intersect.Count &lt;--- 
I'm using Cake at the moment but I'm not super happy with it, so I wanted to give Nuke a try
Host on github and be open minded to issues/pull requests. A general advice i can give is, you should mimic the feel of a native microsoft lib, don't force your users to learn new paradigms.
Look at your loop and the value of *i* during the string format. Good luck with your homework.
+1
No, I mean Yes, I mean- aaaaaaarrrrgh! *Catapults into abyss*
I would love to, but it so far looks like that can't be done. But if you know a way to do it, please let me know.
No it looks like you are quite correct.
Awesome, I just clicked, I have created another variable and it is working fine now, thanks a lot! :)
It's funny how you should post about cake on your cake day. Guessing that was a coincidence.
For WinForms, yes! First you create the MenuStrip for the "main" menu. Lets say it contains MenuItems: "File" and "Entry". Instead of adding toolStripMenuItems to Menu-&gt;Entry you want add a ContextMenuStrip and call it something like contextMenuStripEntry, this is what you want to show when you click Entry in the menu or in your ListBox. You do this by selecting Entry in the menu and set the property *DropDown* to contextMenuStripEntry. Just like you would set ListBox.ContextMenuStrip to show the menu. You can then use the ContextMenuStrip to design the menu for both.
Would you please care to explain why would you prefer this over the standart way of creating controllers/action?
you are totally right that this is something i should really do and my only and bad excuse is that i do that at work enough and just wanted to make that tool without the boring stuff that comes with it and share it with people that are searching for such a tool. i open sourced it just because why not. makes the user not have to fully trust what i say it does but he can see for himself if he wants well it is good practice so i will start adding it over time.
Missed the part about table name, sorry. int numRecords = 10; string table = "DevTaskTable"; command = new SqlCommand($"SELECT TOP {numRecords} @fieldListStr FROM {table}", conn); command.Parameters.Add("@fieldListStr", SqlDbType.Text).Value = "TaskId,Name"; 
Wow, that's actually pretty clever! I'll try this as soon as I get home, thanks :)
Its ok :-) But then what is the point of even using parameters in this case, i mean you already have an injection problem with the numrecords, and table variable, so it there really a point to using parameters for the fieldlist?
Well numrecords is an int so no worries there. You can either sanitize the table name manually or use an enum.tostring()
The cake is a lie. 
No problem, I believe this is the intended way as it will also show up in the main menu while in designmode. And I was also doing some testing with: ~~contextMenuStrip.Items.AddRange(editToolStripMenuItem.Items);~~. But, this doesnt work because somewhere in the code it will assign contextMenuStrip as the parent to the items and disappear from the main menu, whereas I expected the items to just be added as objects in a list and be kept in both menus.
SignalR
What token?
TL;DR: There isn't one (except for a piece of metadata telling compilers that it's actually 'out').
It reads weird, but basically out parameters are ref parameters where you don't need to assign it before using it as an out. The need to assign variables before use is a C# thing, not CLR*. *) Actually, it is in the CLR as well for the code to be verifiable, but this is done when the function is entered, where all local variables are cleared unless otherwise specified in the function flags.
I don't like while true, so for multithreaded apps I usually use a CancellationTokenSource so that I can gracefully exit all running threads/tasks.
Well, the original idea was "let's always have an object available that we can lock", so they made this design where you can lock all objects. Then, if you used an array to do something, and it needed to be synchronized, you could just lock the array. The problem is that it's not clear who "owns" the object. For instance, it's been popular to lock(this). Now, if someone also has the idea to lock that instance from the outside, they'll inadvertently use the same lock. Instead one should, then, create an object specifically for locking. But then we wouldn't need that big elaborate "you can lock every object" feature, because we'll end up creating specific objects to lock. Instead we could just use Monitor instances that would represent locks (whereas now Monitor is a static class).
I think it's an interesting way to make the whole execution flow a lot more centralized (and terse). Consider this: app.UseFluentActions(actions =&gt; { actions .RouteGet("/users/{userId}") .UsingService&lt;IUserService&gt;() .UsingRouteParameter&lt;int&gt;("userId") .To((userService, userId) =&gt; userService.GetUserById(userId)) .ToView("~/Views/Users/DisplayUser.cshtml") }); It's a mouthful :) But the fact that everything from routing to view selection is declared in one place makes it easy to get the full picture without mental context switching.
Nuke looks sweet, but it seems very young. Is it really ready? I started using cake at work a few months ago, I wonder if Nuke is already a viable alternative.
I've just implemented your idea, works like a charm. Now it seems obvious :) Cheers!
Hi:) I'm the author of Nuke, so here are a few thoughts regarding your question. Yes it is young, but there are two major factors which make this much less important. 1) It is build with IDE integration in mind. You'll get syntax-highlighting, auto-completion, refactoring, navigation and debugging in _every_ IDE and most importantly _without_ installing plugins or reading howtos. The basic idea of Nuke is to use a console application for building. Everyone knows how to handle a simple C# project, right? :) 2) Like any other tool, Nuke needs to integrate a lot of 3rd party CLI tools (like MSBuild, dotnet, OpenCover, etc.). However - at least AFAIK - Nuke is the first build system that utilizes code-generation for building this infrastructure. Code-generation allows much faster development, makes unit-tests obsolete, ensures a consistent API and reduces bugs/typos. Besides that, there are even more features the Cake team isn't even working on (yet). For instance, Nuke provides a comprehensive setup script, an [extensible command-line](http://www.nuke.build/command-line.html) and plotting of the dependency graph (soon to be released). If you have further questions, just ask either here or on gitter/github :)
Yeah.
Yep, I recall reading about it some time ago. Currently I'm experimenting with hosting the server with an ASP.NET application on IIS and using the `Microsoft.ASPNET.SignalR.Client` client library with UWP. It's extremely easy to set up and work with, all things considered. I like it. Thanks for the recommendation!
Where is the code for pressing B? Edit: Saw the typo.
Oh sorry i meant R
Another variable? You can just do Write("text",i+1)
What exactly is not working? I think your previous thread got removed for just saying "it's not working". Is there any more information you can give us?
Like i said when i press R it doesnt work aka it doesnt do anything and btw the previos threat didnt get removed i hid it beacuz someone found the error
Sorry, I can't see any immediate problems, try breaking it down, for example remove checking if money&gt;= 1 and see if it works with only pressing R, or vice versa just to be sure the if-statement is triggering at all.
I removed money &gt;= 1 and it worked until i pressed the kill a pig button and then i added the money &gt;= 1 and it worked (i added +1 money in the start) but when i pressed the kill a pig button it did not
Nvm i fixed it, thx for all the help
Did you mean to add an `if` to line 13? Right now you're assigning the value `0` to `num[i]` - and in the next line you check the value of `num[i]` which is **always** `0` (because you just assigned it).
if (nums[i] != nums[nums.Length - 1]) { nums[i] = 0; }
You're setting nums[i] to 0 so the next statement comes in true and sets the next element to 0
Our build system is built on Fake, but the guy who built it off and left as soon as he got his new title (worth a sperate pay in itself). Curious why your not impressed with Cake as I was thinking about setting over…?
does it integrate with visual studio? or will i have to alt-tab to a terminal every time i want to run my code?
In case programmatic build scripts are appealing but you want to play with a prettier, more dsl-y language (F#), take a look at https://github.com/fsharp/FAKE 
You can start a loop at zero and add +1 before displaying, or you can start the loop at 1 and use a -1 for the array index. If you use a 0 index as a default value, then your 1 index can mean first sensor without an off by one issue. Below is a better solution using a foreach loop [microsoft - foreach](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/foreach-in) count i = 0; foreach( Sensor s in sensorArray) { count++; Console.WriteLine("{0}: {1}", count, s); }
That sounds amazing, thanks! For me this comes a little late. We needed a new build system for netstandard based things, so we went with cake. Several other groups have adopted this now, so we're at a point where I'll need some strong reason to go and replace it with something else. May I ask why you decided to do this from scratch instead of joining with the cake team? They seem friendly and open to suggestions/contributions, and the basic idea behind both systems seems similar enough.
We used FAKE for a while for building our main API, but have recently switched to CAKE. The reason for this was to be closer to the language used in our API. Although, we do use F# for integration tests, and do like that.
The `CanExecute` method informs the MVVM if the method can be executed. If it returns `true`, it can be executed. If returns `false`, then it can't be executed (and as a result buttons could be disables, as an example). It's up to the implementer.
There was an attempt :) If you look at their repository, you'll find a lot of issues created by me about general design issues and opportunities for improvement. They've been largely ignored/unnoticed unfortunately. I would claim that I have a lot of experience in build systems in general. Initially I liked Cake very much, but I reached the limits and found serious issues rather quickly. From a purely personal and technical point of view I must say, that Cake doesn't reflect the idea of a framework and build system as good as it should. Plus it contains a lot of anti-patterns. I could give plenty of examples if you want, but maybe that's enough of my opinion already?! :)
Whatever you return from the CanExecute method will decide if the command can be executed. Controls (e.g. buttons) that use a command will check this method and set IsEnabled accordingly. Check out the documentation for the [ICommand interface](https://msdn.microsoft.com/en-us/library/system.windows.input.icommand\(v=vs.110\).aspx) and the [CanExecute method](https://msdn.microsoft.com/en-us/library/system.windows.input.icommand.canexecute\(v=vs.110\).aspx).
does that even work? Cause VS2017 on windows doesn't even do coverage for xunit (VS2017 professional)
Don't have access to Enterprise only professional
At that point the code is already pushed. When writing new code on other non-windows machines it would be nice to know coverage before pushing.
I know that ews API is not capable of changing size of the users mailbox, the dll I'm not sure.
It's not that I'm not impressed, I built our own build system around msbuild for my company so I was really happy when Cake came around :-) I'm coming from the JVM world where I really like gradle as a build system, which seems a bit easier for me. But the difference there is that for example the Java project layout has pretty much a standard, which means that you can just include a plugin. Also the dependencies you define with nuget is out of the build tool, which makes it feel segmented in a way. (I think that the dotnet core way of referencing packages in csproj is a huge step forward). When I started with Cake I had a lot of errors which included a lot of fiddling to get around, that's where I love the idea of Nuke to have IDE integration with code completion etc.
I think you're confused by the parameter, but it's probably just an ICommand method's implementation. The interface says the implementing class must have a CanExecute method which signature must have an object parameter, so you're forced to put it. But here it's actually not used, and the method simply says that the corresponding command can be executed at all times.
Was this written by a ten years old?
Yes, it is that, I saw I command used in that tutorial, but in the docs https://msdn.microsoft.com/en-us/library/system.windows.input.icommand(v=vs.110).aspx can execute is defined as a method... if you put "{}" next to a method it generally means that you are defining a method, array, etc. is this an exception?
I don't really understand your question; I'll try to clarify. CanExecute is a method defined in ICommand. public interface ICommand { // stuff... // In an interface, you don't implement stuff, you only define it bool CanExecute(object parameter); // and that's it; adding {} means implementing // more stuff... } ICommand is an interface; it's meant to be inherited by a class. public class ChangeCommand : ICommand The inheriting class must implement everything defined in ICommand, with the same signatures. public class ChangeCommand : ICommand { // implementing stuff... // implementing CanExecute public bool CanExecute(object parameter) { return true; } // implementing more stuff... } If there's something unclear, feel free to ask.
Don't create another variable; just use `i + 1` in the `string.Format` call.
By convention, he should start the for loop at 0 if the intention is to iterate over the elements of an array or collection. Starting at 1 would break the convention and any decent code reviewer would require him/her to fix it.
I haven't used Nuke but I can't wait to try it out because it looks great.
Great to hear :) Please don't hesitate to ask your questions on [Gitter](https://gitter.im/nuke-build/nuke) or [Twitter](https://twitter.com/nukebuildnet).
There's a Cake plugin that adds tasks from your build.cake script to the Visual Studio tasks window. From there you can double click on a task to run or debug it. If you want more control you can also run the cake script from the package manager console inside vs. That wouldn't technically require an alt-tab. 
Multipart form data.
Did you use this for for your own for once? Did it work?
&gt;or you can start the loop at 1 and use a -1 for the array index. This is a tremendously bad idea, especially as a plausible suggestion to implement.
Thanks for the heads up guys sorry for my English :( I have made changes to it. 
Start a new project with the [Class Library template](https://imgur.com/a/oaUAZ), you can choose .Net Core or Standard. Obviously you won't be able to run this project, but add the functions you want and build it to make sure everything is good. Assuming you're moving functions out of existing projects you'll need to add a reference to the new library to those projects in order to access them. I went through a massive reorganizations for a large winform project and ended up with a number of libraries: * [Prefix].Library.Common (has no dependencies on Winform system libs) * [Prefix].Library.Win.Controls * [Prefix].Library.Win.Forms * [Prefix].Library.Win.Office etc... So I ended up with a solution containing 8 projects. I have all of the projects target [Prefix].Library.Bin when they build, that way they're all in one place, and then when I add a reference to other projects I target the [Prefix].Library.Bin folder. 
It's definitely recommended to make it .NET Standard as opposed to Core because .NET Standard can be used on .NET Framework 4.6.1 and newer as well.
Check out the dictionary class
 switch (tolower(value)) { case "alabama": case "al": Console.WriteLine(2.14) case "kansas": case "ks" Console.WriteLine(5.14) default: break; }
Use a switch statement instead of a bunch of ||. They don't take multiple conditions but you can stack the cases for the same effect. Then you can ToLower the test string so you don't have to compare more than 2 cases
Switch statements can use multiple cases if you want to go that route. You might consider doing something along the lines of letting your user pick from a list of known values which might be a better experience so you won't have to account for spelling errors.
I would suggest a state enum based on full name, then load a dictionary with the kvp k being the state, v being the cost. Then input you tryparse the input and fall through to a abbreviation map
Easiest would be to restrict user input to the two letter abbreviation, or have your user interface translate the full name before going to your logic. Use a dictionary to map the abbreviated states with their avg fuel price. You should not need an if or switch anywhere for this, that would get pretty ugly.
&gt; I was thinking switch statement with cases but they don't take multiple conditions. They do, actually. You stack the conditions. var state = userInput.ToLowerInvariant(); switch (state) { case "al": case "alabama": case "'bama": return 2.14d; ... } However, this is still the wrong way to do it in the long run because you are hard-coding values that will change over time. i.e. constants that are not constant. You'll want something like Dictionary&lt;string, decimal&gt; gasLookup = ReadAndParseDataFile(); string stateKey = NormalizeStateName(userInput); return gasLookup[stateKey]; Where "NormalizeStateName" does the ToLowerInvariant() and has the switch statement to return "al" for all forms of "Alabama" and such. 
Use a combobox instead of, presumably, a textbox. You can define the possible inputs and avoid this problem altogether. 
I would have an extra dictionary[string, string] that holds lower-case versions of all alternate versions of states as the keys and the states they're alternate forms of as the values, then populate it. You can check to see if AltForms["al"] != null and if it isn't, return the value for the string returned by that instead of the one entered. It feels like the obvious answer and I feel like I'm missing something, sorry if I am. https://pastebin.com/RMW8F9sD Incidentally, "I was thinking switch statement with cases but they don't take multiple conditions." - You can use goto case (case) in place of a break statement to jump to another case in a switch statement.
On top of this I would define a readonly string[] populated with the abbreviations. That way they are defined only once, and used to populate comboboxes and dictionaries etc. Unless you can retrieve these from an external source, in which case you would never have to type any abbreviations in code.
Sorry, I didn't (and don't) downvote, but you're right, I should have elaborated. It's a poor idea because it's confusing, unreadable, non-standard, likely to introduce bugs and the goldren rule: there's a simpler way of expressing it.
Do you have a link or reference for this convention?
The loop `for (int i = 0; i &lt; myArray.Length; i++)` is more idiomatic in that it expresses a characteristic of the language itself (i.e the fact that arrays are zero-indexed). Every implementation of a collection C# (that I know of) continues this expression. If C# started its indexes at 1, the *implicit* convention would be `for (int i = 1; i &lt;= myArray.Length; i++)`. Starting an array at anything other than 0 *when the intention is to iterate over the entire array* is unfamiliar and does not express the characteristics of C# collections accurately. Not sure why you want to argue against this?
Combine this and the: value.ToLower() when you do your key lookup.
Learn about objects. Also, based on what little you've said, learn about databases.
It has to take a parameter in order to match the interface it's inheriting the method definition from, even if it's not used in this particular command.
this is a wrapper for ffmpeg that is maintained by microsoft themselves, ive used it before and it's really easy: https://github.com/Microsoft/FFmpegInterop
Thanks, but I don't think there is much hope of using that on OSX or Linux, or .net core. But hey thanks again
Google has a geolocation API where you can query anything, city, landmark, street name, etc. And it returns you coordinates. This could help you possibly.
Doesn't visual studio have a terminal?
What is the use case for this?
Use a dictionary as others have posted, and initialize it with StringComparer.OrdinalIgnoreCase. This will require less normalization.
+1 for this. Much better UX that way.
Sorry, I'm still a jr/mid level myself. What's the difference between your first and second code blocks? It seems like all you did was move it into a method. Edit: nvm I understand now that the key difference is in using the dictionary, which helps if you need to update values. 
And mostly, you're reading the data from a file, that can be updated without having to recompile and/or redistribute your program.
As a decent first step for c# in general, I would get familiar with string methods. Strings are used for so many things and having good knowledge of these will help in a lot of ways. For your program specifically, the toUpper() and toLower() methods could really come in handy.
I took a closer look, some loose notes: - I like the use of properties instead of string identifiers for Targets, but in practice that probably won't make a difference most of the time. Still it's better design. - The OnlyWhen() and Requires() methods are phantastic! I've been doing if-constructs with return statements in cake to achieve that. This is much nicer. - Love the way you generate console help based on this information, listing targets, dependencies and required variables. - Nuke has better terminology. For example cake seems to mix up Target and Task. In the .cake file things are declared as Tasks, but from outside they are referenced as Target... - Cake reports durations with insane precision. It's a super trivial thing but it actually bugs me, so very glad to see you're reporting reasonable numbers :-) - Cake has great documentation and a growing ecosystem of third party addins/tools. I'm happy to find docfx tasks at the core of nuke, still I really like the way cake does it. - Does nuke have something like \#load in cake where you can load targets from another file? We have some .cake files with common/shared logic. I guess this could also be done as a real compiled extension, but for tiny stuff this is handy. - IDE integration seems to be working well for both, cake and nuke. They recently released vscode and vs addins for .cake files.
Because: If it goes to the first **else if** then the *if(hasMainSponsors &amp;&amp; hasRegularSponsors)* returns false. Which means at least one of the two variable must be false. Making the not of the variable true. The First **else if** begins with *hasMainSponsors* which if true, then the second part(*!hasRegularSponsors*) of the statement is also true, because if it wasn't it would have entered the first if. Now on the Second **else if**, !hasMainSponsors is always true because the code did not enter the first else if(meaning *hasMainSponsors* is false) so *!hasMainSponsors* is always true. I hope my explanation is understandable enough :) All in all. For the thing you want to do this expresion is enough: // Do some stuff based on what kind of sponsors we have. if (hasMainSponsors &amp;&amp; hasRegularSponsors) { // Do stuff if we have both main and regular sponsors. } else if (hasMainSponsors) { // Do stuff if we only have main sponsors. } else if (hasRegularSponsors) { // Do stuff if we only have regular sponsors. } else { // Do stuff if we don't have any sponsors. }
You should look at this one also, I think he has some good videos for perhaps next step right after beginner. And he also has started a good series about how to make a program start to end. https://www.youtube.com/channel/UC-ptWR16ITQyYOglXyQmpzw 
I might be overthinking it, but ReSharper might consider them simply unnecessary. If you have both regular and main sponsors then the first **if** is true. Else, if **hasMainSponsors** is true, then **!hasRegularSponsors** would have to be false (or the first **if** would be true) and vice versa. And because you don't have **else if** that is true when there are neither main nor regular sponsors, the check for the absense of the other type of sponsors is unnecessary. Hope that made sense.
Thanks. That makes perfect sense now that you mention it. :)
You could also switch out the for loop with a foreach. foreach (var entry in log.Entries) { if (entry.InstanceId == 2147484722) { lastShutdownLog = entry; break; } } ...
Yes. I needed to a write a custom model formatter in webapi. In .net core it is even easier.
Have you seen auth0? It sounds like what your looking for without much effort
The iterator on the log entries starts from the oldest entry to the newest, and I'm pretty sure the iteration is lazily executed; it's very slow. If you have a lot of entries (like I do, hundreds of thousands) then it takes a _very, very_ long time. Also, if you want to get the latest shutdown reason, you have to iterate until you find the _last_ one. The code as you have it will get the oldest shutdown entry; useless for OP. Hence my use of a standard `for` loop running in reverse. Gets the latest shutdown reason and operates very fast.
The real key difference is using data from the file to get the values. This makes it so that if you ever need to update any of the states or prices, you just have to update the file instead of updating the code and rebuilding the code. When you're doing a small program like this, rebuilding the code isn't a big deal. But what if this was some piece of software that is in the hands of millions of people? Are you going to create a new version of your program (and force them to update since you rebuilt the code), just because you updated a price one cent?
Removed: Rule 3.
FWIW, while resharper is correct in its optimization suggestion, I think your original code is easier to follow. It's one of those times where if I was reading through the code, I'd have to build up the decision tree in my head at first to figure it out, but with your original code it's immediately obvious what the cases are.
Thanks! Great work as always.
Awesome!
Oops; Absolutely should be private 
Removed: Rule 6, spam.
I ran into this problem myself recently. Don't use `Write-Host` or `Write-Output` in your ps1. Try simply outputting what you want directly like this: $test = "Blah"; "This is a test -- $test" Ultimately, I ended up having to use Write-Progress and subscribe to the Progress stream to get all of the behaviors I wanted. I am a powershell novice, so someone who has had more experience with executing powershell scripts from C# might have a better answer. Play around with the streams and see if you can get it to work how you want.
Use branches and CI the branches, create a coverage rule that fails the build, so it can't be merged into main branches
there is no write-host in the above code. It just executes a exchange command. If i do that in a powershell console i get output just fine ? i am just running this command Get-MailboxStatistics user | ft DisplayName, TotalItemSize, ItemCount 
Removed: Spam.
Wow, I didn't know it and I'm glad you posted this update. Gotta use this in future projects.
https://github.com/nunit/docs/wiki/Parallelizable-Attribute
By ASP.NET form you mean ASP.NET Web Forms? If you do, you can try a GridView or a ListView depending on what you need to do with that data on your page.
Haha that's nice, I met this exact case while ago. It took me some time to understand why. Yeah ReSharper is pretty clever. 
Thanks for the kind words :) About the question on "how to extend tiny stuff": For that you can make the Build class a _partial class_ and include a csharp file from anywhere else that contains additional functionality / shadow-targets (i.e., targets that are only _maybe_ present). In order to depend on such a shadow target, you simply define the dependency as a string. For instance: Target Pack =&gt; _ =&gt; _ .DependsOn("Link") // instead of DependsOn(Link) If the target is not found at runtime, it is marked as _absent_ in the summary. However, you'll lose the help of the type-system, but I guess that's okay in this situation. As for some of the other things you've pointed out: * It is remarkable that Cake has grown such a big community. On the other hand, out-sourcing such a lot of addins is not a silver bullet. Many of them seem incomplete to me and don't follow a common code style. Having so many unknown sources should also be considered under security aspects (https://twitter.com/o_cee/status/892306836199800836). * Targets as properties are mostly helpful for better navigation (assume a Build class with hundreds of LOC) and for referencing them via auto-completion and type-safely * The extensions for VisualStudio and VSCode are actually very different in terms of provided features. I guess If I had to stick with Cake, I would only use it inside VSCode. It provides at least proper syntax-highlighting and auto-completion, afaik. * One of my personal favorites compared to Cake is that you can manage packages with your IDE instead of preprocessor directives. The Cake way didn't work for quite a long time unfortunately.
Build automation
This code has a lot of advanced things that will go right over the beginners head
Dunno if its just the color choices but android ui always has a childish feeling with it.
Omfg... this implementation has a complexity of O(n * m)! (Don't call it *solution* therefore!) Why? You allready had the idea of using a ``Set``! Just put both arrays in separate sets and then call the ``Intersect`` method! Then you have only O(n + m) - far better and **efficient**.
Awesome! I use your framework for our lab's internal automation software. It makes making nice looking apps easy!
I have been writing a book about learning C# by programming board games, particularly chess. I have intermediate programmers in mind, probably students who learned Java or Python first. The book is based on a course I teach at my hometown university. I don't expect it to sell particularly well, but it's been a fun experience and hopefully someone will appreciate a different approach to learning C#. The WIP self-published ebook is [here](https://leanpub.com/checkmate-csharp), and the source code to accompany the book's text and exercises is [here](https://github.com/nealterrell/checkmate-source). I'd be happy to comp a copy if someone is willing to casually read through my draft and give feedback.
So i have to annotate every [Test] with this attribute?
yeah, looks like good stuff, thank for sharing 
No. If you read the article and do some experimentation, you'll find that you can specify the attribute at the assembly, class, and method level, and different values of `ParallelScope` are valid at different levels. E. g. you can specify `[Parallelizable(ParallelScope.Self)]` on classes and methods, or `[Parallelizable(ParallelScope.Fixtures)]` at the assembly or class.
I love your work on this and MahApps. I Really appreciate all of your hard work.
Hey cool! I use this library in my software sampler project: https://github.com/padesso/SimpleSampler It's really great (even out of the box) compared to vanilla XAML.
Yes I need to learn how values change over time and keep them updated THANK YOU!
Will give this a go.
Okay, will learn dictionaries.
Indeed, will learn.
Yes, I barely know anything. Databases is on the list, and dictionaries.
Yes, I will now thanks to someone pointing out multiple cases.
Ah, I didn't think of that, yes they could! Since anyone can type in any cap letters.
This is true. I will do my best to analyze lol. And probably come back to it later.
Ah, I will read into it.
Will do, getting so many responses to check it out. Haven't gotten there yet. I need to.
Wow very cool, never typing in abbreviations sounds like what I need.
Because TIL that method exists. 
If I were you my first question would be: How often is my data going to change, and how do I want to go about changing it when I do? You can compile your states into the application, the chances that we're going to get a new state or lose one any time soon is pretty slim (although, watching the news lately, I wouldn't completely rule it out). Your gas prices are likely to change often, and you don't want to distribute a new executable every time they do right? This is something databases can help you with. Depending on how you're planning to distribute your program, a flat file, a web service, or just a plain old XML file sitting on a web server can help you with this instead (databases are hard to set up, and are likely not be worth the trouble if all you need is 50 floating point numbers). Something you'll learn quickly is that there is no set recipe for what you're doing, and no set recipe for 99% of programming tasks. Every little thing you do is a decision, and every decision comes with pros and cons. There is no "right way", but there are plenty of wrong ones. If I were approaching your problem, I'd make a "state" class with a unique identity property (byte - because there are fewer than 255 of them), a string for the name, and either a string or a char array with two entries for the state code (char is a single character, an array puts more than one together). I would have a separate datasource for your gas price data, that would let me pass in a state id and get a gas price back. Remember that if I type in "Al", I may be looking for Alabama (AL), or I may be on my way to typing Alaska. For simplicity's sake, initialize your states and put them in a list. Now, when a user types in characters, do a for loop through your list looking for names or abbreviations that .StartsWith (https://msdn.microsoft.com/en-us/library/baketfxw(v=vs.110).aspx) your input. Return the states that do. Using a switch statement will technically work, but this is an object oriented language, and using objects should be cleaner. The switch statement would execute faster, but your processor can do over a billion calculations a second; you shouldn't notice the difference.
(In addition to the other comment which is more friendly I guess...) This looks like a question for homework, I doubt performance matters that much, and this looks similar to OP's original code. I also gave a disclaimer (both before the answer and after) saying that it probably wasn't the best solution by far.
It's the opposite for me. I find the cleaned up code easier to follow. First branch triggers if both are true, second and third trigger if only one is true.
Changing and updating gas prices is what I need the most but Im still super noob so databases would help with this?
Will MemoryCache be threadsafe? I was reading 1.0 MemoryCache was not thread safe, and was hoping to not have to manage my own locks.
What sort of application is this? Is it a desktop or mobile application others will install, or a web application?
We do this exact same thing at work with EF. We generate from an existing database and we use the [EF Reverse POCO Generator](https://marketplace.visualstudio.com/items?itemName=SimonHughes.EntityFrameworkReversePOCOGenerator) There is Pluralsight and it listed on the referenced site. I use it in all of my projects that need database access. 
Link to [Plurasight course](https://app.pluralsight.com/library/courses/code-first-entity-framework-legacy-databases/table-of-contents) 
If you check the article again he said something concerning the question you are asking. If the method is just a pass through method, ellide the await keyword. I usually ellide it until I have the first function which will have to access the result and not hand through the Task to inject parameters. 
Right, I pointed that out in the initial post as well. I'm just curious if it makes THAT big of a difference. I get the vibe from some developers that it's this massive deal that a state machine has to be created and there's all this overhead. When in reality, sure, you should elide it in this case, but its not that big of a deal if you await all the way down.
If the method really is just a dumb pass-through method that could not possibly throw an exception itself, the only real difference is without `async` it won't appear in stacktraces of exceptions thrown further down the chain. But even if that's the case now, there's always a chance you or someone else comes back to the method later and adds something without thinking about it, and then things could start going wrong. Honestly, unless this method is being called millions of times and you're trying to squeeze out every last ns of performance, just go with `async` everywhere and don't worry about it.
That was my school of thought as well. Sure, it's better, but it's not that big of a deal either way.
Eh if you immediately await an async call even though you don't need the result immediately you lose out on a benefit of being able to continue computing things right up to where you need the value. 
Visual Studio 2017 Community Edition is a good place to start. 
Removed: Rule 4. Plenty of resources/tutorials available online for getting started. Grab Visual Studio Community 2017 from the sidebar. When you run the installer, it'll give you the option to include the various bits for ASP.NET development.
The state machine is a new class that's generated, and a simple state machine for a single await is something like 11 generated IL instructions (we also had this debate at work recently). Although there are cases where you can't elide the await (such as `using` statements that affect resources the returned task needs), if you can elide the await, I would. Async code is more inefficient than sync code and will always perform worse (even if just slightly). What we lose in singular execution speed we gain in the ability to interleave parallel requests. Adding more awaits all the way down multiplies the cost. You're adding overhead (rather than ignoring overhead that would normally exist) for no reason. It's like a developer who constantly calls `.ToList()` on LINQ expressions. Sure, it's not a huge amount of overhead, but why would you do it if you didn't have to?
Agreed, it's not something you should do, but I just don't believe it's this huge sin as some people seem to believe. I feel a lot of people get caught up in these micro-optimizations and readability suffers. Digressing a little, it's similar to calling .ToString() on a value type before sending it into string.Format. Sure, it prevents boxing/unboxing, but I'd rather not see the ToString()
Looks nice and easy to use! I'm on mobile so forgive me for asking, but is it possible to create a menu item with an object attached or is it currently only possible to send the menu item name as a string to the event handler?
I'm not a finance guy, so my head hurts when trying to compute your example where you prorate a list of names with the value 100. This makes about as much sense to me as the square root of a banana. Can you help a dummy understand where I might use this (and I realize I probably never will if I'm not developing financial software). Thanks!
Just curious, what are you reasons for using this over the standard "Code First from database" option? e.g. features missing from the standard option that you find useful.
It is .. Just dident hadd the time to documentt.. Will post a bit later on the how to ... 
Cool!
That's a much more apt comparison; thank you! It also happens to be something I do frequently, but I'm working on heavily-hit framework code where I know GC is a huge issue. I'd never do it in lighter-weight programs.
thank you both very much I appreciate your help I just got done downloading it but nothing is happening after that do I just wait for something to pop up???? 
Which case(s) are you referring to with ToList()?
Sure, I can give my most recent example: Suppose we have a university which needs to work out the cost of each semester for a course. Suppose we have a Course which costs $30,000. We have 4 Semesters in this course. The number of semesters changes per course. Suppose in our code we have a course object and a Semester object. The course object contains a list of semesters. Using this tool we can simply do this: var result = Course.Semesters.ProRate(30000) .Calculate(); With 4 semesters we will have 7500 assigned to each semester. This is accessible as: result.Result[Semester1_object] result.Result[Semester2_object] .. Now suppose we have another requirement where the worth of each semester is based off the number of units in that semester. This would be a weighted pro rata where the number of units divided by the total units in the course would make the semester cost. var result= Course.Semesters.ProRate(30000) .Weight(s=&gt; s.Units.Count() / Course.total_units_count) .Calculate(); I'll add this to the README to clarify things if it makes sense 
It was an inferior example, but I've seen cases where a developer calls `.ToList()` after a LINQ expression and then uses the list to iterate over in one foreach loop. There are cases where you absolutely need to force a LINQ expression to be evaluated and turned into a list, but that's not one of them. They're just so used to working with lists that they just use boilerplate code without understanding why.
How does this work? How to import it your Xamarin Forms project?
Unless you're in a try/catch- or using-block.
I didn't write the article, but that's a good point and I sure hope you're right!
Whilst "code" may be your only issue, it's where all of your work is. It sounds like you're not familiar with the C# language. You need to learn the basics. I recommend kudvenkat on youtube. He has a very good c# series: https://www.youtube.com/playlist?list=PLAC325451207E3105 You'll need to know about events in addition to the C# basics, as GUI-applications are event-driven. I suspect you will also want to learn about basic image manipulations, and re-draw the image based on events fired when you interact with the UI. Looks like this is relevant, but I haven't read it all: https://www.codeproject.com/Articles/165382/Zooming-and-panning-in-Windows-Forms-with-fixed-fo 
Good catch. I think that trick is under used.
Wait I do this all the time, I thought you needed to turn the LINQ expression to a list before iterating over it to prevent the evaluation of the expression every iteration.
This is only necessary if you plan on iterating over the enumerable multiple times (worst case scenario: if you wanted to have two foreach loops going over the same enumerable after one another).
Nice, love this. Too bad it doesn't support UWP development. 
LINQ?
Thanks for the resources. You're right, I am indeed not familiar with C# at all. That withstanding, I still have, after a few painful hours, put together a working application that does what I need it to do, except I have two big problems: I can pan the image and zoom in and out just fine, but I need to learn how to 'lock' the image to the corners of the view frame, so that way when I pan an image too far, I am met with the image being held at the edges, and it doesn't get pulled off track and expose the panel of the form window behind the PictureBox. I am also having this same type of trouble with zooming. Right now, I am able to zoom all the way out to the point that the image is a tiny dot. I would prefer the image to get zoomed all the way out until the image is completely resized to fit the current window size only. Can you maybe shed a little light on how you'd go about that?
WPF dude
Gotta agree here. This may change in the future, and I really hope it does, but at the moment, apart from a Web UI, your only options in C# are very WIP. TornadoFX is a really, really great framework. JavaFX comes with its own set of problems (Not as popular as WPF is / was, the CSS styling is kinda weird), but all in all, it's a good option for cross-platform UIs, if you don't mind the JVM. Kotlin will also feel very familar when you're using C#.
Why precisely can't you use a second thread? What will time out? If it's a problem of execution flow you can use something like TaskCompletionSource or SemaphoreSlim to ensure your first thread doesn't carry on until your second thread has some results.
I understand the reasoning of ReSharper but IMO the original code is more readable and the intention is clearer.
I don’t know whether it is a good idea, but anyhow, a more data driven approach: // using BoolTuple = System.Tuple&lt;bool, bool&gt;; var actions = new Dictionary&lt;BoolTuple, Action&gt; { { new BoolTuple(true, true), () =&gt; { /* Do stuff if we have both main and regular sponsors. */ } }, { new BoolTuple(true, false), () =&gt; { /* Do stuff if we only have main sponsors. */ } }, { new BoolTuple(false, true), () =&gt; { /* Do stuff if we only have regular sponsors. */ } }, { new BoolTuple(false, false), () =&gt; { throw new Exception("No sponsor available."); } }, }; actions[new BoolTuple(hasMainSponsors, hasRegularSponsors)](); 
delete from tablename where Id = IdOfObject
It sounds like the issue is that serialport.ReadLine() is a blocking method. You probably do not need any extra threads. here's how i would do it... When an agent computer receives an SNMP request, it creates a "job" and sticks it into a queue. In your main loop (or second thread if you choose): If you are not currently doing a job, pop one out of the queue, send the serial data and restart a stopwatch. If there is a current job... Check if SerialPort.BytesToRead is greater than zero and if it is then read the data. Do not use ReadLine() as it can block your thread, instead, use SerialPort.Read() and just read however many bytes the serial port says it has. This will not block and you can then look at the data and process it. If you have all of the data you expect, the current job is completed and you can respond appropriately via SNMP. If SerialPort.BytesToRead is zero, look at the stopwatch and see if you should give up. If you give up, respond via SNMP and clear the current job. 
Our biggest thing was the configuration of the tool. We wanted to pick and choose what tables, views and stored procedures we wanted. Also our DBA changes things constantly and this made it a lot easier to generate. We also have this nightmare scenario where we generate against a MSSQL database but we use a SQLite DB to store the data, and we were able to customize the TT files to generate something SQLite would understand. 
Never seen it done like that before. Learn something every day :)
The difference in performance is negligible but I see no reason not to do it. It makes the code shorter and the if I read the code I will stop and wonder why pass-through methods await the results.
Besically right now if you want a custom object you have to inherit from ConsoleMenuItem&lt;T&gt; .. See in github how consoleMenuItem is implemented.. In retrospective i have a better design for that .. But will take a some time before i have the chance to upload a new version so any pull requests will be appriciated .. :)
Posts msdn source Uses Java foreach syntax
Yes, that would be helpful. This is cool. Thanks! edit: Or, simply add "Results" for the examples on your page. Seeing the results of the pro rata "where the number 100 is pro rated evenly across a collection of strings" would probably be an "ooooohh" moment for people, including myself.
Not a good solution! The complexity would stay at O(n * m)! Better would be to create a ``HashSet`` from the first array and *then* call the ``Distinct()``-method with the second array. This would reduce the complexity to O(n + m).
This was extraordinarily helpful thank you so much. 
If you followed the link, then when panning you just need to alter the code to not move within X pixels of the border, where X is the width of the picture box. Do the same for the height. For zooming, it looks like there's a "zoom" variable that initially has the picture width fit to the box. Either don't go above or below this initial value, whichever is the correct way.
 We actually just had this conversation! https://www.reddit.com/r/csharp/comments/6vswx6/net_core_orm_recommendations_please
Entity Framework Core 2.0 works good depending on your work flow. People also seem to like Dapper if you want something more lightweight.
Ugh, I meant to post this question in the /r/dotnet. (A lot of people are subscribed to one but not the other.) Thanks.
Yirks :(
I am 99.9% sure that the == operator on strings checks the length first on both, and if they're not equal it returns false early so it doesn't have to check all the characters in each string if it doesn't have to. Change your strComp array to this and you'll see the string test takes twice as long. private static string[] strComp = { "com.PeculiarHabit.FooTestR", "com.PeculiarHabit.TooTestR", "com.PeculiarHabit.FoDTestR", "com.deculiarHabit.FooTestR", "com.PeculiarHabit.FooTestv", "com.PeculiarHaPit.FooTestR", "com.PeculiarHabit.FooTesti", "com.PeculiarHabit.FooTestM", "com.PeculiarHabit.FooTescv", "com.PeculiarHabit.FooTessR", "com.PeculiarHabit.FooTesaR", "com.PeculiarHabitsFooTestR", "com.PeculiarHabit.FooTestq", "com.PeculiarHabit.FooTestw", "com.PeculiarHabit.FooTest5", "com.PeculiarHabit.FooTest7", "com.PeculiarHabit.FooTest8", "com.PeculiarHabit.FooTest0", "com.PeculiarHabit.FooTest-", "com.PeculiarHabit.FooTest=", "com.PeculiarHabit.FooTest+", "com.PeculiarHabit.FooTest`", "com.PeculiarHabit.FooTestZ", "com.PeculiarHabit.FooTestX" }; 
You should use BenchmarkDotNet for such tests.
:D Yeah, I did an edit already that came to the same conclusion. The speed difference is there now, but not as dramatic as I would've expected. It's still less than half a tick to do the comparison.
Seems a bit like overkill, no?
No?
Not at all. Your code looks very fragile and overkill.
Please explain? I'm just trying to do a simple, straightforward test. Not trying to optimize a project.
You have no warmup phase, you don't take the median, you possibly even run in debug mode, with the debugger attached or without optimizations. BenchmarkDotNet is trivial. Write your test methods, run the benchmark and done. It checks everything, measures correctly and is a safe bet.
FYI, in general you don't want to do .ToLower(), you want to do .ToUpper(CultureInfo.InvariantCulture). I know this doesn't seem like it would make a big difference but it can. There are letters that don't convert correctly when using .ToLower() in other languages but apparently they always work when doing .ToUpper(CultureInfo.InvariantCulture). [It's Microsoft's recommendation](https://msdn.microsoft.com/en-us/library/bb386042.aspx) and even if you aren't doing much international code it's still something to be aware of and to get used to. edit: Apparently there are new recommendations for .NET 2.0 for string comparisons. [Here is the link](https://msdn.microsoft.com/en-us/library/ms973919.aspx). I'm about to read it as well... 
That's a lot of assumptions. The warmup phase is there, it's why I do multiple test runs, and ignore the first. The median isn't necessary because I can just eyeball it. Again, this is just a very simple test. You assume (incorrectly) that I'm running in Debug mode without optimizations. BenchmarkDotNet may be "trivial" if you already have it installed, but this test is far, far more "trivial" when I don't.
Took me a second to realize all of the strings are the same length there. Derp.
You should always try to avoid any code apart from the thing you're trying to benchmark in your benchmark method. Your integer method is probably spending 99% of its time on the `Random.Next` call rather than the actual integer comparison you're trying to benchmark.
The performance in a contrived example is not always an indication of the performance in a real-world example. In this case, you have no multi-threading contention, no threadpool use, and no race conditions. In a threadpool-starvation scenario, which often only happens under max load, the behavior changes. DoStuffFirst(); var result = await DoTask(); // the state machine is supposed to resume here // However, if you are thread-starved, you have no // idea when it will actually resume! It could take 30+ seconds. return result; async/await is a mix of threadless async with things like Native I/O and threadpool tasks (e.g. anything started with Task.Run()). **If you're not actually doing anything async or awaiting anything async, don't mark the method async**. There's a compiler warning for that for a reason. 
Yeah, but prior to adding the Random.Next, I found that the compiler was optimizing the integer array comparisons unfairly, causing a very skewed result. Open for suggestions if you have another way to prevent that.
What kind of unfair optimization would that be? Easiest alternative would be to replace it with `i % intComp.Length`. Even then the integer comparison would still be small part of the overall cost of the method.
&gt; What kind of unfair optimization would that be? Not sure. I'd have to guess that the compiler is somehow recognizing that the pattern would always have the same outcome, so doesn't bother running through the loop on subsequent runs. It was returning impossibly fast values for both. 
&gt; For predefined value types, the equality operator (==) returns true if the values of its operands are equal, false otherwise. For reference types other than string, == returns true if its two operands refer to the same object. For the string type, == compares the values of the strings. Microsoft has supposedly optimized the hell out of strings, according to https://coding.abel.nu/2014/09/net-and-equals/ They are basically reference types thst behave as value types. &gt; The string type is an exception pointed out in the documentation. It is a reference type stored on the heap, but everything possible has been done to make it behave like a value type. It is immutable. ==compares the contents of the strings. .Equals will throw an exception if either of the strings are null, by the way. Something to consider.
Yeah, and ~~.Equals~~ == seems considerably slower than ~~==~~ .Equals. I mean, all of them are in the nano-second range, but still, fun for comparison. Seems that string comparisons are so fast now as to make taking that into consideration fairly pointless. Times have changed. *Edit: Got 'em flipped.*
Looks great - bookmarked/starred.
Much better than I expected. Looks like they finally fixed the damn materializer.
I wonder if the Entity Framework query was done in SQL rather than linq, like the Dapper query, how the performance would differ.
Good summary! Wish I could have had this few days ago. I was trying to gather this same information from GitHub - [Discussion for Auth 2.0 Issue](https://github.com/aspnet/Security/issues/1338) and from Microsoft.AspNetCore.Authentication.JwtBearer's [source code](https://github.com/aspnet/Security/tree/5b29bced0d2f1cfc78843bcd9ec9a828c6fb5fef/src/Microsoft.AspNetCore.Authentication.JwtBearer). Have to still verify that I got things mostly correct in my own app's [modifications](https://github.com/ttu/dotnet-fake-json-server/commit/32a74e4c651cfa2fab7441c119d4af6fb49c6b99#diff-27ab86fd4c56158f0c9cce8dbc53ab09), but at least it is working now. Hope this is the last .NET Core upgrade with bigger breaking changes :D 
Removed: Rule 3, Rule 4. This question as-is is too vague and missing potentially relevant details, including but not limited to: database technology, frequency of requests, size of requests. This is also likely not relevant to C# but the technology stack as a whole. This can also mean the database structure but the database technology itself. At very minimum, you could look into a REST based service. Hit a URL, and some ASP.NET (or even lighter weight service) tosses back the text data relevant for the report to be generated on the client. That said, it sounds like the C#-based front end for the service here could be irrelevant for the processing overhead, especially if you just need a service to perform basic database I/O. If you have concerns about throughput, then there's a good chance the bottleneck will be on the database or network load, not on the C# ASP.NET service. But I still can't say for certain because the question is too vague on details and numbers.
It might be faster but it's just not as nice to write
&gt; just go with async everywhere and don't worry about it. No. It's a compiler warning to have an async method with no awaits for a reason. Likewise, you should pass-through the Task&lt;T&gt; when you can rather than awaiting. Timing a contrived example doesn't tell you how the system will behave under load or when there is threading contention, *which is the whole point of doing async*. It may seem counter-intuitive, but multi-threading (and async/await) does not always improve performance in a multi-threading scenario. Awaiting something unnecessarily can have serious performance ramifications in complex multi-threading scenarios and should not be done with "voodoo programming." In general, you are better off not pretending something synchronous is asynchronous if you want a better chance of avoiding Weird Multithreading Shit (actual technical term (not really (but everyone will know what you mean, so it might as well be))).
I wonder how many products were returned. I also wonder how it compares to two selects in an sp vs including a many to many relationship
It depends, what is the lowest version you can target without needing to do heavy modifications? The lower you can target, the more projects that can implement your package. There are still enterprise solutions using net 4.0/4.5 which would make your package unavailable to them if you targeted .net standard 2.0.
~~Go with the latest .NET Standard that you can use in your ecosystem.~~ Edit: A .NET Standard can target any version **or later** so it actually makes sense to start with the earliest/minimal version of the API that you need and then just increase the .NET Standard version if you need more.
Could the "Order By" in the EF version that doesn't appear in the Dapper SQL String be to blame?
Whenever it wants, basically. The OS can suspend threads mid-execution, and resume them on any logical or physical processor (unless a processor affinity has been specified). You should not interfere with the management of thread pool threads, chances are you'll do more harm than good. If you need a dedicated long running thread, start your own with `new Thread()`.
You should not care what processor or core your application runs on. If you do, then there is an issue with your application. The jumping between cores happens frequently during a context switch. This level of detail is an entire course in CS. Most likely there should be a handle or callback that notifies you when the work is complete.
Additionally, retargeting a nuget package that currently supports 1.x as a package that targets 2.0 is a breaking change for all downstream packages and projects. If something like NewtonSoft.Json suddenly targeted only 2.0 a bunch of people would suffer.
The "order by" clause does indeed affect performance. Our DBA recommends that unless we really need to do it on the server we should order in the client.
Can't you prepare both versions somehow? Honestly though if performance of any individual query which wasn't changing state mattered, it should probably be cached and the cache results be returned instead of running it in the first place.
Removed: Rule 6, spam. Not your fault jogai-san. ServiceStack.net is on notice since one of their employees/owners/associates spammed it.
Take all the parameters and put them in an `IPersonParameters` interface. This looks like a constructor- but it's not- and your method smells: what is a void method named Person doing exactly? It's obviously not a constructor nor returning anything.
NReco wrapper is paid or you have to send them e-mail for demo access. You can use this nuget package its on MIT license: https://www.nuget.org/packages/Xabe.FFMpeg I'm trying to make easy to use FFmpeg library. You can find more information about this at https://github.com/tomaszzmuda/Xabe.FFmpeg
Older versions of EF could spent more time generating the SQL to be sent to the database than the database spent fetching the data. p.s. I don't know if that it still the case.
It looks to me like the EF query is also returning the full category entity. .Include(p =&gt; p.ProductCategory) Doesn't seem like they are comparing the same things.
I wouldn't stop releasing pre-2.0, but I if I were starting something new, I would not be willing to spend time or effort supporting lower than 2.0. 
I'm coming back to [FF1Randomizer](http://github.com/Entroper/FF1Randomizer) after a long hiatus caused by moving house. Recently I've just been doing a lot of cleanup and organization. Moved most of the code to a library targeting .NET Standard. The main app is WPF targeting .NET Framework (obviously), and there's now a console version for .NET Core 2.0. The next project is to have a web version on ASP.NET Core 2.0. Then back to new feature development.
Damn, I forgot about RoslynPad. I have a LINQPad license, but my colleagues could use a quick C# tool with Intellisense. Implementing an integrated debugger must be very hard. Pretty good stuff nonetheless!
Why? The database should be able to order it much more efficiently than your app server code can.
Not sure yet. I think it's more of a calculator type of thing, where users select a state, which populates the average cost for that state, then I have a function that calculates cost per mile depending on their MPG. I envision a mobile app? What route would you go?
No, the "select *" and the "inner join" with ProductCategory create a projection that include ProductCategory in the same property.
That's my goal! You have given me some hope that I can get into c# game dev in Unity without university! How long would you say this took you, and what kind of portfolio should I create?
The linq expressions to sql should be memoized, so time penalty on first run only.
Database is going to maintain a read lock until after it returns the results in order to read the most up to date version. This requires resources on the db longer than not doing the "order by" would which means fewer overall resources available to handle other queries in the same time period.
That is probably the case but if the ordering was taking significant processing time due to volume of queries then it would certainly be easier to have multiple instances of your app server running behind a load balancer and letting them do the ordering. I'd agree with you though that the db is usually the best place to do this. If you find performance bottlenecks then by all means try to ease the burden on the db by moving work out to the app severs.
Me. As I still need to support Windows 10 Mobile, and for now it's stuck on .NET 1.x (idk if 2.0 will ever work there).
My apologise for the pathetic formatting - Damn you Copy and Paste!
If the database has an index, that's true. If you don't have a relevant index, the database is going to do the same work your application would. But it's an expensive machine, possibly with expensive licenses. Your web server boxes are probably a fraction of the cost and can scale out easily.
Also I'm not so sure how I should store the cards, being that you have the string value, the integer value and the suit...
I am self taught, but I did not use any books. If you want to try digital, check out Udemy. Tons of geat courses for free - $10
Not entirely sure what your current design is and how you're trying to use it seeing as (as you point out) the code isn't valid as you have it. The `ACE = 24` is weird for me. What is 24? What does that have to do with aces? Regardless of all that, try creating classes to house this information and enumerations for the individual components only. For example: public enum Suit { Hearts, Diamonds, Clubs, Spades, } public enum FaceValue { Ace, Two, ... King, } public class Card { public FaceValue Value { get; } public Suit Suit { get; } public Card(FaceValue value, Suit suit) { this.Value = value; this.Suit = suit; } } Then your hand can simply be a `List&lt;Card&gt;`, or alternatively, you can create a full blown `Hand` class that wraps a collection of cards.
It's the first time I've written a ~~compiler extension~~ Roslyn analyzer, so any feedback is appreciated.
What do you mean? Invoking a method and passing its return value into another method invocation just as any other expression? Unless there's something weird going on that isn't described by this, then no, on the face of it I wouldn't consider this a code smell. It's a bit reminiscent of functional programming, but only on a very high level. I would say if the code as-is is readable and understandable for you and your team, and makes sense in its context, then it's fine. If you feel that it would benefit with some additional clarity, you could do this: var someMeaningfulName = someOtherFunction(parameter); var something = someFunction(someMeaningfulName); Otherwise, in C#, it's not uncommon to call methods in argument expressions. Ultimately it's just the result of an expression that you're feeding in anyway. I don't think there's any hard and fast rule on this being a smell. If it were, then it would probably introduce other smells/issues because the alternatives could be worse.
Nice, I'll take a look tomorrow! :) Thanks mate!
There's some important information left out of this performance comparison. - Dapper isn't using an parameterized query, which no one would do in production code. SQL Injection. - Dapper isn't ordering the query on the database server It would also useful to express the actual SQL that was run by EFCore. None-the-less the results are interesting, I wonder how both perform on more complicated queries?
even if I use new Thread() the OS can decide to switch core during its execution. I would like to know what the instructions that allow the OS to do such a switch are. Thanks for the reply. Edit: My question makes sense only if my assumption is right. My assumption is that if I start a function that does a while loop on another thread taking the whole processor power (never sleeping), the OS will never have the chance to change the core execution. My assumption is that only Sleep and possibly other instructions allow core switching. I'd like to know what these instructions are. If my assumptions are wrong, please clarify what really happens.
It's not a code smell, but it can make debugging more difficult when you write it that way.
thanks, can context switches happen any time during the execution of a thread or they depends on specific instructions?
Yes, exactly like your example. Inner function is a transformation, basically rounding. I suggested using a private function inside the class that's being called. Others said that would not be testable. So instead they want to apply rounding via a passed public function.
Ah ok thanks. Probably overkill in our situation then, ours is MSSQL only with developers driving most of the DB changes to suit applications so the built-in stuff covers our usage well enough. Your setup sounds like fun!
Your assumption is wrong, modern operating systems use what's called "preemptive multitasking" and can suspend your threads whenever they choose, no matter what you are currently doing. Once upon a time (in the pre-Windows 9x era), OSs did indeed use "cooperative multitasking" where the process had to voluntarily give up control back to the OS, but that's not how it works anymore.
Wouldn't the app keep the session open and the lock actually be held longer if the app is slower to order? It's been my experience in most webapps that the connection in open on request start and closed at the end to ensure a single transaction for the duration to help with consistent results.
It's not a code smell. It does make debugging slightly harder by not letting you set a breakpoint in between the two calls, but you can do that either at the return statement of the inner function or the first statement of the outer function. On the other hand, it's really tedious to introduce a variable every time you need to call a function. Note that this is *not* the same as the 'train wreck' code smell, where an object knows too much about the internals of another object: instanceA.MethodB().MethodC().Property1;
Sorry, but that's a MS-DOS level assumption. Your thread will be suspended whenever there's an I/O operation of some kind, or it's allowed run time is up, or several other reasons. This is because the OS figures that anything going to disk or network will take an eternity compared to accessing main memory, so why not pause that thread and go service some other thread that is ready to run? When the I/O completes or it's opportunity to run comes around again, the scheduler will then cause it to run on any core that's available. There are complex rules around this too - like whether the memory the thread needs to access is local to the core or is on a different core (which is slightly slower - see NUMA). You might be interested in this book which is the story of how Windows NT was created, Microsoft's first preemptive scheduling operating system. [0] https://www.amazon.com/Showstopper-Breakneck-Windows-Generation-Microsoft-ebook/dp/B00J5X5E9U [0] I'm not counting OS/2 since that only sort-of preemptively multitasked. I'm not counting Xenix either, since it was licensed from AT&amp;T and not written by MSFT. Edit: Changed some stuff. 
This depends on the operating system, but for Windows, this is how it works. Each thread is given a time slice of the CPU's time. Windows will send high priority threads first to the first available core, and then when there are no high priority threads it will send the next priority, and so on until the last priority is reached. This can be set in C#, but this is something ultimately decided upon by the operating system (why? you might end up in a situation where none of the lower priority threads get CPU time, because there are too many higher priority threads). You can read Microsoft's documentation on this here: https://docs.microsoft.com/en-us/dotnet/standard/threading/scheduling-threads In other words, there are no "instructions" that will cause a thread to stop executing. Once it's allocated time is up, Windows takes it out, puts it at the end of the line, and puts in another thread that's waiting. Once that thread gets to the start of the line, Windows will pick a core. You can set the core that you want it to go on with a processor affinity (or set an ideal affinity), but you have to realize that you have control over how busy a CPU core is. Microsoft does not recommend doing this unless you are testing, &gt; Setting an affinity mask for a process or thread can result in threads receiving less processor time, as the system is restricted from running the threads on certain processors. In most cases, it is better to let the system select an available processor. You can read more here: https://msdn.microsoft.com/en-us/library/ms686247(VS.85).aspx As well as, &gt; Setting thread affinity should generally be avoided, because it can interfere with the scheduler's ability to schedule threads effectively across processors. This can decrease the performance gains produced by parallel processing. An appropriate use of thread affinity is testing each processor. You can read more here: https://msdn.microsoft.com/en-us/library/windows/desktop/ms684251(v=vs.85).aspx This was written in 2009, but in comparing setting processor affinity vs the Windows scheduler, the Windows scheduler won basically every single time: https://www.codeproject.com/Articles/35679/Parallel-computing-and-processor-affinity-Never-un And the Windows scheduler has only gotten better in the last 8 years.
I wouldn't run a select on the same connection as a transaction unless the select had some sort of impact on the transaction. I'd actually be tempted to design the system in such a way that the select could run against a read only mirror of the database actually (after it fails to get the results from app cache and/or memcache; little reason for any select statement to take a db lock most of the time anyway). 
Fun fact: If you gave that $" string to EF Core 2, it would parameterize it for you.
&gt; Note that this is not the same as the 'train wreck' code smell, where an object knows too much about the internals of another object: instanceA.MethodB().MethodC().Property1; Which, in turn, is not to be confused with a "fluent" design pattern that is intended to be called that way. var burger = BuildBurger().ExtraPickles().NoMustard().Execute(); 
If it looks like LISP, it's a code smell. Otherwise, fine. Stylistically, I like to break it out into multiple lines and use named parameters for any such situation to make it clear. var something = someFunction( param1: getParam1(), abusiveMode: false, bugs: Bugginess.Off ); (pardon the indentation) 
Which DB provider are you using? For SQL Server you can use: "DELETE FROM YourTableName WHERE ID=" + variableWithIDValue If you are using SQL, I recommend to use parameters. 
Not as long as your functions have appropriately meaningful names.
I've written quite a few libraries at work now, all targeting some version of .NET Standard 1.x. While I'll agree that 1.0 wasn't terribly useful, I've flexed quite a bit of programming muscle in 1.5. There's no reason to go to 2.0 if your code works absolutely fine in 1.x. Now, if you need some functionality that's only available in 2.0, go for it. As much as I love to be on the bleeding edge at home, constantly updating everything at work just to use some cool new package because the developer decided to use the latest version isn't feasible.
Won't this work? &lt;DataGridTextColumn Header="Qty" Binding="{Binding XPath=Qty}" HorizontalAlignment="Left" /&gt; I haven't tried doing this while using a setter property on the overall columns but I'd assume it would work.
For those who may not be aware. The immediate window in Visual Studio helps dramatically with the debugging in this scenario.
+1 on making debugging difficult! I personally also find it more readable when separated into 2 calls. Especially when the function names are really really long and they start going passed the right side of the screen and you need to use your scroll bar to read them. See what I did there? :) Also there's the whole *use variable naming to convey the "what" and comments to convey the "why"* thing. Inception methods ^((yeah, that's a thing. Starting now. :P)^) might work if the inner method comes from a factory or a builder, eg UserFactory.GetUser() But sometimes what the method returns and what it does are different, eg: var userId = insertUser() In which case it would be tough to know what is being passed to the outer function without jumping to one of the two functions themselves. From that perspective I could kind of see why someone might consider it a code smell. It's as bad as doing this: var x = someOtherFunction(parameter); var something = someFunction(x); Whereas the following tells us so much more: Guid userID = someOtherFunction(parameter); var something = someFunction(userID); So if we consider using meaningless variable names as a code smell, inception methods kind of are as well... Now I wouldn't say that you should never use inception methods. However, if have them scattered all over your code, it could make your code harder to understand. I think that's the reason I avoid them myself. 
That is pretty cool, need to look into this.
&gt; Others said that would not be testable. So instead they want to apply rounding via a passed public function. Making your methods public just for the purposes of testing just sounds wrong to me. Either you have code coverage for the private method through your public method, or in your case, maybe the rounding logic doesn't belong in the same class and your class would be more cohesive if it used a class who's job it is to do the rounding, which in turn can be tested independantly.
Could you please elaborate? I didn't quite understand.
Put together an XML file to contain your prices. Put that XML file on a web server you have access to. Somewhere the URL will not change. Have your mobile app load and process that XML file on request to get your prices by state. You can load and process the whole thing, there is so little data that it shouldn't be a problem. That way you can change the prices whenever you like and the phone apps will update. You don't have enough data for a database to make sense for your needs. You should be safe to encode the states into your application. Give them all a number that matches the number you use for your state information in the XML file. It's a nice simple solution.
I've used hangfire in projects before and it's worked pretty well. I wasn't the person who set it up, but I don't remember it being anything complicated. You do need a persistent storage, though, iirc. Redis or SQL database works.
My guess is that your inner function is doing a transform from the type of parameter to the type for the function input. One thing that might make it better is to write an extension for the parameter type. Call the extension ToOtherType. Then you call becomes var thing = someFunction(parameter.toOtherType()); Transform functions are perfect as extensions. Just like ToString or Parse, extend your parameter type to own the transform. Same principle as a copy constructor or assignment operator. 
&gt; not to be confused with a "fluent" design pattern that is intended to be called that way. &gt; var burger = BuildBurger().ExtraPickles().NoMustard().Execute(); That's called the Builder Pattern IIRC.
It's both a builder and fluent. Non-fluent builder would be where each of those methods returns void and you have to call them on separate lines before Execute().
These benchmarks are quite misleading since due to using Azure SQL, the majority of the time is going to be spent in transport, not in EF or Dapper. It's a bit like having me race Usain Bolt over 100m, but we have to walk the first 90m side by side. So here's my results using the original code as a base, with the following changes. * Added the MemoryDiagnoser to the benchmark for curiosities sake * Added a cut down view model of the Product model and removed the joins in the query since EF was doing much more mapping than Dapper in the original. * Parameterized the dapper query instead of the string interpolation. * Moved the construction of the EF context outside of the benchmark so that we are only testing connection and querying. This is also important for the memory usage since constructing the model added about 20KB extra. I ran these both against a AdventureWorksLT database in SQL Express on the same machine as the tests. BenchmarkDotNet=v0.10.9, OS=Windows 10 Redstone 2 (10.0.15063) Processor=Intel Core i7-7700 CPU 3.60GHz (Kaby Lake), ProcessorCount=8 Frequency=3515630 Hz, Resolution=284.4440 ns, Timer=TSC .NET Core SDK=2.0.0 [Host] : .NET Core 2.0.0 (Framework 4.6.00001.0), 64bit RyuJIT DefaultJob : .NET Core 2.0.0 (Framework 4.6.00001.0), 64bit RyuJIT Method | Mean | Error | StdDev | Gen 0 | Allocated | ------------------------------- |---------:|---------:|---------:|-------:|----------:| GetProductsWithEntityFramework | 415.2 us | 4.522 us | 4.229 us | 7.8125 | 33.36 KB | GetProductsWithDapper | 216.1 us | 4.627 us | 4.328 us | 2.4414 | 10.2 KB | // * Legends * Mean : Arithmetic mean of all measurements Error : Half of 99.9% confidence interval StdDev : Standard deviation of all measurements Gen 0 : GC Generation 0 collects per 1k Operations Allocated : Allocated memory per single operation (managed only, inclusive, 1KB = 1024B) 1 us : 1 Microsecond (0.000001 sec) Things I found interesting. * Dapper was almost twice as fast as EF * Despite the simplified view model that had to be mapped, EF still consumed 3 times as much memory. My guess is that execution plan caching and the like are responsible. * Coming up with a fair test between Dapper and EF is hard. Mostly it's about making sure that Dapper is doing much the same thing as EF with as few side effects as possible. I could easily spend the rest of the day trying to level the playing field whilst increasing the complexity of the queries, but I'm not going to. 
Why not consult the [Reference Source](https://referencesource.microsoft.com/#mscorlib/system/string.cs,590)? (spoiler: yes, it checks string length after checking reference equality and nullity)
You keep saying that they're passing the function, which is making me confused. You know the actual inner function doesn't get passed through to the outer function, right? The inner function is evaluated and the result is passed to the outer function.
Thanks
Yes. The OS Kernel will typically set an interrupt timer on your CPU's PIC (Programmable Interrupt Controller), either at a fixed frequency (say, 1000Hz) or a variable one in the case of tickless kernels (Windows 8 and newer, Linux since 3.10) based on system load. Every time an interrupt fires off to the CPU it immediately saves necessary state of the CPU and hands control over to the interrupt handler (some code in the kernel) - at this point the kernel can decide it's time to start executing a new thread, so it saves the running state of the program counter and other CPU registers into a data structure associated with the thread, restores that same state for another and allows it to begin executing. It doesn't matter if your program is executing an ADD, a SYSCALL, a FMA instruction, whatever - that interrupt fires and your code is stopped immediately.
Your processor is probably handling thousands of software threads. It has to constantly switch between them to do what needs doing. Whichever logical processor is available will be used when the software thread is picked up. If you wanted to control this, you'd probably have to make your own OS.
Shouldn't you add .AsNotTracking() to the EF query to make it a fair comparison? In my experience tracking adds quite a bit of overhead and I have rarely had it enabled on a list of any kind.
This code makes me want to scream. You're making at least three passes over your data, before your logic even kicks in. There's no reason to segment the results based on a single Boolean filter like this. This case is simply splitting the work into two lists but still performs the work regardless. It's faster to iterate the results and do what ever logic is needed within a single iteration. If you absolutely have to segment the data, the use groupby instead. 
C# in a nutshell. (I generally like O'Reilly books.) For online courses I'm very partial to pluralsight. 
I had added .AsNotTracking() when I had the query still returning entities but I didn't think it was necessary once I switched to a projection and view model.
Do you find it to be worth the cost? How many hours do you watch per week?
I figure $29 a month is pretty cheap for such an enormous library of courses. I try to spend 10 hours a week on "homework" most of that is on pluralsight. If you haven't signed up before I think you can get a free 3 month trial when you download VS community or sign up for the ms developer network (I forget which, they're both free). I started with the trial and thought it was too valuable to give up. 
You can set breakpoints at various points on a line - you just need to use position the cursor and press f9 (or use the menu to insert breakpoint) rather than clicking the line gutter.
Hmm... it would be interesting to see if it makes a difference. I also have no doubt Dapper is faster under the test circumstances, but still not sure it proves much. It seems to me a better comparison for EF would be: var sql = "SELECT * From [SalesLT].[Product] INNER JOIN [SalesLT].[ProductCategory] ON [SalesLT].[ProductCategory].ProductCategoryId = [SalesLT].[Product].ProductCategoryId WHERE [SalesLT].[ProductCategory].ProductCategoryId ={categoryId}"; return context.Database.SqlQuery&lt;Product&gt;(sql).ToList(); 
I got curious about that too. In EF Core 2 you can do context.Product.FromSql() which should be roughly equivalent to conn.Query&lt;Product&gt;("SELECT * FROM Product ...") in Dapper. So hopefully the results should be about how quickly both mappers work. Method | Mean | Error | StdDev | Gen 0 | Allocated | ------------------------------- |---------:|---------:|---------:|-------:|----------:| GetProductsWithEntityFramework | 343.6 us | 4.109 us | 3.843 us | 4.8828 | 21.99 KB | GetProductsWithDapper | 233.2 us | 4.840 us | 7.094 us | 3.9063 | 16.37 KB | The difference in time and memory allocation is much closer now.
I'm in the same position and, as you've no doubt discovered, it's virtually impossible to find anything current enough to be useful because chances are the demo or tutorial became obsolete 4 months after release. But, I have found one course on Plurasight that I think is great. It's [Building a Web App with ASP.NET Core, MVC 6, EF Core, and Angular](https://app.pluralsight.com/library/courses/aspdotnetcore-efcore-bootstrap-angular-web-app/table-of-contents) by Shawn Wildermuth. **First the good:** It's incredibly dense with really useful material, he starts you with a empty project and takes you through every step to create a full .Net Core database web app. That includes html, css, javascript, jquery, bootstrap, MVC, Web API, Authentication and Angular. The project also makes use of a web service for mapping. There are so many good tips in it that I'm constantly thinking, damn that would have taken me months to discover on my own. (Awesome Fonts, Postman) Shawn is really a great teacher and also active in the forum comments for the course. (Which takes the patience of a saint) **The Bad:** The course was originally published in July 2016, so the original tools he used were VS2015, .Net Core 1.0. At the time I started the latest tools were VS2017, .Net Core 1.1, and of course that "broke" some of the tutorial, but to his credit Shawn has updated much of the course to use VS2017 and .Net Core 1.1. (Of course now .Net Core 2.0 is out and Shawn has said in the comments there will be a refresh of the course in the next month or two to incorporate .Net Core 2 and Angular 4.) I've gone through the course two times and I would highly recommend taking notes along the way. It's an incredible amount of content to absorb. (And I already know C# and Entity Framework well) For me it was great until I hit the Angular Routing chapter, (second from last) and then I just ran into to too many things that no longer worked and stopped. And honestly I'm not that interested in learning Angular because I think React/Redux is going to be better for what I want to do. But everything you learn up until then is really valuable. In going through it a second time I've used .Net Core 2.0 and the latest release of every library in the project. (Minus Angular, which I skipped). .Net Core 2 does have a few changes from 1.1 that will be disorienting if it's your first time using it, so if you do the tutorial I think I'd stick with 1.1 and the versions of all the libraries he's using to follow along. Once you're comfortable with 1.1 moving to 2.0 and the latest libraries for development will be much easier. That's probably more than you wanted to know, but I thought it was a great course and would be a good starting point for someone in your situation. 
How about the option / alternative of presenting a warning when detecting case statements with a `default: throw InvalidOperationException("coding error...")` where not all cases are covered `case`s? That's what I do to at least make it obvious at runtime there's an issue. Would be nice if the extension worked without having to specify it. My only concern with that is whether there'd be (m)any false-positives such that it should be opt-in rather than opt out (as you've currently designed it). The obvious choice there would be to have your extension include an exception that was like the `InvalidOperationException` at run time, but triggered the analysis too.
Interesting. Thanks.
I was under the impression that this is just an example...
I think you should stick to calling it a roslyn analyzer, calling it a "compiler extension" has a very specific meaning and implies its extending the language and compiler itself to introduce changes to C# itself.
No. It's just an expression like any other. Also, while I understood what you meant, it isn't correct to say "passing a function" because that implies the outer function will be calling/invoking the function, like a higher-order function from functional programming. That would involve using `delegate`, `Func&lt;T&gt;` or func via lambda syntax `x =&gt; `, `() =&gt;` etc. You will have used these when using LINQ.
thanks a lot! I start to understand now! I think I have to rephrase my question a this point: What I wanted to know is: can I be relatively sure that my ever running thread will always run on the best core available or in order to be sure that my functions do not run on an already clogged up core I have to restart them often? Basically I want to know if there is a real benefit in continue approaching running my short threads often or I can also start long running threads without worrying about them much. I don't want to choose which core my threads run on (hence thread affinity is not what I am looking for), I want to be sure that they run on the best core available. So my question is, in order to do so is it better to run often short threads or is it ok to run long threads too? 
you said the key word "when picked up". So it would imply that the best core available is chosen when a thread start, which would imply that running short threads is better to run long ones. My real question was about knowing if I should run short threads often or I can also run long ones without worrying too much about the core performance. I reformulated the question, I don't want to choose the core, is totally the opposite, but I want to be sure that my threads run on the best cores available.
cool thanks, so it can happen any time. I start to understand that switching context means that the core will focus on another thread (obviously a core runs many logical threads, so it must time split them), but I want to know if the OS can also decide to change the core where the already running thread was running on when it comes back to it.
I think 'code smell' is a 'phrase smell'. Does anyone else hate that term? 
There is a small overhead from creating a new software thread, so performance would be better if you re-use them. I believe this is what the thread pool does. Windows will decide which physical thread will pick up your software thread. If physical threads 0 and 1 are busy running an exclusive full screen game, then it's unlikely that they would be used to run some other task. Rather, Windows would give it to physical thread 3 or 4, e.t.c. 
so right now I use thread pools and therefore I run small threads often. This leads me to never use long running thread (started manually without thread pool), because I assume they are always worse. However I now want to know if this is a right assumption or I am worrying for nothing.
Hi Fizix Man, I had considered using Generic types and I think your approach is a lot more logic driven. In regards to "ACE = 24" I have assigned all the cards their numeric value, so a 2 of diamonds also has the numerical value of 2, 3 of hearts = 3 and so on. It is clear to me now that I have indeed made a mistake with this scheme as Ace ought to equal 13... whoops! Thank-you for the reply, I am going to try using the above ideas this evening :) Many thanks, Elliot
Maybe use a cognitive service? https://azure.microsoft.com/en-us/services/cognitive-services/speech/ It's cloud based. But it might be useful to you.
&gt; What I wanted to know is: can I be relatively sure that my ever running thread will always run on the best core available or in order to be sure that my functions do not run on an already clogged up core I have to restart them often? As far as I know, the Windows scheduler will try to distribute things evenly as best as it can. Windows Vista was already beating manually picking cores; I would imagine that Windows 10 (and even 8) are way better at this. &gt; Basically I want to know if there is a real benefit in continue approaching running my short threads often or I can also start long running threads without worrying about them much. Creating threads can be expensive, so generally you want to avoid creating them all the time. Having said that, use a [blocking event](https://docs.microsoft.com/en-us/dotnet/standard/threading/eventwaithandle) like [AutoResetEvent](https://msdn.microsoft.com/en-us/library/system.threading.autoresetevent.aspx) to pause a thread. You're worried about executing loops, right? Why not use [Parallel.For or Parallel.Foreach](https://msdn.microsoft.com/en-us/library/ff963552.aspx) which will distribute the work to as many cores as it can? (Assuming the work can be done independent of each other)
I don't know if it's a convention or not, but the Java-like namespace seems out of place. Nitpicking I know, but something that caught my eye.
Using TPL (which handles the scheduling of ThreadPool) is not only easier, but is going to give better performance 99% of the time. It will also scale based on the processor. (e.g., running Parallel.For on a R7 1700 should be twice (or near twice) as fast as on a R5 1400, clock for clock; and you don't have to change your code, because TPL will scale it for you!). edit: having said that, you can always test it for yourself. Your experience may differ.
Are you passing a function as in a lamda or delegate? Otherwise, you are just calling a method whose return value is used as a parameter.
Don't worry about it. Every application has a bottleneck, and the way you delegate work to threads is unlikely to ever be that bottleneck. If you want to optimize performance, you've probably got more important things to look out for.
No problem. Having used some other servicestack projects I have mixed feelings about it. I wanted to have some community feedback on it before deciding if it was something for my toolbox. Is the spam rule for this sub only? Because I like to try again in /r/dotnet 
Extension is too harmfull in my opinion. After installing it a lot of project would not compile, which would be a big hassle. Also, there is existing repository for NuGet package https://github.com/astro75/SwitchEnumAnalyzer which adds similar functionality for single project where NuGet package is. It's less invasive and easier to maintain. I and some other coder contributed to repository previous month so it should be up to date. It's available on NuGet :)
You're not passing a function as a parameter, you're calling a function, `someOtherFunction` on a value `parameter`, and then passing the result of the function to the other function, `someFunction`. And no, it's not a problem.
It's not the copy/paste it's that you need to have an empty line above and below your code and indent *each* line by at least four spaces. See also "formatting help".
It's worth pointing out that OSs much older than Windows 9x, for instance Amiga OS, did use preemptive multitasking. Also UNIX, I assume.
BindingSource is implementing IBindingListView
I would just put spaces inside the outer parens to make it more readable. Or write it as: var something = someFunction( someOtherFunction(parameter) ); Just to keep it more readable. (Tab indenting someOtherFunction.)
Unless you use a Stopwatch (which I'd advise against) you're not going to be able to check the time remaining. A better solution would be to use a System.Threading.Timer (set not to repeat) and set a property i.e. MobDue on your class when it ticks. You can easily set the property to false and call Timer.Change and you're ready.
Just this sub, you're free to post it elsewhere.
The way you are explicitly casting should throw an exception if it is not of type GradStudent. So you could either put some error handling around the cast or do a conversion like: GradStudent gStd = stud as GradStudent; Which you could then check gStd if it is null or not. gStd will be null if it is not of type GradStudent. 
This is definitely something that will improve my life...
What does this library give me over AutoFixture with it's integrated support for numerous mocking libraries not just Moq? I'd say not a lot, honestly.
I personally found that incredibly hard to use (you need to write your own IAuthenticationProvider or something) and there are literally no examples out there of what it expects :-( 
Here's what I wrote, that just works with any sentence, not pre-configured grammar: public class SystemSpeechRecognition : ISpeechRecognition { private SpeechRecognitionEngine engine; private bool listening; private TaskCompletionSource&lt;string&gt; results; public bool IsListening { get =&gt; listening; } public void StartListening() { if (listening) throw new InvalidOperationException("Already listening"); engine = new SpeechRecognitionEngine(); engine.SpeechRecognized += Engine_SpeechRecognized; engine.SpeechRecognitionRejected += Engine_SpeechRecognitionRejected; engine.LoadGrammar(new DictationGrammar()); engine.SetInputToDefaultAudioDevice(); engine.RecognizeAsync(RecognizeMode.Single); listening = true; results = new TaskCompletionSource&lt;string&gt;(); } public async Task&lt;string&gt; StopListening() { if (!listening) throw new InvalidOperationException("Not recording"); engine.RecognizeAsyncStop(); listening = false; return await results.Task; } private void Engine_SpeechRecognized(object sender, SpeechRecognizedEventArgs e) { results.SetResult(e.Result.Text); } private void Engine_SpeechRecognitionRejected(object sender, SpeechRecognitionRejectedEventArgs e) { results.SetException(new RecognitionException()); } [Serializable] public class RecognitionException : Exception { public RecognitionException() { } public RecognitionException(string message) : base(message) { } public RecognitionException(string message, Exception inner) : base(message, inner) { } protected RecognitionException( System.Runtime.Serialization.SerializationInfo info, System.Runtime.Serialization.StreamingContext context) : base(info, context) { } } }
I agree and AutoFixture is great. The purpose of the article is merely to show the basic concept for programmers that doesn't work with automockers (such as AutoFixture).
 public interface ISpeechRecognition { bool IsListening { get; } void StartListening(); Task&lt;string&gt; StopListening(); }
Sometimes I think developers are inventing things to keep them employed rather than to make their products better.
Fair enough.
Yes, people like applying their Java-isms on C# code, namespaces in particular for some reason. **Use the conventions of the given language and frameworks, don't apply one type to something that uses a different type**.
Hey I did this and now it kinda works but it deletes an entry which is stored in a database one place before. I think it's because it takes the variable after delete button "visually" deletes current entry. Example: 1 2 I want to delete this one and the #1 gets deleted. 3 I'm using SQL Server.
Well, if I spend more time writing unit tests, I'm not spending it writing new features or improving them. In this particular case, I'm not really sure it saves that much time, considering the draw back automagic always seems to have
Ah Ok, I wasn't aware of that. I noticed some C# libraries for the Speech API. https://docs.microsoft.com/en-us/azure/cognitive-services/speech/getstarted/getstartedcsharpdesktop https://docs.microsoft.com/en-us/azure/cognitive-services/speech/getstarted/getstartedcsharpservicelibrary Maybe you can build on top of the libraries? It would be better though if you could use your own code of course :) good luck!
&gt; Many short-running threads vs. long-running threads The answer is "it depends". There is certainly an overhead in creating a new thread. So if you're creating thousands of them in a short period of time there'll be an impact. However.. the OS and runtime will typically have a pool of already-created but not-currently-doing-anything threads that can be assigned to your work. The size of this pool is managed dynamically based on things like CPU load, available memory, and so on. Back in the old days, the rule of thumb was to create a thread for work that would take longer than 1/10^th of a second to complete. That's now obsolete because of the sheer power of the modern CPU. But you might look at the work you're trying to do and if you've got something long-running, manually create a thread for it and feed it work via a concurrent (thread-safe) queue of some kind.
my 2 cents The only thing I would say is that sometimes you would desire to see / debug / log / whatever the intermediate result (the one returned by someOtherFunction). Especially if the result is not trivial. But even then I wouldn't make a big fuss over that.
I have something close to working, i just cant seem to get all the data string user = searchResultView.SelectedItems[0].SubItems[1].Text; string userName = "userl"; SecureString securePassword = new NetworkCredential("", "pass").SecurePassword; PSCredential cred = new PSCredential(userName, securePassword); WSManConnectionInfo connectionInfo = new WSManConnectionInfo(new Uri("http://server/powershell?serializationLevel=Full"), "http://schemas.microsoft.com/powershell/Microsoft.Exchange", cred); connectionInfo.AuthenticationMechanism = AuthenticationMechanism.Kerberos; using (Runspace runspace = RunspaceFactory.CreateRunspace(connectionInfo)) { using (PowerShell powershell = PowerShell.Create()) { string script2 = "Get-Mailbox user"; powershell.AddScript(script2); runspace.Open(); powershell.Runspace = runspace; Collection&lt;PSObject&gt; results = powershell.Invoke(); MessageBox.Show("REsults count" + results.Count.ToString()); foreach (ErrorRecord err in powershell.Streams.Error) { MessageBox.Show("Error"); MessageBox.Show(err.ToString()); } MessageBox.Show("Results string" + results.ToString()); foreach (PSObject result in results) { MessageBox.Show("Loop results: " + result.ToString()); } } } MessageBox.Show("Mail box statestik for: " + user); now this returns my full name, but not any other data. If i try to do this: string script2 = "Get-Mailbox user | Select -ExpandProperty 'ProhibitSendQuota'"; it breaks and says the select is not part of a cmdlet.... i have also tried with addparameter, and addargument part like so: string script2 = "Get-Mailbox user"; powershell.AddScript(script2); powershell.AddCommand("Select"); powershell.AddParameter("ExpandProperty", "'ProhibitSendQuota'"); this gives the same error.. select is not part of a cmdlet.... string script2 = "Get-Mailbox user"; powershell.AddScript(script2); powershell.AddArgument("Select"); powershell.AddParameter("ExpandProperty", "ProhibitSendQuota"); and this just gives me the full name again.... what am i missing? 
Yes, the state of a running thread is saved in a data structure to system memory when the OS decides it is time to switch to another, there’s absolutely nothing tying it to a specific core and the scheduling routine may very well decide to move it between specific logical processors on a regular basis.
This is great, however it would be nice if there was a way to do it with a switch statement without having to include that line in the actual code. A compiler warning is also nicer than an error. Also, does anyone remember VS doing this itself with intellisense up until recently? Switch statements used to only suggest enum values that weren't taken care of in previous case statements. Now it always suggests all of them, making it hard to catch which cases are missed. It's probably something to do with switch statements being expanded to handle `is`.
I'm working on the next release of Reddit Wallpaper Changer (/r/rwallpaperchanger). It's a C# windows app that will automatically download and apply wallpapers from user specified sub(s) based on various customisable criteria. It supports multi monitors and has a history, favourites and blacklist view. I'm not the original author but he stopped developing it a couple of years ago and chose to OpenSource the code. As a user of the app and wanting to expand my C# skills and see the application expand, I picked up the torch. It's come on a fair bit since, and hope to get a few more user requested features implemented! :) 
That's indicative of an error of array or list indexing. What does the code look like to delete the listbox entry and the corresponding database item?
I like using an auto mocking container, but I set it up to return strict mocks for all auto-mocks so that only mocks that have been setup can be used.
I wrote [ValueOf](https://github.com/mcintyre321/ValueOf), a library for defining value object types in a single line of code. e.g. public class CustomerReference: ValueOf&lt;string, CustomerReference&gt; { } ... CustomerReference x = CustomerReference.From( "ASDF12345"); This is really handy for tightening up your codebase, by creating custom types to represent different values, rather than just using `int`, `string`, `double` etc. everywhere. 
I wouldn't call it a code smell... is var isEmpty=String.IsNullorEmpty(MyString.Trim()) a code smell? If 'someOtherFunction' takes a lot of parameters, or the parameters are not simple then it would make sense to break it into multiple statements.. but to an extent... this is exactly what happens anytime you use a property as an argument... 
Yea, I thought he was talking about passing a delegate from the title.
Removed: Rule 6, spam.
Thanks for the reply. That was the first thing I tried and these as well. Unfortunately nothing works. :( &lt;DataGridTextColumn Header="Species" Binding="{Binding XPath=Animal}" Property="HorizontalAlignment" Value="Center"/&gt; &lt;DataGridTextColumn Header="Details" Binding="{Binding XPath=Prop, NotifyOnTargetUpdated=True}" Width="125" TextBlock.TextAlignment="Left" /&gt;
Thanks you very much, this will be the solution, I already have created some mockup code for that, which functions, so I will implement it in my project. (without the heavy use of statics obviously) This thing waits for the timer, if the timer goes of, sets a property (asynchronously). The object periodically checks whether the property is set, in if its is, resets the timer and the property and does some work. using System; using System.Threading; public static class Example { public static bool IsSet { set; get; } = false; private static Timer ticker; public static void TimerMethod(object state) { Console.WriteLine("Setting IsSet = true"); Console.WriteLine(); Example.IsSet = true; } public static void Main() { ticker = new Timer(TimerMethod, null, 3000, 0); //var ticker2 = new Timer() while (true) { if (IsSet) { Console.WriteLine("IsSet == true, doing something...."); Example.IsSet = false; ticker.Change(3000, 0); for (int i = 0; i &lt; 10; ++i) { Console.Write("."); Thread.Sleep(150); } Console.WriteLine(); Console.WriteLine("Finished doing something"); } } Console.WriteLine("Press the Enter key to end the program."); Console.ReadLine(); } }
At this level, the docs should be enough. Go to MSDN and start there. EDIT: and C# in depth should be a good book too. 
Thank you for your understanding and helpful comment. That is the exact solution that I was looking for.
I ended up fixing it. I had to first set this up in the datagrid resources. &lt;Style x:Key="NameCellStyle" TargetType="DataGridCell"&gt; &lt;Style.Triggers&gt; &lt;Trigger Property="IsSelected" Value="True"&gt; &lt;Setter Property="Foreground" Value="#FFCAA201" /&gt; &lt;Setter Property="Background" Value="Transparent"/&gt; &lt;Setter Property="BorderBrush" Value="Transparent"/&gt; &lt;Setter Property="HorizontalAlignment" Value="Left" /&gt; &lt;Setter Property="VerticalContentAlignment" Value="Center"/&gt; &lt;/Trigger&gt; &lt;/Style.Triggers&gt; &lt;/Style&gt; Then I set the resource value to the specific column property. &lt;DataGridTextColumn Header="Details" CellStyle="{StaticResource NameCellStyle}" Binding="{Binding XPath=Details}" /&gt; 
Np, happy coding!
A file stream can be positioned, so it's possible to read it backward in chunks. You'd have to implement you own TextReader equivalent to parse out the lines though. Sounds like a fun challenge.
But BindingSource need a source that implement IBindingListView :'(
Hey I use this! It's a great app for people who get bored of the same wallpaper but are too lazy to look for new ones. 
Unfortunately I cannot use a database. It has to be in a file.
Do the fluent methods directly call methods inside MVC, or do they build up an underlying semantic model for a controller/action (which is then applied to MVC)? The latter approach is a powerful thing (as you can have data-driven controller definitions by (de)serializing the semantic model classes. 
The code and table indexing was fine, I just had to change when the code executed. I'm using WinForms so I had to change from OnClick to Before (I don't recall what exactly is called). Thank you everyone!
Thanks.
Yes, now that you mention it, it does look out of place. I hardly ever program in Java, but it was the first thing that came to mind when I wanted something that would be globally unique (use a domain that I own, Java-style). What would you suggest? Just use something based on my name/GitHub ID (ABJennings)?
This is how we do it in our internal log file viewer. The log file can get very big and we're mostly interested only in the last few entries. So reading it backwards is the only option.
Is it feasible to check the type string in your code and only allow use for a set of whitelisted types and/or assemblies?
Yes, I may release it as a NuGet package in the future so it can be applied to just one project. But the fact is, you have to opt-in to this functionality on a per-code-block basis (by throwing the right exception), so it shouldn't affect any existing projects. Also, an analyzer error doesn't prevent the project from compiling.
&gt;I dont really want to extract time information from the XNA GameTime gameTime object. Why? Do you have a different custom Game Time object? In my opinion, all timing related functionality (esp in a game) should be based of a Singluar Current Time source... So I would do is something like struct myTimer { long currMS; long totalMS; myTimer(long duration){totalMS=duration;} void Reset(){currMS=0;} bool IsElapsed(long deltaMS){currMS+=deltaMS;return currMS&gt;totalMS;} long RemainMS{get{return totalMS-currMS;}} } myTimer myTimer=new myTimer(10000) void Update(...) { if (myTimer.IsElapsed(MSSinceLastUpdate)) { CreateMob(); myTimer.Reset(); } } 
I suppose it would be if I were to limit it to components of types known at compile time, but not if it were to be used to extend functionality via plugins or some such... 
Not quite *arbitrary* code, just existing code with (somewhat) arbitrary parameters. But yes, these sorts of serialization vulnerabilities can be dangerous. Depending on how you load the types, the attacker is free to choose from any types in your application, your application's references (and references of references), the framework, and the GAC. That's a pretty big attack surface. Easiest fix is to use some sort of whitelisting. Require that all deserializable types, fields and properties are marked with a custom attribute, for example.
yourString [0].ToUpper ();
Correctly handling variable-width UTF-8/16 sequences won't be trivial, though.
Thanks for the comment! I am not really into XNA (and a matter of fact .NET) yet. I see the reason in your comment, but the challenge I see is, that I will have to maintain different timers and the game will also have a pause function. I would like to maintain a clock tracking the net time spent on the current level, without "pause"-time. But yes, I might run into a problem, where I maintain a set of independent Timers / Stopwatches without actually hard-ensure that they run synchron, even if the game slows down. (in that case XNA gameTime and .NET timers might run different speed I suppose) . 
Jon Skeet wrote something like this a while back, it's somewhere in his MiscUtils collection, called ReverseLineReader: http://jonskeet.uk/csharp/miscutil/ The source is available as well as the libraries depending on your purpose.
To be honest, I almost never use switch statements. Maybe it's because of Python, but an if/else block looks more natural to me. So I (personally) need something that works on if/else blocks. You may want to look into https://github.com/astro75/SwitchEnumAnalyzer that someone else mentioned. Also, my analyzer checking only that all the enum values are *mentioned* somewhere in the enclosing block is a bit of a lazy hack. But I realized that it gets 90% of the benefit for 10% of the cost, *and* it can be used for "reverse conversions", too. Say you're writing an EnumFromString function. Your cases will be strings and you'll be returning enum values, so something that detects missing enums in switch cases won't help you. With this analyzer, you can throw the EnumNotExhaustedException at the end and then the compiler will tell you if you add an enum value and forget to add it to your EnumFromString function. It would also handle a "Flags"-type enum, where the values can get OR'ed together and you have a certain function where you want to make sure you handle all components. Though in that case, you'd probably want to hide the "throw new EnumNotExhaustedException" in unreachable code, which is annoying.
Removed: Rule 4.
Yea, some systems require total session time and some require total unpaused session time... my recommendation for that is to maintain two timers. One timer tracks total session time and is initialized at application startup and is never stopped or reset. The second timer is initalized in a paused state... when the player pauses the game this second timer start counting time, when the player unpauses the game it stops counting time. Then to get the currentEffectiveTime (defined as the total unpaused session time) return totalSessionTime-totalPausedTime 
Not necessarily, you need to ensure the correct overload is called, its very finicky because of implicit conversions to string IIRC 
Ok... so I suppose in order for a plugin system to work, there almost has to be some level of trust between the application and the plugin... i.e, notepad++ can't guarantee that a malicious user hasn't created a malicious plugin that would cause notepad++ to behave badly because the point of the plugin system is to allow the application to extend functionality in ways unimagined by the original application author. So, that means that any (assembly based) plugin system is inherently prone to attack. However, that is mitigated by the application user choosing plugins only from trusted sources (similar to how it is safe to download an adroid app from google store, but no some random android app off the net). Once that limitation is acknowledged it is the application developers responsibility to ensure that a malicious user can't leverage the plugin system as an attack vector without the victim introducing a plugin provided by the attacker. So, to accomplish that... I should force each plugin to be annotated with a custom attribute and rather then looking for the load method by name, it should search by attribute? i.e [IsComponentAttribute] public struct SomeComponent { int Foo; int bar; [IsLoadMethod] void Load(...){...} } This would be "Safe"?
That's the fun part. UTF8 multibyte characters have high bit set, and UTF16 surrogates are specific value ranges, so they are easy to identify too.
Thank you all for the response! It's always awesome to have people chime in on something you've created yourself :)
I agree, one of the reasons I built this tool was exactly for what you mentioned. Projects at my work tend to have a very small web layer with business logic + data access defined elsewhere, so for a lot of routes we don't really have the need to break functionality up into separate places/concerns.
take a look at [Task.WhenAll](https://msdn.microsoft.com/en-us/library/hh194766\(v=vs.110\).aspx)
Oh yea, I can see people refactoring this context.From($"Select * from Table where Key = {key}") into this: var sql = $"Select * from Table where Key = {key}"); context.From(sql) without realizing that it will break their code.
It would be *safer* in the sense that it massively reduces the amount of code a potential attacker could try to find exploits in. Of course simply annotating a type doesn't automatically guarantee that it's safe, but it's much easier to audit a couple dozen of types rather than thousands. &gt;there almost has to be some level of trust between the application and the plugin It is possible to make plugins reasonably safe by executing them in restricted sandboxes with limited permissions (e.g. Chrome extensions), but of course that is a lot of additional work and makes the application and plugin development much more complicated and limited.
That is so vulgar. In polite society we say "read uncommitted". 
Ahh. I think I can use that. :D Thanks.
Fluent actions uses its own model that is separate from MVC. I really like your idea, I'm gonna have to try out something like that when I have the time :) So far I've only taken advantage of this separate model in some mildly interesting ways by, for example, autogenerating an API documentation and a front-end API in typescript.
Seems like Visual Studio could include inline breakpoints.
because its a constant, you cant change it during runtime. Also its not static.
What? He’s not trying to change it, and constant can’t be static. 
What error do you get?
I guess you could read a chunk and iterate backwards till you find a new line (or if you don't read another chunk) or are at the start and yield return the line when you do.
You should probably show us a version of ModelFile.cs that reproduces the problem. The only thing I can think of that would cause it is another ConstantsFile class in the same namespace as ModelFile, or in another namespace that ModelFile.cs has imported with a using statement.
&gt; constant can’t be static or rather, you can't use the `static` keyword on a `const` because `const`s are **always** static. From section 10.4 of the C# 5 Specification: &gt; Even though constants are considered static members, a *constant-declaration* neither requires nor allows a `static` modifier. 
Removed: Rule 4. Please include the platform (Windows, Android, etc.), the app type (WPF, Unity, Service), if you're looking to track your own app or all apps running on the system. Also include what research you did, if there were some solutions you found but they weren't usable (you couldn't figure them out, they didn't work, not applicable to your use-case scenario).
Probably not the solution but you should prefix your namespaces with something unique (eg. testapp.constants and testapp.model). If you don't you might get namespace conflicts. 
Thank you so much! I started a blog where I only solve code exercises and problems to help me learn c#, I think it might pay off down the line if I keep doing it. Only have 40 problems complete. 1000+ more to go! 
 using static Constants; ?
Uh, why not just something along the lines of `DELETE FROM ... WHERE age &gt; x`?
If this is SQL Server, look into linked servers. A SQL Server stored proc can operate on data in other servers using linked servers. So you only need one stored proc in whatever database you choose, then link to the other databases. When you add/remove/change a database, just update that single stored proc. In my opinion it would be crazy to do something like this anywhere but in the database. This kind of task is what SQL is for. Use it. A subquery like you describe is perfect for the task. If the indexes are set up correctly, it should be super fast.
I second C# in depth 
No, that won't work. It has to be `using Constants` or `using static Constants.ConstantFile`
That would be my second guess after just a simple typo or stray `}`.
Whenever I come across a scenario where I need to do this, I usually use Sqlite instead of a flat text file.
It does, you just need to right click on the method instead of clicking the empty space on the left of the line.
Your enum props need private sets :P. Keeping the enums, this could be a useful modification to the `Card` class: public class Card : IEquatable, IComparable { public FaceValue Value { get; private set; } public Suit Suit { get; private set; } public Card (FaceValue value, Suit suit) { this.Value = value; this.Suit = suit; } public override bool Equals (Card obj) { return (this.Value == obj.Value &amp;&amp; this.Suit == obj.Suit); } public override bool Equals (Object obj) { var target = obj as Card; if (target == null) { return false; } var card = (Card)obj; return Equals(card); } public override int GetHashCode() { return int.Parse(((int)Value).ToString() + ((int)Suit).ToString()); } public int CompareTo(Card c) { return this.Value.CompareTo(c.Value); } } Then we could make a `Deck` class that handles the dirty work: public class Deck { private Queue&lt;Card&gt; Cards { get; set; } public Deck(bool shuffle = true) { this.Reset(shuffle); } public IList&lt;Card&gt; Draw(int count = 1) { var result = new List&lt;Card&gt;(); count = Math.Max (Math.Min(count, Cards.Count), 0); for (int i = 0; i &lt; count; i++) { result.Add(Cards.Dequeue()); } return result; } public void Reset(bool shuffle = true) { Cards.Clear(); var suits = Enum.GetValues(typeof(Suit)).Cast&lt;Suit&gt;(); var faces = Enum.GetValues(typeof(FaceValue)).Cast&lt;FaceValue&gt;(); for each (Suit s in suits) { for each (FaceValue f in faces) { var card = new Card(f, s); Cards.Enqueue(card); } } if (shuffle) { this.Shuffle(); } } public void Shuffle() { var temp = Cards.ToList(); var rng = new Random(); int count = temp.Count(); while (count &gt; 1) { count--; int k = rng.Next(count + 1); var card = temp[k]; temp[k] = temp[n]; temp[n] = card; } Cards = new Queue&lt;Card&gt;(temp); } } Usage: var deck = new Deck(false); deck.Shuffle(); int drawCount = 2; var hand1 = deck.Draw(drawCount); var hand2 = deck.Draw(drawCount); var hand1Total = 0; var hand2Total = 0; for (int i = 0; i &lt; drawCount; i++) { hand1Total += (int)hand1[i].FaceValue; hand2Total += (int)hand2[i].FaceValue; } var result = "Draw"; if (hand1Total &gt; hand2Total) { result = "Player 1"; } else if (hand2Total &gt; hand1Total) { result = "Player 2"; } Console.WriteLine("Result: {0}", result); Edit: I did this on my phone so please excuse some syntax errors and formatting. 
If changes arent expected and the performance hit of reading it twice isnt problematic, the easiest way would probably be to read it forwards, but write it out backwards to another file (appending new characters to position 0). Then read that second file forwards.
Huh? Why cant you tail the last 10 or what not?
Kudos for doing all that on your phone! But yup, that's the idea to nicely express the problem domain. BTW, I didn't need the private setters; that's a C# 6 feature.
Make a job on the SQL Server that runs like every quarter (3 months) and use /u/tweq's example
C# in a Nutshell is a good reference too. The first few chapters are basic things, but it dives into other advanced topics that are good for newbies to the language, but not programming.
Might want to avoid it forever.
Right, and the reason is because constants are all replaced by the compiler with their values, so at runtime they arent actually variables (im pretty sure anyways). Thats why any assemblies that reference it need to be recompiled if the value changes.
Great to hear that's the approach you've gone for - years ago the Fluent Nhibernate team had to do a massive rewrite to get to a semantic model. You might want to split the two into two projects (the model and the Fluent builder). For me, model driven MVC is more interesting, and fluent builders are just icing on the cake. Having two projects which cater to specific needs might increase your uptake.
if you control the assembly build process you could try strong name signining them, then check public key against a whitelist
Not an option if you're targeting .NET Core/Standard.
The SDK is now open source: https://github.com/Lombiq/Hastlayer-SDK Does it qualify for the subbreddit now?
Like others have said MSDN docs and Stack Overflow for fringe/unique cases. I always felt once you get a decent base just searching Google for certain methods and things you need is the best way to grow as a developer. 
Huh will have to look into swapping over
Sure, feel free to post the github. Just try not to let the submission sound like an advertisement.
Did you ever work this out? I'm trying 4.6 because an Imgur API written for C# uses 4.5. I can build the project in Visual Studio, but when I try running the project I get: Assets/BuildAndDestroyCode/LogsUtil.cs(112,30): error CS0012: The type `System.Object' is defined in an assembly that is not referenced. Consider adding a reference to assembly `System.Runtime, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a' The line of code in question that is causing the problem is: var client = new ImgurClient("1111111111111111", "222222222222222222"); Does anyone have any thoughts on how to resolve? 
Consider going over to r/sql for input from more seasoned DBAs. With that said, I'd follow up with [the suggestion](https://www.reddit.com/r/csharp/comments/6ypu1m/i_want_to_create_a_log_cleaner_program_that/dmp81p8/) by u/Sasken with linked servers and keeping this in a store proc and/or SQL job.
You can try pulling the last three months, delete the whole table, insert the three months... but that's only if you deleting the last ten years to three months... if it's only deleting a weeks worth of files at a time afterwards then just do a normal delete with a clause.
Use a ring buffer the size of the logs you can keep in memory to store the file contents that you read top to bottom. When your done you'll have the last N entries in memory you can read from. 
As an experienced developer, I often use Learn X in Y to do a quick dive: https://learnxinyminutes.com/docs/csharp/ For C#, the C# Pocket Reference ($12) for O'Reilly was all I needed to get a good handle on most of the language.
Oh wow. I'm glad we've had this interaction then! I've been using private setters that way for a while now.
What about a trigger? After insert you can delete the logs you want. I guess you can use the /Sasken idea.
You mentioned multiple servers. I'd say this is something you'd deploy once on each and set it up as an SQL Agent job. And be done with it. Use a query like /u/tweq mentions - just delete any rows where the created-on date is older than the current date minus 90 days. &gt; declare @ninetydaysago datetime set @ninetydaysago = dateadd(day,-90, getdate()) delete from dbo.log where createdon &lt; @ninetydaysago 
Or store your whitelist in a file or database table, so that you can add to it at runtime. 
Depending on how many records are in the table it's probably faster to make a new table that contains only the data you want, drop the old table, then rename the new one back to the old name. Something like: CREATE TABLE db.LOG_TABLE_TMP AS SELECT * FROM db.LOG_TABLE WHERE NOW() - LOG_TIMESTAMP &lt; 90 -- days; DROP TABLE db.LOG_TABLE; ALTER TABLE db.LOG_TABLE_TMP RENAME TO db.LOG_TABLE;
For C# it's much less formal. Either just your product name or maybe your company name/"brand", then the product name 
Definitely the way to go. Better use an existing implementation in this case.
Assuming they're ordered by primary key; just select all rows, reverse them, take count - x, and delete them. Rather than using a stored procedure, you can do it with a client app through Entity Framework. Set that up as a scheduled task. Or look into linked servers like someone else mentioned to share a sproc.
Your comment made me actually read the article. The big advantage I can see compared to what I do is that my setup methods could be much smaller for classes that get multiple injected dependencies, and adding a new constructor parameter wouldn't automatically break all my tests. Still have to be careful when making changes that the unit tests are up to date, but I'd have to anyways with a big setup method.
Sure it would. Just check that the type derives from an interface that you control.
This might just be my ignorance to the subject, but isn't what you are suggesting a possible security flaw? Get credentials for one DB and access multiple DBs across the enterprise. 
When you set up the linked server you have to provide credentials. 
That's not enough lines of code to satisfy my inner software engineer.
UTF-8 has self-synchronization, you can tell if a byte is the start of a sequence just from the byte's value.
A stored procedure's biggest advantage is that it's precompiled, so it runs directly. This is a significant advantage when you have queries running several times per second. In your case, however, the advantage isn't relevant.
Yeah there are some really convoluted ways to do something so simple in this thread.
They'd still be accessible via reflection, so its up the compiler writer to decide which behavior they want.
I have parsed files this size with pretty good performance with similar methods... var changes = File.ReadLines(Path) .Skip(LastLineNumber); This returns an iterator instead of loading a huge array into memory. Edit: add a take(n) to clamp the result size and then just ToList().Reverse() and then foreach Edit: guess you wouldn't really want to clamp your result size in this scenario
My company's production and legacy code are the same thing (misguided "if it ain't broke don't fix it" attitude). I've had a long running personal/for-work side project of improving things with C# and exporting a C++/CLI wrapper library. This was purely to keep myself sane when I wasn't mucking around in poorly written MFC code, a lot of which is older than me... We're finally being forced to ditch VS 6.0 (yes) so I pitched this library and Git. Ended up promoted and in charge of our .NET migration... I'm a Linux guy at heart but I owe a lot to Microsoft and C#
Any update on this? Did you find the error? Could you provide a full non working example?
I usually just initialize any applicable fields or properties in the constructor and then if necessary, call a separate method to initialize whatever database context I need, or whatever the long running operation will be. In that initialization method I'll use Task.Run to run my async code. Maybe I save the resulting task to a field so I can monitor the readiness of my viewmodel with an observable Boolean property so to avoid allowing UI operations before the viewmodel is ready.
Please don't do this
I've tried `Task.Run` in the constructor of my UserControl: Task.Run(async =&gt; { DataContext = await CampaignsViewModel.Create(); }); I got an error though saying that &gt; The calling thread cannot access this object because a different thread owns it.
You probably will need to marshal that to the UI thread using Application.Current.Dispatcher.Invoke(...)
So like this or something? Application.Current.Dispatcher.Invoke(() =&gt; { Task.Run(async =&gt; { DataContext = await CampaignsViewModel.Create(); }); });
I'm not 100% sure but my first instinct is to swap that around and stuff the invoke into the thread instead. Alternatively there might be a BeginInvoke or InvokeAsync option in which case you might get away with not having to use Task.Run at all. Edit: Yep, you've got both InvokeAsync and BeginInvoke. I'm guessing InvokeAsync would be ideal, just don't bother awaiting it, and you can include it in your constructor.
This got rid of the error and seems to work okay Application.Current.Dispatcher.InvokeAsync(async () =&gt; { DataContext = await EmailSendViewModel.Create(); }); I'm inclined to use it because it does what I need but there's so much more I want to know about it... I just don't know what questions to ask.
One idea is to use an IOC container to run a lambda upon construction 
Could I trouble you to share an example?
Let me see what I can come up with, on moment please
So is the objective to create an object and then immediately fire off async methods? Do you need to be able to New up this object and it still behave this way? (e.g. var thing = new MyThing())
&gt; I mean, isn't it basically giving anyone the ability to execute arbitrary code by putting whatever they want into the structs Load method? That depends on who controls the code. If someone can inject code on the target computer, the target computer has much bigger problems. Is it your goal to protect yourself from that attack? &gt;Would it be considered a mitigated threat if the primary assembly did not dynamically link external dll files at run time and only allowed binaries that were linked at compile time? You're using strange terms. All .net assemblies are "dynamically linked", and that happens at compile time. You seem to mean "dynamically *loaded*", is that it? There's dynamic loading of assemblies in your code? If yes, it's still the same question: do you want to protect yourself from someone injecting code? If you do want to protect against injecting the code, then note this: the serialization attack is only one possible avenue, and probably not the most interesting. He who can inject code will surely look for a more simple way, wouldn't they? [There has been a lot of discussion about serialization vulnerabilities in Java a year or so ago](https://foxglovesecurity.com/2015/11/06/what-do-weblogic-websphere-jboss-jenkins-opennms-and-your-application-have-in-common-this-vulnerability/). There, people were using the serialization itself to inject code **through the serialization process**. That part is missing for you, doesn't it?
Please look at C# async constructors I'm on mobile and web pages aren't loading If you went the IOC route, you can register a type using a lambda function, as long as the lambda eventually returns the object you can do whatever you want Then you could ask for your class in the constructor of any classes that depend on it (If you aren't using IOC I recommend autofac, though nearly all offer the majority of major functions, newer .NET stuff has it built in so that can be worth learning - it can be swapped for any other container )
Looking at some old code in WinForms, what I did was create a private async initializer method, and a Task property. In the constructor I simply assigned the method to this property. public MainWindow() { InitializeComponent(); Initialization = InitAsync(); } public Task Initialization { get; private set; } private async Task InitAsync() { await AppInitAsync(); AppInitDone(); } I did this based on Stephen Cleary's blog post, which I can't find right now. Currently he has [this](https://blog.stephencleary.com/2013/01/async-oop-2-constructors.html) on constructors, and [this](https://msdn.microsoft.com/en-us/magazine/dn605875.aspx?f=255&amp;MSPPError=-2147217396) for MVVM patterns 
I suppose that's possible, but surely u/lippiro *built* their code before asking the Internet for help. Surely.
Exactly, just run that against each server.
As ConstantFile is in the namespace Constants, the full type is Constants.ConstantFile. You can avoid referring to the namespace by using a 'using' statement at the top of ModelFile.cs using Constants; this will make you refer to ConstantFile without the namespace. Like you don't have to refer to 'System.String' but can do 'String' if you use using System; HTH (edit: removed '#')
I guess I could calculate the age of the record and do that, I like it. Man, sometimes the simplest things elude me.
I want to eventually make this a tool other dev's in my company could use. I wanted to create a little web front end where you could specify your server, database and log table name and have the service automatically clean up your log tables. I know a stored proc and job would be most efficient but it would need to be implemented on many servers.
I was hoping to have a central location to clean up log files. Our company has a good amount of database servers so setting all that up would be a pain and I'd have to link new servers as they come online. I'm starting to think that I should just do individual jobs for each log and not have a service that other devs could use.
I'm not a fan of triggers aside from populating a history table... which I use in rare cases where data tracking is required.
I'm leaning towards that now.
That seems risky, I'll probably just go with a delete job
We avoid running asynchronous operations in constructors full stop, they belong in a separate method to initialise. Constructors are for creating an object. If the object having no data is not strictly invalid, then the object should be created with empty/default values. Otherwise the necessary data should be prepared ahead of time and passed into the constructor. If you need to run an asynchronous load, have that as a separate method which is called after construction has completed and your data context has been assigned. This also gives you ample chance to throw up a spinner, or whatever 'busy' indicator you prefer.
Yeah, I think I'm going to forgo the service for other devs and just clean up my own logs. I was originally going to make a service that all devs could configure but from all the comments I'm seeing I agree that an SQL job would be most efficient.
Came here to write this. Imagine the call to the async took 30s - what is op expecting the behavior to be?
Yes that's the objective. I'm currently using the ViewModel which immediately fires off async stuff as the DataContext on my user control so a new would probably be best, yes (with parameters)
&gt; If the object having no data is not strictly invalid, then the object should be created with empty/default values. I mean ideally I want to put data in comboboxes for the user to filter with (instead of showing all 239856198256 contacts in the database, rather present a list of contact groups and show the 12 in a selected contact group). That said, its not out of the question for the data to be populated later, but the first thing the user should be able to do is to select a contact group. &gt; Otherwise the necessary data should be prepared ahead of time and passed into the constructor. This is what my Create function is doing, right? &gt;If you need to run an asynchronous load, have that as a separate method which is called after construction has completed and your data context has been assigned. That's where I'm getting mixed up... If not in the constructor, how/where is such a method called and what would it even look like?
Why not? 
Whenever I need to do that I kick off a Timer from Rx and use TaskCompletionSource if there are any results that need to be accessed from the outside later.
use NetworkInterface or PerformanceCounter to get the general up / down speed if you want to create a counter for only 1 process its gonna be hard. you will have to create a network driver that allows filtering per process as windows does not do it by default (Microsoft's Network Monitor does that)
Have a whitelist of structs and types it can deserialize to types. You should only be accepting these from trusted sources, with either Transport or Message Security. Also, take a look at the OWASP documentation for XML vulnerabilities to ensure you're safe and secure.
&gt; This is what my Create function is doing, right? It's being called inside the constructor so... no. Need to call it first and then pass the result (CampaignsViewModel) as a parameter to the constructor. &gt; If not in the constructor If you can't trust yourself or your users to initialize the object properly and in the right order, create a Factory whose sole job is to call the async create method, get the result, and create the object by passing it into the constructor (or create the object and call an initialize method after, whichever you prefer).
Create a test project for one of your existing projects, look for NUnit, Shouldly, Moq, and Autofixture in package manager and install them. NUnit is a testing framework - there is plenty of documentation on their site, and you can find real world examples of it in use here https://github.com/MassTransit/MassTransit/tree/develop/src/MassTransit.Futures.Tests You'll want to install the NUnit runner (Visual Studio extension) Shouldly provides a range of extension methods that Dave you from having to write Assert statements yourself. Moq allows you to setup and inject mock dependencies into your system under test, so that you can focus on testing specific functionality in that without worrying about what the underlying dependency is doing. Less powerful if you aren't writing testable code (most relevant principle from SOLID in this instance is inversion of control) Autofixture allows you to create instances of your classes with properties set so that you don't have to build them yourself, but it's flexible in that regard. Very useful for writing clean, readable, and maintainable tests. Look into arrange, act, assert, it's a fairly fundamental pattern in testing.
Github. Edit: I would appreciate a good workflow example as I wholeheartedly agree with you on the quality of the examples.
Crate a repository on GitHub (public repositories are free, you have to pay a small subscription fee for private) You can create a readme for your repository to cover the technical side that a blog otherwise would, in place of having one yourself. Wiki is also an option, but the readme is what people see first when they find your repo. Snippets can go into a gist (gist.github.com)
I know the new [docs.microsoft.com](https://docs.microsoft.com) website accepts contributions from people. So if you find that the documentation and examples were crap I think the best idea is to try to contribute to the documentation yourself if you have some time to put into it.
This is all very helpful, thank you!
I enjoyed "Effective C#: 50 Specific Ways to Improve your C#", and its sequel "More Effective C#", they both get more into the specifics of good coding practices in certain situations and the reasoning behind it. They only go up to C# 4.0 I believe, but they were great resources for me to learn some more advanced techniques. I also agree with the recommendation for "C# in Depth". After those, then I think it is getting into specific topics if you want advanced stuff, like "Concurrency in C# Cookbook" or "Dependency Injection in .NET". I also loved the "Head First Design Patterns" (although in Java, very similar to C#), and they may have a C# version but I never read it - this is great for learning more complex design patterns that can be applied to any language to solve bigger problems. Other great books for general advanced programming and software design include "Code Complete 2" and "The Pragmatic Programmer". These teach you a lot of best practices and ways to improve your general programming techniques to overall software design and avoiding common mistakes.
Get yourself the book from Roy Osherove: The art of unit testing. This is really excellent and worth the price!
I'll look into picking it up, thanks!
Something is going to new up your object. Then just call your asynchronous operation afterwards. var vm = new ViewModel(args); this.DataContext = vm; await vm.Initialise(); // or fire and forget it You can't await anything in a constructor, and you *definitely* shouldn't have any complex logic that could fail in a constructor, save for perhaps validating that the arguments weren't invalid. What happens if your connection to a database times out/goes bang every 1/1000 calls? You shouldn't need to create a new object to handle this sort of scenario, it should be completely separate to the act of creating an object in memory. What if the disk or network i/o to the database is really slow, and you have a lot of groups to show in the combo boxes and it takes 2 minutes before anything's ready to show? What are you going to show the user here? You don't need to do everything up-front. I would try loading up your Campaigns view model without any data, let it create it's own empty ObservableCollection, and presenting that to the user. Then start your asynchronous loading, and as results appear add them to your lists as the async work progresses.
Your colleagues. Seriously though, there's as many unit test set up and teardown flavours as there are junior devs willing to create them. The company that you work for will be trying to run test creation based on a policy. Learn that from your colleagues. Take risks with your test creation, and test as many paths through your code as possible. You'll learn to recognise the groups of common tests that you need to do. Finally, when you think you're doing good, teach those around you!
&gt; create a Factory whose sole job is to call the async create method Hell, I do that because I don't myself to initialize the object properly and in the right order.
Oh but the C# support for user-defined functions (coming in version 2.1) is just plain awesome: connection.CreateFunction("greet", (string name) =&gt; $"Hello, {name}!"); var command = connection.CreateCommand(); command.CommandText = "SELECT greet('World')"; var result = command.ExecuteScalar(); Console.WriteLine(result);
Ok, that's pretty f-ing amazing. Where are the functions stored? (In memory or in the database?)
My opinion: On one hand, you should learn what you can do with the tools ** Mocking framework ** Testing framework ** Various other tools / techniques / patterns (thinking about test data builders, object comparison, code coverage...) This part is not necessarily difficult. The basic mechanics of moq and xunit can be learned in a couple of days, maybe less Then, on the other hand, you must learn proper and useful ways to use those tools to have meaningful tests. And this is harder, the job of a lifetime of testing. I would encourage you to: ** Check blogs of people like uncle Bob ** Peek into how other people in successful projects do testing. Enter github, and look for repos ** Books. I can recommend you this one: https://www.amazon.com/xUnit-Test-Patterns-Refactoring-Code/dp/0131495054 
That is an excellent idea. I found the article explaining this. https://docs.microsoft.com/en-us/virtualization/community/contribute-to-docs I will check this out in the coming week.
Github or Gitlab Its worthwhile to learn Git as well (even if you already know a different VCS)
In memory. SQLite keeps a function pointer to the managed delegate.
Why do you have # in front of those statements?
It's slow. It would run every single time. Also if there is an error in the trigger it would cause the insert to fail. Not sure if that would apply on an after trigger.
Love this book!
I love it! Would love to watch more videos expanding on making a trainer and navigating memory addresses as a beginner in C#. I find it thoroughly fascinating.
Definitely not a code smell, but just try to write code so that it's clear why you're doing something. If someOtherFunction() is descriptively named and returns a simple/primitive value, then I have no problems calling it directly like that. However, if I need to make it clear that there is something complex happening inside that black box, it's worth breaking it apart. I have a project at work where I have to go through some translation steps due to shared code. I make a point of always doing something like this: var pureThing = _thingService.PerformAction(thingId); return SimilarThing.Convert(pureThing); 
This is right up my alley. I hope you plan to do more on this series. I've always wanted to work with memory addresses for other executables (trainers) in C#.
Thanks for the tip, I'll definitely try this out.
Exciting stuff! Hope he does some stuff about callbacks to C# and calling native functions through C# so you can mod games and do more advanced stuff like loading new levels/spawning enemies. Probably requires a lot of assembler knowledge to get to that level.. :(
You are only giving it "Test" to listen for.. If you want it to recognize "This is a test" instead, you'd need to change that. You should also use the RecognizeAsync method instead instead of just Recognize, as it allows the parameter [RecognizeMode.Multiple](https://msdn.microsoft.com/en-us/library/ms554584\(v=vs.110\).aspx) to be passed. In my own code, I use the event SpeechRecognized, instead of RecognizeCompleted, but I am unsure if that would matter with fixed choices. /u/teppicymon gave a sample of loading dictation grammar, if you want a more generalized type of input.
I have 2 other videos showing using Cheat Engine. One for Grim Dawn and another for Double Dragon. I can always do livestreams too and show you anything u wanna learn about. 
Not sure what else there would be to show. Only 2 future additions for the Memory.dll project would be some kind of ASM writing and full 64bit compatibility.
I did some ASM writing for Grim Dawn (not in C#, but for Cheat Engine's script system), and some for the MacOS Game Hacking with Bit Slicer videos. I also made a few functions in Memory.dll that make injecting C++ DLL files easy with named pipes too which I did with my EQTrainer program. I did a live stream of the EQTrainer program, which I archived in my listed videos recently. Unfortunately that program is now closed source due to some people compiling it and calling it their own.
Lol, I programmed the SNES game genie back in 92. Nice to see the tradition continues. 
So you think potentially running a full table scan after every insert (or whatever) on a table is a good idea? Everyone is way over thinking this! A simple delete statement on schedule is all that's needed
I don't grok how people can write any method that has if/then logic or switch statements and not write unit tests. No tests? You can't prove that the method does what it is supposed to with regards to the inputs. Methods that take in a set of values and return a value or object are extremely easy to unit test. You just setup a test class with XUnit's Theory and InlineData attributes on the test method. That lets you say "for inputs X, Y and Z I should get answer A". Methods that call more complex services may need the use of Moq to stub out the service calls. For instance, if you have a service that takes a ZIP code and returns a state code and relies on a database, there's no point in making the database call. Just create a Mock&lt;IService&gt; object and use .Setup()/.Returns() to say that "no matter what input I get to this method, I'm always going to return 'NY'". Create other mock objects to return different values or exceptional conditions. Note: In order to use Moq effectively, you really need to be using an IoC container (Autofac, StructureMap) so you can pass in things that your class depends on in its constructor. For book recommendations - Professional Test Driven Development with C# by Bender / McWherter.
And yes, that means you can put a breakpoint inside that lambda to debug it.
because sometimes I'm a total idiot and shouldn't be allowed near keyboards. Thanks for notifying me on this total embarrassment! Corrected the lines. I'll now crawl back into my corner mumbling a sorry excuse like "drink coffee first before replying code questions on a website"... 
Ah, nice, that makes sense.
Not exactly what you asked for but a great site IMO is exercism.io They have some great stuff to learn about Test Driven Development where they give you a small test project already built and you implement the class/methods they are testing. I really like it 
Our first question these days tends to be: "Have you used version control on a project". Follow-ups would be whether you are familiar with `git` and GitHub. We've turned down a few applicants this year who have never used version control, even for projects where they are the sole developer and are in full control. We're not a fan of coding problems. The goal during the interview is to figure out whether you can think and solve and solve problems. That doesn't require intimate knowledge of language features that can be looked up later. It's usually a more informal discussion with us. We want to know about your past experiences and whether you've used this technology or that technology, but all that determines is how productive you'll be on day thirty vs day ninety. One goal of the face-to-face interview is to figure out whether you will be a good fit for the team. (i.e. Do you play well with others. Do you grok that you have personal quirks and are you able to keep them from negatively impacting team dynamics.) Would ask what personal steps you've taken in the last year to sharpen your skills (personal projects, books, videos, conferences). 
Yeah I was checking out your vids and website. As I only have what I consider a beginner's level of C# and even less experience with memory editing (I've used Cheat Engine before, but that was a long time ago and I never got into it too much) so your vids are extremely helpful. I will admit, explaining the memory editing side of things was what I was mostly interested in, but I'm sure if I check out more videos, I'll probably learn a bit more in that area. Either way, you may get flak from people, but you'll get praise from me. This is the kind of stuff I was interested in learning more about because this is the kind of stuff you don't really have exposure to when expanding knowledge about C# through tutorials and whatnot!
C# is too bloated for this purpose. You're better off doing this in C or in assembly. 
Clean Code by Robert C. Martin
Thanks for all the fun!
Not true. 
now if only I knew how to use cheat engine that well.
I enjoyed it, although it seemed an odd mix of advanced techniques with basic c# coding. Someone who doesn't understand If syntax probably isn't quite ready to be doing this.
I think that a delete statement in the trigger is not as big as you said, but Im not a DBA, Im sure im wrong.
Did you reverse the memory addresses yourself?
Ah nice to see this. Does this also cover like auto assembly scripts?
Why not split the log file into manageable chunks? Like 10Mb pieces? Easy to manage and no need to read backwards. 
Depends. If one or both functions are very simple then it is OK.
It's just occurred to me that the **Create** domain object population logic I am using may be useful to see as well: var CropId = Request.Form["SelectedCrop"]; var DevelopmentStageName = Request.Form["CropStageName"]; var DevelopmentStageStartAge = Request.Form["CropStageStartAge"]; var DevelopmentStageFactor = Request.Form["CropStageFactor"]; cropDevelopmentStage.UserId = AppendUserToIrrigationObject(cropDevelopmentStage); cropDevelopmentStage.CropId = int.Parse(CropId); cropDevelopmentStage.DevelopmentStageName = DevelopmentStageName; cropDevelopmentStage.DevelopmentStageStartAge = int.Parse(DevelopmentStageStartAge); cropDevelopmentStage.Factor = double.Parse(DevelopmentStageFactor); cropDevelopmentStage.FarmId = ActingFarm;
Can't go wrong with the official spec. https://github.com/dotnet/csharplang/tree/master/spec
Do you happen to know which methods are called when the crucible is started and stopped? Or do you work strictly with memory locations?
You're literally marshalling every second line of code. Even for an external cheat c# is terrible. The only way I see it viable would be coding a proper C DLL and hosting C#, so you can export functions from the DLL, make your own SDK, and use it from within C#. 
Technically, the documentation refers to passing "X" (upper case X) as the formatting string. You are using lower case x. It appears the ToString only adds the leading 0 when the value would otherwise be treated as a negative number (that is, when the leading digit would otherwise be 8, 9, a, b, c, d, e, or f) or when the result fits in 4 bits. The relevant text is &gt;...if the most significant bit of the first byte in the string is set, or if the first hexadecimal digit of the string represents the lower four bits of a byte value... The documentation is incomplete. You could go to the bottom of the page, click 'No' where it asks if the page is helpful, and provide feedback on the missing information.
My understanding is that marshalling is only slow when you have to "massage" the type on the C# side. By-value marshalling to/from numeric types should be more or less a noop.
There is no cost for numeric types, as you said, but PInvoking literally every second function costs **a lot**. It's just not the language to do this in. The same way you wouldn't write a website in C. 
 Uploaded v2 .. Now the ConsoleMenuItem has an underlying object of type T which is sent to the event handler ..
Is there a significant overhead just for calling a function via P/Invoke? My experience has always been that marshalling of more complex data types is the most expensive part (especially when you have to do manual memory management). When the functions only use/return simple data types, there wasn't really a significant performance cost vs a native C# virtual method call. I had part of a benchmark for this at one point, I can modify it and post results when I get home if you're still interested. EDIT: [MSDN says that the overhead for P/Invoke is around 10-30 x86 instructions](http://msdn.microsoft.com/en-us/library/ms235282.aspx), ignoring any marshalling, which definitely puts it in the same order of magnitude as C#'s virtual method calls
Here you go: https://msdn.microsoft.com/en-us/library/ms235282.aspx That page has a lot of useful information. It says here: &gt;PInvoke has an overhead of between 10 and 30 x86 instructions per call. In addition to this fixed cost, marshaling creates additional overhead. There is no marshaling cost between blittable types that have the same representation in managed and unmanaged code. For example, there is no cost to translate between int and Int32. For better performance, have fewer PInvoke calls that marshal as much data as possible, instead of more calls that marshal less data per call.
my right ear enjoyed the start
Yup. I have several other videos where I find some for other games. 
C# can't do asm. You can make an injectable C++ dll do that. 
Using cheat engine's debug you can see lots of structures in Grim Dawn. 
I didn't think it was that advanced, was it?
What I meant was in real world practice it's not "so slow you can't use it". Read/write still happens in milliseconds. Even the AoB scan uses parallel tasks which dramatically makes scanning through pages of memory take only seconds to complete. 
Yes, please 😁
c# can do asm via some detour... http://www.exploit-monday.com/2013/04/MSILbasedShellcodeExec.html You can go even further into the unmanaged area. But i think a native injected proxy library will be more efficient.
If you use a C/C++ payload dll to host the CLR directly in the target process you can read/write the memory locations directly in C# with the unsafe keyword and Marshal.Read*. You'll get pretty comparable performance if you put the work into it. **Resources** *Hosting CLR in a native application (pair it with DllInjection):* https://github.com/dotnet/docs/blob/master/docs/core/tutorials/netcore-hosting.md *Reading/writing internal memory with C#:* https://docs.microsoft.com/en-us/dotnet/api/system.runtime.interopservices.marshal?view=netcore-2.0 *Calling C# from C++:* https://msdn.microsoft.com/en-us/library/at4fb09f(v=vs.110).aspx
Exactly what I meant. This is the only way it should be done if you're consider C#.
I'm using ReactiveUI as my MVVM framework and I create a command in the ViewModel with the loading code, and from the View I execute that command, not from ViewModel. 
Ah nice. Will look into it when i have time &gt;.&lt;
the `is null` construct is part of the new pattern matching implementation in C# 7. It is literally syntactic sugar for `== null` so I wouldn't get too hung up on it. I've been using `==` and `!=` compared to null for decades and never had a problem. You'll be fine in 99.999999% of cases. There are some _rare_ occasions where a change to `Equals(x, null)` is warranted (though preferably this would be `ReferenceEquals(x, null)`) but usually this is when doing a strict(er) comparison when overriding the `Equals` method(s) on a type (i.e. when you are implementing the bones of the `==` operator for a given type) so that should hopefully be self apparent as to why `==` is not wise here. In short: Are you implementing the equality comparison of the given type? If so, don't use `==`/`!=`. Otherwise, use `==`/`!=` e: In response to the many downvotes.. shall we have some evidence? https://sharplab.io/#v2:EYLgtghgzgLgpgJwD4AEAMACFBGA3AWACgUBmLAJgwGEMBvIjRrMlAFgwFkAKASjoaaCA9sABWcAMYwMQjAF4MAOwCuAG1UFCgwTgCcXWQEsoStaowB+DACIAntYwgbi6z1wYBjAL5EvQA==
Yes, if you are using .NET Core.
How can "this" be null? I mean, you are within the objects context, wouldnt that mean "this" can't be null? 
Thanks!
Or Mono.
CLR explicitly allows `this` to be `null` . It is C#'s attempt to prevent that by using `callvirt` instead of `call` when calling methods.
It can be in extension methods :)
It is not equal to the == or != operators, because those could've been overloaded. 
&gt; the `is null` construct is part of the new pattern matching implementation in C# 7. It is literally syntactic sugar for `== null` so I wouldn't get too hung up on it. WARNING: This is VERY wrong! When used as a conditional,`obj is null` is equivalent to `ReferenceEquals(obj, null)`, and definitely NOT `obj == null`. The rest of your advice is also questionable.
&gt; overload of the in/equality operator might cause problems if the "this" object is null That's because the equality/inequality operators must be defined as *static* members on the type: `public static bool operator ==(MyType lhs, MyType rhs)` Overriding equality comparisons for non-struct types is something I can almost never recommend as identity and equality are strongly linked in OOP languages like C#, and separating them out can cause weird behaviour in places that assume they're the same, e.g. hash maps, collections, etc. However, if `MyType` above *is* a class type, you can see that `lhs` or `rhs` could be null, and an esoteric implementation of the equality operator could do something with that value. It's definitely not worth worrying about though; I've never come across this issue except where people were abusing these operators (in which case, you usually have bigger problems anyway haha).
I don't think there's any way `this` can be null if you're programming it C#, but they may be referring to something like this: public static operator=(Foo a, Foo b) =&gt; a.Equals(b) where `Foo` is a class.
Well, advanced as doing memory writing and scanning. Bit farther than Hello World level coding.
The main performance benefit of Object.ReferenceEquals in overridding Object.Equals is that it's a relatively cheap check that can let you skip more expensive ones if you can show that the references being compared are the same actual object. Here's an example for a reference type, Foo, that implements IEquatable&lt;T&gt; and overrides Object.Equals() private static bool AreEqual(Foo x, object y) =&gt; AreEqual(x, y as Foo); return x.Equals(y as Foo); } private static bool AreEqual(Foo x, Foo y) { // same object if (ReferenceEquals(x, y)) { return true; } // x is null and (implicitly) y != x if (ReferenceEquals(null, x)) { return false; } // we now know that x is non-null, so it's safe to delegate to a type-specific overload of Equals, which you have because you implemented IEquatabale&lt;T&gt;, right? return x.Equals(y); } // Don't need to delegate out to the static methods, because this can't be null, but do need to do the type checking public override bool Equals(object o) =&gt; Equals(o as Foo); // this still can't be null, but we do need to check our parameter. public bool Equals(Foo other) { if (ReferenceEquals(null, other)) { return false; } // if other and this are the same object, we don't need to do a more detailed check if (ReferenceEquals(this, other)) { return true; } // from here on, it's custom logic based on Foo's fields and properties } public static operator=(Foo x, Foo y) =&gt; AreEqual(x, y); Here's the same idea for a struct, which elides most of the null checking, since a struct can't be null public override bool Equals(Foo other) { // All comparisons of Foo's fields and properties } // this is the only null check. public override bool Equals(object o) =&gt; o is Foo y &amp;&amp; Equals(y); public static operator=(Foo x, Foo y) =&gt; x.Equals(y); (Note that, if you're doing this, you also need to overload `!=` (overloading `==` and not `!=` is a compile error!), and you should also overload `Object.GetHashCode()`.) As far as it goes, if you're really worried about inexpert == implementations puking when they're asked to compare a null, `is null` *might* be superior, since you can't overload `is`. OTOH, I don't recall if overloads of `is` are coming as part of the next batch of pattern matching enhancements.
Note that equality operators are not used in generic collections (including hash maps). The `Equals` virtual method and `IEquatable` interface are used instead.
You can call an instance method via reflection and pass `null` to be the value of `this`.
Quite correct; but convention usually dictates that overriding the equality operators means overriding `Equals` and implementing `IEquatable` anyway. In fact, I almost always simply defer the equality operator to the overridden `Equals`. It's possible of course to have one without the other; but in my opinion that's even worse: A type where `==` does not necessarily give the same result as `Equals()`.
I once made "this" null by accident - because my custom deserialiser deserialised a delegate incorrectly, and then "this" was null when I invoked the delegate.
I'd of thought it's less "struct vs non-struct", and more "immutable vs mutable" - so long as your type is immutable, it's fine for it to override equality comparisons.
It's certainly better on immutable types vs mutable; but consider the consequences of making two class-types considered equal when their fields are equal: * Overriding equality operators conventially requires overriding `GetHashCode` too. This is surprising behaviour for reference types. Two different instances can not be used as unique dictionary keys, for example. * Places where people use `==` as a check for reference equality will now fail; forcing users of your type to be extremely meticulous about whether they use equality or reference-equality. Essentially you're trying to turn a reference type in to a value type. I hate absolutes so I'm not saying *never*, but it usually sets off alarm bells when I see it.
The 2 points you describe are actually the correct and all-around better behavior for immutable equatable types. For example, consider the built-in type `string`; it would be really weird if you could have multiple entries in a dictionary all corresponding to a `string` key with exactly the same contents, wouldn't it? Same for `==` operator.
That's pretty much a self-inflicted wound on the part of the caller. They *deserve* the NullReferenceException that comes from that.
The difference with `string` is that a string should ideally actually *be* a value type, but it can't be because strings can be huge and must be stored on the heap. The *value* of a `string` can reasonably be argued to be equal to its *identity*. That's rarely the case with reference types, and `string` really is just an uncanny exception. It's a reference type for performance reasons, not structural ones, and therefore it's made to behave as a value type in order to make up for that fact. In fact, that's the only reason I can see for implementing equality operators on reference types. If you want your type to exhibit [value semantics](https://en.wikipedia.org/wiki/Value_semantics) you should be making it a struct anyway; the exception being performance reasons (e.g. it's too big, mostly). By counter-example, two immutable `UDPSocketWrappers` could have the exact same target IP, endpoint, port, buffer size etc, but they're still unique objects. Equality and identity are distinct concepts in a language like C# (unlike, for example, C++). This is why almost every guideline tells you **not** to override `Equals` on reference types unless you have a good reason. In fact, if you have code analysis turned on in Visual Studio, you'll get this warning: https://msdn.microsoft.com/en-us/library/ms182145.aspx 
Funnily enough a few months ago I also tried to make a cheat engine copy in c#. Unfortunately I couldn't figure out how to get C# to read registers, which severely crippled my attempt. I'm glad that someone else was more successful than me at figuring out how to use C# for hacking!
I believe the running machine requires .Net to be installed, yes? Just like Java will run anywhere, but needs a JRE installed.
And the program doesn't use *any* windows specific libraries (such as pretty much anything that makes a GUI besides some parts of System.Windows.Forms in Mono), doesn't have any hardcoded assumptions about file paths etc, and is compiled for "Any CPU". That's far from a given!
This method won't consume a lot of memory, but it will still read and parse the entire file from disk without seeking. That's exactly what OP didn't want to do.
&gt; The *value* of a `string` can reasonably be argued to be equal to its *identity*. The same is true for any immutable equatable type. &gt; It's a reference type for performance reasons, not structural ones Sorry, but that is plain wrong. The `string` type is a reference type because it is a variable-length type (the other one being arrays), which you cannot easily make a value type for architectural issues, not performance ones. In fact, it's quite the opposite of what you said above: the new `System.Memory` family of APIs (which include `Span`, `Memory`, read-only versions of those etc.) is created to address precisely the problem of poor performance of strings and arrays in .NET. The `string` type is indeed a special snowflake in the world of .NET; but not for any of the reasons you mentioned. &gt; that's the only reason I can see for implementing equality operators on reference types. If you want your type to exhibit [value semantics](https://en.wikipedia.org/wiki/Value_semantics) you should be making it a struct anyway This statement contradicts your paragraph later, so I think this is the key to your misunderstanding of the problem. Value semantics (and thus equality and comparison concerns) are very different from the value/reference type distinction. To address your confusion specificly: there may be many reasons why you need to have equality operators on reference types, including technical (e.g. you want virtual dispatch), architectural (e.g. you need a common base type), designing (e.g. you need to have multiple objects refer to the same set of (possibly unmanaged) resources or concepts) etc. Examples for all of these exist in the BCL; my favorite is the `System.Type` type. &gt; unlike, for example, C++ Uhm. No. &gt; almost every guideline tells you **not** to override `Equals` on reference types By quick googling I haven't found many reputable guidelines that recommend that. &gt; if you have code analysis turned on in Visual Studio, you'll get this warning VS Code Analysis is not a guideline. Even if it was, I cannot consider it reputable (my favorite "recommendations" being the IDisposable scope warnings).
You can configure the build for [self-contained deployments](https://docs.microsoft.com/en-us/dotnet/core/deploying/#self-contained-deployments-scd) which include everything necessary (except for the native dependencies).
&gt; Sorry, but that is plain wrong. The string type is a reference type because it is a variable-length type (the other one being arrays), which you cannot easily make a value type for architectural issues, not performance ones. I'm not "plain wrong" at all; if at the time C# 1 was being implemented, they had wanted variable length stack types, they could have made them: We already have `stackalloc`. I'm not disagreeing with you that within the bounds of the language today it's impossible, but even if it *was* possible, you still wouldn't want it. The **main reason** strings are stored on the heap is probably because they copied Java, but the main reason they are in Java is because when Java was first conceived, it was *obvious that storing and copying large data on the stack was a bad idea*. Saying that I'm "plain wrong" is outright disingenuous. The fact that the language today doesn't support that theoretical implementation is secondary, made obvious by the fact that even if it *did*, you still wouldn't want it. &gt; This statement contradicts your paragraph later It really doesn't, I don't think you've read my (admittedly rushed) response properly. My point was that either you want value semantics, in which case use a **value type**; or you don't, in which case don't. The crossover comes *only* when we have to make workarounds either because structs don't support inheritance/virtual dispatch (as you mentioned) or performance reasons. &gt; In fact, it's quite the opposite of what you said above: the new System.Memory family of APIs (which include Span, Memory, read-only versions of those etc.) is created to address precisely the problem of poor performance of strings and arrays in .NET. In what way is that the opposite of what I said? `Span` and its ilk revolve around unifying memory access, reducing garbage, and increasing cache hits via reducing indirection; I don't see why you're dropping them in to this conversation about equality/identity. &gt; Uhm. No. Uhm, yes. &gt; By quick googling I haven't found many reputable guidelines that recommend that. I guess Microsoft themselves wasn't enough? &gt; The same is true for any immutable equatable type. Duh? Your entire response is a lot of misdirection frankly. And how you can say that *I* have a misunderstanding of the problem when you seem to be advocating that all immutable types should have custom equality members that equate value to identity, baffles me. I'm done here; clearly this is going nowhere.
Your instance parameter can be null, but you can't use "this" in the body of an extension method.
Enjoyed it thoroughly. I’m an advanced .Net developer and use it every day for my job and still found it fascinating. Keep it coming. Thanks!
I figured when people refer to `this` in extension methods, they're talking about the instance parameter. 
[removed]
&gt; In fact, I almost always simply defer the equality operator to the overridden Equals. This is one of the reasons why I asked the question to begin with :P
&gt; &gt; By quick googling I haven't found many reputable guidelines that recommend that. &gt; &gt; I guess Microsoft themselves wasn't enough? I think a link supporting this might be appropriate. My personal experience has been that you shouldn't need to override Equals, generally, and that reference types are usually expected to abide by reference semantics for comparisons *but* providing value equality by overriding Equals for an immutable reference type is usually harmless. MSDN, from what I can tell with an quick pass with Google, doesn't provide a strong recommendation either way, but I'd love to know if I've missed something here. 
.NET Core has zero support for any sort of GUI and even less APIs than Mono, even with .NET Standard 2.0.
&gt; When used as a conditional,obj is null is equivalent to ReferenceEquals(obj, null) Thanks for the heads up. From now on I'll use "is null" instead in cases where I only care about null/not null (because less typing lol).
Out of legit curiosity: why would one de/serialise a delegate?
&gt; My point was that either you want value semantics, in which case use a **value type**; or you don't, in which case don't. See, here's your problem again. Value semantics and value/reference types are independent of each other.
Microsoft specifically recommends starting with the lowest version that covers your needs.
&gt; Note that, if you're doing this, (...) you should also overload Object.GetHashCode(). Yeah I found an neat post on that over on Stackoverflow a while ago. Somebody investigated what'd happen if behaviour between Equals and GetHashCode mismatched while used in a Dictionary. TL;DR of that was that he'd get a run-time exception. So if I read your comment correcly, long story short: when comparing two objects, don't worry too much about preferring == / != over (Reference)Equals or vice versa.
If you are trying to micro optimize value type comparison operations (which is probably not necessary for 99% of applications) you could use System.Numeric.Vector&lt;int&gt; values and see a speed up of another 50% or so...at the cost of a lot of wasted time probably better spent in other areas of your application...
Unless you've got a specific reason to prefer ==/!=/Equals/ReferenceEquals over the alternatives, the operators should be fine, and Equals *should* behave consistently with the operators. There are specific places where you might need ReferenceEquals instead of Equals or ==, but if you're running into those a lot, you might want to check for deeper issues with how you're solving problems or your codebase is written.
&gt; You're worried about executing loops, right? Why not use Parallel.For or Parallel.Foreach I think he is talking about a game loop, which is generally a tight loop where you avoid spinning up new resources as often as possible.
I mainly use(d) ReferenceEquals to check whether something is null.
Ick. An interpolated string expression is a different type than string?
I think that's bad advice because if you always took the lowest version you would be stuck in old tech much longer.
Go [Here](https://blogs.msdn.microsoft.com/mazhou/2017/05/30/c-7-series-part-2-async-main/) and scroll down to "The Async Main Method" specifically the code sample underneath "The workaround would be synchronously wait for the operation.": public static void Main(string[] args) { BuildWebHost(args).RunAsync().GetAwaiter().GetResult(); } This was Microsoft's suggestion on how to call an async root from synchronous code: .GetAwaiter().GetResult(); If you need to await more than one top level async method it gets a bit more dicey, but you can do a Task.Run and pass in an async lambda and then do an await Task.WhenAll(...)
Except for, ya know, [I'm right](https://sharplab.io/#v2:EYLgtghgzgLgpgJwD4AEAMACFBGA3AWACgUBmLAJgwGEMBvIjRrMlAFgwFkAKASjoaaCA9sABWcAMYwMQjAF4MAOwCuAG1UFCgwTgCcXWQEsoStaowB+DACIAntYwgbi6z1wYBjAL5EvQA==). 
https://sharplab.io/#v2:EYLgtghgzgLgpgJwD4AEAMACFBGA3AWACgUBmLAJgwGEMBvIjRrMlAFgwFkAKASjoaaCA9sABWcAMYwMQjAF4MAOwCuAG1UFCgwTgCcXWQEsoStaowB+DACIAntYwgbi6z1wYBjAL5EvQA== except it is.
If you can't add an async signature to the interface, then you have a couple options off the top of my head... - If it's a smallish project, just do some async operations in the existing method. Generally you want to be as expressive as possible with your code which means the method should be DoSomethingAsync and it should return a Task instead of void. But you can do asynchronous operations in the implementation of that existing method. Just don't use the await keyword. So call async methods within it and they will return immediately. Assign their return value to a task var if you need to wait on them or check status. - Write a wrapper for the synchronous interface and make your own async API. For a larger project this might be better as it is very clear that it is asynchronous, and you can take advantage of the async/await sugar in your calling code. I would probably do this even in my own smaller projects just so I never use the method and forget it'll return before the work is done.
&gt;I effectively want to do some file io in that method and not have it lock everything up. If by "lock everything up" you mean blocking the caller until the method returns, and if the file IO must be completed before the method returns, you simply can't. Either the method is asynchronous or synchronous, you can't have both. The practical options you have are: 1. If you can change the interface and the code that uses it, modify the signature of `MethodA` to be async or add a second async method/interface that must be used for this implementation (preferred, if possible) 2. If you can change the code that calls the interface but not the definition of the interface, make the code within the interface synchronous and start the call to the interface in a parallel thread 3. If the code calling `MethodA` does not rely on the async work to be completed, start the async work in `MethodA` but return from the method before it is finished (discouraged, very fragile and error prone)
oh :(
And that should work. I would prefer `x == null` in most code, though, just because it seems to be what people expect.
Is it a string expression or a new type that is implicitly convertible into a string? I really should look into it.
I've done some thing like this a few years ago. I used system center orchestrator that called a web service where I wrote all the smo methods to do my tasks. 
Cool, thanks - I'll have a look at that. I've heard of it but never touched it. Not sure what the capabilities are yet.
I think they dropped system center orchestrator for Azure automation hybrid run book stuff now as it has been like 4 years or so. The sql smo is nice and easy to program with 
Technically s/he can make the implementation of that existing interface asynchronous, just not in a way that the await keyword can be used with it in the calling code. But it's not very nice to make code asynchronous when it is not obvious in the method signature, either return a Task or call the method "BeginDoWork" so users of the implementation know it's intentions.
That would be the third option I mentioned, yes. But there would be no way to express completion of the work or exceptions through the existing interface, which is why this is generally a very bad idea and could break existing code that expects the work to be completed as soon as the interface method returns.
Bingo. If it's a small project, there's one developer, and it absolutely doesn't matter whether the work is completed, then okay I guess. But I'd rather just move the async work back to the calling code rather than write bad code in the implementation of the interface.
You can make websites with it. Which is kinda like a GUI. 
Actually, you can use Xamarin Forms, but that doesn't yet have Linux support.
Just replace your is null with ReferenceEquals and you see that the IL is exactly the same. 
That isn't how .NET Standard works. You can reference a .NET Standard library in a .NET Core 2.0 or .NET Framework 4.6.2 app and it will use the methods implemented in the referencing projects specified target framework (i.e. they will be executed at runtime by .NET Core 2.0 or .NET Framework 4.6.2).
Nothing built-in (in the BCL), but there are third-party frameworks in various stages of development / usability.
[FormattableString](https://msdn.microsoft.com/en-us/library/dn906196)...huh. Didn't know that existed. I looked in the check-in that added the support to EF Core and found it pretty quick. I don't remember hearing the type before though. It must be implicitly convertable to string or something.
So I can use .NET Standard 1.x and target all versions of .net core and framework? Cool I thought they were closely related. Like .NET Standard 2 with .NET core 2. In that case there isn't much benefit to using a later version unless you need the API of a later .NET Standard. I refute my points.
I really don't remember any more, sorry. I wasn't trying to serialize a delegate specifically, but a large object graph which must have included a lambda. I suspect it was something you can put down to technical debt.
Thanks
You can make a library in .NET 1.0 Standard and then reference it from (almost all) versions of .NET Core/Framework, Mono, Xamarin, and UWP projects unchanged (assuming .NET Standard 1.0 has the APIs you need). .NET Standard is pretty cool. Basically there is no reason to make a c# class library project in anything except .NET Standard.
Thanks for all the input guys, really appreciated. I'm gonna get my head back into the code tomorrow with all your comments on my mind and see where it takes me 
Simple example var result1 = await someAsyncMethod1(args); var result2 = await someAsyncMethod2(args); Might take significantly longer to run than: var result1Task = someAsyncMethod1(args); var result2Task = someAsyncMethod2(args); await Task.WhenAll(result1Task, result2Task); var result1 = result1Task.Result; var result2 = result2Task.Result; If you await two tasks at a time, then they both run asynchronously at the same time, which is better in almost any case where they don't depend on each other or compete for resources.
yes dot net core was released on 2016 itself. Making it possible now.
Or if you plan to later return the IEnumerable and it was generated using yields or lazy evaluation using resources that will no longer be available after the return (e.g. EF Linq queries with lazy navigation properties can cause this pretty easily).
I usually worry about it for SqlDataReader.ReadAsync. If I don't use it, then when the network drops out I might have x number of readers trying to tie up all of my thread pool threads while they time out locking up the web application. If I do use it, it seems like it could have significant overhead when reading thousands or millions of rows.
Not really, that way of thinking is why we are getting Electron everywhere pushing our fans into their limits.
I see where you're coming from, but I also think this is where personal preference comes into play.
Yes, so as long as you’re coding in C#, it can’t. I guess it’s *technically* an issue if a non-C# CLR program calls your methods. I don’t think anyone ever considers that, though. 
:p. Yeah, I agree. You can also do it from IL. There are several things you can do from IL that C# “doesn’t expect”. 
Yeah, which is actually confusing sometimes.
Gotcha. Although you did just give me (another...) weekend project 😛
If that's the case, then his best bet is definitely creating a Thread(), having it while() for the life of the thread, and using a blocking event like AutoResetEvent that other threads can reset so it doesn't run nonstop: http://dotnetpattern.com/threading-autoresetevent /u/sebasjammer
It’s not “very wrong”. Unless someone has a faulty implementation of ==, it will work the same. I bet it will in 99.99..% cases. It’s just incorrect, no need to exaggerate things. It actually calls `Equals` on `Object` non-virtually (which is indeed equivalent to `ReferenceEquals`. It’s actually surprising to me that it doesn’t just compare with null directly using IL `ceq`, which is what `(object)x == null` does. I guess the jitter turns it into the same, though, if it’s smart. Edit: it seems to depend on the exact compiler version.
I personally use (or used to, at least, before C# 7) `(object)x == null`.
It would seem so, but checking the generated IL, it seems you aren’t. What it does is issue a non-virtual call to Object.Equals. There is no exact way to achieve this in C#. Edit: depending on the exact compiler version. The reason you are seeing `==` is because that operator isn’t overloaded in your example,
Still too much to type out XD
oh I see! thanks :)
https://sharplab.io/#v2:EYLgtghgzgLgpgJwDQxASwDYB8ACAGAAhwEYBuAWACgcBmIgJgIGECBvKgzounAFgICyACgCUbDl0kB7YACs4AYxgEpBALwEAdgFcMGCpUmSSATiEAlOADNEcTQrgBRAI7aIGKEKlItujGIB+AgAiAE9gghAQzWCRAyMuUy91DR09AiCwiKjgmLiJBKTVNChfdMzwyOjY+K4AXyo6oA=
https://sharplab.io/#v2:EYLgtghgzgLgpgJwDQxASwDYB8ACAGAAhwEYBuAWACgcBmIgJgIGECBvKgzounAFgICyACgCUbDl0kB7YACs4AYxgEpBALwEAdgFcMGCpUmSSATiEAlOADNEcTQrgBRAI7aIGKEKlItujGIB+AgAiAE9gghAQzWCRAyMuUy91DR09AiCwiKjgmLiJBKTVNChfdMzwyOjY+K4AXyo6oA=
From CLR perspective there are no "object contexts", all methods are "static" and take the instance as parameter.
https://github.com/AvaloniaUI/Avalonia
You can also run malformed IL (from Reflection.Emit, for example), but that's also self-inflicted pain. 
Yes, NUnit has a [constraint-based syntax](https://github.com/nunit/docs/wiki/Assertions) as well: Assert.That(actual, Is.EqualTo(expected));
Thanks! That's great :)
If possible you could use FluentAssertion or Shouldly too. I find it more readable plus it's kind of nice to not have your unit tests assertions tied to the test framework in my opinion
yes if you're using Mono or .NET core, if you need GUI use GTK# http://www.mono-project.com/docs/gui/gtksharp/
WebAssembly is around the corner too http://www.mono-project.com/news/2017/08/09/hello-webassembly/
Sure, it's entirely possible to write new C# graphical programs that work on Mac/Linux (I wrote one: store.steampowered.com/app/305760/Redirection/), but OP was asking about exisiting programs in general.
That's not the point of Core. 
If you use Newtonsoft's library, you can deserialise JSON into an object by doing: JsonConvert.DeserializeObject(json); If you want to deserialise into a specific type: JsonConvert.DeserializeObject&lt;CustomType&gt;(json): I'm pretty sure there's an xml alternative. Have you checked the overloads on that ancient library? I'd go to JSON if you can.
Electron is only really a problem because Chrome is a bloated piece of shit. There's no reason you couldn't implement the same idea much more efficiently. I'm quite interested in what could be done with the new Gecko engine after servo is finished. There's some really serious performance improvements so far. Even then it's kind of overblown. You've got a lot of comparing pure text editors against things that are essentially light weight IDEs.
https://sharplab.io/#v2:EYLgtghgzgLgpgJwDQxASwDYB8ACAGAAhwEYBuAWACgcBmIgJgIGECBvKgzounAFgICyACgCUbDl0kAVAJ4AHOAQD2BALwEAdgFcMGCpUmSSATiEAlOADNEcDQGM4AUQCOWiBihClSTToxiAfgIAIhlgghAQjWCRfUMuEy81dW1dAiDQ8Mjg6NiJeMSVNChfNIywiKiYuK4AXypaoA== Obviously there is no difference when comparing types that do not have an overloaded equality operator, but `is null` and `== null` do behave differently on types that do.
Couldn't string have been a struct{char[] arr,int length}? But then I guess that's one additional field to copy.
I assume you're developing the server side as well? In my experience a 500 error from the server means there's an unhandled exception on that side. To view the exception info from IIS, use the Windows Event Viewer and look in the Application log for errors from ASP.NET. There's usually 2-3 errors in a row for each exception, each error showing a different part of the exception info. One of them should have the call stack and exception type. 
Yes, I'm also developing the server side. Thanks for the suggestion. I haven't thought of checking the Event Viewer for some reason. Still, there's no ASP.NET folder in there. Did you mean `Applications/Microsoft/Windows/IIS-Logging`? If so, this one is empty for some reason on my server.
No, Windows logs then application. It uses the regular application log to record the errors from iis. 
[I think I'm missing something here...](http://imgur.com/a/ODTHA) Am I doing something wrong? Might be a bit of a stupid question, but how do I display all `Application` logs? 😅 Edit: ... oh. Yeah, it's probably the late hour or something.
On the left hand side (the tree) expand "windows logs". There is an entry in there named "application". Click on it and looking for events where the source is .net or asp.net. Easiest to sort descending by time, run the app until it fails and then refresh the list. The errors will be at the top.
Very nice game! What kind of stuff is it built with?
Yep, I managed to figure it out after staring at it for a few seconds :D Thanks a lot, turns out I haven't set the primary key to `AUTO_INCREMENT` on one of the tables in my actual database. Only on the local one for testing purposes. I feel even more stupid now. Still, thanks a lot for the help!
What's nice about keeping them separate? I've always considered them part of the same package deal.
&gt; Avalonia is now in alpha. Nothing that I could advise business to use on production apps.
If the point is doing web servers, then there are better options, currently. The majority of ADO.NET drivers critical to us doesn't even work yet with Core.
The exception is echoing your source code? 
That's ok but my question was about : if I do such a thing will it keep on running on the best core available as the os can decide to switch the core at any time? The answer seems to be yes but I want to do some tests once I have time. 
Thanks!
What’s wrong with Stopwatch? It’s the most low impact and precise timer available. 
Thanks!
Hardly "ultimate". It doesn't explain anything about how async/await actually works, when you'd want to use it (and when not), what the pitfalls are, etc.
I find fluent assertions more complicated than xUnit type ones. They tend to be overly verbose, making the intention harder to work out. Saying your unit tests should be separated from the test framework is like saying your regular code should be too... 
Actually nothing, I take that back... Years ago a professor told me not to use it like that, but looking into it it seems they were just plain wrong.
https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/compiler-messages/cs0165
string b was declared.
If he renamed it "A short introduction to..." then it would actually be quite reasonable. It's formatted nicely at least. That said, if you're into the realm of giving marks for hand writing you're not really looking at a stellar bit of work. 
Could you recommend a site which has a more in-depth resource (ultimate) on said topic.
You have b declared but not initialized, which is why you get this error. The first time your code hits the else-block and tries to append to b it won't be able to since b is null. Try declaring b like this: string b = ""; or string b = string.empty; 
string b; b = b + "hi"; The error says that you are using an unnasigned variable which is true in this case. You are trying to add "hi" to variable b, but b has no value assigned which causes an error. It is the same thing with b += "hi"; To fix the error you could just assign an empty string to b string b = "";
1) You declare b, but *don't assign an initial value* which means it has the default value for strings which is null. 2) The compiler message says use of **unassigned** local variable 3) `x += 1` is identical to `x = x + 1` Given that, can you see what the problem is with the code you posted? 
thanks worked
thanks
[removed]
I found Stephen Cleary's blog posts on async/await to be very informative. [Link](https://blog.stephencleary.com/2012/02/async-and-await.html)
What was true reviewers reasoning for the code smell. Was pit ersonal preference or a legitimate reoccurring issue that you have in your code base? Looks fine to me, yeah you can declare the inner variable but really that adds minor readibility unless the code is buggy and you'd be expecting to debug into it frequently.
Removed: Spam Article has been posted a couple places around the Internet (all I assume by you, the author). New Reddit account that only posts these two articles. Please familiarize yourself with [Reddt's self-promotion guidelines](https://www.reddit.com/wiki/selfpromotion).
Removed: Spam Article has been posted a couple places around the Internet (all I assume by you, the author). New Reddit account that only posts these two articles. Please familiarize yourself with [Reddt's self-promotion guidelines](https://www.reddit.com/wiki/selfpromotion).
It may be self promotion, but I liked the article.
+1 for Shouldly
You could put it all in a .resx file. That way you can easily change bits of text without going through the code. Also, it makes things like translation to other languages possible. https://msdn.microsoft.com/en-us/library/ekyft91f(v=vs.90).aspx As far as "format," it's a string. What you do with the string is up to you (style wise.) or, if it's a lot of dialog that needs to be sorted and searched, you may just drop it into a database like sql (this isn't free - there is a cost to going to a database, though it's acceptable in most instances.)
If you're writing a chronological dialog and want to order it that way you'd want a [tree structure](https://en.wikipedia.org/wiki/Dialog_tree) and like /u/rfinger1337 mentioned: a database is a good place to keep structured data like this.
I can't say I agree, nor do I use ADO.NET. Everything I've done in the past 5 years has utilized EF. 
&gt;Can a Mac/Linux user run a program (coded with c#)not using a any extra program? Remember, C# is just a language. .NET is the most common framework to interpret C# code. .NET is like a man in the middle, interpreting your code on the fly directly to the operating system. (look up CLR) And while there is nothing stopping you from compiling C# to machine code, like Xamarin does, for the most part when you build an application to run on Windows/Mac/Linux, if you are using .NET, you will need that "extra program" to assist you to deploy your project. You should also define your project type. For example, You will not be able to deploy a Winforms application to Mac. 
Be careful copying from Word. Word will convert double quotes to smart quotes. Just make sure you have consistency that all quotes are "smart" or just plain old double quotes.
Agreed, notepad++ would be a better choice for writing text that will be later pulled into code.
Thanks
That's the whole point of .Net core, to get around that. 
In addition to the rest of the answers here, you should most likely be using StringBuilder if you're going to do a lot of string concatenation.
Just out of curiosity, is the game dialog you're writing at work your job, or for a personal project you're learning C# for?
What about the ReportViewer from MS? It is free, in old VS versions it was incluided with all the controls, now you can install it using nuget. I think that it is not open source. I XP supports .net 4.0
Thanks! I wrote the game in C#, using SDL2 for windowing and input, OpenGL for graphics and OpenAL for sound. On Windows I just ship the .NET EXE, and on Mac and and Linux I ship the game with MonoKickstart, a small standalone distribution of Mono which means the game can run without Mono having to be installed on the system.
Thanks, I'll have a look into .resx. How much text would necessitate a database?
The latter, how come?
Thanks, do you have any suggestions as to where I'd look to find information on databases for this kind of purpose?
Pretty much any DB would do because they all have the same core features (tables, records, SQL language). If you want a simple database next to where your program.exe is going to be then [Sqlite](https://www.sqlite.org/). Other more featured databases like PostgreSQL, MsSQL and MySQL are better suited for dedicated servers because they are bulky and/or tedious to deliver together with your program.
So typically the only difference in nunit/xunit/mstest/fixie or whatever is how you decorate the test. If you want to switch out a test framework for another you can do it with some creative find and replace. Obviously a few things that will need to be adjusted by hand but not that bad. Now this isn't like "wrap EF in case you want to switch ORMs" exercise that we all know would never happen. Lots of reasons I've switched test frameworks. I've gone from mbUnit to nUnit to xUnit in one project alone. What gets tricky is the assertions. Those are more than markers helping a tool know to run. There's very important logic tied to those. A find and replace might work if things are simple but even if it does pass can you ensure that it's passing for a valid reason? Plus the dedicated assertion libraries are just better in general
At least in Denmark, if you're using company resources (eg. being paid or using their computer) for a personal project, the company can claim the rights. So be careful :)
In the US unfortunately it depends on the state. California is close to having great workers rights, while other states much less so. 
Double check your employer's policies on personal projects. If you work on anything for a personal project while at work and/or using resources your employer provides (computer, IDE, etc.), they could claim ownership of your project. Granted it only really matters if you plan to release the project commercially, so if you're just doing it for fun it's likely not a concern, but if the plan is to make money from it, you really need to double check the policies of your employer and the state in which you reside. Same applies even if you're not in the US.
EF requires ADO.NET drivers to work, so it is impossible to use EF without them. So I guess you just use SQL Server.
So I spent the majority of the past few years in a role that involved doing heavy code reviews and tracking down the most difficult issues. Which means I read far more code than I had to physically write. Take for example something like this. Assert.Equals(customers.Count, 4); Easy enough to read. But if that stops failing our build server is going to have an error message saying something like "expected 4, received 3". Not the best message available. Writing the letters out for a test is by far the easiest part of writing unit tests. Coming up with good assertions and more writing them in a way that when they fail in the future it is crystal clear the intention of the original author is obvious is the hard part and I feel that properly using FluentAssertions or Shouldly leads you to that behavior better than the built in assertion libraries. My other reply I wrote about why having a different assertion library from you test framework makes sense. Sure right now people would never think there's a reason not to xUnit forever, but I've converted plenty of MSTest and nUnit test suites that were written by people that never would have thought Microsoft would practically abandon their test library or that nUnit wouldn't be the most modern suite.
As soon as you start to make a decision tree or weighted dialogues based on external values (besides clicking next) then a database would be more suitable than a resx. 
I would consider taking inspiration from [ChoiceScript](https://www.choiceofgames.com/make-your-own-games/choicescript-intro/), a language for writing choice-based interactive fiction. With that, all the dialogue is nicely in one place in a text file. I think editing that is going to be much easier that changing a database, a resx file, or something like that. Though I think you would have to write your own parser.
&gt; Pretty much any DB would do because they all have the same core features (tables, records, SQL language). Non-relational databases exist too and some of them are pretty popular nowadays.
Declared but not *initialized*.
/r/gamedev c# won't have much bearing on this kind of thing really
http://www.chatmapper.com
If you release the pressure as a hobby, please do it in the restroom.
Blarg, gotta love autocorrect and not proofreading from the mobile app. :P
Start learning how to structure a database. That sort of information should never be hard coded into an app. Once you have the tables setup use an ORM like EF to access it. Drive it all with your program. Pretty straightforward. 
[removed]
EF core has MySQL support. I'm sure there's other databases as well. 
I said "The majority of ADO.NET drivers critical to us". Which means Oracle, DB 2 and friends, to put it more clearly. Actual enterprise level RDMS.
I've been working on a similar task and have started designing an XML scheme for all my text needs. Whether it's the best way forward or not, I couldn't tell you, but C# does have a lot of built in support for XML which influenced my decision. 
I prefer notepad++ for opening most documents. 
What are some applications for recursion? Windows explorer. The structure of the folders in windows explorer is an example of recursion. You've got folders within folders, within folders etc.
Recursion can be an elegant solution to solving a number of problems. It's very natural for many operations involving trees and linked lists, for instance.
over the years I've used recursion in programming both games as well as in business programming. A couple examples, in gaming many path finding algorithms are recursive, in business I used recursion on a compound interest calc where I had to certain to less than a penny as the numbers moved. net of all things, when recursion is needed its usually fairly obvious.
It isn't like an infinite loop, since it ends. And another great example that can be solved with recursion is the Fibonacci series: F(n)=F(n-1)+F(n-2). In fact, pretty much any function that's either an iterated function (that is, f^(n)(x)=f^(n-1)(x) ) or defined by a recursion relation ( x(n)=f(x(n-1), x(n-2), ... , x(n-k)) ) can use recursion to solve it.
yeah, me too. I almost never use word anymore.
/u/Tactical_Insertion69 is right, a folder is a great example of recursion of code. Here is a quick example from [Stackoverflow](https://stackoverflow.com/questions/929276/how-to-recursively-list-all-the-files-in-a-directory-in-c) (not my code) Notice that the function takes in a string, then gets all the sub directories for that string, and for each sub directory it calls itself. Pretty easy when you see it (I'm very visual, so i like to see the idea in use) static void DirSearch(string sDir) { try { foreach (string d in Directory.GetDirectories(sDir)) { foreach (string f in Directory.GetFiles(d)) { Console.WriteLine(f); } DirSearch(d); } } catch (System.Exception excpt) { Console.WriteLine(excpt.Message); } }
Maybe not the best advice out there but if you're starting to want to store information and then use it later I would recommend a good ol database. You CAN do it with multiple dictionaries for sure. But it might get a little hectic to code and maintain. But then again how many previous hands are we talking about here? 10? 100? 10k? The larger it is I would suggest using a database. Or if you're only going to keep something like 100 or 1000 you could do something like a csv and I don't think performance would be that bad. The problem with using just dictionaries is you would have something like 5 of them and you'd probably end up calling all 5 whenever you wanted info about any one previous hand. You could create an new object with all the data in it and store it in a list of hands I guess but then the question of scale comes up again. As a side note: you could expand the "using previous results to use for future hands" as a neural network and try messing with that. 
&gt; Is it okay to sort of liken it to an infinite loop, No. Definitely not. A computer can parse through a loop for as long as needed, and it never needs to take more memory than whatever it's working on at the moment. A recursive function takes up a hint more memory with every level of recursion, until the program runs out of memory and crashes. And maybe takes the computer down with it if the compiler isn't careful. &gt; and what are some ways to use recursion. You can do all kinds of stuff with it, if you plan it carefully. Ask Ms. Google.
First, apply recursion
Whoa thats super cool and practical. 
cmd and powershell aren't as daunting as bash, and powershell aliases a lot of stuff so your linux background should give you a good start. Powershell also interoperates with dotnet libraries pretty easily, so it's more an enhancement than anything else. Neither cmd nor powershell are enough of a thing that I'd change languages to avoid it. And if I was moving to the Java platform, I'd jump straight to Kotlin at this point. 
I have been a C# developer for almost 15 years and other than a few really simple batch files (i.e. .BAT) I have never had to write any scripts. And those batch files were just simple utilities to copy files or whatever; nothing sophisticated. Everything I have ever needed to do was doable in the IDE.
&gt; &gt; Is it okay to sort of liken it to an infinite loop, &gt; &gt; No. Definitely not. Might be worth noting that is is sort of a compiler detail. A tail recursive call is trivially refactorable to a simple loop, and compilers in many languages make exactly this sort of optimization. (It mystifies me, actually, that the C# compiler does *not* optimize tail calls this way, as it's not a CLR limitation.)
You don't need scripting at all to develop on Windows. The IDEs and GUI based tools are fully complete.
That's true only if you can't use [tail call optimization](https://blogs.msdn.microsoft.com/chrsmith/2008/08/07/understanding-tail-recursion/). C# doesn't support it, but the CLR does.
The x += y operator is syntactical sugar for x = x + y. It is not just an assignment, its a mathematical operation (or in this case a string operation) combined with an assignment. To use the + operator both sides of it need to have a value. b is null in your case and so the + operator can't do its job. tl;dr: Assign your b a string.Empty, because otherwise it can't be extended and remains null.
My idea was to build about 10-15 or do different dictionaries to store values and was hoping to go into the millions, which is why I wondered if it was the way to go. I remember reading some things about not wanting to do that, so I was thinking about learning how to work with MySQL or something. I've never worked with anything else, and using MySQL with Visual Studio seemed kind of overwhelming to me. I wouldn't know where to start.
Strange how you're not proficient in CMD and Powershell as a C# developer. Don't get me wrong, there's nothing wrong about that; but its odd when C# is considered way more advanced being an object oriented language and the former being basic scripting languages :P
It seems funny on the surface, I agree. My problem with cmd or PS is syntax. It is so incredibly bizarre to me, I have zero interest in working with it beyond the basics. I'll write an application in C# to perform some kind of maintenance (maybe delete all folders with a specific pattern or something) when I know it COULD be done easily in PS. But no thanks. I already have VS installed and probably running at any given time, so I'll write it there.
Short answer: no. Longer: if you learn how to program effectively in c#, you should not fear CMD shells.
I've never had to use powershell as a programmer. It doesn't hurt to know it but it's not required. The command shell is not required but knowing it is incredibly useful. Programming often involves accessing the file system (getting directories, reading files, etc) and not understanding how to use the command shell is like owning a boat and not knowing how to swim. Neither of them is required but both could be useful to know as a developer, regardless of what language you end up primarily using.
No, bit power shell is super powerful and if you can program you can learn it easy. I avoided it for awhile and now I can't live without it.
The first time I realized the power and the beauty of recursion was when I tried to implement an evaluator for simple mathematical expressions. You just have to apply divide-and-conquer recursively. For example, have a function "eval" that takes an expression like "2+5*3-4/2" as input and should return the correct value. You could come up with a clever solution of nested loops, branches and data structures. Or you could try recursion: * Look for the first + operator in the string. If you find one, return eval(&lt;string-before-operator&gt;) + eval(&lt;string-after-operator&gt;). * If you don't find a +, do the same with - (then *, then /) * If none of the above applied, parse the string as number and return it. Boom. You now have a very simple evaluator. I was astonished that I didn't need to invest more logic onto it. Just split the string at the right position and handle each part again calling yourself in recursion. Note that this is very naive approach and prone to many errors that might occur. But I hope you get the idea, because this was the revelation for me that made me go from "pff, recursion is boring, why should I use it" to "wow, some problems can be solved that easy? That is amazing!" almost 20 years ago.
Are you trying to create some kind of AI that would learn how to bet based on history? If you're going to store millions of hands of data, you're going to want to compress that data as much as possible. You could store just the points of learning, such as (3rd hand, 15 cards used so far, deal hand total 12, dealt a queen, busted: 2051 times) Then you could keep that in memory and update the counts every time it plays another round. Based on the counts, the program would decide when to hold or take another card.
You are executing the function in line two Meaning you are executing the function before you add it to the list.
`async` methods always start the moment you call them (`MyMethodAsync()`). Whether you await the task it returns, put it into a list or even completely ignore it makes no difference to the method after it's called.
In my experience, Powershell is just a very practical REPL that has been wrapped in a straight jacket rendering it useless.
I would build a model, lookup domain driven design. You have an aggregate root and that is the only way to access the internals of that model from the outside. Also regardless of tech, if it's a DB or memory, if you get your collections and keys wrong for your queries and inserts you're going to have a bad time. I like domain models as I can literally build my tests as I build the model and get a feel for how the model will be used. I like to seperate persistence from the code model. Others don't, and that is fine...
Yah.. you know I guess I knew that, I think ... (: I've experimented with various grub boot params and have booted to VESA. So that being said - now that I've asked the initial wrong question .. thoughts on taking advantage of VESA mode and doing frame buffer or something to that effect from C# ?
This was very helpful So memory is allocated when using recursion compared to a loop.
I see. Sounds like recursion is important. 
Still a little over my head but will try to analyze. 
recursion didn't seem useful to me until I took a data structures course
Ouch. Yes thanks. Forgot about it is actually calling the method and returning Task result of void.
Thanks, will keep that in mind.
That was my original idea, but then I wanted the option to recall a certain scenarios to see how the hand played out and give each option a weight until one option was clearly the better than the others. The only way I could think that would work to search the player's history and find all matching scenarios, then make a decision.
I'm trying to be careful. The way I have everything right now is that each hand stores a few different values to a struct while the hand is played (Done in the blackjack game). Once complete, the game then transfers that struct to the class that stores all the values "StoreValues(Values)" which then adds to the handCount, that's it. The class that stores all the values also has a lot of private methods that figure out what the best move is for the game, and returns with a single string with a "GetMove()" method that's called by the blackjack game whenever the player has to make a decision. So there's only one way in and out, I suppose.
So storevalue can update the models that might hold various statistics such as the number of X cards played etc. or likelihood of X card being drawn on the next turn. You can have methods on the aggregate root that can give you these statistics and other information in an optimise read way. Then a seperate class that actually does the calculation for the next move using that model. Remember you still want some type of single responsibility in your classes to not make your code turn to spaghetti.
I spent eight months or more writing deployment scripts in it. It has uses, but as a language it tends to encourage some really hacky ideas. 
Makes sense. I guess I'll work on separating certain things. I had it all in one big class, but I guess there's no reason for a database to make any game calculations.
Thanks. When I was working with C#, I was using Bash and Linux' utilities under either Cygwin or Window's Linux Subsystem just for myself. Is it bad to use Bash, when writing scripts for coworkers, when developing C# backend or web applications?
Do you think c# ever will? 
A man can hope 😀.
&gt; To work as a C# developer, is it often needed or better to use cmd or powershell? Needed depends on where you're working. Many, many places will have tools that are implemented only via the command line. In my experience it's uncommon for a commercial project to be entirely buildable, testable, and deployable through an IDE. But not unheard of. Better? If you've used bash for productivity you'll know know powerful it is. Even if you don't have to use cmd or powershell on the job, they can make your life much easier. In my last gig we could technically do everything through GUI tools. Visual Studio handled a lot of that for us. However there were many times where I was able to do stuff much more quickly via the command line. Sometimes a quick script can save you a lot of manual labor. The command line is also a lot easier to use for automation. When I started there was a process my boss spent 20 minutes every week to do with GUI tools. It was quick and easy to script it via PowerShell, paying big dividends and eliminating the possibility of a human mistake really breaking things. &gt; Without knowing much about cmd or powershell, will that affect looking for job opportunies in C# and working as a C# developer? I've never been asked about it in an interview, but I could see it coming up. Keep in mind it never hurts to know more, particularly with respect to tools you can use in the practice of your craft. 
You don't HAVE to know it. Plenty of developers go without knowing it. But when you need it... Man, is it useful.
Which means using it results in a `NullReferenceException`. Hence the warning.
Yep, that's why I pointed it out.
No
Not if you're using Windows. I've been using Microsoft Visual Studio since the 2010 release and it just keeps getting better and better. There's now great github support which takes care of all the git command line elements and to compile C# code you just need to press a "Build" button. I've never had to use any kind of command line scripting. Of course this is only from Windows, I'm not sure about Mac or Linux. I believe there's an official Microsoft Visual Studio port on Mac which looks pretty good, I believe it has all the features of the Windows version but I have absolutely no idea for Linux.
If you don't use Windows you don't have cmd or powershell.
DB2 already is supported. Oracle is coming by the end of 2017. 
I think the difference, sometimes, is that recursion can involve the stack growing each time a recursive call is made to itself; whereas a loop is just a fancy goto. In some cases, your application could loop forever; but if making recursive calls would eventually run out of memory. But it would depend on what you application is doing. 
A simple web crawler following hyperlinks can be recursive. However, in my own application, I use a Queue&lt;T&gt;, and have links added/removed as they are discovered and processed. Many other types of tree-like structures can be processed in some way by using recursive algorithms.
No, you dont need to learn cmd or powershell to develop C# applications 
Probably. But it shouldn't take you long to pick up enough powershell to be dangerous, especially if you leverage dotnet libraries. Once you figure out how to do something in dotnet, getting powershell to do the same thing is generally dead easy - just load the same library, and do the same thing. I had a coworker with zero ps experience who had a script e-mailing regression test results with charts to managers in less than a week. You don't need to be an expert in powershell on day one, you just need to be able to get it to do basic stuff, and go from there. Fake it 'til you make it. :) 
I recommend learning powershell if you ever have to do any server administration. It gets real tedious rdping into some server all the time.
It was bizarre to me, but I had to pick it up recently pretty seriously! It's good at doing what it does. It's handy to do administration/ops type tasks like copying files around and manipulating services, most of which can be done with a single line. It's great at manipulating XML config files. The default case insensitivity with its matching functionality and wildcards come in handy. I think it's #1 virtue from a deployment pipeline perspective is that it doesn't require any compilation. You don't have to build a whole separate code pipeline. If you are manipulating the files of a web application, and you just need to get files in the right place, you can just inject the scripts into any folder structure you want. You just commit something into a repo, and it's functional right away. It can technically do anything that C# can, and call upon C# binaries, when you need some more complicated or more performant code.
Yep. There is value in that powershell is available on almost every Windows system in operation. It's almost like python for Microsoft shops (available everywhere, not compiled). Except Python syntax doesn't make me angry. I've written a few things in powershell and I'm sure if I didn't have significantly more experience with C# I would use it more. But like I said, I hate the syntax. It's ugly and reading it makes me hate programming. So I just won't, unless I have to!
Considering that you can write .NET Core (2) on Linux or Mac with bash... no. Also, even on Linux, I've never really had to know bash. Just the `dotnet ...` commands.
Do you do your own deployment? If so, what CD/CI?
If you develop Web app you may need scripts to deploy and manage your servers automatically. 
Nope, as a line developer you won't really need to know any scripting. I've been writing c# since 2002 and even deploying to lots of servers I've typically used other tools or xcopy deployment to move code up.
https://github.com/mirror/processhacker/blob/master/misc/bugcheck/BugCheck/Win32/API/Functions.cs [DllImport("ntdll.dll", SetLastError = true)] public static extern int ZwQueryInformationThread(int ThreadHandle, THREAD_INFORMATION_CLASS ThreadInformationClass, out long ThreadInformation, int ThreadInformationLength, out int ReturnLength);
TY!
[Next Step](https://www.reddit.com/r/csharp/comments/6zawa7/how_do_i_apply_recursion/dmtz03a/)
Keep in mind that when you call a method, it runs and returns a result. Your not making a list of methods. Your making a list of Tasks. Interestingly, async methods return Tasks when they are run, which is strange on the surface. This is universal behavior and would occur regardless if the method was async. It just so happens you are trying to make a list of the return type of your method, so the compiler says that it's valid. And it is. Think of it as if you were trying to make a list of integers and did .Add(Math.Round(5.5));. The method would return 6 and add it to your list. It wouldn't store the method call itself. Same with async, though harder to see. 
Json as well if you don't need the structure of XML.
Generally, Task represents asynchronous operation that is already running. While it is possible to create a Task that is was not yet started, it is heavily discouraged. And all framework and libraries follow convention of immediately starting the Task it creates. This can be done using the Task constructor (like you are doing), but it's use is discouraged. So you should always assume that Task you are given is either running or already finished. Also, even though you marked your task async, it is not really asynchronous. If you call this method, it will run normally until it hits first await, then it becomes asyncrohous and returns. Which in your case means the method prints Hi and then returns finished Task. If you wanted to force it to return immediately and continue asynchorously, you should put await Task.Yield() as first line in your code. This is basically "no operation" that just serves to break the synchronous code.
Check out the unity3d store. I'm sure there are alot of great options there already coded. But really as a dataset, any db, XML, or json would be easy to read in, manipulate, and then spit back out to just about any format you want. At long as you choose one of those formats, it shouldn't be too hard to make an automated converter to what ever you need next. I'd avoid Word.
Well is is for scripting, not for writing applications in.
I think there are a few different questions here: - Do I need to be able to use the command line? I think the answer is yes; you don't have to excel at it, but some level of proficiency with command line tools (eg. the package management console) is probably mandatory. If you know bash / python, you'll be fine. A lot of .net core tooling is also cli based. You can effectively have a 'bash' on windows using git-bash or msys and it'll be exactly what you're already used to in those rare cases you need it. - Do I need to know / use poweshell? Probably not unless you plan to work in build automation or devops. - Do I need to know / use cmd? No. - What about java... Java tooling is significantly more cli centric; you won't have to learn powershell, but you will have to use the console *a lot*.
I don't know what cd/ci means but I primarily do web apps and I just publish them. 
Step 1) Learn all the great way to use recursion and how it can solve so many problems easily.. Step 2) stop using it so much. Learn when there are better non-recursive solutions.. always be aware that recursion can blow up stack space and take a good look at the parameter list. Every 'loop' through recursion will make copies of any structs you pass there and copies of 'pointers' for everything else.
Bash being a more powerful tool doesn't really make it more daunting. C# is more feature rich than Java but that doesn't make it any harder to learn or use. The default Linux command prompt is an extension of Bash which is what makes Bash so powerful. It's a way to automate OS commands, unlike PowerShell which is its own thing. 
I use power shell all the freaking time. One use is for custom build tasks since I handle my team's builds. Another is for automating every annoying thing I have to do such as reverting VM snapshots or installing products.
What are your definitions of `THREAD_BASIC_INFORMATION`, `ZwQueryInformationThread` and `THREAD_INFORMATION_CLASS`? Presumably `THREAD_BASIC_INFORMATION` is not correctly defined and thus the wrong size.
 [StructLayout(LayoutKind.Sequential)] public struct THREAD_BASIC_INFORMATION { public int ExitStatus; public int TebBaseAddress; public CLIENT_ID ClientId; public int AffinityMask; public int Priority; public int BasePriority; } [StructLayout(LayoutKind.Sequential)] public struct CLIENT_ID { public int UniqueProcess; public int UniqueThread; } [DllImport("ntdll.dll", SetLastError = true)] public static extern int ZwQueryInformationThread(int ThreadHandle, THREAD_INFORMATION_CLASS ThreadInformationClass, ref THREAD_BASIC_INFORMATION ThreadInformation, int ThreadInformationLength, out int ReturnLength); public enum THREAD_INFORMATION_CLASS { // +9 ThreadQuerySetWin32StartAddress, // +19 } 
I collected some small pieces of code to my SDK, e.g calculate MD5/SHA1... of a string/file; or random a string/number within 1 call... https://github.com/LeeVox/sdk/blob/master/test/LeeVox.Sdk.Test/Security/HasherTest.cs
https://github.com/icecream-burglar/ I've got three projects thrown up. One of them is incomplete/broken (idr, tbh) but should still provide insight to the language. Another one *mostly* works. The third one (WaterLogged) is my most recent and aside from touching-up serialization/deserializationit s complete.
You can of course play around with recursion on C# but you shouldn't use that within production code! The reason for this advice is that C# lacks the support for **tail call recursion**. You can easily run into a stack overflow and without TCO recursion becomes **slowly**. If you want to learn about it, you should have a look at languages that foster this idiom, like most *functional* programming languages. I don't know whether F# fosters recursion but if it does you could stay at the .NET world. If that's not important you could take a look at clojure or Scala!
Your enum has only item with value 0
Continuous deployment/ integration
No, but it is useful if you want to use tools for automatic deployments and integration. I didn't know any and had no problems writing the simple scripts they required.
There are 9 other enums before `ThreadQuerySetWin32StartAddress` and 19 after.
Most check-in systems have it automatically built in, or people replace it with Cake, which is still a mock-up language, not really bat or powershell scripts
 Bossland does all of their cheats in C#, and most trainers on (biggestgamehackingsite) is written in C#... so I don't think that's true, at all.
https://github.com/hmol/LinkCrawler A console appliction used to crawl webpage and find broken links. 
[netpkg-tool](https://github.com/phil-harmoniq/netpkg-tool) A .NET Core console app made to build/pack other .NET Core apps into Linux binaries. It also uses [Shell.NET](https://github.com/phil-harmoniq/Shell.NET) which is a .NET Standard library I made to interact with shell commands.
- Windows handles generally should be declared as `IntPtr` to be platform independent (32/64 bit) - the thread id is not the same as a thread handle - the `THREAD_BASIC_INFORMATION` struct presumably belongs to `THREAD_INFORMATION_CLASS.ThreadBasicInformation`, but you ask for `THREAD_INFORMATION_CLASS.ThreadQuerySetWin32StartAddress`
I know that, hence why they aren't ready **today**. Also Oracle is only porting the Managed ODP.NET, which means lots of features are going to be impossible to port outside Windows, because they are only supported on the native driver version, like UDT for example.
Are you sure ZwQueryInformationThread works with ThreadQuerySetWin32StartAddress? The page you linked suggests it only works with ThreadPagePriority at the moment. NtQueryInformationThread looks like it supports it but I'm not sure if that's what you want.
Can't say I've really needed to use the shell, other than needing to run some specific processes from within the code. Heck, I can't even recall the last time I used the command prompt for routine stuff outside of coding. Yes, from time to time you'll need to use the shell. For example, I had to use it a few weeks ago, when installing a windows service I wrote. But even then I had to look up the command to do that, since I knew it existed, as I'd used it before, but couldn't remember it was "sc". Long story short: never have I been asked about my shell skills.
https://github.com/RevenantX/LiteNetLib Reliable UDP networking library for .net, mono, .net core and .net standart
Em... Calculating Fibonacci numbers is classical example of how using recursion is a bad idea for some tasks. It has exponential time complexity (at least the naive implementation).
I guess this gives me a chance to show the two projects of mine that I like: [A Brain F*ck ~~compiler~~ transpiler written in c# targeting c#](https://bitbucket.org/izikblu/brain-f-ck-compiler-for-c) (no real name) and [JAGBE](https://github.com/izik1/JAGBE) A Game Boy emulator.
&gt; async methods always start the moment you call them (MyMethodAsync()). Technically true but a but misleading. A method that is named `Async` and returns a `Task` won't necessarily auto-start. Furthermore, the fact that a method was defined using the `async` keyword isn't part of the function signature. So unless the documentation mentions it, the only way of knowing for sure is to check the state of the `Task` object.
In my experience, I have only ONCE needed to apply recursion in 12 years, or so. However, I needed it in order to perform some calculations on a budget class. Yes, the financial type. Now, a budget is pretty hierarchical, at least the one I had to work with: you had chapters, subchapters, actual lines. Each higher level was the sum of the lower ones. Now, the budget was stored in a database, as a flat object. So you had a parent line, with a specific ID and a ParentId property of zero (or null, or whatever). Then, the lower entries would have their own IDs and their ParentId property would be that of the parent line. And it was all mapped out directly on a user control that would handle the display. This required some extra calculations, however, so I had to write an additional class to emulate the budget's structure and do the sums starting from the bottom and going all the way up until I'd reach the highest level (the parent element) As I said, I've only had to actually use recursion once and I know plenty of programmers who haven't had to deal with it frequently. However, it's a good thing to know at the right time.
I haven't looked into or though about it, what is the non naive implementation?
Resently posted it on this subreddit, but here it is if you missed it: [Data Structures and Algorithms in C#](https://github.com/abdonkov/DSA)
If you build a C# application in 64-bit combined with release mode you'll get tail call optimization
So, these are the issues you've created https://github.com/cake-build/cake/issues?utf8=%E2%9C%93&amp;q=is%3Aissue%20author%3Amatkoch To say the team largely has ignored you feels like a bit of a stretch, it's rather been the opposite were you ignored their questions and comments if you look at this issue https://github.com/cake-build/cake/issues/1401 or this PR https://github.com/cake-build/cake/pull/1408 I'm sure you've got an excellent build system, and I wish you all of luck with that, but please stand on own merit and play your strengths instead of taking a stab at Cake and its Community on every Cake related post/tweet, promoting your own Build system on Cake Gitter chat and issues - it just feels small and malignant. What you see as totally terribly bad - another person could see as a feature - somethings could just boil down to differences in philosophy. There's plenty of room for tools in the .NET community, my philosophy is the more the merrier, so regardless of your endless Cake bashing - thanks for your contribution! It's great to see the renaissance in the .NET Community!
https://github.com/Acidic9/ProcessHacking I got this from a github repo. It should work but it's possible it doesn't I guess?
Those are the issues I meant; some of them even created recently: * https://github.com/cake-build/cake/issues/1406 * https://github.com/cake-build/cake/issues/1730 * https://github.com/cake-build/cake/issues/1521 * https://github.com/cake-build/website/pull/398 * https://github.com/cake-build/cake/issues/1662#issuecomment-319055414 Sorry that you feel my contributions were not as constructive as I intended them to be. Feel free to contact me directly to resolve any of your remaining concerns. Anyway, I wish you and Cake all the best (as I always did).
Powershell will give you lots of extra credit, and definitely does come in handy, specially when debugging on other machines. Be aware that your IT support team may not take your skills so nicely. It you have DevOps though, they will love you. :) Take no notice of the Bashers out there though, Powershell is very powerful, and can do anything that it can.
Thanks. What are the scripts for deploy and server management like? What commands and utilities are used often?
Thanks. What tools have you used for deployment?
Hell yes, does it support UWP?
I think I've got my head around what you're asking. What you're saying, if I've understood correctly, is that the parameter to the Edit method is being populated correctly, but the parameter to the Create method isn't, and you're not sure why. is that correct? If so, start by removing (temporarily) the [Bind] attribute. I don't expect this will make any difference, but let's rule it out. If that makes no difference, then I would expect the problem is most likely with your View. To be clear, MVC does not "know" what a Create method or an Edit method means. Although there are some useful tools for scaffolding them, at run-time they are treated absolutely identically. MVC sees a Post request coming in over HTTP, and it routes that request to the most appropriate action, binding the parameters as best it can on the way. So if your parameters are not being populated, the most likely reason would seem to be that they are not being sent correctly over the HTTP request - and that comes from the View.
Just be aware that if you want to use the built-in hangfire dashboard to monitor job status and requeue failed jobs, your web application needs to be using Owin rather than the legacy IIS pipeline. 
I am trying to get the processor's main thread's start address. And yeah I can change the int to be IntPtr but my problem is not solved... I still need to use the struct buffer :/
true, I didnt really read that literally, I thought he meant having to deal with a command line interface in general
I don't think you understood what OP is looking for. https://askubuntu.com/a/426843
Here is a basic use of recursion to handle user input, it's in Java but the code is similar enough for you to grasp. The code checks a users input and if the number is &lt; 10 it calls itself again asking for users input until the number entered is &gt;10, then it is processed and recursion is no longer. A simple use but one that is fairly understandable and straightforward. https://stackoverflow.com/questions/23322686/use-of-scanner-class-in-recursive-functions
`powershell` is cross platform and `cmd` comes with wine
This is my github, I'm not a professional programmer I just do it for fun so I don't promise quality code https://github.com/cobrce/
yes, thank you
Interesting. How does the MTU detection work? 
didn't know about that, gonna look into it, looks interesting ;)
http://www.daveamenta.com/2011-05/programmatically-or-command-line-change-the-default-sound-playback-device-in-windows-7/ Note that this method uses undocumented APIs (so it may no longer work). Windows normally prohibits (starting with VISTA) the changing of the default audio device programmatically.
Ok so I'm still spinning my wheels on this solution. Here is what I have so far, if you have time and could give me some guidance I'd greatly appreciate it. Currently I'm on the frmSurvMaint.cs trying to get a foreach loop to pull objects(questions) from the list in my class QuestionList.cs using the GetList method. The project purpose is to enter a question on the Question Maintenance form, add it to the QuestionList class, then to be able to go to the Survey Maintenance form and pick questions in the combo boxes, then save it as a survey. Zip file: https://www.dropbox.com/s/rij9qp5lktql45z/SurveyProjectEd.zip?dl=0 EDIT: Github- https://github.com/msm187/SurveyGenerator
Just reading through your Program.cs and it's very clear but also foreign in style. What is your background (out of curiosity)?
GShell is a collection of PowerShell Cmdlets for Google G Suite administration and a few other APIs written in C#. Haven't been able to update on a little while due to baby things, but someday soon I hope. Self taught programmer so it may not be the best code ever, but hey it works. https://github.com/squid808/gShell
I like the idea of functions in the logging. Seems neat. But as far as actual use I see a few hold backs. First, does it write to a file or stream? Sorry if it does, on mobile. Second, log levels are nice when you use them. Nlog has the format of logger.warn("") and setting up the logger you tell it the levels you are concerned about. This is nice because in test I usually run it to pick up debug and above but in prod usually info and above. Also, for debugging I need to know where it happened. Where is the location in the log? Maybe that happens in your function formatter? Looks like a neat idea. Good luck. 
If you want to know how _not_ to write code - feel free to checkout my image collection management tool, [PantEX](https://gitlab.com/icefairy64/PantEX.Net/tree/v0.4-dev) (note that master branch is severely outdated now). I have built it to be able to easily browse for new images for my packs, so it is the most complete functionality for now. Please note that content from most of the sources that are currently supported could be NSFW.
There's an open source project called [SoundSwitch](https://github.com/Belphemur/SoundSwitch/releases) which allows you to switch with hotkeys. As it's open source you look in the code to see what they do. From memory it's as MangoII says, all undocumented crap because who would have thought that changing the output sound device would ever be useful :(
Yes!)
You're going to want to compress the record as much as possible then. Are you going to want to record each time a card is played or just the results of the round? 
https://github.com/griffenx/Apex-Launcher A simple launcher for the game I'm making. Hope this is a good example for you. 
By transferring large packets. Packet sizes used from table: 576 - MaxUdpHeaderSize, //Internet Path MTU for X.25 (RFC 879) 1492 - MaxUdpHeaderSize, //Ethernet with LLC and SNAP, PPPoE (RFC 1042) 1500 - MaxUdpHeaderSize, //Ethernet II (RFC 1191) 4352 - MaxUdpHeaderSize, //FDDI 4464 - MaxUdpHeaderSize, //Token ring 7981 - MaxUdpHeaderSize //WLAN If packet arrives then it sends next packet with increased size.
MVVM much ? try to understand this simple calculator: https://github.com/florinbuda85/JustAnotherCalculator 
I think the only practical application of recursion I've come across is a method to find a parent of a specific type in the visual tree in some XAML structure. Like a Grid in a grid in a grid in a stack panel in a grid etc... and some innermost element wants to find the parent element of type stack panel (or some other element that actually makes sense in the context). Calls GetParent and checks and then calls it again. Not true recursion I guess, but whatever. 
Or maybe it was the other way around, it was calling GetChildren ... I don't remember, anyway there was a bug in it and it looped forever and I had to find out why lol
The problem is that the pipe is a functionality of the shell - but you're not executing from the shell. You're not calling `/sbin/ip` and pass the arguments ` link show eth1` and pipe the result to another process. You're executing `/sbin/ip` and pass the argument ` link show eth1 | grep link/ether | awk '{print $2}'`, which `/sbin/ip` can't deal with, it doesn't know what all those arguments do. Instead of executing `/sbin/ip`, execute the bash directly and pass your command using the `-c` flag to bash.
Would this work for you? https://stackoverflow.com/a/1440238/1269654
Host your code on a public page like Github or Bitbucket. No one is gonna download a potential malicious zip archive.
I get bored quite a bit and I sort of created a library over the years: https://github.com/JaCraig/Craig-s-Utility-Library However with the .Net Standard being set up a bunch of it didn't fit in there. So I've been splitting it up into smaller libraries and making it work in that footprint. I'm about 90% of the way through at the moment: * [Simple Mail](https://github.com/JaCraig/SimpleMail) - Basically a wrapper around MimeKit to send emails. * [MoonUnit](https://github.com/JaCraig/MoonUnit) - A really basic unit testing library that I created years ago. * [Woodcutter](https://github.com/JaCraig/Woodcutter) - The logging portion of CUL. To be honest, use Serilog. It does what my library was originally created for, to be a wrapper around various sinks. When I created it, Serilog didn't exist but it does now so just use it. But if someone wants to use my thing, so be it. * [Corset](https://github.com/JaCraig/Corset) - Library to simplify working with compression. * [SerialBox](https://github.com/JaCraig/SerialBox) - Deals with serialization. Basically you tell it you want a JSON, XML, etc. object and it serializes it for you. * [Valkyrie](https://github.com/JaCraig/Valkyrie) - A validation library. * [Sundial](https://github.com/JaCraig/Sundial) - A code profiling library. Useful more for build servers than anything as it creates a nice html based output with charts. * [Mirage](https://github.com/JaCraig/Mirage) - A random data generation library. Does basic data types, POCOs, company names, full addresses, domain names, phone numbers, female/male names, lorem ipsum, etc. * [Holmes](https://github.com/JaCraig/Holmes) - A library for doing basic database analysis and it returns suggestions for improvement. At present it's just SQL Server and just checks for missing indexes, overlapping indexes, etc. But it could definitely be expanded upon. * [SQLHelper](https://github.com/JaCraig/SQLHelper) - Basically a wrapper for ADO.Net classes. It helps to connect to the database, batch queries, handles transactions automatically, etc. and returns the data in a list of dynamic objects. It's basically a very basic micro ORM... Sort of... * [Data.Modeler](https://github.com/JaCraig/Data.Modeler) - A library used to create and compare database schemas. It was originally part of my ORM but some people asked me to break it out into its own thing. * [Aspectus](https://github.com/JaCraig/Aspectus) - An AOP library. I couldn't find a .Net Standard AOP library and I had one from years ago in my ORM, so I just moved it over. I need to update the documentation on it though as you don't need to specify what assemblies to load anymore beyond your own. It finds the system libraries automatically now. * [BigBookOfDataTypes](https://github.com/JaCraig/BigBookOfDataTypes) - Kind of a dumping ground for extension methods, data types, etc. that I've accumulated over the years. I think it's a couple hundred extension methods at the moment for types like IEnumerable, string, etc. This was the part of CUL that most people used actually. * [Environs](https://github.com/JaCraig/Environs) - Wrapper for WMI, LDAP, and a couple other things. * [Canister](https://github.com/JaCraig/Canister) - My IoC wrapper. It comes with an IoC container but it's more for wrapping various IoC containers. That way you can swap them out if you need to. I needed a way to wire up my libraries automatically and I didn't want to force people into a specific container as people tend to be very opinionated on the subject. * [TaskMaster](https://github.com/JaCraig/TaskMaster) - A library to help with running tasks based on some criteria. Very basic but I find that I write a number of utilities in this manner and I didn't want to rewrite the code each time. * [FileCurator](https://github.com/JaCraig/FileCurator) - Library for managing and parsing files. Basically it can talk to local file systems, http, and resources in the same manner and you can plug in your own file systems. On top of that it can then parse the data based on the file type. It currently handles CSV, Excel, HTML, ICS, EML, MHT, PowerPoint, RSS, VCS, VCF, Word, etc. I need to improve Word, HTML, and other structured file types but it works well enough for now. This was mostly used for a web crawler that I built a while ago but I've since used the library in various web apps. * [Inflatable](https://github.com/JaCraig/Inflatable) - My current gen ORM. I'm currently working on it at the moment. I'm trying to get the batching to work the way I want and need to add many to one properties. But once that's done it should be beta ready. * [Structure.Sketching](https://github.com/JaCraig/Structure.Sketching) - Was originally a fork of ImageSharp to fix the, I think it was 20 or so bugs that I ran into that were show stoppers, however it took so long to fix them and required a large percentage of the code to be modified so I didn't do a pull request. That said, JimBobSquarePants knows about it and I told him to pull whatever he wants over. So most likely this will be a rewrite in the future to move off of their code completely. But I'm currently working on the rest of the CUL rewrite above. At present the only items left are the ORM, encryption, and I think one or two other items and then I'm back to working on Structure.Sketching in my spare time. Well that and some AI stuff that I've been working on. Go, go NLP and deep learning.
Thank you. This was the solution.
First up some cleanup: I see that the `Questions` class has only static members. This means that members in that class are shared between all instances of `Questions` and this isn't what you want. Remove the `static` keywords from that class and rename the class to `Question` because it represents just one question. I've made the `QuestionList` class `static` because all its members are already `static`. This is an optional change but good practice if all of a class members should be static. Now for adding the questions. In the foreach just add the `question.QuestionContent` to the `Items` of `cmbQuestion1` like so: foreach (Question question in QuestionList.QuestionList) { cmbQuestion1.Items.Add(question.QuestionContent); } Now you got something to work from again. Start the program and submit a few answers in the question1 input field you made. Then go to the survey and you should be able to see those possible answers you entered. As the program is now it's not really doing what you want still. So as a possible improvement you can allow users to add multiple questions in the question1 field on `frmQuesMaint`. A way to do that is using comma separated strings like so: private void GetList() { foreach (Question question in QuestionList.QuestionList) { foreach (string answer in question.QuestionContent.Split(',')) { cmbQuestion1.Items.Add(answer); } } } There are multiple other ways to solve this including adding a List&lt;Answer&gt; to your `Question` class instead of one string which is a cleaner solution. This is just a quick-fix to get you going. Let me know if this helped you or if something is unclear.
You are the best! Thanks so much, all set!
You might want to check out Bedia UV, a Home Theatre application: https://github.com/Blissgig
For authoring game content, I've written C# tools using WinForms. The idea is that you have a GUI to do all the work for you. The tool would serialize 'packages' that can then be imported into your game. If you put the exporting/importing logic in a library, your game can use the same library to import the content. It would be up to you as to whether or not you'd want to use the file system or database, so this still doesn't answer your question. However, I thought this idea would be worth mentioning.
I made a game a while back with a custom engine: https://github.com/Egodystonic/EscapeLizards
A Connect Four clone I made in WPF for my Artificial Intelligence class. https://github.com/PikminGuts92/Subliminal
Perhaps another tidbit that could be mentioned is how scope exists for the entire block regardless of where the variable is declared. If we add a new `a` variable after the block, it won't let us: int c; { int a = 5; int b = 10; c = a + b; } int a = 3; //Error CS0136 A local or parameter named 'a' cannot be declared in this scope because that name is used in an enclosing local scope to define a local or parameter Console.WriteLine(c); So even though you couldn't access the inner scoped `a`, and even though it's declared after the inner scope block, you can't declare that second `a` variable. At this point though, you could declare a second scope block just fine since neither scope has any conflicts with shared scope: int c; { int a = 5; int b = 10; c = a + b; } { int a = 1; int b = 2; c = a + b; } Console.WriteLine(c); In practice, I've only ever found this useful with a very particularly niche domain-specific-language/API. Otherwise I avoid it where possible; as you point out, it tends to look like it ought to be associated with some `if`, `for`, lambda, or something else. If you find yourself using it to manage a plethora of variables and scope, it might be a sign of code smell and may warrant changes. Another minor trivia/tidbit. If you turn off compiler optimizations (say in debug mode), you can include an empty block: { } which will add two extra `nop` instructions. Why you ask? So the debugger can hit breakpoints on those curly braces. Otherwise they get compiled out and you can't break or step on them.
If you want a list of jobs, you can add the functions to a list for later execution var funcs = new List&lt;Func&lt;Task&gt;&gt; //make this match your method signature { MyMethodAsync, MyMethodAsync1 }; // for later execution: await Task.WhenAll(funcs); 
Currently poorly documented, but I wrote an [ILDA Image Transfer Format](https://en.wikipedia.org/wiki/International_Laser_Display_Association) file parser: [DSS.ILDA](https://github.com/gsuberland/DSS.ILDA) ILDA is used for storing frames and animations for laser shows. Also wrote a short LINQ script for generating [SHA2017](https://sha2017.org) flag images, because the online generator had some quirks and wouldn't let me generate high-res images for t-shirts at the camp. [SHA 2017 Flag Generator](https://github.com/gsuberland/SHA2017-Flag-Generator).
I don't see the need for every card to be recorded. Also, I don't know how about to go about compressing the data. I need to learn how.