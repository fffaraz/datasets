Good points. Love it that after 15 years of using this language I still learn new stuff :)
https://github.com/Metapyziks/SourceUtils Reads data from Source engine games, with a WebGL map renderer web server / static file exporter. Demo of the exporter's output here: https://metapyziks.github.io/SourceUtils/
I don't even have a background at this point haha. I started teaching myself Python about 2ish years ago and then got into school and started learning Java. I fell in love with C# when .NET Core came out (I use Linux) and have been trying to dig into it as much as I can. I guess my Program.cs *is* a bit more procedural than other C# projects. Is there anywhere you could recommend I check out to get a better idea of normal C# style?
What's wrong with C++/CLI? I would rather have my eyes poked than write P/invoke stuff for this.
I use these sometimes as quick and dirty sanity check to help catch copy/paste errors Without scope: var x1 = 1; var x2 = 2; setWidth(x1 + x2); copy/paste, change x to y. But I missed x1 on line 3 below. However, this bug still compiles because x1 is still in scope from above. var y1 = 3; var y2 = 4; setHeight(x1 + y2); With scope. Doesn't compile until I fix my error { var x1 = 1; var x2 = 2; setWidth(x1 + x2); } { var y1 = 3; var y2 = 4; setHeight(x1 + y2); } &gt; The name 'x1' does not exist in the current context
https://github.com/inflatablefriends/lastfm Last.fm API parser and a couple of associated tools I've been maintaining on and off for a few years now. Aim is to make it as easy as possible to integrate your music app with Last.fm.
I have a few roguelikes and a half working 4x game at http://bitbucket.com/ekolis :) I'd go into more detail but I'm stuck on mobile now; what I can say is that the 4x is a clone of Space Empires IV and it's called FrEee.
[RazorLight](https://github.com/toddams/RazorLight) - I've created a library that allows you to use razor template engine outside MVC. Usually it is used to build emails. Recently introduced preview version with NetStandard 2.0 support
[Here's a file comparison utility I wrote for work](https://github.com/3vbo/FileCompare), and this is a very much in-progress [World of Warcraft addon manager](https://github.com/3vbo/AddonManager) to replace the awful Twitch/Curse client
Yes. They are compiled to the same format as normal .NET code and can still be decompiled.
https://github.com/tusdotnet/tusdotnet Server implementation of the tus protocol for resumable file uploads. Runs on both owin and kestrel (asp.net core). It allows you to continue uploads of large files in case the connection to the server dies (e.g. if your mobile's network coverage goes out) and it all runs on top of http(s) so client compatibility is top notch. 
Wow. That's a lot of stuff. Thanks!
This seems like what functions (local and otherwise) are for. It may seem silly for something as trivial as the above, but if you're doing much of that Ctrl-C, Ctrl-V biz, you're opening yourself up to bugs when the copied block needs updated.
lookup asymmetric keys and signing. don't implement your own version, take something well tested (Microsoft cryptographic namespace or bouncy castle). learn how to create hard keys (initialization vectors,...) and how to use cryptographic hashes to check integrity 
Didn't think about that, here's the github link https://github.com/msm187/SurveyGenerator
Thanks for feedback! Actually, it supprts multiple "listeners" for output. Theoretically you could even implement a listener to send you a text message. Log levels are kinda implemented via tags. I don't personally like having them hardcoded via enum values. Each listener has a "TagFilter" property which whitelists messages with specific tags.
call the method.
sure, but how get the value? and give it to another var that i can consume?
Not too sure what you're asking for. Maybe you need to abstract the string generation to an object (or static class) and add some event handlers/listeners?
I'll plug all this in this afternoon, thanks so much for the help, I'm sure I'll be back to pick your brain some more 
Not sure what you're talking about with regards to not having a "start" function and instead only having "append". What platform are you developing for (e.g., WPF, ASP.NET, Unity, UWP, Console)? Have you tried reinstalling Visual Studio? EDIT: Maybe this is a lost-in-translation issue. By "append" do you mean "attach"? Perhaps you made a "class library" project type and not an application (Console, WPF, etc.) project type? Also, if this is the case, did you make it with the correct language settings? Perhaps you made a different language type (Python, VB, JavaScript).
https://imgur.com/a/479jH In the red circle, there should be the word "Start". But there is no start and when I click this new weird button, there comes this weird window. I am programming a console application.
Can you post an image of your solution explorer and your project properties ("Application" tab): For example: https://i.imgur.com/oqGl1Rj.jpg EDIT: And yeah, that's the "attach debugger to process" dialogue letting you attach to an existing running process.
i got a method which is qr code reader. the method is returning a string "123456". now i want to access this value in my constructor to combine it with a entry.text value. you know what i mean?
 var myvar = method(); 
So, pass it into your constructor, or wrap it with a separate class that has event listeners and can notify any parties of the value. Or a `string` field that reports the last generated value. I think beyond that you'll have to supply some code demonstrating _what you currently have_, and what you would _like_ to have (even if that is pseudo/non-compilable code).
You could be on the right track, there seems to be a problem with the solution explorer: https://imgur.com/a/cZBM2
so basically i want the readed string from may Scan() method, which is called by button.clicked, into my constructor that i can form `email_subject` using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Text.RegularExpressions; using System.Threading.Tasks; using Xamarin.Forms; using Xamarin.Forms.Xaml; namespace TDE { [XamlCompilation(XamlCompilationOptions.Compile)] public partial class Page1 : ContentPage { public Page1 () { InitializeComponent (); var layout = new StackLayout() { Margin = 10, Spacing = 20 }; var label = new Label { Text = "Bitte Scannen Sie den Barcode und geben noch folgende Informationen ein, um den Vorgang abzuschließen:", FontSize = 30, FontAttributes = FontAttributes.Bold }; var button = new Button { Text = "Hier Fahrzeug Scannen", TextColor = Color.FromHex("#004d93"), VerticalOptions = LayoutOptions.FillAndExpand, HorizontalOptions = LayoutOptions.FillAndExpand }; var entry_Kraftstoffmenge = new Entry { Placeholder = "Getankte Kraftstoffmenge in Liter", PlaceholderColor = Color.FromHex("#004d93"), HorizontalTextAlignment = TextAlignment.Center }; var entry_Fahrer = new Entry { Placeholder = "Hier Ihr Name / Kürze", PlaceholderColor = Color.FromHex("#004d93"), HorizontalTextAlignment = TextAlignment.Center }; var entry_KMStd = new Entry { Placeholder = "KM-Stand in KM / Stunden in h", PlaceholderColor = Color.FromHex("#004d93"), HorizontalTextAlignment = TextAlignment.Center }; var entry_Geraet = new Entry { Placeholder = "Gerätename", PlaceholderColor = Color.FromHex("#004d93"), HorizontalTextAlignment = TextAlignment.Center }; layout.Children.Add(label); layout.Children.Add(button); layout.Children.Add(entry_Kraftstoffmenge); layout.Children.Add(entry_Fahrer); layout.Children.Add(entry_KMStd); layout.Children.Add(entry_Geraet); Content = layout; button.Clicked += ButtonScannen; var email_subject = entry_Fahrer.Text + ";" + entry_Geraet.Text + ";" + entry_KMStd.Text + ";" + entry_Kraftstoffmenge.Text; DisplayAlert("ok", email_subject, "ok"); } public void ButtonScannen(object sender, EventArgs e) { Scan(); } public async void Scan() { var scanner = new ZXing.Mobile.MobileBarcodeScanner(); var result = await scanner.Scan(); var _tankbomb = ""; if (result != null) { _tankbomb = result.ToString(); await DisplayAlert("Erkanntes Fahrzeug", _tankbomb, "Ok"); } else { _tankbomb = "000000"; await DisplayAlert("Fahrzeug nicht erkannt", "Es wurde ein Dummy-Fahrzeug eingetragen!", "Ok"); } } } }
I just made a new project and copied all the code, it seems to work now. Still thanks a lot!
I like the idea of tags replacing log levels. Where do you see this library fitting in? Mobile? Web? It's going to be tough to gain traction against Serilog, so maybe a comparison there would help.
No problem. If I had to guess, perhaps the project was removed from the solution (either accidentally or due to a bug/corruption), but you still had C# files opened. Thus all the compilation wasn't applicable and you could build/run the project. Anyhow, glad to see you're back up and running! :)
I know .NET Core uses a different CoreCLR than the full .NET CLR. Are there any functional differences or is it just a different implementation? 
Thanks for replying!
Well, you can't create your `email_subject` string right away like that. You have to wait until the button is pressed. Maybe move it into a field and write it out when you click the `Scan` button? You also don't do anything with the scan `result`. Either return it, set it to a field, or build that `email_subject` (as a field) variable in the Scan method.
I have [rather a lot](https://github.com/martindevans?utf8=✓&amp;tab=repositories&amp;q=&amp;type=&amp;language=c%23) of projects. A few of the most interesting: - [SwizzleMyVectors](https://github.com/martindevans/SwizzleMyVectors) is a set of extension methods and helper types to make working with System.Numerics.Vectors more convenient. Originally this was just a load of swizzling methods (e.g. `Vector2.YX()` returns a new components with the X and Y elements swapped) and it grew out to contain other helpful things like `ManhattanLength` and `IsNaN`. - [HandyCollections](https://github.com/martindevans/HandyCollections) is a handy set of collections. Whenever I need a new collection for one of my projects I usually implement it into this library. Binary trees, bloom filters, Octree, Min/Max Heap and a few assorted extension methods. - [MumbleSharp](https://github.com/martindevans/MumbleSharp) is my most popular project. It's a re-implementation of the [mumble protocol](https://wiki.mumble.info/wiki/Main_Page) from the ground up. Currently it does pretty much everything *except* voice (e.g. text chat, channel membership etc etc). - [SupersonicSound](https://github.com/martindevans/SupersonicSound) is probably my favourite of these projects. It's a wrapper around FMOD which takes a really ugly C style API and wraps it in a nearly zero overhead C# wrapper. Careful usage of structs required! - [WebDesktop](https://github.com/martindevans/WebDesktop) is a pretty cool project I haven't worked on for ages (I'd kind of forgotten about it, maybe I'll pick it back up). It paints a transparent window over your desktop (being careful to make sure clicks are passed through to your desktop, and it's never on top of any windows). The window can have a website (with a transparent background) painted onto it. Kind of like [Rainmeter](https://www.rainmeter.net/) with a web stack. - [CasualGodComplex](https://github.com/martindevans/CasualGodComplex) was a project I built purely for a [blog post](http://martindevans.me/game-development/2016/01/14/Procedural-Generation-For-Dummies-Galaxies/) on procedural generation. It chains together a load of basic procedural generators to generate galaxies (in no way realistic for the number of stars or the layout, it's just for looks). - [MarvellousMarkovModels](https://github.com/martindevans/MarvellousMarkovModels) is another part of the CasualGodComplex project. I intended to write a blog post about this but never did. It generates random star names (e.g. Superba, Alpha Alnati II, A12, Gamma-77, 58.00 Pollun 144, Prime Taygetorcula) using markov chains. - [SharpSteer2](https://github.com/martindevans/SharpSteer2) is a fork of a fork of a C# reimplementation of [OpenSteer](http://opensteer.sourceforge.net/). It provides basic steering behaviours for NPCs in games (path following, obstacle avoidance, flocking etc etc). The original SharpSteer(2) had sat around rotting for years so I forked the project, separated a load of tangled code, fixed many bugs, removed it's dependency on XNA and rewrote a load of it for better readability. - [HashMedly](https://github.com/martindevans/HashMedly) is a little project I threw together because I got fed up with seeing everyone implement `GetHashCode` wrong! It provides a very simple way to generate high quality hashes e.g. `Murmur3.Create().Mix(_field1).Mix(_field2).GetHashCode();` and some base classes to make it relatively easy to add new hashers. The intention was to implement a wide variety of hashes but it turned out murmur3 is amazing and you should just use it for everything.
Can you post the code that you currently have? Also, "instance of a method" doesn't make too much sense. Are you trying to create a delegate to a method?
To be frank, I've never used any logging libraries before. I mostly just included features I thought people would like. It fully supports .net core, idk if serilog does but maybe that'll give it an edge.
They are based on different framework libraries/subsets of API, but the resulting IL is the same
Serilog and nlog support core. Serilog was what they pushed as the default in early core templates if it doesn't still.
Nice, this will come in handy during a huge web migration for work in a few weeks!
Nice, this will come in handy during a huge web migration for work in a few weeks!
https://en.wikipedia.org/wiki/Cheating_in_online_games#Anti-cheating_methods_and_limitations – you're basically looking for DRM as on game consoles, or very invasive stuff like PunkBuster. You could also roll your own, but there's a good chance that time is better spent on a even better game.
Hmmm. Mine may struggle to gain significant traction. If any
Yeah, I have all of that well under my belt. The problem isn't GETTING the hash / signature, it's: so what if you do? They can simply alter the executable to always return "true" on a signature check. 
[GraphQLQueryBuilder ](https://github.com/mclintprojects/GraphQLQueryBuilder) - We're starting to use GraphQL at work so I started working on a Graph QL query builder that uses a fluent API to construct the query. 
https://github.com/JeffFerguson/gepsio
Great! I would advise you to enter issues or contribute if you think something is missing/wrong :)
.NET Core is stripped down for cross-platform compatibility and the system libraries are split into smaller modules. The programs compiled for full .NET would not be incredibly different to those compiled for .NET Core. The biggest difference (excluding system API changes) would probably be the references list because the system libraries have been split up. The format all CLR implementations load, and what decompilers load, has always been the same. No matter what you compile for. Only something like [.NET Native](https://docs.microsoft.com/en-us/dotnet/framework/net-native/net-native-and-compilation) can prevent decompiling effectively.
imho only signing with obfuscation would help to get some degree of anti tampering. to communicate with your server ECDHE-RSA, ECDHE-ECDSA helps
Maybe see https://stackoverflow.com/a/7424266 or look up a tutorial on WinForms + comboboxes on YouTube
Removed: Rule 4. Do some research and if you have specific questions or have trouble understanding particular aspects, feel free to post a question on those aspects. The .NET Framework can often be used (properly or improperly) to reference multiple concepts. But typically it's basically the full umbrella of the .NET technology stack that (typically) exists on Windows. Usually consisting of the runtime, just-in-time compilers, base class libraries, and other related components. .NET Core is a stripped down subset of that .NET Framework intended to represent a "standard" that can be implemented on multiple platforms (Linux, Mac) and potentially future areas (WebAssembly, mobile). It also contains a "Core" runtime, JIT compilers, and a subset of the base class libraries. Plenty of learning resources in the sidebar, sticky, google, books, and /r/learnprogramming. Dive in and see what you find. If you have specific questions about particular aspects, feel free to post a question.
Maybe they mean a non-static method?
Not really true compressing so much as minimizing the storage requirements. For example, you probably don't care about the suit, just the value, assuming you were to want every card. But since you don't, you may only need the round number and the totals, not even the winner since that's obvious. So you could store just the round number (first round, second round, third round, etc) and the totals. The totals are likely never going to ever go over 30. Once they hit 22, they bust, and they will likely stop at 21. Unfortunately you could have more than just the dealer and the player, and each person could split any number of times in one round. So you're best off making one record per player per round (including the dealer) with a couple of bits to use to indicate player number. Figure max of 4 players plus dealer. so a player number (0-4) would need 3 bits. And a hand for one player would need 0 to 30, which is 5 bits. (5 bits can go from 0 to 31. 6 can go to 63, 7 can go to 127, 8 can go to 255). So 3 + 5 comes out to 8 which is lucky. We can use a bite to store it. roundNumber int (4 bytes. Sucks but we need a way to link all the hands for all the players in around, and it has to be able to go to a million, so 4 bytes it is. Next one down is 2 bytes, and that's only about 32k. Next one up is 3 bytes but it's not worth the trouble. So RoundNumber int (4 bytes) PlayerNumber (3 bytes) Hand 5 bytes. You can store that in sql directly as RoundNumber int and HandPlayer tinyint. Alternatively, you can just write all the hands to a binary file, and you don't need the round number if you append a break between them. Something like : 122 253 021 0 057 192 0 Etc. The 0 would denote a new round because no hand can ever be 0. In the first value of 122, that would be 01111010, which would be player 3 (011) who busted with a 26, while the third player was the dealer and he got a 21.
Nice code. Nicely documented as well. I automatically get sexcited whenn I see someone using the "see" tag. That being said, there are so many cool structures and things here it would be nice to have a class level description of each one so I didn't have to Google each one. Then again, if it was alright with you I could research them and write a little blurb for each, to be code reviewed by you. edit: I meant to mention the fact that I DID see the: /// &lt;summary&gt; /// Represents a Sparse matrix. /// &lt;/summary&gt; comments, I just meant further &lt;remarks /&gt; on why it would possibly be used, or even a link to a wikipedia page on the structure or whatever would be nice.
As someone who comes from the game Dev side of C#, I see a lot of people take these kinds of things and just use them without actually understanding the performance impact because they are a More Advanced™ way of doing it. I think some time spent on what is going on under the hood with the heap/stack and memory allocation or size of produced IL with each approach would have far greater benefit.
https://github.com/abishekaditya/DesignPatterns Basically some simple design pattern implementations in C#
Do what PunkBuster and the like do, allow code to be sent from the game server at any point during play which requires a correct response to be returned after executing the code. Yes, hackers can emulate this, but if the library of code to be executed is constantly changing this is one of their bigger headaches. The code can check all sorts of things, like crc'ing an area of memory, a file, use different hash algorithms, request parts of the screen back from the client, take screenshots of the game, even simple stuff that just has to do something new every few days / weeks. Add in debugger checks, VM checks, checks for running processes you know the hackers use. List the modules attached to the program, there will be odd stuff in there from audio drivers / mouse drivers / things with global hooks but at least you have a chance of spotting mapped DLLs the hackers are using attached to your process in the returned data. Don't disconnect the hackers immediately, as then they know which check they failed, mass ban them in bulk later. Yes, this quickly turns the exercise into an arms race, but that is the most annoying to them.
Isn't this what Strong Named Assemblies was meant to solve? You build and sign your assemblies with your private key, then the app only runs those. Since the private key is, well, private, no one can produce an assembly that will pass the strong name verification? https://docs.microsoft.com/en-us/dotnet/framework/app-domains/strong-named-assemblies
I wasn't aware that's what Punkbuster did. I particularly like the "don't immediately ban" thing. Hadn't thought of that. Thanks!
My understanding is that they are done to make sure that the DLLs weren't tampered with when downloaded, but don't actually do any tamper prevention once on the client.
If you are doing online-update as well, you can force the client to download new versions of the assemblies regularly, and just mess with the client/server protocol a little each time, put a version number in the initial connection to the server so play is only allowed with the current shipping version. Then they have to do the patching again, or at the very least they need to write tools to automate the process of modifying your signed assemblies each time. Drop code into some of the assemblies to check other assemblies, but do it randomly between different assemblies.
The strong name is built into the reference. So you should see references in your project to DLL with a PublicKeyHash field. If that assembly can't be found at runtime, it should error.
That doesn't make it make more sense, and I agree with FizixMan that he just means a delegate.
If you check every checkbox during installation because you have no clue what you are doing..then sure, 50 GB should be no problem to reach. If you use vs 2017 and know what environment you need then it is different. I use VS 2017 at work for .Net-Desktop dev. and my installation ist below ~2 Gigs. edit: Even with 2015,2013 the C# Env was always aroung 5 to 10 Gigs for me
I like how you provided a clear list of arguments why visual studio is bad, plus a list of alternative, better IDEs for us to try. Have my upvote, friend.
I think it's a good thing. Imagine not having control of which speakers a random program might use.
Actually &lt;remarks&gt; tag for a further explanation of the data structure / algorithm purpose is a really neat idea. Never though of it. Nice one :)
It's better to set the rules of the race than to catch up to one you didn't know you were participating in!
So minus all the whining you have crappy internet and the download was too large after you mindlessly selected every install option as pointed out by others... put your pitchfork away little guy. 
it was nothing to do with my internet, its hanging on install, not download
the alternative is called sublime text and gcc
That's also just verified on the client, though. If someone is already editing the binaries, they can also edit the references to remove the strong naming/replace the public key.
You are not seriously trying defend the size of Microsoft software are you? There is no justification for it, I dont care how cheap space is.
I start a blank project in visual studio and it takes 5 minutes to load and gives me 18 files full of boilerplate code. Get it to fook.
Removed: Rule 7, Rule 5.
Yes, but the same can be said of any malicious code. I think in this case it's more of an oversight, although I guess it could be design. My Asus motherboard will change the sound output to analogue speakers if I plug them into the front of the machine and various other tricks like that. It can actually do the same switching of outputs trick as SoundSwitcher too. It's only been an issue for me for a few years, since bluetooth headphones, and now USB surround headsets. :)
I took the heaviest project/default I could think of (ASP.NET MVC). Took me 15 seconds to make the blank project. Other project types (WPF, Console) took less than 2 seconds. If you're unhappy with general "bloat" of the full Visual Studio and .NET stack, maybe dive into .NET Core and Visual Studio Code.
Flip question: why is 2GB to 50GB unjustifiable in 2017? Sub-question: What would be a justifiable size and why? 500MB? 100MB? Less?
Fairly interesting post. Thank you. If you were curious, the kind of data I thought was important to keep track of: - the dealer's face up card. Since the dealer's play is static, his face-up card is the only thing I'm interested in. - the player's hand value. - the deck count for each hand, which is based off of the high-lo counting system. - the betsize. - insurance. - result. 0 = win, 1 = loss, etc.. - the initial option. hit, double, split, stand, surrender. I wanted to expand on this to provide an array of options, but I didn't want to over complicate things. - a hand id. A class that handles these values, plus extras, returns a string based on the current information, which the game then processes: var option = Calculations.GetOption(state); //Handles insurance, bet size, and hand options. state is a struct that provides the Calculations class with the current state of the hand as well as providing it with the values listed (if available). Within the Calculations class, there are a couple methods that return a byte array of 2, 4, or 5 indexes which provide the weights for each option: byte[] options = GetWeights(); Result Example: options[196, 51, 23, 10] //If currently playing the hand: 0 = hit, 1 = double, 2 = stand, 3 = surrender Afterwhich, it's kind of like each option throws a ticket into a random number generator, if their ticket gets picked, it returns a string for the game. More tickets, better chances of winnings... more or less. Not too proud of this method, but I couldn't think of anything else better. I also wanted to expand on a few things, like have the counting method be open to change as the game goes on, perhaps give certain cards more value in certain scenarios, which in turn would affect betsizing, options, and whatnot, but the more I think into it, I would have to find a way to compress it all.
Actually, I think they might be asking for MethodInfo.
If I understand, what you'll need is in `System.Reflection`: [Type.GetMethod](https://msdn.microsoft.com/en-us/library/8zz808e6.aspx). If you aren't getting a [MethodInfo](https://msdn.microsoft.com/en-us/library/8zz808e6.aspx) instance from that, you might need to mess around with `BindingFlags`. You can use [Type.GetMethods](https://msdn.microsoft.com/en-us/library/system.type.getmethods.aspx) and the debugger to find the method you're looking for and the flags you need to specify in the `GetMethod` call. EDIT: Also, it's wise to use `nameof` to obtain the method name.
I've been working on an emulation and gaming front end. Kind of like steam, a program to have all your steam, GoG, emulation (etc) games in one place. It supports things like metadata retrieval, controller support and more. It has already had a soft release and I'm hoping to get some contributors to assist. It's pretty feature complete, barring a few rough edges. I haven't been able to work on it in a while as I'm quite ill. http://github.com/dannyglover/gameend
Here's mine: * https://raspi.github.io/projects/winlldpservice/ * WinLLDPService is free, open source and tiny Windows service. It sends Windows’ machine network information via LLDP so that network administrators can find computers with ease. It also uses WiX as the installer and there's chocolatey installer as well. * https://raspi.github.io/projects/screenjournal/ * ScreenJournal is tiny Windows program that takes screenshots in certain intervals to help track your work day.
You need to use that struct if you want `ThreadBasicInformation`, but you want an address so you need an address-sized buffer (i.e. an `IntPtr`),
What is the actual problem you are trying to solve here? The question feel very broad and general.
Edit: never mind, I see that the x64 JITer does tail call optimizations when all the optimizations are enabled. Very cool!
I wanted to SSH into about a thousand network devices (routers/switches) simultaneously. So I built my own SSH library: Surfus.Shell. I still have quite a bit of refactoring and buffer optimizations... but I'll get there one day. https://github.com/ncsurfus/Surfus.Shell
I'm guessing the issue you are having is not knowing how to return a value from a method? or perhaps how to return a value from an async method? Regardless, I'm not sure you can call an async method inside a constructor without blocking. So you need to rejig your thinking about even letting it be available in the constructor. What I would do is disable most of the UI until scanned, or the details are entered in manually. Then recalculate email_subject once Scan has been called, enabling most of your UI. On the assumption you don't know about fields either, https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/fields Fields are variables that are tied to the lifetime of the classes instance. in this case Page1. By declaring a field on Page1 you can share it across your methods. Additionally on the assumption you don't know how to return values from methods / async methods. normal methods: http://www.homeandlearn.co.uk/csharp/csharp_s6p3.html Async methods: https://stackoverflow.com/questions/6045343/how-to-make-an-asynchronous-method-return-a-value 
Nirsoft nircmd can change the default sound device getting the command line: http://www.nirsoft.net/utils/nircmd2.html#using Apologies, I'm on mobile.
Are you trying to prevent unlicensed use by pirates or prevent lost revenue by someone who might try to resell your software and take revenue from you? Imo, a best-effort approach to licensing or anti-tampering is enough. It keeps the honest people honest. The cheaters will always find a way if there is enough demand. I feel like the legal system and appropriate licensing and/or parents is really the only way to prevent the second situation where another individual or organization is trying to pass your software off as their own. The cost in time spent to make it "hacker proof" is not likely to result in a return based on the number of people you kept honest. Unless there's another dynamic at play like in online gaming where people will just stop playing if there's nothing but cheaters and freeloaders on the server.
I'm working on some 3d bin packing software that I might turn into a commercial project, and I recognized SwizzleMyVectors. I scoped it out for ideas. Its one of the few Nuget packages that attempts to use System.Numerics for something practical. Cool seeing you comment about it here.
Well, not really sure if what you've posted works for the full XML spec. Wherever possible, one should probably ought to avoid writing their own XML parser. Plenty have already been written and are (generally) efficient, stable, and implement all of the spec. For example, you have: xml.Replace("&gt;", "@").Split('@') I'm not sure what the purpose of replacing `&gt;` with `@` is before splitting it. But regardless, this can introduce issues where if the text/value content of the various nodes contained an `@` character (say for example, an email field). ----------- While I didn't post specifically a method for a depth-first traversal of an _XML structure_, it could certainly be adapted to do so: public IEnumerable&lt;XmlNode&gt; DepthFirstTraversal(XmlDocument xml) { return xml.ChildNodes.OfType&lt;XmlNode&gt;().SelectMany(n =&gt; DepthFirstTraversal(n)); } public IEnumerable&lt;XmlNode&gt; DepthFirstTraversal(XmlNode node) { Stack&lt;XmlNode&gt; nodes = new Stack&lt;XmlNode&gt;(); nodes.Push(node); while (nodes.Count &gt; 0) { var n = nodes.Pop(); yield return n; for (int i = n.ChildNodes.Count - 1; i &gt;= 0; i--) nodes.Push(n.ChildNodes[i]); } } FileSystemEventArgs FSEA = e as FileSystemEventArgs; XmlDocument xml = new XmlDocument(); xml.Load(FSEA.FullPath); var flattened = DepthFirstTraversal(xml); foreach(var node in flattened) Console.WriteLine(node.Name + ": " + node.Value); Now, you may want to do some filtering depending on the type of `XmlNode` you want (e.g., `XmlText`, `XmlElement`) and pulling the value out that you want, but by-and-large, it's already there and done for you. EDIT: You can relatively easily also adapt it to iterate on XmlAttributes as well: public IEnumerable&lt;XmlNode&gt; DepthFirstTraversal(XmlNode node) { Stack&lt;XmlNode&gt; nodes = new Stack&lt;XmlNode&gt;(); nodes.Push(node); while (nodes.Count &gt; 0) { var n = nodes.Pop(); yield return n; if (n.Attributes != null) for (int i = n.Attributes.Count - 1; i &gt;= 0; i--) nodes.Push(n.Attributes[i]); for (int i = n.ChildNodes.Count - 1; i &gt;= 0; i--) nodes.Push(n.ChildNodes[i]); } }
&gt;result. 0 = win, 1 = loss, etc.. It's only a bit, but with a million hands, you probably don't need to store it. It can be calculated from the values, no? 
Is this a web app? Check what version of .net the application pool your site is using has configured. 
Legacy webforms app. v4.0 integrated. 
I can't see why I won't need it, well, not immediately. Since I'm only tracking the dealer's up card, there'd be no way for me to calculate the result based on the values I currently have. Not sure though, I'm sure there's a better way.
From what I'm reading, this isn't terribly different from what punkbuster does, no?
Great info! Where I'm focusing is on how cheaters/hackers hurt other gamers, though. Specifically in a P2P game.
Specifically I'm trying to find a way to reduce hacking in a peer to peer game.
Yeah, this is kind of the same conclusion I came to. But to keep your players from being screwed it'd be a never-ending cat and mouse game. Was wondering if anyone had come up with a solution that allows clients to police each other, for example?
Check your role features and make sure the 3.5 framework and asp.net features are installed?
You won't need to store it. You will have the final card totals, right? Whichever hand is the highest and not over 21 is the winner.
Gotcha, that is challenging for sure. I like the ideas mentioned earlier about periodically pushing new code down to change the anti-cheat strategies, playing the cat/mouse game. I wonder if it is ultimately wasted effort to go ALL OUT on anti-cheat right up front? I'm thinking of a strategy where you start simple while leaving the framework open to go very advanced later on. That way you effectively spread out your effort over a long period of time. You can do basic things like checking hashes, and in a few months when you know that will probably be compromised, you can roll out your next strategy which is a small increment from before, and repeat with each strategy basically pre-planned. I'm just spitballing but it makes sense to me.
Makes sense. I thought I could save on coding by only needing the dealer's face up card, which is how most moves, if not all, in blackjack are justified. I won't have the final card totals for both the player and the dealer with the method, just the player.
Thanks for the example, yea I wasn't going for the full spec, just the data contained in the xml files I have that are not standard xml... I've been trying to scrape off everything other then the data using strings and queries, or heuristics and trial and error. I chose to attack the structure of xml in general. The xml.Replace("&gt;", "@").Split('@') should've just directly been Split('&gt;') to separate out all the starting xml tags in the string. I then separate out all the attributes so I am left with just starting tags &lt;?xml as example, I use them to get the start index, and then build the close tag from start tag and search the closing tag index, I disregard groupings with &lt;/ in them which is the cause of the error I am currently experiencing.. by ignoring groups and parsing the child elements I am left with a parent element close tag that throws me off when there are more then 1 groupings, this is why I have the Correction, but the correction throws off 'Starts', by removing a part of the string, how do I rewrite 'Starts'? edit: Thank you!! 
I'm in the same boat. Basically just keep changing the algorithm. Doesn't even have to be harder, just enough that they have to constantly change their cheats to stay on top of it, all the while you're logging/banning cheater IDs / IPs
I do it for a hobby only so I'm not sure if its good to learn off of but I've got 3 projects on my [Github](http://github.com/Clone-Conmando/) page. None of them actually are popular or have contributors though :(. "bcrp-db" is the most complex but I stopped because I left the group I made it for, and I'm working on "ssh-script".
It's the AspxLab controls in your app. It's compiled for 2.0 and you're running a 4.0 application. Update or replace and all is good. You can also try building your app against the 2.0 runtime. The former is best. 
I also watched the [Part 1: Events vs. Delegates](https://www.youtube.com/watch?v=el-kKK-7SBU) and I always thought that *+=* is only possible with events, not with delegates. Action a = () =&gt; Console.WriteLine("1"); a += () =&gt; Console.WriteLine("2"); a(); 
Check also projects from the awesome dotnet lists: https://github.com/quozd/awesome-dotnet https://github.com/thangchung/awesome-dotnet-core 
https://code.videolan.org/videolan/vlc-winrt VLC for UWP
I wrote an application https://audioswit.ch/er that does this. And ended up teasing out a library to control the core functions. The 4.0 alpha's are fully async/await compatible too. https://github.com/xenolightning/AudioSwitcher/ Is up on nuget also, https://www.nuget.org/packages/AudioSwitcher.AudioApi.CoreAudio/4.0.0-alpha5
Oh okay that makes more sense. Thanks for the reply. What's motivated you in the past to jump between different test frameworks on the same project?
+1 for `nameof()`
The lambda is capturing the `i` variable from the loop, so all of them use the same value. Create a copy in a variable within the body of the loop.
 var newI = i; This fixed it, thanks!
You should probably use `Parallel` with a different partitioner, though, instead of rolling your own. See [this](https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/how-to-speed-up-small-loop-bodies) for example.
First of all, you are calculating the .Skip-value wrong when doing the async-version. It should be `.Skip(i * itemsPerThread)`, not `.Skip(i * threads)`. Second, you need to be careful when using asynchronous code inside for-loops. You are capturing the value `i` inside `Run.Task`, but while the task is being executed asynchronously the for-loop will mutate the value of `i`. Instead you should create a separate method for what you need to do, in order to capture each unique value, e.g.: for (int i = ; i &lt; threads; i++) { DoWork(i, threads, itemsPerThread, numbers) } private static void DoWork(int i, int threads, int itemsPerThread, IEnumerable&lt;CloneableThing&gt; numbers) { Task.Run(() =&gt; ThreadedTask(numbers.Skip(i * itemsPerThread).Take(itemsPerThread).ToList().Clone().ToList())); } Using this technique, `i` cannot be changed while executing the work asynchronously. Also, note that using `.Skip(n)` and `.Take(m)` can (and probably will) force an enumeration of `n + m` elements for each asynchronous invocation. So if you really need parallelism for performance reasons, you probably shouldn't be using `.Skip`/`.Take` in this manner.
This is covered in Ben Bowens excellent [Common Multithreading mistakes in C#](http://benbowen.blog/post/cmmics_i/) blog series.
Typically the only changes to a JSON format are additions, which your parser should simply ignore until such time as you update your app with the new fields. If a service is well managed they will release a new version on a new url if breaking changes are required. In the unlikely event they make breaking changes to an existing service, most services will provide significant advance warning. Obviously whoever controls the service can do whatever they please, and there are some cowboys out there, but it's not usually worth worrying about.
Your json schema should be common between server and client, but, as anyone who has used a online api will tell you, they will change if you do not have complete control of both ends. The only way around this is to keep an eye on the third parties blog, or write a schema checking tool for early warning of a breaking change. Generally though, third party APIs do understand that people will be building on their schema and will give plenty of notice (whether the majority of companies pay any attention to incoming changes remain to be seen ;) ) Here is an example of the [facebook changelog](https://developers.facebook.com/docs/apps/changelog/) page.
Its generally the component model cache that causes most issues. Delete the visual studio folders in your app data folder. %localappdata%\Microsoft\VisualStudio\14.0\ComponentModelCache _(replace the 14.0 with your Visual Studio version)_ or create a batch file.. DEL %userprofile%\AppData\Local\Microsoft\VisualStudio\10.0\ComponentModelCache DEL %userprofile%\AppData\Local\Microsoft\VisualStudio\12.0\ComponentModelCache DEL %userprofile%\AppData\Local\Microsoft\VisualStudio\14.0\ComponentModelCache Best to do this as a first point of call, then look at your project file for project GUIDs that may be incorrect, so Visual Studio doesnt know how to handle the project.
Hey Thanks. Good to know that it's not likely they will change current versions. 
Remove .Clone; .ToList already makes a copy.
Your question is very vague. "instance of a method named by a string." isn't even formulated as a question. What are you trying to do?
But ZwQueryInformationThread isn't in ntdll.dll. That one has the user mode version. Maybe it makes no difference.
Well, of course [the method] will start. You're *calling it* after all. Yes, the task it returns might not be running, but that would be breaking all guidelines I ever heard of :p.
As a bit of advice, do yourself a favor and don't use the microsoft ribbon library as its usage is pretty awkward, it's very buggy and hasn't been updated in years. Use [Fluent Ribbon](https://github.com/fluentribbon/Fluent.Ribbon) instead. It's much more enjoyable to work with and still actively developed.
This will solve it but the reasoning is different to what the first guy said. The tasks will capture "i" by reference, and so the loop will alter its value between its capture and the task execution. Here, each task will probably start very close to each other, so the value will probably be similar at that point. By creating that new local variable within the loop, once it has been captured by reference, it will not change on the next iteration, as each iteration creates its own distinct variable.
 install an update to the AspxLab controls or install the .Net 1.1 runtime. There's some weirdness with .Net versions from the old days - having v2 installed does not necessarily mean that you have all of v1 installed. Search for the v1.1 runtime for your version of Windows
Honestly... ¯\\\_(ツ)_/¯ That query and structure is just a bit much to try to debug. It's great that got something different working from scratch, but it's a good example of something that is challenging to try to understand, let alone debug.
Why don't just test it yourself? Feed some ill-formed data and observe behavior of your code. In your example, SelectToken would return null, so it's a good idea to add some sort of validation, so the any apparent problem would become more explicit. Don't want to discourage you from asking questions, but I want to encourage you to experiment with your solutions! Curiosity is certainly a big trait for a software developer.
To achieve this with LINQ, you can use the GroupBy()-method. Say you have a list of Person objects and you want to group that list by a person's age. The code would look like this: var personsGroupedByAge = persons.GroupBy(x =&gt; x.Age); I'm not too familiar with the DataGrid used in WPF, but if you want I could take a look at what you've tried so far. 
Confirmed.
I'll try this.
Updating may not be possible with this legacy app but that would certainly be preferred. You all have given me some good things to try. Thank you.
I meant class sorry for the typo
meant class soz
Then you'll probably need to supply us with the code you're using. Given the CS0119 error you're getting, it could just be a simple syntax error.
Removed: Spam. Please familiarize yourself with [Reddit's self-promotion guidelines](https://www.reddit.com/wiki/selfpromotion) and try to take part in the wider Reddit community and discussions. Reddit and /r/csharp is not a promotion/advertising platform.
You'd be better off using DTOs and serializing wrapper that lets you throw appropriate exceptions and logging to be able to react to these changes faster. But other than that most professional RESTful APIs are setup to allow server targeting; semver 2.0 dictates that the signature of an existing API functionality does not change within minor or patch releases. Additions only in minor versions and Bugfixes without API surface compatibility in patch releases... Basically the json output does not change it's signature during when targeting a specific major version. This is achieved most commonly by injecting the major version between the base URL and the root resource. Take Bitbucket for example. The API allows you to Target either dynamically on latest or specifically on v2 for example if you Target v2 all signatures are guaranteed to stay valid.
Usually people write encrypted password and login in registry, with a class begin used to decrypt login/password and use it on the connection chain. At least that's what we do where i work. 
n.p. I understand, I will add commenting, so you understand how I see it, its actually pretty simplistic. public virtual void ParseIt(object e) { //I use File System watcher to parse incoming files. FileSystemEventArgs FSEA = e as FileSystemEventArgs; string xml = File.ReadAllText(FSEA.FullPath); //where xml looks like &lt;tag attribute="value"&gt;value&lt;/tag&gt; split it apart by the end of the start tag. returning value(s) that should look like is &lt;tag attribute="value" and value&lt;/tag&gt;, I filter out value and portions with the tag &lt;/ in it. IEnumerable&lt;string&gt; tags = xml.Split('&gt;').Where(x =&gt; !x.Contains("&lt;/")); //split what could look like &lt;tag attribute="value" by space and return first one, which should leave &lt;tag remaining. var splits = from tag in tags select tag.Split(' ')[0]; //enumerate results from splitting var results = from tag in splits //get the start index of this tag. let Starts = xml.IndexOf(tag) //build closing Xml tag let close = tag.Replace("&lt;", "&lt;/") + "&gt;" //here's where it gets tricky //I want to have a shrinking xml string that removes what I have already parsed within the xml variable string itself. let Correction = from x in xml.AllIndexesOf(close) where x &lt; Starts &amp;&amp; Shrink(ref xml, x, xml.Length) select x let Ends = xml.IndexOf(close) //final step is to substring the result out of the string and check our conditions and remove that part from the xml string. This might work.. good ole' rubber duck debugging.. let nStart = Ends - Starts &gt; 0 ? Starts : xml.IndexOf(tag) let xstr = Ends == -1 ? "" : (nStart != Starts) ? xml.Substring(nStart, Ends - nStart) : xml.Substring(Starts, Ends - Starts) where xstr != string.Empty &amp;&amp; !xstr.Contains("&lt;/") &amp;&amp; Ends != -1 &amp;&amp; Shrink(ref xml, Starts, xml.Length) select xstr; foreach(var x in results) { Console.WriteLine(x); } } public static bool Shrink(ref string x, int y, int MaxLen) { if (y &lt; MaxLen) { x = x.Substring(y); } else { return false; } return true; } [edit] 2nd Solution is to move the function Correction before start... I like this idea more, thanks for letting me use this space to think it out. 
You could use integrated security, thus no passwords to store anywhere.
With possibility of amount of data being huge I would use SQL to do all grouping. Loading all data into memory and working there is fine when number of records is small (up to few hundred maybe) but when the number of records goes to thousands then such approach may become very slow and unusable. 
Yeah, actually diving into this doesn't help. It's just way unnecessarily complicated and out there. This line in particular is bonkers: let Correction = from x in xml.AllIndexesOf(close) where x &lt; Starts &amp;&amp; Shrink(ref xml, x, xml.Length) If only because you grab all the indexes, then iterate on them, but at the same time _modify_ the original `xml` that you grabbed the indexes from _as you iterate on it_. Seems very easy for it to mess up the indexes and have them pointing to the wrong places in the xml string. At the very least, I would say that this needs to be done in reverse order to muck up the indexes, but then I suspect that might also break your XML structure for multiple nodes. Then I got to the substringing the result out and gave up. Especially as one big LINQ query, this code is very difficult to parse, very difficult to understand (regardless of comments), and very difficult to debug (even with the debugger). I can't really help you to debug this. If you really want to do something like this, I suggest you restart from scratch. Break up the various tasks to separate methods, avoid one giant LINQ query. Toss in some automated testing (against multiple XML samples) while you're at it because there's a good chance you'll fix one thing then break another.
Why would I want to choose this library instead of already established one like serilog? 
When I try to use integrated security, I get` Login failed for user 'domain_name_goes_here\server_name_goes_here$'.` Does this mean I have to create the user `server_name_goes_here$` on the sql server?
I had considered using Parallel but didn't know it had partitioning functionality included with it. I'll definitely look into this. Thanks!
Wasn't sure if this was needed, I was trying everything. Thanks.
That user needs to be given access to the SQL server (via the Security section), just like any other user. The '$' indicates a machine account, which will work fine. Basically, add a user to SQL, copy and paste the entire 'domain_name_goes_here\server_name_goes_here$' name, and give it the appropriate read/write permissions to the database. You can also change what account gets used by adjusting the application pool in IIS.
Events are convinient properties for delegates. It keeps anyone but the owning class from invoking it, and you can add handlers for what happens when they are assigned (`+=`) or unassigned (`-=`). So events without accessors is like auto properties. public class Foo { private EventHandler _bar; public event EventHandler Bar { add { _bar += value; Console.WriteLine("'{0}' subscribed!", value.Method.Name); } remove { _bar -= value; Console.WriteLine("'{0}' unsubscribed!", value.Method.Name); } } }
CMD is easy. Squirrel can learn basic syntax in 5 minutes. When CMD is not powerful enough then Powershell can help but it is not fun. Some complex things are easy and some simple ones are frustratingly difficult. Powershell syntax sux. 
If it can be run, it can be decompiled.
mbUnit to nUnit because mbUnit got basically abandoned. nUnit to xUnit mostly due to parallelization support. MSTest to xUnit on inherited projects because, well, MSTest just isn't for me.
/u/Triterium has a good idea, but why do all that work yourself when you can just encrypt your connectionString/web.config file using aspnet_regiis Encrypt a connection string: https://msdn.microsoft.com/en-us/library/dx0f3cf2%28v=vs.85%29.aspx?f=255&amp;MSPPError=-2147217396 Encrypt a whole config file: https://msdn.microsoft.com/en-us/library/bb986855.aspx
Does this machine account need to exist on AD? I just tried copying and pasting without the $ into sql security and it said the account can't be found. 
Thanks for the input, I was just a playing at targeting structure rather then the data itself. I value your input and will probably redo this entire thing in a less functional way that is more easy to understand. I have never ending testing material to work from, AS2 connection that receives these files.. I've just been experimenting with new ideas in parsing through disassembling. I guess I will have to add range checks for nodes with children to really round this out... 
This is what we do (aspnet_regiis). No need for documentation too as it's already on the web. We can even encrypt large sections on the config file this way with no extra work. I wanted to note that this can be done for app.confg(s) too. You just need to run the exe as an administrator for it to decrypt the config file. 
Is it possible to encrypt a single connection string? I have 3 connection strings in the single web.config file.
I think you need the dollar sign. EDIT: Also, why are you running as a machine account? Are you trying to make it so your process can literally only be run from that one machine? If you make your C# code run as a normal AD user account (rather than the machine account of the local machine), you can then grant access in SQL Server to that AD account (and grant it read/write/execute on the databases necessary), and everything will work.
I absolutely always use integrated authentication (SSPI) so that the applications security context is used instead of messing with storing and securing passwords. But if absolutely must use stored credentials, some good options have been mentioned already for storing it securely.
Yup see the first link in my comment 
seconded - we do this as well, it's perfectly secure. integrated has down sides that if the machine is compromised you could get access just as easily if the impersonated user was the one that was compromised. There's more social engineering security worries than anything else, regardless of the path chosen. I've lost count of the times I've gone in on a consulting gig, found a password on a post it note that was for RDP into a server, which was also the user that was used for integrated auth to SQL. That's the very definition of "reckless driving" in software form - never been in an accident, so you have no clue what it means to get burned. One thing to keep in mind is to separate your deployment assets from whatever you keep in source control. Never check in production connection string (always do a transform) regardless of which path you take. 
So, I understand that having your username and password in the web.config in plain-text is a potential security hole, but that's only a problem if the web server has been compromised, otherwise how would someone have access to the web.config? The SQL server instance should probably only be allowing access from certain IPs anyway, so even if the web server is compromised, and someone nefarious has the username/password, they wouldn't be able to connect anyway (unless it's from the web server itself...but then you've got bigger problems to worry about anyway).
I am new myself but ActiveSheet will only save the sheets that are active correct? Just use Workbook.SaveAs( dummypath\\file.xlsx) or it Workbook.Save() 
The C# Player's Guide Third Edition is an excellent choice.
It's certainly a good exercise to attempt. There's a few tutorials and materials out there on rolling your own XML parser from scratch. It's one of those things that's easy to get something working for typical cases and you'll spend 90% of your time dealing with special rules and edge cases if you want to get it to be 100% compliant. But definitely worthwhile and you'll probably learn a bit even writing your own for the basic rules. If you write the basic parser and ability to iterate the nodes, then the making of a depth-first traversal of it should be trivial at that point. :) EDIT: But you probably not ought to use the custom XML parser in production. Leave it for funsies!
If I understand your problem correctly, you could use [MEF](https://docs.microsoft.com/en-us/dotnet/framework/mef/). I love MEF. public interface IMyClass { string Name { get; } void DoStuff(); } using System.ComponentModel.Composition [Export(typeof(IMyClass)] public class MyClass : IMyClass { public string Name { get { return "MyClass"; } } public void DoStuff() { Console.WriteLine("I did stuff."); } } Then you can use something like my [MefImporter](https://github.com/Bryan-Bennett/HomeSoft/blob/dev/HomeSoft.Shared/Components/MefImporter.cs) to wrap importing components. Usage: var assy = typeof(IMyClass).Assembly; //or whatever assembly contains the class that exports IMyClass IMyClass myClass = MefImporter.Import&lt;IMyClass&gt;(assy); Console.WriteLine(myClass.Name); myClass.DoStuff(); Output: MyClass I did stuff. Make sure your project references System.ComponentModel.Composition.
Any value you get from a 3rd party source should be treated as untrusted and should go through a validation by some centralized piece of code before you start using it. For example this api appears to return a list of predicted tags. I might write something like this: public interface ITagPredictionValidator { [NotNull] // nuget package Jetbrains.Annotations [Pure] TagPredictions Validate([NotNull]string content); } public class TagPredictionValidator : ITagPredictionValidator { // If the api changes, this class and the following method might need to change // but the changes should remain isolated to here [PublicAPI] class PredictionApiResponse { public TagPrediction[] Predictions { get; set; } } [NotNull] [Pure] public TagPredictions Validate([NotNull]string content) { PredictionApiResponse result; try { // JsonConvert enforces response has a root object with a Predictions property that is a list of TagPredictons // will through exceptions based on possible malformed responses // nuget package Newtonsoft.Json result = JsonConvert.DeserializeObject&lt;PredictionApiResponse&gt;(content); } catch (Exception ex) { throw new ArgumentException("Exception while deserializing json", nameof(content), ex); } var predictions = result.Predictions; if (predictions == null) { throw new ArgumentException("Content contains no predictions", nameof(content)); } // nuget package System.Collections.Immutable return new TagPredictions(predictions.ToImmutableArray()); } } public class TagPredictions : IReadOnlyList&lt;TagPrediction&gt; { private readonly IReadOnlyList&lt;TagPrediction&gt; _list; public TagPredictions(IReadOnlyList&lt;TagPrediction&gt; list) { _list = list; } public IEnumerator&lt;TagPrediction&gt; GetEnumerator() =&gt; _list.GetEnumerator(); IEnumerator IEnumerable.GetEnumerator() =&gt; _list.GetEnumerator(); public int Count =&gt; _list.Count; public TagPrediction this[int index] =&gt; _list[index]; } public struct TagPrediction { [NotNull] public readonly string Tag; public readonly double Probability; [JsonConstructor] public TagPrediction([NotNull] string tag, double probability) { if (string.IsNullOrWhiteSpace(tag)) { throw new ArgumentException("Invalid tag", nameof(tag)); } if (probability &lt; 0 || probability &gt; 100) { throw new ArgumentOutOfRangeException(nameof(probability), probability, "Expected in range 0 to 100"); } Tag = tag; Probability = probability; } }
Yes thats correct, but there's only one sheet in each workbook, and when I had this exact program using only one excel file the method I used above worked without issue. I think visual studio is confusing the workbooks for each other, trying to save the database as the QC report somehow. I will try saving just the workbook and see if that changes anything. Thanks for the advice.
Storing the credentials via environment variables using a common name for the environment variable. This is a very common scheme for most web applications outside of the dotnet ecosystem. Sure, the credentials are in plain text but are stored on the server itself. You'd need physical access to the machine to get them and if that machine is compromised - the environment variables are probably the least of your concern.
The problem I see with storing credentials in plaintext is that Web.config is traditionally committed to source control and that means you'd end up with secret credentials in your source control system. That's a bad idea.
True, except normally the web.config on the production server is different from the one in your development machine, which is usually the only one that's in version control. So yes, you have secret credentials in version control but only for the dev database which shouldn't have any private information in it. I treat the web.config in development as kind of the "base" one, and once a production server is set up I never re-copy the web.config, because the production one is always different in some way. Ideally it's only the connection string that's different. I suppose that's a minor risk because if the production server crashes then I might have to re-create the production web.config but it's presumably backed up plus the differences between it and the development file should be minor and easy to re-create.
Fair enough, but you only have the web site's credentials in the web.config. These credentials should have limited powers (by SQL server), and limited to certain IP addresses anyway. Sure, you end up with some "secret stuff" checked in to source control, but again -- if your source control is compromised, you've got bigger problems...
&gt; True, except normally the web.config on the production server is different from the one in your development machine, which is usually the only one that's in version control. Config transforms, my friend. If you haven't started using them, I highly recommend them -- *way* easier and less bug prone than trying to manually merge changes into a production config.
Putting stuff in an environment variable is really no different than just having it in a config file, no? Either way, it's plain-text, and you need access to the server itself to see it. Personally, I'd stick with a config file for easy maintenance.
Fortunately so far I haven't needed them. The changes have been so minor and so infrequent that it isn't worth using a tool. I don't think I've had to change a production web.config in years. But yeah, I can see the benefit of tools for any more complicated scenario.
&gt;integrated has down sides that if the machine is compromised you could get access just as easily if the impersonated user was the one that was compromised. There's more social engineering security worries than anything else, regardless of the path chosen. Granted, but if all you're worried about is securing the connections between a web server and a database, then granting access to the credentials of the server's process should be more secure than leaving additional connection info laying around somewhere to be found. If anyone but an administrator can log into the host system with those credentials then I'd think you would have bigger problems than social engineering afoot. 
&gt; I don't think I've had to change a production web.config in years. That is...shocking. We push web.config changes all the time, but we use config files pretty heavily. Need to change the timeout or endpoint for a third-party API? Web.config. Need to change the log level of the app? Web.config. Need to manage some hard-coded value? Web.config instead of having a constant somewhere. Anyway, yeah...web.config all the things, in my opinion.
As it stands in its current state, there probably isn't any major factor to choose this over an already completed library. But other than that, I don't know what serilog supports so I don't really know for sure.
Most of the configuration of my applications is done in the database. I store email settings, application flags, etc. in tables. That way an admin user can change them without somebody having to remote into a server. So I guess "database all the things" in my opinion ;)
If your working directory is wrong (result of `Directory.GetCurrentDirectory()`) you need to adjust it manually Use `Directory.SetCurrentDirectory(String)`, `Assembly.GetXxxAssembly().Location` and `Path.GetDirectoryName(String)` (`Xxx` refers to `Executing` or `Entry` depending on where the piece of code is located Executing = Assembly which executes this statement, Entry = The assembly you called to start the program, most likely the correct one) 
Simplest answer, have your script change to the program directory before running it.
https://github.com/txavier/AutoClutch A generic repository, generic service layer and generic OData controller for .net domain driven design onion architected web projects. You can see one of the web projects I have there to see how I use it. https://github.com/txavier/tractorspecs
There's something about the way this book written that helped me pick up C# after giving up multiple times. +1 for the recommendation. 
This one runs via getty, so I don't have full params like that. But thank you. 
yep - I make a killing on brown field development and security consulting on the side. It's scary how many people don't properly follow SOC and/or PCI for identity security. On paper the companies I work with all look great, but one walk around the office as an insider made me reassess how I share data with otherwise highly competent companies. Automation and cloud based solutions have allowed small teams of 5-10 people to do the work that used to take 50 - 100. It's super easy to do a "hey bro" security hand off to the desk next store and not even realize the negative implications when the delivery guy walks through with a camera phone on record (true story, though I can't tell you who it was). 
After the changeover I've done a few tests without it crashing. It appears that changing it to workbook.saveas has fixed the issue. Thank you for your help. Next I just have to figure out how to find the last used row in an excel file.
Ok thank you, never touched the AssemblyInfo.cs file before, but looks like I am going to learn about it today. Thanks for all the pointing, I think I should be able to work this into something. Though it seems like there should be a param ConfigurationManager.AppSettings no?
For settings that the end-user needs to change, I agree, the database is where they belong. But for apps that don't need that level of control, web.config it is. Most of our sites that we build on a platform of some sort use the database for config (as the platform supplies the admin interface), but if the app is 100% homegrown, we generally stick with the web.config because chances are good a developer will be involved with config changes for those apps.
Go to your main class (I use the name Program) and write static Program() { Directory.SetCurrentDirectory(Path.GetDirectoryName(Assembly.GetEntryAssembly().Location)) } just above/below `Main(String[])`
&gt;Ok thank you, never touched the AssemblyInfo.cs file before, but looks like I am going to learn about it today. Thanks for all the pointing, I think I should be able to work this into something. AssemblyInfo.cs is not required
Yes, for today applications you can just do that, I suppose :-D
Thanks, your solution seems very smart. I came up with this based on this, System.Configuration.ConfigurationFileMap fileMap = new ConfigurationFileMap("/opt/configs/File.config"); but I think changing directory to local path is best
I take it you didn't read the article about wrapping DI containers being an anti Pattern 
C# in depth by Jon Skeet is excellent and as the title suggests, goes in depth
I’m on mobile and struggling to parse the finer details of that document. Where is the encryption key stored? It says the encryption key must be available - but if the encrypted data can be decrypted by aspnet_regiis, and the encryption key is available, then surely a knowledgable hacker could easily decrypt your web.config and find the password? I have a feeling I’m missing something.
Thanks for that string, pretty sure from now on every program I write will have that at the top... seems like a win win win in literally all cases to set the path relative to execution - at least how I think of things in the linux world. I can't think of too many use cases where you would want to run your program from a different directly and operate on a local file. /opt/myprogram.exe image.jpg is about the only use case I can think but that is generally bad practice in the posix world. thanks again
Non-Root Programs in Write-Protected Folders? Or do you code in the directory VSCode is installed in? ;-) /opt is afaik also write protected so you need to write somewhere else... Common in e.g. C:/Program Files/... 
I believe it mostly comes into play with source control, and putting things up on [GitHub](https://github.com/blog/1390-secrets-in-the-code).
My guess is that the article was Mark Seemann since it's a DI thing and he is highly opinionated on the subject. And nope. I find that anyone who says X is an anti pattern is usually not someone that I want to listen to. He tends to fall into that category. My issue with the idea of "Never do X", which is what people mean when they say that X is an anti pattern, is that no one has any actual data. They're just saying their opinion. Give me actual data and I'll listen. Heck the design pattern book from the gang of four isn't even "this is how you should build stuff" design patterns. They were just a bunch of design patterns that they found people were using already and put it in a book describing them. But there isn't even any data attached to them saying that they're GOOD design patterns. Only that they're generic enough that you can use them as a template in a bunch of different situations. I mean bug rates, code churn, etc. associated with a pattern would at least give someone something to go on. But instead we're an industry of opinions...
For the class name string, try "full.namespace.path.Classname, AssemblyName" --EDIT-- For clairity String TypeName = "System.Text.StringBuilder,mscorlib"; Type ObjType = Type.GetType(TypeName); Object obj = Activator.CreateInstance(ObjType); MethodInfo method = ObjType.GetMethod("AppendFormat", new Type[] { typeof(String), typeof(object[]) }); method.Invoke(obj, new object[] { "1: {0} 2:{1} 3:{2}",new object[] { "One", "Two", "Three" } }); Console.WriteLine(obj.ToString()); //=&gt;"1: One 2:Two 3:Three" 
IMO it's very different than storing a Web.config file. Web.config is normally committed to source control which means you'd end up with secrets in your source control system. See my other comment in this thread for more discussion on why this is a bad idea.
Sure, those are best practices but this is the internet and we are all strangers so making an iffy recommendation probably is not a good idea. Source control doesn't have to be compromised. I have no idea who they are and what they are doing with source control. But there are countless stories of credentials getting pushed to public Git repositories. And speaking of Git, if you accidentally commit credentials then it's very difficult to remove traces of those changes from the history of the repository. I'm totally open to counter examples but based on these arguments, I stand firm that there are better solutions to storing secrets than Web.config.
Config transforms are useful, for sure. And goes back to my original point that this would encourage secrets getting stored in source control. Still a bad idea.
This is what i use private static int LastUsedRow(Excel._Worksheet sheet) { int row = 0; row = sheet.Cells.Find( "*", System.Reflection.Missing.Value, Excel.XlFindLookIn.xlValues, Excel.XlLookAt.xlWhole, Excel.XlSearchOrder.xlByRows, Excel.XlSearchDirection.xlPrevious, false, System.Reflection.Missing.Value, System.Reflection.Missing.Value).Row; return row; } Good Luck!
If it's been added to the domain, it should exist. If not, it may be more complicated to use machine accounts - in that case, consider creating a service account in AD, and using that account to run your application pool.
Here's the thing: WPF's DataGrid is retarded and Microsoft's documentation sucks. I don't remember all the details because I implemented grouping a year ago and haven't touched it since, but here's what I did: Set `GroupBySelector` of the `ListCollectionView`to a lambda that returns an instance of a custom class that extends `GroupDescription`. This lambda receives a `CollectionViewGroup` as a parameter, which is limiting, but you can store data in its`Name` property by overriding `GroupNameFromItem` in your `GroupDescription` descendant. Also, for each `GroupDescription` you have to add its child groups by adding them to `GroupNames`. This is by no means a complete explanation of what you have to do, but it's the best I can do without risking giving you misinformation.
C# via CLR if you want an in depth understanding of how the GC works for instance or how async/await work
 my bad I think I deleted the wrong double post.. :/
Removed: Spam.
No problem. I wouldn't ban you for that... or would I...?
I've usually got the username/password for my DEV database in the config, however I get the entire production connection string from a secure provisioning service. Not only are the production username/password pairs not there, neither is the production server name or production database name. My DEV database might get compromised, but I really don't care about that. There's nothing real in that database. It's all mock data.
You're the best. I had tried sheet.usedrange, I had tried Sheet.Range["B" + Sheet.Rows.Count.ToString()].End[excel.XlDirection.xlUp].Row + 1, I had tried sheet.Cells.SpecialCells(Excel.XlCellType.xlCellTypeLastCell, Type.Missing);... But yours works. Thank you this was driving me nuts.
Look up "Windows Forms" in combination with "High DPI".
That's why I have a separate app.config, and connections.config file, with the web.config referencing them.
If you're using TFS it's very easy to have SSPI locally, and have your deployment pipeline insert the actual credentials at release time based on the environment you're going to.
Wrong question. You should be creating an AD user specific for the application and registering that user in the database.
Bingo. You should build your web sites with the assumption that someone is eventually going to download all of your files, including configurations.
&gt; if the web server has been compromised Or if someone accidentally misconfigures it to expose that file to the public.
No, it is very different. Environment variables are much harder to leak than config files. The latter can be picked up remotely if your web server is mis-configured. Or from a misplaced backup file. Or accidentally placed in source control. *** I'm not saying environment variables are a good thing, just a less bad thing.
Duhh....... now I feel really stupid (; haha, still good stuff, will be incorporating a version of it as I always using Config files with my programs. Thanks again
Sorry for the hijack, seemed an appropiate place for my question since I just read about versioning. I manage an aspnetcore API where models are used for serialization and deserialization, If I would want to implement semvers (versions), how would I go about using different models with controllers for each version? For example, this is the current layout: * Models/ApplicationVersionModel.cs * ApiController -&gt; Post(JsonPackageModel model) JsonPackageModel contains a Result object which can be anything, such as ApplicationVersionModel. I use a wrapper package to stay true to the JSON-RPC 2.0 specification.
I don't think there is anything you can do client-side that will stop a skilled and determined hacker. Server side would work (e.g. like FairFight) but your model is P2P...
I see so many open-source projects in this topic that I would love to use for work but I just can't because when it comes to work and business it's a bad choice to reference third-party open source projects. Atleast that's what I've been told and I disagree and agree at the same time...it would require maintenance and updating.
That's the thing I don't get about security. This is not a topic I have the opportunity to dig in at work, so an explanation would be welcome.
Thank you guys, i appreciate your answers, i'll will check them out.
Modified it a bit to better represent the functionality. FileSystemEventArgs FSEA = e as FileSystemEventArgs; string xml = File.ReadAllText(FSEA.FullPath); IEnumerable&lt;string&gt; tags = xml.Split('&gt;').Where(x =&gt; !x.Contains("&lt;/")); var splits = from tag in tags select tag.Split(' ')[0]; var results = from tag in splits let close = tag.Replace("&lt;", "&lt;/") + "&gt;" let Corrections = from x in xml.AllIndexesOf(close) let Starts = xml.IndexOf(tag) where x &lt; Starts select x let work = from Correction in Corrections where Shrink(ref xml, Correction, xml.Length) == true select Correction let Starts = xml.IndexOf(tag) != -1 ? xml.IndexOf(tag) : -1 let Ends = (work.Count() &gt; 1) ? -1 : xml.IndexOf(close) - Starts &gt; 0 ? xml.IndexOf(close) : -1 let xstr = Ends == -1 ? "" : Starts &gt; 0 ? xml.Substring(Starts, Ends - Starts) : string.Empty where xstr != string.Empty &amp; /*!xstr.Contains("&lt;/") &amp;*/ Ends != -1 &amp; Starts &gt; 0 ? Shrink(ref xml, Starts, xml.Length) : false select xstr; foreach(var x in results) { Console.WriteLine(x); } I commented out the part where I filter groups. some groups it parses extremely well.. the standard xml stuff it does great, but the flex xml section it fails where values are attributes.. More work todo, but this should be testable by you at the very least.. :]
Cool I didn't know this! Can someone explain to me how the use of scopes inside functions would be useful? I always try to make functions as small as possible so is there any practical use except for tidyness (which I would achieve anyway)? Example: void main() { var value = GetValue(); //instead of the scope shown in the video Console.WriteLine(value); } On a side note, a colleague recommends small functions just like the above instead of long ones (w/ scopes?) but I have always wondered about the performance impact. 
Yup, this is a known issue of Windows Forms, which was not designed with today's high resolutions in mind. Check [this stackoverflow answer](https://stackoverflow.com/a/4076259/3283203).
But in all fairness, consoles are free of hackers because their OS is isolated and cannot be easily tampered with (if at all).
There's nothing wrong with storing credentials in your web.config. The reason people tell you it's not safe is because your web.config will be committed to source control. If you share your code with anyone, you will share your credentials. Make sure that access to your code is tightly controlled. You can encrypt the web.config file, but there's little point. If anyone gains access to the machine your site is running on, you've got much bigger problems.
Is this supposed to be some kind of 'amazing' feat?
If you want the most detailed perhaps check out the Microsoft site, they have their own guide and gets into the nitty gritty of the language. In terms of understanding the subject, application and building things is what I hear gives you the most benefit. But don't take my word for it. I'm new. So I don't know how much I can help. https://docs.microsoft.com/en-us/dotnet/csharp/
To explain why this is being downvoted: This is a SINGLE line of code. It does NOT need to be a video. There is nothing gained by using this video over googling it, and copy-pasting off the first result. It does not provide any reasons for using this compared to other metgods, either (e.g System.Environment.UserName).
I just looked at it and I bought a copy. Its written in everyday language anyone can understand.
And for those who've done some FPGA development: [here's a Vivado project](https://github.com/Lombiq/Hastlayer-Hardware-Framework---Xilinx) for Xilinx FPGAs that hosts Hastlayer's generated IP core. It contain memory management, Ethernet and UART components and uses a softcore MicroBlaze processor to run a C++ program which deals with the higher-level aspects of Ethernet and serial communication.
&gt; C# Player's Guide Great book, but definitely not "In depth"
No.
There is no reliable way to validate anything on the client side. That's why everything that's important should be validated by the server. As the files are on the client machine, they can be tampered with. There is no reliable way to prevent this. Even the strongest anti-tamper solutions, e.g. Denuvo, Arxan, do not hold off determined hackers for very long. If you want something good, it will cost you big. If you're protecting something valuable, it won't last very long, even with that expense.
You can encrypt databases. Using SSPI makes it so credentials are not in plain text anywhere. It's a small bit of effort to cover a large vector. That means even gaining remote access to the machine doesn't necessarily compromise your data. The next step is to secure what objects the SSPI login can access. For example, you can prevent direct access to tables and only allow the login to access procs. Also strip out schema mod permissions from the SSPI login. I can go on a bit about locking that stuff down more. Naturally your SQL box should be separate. The admin remote logins should not be used for your web portal either. Don't let your web portal login compromise root box access. Might sound like effort but if you want to do security right and not be incompetent and compromised like the Yahoo or Equifax you really should close as many vectors as physically possible by default rather than a "she'll be right" attitude.
Depends on what you're going to be building. If you're going to be building client-side applications then you can probably go without JS. If you're going to be building Web applications then you're gonna have to use JS. But you still may not have to LEARN it. There are so many frameworks out there that hide a lot of the functionality that you're hardly even writing JS anymore. You're writing that framework's domain language instead. OR, if you only need really simple JS (for event handlers, etc.) then you can get away with only knowing a small subset of the language and just copying and pasting like crazy. I have been doing ASP.Net web applications for well over a decade and most of the JS I write is 3-line functions. If I need something complicated, I google it and find that somebody else has already written what I need. So I just use and/or adapt that. On the surface JS is a really simple language. And as long as you just stay on that surface you can avoid any of the goofy stuff. You can create quite complex applications without going any deeper.
Wow this is quite a change from all the Orchard CMS work you guys were doing!
&gt; Is it possible to become a c# developer without liking or knowing Javascript? Yes. The two aren't related in any way. Whether or not you'll be using C# and JS together depends entirely on the job.
Did I hear you say C# and JavaScript? Maybe http://bridge.net can help wrap your mind around some of the differences? Test online at https://deck.net. 
Yes, but if you want to branch out into front-end web development, I think JavaScript is a fundamental skill.
I'd agree with this, I wouldn't say I "know" JavaScript, but I have enough knowledge of the syntax (nearly the same as C#) and basic ideas to be able to Google it. For form validation and other simpler tasks there really isn't much to it
I reread your post.. I need to make a correction to what it does, I gather a enumerable&lt;string&gt;, not a enumerable&lt;int&gt; so I dynamically grab the indexof by each string I gathered, avoiding indexing mistakes, this is the reason I wanted to clip off the parts in the xml that I already used; so I wouldn't dynamically index a old tag ;) 
Very very very very generally: no. Not if you want to do web. Simple as that. If you want to work in web you need it. Most companies I've seen and heard about through over two dozen friends in the industry, demand at least some knowledge of back, front, mid... or html, css, js for front, c#, java, php for mid and sql for db. Those are the "basics" where I am. If you don't know js you simply don't get hired. For web specifically, you NEED js. Just how it is.
jQuery &amp; javscript frameworks (angular, React, etc.) also make using js much easier. Also, I don't recommend using React due to their change in licensing. I just used it as an example of a front-end javascript framework.
It's great exploring the space by implementing something from scratch, even if there are established options out there, so kudos for that! Just a thought - the expression-driven formatting is cool. Serilog has a superficially similar output text formatting system, but it doesn't go as far as to support conditionals or other constructs that would sometimes be useful. There's a plug-in interface `ITextFormatter` that Serilog can use for alternative formatters... We ship the default plain-text one I mentioned, plus a couple of JSON formats (e.g. https://github.com/serilog/serilog-formatting-compact). Building a more powerful expression-driven one would be a fun project, if you happen to be interested in going further down that path?
Generally, you shouldn't assume your program is being run from any particular directory, or attempt to modify the environment's current directory. That is usually fragile and has broader ambient consequences. Instead, if you need to access bundled assets, you should use paths relative to the app executable or install location -- depends how you deploy your stuff. `AppContext.BaseDirectory` is a decent option to use here, or something like `Assembly.GetEntryAssembly().Location`.
C# the language has absolutely nothing do so with JavaScript. Your problem seems to be deeper than "JS bewilders me" You might want to check out ES6 - which is slowly being adopted by all major browser vendors - and it's a simplified superset over javascript. It's syntax, especially the OOP part, has a lot of syntactic sugar to make it easier for novices to get started. Spend some time on youtube/google JavaScript/ES6 Books etc. There is a ton of beginner material to learn the language online. And almost all of it is free.
Microsoft have a close relationship with TypeScript which makes JavaScript a lot less painful. Whilst there are C# careers that focus on other things, allowing yourself to have *some* limited contact with client side web tech by having TypeScript will ease some of the pain potentially.
Yes, just stay away from web. I don't like web for lots of reasons and javascript is one of them too. You'll have to be prepared to really work hard on your core skills though to make up for the fact you're shutting out a majority of the .NET job marketplace.
TypeScript
c# in a nutshell, the best.
Do you know SQL? I mean really know SQL, like windowing functions are your best friend. For a "web developer" like me JavaScript is completely optional. I spend all day building databases and installing C#/WebAPI servers in front of them. JavaScript, C#, SQL: Pick two and you'll be ok. All three, then you've got options.
I haven't written a lick of javascript in ages. Last time I did front end html was 4 and jQuery was out there, but we weren't using it
And since he's the genius behind Stack Overflow, you may as well throw a few bucks his way. I mean, where would we be without him?
I don't want to come off as mean but if you can only barely read javascript, then you might want to brush up on your C# skills. Yes javascript sucks, but at the end of the day the syntax is very much like C#'s. I'm not saying you should be able to write complex applications with it, but you should at least be able to read it well enough to know what it is doing. To answer your question, yes you can get a job with C# without knowing javascript, just not in the web development field.
Yes easily. There are a lot of server side or backend devs who know very little about front end technologies. I've hired tons of them over the years. 
You could look at something like Wisej Or SteveSanderson/Blazor project on github
Also, this is not only "in C#", but also "in .NET". A distinction worth mentioning nowadays.
Behind? More like on?
Depends. My company is SAAS, basically a website. I just work on the back end side of things. In addition to c#, i ask people about sql and nosql in interviews. But couldn't care less about their js
Options: Read it from an environment variable. Have your deployment process set the env var. Pros: 12 factor design. Cons: whatever sets the env var still has to store it somewhere. A system like consul.io (or vault) holds the data. All you have in source control is a temple file. Use consul template agent to read consul and fill in your template file and save the normal config file where you expect it. Pros: code doesn't change. Cons: need to set up consul or vault. Encrypted registry values were mentioned above. That's what we're moving away from. While it's possible to automate, it's a bit tricky (for us, puppet executes powershell that loads one of our dlls to do the encryption). Works though, and has served us well the past decade. Pros: keeps the data out of your config file is about it. Cons: not possible to port to mono / .net core (no registry in Linux)
If you're running IIS you ideally run as application pool identity, not a domain user. AFAIK trusted connection means a domain user account
IIRC asp.net transparently decrypts the encrypted config file and then _writes the plain text one back to disk_. So we've never used it
Application pool identity is the preferred security mode for running IIS. Blocks a whole category of privilege escalation bugs off the bat. And... disallows using trusted connection for sql. If they want to make this more secure, seems not the right direction
Or Jenkins. I'd rather put it in an environment variable than a flat file though.
Go to github.com. Search for "password". It's shocking
Security step 1 - developers of a web app should not need to know the login credentials to production databases. Putting them in web config requires them to know them. If you know them, you then have a massive possibility of developers querying it directly with no controls. Possibly even updating it. I write our database and encryption libraries. I'm super happy to not know either the prod db login credentials or the prod encryption keys. Putting them in environment variables or consul.io allows devs to not know and not care what they are. You have no reasonable expectation that anything you have in git , ghe, or svn can ever be tightly controlled
JSON is not *magic*. If they change their format enough, it'll fail to recognize it, so it will barf in one way or another. Perhaps it won't recognize there's any data there, or perhaps it will barf on the data filelds. (What happens when you call SelectToken and it finds nothing? That's what you need to ask yourself.) 
I'm a .NET software engineer exclusively working with C#, and I haven't ever touched JS with a ten foot pole. In fact, in my experience (Minneapolis area) nobody in C#/.NET uses JS much at all. So, yeah, there's a ton of jobs like what you want!
That depends on your situation. In my case, I'm the API developer. I'm the website developer. I'm the app developer. The game developer. The database admin. I'm the everything. I need to know everything. You probably won't have credentials to the production database in your web.config anyway - I suspect that like me, many people will alter the web.config after deployment to use the production credentials, rather than the credentials for the development database. The guidelines from Microsoft are for people like you, who work at companies. For someone who works for themselves, it's not really an issue. For someone who works in a group of trusted people, as all people working together should be trusted; I don't think it's an issue there either. 
In addition to what you've already found from the Event Viewer, you can gain additional insight from Microsoft's Application Insights. For your reference, status code 500 always indicates a server-side exception. You can log these with Application Insights and access them from the web.
I mean WASM is going to replace Javascript soon anyway so it will be possible to write C# client code.
It is tough. Developers do not have enough time to figure out even "big" stuff so all smaller things must be really shiny to be visible. 
As a noobie I have to ask what kind of hardware do I need to run this? Can I run it on Azure or AWS ?
If you want to make a web application only in c# there's a way. Try this framework [dotvvm](https://www.dotvvm.com/). It uses knockoutjs to create mvvm pattern to communicate between fontend and backend. But you don't need to write any js.
The idea of Azure and AWS is to get away from hardware and do everything on virtual machines that are HW-independent, which gives you unprecedented options for management, load balancing, performance sharing etc etc. From what I see, this project follows opposite philosophy, processing as much as possible on very specialized hardware, which could drastically enhance performance of some tasks, but binds the software to specific hardware on specific computers. ~~So I feel that I can say that no, you can't use this on Azure or AWS.~~ I was wrong, apparently some hosting companies provide this functionality. Which is awesome. 
I can do that, but I may still work on WaterLogged. It's really the first project I've uploaded to github and actually kinda care about. It should be pretty easy to rip-out the parser and re-use it for serilog. I'll start exploring serilog and see what I can do.
Best not to be picky when it comes to your software development career, as language changes are only going to get faster. So, if you have trouble learning Javascript, your career will get very frustrating, very soon. However, if you are not doing web development, the need for Javascript knowledge will usually only ever come in the form of understanding the JSON format. Saying that, nodejs is a great tool to have knowledge of, as a analogue to powershell for various supplementary task you will do as part of software development. Specially if your work involves text content or data manipulation.
Indeed. I can't really think of asmything to make it "shine" either.
As an example of a framework whose focus is not to have to write JavaScript, see [DotVVM](https://www.dotvvm.com/). If you end up having to write JavaScript in bigger amounts, you can also use something like TypeScript that tries to make it more sane. It might be overkill for 3-line functions, but it really helps with bigger code.
As other people have stated the two languages are in no way related and they solve completely different jobs. So to answer your question: Yes. However, I would say that most good C# developers should be able to easily learn most languages with a similar syntax. Both languages have extremely similar syntax and the code looks similar. For example, this statement is the same in Javascript and C#: `for (var i = 0; i &lt; 100; i++) {}`
I'm currently a third-year student at university (Software Engineer degree) and looking for a book to read in my free time. This book is recommended for middle level and I guess I'm not one of them. We went through the basics of OOP, events, delegates, threading, SQL, Linq, async etc. So, is that book worth a time for me or I should look for less advanced book?
Sooner or later you will have to learn JS. You also cannot become a web developer without JS. If you want to use C# and never touch JS best bet is unity game development.
As long as you know the basics you should be fine with this book. Some parts will definitely need multiple readings before you get a firm grasp of it though. I've been through some parts at least three times and still consult the book from time to time. The book is built up around the c# versions, i.e it starts with the features in c# 1 and builds up to c#6 (or maybe 7 if a new edition is out now). That way you sort of get a soft start (although there are some tricky parts in the earlier parts as well). Buy the book, you won't regret it. And even if it is a bit above your current level, you will have a great book to come back to later. 
C# has been my favourite programming language since I started and I've always disliked JavaScript. I'm proficient in both nonetheless. They are completely unrelated. Unfortunately you can't do much web development without JavaScript.
&gt; To begin working with Hastlayer you'll need the following: &gt; Access to Hastlayer Remote Services, which does the actual .NET to hardware transformation. Evaluation access is currently free and you can request it via guys@hastlayer.com. It looks like this is mostly just an SDK for accessing their web service that does the actual translation. While still useful, I think calling it "open SDK" is misleading.
There are cloud machines that give you access to FPGAs. For example, [here is one from Amazon](https://aws.amazon.com/ec2/instance-types/f1/).
My guess is that it should work, at least in theory. [Amazon calls their FPGA AWS instances "F1".](https://aws.amazon.com/ec2/instance-types/f1/) [Microsoft is planning to offer FPGAs in Azure soon.](https://www.top500.org/news/microsofts-plans-for-fpgas-in-azure-should-worry-traditional-chipmakers/) Though it seems this only currently works on a specific kind of FPGA and AWS uses a different one.
Wow, I didn't know about this.
Removed: Spam.
What change in licensing?
Yes. There's plenty of C# development that has little or no JavaScript. It's also kind of limited, in that it's going to be back-end development: C#, SQL, and little-or-no UI. Learn JS, though. Your options are still a lot wider with it than without it. It shouldn't be that big a barrier.
Close, meaning the guy who created C#, and Pascal/Delphi before it, is also the guy behind TypeScript
The others have answered this pretty well! At the time you need [a very specific FPGA board](http://store.digilentinc.com/nexys-4-ddr-artix-7-fpga-trainer-board-recommended-for-ece-curriculum/). We're evaluating which direction to take next to provide some more serious performance than a development board. E.g. support the AWS FPGA VMs or bigger FPGAs for local use.
&gt; explain to me how the use of scopes inside functions would be useful The use cases for a block without a control statement (if/else/for/foreach/while/do/switch/using/try/catch/etc) is pretty limited. Some folks like to have them around switch case bodies, which allows them to reuse local variable names across multiple cases without some weirdness owed to switch's generally crufty nature: switch (foo) { case 1: var x = 2; Console.WriteLine(x); break; case 2: x = 3; Console.WriteLine(x); break; // etc vs switch (foo) { case 1: { var x = 2; Console.WriteLine(x); break; } case 2: { var x = 3; Console.WriteLine(x); break; } // etc the use of blocks causes the declaration of x to be scoped to the case, instead of the whole switch. Once in a very great while, I've found it handy to be able to do this in other contexts, but I think a separate method would make a lot more sense in all or most of those. So, something that may be of interest is that { } is a statement that can contain zero or more statements. Consequently, you can throw a block in pretty much anyplace you throw in a single statement, and, often, vice-versa.
Well yes :). Though it still uses Orchard as an underlying application framework with [Orchard Application Host](https://github.com/Lombiq/Orchard-Application-Host).
Removed: Spam.
[removed]
You're right that not the whole of Hastlayer is open source (though the parts that aren't are still free to use) but that is also not something I've stated; sorry if it came over as misleading. FYI it also contains the [FPGA-PC communication component](https://github.com/Lombiq/Hastlayer-SDK/tree/client/Hast.Communication) which is a very important part of the system, also showcasing how dynamic proxies are used to provide the "now your method call runs on an FPGA" experience which I find quite entertaining (though I'm biased because I've written it :)).
Shall we split hairs then? Or would you care to just make a small effort to understand what I'm saying?
Still, if it's in web config in prod, any attacker instantly knows what it is if they get in. Yes, if they're in they can dig it out of environment variables. Or find the consul token and URL there, and dig it out of consul. It's just good to not make it too easy for them. On the other end of complexity from you - we have dev vms with one password, 8 qa environments with different passwords, and three production datacenters. Simply swapping A with B wouldn't work for us regardless of security, we needed to externalize the credentials just for the site to run
https://blogs.msdn.microsoft.com/ericparvin/2015/04/14/how-to-add-the-applicationpoolidentity-to-a-sql-server-login/
Encrypted with what? We do the same, so I'm curious. We actually load crypt32.dll and use "machine encrypt". That way it's different on each box, and there's no external key to manage
We have a private encryption class wanted by our customer. So it's a totally encrypted by us.
1) Bob Tabor's course is great for drilling-in the concepts. IIRC, it was the exercises and the videos that went over them that were painful enough that you felt sure that you were going to retain the content. 2) The exercise files were downloadable, but I don't think the videos were, this was as of a few years ago so that might've changed 3) Most would say contribute to an OSS project, but I know how hard it is to get the courage to do so. I believe that getting familiar with Unit Testing and finding a favorite workflow for picking a testing framework and starting a new project with it was really helpful for me. The reason is that there is quicker feedback for what your intent was/is and whether or not you've achieved that intent. I basically don't like waiting for the debugger to start up every time I want to check my code, and writing tests is yet another exercise in writing code. I used to enjoy just finding a problem, writing a solution, testing it, and sticking it on github to exercise those muscles. 4) Knowing SQL really helped me because I knew it well before I knew C#. IMO it's easy to pick up and helps you when you choose to start using Entity Framework and think that you don't have to ever touch your DB again, then all the sudden you do. 5) Pluralsight's good if you are a visual/audio learner. I'm not, I have trouble concentrating so it's better for me to look back in a book to re-read things. I'd definitely suggest it for auxiliary learning, coupled with whatever really helps you grok stuff.
I didn't know you could do that, cool. But you need to create a login per computer, not cool. We routinely add new web servers and kill others. If you only have a small fixed number of web servers that could work
It seems that I also prefer books and, as you said, I often need to re-read certain things. Would you recommend to read C# in Depth right after C# Player's Guide? Or probably C# in a Nutshell could be better? Thank you for your kind advice. 
Thanks for producing an example that can be easily copy/pasted. Unfortunately, I can't seem to find anything immediately obvious. I even tried simplifying some of `for` loops in case there was some rounding/creep from all the arithmetic. (Simplified to use basically [compound interest/depreciation formula](https://mathspace.co/learn/world-of-maths/loans-and-depreciation/applications-of-compound-interest-depreciation-12337/losing-value-581/)) Got the same incorrect results. Even tried using `double` instead of `decimal` everywhere, same wrong results. At this point, I would try to validate the data set you're checking against. _Ideally_, you would have a set of correct data that also tests the different depreciation factors independently. That is, a car that is 60 months old, but driven 0 miles, 1 owner, 0 collisions. (Repeat for the other factors) EDIT: Though... the fact that the first two tests (from 50k to 150k) miles made such a big different might point to something. EDITx2: Got it. The exercise isn't expecting you to use compound interest/depreciation. For example, it's not: for (int i = 0; i &lt; AgeInMonths; i++) { CurrentValue = CurrentValue - (CurrentValue * 0.005); } But instead it's just: return CurrentValue * (1 - 0.005 * AgeInMonths); If you update this calculation and the miles and collision depreciations to just use simple multiplication and not compound depreciation, you get the correct answers. EDITx3: [.NET Fiddle proof](https://dotnetfiddle.net/PFfOdG)
One of the biggest things I see lacking in the developers I interview is an understanding of object oriented design and why different constructs are used. The best book I have encountered for this is [Head First Object-Oriented Analysis and Design](http://a.co/hiO3V9Z). The code samples are in java, but the concepts apply to C#. My next recommendation is to look at design patterns. Pluralsight has a great [course](https://www.pluralsight.com/courses/patterns-library) that has several design patterns explained. It's not meant to be gone through beginning-to-end. Pick a pattern and research it. Write some sample code that illustrates the use of the design pattern. Try to write up an explanation of the design pattern and how it is used as if you were going to post it to a blog (or actually post it to a blog). This process will help you really learn the material. Lastly, look at [Clean Code](http://a.co/iHUbgRV). This is fairly language agnostic and all about writing code that is easy to read, understand and modify. I see a lot of developers that write code that might work but looks like a pile of garbage. Methods are hundreds of lines long and hard to follow, code is repeated in numerous places, variables and methods are poorly named and there is very little encapsulation. These topics will help transition you from someone who just "slings code" to a "software craftsman". There are other things that help down this path, but these are my recommendations.
Can be by many reasons. Is depreciated algorithm using decimal or just double? What about this? Integer NumberOfMiles / 1000
I can’t answer any question except 3 but the trick to learning and mastering any language is simply “write more code.” Doesn’t matter why you write. You can write something that exists. Simply think of something and implement it. Then post it here or somewhere else for review. Take their advice, and write your next thing better. Then repeat this as people pay you to write c#. 
I've only referred to C# in Depth for better understanding of deeper stuff, but anything by Jon Skeet is legit. This and the CLR via C# are, IMO, tough reads but high-reward.
The odds are not good. Web related jobs are king right now, and employers will always prefer developers who can do both C# and JS. It's a necessary evil of our industry right now. I'd advise doubling down and finding someway to get comfortable with it.
From [technet](https://technet.microsoft.com/en-us/library/cc771170(v=ws.10\).aspx): &gt;The identity of an application pool is the name of the service account under which the application pool's worker process runs. A service account can be granted access within sql server via integrated security. 
Or you could add it as a step in your build/decom process for a web server. Potentially you could also make an AD group that contained these DOMAIN\server$ logins only, and just add/drop from that group. Then grant the group access to SQL. Not 100% sure that would work but it just might.
Tbh wouldn't it be more future proof to look into the Mono C# to WASM compiler?
How accurate and well-written do you find the C# programming guide on MSDN? I might be biased here but it so far seems inferior compared to the documentation of Python. Some sections really helped me better understand some concepts whereas others (in my humble opinion) lack structure. 
Accurate, sure but well-written is another thing. If it were perfect, then people like me wouldn't have readers looking for better explanations of stuff on their blogs :) I'm always looking at MSDN though for stuff I forget about, especially the sample code and the lists of public members available to you so you don't accidentally end up hand-rolling some method that's already there.
This is great. I remember some buzz about FPGAs on Azure couple of year ago but no more info after that. I am dreaming about speeding up some of my code in the cloud. Never tried it, no idea how it works but man can dream! :)
On Azure FPGAs are not yet publicly available, but I'd guess they'll soon will.
A service account is just a user, either a local user or a domain user. The security preferred way of running IIS is applicationPoolIdentity instead of a user account. In that setup you grant access to IISAPPOOLS\DefaultAppPool instead of MyDomain\sa_foo or MyServer\sa_foo. The goal is to prevent user account escalation bugs.
You could add it as a step, but Jenkins would then need to be able to use a dbo credential to create accounts on sql server. I'd just rather Jenkins not have a dbo level sql credential :)
Love reading this PRs. Kind of surprised this wasn't done by /u/ben_a_adams when I initially opened it.
dumb question, this should make `dotnet build` faster right? If so, pretty excited about this one
I wish Jon Skeet had written a more down to earth C# book :) Something like Professional Javascript for Web-Developers which I like very much and consider to be the best Javascript book (apart from Kyle Simpson's works under the YDKJS series). Reading documentation is vital, but I think that you should ideally have a solid grasp of the fundamentals in order to benefit from reading it. This is why I'm looking for some source of information to get fluent enough in C# so that I can only use references like MSDN and read more advanced books like that by Skeet or Richter.
Sorry m8, a service account is a principal as is a user account. Principals are the entities which are given/denied access via integrated security. As of Win 7 there is no way that I know of to run a process in a windows environment without credentials. If you have windows just fire up sysinternal's process explorer, enable the "User name" column, and you'll see the names of the user/principal each is associated with. Some should be service accounts. IIS isn't a special process that circumvents the rules. Edit: you'll have to elevate process explorer's credentials by running as administrator to see all of the principal names, otherwise you'll just see "access denied" on quite a few.
Lots of open source stuff here with documentation etc. Most of these are on NuGet as packages that you can use, too: https://github.com/jchristn?tab=repositories - 
Not sure if you figured this one out yet, but my solution for grouping in a data grid looked like this: https://i.gyazo.com/e09de9afa1878c267643866d2bfc363a.gif Before I go through the trouble of sharing how it works, let me know if you still need it.
Thank you. That was really informative. Are there any worthy alternatives to the Head First book on object-oriented design? Honestly, their style is absolutely not my cup of tea, I have seen their C# book and I couldn't even figure out how to navigate in that chaotic flow of pictures. I will take a closer look at the Pluralsight course on design patterns. As for Clean Code, I have seen it mentioned so many times as a must-read for any developer that there's no doubt I will start reading it. 
You're running into a common problem and, sadly, there's not an easy solution. The articles and solutions people will give you will all be highly technical, and very confusing without a lot of fundamentals. I'm going to write a lot, but I promise you you'll understand at least why this happens in the end if you soldier through. You need to know the "WHY?" in order to grasp any of the solutions, because they are all stupidly complex. I'm going to start with a sad, uncomfortable truth that could start a flame war from people in denial: &gt; Windows Forms is a very bad framework for writing applications on a wide variety of displays today, and should be avoided. Unfortunately, most books cover it almost exclusively. WPF would be a better idea for a 'starter' framework now, but for many reasons it hasn't had a lot of books about it. OK. That out of the way, let me explain what's going on. Windows Forms is based on GDI+, which is a little bit of extra features on top of GDI, which is the framework that was used for Windows applications starting in Windows 3.1. It's had a lot of features added over the years, but somewhere in the early 2000s it quit receiving updates. More importantly we have to remember the bulk of GDI was designed in a world where 640x480, 800x600, and 1024x768 were the monitor resolutions almost everyone used, and the concept of a high-density display was reserved for super-specialized tasks. When old-school developers wrote GDI applications in C, it was easy to support high-density displays but no one worried about it because they practically didn't exist. In theory, all one had to do was write some code to ask the display for its density, then use that as a scaling factor. So if something was 45 pixels high on a 96 dpi display, and you got a 200 dpi display, you could easily figure out it needed to be 45 * 200 / 96 = ~93 pixels tall on the 200 dpi display to be the same physical size. All of this was laid bare before you and if you wanted to do it, you could. You can still do that in Windows Forms, and it's one of the solutions. The Graphics class has a DpiX and DpiY property that will tell you the display density in either dimension. You can pick some baseline unit like "96 dots per inch", lay out your form using inches, and always converting from inches to pixels using the display's density as a guide. This is very tedious and there's no way to talk the designer into helping you: you'll be doing all your layout by hand. (Incidentally, WPF and all the newer frameworks do exactly this. They don't use "pixels" but "device-independent units". Something that is 48 units tall in WPF is 1/2" tall on every monitor, automatically. This is one reason why it's better to use it today.) Microsoft didn't want to bother Windows Forms developers with that, and when .NET was released in the early 2000s high-density displays were still rare things. But some people used high-DPI in Windows settings for various reasons. So they tried a simple approach WinForms called "auto-scaling". When you design the form, VS stores some magic numbers derived from your display and they get compiled into the application. When you start the application, the magic numbers are recalculated and compared to the ones that were stored when you designed the application. If they are different, the ratio is used to resize everything on the Form. The original algorithm was pretty bad, and most people who needed to support high DPI turned it off and had to do a lot of work. So around .NET 2.0 they tried another algorithm. It turns out it was bad in some cases, too, but better than the last. Windows Vista tried to address it with OS-level scaling, that had issues too. By the time Windows 7 came out it was a big problem because tablets and higher-density displays were becoming a thing. So it introduced new algorithms, they also failed. Windows 8 made several attempts, and I want to say Windows 10 has had its algorithm tweaked at least 3 times already. The problem with all of those algorithms is they try to be one-size-fits-all, and it turns out what you need to do to support high DPI is a little different for every application. It's easiest if you use a framework (like WPF) that was designed with screens in a myriad of resolutions in mind. All of the frameworks like "Modern Windows Applications" and UWP are grandchildren of WPF, and so long as you don't go out of your way to break them they will happily scale up and down on different displays. Odds are, on your new computer, Microsoft has tried to "help" you. Most dense displays ship with the scale set to 125% or higher. This is a ham-fisted attempt to try and save you from apps that have never been updated to high DPI. But this also means the numbers that Visual Studio sees at design time might not match the numbers your application sees. It's also likely that Visual Studio is applying one scaling algorithm, and the OS is applying another, and neither is aware the other is doing it so they interact poorly. It's a big mess. So with that history in place, let me attempt to explain the StackOverflow bullet points /u/kilazur linked in order: * If your OS DPI scaling is set to higher than 100%, all Hell is going to break loose. This has never worked well with Visual Studio and it's especially bad on actual high-density displays. * AutoScaleMode is the "Windows Forms" scaling algorithm. You have two choices: font scaling or DPI scaling. You would think DPI scaling would be smarter, but Font scaling tends to work a little better. Both have scenarios where they fail. * Having multiple font sizes just makes things more complicated. * If you mix AutoScaleMode algorithms, all Hell is going to break loose. * These are the "magic numbers", if you force Visual Studio to use a lie then you have more control over how the algorithm works. * But you'll have to edit this line EVERY TIME you change something in the designer. * (I think the next two are explained well in the SO post.) I don't think you should return your computer. Someday you're going to have to own a machine with a high-density display. The problem here is WinForms is plenty outdated. MS has been trying to get people to migrate to WPF since about 2010. Most of the developer evangelists who could've affected that change moved to iOS or Android because MS really screwed us over in the 2010-2015 timeframe by breaking several promises in a row. I personally wasted about 4 years of my career on a framework MS discontinued a week after promising it was a long-term bet. The fact is WinForms is outdated, and school coursework is even more outdated. I love the Deitel &amp; Deitel books, so that's not a bad choice, but you're going to have to jump through some hoops to get WinForms behaving on a modern machine with a modern display. Look at it this way. Your monitor probably has a pixel density upwards of 200 pixels per inch. The book is expecting 96 pixels per inch. So when it tells you to make your Form 274x400, it's expecting the Form to be 2.8" x 4.1". But on your display, those particular dimensions will render as 1.3" x 2", which is very small for a Form and probably unusable without squinting really hard.
What's the Ebook class? Need more info on that. If it's a third party then it's mostlikely a bug in their code that's causing it. Edit: try forcing your default culture to en-US, perhaps that does anything?
I still think the better solution is to just not let an attacker in. Have a very strong password and change it regularly. Use a secure server like Windows Server, so the password should be the only potential weak point. But I get it. Your environment is a lot more structured than mine. The workplace has more rules. Still though, each connection string can only point to one database, or to a SQL Server linked DB (I believe, never done that). What's so different that you can't just swap the connection strings?
https://imgur.com/QWZMxuG - user name is "IIS APPPOOL\DotNet4"
Now if you want to set up a trusted connection, all you have to do is grant the necessary permissions to the principal in sql server (if it's running on the same machine), and from your web server process, open a connection to the database using a trusted connection. 
There are SIDs for these. They start with S-1-5-82. But they're "virtual accounts", not normal users. www.winterdom.com/2014/05/16/iis-apppool-identity-sids.html
https://docs.microsoft.com/en-us/iis/manage/configuring-security/application-pool-identities is a better description &gt; However, with the switch to unique Application Pool identities, no user profile is created by the system. Only the standard application pools (DefaultAppPool and Classic .NET AppPool) have user profiles on disk. No user profile is created if the Administrator creates a new application pool.+ &gt; However, if you want, you can configure IIS application pools to load the user profile by setting the LoadUserProfile attribute to "true".
Well, it is windows 2008+. Hopefully you're not running on win 7 in prod
Of course it's better to not let an attacker in! But how do you guarantee that? If you can guarantee that, you can just hardcode "password" everywhere :) We could swap the connection strings if we put them in config files and if we had 11 different pipelines. We only have one pipeline now, and those settings just aren't in our code so it works. Currently we put them encrypted in the registry on server build. That externalized them from the app code. We are moving to putting them into vault (consul.io product) and fetching them at app start up. That externalizes them completely from the server. 
Does not one praise Head First C# anymore?
You should be using the `dotnet` command for all of your command line work. You can then do various commands like these: dotnet restore dotnet build dotnet test dotnet run You can read more about the command line tools here: https://docs.microsoft.com/en-us/dotnet/core/tools/?tabs=netcore2x
Thank you, that works for running my console app from the command line. There is way too much outdated information out there! Some tutorials tell me to use "dnu" but then others say that "dnu" is outdated and now it's called "dnx". Now "dnx" is outdated and it's called "dotnet"?! This makes it so much harder to use .NET Core!
I agree about the outdated information. I rely mainly on the official docs at this point and go from there.
Just right click the project and add a reference that way. You'll see the correct format, then if you really want to text-edit it, you'll know how.
You can start with Unity's tutorials. They have tutorials on everything, and even walk-through projects. However, if you want to learn C# in good detail, then I recommend starting with this series: https://www.youtube.com/watch?v=SXmVym6L8dw&amp;list=PLAC325451207E3105 If you don't want to, then just go to Unity's tutorials.
I didn't like pluralsight. Whether or not it will be useful to you depends on what you use it for. They do cover a broad range of topics with video tutorials, so if you need access to decent info about anything you might need, they could be a good resource, but I felt the videos were too drawn out, vague and time consuming to be worth the monthly cost when I can pull up more specific tech docs for free elsewhere.
The EBook class is from Epub.net (it's on nuget) and ye it's probably a bug in there but i don't understand HOW this is bugging as it works perfectly until it just stops (_zero_ codechange) and all I can/need to do is move the project(s) to a fresh solution. Force culture to en-US, do you mean in the solution/project(s)?
Here you go: &gt;On a local SQL Server, the login request will appear as the IIS application pool identity. For instance, if the application pool is called AuthTest, the login will appear as IIS Apppool\AuthTest. &gt;On a remote SQL Server, the login request will appears as the machine name since the built in account is attempting to access SQL. For example, the server IIS01 will appear as domain\IIS01$ in a SQL trace. ([src](https://blogs.msdn.microsoft.com/ericparvin/2015/04/14/how-to-add-the-applicationpoolidentity-to-a-sql-server-login/)) I believe the "macine name" referred to here is the machine account created when the machine is added to a domain.
Yes, but unlike user credentials it's a unique principal per machine running that app pool. That may work for you. Doesn't work well if you're adding and removing web servers regularly. Discussed in another thread here - you set up a single security login at the database server level, but you need to create database logins for each machine running the app pool. Sql logins avoid that. So do domain user credentials, but that's a class of security bugs you avoid by not using domain users for IIS
&gt; I see a lot of developers that write code that might work but looks like a pile of garbage. Methods are hundreds of lines long and hard to follow, code is repeated in numerous places, variables and methods are poorly named and there is very little encapsulation. Pretty much exactly like the place I used to work at -- they even promoted the worst offender to supervisor. This would be an example of what he would do: public class clsMember { public enum MemberType { Standard, Expirt } public void DoStuff() { try { //several thousand line method that uses nested switch cases and if-statements } catch (Exception ex) { } } public int m_mimberId; public IMemberDAL m_mimberDal; public void GetMimberStuff() { Name = m_mimberDal.GetName(m_mimberId); } public clsMember(int memberId) { m_mimberId = memberId; m_mimberDal = new MemberDAL(); GetMimberStuff(); } public void MakeNameUpperCase() { Name = Name.ToUpper(); } public int DoAddition(int a, int b) { return a+b; } public string Name { get; set; } } * Spelling errors * Completely oblivious to encapsulation principles * 'Passes' arguments to methods via class-level member variables (which are usually declared public) * Declares public methods that should be private * Nests switch-cases and if-statements like a rat nest (seriously, 5+ levels deep at some points, I counted once) * Prefixes class names with 'cls' and uses hungarian notation * Prefixes class-level member variables with m_ (not exactly something I cared about but he did it extensively) * Swallowing exceptions * Hardly ever uses a return value other than 'void' * Writes methods that shouldn't be methods. * Writes methods that don't belong in the class * Doesn't know how to format the code within the class properly (like where to put properties, constructors, methods, proper spacing, etc) * No dependency injection or any concept of interface segregation * No comments * Declares public types that should be in their own file (classes, enums, etc) * Absolutely no consideration for software architecture * the list goes on... For a while I was a newbie (had just graduated) and he had several years developing software on me, so when I would code review his stuff I'd largely just look for stuff that would break something or erroneous logic instead of critiquing his 'coding style'. After a couple of years of coming across his shit and having to make changes in 4 different rat nests that had the same functionality because he couldn't abstract out the common logic, I started to give him more and more critical code reviews. The very last code review I had given him had frustrated him to the point where he started saying things like "we need a way to standardize the code reviews because we all have different expectations" and "making all these changes you are suggesting would take time and this needs to be done now" and "just because you read something about a best practice online doesn't mean it is true". That day he had a meeting with the director (a micro-manager who has no business being in software development) and, voila, I was no longer on the code review rotation because "you were transferred to QA and only people on the dev team perform code reviews". Everyone else was pretty much the same but not as bad -- generally sloppy work. We also never really had any dev meetings and the director only cared about the opinions from the business analysts and testers and that single supervisor I mentioned. The director gave a power-point presentation once wherein she actually said something to the effect that "until you've earned the right, you should keep your opinions to yourself". One time I was penalized for telling a business analyst that I would not be adding the new field she required to a database table **just because it would allow her to run through her test cases easier** (she basically wanted me to add yet another field to easily identify certain rows because the current key was too confusing to work with, a result of prior horrible database design to be sure). I also told her that I could write her a SQL script that would do what she needed without adding the field, but since it involved slightly more advanced SQL than what she was used to, she didn't want it (it involved joins, how scary). I also told her that the design of the code and database was within my domain and not hers. All of this was said with more tact and politeness than I am probably conveying here in this post, mind you, and I didn't think anything of the conversation. However, the business analyst told the director and whatever was said resulted in the impression that I "refused to follow the spec from a senior business analyst". None of this was brought up around the time it happened, though, and had only found out during my performance eval when I was docked several points for refusing to follow that spec, several months after it had happened. Oh, and performance evals were rated 1-5 with 5 being the best but it was literally impossible to get a 5.0 -- there was one category that you couldn't get higher than 3.5 because she felt that the category wasn't important enough to allow a 5.0 (even though the performance eval software allowed you to set *weights* to certain categories). She also felt that she had to give people lower scores than they deserve so they would have more room to improve the following year. One of the categories we developers had was something like "to get a 5.0, you have to fix 165 bugs in a year without causing any issues in production"... when we had a **total** of about **110** bugs... between several developers... and she was the grand arbiter of cherry picking so even if you completed a bug it could sit several **months** in staging, spanning a couple of releases. Several times I had received the go-ahead to merge a bug to production and I would be like "wtf is this? oh, yeah, the bug I worked on 6 months ago." Also, she was absolutely unwilling to leverage *very common and basic features of TFS* and we would have to write tools to basically do what TFS could already do. Furthermore, she wouldn't allow us to reverse integrate from a parent branch because "developers couldn't seem to do it right". When I got to QA, I presented to her all the information about how to test software and why we should really focus on developing unit tests instead of focusing entirely on the automated UI tests (which only covered about 20% of the software anyway) and the manual tests and I was met with a degree of hostility that I didn't expect. It was a few weeks later that she gave her presentation about when to have opinions. She also once casually threatened my job with the comment "do you even want to work in this industry?". Finally, when they would agree that what they were doing was not the best solution, they would say "fix it the quick way for now and we will come back to do it the right way later" and, of course, no time was ever allotted to come back and do it the right way. The scary part? We were working on financial software. Anyway, sorry for the vent, but every time I think about that whole mess my blood boils and what you had said invoked some latent PTSD within me.
You could feasibly set up a security group to be granted access within sql server though, and access configuration becomes simply a matter of adding and removing machine accounts from that group. 
&gt; I personally wasted about 4 years of my career on a framework MS discontinued a week after promising it was a long-term bet Do I hear the cries of Silverlight in the distance? :p But yeah, that sucks. I've been lucky to not have been in the market at that time, else I would probably have done the same.
Ooooh, javascript always disgusted me (not bashing, just my feeling about it). This is the main reason I don't want to go into web; I'd like to go into it easily at first, which means keeping on using C#, but really, I hate javascript with a passion. Now that framework looks interesting, no idea it existed!
Yes, dotner build just calls down to msbuild
I find it walks a very thin track through a very thick forest. So that you really don't understand the why's of coding at the end of it.
I had an answer for you, but you went and deleted it :(
Well it's just a guess here but since it complains about encoding, it might be the ISO code (which is chinese (CN)) a workaround might be to set your culture in your project (via C# code).
\* For massive project counts.
Ill try that thanks for the tip.
Either way, good luck with finding a reason and remedy for your issue, I know how annoying it can be to be stuck of something for a long time.
More fixing a linux msbuild performance bug than a structural improvement, but good nonetheless
I guess he is talking about the patent problem https://medium.com/@raulk/if-youre-a-startup-you-should-not-use-react-reflecting-on-the-bsd-patents-license-b049d4a67dd2
You referenced library in wrong way. Instead of referencing dll in Nuget cache folder you should reference nuget package.
I've been programming in C# since its inception. I've maybe written a page of javascript in my career. But I've managed to avoid web development to this point.
Hey, absolutely! Not suggesting you give up on what you're doing at all :-) If you take a shot at the Serilog plug-in and need a hand at all, https://gitter.im/serilog/serilog. Incidentally, there's an expression evaluator that runs over Serilog events at https://github.com/serilog/serilog-filters-expressions that could be a quick way to evaluate things like `PropertyA + 1` in the context of Serilog events. Fun stuff to tinker with - hope it all goes well!
For 3, solve a problem that you have. For example, I needed something like Xenu Link Sleuth (or Screaming Frog), but with more features, and the ability to add more functionality myself. So I wrote it (SEO Macroscope), and am still adding to it. This was my first "proper" C# application, and in fact, my first native Windows application. I'd mostly done server-side stuff before, web development, etc. It's great doing exercise and following tutorials, but it's a lot better to actually *solve* a problem that you have. The same applies to any programming language. 
Anytime you are dragged in to fix some poorly performing app one of the first questions you should ask is "Does this app use multi-threading?" If it does, chances are there are multiple improvements you can make by changing lock strategies and replacing older threading code with newer APIs. 
WCF is way more flexible and powerful than Web API. For example, i can tell WCF to only operate on a single thread. I can also tell it to throttle operations to only a handful of threads. I can have it auto publish a WSDL. It can bind to a queue and receive notifications. It can operation over binary or other communication method. I can go on and on. However, with this powerfulness, it is stupidly complicated and more often than not makes you want punch someone. If you are using a simple web application use Web API, if you have an enterprise solution in which you need fine tuned controls that involve things like distributed transactions use WCF. BTW tell your colleague to learn WCF before tries to do any comparison and contrast. WCF is not going anywhere. If it does hopefully it will just get easier.
yup. They're making it so that anyone using React can't sue Facebook... and it doesn't matter whether React is part of the lawsuit or not. As long as you're using React, you can't sue Facebook for ANY reason whatsoever.
To be fair, I ended up jumping off that boat to a company that was getting interested in Xamarin.Forms just as it released, so all the XAML experience wasn't completely wasted. Now I'm technically using all MS stuff again, it does have me a little nervous.
"However, with this powerfulness, it is stupidly complicated and more often than not makes you want punch someone." I second this statement. 
I've been testing one monster solution that has ~320 projects (this is 20+ years of dev and spans Win32, MFC, WinForms, Silverlight, ASP.NET and some .net core) and while it's ~2x build time speedup versus several smaller solutions, it seems that internal .sln -&gt; msbuild conversion takes almost a minute. I doubt this change help with that, but it would be nice anyways.
WCF (WS-\*) is way bigger and more mature , it does things that WebAPI just won't do probably ever. Secure conversation spec, transactions spec, role-based access control, blah, blah... the downside is the complexity that comes with size. However, it is a "corporate" solution. The cloud world is not using it, it does Json over HTTP (that is, webAPIs). WebAPI is needed when you want to serve javascript clients. In the maturity story, it's low on the scale, which makes it simple.
Web API is a shorter, more understandable path to getting a REST web service that speaks JSON. That's what *most* people want, these days, especially if you need to interoperate with lots of different programming languages and platforms. WCF is better if you need non-HTTP transports, obviously. On paper, WCF is better if you want to automatically generate the client code, but this turns out to be rather hit or miss in practice. It's great when it works, but it's a meteoric learning curve to troubleshoot when it isn't working right. On paper, WCF provides more interoperability tools than Web API. In practice, REST+JSON is such a common pattern that it works better cross-platform. If find writing clients that talk to WebAPI to be more initial work than WCF, but far less total work in the end, especially if you follow some basic design patterns. WCF was designed to solve a lot of problems that REST web services don't, but the REST community solved those problems by punting them completely (for the most part) and that usually turned out to be an acceptable decision.
&gt; i can tell WCF to only operate on a single thread [...] handful of threads Configuration options "maxConcurrentRequestsPerCPU", "maxConcurrentThreadsPerCPU" and "requestQueueLimit" is something that comes to my mind. And there are some other ways to handle it also. So, actually, the only thing that comes to my mind is that it is slightly easier to get two-direction communication channel with WCF then via WebAPI, though SignalR makes that a kind of simple too. And, yup, binary communication too. Anything that goes over HTTP should be encoded to text, which gives a bandwidth overhead.
&gt; Secure conversation spec, transactions spec, role-based access control Those things work fine with WebAPI either. &gt; In the maturity story, it's low on the scale Well.. mature enough, I would think. Can't think of anything that would not work over WebAPI now.
&gt; WCF is better if you want to automatically generate the client code Swagger can do that for WebAPI also. It can generate proxy classes for client part of webapi, a kind of similar to what svcutil.exe generates for WCF service.
If you use sprocs. Another option is to create views to use from your application and only query those. Makes schema modification easier
Where is transactions support with webapi!? What do you mean for the other two?!
And only on linux. And only with CoreCLR.
I don't like it either. I remember Jon Skeet's blog article where he, as politely as was possible, explained that Head First C# is not only just difficult to read and navigate but also contains technical errors. Even if most of them have been corrected by now, the form and structure create the impression that the book has no intention to really teach you programming. 
Now I understand why I feel so unconfident. In spite of knowing the basics, I still struggle in terms of how to properly structure code. 
Each have different target end uses really. WCF should be seen as the granddaddy of communication APIs in the .NET stack. It is a multi-function, format and transit communication tool that is extremely powerful. Because of this WCF can be a bit difficult to work with for one of the most common remoting scenarios: A simple service with a common transport that everyone likes to use. The default SOAP XML template was OK in the day but it was still a pain to get a good WCF service going. WebAPI addresses this by giving you a framework that is centered around getting a service working quickly. Part of this is done by removing much of the flexibility WCF has and focusing on the features 80%+ of the developer base uses the most. Sure you don't have the flexibility of WCF with WebAPI but that does not really matter for most of what most folks do. For the rest you always have the swiss army knife and it will always be useful in lots of specific scenarios both on the web and otherwise. 
Thanks for sharing your code. Do you implement these structures in your own applications to catch changed formats? Your option looks very solid prove. But maybe to complex? 
This was incredibly helpful to me. I read every word. 
From my understanding the answer to all your questions is yes. It all depends where you work and the team you have around you. I'd like to think more often than not though, developers tend to be a friendly, supportive breed of human who like to help those who want to learn 
Yes to every single one of your questions. In a solid week easily. Love it all.
Don't worry, so does everyone else ;-) It'll really depend on the complexity of your problem, though. If it's simple, you can probably get away with everything being in the main function. Anything bigger, though, and you'll want to split each part of the problem into it's own methods/functions. Beyond that, it's time to divide the problem areas into classes/objects, and so on. Nobody understand interfaces... Anything that tends to repeat, can go into a method/function. Further subdivide if it's a big thing. You don't need to do this all at once. As you write your code, some of this will become apparent as your application grows. You can then move (refactor) your code as it grows. 
I've worked with some of the best people on Earth, and also some of the worst. I've worked with egotistical sociopath programmers, but also some incredibly friendly and patient ones. A lot of work can be mundane. The small boring tasks need to get done. Cleanup needs to get done. You probably won't get to pick the thing you work on, and maybe someone else created it. So you get the unglamorous repetitive tasks, without any fame or glory. I worked in the video game industry for a few years. Sounds exciting and creative, right? Even in that field, everything I said can apply. But jobs pay the bills, and good moments exist.
Got me excited now!
calm down
Depends entirely on the company and the culture. I've been on both sides of the fence, I have previously (and do currently, thankfully) worked in an environment that's supportive, fun and rewarding - however in the past I've also had the exact opposite experience, with a toxic work environment and a boss with a serious attitude problem and no meaningful ability to support his team. In that example I eventually decided that dealing with the stress and the way we as employees were being handled wasn't worth what they were paying me, so I quit. Good news is that the job market is very much in the favour of devs (for now, at least) so there's no reason you should have to deal with this (unless you're some kind of sadist I guess)!
Darn. Video game industry is my goal. But thats good to know. Do the VG companies own your side projects? 
There are a few threads out there about the good and bad of working in the game industry, from people that have done it. I recommend checking them out before making any hard decisions. The short version of the bad will be: low pay compared to taking your expertise elsewhere, high stress, lots of overtime, little or no job security even for full timers, and the real possibility that you will have to move across the country to find work after the inevitable layoff. But like I said, go read more opinions and research it first. As for side projects, yes some places do make you sign things that restrict what you make. Others don't. Again, you can research each place to find out. I can make a game on the side now without having to worry about it.
[removed]
This belongs at /r/cscareerquestions 
Well, unless he wants the frank opinion of each community so that he can compare the responses. Maybe what OP is trying to do is see how responsive each community is, and which ones have the worst/best experiences.
working at the IT for a big goverment unit, having a big IT failure, phones ringing everywhere and a collegue that sits all calm and shopping underwear and an another one cutting toenails....
If you still want to add your web.config to source control without the added worry of your db credentials being visible, you could always pull the connection string section out into another config file and omit it from source control &lt;connectionStrings configSource="connectionStrings.config"/&gt; 
[removed]
Peer-to-peer? Use power in numbers - Simply send any calculations to a random list of others peers - Check the results and agree with the highest number who agree. This shouldn't affect performance too much if you concentrate on the highest target values that cheaters would try to affect. Most times all should agree if everyone is running the same code. If someone is failing this concenus multiple times then they are editing the values and you can take action... What specific things are you thinking they will cheat on? This method should prevent most game-logic hacking, but for UI stuff (wallhack etc.) you have to come up with crafty ways to limit the information each client has... Most of the good solutions will depend heavily on the context of your game and what data is transmitted between clients so maybe give us a few more details of what type of 'cheats' you are trying to avoid.
[removed]
Lol but this was just me venting :P. What did you learn haha.
I tend to agree with this sentiment. Even if you're going to be stuck writing API endpoints, most places won't even give you a look if you don't know JS. Regardless of whether or not the current job req requires it.
I'll agree with other commenters who mention this is not what inheritance is for. You should abstract the movement away into a separate component. And the move speeds should be set from configuration (i.e. a file?). EvilVillian is not a different 'thing' conceptually from a Villian so should not be a separate class
second this answer! As a fresh dev, you probably won't be able to tell the difference. Some startups look fun,but have an authoritarian command/control structure. Some big enterprise companies are incredibly great places to work. Switch jobs enough and you start to see the patterns. With that, as you get more experience you'll come to recognize two things: some people are great to work with, and not great to hang out with. So you'll like some people and respect others. Try to find a team where you both like and respect your boss, the upper management, and the majority of your team. There's always going to be an asshole that ruins things, but in a good mature team, that guy doesn't last long. In 6 jobs I've had, I had two that were like this, and the first one I was too fresh to understand the difference.
&gt; Has anyone had a boss that didnt know much about software dev yet vied for control? This must be a trick question... So many situations, the 'higher ups' have no idea what they are doing, how to do anything, or what anything does.
I'd trust the one cutting nails... The one shopping underwear is likely using that as a boss screen to avoid incrimination.
You responded to [my other post](https://www.reddit.com/r/csharp/comments/6zub9e/random_questions_on_learning_c/dmyshix/), so I won't re-hash that here. I will say that it was incredibly bad to work there -- every decision they made was counter-productive to developing a good software product. I understand completely that each workplace won't be perfect and some best practices are ignored, but the degree in which my previous job ignored them seems to be relatively rare. When I interviewed for my current job, I asked several questions about their processes and code base to ensure I wasn't trading one devil for another. They don't seem to be doing anything like my previous employer so I'm good to go now. My previous director that I expanded on in the link I posted was a real piece of work. She has a programming background but that was 20+ years ago and she only did it for a few tears before becoming a business analyst. She had commonly made decisions that developers should be making like when we are allowed to refactor, source control branching strategies, etc. When we had a dev manager, she would routinely bypass him and task developers directly without talking with the manager. After he left, there was no effort to find another manager and she ended up hiring two new senior devs, neither of which would be overseeing all development efforts. Even the supervisor I mentioned in that previous post was still actively developing his own stuff. Furthermore, she was the director for two different dev teams so her attention was always split between the two. Getting a timely response from her on anything was damn near impossible -- I had waited nearly 2 months with several follow up emails trying to get her input on a task I had been working on (it was a very low priority task but still). Any interaction with her in person had to be done by scheduling a meeting in 30min blocks, but her schedule was always full. She was doing way too much and she was the biggest bottleneck in the whole process.
Yes, we write adapters for 3rd party apis in use on our application. This insulates most of our code from 3rd party changes and allows us to respond to them quickly. We restrict the adapter to only provide exactly what we need from the api so that we can know in this specific component what features are needed.
It is better to implement WCF manually instead of using service references or harvesting the metadata, but other than that, I agree with everything you said.
That...was...well, I don't even ^know ^^what^^to^^say.^^yesidobutiwont. ^o_O ....I actually understood all...most of that. I really appreciate you explaining it so well. My instructor was just like "huh? Why is it not work?" (literally). We don't have to do many (or any more) windows forms in VS. It was like a "hey! you don't actually have to write tons of lines of code right out of the gate. You can just pick some boxes and make it look pretty" (yes, I know there's more to it than that. Take it up with the Deitels). I know the next 6 assignments are console apps so we'll see what happens. I just sent that computer out to be repaired anyway (longish story) so looks like I'm back to to using Big Bertha for the foreseeable future. Thanks again pal! 
It all depends. I'm sure a bad boss would not look good to their employees if they sued an employee over a personal side project. If you were working on a side project for Ubisoft while in Perm employment with EA, thats a whole lot different. However, I had a boss claim prior art on a game I made for another company after I left. They were just being dickish, and didn't succeed. 
&gt; In your solution, go to Tools -&gt; Options. Choose Projects and Solutions -&gt; Build and Run and select Diagnostic in “MSbuild project build output verbosity”. That's fixed so many problems for me.
My work environment is really nice. I'll probably stay here for a long time (already there for 8 years now). Small team, in a small town, good supportive and challenging environment. Not having a boss helps. We are all (6 devs) about the same level in the hierarchy and we are all working to release good quality software. Before that, I was the only dev in a finance company. I built a huge system (in-house financing software, transnational website, IT architecture, etc) all by myself. That was fun too. Hanging out with multi-millionaires makes you see the world a different way. The Christmas party were incredible. I also worked in a "programming shop" where the devs were just coding monkeys. That wasn't fun and the people that were happy to be there weren't really good programmers. Nice people though. Maybe it's the fact that I live in a small town in Quebec, but I rarely encountered an hostile work environment or really unfriendly people. 
Swagger has some serious limitations though. 1. You can only use a subset of WebAPIs capabilities. For example, you can have multiple overloads for the same method. 2. You don't get rich data types, everything is limited to only what JSON supports. Still, its better than nothing when using WebAPI. Just make sure you are using it from day 0.
Is your client a website? Use WebAPI. Is your application .NET Core? Use WebAPI. If both your client and server .NET? Use WCF. Do you need real data types that JSON doesn't have (e.g. time span, decimal)? Use WCF. Do you need the ability to communicate over named pipes, message queues, or raw TCP? Use WCF. Do you need the ability to share code (specifically data models) between server and client? Use WCF.
Ditto. Here are my notes on how to share code between client and server using WCF. https://www.infoq.com/articles/WCF-Code-Sharing
Yep, that's what we're doing in production. And this is fun: * Bugs and Documentation Errors in .NET's HttpClient https://www.infoq.com/news/2016/09/HttpClient
&gt; HttpClient is intended to be instantiated once and re-used throughout the life of an application. Especially in server applications, creating a new HttpClient instance for every request will exhaust the number of sockets available under heavy loads. This will result in SocketException errors.3 This is really important advice.
On the flipside, I have used ReSharper's build for a while and it sometimes neglects to build things I actually want built. For example, I am developing a website and I change something internal in a dependency project. Resharper's heuristic checks will see that I didn't alter the public interface so it won't rebuild the website (naturally) but I then have to manually trigger it to build/deploy so I can actually use/test the new change, whereas MSBuild will always build it because that's how it "checks" for compatibility with the newly built dependency. I haven't gone to the effort to see if there is a configuration, instead I've gone back to default msbuild.
I wish I could give you a better answer for Windows Forms but for cruising through the Deitel &amp; Deitel book I'd recommend trying to ignore any part they tell you to make things a specific pixel size and instead "make it right". If it's something like a custom-rendered control (which I can't imagine would be part of an entry-level book) then mentally scale up the pixels 2x and it's *probably* OK. I don't personally have a high-density monitor so I haven't been able to experience it for myself. It's not worth *ignoring* the WinForms chapters, as all of the GUI frameworks are sort of familiar if you know the others. But if afterwards, you find you really love writing GUI applications, try to pick up WPF or even UWP. 
&gt; crap like this You mean `HttpClient`? That's... pretty standard. Not sure what the problem is there.
You don't have to like JavaScript but you must know it. I'm guessing this sentiment is true among most .NET devs.
The MSDN has an article specifically for [C# for Java Developers](https://msdn.microsoft.com/en-us/library/ms228358%28v=vs.90%29.aspx), although I can't really say how outdated or useful it is, but might be a good starting point if you have questions about particular aspects. Given your background, I suspect that you'll spend most of your time familiarizing yourself with the application type and .NET platform in general rather than the C# language. You should be able to pick up most of the important constructs of C# as-you-go. It'll be the other areas of the BCL (standard libraries), the app type (WPF, Console, ASP.NET), and in your particular case, database I/O. Maybe just dive in with making a basic console application, googling some tutorials on basic SQL queries ([for example](https://stackoverflow.com/questions/21709305/how-to-directly-execute-sql-query-in-c-have-example-batch-file)). Then depending on the complexity and usefulness for your scenario, either getting your feet wet with the actual application type (WPF? ASP.NET?) or investigating database abstraction layers. If the latter, Entity Framework is fairly common given that it's basically built-in, but if you have experience with Hibernate, there's [NHibernate](http://nhibernate.info/) too for .NET. Speaking of which, there are often .NET flavours of existing Java libraries, like NHibernate (Hibernate), NUnit (JUnit), log4net (log4j). If you're familiar with a similar Java library, there's little reason to find and use an corresponding .NET version.
Communication frameworks for .NET that expose OOP style APIs: * COM * DCOM * Remoting * WCF * ~~MSMQ~~ Communication frameworks for .NET that make you deal with implementation details of the wire format: * WebAPI/REST After 20+ years of OOP style communication (I'm including pre-.NET VB), going back to dealing with HttpClient is a bit of a culture shock.
The new compiler feature to skip building if the "public" surface area hasn't changed is: https://github.com/dotnet/roslyn/blob/Visual-Studio-2017-Version-15.3/docs/features/refout.md It went out in Visual Studio 2017, Update 3 (15.3). It does the actual public surface area, like you would expect. But it also takes `internal` members into account, when an IVT is specified. As well as taking the fields of a struct into account,which is required for interop scenarios, as well as certain other classes of code (generally unsafe code). 
&gt; COM &gt; DCOM Ok, two points for WebAPI... WCF is nice but complicated to debug compared to simple JSON over HTTP. MSMQ frankly doesn't [look much different](https://stackoverflow.com/questions/11076790/the-bare-minimum-needed-to-write-a-msmq-sample-application) than implementing `HttpClient`. You have to set your formatter, choose queue path, etc. The only thing `HttpClient` doesn't do is format your body content automatically but if you bundle `Newtonsoft.Json` it's dead simple to format your content.
I was looking for a "silver bullet" I suppose. I already do some funky stuff that makes it near impossible to use a memory editor (cheatengine) to "lock" things like health status, inventory items, etc. by newing up those items each time they change. Small hit to performance, but fixes problem 1. I do like the idea of having an "agreement" based system where the other players get to come to a consensus on a player's actions. Basically, the way I'm looking at implementing it is to do a "spot check" each time a potential game-breaking event happens. Each player just randomly says, "Hey, this player just made this move, I'mma personally re-run it based on what I know and see if it's a valid move." If that particular client thinks the move was "illegal" they'll send out a broadcast to the other players saying, "Hey, he made this shady move, can you guys verify?" If the majority also think it's shady, dude will silently get a "tick" as a cheater, and be watched for further action. The one thing I haven't really found a way around is stuff like wall-hacks. I can't NOT send the players certain info (eg: culling) to prevent stuff like wallhacks, or there'd be no way to verify if the player makes a shady move (using the above) so I was thinking if I could lock down my rendering pipeline (or anything else similar) and prevent tampering, that'd be the holy grail. Think of something like an online poker game, where you wouldn't even want the host to be able to cheat by modifying their client to show everyone's cards. That's an idea of what I'm trying to get around.
&gt; &gt; &gt; WCF is nice but complicated to debug compared to simple JSON over HTTP. I don't disagree. I'm just trying to explain the mindset of people like the original poster. 
Wow thanks, I'll definitely check out the C# for java developers section. As for the rest, I'm not sure what you are saying lol but I'm sure I'll pick it up as I go.
The worst? Working for a startup: * Underpaid * Always on call * Not allowed to work on side projects, company demands full loyalty * No job security, the company has no loyalty to the employees * Unlimited vacation time... that we could never use * Stock options that are completely worthless And I worked at a good startup. I didn't have the insane working hours or people being fired on a whim that some startups deal with. 
I've worked a number of programming jobs in a variety of different places. Some were great, some were shit. Some started great and turned to shit. Mostly, it all depends on the people. They typically make or break the situation. Worst job was for a large bank. I was on a team of about 10 people, only two of which were tolerable. The one guy was Canadian and a complete asshole (I don't think Canadians are assholes, all the other ones I met were great. This guy was an anomaly.) Arrogant, know it all pricks abound amongst programmers. Many are decent people, but just socially awkward and unable to interact socially very well. This bank job was full of them. Especially the manager. He was the biggest, arrogant, "I know more than anyone" when he actually didn't. He was just covering up insecurity. He constantly fiddled with two cellphones. He had a 3 year old son he constantly referred to as "a pain in the ass". I don't think he was joking. One day I had a very bad headache and asked anyone if they had any Tylenol. He replied "Yes, but I can't give it to you." I laughed, I thought he was joking. He looked at me dead serious and said, "Because you work for me, if I give you Tylenol and you have a reaction and sue, Im liable." Another manager in a different position said "What? That's bullshit. I have a bottle in your desk drawer, take as many as you want." I replied "Thank you" loudly. I took three, sat down and typed up a letter of resignation. I was out of there in days. Fortunately, there's lots of programming jobs. Had no trouble getting something else. Best job? Worked with great people, had fun, cool boss, played network games on the company LAN after hours. Good times, good money. 
The best, working for a large company. * Really good pay * Generous vacation that I'm strongly encouraged to actually use * Good benefits include health care I can actually afford * Annual bonuses that actually get paid out * Annual education budget (conferences, college, books, etc.) * My requests for tools and hardware are actually granted. (No more spending 100+ hours recreating a $200 tool.) * Job security. They aren't laying off people every time there is slight dip in revenue. * An actual pension plan in addition to a 401K * Reasonable working hours. (I don't work more than 40 hrs/week the vast majority of the time. When I do work overtime, it is balanced by slow periods where I work a couple hours a day.) * A corporate credit card for travel expenses (some companies make you buy the tickets/hotel, then repay you a couple months later)
WCF supported MSMQ, although then you really are in for a lesson in pain. I hate MSMQ. It's not Berkeley sockets so I guess I should be delighted they bothered to provide the awful HttpClient at all. I'm really moaning about nothing. ChannelFactory will hurt you unless you already understand WCF. Grauenwolf is mostly correct. I looked at the example (admittedly quite a few years ago now) and thought: "You lazy fucks" and never went back. I asked the question because I saw someone ask something else about Web.API recently and it reminded me that I've been meaning to ask for like... 5 years... 
Check out the basic naming conventions. DO use PascalCasing for all public member, type, and namespace names consisting of multiple words. https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/naming-guidelines 
Since you are fluent in Java it is going to be very easy for you to adapt to C# as the basic syntax is very similar. I was able to switch from Java to C# and write a very nice app within a day(Of course with the help of documentation and stack overflow). That said, respect and do not underestimate the language, learn the way code is organized as in namespaces etc. Good luck :)
I'm sure that you can find something in C# that doesn't touch JavaScript such as PC application development. I've done a lot of applications that extract and process database information as PC Winforms applications (Though I often choose to display some of that information as HTML/JS/CSS inside the application for ease of displaying). I think the larger issue here is that problem of yours with JavaScript. It's something I'd suggest working on to improve. C# is my favorite language to work with along with the super featured .net framework. The thing is, it's huge and there are endless uses that can be quite difficult to understand and use just like anything else. Just recently I was working on a macro that integrates into a 3D modeling program. There is sparse documentation on the API and it all happens to be in VB.NET. Needless to say, professional development isn't about languages, but an ability to learn and translate knowledge into practice. It's also often about being able to do things like take requirements, design solutions, and implement your ideas.
The day I started.
Depends where you are. One's experiences can vary widely. One company I was at was strictly regimented. You couldn't remove a single line of code unless the lead dev approved AND the analyst approved. There was zero creativity. All requirements were extremely explicit and you need at least two code reviews to get anything committed (that part is good). If you found a bug, you had to get permission from the lead dev and the analyst to create the ticket for it and you were not allowed to fix it. They would maybe assign the fix to you but not always. It was, to minimally say, a very rigid environment and it was soul crushing. There was a clear order in terms of who got the most interesting work. I had a friend who spent an entire year doing only bugs. That's it. By the way, it was not a small company. It owned well over a dozen platforms and was worth millions. (In house they were 120 developers of all stripes) &amp;nbsp; The new place I'm at now is almost the complete opposite. It's a very small company, maybe 10 of us. Our CEO was always a developer and he's the founder and the platforms we support, he built. Very small team, I know everyone's name. My lead dev is awesome. He's very laid back and essentially allows us complete freedom in how to design or implement a new feature. If we find a bug, we note, make a ticket and when work is light, we fix em. It's a way more responsive environment.
&gt; However, with this powerfulness, it is stupidly complicated and ~~more often than not makes~~ will always make you want to punch someone. FTFY. There is a special place in hell for the horribly twisted minds that came up with WCF. 
First things first, don't listing to anyone posting crap on the internet that says turn on automatic migrations. That is a symptom of the real issue. Never turn on automatic migrations, again that is a symptom of the problem. The learning curve is high, but it's something new. I really like the code first and random articles I found on the internet is mostly sufficient. Not sure if I figured this out on my own, but all of the commands you need can be executed in the nuget package manager window. The only other thing I found that was a pain, is you didn't know when you needed to recompile the project. It does not tell you this at all. I found a lot of issues were a result of creating the model then adding the migration and it was empty. This was fixed by just recompiling. 
Best time - getting to go train a customer (the sales staff didn't know the product yet) and watch him get super excited over the time savings it gave him. The firm pivoted around this product a couple of years after I left and now they sell a dozen or more variants of it. Worst time - Getting laid off when a competitor bought us. Because they sucked even before they did this, but they had a lot of money. 
You can use librairies like restsharp, no messy hands. 
Read the **.NET Framework Design Guidelines, 2nd edition**. This is the bible for .NET API design and will help explain how and why things work a certain way.
Try cleaning the projects manually by deleting the obj/bin folders. Then rebuild one project at a time. Sometimes cached builds get out of sync.
I've been a developer, software engineer etc., for about thirty years. It's been an interesting ride, mostly positive. People were friendly, helpful and positive. Most of the time. There were a few exceptions. The Finance Company where everyone was just hostile. I don't know why it was like that... I thought maybe finance companies were just full of people like that. I lasted nine months before I moved on. The second Finance Company, people were much nicer - I left because I found finance, well, boring! Then there were the very clever and talented people. The first I met at a games company. He did not know how to socialise and annoyed everyone he met, eventually including me. The second talented person was arrogant and seemed to think people should work his way, not theirs. The third has been... one of the nicest, wittiest guys I've ever met. The most fun I've had was at the games company. I was involved with audio and they are a crazy bunch of people. I worked on the game engine and the tools but I spent a lot of time talking to *users* - the sound engineers - seeing how they did audio in games. As for what I do all day... it varies a lot. I might be working on a new feature for a couple of weeks or chasing bugs for days. It just depends what's needed.
My 2 cents - If you plan to self-host a WCF app, then be aware that it's very difficult to add firewall exception at process level, and you will need to use fixed-port number exceptions. 
Yeah, I switched and have done a LOTTTT of hours working on this in C++, I seriously learnt the language for this and I'm happy I swithced. But, it's like being raped in the asshole with a huge dildo when you get some errors that cause you to comment 60% of your code to find the source of the error and find out it's because of a missing 'inline' keyword before a function definition.
Honestly, I can't remember the last time I've exposed WCF in a way where firewalls were relevant. I only use it for communication between applications on the same internal network. EDIT: Scratch that. I did have one WCF service that did two-way communication with a Silverlight client. Man, that was a long time ago.
[Hanselman did a blog post on Refit.](https://www.hanselman.com/blog/ExploringRefitAnAutomaticTypesafeRESTLibraryForNETStandard.aspx) I've started to use it. 
your wish has come true 
You can't use `leClass` directly that way. The method is asking for the `System.Type` representation/information about the class. To get that, you need to use the [`typeof` operator](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/typeof): leClass myInstance = (leClass)Activator.CreateInstance(typeof(leClass)); Using `typeof` though pushes everything to the runtime, hence extra cast/typing I had to do. But there's an overload for that method using generics that does that for you: leClass myInstance = Activator.CreateInstance&lt;leClass&gt;(); EDIT: The error you're getting comes from using the `leClass` identifier there. On its own, it's not valid; at that point, the C# language is expecting you to hit some static member on it. For example, this is valid: Activator.CreateInstance(leClass.GetSomething()); This is not, C# thinks the expression is unfinished: Activator.CreateInstance(leClass); EDITx2: Always try to include relevant code whenever you can, and ideally produce a [Minimal, Complete, and Verifiable Example](http://stackoverflow.com/help/mcve). If the code you had was included from the get go, any number of /r/csharp readers would have been able to help you immediately and without confusion. EDITx3: That said, including the error code was also useful, so kudos on that.
I do like Hanselman, I'll give it a look :) Thanks :)
I'll give that one a look too :) Thanks :)
When it comes to .NET, like Java, there are a plethora of different types of applications you can make. Learning the C# language, in practice, is actually only a part of the knowledge you have to learn to be effective. [BCL (Base Class Library)](https://en.wikipedia.org/wiki/Standard_Libraries_%28CLI%29#Base_Class_Library) is referring to the standard libraries that most C#/.NET have access to. For example, in Java you have `ArrayList`, in C# it's `List&lt;T&gt;` (check out generics btw). Or instead of `java.lang.Math` you have `System.Math`. Quite a few 3rd party open source libraries out there made for Java have been ported to .NET. If you're familiar with them and like them, do a quick google search and see if a .NET equivalent is being maintained. * WPF = [Windows Presentation Foundation](https://en.wikipedia.org/wiki/Windows_Presentation_Foundation), basically Windows desktop program. (maybe JavaFX/Swing is an equivalent in Java) * ASP.NET = [Active Server Pages .NET](https://en.wikipedia.org/wiki/ASP.NET) lets you build dynamic web sites. (maybe JSP JavaServer Pages with some MVC framework) * Console = Command Line program
Is it on the system string class or against a string variable? If it's on the system class look at the docs and see if it was removed at any point. If not then it's most likely an extension method. In that case are any projects not building or any references missing?
Some companies are amazing, some are horrible. Just like any sector. It's something I've only learnt to watch out for by working at the bad companies. My career has been a learning curve of how to look out for roles I don't want to do. You learn what to look out for in phone interviews, you learn what to look out for in face to faces. And finally, you learn what to look out for during g your probation period. Though there's some checklists everyone can follow, because everyone is different, the companies they will enjoy working at are different. Your career is a jungle that you work your way through. And each job will make you wiser. But no matter how much you read, and gather data, there's nothing that's going to compare to getting stuck in and learning. Best of luck!
I cant wait try this tomorrow. 
Channelfactory works because the SOAP endpoint defines all possible messages and all possible responses through its WSDL. This allows .NET to define all the objects you're communicating with through templating and give you all the code you need to interact with the service automatically. REST APIs don't do this. Theoretically you could build a HATEOS API that would allow a lot to be derived by a determined crawler, but it'd be a nightmare, and I've never seen one written that way that also has static content you could do that with. It's not a matter of lazy, it's just not possible to build an interface like that over rest. You can build some really good tooling for http calls, and they have, but it's not RPC, and you can't do RPC with it. On the other hand, the code you didn't write for WCF is hugely complex and very heavy and God help you if you need to deviate from it. HttpClient makes rest calls. That's what webapi is.
Look up Julie Lerman's entity framework books. She also has a blog and some pluralsite courses. But I'd recommend actually learning about databases first before you learn an ORM.
I literally had troubles understanding what you were writing, I didn't think that Jon had connections to SO beyond being on it, and thought you were insinuating that he had a deeper connection. I would have *loved* to have learnt that, if it were true, thus why when I corrected you, I did so with ? marks, as I was unsure, otherwise I wouldn't have bothered because I'm not normally that anal. So feel free to think it's a personal attack on your communication like you seem to imply. 
Finally!!
It's a good book. You'll probably learn a fair bit of the general .NET/C# ecosystem/platform. C# In Depth is what you'd want if you really want to learn the language itself, on a pretty deep level.
This is good news. I wish MS started .Net Core with SignalR migration instead of EF.
Its a great book *if you know the language*. The in a nutshell series is a reference book first, a tutorial second. It's made for people who need to learn how to implement or do something quickly. It will explain how a function works, but expects a general knowledge.
Thanks all, I had not considered using WCF for this project but I can see why it is more popular for simple messages and objects. WCF still has a place for more advanced messaging which is kind of what I expected to hear. Thanks again!
Yeah, I wouldn't recommend that book. Don't get me wrong. I LOVE that book, but it isn't a "I want to learn C# book". It's a deep dive into the intricacies of the language. I guess you kinda said that. But I wanted to emphasize that to OP.
Check out devexpress. It has a grouping feature built in. Note: I have no affiliation with them. I just use their datagrid.
I learned on Jesse Liberty's book called "Learning C#", but it hasn't been updated since version 3.0 Not that 3.0 is bad. In fact, I'd say around 3.5 (when LINQ was introduced) is when the language became "mature". It's improved since then, no doubt, but it's been more incremental improvements, rather than revolutionary. Part of the trick with C# is figuring out what you want to do with it. Visual C# making Windows apps? ASP.NET MVC and C# writing line-of-business webpages? C# and DirectX making games? And there are so many frameworks you can code against. Half of being a good developer (in any language) is mastering the frameworks available for it. So what are your goals with learning C#? EDIT: I just flipped thru the ToC for Nutshell 6.0 and yes, it looks like it is "right up your alley". 
GREAT BOOK!! I was in a similar transition with 6.0 and specifically looking to learn more about LINQ. It came with a copy of LINQ Pad too! Coming from the perspective of another language, I could easily get a first-hand feel for how the various constructs used in the language work, how they were similar or different from what I expected... This was useful throughout the text, well-beyond the LINQ sections. The author doesn't spend too much time and detail at all covering the basics and I actually skipped over that part using it mostly as syntax reference. I think it is even factored-out into a separate book where it is given more detail. I enjoyed the book enough to pre-order 7.0 out of appreciation as this learning transition could have been a lot more painful than it actually was.
I learned entity framework by first watching Pluralsight courses and following the examples and creating small practice projects. I then moved to reading different online articles to find different or more complicated scenarios. But I learned the most by implementing it in real projects and searching Google when I stumbled upon something new. But I would say Pluralsight gave me the best introduction. 
Interesting that they require sticky connections now. I'll never forget the triumphant feeling of getting the OG SignalR working across a load balancer. Kids these days have it easy 🙃
I feel like they focused on EF rather SignalR because more folks build .NET applications which use EF than SignalR, which meant that it would have been a higher priory for the majority of developers. Still, it's good that it's out now. They've been talking about it for weeks on the ASP.NET Live Standups. 
Just to clarify your comment, you wouldn't recommend in a Nutshell or In Depth? My thoughts are as OP is a C++ person, he's more likely to appreciate the In Depth book and would recommend that title. I wouldn't however, recommend it to a novice or new comer to programming in general. 
But where do I put the string?
How about learning a micro orm like npoco or dapper instead of the inefficient monstrosity that is EF ? After using them I don't think I'll ever go back to EF.
Thanks for the answer! I have already coded the thing and was inclined to try and perhaps also force a lot of OOP techniques (inheritance, a set of design patterns) even when it was not necessary. The most important thing is, that I have learned a lot. And you are right, would I have to code that right now, I would not separate plain- ,evil- and deadly-villain into different classes. I gained no advantage from that. Where it definitely made sense was the implementation of the villain specific movement behaviors. Each villain type has its movement behavior (plain-, villain-, deadly- movement behavior) specified in its own movement behavior class which is inherited from an abstract movement behavior base. The movement behavior objects are then members inside the villain objects (1 to 1 relationship with composition) I feel the invariable max speed settings are a part of the movement behavior classes. And yes, the max speed settings are initialized from a config file (well at the present I have a public static class Constants, which holds all the magic numbers in a central place, I might refactor that into an external config file). 
Meh. They removed the two main reasons for one to use it - transport degradation and reconnection. 
You don't have to do code first. You can also do database first, as I do. You can design your database in SQL Server, or your preferred database engine. Set up your relationships, constraints, and then generate a model based on that. This is how I like to work. The database is the foundation of any software I develop that uses a database. It's where my design begins; and from there, I build out into applications. Start with Venkat's tutorials: https://www.youtube.com/watch?v=Z7713GBhi4k&amp;list=PL6n9fhu94yhUPBSX-E2aJCnCR3-_6zBZx He covers both code-first and database-first. With Entity Framework Core, the principles you will learn still apply - it's just that the current tooling is a bit shit.
If you already know one language, and have been using it consistently for the last few years, I'd hazard that you are not a beginner. In your position, any book would be worthwhile, as all you'll need is experience of the practicalities of the language. Be aware though, that you can end up programming in C++, using C# if you're not prudent about each languages unique qualities. I have seen boat loads of languages written in the style of other languages, and its a little jarring.
You could make the method internal and set internals visible to your unit testing assembly in your assembly info. Would allow you to test it without exposing it to anything outside of that assembly.
Is there any documentation? The only things I see is some samples.
That's because the migration works through reflection. You have to rebuild your binaries for the migration to know your changes. Standard code-first migrations is where it's at, though.
That or C# in depth, although the new edition of C# in depth isn't out until next year. Nutshell is out at the end of the month to buy iirc. 7 is on Safari now, but I hate Safari and can't recommend it. You can sign up for a trial and have a read through to see how you feel about the book though. 
A lot of these guys are going to recommend our have already recommended you to build the tables first. This is a valid approach and either way you'll want to know some sql in case you need to customize your migration script. But I think the guys that recommend this method are either unfamiliar with EF or simply skeptical of it. There were a few guys in my office who were like this. Code-First EF Migrations are where it's at. Especially when you're working on a team. Manually copying database changes from a remote db to your local db is a pain in the ass. Especially if there are frequent updates. EF is big. Some have called it a "monstrosity" but every MVC application my company develops uses it and the performance is stellar in each. The weight of EF is offset my how incredibly useful it is and how it can greatly simplify your workflow **once you learn how to set it up**. For learning, download Visual Studio Community (unless you have a better version) and create an MVC application (webpage). The database connection will be controlled by the connection string in your web.config file. The string should reference the DatabaseContext class you create. From there it's just a matter of creating your Code-First dbObjects (classes), referencing them in your context, and running a migration, then updating the db with the new migration. Microsoft Virtual Academy is a decent source for learning EF.
My bad. I wouldn't recommend "In Depth". As I said, great book. LOVE IT. My concern is that the dive is TOO deep for someone just picking up the language. Even if they're coming from C++ (which is a hard language to "get".) I *did* peruse the Nutshell 6.0 book table of contents and it covers all the things I would want someone to learn when absorbing C# for the first time. So I get the sense it will be a good book. Conceptually, C# has a bunch of features which just don't exist in C++ and most people still need that gentle slope to get up the learning curve. "In Depth" while a great book, makes less sense until you're already quite familiar with C#. (Well, that was my experience.) In fact, I'm excited for the 7.0 Nutshell book to show up soon. Personally, I haven't really touched C# since 4.0 and I'd like to catch up on the latest improvements (which I've only been following thru articles, not actually programming and practicing...)
No string. Unless you don't have a reference to the type, and the string is the full type name, then you can use [`Type.GetType` method](https://msdn.microsoft.com/en-us/library/w3f99sx1%28v=vs.110%29.aspx): object myInstance = Activator.CreateInstance(Type.GetType(myClassName)); If instead you're talking about using a constructor on `leClass` that takes a string, then you can use [this overload](https://msdn.microsoft.com/en-us/library/wcxyzt4d.aspx): leClass myInstance = (leClass)Activator.CreateInstance(typeof(leClass), nameOfTheInstance);
I think you just sold me that book. i have some idea of how the logic works, but i'm rather clueless as to how to actually _do_ anything with it. i'm building a windows form to return network and broadcast adress for a given IP and subnet (taking a basic CCNA course), and i can make it accept inputs from the user just fine, but what if i wanted to check the contents of a file? i've no idea how to make it read or type or click or do anything that isn't encompassed in the program itself to begin with.
I'm not sure what you're looking for explicitly, but a decent place to start is the [wiki](https://github.com/SignalR/SignalR/wiki)
Many thanks. But seems that wiki is for SignalR 2.x, isn't it ?
You're right, I'm sorry that's the old github repo. The new one is housed under aspnet and doesn't appear to have documentation yet.
I'm not gonna aimlessly dig through 20 files for you, but some things you can check: - are there any additional event handlers for the buttons or the forms' closing events that might close the form - does one of the buttons have a `DialogResult` set
As far as I'm seeing there are no event handlers that would close the Update Student window from the Add Score window. And none of the buttons have DialogResult, it was working yesterday without that, and one of my classmates tried going that route and it was still broke. 
Yup, the `btnAdd` has a `DialogResult` set to `Cancel`. /u/MulishaMan187, change its property back to `None` and it should fix it.
The `frmUpdateStudentScores.btnAdd` had its `DialogResult` set to `Cancel` in the designer. EDIT: Right here: https://github.com/msm187/StudentScores/blob/master/WindowsFormsApp4/frmUpdateStudentScores.Designer.cs#L79
that did it. I was starting to wonder if I accidentally changed a property while I was messing with the properties window. Thanks!!
that did it. I was starting to wonder if I accidentally changed a property while I was messing with the properties window. Thanks!!
np, it's easy to do. Hopefully this reinforces the importance of good, and early, source control! Even if it's not about "rolling back", you should be able to see what files have changed and where, then it's typically pretty easy to spot such shenanigans. Glad everything is back up and running for you!
Things like this can be found so easy if you use version control 
How does EFCore tie anyone to SQL Server? EFCore had MySQL and PostgreSQL providers early on, too.
For login, you can have a resource to create access keys for a given account. In this resource, the caller should use Basic Authentication. The generated access key should be temporary (expires after X minutes) and can be used in all resources using Key Authentication. For resetting passwords you can have a non authenticated resource that sends an email to the account owner with a link that contains an access key that can be used to change the password.
I agree with sasmithjr. All of my .NET Core projects which use EF Core are using non MsSql databases. That was primarily because I do my .NET Core work on either Ubuntu or MacOS and when I started working in .NET Core (around this time last year) there wasn't an MsSql Server for Ubuntu. Microsoft isn't the big bad corporation that wrote the Halloween memos anymore. The reason that they open sourced all of this stuff was because they don't make money on it, want people to use it all, and gain a higher velocity for it (through community contributions; and there have been many, many massive improvements from the community).
I'm a little puzzled how that's a 'good to have'.. generally have avoided any sort of sticky sessions for anything that had to scale. We used the. Net version with redis backplane and it wasn't too hard to set up. Also puzzled about the no reconnect policy now
Also the GitHub page says it's an alpha... That had me worried a bit.. kind of doesn't go well with the announcement on ms blog.. my general expectation is that when they 'announce' a release, is production ready.
What to use instead of EF Core on .NET Core?
* Logging in: POST /sessions/ * Logging out: DELETE /sessions/current * Resetting password: PUT /users/name?password={new password} Generally speaking, try to think of your API in terms of lists of resources and actions upon those lists. There does come a time, however, when RPC makes more sense than REST; password reset workflows, for instance: * POST /passwordResetRequests/ ? * PUT /users/name/reset ? * PUT /users/name?resetFlag=true ? None of these are a good fit, because kicking off a password reset workflow _is_ an RPC instead of a state transfer. The REST police will not kick down your door for implementing ```POST /resetPassword/user```. If you want to sleep better at night you can do RPC in a REST-like manner: * POST /rpc/passwordReset By the RESTful definition this creates an RPC.
Why haven't you gotten, like, all the upvotes? Just did a quick read-thru, and it looks freaking *amazing*. Never having to touch Javascript again? Sign me the hell up!
It depends on what you're doing. If you're making websites, its generally assumed that you have at least a working knowledge (if not necessarily fondness) of Javascript so you can do frontend work. However, if you're mostly doing backend stuff like web APIs, data access, and business logic, you can *probably* get away with knowing next to nothing of Javascript. Having been a backend developer, myself, the only Javascript I'd ever needed to know was an instance where I needed to update a validation regex for an internal site; the rest was either C#, VB.Net, and SQL. *However*, if you're making desktop applications, you'll almost never be touching Javascript. At the very most, you'll be having contact with a scripting language like Python for certain tasks where flexibility (and not necessarily speed) is required to get things done, and SQL for working with databases, and even the latter is going the way of the dodo thanks to things like LINQ-to-SQL and Entity Framework.
The only time I see stuff like this that I can recall is if the library project is a different framework version than the "main" project . Edit: Assuming your extension is in another project
yeah if you hate js then this little framework is definitely for you :)
I was commenting too late :D
Restful for everything is plain stupid. If it makes more sense to go RPC then go for it. After all the goal is to make things simple not just try to conform to some ideology. Wrote like a rebel. Can't live by your rules man...
Lols. That makes this text less relevant &gt; we’ve worked to ensure that the user-facing APIs are very similar to previous versions
Dapper is mostly usable. We ended up switching to EF because Dapper didn't support calling stored procedures with TVPs in the Core version when we were migrating to .NET Core. This was a few months ago though, so the latest version might have added TVP support back in.
I think what is most important is that you can show a WPF form from a windows form. You SHOULD move to WPF. The fact you don't have to do it all at once lowers the barrier to entry. I can't comment on the MVVM, I have only ever created custom controls making my own data grids and binding them. It's so much easier in the long run to do binding. If you grids are consistently implemented you can end up making your own grid and match the types and design.
Don't use a hammer to turn on a light switch. 
That's exactly my concern as well. I've done a lot of pub/sub with a bunch of queue processing servers, and the backplane allowed those servers to send messages to the front end clients easily. Sounds like I may not be able to do that in this version.
Not to threadjack the OP, but I'm a Windows Admin that's looking to learn C# for a few personal projects and possibly some ops stuff. I'd like to focus on .Net IIS type development. Can anyone suggest a resource? I'm obviously technical, and understand the basic concepts of coding &amp; OOP. I just don't have a ton of hands on experience and I learn better by writing code or modifying existing code to figure out how it works and how I can make it do what I want it to do.
I can comment about MVVM, I got caught up in it for a personal project a while ago. When it works it's awesome, but I spent so much time fighting with it that it didn't make the cut for the next project. You don't need MVVM and I would discourage it unless you have a large app, because that's where it's strength is. Edit: hey it's awesome that this comment was marked controversial because that means there is a discussion to be had, I'd love to hear the other side of it if I'm missing something. 
Don't have much time at the moment, but I assume daylight savings is involved here. Maybe this answer/discussion will help you: https://stackoverflow.com/questions/2961848/how-to-use-timezoneinfo-to-get-local-time-during-daylight-savings-time
Isn't Eastern time currently -4?
So here's my take on it - Once I started using web frameworks like Angular ( and now the new version more so) I noticed the parallels between CQRS and REST. So given that: * everything is a command, a Query, or an Event to the systems I build. * All Queries are GET calls * All Commands are POST calls * Events are all internal, and typically push queued command messages ( this may or may not be true depending on if you're using an event store, in that case the commands would all be internal, and the events would all be POST calls) * the UI is 100% separated from the API - different apps and different installations * there's a mediator pattern that handles all calls that come in on the API * in many cases we're using a Roslyn library we found online to generate the API controllers and the typescript for the UI as well, so we're not even creating the API layer, purely convention based So given those architectural guidelines, you start to follow a very specific and repeatable pattern. For the resources that are secured, you have to send the OAUTH token to the API, so identity is already baked in to that, just pipe ICurrentUser into your IoC container. For the state you are talking about conveying, we handle 100% client side in JavaScript / AD - the only thing the client knows is the AD client ID that's passed through a config.json file to Angular. The actual Login that we do is through Azure AD, but if I were to create that on my own, I'd make that an entirely different application form my main app and API. 
&gt;Conceptually, C# has a bunch of features which just don't exist in C++ and most people still need that gentle slope to get up the learning curve. Exactly this. If OP were a Java developer I might make the recommendation for "In Depth" as a first read, but I'd still recommend "In a Nutshell" as a companion book. 
Windows doesn't display it as -4 or -5 based on dst, its always -5. Am I assuming wrong that getting the offset should do the same?
Strike that I probably am wrong,
Between the good and the bad is the ugly.
It's a pretty niche project but I've been working on an "extender" for the video game Space Engineers that wraps the game's client and dedicated server to add more functionality: https://github.com/torchapi There's some interesting stuff in there regarding IL patching and reflection because of the nature of the project. It's my first "major" project and I'm working with multiple other contributors so it's a fun experience learning more about C# and how to set up a more professional development pipeline.
You are correct and incorrect aswell, you are in the EST timezone which is -5 to UTC, you currently tho are in daylight saving, since UTC does not move with DST, only GMT does, you are now -4 in relation to UTC ... I think ... timezones are hard :c
You don't need MVVM. It's a nice pattern that fits well with WPF, but you can do without. You don't have to rewrite everything since you can still use your winform window in a WPF application. Do use DevExpress components. They are great and the grid is versatile. Performance wise, WPF is fast enough for not even trying to measure the difference with winform. Really. 
Not sure about your question but the way you check the handler isn't the best protected virtual void ClientStatus(...) { var handler= OnClientStatus; if (handler!= null) handler(new OnClientStatusArgs(....)); }
Yes, swagger codegen. "Manual" HTTP is... pfffft..
Thats my experiance with MVVM. Makin simple things is sometimes SO hard... I know that's mainly becouse my lack of knowledge and pratice with it but I can't just get my grasp on it. Thanks for response!
Can someone tell me what is the primary difference between using REST and RPC here?
Without mvvm you are gonna have bad times, everything in wpf is built around declarative views/styles/animations... and their bindings If you are gonna rewrite you should try to follow it, anyway you can use wpf in win forms and vice versa so you can do it gradually 
Well most of the time when i change status of any client i do it this way item.Status = ClientStatus.DISCONNECTED; ClientStatus(item); // invoke event So my thought was if would invoke event in ClientInfo class when i set status of client ClientStatus Status { get { ... } set { .... = value; .ClientStatus(...); } } i would call just this item.Status = ClientStatus.DISCONNECTED; and event would be raised but i don't know how to implement this correctly. Hope you understand now what i'm trying to achive here
Well the post also states it's alpha. Announcing things that are not final isn't new for them and helps with planning/architecting for future features.
Not to derail this into a DB region debate, but I haven't used EF in years and I struggle to see a reason to do so since document databases have matured. Everyone has their own preference, and more power to them, but I suggest you try out the plethora of data storage options out their today if you weren't sure what your options were outside of EF.
Yea I really hate dealing with time in general. Now I am not sure if I should even rely on this to do what I need. This code returns -5 properly but at this point. TimeZone localZone = TimeZone.CurrentTimeZone; TimeZoneInfo tzi = TimeZoneInfo.FindSystemTimeZoneById(localZone.StandardName); TimeSpan offset = tzi.BaseUtcOffset;
That's kind of normal for the alpha releases, it is annoying to have to brute force your way out of some sticky situations since there is no documentation. 
Thanks, It did lead me in a few different directions that were helpfull.
While this is good to note for the casual reader, the discussion is about API design and not security best practices. My examples were meant to be contrived.
Are you sure the event is not firing? When you put a breakpoint in the handler, what happens? Because, if you open the popup in the MouseEnter and if the popup is properly closed afterwards I don't see why not it shouldn't open twice.
I couldn't agree more. If it feels like a kludge, then it probably is, and you probably shouldn't do it.
In most REST services, I think there is a distinction between "reset password" and "change password". By "reset", I think this is more of a "forgot password" use case and would involve resetting a password to a random password. For example, a "forgot password" workflow would generate a random password and sent to you by email or sms. In this case, the state of the application changes non-deterministically each time it is invoked. By definition, this is not a idempotent operation and should be a POST method. The "change password" use case can certainly be a PUT method. I do have a problem with this particular PUT answer. The point of PUT is to update a resource by replacing the resource with a new version described in the body of the request. Having the password in a query parameter and not in the body, the PUT request as presented is wrong. Aside from that, making the "change password" action a POST method allows it to be used in web forms. I also [wrote an answer on Stack Overflow](https://softwareengineering.stackexchange.com/questions/313221/implementing-a-composite-rest-service/313274#313274) that may give you some insight too. 
Swagger rings a bell. I'll give that a poke too. 
GMT does not change with DST, although areas using GMT may observe DST (and switch to British Summer Time for example). GMT is UTC for all practical purposes.
The offset is adjusted based on DST, that is why you need to provide a `DateTime` to the method, so it can tell whether that date lies within DST. This is clearly explained in the documentation.
Sorry, I'm new to programming in general and didn't think of a breakpoint. With the breakpoint in the handler, I can see that the MouseEnter event is firing but the popup isn't appearing. So the issue appears to be with the popup instead of the event.
One of the first books I had for C# was The C# Players Guide. I thought it was very easy to understand and learn from.
No? I've never used MSSQL with entity framework....
I understand your point about putting parameters in the path. What are your thoughts on PATCH for changing the password? Do you have a preferred way of representing the patched data? Specific to Web Api.
They are both "standard" of doing things. The big difference is that in RPC, the service call you will create will be action-oriented while in REST it is resources-oriented. For example, you want to update a client: * RPC: PUT http://localhost:80/clients/UpdateClient?ClientId=123 * REST: PUT http://localhost:80/clients?ClientId=123 In RPC, the http verb you use has little to no incidence while in REST, the http verb is what define what you want to do with a resource (GET for get, POST for insert, PUT for update, DELETE for delete). In some case, like in OP's question, REST makes no sense. You would have a resource /users/ and you want to execute a "reset password" action. In REST, you would do a PUT /users/.. but how the servers is supposed to know you want to reset the password, as opposed to update user metadata? That's where RPC becomes interesting, because you can execute multiple action using the same http verb, whereas in REST it is forbidden. * PUT http://localhost:80/users/resetpassword?userid=123 * PUT http://localhost:80/users/updateuser?userid=123 * PUT http://localhost:80/users/activateuser?userid=123 Dunno if that's clear, I haven't really worked with RPC as most of the service I create fit within the REST standard. Maybe someone more experienced can tell you more / correct me if i'm wrong
"final nail into Java's coffin" hahahahahah
No worries, how do you open/close your Popup object? If you use PopupName.IsOpen = true in the MouseEnter handler and IsOpen = false when you close it. You should be able to open/close it as much as you like.
Here is the code I'm using for the popup: private void HelpPopup(UIElement helpData) { PopupPanel.Children.Clear(); PopupPanel.Children.Add(helpData); PopupTest.Placement = System.Windows.Controls.Primitives.PlacementMode.Right; PopupTest.StaysOpen = false; PopupTest.Height = 300; PopupTest.Width = 200; PopupTest.IsOpen = true; } helpData is an object I've created to format the textblock and image that's contained in the popup. I added breakpoints to the class that creates this object and all the code get's executed the same before and after I click within a textbox.
I did write [something on this on Stack Overflow](https://softwareengineering.stackexchange.com/questions/313221/implementing-a-composite-rest-service/313274#313274) a while ago: &gt; REST, at first glance, has been naively described as adhering to the an architectural constraint by using creating, updating, retrieving, and deleting resources. Many people equate this to simply having CRUD objects that are persisted into a database. Although a good portion of microservices do this, it is generally anemic and provide little functionality otherwise. If one thinks a resource is just objects and data only, then they fall into the trap. IDEs and frameworks just love to devolve the idea of a resource to simple mean "objects" or "data", then try to retro-fit them into existing paradigms (like RPC). How does one apply REST and hypermedia constraint to real-world concepts? This skill involves breaking down what you want to do using the constraints given. In my SO answer, I describe what I think about the term "resource": &gt; So, what exactly is a resource? To me, resources also provide abstractions of functionality and process. The representations of a resource are the data the show the state of that functionality or process. From your question, you mention methods like "logging in" and "resetting passwords". To me, these terms are *processes* that have state. But in a stateless protocol like HTTP, how do you maintain state? The only way you can: transferring a representation of that state (the resource) to "something else" that can use and process ("handle") it further. That "something else" could be a web browser, an stand-alone mobile app, or whatever. The "something else" can either: * modify the state and PUT it back. Ex: "updating a user profile". * dissect the state data to retrieve additional resource data. Ex: "navigating a link", * combine data and POST one or more new representations to a different endpoint, creating new resources. Ex: "authentication" So, if you understand "logging in", by now I hope you understand this is really a *process* to "create an authentication token". The data that you POSTed to your authentication endpoint is an _initial_ state of that token (the credentials), the service accepts that representation of the token state, and handles it doing the appropriate token creation process (authenticating), and either responds with an HTTP 200 and updated representation of that token state ("an authentication token") or an HTTP 201 CREATED with a Location header set to the actual URL of the token created or an error (HTTP 401 UNAUTHORIZED or whatever) that indicates a new token was not created. Does this help you somewhat? EDIT: Corrected some information. 
Ok, I tried using your code instead of my Popup.IsOpen = true; (without the helpData bit) and it is working properly. Are you sure that you're closing the popup using Popup.IsOpen = false; properly? Sorry I don't really know where to look else.
&gt; What are your thoughts on PATCH for changing the password? I personally would not, but it is allowed because PATCH is not intended to be safe nor idempotent. &gt; Do you have a preferred way of representing the patched data? Let me explain what PUT and PATCH really are. PUT is *a complete replacement* of a state of a resource. It is truly the direct opposite of GET. The schema of the resource used in GET and PUT should match. one would normally use GET to retrieve the full representation of that resource, change that representation, then post the updated post. Let me ask you this: would you ever emit someone's password in a GET response? My guess is *hell no*. So, changing the password should not be in a PUT. PATCH is a partial update of an existing resource. Even though it is not safe nor idempotent, I treat it as so. I consider the data payload for a PATCH as a subset of the representation of used in either GET or PUT. So, if you wouldn't emit a password field in a GET, we should not use PUT or PATCH either. Therefore, for a "change password", I usually treat this as a process separate from a user profile resource. I'd would use a POST specifically for changing the password and nothing else. It is not safe nor idempotent. POST create resources, so what are we creating? I think of it as "Change Request" that requires your existing password (for verification) and one (or two) new password(s). The response is either "approved" with no body (HTTP 202 ACCEPTED) or "not approved" (HTTP 409 CONFLICT) with a error representation. 
Dapper is really good, but you must write the sql sentences in the code (I hate it) or use stored procedures (I prefer leave SPs for specific things). I prefer Linq2db, fast, linq and CRUD support. 
I put a breakpoint on the MouseLeave event where IsOpen is set to false. Turns out that was the problem. MouseLeave wasn't firing. I don't know why it had an issue, but I deleted and rewrote that section of code and it works perfectly. I feel silly it was something simple like this, but I am so appreciative of your help.
Don't feel silly, that's how we all learn. Happy to see that I have been helpful. Cheers!
I think it is better: OnClientStatus?.Invoke(new OnClientStatusArgs(....));
So, this is getting further from the OP but while we are engaged, imagine I have a GET /users/{id} and return an object with the id included, among other things. Would the corresponding PUT request be /users/{id}, or just PUT /users/? The id would be part of my payload so it can be inferred without the locator, however I think I like using the locator anyway just to be clear about intent. In this scenario I'd reconcile the locator and the payload id to make sure they match or else throw a bad request. 
What if you call ClientStatus(...) instead base.ClientStatus(...) in ClientInfo class?
Yes, that is the new way :) The null propagation makes it look clean again.
Since switching from rest to graphql this would just be another mutation really for me now. Then again its really just more standardized rpc from this pov. 
&gt; *particularly* in the .NET world there is a lot of mindless copy/paste. Amen. 
The way you usually work with data grids in WPF is by binding the data grid to a collection in the viewmodel. You then dynamically change the data grid by manipulating the collection rather than the data grid object. If you for example add an item to the collection you will get a new row in the data grid, if you remove an item you delete a row, and so on. The items in the collection are objects of your choice. E.g. var Customers = new ObservableCollection&lt;Customer&gt;(); For ordinary POCOs the data grid will know how to present the object. Otherwise you have to make a template that will tell the program how to present it. It's quite easy. You can also use LINQ on the collection.
One very thing to remember is that resources are identified by their URL (a universal *resource* locator). The WebAPI (and most REST frameworks) dilute it to simply injecting an integer or string when building this URL. The entire URL should be considered an opaque identifier. So when we talk at the higher level about resources, the URL is the __complete identity__ of this resource. Knowing this, let's respond to your question. For a resource located at http://www.example.com/users/1000 GET /users/1000 should return the complete user resource. When you do the following: PUT /users/1000 you are replacing the entire resource with a new resource described by your representation. The body of your request should contain the *complete* representation of that resource. No partial information. &gt; imagine I have a GET /users/{id} and return an object with the id included, among other things. in this case, if your representation is JSON, an id field is OK. However, I prefer to use the [hypermedia constraint](https://en.wikipedia.org/wiki/HATEOAS). Basically, it is the API equivalent of hyperlinking you already know from using a web browser. In my early APIs, the only option is to put links as part of the representation, which bloats a JSON payload. But there is a proposal to introduce [Link Headers](https://tools.ietf.org/html/rfc5988), which I think is a better solution.
&gt; entire resource So if i PUT /users/1000 and the body includes { "id": 1001 }, what is the expected behavior? It sounds obvious but this is a different paradigm from databases so I'm honestly unsure.
Even if MS could, I'm pretty sure Oracle has patented that process already.
Its usually about enterprise software where you need to support a polyglot of databases on the back end with the smallest investment in maintenance. Document databases are good and can be transactionally consistent, but the enterprise world moves slowly with data sometimes.
I just have unanswered basic questions that aren't covered by the samples. How do I connect to a hub from a client application written in C#? Do I use the HttpConnection object in the library? I don't want to muck around if that isn't even a supported use case yet.
* WPF works fine without MVVM but like others have said you will have a bad time with DiY unless you are experienced in patterns and practices. Really at the end of the day I have used versions of MVVM as well as MVC with WPF. MVVM is easier simply due to the requirements WPF wants to put on the model (requiring you to take dependencies into your data model you may not want). Further MVVM is easier due to the large number of frameworks that drop in fairly easily. Just go with MVVM, you don't have to be a purist and drop the use of your code-behind until you are better acquainted with XAML and how interactions/commands works. * UI speed is equivalent for the most part, and it actually can be quicker due to a better threading model. What tends to slow any load to display down are 3rd party or customer behaviors/converters that are poorly written or are simply heavy in general. * Yes all Win10 machines can run WPF or UWP apps. Since everyone is on Windows 10 I would suggest pushing to use the highest gold version of the .NET framework (VS will default to .NET 4.5.2 iirc, just change it in project properties) Yes grid data load will be fine, your biggest factor is how big the data set is and how many times you iterate through it to build your data view (this depends on how you use LINQ). I've used WPF with near-real-time trading applications with ease. If speed is your biggest concern I would take a careful look at the Task Parallel library and take advantage of classes like the ConcurrantDictionary to leverage the desktop's processor and improve responsiveness. And yes, get away from WinForms. It's only going to get harder to use and support as the industry pulls away from it. 
[David Fowler just opened an issue](https://github.com/aspnet/SignalR/issues/882) to investigate using Polly for retries by adding extension points to SignalR.
Exactly right. UTC doesn't shift with daylight savings. EDT is at GMT -4 just now. 
Simple things are hard with WPF and MVVM, because it is not very entry level friendly. You need to know frameworks or have your own classes for many basic things, that you'd expect to be there from the technology itself normally. It is however, much more powerful the bigger the application gets (once you have all the basics). 
I would suggest looking at an alternative approach rather than rewriting from scratch, with the application being the size it is. This article covers some of the major issues (well worth reading in full) - [Things You Should Never Do, Part I - joelonsoftware.com](https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/) In addition to the points he raises, a couple more I would note are: 1) You're new to WPF so will undoubtedly make some naive choices while writing it. In a small application you can just redo it, but this becomes harder in a large, customer facing application. 2) If you take on too much, you might never get it in a good enough state to be released. If you move on from the company, it just gets abandoned half done and your time was wasted. A couple of alternative approaches I would suggest that would help you move towards it gradually: 1) An application solution can quite happily mix WPF and WinForms projects, and WinForms controls can be hosted inside WPF controls. Consider moving your existing forms over to be hosted in WPF controls. See [WinForms to WPF - How do we get there from here? - StackOverflow](https://stackoverflow.com/questions/3457764/winforms-to-wpf-how-do-we-get-there-from-here). Once that's in place you can gradually improve things in smaller chunks. 2) Refactor your code to remove as much Winforms dependency as you can. So moving your code out of the forms into separate classes and making it work with standard basic types. You can do this over time to improve the overall quality without a huge major release that breaks everything, then once you come to the 'rewrite' you'll just be creating the WPF UI side and hooking it up to your mature, tested code rather than having to do the whole thing in one go which will be a much less imposing and risky task. Rewriting always sounds appealing but it's too easy to replace one mess with a whole other new mess. Going the refactoring route is much more likely to give actual improvements and is a valuable skill to learn which will serve you in the long run.
FYI, if you want your code to have a sane chance at managing time correctly, consider using NodaTime.
https://www.dotnetperls.com/file-readalltext You can store the data locally, parse it how you want, stuff it into a class etc etc etc There are multiple ways to read from and write to files and each has their pros and cons.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/angular2] [X-Post: When REST hurts your brain: how do you handle scenarios where conforming to RESTful princples just doesn't seem possible? • r\/csharp](https://np.reddit.com/r/Angular2/comments/70dz9b/xpost_when_rest_hurts_your_brain_how_do_you/) - [/r/webdev] [X-Post: When REST hurts your brain: how do you handle scenarios where conforming to RESTful princples just doesn't seem possible? • r\/csharp](https://np.reddit.com/r/webdev/comments/70e114/xpost_when_rest_hurts_your_brain_how_do_you/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
ListView? ListView is the control used on Windows Explorer, you can attach a bitmap to each item.
It totally depends on the MVVM implementation, I'm using ReactiveUI (it works even on Winforms) and I couldn't be more happy. Developing on code behind is a nightmare if the project isn't small. 
I like hungarian notation but the rest is a complete mess. Diving into that code would be a nightmare.
NodaTime, full stop. Using the TimeZone class will lead to madness. The hard part of NodaTime is figuring out what IANA timezone (the argument that you're passing to Tzdb[]) should be. But once you have that, figuring out how the UTC date should be displayed in local date/time becomes trivial.
Honestly, turning on a light switch with a hammer is fairly straight forward. OP's example is more like using a hammer to ask permission to turn on a light switch.
Thats for .net clients only
This x2. Code first is where it's at. I don't need the hassle of sending a column change migration Sql script to my entire team and updating our ten dev databases by hand. 
I found that under the issues tab for the "ASP.NET Core SignalR" project, not the old .NET Framework one. David Fowler frequents feedback about these projects. I don't think its a coincidence that they released Asp.net Core SignalR 2.0, people complained on social sites about retries, and hours later David Fowler opened an issue to see they could extend in retry logic. -edit- [This is the github for SignalR for .NET](https://github.com/SignalR/SignalR), its not the one that contains the issue I linked to.
And it also limits the ability to do proper testing.
It might be a bit easier (and faster) to display a list of names of images. Allow the user to scroll through it and display an image one at a time in a PictureBox. A quick google search didn't find much on a buffered image (not BufferedImage) list so I image that might be the best solution (that I can imagine). 
I like that analogy
UTC is what all the time zones are relative to. UTC is the base, and all the time zones are offset from it (mostly); so UTC never moves. When in daylight savings, you will move to a different time zone. For this example, OP will move between EST and EDT, but UTC never moves. GMT does not change with DST. The UK moves between GMT and BST.
Although, I believe exposing the database identity is a leaky abstraction, some teams insist on it being there. So, if you absolutely need it there, then if someone tries the override it as you describe, I would issue an HTTP 409 CONFLICT. 
I dunno, that's also pretty straight forward. I can't imagine a person needing to be hit more than once or twice before letting me turn on the damn light.
You do not need to use mvvm to use wpf. Wpf is designed for mvvm, but you can use any practice that you would use with winforms.
I don't think a DB-first approach is the way to go, but learning EF (or any ORM) before learning DB concepts is going to lead to pitfalls. OOP and relational modeling have some fundamental differences (hence the mapping) and I think a number of important details can be lost. So I'd have to suggest just building a database or two. Learn those concepts. Then learn EF and try out code first.
Turns out that I mucked up a bit by not populating my domain class reference on the view model, and also having differently named properties in my view model than in my domain class
It's funny most people use REST apis through some auto-generated RPC wrapper that abstracts the verb, path, query and body. Makes you think what the point of REST was in the first place. Other than endlessly debating about what is and isn't REST.
Design patterns are ideas of ways that you *can* write software. When they become shackles about which you aren't allowed to deviate in your code, something has gone horribly wrong and it's time to throw the pattern out the window.
Thank you all for the responses - now I know where and how to start!
Again, the link you gave above spoke about Polly on the client side written in .net core. Nothing about typescript clients.
Thanks for following up. I spent a few hours last night googling and couldn't find anyone with an opinion. A few buddies and I debated as well and the consensus seemed to be the same; you wouldn't allow the body of a PUT to change the locator. 
Its a glorified text editor, that's why. A justifiable size for all the the bells and whistles would be 5GB and even that would be ridiculous but they have been adding junk on top of junk for years. They need to rip it all up and start again truth be told.
15 seconds is absolutely horrendous, I could reboot linux 3 times in 15 seconds
Not all commands are post calls. And not all queries are get calls. No. Please no. HTTP 1.1 method specifications are there for a reason. A delete item command is not a post operation. It's a delete operation. A batch deletion is a post operation because it requiresa body (the IDs of the targeted items in my example). Error codes and methods are meant to play along.
When I was a kid my dad's shop, I used a wrench to turn off a light switch I couldn't reach. It didn't have a face plate and I got mildly electrocuted. So don't use a wrench to turn off a light switch.
Found a like minded person. Been wondering this for a while myself
I understand your stance, I agree with it from an academic perspective. But when 100% of the code is generated, no developer involved, why does it matter? There's nothing we're doing that even cares about the action, or the response code, and the system works flawlessly. Even at the UI level, nothing cares, its' just wiring. There are events that post back on signalr or socket.io notifications to the UI that use a similar channel of communication, again, completely abstracted from developers. it becomes purely an academic discussion at that point. using CQRS under the covers, there's only command and query, (or event/query ) to the UI. The only difference in our system is what gets written to the web logs, which we throw away because the logging in the mediator is infinitely more useful. 
Ah I see now. When I read &gt; we should investigate to see if this can be plugged in client side. I read it as: "We could implement Polly on the server side, we should investigate if it is feasible to implement it on the client side as well". I assumed he meant the ts/js client since they haven't even posted samples or documentation for using the .NET Client yet. Why would he post that issue after the release to get feedback on something that hasn't been explained yet?
You make good points! Knowing how to structure a relational db is a must and, in fact, utilizing EF will rely on that knowledge.
So I have to ask... why the hell would you be creating anything new in WebForms?
You definitely do not need to use MVVM. I've never used it and I've developed in WPF for over a decade. I just separate my data and presentation of that data, but even that is a personal preference and not a requirement with WPF. 
Windows timezones are a mess and display incorrectly. Eastern time is currently -4 because of DST. I get the confusion as the Windows UI says (UTC-05:00) Eastern Time (US &amp; Canada). Ignore that -5, it is incorrect during DST. 
Haha! I'm making an app which I will be re-creating as either a Web Forms or ASP.NET application. This version just serves as a POC. I should also add that I just doing this for fun
Thanks for the reply BumSkeeter, I will bare that in mind :)
Brilliant, thank-you for your reply Ronald_Me
WebForms shouldn't even be a consideration for something new. Someone should slap you across the face for even considering it! Seriously, though, WebForms sucks and you're actively doing yourself a disfavor by using it.
I work with timezones a LOT. My thoughts are that you should always use UTC in code and persistent storage. The only time you should mess with timezones is when you're displaying data to the user, where you will just convert your timestamps to local time.
Yea, I am/was trying to make a make shift server selection based on region and timezone to pick a decently close server. not really doing time calculations or anything, just was going to use the offset to query records then fan out if one isn't listed for that offset.
Gotcha. In that case you could just compare utc offsets between server and user. There's probably some edge cases with states which don't have DST or what have you, but should be close enough I imagine. If you're using time zone to estimate distance, you might be better served to use a service to estimate location by IP address? Whatismyip.com has an inexpensive service for this, though I don't know who's API to use to estimate distance between two points.
I thought of that, but my personal IP address regularly locates me several states away, though I suppose my biggest quip was I didn't not want to rely on external services. I was going for more a "this is close enough" to narrow down a list.
You're not concerned about users from South America correct?
Thats why I was picking Region and timezone but I'm seeing that may not be good enough.
Excellent
As someone who does WebForms, WinForms, MVC, Web APIs, etc. I'm going to have to agree. OP, I know Win and Web forms looks easy at first with the whole compenent driven oop style with WYSWYG editors, but once you add any sort of complexity that extends beyond its typically use cases you're just asking for a nightmare. I suggest picking a more modern technology or paradigm to use. The learning curve will be worth it.
meh, in the *programming* world.
Well no, it is pretty clear. The connection issue was never server-side; and reconnect feature was always a feature of the client. But Polly is a .net library so when it is mentioned, it is obvious that it is bot a ts solution. Arguably, one could build their own - but why bother with signalR then?
Ditto.. webforms looks easy and nice at first but when you start doing complex pages it gets ugly fast. Viewstate, postbacks and if your unlucky or ignorant enough to use the ajax control toolkit make you want to throw the computer across the room. I took a week long tutorial for angular 2+ then threw in some PrimeNG controls for complex pages. So glad I did!!!!
&gt; The connection issue was never server-side; and reconnect feature was always a feature of the client. It was a feature of the client, but from what I understand it requires queuing messages on the server side to replay to the client once it reconnects.
Some things are possible to do in WPF without MVVM, but if you attempt to do so, you will just cause yourself a world of pain. I've been there and done that, when I first started using WPF (poorly and without really understanding it) back in 2010.
It's just an example, how you actually do auth is besides the point and a topic all unto itself. If anyone is actually taking authentication and security advice from a post about RESTful endpoint examples then may god have mercy on their soul.
I agree. This is just an exercise in REST. For the authentication itself, it is best to use a proven framework rather than roll your own. I could be wrong, but certain workflows discussed, like resetting &amp; changing passwords, may not in the scope of the auth frameworks.
You can use collection initialisation syntax. ``` var masterList = new List&lt;List&lt;double&gt;&gt;{ new List&lt;double&gt; { 1.0, 2.0, 3.0 }, new List&lt;double&gt; { 4.0, 5.0, 3.0 }, new List&lt;double&gt; { 9.0, 8.0, 3.0 }, new List&lt;double&gt; { 1.3, 2.4 } } ```
Which Roslyn library?
&gt; List&lt;List&lt;double&gt;&gt; MasterList = new List&lt;List&lt;double&gt;&gt;() Thanks. Can i name the new lists instead of immediately populating them? 
Well your current names are not that useful. If you keep that naming scheme, its already being 'named' by its index in the master list. 
So, I cant?
If you need fo name them, you can define them first and then add them to masterList using Add() method. Or, you can use masterList[0], masterList[1] etc to access them to add elements later.
You can but I'd be more interested in what you're intended use for those names are. You already have a reference to those lists in the scope you're defining them in by use of the masterList
If I understand what you're asking, you want to have essentially: List&lt;double&gt; List1 = new List&lt;double&gt;(); List&lt;double&gt; List2 = new List&lt;double&gt;(); List&lt;double&gt; List3 = new List&lt;double&gt;(); List&lt;double&gt; List4 = new List&lt;double&gt;(); List&lt;List&lt;double&gt;&gt; MasterList = new List&lt;List&lt;double&gt;&gt;(); MasterList.Add(List1); MasterList.Add(List2); MasterList.Add(List3); MasterList.Add(List4); Correct? There's a couple ways you could go about doing this. First way doesn't help too much, but can be used in C# 6 and earlier: List&lt;double&gt; List1, List2, List3, List4; List&lt;List&lt;double&gt;&gt; MasterList = new List&lt;List&lt;double&gt;&gt;() { (List1 = new List&lt;double&gt;()), (List2 = new List&lt;double&gt;()), (List2 = new List&lt;double&gt;()), (List2 = new List&lt;double&gt;()), }; C# 7, you can make use of a helper method and abuse the new `out` variable declaration: private static List&lt;double&gt; MakeList(out List&lt;double&gt; list) { list = new List&lt;double&gt;(); return list; } List&lt;List&lt;double&gt;&gt; MasterList = new List&lt;List&lt;double&gt;&gt;() { MakeList(out var List1), MakeList(out var List2), MakeList(out var List3), MakeList(out var List4), }; EDIT: You could also add an extension method, for C# 7: private static List&lt;List&lt;double&gt;&gt; AddList(this List&lt;List&lt;double&gt;&gt; sourceList, out List&lt;double&gt; newList) { newList = new List&lt;double&gt;(); sourceList.Add(newList); return sourceList; } List&lt;List&lt;double&gt;&gt; MasterList = new List&lt;List&lt;double&gt;&gt;() .AddList(out var List1) .AddList(out var List2) .AddList(out var List3) .AddList(out var List4) Or add overload for some expected number of items: private static List&lt;List&lt;double&gt;&gt; AddLists(this List&lt;List&lt;double&gt;&gt; sourceList, out List&lt;double&gt; newList1, out List&lt;double&gt; newList2, out List&lt;double&gt; newList3, out List&lt;double&gt; newList4) { newList1 = new List&lt;double&gt;(); newList2 = new List&lt;double&gt;(); newList3 = new List&lt;double&gt;(); newList4 = new List&lt;double&gt;(); sourceList.Add(newList1); sourceList.Add(newList2); sourceList.Add(newList3); sourceList.Add(newList4); return sourceList; } List&lt;List&lt;double&gt;&gt; MasterList = new List&lt;List&lt;double&gt;&gt;().AddLists( out var List1, out var List2, out var List3, out var List4);
I want to be able to populate/manipulate those lists later in the code, so call them by name would hopefully be easier to me. Am i making sense? Of course then, those names will be changed to something more meaningful.
wow thanks, that worked for me.
Ok i see what you mean now... ok i gotta rethink this lol.. thanks for your input!
[removed]
Yes, here is two ways var list1 = new List&lt;double&gt;(); var list2 = new List&lt;double&gt; { 1.0, 2.0, 3.0 }; var masterList = new List&lt;List&lt;double&gt;&gt; { list1, list2 }; list1.AddRange(Enumerable.Range(1, 3).Select(i=&gt;(double)i)); foreach (var l in masterList) { Console.WriteLine(string.Join(",", l)); } Console.ReadLine();
If I get my way, then one day you'll be able to declare a variable inline like you wrote.
From what you have said your use case is, I don't think you really want a list of lists. I think you want a dictionary of lists. If I was doing this, I would also add an enum so that I didn't have arbitrary text strings throughout the app. enum lists {list1,list2,list3}; public static void Main(string[] args) { var masterList = new Dictionary&lt;lists,List&lt;double&gt;&gt;(); masterList.Add(lists.list1, new List&lt;double&gt; {1.0,2.0,3.4}); } 
why would you do this over creating a SQL function to do the same thing? It's cool, don't get me wrong, but I was curious what benefit it provided over a SQL function.
Judging from experience, most of our client DBA's *hate* CLR in SQL Server. It shows up in almost every RFC and responses to our install guide. It might work for smaller installs, but off-the-shelf is a much harder sale.
Please don't do this.
The big one is that you probably have a lot more C# devs in your organization than TransactSQL developers, so this would be a way to leverage that expertise and maybe unburden your DBAs a bit. I'm given to understand that it doesn't perform terribly well (not sure why; just what I've heard/been told). It's also been my experience that C# programmers wind up being at least mediocre developers of whichever procedural language the DB they're building on top of uses, anyway.
Its just a feature which .NET and SQL Server provides and I just explored. I agree it's not the best way to do it but it's good to learn something new (even if its bad :))
ive been using VS 2010 for WPF projects, you miss out on some new c# features, but i would like to know if i need 2017 for something really worth while.
If you have the space they will install side by side and you can use both at your leisure. I ran VS 2008, 2010, 2012 and 2013 all on the same PC (I needed some of legacy project types and SDKs).
What are the features I'm missing out on newer Visual studio? The 2017 has the .net core 2.0 for ASP.net thing. I'm using Laravel and that's not my concern.
My laptop has a lot of space left. I have vs 2015 and 2017 and now might consider get the 2013 also for performance. Anyway, why do you have VS 2008 on?
Windows CE. I believe Motorola and Honeywell are still releasing new devices running it even though Microsoft abandoned it long ago. Unfortunately they didn't provide a sensible upgrade path for industry users.
You will miss C# 6.0 features, C# 7.0 features and C# 7.1 features.
You're missing out if not using VS 2017. There is an [incredible performance boost](http://www.c-sharpcorner.com/article/xaml-highlight-features-in-visual-studio-2017/) during XAML editing compared to VS 2012-13-15. (VS 2010 was also good in that regard) There's XAML edit and continue, which is great! There's also tools added to analyze UI components, much like [Snoop](https://snoopwpf.codeplex.com/). Only it's integrated into Visual Studio. (I still use Snoop). 
That is 'reconnect'; i think github talks about transport degradation
Implement the levenshtein distance or fisher Yates algorithm in SQL, then you'll know why this exists 
Missing a really important point about the behavior of `readonly` when used with mutable structs. see https://stackoverflow.com/questions/9234910/spinlock-and-readonly-fields
Skip the entire article, read the last paragraph. Thank me later.
Mutable objects in general are dangerous. public static readonly List&lt;string&gt; EmptyStrings = new List&lt;string&gt;(0); EmptyStrings.Add("list is no longer empty"); This code works just fine but doesn't do what some people think it does. Readonly only affects assignment. You can still use the readonly object in all the normal ways. You just can't assign a new object to that address/field/reference.
The name of the issue is "Investigate polly for retires/reconnects", it doesn't mention degradation.
Removed: Rule 7, [plagiarism.](https://blogs.msdn.microsoft.com/mazhou/2017/06/27/c-7-series-part-4-discards/)
Removed: Spam, Rule 7, [plagiarism](http://seesharpdeveloper.blogspot.ca/2016/06/calling-c-method-from-sql-server.html).
VS 2013 is fine for WPF. I'm still on that version and have no issues.
VS 2013 is fine for WPF. I'm still on that version and have no issues.
VS 2013 is fine for WPF. I'm still on that version and have no issues.
VS 2013 is fine for WPF. I'm still on that version and have no issues.
VS 2013 is fine for WPF. I'm still on that version and have no issues.
~~Removed: Rule 7, spam, plagiarism.~~ EDIT: Disregard me. I mixed up and removed the wrong submission. Also, I like the `goto` statement.
Plagiarism.. it's not.. and it's not even spam as well.. show me from where it's copied
Sorry, got my submissions mixed up. Was dealing with other plagiarism submissions and got the submission pages mixed up. Restored.
If you want that behavior - where you can't add or remove the items in the collection you have readonly collections. That doesn't mean you can't mutate the objects in the collection though. It'll have to be turtles all the way down for that.
Turtles have existed for around 215 million years.
After getting pair the full page, delayed add popups, I finally did. He's just a lonely const, looking for someone to love.
I think you're missing a closing curly brace. This line: else if (fvaluta == "usd") Is being associated with the `if/elseif` chain above it: if (avaluta == "usd") else if (avaluta == "euro") Try this instead: if (fvaluta == "sek") { Console.WriteLine("Välj den andra valutan usd &amp; euro"); avaluta = Console.ReadLine(); if (avaluta == "usd") { res = antal * (sek / usd); Console.WriteLine("Du har" + res + "dollar"); } else if (avaluta == "euro") { res = antal * (sek / euro); Console.WriteLine("Du har" + res + "euro"); } } else if (fvaluta == "usd") { Console.WriteLine("Välj den andra valutan sek &amp; euro"); avaluta = Console.ReadLine(); if (avaluta == "sek") { res = antal * (usd / sek); Console.WriteLine("Du har" + res + "sek"); } else if (avaluta == "euro") { res = antal * (usd / euro); Console.WriteLine("Du har" + res + "euro"); } } else if (fvaluta == "euro") { Console.WriteLine("Välj den andra valutan sek &amp; euro"); avaluta = Console.ReadLine(); if (avaluta == "sek") { res = antal * (euro / sek); Console.WriteLine("Du har" + res + "kronor"); } else if (avaluta == "usd") { res = antal * (euro / usd); Console.WriteLine("Du har" + res + "kronor"); } } 
I understand it is deprecating (you could argue that it's totally deprecated at this point) and see some merit in pointing that out - I will most likely recreate this using ASP.NET, but as I say, at the moment my project is a POC and made purely for fun :)
I'm not entirely sure I understand what you have going here. First off, you can avoid the lack of type safety/weirdness of using `Array` by casting to `Cards[]`: Cards[] values = (Cards[])Enum.GetValues(typeof(Cards)); Cards newCommunityCard = values[rnd.Next(values.Length)]; Now, the second part I'm not too sure if I understand what you're trying to achieve. If you're keeping a set of community cards around, you can use the `String.Join` method to easily concatenate them together with a delimiter: List&lt;Cards&gt; allCommunityCards = GetMyCommunityCards(); //where/what ever that is allCommunityCards.Add(newCommunityCard); CommunityCardsTextBox.Text = String.Join(", ", allCommunityCards); 
Thanks
Nailed it FizixMan! Thank-you for the reply :)
thx man
do u by any means know how to do this part in switch and case? I have litterly no idea!!
This should get you started: https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/switch
I read row 5 as "a readonly can only be of the primitive types" (incorrect), after which it's kinda contradicted by row 7. A bit confusing..!
Yeah I was just noting that it is a common gotcha.
TIL
Good bot
Thank you dfcook for voting on AnimalFactsBot. This bot wants to find the best and worst bots on Reddit. [You can view results here](https://goodbot-badbot.herokuapp.com/). *** ^^Even ^^if ^^I ^^don't ^^reply ^^to ^^your ^^comment, ^^I'm ^^still ^^listening ^^for ^^votes. ^^Check ^^the ^^webpage ^^to ^^see ^^if ^^your ^^vote ^^registered!
The question is really .. do you really want to start a new project using versions so out of date due to a single slow dev laptop ? The answer should be no. 
I still don't get how to do the first part just keep getting errors....
&gt; avaluta = Console.ReadLine(); switch (avaluta) 
yes, readonly can be anything... and one more difference: * you cannot use static readonly as optional parameter
That does exactly what people expect.
Looks like it could be a bracket issue. If you are in Visual Studio, do a ctrl k+d. It will format and you can make sure brackets are lining up how They are supposed to.
No it does not. I've seen plenty of developers get confused as to why they can modify readonly fields. It's purely a word choice issue. Readonly can mean multiple things, or multiple levels of readonly.
Where are unity tutorials? Unity is breathing c# and gave life back to it
What do they expect will happen when they call Add? They may need a lesson on why it works, but it still does what they tell it to. Unlike a spin lock, which is the source of very subtle bugs.
In my experience they've either expected it to do one of the following: 1. Not compile 2. Do nothing 3. Throw It has always turned into a lesson, I'm just saying it isn't always obvious to everyone. In my opinion readonly wasn't the best keyword.
&gt; Unity is breathing c# and gave life back to it LOL.
What sort of errors? Switch syntax is pretty simple, but it *is* a little different from the usual in C#. 
For hobbyist game development maybe
Removed: Rule 4. Show us the attempt you made with `switch/case` and the errors you got.
Then why did they write the Add line in the first place? That's some serious cognitive dissonance going on that needs to be addressed in your junior devs.
&gt;Is it a hostile environment, or supportive, do people want to see you improve or tear you apart? All different kinds. I had one place where I found out after the fact that the other guys were all trying to backstab me and claim my code wouldn't work. It did though, and it was easy to tell. It really sucked because I was trying not to step on their toes and trying to work with them. I still have no idea why they did that. My current place is far better. The people I work with now are very supportive. The places I worked with in between were a mix. Some even had a mix of backstabbers and supporters. 
Yea, I actually got burned by that one.
ROFLMAO
Thanks! You can ask me for more facts any time. Beep boop.
Pay attention in class.
I swear I am. My professor likes to give us assignments over things he hasn't taught us.
What are you having trouble with? Capturing the key press? Changing the colour?
Capturing the key press. Once I have that I think I'll be able to figure out the coloring.
Use the forms key down/up event. Set Form.KeyPreview to true this allows the form to process all key events before they get to the control. Also set e.handled if you handle the key press. Edit: this should be easy to Google, make sure you put "C#" at the beginning or end of the search
You are most welcome. Beep boop.
You can use this to crudely convert the VB to C#: http://converter.telerik.com Convert the samples you saw, try and understand how they're working then ask any questions if you get stuck. 
Look up onKeyPressed event. You add a method to it that is called when a key is pressed and you check if that key is tab.
It's not that hard 1. Developer one goes "I need this to be read-only so no changes can be made to the collection, oh hey a readonly keyword" 2. Developer two changes the collection 3. Tragedy Might make perfect sense to you but it's not that difficult to see how people come uo with the wrong conclusion. Not that i have a problem with the readonly keywordal as-is, but not understanding that it modifies the container, not the object itself, isn't that ridiculous of a mistake for someone to make once in their lifetime writing code.
Removed: Rule 4. As others suggested, be sure to include "C#" in your google searches. Break the problem down and work one bit at a time. Someone has already given an idea of how to detect when Tab is pressed so start with that. Otherwise, you'll have to pick up and run through some tutorials and learning material. If you run into specific issues, make an attempt and post the code that you have. Describe what you're trying to achieve, what the code is currently doing, and what errors/issues pop up.
hahaha hilarious joke
If you actually read the article you would see that there are links to Unity tutorials.
In your code you have included what looks like a method called "GetMyCommunityCard",if this is a method, should it except the List&lt;Card&gt; as a parameter? - Now both of us are confused! haha
You didn't specify/show how you're storing the drawn community cards. That method is just a placeholder for you to replace with however you're storing them.
 The install size of 2017 is smaller due to it being component based instead of just installing basically everything, so not only is it faster, smaller install size, it allows for C#6, 7, and any future versions, as well as its the currently most supported ide and allows for xaml edit and continue, what would be any reason NOT to use it?
https://github.com/nirvana-framework Heard about it from a colleague talking about some drunk idiot ranting about "you're doing it wrong". Turns out he was the guy who wrote it... And before talking with him, a few weeks later, I was "doing it wrong". Horribly under documented but brilliant piece of engineering just waiting to be fleshed out. I had to work with him to get a baseline, but it's stable. Though some features are lacking, YMMV though!
using a List to store your current hand is less dirty than doing it in the Text property alone. this is a simple example how to make that work: public partial class Form1 : Form { private List&lt;Cards&gt; currHand; private Random rand; private Cards[] allCards = (Cards[])Enum.GetValues(typeof(Cards)); //no type safety! public Form1() { InitializeComponent(); currHand = new List&lt;Cards&gt;(); rand = new Random(); } private void button1_Click(object sender, EventArgs e) { currHand.Add(allCards[rand.Next(allCards.Length)]); textBox1.Text = String.Join(",", currHand); } } enum Cards { a,b,c //examples }
If you don't need to hold a variable for the lists: var master = new List&lt;List&lt;double&gt;&gt;(); master.Add(new List&lt;double&gt;()); Or you could wrap some of the functionality in a class: public class MasterList&lt;T&gt; : List&lt;T&gt; { public IList&lt;T&gt; Create() { var list = new List&lt;T&gt;(); this.Add(list); return list; } } Usage: var master = new MasterList&lt;double&gt;(); List&lt;double&gt; list1 = master.Create(); List&lt;double&gt; list2 = master.Create();
String.Join(",", s) will do it
Honestly, i dont know. I know im stuck with c# 4... There are some quality of life changes. Im not sure if linq stuff is faster or anything. But vs 2010 runs so much quicker on my pc... Also, some of my third party tools would need to be upgraded, and the hassle to benefit ratio is too far the wrong way.
Ugh... march of the neckbeards... In your example, the only problem would be if you mashed your identity provider with your resource server (i.e. they're the same API). But even still... Logging in: requesting an access token from the authority. GET /auth/token?prop=1&amp;prop=2 The cognitive dissonance above is that this URI is that a REST endpoint should return a collection in this case which is false. REST is about resources. The above URI is a single resource, which is a step in a process to obtain an access token. The other argument is that REST shouldn't have query strings, which is also false. Query strings just have a very specific role in REST and that is to designate parameters (vs. providing properties). In this case, parameters for the token that will be generated off the resource. Resetting Password: POST /auth/passwordreset?user=username Here, you actually are creating a resource. You're creating a temporary landing page that allows the user to reset their password. The username isn't in the resource path because you're not currently doing anything to it; you're not talking to the user object, you're talking to the authority. "passwordreset" is a resource here, an actor. Nothing happens until the password is actually reset. You're also creating an audit record that the reset request was made. Or you're posting the request message, however you need to think about it. I don't see anywhere in the construct that states that anything you POST needs to be retrievable, only that if you were to make it retrievable, it should probably be done with a GET against the parent "collection". In other words, no one is saying that you have to implement every verb for an API to be RESTful. If you wanted to flat out change the user password without a flow, you could implement PATCH /users/username. This would usually be the follow up action to the reset flow. Probably 98% of scenarios fit REST perfectly fine if you think about long enough to find the practice and not convolute the meaning of REST. It's not a square peg in a round hole situation as many people would have you believe. Let me back up; here's why I say this: Idea behind rest is simple. Use a neutral protocol (HTTP instead of SOAP for example) to create, retrieve, update, and delete (GET, POST, PUT, DELETE, PATCH) resources (represented in the URI) in a way that the instructs the server how to process the message (combination of the verb, patch commands, and media types). A well designed REST API looks a particular way that you have probably seen which is what leads people to feel like there's only one correct way to do it which is crap. It looks a particular way because one of the traits of a well designed REST API is that it is discoverable/predictable. For example, if I PUT something at /users/dasjestyr then whether or not it was created or updated, I should expect to be able to retrieve it at GET /users/dasjestyr. Or if I POST something to /users then so long as it is successful, it should return a 201 with a location header telling me where to retrieve it (if permitted) which will likely be at GET /users/&lt;some server generated id&gt; In the Auth scenario, logging in is a GET request. You're asking for a token. The URI is the resource of the token authority/generator. The parameters you provide are needed to deliver the resource. It's fine. In the password scenario, you're creating a landing page (or at least a token that the page will use) that assists with the resetting of a password, and later straight up PATCHing the new password into the user entity. HOW this happens on the server side IS NOT A REST CONCERN. Too many people approach this construct too literally as if you POST something to the API, it should be implemented the same way as placing a file in a folder. That is FALSE. That being said - not every endpoint needs to be a RESTful, I'm just saying that the vast majority of them could be if you think about it for a second. The more you do it, the more obvious it'll become for future endpoints. My rule of thumb is to concentrate on the intent and focus on what the "resource" actually is for any particular use case. And remind yourself that REST != File System -- it just looks that way sometimes when the API is really well designed. In other words, take a step back and revisit your understanding of what REST actually is.
Did you just compare a design construct to the implementation of automation tool? Please understand that REST isn't about server-side development. It's about client side development. It's a construct on designing an INTERFACE. How you make it happen isn't a REST concern.
Aside from passing a password like that, that is not how a PUT works at all.
You cannot "PUT" a password, you can PUT a user, which means the entire state of the user is replaced or created. If you want to change a particular piece of the user, you're looking for a PATCH.
It's also worth noting that a User's password should probably not be part of the user object in the authentication system. By separating the concepts, the approach becomes a bit clearer.
Thanks! I'll definitely be looking into it. 
You are the perfect example of a 'REST' personality type. We deal with you people everyday. It's annoying and pedantic. You make the simplest thing into the most complex. Please go write another 900 page book on REST to enlighten everyone of your breakthrough in computer science.
For webapps, you got ASP.NET MVC -- HTML front-end, C# backend. If you want a desktop app with an HTML front-end, just google "how to host HTML controls in Winforms/WPF/whatever". Others might have better suggestions. I'd elaborate more but I am on my phone.
I've had my VS crash from a stack overflow during debugging, but never a BSOD. What the hell were you doing you lil' hacker!?
Oh! So it can happen? Is there any way to prevent it? or safely handle it? (try and catch then?)
Well, yeah, but like I said -- only Visual Studio crashed for me, not my OS.
Electron and ASP.NET Core
Thanks for the quick answer. I didn't realize I could host HTML in wpf. I guess I'll check that out first.
*generally* it cannot. BSODs are unhandled kernel exceptions, so the only things that can technically cause them are problems with the OS itself or with device drivers, which run in kernel mode. If it keeps happening, make sure you're up to date with windows updates &amp; any 3rd party device drivers you've installed.
Ah thanks! Just what I was looking for. I'll do that. I found it really odd for it to do something so dramatic...
I forgot to mention a 3rd thing, which is usually the most likely: bad hardware. A failing (or just underrated) power supply or memory are common causes of mysterious BSODs.
Yeah, my machine is old... so it would not surprise me. Although I'm fairly studious with my system. I backup every week. Apply all updates. Delete all unnecessary software. It literally hasn't blue screened in a full year. So, I was surprised, which is why I came here. If it's those issues, that shouldn't be difficult to fix. Also, would using C# Windows Forms have any issues with Windows 10? I'm assuming no... but you never know... some googling resulted in not much... it seems it's completely ok to use Forms with Windows 10.
It's perfectly fine to use WinForms with Windows 10.
But beware if you go in this way your application will need huge amounts of ram. Electron uses its own chrome instance to render view. 
What? You dontvreally believe that do you?
Either will work. With the first you lose some of the benefits of EF like caching. This post explains the pros and cons of the different approaches: https://mehdi.me/ambient-dbcontext-in-ef6 The scope management he comes up with might be overkill for a lot of apps, but he does a good job of explaining the DB context lifetime stuff. He also gives a few links to other articles about it. 
That sounds awful. What would be a general benefit to warrant that level of resource use? Edit, clarity: overall, not necessarily in this instance. 
Native OS apis doesn't have methods to render js, html and css. If you want to use those tools you need a js engine, html and css parsers. So electron starts a chrome back end. 
Ach, I see, like .net core. I just thought there had to be better ways to go about accomplishing those tasks, so there must be additional benefit to using that. Thanks. 
Context should be used with any db CRUD operations. It's fine to create only one, but EF can lock up your db at times, so it may be ideal to use the SqlCommand route for operations that you know will take a long time to complete, or if you need to b make concurrent changes while your EF context runs the longer query. If you're running longer stored procedures, go with SqlCommand. Generally, you should only have it ite ite open for the tasks in your methor. If you have multiple methods all relying on the context, then pass the context to the method to use. , Generally, you should create a context to grab your data, spit it out to an IEnumerable instantiated outside of the context, and then close the context as needed. If you have multiple methods and o you want to pass in your context, just make sure the method you're calling is inside the context. Ex (on mobile, sorry for bad formatting) Get Records(int I'd){ List&lt;record&gt;new List = new List&lt;record&gt;(); Using (var db = new dbContext){ List = db. Table. Where (X=&gt; X.id &gt;= Id).ToList(); Process ( List, db); } } Process(List&lt;record&gt; recs, DbContext db) { for each (var rec in recs) { db. Remove (rec); db.SaveChanges (); } }
You don't need MVC or razor, and I wouldn't make something new with MVC unless you want to learn it and your goal is to work on legacy code. I'm sure I'll get voted for the truth, but MVC at this point is legacy, even if MS doesn't want to say it. What you want to build is a webapi in C#. Then call your api as you would with any api in JS. You could store the html,css, and js in the same project/solution, but I don't recommend that. Treat the api and client code as different projects.
Apart from the fact that it’s a pretty awful IDE. 
Makes cross platform applications trivial. That's probably the biggest. Maybe lower barrier of entry. 
Jetbrains Rider is a reasonably new lightweight option, but I don't know anyone that is doing any serious dev with it yet though.. 
This. Almost all BSODs are caused by bad hardware or bad third-party device drivers. If a normal program is able to cause a BSOD and the real culprit isn't one of those two that just happen to get triggered by something the program did, then that can in itself be considered an OS bug.
I highly doubt performance on old hardware is a good reason to go with older versions of Visual Studio. VS2017 runs fine even on hardware from 2012.
That's a pretty big reason not to use an older version IMO. Especially C# 6.0 has a lot of features that at this point are pretty much a must-have. String interpolation and expression-bodied methods/properties being some of the most notable. C# 7.0's out variable declarations and ref locals are also pretty nifty ways of keeping code cleaner.
&gt; Especially C# 6.0 has a lot of features that at this point are pretty much a must-have. String interpolation and expression-bodied methods/properties being some of the most notable. Such trivial syntax sugars are "must-have" for you? They're nice, but definitely not must-have.
They are must-have in the sense that while we survived without them before they existed, they allow writing much cleaner code than what was possible in any reasonable way before, and now that they do exist, I would never want to write or recommend anyone else to write code without them. I mean, people were manually writing properties with backing fields and all the surrounding boilerplate before support for auto-properties were introduced, but that doesn't mean you'd still want to do that today (except in cases where it's actually needed for adding actual functionality to properties).
Sciter might be what you're looking for. 
Is this for a client side application or server side?
It could technically be either. Visual Studio Code is a good example of a client side implementation of Electron. For server side it would basically be like any other website where Electron is the browser instance requesting data from the server. Like others have said though, there are some performance drawbacks to Electron that should be considered.
I needed an AutoResetEvent that supported async and a timeout (AsyncEx supports async, but not timeout, also it doesn't look like it's being maintained). So since it's fairly critical that this actually doesn't behave oddly (like never letting tasks pass, or cancel calling when the task has already completed) I request that someone would be so kind as to look over the class. It's licensed under MIT so you can grab it if you need it yourself. Generally I'm not terribly comfortable with the timeout code. It is based on what `Task.Delay` does. I appreciate any criticism of the code from coding convention to logical errors or better ways to solve it.
This helped a lot! Thanks so much 
I just did a project where I had to embed a PowerBI dashboard into an Asp.net page. Search for "embed PowerBI dashboard" and there's a couple of projects on GitHub that should be of assistance. 
Should the `Timeout` check to see if the task was cancelled or completed? Is it possible that the timer could fire at the same time or while the code in the cancel/result is firing? (Or vice versa, the Timeout fires first, but while it's executing, the result/cancel fire?) I see the locks in those methods, but I don't particularly see where it prevents multiple of those methods firing (and I assume, in theory, one-and-only-one of those should be firing for any task?)
What about .NET Core? 
Excellent feedback! I would think that it should always prefer that the task completes, so it should perhaps check to see if it is able to remove the item in cancel and timeout. I see that there is an issue where WaitOne doesn't keep the lock across the collection insert which I should fix.
Since you have cancellation support anyway, you could create a `CancellationTokenSource` for the timeout to solve both with one code path.
Well, I run Windows 10 and I don't reboot, like, ever. Maybe when an installation requires it.
How about Win 10 education or enterprise edition? You can edit the group policy to avoid restarts.
So I wouldn't be able to do education but Enterprise might be an option. That's an interesting take... So I thought about the group policies as well, and I'm not sure if the folks I talked to hadn't taken a look at them, but apparently had tried a number of other things that seem to get ignored.
Thanks for you time. How would I do that? Add a CancellationTokenSource on the event registration? The API should take a CancellationToken, so how would they play together? I want a timeout to set the task to `false` instead of setting the task to cancelled.
Yeah, that's odd...I'd say one of the biggest complaints I get from my peers about Windows 10 Pro is the automatic reboots that they've tried several ways to disable. I think @dweeb_plus_plus might be onto something with the group policy on the machine.
Just a thought here, but you can totally do what you're asking. Put together HTML pages with a C# backend. So basically you'd end up with a solution where your HTML is your application and it makes Async requests to a C# server layer - WebAPI or whatever. Then your application just changes state based on the server responses. This is very much how SPA (single page apps) work. ReactJS, Angular, etc...most of them function this way. So, that said, yes, you could definitely have your GUI in HTML with no special hoops you're jumping through and have your server software be written in C#.
&lt;3 Coding Blocks ;)
What sevenalive said would work for .NET Core as well. Just create the WebAPI project for your server side calls.
Some people have odd expectations ;)
Yeah its not very straightforward. Basically you set your ethernet connection to "metered" and then set your group policy to delay all updates for 6 months. As long as you update Windows every 6 months (which you should probably be doing anyway) then bob's your uncle.
Something like void WaitOne(int timeout, CancellationToken cancel) { // ... cancel.Register(OnTokenCancelCallback, ...); var timeoutSource = new CancellationTokenSource(timeout); timeoutSource.Token.Register(OnTimeoutCancelCallback, ...); } void OnTokenCancelCallback() { OnCancelCallback(false); } void OnTimeoutCancelCallback() { OnCancelCallback(true); } void OnCancelCallback(bool isTimeout) { // ... if (isTimeout) task.TrySetResult(false); else task.TrySetCanceled(); // ... }
It's run fast on a clean install. But I have browser, sql server and visual studio 2017 with a lot plug-ins and ReSharper. It take a huge time to load and for it to run fast, I need to open it up then wait then open project then wait for everything to load. Sometimes it goes over 15 min to 20 min and on some projects it might take as long as 25 min. I know ReSharper is a problem but developing software without plug in is put me at disadvantages and also I like jet brain product. 
I'd go server 2016. Can't beat the LTSB of will down where you only get critical and security updates.
I might get a ssd. Never use xaml before so I really don't know if it's that good.
Why no? 
Ok, thank you for your answer, but how about the legacy aspect of .NET Core? Is it still recommended to start learning it or is it already almost deprecated? 
Big project and ReSharper kill the speed but improve productivity. I might get ssd for the resharper
It doesn't has wpf. 
Why is it awful?
I agree that the new properties of 6.0 is great and I can encapsulate all field but what about crystal report?
In fact, most of the time you can use `TaskCompletionSource&lt;T&gt;` and `CancellationTokenSource`which are `Task` oriented and ignore `AutoResetEvent` and `ManualResetEvent` alltogether. (There are situations where it's not possible of course)
Give me a few minutes to find the answer. I can't rember how right now but I'm almost sure that there is a way to use a cancellationtoken to do what you want. There is something that you can use that either waits for the cancelationtoken or the operation to finish.
This is VERY similar to something I was doing. Remove async and await from within your Task.Run() and the problem I suspect will vanish. I was doing this and found it to be murdering performance and in Process Explorer it was showing millions and millions of context switches every second. Removing the async await stopped the context switching and performance was massively better. Is there a sync version of CopyTo?
Don't you need to drop massive amounts of $ for WS license? And based on a quick google, you don't even need Enterprise to hack out the automatic update, Pro is enough (but I never tried).
CopyToAsync works fine, it's when I try it with the asynchronous socket methods and WriteAsync/Read/Async that it is a problem. I need a finer control than CopyToAsync provides.
Found it! You must use a cancelationtoken. With the token you can use : cancellationToken.WaitHandle.WaitOne(500); This way, if the copy ends on time, all is good, but if the copy takes to much time, the cancelationtoken cancels the copy :) No CPU pegging! Yay!
Thanks! I found a temporary solution by ripping out the source code for CopyToAsync and editing it, but I still have no idea why that works and what I was doing isn't, because it is just internally calling WriteAsync/ReadAsync. Still very curious about the solution though.
Can confirm, I have enterprise edition of Win10 and manage everything via policies only. Now Win10 simply advised me via pop up that new updates are available but I can just click ok and ignore. It also does not download anything automatically. I update every 2 weeks or so when I feel like it. 
I've had maybe 4 automatic reboots in the last few years since 10 came out, so it hasn't been an issue. That said, I switched to running my dev environments in virtual machines 100% about 6 years ago, so I just put the VM to sleep when I'm done for the day, leaving everything exactly where it was. I've also been doing this long enough to remember when "save often, save early" was preached on numerous email lists I belonged to, so I tend to hit the save button any time I notice it up there in the toolbar, and can only remember losing a couple of hours of work once in the last 10 years or so (due to a weird VS crash). 
Glad to help and for letting me know :)
That is an interesting, and weird workaround but totally makes sense. Appreciate it!
Yeah, I've worked on Ent editions of Windows before and it definitely intervenes less because Enterprises would probably drop Microsoft like a hot potato if they went around changing systems without IT's knowledge. Thanks for the info!
So, if you were buying a license of server, yeah, it could run into cash. But if you have a Visual Studio Online license, you can typically get the developer edition of the OS included in your subscription. And on the configuring Win 10 not to do the automatic updates - I've got some smart friends who keep trying and they keep failing...and then outrage sets in :-)
Yeah, I hear you on the save often thing. It's odd though - as far back as I can remember, Windows would just tell you that "Hey there's an update" (assuming your IT department didn't have forced updates in place) so it was never a big deal. Like you walk away, grab dinner and come back and all was well. Not lately though. 
So it's interesting - I've gotten a lot of replies in regards to, you can update group policies (assuming you've got the admin rights to do it and your domain controllers don't just reset it), but nothing really in terms of - "I've been running 2016 Server and love it" or "I've been running 2016 Server and hate it". Guess not that many people have tried?
It's most definitely not deprecated. They just came out with the latest version 2.0... https://blogs.msdn.microsoft.com/dotnet/2017/08/14/announcing-net-core-2-0/ Microsoft is heavily invested in the cross-platform game nowadays. Also, if you're considering .NET Core, look at .NET Standard as well - more cross platform functionality because you're coding to standardized interfaces rather than just .NET Core classes. Will open up possibilities down the road. Here's the .NET Standard info - crazy this isn't more popular as I feel like it's probably the best path to go down if you're starting a new project: https://docs.microsoft.com/en-us/dotnet/standard/net-standard 
The statement above is one I can get behind!
BTW - I think I just understood your confusion. The previous poster mentioned that MVC is deprecated (controversial statement) - not .NET Core itself. He was talking about Microsoft ASP.NET's MVC framework: https://www.asp.net/mvc A lot of folks are moving away from that in favor of less server-side rendering of pages / binding. So more along the lines of a fat-client such as Angular, ReactJS, Vue, etc. + the server side pieces of WebAPI. The old MVC pattern builds the pages on the server and sends them down to the client. The "newer" pattern is to send the application payload down to the client and then make small requests to the server to retrieve data / update state. Then the application changes based on the resulting data. Hope that helps to clarify some things.
My company was forced to go WS2016. However, keep in mind that if you are looking to virtualize it on a server, you pay per core for licensing. Our 48 core server will cost us over $20k in licensing, and that's with using SLA.
You will eventually fall out of complience and Windows 10 will shut itself off or install updates. Doesn't matter the edition. It's the reason no POS system can use Win10 right now. Windows 10 IoT or LTSB have been the only to have extended time periods to avoid updates, but Windows will not ever ignore them, even with group policy. Microsoft seriously fucked up here when it comes to enterprise and POS.
While it's not anywhere near ready for production, you might want to check out [Blazor](https://github.com/SteveSanderson/Blazor). It's a WASM framework for C# based on ASP.Net MVC/Razor. 
I've run both desktop and server editions at various times over the years. It all came down to which one was a closer match to the target deployment environment. 
My Win 10 machine doesn't seem to notify me about pending reboots until after it has rebooted :P I don't lose work, but I do lose all my context.
That is why the reboots from the update is automatic....they dont reboot it after multiple warnings
Yeah, very true if this was on a server environment. I'd specifically be talking about running developer edition via the Visual Studio subscription.
Yes, my confusion was about the fact that .Net Core just got upgraded to version 2.0, and I thought the standard way of using it for a website was the same as with ASP.NET, so I didn't get the "use an API and call it with JS" thing. Thanks for your answers, I get it now. 
I like this answer a lot, and one of the reasons I was thinking about going the 2016 route - much easier to see if containers work as expected as well as any virtualization pieces.
Same complaint I hear from my peers...
Awesome...glad I could help out!
I feel you didnt read any of what i said
I'm in POS and almost all of our clients are running on 10.
Yes there is a sync version of CopyTo. I'm explicitly avoiding synchronous because this application has to support thousands of concurrent connection which would either exhaust threadpool or provide unacceptable overhead because iirc, a .net thread has a 1mb callstack. I don't understand how I am supposed to "remove async/await" from Task.Run and still achieve the desired behavior. Also, like I said the issue was not with the Task.Run(async () =&gt; await stream.CopyToAsync(stream)) code. That code worked fine with minimal cpu overhead. The issue was when I tried to use methods like the ones I linked in the pastebin, in the cases I used the asynchronous socket api and the asynchronous network stream api NOT when I was using CopyToAsync
You don't develop application architecture based on the slowest dev computer. You can replace that for a few hundred dollars. Migrating your project later could be much more costly. You are losing native C# 6+ syntax support for instance by going back to 2013. 
Now I can move on to make the combo boxes move over to the Survey form. 
&gt; So far I've heard people try a number of things to avoid this, but to no avail. You mean, saving your work? Windows is good enough with detecting when it's save to update and when it isn't. Regularly shutting down and restarting (and by regularly, I mean once or twice a week, or even once every two weeks), is also enough to let the system update uninterrupted. Choosing one or the other because of update policy is... not needed, to say the least.
Same Problem: InternetExplorer IE = new InternetExplorer(); IE.OnQuit += IE_OnQuit; private void OnQuit(ref bool Cancel) { Application.Current.Dispatcher.Invoke((Action)delegate { tb.Text += "OnQuit"; }); } This Event is triggering for a while. But when i open or close some other tabs etc. , the Event doesn't fire anymore even when the process is still running. 
It's unlikely that anything you do in .NET will crash Windows.
It's not super duper awful, but yeah you're looking at ~200mb for an application at least. Definitely something to consider if it's worth using. It's main advantage is being able to build cross platform apps with a rich HTML/JS based UI. Insanely easy to use, pretty well documented, and currently pretty popular. This isn't the only route to go. You could do pretty much the same with GTK, and have a cross platform app, but it's not nearly as well documented. I tried this route before and just quit because I couldn't find what I needed.
Hey I just started out programming and was told by my prof to use VS. I downloaded VS 2017 and it seems to be extremely slow when starting up, when I create my first .cpp file and etc, it took more than 2 minutes. And why does it look so different from the old VS? I downloaded the software from their website, I clicked on the software and it lead me to a page where there is three option. Enterprise, community and another one. I choose community and it started installing, but whenever I open VS I have to go through the software I downloaded from their website and it's pretty troublesome and takes some time before I can start using VS. Is there any quicker solution where you click on the VS icon on your pc and it opens VS straight away without having to go through which version of VS you want to use? 
I normally go weeks without a reboot. unless I have a long running process, then of course I get a reboot as soon as I walk out the door. "I'll just let this run overnight" must send up a signal for updates to be pushed.
"walk away for a few hours and plan to come back and wrap things up, this can be devastating if they lose their work" Jesus, man, just save your work before you leave your PC. If you walk away from your PC and leave anything unsaved, you deserve to lose your work. Sure, I guess a restart might cause you some temporary inconvenience if you had a bunch of stuff open and had to re-open it all, but if it causes you to lose unsaved changes that's all on you. If you're really worried about updates, just do them yourself when you have 2 minutes to spare. That way they won't install automatically. But as others have said, it's a total non-issue. I have never had Windows 10 reboot on me.
Can you post the original code that had the issue? As far as I know `NetworkStream.ReadAsync` should only return 0 bytes once the connection is being closed, and otherwise wait until data is available.
I'm actually saving up for the new Dell XPS or Macbook. They're so expensive but I've seen Visual studio 2017 ran on them nicely. You're right about not developing application on slow computer. But If I had ability to afford new laptop, I wouldn't ask this question.
Wow, I'm kinda shocked at this brash of a reply. I've known several times over my career where you're used to things just working so it's not Ctrl + S every two seconds. I mean I get what your'e saying, but wow...fwiw, there's definitely things that I work on that I don't save - say I'm writing some ad-hoc queries trying to reproduce a set of steps to a problem...I probably won't save that as it's not a long term thing I want to junk up my drive. Everyone works in different ways - losing that could lose hours of work. Should the person who was working in it have saved it? I mean, I guess it boils down to expectations. I get your point, but just assuming your PC is going to shut down on you with no warning seems a bit suspect and tbh, it's several people that have complained to me about the problem. Either way, still doesn't add to the idea of "should a developer run on win server 2016" - is there any benefit over Windows 10?
Maybe you shouldn't use Task.Run - it's used for CPU bound operations, not I/O. https://docs.microsoft.com/en-us/dotnet/csharp/async
I guess it all comes down to trust. I don't trust my PC to keep running if I am stepping away from it. It's not just updates - what if the power goes off? What if the cleaning staff unplugs it? What if my daughter turns it off as a "prank"? There are lots of ways a PC can go off and result in work being lost. If you have something that you're working on that you can't afford to lose, you need to save it. I use Sticky Notes a lot for things like this. It saves automatically (somewhere) so when I'm done with something I just delete the note and it's gone. Longer stuff I just save in a temp folder and clear out occasionally. Disk space is cheap. My time isn't. I don't want to have to redo work just because I didn't want to "junk up" my drive. All I'm saying is, if you walk away from your PC and lose unsaved data as a result, that's 100% on you.
It has to support multiple sessions basically, and as far as I know, using task.run is the best practices way of doing things as a background process. Like it is bridging hundreds of concurrent connections, even when I am testing.
This code will peg cpu: https://pastebin.com/TKVbgi3E
Oh lol, just realized I'm being a scrub and not terminating when it reads 0 bytes, like I should. Thanks for the info
Okay I've implementet it using `CancellationTokenSource`. Thank you!
Wait, I'm annoying and pedantic because I suggested that it's about designing interfaces and not implementations? Are you one of those people that think interfaces are a waste of time too? I should write another 900 page book that teaches you to what... engage your brain? You're the one that compared the validity of the construct to a tool that someone may or may not even use, genius. Good grief. Who hurt you? &gt; It's funny most people use REST apis through some auto-generated RPC wrapper that abstracts the verb, path, query and body. "Most people" ... that's a bold claim. Care to share the study on this ground breaking dissertation, professor?
&gt; RPC: PUT http://localhost:80/clients/UpdateClient?ClientId=123 &gt; REST: PUT http://localhost:80/clients?ClientId=123 The REST call would probably be more appropriate as `PUT /clients/123`. Query parameters should only be parameters/filters (e.g. limiting results to certain fields, etc.). The equivalent GET would either be the same unless you were pulling a specific subset of the full `/users` collection. I agree with you on the RPC implementation. I'd probably describe RPC as an HTTP interface to your actual implementation of the API (a 1:1 to your methods on the API implementation). REST is also an interface, but more of an abstraction or facade to dealing with resources on the server as if they were objects in the real world. Many compare it to a file system approach, but I think some end up taking that too literally at times and it distorts how they implement things.
So what would one use this for? I'm still in college, but this is at the least interesting to look at. 
Use a [CancellationTokenSource](https://msdn.microsoft.com/en-us/library/hh139229\(v=vs.110\).aspx) instead.
Are you talking embedded POS?
Design patterns are a way of describing a time tested, battle hardened solution to a particular design problem. Much easier to tell someone that it's a strategy pattern than it is to explain everything little thing about how it works. They're tools, not a specific way to build a system. I think your causation is backwards. When they become shackles, then it's not time to throw the pattern out the window. It's time to rethink what you're doing (design smell). If the pattern is correctly implemented, then feeling like you're forced to break the pattern to get a job done is almost always an indicator that you're doing it in the wrong place (wrong layer, wrong object, etc.). That said, it's totally find to combine patterns so long as it's clear what you're doing.
My point was more meant to basically tell you use all new stuff and suffer the slowness for now until you can upgrade the PC. When you develop from scratch you need to try your best to see where you want to be in X months / years. It sounds like you have a plan to upgrade at some point so there is no need to handicap your application with old tooling and workarounds from day 1. 
Are you sure its not asking for a program that literally sorts spaghetti? 
&gt; Design patterns are a way of describing a time tested, battle hardened solution to a particular design problem. Design patterns are a way of describing a time tested, battle hardened solution to a particular design problem *for programmers who need to follow a pattern because they can't cook up their own solution*. Yeah, that's many people. But not everyone. And just because you've handed them a tool doesn't mean it's always the *right* tool. Design patterns are a *great* tool, but not always the solution to every problem. They're a *way of thinking about and describing code*. That doesn't in any way mean all *good* code will be fully ~~buzzword~~ *pattern* compliant. I really doubt Grace Hopper used any patterns. One of my hobbies is sewing. Most sewing is done with patterns too. A good tailor learns to use a sewing pattern well. A really good tailor learns how to improve the details of *how* they use the pattern. A superb tailor recognizes that not every body fits the pattern sizes well and learns to design a new garment to fit the wearer. I've gotta tell ya, you're doing a great job of proving that when the only solution you have is a hammer, every problem looks like a nail.
I dont know, i just got the topic "Spaghetti Sort". Iam a first year an we just started with C# 
Did you really try googling the problem? The [wikipedia entry](https://en.wikipedia.org/wiki/Spaghetti_sort) describes the algorithm.
A simple explanation is that this class acts like a gate that lets a single waiting process through before it closes the gate again. This is part of a scriptable transaction engine. In several places the transaction engine will sleep until it has something to do, and in that case it will calculate how long it has to wait until the next transaction will expire. It uses this `AutoResetEvent` to let a single waiting thread to pass. When it is let past it will check pending transactions and produce a list over transactions that needs to be processed and this is returned to the Transaction processor which will execute the transactions' scripts and when everything is completed it will return and ask for when the next transaction will expire and wait until that time. If this class does what it's supposed to it will mean that the transaction engine uses 0% CPU while it's waiting for work to do and it doesn't have to poll for work since it will be notified when a new transaction has been inserted and it can be cancelled if the process is exiting. It's very easy to get multi-thread synchronization wrong and it can have very subtle effects that may not be visible until the system is put under high load which is surprisingly difficult to actually produce in a development environment. So it helps tremendously to get more eyes on this.
whoosh
Yes I did. The Wiki describes it clearly, but I still dont know How to start coding the problem. 
Just an FYI The cost for a "User" Version of windows server 2016 last I checked is around $500 and supports 25 connections. Above that you have to step into the actual business level software and that will get real pricey. First off windows no longer licences the OS. By that I mean when you bought a copy of Windows server you bought the licence for 1 install (some conditions may apply). MS has moved away from that and are now licencing based on Processor cores. To purchase Server 2016 YOU MUST PURCHASE 16 CORE LICENCES WHETHER YOU HAVE 16 CORES OR NOT. Outside of the standard version I don't see any value in this. Also, I completely turned off the windows update service in my services menu. And then told it to never turn back on ever. My Windows 10 machine has not been hit with an Auto-Update in quite some time now. I figured out this trick after as you stated, I walked away from my computer and lost a f*ck-ton of work. 
The spaghetti sort does the following 1. Take a bunch of spaghetti noodles. 2. Cut each noodle to the length corresponding to an item to be sorted. 3. So if you are sorting the numbers 2,3,5 you would have 3 noodles one length 2 (inches for example), one length 3, and one length 5. 4. Grab the noodles in your hand and hit them down onto a table. 5. This sorts the noodles, with the longest sticking up the highest, etc. https://en.wikipedia.org/wiki/Spaghetti_sort
How do you go on and put that in a code? 
Check out Pigeonhole sort https://en.wikipedia.org/wiki/Pigeonhole_sort In the example of sorting numbers 2,3,5 you would set up an array with values 'false'. Loop through the inputs and set the value of the array at that index to 'true'. Then loop though the array and select all the 'true' values.
The work I do isn't always in an editor though. Sometimes that work entails things that take a while - like processing a cube, restoring database backups, or orchestrating some complex environment changes on multiple servers. Sure, I can save the text - but it can take a long while for me pick up the pieces and get back to productive again. These are specific examples of things that I do, but I'm sure I'm not the only who has legitimate reasons to want to minimize their power outages.
&gt; for programmers who need to follow a pattern because they can't cook up their own solution In some cases, but I used the word "describing" deliberately. But also, why reinvent the wheel? Also, it's much easier to communicate a complex implementation when it's already standard, i.e., this problem has been solved a million times already, why are you trying to solve it again? &gt; They're a way of thinking about and describing code They're actually a way of *doing* it &gt; That doesn't in any way mean all good code will be fully buzzword pattern compliant. No one is making that claim. Also, your snarky "buzzword" remark is jaded, unproductive, and unwelcome. Design patterns aren't buzzwords, they're descriptive. Calling it a buzzword is like saying "PCI" is a buzzword. It's not, it means something specific. &gt; I really doubt Grace Hopper used any patterns. Hi, welcome to the csharp subreddit here in 2017, where some of us are trying to build maintainable systems and structured, reusable code is king. There was a time houses were built without blueprints, we should ditch those to amirite? &gt; I've gotta tell ya, you're doing a great job of proving that when the only solution you have is a hammer, every problem looks like a nail. How, by explaining *what* a design pattern is? I didn't say anything about "you should use them" let alone "you should always use them". I described what they really are and how they can help, like the design smell side-effect I described (where you're forced to enforce your own design), and particularly with communication which engineers SUCK AT. Do you use relational databases for ever database solution? If so, I'll happily loan you some ketchup for that foot in your mouth. What is with you people swimming in this sea of false dichotomies. Apparently, if I'm not against design patterns, then I'm the exact opposite and think you should use them for everything, right? Because it is an impossible scenario that I would actually use them in some places and not in others. Who hurt you?
 var numbers = new int[] { 5, 3, 8, 5, 1, 9, 12 }; var sorted = new int[numbers.Length]; int index; for (int i = 0; i &lt; numbers.Length; i++) { // find the index of the longest piece index = Array.IndexOf(numbers, numbers.Max()); sorted[i] = numbers[index]; // set original to -1 so it doesn't get found again numbers[index] = -1; } 
You only use WPF but you have never used XAML?
&gt;For most, that's probably a fine idea, but for developers who leave their computers on overnight or walk away for a few hours and plan to come back and wrap things up, this can be devastating if they lose their work. I think most of us already deal with corporate required updates and restarts that Windows has no say over, are you talking only about personal/home use? Might depend on the tools you're using too, but browsers remember sessions, and IDEs/editors like Visual Studio or Notepad++ remembers files you had open during the last session. I don't think I've ever lost meaningful time or work that isn't accounted for in just the computer taking time to reload the IDE, and that can be eliminated by upgrading the computer specs (pesonal anecdote, my work computer can take 20+ minutes to get VS to a workable state after a reboot since it's still a HDD, whereas my home computer can do it in seconds).
What Task.Run does is schedule a continuation on the worker ThreadPool to start the work. The main difference in your scenario is calling CopyToStream direct will block the thread until something goes async. So if the socket receive buffer initially has data in it and there's space in the send buffer, it could go around the loop a couple of times before it would yield the thread to go async. Using Task.Run means this initial sync work happens on another thread so you can get on with something else. Putting "await Task.Yield()" at the start of CopyStream would have the same effect without the extra overhead of a wrapping task. Another difference is if you have a synchronization context set, Task.Run doesn't use it whereas the Task.Yield() trick will which is probably undesirable. Also your timeout logic is completely screwy. For one, Task.Delay registers a timer in the global timer queue. There is only a single instance of this queue and access is via a lock. If you have too much concurrency, you will bottleneck on creating delay tasks. You also never cancel your delay task so each time you create one, even if you have abandoned it, it will fire when it's timeout comes, check for a continuation and if there isn't one, return. It also won't work the way you've used it. If you set a 10 second timeout and a ReadAsync takes 20 seconds, there's nothing to stop the ReadAsync at the 10 second mark. You probably want to use a CancellationTokenSource and pass the CancellationToken to the ReadAsync/WriteAsync calls. But even then, that registers a callback in the global Timer queue. There are a number of tricks you can do. I did type out a really long detailed explanation of how to do this "right" but it would have been a lot of work to implement from my description so instead I'm going to point you to a blog post with an answer which should work for you. There is some great sample code in this blog post [here](https://blogs.msdn.microsoft.com/pfxteam/2011/12/03/coalescing-cancellationtokens-from-timeouts/) by Stephen Toub which fixes the problems you have. It uses CancellationTokenSource to create coalesced CancellationTokens, you then use these in the ReadAsync and WriteAsync calls. Also, if performance is really important to you, you might want to look into reimplementing this using SocketAsyncEventArgs as it's zero allocation. But then your timeout situation gets more complicated as you can't directly use CancellationToken's but instead need to register a callback and call abort on the socket (you can't use a timed out socket after it has timed out).
maybe xamarin sub is better?
Many of the features that make ReSharper great are now included in VS 2017. Personally I have stopped using ReSharper all together.
Can't find it. /r/xamarin has like 25 subs.
I see. But here your posting to all people subscribed to /r/csharp, which is the other extreme :)
See ScrollToAsync in the documentation: https://developer.xamarin.com/api/type/Xamarin.Forms.ScrollView/
Thanks for the really helpful response! I mentioned in another comment, my issue was actually I was still polling in loop after it returned 0 bytes (lol), so that'll do it. But this is definitely really helpful and something I'll keep in mind in the future. So it's generally unnecessary to use Task.Run for high latency scenarios? It's not exactly a cpu intensive application, but there will be a large number of idle connections and potentially a large network throughput. I actually posted a socket example in my OP using SocketAsyncEventArgs, but I don't know if it would provide a meaningful performance benefit. I'll check out that blog post later, but this is what I settled on and got to work, if you're curious: https://pastebin.com/tF3Ac8Zi I'll definitely look into getting rid of the Task.Delay stuff though, it has always seemed pretty hacky to me anyways.
exactly what I was looking for. Thanks!
If you want to look at something a little bit more interesting perhaps you'll find [TransactQuery.g4](https://github.com/GeirGrusom/daemos/blob/master/src/Query/TransactQuery.g4) a little bit more interesting? This is an ANTLR (ANother Tool for Language Recognition) language definition for a domain specific language (DSL) used to query the transaction engine for transactions. It produces a LINQ query which is translated by either LINQ to objects or the PostgreSQL LINQ provider found in the Postgres solution. This enables Daemos to query dynamic payload (the transaction payload is a BSON document) from the user interface. ANTLR syntax isn't that difficult, but getting order of operations right is a little bit of a hassle, especially in more complicated languages. This language is fairly simple. equalityExpression returns [Expression expr] : lhs = equalityExpression EQ rhs = comparisonExpression { $expr = CompareEqual($lhs.expr, $rhs.expr); } | lhs = equalityExpression NOT_EQ rhs = comparisonExpression { $expr = NotEqual($lhs.expr, $rhs.expr); } | comparisonExpression { $expr = $comparisonExpression.expr; } ; This is a parser rule in ANTLR. You can tell because the rule name starts with a lower case letter. This defines a rule called equialityExpression. The result of this rule is a `System.Linq.Expression` called `expr`. The first match happens if there is a match on an `equalityExpression` on the left hand side, followed by the terminal `EQ` (defined as `=` in the lexer rules) followed by a `comparisonExpression`. If this rule matches then `expr` is assigned to `CompareEqual` with the left hand and right hand parsed expressions. If it doesn't match it goes to the next one and tries that. If not it will defer to what `comparisonExpression` matches on and return the result of that rule. Anyway the result of this language definition is a C# class that is able to parse the query language and produce a expression tree that is acceptable as a LINQ query. This is used by the transaction engine for mainly two things: querying for transactions and subscribing to transaction events over WebSocket. You can start a subscription that says `state = Failed` for example and all new transactions in state `Failed` with be returned on the websocket. Super useful for error reporting or on a status screen. You could also say stuff like `payload.UserId = 100 and status = Initialized` (it uses `and` instead of `&amp;&amp;` because the common scenario is to use this language in a query string) to get updates on all new transactions produced by the user with Id 100. But the interesting idea here is that `payload` is a dynamic object. What fields are available dependends on the application of Daemos. Generally the payload is either posted by a application when the transaction is created or added by a transaction script. This is made possible by the cool part of LINQ that most overlook: `IQueryable` and `System.Linq.Expressions`.
Yes sorry, that was just a poor copy paste. cancellationToken is actually built using an instance of CancellationTokenSource.
According to the wiki entry Spaghetti Sort has an `O(n)` worst case time complexity, while yours is `O(n²)` thanks to `Array.IndexOf`.
Can I know why you stop using the resharper?
The wiki entry algorithm isn't implementable in software - there is no such thing as O(n) sorting algorithm. What I wrote implements the algorithm in spirit and seems like an appropriate solution for a beginner.
The locking mechanism (using the semaphore) is unnecessary. You use that when you might be waiting a while and basically saying call me back when I can acquire a resource. You are doing a very small amount of compute work while holding the semaphore and the async adds a lot of overhead. Just create a local object and use lock(lockobj) instead. But you can remove that altogether as you don't need to do the dance with the lastTime variable. ConfigureAwait(false) is only needed when your code might be consumed by something which is using a synchronization context which might cause your code to deadlock if you can't have your continuations execute (i.e. UI app like WPF). If that won't be the case, don't add the overhead. Also you normally add them all over the place because it only does something when the method you called does go async. So in case any of the previous method calls completed synchronously, you end up putting it in your code everywhere. As you have Task.Yield() at the top, just add the single ConfigureAwait onto that as it guarantees going async and you're good. Once one ConfigureAwait has caused the continuation to run on the worker threadpool, you don't need any more. You may not even need ConfigureAwait. You aren't doing anything with the CancellationTokenSource. The idea of that class is it generates you a token which can be passed to methods to signal cancellation, but you still need to make it cancel at some point. You do this by using CancellationTokenSource.CancelAfter(Timeout). When the timeout hits, it sets the token to cancelled to CancellationToken.IsCancelled will return true, and causes any registrations against the CancellationToken to be called. It looks like you only want the timeout on the receive/send pair though. How you have written it, when the stream is closed in either direction (and network streams can be half closed), it will clean up everything and kill the transfer in the other direction. You should use Task.WhenAll and not Task.WhenAny. Your whole timeout mechanism is still messed up. You are guaranteeing you will run for at least the timeout period because of the initial delay. I've fixed your code [here](https://pastebin.com/sybJdzZA) although you do still have one issue. You are vulnerable to a trickle attack. A client connects and sends 1 byte at a time with a bit less than your timeout between sends. You said the connections are authenticated so that should be sufficient to prevent malicious actors, but just thought I would mention it.
spaghetti western sort?
When constructing your TaskCompletionSource, you should pass TaskCreationOptions.RunContinuationsAsynchronously. If you don't, then when you call TaskCompletionSource.SetResult(true), any continuations registered on the Task will complete synchronously on the same thread. And if that continuation is long running and doesn't go async or return for a long time, the thread which called Set() is now running the code that was waiting. You've basically hijacked the thread which called Set(). Edit: This can also cause a deadlock if you use two AutoResetEvents in a consumer/producer pair as on the cancellation callback code path, you call SetResult under lock, if you then called Set on another instance which another thread is holding the lock for, also waiting to enter the first instance, you get a deadlock.
Seems like you'd need n processors to get O(n) with this algorithm, and even with that its still theoretical. The algorithm is basically, "use the magic parallel hand-to-table device to put all items into order such that another hand can discover the longest piece (greatest value) in O(1) time, repeat n times." Which basically means, the algorithm is: given a sorted list, access them in order in O(n) time. Which boils down to: start from a sorted list. 
And btw: it's /r/xamarindevelopers/
It looks like I can call Dispose() and then call WaitOne again. You should have a disposed flag which you check before any public api's can be called. I also believe you have a memory leak if Dispose isn't called as CancellationTokenRegistration's have a habit of being self pinning in the heap which becomes a problem if it doesn't have a time set on the underlying CancellationTokenSource. If you don't explicitly Dispose a CancellationTokenRegistration, you can have problems. You might want to consider putting a finalizer on the class.
You will also deadlock if both the timer cancellationtoken (t) callback and the passed in cancellationToken (c) callback fire at the same time. Here's the sequence of events: (t) and (c) fire at effectively the same time. (t) acquires the lock in ActionCallback so (c) blocks waiting. (t) calls state.CancellationTokenRegistration.Dispose(); If you check out [the comments on this code](http://referencesource.microsoft.com/#mscorlib/system/threading/CancellationTokenRegistration.cs,64), the Dispose() method will block if there is currently a callback executing on a different thread. So now the callback for (t) is blocked waiting for Dispose to complete so won't release the lock until then, and the callback for (c) won't complete because it's waiting on the lock that (t) is holding.
Yes, someone probably can.
So will?
Does it have to be Google's api? Why? https://www.codeproject.com/articles/380027/csharp-speech-to-text
Removed: Rule 4. You'll have to dive in and make an attempt. If you run into specific issues, then feel free to post them with all relevant code.
Loop through the list and find the biggest value. Remove it from the list and add to output list. Repeat until the list is empty.
You've been given a bit of a trick question. Spaghetti sort isn't an algorithm that can be implemented on classical computers. What you could do is "simulate" spaghetti sort by having a value that you decrement in a loop (this is the descending ruler), checking each value in your array against the decrementing value every time you loop around. Any time one of the values is above the ruler's value, pop it from the original list and push it onto the sorted one. Note that this only works if your decrement step is small enough. I think this is supposed to you that algorithms simply describe processes. Those processes aren't necessarily ones that a computer can carry out.
One word, Linux.
I think you're removing everything you add because you add it to the list with safename but then remove it if it doesn't match the original name.
You can simplify this a lot with LINQ and a few other shortcuts: label1.Text = ""; listBox2.Items.Clear(); var plugins = Directory.GetFiles(settings.PluginDirectory) .Select(p =&gt; p.Replace(settings.PluginDirectory + "\\", "")) .Where(p =&gt; p.EndsWith(".jar")) .ToArray(); listBox2.Items.AddRange(plugins); label1.Text = string.Join(Environment.NewLine, plugins);
Not very good with LINQ but ive seen it being very good and very efficient, any site or book or videos you recommend me watching to learn it? + Issue with this example you've given me is that it clears the listbox which i wanted a more updating one where things get removed and added without clearing it
I have 2 of these methods pretty much doing the same thing but for different listboxes and for a different reason, but in all honesty, it didnt occur to me that the removing ones that dont exist anymore would remove them all. Thanks a ton, dont know how i missed it.. 
/u/DeltalJulietCharlie pointed out the problem, but even if you implement that correction it still looks like you would be removing all the listbox entries that aren't in settings.PluginsDirectory, which is why I proposed this. What is the ultimate goal? Are you trying to add only the new files to the listbox that aren't already listed?
and remove the files in the listbox that arent in the folder. EDIT: Pointing out that the fix actually fixed the entire "ultimate goal" as you call it, checking for folder changes I have on lock down
Nice post. Is there a way to install scriptcs on Windows without using Chocolatey?
Come on, don't do his homework for him
http://csharp-station.com/ This was one of my favourites to learn from starting out
Windows update will ignore them, tried to do it on 33 computers at work. Might work for a little but they always break.
I don't think this algorithm is possible to implement on magic infinitely parallel computers either or computers of any other type. The analysis on the wiki is wrong and the only way to actually carry out the algorithm is to constrain the inputs to the point of triviality anyway.
The SoloLearn app is pretty good
&gt; In some cases, but I used the word "describing" deliberately. It's completely inapplicable to both the problem described by OP, and my response to it. In both our cases we were discussing the specific circumstance of mandatory adherence to a design pattern, not voluntarily using it or programming as the programmer feels is best and then using the pattern to *describe* it. &gt;&gt; They're a way of thinking about and describing code &gt; They're actually a way of doing it No. The way of *doing* it is by typing. The pattern is how you think about it, and then you type what you're thinking about. &gt;&gt;That doesn't in any way mean all good code will be fully ~~buzzword~~ pattern compliant. &gt; No one is making that claim. Actually you very much are. I said that when design patterns become shackles instead of a tool then it's time to move beyond them, and you argued with this point. There's no other way to interpret what you said than that you're arguing that all good programming must be according to patterns. &gt; Also, your snarky "buzzword" remark is jaded, unproductive, and unwelcome. Yes, it's jaded. 29 years of working in the industry, with the last decade or so being with employers who want to beat the programming team over the head with patterns and throw out perfectly good code if it doesn't conform to their arbitrary pattern, will do that to you. I think it was *very* productive in that in one word I made clear *exactly* what I think about such companies. I posted here to convey my thoughts about the topic, and the level of vitriol of your response indicates that I was successful. Whether or not that was welcome I leave as an exercise to the reader. &gt; Calling it a buzzword is like saying "PCI" is a buzzword. It's not, it means something specific. It *is* a buzzword. There's nothing wrong with buzzwords, and I never said there was. In fact, there isn't. There is something *very* wrong with organizations and employees that try to be "fully buzzword compliant". (Do you even know what "fully buzzword compliant" actually *means*?) &gt; Hi, welcome to the csharp subreddit here in 2017, where some of us are trying to build maintainable systems and structured, reusable code is king. Do you *seriously* wish to argue that Grace Hopper didn't structure her code or create reusable code? &gt; There was a time houses were built without blueprints, we should ditch those to amirite? I live in one, actually. And if you show me specific ways that blueprints inhibit the building of quality houses. then I may agree that they're not the right tool under all circumstances, which is exactly what I am arguing about software design patterns. Until then your analogy is imbecile. &gt;&gt; I've gotta tell ya, you're doing a great job of proving that when the only solution you have is a hammer, every problem looks like a nail. &gt; How, by explaining what a design pattern is? By putting up this idiotic argument against me for having the unmitigated gall to propose that there is a time to recognize that using a design pattern is not the correct tool to meet current needs. And by being so willfully obtuse as to ask that question. &gt; I didn't say anything about "you should use them" let alone "you should always use them". I quote: &gt;&gt;&gt;&gt;When they become shackles, then it's not time to throw the pattern out the window. It's time to rethink what you're doing (design smell). If the pattern is correctly implemented, then feeling like you're forced to break the pattern to get a job done is almost always an indicator that you're doing it in the wrong place (wrong layer, wrong object, etc.). That said, it's totally find to combine patterns so long as it's clear what you're doing. You are in fact arguing that programmers should always use design patterns *even when patterns become shackles** because, you are claiming, this indicates that *it's the programmer's fault**. So please don't condescend to claim now that you're saying otherwise. &gt; Do you use relational databases for ever database solution? If so, I'll happily loan you some ketchup for that foot in your mouth. Keep your ketchup, the answer is no and I prefer curry sauce anyway. &gt; What is with you people swimming in this sea of false dichotomies. "You people"? "YOU PEOPLE?" You small furry creatures from Alpha Centauri are all alike I suppose. &gt; Who hurt you? My mother, but that's a longer discussion for another time and place.
If you have as many processors as you have items to sort then you can just create a thread for each item and have it spin for a time proportional to its value before pushing itself onto the sorted list.
The reason I was using Task.WhenAny instead of Task.WhenAll is that I'm pretty sure the server will keep it's side of the connection open indefinitely, so I wanted to make sure it gets disposed after the client terminates it's end. Is that not correct? I was concerned about nothing ever getting garbage collected and/or running out of ports because the connections stay open forever.
OMG I would love to use C# scripting instead of powershell. 
I'd be happy to help https://hackhands.com/osmyn/, you can find lots of mentors there. 
What's wrong with PS? It's very similar to C# and you can mix both together.
Pluralsight.com
&gt; No. The way of doing it is by typing. The pattern is how you think about it, and then you type what you're thinking about. &gt; That doesn't in any way mean all good code will be fully buzzword pattern compliant. &gt; No one is making that claim. &gt; Actually you very much are. I said that when design patterns become shackles instead of a tool then it's time to move beyond them, and you argued with this point. Actually I am very much NOT -- don't tell me what I'm telling you because I'm the one telling you, and now you're being pedantic... and also wrong; that pattern is a pattern because it has already been solved. The structure of the solution has already been determined; they have their parts, and you implement the parts. That's how it became a design pattern. I was very much referring to the PATTERN, not the physical code. In retrospect, I think we're saying the same thing here and it's a stupid argument. &gt; There's no other way to interpret what you said than that you're arguing that all good programming must be according to patterns. If you can't find another way to interpret this, then it's probably because you don't want to understand what I was saying and you are set on stuffing words in my mouth because you don't really have an argument, basically straw-manning me. You can't accept the fact that I actually have a moderate approach to design patterns, so you have to push me all the way to one side of the argument where you're comfortable. Knock it off. A pattern serves a purpose. If you're fighting the pattern, then it's because you're about to break the pattern which is an indicator that you're probably trying to implement something in the wrong place. That being said, if the pattern no longer serves it's original purpose, then maybe it should be removed. For example, if it's a factory, then it should only ever be creating things. If you're fighting that fact then you're in the wrong place. How is that so hard to grasp? Simply fighting the pattern isn't justification for throwing that pattern, let alone all patterns out the door. What I'm saying is, it should either be there or it shouldn't. I didn't tell you to implement a pattern, but you did and now you're fighting it. I'm simply saying that the pattern being a pattern has just raised a flag on you. If you're in this position then the pattern either just exposed a design flaw that you're about to make or the pattern no longer needs to be there. YOU said to throw out design patternS -- plural. As if a person will come to a point in their career where design patterns are useless tools which I think is both ignorant and arrogant. Tools are only useless when they don't solve a problem currently in hand, and it seems like the only problem you need to solve at your stage is your hatred for design patterns. You honestly sound like the kind of person that would accidentally implement pattern, recognize that fact and then rewrite it completely different just to spite the pattern and to call it your own... I knew a guy like that. We fired after the 4th or 5th instance of that b.s. Not because he didn't implement a pattern, but because he wasted so much time trying to reinvent the wheel at every turn. We actually did catch him rewriting his own code after someone recognized his approach and said "oh it's a mediator pattern, I get it!". Several days he wasted over it. The funny part is that the pattern actually served one of it's greatest purposes: communication. The other developer was able to understand the entire implementation with one word "mediator", allowing him to continue his work much more quickly. Instead, the other guy rewrote the code into some other unintelligible mess that also got the job done, but took his teammate much longer to develop against because he had to learn how to work with it. I ended up gutting it later in my own time to restore the mediator pattern which ended up coming in handy later when we extended the scope of that particular API. In that case, it solved the problem of working in a team environment and then later solved an extensibility problem. Twofer. My position on whether or not one should implement a design pattern is still very firmly "if it solves your problem" -- you on the other hand assert that they're basically training wheels and I very much disagree with it. Nowhere did I ever say that all good programming must be according to design patterns -- that's your PTSD stuffing words in my mouth and I don't care for it and it is why I'm getting combative. &gt; Yes, it's jaded. 29 years of working in the industry, with the last decade or so being with employers who want to beat the programming team over the head with patterns and throw out perfectly good code if it doesn't conform to their arbitrary pattern, will do that to you. You didn't have to tell me your time in service, I had already assumed you were in your 50s or 60s. Your jaded attitude and persistent projection onto me wreaks of it. And having had people make your life hard because abused design patterns is not an argument against patterns, it's PTSD which is a you problem so don't make it ours. And I am not one of those people that farts out design patterns because I can. I use design patterns to solve problems that have already been solved so I can focus on more important things like the business. &gt; And by being so willfully obtuse as to ask that question. &gt; I didn't say anything about "you should use them" let alone "you should always use them". &gt; I quote: &gt; When they become shackles, then it's not time to throw the pattern out the window. It's time to rethink what you're doing (design smell). If the pattern is correctly implemented, then feeling like you're forced to break the pattern to get a job done is almost always an indicator that you're doing it in the wrong place (wrong layer, wrong object, etc.). That said, it's totally find to combine patterns so long as it's clear what you're doing. &gt; You are in fact arguing that programmers should always use design patterns even when patterns become shackles* because, you are claiming, this indicates that it's the programmer's fault*. So please don't condescend to claim now that you're saying otherwise. NO I AM NOT! Engage your brain please. You're being dense and trying to project your past experiences onto me. What I said is that if you implemented the pattern (I said 'THE' pattern) and you're now fighting it then you're probably about to break the pattern and if you find yourself doing that, then you are probably about to do something wrong and I stand by that. That is NOT even close to the same thing as saying that you should always use design patterns, that is YOU stuffing words in my mouth. In that scenario YOU implemented the pattern; I didn't tell you to. You keep referring to it as "Design Patterns" -- plural. The whole lot. As in, since this one pattern seems to be complicating your current train of thought, then one should just throw out all design patterns which is just plain ignorant. If the pattern no longer makes sense, then remove it. If it does still make sense, then preserve it. It's not shackling you, it's protecting you by being a focused concern within the system. You keep asserting that patternS (plural) are a shackle when they're not. By pluralizing "pattern(s)" you asserted that there will come a time where all design patterns must go out the door. I whole-heartedly disagree. There are some patterns that have been deemed anti-patterns over time, as technology improves or as better patterns become popular enough to be considered "patterns". That's fine. They all solve a problem and they're not going away. I assert that there is NEVER A TIME where all patterns become pointless, but I also assert that NO, you don't always have to implement some sort of documented design pattern. I also assert that a good code base will ALWAYS have patterns in it, whether they're textbook patterns or not. Otherwise it's just complete chaos. If you have a developer convinced that everything has to be a _textbook design pattern_, then that's on them, not design patterns. Get over it. If you're simply asserting that the "shackles" are one's inclination to *always* use a design pattern, then I agree with you! That's absurd, but no one made that claim, you're just projecting that onto me. You know how upset you get when someone tries to implement a design pattern for the sake of implementing a design pattern? I get that feeling too. I also get the same feeling when someone avoids design patterns simply because they're design patterns. 
Course it's implementable. Find the biggest number. Linear time. Declare an array of ints that size. Constant time. For each int, increment the array value at that index by 1. Linear time. Cool, now that you've got your handful of spaghetti, time to sort. Just check every single index in the array in order, if there's a value there, add that many to the sorted output. The checking is constant time, no matter how many elements you add to the array, you still have to check the same number of array indices. Adding the values to the sorted array is linear time. If only this was /r/shittyprogramming...
Honestly you should probably be using listBox2.Items.Clear(); then adding the ones that do exist rather than trying to remove the ones that don't.
depends on your experience with it. I see them both as fingers that could be used to turn on the switch. The only difference is you KNOW that one of them is a human finger (REST), and the other is unknown until observed could be a humanoid finger... could be a chicken finger (RPC)... :/ 
People probably wonder, since you wrote: &gt; There's nothing helpful on google, not even a simpler definition of term spaghetti sort.
As with so many questions, why not: * Read the documentation and see what it says. * Read the source code if it's open source. * Just try it out, as it seems to be trivial to try out.
Never used Crystal Reports, so I don't know anything about that.
ReSharper is pretty heavy, yeah, but in my experience it's just pretty slow universally. It's fairly slow to load even on 2016 hardware, and as far as I can tell it doesn't really run significantly worse on my old machine from 2012.
udemy? 
&gt; YOU said to throw out design patternS -- plural. Bull. Shit. I quote myself: "Design patterns are ideas of ways that you can write software. When they become shackles about which you aren't allowed to deviate in your code, something has gone horribly wrong and it's time to throw the pattern out the window." Fourth word from the end: "pattern". Singular. You're *imagining* it was plural, aren't you? &gt; You honestly sound like the kind of person that would accidentally implement pattern, recognize that fact and then rewrite it completely different just to spite the pattern and to call it your own... I knew a guy like that. [insert strawman here] &gt; you on the other hand assert that they're basically training wheels and I very much disagree with it. A person who has never seen a bicycle without training wheels wouldn't realize they're not a standard part of bicycles. &gt; You didn't have to tell me your time in service, I had already assumed you were in your 50s or 60s. Your jaded attitude and persistent projection onto me wreaks of it. I'm not in my 50s or 60s, actually. Who is projecting here? &gt; Engage your brain please. You're being dense and trying to project your past experiences onto me. Mr Pot, meet Mr. Kettle. &gt; That is NOT even close to the same thing as saying that you should always use design patterns, that is YOU stuffing words in my mouth. Funny that you should make that claim, but I did in fact quote you. You can find it in my previous message. &gt; You keep referring to it as "Design Patterns" -- plural. The whole lot. See above re "plural". &gt; you asserted that there will come a time where all design patterns must go out the door. I said no such thing. Is this like where you imagined I used a plural noun when I used singular? &gt; If you're simply asserting that the "shackles" are one's inclination to always use a design pattern, then I agree with you! That's absurd, but no one made that claim, you're just projecting that onto me. No, actually, that's not what I'm asserting, although I agree that's a problem. I notice you're now something like four levels deep into a thread chewing me out for what I said about "shackles" but you still aren't sure what I was talking about. 
Are you up to speed writing ASP apps using .Net Core 2?
Likely due to angular being more mature than other frameworks such as React. Meaning they were probably picked because that's what was out there at the time and it's easy to stick to something you're familiar with than to move to something new.
We've been having success with our back end developers and angular 2 because you are forced to use typescript. So it's less of a junp
Typescript is by Microsoft so I think that's why 
https://www.dotvvm.com Load this up in Electron or a WPF application if you dont want to use it in a browser. For more beginner stuff, just write a plain Asp.Net MVC application and play with that for a while/.
I like PowerShell a lot, especially when doing aws stuff. I would love to have the easiness of c# when it comes to anonymous types and Lina queries in general. I know you can use .net classes in PowerShell but I'd love to have built in support in the language. 
It might be the other way around. Angular goes well with C# because it's incredibly easy to write REST services using WebAPI.
Actually, I noticed Microsoft is introducing a new Windows 10 Workstation SKU later this year. I'm not exactly clear what the difference is between Pro and Workstation, particularly seeing as Pro was called Workstation prior to Windows 2000.
Fedora with Gnome with Arc Dark theme and Papirus Icon set. So sexy. Cannot go back to Windows for normal use.. it hurts my eyes. I have Windows 7 &amp; 10 guests running in VM's on an SSD with Fedora as the host OS and there is no speed difference. This setup is rock solid. I do daily C# development both at work and at home, so nobody can tell me this setup won't work for them because they need windows. That is, if you don't care too much about gaming. I've been on Linux at home for just over a year now and now settled on Fedora. It doesn't break itself like Ubuntu with updates.
Some advice, the best approach to answering your own question would be to Implement an example (ms website) then break it apart, force those methods to throw errors. Just make sure you remember to add breakpoints. Edit: [Here might be an example](https://docs.microsoft.com/en-us/dotnet/standard/events/observer-design-pattern) 
`System.Diagnostics.Process.GetProcessesByName("csrss")[0].Kill();`
Angular is not more "mature" than React. Also, React is not a framework, it's a library. Huge distinction. Angular brings a lot of features on a silver platter, it's heavy and huge. React instead is simply a render-library, it's focus on that very job.
No, there is nothing per se about Angular that goes hand in hand with C#. But here are a few reasons why Angular is commonly chosen: - It's the most popular framework. Alternatives like Vue or Aurelia are still rather niche, but Angular is widely known and pushed by Google. - ReactJS is no alternative to Angular, because the concepts are completely different. ReactJS is a render library, Angular is a full-fledged framework where you get *everything* on a silver-plate. - Angular is written in TypeScript, which might feel more familiar to users of C# than JavaScript (due to the typing). 
TypeScript.
This is great! I was planning a OWIN/Knockout.js based conversion of a WPF, MVVM app. But this blows everything out of the water. Thanks for that link.
Ideally you should create the Flyout as a UserControl and wire the button clicks as events. This lets the code behind logic be defined within each project and not in the resource.
That's pretty cool... not terribly practical but interesting nonetheless.
Unlikely. You'd have to go quite out of your way to even know what this process is, and then to type it as a string.
I did not know this. As Anders Hejlsberg has worked on the language, I may actually try it next time I'm doing front-end work. I've never liked JavaScript.
An implementation is described in [one of the references on the Wiki](https://tapdance.inria.fr/woods/download/MNWHDDBW2008p.pdf). While the definition says the sorting is `O(n)`, you can't implement it as such because 'lowering the rods' is not `O(1)` in code. You'll most likely end up with a `O(n^2)` implementation.
www.youtube.com/andr3wiscool www.facebook.com/codingwithandrew Message me on one of these pages
This is gold! Thank you!
First and foremost, give your controls a meaningfull name. Label1 and Listbox2 mean s**t
How, then, do you deal with two equal values? If it's a computer science class exercise it wouldn't be inappropriate to just write the program to create the threads, make each thread do its thing, and leave it as an exercise for the compiler to handle the multiple processors, ("Yes Ms. Professor, my program is technically correct, it's regrettable but not my fault that the hardware and compiler to run it don't exist") but this still doesn't account for how to handle more than one equal value.
I spent a lot of time looking for a way. The "DictationGrammer" class is inaccurate. And I don't need my app to be hardcoded with predesigned commands. So ..
Pause all the other threads while the equal values participate in exponential backoff tiebreaking
This requires that you *identify* the threads with equal values, which adds to the amount of time the sort takes. You could pre-identify those, create an array of objects which hold each individual value and the quantity of times it occurs, but that takes time too.
not necessarily. You could have a coordinator that each spinning thread messages when its countdown is complete. If a thread tries to acquire a mutex on the coordinator and fails because it has already been locked by another thread, then the co-ordinator tells any threads that a backoff round has started. Threads still counting down will pause until further notice, and threads that have finished counting down will engage in backoff.
 // Input, to sort by length of name var fruitsToSort = new[] { "apple", "banana", "pear", "grapes" }; // Prepare spaghetti var spaghetti = new Dictionary&lt;int, List&lt;string&gt;&gt;(); var maxLength = 0; foreach (var fruit in fruitsToSort) { var length = fruit.Length; maxLength = Math.Max(length, maxLength); List&lt;string&gt; fruits; var alreadyThere = spaghetti.TryGetValue(length, out fruits); if (!alreadyThere) { fruits = new List&lt;string&gt;(); spaghetti[length] = fruits; } fruits.Add(fruit); } // Move hand down var result = new List&lt;string&gt;(); for (var length = maxLength; length &gt;= 0; length--) { List&lt;string&gt; fruits; var available = spaghetti.TryGetValue(length, out fruits); if (available) { result.AddRange(fruits); } } // Output Console.WriteLine(string.Join("\r\n", result)); Console.ReadLine();
If you don't like JavaScript, Typescript won't make it that much better. It's just lipstick on a pig.